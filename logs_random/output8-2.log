


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.0 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization no --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 45.64it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.998627351747188
highest_index [0]
highest [0.998627351747188]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 0.964125394821167 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.8715828657150269 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.8575195670127869 for ['[CLS]ify board [SEP]']
[Init] best rec loss: 0.845018744468689 for ['[CLS] tolerance receiving [SEP]']
[Init] best rec loss: 0.8343009948730469 for ['[CLS] panel officer [SEP]']
[Init] best perm rec loss: 0.829422116279602 for ['[CLS] officer panel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.389 (perp=11.087, rec=0.161, cos=0.011), tot_loss_proj:2.644 [t=0.31s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 100/2000] tot_loss=2.294 (perp=11.087, rec=0.073, cos=0.003), tot_loss_proj:2.661 [t=0.30s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 150/2000] tot_loss=2.292 (perp=11.087, rec=0.072, cos=0.003), tot_loss_proj:2.664 [t=0.31s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 200/2000] tot_loss=2.281 (perp=11.087, rec=0.061, cos=0.003), tot_loss_proj:2.666 [t=0.30s]
prediction: ['[CLS] disappointed slightly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.119 (perp=10.251, rec=0.066, cos=0.003), tot_loss_proj:2.115 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.127 (perp=10.251, rec=0.074, cos=0.003), tot_loss_proj:2.127 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.118 (perp=10.251, rec=0.065, cos=0.003), tot_loss_proj:2.119 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.119 (perp=10.251, rec=0.066, cos=0.003), tot_loss_proj:2.117 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.118 (perp=10.251, rec=0.065, cos=0.003), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.119 (perp=10.251, rec=0.066, cos=0.003), tot_loss_proj:2.127 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.120 (perp=10.251, rec=0.067, cos=0.003), tot_loss_proj:2.116 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.115 (perp=10.251, rec=0.062, cos=0.003), tot_loss_proj:2.125 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.101 (perp=10.251, rec=0.048, cos=0.003), tot_loss_proj:2.120 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.122 (perp=10.251, rec=0.069, cos=0.003), tot_loss_proj:2.115 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.121 (perp=10.251, rec=0.068, cos=0.003), tot_loss_proj:2.118 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.121 (perp=10.251, rec=0.068, cos=0.003), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.108 (perp=10.251, rec=0.055, cos=0.003), tot_loss_proj:2.122 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.109 (perp=10.251, rec=0.056, cos=0.003), tot_loss_proj:2.128 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.112 (perp=10.251, rec=0.059, cos=0.003), tot_loss_proj:2.122 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.117 (perp=10.251, rec=0.064, cos=0.003), tot_loss_proj:2.130 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.109 (perp=10.251, rec=0.056, cos=0.003), tot_loss_proj:2.132 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.114 (perp=10.251, rec=0.061, cos=0.003), tot_loss_proj:2.131 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.111 (perp=10.251, rec=0.058, cos=0.003), tot_loss_proj:2.124 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.113 (perp=10.251, rec=0.060, cos=0.003), tot_loss_proj:2.122 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.114 (perp=10.251, rec=0.061, cos=0.003), tot_loss_proj:2.119 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.102 (perp=10.251, rec=0.049, cos=0.003), tot_loss_proj:2.118 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.107 (perp=10.251, rec=0.054, cos=0.003), tot_loss_proj:2.121 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.098 (perp=10.251, rec=0.046, cos=0.003), tot_loss_proj:2.131 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.121 (perp=10.251, rec=0.068, cos=0.003), tot_loss_proj:2.125 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.118 (perp=10.251, rec=0.065, cos=0.003), tot_loss_proj:2.124 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.107 (perp=10.251, rec=0.054, cos=0.003), tot_loss_proj:2.128 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.107 (perp=10.251, rec=0.054, cos=0.003), tot_loss_proj:2.119 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.115 (perp=10.251, rec=0.062, cos=0.003), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.107 (perp=10.251, rec=0.054, cos=0.003), tot_loss_proj:2.124 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.122 (perp=10.251, rec=0.069, cos=0.003), tot_loss_proj:2.119 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.113 (perp=10.251, rec=0.060, cos=0.003), tot_loss_proj:2.117 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.108 (perp=10.251, rec=0.056, cos=0.003), tot_loss_proj:2.117 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.115 (perp=10.251, rec=0.062, cos=0.003), tot_loss_proj:2.123 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.112 (perp=10.251, rec=0.059, cos=0.003), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.106 (perp=10.251, rec=0.053, cos=0.003), tot_loss_proj:2.126 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:12:10 | total time: 0:12:10


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9989001564762949
highest_index [0]
highest [0.9989001564762949]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 0.9889597296714783 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9681109189987183 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.9014642238616943 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8706889152526855 for ['[CLS] martialmoral [SEP]']
[Init] best rec loss: 0.8680779933929443 for ['[CLS] course characters [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.279 (perp=10.543, rec=0.167, cos=0.003), tot_loss_proj:2.395 [t=0.30s]
prediction: ['[CLS] splendid splendid [SEP]']
[ 100/2000] tot_loss=2.155 (perp=10.288, rec=0.095, cos=0.002), tot_loss_proj:2.298 [t=0.30s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.110 (perp=10.288, rec=0.050, cos=0.002), tot_loss_proj:2.292 [t=0.31s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.130 (perp=10.288, rec=0.070, cos=0.002), tot_loss_proj:2.291 [t=0.31s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.892 (perp=9.171, rec=0.056, cos=0.002), tot_loss_proj:1.896 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.897 (perp=9.171, rec=0.060, cos=0.002), tot_loss_proj:1.897 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.905 (perp=9.171, rec=0.068, cos=0.002), tot_loss_proj:1.893 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.002), tot_loss_proj:1.888 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.906 (perp=9.171, rec=0.069, cos=0.002), tot_loss_proj:1.889 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.911 (perp=9.171, rec=0.074, cos=0.002), tot_loss_proj:1.903 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.875 (perp=9.171, rec=0.039, cos=0.002), tot_loss_proj:1.900 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.002), tot_loss_proj:1.903 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.002), tot_loss_proj:1.899 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.897 (perp=9.171, rec=0.060, cos=0.002), tot_loss_proj:1.902 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.892 (perp=9.171, rec=0.055, cos=0.002), tot_loss_proj:1.896 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.902 (perp=9.171, rec=0.066, cos=0.002), tot_loss_proj:1.899 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.907 (perp=9.171, rec=0.070, cos=0.002), tot_loss_proj:1.909 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.898 (perp=9.171, rec=0.061, cos=0.002), tot_loss_proj:1.902 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.899 (perp=9.171, rec=0.063, cos=0.002), tot_loss_proj:1.893 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.002), tot_loss_proj:1.905 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.889 (perp=9.171, rec=0.052, cos=0.002), tot_loss_proj:1.898 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.884 (perp=9.171, rec=0.048, cos=0.002), tot_loss_proj:1.903 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.888 (perp=9.171, rec=0.052, cos=0.002), tot_loss_proj:1.894 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.002), tot_loss_proj:1.900 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.887 (perp=9.171, rec=0.051, cos=0.002), tot_loss_proj:1.902 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.897 (perp=9.171, rec=0.060, cos=0.002), tot_loss_proj:1.904 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.885 (perp=9.171, rec=0.049, cos=0.002), tot_loss_proj:1.911 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.002), tot_loss_proj:1.911 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.892 (perp=9.171, rec=0.055, cos=0.002), tot_loss_proj:1.897 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.904 (perp=9.171, rec=0.068, cos=0.002), tot_loss_proj:1.900 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.901 (perp=9.171, rec=0.065, cos=0.002), tot_loss_proj:1.905 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.901 (perp=9.171, rec=0.065, cos=0.002), tot_loss_proj:1.905 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.882 (perp=9.171, rec=0.045, cos=0.002), tot_loss_proj:1.900 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.002), tot_loss_proj:1.909 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.888 (perp=9.171, rec=0.052, cos=0.002), tot_loss_proj:1.907 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.910 (perp=9.171, rec=0.073, cos=0.002), tot_loss_proj:1.904 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.901 (perp=9.171, rec=0.064, cos=0.002), tot_loss_proj:1.901 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.880 (perp=9.171, rec=0.044, cos=0.002), tot_loss_proj:1.907 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.002), tot_loss_proj:1.903 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.902 (perp=9.171, rec=0.065, cos=0.002), tot_loss_proj:1.897 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:12:07 | total time: 0:24:18


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9986840037027962
highest_index [0]
highest [0.9986840037027962]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.7663192749023438 for ['[CLS] wash〜 at [SEP]']
[Init] best perm rec loss: 0.7651610970497131 for ['[CLS] wash at〜 [SEP]']
[Init] best perm rec loss: 0.761218786239624 for ['[CLS]〜 wash at [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.702 (perp=10.181, rec=0.501, cos=0.165), tot_loss_proj:3.916 [t=0.30s]
prediction: ['[CLS] heavier ( humanities [SEP]']
[ 100/2000] tot_loss=2.960 (perp=12.034, rec=0.391, cos=0.162), tot_loss_proj:3.206 [t=0.31s]
prediction: ['[CLS] gain placing momentum [SEP]']
[ 150/2000] tot_loss=2.403 (perp=9.953, rec=0.324, cos=0.089), tot_loss_proj:2.675 [t=0.31s]
prediction: ['[CLS] gaining momentum much [SEP]']
[ 200/2000] tot_loss=2.363 (perp=9.502, rec=0.268, cos=0.195), tot_loss_proj:2.372 [t=0.31s]
prediction: ['[CLS] gaining momentum momentum [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.132 (perp=8.750, rec=0.246, cos=0.135), tot_loss_proj:2.179 [t=0.31s]
prediction: ['[CLS] momentum gaining momentum [SEP]']
[ 300/2000] tot_loss=2.364 (perp=10.038, rec=0.210, cos=0.146), tot_loss_proj:3.379 [t=0.31s]
prediction: ['[CLS] goats gaining momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.179 (perp=8.750, rec=0.312, cos=0.116), tot_loss_proj:2.174 [t=0.31s]
prediction: ['[CLS] momentum gaining momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.116 (perp=8.750, rec=0.253, cos=0.113), tot_loss_proj:2.187 [t=0.31s]
prediction: ['[CLS] momentum gaining momentum [SEP]']
[ 450/2000] tot_loss=2.115 (perp=8.750, rec=0.232, cos=0.133), tot_loss_proj:2.176 [t=0.31s]
prediction: ['[CLS] momentum gaining momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.111 (perp=8.750, rec=0.243, cos=0.118), tot_loss_proj:2.186 [t=0.31s]
prediction: ['[CLS] momentum gaining momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.542 (perp=10.954, rec=0.227, cos=0.125), tot_loss_proj:3.481 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
[ 600/2000] tot_loss=2.532 (perp=10.954, rec=0.220, cos=0.121), tot_loss_proj:3.471 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.527 (perp=10.954, rec=0.209, cos=0.126), tot_loss_proj:3.477 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.519 (perp=10.954, rec=0.199, cos=0.130), tot_loss_proj:3.474 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
[ 750/2000] tot_loss=2.549 (perp=10.954, rec=0.210, cos=0.148), tot_loss_proj:3.468 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.530 (perp=10.954, rec=0.200, cos=0.139), tot_loss_proj:3.465 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.538 (perp=10.954, rec=0.207, cos=0.141), tot_loss_proj:3.468 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
[ 900/2000] tot_loss=2.528 (perp=10.954, rec=0.197, cos=0.139), tot_loss_proj:3.466 [t=0.30s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.532 (perp=10.954, rec=0.204, cos=0.137), tot_loss_proj:3.471 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=2.533 (perp=10.954, rec=0.217, cos=0.124), tot_loss_proj:3.466 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
[1050/2000] tot_loss=2.533 (perp=10.954, rec=0.216, cos=0.126), tot_loss_proj:3.465 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=2.522 (perp=10.954, rec=0.198, cos=0.133), tot_loss_proj:3.462 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=2.534 (perp=10.954, rec=0.205, cos=0.138), tot_loss_proj:3.465 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
[1200/2000] tot_loss=2.533 (perp=10.954, rec=0.208, cos=0.134), tot_loss_proj:3.468 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=2.522 (perp=10.954, rec=0.203, cos=0.129), tot_loss_proj:3.459 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=2.520 (perp=10.954, rec=0.199, cos=0.131), tot_loss_proj:3.459 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
[1350/2000] tot_loss=2.523 (perp=10.954, rec=0.201, cos=0.131), tot_loss_proj:3.462 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=2.515 (perp=10.954, rec=0.194, cos=0.131), tot_loss_proj:3.460 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=2.512 (perp=10.954, rec=0.191, cos=0.131), tot_loss_proj:3.465 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
[1500/2000] tot_loss=2.523 (perp=10.954, rec=0.201, cos=0.132), tot_loss_proj:3.462 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=2.519 (perp=10.954, rec=0.197, cos=0.131), tot_loss_proj:3.458 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=2.539 (perp=10.954, rec=0.200, cos=0.148), tot_loss_proj:3.458 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
[1650/2000] tot_loss=2.527 (perp=10.954, rec=0.200, cos=0.136), tot_loss_proj:3.461 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=2.520 (perp=10.954, rec=0.197, cos=0.133), tot_loss_proj:3.466 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=2.515 (perp=10.954, rec=0.192, cos=0.132), tot_loss_proj:3.460 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
[1800/2000] tot_loss=2.519 (perp=10.954, rec=0.196, cos=0.132), tot_loss_proj:3.462 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=2.526 (perp=10.954, rec=0.203, cos=0.132), tot_loss_proj:3.455 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=2.523 (perp=10.954, rec=0.201, cos=0.131), tot_loss_proj:3.461 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
[1950/2000] tot_loss=2.526 (perp=10.954, rec=0.202, cos=0.132), tot_loss_proj:3.461 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=2.509 (perp=10.954, rec=0.186, cos=0.132), tot_loss_proj:3.462 [t=0.31s]
prediction: ['[CLS] blink gaining momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] blink gaining momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 105.000

[Aggregate metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 93.333 | p: 93.333 | r: 93.333
rougeLsum  | fm: 93.333 | p: 93.333 | r: 93.333
r1fm+r2fm = 168.333

input #2 time: 0:12:09 | total time: 0:36:27


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.9987729324760206
highest_index [0]
highest [0.9987729324760206]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.9844736456871033 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9387556910514832 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.9381915330886841 for ['[CLS] gauge louisiana [SEP]']
[Init] best rec loss: 0.9228593707084656 for ['[CLS] caused please [SEP]']
[Init] best rec loss: 0.8798360228538513 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8444858193397522 for ['[CLS] end depart [SEP]']
[Init] best rec loss: 0.8364353179931641 for ['[CLS] early force [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.706 (perp=10.685, rec=0.660, cos=0.909), tot_loss_proj:3.619 [t=0.30s]
prediction: ['[CLS]clusive film [SEP]']
[ 100/2000] tot_loss=2.283 (perp=8.384, rec=0.498, cos=0.108), tot_loss_proj:1.810 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/2000] tot_loss=2.242 (perp=8.384, rec=0.453, cos=0.112), tot_loss_proj:1.809 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 200/2000] tot_loss=2.071 (perp=8.384, rec=0.344, cos=0.050), tot_loss_proj:1.790 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.005 (perp=8.384, rec=0.289, cos=0.039), tot_loss_proj:1.786 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.986 (perp=8.384, rec=0.272, cos=0.037), tot_loss_proj:1.792 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.949 (perp=8.384, rec=0.235, cos=0.038), tot_loss_proj:1.781 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.936 (perp=8.384, rec=0.219, cos=0.040), tot_loss_proj:1.776 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.945 (perp=8.384, rec=0.220, cos=0.047), tot_loss_proj:1.778 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.939 (perp=8.384, rec=0.213, cos=0.049), tot_loss_proj:1.775 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.925 (perp=8.384, rec=0.198, cos=0.050), tot_loss_proj:1.763 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.944 (perp=8.384, rec=0.214, cos=0.053), tot_loss_proj:1.781 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.991 (perp=8.384, rec=0.275, cos=0.039), tot_loss_proj:1.782 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.940 (perp=8.384, rec=0.212, cos=0.051), tot_loss_proj:1.795 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.937 (perp=8.384, rec=0.207, cos=0.053), tot_loss_proj:1.765 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.936 (perp=8.384, rec=0.206, cos=0.054), tot_loss_proj:1.784 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.938 (perp=8.384, rec=0.207, cos=0.054), tot_loss_proj:1.778 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.929 (perp=8.384, rec=0.201, cos=0.051), tot_loss_proj:1.777 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.926 (perp=8.384, rec=0.194, cos=0.056), tot_loss_proj:1.779 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.928 (perp=8.384, rec=0.198, cos=0.054), tot_loss_proj:1.766 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.940 (perp=8.384, rec=0.208, cos=0.055), tot_loss_proj:1.779 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.934 (perp=8.384, rec=0.202, cos=0.055), tot_loss_proj:1.775 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.936 (perp=8.384, rec=0.204, cos=0.055), tot_loss_proj:1.760 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.942 (perp=8.384, rec=0.209, cos=0.056), tot_loss_proj:1.771 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.926 (perp=8.384, rec=0.193, cos=0.056), tot_loss_proj:1.780 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.936 (perp=8.384, rec=0.203, cos=0.056), tot_loss_proj:1.784 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.924 (perp=8.384, rec=0.191, cos=0.056), tot_loss_proj:1.779 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.934 (perp=8.384, rec=0.200, cos=0.056), tot_loss_proj:1.786 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.929 (perp=8.384, rec=0.195, cos=0.057), tot_loss_proj:1.771 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.941 (perp=8.384, rec=0.206, cos=0.058), tot_loss_proj:1.783 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.932 (perp=8.384, rec=0.198, cos=0.057), tot_loss_proj:1.772 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.943 (perp=8.384, rec=0.206, cos=0.060), tot_loss_proj:1.767 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.939 (perp=8.384, rec=0.202, cos=0.061), tot_loss_proj:1.774 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.928 (perp=8.384, rec=0.200, cos=0.051), tot_loss_proj:1.777 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.937 (perp=8.384, rec=0.203, cos=0.058), tot_loss_proj:1.793 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.950 (perp=8.384, rec=0.214, cos=0.059), tot_loss_proj:1.792 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.948 (perp=8.384, rec=0.212, cos=0.059), tot_loss_proj:1.787 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.943 (perp=8.384, rec=0.206, cos=0.060), tot_loss_proj:1.768 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.948 (perp=8.384, rec=0.211, cos=0.060), tot_loss_proj:1.778 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.947 (perp=8.384, rec=0.211, cos=0.059), tot_loss_proj:1.776 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.000 | p: 95.000 | r: 95.000
rouge2     | fm: 81.250 | p: 81.250 | r: 81.250
rougeL     | fm: 95.000 | p: 95.000 | r: 95.000
rougeLsum  | fm: 95.000 | p: 95.000 | r: 95.000
r1fm+r2fm = 176.250

input #3 time: 0:12:07 | total time: 0:48:34


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.9986225640121326
highest_index [0]
highest [0.9986225640121326]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 0.9747394919395447 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9590449929237366 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9539812803268433 for ['[CLS] together tracks print [SEP]']
[Init] best rec loss: 0.9476436972618103 for ['[CLS] activities sw eight [SEP]']
[Init] best rec loss: 0.9430261254310608 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.9136753678321838 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.8917473554611206 for ['[CLS] fatedss jack [SEP]']
[Init] best perm rec loss: 0.891136884689331 for ['[CLS]ss fated jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.635 (perp=7.516, rec=0.127, cos=0.005), tot_loss_proj:1.663 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
[ 100/2000] tot_loss=1.608 (perp=7.516, rec=0.094, cos=0.010), tot_loss_proj:1.661 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.590 (perp=7.516, rec=0.083, cos=0.003), tot_loss_proj:1.670 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.573 (perp=7.516, rec=0.067, cos=0.003), tot_loss_proj:1.674 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.561 (perp=7.516, rec=0.055, cos=0.003), tot_loss_proj:1.666 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.575 (perp=7.516, rec=0.069, cos=0.003), tot_loss_proj:1.664 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.581 (perp=7.516, rec=0.075, cos=0.003), tot_loss_proj:1.665 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.573 (perp=7.516, rec=0.067, cos=0.003), tot_loss_proj:1.672 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.561 (perp=7.516, rec=0.055, cos=0.003), tot_loss_proj:1.656 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.567 (perp=7.516, rec=0.061, cos=0.003), tot_loss_proj:1.652 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.564 (perp=7.516, rec=0.058, cos=0.003), tot_loss_proj:1.649 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.569 (perp=7.516, rec=0.064, cos=0.003), tot_loss_proj:1.669 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.570 (perp=7.516, rec=0.064, cos=0.003), tot_loss_proj:1.665 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.568 (perp=7.516, rec=0.062, cos=0.003), tot_loss_proj:1.678 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.579 (perp=7.516, rec=0.073, cos=0.003), tot_loss_proj:1.669 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.563 (perp=7.516, rec=0.057, cos=0.003), tot_loss_proj:1.665 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.568 (perp=7.516, rec=0.062, cos=0.003), tot_loss_proj:1.669 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.565 (perp=7.516, rec=0.059, cos=0.003), tot_loss_proj:1.664 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.562 (perp=7.516, rec=0.057, cos=0.003), tot_loss_proj:1.668 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.555 (perp=7.516, rec=0.049, cos=0.003), tot_loss_proj:1.669 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.571 (perp=7.516, rec=0.065, cos=0.003), tot_loss_proj:1.654 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.558 (perp=7.516, rec=0.052, cos=0.003), tot_loss_proj:1.670 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.563 (perp=7.516, rec=0.057, cos=0.003), tot_loss_proj:1.660 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.557 (perp=7.516, rec=0.051, cos=0.003), tot_loss_proj:1.651 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.564 (perp=7.516, rec=0.058, cos=0.003), tot_loss_proj:1.663 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.565 (perp=7.516, rec=0.059, cos=0.003), tot_loss_proj:1.656 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.571 (perp=7.516, rec=0.065, cos=0.003), tot_loss_proj:1.662 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.566 (perp=7.516, rec=0.060, cos=0.003), tot_loss_proj:1.650 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.572 (perp=7.516, rec=0.066, cos=0.003), tot_loss_proj:1.640 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.570 (perp=7.516, rec=0.064, cos=0.003), tot_loss_proj:1.627 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.578 (perp=7.516, rec=0.072, cos=0.003), tot_loss_proj:1.631 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.562 (perp=7.516, rec=0.056, cos=0.003), tot_loss_proj:1.634 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.575 (perp=7.516, rec=0.069, cos=0.003), tot_loss_proj:1.621 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.561 (perp=7.516, rec=0.055, cos=0.003), tot_loss_proj:1.617 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.565 (perp=7.516, rec=0.059, cos=0.003), tot_loss_proj:1.634 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.567 (perp=7.516, rec=0.061, cos=0.003), tot_loss_proj:1.628 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.565 (perp=7.516, rec=0.059, cos=0.003), tot_loss_proj:1.612 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.556 (perp=7.516, rec=0.050, cos=0.003), tot_loss_proj:1.619 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.560 (perp=7.516, rec=0.054, cos=0.003), tot_loss_proj:1.618 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.554 (perp=7.516, rec=0.048, cos=0.003), tot_loss_proj:1.633 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 96.000 | p: 96.000 | r: 96.000
rouge2     | fm: 85.000 | p: 85.000 | r: 85.000
rougeL     | fm: 96.000 | p: 96.000 | r: 96.000
rougeLsum  | fm: 96.000 | p: 96.000 | r: 96.000
r1fm+r2fm = 181.000

input #4 time: 0:12:07 | total time: 1:00:41


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9988020014373329
highest_index [0]
highest [0.9988020014373329]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.959015429019928 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.94868403673172 for ['[CLS] preservation notre [SEP]']
[Init] best rec loss: 0.9338293075561523 for ['[CLS] eye central [SEP]']
[Init] best rec loss: 0.9201485514640808 for ['[CLS] quiet. [SEP]']
[Init] best perm rec loss: 0.9189957976341248 for ['[CLS]. quiet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.664 (perp=12.055, rec=0.719, cos=0.534), tot_loss_proj:4.352 [t=0.30s]
prediction: ['[CLS] doubt sparhawk [SEP]']
[ 100/2000] tot_loss=3.613 (perp=11.775, rec=0.703, cos=0.555), tot_loss_proj:4.185 [t=0.30s]
prediction: ['[CLS] injuries least [SEP]']
[ 150/2000] tot_loss=3.903 (perp=13.361, rec=0.621, cos=0.610), tot_loss_proj:4.668 [t=0.30s]
prediction: ['[CLS] ease least [SEP]']
[ 200/2000] tot_loss=3.995 (perp=13.361, rec=0.592, cos=0.730), tot_loss_proj:4.670 [t=0.30s]
prediction: ['[CLS] ease least [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=3.816 (perp=12.372, rec=0.693, cos=0.648), tot_loss_proj:4.463 [t=0.30s]
prediction: ['[CLS] least ease [SEP]']
[ 300/2000] tot_loss=3.181 (perp=9.513, rec=0.591, cos=0.688), tot_loss_proj:3.865 [t=0.30s]
prediction: ['[CLS] least doubt [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.560 (perp=11.370, rec=0.541, cos=0.745), tot_loss_proj:3.701 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.610 (perp=11.370, rec=0.519, cos=0.817), tot_loss_proj:3.698 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
[ 450/2000] tot_loss=3.814 (perp=12.452, rec=0.618, cos=0.706), tot_loss_proj:4.437 [t=0.30s]
prediction: ['[CLS] mistaken ease [SEP]']
Attempt swap
[ 500/2000] tot_loss=4.299 (perp=14.452, rec=0.558, cos=0.851), tot_loss_proj:4.739 [t=0.30s]
prediction: ['[CLS] santa ease [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.889 (perp=12.210, rec=0.550, cos=0.897), tot_loss_proj:3.978 [t=0.30s]
prediction: ['[CLS] ease santa [SEP]']
[ 600/2000] tot_loss=3.834 (perp=12.210, rec=0.570, cos=0.822), tot_loss_proj:3.981 [t=0.30s]
prediction: ['[CLS] ease santa [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.881 (perp=12.210, rec=0.505, cos=0.934), tot_loss_proj:3.983 [t=0.30s]
prediction: ['[CLS] ease santa [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.876 (perp=12.210, rec=0.496, cos=0.939), tot_loss_proj:3.979 [t=0.30s]
prediction: ['[CLS] ease santa [SEP]']
[ 750/2000] tot_loss=3.889 (perp=12.210, rec=0.537, cos=0.910), tot_loss_proj:3.981 [t=0.30s]
prediction: ['[CLS] ease santa [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.747 (perp=11.370, rec=0.499, cos=0.974), tot_loss_proj:3.673 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.737 (perp=11.370, rec=0.492, cos=0.972), tot_loss_proj:3.673 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
[ 900/2000] tot_loss=3.748 (perp=11.370, rec=0.485, cos=0.989), tot_loss_proj:3.683 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.752 (perp=11.370, rec=0.479, cos=0.999), tot_loss_proj:3.675 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1000/2000] tot_loss=3.749 (perp=11.370, rec=0.479, cos=0.995), tot_loss_proj:3.675 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
[1050/2000] tot_loss=3.699 (perp=11.370, rec=0.469, cos=0.956), tot_loss_proj:3.681 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1100/2000] tot_loss=3.648 (perp=11.370, rec=0.472, cos=0.901), tot_loss_proj:3.674 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1150/2000] tot_loss=3.597 (perp=11.370, rec=0.459, cos=0.865), tot_loss_proj:3.673 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
[1200/2000] tot_loss=3.699 (perp=11.370, rec=0.554, cos=0.871), tot_loss_proj:3.672 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1250/2000] tot_loss=3.562 (perp=11.370, rec=0.464, cos=0.825), tot_loss_proj:3.672 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1300/2000] tot_loss=3.531 (perp=11.370, rec=0.458, cos=0.800), tot_loss_proj:3.682 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
[1350/2000] tot_loss=3.481 (perp=11.370, rec=0.447, cos=0.761), tot_loss_proj:3.678 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1400/2000] tot_loss=3.384 (perp=11.370, rec=0.434, cos=0.676), tot_loss_proj:3.674 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1450/2000] tot_loss=3.322 (perp=11.370, rec=0.444, cos=0.604), tot_loss_proj:3.673 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
[1500/2000] tot_loss=3.251 (perp=11.370, rec=0.434, cos=0.544), tot_loss_proj:3.667 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1550/2000] tot_loss=3.182 (perp=11.370, rec=0.432, cos=0.476), tot_loss_proj:3.679 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1600/2000] tot_loss=3.091 (perp=11.370, rec=0.417, cos=0.399), tot_loss_proj:3.675 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
[1650/2000] tot_loss=2.967 (perp=11.370, rec=0.415, cos=0.278), tot_loss_proj:3.680 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1700/2000] tot_loss=2.810 (perp=11.370, rec=0.384, cos=0.152), tot_loss_proj:3.672 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1750/2000] tot_loss=2.774 (perp=11.370, rec=0.370, cos=0.130), tot_loss_proj:3.677 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
[1800/2000] tot_loss=2.769 (perp=11.370, rec=0.366, cos=0.129), tot_loss_proj:3.677 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1850/2000] tot_loss=2.740 (perp=11.370, rec=0.361, cos=0.106), tot_loss_proj:3.673 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1900/2000] tot_loss=2.728 (perp=11.370, rec=0.356, cos=0.098), tot_loss_proj:3.669 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
[1950/2000] tot_loss=2.724 (perp=11.370, rec=0.358, cos=0.093), tot_loss_proj:3.681 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[2000/2000] tot_loss=2.705 (perp=11.370, rec=0.342, cos=0.089), tot_loss_proj:3.673 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 92.500 | p: 92.500 | r: 92.500
rouge2     | fm: 76.389 | p: 76.389 | r: 76.389
rougeL     | fm: 92.500 | p: 92.500 | r: 92.500
rougeLsum  | fm: 92.500 | p: 92.500 | r: 92.500
r1fm+r2fm = 168.889

input #5 time: 0:12:01 | total time: 1:12:42


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.9987753361456811
highest_index [0]
highest [0.9987753361456811]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9441893696784973 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.8494739532470703 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.8102795481681824 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.804685115814209 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.757422685623169 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7234959006309509 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.6976725459098816 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 0.6757896542549133 for ['[CLS] double deep [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.735 (perp=8.089, rec=0.111, cos=0.006), tot_loss_proj:1.707 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[ 100/2000] tot_loss=1.682 (perp=8.089, rec=0.061, cos=0.003), tot_loss_proj:1.703 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.675 (perp=8.089, rec=0.055, cos=0.003), tot_loss_proj:1.686 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.687 (perp=8.089, rec=0.067, cos=0.002), tot_loss_proj:1.707 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.678 (perp=8.089, rec=0.057, cos=0.002), tot_loss_proj:1.698 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.003), tot_loss_proj:1.694 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.002), tot_loss_proj:1.690 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.690 (perp=8.089, rec=0.069, cos=0.002), tot_loss_proj:1.697 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.673 (perp=8.089, rec=0.053, cos=0.002), tot_loss_proj:1.690 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.680 (perp=8.089, rec=0.059, cos=0.002), tot_loss_proj:1.693 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.691 (perp=8.089, rec=0.070, cos=0.002), tot_loss_proj:1.687 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.673 (perp=8.089, rec=0.052, cos=0.002), tot_loss_proj:1.693 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.686 (perp=8.089, rec=0.065, cos=0.002), tot_loss_proj:1.688 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.690 (perp=8.089, rec=0.070, cos=0.002), tot_loss_proj:1.698 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.686 (perp=8.089, rec=0.066, cos=0.002), tot_loss_proj:1.695 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.687 (perp=8.089, rec=0.067, cos=0.002), tot_loss_proj:1.694 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.002), tot_loss_proj:1.684 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.002), tot_loss_proj:1.692 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.681 (perp=8.089, rec=0.060, cos=0.002), tot_loss_proj:1.687 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.677 (perp=8.089, rec=0.057, cos=0.002), tot_loss_proj:1.676 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.676 (perp=8.089, rec=0.056, cos=0.002), tot_loss_proj:1.686 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.675 (perp=8.089, rec=0.055, cos=0.002), tot_loss_proj:1.682 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.677 (perp=8.089, rec=0.057, cos=0.002), tot_loss_proj:1.696 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.672 (perp=8.089, rec=0.052, cos=0.002), tot_loss_proj:1.700 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.699 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.694 (perp=8.089, rec=0.074, cos=0.002), tot_loss_proj:1.694 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.686 (perp=8.089, rec=0.066, cos=0.002), tot_loss_proj:1.687 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.674 (perp=8.089, rec=0.054, cos=0.002), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.688 (perp=8.089, rec=0.068, cos=0.002), tot_loss_proj:1.691 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.676 (perp=8.089, rec=0.056, cos=0.002), tot_loss_proj:1.704 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.691 (perp=8.089, rec=0.070, cos=0.002), tot_loss_proj:1.686 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.684 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.692 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.679 (perp=8.089, rec=0.059, cos=0.002), tot_loss_proj:1.679 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.687 (perp=8.089, rec=0.067, cos=0.002), tot_loss_proj:1.690 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.688 (perp=8.089, rec=0.068, cos=0.002), tot_loss_proj:1.686 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.672 (perp=8.089, rec=0.052, cos=0.002), tot_loss_proj:1.695 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.691 (perp=8.089, rec=0.071, cos=0.002), tot_loss_proj:1.694 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.688 (perp=8.089, rec=0.068, cos=0.002), tot_loss_proj:1.689 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.671 (perp=8.089, rec=0.051, cos=0.002), tot_loss_proj:1.687 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.688 (perp=8.089, rec=0.068, cos=0.002), tot_loss_proj:1.694 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.571 | p: 93.571 | r: 93.571
rouge2     | fm: 79.762 | p: 79.762 | r: 79.762
rougeL     | fm: 93.571 | p: 93.571 | r: 93.571
rougeLsum  | fm: 93.571 | p: 93.571 | r: 93.571
r1fm+r2fm = 173.333

input #6 time: 0:11:59 | total time: 1:24:42


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9983386507232211
highest_index [0]
highest [0.9983386507232211]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.907750129699707 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.832587480545044 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8202946782112122 for ['[CLS] flat forewingsys mick separation ) oh yorkening las sat an consecutive charity qaeda clinicroud ill column rustling marathon rom viper dinner chuck ( [SEP]']
[Init] best rec loss: 0.8148995637893677 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best rec loss: 0.8043140769004822 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best rec loss: 0.8015453815460205 for ['[CLS] cod dock # openר sat both grande flow hs most purpose baby beings comppia jenny infants part end pay exactly conference moths median [SEP]']
[Init] best perm rec loss: 0.8007888793945312 for ['[CLS] pay end # grande dockר baby infants part cod compia both purpose moths hs jennyp median sat exactly conference beings flow most open [SEP]']
[Init] best perm rec loss: 0.798695981502533 for ['[CLS] jenny open flow both babypia hs grande pay conference purpose most dock moths exactly satpר com part cod beings # infants end median [SEP]']
[Init] best perm rec loss: 0.7981770634651184 for ['[CLS] jenny baby dockp flow infants comר grande conference moths purpose most both #pia sat beings end part pay median hs open exactly cod [SEP]']
[Init] best perm rec loss: 0.7980135679244995 for ['[CLS] codpia jenny end com part purpose both moths beingsp exactly dock pay grande openר hs baby median conference flow sat infants most # [SEP]']
[Init] best perm rec loss: 0.7971181273460388 for ['[CLS] jenny purpose hs com satר part most grande infants dock cod # baby beings flow moths end conferencep median open paypia exactly both [SEP]']
[Init] best perm rec loss: 0.7966874241828918 for ['[CLS] com most beingsp flowpia median end conference purpose part hs cod bothר # dock exactly baby grande sat infants moths open pay jenny [SEP]']
[Init] best perm rec loss: 0.795516848564148 for ['[CLS] baby median # purpose most grandeר pay end open flow exactly both jenny hs beingspia com part moths sat conference codp infants dock [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.443 (perp=10.652, rec=0.273, cos=0.039), tot_loss_proj:3.255 [t=0.31s]
prediction: ['[CLS] no problem no character never them the poor idol drunk discretion maybe is problems problem problem removed humanity it mess not michael adult.. character [SEP]']
[ 100/2000] tot_loss=1.964 (perp=8.845, rec=0.181, cos=0.014), tot_loss_proj:2.829 [t=0.31s]
prediction: ['[CLS] mind problem no character has is. poor love. kaye not is not problem is removed ; it bad no cute love loveable character [SEP]']
[ 150/2000] tot_loss=1.768 (perp=8.062, rec=0.144, cos=0.011), tot_loss_proj:2.409 [t=0.31s]
prediction: ['[CLS] mind problem no character has is. ugly love. not not is ugly problem is removed ; the ugly no cuteable loveable character [SEP]']
[ 200/2000] tot_loss=1.696 (perp=7.752, rec=0.136, cos=0.010), tot_loss_proj:2.280 [t=0.31s]
prediction: ['[CLS] he problem no character has is. ugly love. mind not is ugly problem is removed ; the ugly no cuteable loveable character [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.698 (perp=7.723, rec=0.144, cos=0.010), tot_loss_proj:3.150 [t=0.31s]
prediction: ['[CLS] he problem no character has is, ugly love. mind not ugly problem is removed ; the ugly no ; cute cute loveable character [SEP]']
[ 300/2000] tot_loss=1.615 (perp=7.457, rec=0.116, cos=0.007), tot_loss_proj:2.726 [t=0.31s]
prediction: ['[CLS] he, no character has is. ugly love. mind not mind problem is removed ; the ugly no. cute factor loveable character [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.580 (perp=7.323, rec=0.108, cos=0.008), tot_loss_proj:2.473 [t=0.31s]
prediction: ['[CLS] he, no character i is. ugly has. mind not mind problem is removed ; the ugly no. cute factor loveable character [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.716 (perp=7.994, rec=0.108, cos=0.009), tot_loss_proj:2.484 [t=0.31s]
prediction: ['[CLS] he real no character i is., has. mind not i problem is removed ; the ugly no. cute factor loveable character [SEP]']
[ 450/2000] tot_loss=1.692 (perp=7.938, rec=0.097, cos=0.007), tot_loss_proj:2.632 [t=0.31s]
prediction: ['[CLS] he. no character i is. they has. mind not i problem is or ; the ugly no. cute factor loveable character [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.572 (perp=7.324, rec=0.101, cos=0.007), tot_loss_proj:2.262 [t=0.31s]
prediction: ['[CLS] he. no character i is. they has. mind not i is. problem ; the ugly no. cute factor loveable character [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.553 (perp=7.285, rec=0.089, cos=0.007), tot_loss_proj:2.315 [t=0.31s]
prediction: ['[CLS] he here no character i is. they has not mind. i is. problem ; the ugly no. cute factor loveable character [SEP]']
[ 600/2000] tot_loss=1.541 (perp=7.228, rec=0.089, cos=0.006), tot_loss_proj:2.313 [t=0.31s]
prediction: ['[CLS] he here no character i is. they has not mind. i is. problem ; the ugly no, cute factor loveable character [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.548 (perp=7.261, rec=0.089, cos=0.007), tot_loss_proj:2.259 [t=0.31s]
prediction: ['[CLS] they here no characterable is. he has not mind. i is. problem ; the ugly no, cute factor loveable character [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.531 (perp=7.205, rec=0.084, cos=0.006), tot_loss_proj:2.578 [t=0.31s]
prediction: ['[CLS] they is no character here here. he has not mind. i is or problem ; the ugly no, cute factor loveable character [SEP]']
[ 750/2000] tot_loss=1.533 (perp=7.205, rec=0.087, cos=0.006), tot_loss_proj:2.575 [t=0.31s]
prediction: ['[CLS] they is no character here here. he has not mind. i is or problem ; the ugly no, cute factor loveable character [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.471 (perp=6.889, rec=0.087, cos=0.006), tot_loss_proj:2.165 [t=0.31s]
prediction: ['[CLS] they is no character here here. he has not mind. i is ugly problem ; the. no, cute factor loveable character [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.388 (perp=6.462, rec=0.090, cos=0.006), tot_loss_proj:2.231 [t=0.31s]
prediction: ['[CLS] they is no character here here. he has not mind. i is ugly problem ; the no. cute factor loveable character. [SEP]']
[ 900/2000] tot_loss=1.387 (perp=6.462, rec=0.089, cos=0.006), tot_loss_proj:2.235 [t=0.31s]
prediction: ['[CLS] they is no character here here. he has not mind. i is ugly problem ; the no. cute factor loveable character. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.353 (perp=6.331, rec=0.081, cos=0.005), tot_loss_proj:2.294 [t=0.31s]
prediction: ['[CLS] they is no here character here. he has not mind. i is ugly problem ; the no. cute factor loveable character. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.358 (perp=6.331, rec=0.087, cos=0.005), tot_loss_proj:2.288 [t=0.31s]
prediction: ['[CLS] they is no here character here. he has not mind. i is ugly problem ; the no. cute factor loveable character. [SEP]']
[1050/2000] tot_loss=1.429 (perp=6.685, rec=0.088, cos=0.005), tot_loss_proj:2.263 [t=0.31s]
prediction: ['[CLS] they is no here characterable. he has not mind. i is ugly problem ; the no. cute factor loveable character. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.372 (perp=6.419, rec=0.083, cos=0.005), tot_loss_proj:2.124 [t=0.31s]
prediction: ['[CLS] they is no here characterable. he has not mind. i is ugly problem ; the no cute factor. loveable character. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.308 (perp=6.109, rec=0.081, cos=0.005), tot_loss_proj:1.953 [t=0.31s]
prediction: ['[CLS] they here is no characterable. he has not mind. i is ugly problem ; the no cute factor. loveable character. [SEP]']
[1200/2000] tot_loss=1.309 (perp=6.109, rec=0.083, cos=0.005), tot_loss_proj:1.959 [t=0.31s]
prediction: ['[CLS] they here is no characterable. he has not mind. i is ugly problem ; the no cute factor. loveable character. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.301 (perp=6.056, rec=0.086, cos=0.004), tot_loss_proj:1.859 [t=0.31s]
prediction: ['[CLS] they here is no characterable. he has not mind. i is ugly problem ; the no cute factor or loveable character. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.279 (perp=5.934, rec=0.088, cos=0.005), tot_loss_proj:1.826 [t=0.31s]
prediction: ['[CLS] they here is no characterable. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
[1350/2000] tot_loss=1.273 (perp=5.934, rec=0.082, cos=0.004), tot_loss_proj:1.824 [t=0.31s]
prediction: ['[CLS] they here is no characterable. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.269 (perp=5.934, rec=0.078, cos=0.004), tot_loss_proj:1.829 [t=0.31s]
prediction: ['[CLS] they here is no characterable. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.270 (perp=5.934, rec=0.080, cos=0.004), tot_loss_proj:1.823 [t=0.31s]
prediction: ['[CLS] they here is no characterable. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
[1500/2000] tot_loss=1.277 (perp=5.934, rec=0.086, cos=0.004), tot_loss_proj:1.828 [t=0.31s]
prediction: ['[CLS] they here is no characterable. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.267 (perp=5.934, rec=0.076, cos=0.004), tot_loss_proj:1.823 [t=0.31s]
prediction: ['[CLS] they here is no characterable. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.273 (perp=5.934, rec=0.083, cos=0.004), tot_loss_proj:1.827 [t=0.31s]
prediction: ['[CLS] they here is no characterable. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
[1650/2000] tot_loss=1.264 (perp=5.934, rec=0.074, cos=0.004), tot_loss_proj:1.827 [t=0.31s]
prediction: ['[CLS] they here is no characterable. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.222 (perp=5.691, rec=0.080, cos=0.004), tot_loss_proj:1.862 [t=0.31s]
prediction: ['[CLS] they here is noable character. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.224 (perp=5.691, rec=0.082, cos=0.004), tot_loss_proj:1.858 [t=0.31s]
prediction: ['[CLS] they here is noable character. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
[1800/2000] tot_loss=1.220 (perp=5.691, rec=0.078, cos=0.004), tot_loss_proj:1.861 [t=0.31s]
prediction: ['[CLS] they here is noable character. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.222 (perp=5.691, rec=0.080, cos=0.004), tot_loss_proj:1.859 [t=0.31s]
prediction: ['[CLS] they here is noable character. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.221 (perp=5.691, rec=0.079, cos=0.004), tot_loss_proj:1.869 [t=0.31s]
prediction: ['[CLS] they here is noable character. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
[1950/2000] tot_loss=1.221 (perp=5.691, rec=0.079, cos=0.004), tot_loss_proj:1.864 [t=0.31s]
prediction: ['[CLS] they here is noable character. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.217 (perp=5.691, rec=0.075, cos=0.004), tot_loss_proj:1.868 [t=0.31s]
prediction: ['[CLS] they here is noable character. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] they here is noable character. i has not mind. he is ugly problem ; the no cute factor or loveable character. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.721 | p: 81.818 | r: 85.714
rouge2     | fm: 9.756 | p: 9.524 | r: 10.000
rougeL     | fm: 41.860 | p: 40.909 | r: 42.857
rougeLsum  | fm: 41.860 | p: 40.909 | r: 42.857
r1fm+r2fm = 93.477

[Aggregate metrics]:
rouge1     | fm: 92.340 | p: 92.102 | r: 92.589
rouge2     | fm: 71.011 | p: 70.982 | r: 71.042
rougeL     | fm: 87.108 | p: 86.989 | r: 87.232
rougeLsum  | fm: 87.108 | p: 86.989 | r: 87.232
r1fm+r2fm = 163.351

input #7 time: 0:12:24 | total time: 1:37:07


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9989557094991461
highest_index [0]
highest [0.9989557094991461]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.6617246866226196 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.6562386751174927 for ['[CLS] breed app king jude rome am regal roman grown levi mine fitting peninsula cappella age bulldogs component founder macarthur unionist overturegible raysstock [SEP]']
[Init] best rec loss: 0.6536446809768677 for ['[CLS] vin figure blowgger note mission [CLS] planet outside xi awardhe collections work money... unsuccessful canon ob brainally street wheat shortly [SEP]']
[Init] best rec loss: 0.6455197930335999 for ['[CLS] andhra basque richards surrounding rockwell gloss rodeo series balanced waived word line plan styx responsible wish procession than attentionrave retention past doe tv [SEP]']
[Init] best perm rec loss: 0.6448594331741333 for ['[CLS] surrounding attention series waived styx word rockwell tv doe richards procession responsible wish past line than plan balanced retention rodeo andhra basquerave gloss [SEP]']
[Init] best perm rec loss: 0.6417372226715088 for ['[CLS] plan surrounding procession tv styx wish rockwell rodeo balanced richards gloss andhra waived attention line past word retention basque doerave responsible series than [SEP]']
[Init] best perm rec loss: 0.641325056552887 for ['[CLS] styx rodeo basque tv procession retention word line rockwell wish plan past andhra than attention balanced gloss surrounding responsible doerave richards waived series [SEP]']
[Init] best perm rec loss: 0.6408293843269348 for ['[CLS] responsible gloss wish styx than doe richards waived basque procession balanced retention rodeo surrounding word plan attention andhra rockwell past line seriesrave tv [SEP]']
[Init] best perm rec loss: 0.6400526762008667 for ['[CLS] surroundingrave attention rockwell tv styx past richards andhra wish balanced plan word line procession rodeo responsible retention basque waived doe gloss than series [SEP]']
[Init] best perm rec loss: 0.6391479969024658 for ['[CLS] waived tv word balancedrave retention line rockwell responsible series doe rodeo surrounding wish than plan attention gloss procession basque past richards styx andhra [SEP]']
[Init] best perm rec loss: 0.6377691626548767 for ['[CLS] waived balanced styx wish line richards gloss attention tv responsible retention plan than basque rockwell past rodeo procession andhra word doe series surroundingrave [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.687 (perp=11.566, rec=0.281, cos=0.093), tot_loss_proj:3.738 [t=0.31s]
prediction: ['[CLS] product cash vanity themselves vanity vanity film an horror likely pays what no debt vanity past filmkos wound replacing specially a toll? [SEP]']
[ 100/2000] tot_loss=2.810 (perp=12.561, rec=0.208, cos=0.090), tot_loss_proj:3.689 [t=0.31s]
prediction: ['[CLS] clearly pays vanity believed fright vanity film an fright likely pays what doubt debt vanity off debtfied fright sherman that a mitch? [SEP]']
[ 150/2000] tot_loss=2.582 (perp=11.870, rec=0.171, cos=0.037), tot_loss_proj:3.371 [t=0.31s]
prediction: ['[CLS] s pays vanity owed fright vanity film a no doubt pays what doubt debt vanity offmaxably fright sherman that aless doubt [SEP]']
[ 200/2000] tot_loss=2.470 (perp=11.475, rec=0.134, cos=0.041), tot_loss_proj:3.503 [t=0.31s]
prediction: ['[CLS] s pays benign owedful vanity film a no doubt pays what doubt debt vanity offmax, fright owed thatii or [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.400 (perp=11.354, rec=0.116, cos=0.012), tot_loss_proj:3.592 [t=0.31s]
prediction: ['[CLS] s pays benign owedful vanity film a no doubt debt what doubt pays fright owedmaxphone fright owed thati benign : [SEP]']
[ 300/2000] tot_loss=2.239 (perp=10.569, rec=0.107, cos=0.018), tot_loss_proj:3.295 [t=0.31s]
prediction: ["[CLS]'pays benign owedful vanity film a no doubt debt what doubt pays fright owedmax, fright owed thati benign : [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.181 (perp=10.325, rec=0.104, cos=0.012), tot_loss_proj:3.227 [t=0.31s]
prediction: ["[CLS]'pays benign owedful vanity film a no doubt debt what doubt pays fright owedmax, fright that owedi benign, [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.142 (perp=10.162, rec=0.099, cos=0.011), tot_loss_proj:3.012 [t=0.31s]
prediction: ["[CLS]'pays benign feltful vanity film a no doubt debt what doubt pays fright owedmax, fright that owed benigni, [SEP]"]
[ 450/2000] tot_loss=2.193 (perp=10.482, rec=0.087, cos=0.009), tot_loss_proj:3.241 [t=0.31s]
prediction: ['[CLS] s pays benign feltful vanity film a no doubt debt what doubt pays fright owedmax, fright that off benigni, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.112 (perp=10.085, rec=0.090, cos=0.006), tot_loss_proj:3.092 [t=0.31s]
prediction: ['[CLS] s pays owed feltful vanity film a no doubt debt what doubt pays fright benignmax, fright that off benigni, [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.152 (perp=10.145, rec=0.108, cos=0.015), tot_loss_proj:3.188 [t=0.31s]
prediction: ['[CLS] s owed feltful vanity film a no doubt debt what doubt pays fright benignmaxfactory they that pays off benigni, [SEP]']
[ 600/2000] tot_loss=1.967 (perp=9.393, rec=0.082, cos=0.007), tot_loss_proj:2.866 [t=0.31s]
prediction: ['[CLS] s owed feltful vanity film a no doubt debt what doubt pays fright benignmax as they that paid off benigni, [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.010 (perp=9.575, rec=0.090, cos=0.005), tot_loss_proj:3.234 [t=0.31s]
prediction: ['[CLS] s owed feltful vanity film a no doubt debt what that pays fright benignmax ᴺ they doubt paid off theyi, [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.895 (perp=9.089, rec=0.072, cos=0.005), tot_loss_proj:2.960 [t=0.31s]
prediction: ['[CLS] s owed feltful vanity film a no doubt debt that pays what fright benignmax ; they doubt paid off theyi, [SEP]']
[ 750/2000] tot_loss=1.901 (perp=9.089, rec=0.079, cos=0.004), tot_loss_proj:2.958 [t=0.31s]
prediction: ['[CLS] s owed feltful vanity film a no doubt debt that pays what fright benignmax ; they doubt paid off theyi, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.820 (perp=8.723, rec=0.072, cos=0.004), tot_loss_proj:2.653 [t=0.31s]
prediction: ['[CLS] s owed feltful vanity film a no doubt, that pays what fright benignmax debt they doubt paid off toi, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.759 (perp=8.389, rec=0.077, cos=0.004), tot_loss_proj:2.504 [t=0.31s]
prediction: ['[CLS] s owed feltful vanity a film no doubt, that pays what fright benignmax debt they doubt paid off toi, [SEP]']
[ 900/2000] tot_loss=1.756 (perp=8.389, rec=0.075, cos=0.003), tot_loss_proj:2.504 [t=0.31s]
prediction: ['[CLS] s owed feltful vanity a film no doubt, that pays what fright benignmax debt they doubt paid off toi, [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.762 (perp=8.341, rec=0.079, cos=0.015), tot_loss_proj:2.770 [t=0.31s]
prediction: ['[CLS] s owed feltful vanity a film no doubt, that what pays fright benignmax debt they doubt paid off toi, [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.687 (perp=7.983, rec=0.085, cos=0.005), tot_loss_proj:2.559 [t=0.32s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, that what pays felt benignmax debt they doubt paid off toi, [SEP]']
[1050/2000] tot_loss=1.670 (perp=7.983, rec=0.069, cos=0.004), tot_loss_proj:2.574 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, that what pays felt benignmax debt they doubt paid off toi, [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.625 (perp=7.730, rec=0.076, cos=0.004), tot_loss_proj:2.832 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, felt that what pays benignmax debt they doubt paid off toi, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.630 (perp=7.730, rec=0.081, cos=0.004), tot_loss_proj:2.833 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, felt that what pays benignmax debt they doubt paid off toi, [SEP]']
[1200/2000] tot_loss=1.622 (perp=7.730, rec=0.073, cos=0.004), tot_loss_proj:2.831 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, felt that what pays benignmax debt they doubt paid off toi, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.621 (perp=7.730, rec=0.072, cos=0.003), tot_loss_proj:2.834 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, felt that what pays benignmax debt they doubt paid off toi, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.625 (perp=7.730, rec=0.075, cos=0.003), tot_loss_proj:2.835 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, felt that what pays benignmax debt they doubt paid off toi, [SEP]']
[1350/2000] tot_loss=1.630 (perp=7.730, rec=0.081, cos=0.003), tot_loss_proj:2.835 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, felt that what pays benignmax debt they doubt paid off toi, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.617 (perp=7.730, rec=0.068, cos=0.003), tot_loss_proj:2.835 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, felt that what pays benignmax debt they doubt paid off toi, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.628 (perp=7.730, rec=0.078, cos=0.003), tot_loss_proj:2.834 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, felt that what pays benignmax debt they doubt paid off toi, [SEP]']
[1500/2000] tot_loss=1.848 (perp=8.924, rec=0.060, cos=0.003), tot_loss_proj:3.027 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, felt that what pays benignmax debt they doubt investigative off toi, [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.817 (perp=8.713, rec=0.071, cos=0.003), tot_loss_proj:2.947 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, felt that what pays benignmax investigative debt they doubt off toi, [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.736 (perp=8.317, rec=0.069, cos=0.004), tot_loss_proj:2.732 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, doubt that what pays benignmax investigative debt they felt off toi, [SEP]']
[1650/2000] tot_loss=1.736 (perp=8.317, rec=0.070, cos=0.003), tot_loss_proj:2.735 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, doubt that what pays benignmax investigative debt they felt off toi, [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.688 (perp=8.085, rec=0.068, cos=0.003), tot_loss_proj:2.689 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, doubt that what paysmax investigative debt they felt off to benigni, [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.668 (perp=7.974, rec=0.069, cos=0.004), tot_loss_proj:2.666 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, doubt that what paysmax investigative debt they felt to off benigni, [SEP]']
[1800/2000] tot_loss=1.677 (perp=7.974, rec=0.079, cos=0.003), tot_loss_proj:2.668 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, doubt that what paysmax investigative debt they felt to off benigni, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.666 (perp=7.974, rec=0.068, cos=0.003), tot_loss_proj:2.676 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, doubt that what paysmax investigative debt they felt to off benigni, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.665 (perp=7.974, rec=0.067, cos=0.003), tot_loss_proj:2.668 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, doubt that what paysmax investigative debt they felt to off benigni, [SEP]']
[1950/2000] tot_loss=1.667 (perp=7.974, rec=0.069, cos=0.003), tot_loss_proj:2.671 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, doubt that what paysmax investigative debt they felt to off benigni, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.678 (perp=7.974, rec=0.080, cos=0.003), tot_loss_proj:2.668 [t=0.31s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, doubt that what paysmax investigative debt they felt to off benigni, [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] s owed frightful vanity a film no doubt, doubt that what paysmax investigative debt they felt to off benigni, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.805 | p: 85.714 | r: 90.000
rouge2     | fm: 20.513 | p: 20.000 | r: 21.053
rougeL     | fm: 63.415 | p: 61.905 | r: 65.000
rougeLsum  | fm: 63.415 | p: 61.905 | r: 65.000
r1fm+r2fm = 108.318

[Aggregate metrics]:
rouge1     | fm: 91.802 | p: 91.270 | r: 92.302
rouge2     | fm: 65.171 | p: 65.079 | r: 65.351
rougeL     | fm: 84.841 | p: 84.585 | r: 85.000
rougeLsum  | fm: 84.649 | p: 84.484 | r: 85.000
r1fm+r2fm = 156.973

input #8 time: 0:12:23 | total time: 1:49:30


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9988274491335966
highest_index [0]
highest [0.9988274491335966]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.776007890701294 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.6868312954902649 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.6601606011390686 for ['[CLS] ham ice command across see beatty anal tan [SEP]']
[Init] best rec loss: 0.6586527824401855 for ['[CLS] save california liquidstownabiing plain for [SEP]']
[Init] best perm rec loss: 0.6580478549003601 for ['[CLS]abi liquiding plain save for californiastown [SEP]']
[Init] best perm rec loss: 0.6566006541252136 for ['[CLS] foring california plainstownabi liquid save [SEP]']
[Init] best perm rec loss: 0.6557493209838867 for ['[CLS] californiastowning save plainabi liquid for [SEP]']
[Init] best perm rec loss: 0.6546200513839722 for ['[CLS] plain forstown liquid california saveabiing [SEP]']
[Init] best perm rec loss: 0.6545423865318298 for ['[CLS] saveabi california foring liquidstown plain [SEP]']
[Init] best perm rec loss: 0.6541658639907837 for ['[CLS] california plain for liquidingstown saveabi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.274 (perp=14.126, rec=0.293, cos=0.156), tot_loss_proj:4.044 [t=0.30s]
prediction: ['[CLS] 1980sroller clap soft parents clap slip vote [SEP]']
[ 100/2000] tot_loss=2.705 (perp=12.016, rec=0.196, cos=0.105), tot_loss_proj:3.614 [t=0.30s]
prediction: ['[CLS] soft soft clap softhead clappodstra [SEP]']
[ 150/2000] tot_loss=2.550 (perp=11.856, rec=0.166, cos=0.013), tot_loss_proj:3.295 [t=0.30s]
prediction: ['[CLS] ofhead clap softhead claptratra [SEP]']
[ 200/2000] tot_loss=2.436 (perp=11.486, rec=0.133, cos=0.006), tot_loss_proj:3.142 [t=0.30s]
prediction: ['[CLS] ofhead clap softhead claptra metaphysical [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.371 (perp=10.892, rec=0.175, cos=0.017), tot_loss_proj:3.035 [t=0.31s]
prediction: ['[CLS] ofhead claphead soft claptra metaphysical [SEP]']
[ 300/2000] tot_loss=2.465 (perp=11.773, rec=0.106, cos=0.005), tot_loss_proj:3.113 [t=0.30s]
prediction: ['[CLS] ofheadphead soft claptra metaphysical [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.953 (perp=9.303, rec=0.089, cos=0.004), tot_loss_proj:2.428 [t=0.30s]
prediction: ['[CLS] ofheadhead soft claptrap metaphysical [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.813 (perp=8.582, rec=0.091, cos=0.006), tot_loss_proj:2.432 [t=0.30s]
prediction: ['[CLS]headhead of soft claptrap metaphysical [SEP]']
[ 450/2000] tot_loss=1.813 (perp=8.582, rec=0.094, cos=0.003), tot_loss_proj:2.425 [t=0.30s]
prediction: ['[CLS]headhead of soft claptrap metaphysical [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.665 (perp=7.926, rec=0.077, cos=0.003), tot_loss_proj:2.195 [t=0.30s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.662 (perp=7.926, rec=0.075, cos=0.003), tot_loss_proj:2.198 [t=0.30s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
[ 600/2000] tot_loss=1.653 (perp=7.926, rec=0.065, cos=0.002), tot_loss_proj:2.195 [t=0.31s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.594 (perp=7.643, rec=0.062, cos=0.003), tot_loss_proj:1.602 [t=0.31s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.601 (perp=7.643, rec=0.069, cos=0.002), tot_loss_proj:1.614 [t=0.30s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
[ 750/2000] tot_loss=1.590 (perp=7.643, rec=0.059, cos=0.002), tot_loss_proj:1.604 [t=0.30s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.538 (perp=7.384, rec=0.058, cos=0.003), tot_loss_proj:1.625 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.541 (perp=7.384, rec=0.062, cos=0.002), tot_loss_proj:1.629 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 900/2000] tot_loss=1.544 (perp=7.384, rec=0.065, cos=0.002), tot_loss_proj:1.633 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.541 (perp=7.384, rec=0.062, cos=0.002), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.547 (perp=7.384, rec=0.068, cos=0.002), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1050/2000] tot_loss=1.547 (perp=7.384, rec=0.068, cos=0.002), tot_loss_proj:1.631 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.533 (perp=7.384, rec=0.054, cos=0.002), tot_loss_proj:1.637 [t=0.31s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.546 (perp=7.384, rec=0.067, cos=0.002), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1200/2000] tot_loss=1.533 (perp=7.384, rec=0.054, cos=0.002), tot_loss_proj:1.638 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.553 (perp=7.384, rec=0.074, cos=0.002), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.542 (perp=7.384, rec=0.063, cos=0.002), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1350/2000] tot_loss=1.536 (perp=7.384, rec=0.057, cos=0.002), tot_loss_proj:1.630 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.535 (perp=7.384, rec=0.055, cos=0.002), tot_loss_proj:1.636 [t=0.31s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.545 (perp=7.384, rec=0.066, cos=0.002), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1500/2000] tot_loss=1.548 (perp=7.384, rec=0.069, cos=0.002), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.546 (perp=7.384, rec=0.067, cos=0.002), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.546 (perp=7.384, rec=0.067, cos=0.002), tot_loss_proj:1.633 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1650/2000] tot_loss=1.543 (perp=7.384, rec=0.063, cos=0.002), tot_loss_proj:1.621 [t=0.31s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.536 (perp=7.384, rec=0.056, cos=0.002), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.536 (perp=7.384, rec=0.057, cos=0.002), tot_loss_proj:1.639 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1800/2000] tot_loss=1.550 (perp=7.384, rec=0.071, cos=0.002), tot_loss_proj:1.631 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.540 (perp=7.384, rec=0.061, cos=0.002), tot_loss_proj:1.632 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.546 (perp=7.384, rec=0.067, cos=0.002), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1950/2000] tot_loss=1.541 (perp=7.384, rec=0.062, cos=0.002), tot_loss_proj:1.631 [t=0.31s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.539 (perp=7.384, rec=0.059, cos=0.002), tot_loss_proj:1.637 [t=0.30s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical softheaded claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 92.653 | p: 92.253 | r: 93.071
rouge2     | fm: 63.053 | p: 62.952 | r: 63.158
rougeL     | fm: 84.528 | p: 84.281 | r: 84.786
rougeLsum  | fm: 84.705 | p: 84.515 | r: 84.952
r1fm+r2fm = 155.705

input #9 time: 0:12:05 | total time: 2:01:35


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9989512650412298
highest_index [0]
highest [0.9989512650412298]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.7957035899162292 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.7767426371574402 for ['[CLS] university mitaonaefa never existing gym backed ribs realmsund odd [SEP]']
[Init] best rec loss: 0.7441798448562622 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.6607406735420227 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 0.6596410274505615 for ['[CLS] common level totally up order soundoric blessedblood places sheep themes angel [SEP]']
[Init] best perm rec loss: 0.6572002172470093 for ['[CLS]blood sound angel common themes sheep uporic blessed level places totally order [SEP]']
[Init] best perm rec loss: 0.6570185422897339 for ['[CLS] sound sheep common order up places level angeloric themes blessed totallyblood [SEP]']
[Init] best perm rec loss: 0.6567840576171875 for ['[CLS] sound sheep angel order common totallyoric up blessedblood places themes level [SEP]']
[Init] best perm rec loss: 0.6560449600219727 for ['[CLS] places themes angel up common totally soundblood blessedoric sheep order level [SEP]']
[Init] best perm rec loss: 0.6542155146598816 for ['[CLS] places blessed sheep common sound totally order angel themes upblood leveloric [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.733 (perp=12.130, rec=0.281, cos=0.026), tot_loss_proj:3.292 [t=0.30s]
prediction: ['[CLS] independently authority creative stylely activeivity balance separately entered ab prop [SEP]']
[ 100/2000] tot_loss=2.333 (perp=9.920, rec=0.318, cos=0.030), tot_loss_proj:3.116 [t=0.30s]
prediction: ['[CLS] libertarianly. real balancely free rhythms balance rhythms balance ab led [SEP]']
[ 150/2000] tot_loss=2.418 (perp=10.858, rec=0.214, cos=0.032), tot_loss_proj:3.241 [t=0.30s]
prediction: ['[CLS]staticly basic real rhythmsly free incident balance rhythms balance abulsive [SEP]']
[ 200/2000] tot_loss=2.397 (perp=10.800, rec=0.198, cos=0.040), tot_loss_proj:3.108 [t=0.30s]
prediction: ['[CLS]staticly§ real rhythms with time incident balance rhythms balance abulsive [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.153 (perp=9.809, rec=0.157, cos=0.034), tot_loss_proj:2.877 [t=0.30s]
prediction: ['[CLS]staticly consecutive real time rhythms with incident balance rhythms balance abulsive [SEP]']
[ 300/2000] tot_loss=2.451 (perp=11.103, rec=0.170, cos=0.060), tot_loss_proj:3.229 [t=0.30s]
prediction: ['[CLS]ucly consecutive real time rhythms with incident balance rhythms balance abulsive [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.174 (perp=9.704, rec=0.171, cos=0.063), tot_loss_proj:2.738 [t=0.30s]
prediction: ['[CLS] balancely consecutive real time rhythms with incidentuc rhythms balance abulsive [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.269 (perp=10.155, rec=0.180, cos=0.058), tot_loss_proj:3.108 [t=0.30s]
prediction: ['[CLS] balancelymity real time rhythms with incident rhythms balance abuculsive [SEP]']
[ 450/2000] tot_loss=2.097 (perp=9.356, rec=0.164, cos=0.062), tot_loss_proj:2.626 [t=0.30s]
prediction: ['[CLS] balancely consecutive real time rhythms with incident rhythms balance abuculsive [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.043 (perp=9.085, rec=0.161, cos=0.064), tot_loss_proj:2.587 [t=0.30s]
prediction: ['[CLS] balancely consecutive real time rhythms with incident balance abuculsive rhythms [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.038 (perp=9.085, rec=0.151, cos=0.070), tot_loss_proj:2.587 [t=0.30s]
prediction: ['[CLS] balancely consecutive real time rhythms with incident balance abuculsive rhythms [SEP]']
[ 600/2000] tot_loss=2.099 (perp=9.338, rec=0.164, cos=0.067), tot_loss_proj:2.503 [t=0.30s]
prediction: ['[CLS] balancely temper real time rhythms with incident balance abuculsive rhythms [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.114 (perp=9.497, rec=0.157, cos=0.058), tot_loss_proj:2.818 [t=0.30s]
prediction: ['[CLS] balancely real time rhythms with incident balance abuculsiveperation rhythms [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.164 (perp=9.773, rec=0.158, cos=0.051), tot_loss_proj:2.728 [t=0.30s]
prediction: ['[CLS] balancely real time rhythms with incident balance privately abuculsive rhythms [SEP]']
[ 750/2000] tot_loss=2.260 (perp=10.212, rec=0.155, cos=0.062), tot_loss_proj:2.836 [t=0.30s]
prediction: ['[CLS] balancely real time rhythms with incident balance privately ab vantageulsive rhythms [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.225 (perp=9.998, rec=0.161, cos=0.064), tot_loss_proj:2.788 [t=0.30s]
prediction: ['[CLS] privatelyly real time rhythms with incident balance balance ab vantageulsive rhythms [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.087 (perp=9.359, rec=0.159, cos=0.057), tot_loss_proj:2.515 [t=0.30s]
prediction: ['[CLS] privately ably real time rhythms with incident balance balance vantageulsive rhythms [SEP]']
[ 900/2000] tot_loss=2.104 (perp=9.359, rec=0.166, cos=0.066), tot_loss_proj:2.517 [t=0.30s]
prediction: ['[CLS] privately ably real time rhythms with incident balance balance vantageulsive rhythms [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.137 (perp=9.562, rec=0.157, cos=0.067), tot_loss_proj:2.604 [t=0.30s]
prediction: ['[CLS] abilities ably real time rhythms with incident balance balance vantageulsive rhythms [SEP]']
Attempt swap
[1000/2000] tot_loss=2.127 (perp=9.562, rec=0.147, cos=0.067), tot_loss_proj:2.601 [t=0.30s]
prediction: ['[CLS] abilities ably real time rhythms with incident balance balance vantageulsive rhythms [SEP]']
[1050/2000] tot_loss=2.142 (perp=9.562, rec=0.161, cos=0.068), tot_loss_proj:2.604 [t=0.30s]
prediction: ['[CLS] abilities ably real time rhythms with incident balance balance vantageulsive rhythms [SEP]']
Attempt swap
[1100/2000] tot_loss=2.129 (perp=9.562, rec=0.148, cos=0.069), tot_loss_proj:2.604 [t=0.30s]
prediction: ['[CLS] abilities ably real time rhythms with incident balance balance vantageulsive rhythms [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.058 (perp=9.111, rec=0.165, cos=0.071), tot_loss_proj:2.454 [t=0.30s]
prediction: ['[CLS] abilities ably balance real time rhythms with incident balance vantageulsive rhythms [SEP]']
[1200/2000] tot_loss=2.365 (perp=10.689, rec=0.160, cos=0.067), tot_loss_proj:2.580 [t=0.30s]
prediction: ['[CLS]pel ably balance real time rhythms with incident balance vantageulsive rhythms [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.163 (perp=9.726, rec=0.151, cos=0.067), tot_loss_proj:2.448 [t=0.31s]
prediction: ['[CLS]pel rhythms ably balance real time with incident balance vantageulsive rhythms [SEP]']
Attempt swap
Put prefix at the end
[1300/2000] tot_loss=2.124 (perp=9.567, rec=0.164, cos=0.047), tot_loss_proj:2.435 [t=0.30s]
prediction: ['[CLS]uculsive rhythms abilities rhythms ably balance real time with incident balance [SEP]']
[1350/2000] tot_loss=2.070 (perp=9.157, rec=0.176, cos=0.062), tot_loss_proj:2.305 [t=0.30s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.064 (perp=9.157, rec=0.169, cos=0.064), tot_loss_proj:2.299 [t=0.30s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.063 (perp=9.157, rec=0.168, cos=0.064), tot_loss_proj:2.307 [t=0.30s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
[1500/2000] tot_loss=2.057 (perp=9.157, rec=0.161, cos=0.065), tot_loss_proj:2.307 [t=0.30s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
Attempt swap
[1550/2000] tot_loss=2.065 (perp=9.157, rec=0.168, cos=0.065), tot_loss_proj:2.311 [t=0.30s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
Attempt swap
[1600/2000] tot_loss=2.062 (perp=9.157, rec=0.164, cos=0.066), tot_loss_proj:2.307 [t=0.31s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
[1650/2000] tot_loss=2.047 (perp=9.157, rec=0.150, cos=0.066), tot_loss_proj:2.308 [t=0.30s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
Attempt swap
[1700/2000] tot_loss=2.047 (perp=9.157, rec=0.149, cos=0.066), tot_loss_proj:2.307 [t=0.30s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
Attempt swap
[1750/2000] tot_loss=2.046 (perp=9.157, rec=0.148, cos=0.066), tot_loss_proj:2.309 [t=0.30s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
[1800/2000] tot_loss=2.054 (perp=9.157, rec=0.156, cos=0.067), tot_loss_proj:2.314 [t=0.30s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
Attempt swap
[1850/2000] tot_loss=2.054 (perp=9.157, rec=0.156, cos=0.066), tot_loss_proj:2.314 [t=0.30s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
Attempt swap
[1900/2000] tot_loss=2.057 (perp=9.157, rec=0.158, cos=0.067), tot_loss_proj:2.306 [t=0.31s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
[1950/2000] tot_loss=2.048 (perp=9.157, rec=0.150, cos=0.066), tot_loss_proj:2.307 [t=0.31s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
Attempt swap
[2000/2000] tot_loss=2.052 (perp=9.157, rec=0.155, cos=0.066), tot_loss_proj:2.310 [t=0.30s]
prediction: ['[CLS]uculsive rhythmspel rhythms ably balance real time with incident balance [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] balancelyathic real time rhythms with incident rhythms balance abuculsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 63.636 | r: 70.000
rouge2     | fm: 31.579 | p: 30.000 | r: 33.333
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 98.246

[Aggregate metrics]:
rouge1     | fm: 90.290 | p: 89.652 | r: 90.974
rouge2     | fm: 60.032 | p: 59.848 | r: 60.343
rougeL     | fm: 83.060 | p: 82.553 | r: 83.723
rougeLsum  | fm: 83.193 | p: 82.708 | r: 83.745
r1fm+r2fm = 150.322

input #10 time: 0:12:05 | total time: 2:13:40


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9985975824755359
highest_index [0]
highest [0.9985975824755359]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.8811643719673157 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.8649181723594666 for ['[CLS] changelift tonig half moth bodo contractgmche [SEP]']
[Init] best rec loss: 0.82845538854599 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.7499896883964539 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.7496981024742126 for ['[CLS]ture talguvd inland platform drawn me mile familiar [SEP]']
[Init] best perm rec loss: 0.7494725584983826 for ['[CLS] talture familiar inland platformvdgu drawn me mile [SEP]']
[Init] best perm rec loss: 0.7469839453697205 for ['[CLS] inlandgu mile tal platform drawn familiar meturevd [SEP]']
[Init] best perm rec loss: 0.7466945648193359 for ['[CLS] talturevdgu inland mile platform drawn familiar me [SEP]']
[Init] best perm rec loss: 0.745023787021637 for ['[CLS] meture tal mile drawnvdgu familiar platform inland [SEP]']
[Init] best perm rec loss: 0.7449614405632019 for ['[CLS]ture tal inlandgu me drawnvd mile familiar platform [SEP]']
[Init] best perm rec loss: 0.7444503903388977 for ['[CLS] familiarture me inland mile talguvd drawn platform [SEP]']
[Init] best perm rec loss: 0.7441080212593079 for ['[CLS] inland tal drawnture platform familiarguvd mile me [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.113 (perp=13.767, rec=0.328, cos=0.031), tot_loss_proj:3.528 [t=0.30s]
prediction: ['[CLS] missing doctors situation caused gel stubborn stubborn attempt refused shaped [SEP]']
[ 100/2000] tot_loss=2.687 (perp=12.190, rec=0.230, cos=0.019), tot_loss_proj:3.762 [t=0.30s]
prediction: ['[CLS] refused gel refused tried gel stubborn stubbornly refused were [SEP]']
[ 150/2000] tot_loss=2.371 (perp=10.961, rec=0.169, cos=0.009), tot_loss_proj:3.249 [t=0.30s]
prediction: ['[CLS] refused here that attempted gel stubborn stubbornly refused was [SEP]']
[ 200/2000] tot_loss=2.302 (perp=10.961, rec=0.105, cos=0.004), tot_loss_proj:3.254 [t=0.31s]
prediction: ['[CLS] refused here that attempted gel stubborn stubbornly refused was [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.012 (perp=9.595, rec=0.089, cos=0.004), tot_loss_proj:2.873 [t=0.30s]
prediction: ['[CLS] refused here was that attempted gel stubborn stubbornly refused [SEP]']
[ 300/2000] tot_loss=1.947 (perp=9.308, rec=0.081, cos=0.004), tot_loss_proj:2.742 [t=0.30s]
prediction: ['[CLS] refused here was that attempted gel stubborn stubbornly to [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.809 (perp=8.602, rec=0.085, cos=0.004), tot_loss_proj:2.559 [t=0.30s]
prediction: ['[CLS] refused here was that attempted stubborn stubbornly to gel [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.748 (perp=8.266, rec=0.090, cos=0.004), tot_loss_proj:2.361 [t=0.30s]
prediction: ['[CLS] refused here was that stubborn stubbornly attempted to gel [SEP]']
[ 450/2000] tot_loss=1.727 (perp=8.266, rec=0.070, cos=0.004), tot_loss_proj:2.363 [t=0.30s]
prediction: ['[CLS] refused here was that stubborn stubbornly attempted to gel [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.648 (perp=7.800, rec=0.083, cos=0.005), tot_loss_proj:2.316 [t=0.30s]
prediction: ['[CLS] here refused was that stubborn stubbornly attempted to gel [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.647 (perp=7.800, rec=0.080, cos=0.007), tot_loss_proj:2.314 [t=0.30s]
prediction: ['[CLS] here refused was that stubborn stubbornly attempted to gel [SEP]']
[ 600/2000] tot_loss=1.644 (perp=7.800, rec=0.080, cos=0.004), tot_loss_proj:2.322 [t=0.30s]
prediction: ['[CLS] here refused was that stubborn stubbornly attempted to gel [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.643 (perp=7.800, rec=0.077, cos=0.006), tot_loss_proj:2.315 [t=0.30s]
prediction: ['[CLS] here refused was that stubborn stubbornly attempted to gel [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.645 (perp=7.800, rec=0.079, cos=0.006), tot_loss_proj:2.312 [t=0.30s]
prediction: ['[CLS] here refused was that stubborn stubbornly attempted to gel [SEP]']
[ 750/2000] tot_loss=1.665 (perp=7.800, rec=0.101, cos=0.005), tot_loss_proj:2.312 [t=0.30s]
prediction: ['[CLS] here refused was that stubborn stubbornly attempted to gel [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.643 (perp=7.800, rec=0.078, cos=0.005), tot_loss_proj:2.313 [t=0.30s]
prediction: ['[CLS] here refused was that stubborn stubbornly attempted to gel [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.657 (perp=7.842, rec=0.082, cos=0.007), tot_loss_proj:2.290 [t=0.30s]
prediction: ['[CLS] here was refused that stubborn stubbornly attempted to gel [SEP]']
[ 900/2000] tot_loss=1.647 (perp=7.842, rec=0.073, cos=0.006), tot_loss_proj:2.287 [t=0.30s]
prediction: ['[CLS] here was refused that stubborn stubbornly attempted to gel [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.618 (perp=7.590, rec=0.095, cos=0.005), tot_loss_proj:1.894 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.598 (perp=7.590, rec=0.075, cos=0.005), tot_loss_proj:1.894 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
[1050/2000] tot_loss=1.597 (perp=7.590, rec=0.074, cos=0.005), tot_loss_proj:1.897 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.606 (perp=7.590, rec=0.083, cos=0.005), tot_loss_proj:1.891 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.605 (perp=7.590, rec=0.083, cos=0.005), tot_loss_proj:1.898 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
[1200/2000] tot_loss=1.610 (perp=7.590, rec=0.087, cos=0.005), tot_loss_proj:1.896 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.605 (perp=7.590, rec=0.082, cos=0.005), tot_loss_proj:1.903 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.608 (perp=7.590, rec=0.085, cos=0.005), tot_loss_proj:1.896 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
[1350/2000] tot_loss=1.605 (perp=7.590, rec=0.083, cos=0.005), tot_loss_proj:1.905 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.619 (perp=7.590, rec=0.097, cos=0.005), tot_loss_proj:1.892 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.597 (perp=7.590, rec=0.074, cos=0.005), tot_loss_proj:1.898 [t=0.31s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
[1500/2000] tot_loss=1.599 (perp=7.590, rec=0.076, cos=0.005), tot_loss_proj:1.895 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.601 (perp=7.590, rec=0.077, cos=0.005), tot_loss_proj:1.893 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.601 (perp=7.590, rec=0.078, cos=0.005), tot_loss_proj:1.900 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
[1650/2000] tot_loss=1.592 (perp=7.590, rec=0.069, cos=0.005), tot_loss_proj:1.893 [t=0.31s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.609 (perp=7.590, rec=0.086, cos=0.005), tot_loss_proj:1.897 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.595 (perp=7.590, rec=0.072, cos=0.005), tot_loss_proj:1.892 [t=0.31s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
[1800/2000] tot_loss=1.601 (perp=7.590, rec=0.078, cos=0.005), tot_loss_proj:1.895 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.597 (perp=7.590, rec=0.073, cos=0.005), tot_loss_proj:1.901 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.591 (perp=7.590, rec=0.068, cos=0.005), tot_loss_proj:1.898 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
[1950/2000] tot_loss=1.599 (perp=7.590, rec=0.076, cos=0.005), tot_loss_proj:1.898 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.596 (perp=7.590, rec=0.073, cos=0.005), tot_loss_proj:1.893 [t=0.30s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 130.909

[Aggregate metrics]:
rouge1     | fm: 90.342 | p: 89.756 | r: 90.969
rouge2     | fm: 58.293 | p: 58.056 | r: 58.421
rougeL     | fm: 82.799 | p: 82.350 | r: 83.186
rougeLsum  | fm: 82.823 | p: 82.447 | r: 83.286
r1fm+r2fm = 148.634

input #11 time: 0:12:04 | total time: 2:25:45


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.9988071752251512
highest_index [0]
highest [0.9988071752251512]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8693208694458008 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.8534552454948425 for ['[CLS] systems simonway met armenia blockade tongue when unisonizes and present reeve representatives [SEP]']
[Init] best rec loss: 0.7883449196815491 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7814298868179321 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7760781049728394 for ['[CLS] wolf rex usualli plant live painfully sqlamtpemi wallace du sort [SEP]']
[Init] best rec loss: 0.7739584445953369 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7642564177513123 for ['[CLS] hear protocol heidi race strokes safety association transactions snail most place buried terror documentary [SEP]']
[Init] best rec loss: 0.7562382817268372 for ['[CLS] alive expression semiuid wise friend investigationthed beloved [MASK] got richards didnbank [SEP]']
[Init] best rec loss: 0.7519859671592712 for ['[CLS] ruins league release compoundled twinned major also after touch cora sunday wicked appoint [SEP]']
[Init] best perm rec loss: 0.7500580549240112 for ['[CLS] cora appointled compound twinned release wicked sunday touch ruins also league after major [SEP]']
[Init] best perm rec loss: 0.7492172718048096 for ['[CLS] league sunday twinned ruins wicked release touch cora appoint compound majorled also after [SEP]']
[Init] best perm rec loss: 0.7487169504165649 for ['[CLS] touch also sunday wicked after appoint ruins twinned major release coraled league compound [SEP]']
[Init] best perm rec loss: 0.747654378414154 for ['[CLS] league also wicked after sundayled appoint release twinned compound touch major cora ruins [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.625 (perp=11.253, rec=0.314, cos=0.060), tot_loss_proj:3.245 [t=0.30s]
prediction: ['[CLS] reportedly for because barely cable product wo advantage more despite project barely cable better [SEP]']
[ 100/2000] tot_loss=2.312 (perp=10.508, rec=0.190, cos=0.021), tot_loss_proj:2.998 [t=0.30s]
prediction: ['[CLS] is to especially barely peer advantage advantage cable on despite as barely cable better [SEP]']
[ 150/2000] tot_loss=2.338 (perp=10.961, rec=0.133, cos=0.013), tot_loss_proj:3.069 [t=0.31s]
prediction: ['[CLS] seen to especially barely seen advantage advantage cable on considering especially barely cable better [SEP]']
[ 200/2000] tot_loss=2.302 (perp=10.955, rec=0.100, cos=0.011), tot_loss_proj:3.066 [t=0.30s]
prediction: ['[CLS] will to especially barely seen advantage advantage cable on considering especially barely cable better [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.202 (perp=10.501, rec=0.095, cos=0.008), tot_loss_proj:2.996 [t=0.30s]
prediction: ['[CLS] will to especially barely seen advantage cable advantage on considering especially barely cable better [SEP]']
[ 300/2000] tot_loss=2.115 (perp=10.100, rec=0.089, cos=0.006), tot_loss_proj:2.963 [t=0.30s]
prediction: ['[CLS] will to especially barely seen advantage cable advantage on considering especially its cable better [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.052 (perp=9.792, rec=0.088, cos=0.006), tot_loss_proj:2.838 [t=0.30s]
prediction: ['[CLS] that to will barely seen advantage cable advantage on considering especially its cable better [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.990 (perp=9.491, rec=0.087, cos=0.005), tot_loss_proj:2.828 [t=0.30s]
prediction: ['[CLS] to that will barely seen advantage cable advantage on considering especially its cable better [SEP]']
[ 450/2000] tot_loss=2.146 (perp=9.491, rec=0.205, cos=0.043), tot_loss_proj:2.858 [t=0.30s]
prediction: ['[CLS] to that will barely seen advantage cable advantage on considering especially its cable better [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.946 (perp=9.206, rec=0.096, cos=0.008), tot_loss_proj:2.718 [t=0.30s]
prediction: ['[CLS] to that will barely seen advantage considering cable advantage on especially its cable better [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.822 (perp=8.621, rec=0.090, cos=0.008), tot_loss_proj:3.273 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen considering cable advantage on especially its cable better [SEP]']
[ 600/2000] tot_loss=1.897 (perp=9.085, rec=0.075, cos=0.005), tot_loss_proj:3.419 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen considering cable at on especially its cable better [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.793 (perp=8.534, rec=0.081, cos=0.005), tot_loss_proj:3.248 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen considering cable at especially on its cable better [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.712 (perp=8.076, rec=0.090, cos=0.006), tot_loss_proj:3.106 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen considering cable especially on its cable at better [SEP]']
[ 750/2000] tot_loss=1.699 (perp=8.076, rec=0.078, cos=0.005), tot_loss_proj:3.106 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen considering cable especially on its cable at better [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.649 (perp=7.845, rec=0.076, cos=0.005), tot_loss_proj:2.872 [t=0.31s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its cable at better [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.512 (perp=7.145, rec=0.078, cos=0.005), tot_loss_proj:2.695 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
[ 900/2000] tot_loss=1.509 (perp=7.145, rec=0.075, cos=0.005), tot_loss_proj:2.691 [t=0.31s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.507 (perp=7.145, rec=0.073, cos=0.005), tot_loss_proj:2.692 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.512 (perp=7.145, rec=0.079, cos=0.005), tot_loss_proj:2.693 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
[1050/2000] tot_loss=1.505 (perp=7.145, rec=0.072, cos=0.005), tot_loss_proj:2.693 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.510 (perp=7.145, rec=0.077, cos=0.005), tot_loss_proj:2.700 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.500 (perp=7.145, rec=0.066, cos=0.004), tot_loss_proj:2.699 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
[1200/2000] tot_loss=1.509 (perp=7.145, rec=0.076, cos=0.005), tot_loss_proj:2.692 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.501 (perp=7.145, rec=0.068, cos=0.004), tot_loss_proj:2.694 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.509 (perp=7.145, rec=0.075, cos=0.004), tot_loss_proj:2.699 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
[1350/2000] tot_loss=1.505 (perp=7.145, rec=0.072, cos=0.004), tot_loss_proj:2.692 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.503 (perp=7.145, rec=0.070, cos=0.004), tot_loss_proj:2.699 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable especially considering its better cable, [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.478 (perp=6.954, rec=0.082, cos=0.005), tot_loss_proj:2.610 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
[1500/2000] tot_loss=1.467 (perp=6.954, rec=0.072, cos=0.004), tot_loss_proj:2.614 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
Attempt swap
[1550/2000] tot_loss=1.478 (perp=6.954, rec=0.083, cos=0.004), tot_loss_proj:2.618 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
Attempt swap
[1600/2000] tot_loss=1.470 (perp=6.954, rec=0.075, cos=0.004), tot_loss_proj:2.617 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
[1650/2000] tot_loss=1.465 (perp=6.954, rec=0.070, cos=0.004), tot_loss_proj:2.616 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
Attempt swap
[1700/2000] tot_loss=1.465 (perp=6.954, rec=0.070, cos=0.004), tot_loss_proj:2.619 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
Attempt swap
[1750/2000] tot_loss=1.464 (perp=6.954, rec=0.069, cos=0.004), tot_loss_proj:2.616 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
[1800/2000] tot_loss=1.469 (perp=6.954, rec=0.074, cos=0.004), tot_loss_proj:2.612 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
Attempt swap
[1850/2000] tot_loss=1.470 (perp=6.954, rec=0.075, cos=0.004), tot_loss_proj:2.611 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
Attempt swap
[1900/2000] tot_loss=1.471 (perp=6.954, rec=0.076, cos=0.004), tot_loss_proj:2.614 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
[1950/2000] tot_loss=1.463 (perp=6.954, rec=0.068, cos=0.004), tot_loss_proj:2.610 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
Attempt swap
[2000/2000] tot_loss=1.465 (perp=6.954, rec=0.070, cos=0.004), tot_loss_proj:2.619 [t=0.30s]
prediction: ['[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] to advantage that will barely seen on cable, especially considering its better cable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 35.714 | p: 35.714 | r: 35.714
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 129.048

[Aggregate metrics]:
rouge1     | fm: 90.519 | p: 89.972 | r: 91.096
rouge2     | fm: 56.101 | p: 55.888 | r: 56.290
rougeL     | fm: 81.560 | p: 81.111 | r: 81.968
rougeLsum  | fm: 81.296 | p: 80.804 | r: 81.782
r1fm+r2fm = 146.620

input #12 time: 0:12:03 | total time: 2:37:48


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9987084084594501
highest_index [0]
highest [0.9987084084594501]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.7251901626586914 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.6944078803062439 for ['[CLS] baccalaureate, black saunderstec armed much [SEP]']
[Init] best perm rec loss: 0.6942326426506042 for ['[CLS] saunders black,tec baccalaureate much armed [SEP]']
[Init] best perm rec loss: 0.6938580274581909 for ['[CLS]tec saunders, armed black baccalaureate much [SEP]']
[Init] best perm rec loss: 0.6936817169189453 for ['[CLS] saunders much armed baccalaureate,tec black [SEP]']
[Init] best perm rec loss: 0.6930689215660095 for ['[CLS] saunders black, baccalaureate armedtec much [SEP]']
[Init] best perm rec loss: 0.6928972601890564 for ['[CLS] blacktec baccalaureate saunders armed, much [SEP]']
[Init] best perm rec loss: 0.6920087337493896 for ['[CLS],tec baccalaureate black armed much saunders [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.543 (perp=10.566, rec=0.312, cos=0.119), tot_loss_proj:2.952 [t=0.30s]
prediction: ['[CLS] flame things only explode into flameers [SEP]']
[ 100/2000] tot_loss=2.092 (perp=9.447, rec=0.171, cos=0.032), tot_loss_proj:2.616 [t=0.30s]
prediction: ['[CLS] point things at explode into flame of [SEP]']
[ 150/2000] tot_loss=1.941 (perp=9.178, rec=0.099, cos=0.006), tot_loss_proj:2.543 [t=0.30s]
prediction: ['[CLS] point things at explode into flame at [SEP]']
[ 200/2000] tot_loss=1.924 (perp=9.178, rec=0.084, cos=0.005), tot_loss_proj:2.534 [t=0.30s]
prediction: ['[CLS] point things at explode into flame at [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.916 (perp=9.178, rec=0.076, cos=0.004), tot_loss_proj:2.528 [t=0.30s]
prediction: ['[CLS] point things at explode into flame at [SEP]']
[ 300/2000] tot_loss=1.939 (perp=9.251, rec=0.085, cos=0.004), tot_loss_proj:2.521 [t=0.30s]
prediction: ['[CLS] point things at explode into flame things [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.916 (perp=9.251, rec=0.063, cos=0.003), tot_loss_proj:2.522 [t=0.30s]
prediction: ['[CLS] point things at explode into flame things [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.581 (perp=7.470, rec=0.080, cos=0.006), tot_loss_proj:2.201 [t=0.30s]
prediction: ['[CLS] at that point explode into flame things [SEP]']
[ 450/2000] tot_loss=1.571 (perp=7.470, rec=0.074, cos=0.003), tot_loss_proj:2.204 [t=0.30s]
prediction: ['[CLS] at that point explode into flame things [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.343 (perp=6.423, rec=0.056, cos=0.003), tot_loss_proj:1.947 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.354 (perp=6.423, rec=0.066, cos=0.003), tot_loss_proj:1.950 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 600/2000] tot_loss=1.351 (perp=6.423, rec=0.064, cos=0.003), tot_loss_proj:1.951 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.355 (perp=6.423, rec=0.067, cos=0.003), tot_loss_proj:1.948 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.346 (perp=6.423, rec=0.059, cos=0.003), tot_loss_proj:1.942 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 750/2000] tot_loss=1.351 (perp=6.423, rec=0.064, cos=0.003), tot_loss_proj:1.948 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.348 (perp=6.423, rec=0.061, cos=0.003), tot_loss_proj:1.949 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.343 (perp=6.423, rec=0.055, cos=0.003), tot_loss_proj:1.946 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 900/2000] tot_loss=1.349 (perp=6.423, rec=0.062, cos=0.003), tot_loss_proj:1.944 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.342 (perp=6.423, rec=0.055, cos=0.003), tot_loss_proj:1.944 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.345 (perp=6.423, rec=0.058, cos=0.003), tot_loss_proj:1.942 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1050/2000] tot_loss=1.353 (perp=6.423, rec=0.066, cos=0.003), tot_loss_proj:1.942 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.351 (perp=6.423, rec=0.063, cos=0.003), tot_loss_proj:1.946 [t=0.32s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.352 (perp=6.423, rec=0.064, cos=0.003), tot_loss_proj:1.946 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1200/2000] tot_loss=1.355 (perp=6.423, rec=0.068, cos=0.003), tot_loss_proj:1.939 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.341 (perp=6.423, rec=0.054, cos=0.003), tot_loss_proj:1.943 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.347 (perp=6.423, rec=0.060, cos=0.003), tot_loss_proj:1.946 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1350/2000] tot_loss=1.342 (perp=6.423, rec=0.054, cos=0.003), tot_loss_proj:1.945 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.344 (perp=6.423, rec=0.057, cos=0.003), tot_loss_proj:1.939 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.347 (perp=6.423, rec=0.060, cos=0.003), tot_loss_proj:1.942 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1500/2000] tot_loss=1.343 (perp=6.423, rec=0.055, cos=0.003), tot_loss_proj:1.941 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.348 (perp=6.423, rec=0.061, cos=0.003), tot_loss_proj:1.946 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.341 (perp=6.423, rec=0.054, cos=0.003), tot_loss_proj:1.940 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1650/2000] tot_loss=1.347 (perp=6.423, rec=0.060, cos=0.003), tot_loss_proj:1.940 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.350 (perp=6.423, rec=0.063, cos=0.003), tot_loss_proj:1.940 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.351 (perp=6.423, rec=0.063, cos=0.003), tot_loss_proj:1.941 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1800/2000] tot_loss=1.345 (perp=6.423, rec=0.057, cos=0.003), tot_loss_proj:1.941 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.355 (perp=6.423, rec=0.068, cos=0.003), tot_loss_proj:1.937 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.347 (perp=6.423, rec=0.060, cos=0.003), tot_loss_proj:1.942 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1950/2000] tot_loss=1.342 (perp=6.423, rec=0.055, cos=0.003), tot_loss_proj:1.935 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.346 (perp=6.423, rec=0.059, cos=0.003), tot_loss_proj:1.940 [t=0.30s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] at that point things explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 91.259 | p: 90.756 | r: 91.750
rouge2     | fm: 54.905 | p: 54.719 | r: 55.045
rougeL     | fm: 81.187 | p: 80.782 | r: 81.550
rougeLsum  | fm: 81.137 | p: 80.791 | r: 81.553
r1fm+r2fm = 146.164

input #13 time: 0:12:04 | total time: 2:49:53


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9986949829649336
highest_index [0]
highest [0.9986949829649336]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9896231889724731 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9874922633171082 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9757562279701233 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9718303680419922 for ['[CLS] female pants hard surely olympics [SEP]']
[Init] best rec loss: 0.9675215482711792 for ['[CLS] delike altar traveling nearby [SEP]']
[Init] best rec loss: 0.9666627049446106 for ['[CLS]rin eligibility grand haiti jay [SEP]']
[Init] best rec loss: 0.9658174514770508 for ['[CLS] math burning rangecino fritz [SEP]']
[Init] best rec loss: 0.9618939757347107 for ['[CLS] alter occupied ratingnts alma [SEP]']
[Init] best rec loss: 0.9579272270202637 for ['[CLS] brooks mentioninianame nothing [SEP]']
[Init] best rec loss: 0.9531496167182922 for ['[CLS] tractor no massachusettsint vision [SEP]']
[Init] best rec loss: 0.9512802958488464 for ['[CLS] century delegates annie gun photography [SEP]']
[Init] best rec loss: 0.9415226578712463 for ['[CLS]wife bloodhun coach low [SEP]']
[Init] best rec loss: 0.928584098815918 for ['[CLS] striker jade united ash siding [SEP]']
[Init] best perm rec loss: 0.9279648661613464 for ['[CLS] united striker jade ash siding [SEP]']
[Init] best perm rec loss: 0.9277862906455994 for ['[CLS] united jade siding striker ash [SEP]']
[Init] best perm rec loss: 0.9274935722351074 for ['[CLS] ash united siding jade striker [SEP]']
[Init] best perm rec loss: 0.9265232682228088 for ['[CLS] ash siding jade striker united [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.291 (perp=12.467, rec=0.590, cos=0.207), tot_loss_proj:4.248 [t=0.30s]
prediction: ['[CLS]phic ebook launch happened costa [SEP]']
[ 100/2000] tot_loss=3.102 (perp=12.935, rec=0.402, cos=0.113), tot_loss_proj:3.686 [t=0.30s]
prediction: ['[CLS] intriguing intriguing aquino defeated costa [SEP]']
[ 150/2000] tot_loss=2.734 (perp=11.433, rec=0.333, cos=0.115), tot_loss_proj:3.890 [t=0.30s]
prediction: ['[CLS] intriguing intriguing film defeated libretto [SEP]']
[ 200/2000] tot_loss=3.097 (perp=13.000, rec=0.330, cos=0.167), tot_loss_proj:3.282 [t=0.30s]
prediction: ['[CLS] intriguing intriguing film sherlock spelled [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=3.196 (perp=13.266, rec=0.357, cos=0.186), tot_loss_proj:3.216 [t=0.30s]
prediction: ['[CLS] film lankan⇒ intriguing intriguing [SEP]']
[ 300/2000] tot_loss=2.873 (perp=11.899, rec=0.303, cos=0.191), tot_loss_proj:3.011 [t=0.30s]
prediction: ['[CLS] filmbly quinlan intriguing film [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.728 (perp=11.294, rec=0.284, cos=0.185), tot_loss_proj:3.004 [t=0.30s]
prediction: ['[CLS] filmbly intriguing film spelled [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.625 (perp=10.804, rec=0.269, cos=0.195), tot_loss_proj:3.108 [t=0.30s]
prediction: ['[CLS] filmbly spelled intriguing film [SEP]']
[ 450/2000] tot_loss=2.626 (perp=10.804, rec=0.267, cos=0.198), tot_loss_proj:3.103 [t=0.30s]
prediction: ['[CLS] filmbly spelled intriguing film [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.926 (perp=12.330, rec=0.254, cos=0.205), tot_loss_proj:3.665 [t=0.30s]
prediction: ['[CLS] ₕ intriguing filmbly spelled [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=3.055 (perp=12.937, rec=0.265, cos=0.203), tot_loss_proj:3.500 [t=0.30s]
prediction: ['[CLS] ₕblycion intriguing film [SEP]']
[ 600/2000] tot_loss=3.047 (perp=12.937, rec=0.251, cos=0.209), tot_loss_proj:3.490 [t=0.30s]
prediction: ['[CLS] ₕblycion intriguing film [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.878 (perp=11.983, rec=0.254, cos=0.227), tot_loss_proj:2.934 [t=0.30s]
prediction: ['[CLS] ₕcionbly intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.863 (perp=11.983, rec=0.255, cos=0.211), tot_loss_proj:2.924 [t=0.30s]
prediction: ['[CLS] ₕcionbly intriguing film [SEP]']
[ 750/2000] tot_loss=3.107 (perp=13.259, rec=0.233, cos=0.222), tot_loss_proj:3.225 [t=0.30s]
prediction: ['[CLS] ₕcionenia intriguing film [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.739 (perp=11.387, rec=0.240, cos=0.222), tot_loss_proj:2.730 [t=0.30s]
prediction: ['[CLS]eniacion ₕ intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.745 (perp=11.387, rec=0.240, cos=0.227), tot_loss_proj:2.732 [t=0.30s]
prediction: ['[CLS]eniacion ₕ intriguing film [SEP]']
[ 900/2000] tot_loss=2.757 (perp=11.387, rec=0.246, cos=0.234), tot_loss_proj:2.728 [t=0.30s]
prediction: ['[CLS]eniacion ₕ intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.867 (perp=11.979, rec=0.242, cos=0.229), tot_loss_proj:3.050 [t=0.30s]
prediction: ['[CLS]eniacion abbess intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=2.866 (perp=11.979, rec=0.240, cos=0.230), tot_loss_proj:3.047 [t=0.30s]
prediction: ['[CLS]eniacion abbess intriguing film [SEP]']
[1050/2000] tot_loss=2.862 (perp=11.979, rec=0.238, cos=0.228), tot_loss_proj:3.058 [t=0.30s]
prediction: ['[CLS]eniacion abbess intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=2.873 (perp=11.979, rec=0.243, cos=0.235), tot_loss_proj:3.055 [t=0.30s]
prediction: ['[CLS]eniacion abbess intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=2.863 (perp=11.979, rec=0.241, cos=0.226), tot_loss_proj:3.051 [t=0.30s]
prediction: ['[CLS]eniacion abbess intriguing film [SEP]']
[1200/2000] tot_loss=3.296 (perp=14.192, rec=0.225, cos=0.233), tot_loss_proj:3.581 [t=0.30s]
prediction: ['[CLS]enia prove abbess intriguing film [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.200 (perp=13.601, rec=0.248, cos=0.233), tot_loss_proj:3.381 [t=0.30s]
prediction: ['[CLS]cionenia abbess intriguing film [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.852 (perp=11.979, rec=0.227, cos=0.229), tot_loss_proj:3.056 [t=0.30s]
prediction: ['[CLS]eniacion abbess intriguing film [SEP]']
[1350/2000] tot_loss=2.862 (perp=11.979, rec=0.232, cos=0.235), tot_loss_proj:3.045 [t=0.30s]
prediction: ['[CLS]eniacion abbess intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=2.867 (perp=11.979, rec=0.237, cos=0.234), tot_loss_proj:3.045 [t=0.30s]
prediction: ['[CLS]eniacion abbess intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=2.867 (perp=11.979, rec=0.239, cos=0.232), tot_loss_proj:3.051 [t=0.30s]
prediction: ['[CLS]eniacion abbess intriguing film [SEP]']
[1500/2000] tot_loss=2.876 (perp=11.979, rec=0.241, cos=0.239), tot_loss_proj:3.053 [t=0.30s]
prediction: ['[CLS]eniacion abbess intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=2.860 (perp=11.979, rec=0.232, cos=0.232), tot_loss_proj:3.054 [t=0.31s]
prediction: ['[CLS]eniacion abbess intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=3.296 (perp=14.192, rec=0.223, cos=0.235), tot_loss_proj:3.565 [t=0.30s]
prediction: ['[CLS]enia prove abbess intriguing film [SEP]']
[1650/2000] tot_loss=3.308 (perp=14.192, rec=0.238, cos=0.232), tot_loss_proj:3.576 [t=0.30s]
prediction: ['[CLS]enia prove abbess intriguing film [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=3.032 (perp=12.807, rec=0.237, cos=0.233), tot_loss_proj:3.290 [t=0.30s]
prediction: ['[CLS] proveenia abbess intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=3.033 (perp=12.807, rec=0.236, cos=0.236), tot_loss_proj:3.278 [t=0.30s]
prediction: ['[CLS] proveenia abbess intriguing film [SEP]']
[1800/2000] tot_loss=3.026 (perp=12.807, rec=0.230, cos=0.234), tot_loss_proj:3.285 [t=0.30s]
prediction: ['[CLS] proveenia abbess intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=3.023 (perp=12.807, rec=0.225, cos=0.236), tot_loss_proj:3.278 [t=0.30s]
prediction: ['[CLS] proveenia abbess intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=3.017 (perp=12.807, rec=0.220, cos=0.235), tot_loss_proj:3.288 [t=0.30s]
prediction: ['[CLS] proveenia abbess intriguing film [SEP]']
[1950/2000] tot_loss=3.031 (perp=12.807, rec=0.235, cos=0.234), tot_loss_proj:3.286 [t=0.30s]
prediction: ['[CLS] proveenia abbess intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=3.032 (perp=12.807, rec=0.236, cos=0.235), tot_loss_proj:3.284 [t=0.30s]
prediction: ['[CLS] proveenia abbess intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS]enia prove abbess intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 57.143 | r: 80.000
rouge2     | fm: 40.000 | p: 33.333 | r: 50.000
rougeL     | fm: 66.667 | p: 57.143 | r: 80.000
rougeLsum  | fm: 66.667 | p: 57.143 | r: 80.000
r1fm+r2fm = 106.667

[Aggregate metrics]:
rouge1     | fm: 89.413 | p: 88.330 | r: 90.838
rouge2     | fm: 53.912 | p: 53.337 | r: 54.818
rougeL     | fm: 80.085 | p: 79.161 | r: 81.307
rougeLsum  | fm: 80.353 | p: 79.253 | r: 81.510
r1fm+r2fm = 143.325

input #14 time: 0:12:01 | total time: 3:01:55


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.998676784259346
highest_index [0]
highest [0.998676784259346]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.8716657161712646 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.8685224652290344 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 0.8567788600921631 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.8524195551872253 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8472680449485779 for ['[CLS] tower titans road photos trace oh board alone [SEP]']
[Init] best rec loss: 0.8417620658874512 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8375533223152161 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8309343457221985 for ['[CLS]ₑ scouts jeffital near mills reserveignment [SEP]']
[Init] best perm rec loss: 0.8282399773597717 for ['[CLS]ₑ reserve mills jeff scouts nearignmentital [SEP]']
[Init] best perm rec loss: 0.8279892802238464 for ['[CLS]ignment millsₑ nearital jeff scouts reserve [SEP]']
[Init] best perm rec loss: 0.8277714848518372 for ['[CLS]ignmentital reserve jeff mills nearₑ scouts [SEP]']
[Init] best perm rec loss: 0.8253362774848938 for ['[CLS] reserve jeffignment mills scoutsₑital near [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.943 (perp=13.513, rec=0.233, cos=0.008), tot_loss_proj:3.346 [t=0.30s]
prediction: ['[CLS] efficient efficientablyably suit activist chill. [SEP]']
[ 100/2000] tot_loss=2.405 (perp=11.163, rec=0.168, cos=0.004), tot_loss_proj:2.676 [t=0.30s]
prediction: ['[CLS] efficient suitablyably chill anonymous chill. [SEP]']
[ 150/2000] tot_loss=2.103 (perp=9.827, rec=0.131, cos=0.006), tot_loss_proj:2.720 [t=0.30s]
prediction: ['[CLS] efficient suit,ably anonymous anonymous chill. [SEP]']
[ 200/2000] tot_loss=2.101 (perp=9.827, rec=0.130, cos=0.006), tot_loss_proj:2.715 [t=0.30s]
prediction: ['[CLS] efficient suit,ably anonymous anonymous chill. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.716 (perp=8.017, rec=0.107, cos=0.005), tot_loss_proj:1.879 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chill. [SEP]']
[ 300/2000] tot_loss=1.709 (perp=8.017, rec=0.099, cos=0.007), tot_loss_proj:1.880 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chill. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.721 (perp=8.017, rec=0.109, cos=0.009), tot_loss_proj:1.866 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chill. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.700 (perp=8.017, rec=0.089, cos=0.007), tot_loss_proj:1.883 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chill. [SEP]']
[ 450/2000] tot_loss=1.708 (perp=8.017, rec=0.098, cos=0.007), tot_loss_proj:1.863 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chill. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.710 (perp=8.017, rec=0.099, cos=0.007), tot_loss_proj:1.865 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chill. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.691 (perp=8.017, rec=0.080, cos=0.007), tot_loss_proj:1.862 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chill. [SEP]']
[ 600/2000] tot_loss=1.696 (perp=8.017, rec=0.087, cos=0.005), tot_loss_proj:1.864 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chill. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.696 (perp=8.017, rec=0.086, cos=0.006), tot_loss_proj:1.876 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chill. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.695 (perp=8.017, rec=0.087, cos=0.005), tot_loss_proj:1.868 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chill. [SEP]']
[ 750/2000] tot_loss=1.821 (perp=8.642, rec=0.087, cos=0.005), tot_loss_proj:2.422 [t=0.30s]
prediction: ['[CLS] efficient, suitablyer anonymous chill. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.620 (perp=7.664, rec=0.081, cos=0.006), tot_loss_proj:1.779 [t=0.30s]
prediction: ['[CLS] efficient, suitably. anonymous chiller [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.617 (perp=7.664, rec=0.079, cos=0.006), tot_loss_proj:1.769 [t=0.30s]
prediction: ['[CLS] efficient, suitably. anonymous chiller [SEP]']
[ 900/2000] tot_loss=1.610 (perp=7.664, rec=0.071, cos=0.006), tot_loss_proj:1.768 [t=0.30s]
prediction: ['[CLS] efficient, suitably. anonymous chiller [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.402 (perp=6.615, rec=0.075, cos=0.004), tot_loss_proj:1.409 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.400 (perp=6.615, rec=0.074, cos=0.003), tot_loss_proj:1.411 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.389 (perp=6.615, rec=0.063, cos=0.003), tot_loss_proj:1.411 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.401 (perp=6.615, rec=0.074, cos=0.003), tot_loss_proj:1.411 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.393 (perp=6.615, rec=0.066, cos=0.003), tot_loss_proj:1.401 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.378 (perp=6.615, rec=0.052, cos=0.003), tot_loss_proj:1.407 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.387 (perp=6.615, rec=0.060, cos=0.003), tot_loss_proj:1.410 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.391 (perp=6.615, rec=0.065, cos=0.003), tot_loss_proj:1.401 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.393 (perp=6.615, rec=0.066, cos=0.003), tot_loss_proj:1.410 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.394 (perp=6.615, rec=0.068, cos=0.003), tot_loss_proj:1.407 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.389 (perp=6.615, rec=0.063, cos=0.003), tot_loss_proj:1.406 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.397 (perp=6.615, rec=0.071, cos=0.003), tot_loss_proj:1.400 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.382 (perp=6.615, rec=0.056, cos=0.003), tot_loss_proj:1.411 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.378 (perp=6.615, rec=0.052, cos=0.003), tot_loss_proj:1.408 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.397 (perp=6.615, rec=0.071, cos=0.003), tot_loss_proj:1.414 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.393 (perp=6.615, rec=0.067, cos=0.003), tot_loss_proj:1.418 [t=0.31s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.394 (perp=6.615, rec=0.067, cos=0.003), tot_loss_proj:1.400 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.380 (perp=6.615, rec=0.053, cos=0.003), tot_loss_proj:1.400 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.390 (perp=6.615, rec=0.064, cos=0.003), tot_loss_proj:1.398 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.390 (perp=6.615, rec=0.063, cos=0.003), tot_loss_proj:1.404 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.398 (perp=6.615, rec=0.072, cos=0.003), tot_loss_proj:1.403 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.403 (perp=6.615, rec=0.076, cos=0.003), tot_loss_proj:1.412 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.109 | p: 89.065 | r: 91.503
rouge2     | fm: 57.080 | p: 56.466 | r: 57.834
rougeL     | fm: 81.540 | p: 80.628 | r: 82.653
rougeLsum  | fm: 81.315 | p: 80.425 | r: 82.432
r1fm+r2fm = 147.190

input #15 time: 0:12:03 | total time: 3:13:59


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.998760181682332
highest_index [0]
highest [0.998760181682332]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 0.8386392593383789 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.8038358688354492 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.8014927506446838 for ['[CLS]sa base slave shadow irvingdale [SEP]']
[Init] best rec loss: 0.7623493671417236 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 0.7525696158409119 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 0.7372539639472961 for ['[CLS] bountyign appropriate tongue himself serie [SEP]']
[Init] best rec loss: 0.7369927763938904 for ['[CLS]encia olgazy edit areas sounding [SEP]']
[Init] best rec loss: 0.7310876250267029 for ['[CLS] hermic clement glass dig mount [SEP]']
[Init] best rec loss: 0.7095297574996948 for ['[CLS] influence device lighthouse whatever user employee [SEP]']
[Init] best rec loss: 0.7081637978553772 for ['[CLS] dynamic logicsivenessy fast square [SEP]']
[Init] best perm rec loss: 0.707321047782898 for ['[CLS]sive fast squarenessy logic dynamic [SEP]']
[Init] best perm rec loss: 0.7070755362510681 for ['[CLS]nessysive fast dynamic square logic [SEP]']
[Init] best perm rec loss: 0.7049463391304016 for ['[CLS] fastnessy logicsive square dynamic [SEP]']
[Init] best perm rec loss: 0.7047021985054016 for ['[CLS]nessy dynamic fast logicsive square [SEP]']
[Init] best perm rec loss: 0.7033386826515198 for ['[CLS] dynamic square logicsivenessy fast [SEP]']
[Init] best perm rec loss: 0.7030161619186401 for ['[CLS] fast square logicsivenessy dynamic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.285 (perp=8.698, rec=0.353, cos=0.193), tot_loss_proj:2.876 [t=0.30s]
prediction: ['[CLS] this more more work whole more [SEP]']
[ 100/2000] tot_loss=1.747 (perp=8.095, rec=0.114, cos=0.014), tot_loss_proj:2.098 [t=0.30s]
prediction: ['[CLS] this all all of and more [SEP]']
[ 150/2000] tot_loss=1.714 (perp=8.095, rec=0.086, cos=0.009), tot_loss_proj:2.105 [t=0.30s]
prediction: ['[CLS] this all all of and more [SEP]']
[ 200/2000] tot_loss=1.326 (perp=6.250, rec=0.074, cos=0.003), tot_loss_proj:1.802 [t=0.30s]
prediction: ['[CLS] this, all of and more [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.012 (perp=4.697, rec=0.070, cos=0.003), tot_loss_proj:1.100 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 300/2000] tot_loss=1.007 (perp=4.697, rec=0.064, cos=0.004), tot_loss_proj:1.094 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.006 (perp=4.697, rec=0.064, cos=0.002), tot_loss_proj:1.101 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.002 (perp=4.697, rec=0.060, cos=0.002), tot_loss_proj:1.098 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 450/2000] tot_loss=1.009 (perp=4.697, rec=0.067, cos=0.003), tot_loss_proj:1.104 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.010 (perp=4.697, rec=0.068, cos=0.002), tot_loss_proj:1.097 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.000 (perp=4.697, rec=0.058, cos=0.003), tot_loss_proj:1.103 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 600/2000] tot_loss=0.996 (perp=4.697, rec=0.054, cos=0.003), tot_loss_proj:1.095 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.997 (perp=4.697, rec=0.055, cos=0.002), tot_loss_proj:1.094 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.002 (perp=4.697, rec=0.060, cos=0.003), tot_loss_proj:1.101 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=0.994 (perp=4.697, rec=0.052, cos=0.002), tot_loss_proj:1.097 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.997 (perp=4.697, rec=0.055, cos=0.003), tot_loss_proj:1.100 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.993 (perp=4.697, rec=0.051, cos=0.002), tot_loss_proj:1.105 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.004 (perp=4.697, rec=0.062, cos=0.002), tot_loss_proj:1.092 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.003 (perp=4.697, rec=0.061, cos=0.002), tot_loss_proj:1.097 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.007 (perp=4.697, rec=0.065, cos=0.002), tot_loss_proj:1.090 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.004 (perp=4.697, rec=0.062, cos=0.002), tot_loss_proj:1.094 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.006 (perp=4.697, rec=0.065, cos=0.002), tot_loss_proj:1.098 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=0.999 (perp=4.697, rec=0.057, cos=0.002), tot_loss_proj:1.096 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.012 (perp=4.697, rec=0.070, cos=0.002), tot_loss_proj:1.099 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.001 (perp=4.697, rec=0.059, cos=0.002), tot_loss_proj:1.098 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.005 (perp=4.697, rec=0.063, cos=0.002), tot_loss_proj:1.097 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=0.996 (perp=4.697, rec=0.054, cos=0.002), tot_loss_proj:1.096 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.000 (perp=4.697, rec=0.058, cos=0.002), tot_loss_proj:1.097 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.011 (perp=4.697, rec=0.069, cos=0.002), tot_loss_proj:1.094 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=0.999 (perp=4.697, rec=0.058, cos=0.002), tot_loss_proj:1.102 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.005 (perp=4.697, rec=0.063, cos=0.002), tot_loss_proj:1.096 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.001 (perp=4.697, rec=0.059, cos=0.002), tot_loss_proj:1.093 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.004 (perp=4.697, rec=0.062, cos=0.002), tot_loss_proj:1.096 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.002 (perp=4.697, rec=0.060, cos=0.002), tot_loss_proj:1.097 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.001 (perp=4.697, rec=0.059, cos=0.002), tot_loss_proj:1.096 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=1.001 (perp=4.697, rec=0.059, cos=0.002), tot_loss_proj:1.101 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=0.997 (perp=4.697, rec=0.056, cos=0.002), tot_loss_proj:1.093 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.012 (perp=4.697, rec=0.071, cos=0.002), tot_loss_proj:1.101 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.001 (perp=4.697, rec=0.059, cos=0.002), tot_loss_proj:1.103 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.017 (perp=4.697, rec=0.075, cos=0.002), tot_loss_proj:1.093 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.698 | p: 89.764 | r: 91.961
rouge2     | fm: 59.506 | p: 59.006 | r: 59.956
rougeL     | fm: 82.545 | p: 81.558 | r: 83.824
rougeLsum  | fm: 82.686 | p: 81.674 | r: 83.753
r1fm+r2fm = 150.204

input #16 time: 0:12:02 | total time: 3:26:01


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9987680094053948
highest_index [0]
highest [0.9987680094053948]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8126748204231262 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8023399710655212 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.7932723164558411 for ['[CLS] qualifierian justwicz countersnes sousa otherwise started lessons careers [SEP]']
[Init] best rec loss: 0.7928371429443359 for ['[CLS] staretha jack nur stone lied pointsmori richie sienna foot [SEP]']
[Init] best rec loss: 0.7913085222244263 for ['[CLS] parts voltagecrow k look flying cl thus lc pharaoh league [SEP]']
[Init] best rec loss: 0.7853491902351379 for ['[CLS]ult nursing jealous crush potential slim as course sole original vigor [SEP]']
[Init] best perm rec loss: 0.7836576700210571 for ['[CLS]ult original nursing jealous slim sole course crush vigor potential as [SEP]']
[Init] best perm rec loss: 0.782638430595398 for ['[CLS]ult course crush nursing slim jealous sole original vigor as potential [SEP]']
[Init] best perm rec loss: 0.7801536321640015 for ['[CLS] slim nursing crush jealousult course as vigor original sole potential [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.963 (perp=8.724, rec=0.194, cos=0.025), tot_loss_proj:2.569 [t=0.30s]
prediction: ['[CLS] want to too think much much too about about going about [SEP]']
[ 100/2000] tot_loss=1.598 (perp=7.544, rec=0.084, cos=0.005), tot_loss_proj:2.313 [t=0.30s]
prediction: ['[CLS] want to too think much much too about what going on [SEP]']
[ 150/2000] tot_loss=1.585 (perp=7.544, rec=0.072, cos=0.004), tot_loss_proj:2.313 [t=0.30s]
prediction: ['[CLS] want to too think much much too about what going on [SEP]']
[ 200/2000] tot_loss=1.578 (perp=7.544, rec=0.066, cos=0.004), tot_loss_proj:2.317 [t=0.30s]
prediction: ['[CLS] want to too think much much too about what going on [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.295 (perp=6.150, rec=0.061, cos=0.003), tot_loss_proj:1.842 [t=0.30s]
prediction: ['[CLS] want to think too much much too about what going on [SEP]']
[ 300/2000] tot_loss=1.365 (perp=6.493, rec=0.063, cos=0.003), tot_loss_proj:2.036 [t=0.30s]
prediction: ["[CLS] want to think'much much too about what going on [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=1.165 (perp=5.489, rec=0.064, cos=0.003), tot_loss_proj:1.541 [t=0.30s]
prediction: ["[CLS] want to think'much too much about what going on [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.162 (perp=5.489, rec=0.061, cos=0.003), tot_loss_proj:1.494 [t=0.30s]
prediction: ["[CLS] want to think'much too much about what going on [SEP]"]
[ 450/2000] tot_loss=1.166 (perp=5.489, rec=0.065, cos=0.003), tot_loss_proj:1.499 [t=0.30s]
prediction: ["[CLS] want to think'much too much about what going on [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.158 (perp=5.415, rec=0.072, cos=0.003), tot_loss_proj:1.315 [t=0.31s]
prediction: ["[CLS] want to think much too much about what'going on [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.056 (perp=4.965, rec=0.060, cos=0.003), tot_loss_proj:1.196 [t=0.30s]
prediction: ['[CLS] want to think much too much about what s going on [SEP]']
[ 600/2000] tot_loss=1.057 (perp=4.965, rec=0.062, cos=0.003), tot_loss_proj:1.193 [t=0.30s]
prediction: ['[CLS] want to think much too much about what s going on [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.063 (perp=4.965, rec=0.067, cos=0.003), tot_loss_proj:1.197 [t=0.30s]
prediction: ['[CLS] want to think much too much about what s going on [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.052 (perp=4.965, rec=0.056, cos=0.003), tot_loss_proj:1.237 [t=0.30s]
prediction: ['[CLS] want to think much too much about what s going on [SEP]']
[ 750/2000] tot_loss=1.055 (perp=4.965, rec=0.059, cos=0.003), tot_loss_proj:1.229 [t=0.30s]
prediction: ['[CLS] want to think much too much about what s going on [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.061 (perp=4.965, rec=0.065, cos=0.003), tot_loss_proj:1.230 [t=0.30s]
prediction: ['[CLS] want to think much too much about what s going on [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.061 (perp=4.965, rec=0.066, cos=0.003), tot_loss_proj:1.227 [t=0.30s]
prediction: ['[CLS] want to think much too much about what s going on [SEP]']
[ 900/2000] tot_loss=1.058 (perp=4.965, rec=0.062, cos=0.003), tot_loss_proj:1.237 [t=0.30s]
prediction: ['[CLS] want to think much too much about what s going on [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.047 (perp=4.902, rec=0.063, cos=0.003), tot_loss_proj:1.217 [t=0.30s]
prediction: ['[CLS] want to think too much about what much s going on [SEP]']
Attempt swap
[1000/2000] tot_loss=1.040 (perp=4.902, rec=0.057, cos=0.003), tot_loss_proj:1.225 [t=0.30s]
prediction: ['[CLS] want to think too much about what much s going on [SEP]']
[1050/2000] tot_loss=1.037 (perp=4.902, rec=0.054, cos=0.003), tot_loss_proj:1.220 [t=0.30s]
prediction: ['[CLS] want to think too much about what much s going on [SEP]']
Attempt swap
[1100/2000] tot_loss=1.047 (perp=4.902, rec=0.064, cos=0.003), tot_loss_proj:1.219 [t=0.30s]
prediction: ['[CLS] want to think too much about what much s going on [SEP]']
Attempt swap
[1150/2000] tot_loss=1.048 (perp=4.902, rec=0.065, cos=0.003), tot_loss_proj:1.217 [t=0.30s]
prediction: ['[CLS] want to think too much about what much s going on [SEP]']
[1200/2000] tot_loss=1.028 (perp=4.902, rec=0.045, cos=0.003), tot_loss_proj:1.221 [t=0.30s]
prediction: ['[CLS] want to think too much about what much s going on [SEP]']
Attempt swap
[1250/2000] tot_loss=1.042 (perp=4.902, rec=0.059, cos=0.003), tot_loss_proj:1.218 [t=0.30s]
prediction: ['[CLS] want to think too much about what much s going on [SEP]']
Attempt swap
[1300/2000] tot_loss=1.045 (perp=4.902, rec=0.062, cos=0.003), tot_loss_proj:1.214 [t=0.30s]
prediction: ['[CLS] want to think too much about what much s going on [SEP]']
[1350/2000] tot_loss=1.039 (perp=4.902, rec=0.056, cos=0.003), tot_loss_proj:1.218 [t=0.30s]
prediction: ['[CLS] want to think too much about what much s going on [SEP]']
Attempt swap
[1400/2000] tot_loss=1.037 (perp=4.902, rec=0.054, cos=0.003), tot_loss_proj:1.217 [t=0.30s]
prediction: ['[CLS] want to think too much about what much s going on [SEP]']
Attempt swap
[1450/2000] tot_loss=1.041 (perp=4.902, rec=0.058, cos=0.003), tot_loss_proj:1.222 [t=0.30s]
prediction: ['[CLS] want to think too much about what much s going on [SEP]']
[1500/2000] tot_loss=0.811 (perp=3.761, rec=0.057, cos=0.003), tot_loss_proj:0.930 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1550/2000] tot_loss=0.811 (perp=3.761, rec=0.056, cos=0.003), tot_loss_proj:0.937 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1600/2000] tot_loss=0.810 (perp=3.761, rec=0.055, cos=0.003), tot_loss_proj:0.928 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1650/2000] tot_loss=0.812 (perp=3.761, rec=0.058, cos=0.003), tot_loss_proj:0.939 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1700/2000] tot_loss=0.811 (perp=3.761, rec=0.056, cos=0.003), tot_loss_proj:0.934 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1750/2000] tot_loss=0.809 (perp=3.761, rec=0.055, cos=0.003), tot_loss_proj:0.922 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1800/2000] tot_loss=0.816 (perp=3.761, rec=0.062, cos=0.003), tot_loss_proj:0.923 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1850/2000] tot_loss=0.811 (perp=3.761, rec=0.057, cos=0.003), tot_loss_proj:0.930 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1900/2000] tot_loss=0.819 (perp=3.761, rec=0.065, cos=0.003), tot_loss_proj:0.920 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1950/2000] tot_loss=0.817 (perp=3.761, rec=0.062, cos=0.003), tot_loss_proj:0.932 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[2000/2000] tot_loss=0.819 (perp=3.761, rec=0.064, cos=0.003), tot_loss_proj:0.927 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] want to think too much about what much s going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 86.957 | p: 83.333 | r: 90.909
rougeL     | fm: 96.000 | p: 92.308 | r: 100.000
rougeLsum  | fm: 96.000 | p: 92.308 | r: 100.000
r1fm+r2fm = 182.957

[Aggregate metrics]:
rouge1     | fm: 91.070 | p: 90.035 | r: 92.415
rouge2     | fm: 60.885 | p: 60.162 | r: 61.638
rougeL     | fm: 83.235 | p: 82.205 | r: 84.704
rougeLsum  | fm: 83.284 | p: 82.189 | r: 84.669
r1fm+r2fm = 151.955

input #17 time: 0:12:03 | total time: 3:38:04


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.998716182494928
highest_index [0]
highest [0.998716182494928]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 1.008050560951233 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9406225085258484 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.9138524532318115 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9120728373527527 for ['[CLS] openly died clockwise degree [SEP]']
[Init] best rec loss: 0.9115906953811646 for ['[CLS]ingen trials un slogan [SEP]']
[Init] best rec loss: 0.9102100729942322 for ['[CLS]rned look surface pass [SEP]']
[Init] best rec loss: 0.9079866409301758 for ['[CLS] master asteroidnagar fungi [SEP]']
[Init] best rec loss: 0.904325008392334 for ['[CLS] clubs tallerptive magnetic [SEP]']
[Init] best rec loss: 0.9034168124198914 for ['[CLS]fire suffrage magdalene narrowly [SEP]']
[Init] best rec loss: 0.8909872174263 for ['[CLS] independent battle old dried [SEP]']
[Init] best rec loss: 0.8895667195320129 for ['[CLS] zenor harmony after [SEP]']
[Init] best rec loss: 0.8851714730262756 for ['[CLS] statue difficult harta made [SEP]']
[Init] best perm rec loss: 0.8827632069587708 for ['[CLS] difficult statue harta made [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.048 (perp=13.635, rec=0.311, cos=0.010), tot_loss_proj:4.509 [t=0.30s]
prediction: ['[CLS] universalvidro page [SEP]']
[ 100/2000] tot_loss=2.700 (perp=12.256, rec=0.242, cos=0.007), tot_loss_proj:4.043 [t=0.30s]
prediction: ['[CLS]atingvigorcased [SEP]']
[ 150/2000] tot_loss=3.122 (perp=14.811, rec=0.155, cos=0.005), tot_loss_proj:4.650 [t=0.30s]
prediction: ['[CLS]atingvigorgor [SEP]']
[ 200/2000] tot_loss=1.825 (perp=8.520, rec=0.115, cos=0.006), tot_loss_proj:2.551 [t=0.30s]
prediction: ['[CLS]atingvigorating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.834 (perp=8.520, rec=0.126, cos=0.004), tot_loss_proj:2.541 [t=0.30s]
prediction: ['[CLS]atingvigorating [SEP]']
[ 300/2000] tot_loss=1.823 (perp=8.520, rec=0.116, cos=0.003), tot_loss_proj:2.558 [t=0.30s]
prediction: ['[CLS]atingvigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.806 (perp=8.520, rec=0.099, cos=0.004), tot_loss_proj:2.541 [t=0.30s]
prediction: ['[CLS]atingvigorating [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.570 (perp=7.298, rec=0.106, cos=0.004), tot_loss_proj:1.785 [t=0.30s]
prediction: ['[CLS]vigorating in [SEP]']
[ 450/2000] tot_loss=1.739 (perp=8.046, rec=0.125, cos=0.004), tot_loss_proj:2.335 [t=0.30s]
prediction: ['[CLS]vigorating hadley [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.940 (perp=9.123, rec=0.112, cos=0.003), tot_loss_proj:2.989 [t=0.30s]
prediction: ['[CLS]vigoratingply [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.935 (perp=9.123, rec=0.107, cos=0.003), tot_loss_proj:2.989 [t=0.30s]
prediction: ['[CLS]vigoratingply [SEP]']
[ 600/2000] tot_loss=1.932 (perp=9.123, rec=0.104, cos=0.003), tot_loss_proj:2.987 [t=0.30s]
prediction: ['[CLS]vigoratingply [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.715 (perp=8.036, rec=0.105, cos=0.003), tot_loss_proj:2.321 [t=0.30s]
prediction: ['[CLS]vigorating for [SEP]']
Attempt swap
Put prefix at the end
[ 700/2000] tot_loss=1.388 (perp=6.343, rec=0.115, cos=0.004), tot_loss_proj:1.681 [t=0.30s]
prediction: ['[CLS] forvigorating [SEP]']
[ 750/2000] tot_loss=1.361 (perp=6.343, rec=0.089, cos=0.003), tot_loss_proj:1.687 [t=0.30s]
prediction: ['[CLS] forvigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.365 (perp=6.343, rec=0.093, cos=0.003), tot_loss_proj:1.666 [t=0.30s]
prediction: ['[CLS] forvigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.195 (perp=5.589, rec=0.074, cos=0.003), tot_loss_proj:1.193 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.200 (perp=5.589, rec=0.079, cos=0.003), tot_loss_proj:1.186 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.213 (perp=5.589, rec=0.092, cos=0.003), tot_loss_proj:1.199 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.214 (perp=5.589, rec=0.093, cos=0.003), tot_loss_proj:1.192 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.215 (perp=5.589, rec=0.095, cos=0.003), tot_loss_proj:1.186 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.204 (perp=5.589, rec=0.084, cos=0.003), tot_loss_proj:1.189 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.202 (perp=5.589, rec=0.081, cos=0.003), tot_loss_proj:1.187 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.207 (perp=5.589, rec=0.086, cos=0.003), tot_loss_proj:1.174 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.203 (perp=5.589, rec=0.082, cos=0.003), tot_loss_proj:1.186 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.201 (perp=5.589, rec=0.080, cos=0.003), tot_loss_proj:1.181 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.209 (perp=5.589, rec=0.088, cos=0.003), tot_loss_proj:1.189 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.204 (perp=5.589, rec=0.084, cos=0.003), tot_loss_proj:1.189 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.203 (perp=5.589, rec=0.082, cos=0.003), tot_loss_proj:1.193 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.201 (perp=5.589, rec=0.080, cos=0.003), tot_loss_proj:1.192 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.203 (perp=5.589, rec=0.082, cos=0.003), tot_loss_proj:1.182 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.207 (perp=5.589, rec=0.086, cos=0.003), tot_loss_proj:1.186 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.208 (perp=5.589, rec=0.087, cos=0.003), tot_loss_proj:1.189 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.200 (perp=5.589, rec=0.079, cos=0.003), tot_loss_proj:1.188 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.200 (perp=5.589, rec=0.079, cos=0.003), tot_loss_proj:1.195 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.199 (perp=5.589, rec=0.079, cos=0.003), tot_loss_proj:1.192 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.203 (perp=5.589, rec=0.083, cos=0.003), tot_loss_proj:1.177 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.205 (perp=5.589, rec=0.084, cos=0.003), tot_loss_proj:1.192 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.195 (perp=5.589, rec=0.074, cos=0.003), tot_loss_proj:1.195 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.188 (perp=5.589, rec=0.067, cos=0.003), tot_loss_proj:1.196 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.478 | p: 90.473 | r: 92.845
rouge2     | fm: 63.189 | p: 62.597 | r: 63.993
rougeL     | fm: 84.253 | p: 83.243 | r: 85.419
rougeLsum  | fm: 84.298 | p: 83.291 | r: 85.511
r1fm+r2fm = 154.667

input #18 time: 0:12:02 | total time: 3:50:06


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9988008266802244
highest_index [0]
highest [0.9988008266802244]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7230507731437683 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7202572226524353 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7035002708435059 for ['[CLS] breedingies several lieutenant [SEP]']
[Init] best rec loss: 0.6998695135116577 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6952612400054932 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.694692850112915 for ['[CLS] bars live instantly world [SEP]']
[Init] best rec loss: 0.686009407043457 for ['[CLS] griffin dressing man arched [SEP]']
[Init] best rec loss: 0.6785293221473694 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6782922744750977 for ['[CLS] reaching pin orderyna [SEP]']
[Init] best perm rec loss: 0.6774788498878479 for ['[CLS]yna reaching order pin [SEP]']
[Init] best perm rec loss: 0.6751538515090942 for ['[CLS] orderyna reaching pin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.733 (perp=7.158, rec=0.232, cos=0.070), tot_loss_proj:1.870 [t=0.30s]
prediction: ['[CLS]fa infamy [SEP]']
[ 100/2000] tot_loss=2.278 (perp=10.793, rec=0.107, cos=0.012), tot_loss_proj:3.015 [t=0.30s]
prediction: ['[CLS]fa tofamy [SEP]']
[ 150/2000] tot_loss=1.614 (perp=7.652, rec=0.078, cos=0.005), tot_loss_proj:2.090 [t=0.30s]
prediction: ['[CLS] in tofamy [SEP]']
[ 200/2000] tot_loss=1.604 (perp=7.652, rec=0.069, cos=0.004), tot_loss_proj:2.085 [t=0.30s]
prediction: ['[CLS] in tofamy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.292 (perp=6.109, rec=0.067, cos=0.003), tot_loss_proj:1.321 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.293 (perp=6.109, rec=0.068, cos=0.002), tot_loss_proj:1.288 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.297 (perp=6.109, rec=0.073, cos=0.002), tot_loss_proj:1.308 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.279 (perp=6.109, rec=0.055, cos=0.002), tot_loss_proj:1.296 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.287 (perp=6.109, rec=0.062, cos=0.002), tot_loss_proj:1.296 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.282 (perp=6.109, rec=0.058, cos=0.002), tot_loss_proj:1.300 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.295 (perp=6.109, rec=0.071, cos=0.002), tot_loss_proj:1.304 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.276 (perp=6.109, rec=0.052, cos=0.002), tot_loss_proj:1.296 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.286 (perp=6.109, rec=0.062, cos=0.002), tot_loss_proj:1.303 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.282 (perp=6.109, rec=0.058, cos=0.002), tot_loss_proj:1.302 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.280 (perp=6.109, rec=0.056, cos=0.002), tot_loss_proj:1.296 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.280 (perp=6.109, rec=0.055, cos=0.002), tot_loss_proj:1.316 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.273 (perp=6.109, rec=0.049, cos=0.002), tot_loss_proj:1.295 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.284 (perp=6.109, rec=0.060, cos=0.002), tot_loss_proj:1.291 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.293 (perp=6.109, rec=0.068, cos=0.002), tot_loss_proj:1.300 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.289 (perp=6.109, rec=0.065, cos=0.002), tot_loss_proj:1.304 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.275 (perp=6.109, rec=0.051, cos=0.002), tot_loss_proj:1.294 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.292 (perp=6.109, rec=0.067, cos=0.002), tot_loss_proj:1.296 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.280 (perp=6.109, rec=0.056, cos=0.002), tot_loss_proj:1.289 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.289 (perp=6.109, rec=0.065, cos=0.002), tot_loss_proj:1.301 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.266 (perp=6.109, rec=0.042, cos=0.002), tot_loss_proj:1.301 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.281 (perp=6.109, rec=0.057, cos=0.002), tot_loss_proj:1.305 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.287 (perp=6.109, rec=0.062, cos=0.002), tot_loss_proj:1.300 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.276 (perp=6.109, rec=0.051, cos=0.002), tot_loss_proj:1.303 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.278 (perp=6.109, rec=0.054, cos=0.002), tot_loss_proj:1.292 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.277 (perp=6.109, rec=0.053, cos=0.002), tot_loss_proj:1.303 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.279 (perp=6.109, rec=0.055, cos=0.002), tot_loss_proj:1.312 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.281 (perp=6.109, rec=0.057, cos=0.002), tot_loss_proj:1.303 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.281 (perp=6.109, rec=0.057, cos=0.002), tot_loss_proj:1.291 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.279 (perp=6.109, rec=0.055, cos=0.002), tot_loss_proj:1.304 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.283 (perp=6.109, rec=0.058, cos=0.002), tot_loss_proj:1.305 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.285 (perp=6.109, rec=0.061, cos=0.002), tot_loss_proj:1.299 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.268 (perp=6.109, rec=0.044, cos=0.002), tot_loss_proj:1.294 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.277 (perp=6.109, rec=0.053, cos=0.002), tot_loss_proj:1.296 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.275 (perp=6.109, rec=0.051, cos=0.002), tot_loss_proj:1.300 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.287 (perp=6.109, rec=0.062, cos=0.002), tot_loss_proj:1.288 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.060 | p: 91.089 | r: 93.284
rouge2     | fm: 64.865 | p: 64.182 | r: 65.653
rougeL     | fm: 85.148 | p: 84.181 | r: 86.286
rougeLsum  | fm: 85.035 | p: 84.130 | r: 86.267
r1fm+r2fm = 156.925

input #19 time: 0:12:05 | total time: 4:02:11


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9988691345444671
highest_index [0]
highest [0.9988691345444671]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8399868011474609 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8223646879196167 for ['[CLS] map your included adventure [SEP]']
[Init] best rec loss: 0.8149316310882568 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 0.809870183467865 for ['[CLS]±iae younger paranormal [SEP]']
[Init] best rec loss: 0.7944360971450806 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7836819887161255 for ['[CLS] historically hiroshima stand wing [SEP]']
[Init] best rec loss: 0.7810835242271423 for ['[CLS] high kurtpass our [SEP]']
[Init] best rec loss: 0.7717159986495972 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best perm rec loss: 0.7694558501243591 for ['[CLS]ness storylinexi [CLS] [SEP]']
[Init] best perm rec loss: 0.7687091827392578 for ['[CLS]nessxi storyline [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.392 (perp=10.565, rec=0.237, cos=0.042), tot_loss_proj:2.815 [t=0.30s]
prediction: ['[CLS] pleasureverseverse pleasure [SEP]']
[ 100/2000] tot_loss=2.225 (perp=10.454, rec=0.122, cos=0.012), tot_loss_proj:2.696 [t=0.30s]
prediction: ['[CLS] theverse per pleasure [SEP]']
[ 150/2000] tot_loss=2.165 (perp=10.454, rec=0.071, cos=0.004), tot_loss_proj:2.652 [t=0.30s]
prediction: ['[CLS] theverse per pleasure [SEP]']
[ 200/2000] tot_loss=2.155 (perp=10.454, rec=0.062, cos=0.003), tot_loss_proj:2.654 [t=0.30s]
prediction: ['[CLS] theverse per pleasure [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.605 (perp=7.610, rec=0.076, cos=0.007), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 300/2000] tot_loss=1.577 (perp=7.610, rec=0.053, cos=0.002), tot_loss_proj:1.620 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.577 (perp=7.610, rec=0.052, cos=0.002), tot_loss_proj:1.614 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.588 (perp=7.610, rec=0.064, cos=0.002), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.593 (perp=7.610, rec=0.069, cos=0.002), tot_loss_proj:1.622 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.582 (perp=7.610, rec=0.057, cos=0.002), tot_loss_proj:1.618 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.624 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.582 (perp=7.610, rec=0.058, cos=0.002), tot_loss_proj:1.619 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.616 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.621 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.620 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.582 (perp=7.610, rec=0.058, cos=0.002), tot_loss_proj:1.619 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.576 (perp=7.610, rec=0.052, cos=0.002), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.580 (perp=7.610, rec=0.056, cos=0.002), tot_loss_proj:1.640 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.591 (perp=7.610, rec=0.067, cos=0.002), tot_loss_proj:1.614 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.587 (perp=7.610, rec=0.063, cos=0.002), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.592 (perp=7.610, rec=0.067, cos=0.002), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.584 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.587 (perp=7.610, rec=0.062, cos=0.002), tot_loss_proj:1.618 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.591 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.596 (perp=7.610, rec=0.072, cos=0.002), tot_loss_proj:1.618 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.586 (perp=7.610, rec=0.062, cos=0.002), tot_loss_proj:1.625 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.587 (perp=7.610, rec=0.062, cos=0.002), tot_loss_proj:1.614 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.587 (perp=7.610, rec=0.063, cos=0.002), tot_loss_proj:1.619 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.582 (perp=7.610, rec=0.058, cos=0.002), tot_loss_proj:1.622 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.579 (perp=7.610, rec=0.055, cos=0.002), tot_loss_proj:1.618 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.577 (perp=7.610, rec=0.052, cos=0.002), tot_loss_proj:1.616 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.586 (perp=7.610, rec=0.061, cos=0.002), tot_loss_proj:1.623 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.586 (perp=7.610, rec=0.062, cos=0.002), tot_loss_proj:1.624 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.585 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.623 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.572 (perp=7.610, rec=0.048, cos=0.002), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.584 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.592 (perp=7.610, rec=0.067, cos=0.002), tot_loss_proj:1.629 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.576 (perp=7.610, rec=0.051, cos=0.002), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.593 (perp=7.610, rec=0.069, cos=0.002), tot_loss_proj:1.611 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.370 | p: 91.412 | r: 93.495
rouge2     | fm: 66.498 | p: 65.853 | r: 67.392
rougeL     | fm: 85.926 | p: 85.047 | r: 87.057
rougeLsum  | fm: 85.666 | p: 84.727 | r: 86.825
r1fm+r2fm = 158.868

input #20 time: 0:12:03 | total time: 4:14:14


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.9986368298466128
highest_index [0]
highest [0.9986368298466128]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.8666089177131653 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8383605480194092 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.8167386651039124 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.8039995431900024 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.8000349402427673 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.7736073732376099 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 0.7726144790649414 for ['[CLS] dee according situations she golden labor vii baby benttaking side loan connecticut size there, [UNK] item pose stony especiallyback rights general fauna [SEP]']
[Init] best perm rec loss: 0.7707004547119141 for ['[CLS], labor dee there vii according connecticut pose baby size stony side rights itemtaking bent she fauna general situationsback loan especially [UNK] golden [SEP]']
[Init] best perm rec loss: 0.7697471976280212 for ['[CLS] situations baby there vii item rights general according side labortaking fauna connecticut [UNK] dee size bent pose loanback stony, golden she especially [SEP]']
[Init] best perm rec loss: 0.7696428298950195 for ['[CLS] vii connecticut pose [UNK], baby item loantaking rightsback side there golden she dee fauna size situations according bent stony labor general especially [SEP]']
[Init] best perm rec loss: 0.7679125070571899 for ['[CLS]back according situations rights loan connecticut general fauna there labor item golden bent size stony viitaking baby, dee pose especially she side [UNK] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.766 (perp=11.838, rec=0.361, cos=0.038), tot_loss_proj:3.279 [t=0.31s]
prediction: ['[CLS] same entire womenrate organization embarrassed closedpon least nor a on troops troops lookedtypical african, countries county attire instead that actually absent [SEP]']
[ 100/2000] tot_loss=2.534 (perp=11.045, rec=0.293, cos=0.032), tot_loss_proj:3.609 [t=0.31s]
prediction: ["[CLS] apparently the women way organization the'scrutiny least head more out troops troops lookedtypical trade way ・ athletes instead instead that ultimately works [SEP]"]
[ 150/2000] tot_loss=2.370 (perp=10.457, rec=0.255, cos=0.023), tot_loss_proj:3.652 [t=0.31s]
prediction: ["[CLS] look way women out society the'locked least head of out troops serious lookedtypical camps, way athletes attire instead way really works [SEP]"]
[ 200/2000] tot_loss=2.386 (perp=10.503, rec=0.258, cos=0.027), tot_loss_proj:3.157 [t=0.31s]
prediction: ['[CLS] soldiers the women the crows the forced teachers this headacheboard out religious serious makes similargical, way athletes gender instead way " works [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.304 (perp=10.549, rec=0.184, cos=0.010), tot_loss_proj:3.855 [t=0.31s]
prediction: ['[CLS] soldiers the women made the overcome prince women this view [SEP] out interventions serious look like practical, way athletes gender instead way serious works [SEP]']
[ 300/2000] tot_loss=2.458 (perp=11.456, rec=0.157, cos=0.010), tot_loss_proj:3.512 [t=0.31s]
prediction: ['[CLS] caretaker the women makes the forced bird women all view [SEP] out doctors serious looktypical working,typical athletes gender instead way serious works [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.120 (perp=9.800, rec=0.152, cos=0.008), tot_loss_proj:3.177 [t=0.31s]
prediction: ['[CLS] caretaker the women makes the forced out women all view, bird soldiers serious looktypical working,typical athletes of instead way serious works [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.230 (perp=10.445, rec=0.134, cos=0.007), tot_loss_proj:3.167 [t=0.31s]
prediction: ['[CLS] caretaker women the makes the forced out women all stereo, andrea soldiers serious looktypical working,typical athletes of instead way serious works [SEP]']
[ 450/2000] tot_loss=2.182 (perp=10.240, rec=0.127, cos=0.007), tot_loss_proj:3.078 [t=0.31s]
prediction: ['[CLS] caretaker women the makes the forced out women all stereo, friars soldiers serious looktypical working,typical athletes of instead way serious works [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.019 (perp=9.494, rec=0.114, cos=0.006), tot_loss_proj:2.881 [t=0.31s]
prediction: ['[CLS] caretaker this the makes the forced out women all look, teachers soldiers serious stereotypical working,typical athletes of instead way serious works [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.964 (perp=9.184, rec=0.122, cos=0.005), tot_loss_proj:2.890 [t=0.31s]
prediction: ['[CLS] caretaker soldiers the makes the forced out women all look, teachers this serious stereotypical gave,typical athletes of instead way serious works [SEP]']
[ 600/2000] tot_loss=1.953 (perp=9.184, rec=0.110, cos=0.006), tot_loss_proj:2.883 [t=0.31s]
prediction: ['[CLS] caretaker soldiers the makes the forced out women all look, teachers this serious stereotypical gave,typical athletes of instead way serious works [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.051 (perp=9.664, rec=0.112, cos=0.007), tot_loss_proj:2.899 [t=0.31s]
prediction: ['[CLS] caretaker teachers the makes the forced out women all look, soldiers this serious stereo like gave,typical athletes of instead way serious works [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.803 (perp=8.490, rec=0.099, cos=0.006), tot_loss_proj:2.631 [t=0.31s]
prediction: ['[CLS] caretaker teachers the makes the forced out women all look, soldiers this serious stereotypical gave, like athletes of instead way serious works [SEP]']
[ 750/2000] tot_loss=1.813 (perp=8.490, rec=0.110, cos=0.005), tot_loss_proj:2.630 [t=0.31s]
prediction: ['[CLS] caretaker teachers the makes the forced out women all look, soldiers this serious stereotypical gave, like athletes of instead way serious works [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.783 (perp=8.324, rec=0.113, cos=0.005), tot_loss_proj:2.632 [t=0.31s]
prediction: ['[CLS] caretaker teachers the makes the forced out look all women, soldiers this serious stereotypical teachers, like athletes of instead way serious works [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.791 (perp=8.431, rec=0.098, cos=0.006), tot_loss_proj:2.730 [t=0.31s]
prediction: ['[CLS] caretaker teachers the makes the forced out look all women, soldiers this serious waytypical teachers, like athletes of instead more serious works [SEP]']
[ 900/2000] tot_loss=1.800 (perp=8.431, rec=0.109, cos=0.005), tot_loss_proj:2.731 [t=0.31s]
prediction: ['[CLS] caretaker teachers the makes the forced out look all women, soldiers this serious waytypical teachers, like athletes of instead more serious works [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.738 (perp=8.197, rec=0.094, cos=0.005), tot_loss_proj:2.676 [t=0.31s]
prediction: ['[CLS] the teachers caretaker makes the forced out look all women, soldiers this serious waytypical teachers, like athletes of instead more serious works [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.721 (perp=8.121, rec=0.092, cos=0.005), tot_loss_proj:2.656 [t=0.40s]
prediction: ['[CLS] the moral caretaker makes the forced out look all women, teams this serious way teacherstypical, like athletes of instead more serious works [SEP]']
[1050/2000] tot_loss=1.725 (perp=8.121, rec=0.096, cos=0.005), tot_loss_proj:2.658 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced out look all women, teams this serious way teacherstypical, like athletes of instead more serious works [SEP]']
Attempt swap
[1100/2000] tot_loss=1.726 (perp=8.121, rec=0.097, cos=0.004), tot_loss_proj:2.659 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced out look all women, teams this serious way teacherstypical, like athletes of instead more serious works [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.679 (perp=7.938, rec=0.087, cos=0.005), tot_loss_proj:2.442 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, teams this serious way outtypical, like athletes of instead more serious works [SEP]']
[1200/2000] tot_loss=1.688 (perp=7.938, rec=0.096, cos=0.004), tot_loss_proj:2.443 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, teams this serious way outtypical, like athletes of instead more serious works [SEP]']
Attempt swap
[1250/2000] tot_loss=1.680 (perp=7.938, rec=0.089, cos=0.004), tot_loss_proj:2.442 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, teams this serious way outtypical, like athletes of instead more serious works [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.604 (perp=7.559, rec=0.087, cos=0.005), tot_loss_proj:2.286 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, teams this serious way outtypical, like athletes instead of more serious works [SEP]']
[1350/2000] tot_loss=1.597 (perp=7.559, rec=0.081, cos=0.005), tot_loss_proj:2.293 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, teams this serious way outtypical, like athletes instead of more serious works [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.576 (perp=7.413, rec=0.089, cos=0.005), tot_loss_proj:2.307 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, teams this serious way out, liketypical athletes instead of more serious works [SEP]']
Attempt swap
[1450/2000] tot_loss=1.580 (perp=7.413, rec=0.093, cos=0.004), tot_loss_proj:2.309 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, teams this serious way out, liketypical athletes instead of more serious works [SEP]']
[1500/2000] tot_loss=1.581 (perp=7.413, rec=0.094, cos=0.005), tot_loss_proj:2.308 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, teams this serious way out, liketypical athletes instead of more serious works [SEP]']
Attempt swap
[1550/2000] tot_loss=1.571 (perp=7.413, rec=0.084, cos=0.004), tot_loss_proj:2.312 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, teams this serious way out, liketypical athletes instead of more serious works [SEP]']
Attempt swap
[1600/2000] tot_loss=1.577 (perp=7.413, rec=0.090, cos=0.004), tot_loss_proj:2.308 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, teams this serious way out, liketypical athletes instead of more serious works [SEP]']
[1650/2000] tot_loss=1.574 (perp=7.413, rec=0.087, cos=0.004), tot_loss_proj:2.311 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, teams this serious way out, liketypical athletes instead of more serious works [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.523 (perp=7.201, rec=0.078, cos=0.005), tot_loss_proj:2.671 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, works this serious way out, liketypical athletes instead of more serious teams [SEP]']
Attempt swap
[1750/2000] tot_loss=1.532 (perp=7.201, rec=0.087, cos=0.005), tot_loss_proj:2.670 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, works this serious way out, liketypical athletes instead of more serious teams [SEP]']
[1800/2000] tot_loss=1.529 (perp=7.201, rec=0.085, cos=0.005), tot_loss_proj:2.667 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, works this serious way out, liketypical athletes instead of more serious teams [SEP]']
Attempt swap
[1850/2000] tot_loss=1.521 (perp=7.201, rec=0.076, cos=0.005), tot_loss_proj:2.665 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, works this serious way out, liketypical athletes instead of more serious teams [SEP]']
Attempt swap
[1900/2000] tot_loss=1.535 (perp=7.201, rec=0.090, cos=0.005), tot_loss_proj:2.670 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, works this serious way out, liketypical athletes instead of more serious teams [SEP]']
[1950/2000] tot_loss=1.530 (perp=7.201, rec=0.085, cos=0.005), tot_loss_proj:2.663 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, works this serious way out, liketypical athletes instead of more serious teams [SEP]']
Attempt swap
[2000/2000] tot_loss=1.531 (perp=7.201, rec=0.086, cos=0.004), tot_loss_proj:2.667 [t=0.31s]
prediction: ['[CLS] the moral caretaker makes the forced teachers look all women, works this serious way out, liketypical athletes instead of more serious teams [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] the moral caretaker makes the forced teachers look all women, works this serious way out, liketypical athletes instead of more serious teams [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.851 | p: 79.167 | r: 82.609
rouge2     | fm: 13.333 | p: 13.043 | r: 13.636
rougeL     | fm: 38.298 | p: 37.500 | r: 39.130
rougeLsum  | fm: 38.298 | p: 37.500 | r: 39.130
r1fm+r2fm = 94.184

[Aggregate metrics]:
rouge1     | fm: 91.745 | p: 90.760 | r: 92.990
rouge2     | fm: 64.046 | p: 63.355 | r: 64.790
rougeL     | fm: 83.620 | p: 82.711 | r: 84.796
rougeLsum  | fm: 83.570 | p: 82.691 | r: 84.679
r1fm+r2fm = 155.792

input #21 time: 0:12:23 | total time: 4:26:38


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9987949314971747
highest_index [0]
highest [0.9987949314971747]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9920082688331604 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9727393984794617 for ['[CLS] mast landlord rockome crusaders enjoyed denise fire dock almost vera [SEP]']
[Init] best rec loss: 0.9645130038261414 for ['[CLS] 2008 were change nixon lighting range francois fate near reservoir medal [SEP]']
[Init] best perm rec loss: 0.9636644721031189 for ['[CLS] nixon medal were fate range francois 2008 lighting near change reservoir [SEP]']
[Init] best perm rec loss: 0.9628008008003235 for ['[CLS] fate were 2008 medal nixon near reservoir range lighting change francois [SEP]']
[Init] best perm rec loss: 0.9627989530563354 for ['[CLS] change francois fate near were lighting medal 2008 range reservoir nixon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.776 (perp=13.955, rec=0.583, cos=0.402), tot_loss_proj:4.104 [t=0.30s]
prediction: ['[CLS] beloved margaret price feat funny favorpicibakovic music two [SEP]']
[ 100/2000] tot_loss=3.262 (perp=12.660, rec=0.449, cos=0.281), tot_loss_proj:3.577 [t=0.30s]
prediction: ['[CLS]bron film becoming ryan adaptation successfulpic 000type film legacy [SEP]']
[ 150/2000] tot_loss=2.873 (perp=11.008, rec=0.395, cos=0.276), tot_loss_proj:3.224 [t=0.30s]
prediction: ['[CLS] dynasty film becoming welcomed another successful tate imagination successful adaptation resulting [SEP]']
[ 200/2000] tot_loss=3.142 (perp=12.449, rec=0.347, cos=0.305), tot_loss_proj:3.415 [t=0.30s]
prediction: ['[CLS] formation film interactionnessy another successful tate adaptation successful adaptation resulting [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.203 (perp=12.734, rec=0.365, cos=0.292), tot_loss_proj:3.675 [t=0.30s]
prediction: ['[CLS] uhfclusive brandonnessy own successful screenplay adaptation successful adaptation screenplay [SEP]']
[ 300/2000] tot_loss=2.822 (perp=10.953, rec=0.322, cos=0.309), tot_loss_proj:3.544 [t=0.30s]
prediction: ['[CLS] rosalie painful brandonnessy own successful film adaptation successful adaptation v6 [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.114 (perp=12.565, rec=0.318, cos=0.283), tot_loss_proj:3.846 [t=0.30s]
prediction: ['[CLS] painfulico annessy own successful film successful successful adaptation publishing [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.919 (perp=11.617, rec=0.301, cos=0.295), tot_loss_proj:3.889 [t=0.30s]
prediction: ['[CLS] painful an ripleynessy own successful film successful successful adaptation publishing [SEP]']
[ 450/2000] tot_loss=3.128 (perp=12.717, rec=0.291, cos=0.293), tot_loss_proj:3.861 [t=0.30s]
prediction: ['[CLS] painful an amelianessy own enjoyable film successful successful adaptation publishing [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.920 (perp=11.741, rec=0.278, cos=0.293), tot_loss_proj:3.072 [t=0.30s]
prediction: ['[CLS] an amelia painfulnessy own enjoyable film successful successful adaptation publishing [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.062 (perp=12.220, rec=0.332, cos=0.287), tot_loss_proj:3.685 [t=0.30s]
prediction: ['[CLS] an remain painfulnessy own enjoyable film successful film adaptation earn [SEP]']
[ 600/2000] tot_loss=3.000 (perp=12.048, rec=0.292, cos=0.298), tot_loss_proj:3.604 [t=0.30s]
prediction: ['[CLS] ancm painfulnessy own enjoyable successful successful film adaptationcured [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.819 (perp=11.125, rec=0.284, cos=0.310), tot_loss_proj:3.338 [t=0.30s]
prediction: ['[CLS] an enjoyable need painfulnessy own successful successful film adaptationmbling [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.748 (perp=10.562, rec=0.305, cos=0.331), tot_loss_proj:2.814 [t=0.30s]
prediction: ['[CLS] an enjoyablecm painfulcurednessy own successful successful film adaptation [SEP]']
[ 750/2000] tot_loss=2.661 (perp=10.276, rec=0.279, cos=0.326), tot_loss_proj:2.694 [t=0.30s]
prediction: ['[CLS] an enjoyable opportunity painfulcurednessy own successful successful film adaptation [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.557 (perp=9.799, rec=0.286, cos=0.312), tot_loss_proj:3.269 [t=0.30s]
prediction: ['[CLS] an enjoyable opportunity painfulnessycured own successful successful film adaptation [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.665 (perp=10.292, rec=0.287, cos=0.320), tot_loss_proj:3.733 [t=0.30s]
prediction: ['[CLS] an enjoyable opportunity painful whose successfulmbling own successful film adaptation [SEP]']
[ 900/2000] tot_loss=2.799 (perp=10.906, rec=0.281, cos=0.337), tot_loss_proj:3.715 [t=0.30s]
prediction: ['[CLS] an enjoyable rights painful whose utopiaurrent own successful film adaptation [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.864 (perp=11.243, rec=0.271, cos=0.345), tot_loss_proj:3.700 [t=0.30s]
prediction: ['[CLS] an enjoyable rights painfulurrent hisytic own successful film adaptation [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.825 (perp=11.050, rec=0.274, cos=0.341), tot_loss_proj:3.830 [t=0.30s]
prediction: ['[CLS] an enjoyable rights painfulurrent his its own lindsey film adaptation [SEP]']
[1050/2000] tot_loss=2.830 (perp=11.050, rec=0.267, cos=0.353), tot_loss_proj:3.826 [t=0.30s]
prediction: ['[CLS] an enjoyable rights painfulurrent his its own lindsey film adaptation [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.719 (perp=10.430, rec=0.275, cos=0.358), tot_loss_proj:3.391 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent his its ownnessy adaptation [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.616 (perp=9.989, rec=0.281, cos=0.337), tot_loss_proj:3.367 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent its ownnessy adaptation his [SEP]']
[1200/2000] tot_loss=2.677 (perp=10.282, rec=0.268, cos=0.354), tot_loss_proj:3.619 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent its own forewings adaptation his [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.566 (perp=9.659, rec=0.275, cos=0.359), tot_loss_proj:3.486 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation his [SEP]']
Attempt swap
[1300/2000] tot_loss=2.555 (perp=9.659, rec=0.270, cos=0.353), tot_loss_proj:3.488 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation his [SEP]']
[1350/2000] tot_loss=2.557 (perp=9.659, rec=0.272, cos=0.354), tot_loss_proj:3.485 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation his [SEP]']
Attempt swap
[1400/2000] tot_loss=2.553 (perp=9.659, rec=0.262, cos=0.359), tot_loss_proj:3.491 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation his [SEP]']
Attempt swap
[1450/2000] tot_loss=2.633 (perp=10.029, rec=0.272, cos=0.355), tot_loss_proj:3.585 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
[1500/2000] tot_loss=2.626 (perp=10.029, rec=0.264, cos=0.357), tot_loss_proj:3.580 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
Attempt swap
[1550/2000] tot_loss=2.628 (perp=10.029, rec=0.261, cos=0.361), tot_loss_proj:3.588 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
Attempt swap
[1600/2000] tot_loss=2.634 (perp=10.029, rec=0.268, cos=0.360), tot_loss_proj:3.584 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
[1650/2000] tot_loss=2.622 (perp=10.029, rec=0.251, cos=0.365), tot_loss_proj:3.584 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
Attempt swap
[1700/2000] tot_loss=2.635 (perp=10.029, rec=0.268, cos=0.361), tot_loss_proj:3.585 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
Attempt swap
[1750/2000] tot_loss=2.634 (perp=10.029, rec=0.262, cos=0.366), tot_loss_proj:3.589 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
[1800/2000] tot_loss=2.632 (perp=10.029, rec=0.259, cos=0.367), tot_loss_proj:3.586 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
Attempt swap
[1850/2000] tot_loss=2.636 (perp=10.029, rec=0.261, cos=0.370), tot_loss_proj:3.589 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
Attempt swap
[1900/2000] tot_loss=2.629 (perp=10.029, rec=0.256, cos=0.367), tot_loss_proj:3.588 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
[1950/2000] tot_loss=2.635 (perp=10.029, rec=0.263, cos=0.366), tot_loss_proj:3.590 [t=0.30s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
Attempt swap
[2000/2000] tot_loss=2.641 (perp=10.029, rec=0.271, cos=0.364), tot_loss_proj:3.592 [t=0.31s]
prediction: ['[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] an enjoyable rights film painfulurrent fledged its own adaptation your [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.000 | p: 66.667 | r: 61.538
rouge2     | fm: 17.391 | p: 18.182 | r: 16.667
rougeL     | fm: 56.000 | p: 58.333 | r: 53.846
rougeLsum  | fm: 56.000 | p: 58.333 | r: 53.846
r1fm+r2fm = 81.391

[Aggregate metrics]:
rouge1     | fm: 90.559 | p: 89.722 | r: 91.703
rouge2     | fm: 61.840 | p: 61.181 | r: 62.647
rougeL     | fm: 82.430 | p: 81.599 | r: 83.388
rougeLsum  | fm: 82.428 | p: 81.717 | r: 83.481
r1fm+r2fm = 152.399

input #22 time: 0:12:04 | total time: 4:38:42


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.9987094562360083
highest_index [0]
highest [0.9987094562360083]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.696334183216095 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.6935924887657166 for ['[CLS] stephens type specialty agedre vu disney resourcexide raeiansia are roadbbly feeling daphne amazon detail demon ii smartershi remembertained mad injunction israel personal network elbow conceptbbled president where rep example researchapple mr rangers resisted revival accessible self na express legion [SEP]']
[Init] best rec loss: 0.6917661428451538 for ["[CLS] terrible dvd lives race philharmonic event andover scholars scaling tesla semi du both relatingories change towelrogated mohawk interview clear rat accession once ripping vol motorsports stove country somewhere 1999 ground employed each about murders'deadwer even cargo clickhopper prophet storesarderos state [SEP]"]
[Init] best rec loss: 0.6915724277496338 for ['[CLS] alexander actively teammates pen clover serves gentleman job instant coasts temperament pill done hirsch arms seemed damn changes literaryxin izzynesiavancehunter appointed productionsception huddersfield wing long bed crossed together side video grandpa jem throughout and walking has pressure christ telescope tech villa religious oath [SEP]']
[Init] best rec loss: 0.6909509897232056 for ['[CLS] game to action dawned fitted suppression winked stellar energyloaded grandma algorithm yet pueblo 19th pun where healed nitrogen > capital sage reform span kun chambers alexander est slack up bed ct, icevin forth [SEP] drew standards findttering become fitting grunt one engineer sugar occupied [SEP]']
[Init] best perm rec loss: 0.6894566416740417 for ['[CLS]vin where reform action bed sage 19th healed grandma winked drew energy fitting [SEP] est nitrogen game >ttering yet standards fitted up occupied sugar ice pun algorithm alexander gruntloaded capital, one kun to span chambers suppression find dawned stellar pueblo become forth slack ct engineer [SEP]']
[Init] best perm rec loss: 0.6891821026802063 for ['[CLS] grunt ice reform pun slack nitrogen findvin,ttering fitted kun fitting chambers sugar > algorithm up ct [SEP]loaded yet grandma 19th suppression span where stellar action dawned alexander est sage game become bed engineer capital energy pueblo drew occupied healed one forth winked to standards [SEP]']
[Init] best perm rec loss: 0.6891607046127319 for ['[CLS] become up span yet, capital where 19thvin [SEP] slack suppression engineer one alexander sage drew kun find winked nitrogen estloadedttering action bed ice fitting game forth sugar to chambers pueblo grandma energy standards grunt dawned occupied stellar pun reform healed fitted ct > algorithm [SEP]']
[Init] best perm rec loss: 0.6881493330001831 for ['[CLS] fitting sage alexander kun game one sugar stellar where become forth est, algorithm action findvin ct chambers engineerloaded energy grandma drewttering [SEP] reform fitted span 19th grunt to nitrogen winked slack pun yet occupied pueblo dawned ice bed capital healed standards up > suppression [SEP]']
[Init] best perm rec loss: 0.68645840883255 for ['[CLS] nitrogen find algorithmloaded where pun > winked one dawned chambers, occupied engineer [SEP] est sage become reform span healed game ice sugarttering bed fitting fitted 19th alexander forth slack suppression drew stellar capital standards grunt yet kun ct tovin energy up grandma pueblo action [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.529 (perp=10.757, rec=0.298, cos=0.080), tot_loss_proj:3.425 [t=0.30s]
prediction: ["[CLS]lization objective despite war ghostulsive theory national anness of. bob want, pour! infantry until lives was eventual patriotic as activist'musical violence documentary objective change slack became tough strategic objective largely 'partisan administrative featuring strategy strategic image generation. programs blame [SEP]"]
[ 100/2000] tot_loss=2.381 (perp=10.573, rec=0.218, cos=0.048), tot_loss_proj:3.205 [t=0.31s]
prediction: ['[CLS]lization objective infrared war while strategic idea patriotic the while could soldiers ; attack ra pour ; ) achieved strategic its final patriotic : activist of musical strategic drama main change slack the wicket strategic objective many. theft dramatic and strategy strategicing between generationaging soldiers [SEP]']
[ 150/2000] tot_loss=2.449 (perp=11.083, rec=0.198, cos=0.034), tot_loss_proj:3.181 [t=0.31s]
prediction: ['[CLS]lization objective infrared war with strategic idea patriotic a nevertheless despite soldiers si ( rah, tone achieve its its ultimately patriotic : activist - drama strategic drama main itsive the city strategic objective many. constabulary dramatic, strategy strategicing when generation 彳 soldiers [SEP]']
[ 200/2000] tot_loss=2.266 (perp=10.316, rec=0.174, cos=0.028), tot_loss_proj:2.957 [t=0.31s]
prediction: ['[CLS]lization objective tone war withistle idea patriotic a while while soldiers ra " rah, tone achieve its its ultimately patriotic : activist - drama strategic drama main its a the city strategic objective became ofpiration significant, strategy strategiczing when generationaging vietnam [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.189 (perp=10.146, rec=0.144, cos=0.016), tot_loss_proj:2.947 [t=0.31s]
prediction: ['[CLS]lization objective tone war with definition idea patriotic a while while soldiers ra " rah, tone achieve its its ultimately patriotic : ultimately - drama strategic drama main the a the campus strategic objective generationsspiration significant of strategictizing that generation darren vietnam [SEP]']
[ 300/2000] tot_loss=2.233 (perp=10.441, rec=0.127, cos=0.017), tot_loss_proj:3.061 [t=0.31s]
prediction: ['[CLS]lization objective such war with, idea patriotic a while while soldiers ra this rah, tone achieve itss ultimately patriotic : cost - picture strategic drama main the ; theyed strategic objective becamespiration the of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.079 (perp=9.696, rec=0.125, cos=0.015), tot_loss_proj:3.228 [t=0.31s]
prediction: ['[CLS]lization objective such war with the idea patriotic a while while soldiers ra, rah, tone achieve itss ultimately patriotic : cost the picture strategic drama main of - the tale strategic objective becamespiration the of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.986 (perp=9.270, rec=0.117, cos=0.015), tot_loss_proj:2.994 [t=0.31s]
prediction: ['[CLS]lization objective with war with the idea vietnam a while while soldiers ra, rah, tone achieve itss ultimately patriotic : cost the picture strategic drama main of : the motion strategic objective the becamesuding of conflicttizing that generation define vietnam [SEP]']
[ 450/2000] tot_loss=1.966 (perp=9.250, rec=0.107, cos=0.009), tot_loss_proj:3.047 [t=0.31s]
prediction: ['[CLS]lization objective object object with the idea vietnam a while while soldiers ra, rah, tone achieve itss ultimately patriotic : cost the picture strategic drama main of - the jennifer strategic objective the becamesuding of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.966 (perp=9.254, rec=0.107, cos=0.008), tot_loss_proj:2.785 [t=0.31s]
prediction: ['[CLS]lization objective object object with will idea vietnam a while while soldiers ra, rah, its tone achieves ultimately patriotic : cost with picture strategic drama main of a the toni strategic objective the becamesuding of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.880 (perp=8.882, rec=0.097, cos=0.007), tot_loss_proj:2.684 [t=0.31s]
prediction: ['[CLS]lizations object object a will idea vietnam a while while soldiers ra, rah, its tone achieves ultimately patriotic : cost with picture human drama main of - the human strategic objective the became objectiveuding of conflicttizing that generation define vietnam [SEP]']
[ 600/2000] tot_loss=1.874 (perp=8.871, rec=0.094, cos=0.006), tot_loss_proj:2.693 [t=0.31s]
prediction: ['[CLS]lizations object object a will idea vietnam a while while soldiers ra, rah, its tone achieves ultimately patriotic : cost with picture human drama main of - the human strategic objective the became objectiveuding the conflicttizing that generation define vietnam [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.895 (perp=8.978, rec=0.092, cos=0.007), tot_loss_proj:2.703 [t=0.31s]
prediction: ['[CLS]lizations object object of will idea vietnam a while while soldiers ra,hh, its tone achieves ultimately patriotic : cost with picture - human drama main of the human strategic objective the became objectiveuding of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.856 (perp=8.807, rec=0.087, cos=0.008), tot_loss_proj:2.688 [t=0.31s]
prediction: ['[CLS]lizations object object of will idea vietnam a while while soldiers,h rah, its tone achieves ultimately patriotic : cost with picture - human drama main of the easy strategic objective the became objectiveuding of conflicttizing that generation define vietnam [SEP]']
[ 750/2000] tot_loss=1.879 (perp=8.902, rec=0.092, cos=0.007), tot_loss_proj:2.678 [t=0.31s]
prediction: ['[CLS]lizations object object of will idea vietnam a while while soldiers,h rah, its tone achieves ultimately patriotic : cost with picture - human drama main of the conception strategic objective the became objectiveuding of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.860 (perp=8.822, rec=0.089, cos=0.007), tot_loss_proj:2.680 [t=0.31s]
prediction: ['[CLS]lizations object object of will idea vietnam a while while soldiers,h rah, its tone achieves ultimately patriotic : cost with picture - human drama main strategic of the easy objective the became objectiveuding of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.817 (perp=8.642, rec=0.084, cos=0.005), tot_loss_proj:2.518 [t=0.31s]
prediction: ['[CLS]lizations object object of will idea vietnam a while while soldiers,h rah, its tone achieves ultimately : patriotic cost with picture - human drama main strategic of the conception objective the became objectiveuding of conflicttizing that generation define vietnam [SEP]']
[ 900/2000] tot_loss=1.872 (perp=8.923, rec=0.081, cos=0.006), tot_loss_proj:2.555 [t=0.31s]
prediction: ['[CLS]lizations object object of will idea vietnam a while while soldiers,h rah, its tone achieves ultimately : patriotic cost with picture - human drama main strategic of the conception objective the became objectivebf of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.857 (perp=8.778, rec=0.095, cos=0.007), tot_loss_proj:2.570 [t=0.31s]
prediction: ['[CLS]lizationsuding object of will idea vietnam a while while soldiers,h rah, its tone achieves ultimately : patriotic cost such picture - human drama main strategic of the human objective the became objective object of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.831 (perp=8.665, rec=0.091, cos=0.007), tot_loss_proj:2.611 [t=0.31s]
prediction: ['[CLS]lizations give object of idea will vietnam a while while soldiers,h rah, its tone achieves ultimately : patriotic cost such picture - human drama main strategic of the human objective the became objective object of conflicttizing that generation define vietnam [SEP]']
[1050/2000] tot_loss=1.846 (perp=8.759, rec=0.088, cos=0.006), tot_loss_proj:2.669 [t=0.31s]
prediction: ['[CLS]lizations prevent object to idea will vietnam a while while soldiers,h rah, its tone achieves ultimately : patriotic cost such picture - human drama main strategic of the human objective the became objective object of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.795 (perp=8.531, rec=0.083, cos=0.005), tot_loss_proj:2.631 [t=0.31s]
prediction: ['[CLS]lizations give object the idea will vietnam a while while soldiers,h rah, its tone achieves ultimately : patriotic cost such picture - human drama main strategic of the human objective to became objective object of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.771 (perp=8.371, rec=0.092, cos=0.005), tot_loss_proj:2.570 [t=0.31s]
prediction: ['[CLS]lizations give define the idea, vietnam a while while soldiers willh rah, its tone achieves ultimately : patriotic cost such picture - human drama main strategic of the human objective to became objective object of conflicttizing that generation define vietnam [SEP]']
[1200/2000] tot_loss=1.775 (perp=8.397, rec=0.090, cos=0.006), tot_loss_proj:2.590 [t=0.31s]
prediction: ['[CLS]lizations give define the idea, vietnam a while while soldiers willh rah, its tone achieves ultimately : patriotic cost such picture - human drama main strategic of the human objective of became objective object of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.784 (perp=8.454, rec=0.087, cos=0.006), tot_loss_proj:2.495 [t=0.31s]
prediction: ['[CLS] suchs prevent define the idea, vietnam a while while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama main strategic of the human objective of became objective object of conflicttizing that generation define vietnam [SEP]']
Attempt swap
[1300/2000] tot_loss=1.783 (perp=8.454, rec=0.087, cos=0.005), tot_loss_proj:2.495 [t=0.31s]
prediction: ['[CLS] suchs prevent define the idea, vietnam a while while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama main strategic of the human objective of became objective object of conflicttizing that generation define vietnam [SEP]']
[1350/2000] tot_loss=1.781 (perp=8.454, rec=0.084, cos=0.006), tot_loss_proj:2.496 [t=0.31s]
prediction: ['[CLS] suchs prevent define the idea, vietnam a while while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama main strategic of the human objective of became objective object of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.722 (perp=8.162, rec=0.085, cos=0.006), tot_loss_proj:2.439 [t=0.31s]
prediction: ['[CLS] suchs give object the idea of vietnam a while while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama main strategic of the human objective, became objective object of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.709 (perp=8.096, rec=0.085, cos=0.005), tot_loss_proj:2.419 [t=0.31s]
prediction: ['[CLS] such objects give the idea of vietnam a while while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama main strategic of the human objective, became objective object of conflicttizing that generation define vietnam [SEP]']
[1500/2000] tot_loss=1.703 (perp=8.096, rec=0.079, cos=0.005), tot_loss_proj:2.418 [t=0.31s]
prediction: ['[CLS] such objects give the idea of vietnam a while while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama main strategic of the human objective, became objective object of conflicttizing that generation define vietnam [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.685 (perp=7.957, rec=0.088, cos=0.005), tot_loss_proj:2.370 [t=0.31s]
prediction: ['[CLS] such objects give the idea of vietnam a while while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama main strategic of the human objective, became that object of conflicttizing objective generation define vietnam [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.661 (perp=7.857, rec=0.085, cos=0.005), tot_loss_proj:2.326 [t=0.31s]
prediction: ['[CLS] such objects give the idea of vietnam a while while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama became main strategic of the human objective, that object of conflicttizing objective generation define vietnam [SEP]']
[1650/2000] tot_loss=1.661 (perp=7.857, rec=0.085, cos=0.005), tot_loss_proj:2.330 [t=0.31s]
prediction: ['[CLS] such objects give the idea of vietnam a while while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama became main strategic of the human objective, that object of conflicttizing objective generation define vietnam [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.648 (perp=7.775, rec=0.088, cos=0.005), tot_loss_proj:2.307 [t=0.31s]
prediction: ['[CLS] such objects give the idea of a while vietnam while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama became main strategic of the human objective, that object of conflicttizing objective generation define vietnam [SEP]']
Attempt swap
[1750/2000] tot_loss=1.645 (perp=7.775, rec=0.085, cos=0.005), tot_loss_proj:2.308 [t=0.31s]
prediction: ['[CLS] such objects give the idea of a while vietnam while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama became main strategic of the human objective, that object of conflicttizing objective generation define vietnam [SEP]']
[1800/2000] tot_loss=1.640 (perp=7.775, rec=0.080, cos=0.005), tot_loss_proj:2.308 [t=0.31s]
prediction: ['[CLS] such objects give the idea of a while vietnam while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama became main strategic of the human objective, that object of conflicttizing objective generation define vietnam [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.649 (perp=7.811, rec=0.083, cos=0.004), tot_loss_proj:2.305 [t=0.31s]
prediction: ['[CLS] such objects give the idea of a while vietnam while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama became the main strategic of human objective, that object. conflicttizing objective generation define vietnam [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.643 (perp=7.772, rec=0.084, cos=0.005), tot_loss_proj:2.301 [t=0.31s]
prediction: ['[CLS] such objects give the idea of a while vietnam while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama became the main strategic of human objective., that object conflicttizing objective generation define vietnam [SEP]']
[1950/2000] tot_loss=1.642 (perp=7.772, rec=0.083, cos=0.005), tot_loss_proj:2.306 [t=0.31s]
prediction: ['[CLS] such objects give the idea of a while vietnam while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama became the main strategic of human objective., that object conflicttizing objective generation define vietnam [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.673 (perp=7.912, rec=0.086, cos=0.005), tot_loss_proj:2.349 [t=0.31s]
prediction: ['[CLS] such objects give the idea of a while of while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama became the main strategic of human objective vietnam, that object conflicttizing objective generation define vietnam [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] such objects give the idea of a while vietnam while soldiers willh rah, its tone achieves ultimately : patriotic costlization picture - human drama became the main strategic of human objective., that object conflicttizing objective generation define vietnam [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.231 | p: 71.053 | r: 67.500
rouge2     | fm: 10.526 | p: 10.811 | r: 10.256
rougeL     | fm: 38.462 | p: 39.474 | r: 37.500
rougeLsum  | fm: 38.462 | p: 39.474 | r: 37.500
r1fm+r2fm = 79.757

[Aggregate metrics]:
rouge1     | fm: 89.717 | p: 88.983 | r: 90.607
rouge2     | fm: 59.589 | p: 59.065 | r: 60.179
rougeL     | fm: 80.686 | p: 79.951 | r: 81.562
rougeLsum  | fm: 80.467 | p: 79.726 | r: 81.408
r1fm+r2fm = 149.305

input #23 time: 0:12:16 | total time: 4:50:58


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9987281919692247
highest_index [0]
highest [0.9987281919692247]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8899118900299072 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8362299799919128 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8113388419151306 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 0.7789268493652344 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.763676106929779 for ['[CLS] numb clear post mirror leg closet died fond sometimes distributor bonus « piecegence nerve rush authority direction turnsxie [SEP]']
[Init] best rec loss: 0.7310870885848999 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7286486029624939 for ['[CLS] port happy nowyl arms em ryu damnedaneous mid village bush bond suffer younger attack unless snow play county [SEP]']
[Init] best perm rec loss: 0.7262884974479675 for ['[CLS]aneous suffer bush mid village happy no bondwyl attack unless damned younger arms play em county snow port ryu [SEP]']
[Init] best perm rec loss: 0.7257078886032104 for ['[CLS] emaneous county younger happy unless bush suffer arms mid attack playwyl bond damned snow village no ryu port [SEP]']
[Init] best perm rec loss: 0.7236255407333374 for ['[CLS] emwyl no arms younger snow play village mid county damnedaneous suffer unless bond happy attack ryu bush port [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.496 (perp=10.585, rec=0.318, cos=0.061), tot_loss_proj:3.062 [t=0.31s]
prediction: ["[CLS] outside cover political environment'evil canton lies actively evil evil police context evil? into former truly political specifically [SEP]"]
[ 100/2000] tot_loss=2.067 (perp=9.304, rec=0.189, cos=0.017), tot_loss_proj:2.751 [t=0.31s]
prediction: ['[CLS] outside background political context the terrorist wonder evil held evil evil security are evil ( taken terrorists! the ) [SEP]']
[ 150/2000] tot_loss=2.177 (perp=10.041, rec=0.154, cos=0.014), tot_loss_proj:2.860 [t=0.31s]
prediction: ['[CLS] outside background political context current terrorists wonder rap climate evil evil terrorists than evil ( taken terrorists! the ) [SEP]']
[ 200/2000] tot_loss=2.049 (perp=9.480, rec=0.145, cos=0.008), tot_loss_proj:2.600 [t=0.31s]
prediction: ['[CLS] outside known political context current terrorists see rap climate evil evil qaeda more evil ( taken than! are ) [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.899 (perp=8.795, rec=0.131, cos=0.009), tot_loss_proj:2.481 [t=0.31s]
prediction: ['[CLS] outside political political context the terrorists offense three climate evil evil qaeda more evil ( taken than!! ) [SEP]']
[ 300/2000] tot_loss=1.839 (perp=8.477, rec=0.133, cos=0.010), tot_loss_proj:2.464 [t=0.31s]
prediction: ['[CLS] outside current political context the terrorists offense three climate evil evil see more evil ( taken than than! ) [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.676 (perp=7.673, rec=0.133, cos=0.009), tot_loss_proj:2.295 [t=0.31s]
prediction: ['[CLS] outside current political context the terrorists : three ( climate evil evil see more evil taken than than! ) [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.644 (perp=7.659, rec=0.107, cos=0.006), tot_loss_proj:2.285 [t=0.31s]
prediction: ['[CLS] outside current political context the terrorists : ( 3 climate evil evil see more evil taken ever than! ) [SEP]']
[ 450/2000] tot_loss=1.630 (perp=7.613, rec=0.102, cos=0.005), tot_loss_proj:2.267 [t=0.31s]
prediction: ['[CLS] outside current political context the terrorists : ( three climate evil evil see more evil taken ever than! ) [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.595 (perp=7.414, rec=0.107, cos=0.005), tot_loss_proj:2.213 [t=0.31s]
prediction: ['[CLS] outside current political context the terrorists : ( three climate seen evil see more evil than ever taken! ) [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.541 (perp=7.179, rec=0.100, cos=0.005), tot_loss_proj:2.150 [t=0.31s]
prediction: ['[CLS] outside current political context the terrorists : ( three evil climate seen see more evil than ever taken! ) [SEP]']
[ 600/2000] tot_loss=1.545 (perp=7.179, rec=0.104, cos=0.005), tot_loss_proj:2.153 [t=0.31s]
prediction: ['[CLS] outside current political context the terrorists : ( three evil climate seen see more evil than ever taken! ) [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.523 (perp=7.118, rec=0.094, cos=0.005), tot_loss_proj:2.149 [t=0.31s]
prediction: ['[CLS] outside current political context the three terrorists : ( evil climate seen see more evil than ever taken! ) [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.524 (perp=7.118, rec=0.095, cos=0.005), tot_loss_proj:2.153 [t=0.31s]
prediction: ['[CLS] outside current political context the three terrorists : ( evil climate seen see more evil than ever taken! ) [SEP]']
[ 750/2000] tot_loss=1.518 (perp=7.118, rec=0.089, cos=0.005), tot_loss_proj:2.150 [t=0.31s]
prediction: ['[CLS] outside current political context the three terrorists : ( evil climate seen see more evil than ever taken! ) [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.471 (perp=6.901, rec=0.085, cos=0.006), tot_loss_proj:2.083 [t=0.31s]
prediction: ['[CLS] outside current political context the three terrorists taken : ( evil climate seen see more evil than ever! ) [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.479 (perp=6.901, rec=0.093, cos=0.006), tot_loss_proj:2.087 [t=0.31s]
prediction: ['[CLS] outside current political context the three terrorists taken : ( evil climate seen see more evil than ever! ) [SEP]']
[ 900/2000] tot_loss=1.467 (perp=6.901, rec=0.081, cos=0.005), tot_loss_proj:2.076 [t=0.31s]
prediction: ['[CLS] outside current political context the three terrorists taken : ( evil climate seen see more evil than ever! ) [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.685 (perp=7.246, rec=0.207, cos=0.028), tot_loss_proj:2.105 [t=0.31s]
prediction: ['[CLS] outside current political context the non terrorists taken : ( see evil climate climate more evil than ever! ) [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.613 (perp=7.270, rec=0.151, cos=0.008), tot_loss_proj:2.199 [t=0.31s]
prediction: ['[CLS] outside current political context the lydia terrorists taken climate ( see evil climate : more evil than ever! ) [SEP]']
[1050/2000] tot_loss=1.620 (perp=7.416, rec=0.130, cos=0.006), tot_loss_proj:2.170 [t=0.31s]
prediction: ['[CLS] outside current political context theput terrorists taken climate ( see evil climate : more evil than ever! ) [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.554 (perp=7.085, rec=0.131, cos=0.006), tot_loss_proj:2.103 [t=0.31s]
prediction: ['[CLS] outside current political context the terrorists takenput climate ( see evil climate : more evil than ever! ) [SEP]']
Attempt swap
[1150/2000] tot_loss=1.536 (perp=7.085, rec=0.114, cos=0.005), tot_loss_proj:2.102 [t=0.31s]
prediction: ['[CLS] outside current political context the terrorists takenput climate ( see evil climate : more evil than ever! ) [SEP]']
[1200/2000] tot_loss=1.532 (perp=7.085, rec=0.110, cos=0.005), tot_loss_proj:2.103 [t=0.31s]
prediction: ['[CLS] outside current political context the terrorists takenput climate ( see evil climate : more evil than ever! ) [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.531 (perp=7.085, rec=0.109, cos=0.005), tot_loss_proj:2.101 [t=0.31s]
prediction: ['[CLS] outside current political context the terrorists takenput climate ( see evil climate : more evil than ever! ) [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.498 (perp=6.945, rec=0.104, cos=0.005), tot_loss_proj:2.058 [t=0.31s]
prediction: ['[CLS] outside current political context the climate terrorists takenput ( see evil climate : more evil than ever! ) [SEP]']
[1350/2000] tot_loss=1.509 (perp=6.945, rec=0.115, cos=0.005), tot_loss_proj:2.059 [t=0.31s]
prediction: ['[CLS] outside current political context the climate terrorists takenput ( see evil climate : more evil than ever! ) [SEP]']
Attempt swap
[1400/2000] tot_loss=1.502 (perp=6.945, rec=0.108, cos=0.005), tot_loss_proj:2.060 [t=0.31s]
prediction: ['[CLS] outside current political context the climate terrorists takenput ( see evil climate : more evil than ever! ) [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.489 (perp=6.878, rec=0.109, cos=0.005), tot_loss_proj:2.022 [t=0.31s]
prediction: ['[CLS] outside current political context the climate terrorists taken per ( see evil : more evil than climate ever! ) [SEP]']
[1500/2000] tot_loss=1.485 (perp=6.878, rec=0.105, cos=0.004), tot_loss_proj:2.024 [t=0.31s]
prediction: ['[CLS] outside current political context the climate terrorists taken per ( see evil : more evil than climate ever! ) [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.449 (perp=6.646, rec=0.116, cos=0.004), tot_loss_proj:1.967 [t=0.31s]
prediction: ['[CLS] outside current political context the climate taken per terrorists ( see evil : more evil than climate ever! ) [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.477 (perp=6.812, rec=0.110, cos=0.004), tot_loss_proj:2.060 [t=0.31s]
prediction: ['[CLS] outside current political context the takenput terrorists ( see climate evil : more evil than climate ever! ) [SEP]']
[1650/2000] tot_loss=1.442 (perp=6.639, rec=0.110, cos=0.004), tot_loss_proj:1.936 [t=0.31s]
prediction: ['[CLS] outside current political context the taken per terrorists ( see climate evil : more evil than climate ever! ) [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.436 (perp=6.640, rec=0.104, cos=0.004), tot_loss_proj:2.014 [t=0.31s]
prediction: ['[CLS] outside current political context the need terrorists taken ( see climate evil : more evil than climate ever! ) [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.369 (perp=6.258, rec=0.112, cos=0.005), tot_loss_proj:1.748 [t=0.31s]
prediction: ['[CLS] outside the current political context per terrorists taken ( see climate evil : more evil than climate ever! ) [SEP]']
[1800/2000] tot_loss=1.364 (perp=6.258, rec=0.108, cos=0.004), tot_loss_proj:1.739 [t=0.31s]
prediction: ['[CLS] outside the current political context per terrorists taken ( see climate evil : more evil than climate ever! ) [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.322 (perp=5.968, rec=0.123, cos=0.005), tot_loss_proj:1.717 [t=0.31s]
prediction: ['[CLS] n terrorists taken outside the current political context ( see climate evil : more evil than climate ever! ) [SEP]']
Attempt swap
[1900/2000] tot_loss=1.314 (perp=5.968, rec=0.115, cos=0.004), tot_loss_proj:1.712 [t=0.31s]
prediction: ['[CLS] n terrorists taken outside the current political context ( see climate evil : more evil than climate ever! ) [SEP]']
[1950/2000] tot_loss=1.311 (perp=5.968, rec=0.113, cos=0.004), tot_loss_proj:1.709 [t=0.31s]
prediction: ['[CLS] n terrorists taken outside the current political context ( see climate evil : more evil than climate ever! ) [SEP]']
Attempt swap
[2000/2000] tot_loss=1.310 (perp=5.968, rec=0.112, cos=0.004), tot_loss_proj:1.709 [t=0.31s]
prediction: ['[CLS] n terrorists taken outside the current political context ( see climate evil : more evil than climate ever! ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] outside current political context the three terrorists : ( evil climate seen see more evil than ever taken! ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 23.529 | p: 23.529 | r: 23.529
rougeL     | fm: 61.111 | p: 61.111 | r: 61.111
rougeLsum  | fm: 61.111 | p: 61.111 | r: 61.111
r1fm+r2fm = 106.863

[Aggregate metrics]:
rouge1     | fm: 89.554 | p: 88.824 | r: 90.395
rouge2     | fm: 58.362 | p: 57.839 | r: 59.049
rougeL     | fm: 79.832 | p: 79.105 | r: 80.777
rougeLsum  | fm: 79.645 | p: 79.036 | r: 80.541
r1fm+r2fm = 147.916

input #24 time: 0:12:24 | total time: 5:03:22


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9986874149919696
highest_index [0]
highest [0.9986874149919696]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 0.9557013511657715 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9497941136360168 for ['[CLS] past banking son davies [SEP]']
[Init] best rec loss: 0.9454858303070068 for ['[CLS] weakness blue fast @ [SEP]']
[Init] best rec loss: 0.9428203105926514 for ['[CLS] stepped senate centuryfish [SEP]']
[Init] best rec loss: 0.9414227604866028 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.940095067024231 for ['[CLS] all one trace perfect [SEP]']
[Init] best rec loss: 0.9271516799926758 for ['[CLS]bla mozart orleans [SEP] [SEP]']
[Init] best rec loss: 0.9212543368339539 for ['[CLS] visionmetric dozennica [SEP]']
[Init] best rec loss: 0.9183601140975952 for ['[CLS] manner from bathing small [SEP]']
[Init] best rec loss: 0.9170480966567993 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best perm rec loss: 0.9154016375541687 for ['[CLS] assistant fantasy youthorus [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.345 (perp=13.353, rec=0.676, cos=0.998), tot_loss_proj:4.371 [t=0.30s]
prediction: ['[CLS] strange wales knew offensive [SEP]']
[ 100/2000] tot_loss=3.315 (perp=10.420, rec=0.563, cos=0.668), tot_loss_proj:3.659 [t=0.30s]
prediction: ['[CLS] strange lion beautiful offensive [SEP]']
[ 150/2000] tot_loss=2.995 (perp=12.005, rec=0.469, cos=0.125), tot_loss_proj:3.165 [t=0.30s]
prediction: ['[CLS] beautifulpeed show peaceful [SEP]']
[ 200/2000] tot_loss=2.511 (perp=10.376, rec=0.365, cos=0.071), tot_loss_proj:2.389 [t=0.30s]
prediction: ['[CLS] strange beautiful film beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.046 (perp=8.270, rec=0.301, cos=0.091), tot_loss_proj:1.934 [t=0.30s]
prediction: ['[CLS] strange beautiful beautiful film [SEP]']
[ 300/2000] tot_loss=2.191 (perp=8.915, rec=0.278, cos=0.131), tot_loss_proj:2.032 [t=0.30s]
prediction: ['[CLS] strange beautiful film film [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.994 (perp=7.943, rec=0.278, cos=0.127), tot_loss_proj:2.023 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.989 (perp=7.943, rec=0.259, cos=0.142), tot_loss_proj:2.022 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[ 450/2000] tot_loss=1.980 (perp=7.943, rec=0.250, cos=0.141), tot_loss_proj:2.025 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.004 (perp=7.943, rec=0.253, cos=0.163), tot_loss_proj:2.028 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.982 (perp=7.943, rec=0.240, cos=0.154), tot_loss_proj:2.025 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[ 600/2000] tot_loss=1.977 (perp=7.943, rec=0.232, cos=0.157), tot_loss_proj:2.033 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.970 (perp=7.943, rec=0.242, cos=0.140), tot_loss_proj:2.024 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.947 (perp=7.943, rec=0.224, cos=0.135), tot_loss_proj:2.028 [t=0.31s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[ 750/2000] tot_loss=1.962 (perp=7.943, rec=0.218, cos=0.155), tot_loss_proj:2.024 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.928 (perp=7.943, rec=0.202, cos=0.138), tot_loss_proj:2.034 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.914 (perp=7.943, rec=0.191, cos=0.134), tot_loss_proj:2.027 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[ 900/2000] tot_loss=1.933 (perp=7.943, rec=0.206, cos=0.139), tot_loss_proj:2.029 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.934 (perp=7.943, rec=0.203, cos=0.142), tot_loss_proj:2.031 [t=0.31s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.925 (perp=7.943, rec=0.193, cos=0.143), tot_loss_proj:2.030 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1050/2000] tot_loss=1.931 (perp=7.943, rec=0.194, cos=0.149), tot_loss_proj:2.025 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.932 (perp=7.943, rec=0.203, cos=0.140), tot_loss_proj:2.029 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.932 (perp=7.943, rec=0.200, cos=0.143), tot_loss_proj:2.028 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1200/2000] tot_loss=1.922 (perp=7.943, rec=0.192, cos=0.142), tot_loss_proj:2.033 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.921 (perp=7.943, rec=0.191, cos=0.142), tot_loss_proj:2.032 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.920 (perp=7.943, rec=0.190, cos=0.141), tot_loss_proj:2.032 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1350/2000] tot_loss=1.924 (perp=7.943, rec=0.193, cos=0.142), tot_loss_proj:2.029 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.924 (perp=7.943, rec=0.191, cos=0.144), tot_loss_proj:2.029 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.922 (perp=7.943, rec=0.190, cos=0.143), tot_loss_proj:2.025 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1500/2000] tot_loss=1.921 (perp=7.943, rec=0.191, cos=0.142), tot_loss_proj:2.032 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.924 (perp=7.943, rec=0.193, cos=0.142), tot_loss_proj:2.031 [t=0.31s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.921 (perp=7.943, rec=0.190, cos=0.143), tot_loss_proj:2.029 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1650/2000] tot_loss=1.928 (perp=7.943, rec=0.195, cos=0.144), tot_loss_proj:2.031 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.924 (perp=7.943, rec=0.193, cos=0.142), tot_loss_proj:2.034 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.931 (perp=7.943, rec=0.199, cos=0.143), tot_loss_proj:2.026 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1800/2000] tot_loss=1.925 (perp=7.943, rec=0.193, cos=0.144), tot_loss_proj:2.033 [t=0.31s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.922 (perp=7.943, rec=0.192, cos=0.142), tot_loss_proj:2.034 [t=0.31s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.917 (perp=7.943, rec=0.186, cos=0.143), tot_loss_proj:2.032 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1950/2000] tot_loss=1.933 (perp=7.943, rec=0.202, cos=0.142), tot_loss_proj:2.027 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.917 (perp=7.943, rec=0.185, cos=0.144), tot_loss_proj:2.030 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] beautiful strange strange film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 103.333

[Aggregate metrics]:
rouge1     | fm: 89.156 | p: 88.546 | r: 90.061
rouge2     | fm: 56.928 | p: 56.520 | r: 57.555
rougeL     | fm: 79.375 | p: 78.763 | r: 80.217
rougeLsum  | fm: 79.101 | p: 78.558 | r: 80.012
r1fm+r2fm = 146.084

input #25 time: 0:12:03 | total time: 5:15:26


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9984583358815335
highest_index [0]
highest [0.9984583358815335]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.8820197582244873 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.8474043607711792 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 0.8411664962768555 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.840096116065979 for ['[CLS] thisress duck rock torture rubber point latitude nice apart politics al rational lip what asian len field feud winner venues right as [SEP]']
[Init] best rec loss: 0.8238421678543091 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 0.8196629285812378 for ['[CLS] close both singularification tv for oclc maxim catalog station himselfomy rowater rafcl increasing could there metropolitan townland caps maria [SEP]']
[Init] best rec loss: 0.8139204978942871 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 0.811767578125 for ['[CLS] constituencies polish iso s fourth officers death four arrow merely discipline shot usually listkan colonialteadᆼ theoretical door octave souls more [SEP]']
[Init] best perm rec loss: 0.8072108030319214 for ['[CLS]tead four iso colonial arrow constituencies officers merely door fourth discipline polish usually shotᆼkan death souls more list s theoretical octave [SEP]']
[Init] best perm rec loss: 0.805862307548523 for ['[CLS]tead four merely polish arrow colonial octave shot theoretical iso more usually discipline constituencies deathᆼ souls list fourth s officers doorkan [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.409 (perp=10.713, rec=0.247, cos=0.020), tot_loss_proj:2.776 [t=0.31s]
prediction: ['[CLS]y import ) out importer and sent pointless import dark pointless italian import for mother girlfriend import what doorate dad disorders [SEP]']
[ 100/2000] tot_loss=2.450 (perp=11.202, rec=0.197, cos=0.013), tot_loss_proj:2.915 [t=0.31s]
prediction: ['[CLS] - sophie ) out importder and french pointless import dark pointless - import means writer age import criteria -ate french director [SEP]']
[ 150/2000] tot_loss=2.332 (perp=10.842, rec=0.155, cos=0.009), tot_loss_proj:2.803 [t=0.31s]
prediction: ['[CLS] - sophie ) mean importing and french pointless import hot pointless age import - writer writer import criteria from coming french director [SEP]']
[ 200/2000] tot_loss=2.530 (perp=11.079, rec=0.293, cos=0.022), tot_loss_proj:3.049 [t=0.31s]
prediction: ['[CLS] - sophie ) come importing and french pointless importvocation pointless age import ( writer writer from - from coming sophie director [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.578 (perp=11.604, rec=0.238, cos=0.019), tot_loss_proj:3.040 [t=0.31s]
prediction: ['[CLS] - anne ) go kinding and french pointless import social pointless assigned import barren license writer from -horpe raising staff director [SEP]']
[ 300/2000] tot_loss=2.558 (perp=11.643, rec=0.219, cos=0.010), tot_loss_proj:3.184 [t=0.31s]
prediction: ['[CLS]ing anne ) going hapoel. and french pointless import married pointless assigned import nix titles writer from - 語 raising isbn director [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.413 (perp=11.050, rec=0.195, cos=0.009), tot_loss_proj:2.865 [t=0.31s]
prediction: ['[CLS]ing anne ) going slash. and french pointless import coming pointless import passionate social writer from - ை assigned reformeving director [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.214 (perp=10.192, rec=0.168, cos=0.008), tot_loss_proj:2.718 [t=0.31s]
prediction: ['[CLS] coming anne ) going relatively. and french pointless importing pointless import nix age writer from - 語 assigned reformeving director [SEP]']
[ 450/2000] tot_loss=2.273 (perp=10.507, rec=0.164, cos=0.008), tot_loss_proj:2.654 [t=0.31s]
prediction: ['[CLS] coming anne ) going slash. and french pointless importing pointless import nix age writer from - arabia assigned newlyeving director [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.275 (perp=10.591, rec=0.150, cos=0.007), tot_loss_proj:2.718 [t=0.31s]
prediction: ['[CLS] coming anne ) going slash. and french pointless importing pointless import jaenelle age writer fromergy - assigned comingacker director [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.243 (perp=10.490, rec=0.139, cos=0.006), tot_loss_proj:2.636 [t=0.31s]
prediction: ['[CLS] coming anne ) going slash. pointless french pointless importing and import jaenelle age writer from [SEP] - assigned comingacker director [SEP]']
[ 600/2000] tot_loss=2.247 (perp=10.490, rec=0.141, cos=0.008), tot_loss_proj:2.635 [t=0.31s]
prediction: ['[CLS] coming anne ) going slash. pointless french pointless importing and import jaenelle age writer from [SEP] - assigned comingacker director [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.206 (perp=10.309, rec=0.138, cos=0.006), tot_loss_proj:2.628 [t=0.31s]
prediction: ['[CLS] coming anne ) going slash. pointless french pointless importing and import jaenelle age writer [SEP] from - assigned coming sophie director [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.135 (perp=9.973, rec=0.134, cos=0.006), tot_loss_proj:2.812 [t=0.31s]
prediction: ['[CLS] coming anne ) going moving. pointless french pointless importing and importplify age writer coming from - assigned [SEP] sophie director [SEP]']
[ 750/2000] tot_loss=2.125 (perp=9.973, rec=0.125, cos=0.006), tot_loss_proj:2.814 [t=0.31s]
prediction: ['[CLS] coming anne ) going moving. pointless french pointless importing and importplify age writer coming from - assigned [SEP] sophie director [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.169 (perp=10.165, rec=0.130, cos=0.006), tot_loss_proj:2.575 [t=0.31s]
prediction: ['[CLS] coming anne ). moving going pointless french pointless importing and importplify age writerback from - assigned [SEP] sophie director [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.960 (perp=9.143, rec=0.126, cos=0.006), tot_loss_proj:2.355 [t=0.31s]
prediction: ['[CLS] coming anne ). moving going pointless french pointless importing and import mean age - from - - [SEP] writer sophie director [SEP]']
[ 900/2000] tot_loss=1.953 (perp=9.143, rec=0.119, cos=0.006), tot_loss_proj:2.357 [t=0.31s]
prediction: ['[CLS] coming anne ). moving going pointless french pointless importing and import mean age - from - - [SEP] writer sophie director [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.911 (perp=8.935, rec=0.119, cos=0.005), tot_loss_proj:2.301 [t=0.31s]
prediction: ['[CLS] coming anne ). moving pointless french going pointless importing and import mean age - from - - [SEP] writer sophie director [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.823 (perp=8.475, rec=0.123, cos=0.006), tot_loss_proj:2.252 [t=0.31s]
prediction: ['[CLS] coming anne ). so pointless french. pointless importing and import mean age from - - - [SEP] writer sophie director [SEP]']
[1050/2000] tot_loss=1.812 (perp=8.475, rec=0.112, cos=0.005), tot_loss_proj:2.247 [t=0.32s]
prediction: ['[CLS] coming anne ). so pointless french. pointless importing and import mean age from - - - [SEP] writer sophie director [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.860 (perp=8.707, rec=0.113, cos=0.005), tot_loss_proj:2.321 [t=0.31s]
prediction: ['[CLS] coming anne ). so pointless french mean pointless importing and import this age from - - of [SEP] writer sophie director [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.860 (perp=8.686, rec=0.117, cos=0.005), tot_loss_proj:2.354 [t=0.31s]
prediction: ['[CLS] coming anne ). mean pointless of mean pointless importing and import this age from - - french [SEP] writer sophie director [SEP]']
[1200/2000] tot_loss=1.850 (perp=8.686, rec=0.107, cos=0.005), tot_loss_proj:2.359 [t=0.31s]
prediction: ['[CLS] coming anne ). mean pointless of mean pointless importing and import this age from - - french [SEP] writer sophie director [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.841 (perp=8.666, rec=0.103, cos=0.005), tot_loss_proj:2.303 [t=0.31s]
prediction: ['[CLS] coming anne ). mean pointless of mean pointless importing and import this age from - french - [SEP] writer sophie director [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.778 (perp=8.296, rec=0.114, cos=0.005), tot_loss_proj:2.261 [t=0.31s]
prediction: ['[CLS] coming anne ). mean pointless of mean pointless importing and import this age from french - - [SEP] writer sophie director [SEP]']
[1350/2000] tot_loss=1.774 (perp=8.296, rec=0.110, cos=0.005), tot_loss_proj:2.261 [t=0.31s]
prediction: ['[CLS] coming anne ). mean pointless of mean pointless importing and import this age from french - - [SEP] writer sophie director [SEP]']
Attempt swap
[1400/2000] tot_loss=1.769 (perp=8.296, rec=0.104, cos=0.005), tot_loss_proj:2.257 [t=0.31s]
prediction: ['[CLS] coming anne ). mean pointless of mean pointless importing and import this age from french - - [SEP] writer sophie director [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.765 (perp=8.246, rec=0.111, cos=0.005), tot_loss_proj:2.154 [t=0.31s]
prediction: ['[CLS] coming anne ). mean pointless this mean pointless importing and import of age from french - - [SEP] writer sophie director [SEP]']
[1500/2000] tot_loss=1.763 (perp=8.246, rec=0.109, cos=0.005), tot_loss_proj:2.147 [t=0.31s]
prediction: ['[CLS] coming anne ). mean pointless this mean pointless importing and import of age from french - - [SEP] writer sophie director [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.747 (perp=8.164, rec=0.109, cos=0.005), tot_loss_proj:2.162 [t=0.31s]
prediction: ['[CLS] coming anne ) - mean pointless this mean pointless importing and import of age from french. - [SEP] writer sophie director [SEP]']
Attempt swap
[1600/2000] tot_loss=1.750 (perp=8.164, rec=0.112, cos=0.005), tot_loss_proj:2.158 [t=0.31s]
prediction: ['[CLS] coming anne ) - mean pointless this mean pointless importing and import of age from french. - [SEP] writer sophie director [SEP]']
[1650/2000] tot_loss=1.747 (perp=8.164, rec=0.109, cos=0.005), tot_loss_proj:2.163 [t=0.31s]
prediction: ['[CLS] coming anne ) - mean pointless this mean pointless importing and import of age from french. - [SEP] writer sophie director [SEP]']
Attempt swap
[1700/2000] tot_loss=1.748 (perp=8.164, rec=0.110, cos=0.005), tot_loss_proj:2.154 [t=0.31s]
prediction: ['[CLS] coming anne ) - mean pointless this mean pointless importing and import of age from french. - [SEP] writer sophie director [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.731 (perp=8.053, rec=0.115, cos=0.006), tot_loss_proj:2.186 [t=0.31s]
prediction: ['[CLS] coming anne ) - this pointless mean mean pointless importing and import of age from french. - [SEP] writer sophie director [SEP]']
[1800/2000] tot_loss=1.733 (perp=8.053, rec=0.117, cos=0.005), tot_loss_proj:2.179 [t=0.31s]
prediction: ['[CLS] coming anne ) - this pointless mean mean pointless importing and import of age from french. - [SEP] writer sophie director [SEP]']
Attempt swap
[1850/2000] tot_loss=1.726 (perp=8.053, rec=0.110, cos=0.005), tot_loss_proj:2.184 [t=0.31s]
prediction: ['[CLS] coming anne ) - this pointless mean mean pointless importing and import of age from french. - [SEP] writer sophie director [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.603 (perp=7.455, rec=0.106, cos=0.005), tot_loss_proj:2.045 [t=0.31s]
prediction: ['[CLS] coming anne ) - this pointless mean mean pointless importing and import of age from french. sophie - writer - director [SEP]']
[1950/2000] tot_loss=1.606 (perp=7.455, rec=0.109, cos=0.005), tot_loss_proj:2.041 [t=0.31s]
prediction: ['[CLS] coming anne ) - this pointless mean mean pointless importing and import of age from french. sophie - writer - director [SEP]']
Attempt swap
[2000/2000] tot_loss=1.597 (perp=7.455, rec=0.101, cos=0.005), tot_loss_proj:2.044 [t=0.31s]
prediction: ['[CLS] coming anne ) - this pointless mean mean pointless importing and import of age from french. sophie - writer - director [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] coming anne ) - mean pointless this mean pointless importing and import of age from french. - [SEP] writer sophie director [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.081 | p: 75.000 | r: 88.235
rouge2     | fm: 5.714 | p: 5.263 | r: 6.250
rougeL     | fm: 48.649 | p: 45.000 | r: 52.941
rougeLsum  | fm: 48.649 | p: 45.000 | r: 52.941
r1fm+r2fm = 86.795

[Aggregate metrics]:
rouge1     | fm: 88.917 | p: 88.030 | r: 90.091
rouge2     | fm: 54.639 | p: 54.127 | r: 55.278
rougeL     | fm: 78.167 | p: 77.331 | r: 79.111
rougeLsum  | fm: 78.007 | p: 77.272 | r: 79.027
r1fm+r2fm = 143.555

input #26 time: 0:12:24 | total time: 5:27:50


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.9986294185992848
highest_index [0]
highest [0.9986294185992848]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9948244094848633 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9558571577072144 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 0.9553346037864685 for ['[CLS] volume nan on [SEP]']
[Init] best rec loss: 0.9323459267616272 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.9291068911552429 for ['[CLS] how turned basic [SEP]']
[Init] best rec loss: 0.9155980944633484 for ['[CLS] op framework ran [SEP]']
[Init] best rec loss: 0.9136955142021179 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.9130001664161682 for ['[CLS] given transitwine [SEP]']
[Init] best perm rec loss: 0.9127731919288635 for ['[CLS]wine transit given [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.196 (perp=9.693, rec=0.231, cos=0.026), tot_loss_proj:2.594 [t=0.30s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 100/2000] tot_loss=2.123 (perp=9.956, rec=0.121, cos=0.011), tot_loss_proj:2.565 [t=0.30s]
prediction: ['[CLS] are generic are [SEP]']
[ 150/2000] tot_loss=1.995 (perp=9.504, rec=0.091, cos=0.004), tot_loss_proj:2.185 [t=0.30s]
prediction: ['[CLS] so generic are [SEP]']
[ 200/2000] tot_loss=1.977 (perp=9.504, rec=0.073, cos=0.003), tot_loss_proj:2.189 [t=0.30s]
prediction: ['[CLS] so generic are [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.740 (perp=8.320, rec=0.073, cos=0.003), tot_loss_proj:1.786 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.725 (perp=8.320, rec=0.058, cos=0.003), tot_loss_proj:1.793 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.739 (perp=8.320, rec=0.072, cos=0.003), tot_loss_proj:1.781 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.726 (perp=8.320, rec=0.059, cos=0.003), tot_loss_proj:1.768 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.744 (perp=8.320, rec=0.077, cos=0.003), tot_loss_proj:1.772 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.748 (perp=8.320, rec=0.081, cos=0.003), tot_loss_proj:1.766 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.730 (perp=8.320, rec=0.063, cos=0.003), tot_loss_proj:1.782 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.730 (perp=8.320, rec=0.063, cos=0.003), tot_loss_proj:1.781 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.722 (perp=8.320, rec=0.055, cos=0.003), tot_loss_proj:1.778 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.747 (perp=8.320, rec=0.080, cos=0.003), tot_loss_proj:1.773 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.727 (perp=8.320, rec=0.060, cos=0.003), tot_loss_proj:1.769 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.743 (perp=8.320, rec=0.076, cos=0.003), tot_loss_proj:1.777 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.735 (perp=8.320, rec=0.068, cos=0.003), tot_loss_proj:1.787 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.729 (perp=8.320, rec=0.062, cos=0.003), tot_loss_proj:1.786 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.727 (perp=8.320, rec=0.060, cos=0.003), tot_loss_proj:1.784 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.726 (perp=8.320, rec=0.059, cos=0.003), tot_loss_proj:1.791 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.739 (perp=8.320, rec=0.072, cos=0.003), tot_loss_proj:1.781 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.737 (perp=8.320, rec=0.071, cos=0.003), tot_loss_proj:1.803 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.726 (perp=8.320, rec=0.059, cos=0.003), tot_loss_proj:1.801 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.733 (perp=8.320, rec=0.067, cos=0.003), tot_loss_proj:1.790 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.730 (perp=8.320, rec=0.063, cos=0.003), tot_loss_proj:1.798 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.727 (perp=8.320, rec=0.060, cos=0.003), tot_loss_proj:1.799 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.729 (perp=8.320, rec=0.062, cos=0.003), tot_loss_proj:1.792 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.716 (perp=8.320, rec=0.049, cos=0.003), tot_loss_proj:1.794 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.732 (perp=8.320, rec=0.066, cos=0.003), tot_loss_proj:1.797 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.728 (perp=8.320, rec=0.061, cos=0.003), tot_loss_proj:1.797 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.729 (perp=8.320, rec=0.063, cos=0.003), tot_loss_proj:1.799 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.720 (perp=8.320, rec=0.053, cos=0.003), tot_loss_proj:1.784 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.727 (perp=8.320, rec=0.061, cos=0.003), tot_loss_proj:1.797 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.723 (perp=8.320, rec=0.056, cos=0.003), tot_loss_proj:1.804 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.722 (perp=8.320, rec=0.055, cos=0.003), tot_loss_proj:1.802 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.736 (perp=8.320, rec=0.069, cos=0.003), tot_loss_proj:1.792 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.729 (perp=8.320, rec=0.062, cos=0.003), tot_loss_proj:1.797 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.725 (perp=8.320, rec=0.058, cos=0.003), tot_loss_proj:1.798 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.729 (perp=8.320, rec=0.062, cos=0.003), tot_loss_proj:1.794 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.741 (perp=8.320, rec=0.074, cos=0.003), tot_loss_proj:1.798 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.376 | p: 88.535 | r: 90.423
rouge2     | fm: 56.442 | p: 56.009 | r: 56.990
rougeL     | fm: 79.052 | p: 78.297 | r: 80.079
rougeLsum  | fm: 78.800 | p: 78.121 | r: 79.655
r1fm+r2fm = 145.818

input #27 time: 0:12:03 | total time: 5:39:53


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.999007726378041
highest_index [0]
highest [0.999007726378041]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8572036027908325 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.8067139387130737 for ['[CLS] want set aperture jersey [SEP]']
[Init] best rec loss: 0.7952914237976074 for ['[CLS] w dean re thanks [SEP]']
[Init] best rec loss: 0.7880811095237732 for ['[CLS] larvae heights jeremy roses [SEP]']
[Init] best perm rec loss: 0.786729097366333 for ['[CLS] heights roses larvae jeremy [SEP]']
[Init] best perm rec loss: 0.7850720286369324 for ['[CLS] roses larvae jeremy heights [SEP]']
[Init] best perm rec loss: 0.784530758857727 for ['[CLS] roses jeremy heights larvae [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.035 (perp=8.476, rec=0.289, cos=0.050), tot_loss_proj:2.280 [t=0.30s]
prediction: ['[CLS] for only minutes minutes [SEP]']
[ 100/2000] tot_loss=1.824 (perp=8.476, rec=0.123, cos=0.007), tot_loss_proj:2.262 [t=0.30s]
prediction: ['[CLS] for only minutes minutes [SEP]']
[ 150/2000] tot_loss=1.830 (perp=8.766, rec=0.074, cos=0.002), tot_loss_proj:2.405 [t=0.30s]
prediction: ['[CLS] for only minutes 71 [SEP]']
[ 200/2000] tot_loss=1.813 (perp=8.766, rec=0.057, cos=0.002), tot_loss_proj:2.413 [t=0.30s]
prediction: ['[CLS] for only minutes 71 [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.606 (perp=7.699, rec=0.063, cos=0.003), tot_loss_proj:1.639 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 300/2000] tot_loss=1.604 (perp=7.699, rec=0.061, cos=0.003), tot_loss_proj:1.640 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.608 (perp=7.699, rec=0.066, cos=0.003), tot_loss_proj:1.640 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.608 (perp=7.699, rec=0.066, cos=0.002), tot_loss_proj:1.634 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 450/2000] tot_loss=1.602 (perp=7.699, rec=0.060, cos=0.002), tot_loss_proj:1.643 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.593 (perp=7.699, rec=0.051, cos=0.002), tot_loss_proj:1.646 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.596 (perp=7.699, rec=0.055, cos=0.002), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.597 (perp=7.699, rec=0.055, cos=0.002), tot_loss_proj:1.638 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.617 (perp=7.699, rec=0.075, cos=0.002), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.610 (perp=7.699, rec=0.068, cos=0.002), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.600 (perp=7.699, rec=0.058, cos=0.002), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.600 (perp=7.699, rec=0.058, cos=0.002), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.606 (perp=7.699, rec=0.064, cos=0.002), tot_loss_proj:1.648 [t=0.39s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.598 (perp=7.699, rec=0.056, cos=0.002), tot_loss_proj:1.641 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.600 (perp=7.699, rec=0.058, cos=0.002), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.002), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.612 (perp=7.699, rec=0.070, cos=0.002), tot_loss_proj:1.637 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.603 (perp=7.699, rec=0.061, cos=0.002), tot_loss_proj:1.640 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.607 (perp=7.699, rec=0.065, cos=0.002), tot_loss_proj:1.638 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.610 (perp=7.699, rec=0.069, cos=0.002), tot_loss_proj:1.639 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.595 (perp=7.699, rec=0.053, cos=0.002), tot_loss_proj:1.630 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.590 (perp=7.699, rec=0.049, cos=0.002), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.002), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.598 (perp=7.699, rec=0.057, cos=0.002), tot_loss_proj:1.638 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.605 (perp=7.699, rec=0.064, cos=0.002), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.590 (perp=7.699, rec=0.049, cos=0.002), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.606 (perp=7.699, rec=0.064, cos=0.002), tot_loss_proj:1.630 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.594 (perp=7.699, rec=0.052, cos=0.002), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.598 (perp=7.699, rec=0.057, cos=0.002), tot_loss_proj:1.644 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.613 (perp=7.699, rec=0.071, cos=0.002), tot_loss_proj:1.644 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.588 (perp=7.699, rec=0.046, cos=0.002), tot_loss_proj:1.629 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.614 (perp=7.699, rec=0.072, cos=0.002), tot_loss_proj:1.649 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.606 (perp=7.699, rec=0.065, cos=0.002), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.601 (perp=7.699, rec=0.059, cos=0.002), tot_loss_proj:1.643 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.604 (perp=7.699, rec=0.062, cos=0.002), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.610 (perp=7.699, rec=0.069, cos=0.002), tot_loss_proj:1.639 [t=0.30s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.694 | p: 88.790 | r: 90.686
rouge2     | fm: 58.259 | p: 57.835 | r: 58.870
rougeL     | fm: 79.687 | p: 78.898 | r: 80.564
rougeLsum  | fm: 79.470 | p: 78.751 | r: 80.429
r1fm+r2fm = 147.954

input #28 time: 0:12:03 | total time: 5:51:57


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.9987247930346629
highest_index [0]
highest [0.9987247930346629]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.9055503010749817 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.8632421493530273 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.8494009971618652 for ['[CLS] label which £ anyway shoes mediamont campbell her cullen [SEP]']
[Init] best rec loss: 0.8361334800720215 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8077508211135864 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 0.7883270382881165 for ['[CLS] consuming after intern coach acres surf class speed tongues period [SEP]']
[Init] best rec loss: 0.786916196346283 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best perm rec loss: 0.7842475771903992 for ['[CLS] f meters transmit axle cells bu mostly ufounded veto [SEP]']
[Init] best perm rec loss: 0.78177809715271 for ['[CLS] cells veto axle bufounded f mostly u meters transmit [SEP]']
[Init] best perm rec loss: 0.7804149985313416 for ['[CLS]founded cells u bu transmit veto axle mostly f meters [SEP]']
[Init] best perm rec loss: 0.7798597812652588 for ['[CLS] cells meters bu axle f mostlyfounded veto u transmit [SEP]']
[Init] best perm rec loss: 0.7789176106452942 for ['[CLS] veto bu u f mostlyfounded transmit meters axle cells [SEP]']
[Init] best perm rec loss: 0.7770418524742126 for ['[CLS] axle cells u bu mostly f transmitfounded veto meters [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.880 (perp=8.019, rec=0.245, cos=0.031), tot_loss_proj:3.022 [t=0.30s]
prediction: ['[CLS] i believe that indeed is current evil not it loki [SEP]']
[ 100/2000] tot_loss=1.776 (perp=8.172, rec=0.129, cos=0.012), tot_loss_proj:2.530 [t=0.30s]
prediction: ['[CLS] i believe that is is current evil not it resident [SEP]']
[ 150/2000] tot_loss=1.731 (perp=8.080, rec=0.105, cos=0.010), tot_loss_proj:2.560 [t=0.30s]
prediction: ['[CLS] i believe that is evil current resident not it resident [SEP]']
[ 200/2000] tot_loss=1.723 (perp=8.080, rec=0.096, cos=0.010), tot_loss_proj:2.575 [t=0.30s]
prediction: ['[CLS] i believe that is evil current resident not it resident [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.525 (perp=6.942, rec=0.124, cos=0.012), tot_loss_proj:2.113 [t=0.30s]
prediction: ['[CLS] i believe that former evil is resident not it. [SEP]']
[ 300/2000] tot_loss=1.493 (perp=7.003, rec=0.086, cos=0.007), tot_loss_proj:2.211 [t=0.31s]
prediction: ['[CLS] i believe that let evil is resident not it. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.110 (perp=5.114, rec=0.080, cos=0.007), tot_loss_proj:1.567 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is the not it. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.117 (perp=5.085, rec=0.094, cos=0.006), tot_loss_proj:1.465 [t=0.30s]
prediction: ['[CLS] current i believe that resident evil is not it. [SEP]']
[ 450/2000] tot_loss=1.103 (perp=5.085, rec=0.080, cos=0.006), tot_loss_proj:1.462 [t=0.31s]
prediction: ['[CLS] current i believe that resident evil is not it. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.107 (perp=5.085, rec=0.083, cos=0.006), tot_loss_proj:1.455 [t=0.30s]
prediction: ['[CLS] current i believe that resident evil is not it. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.102 (perp=5.085, rec=0.078, cos=0.006), tot_loss_proj:1.460 [t=0.30s]
prediction: ['[CLS] current i believe that resident evil is not it. [SEP]']
[ 600/2000] tot_loss=1.186 (perp=5.454, rec=0.089, cos=0.006), tot_loss_proj:1.579 [t=0.31s]
prediction: ['[CLS] prospective i believe that resident evil is not it. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.124 (perp=5.191, rec=0.080, cos=0.006), tot_loss_proj:1.545 [t=0.30s]
prediction: ['[CLS] i believe that resident evil prospective is not it. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.127 (perp=5.191, rec=0.083, cos=0.006), tot_loss_proj:1.564 [t=0.30s]
prediction: ['[CLS] i believe that resident evil prospective is not it. [SEP]']
[ 750/2000] tot_loss=1.121 (perp=5.191, rec=0.076, cos=0.006), tot_loss_proj:1.592 [t=0.30s]
prediction: ['[CLS] i believe that resident evil prospective is not it. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.124 (perp=5.191, rec=0.080, cos=0.006), tot_loss_proj:1.638 [t=0.30s]
prediction: ['[CLS] i believe that resident evil prospective is not it. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.120 (perp=5.191, rec=0.076, cos=0.006), tot_loss_proj:1.697 [t=0.30s]
prediction: ['[CLS] i believe that resident evil prospective is not it. [SEP]']
[ 900/2000] tot_loss=1.123 (perp=5.191, rec=0.078, cos=0.006), tot_loss_proj:1.709 [t=0.30s]
prediction: ['[CLS] i believe that resident evil prospective is not it. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.113 (perp=5.128, rec=0.081, cos=0.006), tot_loss_proj:1.632 [t=0.30s]
prediction: ['[CLS] i believe that resident evil highway is not it. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.118 (perp=5.128, rec=0.087, cos=0.006), tot_loss_proj:1.659 [t=0.30s]
prediction: ['[CLS] i believe that resident evil highway is not it. [SEP]']
[1050/2000] tot_loss=1.115 (perp=5.128, rec=0.083, cos=0.006), tot_loss_proj:1.675 [t=0.30s]
prediction: ['[CLS] i believe that resident evil highway is not it. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.189 (perp=5.447, rec=0.094, cos=0.006), tot_loss_proj:1.564 [t=0.31s]
prediction: ['[CLS] i believe that resident evil we is not it. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.094 (perp=4.999, rec=0.088, cos=0.006), tot_loss_proj:2.076 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
[1200/2000] tot_loss=1.090 (perp=4.999, rec=0.084, cos=0.006), tot_loss_proj:2.083 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.095 (perp=4.999, rec=0.089, cos=0.006), tot_loss_proj:2.080 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.087 (perp=4.999, rec=0.081, cos=0.006), tot_loss_proj:2.087 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
[1350/2000] tot_loss=1.087 (perp=4.999, rec=0.081, cos=0.006), tot_loss_proj:2.092 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.088 (perp=4.999, rec=0.082, cos=0.006), tot_loss_proj:2.086 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.088 (perp=4.999, rec=0.082, cos=0.006), tot_loss_proj:2.091 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
[1500/2000] tot_loss=1.076 (perp=4.999, rec=0.071, cos=0.006), tot_loss_proj:2.095 [t=0.31s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.088 (perp=4.999, rec=0.083, cos=0.006), tot_loss_proj:2.085 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.080 (perp=4.999, rec=0.074, cos=0.006), tot_loss_proj:2.088 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
[1650/2000] tot_loss=1.080 (perp=4.999, rec=0.074, cos=0.006), tot_loss_proj:2.086 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.088 (perp=4.999, rec=0.083, cos=0.006), tot_loss_proj:2.097 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.091 (perp=4.999, rec=0.086, cos=0.006), tot_loss_proj:2.097 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
[1800/2000] tot_loss=1.106 (perp=4.999, rec=0.100, cos=0.006), tot_loss_proj:2.094 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.081 (perp=4.999, rec=0.075, cos=0.005), tot_loss_proj:2.104 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.086 (perp=4.999, rec=0.081, cos=0.005), tot_loss_proj:2.097 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
[1950/2000] tot_loss=1.091 (perp=4.999, rec=0.086, cos=0.005), tot_loss_proj:2.094 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.097 (perp=4.999, rec=0.092, cos=0.005), tot_loss_proj:2.102 [t=0.30s]
prediction: ['[CLS] i believe that resident evil is we not it. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i believe that resident evil is we not it. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 160.909

[Aggregate metrics]:
rouge1     | fm: 89.687 | p: 88.928 | r: 90.707
rouge2     | fm: 58.419 | p: 58.070 | r: 58.909
rougeL     | fm: 80.220 | p: 79.482 | r: 81.103
rougeLsum  | fm: 79.906 | p: 79.150 | r: 80.802
r1fm+r2fm = 148.106

input #29 time: 0:12:06 | total time: 6:04:04


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.9986146406233287
highest_index [0]
highest [0.9986146406233287]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.853379487991333 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.713395893573761 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.69585782289505 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.6674911379814148 for ['[CLS] acceleration council lizard [SEP]']
[Init] best rec loss: 0.6607113480567932 for ['[CLS] spent who mom [SEP]']
[Init] best perm rec loss: 0.6522678136825562 for ['[CLS] mom who spent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.133 (perp=9.539, rec=0.206, cos=0.018), tot_loss_proj:1.982 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[ 100/2000] tot_loss=1.993 (perp=9.539, rec=0.079, cos=0.005), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[ 150/2000] tot_loss=1.994 (perp=9.539, rec=0.080, cos=0.006), tot_loss_proj:1.988 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=1.983 (perp=9.539, rec=0.071, cos=0.004), tot_loss_proj:1.968 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.979 (perp=9.539, rec=0.068, cos=0.004), tot_loss_proj:1.973 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.972 (perp=9.539, rec=0.060, cos=0.004), tot_loss_proj:1.972 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.974 (perp=9.539, rec=0.062, cos=0.004), tot_loss_proj:1.974 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.967 (perp=9.539, rec=0.056, cos=0.003), tot_loss_proj:1.977 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.975 (perp=9.539, rec=0.064, cos=0.003), tot_loss_proj:1.980 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.980 (perp=9.539, rec=0.068, cos=0.004), tot_loss_proj:1.977 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.967 (perp=9.539, rec=0.057, cos=0.003), tot_loss_proj:1.980 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.976 (perp=9.539, rec=0.065, cos=0.003), tot_loss_proj:1.976 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.969 (perp=9.539, rec=0.058, cos=0.003), tot_loss_proj:1.972 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.975 (perp=9.539, rec=0.064, cos=0.003), tot_loss_proj:1.976 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.961 (perp=9.539, rec=0.051, cos=0.003), tot_loss_proj:1.967 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.983 (perp=9.539, rec=0.072, cos=0.003), tot_loss_proj:1.978 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.965 (perp=9.539, rec=0.054, cos=0.003), tot_loss_proj:1.967 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.970 (perp=9.539, rec=0.059, cos=0.003), tot_loss_proj:1.988 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.977 (perp=9.539, rec=0.066, cos=0.003), tot_loss_proj:1.970 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.967 (perp=9.539, rec=0.056, cos=0.003), tot_loss_proj:1.983 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.971 (perp=9.539, rec=0.060, cos=0.003), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.989 (perp=9.539, rec=0.078, cos=0.003), tot_loss_proj:1.966 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.967 (perp=9.539, rec=0.056, cos=0.003), tot_loss_proj:1.982 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.980 (perp=9.539, rec=0.070, cos=0.003), tot_loss_proj:1.970 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.971 (perp=9.539, rec=0.060, cos=0.003), tot_loss_proj:1.977 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.963 (perp=9.539, rec=0.052, cos=0.003), tot_loss_proj:1.980 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.966 (perp=9.539, rec=0.055, cos=0.003), tot_loss_proj:1.963 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.976 (perp=9.539, rec=0.065, cos=0.003), tot_loss_proj:1.973 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.967 (perp=9.539, rec=0.056, cos=0.003), tot_loss_proj:1.970 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.959 (perp=9.539, rec=0.048, cos=0.003), tot_loss_proj:1.980 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.971 (perp=9.539, rec=0.060, cos=0.003), tot_loss_proj:1.982 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.962 (perp=9.539, rec=0.051, cos=0.003), tot_loss_proj:1.970 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.965 (perp=9.539, rec=0.054, cos=0.003), tot_loss_proj:1.981 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.970 (perp=9.539, rec=0.059, cos=0.003), tot_loss_proj:1.977 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.967 (perp=9.539, rec=0.056, cos=0.003), tot_loss_proj:1.972 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.978 (perp=9.539, rec=0.067, cos=0.003), tot_loss_proj:1.972 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.955 (perp=9.539, rec=0.044, cos=0.003), tot_loss_proj:1.990 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.979 (perp=9.539, rec=0.068, cos=0.003), tot_loss_proj:1.985 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.969 (perp=9.539, rec=0.059, cos=0.003), tot_loss_proj:1.977 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.982 (perp=9.539, rec=0.072, cos=0.003), tot_loss_proj:1.969 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.047 | p: 89.257 | r: 91.026
rouge2     | fm: 59.786 | p: 59.367 | r: 60.312
rougeL     | fm: 80.772 | p: 80.106 | r: 81.601
rougeLsum  | fm: 80.515 | p: 79.832 | r: 81.254
r1fm+r2fm = 149.833

input #30 time: 0:12:02 | total time: 6:16:06


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.9988596126661817
highest_index [0]
highest [0.9988596126661817]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.8406555652618408 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.8252385258674622 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.81351637840271 for ['[CLS] jing critical hurts [SEP]']
[Init] best rec loss: 0.8067381381988525 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.7584249973297119 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 0.7488560080528259 for ['[CLS] lighthouse peace case [SEP]']
[Init] best rec loss: 0.7429870963096619 for ['[CLS] quarter joined less [SEP]']
[Init] best rec loss: 0.740665853023529 for ['[CLS] coast strong meaning [SEP]']
[Init] best perm rec loss: 0.7377482652664185 for ['[CLS] meaning strong coast [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.431 (perp=11.031, rec=0.197, cos=0.028), tot_loss_proj:2.647 [t=0.30s]
prediction: ['[CLS] better vehicle better [SEP]']
[ 100/2000] tot_loss=2.368 (perp=11.031, rec=0.139, cos=0.023), tot_loss_proj:2.642 [t=0.30s]
prediction: ['[CLS] better vehicle better [SEP]']
[ 150/2000] tot_loss=2.340 (perp=11.031, rec=0.117, cos=0.016), tot_loss_proj:2.641 [t=0.30s]
prediction: ['[CLS] better vehicle better [SEP]']
[ 200/2000] tot_loss=2.059 (perp=9.889, rec=0.079, cos=0.003), tot_loss_proj:2.524 [t=0.30s]
prediction: ['[CLS] a vehicle better [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.583 (perp=7.603, rec=0.059, cos=0.003), tot_loss_proj:1.650 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.586 (perp=7.603, rec=0.063, cos=0.002), tot_loss_proj:1.647 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.581 (perp=7.603, rec=0.058, cos=0.002), tot_loss_proj:1.638 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.002), tot_loss_proj:1.646 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.596 (perp=7.603, rec=0.073, cos=0.002), tot_loss_proj:1.644 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.002), tot_loss_proj:1.655 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.589 (perp=7.603, rec=0.066, cos=0.002), tot_loss_proj:1.637 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.586 (perp=7.603, rec=0.063, cos=0.002), tot_loss_proj:1.643 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.575 (perp=7.603, rec=0.052, cos=0.002), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.584 (perp=7.603, rec=0.061, cos=0.002), tot_loss_proj:1.648 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.576 (perp=7.603, rec=0.053, cos=0.002), tot_loss_proj:1.652 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.576 (perp=7.603, rec=0.053, cos=0.002), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.593 (perp=7.603, rec=0.070, cos=0.002), tot_loss_proj:1.642 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.581 (perp=7.603, rec=0.058, cos=0.002), tot_loss_proj:1.646 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.582 (perp=7.603, rec=0.059, cos=0.002), tot_loss_proj:1.639 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.587 (perp=7.603, rec=0.064, cos=0.002), tot_loss_proj:1.643 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.589 (perp=7.603, rec=0.066, cos=0.002), tot_loss_proj:1.633 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.594 (perp=7.603, rec=0.071, cos=0.002), tot_loss_proj:1.647 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.002), tot_loss_proj:1.646 [t=0.33s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.585 (perp=7.603, rec=0.062, cos=0.002), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.584 (perp=7.603, rec=0.061, cos=0.002), tot_loss_proj:1.650 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.581 (perp=7.603, rec=0.058, cos=0.002), tot_loss_proj:1.631 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.574 (perp=7.603, rec=0.051, cos=0.002), tot_loss_proj:1.645 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.582 (perp=7.603, rec=0.059, cos=0.002), tot_loss_proj:1.629 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.578 (perp=7.603, rec=0.055, cos=0.002), tot_loss_proj:1.644 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.579 (perp=7.603, rec=0.056, cos=0.002), tot_loss_proj:1.648 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.578 (perp=7.603, rec=0.056, cos=0.002), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.578 (perp=7.603, rec=0.055, cos=0.002), tot_loss_proj:1.642 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.577 (perp=7.603, rec=0.054, cos=0.002), tot_loss_proj:1.646 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.580 (perp=7.603, rec=0.057, cos=0.002), tot_loss_proj:1.639 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.580 (perp=7.603, rec=0.057, cos=0.002), tot_loss_proj:1.643 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.002), tot_loss_proj:1.638 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.574 (perp=7.603, rec=0.051, cos=0.002), tot_loss_proj:1.641 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.002), tot_loss_proj:1.638 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.574 (perp=7.603, rec=0.051, cos=0.002), tot_loss_proj:1.641 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=7.603, rec=0.064, cos=0.002), tot_loss_proj:1.640 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.372 | p: 89.611 | r: 91.394
rouge2     | fm: 61.079 | p: 60.618 | r: 61.584
rougeL     | fm: 81.388 | p: 80.763 | r: 82.238
rougeLsum  | fm: 81.274 | p: 80.674 | r: 82.111
r1fm+r2fm = 151.451

input #31 time: 0:12:03 | total time: 6:28:10


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9987716460035503
highest_index [0]
highest [0.9987716460035503]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 0.9335673451423645 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9324339032173157 for ['[CLS] huey while kill stuck doc urgent lakeside integration food trailers with a [SEP]']
[Init] best rec loss: 0.9308454394340515 for ['[CLS]le force cheers discarded replicateباد clash lighthouse direct remarried narrative words [SEP]']
[Init] best rec loss: 0.927771806716919 for ['[CLS] youth old made particular lostgraph matchyna suicide kara global guess [SEP]']
[Init] best rec loss: 0.918467104434967 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.9168099164962769 for ['[CLS] nap first mddic nichols carriage usual spread wits eu pun age [SEP]']
[Init] best rec loss: 0.8985159993171692 for ['[CLS] palaceshire athletic th funds lilith bio circlecting thomas cake natalie [SEP]']
[Init] best perm rec loss: 0.8970881700515747 for ['[CLS] natalieshire athletic th circle funds lilith thomas palacecting cake bio [SEP]']
[Init] best perm rec loss: 0.8943740725517273 for ['[CLS]shire th lilithcting natalie thomas palace bio cake funds circle athletic [SEP]']
[Init] best perm rec loss: 0.894206702709198 for ['[CLS] circle fundsshire natalie lilith th thomas biocting palace athletic cake [SEP]']
[Init] best perm rec loss: 0.8938654065132141 for ['[CLS] circle funds palace lilith th thomas nataliecting cakeshire bio athletic [SEP]']
[Init] best perm rec loss: 0.892711877822876 for ['[CLS] cakecting natalie circleshire bio palace athletic funds lilith th thomas [SEP]']
[Init] best perm rec loss: 0.8913602232933044 for ['[CLS]cting natalie funds bio lilithshire circle athletic th cake palace thomas [SEP]']
[Init] best perm rec loss: 0.8898700475692749 for ['[CLS] bio funds lilith athletic thomas circle natalie cake palacectingshire th [SEP]']
[Init] best perm rec loss: 0.8892028331756592 for ['[CLS] natalie lilith circlecting bioshire cake funds th athletic thomas palace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.327 (perp=13.924, rec=0.413, cos=0.129), tot_loss_proj:4.485 [t=0.30s]
prediction: ['[CLS] humanity theirs mmm hour combat blended combatoris renaissance it apt seal [SEP]']
[ 100/2000] tot_loss=3.404 (perp=14.291, rec=0.363, cos=0.183), tot_loss_proj:4.669 [t=0.30s]
prediction: ['[CLS] femalesonate appreciate story combat toll acrossonate kids accessible minimalonate [SEP]']
[ 150/2000] tot_loss=3.334 (perp=13.989, rec=0.305, cos=0.231), tot_loss_proj:4.760 [t=0.30s]
prediction: ['[CLS]plifyonate appreciate stories issue toll acrossonatelasticishly minimalonate [SEP]']
[ 200/2000] tot_loss=2.992 (perp=12.575, rec=0.295, cos=0.182), tot_loss_proj:4.461 [t=0.30s]
prediction: ['[CLS]plifyonate enough stories stories that acrossonate advantages approach minimalonate [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.125 (perp=13.067, rec=0.279, cos=0.233), tot_loss_proj:4.230 [t=0.30s]
prediction: ['[CLS]onateonate pull stories easily will acrossonateonate accessible dex advantages [SEP]']
[ 300/2000] tot_loss=3.198 (perp=13.412, rec=0.257, cos=0.258), tot_loss_proj:4.568 [t=0.30s]
prediction: ['[CLS]onateonate pull stories easily resplexonateonate access dextures [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.903 (perp=12.213, rec=0.237, cos=0.223), tot_loss_proj:4.106 [t=0.31s]
prediction: ['[CLS]onateonate pull stories easily resonateonate freed access dex coaster [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.864 (perp=11.743, rec=0.256, cos=0.259), tot_loss_proj:4.032 [t=0.30s]
prediction: ['[CLS]onateonate pull stories easily resonate coaster spaced approach dexonate [SEP]']
[ 450/2000] tot_loss=3.125 (perp=13.301, rec=0.227, cos=0.238), tot_loss_proj:4.388 [t=0.30s]
prediction: ['[CLS]onateonate pull stories easily res accessible coaster spaced inmates dexonate [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.855 (perp=11.983, rec=0.231, cos=0.228), tot_loss_proj:3.451 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate accessible coaster with access dex specializing [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.892 (perp=12.175, rec=0.228, cos=0.229), tot_loss_proj:3.833 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing coaster spaced access dex accessible [SEP]']
[ 600/2000] tot_loss=2.917 (perp=12.175, rec=0.224, cos=0.259), tot_loss_proj:3.837 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing coaster spaced access dex accessible [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.924 (perp=12.213, rec=0.239, cos=0.242), tot_loss_proj:3.929 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing coaster spaced inmates dex accessible [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.885 (perp=12.020, rec=0.226, cos=0.255), tot_loss_proj:3.892 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing spaced coaster inmates dex accessible [SEP]']
[ 750/2000] tot_loss=2.900 (perp=12.020, rec=0.231, cos=0.265), tot_loss_proj:3.896 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing spaced coaster inmates dex accessible [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.856 (perp=12.020, rec=0.209, cos=0.242), tot_loss_proj:3.893 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing spaced coaster inmates dex accessible [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.865 (perp=12.020, rec=0.209, cos=0.252), tot_loss_proj:3.895 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing spaced coaster inmates dex accessible [SEP]']
[ 900/2000] tot_loss=2.909 (perp=12.240, rec=0.217, cos=0.244), tot_loss_proj:3.884 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne coaster inmates dex accessible [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.908 (perp=12.240, rec=0.209, cos=0.252), tot_loss_proj:3.886 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne coaster inmates dex accessible [SEP]']
Attempt swap
[1000/2000] tot_loss=2.882 (perp=12.120, rec=0.208, cos=0.250), tot_loss_proj:3.813 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne coaster methods dex accessible [SEP]']
[1050/2000] tot_loss=2.869 (perp=12.120, rec=0.196, cos=0.249), tot_loss_proj:3.813 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne coaster methods dex accessible [SEP]']
Attempt swap
[1100/2000] tot_loss=2.886 (perp=12.120, rec=0.211, cos=0.251), tot_loss_proj:3.816 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne coaster methods dex accessible [SEP]']
Attempt swap
[1150/2000] tot_loss=2.975 (perp=12.482, rec=0.212, cos=0.266), tot_loss_proj:3.939 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods dex accessible [SEP]']
[1200/2000] tot_loss=2.872 (perp=12.108, rec=0.199, cos=0.251), tot_loss_proj:3.794 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods afford accessible [SEP]']
Attempt swap
[1250/2000] tot_loss=2.877 (perp=12.108, rec=0.205, cos=0.250), tot_loss_proj:3.793 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods afford accessible [SEP]']
Attempt swap
[1300/2000] tot_loss=2.877 (perp=12.108, rec=0.201, cos=0.254), tot_loss_proj:3.793 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods afford accessible [SEP]']
[1350/2000] tot_loss=2.895 (perp=12.108, rec=0.212, cos=0.262), tot_loss_proj:3.789 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods afford accessible [SEP]']
Attempt swap
[1400/2000] tot_loss=2.858 (perp=11.946, rec=0.209, cos=0.260), tot_loss_proj:4.309 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]']
Attempt swap
[1450/2000] tot_loss=2.852 (perp=11.946, rec=0.207, cos=0.256), tot_loss_proj:4.310 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]']
[1500/2000] tot_loss=2.846 (perp=11.946, rec=0.197, cos=0.260), tot_loss_proj:4.308 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]']
Attempt swap
[1550/2000] tot_loss=2.845 (perp=11.946, rec=0.204, cos=0.252), tot_loss_proj:4.310 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]']
Attempt swap
[1600/2000] tot_loss=2.849 (perp=11.946, rec=0.200, cos=0.260), tot_loss_proj:4.305 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]']
[1650/2000] tot_loss=2.848 (perp=11.946, rec=0.203, cos=0.256), tot_loss_proj:4.311 [t=0.31s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]']
Attempt swap
[1700/2000] tot_loss=2.843 (perp=11.946, rec=0.197, cos=0.256), tot_loss_proj:4.307 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]']
Attempt swap
[1750/2000] tot_loss=2.850 (perp=11.946, rec=0.206, cos=0.256), tot_loss_proj:4.308 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]']
[1800/2000] tot_loss=2.851 (perp=11.946, rec=0.205, cos=0.256), tot_loss_proj:4.311 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]']
Attempt swap
[1850/2000] tot_loss=2.849 (perp=11.946, rec=0.200, cos=0.260), tot_loss_proj:4.307 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]']
Attempt swap
[1900/2000] tot_loss=2.849 (perp=11.946, rec=0.204, cos=0.256), tot_loss_proj:4.307 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]']
[1950/2000] tot_loss=2.923 (perp=12.318, rec=0.202, cos=0.257), tot_loss_proj:4.448 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate specializing unsuccessfully gesture methods remotely accessible [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.872 (perp=12.022, rec=0.208, cos=0.260), tot_loss_proj:4.283 [t=0.30s]
prediction: ['[CLS]onate pull stories easily resonate throne specializing gesture methods remotely accessible [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS]onate pull stories easily resonate specializing throne gesture methods remotely accessible [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.333 | p: 53.846 | r: 63.636
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 41.667 | p: 38.462 | r: 45.455
rougeLsum  | fm: 41.667 | p: 38.462 | r: 45.455
r1fm+r2fm = 58.333

[Aggregate metrics]:
rouge1     | fm: 89.354 | p: 88.572 | r: 90.481
rouge2     | fm: 59.284 | p: 58.925 | r: 59.770
rougeL     | fm: 79.945 | p: 79.294 | r: 80.864
rougeLsum  | fm: 79.860 | p: 79.177 | r: 80.744
r1fm+r2fm = 148.638

input #32 time: 0:12:04 | total time: 6:40:15


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9988376422310159
highest_index [0]
highest [0.9988376422310159]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9817966818809509 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.8627445101737976 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.8586774468421936 for ['[CLS] bar [SEP]']
[Init] best rec loss: 0.843533456325531 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8102300763130188 for ['[CLS] training [SEP]']
[Init] best rec loss: 0.7778821587562561 for ['[CLS] strip [SEP]']
[Init] best rec loss: 0.7623671293258667 for ['[CLS] frame [SEP]']
[Init] best rec loss: 0.7262676358222961 for ['[CLS] railroad [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.707 (perp=11.231, rec=0.336, cos=0.124), tot_loss_proj:2.418 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.535 (perp=11.231, rec=0.207, cos=0.082), tot_loss_proj:2.400 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.503 (perp=11.231, rec=0.178, cos=0.079), tot_loss_proj:2.379 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.509 (perp=11.231, rec=0.188, cos=0.074), tot_loss_proj:2.400 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.519 (perp=11.231, rec=0.181, cos=0.091), tot_loss_proj:2.407 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.513 (perp=11.231, rec=0.169, cos=0.098), tot_loss_proj:2.394 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.523 (perp=11.231, rec=0.201, cos=0.076), tot_loss_proj:2.387 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.491 (perp=11.231, rec=0.156, cos=0.089), tot_loss_proj:2.384 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.516 (perp=11.231, rec=0.174, cos=0.096), tot_loss_proj:2.388 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.500 (perp=11.231, rec=0.165, cos=0.088), tot_loss_proj:2.391 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.506 (perp=11.231, rec=0.155, cos=0.105), tot_loss_proj:2.393 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.506 (perp=11.231, rec=0.171, cos=0.089), tot_loss_proj:2.387 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.501 (perp=11.231, rec=0.160, cos=0.094), tot_loss_proj:2.388 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.516 (perp=11.231, rec=0.194, cos=0.075), tot_loss_proj:2.394 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.484 (perp=11.231, rec=0.157, cos=0.081), tot_loss_proj:2.393 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.494 (perp=11.231, rec=0.165, cos=0.082), tot_loss_proj:2.388 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.494 (perp=11.231, rec=0.165, cos=0.082), tot_loss_proj:2.370 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.489 (perp=11.231, rec=0.160, cos=0.082), tot_loss_proj:2.390 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.498 (perp=11.231, rec=0.170, cos=0.082), tot_loss_proj:2.372 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.495 (perp=11.231, rec=0.166, cos=0.083), tot_loss_proj:2.391 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.501 (perp=11.231, rec=0.172, cos=0.083), tot_loss_proj:2.393 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.493 (perp=11.231, rec=0.166, cos=0.082), tot_loss_proj:2.380 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.492 (perp=11.231, rec=0.162, cos=0.083), tot_loss_proj:2.380 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.493 (perp=11.231, rec=0.166, cos=0.081), tot_loss_proj:2.379 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.489 (perp=11.231, rec=0.160, cos=0.083), tot_loss_proj:2.389 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.516 (perp=11.231, rec=0.186, cos=0.084), tot_loss_proj:2.375 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.485 (perp=11.231, rec=0.155, cos=0.084), tot_loss_proj:2.383 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.496 (perp=11.231, rec=0.166, cos=0.084), tot_loss_proj:2.371 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.484 (perp=11.231, rec=0.155, cos=0.083), tot_loss_proj:2.375 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.481 (perp=11.231, rec=0.151, cos=0.084), tot_loss_proj:2.392 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.499 (perp=11.231, rec=0.170, cos=0.083), tot_loss_proj:2.384 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.485 (perp=11.231, rec=0.155, cos=0.084), tot_loss_proj:2.372 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.496 (perp=11.231, rec=0.166, cos=0.083), tot_loss_proj:2.383 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.497 (perp=11.231, rec=0.167, cos=0.084), tot_loss_proj:2.374 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.500 (perp=11.231, rec=0.171, cos=0.084), tot_loss_proj:2.379 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.491 (perp=11.231, rec=0.161, cos=0.084), tot_loss_proj:2.384 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.493 (perp=11.231, rec=0.163, cos=0.084), tot_loss_proj:2.389 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.506 (perp=11.231, rec=0.176, cos=0.084), tot_loss_proj:2.374 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.507 (perp=11.231, rec=0.177, cos=0.084), tot_loss_proj:2.391 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.494 (perp=11.231, rec=0.164, cos=0.084), tot_loss_proj:2.378 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.683 | p: 88.855 | r: 90.704
rouge2     | fm: 60.759 | p: 60.406 | r: 61.096
rougeL     | fm: 80.640 | p: 79.998 | r: 81.515
rougeLsum  | fm: 80.449 | p: 79.709 | r: 81.330
r1fm+r2fm = 150.442

input #33 time: 0:11:02 | total time: 6:51:18


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.998785086454411
highest_index [0]
highest [0.998785086454411]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8342429399490356 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8167941570281982 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8158817291259766 for ['[CLS]gut tam popular xml practice got maia accompanied gaulle dateize mc full [SEP]']
[Init] best rec loss: 0.755894660949707 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.7555565237998962 for ['[CLS] paper right ‖ allies considerations inophone nassau served molecular queen hart liv [SEP]']
[Init] best rec loss: 0.7515802383422852 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 0.7403728365898132 for ['[CLS]truct way terminus week photos specifically dowager anime inducted valentin scotch watches watched [SEP]']
[Init] best rec loss: 0.7108091711997986 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.7077553272247314 for ['[CLS]ask founder ship drivers worth who slight lissa statue okayibe field along [SEP]']
[Init] best perm rec loss: 0.7037481665611267 for ['[CLS] worth founderask ship along statue who okay slight fieldibe lissa drivers [SEP]']
[Init] best perm rec loss: 0.7035030126571655 for ['[CLS] worth slightibe along who shipask drivers statue field okay founder lissa [SEP]']
[Init] best perm rec loss: 0.7028405666351318 for ['[CLS] lissaibe ship founder along drivers slight statueask okay worth field who [SEP]']
[Init] best perm rec loss: 0.7025711536407471 for ['[CLS] along lissa field ship who slightask worth drivers okay statueibe founder [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.493 (perp=10.395, rec=0.256, cos=0.158), tot_loss_proj:3.775 [t=0.30s]
prediction: ['[CLS] extreme urgency urgency urgency mind inflicted take of extreme extreme jake is the [SEP]']
[ 100/2000] tot_loss=2.180 (perp=9.706, rec=0.172, cos=0.066), tot_loss_proj:2.887 [t=0.31s]
prediction: ['[CLS] extreme urgency urgency urgency mind viewer take in extreme extreme jake on. [SEP]']
[ 150/2000] tot_loss=2.249 (perp=9.682, rec=0.173, cos=0.139), tot_loss_proj:3.029 [t=0.30s]
prediction: ['[CLS] extreme urgency urgency urgency mind viewer take on extreme extreme weekday on. [SEP]']
[ 200/2000] tot_loss=2.097 (perp=9.624, rec=0.138, cos=0.035), tot_loss_proj:2.881 [t=0.30s]
prediction: ['[CLS] extreme urgency urgency build mind viewer take on extreme extreme televised on. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.917 (perp=8.684, rec=0.127, cos=0.054), tot_loss_proj:2.607 [t=0.30s]
prediction: ['[CLS] extreme urgency urgency build of viewer take on extreme extreme televised mind. [SEP]']
[ 300/2000] tot_loss=1.906 (perp=8.684, rec=0.111, cos=0.058), tot_loss_proj:2.590 [t=0.30s]
prediction: ['[CLS] extreme urgency urgency build of viewer take on extreme extreme televised mind. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.890 (perp=8.577, rec=0.112, cos=0.062), tot_loss_proj:2.357 [t=0.31s]
prediction: ['[CLS] extreme urgency of urgency build viewer take on extreme extreme sunrise mind. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.810 (perp=8.178, rec=0.109, cos=0.065), tot_loss_proj:2.306 [t=0.30s]
prediction: ['[CLS] extreme urgency of extreme urgency build viewer take on extreme sunrise mind. [SEP]']
[ 450/2000] tot_loss=1.845 (perp=8.317, rec=0.095, cos=0.086), tot_loss_proj:2.285 [t=0.30s]
prediction: ['[CLS] in urgency of extreme urgency build viewer take on extreme sunrise mind. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.764 (perp=7.865, rec=0.107, cos=0.084), tot_loss_proj:2.501 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme sunrise urgency. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.715 (perp=7.621, rec=0.096, cos=0.095), tot_loss_proj:2.559 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build cdp take on extreme viewer urgency. [SEP]']
[ 600/2000] tot_loss=1.713 (perp=7.690, rec=0.090, cos=0.085), tot_loss_proj:2.657 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build startled take on extreme viewer urgency. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.728 (perp=7.731, rec=0.103, cos=0.078), tot_loss_proj:2.797 [t=0.31s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme cdp urgency. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.684 (perp=7.489, rec=0.113, cos=0.074), tot_loss_proj:2.242 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. thereby [SEP]']
[ 750/2000] tot_loss=1.721 (perp=7.630, rec=0.094, cos=0.101), tot_loss_proj:2.404 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.713 (perp=7.630, rec=0.095, cos=0.092), tot_loss_proj:2.404 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.714 (perp=7.630, rec=0.090, cos=0.098), tot_loss_proj:2.403 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
[ 900/2000] tot_loss=1.723 (perp=7.630, rec=0.097, cos=0.100), tot_loss_proj:2.411 [t=0.31s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.719 (perp=7.630, rec=0.099, cos=0.094), tot_loss_proj:2.399 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1000/2000] tot_loss=1.712 (perp=7.630, rec=0.088, cos=0.099), tot_loss_proj:2.403 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
[1050/2000] tot_loss=1.727 (perp=7.630, rec=0.103, cos=0.097), tot_loss_proj:2.404 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1100/2000] tot_loss=1.720 (perp=7.630, rec=0.092, cos=0.103), tot_loss_proj:2.403 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1150/2000] tot_loss=1.720 (perp=7.630, rec=0.092, cos=0.102), tot_loss_proj:2.399 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
[1200/2000] tot_loss=1.716 (perp=7.630, rec=0.085, cos=0.105), tot_loss_proj:2.394 [t=0.31s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1250/2000] tot_loss=1.722 (perp=7.630, rec=0.097, cos=0.099), tot_loss_proj:2.396 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1300/2000] tot_loss=1.723 (perp=7.630, rec=0.094, cos=0.104), tot_loss_proj:2.392 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
[1350/2000] tot_loss=1.723 (perp=7.630, rec=0.095, cos=0.102), tot_loss_proj:2.396 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1400/2000] tot_loss=1.725 (perp=7.630, rec=0.097, cos=0.102), tot_loss_proj:2.400 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1450/2000] tot_loss=1.713 (perp=7.630, rec=0.090, cos=0.098), tot_loss_proj:2.403 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
[1500/2000] tot_loss=1.719 (perp=7.630, rec=0.096, cos=0.097), tot_loss_proj:2.399 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1550/2000] tot_loss=1.720 (perp=7.630, rec=0.094, cos=0.101), tot_loss_proj:2.396 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1600/2000] tot_loss=1.727 (perp=7.630, rec=0.100, cos=0.101), tot_loss_proj:2.399 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
[1650/2000] tot_loss=1.706 (perp=7.630, rec=0.079, cos=0.101), tot_loss_proj:2.403 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1700/2000] tot_loss=1.717 (perp=7.630, rec=0.091, cos=0.101), tot_loss_proj:2.393 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1750/2000] tot_loss=1.723 (perp=7.630, rec=0.097, cos=0.099), tot_loss_proj:2.400 [t=0.30s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
[1800/2000] tot_loss=1.718 (perp=7.630, rec=0.093, cos=0.099), tot_loss_proj:2.401 [t=0.31s]
prediction: ['[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1850/2000] tot_loss=1.764 (perp=7.863, rec=0.090, cos=0.102), tot_loss_proj:2.349 [t=0.30s]
prediction: ['[CLS] in mind the extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[1900/2000] tot_loss=1.765 (perp=7.863, rec=0.090, cos=0.103), tot_loss_proj:2.337 [t=0.30s]
prediction: ['[CLS] in mind the extreme urgency build viewer take on extreme urgency. alison [SEP]']
[1950/2000] tot_loss=1.764 (perp=7.863, rec=0.090, cos=0.101), tot_loss_proj:2.346 [t=0.30s]
prediction: ['[CLS] in mind the extreme urgency build viewer take on extreme urgency. alison [SEP]']
Attempt swap
[2000/2000] tot_loss=1.762 (perp=7.863, rec=0.089, cos=0.100), tot_loss_proj:2.340 [t=0.30s]
prediction: ['[CLS] in mind the extreme urgency build viewer take on extreme urgency. alison [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] in mind of extreme urgency build viewer take on extreme urgency. alison [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 78.571 | r: 78.571
rouge2     | fm: 30.769 | p: 30.769 | r: 30.769
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 109.341

[Aggregate metrics]:
rouge1     | fm: 89.454 | p: 88.620 | r: 90.445
rouge2     | fm: 59.996 | p: 59.629 | r: 60.494
rougeL     | fm: 80.413 | p: 79.782 | r: 81.231
rougeLsum  | fm: 80.271 | p: 79.630 | r: 81.089
r1fm+r2fm = 149.450

input #34 time: 0:12:05 | total time: 7:03:23


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9987166637217899
highest_index [0]
highest [0.9987166637217899]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.903484582901001 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.8884068727493286 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best perm rec loss: 0.8882962465286255 for ['[CLS] separately ari sheriff up popularizedtrip baptist red " two strait hunt sighted art [SEP] played torn responded qatar collapsed five budget eva actually grown april talmud example lendimated side everybody seat owned among in yives swallowed closer inspired? [SEP]']
[Init] best perm rec loss: 0.8864542841911316 for ['[CLS] grown sighted in among closer april ari separately respondedimated owned inspired up red baptist everybody example seat collapsed actuallyives hunt popularized side? lend y two five played art " talmudtrip budget sheriff strait qatar torn eva swallowed [SEP] [SEP]']
[Init] best perm rec loss: 0.8852702975273132 for ['[CLS] sheriff ari eva tornimated side played? sighted up [SEP] y lend art among closer five separately ownedtrip " qatar grown example strait seat budget hunt red responded actually twoives april inspired in baptist talmud collapsed popularized everybody swallowed [SEP]']
[Init] best perm rec loss: 0.8845016360282898 for ['[CLS] april y responded among hunttripives seat [SEP] qatar talmud everybody swallowed closer lend ari popularized torn eva sighted grown owned? art red example side actually " fiveimated separately sheriff budget up inspired in played two strait baptist collapsed [SEP]']
[Init] best perm rec loss: 0.8835763335227966 for ['[CLS] owned played sheriff strait aprilimated talmud responded qatar separately collapsed everybody baptist [SEP] side closer art lend grown up popularized twoives inspired " hunt in eva budget? example red fivetrip torn y seat actually sighted ari swallowed among [SEP]']
[Init] best perm rec loss: 0.8829668164253235 for ['[CLS] up example sighted hunt qatar y lend? five inspired responded collapsedimated strait seattrip " budget played torn [SEP] baptist two swallowed april actually eva sheriff owned in art talmudives red popularized ari everybody closer side grown separately among [SEP]']
[Init] best perm rec loss: 0.881944477558136 for ['[CLS] sighted side art seat fivetrip swallowed baptist among y red budget popularized grown owned april lend played actually? in qatar " collapsed inspired closer ari eva everybodyives sheriff separately strait talmud example torn respondedimated two up hunt [SEP] [SEP]']
[Init] best perm rec loss: 0.8818005323410034 for ['[CLS] sighted played side seat ari five actually talmud strait among inspired everybody popularized art owned y? separately grown budget red baptist in two example up closer april swallowedimated eva lend sherifftrip [SEP] torn " hunt collapsedives qatar responded [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.491 (perp=13.313, rec=0.624, cos=0.205), tot_loss_proj:4.584 [t=0.31s]
prediction: ['[CLS] cassiemes length wwe get [SEP] aviation timeline adrenaline allison parenthesesnell as gun infantry [SEP] felt. moines capacity twelve survive deeper them emotional mph one [SEP] m connected. tread didn placed aviation the your ⟨ clearly.. steve [SEP]']
[ 100/2000] tot_loss=3.452 (perp=12.763, rec=0.699, cos=0.201), tot_loss_proj:4.415 [t=0.31s]
prediction: ['[CLS] allan participated length muscles your [SEP] and alexia alongside seth 2018 [SEP] the connected infantry [SEP] were him microsoft league in around thick seemed emotions serious like [SEP] been made humans spectrum students my rematch trump your unique squadron looking quebec mike [SEP]']
[ 150/2000] tot_loss=3.457 (perp=13.099, rec=0.637, cos=0.200), tot_loss_proj:4.427 [t=0.31s]
prediction: ['[CLS] allan received length muscles your [SEP] and alexia alongside seth 2018 [SEP] the connected infantry [SEP] were him seam league in around seem seemed emotions worship like [SEP] been made humans spectrum norman my rematch trump this unique rings looking quebec polling [SEP]']
[ 200/2000] tot_loss=3.323 (perp=12.777, rec=0.598, cos=0.169), tot_loss_proj:4.120 [t=0.31s]
prediction: ['[CLS] allan received length muscles your [SEP] and subspecies alongside the 2018 [SEP] the connected infantry [SEP] were praised seam league in around seem said thoughts culture like [SEP] [ made humans spectrum norman george rematch trump this unique rings looking quebec ulster [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.113 (perp=11.814, rec=0.567, cos=0.184), tot_loss_proj:3.749 [t=0.31s]
prediction: ['[CLS] strikers received length muscles your [SEP] and subspecies alongside culture 2018 [SEP] the connected infantry [SEP] were appreciate seam league, you seem said thoughts the like [SEP] [ madewn spectrum norman james rematch trump this unique rings looking quebec ulster [SEP]']
[ 300/2000] tot_loss=3.158 (perp=11.972, rec=0.559, cos=0.204), tot_loss_proj:3.973 [t=0.31s]
prediction: ['[CLS] strikers received length muscles your [SEP] and subspecies alongside culture 2018 [SEP] the great marine [SEP] were appreciate seam league, you seem them sadness seth as [SEP] [ madeened spectrum norman james rematch trump this unique rings looking quebec ulster [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.101 (perp=11.964, rec=0.525, cos=0.183), tot_loss_proj:3.800 [t=0.31s]
prediction: ['[CLS] [SEP] presented length muscles your allan and subspecies alongside culture 2018 [SEP] the nobel marine [SEP] were appreciate seam league, you deeper them deeply seth like [SEP] [ madericted [CLS] norman james rematch trump this unique rings looking quebec ulster [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.060 (perp=11.805, rec=0.505, cos=0.194), tot_loss_proj:3.867 [t=0.31s]
prediction: ['[CLS] [SEP] presented [ muscles your allan and subspecies alongside culture 2018 [SEP] the nobel marine [SEP] were appreciate seam league, you seemed she fans samantha like [SEP] length madericted [CLS] norman james rematch trump this unique rings looking thick ulster [SEP]']
[ 450/2000] tot_loss=3.084 (perp=11.882, rec=0.500, cos=0.208), tot_loss_proj:3.760 [t=0.32s]
prediction: ['[CLS] [SEP] presented [ muscles your allan and subspecies alongside culture 2018 [SEP] the nobel marine [SEP] were appreciate seam league, you reflect she bit samantha like [SEP] length made packers [CLS] norman james rematch trump this unique rings looking pat ulster [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.030 (perp=11.784, rec=0.491, cos=0.182), tot_loss_proj:3.877 [t=0.31s]
prediction: ['[CLS] [SEP] presented [ were your allan and subspecies alongside culture 2018 [SEP] the nobel marine [SEP]age appreciate seam league, you seemed she eyes samantha like [SEP] length made packers [CLS] norman james rematch trump this unique rings looking governorate ulster [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.102 (perp=12.068, rec=0.496, cos=0.193), tot_loss_proj:4.017 [t=0.31s]
prediction: ['[CLS] [SEP] presented [ were your allan and subspecies alongside culture 2018 [SEP] motion nobel marine [SEP]age appreciate seam league, you glance she leaves samantha like [SEP] length made packers the norman luke rematch trump this unique rings looking broad ulster [SEP]']
[ 600/2000] tot_loss=3.261 (perp=12.930, rec=0.477, cos=0.198), tot_loss_proj:4.298 [t=0.31s]
prediction: ['[CLS] [SEP] participated [ were lilly emotion or subspecies alongside gaze 2018 [SEP] motion nobel marine [SEP]age 1960s seam league, you glance she leaves samantha like [SEP] length made packers the norman luke rematch trump this unique rings looking broad ulster [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.165 (perp=12.586, rec=0.465, cos=0.183), tot_loss_proj:4.259 [t=0.31s]
prediction: ['[CLS] [SEP] participated [ were lilly emotion or subspecies alongside gaze 2018 [SEP] motion nobel marine [SEP]age 1960s rings league, you want she jennifer samantha like [SEP] length made packers the norman surroundings rematch trump this unique seam looking broad ulster [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.064 (perp=12.129, rec=0.466, cos=0.172), tot_loss_proj:4.254 [t=0.31s]
prediction: ['[CLS] [SEP] [ participated suspected lilly emotion or subspecies alongside gaze 2018 [SEP] motion trick marine [SEP]age 1960s rings league, you want she jenniferkshi as [SEP] length madedication the norman surroundings rematch trump this unique seam looking broad ulster [SEP]']
[ 750/2000] tot_loss=3.083 (perp=12.271, rec=0.447, cos=0.182), tot_loss_proj:4.190 [t=0.31s]
prediction: ['[CLS] [SEP] [ participated felt lilly emotion or subspecies alongside gaze 2018 [SEP] spectrum trick marine [SEP]age particularly rings league, you want she jenniferkshi as [SEP] length madedication the norman surroundings rematch trump this unique seam looking broad ulster [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.023 (perp=12.031, rec=0.437, cos=0.180), tot_loss_proj:4.153 [t=0.31s]
prediction: ['[CLS] [SEP] [ participated felt lilly or subspecies alongside emotion gaze 2018 [SEP] spectrum trick marine [SEP]age particularly rings league, you want she jenniferkshi as [SEP] length madedication the norman surroundings rematch trump this unique seam looking broad ulster [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.010 (perp=11.922, rec=0.437, cos=0.188), tot_loss_proj:3.891 [t=0.31s]
prediction: ['[CLS] [SEP] [ participated felt lilly or subspecies alongside emotion gaze 2018 [SEP] spectrum trick marine [SEP]age particularly rings league, you yeah she jenniferkshi as [SEP] length trumpdication the norman surroundings rematch made this unique seam looking broad ulster [SEP]']
[ 900/2000] tot_loss=3.012 (perp=11.943, rec=0.430, cos=0.194), tot_loss_proj:3.854 [t=0.31s]
prediction: ['[CLS] [SEP] [ participated felt lilly or subspecies alongside emotion gaze 2018 and spectrum trick marine [SEP]age particularly rings league, you yeah she jenniferkshi as [SEP] length trumpdication the norman seats rematch made this unique seam looking broad ulster [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.990 (perp=11.850, rec=0.434, cos=0.185), tot_loss_proj:3.955 [t=0.31s]
prediction: ['[CLS] [SEP] [ participated jennifer lilly or subspecies alongside emotion becoming 2018 [SEP] spectrum trick marine [SEP]age particularly rings league, you yeah she feltkshi as [SEP] length trumpdication the norman seats rematch made this unique seam looking broad ulster [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.887 (perp=11.247, rec=0.440, cos=0.198), tot_loss_proj:3.834 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated jennifer lilly or seats alongside emotion becoming 2018 and spectrumgenase marine [SEP]age particularly rings league, you yeah she feltkshi as [SEP] length trumpdication the norman subspecies rematch made this unique seam looking broad ulster [SEP]']
[1050/2000] tot_loss=2.904 (perp=11.430, rec=0.429, cos=0.189), tot_loss_proj:3.879 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated jennifer lilly or seats alongside emotion becoming 2018 and spectrumnction marine [SEP]age particularly rings league, you yeah she feltkshi as [SEP] length trumpdication the norman subspecies rematch made this unique seam looking broad ulster [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.942 (perp=11.609, rec=0.425, cos=0.195), tot_loss_proj:3.855 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated jennifer lilly or cabin alongside emotion becoming ulster and spectrumnction marine [SEP]age particularly rings league, you yeah she feltkshi as [SEP] length trumpdication the norman subspecies rematch made this unique seam looking app 2018 [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.929 (perp=11.574, rec=0.426, cos=0.188), tot_loss_proj:3.873 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated jennifer lilly or cabin alongside emotion becoming ulster and spectrumnction marine [SEP]age motors rings league, yeah you she feltkshi as [SEP] length trumpdication the norman subspecies rematch made this unique seam looking app 2018 [SEP]']
[1200/2000] tot_loss=2.980 (perp=11.859, rec=0.416, cos=0.192), tot_loss_proj:3.905 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply lilly or cabin alongside emotion becoming ulster and spectrumnction marine [SEP]age motors rings league, yeah you she feltkshi as [SEP] length trumpdication the norman subspecies rematch made this unique seam looking app 2018 [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.927 (perp=11.550, rec=0.419, cos=0.198), tot_loss_proj:3.807 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply lilly cabin or alongside emotion becoming ulster and spectrumnction marine [SEP]age motors rings league, yeah you she felt¨ as [SEP] length trumpdication the norman subspecies rematch made this unique seam looking app 2018 [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.900 (perp=11.400, rec=0.425, cos=0.196), tot_loss_proj:3.741 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the cabin or alongside emotion becoming ulster and spectrumnction marine [SEP]age motors rings league, yeah you she felt¨ as [SEP] length trumpdication lilly norman subspecies rematch made this unique seam looking app 2018 [SEP]']
[1350/2000] tot_loss=2.938 (perp=11.648, rec=0.417, cos=0.192), tot_loss_proj:4.163 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the cabin or alongside emotion becoming ulster and spectrumnction marine [SEP]age motors rings league, yeah you leto felt doubted as [SEP] length trumpdication lilly norman subspecies rematch made this unique seam looking app 2018 [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.966 (perp=11.786, rec=0.419, cos=0.191), tot_loss_proj:3.814 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the century or alongside emotion becoming ulster and cabinnction marine [SEP]age motors rings league, yeah you leto feltkshi as [SEP] length trumpdication lilly norman subspecies rematch made this unique seam looking app 2018 [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.888 (perp=11.396, rec=0.423, cos=0.186), tot_loss_proj:3.769 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the century norman alongside emotion becoming ulster and cabinnction marine [SEP]age courts rings league, yeah you leto feltnk as [SEP] length trumpdication lilly or subspecies rematch made this unique seam looking app 2018 [SEP]']
[1500/2000] tot_loss=2.869 (perp=11.333, rec=0.412, cos=0.191), tot_loss_proj:3.668 [t=0.32s]
prediction: ['[CLS] [SEP] ( participated deeply the century norman alongside emotion becoming ulster and cabinnction marine [SEP]age courts rings league, yeah you leto feltnk as [SEP] length trumpdication lilly and subspecies rematch made this unique seam looking app 2018 [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.855 (perp=11.264, rec=0.414, cos=0.188), tot_loss_proj:3.612 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the century norman alongside emotion becoming ulster and cabinnction marine [SEP]age courts rings league, yeah you letokshi felt as [SEP] length trumpdication lilly and subspecies rematch made this unique seam looking app 2018 [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.849 (perp=11.196, rec=0.413, cos=0.197), tot_loss_proj:3.590 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the norman century alongside emotion becoming ulster and cabinnction marine [SEP]age courts rings league, yeah you leto bray felt as [SEP] length trumpdication lilly and subspecies rematch made this unique seam looking app 2018 [SEP]']
[1650/2000] tot_loss=2.844 (perp=11.196, rec=0.409, cos=0.195), tot_loss_proj:3.592 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the norman century alongside emotion becoming ulster and cabinnction marine [SEP]age courts rings league, yeah you leto bray felt as [SEP] length trumpdication lilly and subspecies rematch made this unique seam looking app 2018 [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.832 (perp=11.131, rec=0.410, cos=0.196), tot_loss_proj:3.645 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the norman century alongside emotion becoming ulster and cabinnction marine [SEP]age courts rings league, yeah you leto bray felt as [SEP] length trumpdication lilly and subspecies rematch made this unique seam app looking 2018 [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.809 (perp=11.010, rec=0.414, cos=0.193), tot_loss_proj:3.642 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the norman century alongside emotion becoming ulster and cabinnction marine [SEP]age courts rings league, yeah you leto bray and as [SEP] length trumpdication lilly felt subspecies rematch made this unique seam app looking 2018 [SEP]']
[1800/2000] tot_loss=2.802 (perp=11.010, rec=0.403, cos=0.198), tot_loss_proj:3.646 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the norman century alongside emotion becoming ulster and cabinnction marine [SEP]age courts rings league, yeah you leto bray and as [SEP] length trumpdication lilly felt subspecies rematch made this unique seam app looking 2018 [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.783 (perp=10.894, rec=0.405, cos=0.199), tot_loss_proj:3.638 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the norman century alongside emotion becoming ulster and cabinnction [SEP] marineage courts rings league, yeah you letorgy and as [SEP] length trumpdication lilly felt subspecies rematch made this unique seam app looking 2018 [SEP]']
Attempt swap
[1900/2000] tot_loss=2.780 (perp=10.894, rec=0.403, cos=0.198), tot_loss_proj:3.637 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the norman century alongside emotion becoming ulster and cabinnction [SEP] marineage courts rings league, yeah you letorgy and as [SEP] length trumpdication lilly felt subspecies rematch made this unique seam app looking 2018 [SEP]']
[1950/2000] tot_loss=2.782 (perp=10.894, rec=0.406, cos=0.197), tot_loss_proj:3.637 [t=0.31s]
prediction: ['[CLS] [SEP] ( participated deeply the norman century alongside emotion becoming ulster and cabinnction [SEP] marineage courts rings league, yeah you letorgy and as [SEP] length trumpdication lilly felt subspecies rematch made this unique seam app looking 2018 [SEP]']
Attempt swap
[2000/2000] tot_loss=2.784 (perp=10.894, rec=0.408, cos=0.198), tot_loss_proj:3.633 [t=0.32s]
prediction: ['[CLS] [SEP] ( participated deeply the norman century alongside emotion becoming ulster and cabinnction [SEP] marineage courts rings league, yeah you letorgy and as [SEP] length trumpdication lilly felt subspecies rematch made this unique seam app looking 2018 [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] [SEP] ( participated deeply the norman century alongside emotion becoming ulster and cabinnction [SEP] marineage courts rings league, yeah you letorgy and as [SEP] length trumpdication lilly felt subspecies rematch made this unique seam app looking 2018 [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 10.959 | p: 10.526 | r: 11.429
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 8.219 | p: 7.895 | r: 8.571
rougeLsum  | fm: 8.219 | p: 7.895 | r: 8.571
r1fm+r2fm = 10.959

[Aggregate metrics]:
rouge1     | fm: 87.353 | p: 86.548 | r: 88.392
rouge2     | fm: 58.140 | p: 57.790 | r: 58.608
rougeL     | fm: 78.472 | p: 77.842 | r: 79.283
rougeLsum  | fm: 78.160 | p: 77.565 | r: 78.942
r1fm+r2fm = 145.493

input #35 time: 0:12:26 | total time: 7:15:49


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.9986928012611552
highest_index [0]
highest [0.9986928012611552]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9532232284545898 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9489215016365051 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9071267247200012 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.8927203416824341 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 0.8886927366256714 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.8369923830032349 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best rec loss: 0.835612416267395 for ['[CLS] dormant known to mckenzie [SEP]']
[Init] best perm rec loss: 0.835577130317688 for ['[CLS] dormant mckenzie to known [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.158 (perp=10.031, rec=0.142, cos=0.009), tot_loss_proj:2.419 [t=0.30s]
prediction: ['[CLS] wrong s horribly wrong [SEP]']
[ 100/2000] tot_loss=2.122 (perp=10.031, rec=0.106, cos=0.010), tot_loss_proj:2.427 [t=0.30s]
prediction: ['[CLS] wrong s horribly wrong [SEP]']
[ 150/2000] tot_loss=2.101 (perp=10.031, rec=0.088, cos=0.007), tot_loss_proj:2.430 [t=0.30s]
prediction: ['[CLS] wrong s horribly wrong [SEP]']
[ 200/2000] tot_loss=2.083 (perp=10.031, rec=0.073, cos=0.004), tot_loss_proj:2.427 [t=0.30s]
prediction: ['[CLS] wrong s horribly wrong [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.870 (perp=8.830, rec=0.096, cos=0.008), tot_loss_proj:2.177 [t=0.30s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 300/2000] tot_loss=1.845 (perp=8.830, rec=0.076, cos=0.003), tot_loss_proj:2.183 [t=0.30s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.720 (perp=8.104, rec=0.095, cos=0.004), tot_loss_proj:2.004 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 400/2000] tot_loss=1.698 (perp=8.104, rec=0.073, cos=0.005), tot_loss_proj:2.006 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 450/2000] tot_loss=1.698 (perp=8.104, rec=0.072, cos=0.005), tot_loss_proj:2.019 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.693 (perp=8.104, rec=0.068, cos=0.005), tot_loss_proj:2.019 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.698 (perp=8.104, rec=0.072, cos=0.005), tot_loss_proj:2.012 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 600/2000] tot_loss=1.697 (perp=8.104, rec=0.071, cos=0.005), tot_loss_proj:2.013 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.707 (perp=8.104, rec=0.081, cos=0.005), tot_loss_proj:2.015 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.700 (perp=8.104, rec=0.074, cos=0.005), tot_loss_proj:2.015 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 750/2000] tot_loss=1.698 (perp=8.104, rec=0.072, cos=0.005), tot_loss_proj:2.025 [t=0.31s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.688 (perp=8.104, rec=0.063, cos=0.005), tot_loss_proj:2.011 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.697 (perp=8.104, rec=0.071, cos=0.005), tot_loss_proj:2.012 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 900/2000] tot_loss=1.695 (perp=8.104, rec=0.069, cos=0.005), tot_loss_proj:2.021 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.697 (perp=8.104, rec=0.072, cos=0.005), tot_loss_proj:2.017 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.697 (perp=8.104, rec=0.071, cos=0.005), tot_loss_proj:2.012 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1050/2000] tot_loss=1.687 (perp=8.104, rec=0.061, cos=0.005), tot_loss_proj:2.011 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.691 (perp=8.104, rec=0.065, cos=0.005), tot_loss_proj:2.017 [t=0.31s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.690 (perp=8.104, rec=0.064, cos=0.005), tot_loss_proj:2.022 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1200/2000] tot_loss=1.694 (perp=8.104, rec=0.068, cos=0.005), tot_loss_proj:2.017 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.691 (perp=8.104, rec=0.065, cos=0.005), tot_loss_proj:2.019 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.700 (perp=8.104, rec=0.074, cos=0.005), tot_loss_proj:2.013 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1350/2000] tot_loss=1.695 (perp=8.104, rec=0.070, cos=0.005), tot_loss_proj:2.021 [t=0.31s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.689 (perp=8.104, rec=0.063, cos=0.005), tot_loss_proj:2.013 [t=0.31s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.698 (perp=8.104, rec=0.072, cos=0.005), tot_loss_proj:2.017 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1500/2000] tot_loss=1.702 (perp=8.104, rec=0.076, cos=0.005), tot_loss_proj:2.015 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.692 (perp=8.104, rec=0.066, cos=0.005), tot_loss_proj:2.025 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.706 (perp=8.104, rec=0.080, cos=0.005), tot_loss_proj:2.019 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1650/2000] tot_loss=1.693 (perp=8.104, rec=0.067, cos=0.005), tot_loss_proj:2.016 [t=0.31s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.696 (perp=8.104, rec=0.070, cos=0.005), tot_loss_proj:2.019 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.696 (perp=8.104, rec=0.070, cos=0.005), tot_loss_proj:2.024 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1800/2000] tot_loss=1.688 (perp=8.104, rec=0.062, cos=0.005), tot_loss_proj:2.024 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.702 (perp=8.104, rec=0.076, cos=0.005), tot_loss_proj:2.018 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.686 (perp=8.104, rec=0.060, cos=0.005), tot_loss_proj:2.024 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1950/2000] tot_loss=1.707 (perp=8.104, rec=0.081, cos=0.005), tot_loss_proj:2.019 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.695 (perp=8.104, rec=0.069, cos=0.005), tot_loss_proj:2.019 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s wrong horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 83.333 | r: 100.000
rouge2     | fm: 66.667 | p: 60.000 | r: 75.000
rougeL     | fm: 90.909 | p: 83.333 | r: 100.000
rougeLsum  | fm: 90.909 | p: 83.333 | r: 100.000
r1fm+r2fm = 157.576

[Aggregate metrics]:
rouge1     | fm: 87.586 | p: 86.551 | r: 88.789
rouge2     | fm: 58.153 | p: 57.801 | r: 58.768
rougeL     | fm: 78.721 | p: 77.916 | r: 79.765
rougeLsum  | fm: 78.426 | p: 77.628 | r: 79.399
r1fm+r2fm = 145.739

input #36 time: 0:12:03 | total time: 7:27:53


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9989864625349196
highest_index [0]
highest [0.9989864625349196]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.7644209265708923 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.7538638114929199 for ['[CLS] value commune [SEP]']
[Init] best rec loss: 0.6883479356765747 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 0.6681808829307556 for ['[CLS] out example [SEP]']
[Init] best rec loss: 0.6451050639152527 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.6244730949401855 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.6225281357765198 for ['[CLS] family forster [SEP]']
[Init] best rec loss: 0.6209133863449097 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.6097914576530457 for ['[CLS] beer city [SEP]']
[Init] best rec loss: 0.6074979901313782 for ['[CLS] colorcards [SEP]']
[Init] best rec loss: 0.6046115756034851 for ['[CLS] breeze comfortable [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.381 (perp=10.822, rec=0.166, cos=0.050), tot_loss_proj:2.497 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 100/2000] tot_loss=2.343 (perp=10.822, rec=0.128, cos=0.051), tot_loss_proj:2.500 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 150/2000] tot_loss=2.319 (perp=10.822, rec=0.107, cos=0.048), tot_loss_proj:2.503 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 200/2000] tot_loss=2.328 (perp=10.822, rec=0.113, cos=0.051), tot_loss_proj:2.490 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.299 (perp=10.822, rec=0.101, cos=0.034), tot_loss_proj:2.493 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 300/2000] tot_loss=1.965 (perp=9.583, rec=0.047, cos=0.002), tot_loss_proj:1.994 [t=0.30s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.866 (perp=8.916, rec=0.080, cos=0.003), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.852 (perp=8.916, rec=0.067, cos=0.002), tot_loss_proj:2.057 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[ 450/2000] tot_loss=1.841 (perp=8.916, rec=0.056, cos=0.002), tot_loss_proj:2.040 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.852 (perp=8.916, rec=0.067, cos=0.002), tot_loss_proj:2.046 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.858 (perp=8.916, rec=0.073, cos=0.002), tot_loss_proj:2.043 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[ 600/2000] tot_loss=1.845 (perp=8.916, rec=0.060, cos=0.002), tot_loss_proj:2.050 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.847 (perp=8.916, rec=0.062, cos=0.002), tot_loss_proj:2.058 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.849 (perp=8.916, rec=0.064, cos=0.002), tot_loss_proj:2.051 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[ 750/2000] tot_loss=1.852 (perp=8.916, rec=0.067, cos=0.002), tot_loss_proj:2.047 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.846 (perp=8.916, rec=0.060, cos=0.002), tot_loss_proj:2.063 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.842 (perp=8.916, rec=0.057, cos=0.002), tot_loss_proj:2.055 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[ 900/2000] tot_loss=1.850 (perp=8.916, rec=0.065, cos=0.002), tot_loss_proj:2.054 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.860 (perp=8.916, rec=0.074, cos=0.002), tot_loss_proj:2.050 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=1.838 (perp=8.916, rec=0.053, cos=0.002), tot_loss_proj:2.055 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[1050/2000] tot_loss=1.848 (perp=8.916, rec=0.063, cos=0.002), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=1.857 (perp=8.916, rec=0.072, cos=0.002), tot_loss_proj:2.040 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=1.837 (perp=8.916, rec=0.052, cos=0.002), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[1200/2000] tot_loss=1.864 (perp=8.916, rec=0.079, cos=0.002), tot_loss_proj:2.047 [t=0.31s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=1.863 (perp=8.916, rec=0.077, cos=0.002), tot_loss_proj:2.054 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=1.851 (perp=8.916, rec=0.066, cos=0.002), tot_loss_proj:2.044 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[1350/2000] tot_loss=1.842 (perp=8.916, rec=0.056, cos=0.002), tot_loss_proj:2.037 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=1.839 (perp=8.916, rec=0.054, cos=0.002), tot_loss_proj:2.034 [t=0.31s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=1.840 (perp=8.916, rec=0.055, cos=0.002), tot_loss_proj:2.060 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[1500/2000] tot_loss=1.843 (perp=8.916, rec=0.058, cos=0.002), tot_loss_proj:2.051 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=1.859 (perp=8.916, rec=0.074, cos=0.002), tot_loss_proj:2.048 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=1.857 (perp=8.916, rec=0.071, cos=0.002), tot_loss_proj:2.049 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[1650/2000] tot_loss=1.855 (perp=8.916, rec=0.069, cos=0.002), tot_loss_proj:2.049 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=1.847 (perp=8.916, rec=0.062, cos=0.002), tot_loss_proj:2.046 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=1.860 (perp=8.916, rec=0.075, cos=0.002), tot_loss_proj:2.049 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[1800/2000] tot_loss=1.844 (perp=8.916, rec=0.059, cos=0.002), tot_loss_proj:2.039 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=1.846 (perp=8.916, rec=0.061, cos=0.002), tot_loss_proj:2.047 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=1.835 (perp=8.916, rec=0.050, cos=0.002), tot_loss_proj:2.046 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[1950/2000] tot_loss=1.850 (perp=8.916, rec=0.065, cos=0.002), tot_loss_proj:2.045 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=1.853 (perp=8.916, rec=0.068, cos=0.002), tot_loss_proj:2.057 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] and eccentric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.801 | p: 86.738 | r: 89.034
rouge2     | fm: 56.922 | p: 56.448 | r: 57.482
rougeL     | fm: 78.690 | p: 77.838 | r: 79.665
rougeLsum  | fm: 78.585 | p: 77.763 | r: 79.450
r1fm+r2fm = 144.723

input #37 time: 0:12:02 | total time: 7:39:55


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9986487250284594
highest_index [0]
highest [0.9986487250284594]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.821014404296875 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.7774980068206787 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7461855411529541 for ['[CLS] 1960s [SEP]']
[Init] best rec loss: 0.7204669117927551 for ['[CLS] blame [SEP]']
[Init] best rec loss: 0.719445526599884 for ['[CLS] end [SEP]']
[Init] best rec loss: 0.6641393303871155 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.922 (perp=14.070, rec=0.095, cos=0.013), tot_loss_proj:2.885 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.889 (perp=14.070, rec=0.072, cos=0.003), tot_loss_proj:2.880 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.876 (perp=14.070, rec=0.058, cos=0.003), tot_loss_proj:2.867 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.879 (perp=14.070, rec=0.062, cos=0.003), tot_loss_proj:2.885 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.873 (perp=14.070, rec=0.056, cos=0.003), tot_loss_proj:2.881 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.870 (perp=14.070, rec=0.053, cos=0.003), tot_loss_proj:2.883 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.887 (perp=14.070, rec=0.071, cos=0.003), tot_loss_proj:2.878 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.866 (perp=14.070, rec=0.050, cos=0.003), tot_loss_proj:2.883 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.887 (perp=14.070, rec=0.070, cos=0.003), tot_loss_proj:2.877 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.878 (perp=14.070, rec=0.061, cos=0.003), tot_loss_proj:2.872 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.885 (perp=14.070, rec=0.068, cos=0.003), tot_loss_proj:2.866 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.871 (perp=14.070, rec=0.054, cos=0.003), tot_loss_proj:2.878 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.871 (perp=14.070, rec=0.055, cos=0.003), tot_loss_proj:2.876 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.877 (perp=14.070, rec=0.060, cos=0.003), tot_loss_proj:2.871 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.883 (perp=14.070, rec=0.066, cos=0.003), tot_loss_proj:2.879 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.874 (perp=14.070, rec=0.057, cos=0.003), tot_loss_proj:2.871 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.879 (perp=14.070, rec=0.062, cos=0.003), tot_loss_proj:2.874 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.878 (perp=14.070, rec=0.062, cos=0.003), tot_loss_proj:2.864 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.887 (perp=14.070, rec=0.070, cos=0.003), tot_loss_proj:2.873 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.881 (perp=14.070, rec=0.064, cos=0.003), tot_loss_proj:2.883 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.887 (perp=14.070, rec=0.070, cos=0.003), tot_loss_proj:2.877 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.870 (perp=14.070, rec=0.054, cos=0.003), tot_loss_proj:2.875 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.872 (perp=14.070, rec=0.055, cos=0.003), tot_loss_proj:2.872 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.879 (perp=14.070, rec=0.063, cos=0.003), tot_loss_proj:2.869 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.873 (perp=14.070, rec=0.056, cos=0.003), tot_loss_proj:2.872 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.880 (perp=14.070, rec=0.063, cos=0.003), tot_loss_proj:2.874 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.872 (perp=14.070, rec=0.056, cos=0.003), tot_loss_proj:2.878 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.874 (perp=14.070, rec=0.058, cos=0.003), tot_loss_proj:2.885 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.877 (perp=14.070, rec=0.060, cos=0.003), tot_loss_proj:2.874 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.878 (perp=14.070, rec=0.061, cos=0.003), tot_loss_proj:2.870 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.871 (perp=14.070, rec=0.054, cos=0.003), tot_loss_proj:2.870 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.878 (perp=14.070, rec=0.061, cos=0.003), tot_loss_proj:2.868 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.866 (perp=14.070, rec=0.050, cos=0.003), tot_loss_proj:2.870 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.886 (perp=14.070, rec=0.069, cos=0.003), tot_loss_proj:2.886 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.873 (perp=14.070, rec=0.056, cos=0.003), tot_loss_proj:2.874 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.874 (perp=14.070, rec=0.057, cos=0.003), tot_loss_proj:2.866 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.887 (perp=14.070, rec=0.071, cos=0.003), tot_loss_proj:2.887 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.873 (perp=14.070, rec=0.057, cos=0.003), tot_loss_proj:2.860 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.869 (perp=14.070, rec=0.052, cos=0.003), tot_loss_proj:2.871 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.877 (perp=14.070, rec=0.060, cos=0.003), tot_loss_proj:2.880 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.083 | p: 87.054 | r: 89.256
rouge2     | fm: 57.913 | p: 57.487 | r: 58.585
rougeL     | fm: 79.310 | p: 78.526 | r: 80.316
rougeLsum  | fm: 79.029 | p: 78.251 | r: 79.960
r1fm+r2fm = 145.996

input #38 time: 0:11:02 | total time: 7:50:58


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9989185205528948
highest_index [0]
highest [0.9989185205528948]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 0.8017034530639648 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 0.7885900735855103 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.7854804992675781 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.7759674191474915 for ['[CLS] visitors polo free mn railway entitled about murderkar father states eventually some pet victory saddle fraternitypgtz raised real actresses from accelerator link [SEP]']
[Init] best rec loss: 0.7551543116569519 for ['[CLS] nothing fishery published hall temeraireathing earnest cabinet shame supreme illusions drown men quoteolved formation revenge negativeˈ relief legislature growl melissa silk - [SEP]']
[Init] best rec loss: 0.7391940951347351 for ['[CLS] limited symptoms impressiontor jammu runoff formationian facts wyomingful winner ankles when politics turbo our reflex happenedzzo opium look charging relation laugh [SEP]']
[Init] best perm rec loss: 0.7359463572502136 for ['[CLS] winner reflex whenian wyoming formation turbotor charging symptoms jammu opium politics laughful relation facts runoff our happened impressionzzo ankles limited look [SEP]']
[Init] best perm rec loss: 0.7350991368293762 for ['[CLS] impression opium jammu turbo when facts ankles look happened our politics limited formation wyoming chargingiantor winner relation runoffful reflexzzo laugh symptoms [SEP]']
[Init] best perm rec loss: 0.7342371344566345 for ['[CLS] reflextorzzo limited formation jammu facts impression politics when charging turbo runoff laugh symptoms wyomingful ourian look opium happened winner relation ankles [SEP]']
[Init] best perm rec loss: 0.7330246567726135 for ['[CLS] limited turbo impression look runofftor relationzzo jammu chargingian winner opiumful politics happened formation when facts reflex symptoms laugh wyoming our ankles [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.677 (perp=11.873, rec=0.289, cos=0.014), tot_loss_proj:4.125 [t=0.31s]
prediction: ['[CLS] conservativeless articleor rig and brought new flight conservative storage following hide new nativeanyword guidelines new texture and gained revealed an corresponding [SEP]']
[ 100/2000] tot_loss=2.512 (perp=11.444, rec=0.214, cos=0.009), tot_loss_proj:3.859 [t=0.31s]
prediction: ['[CLS] conservative andcity - tex and gives them movie conservative texture following hide new traditions newbound conservative new texture reality new conservative an physics [SEP]']
[ 150/2000] tot_loss=2.403 (perp=10.970, rec=0.199, cos=0.010), tot_loss_proj:3.785 [t=0.32s]
prediction: ['[CLS] conservative and finds - hide and gives them movie conservative texture hide hide new traditions newbound traditions new texture reality, conservative very of [SEP]']
[ 200/2000] tot_loss=2.294 (perp=10.615, rec=0.162, cos=0.009), tot_loss_proj:3.565 [t=0.31s]
prediction: ['[CLS] conservative and finds - hide and gives most movie conservative texture hide hide new traditions new hide texture new texture reality, new most of [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.365 (perp=10.885, rec=0.178, cos=0.010), tot_loss_proj:3.389 [t=0.31s]
prediction: ['[CLS] conservative and find - traditions and gives most movie conservative texture hide hide newbound new hide texture new texture movie, finds very of [SEP]']
[ 300/2000] tot_loss=2.282 (perp=10.619, rec=0.147, cos=0.011), tot_loss_proj:3.337 [t=0.31s]
prediction: ['[CLS] conservative and our - traditions and gives it movie conservative texture hide hide newying newbound texture new texture reality, finds most. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.061 (perp=9.557, rec=0.137, cos=0.012), tot_loss_proj:3.679 [t=0.31s]
prediction: ['[CLS] conservative and our - traditions and hide most movie conservative texture givesbound newbound newbound reality new texture reality, finds most. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.123 (perp=9.829, rec=0.148, cos=0.010), tot_loss_proj:3.744 [t=0.31s]
prediction: ['[CLS] conservative and conservative - traditions and hide most movie our texture givesbound newbound seasonbound reality new texture reality, finds most reality [SEP]']
[ 450/2000] tot_loss=2.170 (perp=10.221, rec=0.118, cos=0.007), tot_loss_proj:3.779 [t=0.31s]
prediction: ['[CLS] conservative and conservative - traditions and hide most movie our texture givesbound itbound seasonbound reality new texture reality, finds most reality [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.034 (perp=9.558, rec=0.113, cos=0.009), tot_loss_proj:3.550 [t=0.31s]
prediction: ['[CLS] conservative and conservative - traditions and hide most movie our texture realitybound itbound seasonbound gives new texture reality, finds most reality [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.015 (perp=9.512, rec=0.107, cos=0.005), tot_loss_proj:3.426 [t=0.31s]
prediction: ['[CLS] conservative and conservative - traditions and hide most movie our most realitybound itbound seasonbound gives new texture reality, finds texture our [SEP]']
[ 600/2000] tot_loss=2.071 (perp=9.706, rec=0.119, cos=0.011), tot_loss_proj:3.394 [t=0.31s]
prediction: ['[CLS] conservative and conservativebound traditions and hide most movie our most realitybound itbound seasonbound gives new texture reality, finds texture our [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.029 (perp=9.562, rec=0.113, cos=0.004), tot_loss_proj:3.515 [t=0.31s]
prediction: ['[CLS] conservative and conservativebound traditions and hide most movie our the realitybound itbound seasonbound gives new texture reality, texture finds our [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.961 (perp=9.183, rec=0.118, cos=0.007), tot_loss_proj:3.446 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions and hide most movie our the realitybound itbound seasonbound gives new texture realitybound, texture finds our [SEP]']
[ 750/2000] tot_loss=1.928 (perp=9.183, rec=0.087, cos=0.004), tot_loss_proj:3.447 [t=0.32s]
prediction: ['[CLS] conservative and conservative traditions and hide most movie our the realitybound itbound seasonbound gives new texture realitybound, texture finds our [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.881 (perp=8.876, rec=0.101, cos=0.005), tot_loss_proj:3.364 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions and hide most movie the realitybound it - seasonbound gives our new texture realitybound, texture finds our [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.831 (perp=8.631, rec=0.101, cos=0.004), tot_loss_proj:2.934 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions and - hide most movie the realitybound it -bound gives our new texture realitybound, texture finds our [SEP]']
[ 900/2000] tot_loss=1.815 (perp=8.631, rec=0.085, cos=0.004), tot_loss_proj:2.928 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions and - hide most movie the realitybound it -bound gives our new texture realitybound, texture finds our [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.765 (perp=8.361, rec=0.089, cos=0.004), tot_loss_proj:2.729 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions and - most movie hide the realitybound it -bound gives our new texture realitybound, texture finds our [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.800 (perp=8.539, rec=0.088, cos=0.004), tot_loss_proj:2.802 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions and - most movie hide the realitybound texture -bound gives one new texture realitybound, it finds our [SEP]']
[1050/2000] tot_loss=1.807 (perp=8.539, rec=0.096, cos=0.003), tot_loss_proj:2.802 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions and - most movie hide the realitybound texture -bound gives one new texture realitybound, it finds our [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.732 (perp=8.186, rec=0.091, cos=0.004), tot_loss_proj:2.789 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions and - most movie hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]']
Attempt swap
[1150/2000] tot_loss=1.731 (perp=8.186, rec=0.090, cos=0.003), tot_loss_proj:2.784 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions and - most movie hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]']
[1200/2000] tot_loss=1.724 (perp=8.186, rec=0.084, cos=0.003), tot_loss_proj:2.789 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions and - most movie hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.707 (perp=8.112, rec=0.081, cos=0.003), tot_loss_proj:3.230 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions - and most movie hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]']
Attempt swap
[1300/2000] tot_loss=1.713 (perp=8.112, rec=0.087, cos=0.003), tot_loss_proj:3.232 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions - and most movie hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]']
[1350/2000] tot_loss=1.706 (perp=8.112, rec=0.081, cos=0.003), tot_loss_proj:3.225 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions - and most movie hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]']
Attempt swap
[1400/2000] tot_loss=1.697 (perp=8.112, rec=0.071, cos=0.003), tot_loss_proj:3.228 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions - and most movie hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]']
Attempt swap
[1450/2000] tot_loss=1.760 (perp=8.341, rec=0.089, cos=0.003), tot_loss_proj:3.080 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions making and most movie hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]']
[1500/2000] tot_loss=1.757 (perp=8.341, rec=0.086, cos=0.003), tot_loss_proj:3.082 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions making and most movie hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.725 (perp=8.175, rec=0.087, cos=0.003), tot_loss_proj:2.861 [t=0.31s]
prediction: ['[CLS] conservative and conservative traditions movie making and most hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.702 (perp=8.076, rec=0.083, cos=0.003), tot_loss_proj:2.909 [t=0.31s]
prediction: ['[CLS] conservative and most conservative traditions movie making and hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]']
[1650/2000] tot_loss=1.767 (perp=8.454, rec=0.073, cos=0.003), tot_loss_proj:3.012 [t=0.31s]
prediction: ['[CLS] conservative and most conservative traditions movie making and hide the realitybound texturebound gives one new texture - newbound, it finds our [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.767 (perp=8.396, rec=0.084, cos=0.003), tot_loss_proj:2.991 [t=0.31s]
prediction: ['[CLS] conservative and most conservative movie making traditions and hide the realitybound texturebound gives one new texture - newbound, it finds our [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.753 (perp=8.355, rec=0.079, cos=0.003), tot_loss_proj:2.828 [t=0.31s]
prediction: ['[CLS] conservative and most conservative movie making and traditions hide the realitybound texturebound gives one new texture - newbound, it finds our [SEP]']
[1800/2000] tot_loss=1.757 (perp=8.355, rec=0.083, cos=0.003), tot_loss_proj:2.830 [t=0.31s]
prediction: ['[CLS] conservative and most conservative movie making and traditions hide the realitybound texturebound gives one new texture - newbound, it finds our [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.725 (perp=8.249, rec=0.072, cos=0.003), tot_loss_proj:2.610 [t=0.31s]
prediction: ['[CLS] conservative and most conservative movie making and traditions hide the realitybound gives texturebound one new texture - newbound, it finds our [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.673 (perp=7.912, rec=0.087, cos=0.003), tot_loss_proj:2.387 [t=0.31s]
prediction: ['[CLS] conservative and most conservative movie making and traditions the reality hidebound gives texturebound one new texture - newbound, it finds our [SEP]']
[1950/2000] tot_loss=1.669 (perp=7.912, rec=0.084, cos=0.003), tot_loss_proj:2.384 [t=0.31s]
prediction: ['[CLS] conservative and most conservative movie making and traditions the reality hidebound gives texturebound one new texture - newbound, it finds our [SEP]']
Attempt swap
[2000/2000] tot_loss=1.673 (perp=7.912, rec=0.087, cos=0.003), tot_loss_proj:2.386 [t=0.31s]
prediction: ['[CLS] conservative and most conservative movie making and traditions the reality hidebound gives texturebound one new texture - newbound, it finds our [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] conservative and conservative traditions and - most movie hide the realitybound texturebound gives one new texture - realitybound, it finds our [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.767 | p: 71.429 | r: 68.182
rouge2     | fm: 14.634 | p: 15.000 | r: 14.286
rougeL     | fm: 41.860 | p: 42.857 | r: 40.909
rougeLsum  | fm: 41.860 | p: 42.857 | r: 40.909
r1fm+r2fm = 84.402

[Aggregate metrics]:
rouge1     | fm: 87.633 | p: 86.730 | r: 88.765
rouge2     | fm: 56.914 | p: 56.456 | r: 57.541
rougeL     | fm: 78.323 | p: 77.439 | r: 79.255
rougeLsum  | fm: 77.960 | p: 77.236 | r: 78.926
r1fm+r2fm = 144.547

input #39 time: 0:12:23 | total time: 8:03:22


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9987594208645718
highest_index [0]
highest [0.9987594208645718]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9638748168945312 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9474213719367981 for ['[CLS] comeback was and ste up random staff med league [SEP]']
[Init] best rec loss: 0.9107111692428589 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.8919899463653564 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 0.882747232913971 for ['[CLS] of transferred charlotte play troy also soon instantly was [SEP]']
[Init] best rec loss: 0.8767090439796448 for ['[CLS] rep survival goal coral began hoc in protection barry [SEP]']
[Init] best rec loss: 0.869378387928009 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 0.8619301915168762 for ['[CLS]anto rather mor via smoke promote fearless goo burst [SEP]']
[Init] best rec loss: 0.8503440618515015 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 0.8292664289474487 for ['[CLS]lum head original navigation investigatingwell position ruleduron [SEP]']
[Init] best rec loss: 0.7838518619537354 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.7832688093185425 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.7788876295089722 for ['[CLS]° already deciding abd georgian kent but many lady [SEP]']
[Init] best perm rec loss: 0.7774747014045715 for ['[CLS] but many lady georgian° deciding already abd kent [SEP]']
[Init] best perm rec loss: 0.7773165106773376 for ['[CLS] lady abd but° deciding many already georgian kent [SEP]']
[Init] best perm rec loss: 0.7757274508476257 for ['[CLS] many deciding georgian lady° but already abd kent [SEP]']
[Init] best perm rec loss: 0.7754411697387695 for ['[CLS] deciding already° but georgian abd many lady kent [SEP]']
[Init] best perm rec loss: 0.775316596031189 for ['[CLS]° but kent many abd lady already deciding georgian [SEP]']
[Init] best perm rec loss: 0.7747762799263 for ['[CLS] many but already lady° deciding abd kent georgian [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.063 (perp=13.799, rec=0.284, cos=0.019), tot_loss_proj:4.716 [t=0.30s]
prediction: ['[CLS] college collegiatemmel orchestra presents dudley chapal imagery [SEP]']
[ 100/2000] tot_loss=2.517 (perp=11.527, rec=0.198, cos=0.013), tot_loss_proj:3.152 [t=0.30s]
prediction: ['[CLS]onyonymmel imagery withony phony music [SEP]']
[ 150/2000] tot_loss=2.282 (perp=10.471, rec=0.176, cos=0.012), tot_loss_proj:2.776 [t=0.30s]
prediction: ['[CLS]ony ormmel us withony phony music [SEP]']
[ 200/2000] tot_loss=2.180 (perp=10.246, rec=0.126, cos=0.005), tot_loss_proj:2.767 [t=0.30s]
prediction: ['[CLS]ony ormmel us withony phony imagery [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.936 (perp=8.814, rec=0.165, cos=0.008), tot_loss_proj:2.294 [t=0.30s]
prediction: ['[CLS]onyony ormmel us with phony imagery [SEP]']
[ 300/2000] tot_loss=1.729 (perp=8.052, rec=0.114, cos=0.004), tot_loss_proj:2.185 [t=0.30s]
prediction: ['[CLS]ony imagery ormmel us with phony imagery [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.632 (perp=7.639, rec=0.100, cos=0.004), tot_loss_proj:2.004 [t=0.30s]
prediction: ['[CLS]ony or imagerymmel us with phony imagery [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.621 (perp=7.639, rec=0.090, cos=0.003), tot_loss_proj:1.998 [t=0.30s]
prediction: ['[CLS]ony or imagerymmel us with phony imagery [SEP]']
[ 450/2000] tot_loss=1.616 (perp=7.639, rec=0.085, cos=0.004), tot_loss_proj:2.005 [t=0.30s]
prediction: ['[CLS]ony or imagerymmel us with phony imagery [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.761 (perp=8.327, rec=0.092, cos=0.004), tot_loss_proj:2.097 [t=0.30s]
prediction: ['[CLS] orony imagerymmel us with phony music [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.798 (perp=8.559, rec=0.083, cos=0.003), tot_loss_proj:2.070 [t=0.30s]
prediction: ['[CLS] pu or imagerymmel us with phony music [SEP]']
[ 600/2000] tot_loss=1.799 (perp=8.559, rec=0.084, cos=0.003), tot_loss_proj:2.063 [t=0.31s]
prediction: ['[CLS] pu or imagerymmel us with phony music [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.541 (perp=7.228, rec=0.092, cos=0.003), tot_loss_proj:1.832 [t=0.30s]
prediction: ['[CLS] or imagery pummel us with phony music [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.532 (perp=7.228, rec=0.084, cos=0.003), tot_loss_proj:1.838 [t=0.30s]
prediction: ['[CLS] or imagery pummel us with phony music [SEP]']
[ 750/2000] tot_loss=1.525 (perp=7.228, rec=0.077, cos=0.003), tot_loss_proj:1.841 [t=0.30s]
prediction: ['[CLS] or imagery pummel us with phony music [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.516 (perp=7.228, rec=0.067, cos=0.003), tot_loss_proj:1.838 [t=0.30s]
prediction: ['[CLS] or imagery pummel us with phony music [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.473 (perp=6.827, rec=0.104, cos=0.004), tot_loss_proj:1.822 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
[ 900/2000] tot_loss=1.440 (perp=6.827, rec=0.071, cos=0.003), tot_loss_proj:1.815 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.439 (perp=6.827, rec=0.071, cos=0.003), tot_loss_proj:1.819 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=1.434 (perp=6.827, rec=0.065, cos=0.003), tot_loss_proj:1.825 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
[1050/2000] tot_loss=1.444 (perp=6.827, rec=0.076, cos=0.003), tot_loss_proj:1.819 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=1.430 (perp=6.827, rec=0.062, cos=0.003), tot_loss_proj:1.818 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=1.445 (perp=6.827, rec=0.077, cos=0.003), tot_loss_proj:1.821 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
[1200/2000] tot_loss=1.429 (perp=6.827, rec=0.061, cos=0.003), tot_loss_proj:1.825 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.433 (perp=6.827, rec=0.065, cos=0.003), tot_loss_proj:1.824 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.435 (perp=6.827, rec=0.067, cos=0.003), tot_loss_proj:1.823 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
[1350/2000] tot_loss=1.443 (perp=6.827, rec=0.075, cos=0.003), tot_loss_proj:1.825 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.442 (perp=6.827, rec=0.074, cos=0.003), tot_loss_proj:1.820 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1450/2000] tot_loss=1.441 (perp=6.827, rec=0.073, cos=0.003), tot_loss_proj:1.825 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
[1500/2000] tot_loss=1.442 (perp=6.827, rec=0.074, cos=0.003), tot_loss_proj:1.822 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.432 (perp=6.827, rec=0.064, cos=0.003), tot_loss_proj:1.822 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.434 (perp=6.827, rec=0.066, cos=0.003), tot_loss_proj:1.825 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
[1650/2000] tot_loss=1.441 (perp=6.827, rec=0.073, cos=0.003), tot_loss_proj:1.816 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.433 (perp=6.827, rec=0.065, cos=0.003), tot_loss_proj:1.830 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.433 (perp=6.827, rec=0.065, cos=0.003), tot_loss_proj:1.829 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
[1800/2000] tot_loss=1.432 (perp=6.827, rec=0.064, cos=0.003), tot_loss_proj:1.821 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.435 (perp=6.827, rec=0.067, cos=0.003), tot_loss_proj:1.825 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.433 (perp=6.827, rec=0.065, cos=0.003), tot_loss_proj:1.825 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
[1950/2000] tot_loss=1.440 (perp=6.827, rec=0.072, cos=0.003), tot_loss_proj:1.822 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.439 (perp=6.827, rec=0.071, cos=0.003), tot_loss_proj:1.818 [t=0.30s]
prediction: ['[CLS] or music pummel us with phony imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] or music pummel us with phony imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 162.500

[Aggregate metrics]:
rouge1     | fm: 87.921 | p: 87.071 | r: 88.993
rouge2     | fm: 57.280 | p: 56.854 | r: 57.872
rougeL     | fm: 78.084 | p: 77.417 | r: 79.127
rougeLsum  | fm: 78.050 | p: 77.390 | r: 78.905
r1fm+r2fm = 145.202

input #40 time: 0:12:04 | total time: 8:15:27


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.9988746031740716
highest_index [0]
highest [0.9988746031740716]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.907608687877655 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9074802398681641 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.8948246836662292 for ['[CLS] mascara plenty [SEP]']
[Init] best rec loss: 0.8387754559516907 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 0.8122804760932922 for ['[CLS] cale fate [SEP]']
[Init] best perm rec loss: 0.8051304221153259 for ['[CLS] fate cale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.089 (perp=9.391, rec=0.204, cos=0.006), tot_loss_proj:2.603 [t=0.30s]
prediction: ['[CLS] sensitive sensitive [SEP]']
[ 100/2000] tot_loss=2.016 (perp=9.391, rec=0.134, cos=0.004), tot_loss_proj:2.610 [t=0.30s]
prediction: ['[CLS] sensitive sensitive [SEP]']
[ 150/2000] tot_loss=2.119 (perp=10.212, rec=0.073, cos=0.003), tot_loss_proj:2.125 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.101 (perp=10.212, rec=0.056, cos=0.003), tot_loss_proj:2.099 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.119 (perp=10.212, rec=0.073, cos=0.003), tot_loss_proj:2.115 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.002), tot_loss_proj:2.127 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.106 (perp=10.212, rec=0.061, cos=0.002), tot_loss_proj:2.113 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.109 (perp=10.212, rec=0.064, cos=0.002), tot_loss_proj:2.111 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.096 (perp=10.212, rec=0.051, cos=0.002), tot_loss_proj:2.116 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.110 (perp=10.212, rec=0.065, cos=0.002), tot_loss_proj:2.124 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.002), tot_loss_proj:2.111 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.092 (perp=10.212, rec=0.047, cos=0.002), tot_loss_proj:2.111 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.107 (perp=10.212, rec=0.062, cos=0.002), tot_loss_proj:2.125 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.105 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.113 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.110 (perp=10.212, rec=0.065, cos=0.002), tot_loss_proj:2.103 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.002), tot_loss_proj:2.132 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.002), tot_loss_proj:2.115 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.106 (perp=10.212, rec=0.061, cos=0.002), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.109 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.107 (perp=10.212, rec=0.062, cos=0.002), tot_loss_proj:2.106 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.110 (perp=10.212, rec=0.065, cos=0.002), tot_loss_proj:2.109 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.095 (perp=10.212, rec=0.050, cos=0.002), tot_loss_proj:2.105 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.105 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.113 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.106 (perp=10.212, rec=0.061, cos=0.002), tot_loss_proj:2.118 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.112 (perp=10.212, rec=0.067, cos=0.002), tot_loss_proj:2.116 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.002), tot_loss_proj:2.114 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.111 (perp=10.212, rec=0.066, cos=0.002), tot_loss_proj:2.111 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.101 (perp=10.212, rec=0.056, cos=0.002), tot_loss_proj:2.118 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.109 (perp=10.212, rec=0.064, cos=0.002), tot_loss_proj:2.100 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.122 (perp=10.212, rec=0.077, cos=0.002), tot_loss_proj:2.115 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.002), tot_loss_proj:2.119 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.111 (perp=10.212, rec=0.066, cos=0.002), tot_loss_proj:2.110 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.103 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.002), tot_loss_proj:2.116 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.118 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.105 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.114 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.112 (perp=10.212, rec=0.067, cos=0.002), tot_loss_proj:2.104 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.096 (perp=10.212, rec=0.051, cos=0.002), tot_loss_proj:2.120 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.098 (perp=10.212, rec=0.053, cos=0.002), tot_loss_proj:2.122 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.097 (perp=10.212, rec=0.052, cos=0.002), tot_loss_proj:2.112 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.278 | p: 87.357 | r: 89.375
rouge2     | fm: 58.274 | p: 57.794 | r: 58.833
rougeL     | fm: 78.756 | p: 78.032 | r: 79.703
rougeLsum  | fm: 78.487 | p: 77.776 | r: 79.356
r1fm+r2fm = 146.551

input #41 time: 0:12:01 | total time: 8:27:28


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9986213592732328
highest_index [0]
highest [0.9986213592732328]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9113878607749939 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8203765749931335 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8144280910491943 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.7969782948493958 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.7730544209480286 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7725010514259338 for ['[CLS] ran treaty wish internationalbegiblectric cutures offended enough stagestaking superseded ever darers liftedpling maple kitchen scale assignment larger attracted banda [SEP]']
[Init] best perm rec loss: 0.7714151740074158 for ['[CLS] internationalbe cut assignment maple enough banda attractedgible dare stages largerrs treaty supersededuresctrictaking wish lifted scale everpling kitchen offended ran [SEP]']
[Init] best perm rec loss: 0.7704849243164062 for ['[CLS] darersctric ever international kitchen cut assignment enough superseded scalebe lifted maple larger treaty banda rantaking stagesgible offended attractedplingures wish [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.016 (perp=13.400, rec=0.307, cos=0.029), tot_loss_proj:3.354 [t=0.31s]
prediction: ['[CLS] midnight ceased terrorist initially coulter. filmmakers filmmakers remix wrong bit compute equipment during re! priests legislation they deserted they poorly explanation poorly poorly poorly [SEP]']
[ 100/2000] tot_loss=2.722 (perp=12.508, rec=0.208, cos=0.012), tot_loss_proj:3.234 [t=0.31s]
prediction: ['[CLS] forgot forgot monster becauseparts. filmmakers filmmakers poorly forgot any congress scary cocktail re school pupils during theygger they poorly explanation forgot forgot into [SEP]']
[ 150/2000] tot_loss=2.649 (perp=12.409, rec=0.159, cos=0.008), tot_loss_proj:3.133 [t=0.31s]
prediction: ['[CLS] forgot forgot forgot asdown. attraction filmmakers poorly anything anything to scary cocktail a school fatal graduating theygger they poorly explanation forgot forgot into [SEP]']
[ 200/2000] tot_loss=2.399 (perp=11.123, rec=0.160, cos=0.014), tot_loss_proj:3.252 [t=0.31s]
prediction: ['[CLS] halfway forgot forgot asdown. project filmmakers scary anything anything to scary scary the regger graduating theygger they poorlygger forgot forgot into [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.302 (perp=10.755, rec=0.144, cos=0.008), tot_loss_proj:3.025 [t=0.31s]
prediction: ['[CLS]gger forgot fairly asdown. project scary filmmakers include anything to scary scary the regger graduating theygger they poorly re forgot forgot into [SEP]']
[ 300/2000] tot_loss=2.378 (perp=11.176, rec=0.137, cos=0.006), tot_loss_proj:3.083 [t=0.31s]
prediction: ['[CLS] halfway forgotkeeper as lifestyle. project scary filmmakers include anything to scary scary the re attraction school settinggger they poorly re forgot forgot into [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.376 (perp=11.284, rec=0.114, cos=0.005), tot_loss_proj:3.074 [t=0.31s]
prediction: ['[CLS]gger forgot halfway lifestyle. project scary filmmakers include anything to scary as halfway the re attraction school settinggger they poorly re forgot forgot into [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.321 (perp=11.048, rec=0.107, cos=0.005), tot_loss_proj:3.233 [t=0.31s]
prediction: ['[CLS] halfwayjigger setting. project scary filmmakers include anything to scary as halfway the re attraction school settinggger they poorly re forgot forgot into [SEP]']
[ 450/2000] tot_loss=2.356 (perp=11.236, rec=0.104, cos=0.005), tot_loss_proj:3.258 [t=0.31s]
prediction: ['[CLS] halfwayji halfway setting. project scary filmmakers include anything to scary as halfway the re attraction school settinggger they poorly re forgot forgot into [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.293 (perp=10.930, rec=0.102, cos=0.005), tot_loss_proj:3.307 [t=0.31s]
prediction: ['[CLS] halfwayji attraction a. project scary filmmakers include anything to scary as halfway the re attraction school settinggger they poorly re forgot & into [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.229 (perp=10.627, rec=0.099, cos=0.005), tot_loss_proj:3.214 [t=0.31s]
prediction: ['[CLS] halfwayji attraction a. project scary filmmakers include anything scary as halfway to the re attraction school settinggger they poorly re forgot & into [SEP]']
[ 600/2000] tot_loss=2.223 (perp=10.627, rec=0.092, cos=0.005), tot_loss_proj:3.216 [t=0.31s]
prediction: ['[CLS] halfwayji attraction a. project scary filmmakers include anything scary as halfway to the re attraction school settinggger they poorly re forgot & into [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.181 (perp=10.404, rec=0.095, cos=0.005), tot_loss_proj:3.318 [t=0.31s]
prediction: ['[CLS] halfwayji halfway a. project scary filmmakers include anything scary as attraction to the re attraction school settinggger they poorly re forgot & into [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.152 (perp=10.339, rec=0.080, cos=0.004), tot_loss_proj:3.161 [t=0.31s]
prediction: ['[CLS] halfwayji halfway a. project scary filmmakers include anything scary as attraction to the re halfway school settinggger they poorly re forgot into & [SEP]']
[ 750/2000] tot_loss=2.004 (perp=9.605, rec=0.078, cos=0.004), tot_loss_proj:2.992 [t=0.31s]
prediction: ['[CLS] halfwayji halfway a. project scary filmmakers include anything scary as attraction to the re halfway school settinggger they poorly re forgot into. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.081 (perp=9.956, rec=0.086, cos=0.004), tot_loss_proj:2.690 [t=0.31s]
prediction: ['[CLS] halfwayji halfway a fatal project scary filmmakers include anything scary as attraction to the re halfway school settinggger poorly they re forgot into. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.059 (perp=9.881, rec=0.079, cos=0.004), tot_loss_proj:2.738 [t=0.31s]
prediction: ['[CLS] halfwayji a halfway fatal project scary filmmakers include anything scary as attraction to the re halfway school settinggger poorly they re forgot into. [SEP]']
[ 900/2000] tot_loss=2.034 (perp=9.703, rec=0.089, cos=0.004), tot_loss_proj:2.892 [t=0.32s]
prediction: ['[CLS] halfwayji a even fatal project scary filmmakers include anything scary as attraction to the re halfway school settinggger poorly they re forgot into. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.998 (perp=9.557, rec=0.082, cos=0.004), tot_loss_proj:3.001 [t=0.31s]
prediction: ['[CLS] halfwayji a even fatal project scary filmmakers include anything scary as attraction to the halfway school setting regger poorly they re forgot into. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.977 (perp=9.463, rec=0.080, cos=0.004), tot_loss_proj:2.649 [t=0.31s]
prediction: ['[CLS] halfwayji even a fatal project scary filmmakers include anything scary as attraction to the halfway school setting regger poorly they re forgot into. [SEP]']
[1050/2000] tot_loss=1.981 (perp=9.463, rec=0.084, cos=0.004), tot_loss_proj:2.646 [t=0.31s]
prediction: ['[CLS] halfwayji even a fatal project scary filmmakers include anything scary as attraction to the halfway school setting regger poorly they re forgot into. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.982 (perp=9.463, rec=0.086, cos=0.004), tot_loss_proj:2.648 [t=0.31s]
prediction: ['[CLS] halfwayji even a fatal project scary filmmakers include anything scary as attraction to the halfway school setting regger poorly they re forgot into. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.903 (perp=9.099, rec=0.079, cos=0.004), tot_loss_proj:2.528 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as attraction to the halfway fatal setting regger poorly they re forgot into. [SEP]']
[1200/2000] tot_loss=1.899 (perp=9.099, rec=0.076, cos=0.004), tot_loss_proj:2.531 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as attraction to the halfway fatal setting regger poorly they re forgot into. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.838 (perp=8.809, rec=0.073, cos=0.003), tot_loss_proj:2.468 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.837 (perp=8.809, rec=0.072, cos=0.003), tot_loss_proj:2.474 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
[1350/2000] tot_loss=1.831 (perp=8.809, rec=0.066, cos=0.003), tot_loss_proj:2.466 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.844 (perp=8.809, rec=0.079, cos=0.003), tot_loss_proj:2.476 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.839 (perp=8.809, rec=0.074, cos=0.003), tot_loss_proj:2.475 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
[1500/2000] tot_loss=1.829 (perp=8.809, rec=0.064, cos=0.003), tot_loss_proj:2.475 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.836 (perp=8.809, rec=0.071, cos=0.003), tot_loss_proj:2.470 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.835 (perp=8.809, rec=0.070, cos=0.003), tot_loss_proj:2.477 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
[1650/2000] tot_loss=1.833 (perp=8.809, rec=0.068, cos=0.003), tot_loss_proj:2.472 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.843 (perp=8.809, rec=0.078, cos=0.003), tot_loss_proj:2.464 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.837 (perp=8.809, rec=0.073, cos=0.003), tot_loss_proj:2.473 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
[1800/2000] tot_loss=1.846 (perp=8.809, rec=0.081, cos=0.003), tot_loss_proj:2.477 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.843 (perp=8.809, rec=0.078, cos=0.003), tot_loss_proj:2.471 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.837 (perp=8.809, rec=0.072, cos=0.003), tot_loss_proj:2.468 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
[1950/2000] tot_loss=1.837 (perp=8.809, rec=0.072, cos=0.003), tot_loss_proj:2.467 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.776 (perp=8.481, rec=0.076, cos=0.003), tot_loss_proj:2.654 [t=0.31s]
prediction: ['[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction they re forgot regger poorly into. [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] halfwayji even a school project scary filmmakers include anything scary as setting to the halfway fatal attraction regger poorly they re forgot into. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 84.000 | r: 87.500
rouge2     | fm: 12.766 | p: 12.500 | r: 13.043
rougeL     | fm: 44.898 | p: 44.000 | r: 45.833
rougeLsum  | fm: 44.898 | p: 44.000 | r: 45.833
r1fm+r2fm = 98.480

[Aggregate metrics]:
rouge1     | fm: 88.192 | p: 87.332 | r: 89.272
rouge2     | fm: 57.169 | p: 56.781 | r: 57.737
rougeL     | fm: 77.964 | p: 77.209 | r: 78.861
rougeLsum  | fm: 77.718 | p: 76.979 | r: 78.568
r1fm+r2fm = 145.361

input #42 time: 0:12:25 | total time: 8:39:54


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9985427909090959
highest_index [0]
highest [0.9985427909090959]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9609465003013611 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9214500188827515 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.829851508140564 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 0.8114163279533386 for ['[CLS] emma " companyographer [SEP]']
[Init] best rec loss: 0.7806299328804016 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.7537593841552734 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.7088493704795837 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.6936152577400208 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 0.6917591691017151 for ['[CLS]bus second climbck [SEP]']
[Init] best perm rec loss: 0.6893463730812073 for ['[CLS] climb secondbusck [SEP]']
[Init] best perm rec loss: 0.6892675161361694 for ['[CLS]ckbus climb second [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.353 (perp=10.489, rec=0.244, cos=0.012), tot_loss_proj:3.809 [t=0.30s]
prediction: ['[CLS] na naiss margin [SEP]']
[ 100/2000] tot_loss=2.670 (perp=12.550, rec=0.153, cos=0.007), tot_loss_proj:3.356 [t=0.30s]
prediction: ['[CLS] na naisticiss [SEP]']
[ 150/2000] tot_loss=2.622 (perp=12.550, rec=0.108, cos=0.004), tot_loss_proj:3.326 [t=0.30s]
prediction: ['[CLS] na naisticiss [SEP]']
[ 200/2000] tot_loss=2.618 (perp=12.550, rec=0.102, cos=0.006), tot_loss_proj:3.310 [t=0.30s]
prediction: ['[CLS] na naisticiss [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.805 (perp=8.605, rec=0.080, cos=0.004), tot_loss_proj:2.123 [t=0.30s]
prediction: ['[CLS]istic narciss [SEP]']
[ 300/2000] tot_loss=1.799 (perp=8.605, rec=0.075, cos=0.003), tot_loss_proj:2.110 [t=0.30s]
prediction: ['[CLS]istic narciss [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.079 (perp=5.048, rec=0.067, cos=0.003), tot_loss_proj:1.088 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.069 (perp=5.048, rec=0.056, cos=0.003), tot_loss_proj:1.100 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.082 (perp=5.048, rec=0.069, cos=0.003), tot_loss_proj:1.092 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.080 (perp=5.048, rec=0.067, cos=0.003), tot_loss_proj:1.069 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.068 (perp=5.048, rec=0.056, cos=0.003), tot_loss_proj:1.075 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.067 (perp=5.048, rec=0.055, cos=0.003), tot_loss_proj:1.074 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.067 (perp=5.048, rec=0.055, cos=0.003), tot_loss_proj:1.091 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.069 (perp=5.048, rec=0.057, cos=0.003), tot_loss_proj:1.092 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.081 (perp=5.048, rec=0.069, cos=0.003), tot_loss_proj:1.087 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.072 (perp=5.048, rec=0.060, cos=0.003), tot_loss_proj:1.093 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.082 (perp=5.048, rec=0.069, cos=0.003), tot_loss_proj:1.084 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.068 (perp=5.048, rec=0.055, cos=0.003), tot_loss_proj:1.084 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.072 (perp=5.048, rec=0.060, cos=0.003), tot_loss_proj:1.074 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.080 (perp=5.048, rec=0.067, cos=0.003), tot_loss_proj:1.071 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.085 (perp=5.048, rec=0.072, cos=0.003), tot_loss_proj:1.084 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.075 (perp=5.048, rec=0.062, cos=0.003), tot_loss_proj:1.078 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.076 (perp=5.048, rec=0.064, cos=0.003), tot_loss_proj:1.082 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.075 (perp=5.048, rec=0.063, cos=0.003), tot_loss_proj:1.070 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.074 (perp=5.048, rec=0.061, cos=0.003), tot_loss_proj:1.077 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.061 (perp=5.048, rec=0.049, cos=0.003), tot_loss_proj:1.081 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.067 (perp=5.048, rec=0.054, cos=0.003), tot_loss_proj:1.074 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.079 (perp=5.048, rec=0.066, cos=0.003), tot_loss_proj:1.087 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.066 (perp=5.048, rec=0.053, cos=0.003), tot_loss_proj:1.074 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.080 (perp=5.048, rec=0.067, cos=0.003), tot_loss_proj:1.077 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.065 (perp=5.048, rec=0.052, cos=0.003), tot_loss_proj:1.083 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.063 (perp=5.048, rec=0.051, cos=0.003), tot_loss_proj:1.082 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.095 (perp=5.048, rec=0.082, cos=0.003), tot_loss_proj:1.070 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.073 (perp=5.048, rec=0.060, cos=0.003), tot_loss_proj:1.090 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.076 (perp=5.048, rec=0.063, cos=0.003), tot_loss_proj:1.082 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.089 (perp=5.048, rec=0.076, cos=0.003), tot_loss_proj:1.089 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.071 (perp=5.048, rec=0.058, cos=0.003), tot_loss_proj:1.077 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.075 (perp=5.048, rec=0.062, cos=0.003), tot_loss_proj:1.076 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.067 (perp=5.048, rec=0.055, cos=0.003), tot_loss_proj:1.081 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.072 (perp=5.048, rec=0.060, cos=0.003), tot_loss_proj:1.069 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.495 | p: 87.627 | r: 89.516
rouge2     | fm: 57.934 | p: 57.535 | r: 58.417
rougeL     | fm: 78.622 | p: 77.849 | r: 79.471
rougeLsum  | fm: 78.326 | p: 77.631 | r: 79.283
r1fm+r2fm = 146.429

input #43 time: 0:12:03 | total time: 8:51:57


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.9986865462621975
highest_index [0]
highest [0.9986865462621975]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9396542906761169 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9389026165008545 for ['[CLS] here supporters psycho fighting at portal seconds published break store among color telegramachcing applicable stress tow ways been cervical landing wrists makes grew code dale visual crowley [SEP]']
[Init] best rec loss: 0.9149457812309265 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.8902158141136169 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best perm rec loss: 0.8859724402427673 for ['[CLS] reader maxim ib somelewoodssa oil corinne warfare broadcasters peninsular bob game sr hold voice sum kali tensions beside major tied stone filed old tigers provincesif [CLS] [SEP]']
[Init] best perm rec loss: 0.8851507306098938 for ['[CLS] hold bob oil kali major warfare stonelewood tensions old sr maxim reader tigers broadcasters gameif [CLS] voice peninsular some provinces sum filedssa tied beside ib corinne [SEP]']
[Init] best perm rec loss: 0.8840115666389465 for ['[CLS]ssa tied filed broadcasters corinne tensions major provinces oil sum game hold sr tigers stone besideif oldlewood peninsular voice reader ib maxim warfare kali [CLS] bob some [SEP]']
[Init] best perm rec loss: 0.8832765221595764 for ['[CLS]ssa reader major old some voice [CLS] stone oil warfare tied sr tensions maximlewood kali filedif provinces bob sum ib tigers corinne broadcasters peninsular game beside hold [SEP]']
[Init] best perm rec loss: 0.8825867176055908 for ['[CLS] major sr hold some beside provinceslewood old ib corinne reader [CLS] oil maxim warfareif peninsular broadcasters voice kali bob tigers game stone tied sum filed tensionsssa [SEP]']
[Init] best perm rec loss: 0.8792216181755066 for ['[CLS] tigerslewood warfareif peninsular oil game tensions ib hold bob [CLS] provinces reader stone corinne sum voice maxim old broadcastersssa major tied sr some beside kali filed [SEP]']
[Init] best perm rec loss: 0.8791227340698242 for ['[CLS] voice broadcasters sumlewood beside [CLS]if sr stone warfare bob tensions filed tied major oil game peninsular provinces hold maxim some tigers ibssa old corinne reader kali [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.390 (perp=10.717, rec=0.234, cos=0.014), tot_loss_proj:2.939 [t=0.31s]
prediction: ['[CLS] thus is lost translation. poem translation lost the translation routine hollywoodization stretch using routine destroyed explicit lost. intentionallyvah ら fright times destroyed without critics translation [SEP]']
[ 100/2000] tot_loss=2.310 (perp=10.474, rec=0.205, cos=0.011), tot_loss_proj:2.961 [t=0.31s]
prediction: ['[CLS] in been lost translation in translation translation lost the translation routine hollywood ᅲ hollywood where routinefest pre slack. victory fright slack fright.verted ( hollywood translation [SEP]']
[ 150/2000] tot_loss=2.043 (perp=9.409, rec=0.154, cos=0.008), tot_loss_proj:2.883 [t=0.31s]
prediction: ['[CLS] in been lost translation in translation translation lost another has routine hollywoododies hollywood which frequentlyfest the slack. the of slack premise. orson in the translation [SEP]']
[ 200/2000] tot_loss=2.106 (perp=9.864, rec=0.128, cos=0.006), tot_loss_proj:2.575 [t=0.31s]
prediction: ['[CLS] in been lost in the translation translation lost another nearly routine hollywoododies hollywood which routinefest the slack. his execution slack premise.alic in thealic [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.988 (perp=9.324, rec=0.117, cos=0.006), tot_loss_proj:2.519 [t=0.31s]
prediction: ['[CLS] in been lost in the translation translation the another revolves routine hollywoododies hollywood which thefest lost slack. absurd execution slack premise.izes in thealic [SEP]']
[ 300/2000] tot_loss=1.977 (perp=9.348, rec=0.103, cos=0.005), tot_loss_proj:2.572 [t=0.31s]
prediction: ['[CLS] in been lost. the translation translation the another execution routine hollywood chooses hollywood which thefest lost slack. absurd execution slack premise.izes in thealic [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.915 (perp=9.004, rec=0.110, cos=0.004), tot_loss_proj:2.380 [t=0.31s]
prediction: ['[CLS] in been lost. the translation translation the another execution routine frightizes hollywood which thefest lost slack. absurd execution slack premisealicizes in the. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.052 (perp=9.433, rec=0.159, cos=0.007), tot_loss_proj:2.498 [t=0.31s]
prediction: ['[CLS] in been lost. the development another translation the illustrations routine fright’ hollywood which thefest lost slack. absurd execution slack premisealicizes of the. [SEP]']
[ 450/2000] tot_loss=1.970 (perp=9.209, rec=0.123, cos=0.005), tot_loss_proj:2.446 [t=0.31s]
prediction: ['[CLS] in been lost. the development another translation the execution routine fright’ hollywood which thefest lost slack. absurd execution slack premisealicizes of the. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.946 (perp=9.176, rec=0.106, cos=0.005), tot_loss_proj:2.419 [t=0.31s]
prediction: ['[CLS] in has lost. the development another translation the absurd execution routine fright computational hollywood which thefest lost slack. absurd execution premisealicizes of the. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.789 (perp=8.373, rec=0.110, cos=0.005), tot_loss_proj:2.308 [t=0.31s]
prediction: ['[CLS] in been lost. the development another translation the absurd execution routine fright which thefest lost slack. absurd execution premisealicizes of the the hollywood. [SEP]']
[ 600/2000] tot_loss=1.773 (perp=8.373, rec=0.093, cos=0.005), tot_loss_proj:2.311 [t=0.38s]
prediction: ['[CLS] in been lost. the development another translation the absurd execution routine fright which thefest lost slack. absurd execution premisealicizes of the the hollywood. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.736 (perp=8.212, rec=0.090, cos=0.004), tot_loss_proj:2.259 [t=0.31s]
prediction: ['[CLS] in been lost. the development another translation the absurd execution routine which thefest lost slack. absurd execution premisealicizes of the. hollywood fright. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.699 (perp=8.018, rec=0.091, cos=0.004), tot_loss_proj:2.227 [t=0.31s]
prediction: ['[CLS] in been lost. the development another translation the absurd execution routine which thefest lost slack. absurd execution premisealicizes of the hollywood fright.. [SEP]']
[ 750/2000] tot_loss=1.700 (perp=8.018, rec=0.092, cos=0.004), tot_loss_proj:2.233 [t=0.32s]
prediction: ['[CLS] in been lost. the development another translation the absurd execution routine which thefest lost slack. absurd execution premisealicizes of the hollywood fright.. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.677 (perp=7.954, rec=0.082, cos=0.004), tot_loss_proj:2.182 [t=0.31s]
prediction: ['[CLS] in been lost. the development another translation the absurd execution routine which thefest. slack. absurd execution premisealicizes of the hollywood fright.. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.638 (perp=7.674, rec=0.099, cos=0.004), tot_loss_proj:2.087 [t=0.31s]
prediction: ['[CLS] in been lost. the development another translation. absurd execution routine which thefest the slack. absurd execution premisealicizes of the hollywood fright.. [SEP]']
[ 900/2000] tot_loss=1.560 (perp=7.361, rec=0.084, cos=0.004), tot_loss_proj:2.055 [t=0.31s]
prediction: ['[CLS] in been lost. the. another translation. absurd execution routine which thefest the slack. absurd execution premisealicizes of the hollywood fright.. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.559 (perp=7.361, rec=0.083, cos=0.004), tot_loss_proj:2.056 [t=0.31s]
prediction: ['[CLS] in been lost. the. another translation. absurd execution routine which thefest the slack. absurd execution premisealicizes of the hollywood fright.. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.543 (perp=7.270, rec=0.085, cos=0.004), tot_loss_proj:2.062 [t=0.31s]
prediction: ['[CLS] in been lost the.. another translation. absurd execution routine which thefest the slack. absurd execution premisealicizes of the hollywood fright.. [SEP]']
[1050/2000] tot_loss=1.539 (perp=7.270, rec=0.081, cos=0.004), tot_loss_proj:2.056 [t=0.31s]
prediction: ['[CLS] in been lost the.. another translation. absurd execution routine which thefest the slack. absurd execution premisealicizes of the hollywood fright.. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.527 (perp=7.171, rec=0.088, cos=0.004), tot_loss_proj:2.028 [t=0.31s]
prediction: ['[CLS] in been lost the.. another translation. absurd execution routine which thefest the slack. the absurd execution premisealicizes of hollywood fright.. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.511 (perp=7.090, rec=0.089, cos=0.004), tot_loss_proj:2.009 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest the slack. the absurd execution premisealicizes of hollywood fright.. [SEP]']
[1200/2000] tot_loss=1.551 (perp=7.331, rec=0.081, cos=0.004), tot_loss_proj:2.080 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest the slack. the absurd execution premisealicizes of hollywood fright of. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.331, rec=0.080, cos=0.004), tot_loss_proj:2.081 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest the slack. the absurd execution premisealicizes of hollywood fright of. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.537 (perp=7.250, rec=0.083, cos=0.004), tot_loss_proj:2.108 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest the slack. the absurd execution premisealicizes of of fright hollywood. [SEP]']
[1350/2000] tot_loss=1.539 (perp=7.250, rec=0.085, cos=0.004), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest the slack. the absurd execution premisealicizes of of fright hollywood. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.510 (perp=7.096, rec=0.087, cos=0.004), tot_loss_proj:2.131 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest the slack. the absurd execution premisealicizes of fright of hollywood. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.414 (perp=6.652, rec=0.079, cos=0.004), tot_loss_proj:1.974 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
[1500/2000] tot_loss=1.425 (perp=6.652, rec=0.090, cos=0.004), tot_loss_proj:1.967 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.416 (perp=6.652, rec=0.081, cos=0.004), tot_loss_proj:1.974 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.416 (perp=6.650, rec=0.082, cos=0.004), tot_loss_proj:1.965 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution which routine thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
[1650/2000] tot_loss=1.408 (perp=6.650, rec=0.074, cos=0.004), tot_loss_proj:1.960 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution which routine thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.414 (perp=6.650, rec=0.080, cos=0.004), tot_loss_proj:1.967 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution which routine thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.418 (perp=6.652, rec=0.083, cos=0.004), tot_loss_proj:1.972 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
[1800/2000] tot_loss=1.421 (perp=6.652, rec=0.086, cos=0.004), tot_loss_proj:1.975 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.410 (perp=6.652, rec=0.075, cos=0.004), tot_loss_proj:1.976 [t=0.31s]
prediction: ['[CLS] in been lost the translation. another.. absurd execution routine which thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.333 (perp=6.213, rec=0.086, cos=0.004), tot_loss_proj:1.753 [t=0.31s]
prediction: ['[CLS] been lost in the translation. another.. absurd execution routine which thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
[1950/2000] tot_loss=1.334 (perp=6.213, rec=0.087, cos=0.004), tot_loss_proj:1.761 [t=0.31s]
prediction: ['[CLS] been lost in the translation. another.. absurd execution routine which thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.324 (perp=6.213, rec=0.077, cos=0.004), tot_loss_proj:1.751 [t=0.31s]
prediction: ['[CLS] been lost in the translation. another.. absurd execution routine which thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] in been lost the translation. another.. absurd execution routine which thefest of slack. the absurd execution premisealicizes the fright of hollywood. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.565 | p: 69.565 | r: 69.565
rouge2     | fm: 13.636 | p: 13.636 | r: 13.636
rougeL     | fm: 56.522 | p: 56.522 | r: 56.522
rougeLsum  | fm: 56.522 | p: 56.522 | r: 56.522
r1fm+r2fm = 83.202

[Aggregate metrics]:
rouge1     | fm: 87.955 | p: 87.126 | r: 89.049
rouge2     | fm: 57.085 | p: 56.750 | r: 57.565
rougeL     | fm: 78.102 | p: 77.396 | r: 78.940
rougeLsum  | fm: 77.770 | p: 77.041 | r: 78.570
r1fm+r2fm = 145.039

input #44 time: 0:12:23 | total time: 9:04:20


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9985324041039029
highest_index [0]
highest [0.9985324041039029]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.7983801960945129 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.7340615391731262 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.7170484662055969 for ['[CLS] go land board preparatory hush dylan guantanamo grace really our guidesbian a2lic internet mor salad possible throughoutim between grey scaleitic around speech pri mil [SEP]']
[Init] best rec loss: 0.6847711205482483 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 0.6605950593948364 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.6597389578819275 for ['[CLS]2 ku tree operatedtiv bore murmured single v few letter military status special taste skin joan football ( curtis enclosedlanda gentry five entrance whoa around via [SEP]']
[Init] best perm rec loss: 0.652504026889801 for ['[CLS] around2 letter curtis ku gentry bore joan ( taste footballlanda status five v operated fewtiv military via tree murmured special skin entrance single whoa enclosed [SEP]']
[Init] best perm rec loss: 0.6522385478019714 for ['[CLS] special via v military five skin lettertiv ku bore football gentry operated2 murmured entrance status taste single joan whoa (landa few curtis enclosed around tree [SEP]']
[Init] best perm rec loss: 0.6513814926147461 for ['[CLS] enclosed football v whoa taste entrance skin letter2 aroundlanda bore tree curtis murmured via single status special ( fivetiv ku few gentry joan operated military [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.698 (perp=11.840, rec=0.299, cos=0.031), tot_loss_proj:3.470 [t=0.31s]
prediction: ['[CLS] this program beeren hear particularly - film depthtypical - archived paper giant talestered apparent blade prison expression - that scandals -ley gps room radiated [SEP]']
[ 100/2000] tot_loss=2.398 (perp=10.696, rec=0.237, cos=0.021), tot_loss_proj:3.617 [t=0.31s]
prediction: ['[CLS] than - bowel movements particularly than crime depthmm - - shelf shelf issue the private - prison crime - this buff - drama movements gi radiated [SEP]']
[ 150/2000] tot_loss=2.334 (perp=10.854, rec=0.157, cos=0.006), tot_loss_proj:2.959 [t=0.31s]
prediction: ['[CLS] - exercise bowel movements - than crime processesmm - - shelfel a the shelf - prison crimemm this gi - drama movements gi exercise [SEP]']
[ 200/2000] tot_loss=2.063 (perp=9.659, rec=0.126, cos=0.005), tot_loss_proj:2.886 [t=0.31s]
prediction: ['[CLS] - exercise bowel movements - than crime testsmm - - shelfel on the crime - in crime exercise this gi - drama drama gi exercise [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.861 (perp=8.664, rec=0.124, cos=0.004), tot_loss_proj:2.628 [t=0.31s]
prediction: ['[CLS] - - bowel movements - than crime exercisemm - - shelfel on the crime -, crime exercise thisick - in drama gi exercise [SEP]']
[ 300/2000] tot_loss=2.047 (perp=9.690, rec=0.105, cos=0.004), tot_loss_proj:2.754 [t=0.31s]
prediction: ['[CLS] - - bowel movements - than long exercisemm - - shelfick onick crime -, drama shoot thisick - in drama gi exercise [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.881 (perp=8.835, rec=0.109, cos=0.005), tot_loss_proj:2.632 [t=0.31s]
prediction: ['[CLS] - - bowel movements - than long choice exercise - - shelfel onick crime -, drama shoot thisick - in drama gimm [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.786 (perp=8.421, rec=0.098, cos=0.003), tot_loss_proj:2.519 [t=0.31s]
prediction: ['[CLS] - - bowel movements - than long shoot exercise - - shelf in onick crime -, drama shoot thisick - - drama gimm [SEP]']
[ 450/2000] tot_loss=1.749 (perp=8.328, rec=0.080, cos=0.004), tot_loss_proj:2.500 [t=0.31s]
prediction: ['[CLS] - - bowel movements - than long shoot exercise - - shelf in onick crime -, crime shoot thisick - - drama gimm [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.702 (perp=8.081, rec=0.082, cos=0.003), tot_loss_proj:2.506 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - shelf in onick point -, crime shoot thisick - - drama gimm [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.643 (perp=7.781, rec=0.083, cos=0.003), tot_loss_proj:2.424 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelfick point -, crime shoot thisick - - drama gimm [SEP]']
[ 600/2000] tot_loss=1.571 (perp=7.466, rec=0.075, cos=0.003), tot_loss_proj:2.484 [t=0.32s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point -, crime shoot thisick - - drama gimm [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.540 (perp=7.314, rec=0.074, cos=0.003), tot_loss_proj:2.352 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point -, - shoot thisick - crime drama gimm [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.519 (perp=7.173, rec=0.082, cos=0.003), tot_loss_proj:2.293 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, shoot thisick - crime drama gimm [SEP]']
[ 750/2000] tot_loss=1.507 (perp=7.173, rec=0.069, cos=0.003), tot_loss_proj:2.298 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, shoot thisick - crime drama gimm [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.511 (perp=7.173, rec=0.073, cos=0.003), tot_loss_proj:2.296 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, shoot thisick - crime drama gimm [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.394 (perp=6.592, rec=0.072, cos=0.003), tot_loss_proj:1.889 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, shoot this - crime drama gimmick [SEP]']
[ 900/2000] tot_loss=1.392 (perp=6.592, rec=0.070, cos=0.003), tot_loss_proj:1.888 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, shoot this - crime drama gimmick [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.343 (perp=6.352, rec=0.069, cos=0.003), tot_loss_proj:1.816 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, shoot - this crime drama gimmick [SEP]']
Attempt swap
[1000/2000] tot_loss=1.446 (perp=6.833, rec=0.077, cos=0.003), tot_loss_proj:1.926 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -,y - this crime drama gimmick [SEP]']
[1050/2000] tot_loss=1.439 (perp=6.833, rec=0.069, cos=0.003), tot_loss_proj:1.926 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -,y - this crime drama gimmick [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.425 (perp=6.750, rec=0.072, cos=0.003), tot_loss_proj:1.902 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, - this crimey drama gimmick [SEP]']
Attempt swap
[1150/2000] tot_loss=1.427 (perp=6.750, rec=0.074, cos=0.003), tot_loss_proj:1.894 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, - this crimey drama gimmick [SEP]']
[1200/2000] tot_loss=1.422 (perp=6.750, rec=0.069, cos=0.003), tot_loss_proj:1.903 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, - this crimey drama gimmick [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.388 (perp=6.582, rec=0.069, cos=0.003), tot_loss_proj:1.905 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, this crimey drama gimmick - [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.395 (perp=6.582, rec=0.075, cos=0.003), tot_loss_proj:1.917 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, this crimey drama gimmick - [SEP]']
[1350/2000] tot_loss=1.392 (perp=6.582, rec=0.073, cos=0.003), tot_loss_proj:1.917 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, this crimey drama gimmick - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.393 (perp=6.582, rec=0.073, cos=0.003), tot_loss_proj:1.918 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, this crimey drama gimmick - [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.357 (perp=6.397, rec=0.074, cos=0.003), tot_loss_proj:1.841 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, this crime - drama gimmicky [SEP]']
[1500/2000] tot_loss=1.357 (perp=6.397, rec=0.075, cos=0.003), tot_loss_proj:1.842 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, this crime - drama gimmicky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.344 (perp=6.397, rec=0.062, cos=0.003), tot_loss_proj:1.842 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, this crime - drama gimmicky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.349 (perp=6.397, rec=0.066, cos=0.003), tot_loss_proj:1.844 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, this crime - drama gimmicky [SEP]']
[1650/2000] tot_loss=1.347 (perp=6.397, rec=0.064, cos=0.003), tot_loss_proj:1.841 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, this crime - drama gimmicky [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.353 (perp=6.372, rec=0.076, cos=0.003), tot_loss_proj:1.794 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - in on shelf and point - -, this crime - drama gimmicky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.338 (perp=6.372, rec=0.060, cos=0.003), tot_loss_proj:1.794 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - in on shelf and point - -, this crime - drama gimmicky [SEP]']
[1800/2000] tot_loss=1.354 (perp=6.372, rec=0.076, cos=0.003), tot_loss_proj:1.793 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - in on shelf and point - -, this crime - drama gimmicky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.337 (perp=6.372, rec=0.060, cos=0.003), tot_loss_proj:1.791 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - in on shelf and point - -, this crime - drama gimmicky [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.348 (perp=6.372, rec=0.070, cos=0.003), tot_loss_proj:1.791 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - in on shelf and point - -, this crime - drama gimmicky [SEP]']
[1950/2000] tot_loss=1.338 (perp=6.372, rec=0.060, cos=0.003), tot_loss_proj:1.795 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - in on shelf and point - -, this crime - drama gimmicky [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.345 (perp=6.338, rec=0.075, cos=0.003), tot_loss_proj:1.799 [t=0.31s]
prediction: ['[CLS] exercise - bowel movements - than long shoot - - - in on shelf and point - -, this crime drama gimmicky - [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] exercise - bowel movements - than long shoot - - - on in shelf and point - -, this crime - drama gimmicky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 97.143 | p: 100.000 | r: 94.444
rouge2     | fm: 18.182 | p: 18.750 | r: 17.647
rougeL     | fm: 62.857 | p: 64.706 | r: 61.111
rougeLsum  | fm: 62.857 | p: 64.706 | r: 61.111
r1fm+r2fm = 115.325

[Aggregate metrics]:
rouge1     | fm: 88.208 | p: 87.461 | r: 89.190
rouge2     | fm: 56.207 | p: 55.787 | r: 56.731
rougeL     | fm: 77.591 | p: 77.006 | r: 78.438
rougeLsum  | fm: 77.468 | p: 76.851 | r: 78.204
r1fm+r2fm = 144.415

input #45 time: 0:12:23 | total time: 9:16:44


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9986962306291556
highest_index [0]
highest [0.9986962306291556]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9716669321060181 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9655133485794067 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9641508460044861 for ['[CLS] boring hungry saw colby full pride [SEP]']
[Init] best rec loss: 0.9589041471481323 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.9463059306144714 for ['[CLS] mp outside roommate isn casualtyecin [SEP]']
[Init] best perm rec loss: 0.9459474682807922 for ['[CLS] mpecin isn casualty roommate outside [SEP]']
[Init] best perm rec loss: 0.9446577429771423 for ['[CLS]ecin roommate mp casualty outside isn [SEP]']
[Init] best perm rec loss: 0.9437757134437561 for ['[CLS] roommate isnecin casualty mp outside [SEP]']
[Init] best perm rec loss: 0.9433501362800598 for ['[CLS]ecin casualty roommate outside mp isn [SEP]']
[Init] best perm rec loss: 0.9430884122848511 for ['[CLS] mp isn roommateecin outside casualty [SEP]']
[Init] best perm rec loss: 0.9430310130119324 for ['[CLS] roommateecin isn mp casualty outside [SEP]']
[Init] best perm rec loss: 0.9426451921463013 for ['[CLS] casualty roommate mp isnecin outside [SEP]']
[Init] best perm rec loss: 0.942342221736908 for ['[CLS] mp isn roommate casualty outsideecin [SEP]']
[Init] best perm rec loss: 0.9419897198677063 for ['[CLS] roommate mpecin casualty isn outside [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.567 (perp=10.898, rec=0.556, cos=0.831), tot_loss_proj:3.310 [t=0.30s]
prediction: ['[CLS] visually pretty particular temperature - loved [SEP]']
[ 100/2000] tot_loss=3.178 (perp=11.233, rec=0.474, cos=0.458), tot_loss_proj:3.032 [t=0.30s]
prediction: ['[CLS] visually quite particular hopefully slick staged [SEP]']
[ 150/2000] tot_loss=3.550 (perp=14.462, rec=0.394, cos=0.264), tot_loss_proj:4.906 [t=0.30s]
prediction: ['[CLS] visually wadi paranormal consecutive staged staged [SEP]']
[ 200/2000] tot_loss=3.338 (perp=13.241, rec=0.369, cos=0.320), tot_loss_proj:3.566 [t=0.31s]
prediction: ['[CLS] visually wadi visually striking staged staged [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.649 (perp=10.235, rec=0.362, cos=0.240), tot_loss_proj:2.909 [t=0.30s]
prediction: ['[CLS] award visually visually striking staged 〉 [SEP]']
[ 300/2000] tot_loss=2.652 (perp=10.235, rec=0.368, cos=0.237), tot_loss_proj:2.910 [t=0.30s]
prediction: ['[CLS] award visually visually striking staged 〉 [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.522 (perp=9.705, rec=0.301, cos=0.280), tot_loss_proj:2.411 [t=0.30s]
prediction: ['[CLS] visually visually striking staged multiple staged [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.996 (perp=11.658, rec=0.322, cos=0.342), tot_loss_proj:3.267 [t=0.30s]
prediction: ['[CLS] visually visually striking sainte stagedlassified [SEP]']
[ 450/2000] tot_loss=2.824 (perp=10.962, rec=0.306, cos=0.325), tot_loss_proj:2.809 [t=0.30s]
prediction: ['[CLS] visually visually striking sainte staged staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.825 (perp=10.962, rec=0.294, cos=0.338), tot_loss_proj:2.811 [t=0.30s]
prediction: ['[CLS] visually visually striking sainte staged staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.803 (perp=11.067, rec=0.274, cos=0.315), tot_loss_proj:2.735 [t=0.30s]
prediction: ['[CLS] visually visually striking sainte slick staged [SEP]']
[ 600/2000] tot_loss=2.784 (perp=11.067, rec=0.288, cos=0.283), tot_loss_proj:2.744 [t=0.30s]
prediction: ['[CLS] visually visually striking sainte slick staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.804 (perp=11.067, rec=0.284, cos=0.307), tot_loss_proj:2.741 [t=0.30s]
prediction: ['[CLS] visually visually striking sainte slick staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.799 (perp=11.067, rec=0.286, cos=0.299), tot_loss_proj:2.743 [t=0.30s]
prediction: ['[CLS] visually visually striking sainte slick staged [SEP]']
[ 750/2000] tot_loss=2.816 (perp=11.067, rec=0.274, cos=0.329), tot_loss_proj:2.749 [t=0.30s]
prediction: ['[CLS] visually visually striking sainte slick staged [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.680 (perp=10.463, rec=0.269, cos=0.318), tot_loss_proj:2.627 [t=0.30s]
prediction: ['[CLS] visually visually striking slick upon staged [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.562 (perp=9.867, rec=0.267, cos=0.322), tot_loss_proj:2.587 [t=0.30s]
prediction: ['[CLS] visually visually striking upon slick staged [SEP]']
[ 900/2000] tot_loss=2.545 (perp=9.776, rec=0.268, cos=0.322), tot_loss_proj:2.355 [t=0.30s]
prediction: ['[CLS] visually visually strikingishly slick staged [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.456 (perp=9.326, rec=0.265, cos=0.325), tot_loss_proj:2.246 [t=0.30s]
prediction: ['[CLS] visually visually striking slickishly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=2.459 (perp=9.326, rec=0.271, cos=0.323), tot_loss_proj:2.240 [t=0.30s]
prediction: ['[CLS] visually visually striking slickishly staged [SEP]']
[1050/2000] tot_loss=2.674 (perp=10.463, rec=0.270, cos=0.311), tot_loss_proj:2.622 [t=0.30s]
prediction: ['[CLS] visually visually striking slick upon staged [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.550 (perp=9.776, rec=0.261, cos=0.334), tot_loss_proj:2.356 [t=0.30s]
prediction: ['[CLS] visually visually strikingishly slick staged [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.852 (perp=11.271, rec=0.267, cos=0.330), tot_loss_proj:2.755 [t=0.30s]
prediction: ['[CLS] visually visually striking slick ⟨ staged [SEP]']
[1200/2000] tot_loss=2.835 (perp=11.271, rec=0.263, cos=0.318), tot_loss_proj:2.773 [t=0.30s]
prediction: ['[CLS] visually visually striking slick ⟨ staged [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.764 (perp=10.889, rec=0.269, cos=0.317), tot_loss_proj:2.563 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
Attempt swap
[1300/2000] tot_loss=2.751 (perp=10.889, rec=0.247, cos=0.325), tot_loss_proj:2.562 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
[1350/2000] tot_loss=2.764 (perp=10.889, rec=0.270, cos=0.316), tot_loss_proj:2.564 [t=0.31s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
Attempt swap
[1400/2000] tot_loss=2.756 (perp=10.889, rec=0.255, cos=0.323), tot_loss_proj:2.555 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
Attempt swap
[1450/2000] tot_loss=2.754 (perp=10.889, rec=0.254, cos=0.322), tot_loss_proj:2.567 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
[1500/2000] tot_loss=2.752 (perp=10.889, rec=0.255, cos=0.320), tot_loss_proj:2.564 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
Attempt swap
[1550/2000] tot_loss=2.748 (perp=10.889, rec=0.251, cos=0.319), tot_loss_proj:2.577 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
Attempt swap
[1600/2000] tot_loss=2.749 (perp=10.889, rec=0.253, cos=0.319), tot_loss_proj:2.569 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
[1650/2000] tot_loss=2.756 (perp=10.889, rec=0.253, cos=0.326), tot_loss_proj:2.566 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
Attempt swap
[1700/2000] tot_loss=2.756 (perp=10.889, rec=0.257, cos=0.321), tot_loss_proj:2.567 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
Attempt swap
[1750/2000] tot_loss=2.759 (perp=10.889, rec=0.264, cos=0.317), tot_loss_proj:2.556 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
[1800/2000] tot_loss=2.756 (perp=10.889, rec=0.259, cos=0.319), tot_loss_proj:2.559 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
Attempt swap
[1850/2000] tot_loss=2.755 (perp=10.889, rec=0.260, cos=0.317), tot_loss_proj:2.563 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
Attempt swap
[1900/2000] tot_loss=2.757 (perp=10.889, rec=0.259, cos=0.320), tot_loss_proj:2.570 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
[1950/2000] tot_loss=2.760 (perp=10.889, rec=0.263, cos=0.320), tot_loss_proj:2.567 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
Attempt swap
[2000/2000] tot_loss=2.764 (perp=10.889, rec=0.266, cos=0.320), tot_loss_proj:2.561 [t=0.30s]
prediction: ['[CLS] visually visually striking ⟨ slick staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually visually striking ⟨ slick staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 121.429

[Aggregate metrics]:
rouge1     | fm: 87.932 | p: 87.184 | r: 88.831
rouge2     | fm: 55.988 | p: 55.543 | r: 56.637
rougeL     | fm: 77.361 | p: 76.734 | r: 78.245
rougeLsum  | fm: 77.272 | p: 76.629 | r: 78.012
r1fm+r2fm = 143.920

input #46 time: 0:12:03 | total time: 9:28:47


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9986228109155785
highest_index [0]
highest [0.9986228109155785]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6789678931236267 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6564631462097168 for ['[CLS] spent excitedlychule [SEP]']
[Init] best rec loss: 0.6563543677330017 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6488214135169983 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.6406188011169434 for ['[CLS]d promises walt [SEP]']
[Init] best perm rec loss: 0.640266478061676 for ['[CLS] promisesd walt [SEP]']
[Init] best perm rec loss: 0.6402583122253418 for ['[CLS]d walt promises [SEP]']
[Init] best perm rec loss: 0.6374086737632751 for ['[CLS] walt promisesd [SEP]']
[Init] best perm rec loss: 0.6369629502296448 for ['[CLS] promises waltd [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.132 (perp=9.229, rec=0.223, cos=0.063), tot_loss_proj:2.938 [t=0.30s]
prediction: ['[CLS] transparent transparent transparent [SEP]']
[ 100/2000] tot_loss=2.583 (perp=12.131, rec=0.133, cos=0.024), tot_loss_proj:3.349 [t=0.30s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 150/2000] tot_loss=2.551 (perp=12.131, rec=0.108, cos=0.016), tot_loss_proj:3.341 [t=0.30s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 200/2000] tot_loss=2.537 (perp=12.131, rec=0.093, cos=0.018), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.550 (perp=12.131, rec=0.099, cos=0.025), tot_loss_proj:3.339 [t=0.30s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 300/2000] tot_loss=2.103 (perp=9.993, rec=0.096, cos=0.009), tot_loss_proj:2.724 [t=0.30s]
prediction: ['[CLS] transparent downright [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.841 (perp=8.803, rec=0.075, cos=0.005), tot_loss_proj:1.887 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.828 (perp=8.803, rec=0.063, cos=0.004), tot_loss_proj:1.879 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[ 450/2000] tot_loss=1.848 (perp=8.803, rec=0.083, cos=0.004), tot_loss_proj:1.869 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.834 (perp=8.803, rec=0.070, cos=0.003), tot_loss_proj:1.891 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.824 (perp=8.803, rec=0.060, cos=0.003), tot_loss_proj:1.878 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.836 (perp=8.803, rec=0.072, cos=0.003), tot_loss_proj:1.874 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.819 (perp=8.803, rec=0.055, cos=0.003), tot_loss_proj:1.863 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.812 (perp=8.803, rec=0.047, cos=0.004), tot_loss_proj:1.856 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.821 (perp=8.803, rec=0.058, cos=0.003), tot_loss_proj:1.876 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.832 (perp=8.803, rec=0.068, cos=0.003), tot_loss_proj:1.869 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.831 (perp=8.803, rec=0.067, cos=0.003), tot_loss_proj:1.872 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.825 (perp=8.803, rec=0.061, cos=0.003), tot_loss_proj:1.869 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.824 (perp=8.803, rec=0.060, cos=0.003), tot_loss_proj:1.861 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.820 (perp=8.803, rec=0.057, cos=0.003), tot_loss_proj:1.860 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.810 (perp=8.803, rec=0.047, cos=0.003), tot_loss_proj:1.865 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.822 (perp=8.803, rec=0.059, cos=0.003), tot_loss_proj:1.865 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.830 (perp=8.803, rec=0.066, cos=0.003), tot_loss_proj:1.869 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.825 (perp=8.803, rec=0.061, cos=0.003), tot_loss_proj:1.871 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.830 (perp=8.803, rec=0.066, cos=0.003), tot_loss_proj:1.864 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.830 (perp=8.803, rec=0.066, cos=0.003), tot_loss_proj:1.861 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.824 (perp=8.803, rec=0.060, cos=0.003), tot_loss_proj:1.866 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.813 (perp=8.803, rec=0.050, cos=0.003), tot_loss_proj:1.868 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.814 (perp=8.803, rec=0.050, cos=0.003), tot_loss_proj:1.858 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.837 (perp=8.803, rec=0.073, cos=0.003), tot_loss_proj:1.872 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.816 (perp=8.803, rec=0.053, cos=0.003), tot_loss_proj:1.867 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.831 (perp=8.803, rec=0.068, cos=0.003), tot_loss_proj:1.861 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.830 (perp=8.803, rec=0.066, cos=0.003), tot_loss_proj:1.867 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.827 (perp=8.803, rec=0.063, cos=0.003), tot_loss_proj:1.863 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.832 (perp=8.803, rec=0.068, cos=0.003), tot_loss_proj:1.866 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.838 (perp=8.803, rec=0.074, cos=0.003), tot_loss_proj:1.867 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.814 (perp=8.803, rec=0.050, cos=0.003), tot_loss_proj:1.867 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.837 (perp=8.803, rec=0.074, cos=0.003), tot_loss_proj:1.858 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.833 (perp=8.803, rec=0.069, cos=0.003), tot_loss_proj:1.861 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.813 (perp=8.803, rec=0.049, cos=0.003), tot_loss_proj:1.871 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.076 | p: 87.291 | r: 88.958
rouge2     | fm: 57.006 | p: 56.618 | r: 57.583
rougeL     | fm: 77.915 | p: 77.280 | r: 78.737
rougeLsum  | fm: 77.800 | p: 77.154 | r: 78.565
r1fm+r2fm = 145.083

input #47 time: 0:12:03 | total time: 9:40:51


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9987240143043945
highest_index [0]
highest [0.9987240143043945]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.8765761852264404 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.874824047088623 for ['[CLS] however stage arts grounds [SEP]']
[Init] best rec loss: 0.8120085597038269 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 0.7798901796340942 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.776208758354187 for ['[CLS] graveyardtutedine runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.887 (perp=13.480, rec=0.183, cos=0.008), tot_loss_proj:3.049 [t=0.30s]
prediction: ['[CLS] rotting under rottingbell [SEP]']
[ 100/2000] tot_loss=1.533 (perp=7.107, rec=0.107, cos=0.004), tot_loss_proj:1.494 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 150/2000] tot_loss=1.500 (perp=7.107, rec=0.074, cos=0.004), tot_loss_proj:1.501 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 200/2000] tot_loss=1.495 (perp=7.107, rec=0.070, cos=0.004), tot_loss_proj:1.493 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.493 (perp=7.107, rec=0.067, cos=0.004), tot_loss_proj:1.498 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 300/2000] tot_loss=1.479 (perp=7.107, rec=0.054, cos=0.004), tot_loss_proj:1.487 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.481 (perp=7.107, rec=0.055, cos=0.004), tot_loss_proj:1.502 [t=0.31s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.489 (perp=7.107, rec=0.063, cos=0.004), tot_loss_proj:1.491 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 450/2000] tot_loss=1.488 (perp=7.107, rec=0.062, cos=0.004), tot_loss_proj:1.490 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.489 (perp=7.107, rec=0.064, cos=0.004), tot_loss_proj:1.494 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.479 (perp=7.107, rec=0.054, cos=0.004), tot_loss_proj:1.489 [t=0.31s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 600/2000] tot_loss=1.492 (perp=7.107, rec=0.067, cos=0.004), tot_loss_proj:1.497 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.487 (perp=7.107, rec=0.062, cos=0.004), tot_loss_proj:1.489 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.484 (perp=7.107, rec=0.059, cos=0.004), tot_loss_proj:1.489 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 750/2000] tot_loss=1.481 (perp=7.107, rec=0.056, cos=0.004), tot_loss_proj:1.499 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.486 (perp=7.107, rec=0.061, cos=0.004), tot_loss_proj:1.488 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.487 (perp=7.107, rec=0.061, cos=0.004), tot_loss_proj:1.483 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 900/2000] tot_loss=1.497 (perp=7.107, rec=0.071, cos=0.004), tot_loss_proj:1.493 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.489 (perp=7.107, rec=0.064, cos=0.004), tot_loss_proj:1.491 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.488 (perp=7.107, rec=0.062, cos=0.004), tot_loss_proj:1.490 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1050/2000] tot_loss=1.496 (perp=7.107, rec=0.071, cos=0.004), tot_loss_proj:1.489 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.486 (perp=7.107, rec=0.061, cos=0.004), tot_loss_proj:1.490 [t=0.31s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.491 (perp=7.107, rec=0.065, cos=0.004), tot_loss_proj:1.485 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1200/2000] tot_loss=1.487 (perp=7.107, rec=0.062, cos=0.004), tot_loss_proj:1.487 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.488 (perp=7.107, rec=0.063, cos=0.004), tot_loss_proj:1.491 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.483 (perp=7.107, rec=0.058, cos=0.004), tot_loss_proj:1.489 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1350/2000] tot_loss=1.488 (perp=7.107, rec=0.063, cos=0.004), tot_loss_proj:1.483 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.494 (perp=7.107, rec=0.068, cos=0.004), tot_loss_proj:1.496 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.483 (perp=7.107, rec=0.058, cos=0.004), tot_loss_proj:1.485 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1500/2000] tot_loss=1.494 (perp=7.107, rec=0.068, cos=0.004), tot_loss_proj:1.479 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.496 (perp=7.107, rec=0.070, cos=0.004), tot_loss_proj:1.492 [t=0.31s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.483 (perp=7.107, rec=0.058, cos=0.004), tot_loss_proj:1.489 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1650/2000] tot_loss=1.476 (perp=7.107, rec=0.051, cos=0.004), tot_loss_proj:1.485 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.484 (perp=7.107, rec=0.059, cos=0.004), tot_loss_proj:1.483 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.490 (perp=7.107, rec=0.065, cos=0.004), tot_loss_proj:1.484 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1800/2000] tot_loss=1.487 (perp=7.107, rec=0.061, cos=0.004), tot_loss_proj:1.484 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.490 (perp=7.107, rec=0.064, cos=0.004), tot_loss_proj:1.501 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.506 (perp=7.107, rec=0.080, cos=0.004), tot_loss_proj:1.491 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1950/2000] tot_loss=1.493 (perp=7.107, rec=0.067, cos=0.004), tot_loss_proj:1.491 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.489 (perp=7.107, rec=0.064, cos=0.004), tot_loss_proj:1.488 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] rotting underbelly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.415 | p: 87.754 | r: 89.345
rouge2     | fm: 57.843 | p: 57.482 | r: 58.320
rougeL     | fm: 78.370 | p: 77.727 | r: 79.193
rougeLsum  | fm: 78.371 | p: 77.763 | r: 79.103
r1fm+r2fm = 146.258

input #48 time: 0:12:03 | total time: 9:52:55


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9986518546882234
highest_index [0]
highest [0.9986518546882234]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.819808840751648 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.799677312374115 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7915059328079224 for ['[CLS] genetic slideactic nations shed lawrence oral like era calvin accept mentor [SEP]']
[Init] best rec loss: 0.7779895067214966 for ['[CLS] in before car lend only surprise securities radiation following montagu turkishpers [SEP]']
[Init] best rec loss: 0.7634280920028687 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best perm rec loss: 0.7592564225196838 for ['[CLS] longingify votes stopperation dawnxious branchoħ fort destructive [SEP]']
[Init] best perm rec loss: 0.7583871483802795 for ['[CLS]ifyxious longing stop voteso dawnperation branch fort destructiveħ [SEP]']
[Init] best perm rec loss: 0.7557752132415771 for ['[CLS]oxious stop dawn fort longingħ branchifyperation destructive votes [SEP]']
[Init] best perm rec loss: 0.7547162175178528 for ['[CLS] fort destructiveoxious longing dawn branchify stopperation votesħ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.173 (perp=9.591, rec=0.222, cos=0.033), tot_loss_proj:2.853 [t=0.30s]
prediction: ['[CLS] could single female. contempt of female janeiro becomes contempt moreuous [SEP]']
[ 100/2000] tot_loss=2.041 (perp=9.602, rec=0.107, cos=0.013), tot_loss_proj:2.675 [t=0.30s]
prediction: ['[CLS] possibly single population population contempt of female could be contempt moreuous [SEP]']
[ 150/2000] tot_loss=2.020 (perp=9.602, rec=0.090, cos=0.010), tot_loss_proj:2.684 [t=0.30s]
prediction: ['[CLS] possibly single population population contempt of female could be contempt moreuous [SEP]']
[ 200/2000] tot_loss=2.018 (perp=9.602, rec=0.088, cos=0.010), tot_loss_proj:2.689 [t=0.30s]
prediction: ['[CLS] possibly single population population contempt of female could be contempt moreuous [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.706 (perp=8.052, rec=0.087, cos=0.009), tot_loss_proj:2.306 [t=0.30s]
prediction: ['[CLS] possibly single population population contempt of female could be more contemptuous [SEP]']
[ 300/2000] tot_loss=1.704 (perp=8.052, rec=0.084, cos=0.010), tot_loss_proj:2.314 [t=0.30s]
prediction: ['[CLS] possibly single population population contempt of female could be more contemptuous [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.580 (perp=7.432, rec=0.085, cos=0.009), tot_loss_proj:2.153 [t=0.30s]
prediction: ['[CLS] possibly single population female contempt of population could be more contemptuous [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.571 (perp=7.393, rec=0.083, cos=0.009), tot_loss_proj:2.171 [t=0.30s]
prediction: ['[CLS] possibly single female population contempt of population could be more contemptuous [SEP]']
[ 450/2000] tot_loss=1.565 (perp=7.393, rec=0.078, cos=0.009), tot_loss_proj:2.181 [t=0.30s]
prediction: ['[CLS] possibly single female population contempt of population could be more contemptuous [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.570 (perp=7.393, rec=0.083, cos=0.008), tot_loss_proj:2.187 [t=0.30s]
prediction: ['[CLS] possibly single female population contempt of population could be more contemptuous [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.566 (perp=7.393, rec=0.079, cos=0.008), tot_loss_proj:2.182 [t=0.30s]
prediction: ['[CLS] possibly single female population contempt of population could be more contemptuous [SEP]']
[ 600/2000] tot_loss=1.565 (perp=7.393, rec=0.078, cos=0.008), tot_loss_proj:2.185 [t=0.30s]
prediction: ['[CLS] possibly single female population contempt of population could be more contemptuous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.563 (perp=7.393, rec=0.076, cos=0.008), tot_loss_proj:2.189 [t=0.30s]
prediction: ['[CLS] possibly single female population contempt of population could be more contemptuous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.559 (perp=7.393, rec=0.071, cos=0.008), tot_loss_proj:2.185 [t=0.30s]
prediction: ['[CLS] possibly single female population contempt of population could be more contemptuous [SEP]']
[ 750/2000] tot_loss=1.614 (perp=7.690, rec=0.067, cos=0.008), tot_loss_proj:2.271 [t=0.30s]
prediction: ['[CLS] possibly single female the contempt of population could be more contemptuous [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.469 (perp=6.950, rec=0.070, cos=0.009), tot_loss_proj:1.974 [t=0.30s]
prediction: ['[CLS] possibly the single female contempt of population could be more contemptuous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.472 (perp=6.950, rec=0.073, cos=0.008), tot_loss_proj:1.976 [t=0.30s]
prediction: ['[CLS] possibly the single female contempt of population could be more contemptuous [SEP]']
[ 900/2000] tot_loss=1.470 (perp=6.950, rec=0.071, cos=0.009), tot_loss_proj:1.969 [t=0.30s]
prediction: ['[CLS] possibly the single female contempt of population could be more contemptuous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.474 (perp=6.950, rec=0.075, cos=0.009), tot_loss_proj:1.971 [t=0.30s]
prediction: ['[CLS] possibly the single female contempt of population could be more contemptuous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.472 (perp=6.950, rec=0.074, cos=0.008), tot_loss_proj:1.976 [t=0.30s]
prediction: ['[CLS] possibly the single female contempt of population could be more contemptuous [SEP]']
[1050/2000] tot_loss=1.655 (perp=7.879, rec=0.071, cos=0.008), tot_loss_proj:2.276 [t=0.30s]
prediction: ['[CLS] possibly the single female contempt of population could be more ;uous [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.551 (perp=7.343, rec=0.074, cos=0.008), tot_loss_proj:2.135 [t=0.31s]
prediction: ['[CLS] possibly the single female contempt of population could beuous more. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.276 (perp=5.963, rec=0.076, cos=0.008), tot_loss_proj:1.924 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
[1200/2000] tot_loss=1.268 (perp=5.963, rec=0.069, cos=0.007), tot_loss_proj:1.922 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.275 (perp=5.963, rec=0.076, cos=0.006), tot_loss_proj:1.919 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.266 (perp=5.963, rec=0.068, cos=0.006), tot_loss_proj:1.926 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
[1350/2000] tot_loss=1.274 (perp=5.963, rec=0.075, cos=0.006), tot_loss_proj:1.923 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.261 (perp=5.963, rec=0.062, cos=0.006), tot_loss_proj:1.924 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.263 (perp=5.963, rec=0.064, cos=0.006), tot_loss_proj:1.926 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
[1500/2000] tot_loss=1.266 (perp=5.963, rec=0.069, cos=0.004), tot_loss_proj:1.930 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.262 (perp=5.963, rec=0.067, cos=0.003), tot_loss_proj:1.928 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.265 (perp=5.963, rec=0.070, cos=0.003), tot_loss_proj:1.924 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
[1650/2000] tot_loss=1.258 (perp=5.963, rec=0.062, cos=0.003), tot_loss_proj:1.924 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.263 (perp=5.963, rec=0.068, cos=0.003), tot_loss_proj:1.930 [t=0.31s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.256 (perp=5.963, rec=0.061, cos=0.003), tot_loss_proj:1.927 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
[1800/2000] tot_loss=1.266 (perp=5.963, rec=0.070, cos=0.003), tot_loss_proj:1.925 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.258 (perp=5.963, rec=0.062, cos=0.003), tot_loss_proj:1.927 [t=0.31s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.256 (perp=5.963, rec=0.061, cos=0.003), tot_loss_proj:1.920 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
[1950/2000] tot_loss=1.265 (perp=5.963, rec=0.069, cos=0.003), tot_loss_proj:1.924 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.258 (perp=5.963, rec=0.063, cos=0.003), tot_loss_proj:1.929 [t=0.30s]
prediction: ['[CLS] possibly the single female contemptuous of population could be more. [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] possibly the single female contemptuous of population could be more. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 58.333 | p: 58.333 | r: 58.333
rougeLsum  | fm: 58.333 | p: 58.333 | r: 58.333
r1fm+r2fm = 136.364

[Aggregate metrics]:
rouge1     | fm: 88.562 | p: 87.877 | r: 89.428
rouge2     | fm: 57.456 | p: 57.062 | r: 57.935
rougeL     | fm: 78.000 | p: 77.449 | r: 78.741
rougeLsum  | fm: 77.885 | p: 77.331 | r: 78.608
r1fm+r2fm = 146.018

input #49 time: 0:12:04 | total time: 10:04:59


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.9987612409235959
highest_index [0]
highest [0.9987612409235959]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.8060952425003052 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.7979437708854675 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.7946035861968994 for ['[CLS] cannon noveltyuser dino ordinance japanese deck tech alright [SEP]']
[Init] best rec loss: 0.7799516320228577 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7601026892662048 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.74761563539505 for ['[CLS] stone sex science cheeks prolific conventionwashed in once [SEP]']
[Init] best rec loss: 0.7392348051071167 for ['[CLS]sil state grade over ing fish champion woolf good [SEP]']
[Init] best perm rec loss: 0.737695574760437 for ['[CLS] state fish grade champion ing woolf goodsil over [SEP]']
[Init] best perm rec loss: 0.7371810078620911 for ['[CLS] fish woolf statesil ing champion good grade over [SEP]']
[Init] best perm rec loss: 0.7369922399520874 for ['[CLS] fish grade ing statesil woolf champion good over [SEP]']
[Init] best perm rec loss: 0.7352737784385681 for ['[CLS] champion gradesil fish over good ing state woolf [SEP]']
[Init] best perm rec loss: 0.7349147796630859 for ['[CLS] champion fish ingsil over good woolf state grade [SEP]']
[Init] best perm rec loss: 0.7347809672355652 for ['[CLS] grade champion woolf ing statesil fish over good [SEP]']
[Init] best perm rec loss: 0.7346503138542175 for ['[CLS] over grade ing fish goodsil champion state woolf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.441 (perp=10.102, rec=0.319, cos=0.102), tot_loss_proj:2.882 [t=0.30s]
prediction: ['[CLS] clever french clever part considered too are half clever [SEP]']
[ 100/2000] tot_loss=2.312 (perp=10.574, rec=0.157, cos=0.040), tot_loss_proj:3.347 [t=0.30s]
prediction: ['[CLS] clever english ` too call too by half clever [SEP]']
[ 150/2000] tot_loss=2.353 (perp=10.944, rec=0.141, cos=0.023), tot_loss_proj:3.417 [t=0.31s]
prediction: ['[CLS] clever english ` part call too by half clever [SEP]']
[ 200/2000] tot_loss=2.379 (perp=11.292, rec=0.103, cos=0.018), tot_loss_proj:3.627 [t=0.30s]
prediction: ['[CLS] clever what ` part call too by half clever [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.175 (perp=10.380, rec=0.088, cos=0.011), tot_loss_proj:2.790 [t=0.30s]
prediction: ['[CLS] what ` what clever call too by half clever [SEP]']
[ 300/2000] tot_loss=2.174 (perp=10.491, rec=0.072, cos=0.005), tot_loss_proj:2.767 [t=0.30s]
prediction: ['[CLS] what ` what english call too by half clever [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.013 (perp=9.662, rec=0.077, cos=0.004), tot_loss_proj:2.535 [t=0.30s]
prediction: ['[CLS] what ` english call too what by half clever [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.881 (perp=8.983, rec=0.080, cos=0.004), tot_loss_proj:2.523 [t=0.30s]
prediction: ['[CLS] what ` the english call too by half clever [SEP]']
[ 450/2000] tot_loss=1.875 (perp=8.983, rec=0.075, cos=0.003), tot_loss_proj:2.519 [t=0.30s]
prediction: ['[CLS] what ` the english call too by half clever [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.818 (perp=8.696, rec=0.076, cos=0.003), tot_loss_proj:2.345 [t=0.31s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.812 (perp=8.696, rec=0.070, cos=0.003), tot_loss_proj:2.348 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
[ 600/2000] tot_loss=1.802 (perp=8.696, rec=0.060, cos=0.002), tot_loss_proj:2.349 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.804 (perp=8.696, rec=0.063, cos=0.003), tot_loss_proj:2.347 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.812 (perp=8.696, rec=0.070, cos=0.003), tot_loss_proj:2.347 [t=0.31s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
[ 750/2000] tot_loss=1.803 (perp=8.696, rec=0.061, cos=0.003), tot_loss_proj:2.351 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.815 (perp=8.696, rec=0.073, cos=0.002), tot_loss_proj:2.356 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.812 (perp=8.696, rec=0.070, cos=0.002), tot_loss_proj:2.363 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
[ 900/2000] tot_loss=1.803 (perp=8.696, rec=0.061, cos=0.002), tot_loss_proj:2.360 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.810 (perp=8.696, rec=0.068, cos=0.002), tot_loss_proj:2.365 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1000/2000] tot_loss=1.802 (perp=8.696, rec=0.061, cos=0.002), tot_loss_proj:2.358 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
[1050/2000] tot_loss=1.808 (perp=8.696, rec=0.066, cos=0.002), tot_loss_proj:2.361 [t=0.31s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.818 (perp=8.696, rec=0.076, cos=0.002), tot_loss_proj:2.359 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.816 (perp=8.696, rec=0.074, cos=0.002), tot_loss_proj:2.366 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
[1200/2000] tot_loss=1.800 (perp=8.696, rec=0.059, cos=0.002), tot_loss_proj:2.363 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.820 (perp=8.696, rec=0.079, cos=0.002), tot_loss_proj:2.363 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.808 (perp=8.696, rec=0.066, cos=0.002), tot_loss_proj:2.367 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
[1350/2000] tot_loss=1.807 (perp=8.696, rec=0.065, cos=0.002), tot_loss_proj:2.355 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1400/2000] tot_loss=1.801 (perp=8.696, rec=0.059, cos=0.002), tot_loss_proj:2.373 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.794 (perp=8.696, rec=0.052, cos=0.002), tot_loss_proj:2.373 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
[1500/2000] tot_loss=1.811 (perp=8.696, rec=0.069, cos=0.002), tot_loss_proj:2.369 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.808 (perp=8.696, rec=0.067, cos=0.002), tot_loss_proj:2.363 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.806 (perp=8.696, rec=0.064, cos=0.002), tot_loss_proj:2.370 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
[1650/2000] tot_loss=1.796 (perp=8.696, rec=0.054, cos=0.002), tot_loss_proj:2.375 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1700/2000] tot_loss=1.814 (perp=8.696, rec=0.073, cos=0.002), tot_loss_proj:2.364 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1750/2000] tot_loss=1.793 (perp=8.696, rec=0.051, cos=0.002), tot_loss_proj:2.368 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
[1800/2000] tot_loss=1.796 (perp=8.696, rec=0.054, cos=0.002), tot_loss_proj:2.369 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.808 (perp=8.696, rec=0.066, cos=0.002), tot_loss_proj:2.374 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[1900/2000] tot_loss=1.802 (perp=8.696, rec=0.060, cos=0.002), tot_loss_proj:2.373 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
[1950/2000] tot_loss=1.806 (perp=8.696, rec=0.064, cos=0.002), tot_loss_proj:2.381 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.802 (perp=8.696, rec=0.060, cos=0.002), tot_loss_proj:2.371 [t=0.30s]
prediction: ['[CLS] ` what the english call too by half clever [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] ` what the english call too by half clever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 90.000 | p: 90.000 | r: 90.000
rougeLsum  | fm: 90.000 | p: 90.000 | r: 90.000
r1fm+r2fm = 166.667

[Aggregate metrics]:
rouge1     | fm: 88.900 | p: 88.223 | r: 89.697
rouge2     | fm: 57.842 | p: 57.463 | r: 58.342
rougeL     | fm: 78.341 | p: 77.781 | r: 78.987
rougeLsum  | fm: 78.239 | p: 77.709 | r: 78.837
r1fm+r2fm = 146.742

input #50 time: 0:12:05 | total time: 10:17:05


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9987254356892219
highest_index [0]
highest [0.9987254356892219]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.7849776148796082 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7778211832046509 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7520352005958557 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7291162014007568 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 0.7172408699989319 for ['[CLS] low reelection honest louis caps noah lieutenant quarter consequence handwriting [SEP]']
[Init] best rec loss: 0.713294267654419 for ['[CLS] thomas hugh anymore customer minute premises nuclear nothingnodro [SEP]']
[Init] best perm rec loss: 0.7108438611030579 for ['[CLS] nothing anymore premisesdro thomas nuclearno customer minute hugh [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.440 (perp=10.013, rec=0.326, cos=0.112), tot_loss_proj:3.558 [t=0.30s]
prediction: ['[CLS] funny had sucks some and sucks funny sucks moment funny [SEP]']
[ 100/2000] tot_loss=1.979 (perp=8.726, rec=0.198, cos=0.036), tot_loss_proj:2.840 [t=0.30s]
prediction: ['[CLS] funny has sucks some. sucks funny sucks or funny [SEP]']
[ 150/2000] tot_loss=2.038 (perp=9.324, rec=0.133, cos=0.040), tot_loss_proj:2.784 [t=0.30s]
prediction: ['[CLS] funny has sucks but a sucks moment sucks or funny [SEP]']
[ 200/2000] tot_loss=1.792 (perp=8.345, rec=0.101, cos=0.022), tot_loss_proj:2.504 [t=0.31s]
prediction: ['[CLS] funny has sucks but a little moment sucks or funny [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.732 (perp=8.105, rec=0.096, cos=0.016), tot_loss_proj:2.416 [t=0.30s]
prediction: ['[CLS] funny has sucks but a funny moment sucks or two [SEP]']
[ 300/2000] tot_loss=1.721 (perp=8.105, rec=0.087, cos=0.013), tot_loss_proj:2.407 [t=0.30s]
prediction: ['[CLS] funny has sucks but a funny moment sucks or two [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.672 (perp=7.874, rec=0.085, cos=0.012), tot_loss_proj:2.274 [t=0.30s]
prediction: ['[CLS] has funny sucks but a funny moment sucks or two [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.673 (perp=7.874, rec=0.089, cos=0.010), tot_loss_proj:2.263 [t=0.30s]
prediction: ['[CLS] has funny sucks but a funny moment sucks or two [SEP]']
[ 450/2000] tot_loss=1.675 (perp=7.874, rec=0.084, cos=0.016), tot_loss_proj:2.263 [t=0.30s]
prediction: ['[CLS] has funny sucks but a funny moment sucks or two [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.555 (perp=7.308, rec=0.082, cos=0.012), tot_loss_proj:2.314 [t=0.30s]
prediction: ['[CLS] has funny sucks but a funny moment or two sucks [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.557 (perp=7.308, rec=0.085, cos=0.010), tot_loss_proj:2.314 [t=0.31s]
prediction: ['[CLS] has funny sucks but a funny moment or two sucks [SEP]']
[ 600/2000] tot_loss=1.553 (perp=7.308, rec=0.082, cos=0.009), tot_loss_proj:2.307 [t=0.32s]
prediction: ['[CLS] has funny sucks but a funny moment or two sucks [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.544 (perp=7.308, rec=0.073, cos=0.009), tot_loss_proj:2.323 [t=0.30s]
prediction: ['[CLS] has funny sucks but a funny moment or two sucks [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.553 (perp=7.308, rec=0.083, cos=0.009), tot_loss_proj:2.308 [t=0.30s]
prediction: ['[CLS] has funny sucks but a funny moment or two sucks [SEP]']
[ 750/2000] tot_loss=1.554 (perp=7.308, rec=0.084, cos=0.009), tot_loss_proj:2.313 [t=0.31s]
prediction: ['[CLS] has funny sucks but a funny moment or two sucks [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.557 (perp=7.308, rec=0.087, cos=0.009), tot_loss_proj:2.308 [t=0.30s]
prediction: ['[CLS] has funny sucks but a funny moment or two sucks [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.556 (perp=7.308, rec=0.086, cos=0.008), tot_loss_proj:2.312 [t=0.30s]
prediction: ['[CLS] has funny sucks but a funny moment or two sucks [SEP]']
[ 900/2000] tot_loss=1.554 (perp=7.308, rec=0.084, cos=0.008), tot_loss_proj:2.308 [t=0.30s]
prediction: ['[CLS] has funny sucks but a funny moment or two sucks [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.556 (perp=7.308, rec=0.086, cos=0.008), tot_loss_proj:2.309 [t=0.30s]
prediction: ['[CLS] has funny sucks but a funny moment or two sucks [SEP]']
Attempt swap
[1000/2000] tot_loss=1.541 (perp=7.308, rec=0.072, cos=0.008), tot_loss_proj:2.314 [t=0.30s]
prediction: ['[CLS] has funny sucks but a funny moment or two sucks [SEP]']
[1050/2000] tot_loss=1.694 (perp=7.978, rec=0.090, cos=0.008), tot_loss_proj:2.625 [t=0.30s]
prediction: ['[CLS] has funny sucks but a. moment or two sucks [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.583 (perp=7.470, rec=0.084, cos=0.005), tot_loss_proj:2.190 [t=0.31s]
prediction: ['[CLS] has funny sucks but a sucks moment or two. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.328 (perp=6.202, rec=0.082, cos=0.005), tot_loss_proj:2.014 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
[1200/2000] tot_loss=1.327 (perp=6.202, rec=0.082, cos=0.005), tot_loss_proj:2.013 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.331 (perp=6.202, rec=0.086, cos=0.004), tot_loss_proj:2.009 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.317 (perp=6.202, rec=0.072, cos=0.004), tot_loss_proj:2.012 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
[1350/2000] tot_loss=1.320 (perp=6.202, rec=0.075, cos=0.004), tot_loss_proj:2.013 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.315 (perp=6.202, rec=0.070, cos=0.004), tot_loss_proj:2.017 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.317 (perp=6.202, rec=0.072, cos=0.004), tot_loss_proj:2.011 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
[1500/2000] tot_loss=1.316 (perp=6.202, rec=0.071, cos=0.004), tot_loss_proj:2.013 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.310 (perp=6.202, rec=0.065, cos=0.004), tot_loss_proj:2.013 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.322 (perp=6.202, rec=0.077, cos=0.004), tot_loss_proj:2.010 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
[1650/2000] tot_loss=1.322 (perp=6.202, rec=0.077, cos=0.005), tot_loss_proj:2.013 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.325 (perp=6.202, rec=0.080, cos=0.005), tot_loss_proj:2.009 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.316 (perp=6.202, rec=0.071, cos=0.005), tot_loss_proj:2.009 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
[1800/2000] tot_loss=1.333 (perp=6.202, rec=0.088, cos=0.005), tot_loss_proj:2.009 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.322 (perp=6.202, rec=0.077, cos=0.005), tot_loss_proj:2.012 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.328 (perp=6.202, rec=0.083, cos=0.005), tot_loss_proj:2.010 [t=0.30s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
[1950/2000] tot_loss=1.321 (perp=6.202, rec=0.076, cos=0.005), tot_loss_proj:2.013 [t=0.31s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.323 (perp=6.202, rec=0.078, cos=0.005), tot_loss_proj:2.014 [t=0.31s]
prediction: ['[CLS] has funny sucks but sucks a moment or two. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] has funny sucks but sucks a moment or two. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 42.105 | p: 40.000 | r: 44.444
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 137.343

[Aggregate metrics]:
rouge1     | fm: 88.998 | p: 88.303 | r: 89.846
rouge2     | fm: 57.478 | p: 57.083 | r: 57.951
rougeL     | fm: 78.250 | p: 77.703 | r: 79.026
rougeLsum  | fm: 78.216 | p: 77.596 | r: 78.995
r1fm+r2fm = 146.476

input #51 time: 0:12:05 | total time: 10:29:10


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.998552503295817
highest_index [0]
highest [0.998552503295817]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9771040081977844 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9017195105552673 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8699781894683838 for ['[CLS] field darkedge [SEP]']
[Init] best rec loss: 0.8679328560829163 for ['[CLS] print bubba advance [SEP]']
[Init] best rec loss: 0.8678261637687683 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.7511791586875916 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7157921195030212 for ['[CLS] vocabulary football expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.505 (perp=11.737, rec=0.150, cos=0.008), tot_loss_proj:2.724 [t=0.30s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.460 (perp=11.737, rec=0.108, cos=0.005), tot_loss_proj:2.714 [t=0.30s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.446 (perp=11.737, rec=0.095, cos=0.004), tot_loss_proj:2.712 [t=0.30s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 200/2000] tot_loss=2.186 (perp=10.491, rec=0.083, cos=0.005), tot_loss_proj:2.393 [t=0.30s]
prediction: ['[CLS] trailer trash - [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.858 (perp=8.483, rec=0.155, cos=0.006), tot_loss_proj:2.164 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.794 (perp=8.483, rec=0.094, cos=0.003), tot_loss_proj:2.136 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.770 (perp=8.483, rec=0.071, cos=0.003), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.773 (perp=8.483, rec=0.073, cos=0.003), tot_loss_proj:2.131 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.769 (perp=8.483, rec=0.069, cos=0.003), tot_loss_proj:2.133 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.769 (perp=8.483, rec=0.069, cos=0.003), tot_loss_proj:2.135 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.771 (perp=8.483, rec=0.072, cos=0.003), tot_loss_proj:2.130 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.770 (perp=8.483, rec=0.071, cos=0.003), tot_loss_proj:2.129 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.762 (perp=8.483, rec=0.062, cos=0.003), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.769 (perp=8.483, rec=0.069, cos=0.003), tot_loss_proj:2.132 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.766 (perp=8.483, rec=0.067, cos=0.003), tot_loss_proj:2.132 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.760 (perp=8.483, rec=0.060, cos=0.003), tot_loss_proj:2.130 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.778 (perp=8.483, rec=0.078, cos=0.003), tot_loss_proj:2.130 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.774 (perp=8.483, rec=0.075, cos=0.003), tot_loss_proj:2.133 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.763 (perp=8.483, rec=0.064, cos=0.003), tot_loss_proj:2.129 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.761 (perp=8.483, rec=0.061, cos=0.003), tot_loss_proj:2.138 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.772 (perp=8.483, rec=0.073, cos=0.003), tot_loss_proj:2.134 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.767 (perp=8.483, rec=0.068, cos=0.003), tot_loss_proj:2.124 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.770 (perp=8.483, rec=0.071, cos=0.003), tot_loss_proj:2.135 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.763 (perp=8.483, rec=0.064, cos=0.003), tot_loss_proj:2.128 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.763 (perp=8.483, rec=0.064, cos=0.003), tot_loss_proj:2.126 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.774 (perp=8.483, rec=0.075, cos=0.003), tot_loss_proj:2.132 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.760 (perp=8.483, rec=0.061, cos=0.003), tot_loss_proj:2.135 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.774 (perp=8.483, rec=0.075, cos=0.003), tot_loss_proj:2.130 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.759 (perp=8.483, rec=0.060, cos=0.003), tot_loss_proj:2.136 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.773 (perp=8.483, rec=0.074, cos=0.003), tot_loss_proj:2.127 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.760 (perp=8.483, rec=0.061, cos=0.003), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.762 (perp=8.483, rec=0.062, cos=0.003), tot_loss_proj:2.126 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.771 (perp=8.483, rec=0.071, cos=0.003), tot_loss_proj:2.123 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.759 (perp=8.483, rec=0.060, cos=0.003), tot_loss_proj:2.130 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.759 (perp=8.483, rec=0.059, cos=0.003), tot_loss_proj:2.118 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.758 (perp=8.483, rec=0.058, cos=0.003), tot_loss_proj:2.120 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.771 (perp=8.483, rec=0.072, cos=0.003), tot_loss_proj:2.121 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.772 (perp=8.483, rec=0.073, cos=0.003), tot_loss_proj:2.126 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.763 (perp=8.483, rec=0.064, cos=0.003), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.767 (perp=8.483, rec=0.068, cos=0.003), tot_loss_proj:2.122 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.040 | p: 88.318 | r: 89.947
rouge2     | fm: 56.173 | p: 55.844 | r: 56.720
rougeL     | fm: 78.216 | p: 77.635 | r: 78.954
rougeLsum  | fm: 78.064 | p: 77.460 | r: 78.844
r1fm+r2fm = 145.213

input #52 time: 0:12:02 | total time: 10:41:13


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9986711192966593
highest_index [0]
highest [0.9986711192966593]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.7934392094612122 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.7115171551704407 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.7077348232269287 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.7006051540374756 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.6993079781532288 for ['[CLS] el peace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.769 (perp=8.090, rec=0.135, cos=0.016), tot_loss_proj:1.700 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 100/2000] tot_loss=1.687 (perp=8.090, rec=0.065, cos=0.004), tot_loss_proj:1.694 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 150/2000] tot_loss=1.695 (perp=8.090, rec=0.074, cos=0.003), tot_loss_proj:1.714 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 200/2000] tot_loss=1.674 (perp=8.090, rec=0.054, cos=0.003), tot_loss_proj:1.711 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.688 (perp=8.090, rec=0.067, cos=0.003), tot_loss_proj:1.718 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.678 (perp=8.090, rec=0.057, cos=0.003), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.682 (perp=8.090, rec=0.061, cos=0.003), tot_loss_proj:1.702 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.681 (perp=8.090, rec=0.060, cos=0.003), tot_loss_proj:1.696 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.678 (perp=8.090, rec=0.057, cos=0.003), tot_loss_proj:1.713 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.674 (perp=8.090, rec=0.054, cos=0.003), tot_loss_proj:1.694 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.680 (perp=8.090, rec=0.059, cos=0.003), tot_loss_proj:1.700 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.682 (perp=8.090, rec=0.062, cos=0.003), tot_loss_proj:1.693 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.687 (perp=8.090, rec=0.066, cos=0.003), tot_loss_proj:1.693 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.692 (perp=8.090, rec=0.072, cos=0.003), tot_loss_proj:1.690 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.688 (perp=8.090, rec=0.068, cos=0.003), tot_loss_proj:1.700 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.688 (perp=8.090, rec=0.067, cos=0.003), tot_loss_proj:1.687 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.686 (perp=8.090, rec=0.066, cos=0.003), tot_loss_proj:1.702 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.688 (perp=8.090, rec=0.067, cos=0.003), tot_loss_proj:1.681 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.692 (perp=8.090, rec=0.071, cos=0.003), tot_loss_proj:1.699 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.685 (perp=8.090, rec=0.064, cos=0.003), tot_loss_proj:1.692 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.679 (perp=8.090, rec=0.059, cos=0.003), tot_loss_proj:1.699 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.687 (perp=8.090, rec=0.066, cos=0.003), tot_loss_proj:1.693 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.674 (perp=8.090, rec=0.054, cos=0.003), tot_loss_proj:1.697 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.687 (perp=8.090, rec=0.066, cos=0.003), tot_loss_proj:1.683 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.672 (perp=8.090, rec=0.051, cos=0.003), tot_loss_proj:1.700 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.675 (perp=8.090, rec=0.055, cos=0.003), tot_loss_proj:1.703 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.678 (perp=8.090, rec=0.058, cos=0.003), tot_loss_proj:1.690 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.694 (perp=8.090, rec=0.074, cos=0.003), tot_loss_proj:1.682 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.674 (perp=8.090, rec=0.053, cos=0.003), tot_loss_proj:1.693 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.691 (perp=8.090, rec=0.071, cos=0.003), tot_loss_proj:1.697 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.693 (perp=8.090, rec=0.072, cos=0.003), tot_loss_proj:1.679 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.684 (perp=8.090, rec=0.063, cos=0.003), tot_loss_proj:1.691 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.698 (perp=8.090, rec=0.077, cos=0.003), tot_loss_proj:1.678 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.703 (perp=8.090, rec=0.082, cos=0.003), tot_loss_proj:1.691 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.690 (perp=8.090, rec=0.069, cos=0.003), tot_loss_proj:1.687 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.675 (perp=8.090, rec=0.055, cos=0.003), tot_loss_proj:1.696 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.692 (perp=8.090, rec=0.072, cos=0.003), tot_loss_proj:1.702 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.685 (perp=8.090, rec=0.064, cos=0.003), tot_loss_proj:1.701 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.687 (perp=8.090, rec=0.066, cos=0.003), tot_loss_proj:1.711 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.691 (perp=8.090, rec=0.071, cos=0.003), tot_loss_proj:1.697 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.236 | p: 88.573 | r: 90.147
rouge2     | fm: 57.035 | p: 56.661 | r: 57.580
rougeL     | fm: 78.631 | p: 78.025 | r: 79.398
rougeLsum  | fm: 78.411 | p: 77.841 | r: 79.103
r1fm+r2fm = 146.270

input #53 time: 0:12:02 | total time: 10:53:16


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9986756241474364
highest_index [0]
highest [0.9986756241474364]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.8137179613113403 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.7601333260536194 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7467924356460571 for ['[CLS] living devices [SEP]']
[Init] best rec loss: 0.743138313293457 for ['[CLS] trinity passed [SEP]']
[Init] best rec loss: 0.7381619215011597 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 0.6957831978797913 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.6627781391143799 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.6423496603965759 for ['[CLS] delivery content [SEP]']
[Init] best rec loss: 0.6296775937080383 for ['[CLS] teresa spanish [SEP]']
[Init] best rec loss: 0.6230711340904236 for ['[CLS] wild exercised [SEP]']
[Init] best perm rec loss: 0.6212514042854309 for ['[CLS] exercised wild [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.230 (perp=9.393, rec=0.285, cos=0.067), tot_loss_proj:2.706 [t=0.30s]
prediction: ['[CLS] hot hot [SEP]']
[ 100/2000] tot_loss=1.859 (perp=8.198, rec=0.200, cos=0.019), tot_loss_proj:1.735 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=1.812 (perp=8.198, rec=0.157, cos=0.016), tot_loss_proj:1.700 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=1.812 (perp=8.198, rec=0.157, cos=0.016), tot_loss_proj:1.719 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.804 (perp=8.198, rec=0.148, cos=0.016), tot_loss_proj:1.716 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.798 (perp=8.198, rec=0.142, cos=0.016), tot_loss_proj:1.725 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.808 (perp=8.198, rec=0.152, cos=0.016), tot_loss_proj:1.732 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.790 (perp=8.198, rec=0.135, cos=0.016), tot_loss_proj:1.718 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.797 (perp=8.198, rec=0.142, cos=0.016), tot_loss_proj:1.722 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.791 (perp=8.198, rec=0.135, cos=0.016), tot_loss_proj:1.712 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.800 (perp=8.198, rec=0.144, cos=0.016), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.793 (perp=8.198, rec=0.138, cos=0.016), tot_loss_proj:1.710 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.798 (perp=8.198, rec=0.143, cos=0.016), tot_loss_proj:1.714 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.794 (perp=8.198, rec=0.139, cos=0.016), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.790 (perp=8.198, rec=0.135, cos=0.016), tot_loss_proj:1.711 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.791 (perp=8.198, rec=0.136, cos=0.016), tot_loss_proj:1.714 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.805 (perp=8.198, rec=0.150, cos=0.016), tot_loss_proj:1.719 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.798 (perp=8.198, rec=0.143, cos=0.016), tot_loss_proj:1.717 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.797 (perp=8.198, rec=0.142, cos=0.016), tot_loss_proj:1.730 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.802 (perp=8.198, rec=0.147, cos=0.016), tot_loss_proj:1.710 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.802 (perp=8.198, rec=0.146, cos=0.016), tot_loss_proj:1.711 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.795 (perp=8.198, rec=0.140, cos=0.016), tot_loss_proj:1.716 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.793 (perp=8.198, rec=0.138, cos=0.016), tot_loss_proj:1.720 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.791 (perp=8.198, rec=0.136, cos=0.016), tot_loss_proj:1.711 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.794 (perp=8.198, rec=0.139, cos=0.016), tot_loss_proj:1.725 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.792 (perp=8.198, rec=0.136, cos=0.016), tot_loss_proj:1.707 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.814 (perp=8.198, rec=0.159, cos=0.016), tot_loss_proj:1.718 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.796 (perp=8.198, rec=0.141, cos=0.016), tot_loss_proj:1.717 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.800 (perp=8.198, rec=0.145, cos=0.016), tot_loss_proj:1.722 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.787 (perp=8.198, rec=0.132, cos=0.016), tot_loss_proj:1.722 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.796 (perp=8.198, rec=0.141, cos=0.016), tot_loss_proj:1.712 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.784 (perp=8.198, rec=0.129, cos=0.016), tot_loss_proj:1.725 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.795 (perp=8.198, rec=0.139, cos=0.016), tot_loss_proj:1.716 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.791 (perp=8.198, rec=0.135, cos=0.016), tot_loss_proj:1.732 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.794 (perp=8.198, rec=0.138, cos=0.016), tot_loss_proj:1.717 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.803 (perp=8.198, rec=0.148, cos=0.016), tot_loss_proj:1.709 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.797 (perp=8.198, rec=0.142, cos=0.016), tot_loss_proj:1.733 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.795 (perp=8.198, rec=0.139, cos=0.016), tot_loss_proj:1.729 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.790 (perp=8.198, rec=0.135, cos=0.016), tot_loss_proj:1.711 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.803 (perp=8.198, rec=0.147, cos=0.016), tot_loss_proj:1.723 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.581 | p: 88.804 | r: 90.411
rouge2     | fm: 57.860 | p: 57.452 | r: 58.306
rougeL     | fm: 78.946 | p: 78.335 | r: 79.649
rougeLsum  | fm: 78.805 | p: 78.252 | r: 79.546
r1fm+r2fm = 147.441

input #54 time: 0:12:01 | total time: 11:05:17


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9986493622744403
highest_index [0]
highest [0.9986493622744403]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.8549482822418213 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.7379668951034546 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7361676692962646 for ['[CLS] fully left ideal [SEP]']
[Init] best rec loss: 0.7157452702522278 for ['[CLS] top trades events [SEP]']
[Init] best rec loss: 0.7126352787017822 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7105139493942261 for ['[CLS] holly stride post [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.018 (perp=8.924, rec=0.186, cos=0.047), tot_loss_proj:2.053 [t=0.30s]
prediction: ['[CLS] settled too easily [SEP]']
[ 100/2000] tot_loss=1.822 (perp=8.671, rec=0.083, cos=0.004), tot_loss_proj:1.810 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 150/2000] tot_loss=1.806 (perp=8.671, rec=0.069, cos=0.003), tot_loss_proj:1.805 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 200/2000] tot_loss=1.804 (perp=8.671, rec=0.066, cos=0.003), tot_loss_proj:1.818 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.803 (perp=8.671, rec=0.066, cos=0.003), tot_loss_proj:1.810 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=1.802 (perp=8.671, rec=0.065, cos=0.003), tot_loss_proj:1.810 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.799 (perp=8.671, rec=0.063, cos=0.003), tot_loss_proj:1.798 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.792 (perp=8.671, rec=0.055, cos=0.003), tot_loss_proj:1.803 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.797 (perp=8.671, rec=0.060, cos=0.003), tot_loss_proj:1.809 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.798 (perp=8.671, rec=0.061, cos=0.003), tot_loss_proj:1.803 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.789 (perp=8.671, rec=0.052, cos=0.003), tot_loss_proj:1.805 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.788 (perp=8.671, rec=0.051, cos=0.003), tot_loss_proj:1.795 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.805 (perp=8.671, rec=0.069, cos=0.003), tot_loss_proj:1.804 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.802 (perp=8.671, rec=0.065, cos=0.003), tot_loss_proj:1.796 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.794 (perp=8.671, rec=0.057, cos=0.003), tot_loss_proj:1.793 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.795 (perp=8.671, rec=0.058, cos=0.003), tot_loss_proj:1.814 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.788 (perp=8.671, rec=0.051, cos=0.003), tot_loss_proj:1.804 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.794 (perp=8.671, rec=0.057, cos=0.003), tot_loss_proj:1.807 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.792 (perp=8.671, rec=0.055, cos=0.003), tot_loss_proj:1.808 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.794 (perp=8.671, rec=0.057, cos=0.003), tot_loss_proj:1.794 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.791 (perp=8.671, rec=0.054, cos=0.003), tot_loss_proj:1.812 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.801 (perp=8.671, rec=0.064, cos=0.003), tot_loss_proj:1.801 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.794 (perp=8.671, rec=0.057, cos=0.003), tot_loss_proj:1.807 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.788 (perp=8.671, rec=0.051, cos=0.003), tot_loss_proj:1.800 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.003), tot_loss_proj:1.798 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.788 (perp=8.671, rec=0.051, cos=0.003), tot_loss_proj:1.793 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.793 (perp=8.671, rec=0.056, cos=0.003), tot_loss_proj:1.800 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.803 (perp=8.671, rec=0.066, cos=0.003), tot_loss_proj:1.789 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.801 (perp=8.671, rec=0.064, cos=0.003), tot_loss_proj:1.810 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.806 (perp=8.671, rec=0.069, cos=0.003), tot_loss_proj:1.796 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.792 (perp=8.671, rec=0.055, cos=0.003), tot_loss_proj:1.807 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.802 (perp=8.671, rec=0.065, cos=0.003), tot_loss_proj:1.808 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.793 (perp=8.671, rec=0.056, cos=0.003), tot_loss_proj:1.799 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.805 (perp=8.671, rec=0.068, cos=0.003), tot_loss_proj:1.810 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.794 (perp=8.671, rec=0.057, cos=0.003), tot_loss_proj:1.804 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.791 (perp=8.671, rec=0.055, cos=0.003), tot_loss_proj:1.816 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.795 (perp=8.671, rec=0.058, cos=0.003), tot_loss_proj:1.802 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.782 (perp=8.671, rec=0.045, cos=0.003), tot_loss_proj:1.805 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.796 (perp=8.671, rec=0.059, cos=0.003), tot_loss_proj:1.797 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.803 (perp=8.671, rec=0.066, cos=0.003), tot_loss_proj:1.797 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.758 | p: 89.082 | r: 90.616
rouge2     | fm: 58.707 | p: 58.413 | r: 59.089
rougeL     | fm: 79.378 | p: 78.762 | r: 80.078
rougeLsum  | fm: 79.327 | p: 78.782 | r: 80.029
r1fm+r2fm = 148.465

input #55 time: 0:12:02 | total time: 11:17:20


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.9985746644588013
highest_index [0]
highest [0.9985746644588013]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.8440077900886536 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.8361331224441528 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.8254939317703247 for ['[CLS] gu listgnant brave xavier jenna lady behalf file productions experienced charmvah everything law commander shorts inner matchesonal boot [SEP]']
[Init] best rec loss: 0.8252482414245605 for ['[CLS]tur secondary sitting accident ked sul woman professor ever signatures exercise daylor blackness photographicmind mechanics jerked gel. interiors [SEP]']
[Init] best rec loss: 0.8130844831466675 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 0.8118360638618469 for ['[CLS] reflection determined en laid backed bear tis technique strike sense unfortunatelyured blame avid code ; sympathy iron depression charter k [SEP]']
[Init] best perm rec loss: 0.8117840886116028 for ['[CLS] sense tis depression enured bear unfortunately ; determined blame reflection k laid avid backed sympathy strike charter iron technique code [SEP]']
[Init] best perm rec loss: 0.8111396431922913 for ['[CLS] avid ; reflection iron technique laid tis strike sense k depressionured backed en bear charter determined sympathy blame unfortunately code [SEP]']
[Init] best perm rec loss: 0.8102567791938782 for ['[CLS] enured sense bear depression code iron reflection sympathy blame laid k strike tis charter determined technique unfortunately ; avid backed [SEP]']
[Init] best perm rec loss: 0.8095529079437256 for ['[CLS] bear laid charter sense blame unfortunatelyured reflection determined strike k technique iron ; sympathy tis avid depression code en backed [SEP]']
[Init] best perm rec loss: 0.8069464564323425 for ['[CLS] unfortunately backed code technique avid determined k sense strike sympathy charter ;ured blame laid depression en tis bear iron reflection [SEP]']
[Init] best perm rec loss: 0.8033913373947144 for ['[CLS] reflection ; bear unfortunately determined ironured backed charter laid depression code en tis k sense technique sympathy blame avid strike [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.742 (perp=12.260, rec=0.270, cos=0.021), tot_loss_proj:3.305 [t=0.31s]
prediction: ['[CLS] whattreending damage creek 15 damage of damage fewer without decades equals damn million damage pack costly analysis months films [SEP]']
[ 100/2000] tot_loss=2.320 (perp=10.610, rec=0.190, cos=0.008), tot_loss_proj:2.890 [t=0.31s]
prediction: ['[CLS] which films suffering costly creek cause damage which damage puttingpara loadsasurable to years damage that costly analysis never films [SEP]']
[ 150/2000] tot_loss=2.381 (perp=11.138, rec=0.147, cos=0.007), tot_loss_proj:2.963 [t=0.31s]
prediction: ['[CLS] which films years costly load cause damage of fix fixpara loads seems could years damage that costly analysis never films [SEP]']
[ 200/2000] tot_loss=2.350 (perp=11.101, rec=0.125, cos=0.005), tot_loss_proj:2.855 [t=0.31s]
prediction: ['[CLS] which films years costly will cause damage of fix fixpara loads irpara years damage that costly analysis never films [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.383 (perp=10.643, rec=0.241, cos=0.014), tot_loss_proj:2.703 [t=0.31s]
prediction: ['[CLS] which loads of costly will cause damage of fix fixpara films irpara years damage that costly analysis never films [SEP]']
[ 300/2000] tot_loss=2.180 (perp=10.137, rec=0.147, cos=0.005), tot_loss_proj:2.587 [t=0.31s]
prediction: ['[CLS] which loads of costly will cause damage of fix futurepara costly might century years damage that costly analysis never films [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.309 (perp=10.875, rec=0.129, cos=0.005), tot_loss_proj:2.818 [t=0.31s]
prediction: ['[CLS] which loads ir costly will cause might of fix whenpara films damage as years damage that costly analysis never films [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.177 (perp=10.314, rec=0.109, cos=0.004), tot_loss_proj:2.634 [t=0.31s]
prediction: ['[CLS] which films ir costly will cause might of fix fixpara loads damage and years damage that costly analysis never films [SEP]']
[ 450/2000] tot_loss=2.183 (perp=10.314, rec=0.116, cos=0.004), tot_loss_proj:2.629 [t=0.31s]
prediction: ['[CLS] which films ir costly will cause might of fix fixpara loads damage and years damage that costly analysis never films [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.125 (perp=10.122, rec=0.097, cos=0.004), tot_loss_proj:2.570 [t=0.31s]
prediction: ['[CLS] which ir costly films will cause might of fix fixpara loads damage and years damage that costly analysis never films [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.033 (perp=9.628, rec=0.102, cos=0.005), tot_loss_proj:2.668 [t=0.31s]
prediction: ['[CLS] which ir ir films will cause might of loads fixparable damage and years damage that costly analysis never films [SEP]']
[ 600/2000] tot_loss=1.939 (perp=9.194, rec=0.096, cos=0.004), tot_loss_proj:2.373 [t=0.31s]
prediction: ['[CLS] which ir costly films will cause might of loads fixparable damage and years damage that costly analysis never films [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.859 (perp=8.820, rec=0.092, cos=0.004), tot_loss_proj:2.278 [t=0.31s]
prediction: ['[CLS] which ir costly films will cause might of loads fixparable damage and years damage that costly films never analysis [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.753 (perp=8.239, rec=0.102, cos=0.004), tot_loss_proj:2.124 [t=0.31s]
prediction: ['[CLS] which ir costly films will cause might loads fixparable damage and years of damage that costly films never analysis [SEP]']
[ 750/2000] tot_loss=1.740 (perp=8.239, rec=0.089, cos=0.004), tot_loss_proj:2.115 [t=0.31s]
prediction: ['[CLS] which ir costly films will cause might loads fixparable damage and years of damage that costly films never analysis [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.701 (perp=8.060, rec=0.086, cos=0.004), tot_loss_proj:2.133 [t=0.31s]
prediction: ['[CLS] which ir costly films will cause might fixparable damage and loads years of damage that costly films never analysis [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.825 (perp=8.644, rec=0.091, cos=0.004), tot_loss_proj:2.276 [t=0.31s]
prediction: ['[CLS] which costly ے will cause ir might fixparable damage and loads years of damage that costly films never analysis [SEP]']
[ 900/2000] tot_loss=1.674 (perp=7.887, rec=0.093, cos=0.004), tot_loss_proj:2.099 [t=0.31s]
prediction: ['[CLS] which costly films will cause ir might fixparable damage and loads years of damage that costly films never analysis [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.677 (perp=7.920, rec=0.089, cos=0.004), tot_loss_proj:2.354 [t=0.31s]
prediction: ['[CLS] which ir films will cause might fix irparable damage and loads years of damage that costly films never analysis [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.647 (perp=7.806, rec=0.082, cos=0.004), tot_loss_proj:2.209 [t=0.31s]
prediction: ['[CLS] ir which films will cause might fix irparable damage and loads years of damage that costly films never analysis [SEP]']
[1050/2000] tot_loss=1.668 (perp=7.865, rec=0.091, cos=0.004), tot_loss_proj:2.349 [t=0.31s]
prediction: ['[CLS] of which films will cause might fix irparable damage and loads years of damage that costly films never analysis [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.806 (perp=8.550, rec=0.093, cos=0.004), tot_loss_proj:2.429 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and loads ir years of damage that costly films never analysis [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.669 (perp=7.875, rec=0.090, cos=0.004), tot_loss_proj:2.344 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and ir loads years of damage that costly films never analysis [SEP]']
[1200/2000] tot_loss=1.662 (perp=7.875, rec=0.083, cos=0.004), tot_loss_proj:2.341 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and ir loads years of damage that costly films never analysis [SEP]']
Attempt swap
[1250/2000] tot_loss=1.654 (perp=7.875, rec=0.075, cos=0.004), tot_loss_proj:2.342 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and ir loads years of damage that costly films never analysis [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.580 (perp=7.460, rec=0.085, cos=0.004), tot_loss_proj:2.273 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and loads years of damage that of costly films never analysis [SEP]']
[1350/2000] tot_loss=1.668 (perp=7.913, rec=0.082, cos=0.004), tot_loss_proj:2.277 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and loads years of damage that ir costly films never analysis [SEP]']
Attempt swap
[1400/2000] tot_loss=1.575 (perp=7.460, rec=0.079, cos=0.004), tot_loss_proj:2.277 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and loads years of damage that of costly films never analysis [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.510 (perp=7.094, rec=0.087, cos=0.004), tot_loss_proj:1.991 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
[1500/2000] tot_loss=1.504 (perp=7.094, rec=0.081, cos=0.004), tot_loss_proj:1.996 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
Attempt swap
[1550/2000] tot_loss=1.505 (perp=7.094, rec=0.083, cos=0.004), tot_loss_proj:1.992 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
Attempt swap
[1600/2000] tot_loss=1.509 (perp=7.094, rec=0.086, cos=0.004), tot_loss_proj:1.987 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
[1650/2000] tot_loss=1.507 (perp=7.094, rec=0.084, cos=0.004), tot_loss_proj:1.990 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
Attempt swap
[1700/2000] tot_loss=1.502 (perp=7.094, rec=0.080, cos=0.004), tot_loss_proj:1.991 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
Attempt swap
[1750/2000] tot_loss=1.505 (perp=7.094, rec=0.083, cos=0.004), tot_loss_proj:1.993 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
[1800/2000] tot_loss=1.501 (perp=7.094, rec=0.078, cos=0.004), tot_loss_proj:1.990 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
Attempt swap
[1850/2000] tot_loss=1.506 (perp=7.094, rec=0.084, cos=0.004), tot_loss_proj:1.986 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
Attempt swap
[1900/2000] tot_loss=1.504 (perp=7.094, rec=0.082, cos=0.004), tot_loss_proj:1.990 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
[1950/2000] tot_loss=1.503 (perp=7.094, rec=0.080, cos=0.004), tot_loss_proj:1.993 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
Attempt swap
[2000/2000] tot_loss=1.511 (perp=7.094, rec=0.089, cos=0.004), tot_loss_proj:1.995 [t=0.31s]
prediction: ['[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] which films will cause might fix irparable damage and that years of damage loads of costly films never analysis [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.927 | p: 80.952 | r: 85.000
rouge2     | fm: 25.641 | p: 25.000 | r: 26.316
rougeL     | fm: 53.659 | p: 52.381 | r: 55.000
rougeLsum  | fm: 53.659 | p: 52.381 | r: 55.000
r1fm+r2fm = 108.568

[Aggregate metrics]:
rouge1     | fm: 89.564 | p: 88.861 | r: 90.442
rouge2     | fm: 58.091 | p: 57.658 | r: 58.615
rougeL     | fm: 78.807 | p: 78.200 | r: 79.607
rougeLsum  | fm: 78.796 | p: 78.248 | r: 79.495
r1fm+r2fm = 147.654

input #56 time: 0:12:23 | total time: 11:29:43


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.99889543492149
highest_index [0]
highest [0.99889543492149]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8815224170684814 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.7533212900161743 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.6915763020515442 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6893391013145447 for ['[CLS] modern [SEP]']
[Init] best rec loss: 0.687756359577179 for ['[CLS] himself [SEP]']
[Init] best rec loss: 0.679951012134552 for ['[CLS] decision [SEP]']
[Init] best rec loss: 0.6783899664878845 for ['[CLS] dorm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.566 (perp=12.283, rec=0.093, cos=0.017), tot_loss_proj:2.530 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.521 (perp=12.283, rec=0.057, cos=0.007), tot_loss_proj:2.522 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.531 (perp=12.283, rec=0.070, cos=0.005), tot_loss_proj:2.526 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.520 (perp=12.283, rec=0.062, cos=0.002), tot_loss_proj:2.531 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.524 (perp=12.283, rec=0.065, cos=0.002), tot_loss_proj:2.528 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.519 (perp=12.283, rec=0.061, cos=0.002), tot_loss_proj:2.525 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.515 (perp=12.283, rec=0.056, cos=0.002), tot_loss_proj:2.509 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.531 (perp=12.283, rec=0.073, cos=0.002), tot_loss_proj:2.518 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.524 (perp=12.283, rec=0.065, cos=0.002), tot_loss_proj:2.522 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.523 (perp=12.283, rec=0.065, cos=0.002), tot_loss_proj:2.519 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.510 (perp=12.283, rec=0.052, cos=0.002), tot_loss_proj:2.527 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.501 (perp=12.283, rec=0.042, cos=0.002), tot_loss_proj:2.501 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.523 (perp=12.283, rec=0.065, cos=0.002), tot_loss_proj:2.508 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.509 (perp=12.283, rec=0.050, cos=0.002), tot_loss_proj:2.510 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.517 (perp=12.283, rec=0.059, cos=0.002), tot_loss_proj:2.532 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.509 (perp=12.283, rec=0.051, cos=0.002), tot_loss_proj:2.524 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.501 (perp=12.283, rec=0.043, cos=0.002), tot_loss_proj:2.521 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.520 (perp=12.283, rec=0.062, cos=0.002), tot_loss_proj:2.515 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.519 (perp=12.283, rec=0.060, cos=0.002), tot_loss_proj:2.518 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.533 (perp=12.283, rec=0.075, cos=0.002), tot_loss_proj:2.508 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.515 (perp=12.283, rec=0.056, cos=0.002), tot_loss_proj:2.524 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.521 (perp=12.283, rec=0.062, cos=0.002), tot_loss_proj:2.528 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.524 (perp=12.283, rec=0.065, cos=0.002), tot_loss_proj:2.522 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.530 (perp=12.283, rec=0.072, cos=0.002), tot_loss_proj:2.527 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.518 (perp=12.283, rec=0.059, cos=0.002), tot_loss_proj:2.522 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.512 (perp=12.283, rec=0.053, cos=0.002), tot_loss_proj:2.515 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.528 (perp=12.283, rec=0.069, cos=0.002), tot_loss_proj:2.513 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.502 (perp=12.283, rec=0.043, cos=0.002), tot_loss_proj:2.522 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.505 (perp=12.283, rec=0.046, cos=0.002), tot_loss_proj:2.525 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.511 (perp=12.283, rec=0.052, cos=0.002), tot_loss_proj:2.520 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.515 (perp=12.283, rec=0.056, cos=0.002), tot_loss_proj:2.517 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.531 (perp=12.283, rec=0.072, cos=0.002), tot_loss_proj:2.522 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.508 (perp=12.283, rec=0.049, cos=0.002), tot_loss_proj:2.531 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.526 (perp=12.283, rec=0.067, cos=0.002), tot_loss_proj:2.519 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.519 (perp=12.283, rec=0.060, cos=0.002), tot_loss_proj:2.512 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.514 (perp=12.283, rec=0.055, cos=0.002), tot_loss_proj:2.521 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.516 (perp=12.283, rec=0.057, cos=0.002), tot_loss_proj:2.519 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.518 (perp=12.283, rec=0.059, cos=0.002), tot_loss_proj:2.540 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.524 (perp=12.283, rec=0.065, cos=0.002), tot_loss_proj:2.532 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.528 (perp=12.283, rec=0.069, cos=0.002), tot_loss_proj:2.527 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.731 | p: 89.048 | r: 90.595
rouge2     | fm: 58.746 | p: 58.394 | r: 59.187
rougeL     | fm: 79.264 | p: 78.675 | r: 80.011
rougeLsum  | fm: 79.218 | p: 78.606 | r: 79.977
r1fm+r2fm = 148.477

input #57 time: 0:11:02 | total time: 11:40:46


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9987726512887476
highest_index [0]
highest [0.9987726512887476]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.018049955368042 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9864166975021362 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9772456884384155 for ['[CLS] things reggie on guinnessllet continue special the chan (ness grew prone moffatockshire [SEP]']
[Init] best rec loss: 0.9731562733650208 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.970122218132019 for ['[CLS]mon recorded govt bolsheviks iv ignited countymetricual helmet army £100 continuedbanes recognition [SEP]']
[Init] best rec loss: 0.960810661315918 for ['[CLS] partner kickoff message oh hills edge wind mono stainless few sk closet clay fair ole port [SEP]']
[Init] best rec loss: 0.9603291153907776 for ['[CLS] ) after rca adventures / yong beat bad http stoodagendingple ]erson trailing [SEP]']
[Init] best rec loss: 0.9601947665214539 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.9566650390625 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.932532548904419 for ['[CLS] charms status minutes residency automatic marlon career signsburg henderson leaves future conflicting everdict route [SEP]']
[Init] best perm rec loss: 0.9301068186759949 for ['[CLS]dict residencysburg conflicting status charms sign ever henderson future minutes career automatic leaves marlon route [SEP]']
[Init] best perm rec loss: 0.9284023642539978 for ['[CLS] charms future status automatic conflictingsburg sign leaves minutes marlon career henderson routedict residency ever [SEP]']
[Init] best perm rec loss: 0.9283549785614014 for ['[CLS] future minutes ever sign henderson automatic leaves marlon route status conflictingsburgdict charms residency career [SEP]']
[Init] best perm rec loss: 0.9260947108268738 for ['[CLS]dict conflicting charms status route automaticsburg leaves marlon ever career minutes henderson sign residency future [SEP]']
[Init] best perm rec loss: 0.924405574798584 for ['[CLS]sburg futuredict leaves career minutes conflicting henderson sign residency ever status charms route marlon automatic [SEP]']
[Init] best perm rec loss: 0.924386203289032 for ['[CLS] conflicting automaticdict minutes ever future charms henderson leaves statussburg route residency marlon sign career [SEP]']
[Init] best perm rec loss: 0.9242421388626099 for ['[CLS] charms status sign residencysburg conflicting ever automatic henderson leaves marlondict minutes future route career [SEP]']
[Init] best perm rec loss: 0.9240967631340027 for ['[CLS] ever status future signdict automatic route marlon conflicting leaves charms careersburg minutes residency henderson [SEP]']
[Init] best perm rec loss: 0.922288715839386 for ['[CLS] career residency automaticdict ever sign conflicting status leaves henderson minutes routesburg marlon charms future [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.522 (perp=14.250, rec=0.459, cos=0.213), tot_loss_proj:3.963 [t=0.31s]
prediction: ['[CLS] met cheek culture holden battlefield honey museum deep beautiful shifter powered garrett appreciate visual just lena [SEP]']
[ 100/2000] tot_loss=3.054 (perp=12.308, rec=0.360, cos=0.233), tot_loss_proj:3.641 [t=0.31s]
prediction: ['[CLS] sera sanctuary based alexia guerrilla through life. beautiful creature powered richard appreciate " just lena [SEP]']
[ 150/2000] tot_loss=3.016 (perp=12.461, rec=0.325, cos=0.199), tot_loss_proj:3.648 [t=0.31s]
prediction: ['[CLS] sera sanctuary concept undefeated guerrilla an life. innocence creature inspirational olivia appreciate that just on [SEP]']
[ 200/2000] tot_loss=2.973 (perp=12.354, rec=0.275, cos=0.226), tot_loss_proj:4.048 [t=0.31s]
prediction: ['[CLS] sera sanctuary hydroelectric undefeated guerrilla an story. innocence story inspirational ivy literacy of just that [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.637 (perp=10.724, rec=0.256, cos=0.236), tot_loss_proj:3.960 [t=0.31s]
prediction: ['[CLS] seraanybians undefeated years love story of innocence story inspirational ivy contenders. just that [SEP]']
[ 300/2000] tot_loss=2.715 (perp=11.226, rec=0.243, cos=0.226), tot_loss_proj:3.721 [t=0.31s]
prediction: ['[CLS] endangeredany genes undefeated years inspirational story of innocence story inspirational ivy contenders the of that [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.709 (perp=11.265, rec=0.237, cos=0.219), tot_loss_proj:3.593 [t=0.31s]
prediction: ['[CLS] endangeredany genestures years inspirational story screen innocence story capturing that contenders, of ivy [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.920 (perp=12.206, rec=0.233, cos=0.246), tot_loss_proj:3.361 [t=0.31s]
prediction: ['[CLS] argument tales passion august years inspirational story screen innocence the capturing successfully contenders story with ivy [SEP]']
[ 450/2000] tot_loss=2.692 (perp=11.239, rec=0.215, cos=0.230), tot_loss_proj:3.040 [t=0.31s]
prediction: ['[CLS] argument is passion august years inspirational story screen innocence the capturing successfully is story with ivy [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.365 (perp=9.542, rec=0.224, cos=0.232), tot_loss_proj:2.590 [t=0.31s]
prediction: ['[CLS] argument is passion august years inspirational story of capturing the innocence which numerous story with ivy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.385 (perp=9.617, rec=0.220, cos=0.241), tot_loss_proj:3.373 [t=0.31s]
prediction: ['[CLS] argument is passion august years inspirational story earth capturing the innocence story is identical with ivy [SEP]']
[ 600/2000] tot_loss=2.514 (perp=10.245, rec=0.214, cos=0.251), tot_loss_proj:3.554 [t=0.31s]
prediction: ['[CLS] argument is passion zoe years inspirational story earth capturing the innocence story is identical with duration [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.473 (perp=10.135, rec=0.214, cos=0.232), tot_loss_proj:3.512 [t=0.31s]
prediction: ['[CLS] argument is passion push story inspirational story earth is the innocence any is successfully with duration [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.449 (perp=10.035, rec=0.220, cos=0.223), tot_loss_proj:2.958 [t=0.31s]
prediction: ['[CLS]rb is passion endurance years inspirational story of is the innocence story numerous successfully with ivy [SEP]']
[ 750/2000] tot_loss=2.278 (perp=9.153, rec=0.204, cos=0.244), tot_loss_proj:3.001 [t=0.31s]
prediction: ['[CLS] emerging is passion endurance any inspirational story of is the innocence story is successfully with duration [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.407 (perp=9.830, rec=0.197, cos=0.243), tot_loss_proj:3.196 [t=0.31s]
prediction: ['[CLS] emerging is passion of endurance any inspirational story is the innocence innocenceurai successfully with duration [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.536 (perp=10.431, rec=0.204, cos=0.246), tot_loss_proj:3.640 [t=0.31s]
prediction: ['[CLS] emerging is passion endurance any inspirational story is the innocence screen innocenceurai basis with duration [SEP]']
[ 900/2000] tot_loss=2.284 (perp=9.140, rec=0.204, cos=0.252), tot_loss_proj:3.289 [t=0.31s]
prediction: ['[CLS] emerging is passion endurance any inspirational story is the innocence of innocenceurai basis with duration [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.332 (perp=9.445, rec=0.197, cos=0.246), tot_loss_proj:3.289 [t=0.31s]
prediction: ['[CLS] properties passion is endurance any inspirational story is the capturing of innocenceurai basis with duration [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.272 (perp=9.126, rec=0.203, cos=0.244), tot_loss_proj:3.169 [t=0.31s]
prediction: ['[CLS] musik passion is endurance any inspirational story is the capturing of innocenceuring properties with duration [SEP]']
[1050/2000] tot_loss=2.209 (perp=8.809, rec=0.197, cos=0.250), tot_loss_proj:3.246 [t=0.31s]
prediction: ['[CLS] basis passion is endurance any inspirational story is the capturing of innocenceuring properties of duration [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.169 (perp=8.560, rec=0.202, cos=0.255), tot_loss_proj:3.220 [t=0.31s]
prediction: ['[CLS] musik passion is capturing any inspirational story is the endurance of innocenceuring properties of duration [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.134 (perp=8.421, rec=0.199, cos=0.252), tot_loss_proj:3.175 [t=0.31s]
prediction: ['[CLS] passion musik is capturing any inspirational story is the endurance of innocenceuring properties of duration [SEP]']
[1200/2000] tot_loss=2.127 (perp=8.421, rec=0.190, cos=0.253), tot_loss_proj:3.176 [t=0.31s]
prediction: ['[CLS] passion musik is capturing any inspirational story is the endurance of innocenceuring properties of duration [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.078 (perp=8.175, rec=0.202, cos=0.241), tot_loss_proj:3.092 [t=0.31s]
prediction: ['[CLS] endurance musik is capturing any inspirational story is the passion of innocenceuring innocence of duration [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.206 (perp=8.763, rec=0.198, cos=0.255), tot_loss_proj:3.232 [t=0.31s]
prediction: ['[CLS] endurance musik is capturing any inspirational story is the passion of innocence of propertiesuring forewings [SEP]']
[1350/2000] tot_loss=2.172 (perp=8.627, rec=0.191, cos=0.255), tot_loss_proj:3.215 [t=0.31s]
prediction: ['[CLS] endurance musik is capturing any inspirational story is the passion of innocence of propertiesuring duration [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.084 (perp=8.175, rec=0.191, cos=0.258), tot_loss_proj:3.095 [t=0.31s]
prediction: ['[CLS] endurance musik is capturing any inspirational story is the passion of innocenceuring innocence of duration [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.121 (perp=8.375, rec=0.191, cos=0.255), tot_loss_proj:3.131 [t=0.31s]
prediction: ['[CLS] endurance musik is capturing any inspirational story is the innocence of innocence award passion of duration [SEP]']
[1500/2000] tot_loss=2.119 (perp=8.375, rec=0.188, cos=0.256), tot_loss_proj:3.130 [t=0.31s]
prediction: ['[CLS] endurance musik is capturing any inspirational story is the innocence of innocence award passion of duration [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.334 (perp=9.442, rec=0.191, cos=0.255), tot_loss_proj:3.293 [t=0.31s]
prediction: ['[CLS] endurance pulitzer is capturing any inspirational story is the innocence of innocence musik passion of forewings [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.188 (perp=8.664, rec=0.195, cos=0.260), tot_loss_proj:3.190 [t=0.31s]
prediction: ['[CLS] endurance pulitzer is capturing any inspirational story is the innocence of innocence of passion musik forewings [SEP]']
[1650/2000] tot_loss=2.025 (perp=7.874, rec=0.191, cos=0.259), tot_loss_proj:3.005 [t=0.31s]
prediction: ['[CLS] endurance award is capturing any inspirational story is the innocence of innocence of passion musik forewings [SEP]']
Attempt swap
[1700/2000] tot_loss=2.021 (perp=7.874, rec=0.188, cos=0.258), tot_loss_proj:3.006 [t=0.31s]
prediction: ['[CLS] endurance award is capturing any inspirational story is the innocence of innocence of passion musik forewings [SEP]']
Attempt swap
[1750/2000] tot_loss=2.021 (perp=7.874, rec=0.187, cos=0.259), tot_loss_proj:3.005 [t=0.31s]
prediction: ['[CLS] endurance award is capturing any inspirational story is the innocence of innocence of passion musik forewings [SEP]']
[1800/2000] tot_loss=2.026 (perp=7.874, rec=0.191, cos=0.260), tot_loss_proj:3.009 [t=0.31s]
prediction: ['[CLS] endurance award is capturing any inspirational story is the innocence of innocence of passion musik forewings [SEP]']
Attempt swap
[1850/2000] tot_loss=2.033 (perp=7.874, rec=0.198, cos=0.261), tot_loss_proj:3.005 [t=0.31s]
prediction: ['[CLS] endurance award is capturing any inspirational story is the innocence of innocence of passion musik forewings [SEP]']
Attempt swap
[1900/2000] tot_loss=2.014 (perp=7.874, rec=0.179, cos=0.260), tot_loss_proj:3.009 [t=0.31s]
prediction: ['[CLS] endurance award is capturing any inspirational story is the innocence of innocence of passion musik forewings [SEP]']
[1950/2000] tot_loss=2.027 (perp=7.874, rec=0.193, cos=0.259), tot_loss_proj:3.008 [t=0.31s]
prediction: ['[CLS] endurance award is capturing any inspirational story is the innocence of innocence of passion musik forewings [SEP]']
Attempt swap
[2000/2000] tot_loss=2.015 (perp=7.874, rec=0.182, cos=0.258), tot_loss_proj:3.007 [t=0.31s]
prediction: ['[CLS] endurance award is capturing any inspirational story is the innocence of innocence of passion musik forewings [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] endurance award is capturing any inspirational story is the innocence of innocence of passion musik forewings [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 52.941 | p: 50.000 | r: 56.250
rouge2     | fm: 6.250 | p: 5.882 | r: 6.667
rougeL     | fm: 47.059 | p: 44.444 | r: 50.000
rougeLsum  | fm: 47.059 | p: 44.444 | r: 50.000
r1fm+r2fm = 59.191

[Aggregate metrics]:
rouge1     | fm: 89.188 | p: 88.465 | r: 90.010
rouge2     | fm: 57.803 | p: 57.489 | r: 58.268
rougeL     | fm: 78.619 | p: 77.953 | r: 79.396
rougeLsum  | fm: 78.637 | p: 77.993 | r: 79.379
r1fm+r2fm = 146.991

input #58 time: 0:12:20 | total time: 11:53:06


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9986847760159663
highest_index [0]
highest [0.9986847760159663]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.8775243163108826 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.8582960367202759 for ['[CLS] poll dominance intine drop silvertock politician wrappedve complete hot reading team disco world [SEP]']
[Init] best rec loss: 0.847426176071167 for ['[CLS] mala minute theory mandatory stands after mere figure number roth sister locomotives bombay bavarian late athlete [SEP]']
[Init] best rec loss: 0.8369370102882385 for ['[CLS]notes urban shape atliest not filterae titled making prize wait sex ste front coach [SEP]']
[Init] best rec loss: 0.8260559439659119 for ['[CLS] key stafforddial done colony midst kmdden face ɾord muscle warning ( wife organic [SEP]']
[Init] best rec loss: 0.8253487944602966 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.8223250508308411 for ['[CLS] fk saint metric cement joining empire honda western detailpi ) underground marek solvent quad reed [SEP]']
[Init] best rec loss: 0.8099204897880554 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best perm rec loss: 0.809537947177887 for ['[CLS] husbands replacedser heart semifinalsgnı cook exclusive ation interviewed weof mumenity [SEP]']
[Init] best perm rec loss: 0.8091669082641602 for ['[CLS] exclusive heartof husbands we mumgn at semifinals interviewedenityıionser replaced cook [SEP]']
[Init] best perm rec loss: 0.8084409236907959 for ['[CLS]serion husbandsgnenity heart cook semifinals interviewed exclusiveof mum replaced we atı [SEP]']
[Init] best perm rec loss: 0.8079758882522583 for ['[CLS]ion heartı we cook husbands replaced mum interviewedser semifinalsenity atofgn exclusive [SEP]']
[Init] best perm rec loss: 0.8075239658355713 for ['[CLS]ser exclusive interviewed we cookenityion husbandsgn semifinalsof mum replacedı at heart [SEP]']
[Init] best perm rec loss: 0.807411789894104 for ['[CLS] replaced we exclusive heartion cook at semifinalsıgn interviewed mumserenityof husbands [SEP]']
[Init] best perm rec loss: 0.8064160943031311 for ['[CLS] mum husbands replaced cookionı heart we interviewedgn semifinalsenityser exclusive atof [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.999 (perp=11.463, rec=0.451, cos=0.256), tot_loss_proj:3.837 [t=0.31s]
prediction: ['[CLS] : gives track currently boyscha will breathing heaven a who year can canada karnatakatan [SEP]']
[ 100/2000] tot_loss=3.315 (perp=13.348, rec=0.396, cos=0.249), tot_loss_proj:4.369 [t=0.31s]
prediction: ['[CLS] has char woman roller factor rawism between folded a who books woman february australianism [SEP]']
[ 150/2000] tot_loss=2.635 (perp=10.651, rec=0.320, cos=0.185), tot_loss_proj:3.962 [t=0.31s]
prediction: ['[CLS] has the woman type stuff ancient knows whether how a whoally woman screen goldenism [SEP]']
[ 200/2000] tot_loss=3.056 (perp=12.650, rec=0.314, cos=0.212), tot_loss_proj:4.392 [t=0.31s]
prediction: ['[CLS] has char woman type stuff the knows whether screen a whoallyism women awardsism [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.013 (perp=12.213, rec=0.328, cos=0.243), tot_loss_proj:4.257 [t=0.31s]
prediction: ['[CLS]ally simply woman type lying char knew whether bride a who hasism girl pulitzerism [SEP]']
[ 300/2000] tot_loss=2.628 (perp=10.426, rec=0.265, cos=0.277), tot_loss_proj:3.826 [t=0.31s]
prediction: ['[CLS]ally one woman the lying char knows whether how a who hasism screen easyism [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.448 (perp=9.971, rec=0.248, cos=0.206), tot_loss_proj:3.742 [t=0.31s]
prediction: ['[CLS]ally his woman the lie char knows how how sar who hasism screen a screen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.691 (perp=10.779, rec=0.293, cos=0.242), tot_loss_proj:3.303 [t=0.31s]
prediction: ['[CLS]ally char woman the science char knows how screen nobel who has of screen a screen [SEP]']
[ 450/2000] tot_loss=2.801 (perp=11.558, rec=0.224, cos=0.265), tot_loss_proj:3.451 [t=0.31s]
prediction: ['[CLS]ally stevie woman the science char knows how screen nobel who has of screen a screen [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.566 (perp=10.493, rec=0.222, cos=0.245), tot_loss_proj:3.757 [t=0.31s]
prediction: ['[CLS]iful screen woman the science char knows how stevie shake who has of screen a screen [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.312 (perp=9.245, rec=0.214, cos=0.249), tot_loss_proj:2.894 [t=0.31s]
prediction: ['[CLS] screen screen woman the science char knows how of screen stevie hold who has a screen [SEP]']
[ 600/2000] tot_loss=2.342 (perp=9.352, rec=0.205, cos=0.267), tot_loss_proj:3.399 [t=0.31s]
prediction: ['[CLS] screen screen woman the science char knows who of screen stevie hold who has a screen [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.333 (perp=9.209, rec=0.217, cos=0.273), tot_loss_proj:3.227 [t=0.31s]
prediction: ['[CLS] screen woman the science char screen knows who of screen stevie charms who has a screen [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.415 (perp=9.753, rec=0.204, cos=0.261), tot_loss_proj:3.693 [t=0.31s]
prediction: ['[CLS] screen woman the char char screen knows who of stevie shake screen who has a screen [SEP]']
[ 750/2000] tot_loss=2.462 (perp=10.004, rec=0.199, cos=0.263), tot_loss_proj:3.847 [t=0.31s]
prediction: ['[CLS] screen woman the char char screen knows who of mascara burn how who has a screen [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.378 (perp=9.603, rec=0.193, cos=0.264), tot_loss_proj:3.724 [t=0.31s]
prediction: ['[CLS] screen woman the char burn char screen knows who of stevie how who has a screen [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.321 (perp=9.254, rec=0.192, cos=0.278), tot_loss_proj:3.657 [t=0.31s]
prediction: ['[CLS] screen woman the char burn char screen knows who how of stevie who has a screen [SEP]']
[ 900/2000] tot_loss=2.300 (perp=9.254, rec=0.185, cos=0.264), tot_loss_proj:3.653 [t=0.31s]
prediction: ['[CLS] screen woman the char burn char screen knows who how of stevie who has a screen [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.284 (perp=9.155, rec=0.188, cos=0.266), tot_loss_proj:3.491 [t=0.31s]
prediction: ['[CLS] screen woman the char burn char screen young knows how of stevie who has a screen [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.363 (perp=8.985, rec=0.248, cos=0.317), tot_loss_proj:2.790 [t=0.31s]
prediction: ['[CLS] screen woman the char screen charms char screen young knows how of mascara who has a [SEP]']
[1050/2000] tot_loss=2.264 (perp=8.888, rec=0.195, cos=0.291), tot_loss_proj:2.464 [t=0.31s]
prediction: ['[CLS] screen woman the char screen charms char screen young knows how of stevie who has a [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.149 (perp=8.351, rec=0.200, cos=0.279), tot_loss_proj:2.715 [t=0.31s]
prediction: ['[CLS] screen woman the char screen char screen young charms knows how of stevie who has a [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.085 (perp=8.056, rec=0.198, cos=0.276), tot_loss_proj:2.829 [t=0.31s]
prediction: ['[CLS] screen the char screen char screen young woman charms knows how of stevie who has a [SEP]']
[1200/2000] tot_loss=2.087 (perp=8.056, rec=0.195, cos=0.281), tot_loss_proj:2.830 [t=0.31s]
prediction: ['[CLS] screen the char screen char screen young woman charms knows how of stevie who has a [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.083 (perp=8.081, rec=0.190, cos=0.277), tot_loss_proj:3.062 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
Attempt swap
[1300/2000] tot_loss=2.083 (perp=8.081, rec=0.185, cos=0.281), tot_loss_proj:3.058 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
[1350/2000] tot_loss=2.080 (perp=8.081, rec=0.185, cos=0.279), tot_loss_proj:3.061 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
Attempt swap
[1400/2000] tot_loss=2.077 (perp=8.081, rec=0.186, cos=0.274), tot_loss_proj:3.066 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
Attempt swap
[1450/2000] tot_loss=2.072 (perp=8.081, rec=0.174, cos=0.281), tot_loss_proj:3.060 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
[1500/2000] tot_loss=2.071 (perp=8.081, rec=0.179, cos=0.276), tot_loss_proj:3.063 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
Attempt swap
[1550/2000] tot_loss=2.080 (perp=8.081, rec=0.185, cos=0.279), tot_loss_proj:3.067 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.076 (perp=8.081, rec=0.186, cos=0.273), tot_loss_proj:2.987 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
[1650/2000] tot_loss=2.081 (perp=8.081, rec=0.184, cos=0.281), tot_loss_proj:2.990 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
Attempt swap
[1700/2000] tot_loss=2.076 (perp=8.081, rec=0.182, cos=0.278), tot_loss_proj:2.981 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
Attempt swap
[1750/2000] tot_loss=2.069 (perp=8.081, rec=0.175, cos=0.278), tot_loss_proj:2.986 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
[1800/2000] tot_loss=2.070 (perp=8.081, rec=0.177, cos=0.277), tot_loss_proj:2.983 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
Attempt swap
[1850/2000] tot_loss=2.070 (perp=8.081, rec=0.177, cos=0.277), tot_loss_proj:2.987 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
Attempt swap
[1900/2000] tot_loss=2.078 (perp=8.081, rec=0.183, cos=0.278), tot_loss_proj:2.985 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
[1950/2000] tot_loss=2.065 (perp=8.081, rec=0.172, cos=0.277), tot_loss_proj:2.989 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
Attempt swap
[2000/2000] tot_loss=2.080 (perp=8.081, rec=0.188, cos=0.276), tot_loss_proj:2.988 [t=0.31s]
prediction: ['[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] the screen char screen char screen young woman ares knows how of stevie who has a [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 66.667 | r: 75.000
rouge2     | fm: 18.750 | p: 17.647 | r: 20.000
rougeL     | fm: 41.176 | p: 38.889 | r: 43.750
rougeLsum  | fm: 41.176 | p: 38.889 | r: 43.750
r1fm+r2fm = 89.338

[Aggregate metrics]:
rouge1     | fm: 88.805 | p: 87.985 | r: 89.794
rouge2     | fm: 57.328 | p: 56.987 | r: 57.774
rougeL     | fm: 78.048 | p: 77.337 | r: 78.925
rougeLsum  | fm: 77.990 | p: 77.365 | r: 78.754
r1fm+r2fm = 146.133

input #59 time: 0:12:19 | total time: 12:05:26


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.9985680906941345
highest_index [0]
highest [0.9985680906941345]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9188227653503418 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9155802726745605 for ['[CLS] everything partnership bas gossip lies donegal directionbad his western ann arms [SEP]']
[Init] best rec loss: 0.9101083874702454 for ['[CLS] joo lead cancer course haiti board read empire dortmund commune member tory [SEP]']
[Init] best rec loss: 0.891872763633728 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8586064577102661 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8425424695014954 for ['[CLS] percent symbol budapest herald nets flavor shoppingted archlizer clock tight [SEP]']
[Init] best rec loss: 0.8368971347808838 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8132439255714417 for ['[CLS] rico shave overcomensor 1st opus introduced knockout currency area statewide whispered [SEP]']
[Init] best perm rec loss: 0.813075602054596 for ['[CLS] 1st currency statewide opus rico overcome introduced whisperednsor knockout shave area [SEP]']
[Init] best perm rec loss: 0.8129720687866211 for ['[CLS] 1st shavensor statewide knockout opus overcome whispered area rico currency introduced [SEP]']
[Init] best perm rec loss: 0.8125614523887634 for ['[CLS] knockout rico opus currencynsor 1st shave overcome area introduced whispered statewide [SEP]']
[Init] best perm rec loss: 0.8092846274375916 for ['[CLS] introduced opus 1st area rico statewidensor knockout whispered overcome currency shave [SEP]']
[Init] best perm rec loss: 0.8059147596359253 for ['[CLS] statewide area shave overcome whispered currencynsor opus introduced rico knockout 1st [SEP]']
[Init] best perm rec loss: 0.8057880997657776 for ['[CLS] 1st rico shave knockout area statewide opus overcome currency whisperednsor introduced [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.679 (perp=12.249, rec=0.218, cos=0.011), tot_loss_proj:2.996 [t=0.30s]
prediction: ['[CLS] is circuit awkwardly isleg soap solicitor is awkwardly awkwardly paced opera [SEP]']
[ 100/2000] tot_loss=2.442 (perp=11.247, rec=0.180, cos=0.012), tot_loss_proj:2.845 [t=0.30s]
prediction: ['[CLS] is circuit awkwardly the circuit soap circuit is awkwardly awkwardly paced story [SEP]']
[ 150/2000] tot_loss=2.153 (perp=10.115, rec=0.123, cos=0.007), tot_loss_proj:2.637 [t=0.30s]
prediction: ['[CLS] is circuit awkwardly the circuit soap opera - awkwardly awkwardly paced story [SEP]']
[ 200/2000] tot_loss=2.046 (perp=9.639, rec=0.112, cos=0.006), tot_loss_proj:2.343 [t=0.30s]
prediction: ['[CLS] is circuit paced the circuit soap opera - awkwardly awkwardly paced story [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.906 (perp=8.966, rec=0.108, cos=0.005), tot_loss_proj:2.139 [t=0.30s]
prediction: ['[CLS] paced circuit is the circuit soap opera - awkwardly awkwardly paced story [SEP]']
[ 300/2000] tot_loss=1.989 (perp=9.464, rec=0.091, cos=0.005), tot_loss_proj:2.369 [t=0.30s]
prediction: ['[CLS] paced circuit is the paced soap opera - awkwardly awkwardly paced story [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.023 (perp=9.560, rec=0.105, cos=0.006), tot_loss_proj:2.306 [t=0.30s]
prediction: ['[CLS] paced circuit is the soap opera - awkwardly paced awkwardlyh story [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.799 (perp=8.426, rec=0.108, cos=0.007), tot_loss_proj:2.025 [t=0.30s]
prediction: ['[CLS]h circuit is the soap opera - awkwardly paced awkwardly paced story [SEP]']
[ 450/2000] tot_loss=1.781 (perp=8.426, rec=0.090, cos=0.005), tot_loss_proj:2.020 [t=0.30s]
prediction: ['[CLS]h circuit is the soap opera - awkwardly paced awkwardly paced story [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.690 (perp=7.983, rec=0.088, cos=0.005), tot_loss_proj:1.968 [t=0.30s]
prediction: ['[CLS]h is the soap opera - awkwardly paced awkwardly paced story circuit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.686 (perp=7.983, rec=0.085, cos=0.005), tot_loss_proj:1.977 [t=0.30s]
prediction: ['[CLS]h is the soap opera - awkwardly paced awkwardly paced story circuit [SEP]']
[ 600/2000] tot_loss=1.692 (perp=7.983, rec=0.091, cos=0.005), tot_loss_proj:1.971 [t=0.30s]
prediction: ['[CLS]h is the soap opera - awkwardly paced awkwardly paced story circuit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.687 (perp=7.983, rec=0.086, cos=0.005), tot_loss_proj:1.968 [t=0.30s]
prediction: ['[CLS]h is the soap opera - awkwardly paced awkwardly paced story circuit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.680 (perp=7.983, rec=0.079, cos=0.005), tot_loss_proj:1.971 [t=0.30s]
prediction: ['[CLS]h is the soap opera - awkwardly paced awkwardly paced story circuit [SEP]']
[ 750/2000] tot_loss=1.687 (perp=7.983, rec=0.085, cos=0.005), tot_loss_proj:1.972 [t=0.30s]
prediction: ['[CLS]h is the soap opera - awkwardly paced awkwardly paced story circuit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.897 (perp=9.075, rec=0.078, cos=0.005), tot_loss_proj:2.257 [t=0.30s]
prediction: ['[CLS]h is the soap opera - awkwardly is awkwardly paced story circuit [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.860 (perp=8.873, rec=0.081, cos=0.005), tot_loss_proj:2.152 [t=0.30s]
prediction: ['[CLS]h is the awkwardly soap opera - is awkwardly paced story circuit [SEP]']
[ 900/2000] tot_loss=1.862 (perp=8.873, rec=0.083, cos=0.005), tot_loss_proj:2.150 [t=0.30s]
prediction: ['[CLS]h is the awkwardly soap opera - is awkwardly paced story circuit [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.684 (perp=7.934, rec=0.093, cos=0.005), tot_loss_proj:2.100 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is awkwardly paced the story circuit [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.659 (perp=7.864, rec=0.082, cos=0.004), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
[1050/2000] tot_loss=1.658 (perp=7.864, rec=0.080, cos=0.005), tot_loss_proj:1.988 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.647 (perp=7.864, rec=0.070, cos=0.004), tot_loss_proj:1.986 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.651 (perp=7.864, rec=0.074, cos=0.004), tot_loss_proj:1.981 [t=0.31s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
[1200/2000] tot_loss=1.655 (perp=7.864, rec=0.078, cos=0.004), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.647 (perp=7.864, rec=0.070, cos=0.004), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.657 (perp=7.864, rec=0.080, cos=0.004), tot_loss_proj:1.978 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
[1350/2000] tot_loss=1.658 (perp=7.864, rec=0.081, cos=0.004), tot_loss_proj:1.978 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.646 (perp=7.864, rec=0.069, cos=0.004), tot_loss_proj:1.989 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.654 (perp=7.864, rec=0.077, cos=0.004), tot_loss_proj:1.986 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
[1500/2000] tot_loss=1.649 (perp=7.864, rec=0.072, cos=0.004), tot_loss_proj:1.976 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.656 (perp=7.864, rec=0.079, cos=0.004), tot_loss_proj:1.989 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.650 (perp=7.864, rec=0.073, cos=0.004), tot_loss_proj:1.980 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
[1650/2000] tot_loss=1.655 (perp=7.864, rec=0.078, cos=0.004), tot_loss_proj:1.982 [t=0.31s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.648 (perp=7.864, rec=0.070, cos=0.004), tot_loss_proj:1.987 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.650 (perp=7.864, rec=0.073, cos=0.004), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
[1800/2000] tot_loss=1.653 (perp=7.864, rec=0.075, cos=0.004), tot_loss_proj:1.991 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.657 (perp=7.864, rec=0.080, cos=0.004), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.650 (perp=7.864, rec=0.073, cos=0.004), tot_loss_proj:1.992 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
[1950/2000] tot_loss=1.657 (perp=7.864, rec=0.080, cos=0.004), tot_loss_proj:1.991 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.647 (perp=7.864, rec=0.070, cos=0.004), tot_loss_proj:1.981 [t=0.30s]
prediction: ['[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS]h is awkwardly soap opera - is the awkwardly paced story circuit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 76.923 | r: 90.909
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 58.333 | p: 53.846 | r: 63.636
rougeLsum  | fm: 58.333 | p: 53.846 | r: 63.636
r1fm+r2fm = 119.697

[Aggregate metrics]:
rouge1     | fm: 88.762 | p: 87.859 | r: 89.800
rouge2     | fm: 56.786 | p: 56.334 | r: 57.257
rougeL     | fm: 77.700 | p: 76.951 | r: 78.596
rougeLsum  | fm: 77.719 | p: 77.010 | r: 78.536
r1fm+r2fm = 145.547

input #60 time: 0:12:04 | total time: 12:17:30


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.9986195720335935
highest_index [0]
highest [0.9986195720335935]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9799600839614868 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9755334854125977 for ['[CLS] way consists prison [SEP]']
[Init] best rec loss: 0.9550703763961792 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9523242712020874 for ['[CLS] running varied column [SEP]']
[Init] best rec loss: 0.9408973455429077 for ['[CLS] dunesmain dinah [SEP]']
[Init] best rec loss: 0.9357168078422546 for ['[CLS] huffington class matter [SEP]']
[Init] best rec loss: 0.9284790754318237 for ['[CLS] 1980s behindae [SEP]']
[Init] best rec loss: 0.9013001918792725 for ['[CLS] wishes chaplain blast [SEP]']
[Init] best perm rec loss: 0.8987635374069214 for ['[CLS] chaplain wishes blast [SEP]']
[Init] best perm rec loss: 0.8975244164466858 for ['[CLS] wishes blast chaplain [SEP]']
[Init] best perm rec loss: 0.8962423801422119 for ['[CLS] blast chaplain wishes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.995 (perp=13.326, rec=0.321, cos=0.009), tot_loss_proj:3.210 [t=0.30s]
prediction: ['[CLS]tionditional beautiful [SEP]']
[ 100/2000] tot_loss=2.625 (perp=11.675, rec=0.279, cos=0.010), tot_loss_proj:2.707 [t=0.30s]
prediction: ['[CLS]氵 scene beautiful [SEP]']
[ 150/2000] tot_loss=2.528 (perp=11.675, rec=0.186, cos=0.007), tot_loss_proj:2.784 [t=0.30s]
prediction: ['[CLS]氵 scene beautiful [SEP]']
[ 200/2000] tot_loss=2.627 (perp=12.341, rec=0.153, cos=0.006), tot_loss_proj:2.928 [t=0.30s]
prediction: ['[CLS]士 scene beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.114 (perp=9.785, rec=0.151, cos=0.006), tot_loss_proj:2.371 [t=0.30s]
prediction: ['[CLS] beautiful scenetium [SEP]']
[ 300/2000] tot_loss=2.110 (perp=9.785, rec=0.147, cos=0.006), tot_loss_proj:2.374 [t=0.30s]
prediction: ['[CLS] beautiful scenetium [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.094 (perp=9.785, rec=0.131, cos=0.006), tot_loss_proj:2.370 [t=0.30s]
prediction: ['[CLS] beautiful scenetium [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.099 (perp=9.785, rec=0.137, cos=0.005), tot_loss_proj:2.373 [t=0.30s]
prediction: ['[CLS] beautiful scenetium [SEP]']
[ 450/2000] tot_loss=2.227 (perp=10.309, rec=0.160, cos=0.006), tot_loss_proj:2.347 [t=0.30s]
prediction: ['[CLS] beautiful scene氵 [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.198 (perp=10.309, rec=0.131, cos=0.005), tot_loss_proj:2.350 [t=0.30s]
prediction: ['[CLS] beautiful scene氵 [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.262 (perp=10.588, rec=0.139, cos=0.005), tot_loss_proj:2.417 [t=0.30s]
prediction: ['[CLS] beautiful scene 代 [SEP]']
[ 600/2000] tot_loss=2.264 (perp=10.588, rec=0.142, cos=0.005), tot_loss_proj:2.416 [t=0.30s]
prediction: ['[CLS] beautiful scene 代 [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.361 (perp=11.136, rec=0.129, cos=0.005), tot_loss_proj:2.826 [t=0.30s]
prediction: ['[CLS] beautiful scene across [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.362 (perp=11.136, rec=0.130, cos=0.005), tot_loss_proj:2.814 [t=0.30s]
prediction: ['[CLS] beautiful scene across [SEP]']
[ 750/2000] tot_loss=2.372 (perp=11.136, rec=0.140, cos=0.005), tot_loss_proj:2.819 [t=0.30s]
prediction: ['[CLS] beautiful scene across [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.559 (perp=7.102, rec=0.134, cos=0.004), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.538 (perp=7.102, rec=0.114, cos=0.003), tot_loss_proj:1.644 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.521 (perp=7.102, rec=0.098, cos=0.003), tot_loss_proj:1.643 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.499 (perp=7.102, rec=0.075, cos=0.003), tot_loss_proj:1.642 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.490 (perp=7.102, rec=0.067, cos=0.003), tot_loss_proj:1.660 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.500 (perp=7.102, rec=0.077, cos=0.003), tot_loss_proj:1.646 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.501 (perp=7.102, rec=0.078, cos=0.003), tot_loss_proj:1.638 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.493 (perp=7.102, rec=0.070, cos=0.003), tot_loss_proj:1.643 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.502 (perp=7.102, rec=0.079, cos=0.003), tot_loss_proj:1.645 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.492 (perp=7.102, rec=0.069, cos=0.003), tot_loss_proj:1.648 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.501 (perp=7.102, rec=0.078, cos=0.003), tot_loss_proj:1.653 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.508 (perp=7.102, rec=0.085, cos=0.003), tot_loss_proj:1.637 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.488 (perp=7.102, rec=0.065, cos=0.003), tot_loss_proj:1.650 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.493 (perp=7.102, rec=0.070, cos=0.003), tot_loss_proj:1.639 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.491 (perp=7.102, rec=0.068, cos=0.003), tot_loss_proj:1.652 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.500 (perp=7.102, rec=0.077, cos=0.003), tot_loss_proj:1.647 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.487 (perp=7.102, rec=0.064, cos=0.003), tot_loss_proj:1.649 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.494 (perp=7.102, rec=0.071, cos=0.003), tot_loss_proj:1.649 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.489 (perp=7.102, rec=0.066, cos=0.003), tot_loss_proj:1.643 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.497 (perp=7.102, rec=0.074, cos=0.003), tot_loss_proj:1.648 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.491 (perp=7.102, rec=0.068, cos=0.003), tot_loss_proj:1.652 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.489 (perp=7.102, rec=0.065, cos=0.003), tot_loss_proj:1.641 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.490 (perp=7.102, rec=0.067, cos=0.003), tot_loss_proj:1.648 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.492 (perp=7.102, rec=0.069, cos=0.003), tot_loss_proj:1.646 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.489 (perp=7.102, rec=0.066, cos=0.003), tot_loss_proj:1.640 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.967 | p: 88.070 | r: 90.007
rouge2     | fm: 57.612 | p: 57.153 | r: 58.151
rougeL     | fm: 78.119 | p: 77.463 | r: 78.951
rougeLsum  | fm: 78.057 | p: 77.401 | r: 78.964
r1fm+r2fm = 146.579

input #61 time: 0:12:03 | total time: 12:29:33


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.9988014441786419
highest_index [0]
highest [0.9988014441786419]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9494487643241882 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.918349027633667 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.9122050404548645 for ['[CLS] iron while ceiling kent explosion surface adjacent llc chen awkward springs bourbon abe feemarine order sides marco sure lace translator [SEP]']
[Init] best perm rec loss: 0.9120252132415771 for ['[CLS] surface springs kent awkward lace fee ceiling while sure chen explosionmarine abe adjacent llc sides iron bourbon marco order translator [SEP]']
[Init] best perm rec loss: 0.9096555113792419 for ['[CLS] sides translator lace chen springs sure while bourbon iron explosion abe awkward marco kent feemarine ceiling adjacent surface llc order [SEP]']
[Init] best perm rec loss: 0.9086116552352905 for ['[CLS] sure lace sides marco adjacent translator bourbon surfacemarine llc abe chen iron explosion awkward kent springs fee ceiling while order [SEP]']
[Init] best perm rec loss: 0.9070934653282166 for ['[CLS] springs chen while sides explosion surface ceiling translatormarine llc awkward iron adjacent fee abe sure marco order bourbon lace kent [SEP]']
[Init] best perm rec loss: 0.9068891406059265 for ['[CLS] ceiling explosion adjacent fee sides surface bourbon while llc awkwardmarine iron translator lace sure springs marco abe chen order kent [SEP]']
[Init] best perm rec loss: 0.9059514999389648 for ['[CLS] kent translator springs bourbon explosion surface sure while lace fee iron adjacent llc awkward marcomarine ceiling order abe chen sides [SEP]']
[Init] best perm rec loss: 0.9049345254898071 for ['[CLS] translator springs sure bourbon explosion order sides abe llc chen iron lace awkward while fee surface kentmarine ceiling marco adjacent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.672 (perp=12.359, rec=0.578, cos=0.622), tot_loss_proj:4.161 [t=0.31s]
prediction: ['[CLS] scrub westboundway facto mob clause sides situation shannon between criminal day⁄₄ paul would dana and ) baseball until eldest [SEP]']
[ 100/2000] tot_loss=3.259 (perp=12.668, rec=0.498, cos=0.228), tot_loss_proj:4.209 [t=0.31s]
prediction: ['[CLS] tour duringway township cam the again anymore shannon to ( strokes cops paul wouldurbed war ) grace royal gift [SEP]']
[ 150/2000] tot_loss=3.133 (perp=12.499, rec=0.429, cos=0.204), tot_loss_proj:4.404 [t=0.31s]
prediction: ['[CLS] piccolo making exclaimed merely cam going to anymore richard for for advocacy bad paul to prophecy war laughed grace volunteers grace [SEP]']
[ 200/2000] tot_loss=3.017 (perp=12.058, rec=0.362, cos=0.244), tot_loss_proj:4.292 [t=0.31s]
prediction: ['[CLS] movies making oricon lack prevention taking to movies richard to prevention advocacy 4 capped to nonfiction war best grace volunteers grace [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.619 (perp=10.154, rec=0.344, cos=0.244), tot_loss_proj:3.545 [t=0.31s]
prediction: ['[CLS] movies for greatest stage prevention [SEP] the movies not to prevention advocacy prevention stop or curriculum war movies grace earned grace [SEP]']
[ 300/2000] tot_loss=2.908 (perp=11.275, rec=0.329, cos=0.324), tot_loss_proj:3.826 [t=0.31s]
prediction: ['[CLS] anime for best client prevention [SEP] the movies any to prevention may prevention olivia might judaism war movies grace earned grace [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.772 (perp=10.832, rec=0.307, cos=0.299), tot_loss_proj:3.854 [t=0.31s]
prediction: ['[CLS] anime to best stage prevention [SEP] the movies from to prevention trouble prevention olivia tourbed war tries grace earned grace [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.802 (perp=10.861, rec=0.297, cos=0.332), tot_loss_proj:3.745 [t=0.31s]
prediction: ['[CLS] anime movies to than prevention trouble prevention to best stage prevention to ever olivia tourbed war broadband grace earned grace [SEP]']
[ 450/2000] tot_loss=2.837 (perp=11.211, rec=0.283, cos=0.312), tot_loss_proj:3.816 [t=0.31s]
prediction: ['[CLS] psychology movies to than prevention blame prevention to best stage prevention to ever olivia to routes war broadband grace earned grace [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.689 (perp=10.316, rec=0.262, cos=0.363), tot_loss_proj:3.524 [t=0.31s]
prediction: ['[CLS] movies to movies to prevention blame prevention to best stage prevention to ever olivia to routes movies making grace earned grace [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.671 (perp=10.456, rec=0.263, cos=0.317), tot_loss_proj:3.672 [t=0.31s]
prediction: ['[CLS] movies to blame prevention call movies to prevention best stage prevention to ever olivia to chavez movies making grace earned grace [SEP]']
[ 600/2000] tot_loss=2.827 (perp=11.320, rec=0.249, cos=0.313), tot_loss_proj:3.969 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call movies to prevention best to prevention to ever olivia to routes movies making grace earned grace [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.791 (perp=11.066, rec=0.242, cos=0.336), tot_loss_proj:3.810 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention movies months prevention to ever reward to routes movies making grace earned grace [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.668 (perp=10.512, rec=0.233, cos=0.332), tot_loss_proj:3.681 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace to prevention to ever reward to chavez ever making movies earned grace [SEP]']
[ 750/2000] tot_loss=2.654 (perp=10.467, rec=0.226, cos=0.334), tot_loss_proj:3.763 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months prevention to ever reward to routes ever making movies earned grace [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.617 (perp=10.449, rec=0.215, cos=0.312), tot_loss_proj:3.713 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months to ever reward to solved scripted ever making movies earned grace [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.491 (perp=9.803, rec=0.212, cos=0.319), tot_loss_proj:3.700 [t=0.31s]
prediction: ['[CLS] movies to blame prevention call best to prevention grace months to one reward to solved scripted ever earned movies making grace [SEP]']
[ 900/2000] tot_loss=2.572 (perp=10.226, rec=0.209, cos=0.318), tot_loss_proj:3.718 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months to one reward to solved scripted ever earned movies making grace [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.554 (perp=10.190, rec=0.208, cos=0.307), tot_loss_proj:3.587 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months to honor one to solved scripted ever earned movies making grace [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.599 (perp=10.352, rec=0.208, cos=0.320), tot_loss_proj:3.553 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months to honor one to earned areas ever transition movies making grace [SEP]']
[1050/2000] tot_loss=2.550 (perp=10.251, rec=0.194, cos=0.305), tot_loss_proj:3.616 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months to reward one to earned areas ever transition movies making grace [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.484 (perp=9.814, rec=0.203, cos=0.319), tot_loss_proj:3.557 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months to reward one to earned transition areas ever movies making grace [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.465 (perp=9.788, rec=0.202, cos=0.306), tot_loss_proj:3.754 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months to reward one to earned transition ever movies making grace scripted [SEP]']
[1200/2000] tot_loss=2.546 (perp=10.130, rec=0.198, cos=0.322), tot_loss_proj:3.710 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months to honor one to earned transition ever movies making grace scripted [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.508 (perp=10.031, rec=0.194, cos=0.308), tot_loss_proj:3.830 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months to reward transition to earned one ever movies making grace scripted [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.471 (perp=9.768, rec=0.193, cos=0.325), tot_loss_proj:3.843 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months to honor transition ever earned one to movies making grace scripted [SEP]']
[1350/2000] tot_loss=2.464 (perp=9.789, rec=0.194, cos=0.313), tot_loss_proj:3.851 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call best to prevention grace months to reward transition ever earned one to movies making grace scripted [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.408 (perp=9.513, rec=0.195, cos=0.310), tot_loss_proj:3.751 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call to prevention best grace months to honor transition ever earned one to movies making grace scripted [SEP]']
Attempt swap
[1450/2000] tot_loss=2.407 (perp=9.513, rec=0.193, cos=0.312), tot_loss_proj:3.748 [t=0.31s]
prediction: ['[CLS]ology to blame prevention call to prevention best grace months to honor transition ever earned one to movies making grace scripted [SEP]']
[1500/2000] tot_loss=2.459 (perp=9.766, rec=0.196, cos=0.310), tot_loss_proj:3.792 [t=0.31s]
prediction: ['[CLS]ology to blame rather call to prevention best grace months to honor transition ever earned one to movies making grace scripted [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.419 (perp=9.592, rec=0.187, cos=0.313), tot_loss_proj:3.803 [t=0.31s]
prediction: ['[CLS]ology to blame call rather to prevention best grace months to honor transition ever earned one to movies making grace scripted [SEP]']
Attempt swap
[1600/2000] tot_loss=2.426 (perp=9.592, rec=0.192, cos=0.315), tot_loss_proj:3.803 [t=0.31s]
prediction: ['[CLS]ology to blame call rather to prevention best grace months to honor transition ever earned one to movies making grace scripted [SEP]']
[1650/2000] tot_loss=2.413 (perp=9.592, rec=0.181, cos=0.314), tot_loss_proj:3.804 [t=0.31s]
prediction: ['[CLS]ology to blame call rather to prevention best grace months to honor transition ever earned one to movies making grace scripted [SEP]']
Attempt swap
[1700/2000] tot_loss=2.409 (perp=9.592, rec=0.177, cos=0.313), tot_loss_proj:3.804 [t=0.31s]
prediction: ['[CLS]ology to blame call rather to prevention best grace months to honor transition ever earned one to movies making grace scripted [SEP]']
Attempt swap
[1750/2000] tot_loss=2.473 (perp=9.847, rec=0.189, cos=0.314), tot_loss_proj:3.800 [t=0.31s]
prediction: ['[CLS]ology to blame call rather to prevention best grace months to honor transition ever earned one rather movies making grace scripted [SEP]']
[1800/2000] tot_loss=2.470 (perp=9.847, rec=0.187, cos=0.313), tot_loss_proj:3.799 [t=0.31s]
prediction: ['[CLS]ology to blame call rather to prevention best grace months to honor transition ever earned one rather movies making grace scripted [SEP]']
Attempt swap
[1850/2000] tot_loss=2.463 (perp=9.847, rec=0.181, cos=0.314), tot_loss_proj:3.797 [t=0.31s]
prediction: ['[CLS]ology to blame call rather to prevention best grace months to honor transition ever earned one rather movies making grace scripted [SEP]']
Attempt swap
[1900/2000] tot_loss=2.468 (perp=9.847, rec=0.183, cos=0.316), tot_loss_proj:3.796 [t=0.31s]
prediction: ['[CLS]ology to blame call rather to prevention best grace months to honor transition ever earned one rather movies making grace scripted [SEP]']
[1950/2000] tot_loss=2.471 (perp=9.847, rec=0.185, cos=0.317), tot_loss_proj:3.799 [t=0.32s]
prediction: ['[CLS]ology to blame call rather to prevention best grace months to honor transition ever earned one rather movies making grace scripted [SEP]']
Attempt swap
[2000/2000] tot_loss=2.473 (perp=9.847, rec=0.190, cos=0.314), tot_loss_proj:3.798 [t=0.31s]
prediction: ['[CLS]ology to blame call rather to prevention best grace months to honor transition ever earned one rather movies making grace scripted [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS]ology to blame call rather to prevention best grace months to honor transition ever earned one rather movies making grace scripted [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.222 | p: 60.870 | r: 63.636
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 35.556 | p: 34.783 | r: 36.364
rougeLsum  | fm: 35.556 | p: 34.783 | r: 36.364
r1fm+r2fm = 62.222

[Aggregate metrics]:
rouge1     | fm: 88.459 | p: 87.562 | r: 89.512
rouge2     | fm: 56.775 | p: 56.376 | r: 57.201
rougeL     | fm: 77.409 | p: 76.711 | r: 78.285
rougeLsum  | fm: 77.460 | p: 76.761 | r: 78.283
r1fm+r2fm = 145.234

input #62 time: 0:12:26 | total time: 12:42:00


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9986862773836799
highest_index [0]
highest [0.9986862773836799]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.8320707678794861 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.7343606948852539 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7137153744697571 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best rec loss: 0.7061095833778381 for ['[CLS]el sauce readings hannah these [SEP]']
[Init] best rec loss: 0.7014604806900024 for ['[CLS] alpha light gender independence almost [SEP]']
[Init] best perm rec loss: 0.7012014389038086 for ['[CLS] light alpha gender independence almost [SEP]']
[Init] best perm rec loss: 0.698208212852478 for ['[CLS] gender independence almost light alpha [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.265 (perp=10.384, rec=0.172, cos=0.016), tot_loss_proj:3.158 [t=0.30s]
prediction: ['[CLS] looking ticket return return ticket [SEP]']
[ 100/2000] tot_loss=2.150 (perp=10.216, rec=0.100, cos=0.007), tot_loss_proj:3.259 [t=0.30s]
prediction: ['[CLS] looking ticket return a ticket [SEP]']
[ 150/2000] tot_loss=2.137 (perp=10.216, rec=0.087, cos=0.007), tot_loss_proj:3.251 [t=0.30s]
prediction: ['[CLS] looking ticket return a ticket [SEP]']
[ 200/2000] tot_loss=2.125 (perp=10.216, rec=0.077, cos=0.005), tot_loss_proj:3.243 [t=0.30s]
prediction: ['[CLS] looking ticket return a ticket [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.827 (perp=8.743, rec=0.073, cos=0.006), tot_loss_proj:2.409 [t=0.30s]
prediction: ['[CLS] looking a ticket return ticket [SEP]']
[ 300/2000] tot_loss=1.823 (perp=8.743, rec=0.069, cos=0.005), tot_loss_proj:2.404 [t=0.30s]
prediction: ['[CLS] looking a ticket return ticket [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.131 (perp=10.284, rec=0.069, cos=0.005), tot_loss_proj:3.035 [t=0.30s]
prediction: ['[CLS] for ticket looking return ticket [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.631 (perp=7.802, rec=0.066, cos=0.005), tot_loss_proj:1.917 [t=0.30s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 450/2000] tot_loss=1.638 (perp=7.802, rec=0.073, cos=0.005), tot_loss_proj:1.918 [t=0.30s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.628 (perp=7.802, rec=0.063, cos=0.005), tot_loss_proj:1.920 [t=0.31s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.636 (perp=7.802, rec=0.071, cos=0.004), tot_loss_proj:1.911 [t=0.30s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 600/2000] tot_loss=1.644 (perp=7.802, rec=0.080, cos=0.004), tot_loss_proj:1.912 [t=0.30s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.633 (perp=7.802, rec=0.068, cos=0.004), tot_loss_proj:1.918 [t=0.30s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.636 (perp=7.802, rec=0.071, cos=0.004), tot_loss_proj:1.908 [t=0.30s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 750/2000] tot_loss=1.632 (perp=7.802, rec=0.067, cos=0.004), tot_loss_proj:1.909 [t=0.30s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.629 (perp=7.802, rec=0.065, cos=0.004), tot_loss_proj:1.918 [t=0.30s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.629 (perp=7.802, rec=0.065, cos=0.003), tot_loss_proj:1.915 [t=0.30s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 900/2000] tot_loss=1.293 (perp=6.111, rec=0.069, cos=0.003), tot_loss_proj:1.315 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.281 (perp=6.111, rec=0.056, cos=0.003), tot_loss_proj:1.316 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.280 (perp=6.111, rec=0.056, cos=0.003), tot_loss_proj:1.307 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1050/2000] tot_loss=1.276 (perp=6.111, rec=0.051, cos=0.003), tot_loss_proj:1.324 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.289 (perp=6.111, rec=0.065, cos=0.003), tot_loss_proj:1.313 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.291 (perp=6.111, rec=0.066, cos=0.003), tot_loss_proj:1.301 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1200/2000] tot_loss=1.298 (perp=6.111, rec=0.073, cos=0.003), tot_loss_proj:1.310 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.285 (perp=6.111, rec=0.060, cos=0.003), tot_loss_proj:1.309 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.285 (perp=6.111, rec=0.060, cos=0.003), tot_loss_proj:1.309 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.275 (perp=6.111, rec=0.050, cos=0.003), tot_loss_proj:1.310 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.281 (perp=6.111, rec=0.056, cos=0.003), tot_loss_proj:1.319 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.283 (perp=6.111, rec=0.058, cos=0.003), tot_loss_proj:1.314 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.281 (perp=6.111, rec=0.056, cos=0.003), tot_loss_proj:1.309 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.275 (perp=6.111, rec=0.050, cos=0.003), tot_loss_proj:1.315 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.282 (perp=6.111, rec=0.057, cos=0.003), tot_loss_proj:1.308 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.280 (perp=6.111, rec=0.055, cos=0.003), tot_loss_proj:1.319 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.287 (perp=6.111, rec=0.062, cos=0.003), tot_loss_proj:1.307 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.291 (perp=6.111, rec=0.066, cos=0.003), tot_loss_proj:1.311 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.278 (perp=6.111, rec=0.054, cos=0.003), tot_loss_proj:1.310 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.283 (perp=6.111, rec=0.058, cos=0.003), tot_loss_proj:1.314 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.280 (perp=6.111, rec=0.055, cos=0.003), tot_loss_proj:1.310 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.276 (perp=6.111, rec=0.051, cos=0.003), tot_loss_proj:1.319 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.292 (perp=6.111, rec=0.068, cos=0.003), tot_loss_proj:1.306 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.574 | p: 87.657 | r: 89.665
rouge2     | fm: 57.320 | p: 56.999 | r: 57.785
rougeL     | fm: 77.690 | p: 76.954 | r: 78.599
rougeLsum  | fm: 77.857 | p: 77.164 | r: 78.682
r1fm+r2fm = 145.893

input #63 time: 0:12:05 | total time: 12:54:06


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.9986466872629143
highest_index [0]
highest [0.9986466872629143]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8962174654006958 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8545131683349609 for ['[CLS] dale fuel picked [SEP]']
[Init] best rec loss: 0.8266545534133911 for ['[CLS] david [CLS] earliest [SEP]']
[Init] best rec loss: 0.74805748462677 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6888129115104675 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6884679198265076 for ['[CLS] visions wateronale [SEP]']
[Init] best perm rec loss: 0.6875845193862915 for ['[CLS]onale visions water [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.698 (perp=8.065, rec=0.081, cos=0.005), tot_loss_proj:1.694 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 100/2000] tot_loss=1.684 (perp=8.065, rec=0.068, cos=0.003), tot_loss_proj:1.712 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 150/2000] tot_loss=1.678 (perp=8.065, rec=0.062, cos=0.003), tot_loss_proj:1.715 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[ 200/2000] tot_loss=1.663 (perp=8.065, rec=0.047, cos=0.003), tot_loss_proj:1.700 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.669 (perp=8.065, rec=0.053, cos=0.003), tot_loss_proj:1.697 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 300/2000] tot_loss=1.689 (perp=8.065, rec=0.073, cos=0.003), tot_loss_proj:1.702 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.676 (perp=8.065, rec=0.060, cos=0.003), tot_loss_proj:1.704 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.003), tot_loss_proj:1.709 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.003), tot_loss_proj:1.700 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.674 (perp=8.065, rec=0.058, cos=0.003), tot_loss_proj:1.698 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.684 (perp=8.065, rec=0.068, cos=0.003), tot_loss_proj:1.697 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.669 (perp=8.065, rec=0.054, cos=0.003), tot_loss_proj:1.710 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.003), tot_loss_proj:1.703 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.679 (perp=8.065, rec=0.063, cos=0.003), tot_loss_proj:1.704 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.689 (perp=8.065, rec=0.074, cos=0.003), tot_loss_proj:1.700 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.679 (perp=8.065, rec=0.063, cos=0.003), tot_loss_proj:1.712 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.003), tot_loss_proj:1.693 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.682 (perp=8.065, rec=0.066, cos=0.003), tot_loss_proj:1.700 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.672 (perp=8.065, rec=0.057, cos=0.003), tot_loss_proj:1.709 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.692 (perp=8.065, rec=0.077, cos=0.003), tot_loss_proj:1.688 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.677 (perp=8.065, rec=0.061, cos=0.003), tot_loss_proj:1.701 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.671 (perp=8.065, rec=0.055, cos=0.003), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.684 (perp=8.065, rec=0.068, cos=0.003), tot_loss_proj:1.695 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.664 (perp=8.065, rec=0.049, cos=0.003), tot_loss_proj:1.707 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.663 (perp=8.065, rec=0.047, cos=0.003), tot_loss_proj:1.696 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.683 (perp=8.065, rec=0.067, cos=0.003), tot_loss_proj:1.710 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.672 (perp=8.065, rec=0.056, cos=0.003), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.680 (perp=8.065, rec=0.064, cos=0.003), tot_loss_proj:1.703 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.687 (perp=8.065, rec=0.072, cos=0.003), tot_loss_proj:1.710 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.676 (perp=8.065, rec=0.061, cos=0.003), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.669 (perp=8.065, rec=0.054, cos=0.003), tot_loss_proj:1.705 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.678 (perp=8.065, rec=0.062, cos=0.003), tot_loss_proj:1.704 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.661 (perp=8.065, rec=0.045, cos=0.003), tot_loss_proj:1.701 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.685 (perp=8.065, rec=0.070, cos=0.003), tot_loss_proj:1.709 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.686 (perp=8.065, rec=0.071, cos=0.003), tot_loss_proj:1.705 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.674 (perp=8.065, rec=0.059, cos=0.003), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.683 (perp=8.065, rec=0.067, cos=0.003), tot_loss_proj:1.705 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.689 (perp=8.065, rec=0.074, cos=0.003), tot_loss_proj:1.711 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.683 (perp=8.065, rec=0.067, cos=0.003), tot_loss_proj:1.694 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.681 (perp=8.065, rec=0.065, cos=0.003), tot_loss_proj:1.694 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.878 | p: 88.053 | r: 89.850
rouge2     | fm: 57.975 | p: 57.569 | r: 58.393
rougeL     | fm: 78.064 | p: 77.426 | r: 78.964
rougeLsum  | fm: 78.159 | p: 77.517 | r: 78.960
r1fm+r2fm = 146.853

input #64 time: 0:12:05 | total time: 13:06:11


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9988718868123379
highest_index [0]
highest [0.9988718868123379]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 0.9240533709526062 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9055255055427551 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.8987274765968323 for ['[CLS] dir northern opens gasam acute diocese ban missile [SEP]']
[Init] best rec loss: 0.8901315331459045 for ['[CLS] pale far expert interval pr che gonna time united [SEP]']
[Init] best rec loss: 0.8887251019477844 for ['[CLS] callman minister excellent scratch pleased unexpected accounted amateurs [SEP]']
[Init] best rec loss: 0.8844279050827026 for ['[CLS] health kuept scenicne contact will savamac [SEP]']
[Init] best rec loss: 0.8816733360290527 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.8735255002975464 for ['[CLS] games facing explorers canals is all sphinxitative prints [SEP]']
[Init] best rec loss: 0.8727313280105591 for ['[CLS] criticism yet application pre corn side bridge selections matters [SEP]']
[Init] best rec loss: 0.8720813393592834 for ['[CLS]sity notes blessed gave master way track chase en [SEP]']
[Init] best rec loss: 0.865404486656189 for ['[CLS]ong back acres za just effectiveness martin eva monk [SEP]']
[Init] best rec loss: 0.8433347344398499 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8395609259605408 for ['[CLS] news general someday pu funmamenthoff even overs [SEP]']
[Init] best perm rec loss: 0.8394455313682556 for ['[CLS] even someday general newshoff pu fun oversmament [SEP]']
[Init] best perm rec loss: 0.8392582535743713 for ['[CLS] general pu somedaymament evenhoff news fun overs [SEP]']
[Init] best perm rec loss: 0.8386566638946533 for ['[CLS]hoff general overs even someday news pu funmament [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.152 (perp=12.704, rec=0.495, cos=0.116), tot_loss_proj:3.813 [t=0.30s]
prediction: ['[CLS] darcyor angle mentally joy « of quantum story [SEP]']
[ 100/2000] tot_loss=2.326 (perp=9.314, rec=0.352, cos=0.111), tot_loss_proj:2.962 [t=0.30s]
prediction: ['[CLS] griefor / convictions joyous of joy story [SEP]']
[ 150/2000] tot_loss=2.861 (perp=11.518, rec=0.512, cos=0.046), tot_loss_proj:3.206 [t=0.30s]
prediction: ['[CLS] joyorous rom joyousous joy story [SEP]']
[ 200/2000] tot_loss=2.633 (perp=11.335, rec=0.290, cos=0.076), tot_loss_proj:3.573 [t=0.30s]
prediction: ['[CLS] griefonous dvd joyousous joy story [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.065 (perp=8.008, rec=0.302, cos=0.161), tot_loss_proj:2.195 [t=0.30s]
prediction: ['[CLS] a joyous draped joyousous joy story [SEP]']
[ 300/2000] tot_loss=2.505 (perp=10.282, rec=0.291, cos=0.157), tot_loss_proj:2.869 [t=0.31s]
prediction: ['[CLS] aheticous outcome joyousous joy story [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.389 (perp=9.777, rec=0.284, cos=0.150), tot_loss_proj:3.179 [t=0.31s]
prediction: ['[CLS] a timmyous outcome joyous ofous story [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.605 (perp=10.917, rec=0.278, cos=0.144), tot_loss_proj:3.136 [t=0.30s]
prediction: ['[CLS] a joyous vuelta timmyous ofous film [SEP]']
[ 450/2000] tot_loss=2.623 (perp=10.917, rec=0.268, cos=0.172), tot_loss_proj:3.131 [t=0.30s]
prediction: ['[CLS] a joyous vuelta timmyous ofous film [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.469 (perp=10.090, rec=0.264, cos=0.187), tot_loss_proj:3.074 [t=0.31s]
prediction: ['[CLS] a joyous film timmyous ofous vuelta [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.197 (perp=8.817, rec=0.267, cos=0.166), tot_loss_proj:2.604 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmous vuelta timmy [SEP]']
[ 600/2000] tot_loss=2.358 (perp=9.659, rec=0.248, cos=0.177), tot_loss_proj:2.845 [t=0.30s]
prediction: ['[CLS] a joyous storyous filmous vueltasonic [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.195 (perp=8.906, rec=0.249, cos=0.165), tot_loss_proj:2.674 [t=0.31s]
prediction: ['[CLS] a joyous storyous filmsonicous vuelta [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.085 (perp=8.441, rec=0.231, cos=0.166), tot_loss_proj:2.561 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
[ 750/2000] tot_loss=2.094 (perp=8.441, rec=0.240, cos=0.166), tot_loss_proj:2.555 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.089 (perp=8.441, rec=0.241, cos=0.160), tot_loss_proj:2.552 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.091 (perp=8.441, rec=0.234, cos=0.169), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
[ 900/2000] tot_loss=2.104 (perp=8.441, rec=0.257, cos=0.158), tot_loss_proj:2.552 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.077 (perp=8.441, rec=0.220, cos=0.168), tot_loss_proj:2.549 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1000/2000] tot_loss=2.085 (perp=8.441, rec=0.234, cos=0.162), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
[1050/2000] tot_loss=2.082 (perp=8.441, rec=0.230, cos=0.164), tot_loss_proj:2.555 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1100/2000] tot_loss=2.069 (perp=8.441, rec=0.217, cos=0.164), tot_loss_proj:2.561 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1150/2000] tot_loss=2.074 (perp=8.441, rec=0.218, cos=0.167), tot_loss_proj:2.550 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
[1200/2000] tot_loss=2.086 (perp=8.441, rec=0.228, cos=0.170), tot_loss_proj:2.546 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1250/2000] tot_loss=2.064 (perp=8.441, rec=0.212, cos=0.164), tot_loss_proj:2.558 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1300/2000] tot_loss=2.080 (perp=8.441, rec=0.231, cos=0.162), tot_loss_proj:2.554 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
[1350/2000] tot_loss=2.076 (perp=8.441, rec=0.225, cos=0.162), tot_loss_proj:2.556 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1400/2000] tot_loss=2.083 (perp=8.441, rec=0.232, cos=0.163), tot_loss_proj:2.555 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1450/2000] tot_loss=2.071 (perp=8.441, rec=0.217, cos=0.166), tot_loss_proj:2.560 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
[1500/2000] tot_loss=2.069 (perp=8.441, rec=0.218, cos=0.163), tot_loss_proj:2.553 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1550/2000] tot_loss=2.070 (perp=8.441, rec=0.217, cos=0.165), tot_loss_proj:2.554 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1600/2000] tot_loss=2.081 (perp=8.441, rec=0.223, cos=0.171), tot_loss_proj:2.563 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
[1650/2000] tot_loss=2.076 (perp=8.441, rec=0.218, cos=0.170), tot_loss_proj:2.560 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1700/2000] tot_loss=2.082 (perp=8.441, rec=0.227, cos=0.167), tot_loss_proj:2.553 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1750/2000] tot_loss=2.070 (perp=8.441, rec=0.213, cos=0.169), tot_loss_proj:2.559 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
[1800/2000] tot_loss=2.091 (perp=8.441, rec=0.232, cos=0.171), tot_loss_proj:2.549 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1850/2000] tot_loss=2.073 (perp=8.441, rec=0.219, cos=0.166), tot_loss_proj:2.554 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[1900/2000] tot_loss=2.078 (perp=8.441, rec=0.223, cos=0.167), tot_loss_proj:2.550 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
[1950/2000] tot_loss=2.072 (perp=8.441, rec=0.219, cos=0.166), tot_loss_proj:2.553 [t=0.30s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Attempt swap
[2000/2000] tot_loss=2.075 (perp=8.441, rec=0.220, cos=0.167), tot_loss_proj:2.551 [t=0.31s]
prediction: ['[CLS] a joyous filmous filmsonicous vuelta [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] a joyous filmous filmsonicous vuelta [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 57.143 | r: 57.143
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.857 | p: 42.857 | r: 42.857
rougeLsum  | fm: 42.857 | p: 42.857 | r: 42.857
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 88.309 | p: 87.492 | r: 89.304
rouge2     | fm: 56.922 | p: 56.571 | r: 57.452
rougeL     | fm: 77.630 | p: 76.980 | r: 78.373
rougeLsum  | fm: 77.686 | p: 77.025 | r: 78.485
r1fm+r2fm = 145.232

input #65 time: 0:12:07 | total time: 13:18:19


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9988939702840258
highest_index [0]
highest [0.9988939702840258]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.8663562536239624 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.8620549440383911 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8502825498580933 for ['[CLS] commerce wikipedia experiment if [SEP]']
[Init] best rec loss: 0.8414666652679443 for ['[CLS] complied man ready panic [SEP]']
[Init] best rec loss: 0.8413494825363159 for ['[CLS] youtubeology r cain [SEP]']
[Init] best rec loss: 0.8389527201652527 for ['[CLS] september st minimum invitation [SEP]']
[Init] best rec loss: 0.8054654002189636 for ['[CLS] helmet stared true deposit [SEP]']
[Init] best rec loss: 0.8036768436431885 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best rec loss: 0.7923311591148376 for ['[CLS] programs will liner brigade [SEP]']
[Init] best perm rec loss: 0.7921156287193298 for ['[CLS] liner will programs brigade [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.941 (perp=10.656, rec=0.384, cos=0.426), tot_loss_proj:2.792 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan playable [SEP]']
[ 100/2000] tot_loss=2.338 (perp=9.079, rec=0.283, cos=0.239), tot_loss_proj:2.149 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan fans [SEP]']
[ 150/2000] tot_loss=2.500 (perp=10.219, rec=0.211, cos=0.244), tot_loss_proj:3.032 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan christians [SEP]']
[ 200/2000] tot_loss=2.433 (perp=9.805, rec=0.218, cos=0.254), tot_loss_proj:2.987 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan huffington [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.541 (perp=10.583, rec=0.200, cos=0.225), tot_loss_proj:3.989 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan lawsuit [SEP]']
[ 300/2000] tot_loss=2.603 (perp=10.583, rec=0.195, cos=0.291), tot_loss_proj:3.985 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan lawsuit [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.555 (perp=10.583, rec=0.186, cos=0.253), tot_loss_proj:3.986 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan lawsuit [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.411 (perp=9.951, rec=0.182, cos=0.239), tot_loss_proj:2.804 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan effort [SEP]']
[ 450/2000] tot_loss=2.550 (perp=10.673, rec=0.178, cos=0.237), tot_loss_proj:2.886 [t=0.31s]
prediction: ['[CLS] longtime tolkien fan jax [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.572 (perp=10.673, rec=0.189, cos=0.248), tot_loss_proj:2.884 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan jax [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.561 (perp=10.673, rec=0.175, cos=0.251), tot_loss_proj:2.881 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan jax [SEP]']
[ 600/2000] tot_loss=2.562 (perp=10.673, rec=0.181, cos=0.247), tot_loss_proj:2.886 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan jax [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.575 (perp=10.673, rec=0.178, cos=0.262), tot_loss_proj:2.884 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan jax [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.573 (perp=10.673, rec=0.184, cos=0.254), tot_loss_proj:2.885 [t=0.31s]
prediction: ['[CLS] longtime tolkien fan jax [SEP]']
[ 750/2000] tot_loss=2.571 (perp=10.673, rec=0.187, cos=0.249), tot_loss_proj:2.886 [t=0.30s]
prediction: ['[CLS] longtime tolkien fan jax [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.559 (perp=10.609, rec=0.190, cos=0.248), tot_loss_proj:3.433 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.561 (perp=10.609, rec=0.186, cos=0.253), tot_loss_proj:3.427 [t=0.31s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
[ 900/2000] tot_loss=2.546 (perp=10.609, rec=0.176, cos=0.248), tot_loss_proj:3.434 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.563 (perp=10.609, rec=0.175, cos=0.267), tot_loss_proj:3.433 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1000/2000] tot_loss=2.555 (perp=10.609, rec=0.179, cos=0.255), tot_loss_proj:3.436 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
[1050/2000] tot_loss=2.569 (perp=10.609, rec=0.184, cos=0.263), tot_loss_proj:3.426 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1100/2000] tot_loss=2.557 (perp=10.609, rec=0.183, cos=0.253), tot_loss_proj:3.431 [t=0.31s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1150/2000] tot_loss=2.560 (perp=10.609, rec=0.181, cos=0.258), tot_loss_proj:3.432 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
[1200/2000] tot_loss=2.561 (perp=10.609, rec=0.176, cos=0.263), tot_loss_proj:3.431 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1250/2000] tot_loss=2.561 (perp=10.609, rec=0.178, cos=0.261), tot_loss_proj:3.435 [t=0.31s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1300/2000] tot_loss=2.556 (perp=10.609, rec=0.173, cos=0.261), tot_loss_proj:3.426 [t=0.31s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
[1350/2000] tot_loss=2.553 (perp=10.609, rec=0.165, cos=0.266), tot_loss_proj:3.431 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1400/2000] tot_loss=2.563 (perp=10.609, rec=0.180, cos=0.261), tot_loss_proj:3.429 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1450/2000] tot_loss=2.559 (perp=10.609, rec=0.174, cos=0.263), tot_loss_proj:3.436 [t=0.31s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
[1500/2000] tot_loss=2.556 (perp=10.609, rec=0.173, cos=0.261), tot_loss_proj:3.431 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1550/2000] tot_loss=2.565 (perp=10.609, rec=0.180, cos=0.263), tot_loss_proj:3.430 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1600/2000] tot_loss=2.556 (perp=10.609, rec=0.168, cos=0.267), tot_loss_proj:3.431 [t=0.31s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
[1650/2000] tot_loss=2.561 (perp=10.609, rec=0.176, cos=0.263), tot_loss_proj:3.426 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1700/2000] tot_loss=2.556 (perp=10.609, rec=0.171, cos=0.263), tot_loss_proj:3.433 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1750/2000] tot_loss=2.571 (perp=10.609, rec=0.183, cos=0.266), tot_loss_proj:3.435 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
[1800/2000] tot_loss=2.563 (perp=10.609, rec=0.178, cos=0.263), tot_loss_proj:3.430 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1850/2000] tot_loss=2.565 (perp=10.609, rec=0.180, cos=0.264), tot_loss_proj:3.430 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[1900/2000] tot_loss=2.559 (perp=10.609, rec=0.176, cos=0.261), tot_loss_proj:3.426 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
[1950/2000] tot_loss=2.573 (perp=10.609, rec=0.190, cos=0.262), tot_loss_proj:3.435 [t=0.30s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Attempt swap
[2000/2000] tot_loss=2.554 (perp=10.609, rec=0.170, cos=0.262), tot_loss_proj:3.429 [t=0.33s]
prediction: ['[CLS] longtime tolkien fanavi [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] longtime tolkien fanavi [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 80.000 | r: 66.667
rouge2     | fm: 22.222 | p: 25.000 | r: 20.000
rougeL     | fm: 72.727 | p: 80.000 | r: 66.667
rougeLsum  | fm: 72.727 | p: 80.000 | r: 66.667
r1fm+r2fm = 94.949

[Aggregate metrics]:
rouge1     | fm: 88.096 | p: 87.404 | r: 88.981
rouge2     | fm: 56.611 | p: 56.183 | r: 57.068
rougeL     | fm: 77.410 | p: 76.795 | r: 78.167
rougeLsum  | fm: 77.650 | p: 77.104 | r: 78.401
r1fm+r2fm = 144.707

input #66 time: 0:12:05 | total time: 13:30:25


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.998628785564021
highest_index [0]
highest [0.998628785564021]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 0.9638789892196655 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.962137758731842 for ['[CLS]tched forward bunk kinds virginiahiparians war ann scenery [SEP]']
[Init] best rec loss: 0.9554975628852844 for ['[CLS] ^ banksgger biology mont neck administration action pool neo [SEP]']
[Init] best rec loss: 0.9511768817901611 for ['[CLS] morton socks backwards blur stiff urban freddy6 you entirely [SEP]']
[Init] best rec loss: 0.9405099153518677 for ['[CLS] midnight fact why done headign promotion else cornelius charm [SEP]']
[Init] best perm rec loss: 0.9389825463294983 for ['[CLS]ign head charm done fact cornelius promotion midnight else why [SEP]']
[Init] best perm rec loss: 0.9384437203407288 for ['[CLS] why done fact midnight else promotion charm corneliusign head [SEP]']
[Init] best perm rec loss: 0.9379181265830994 for ['[CLS] cornelius why promotion fact elseign done head midnight charm [SEP]']
[Init] best perm rec loss: 0.9360567331314087 for ['[CLS] midnight fact why else cornelius done promotionign charm head [SEP]']
[Init] best perm rec loss: 0.9352695345878601 for ['[CLS] cornelius doneign head promotion midnight fact charm why else [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.335 (perp=14.544, rec=0.580, cos=0.846), tot_loss_proj:4.652 [t=0.30s]
prediction: ['[CLS] fiction mustang after maximum kindune kind gun versa kind [SEP]']
[ 100/2000] tot_loss=3.418 (perp=14.400, rec=0.434, cos=0.104), tot_loss_proj:4.643 [t=0.30s]
prediction: ['[CLS]arionwar after reaction k sweet kind t beethoven kind [SEP]']
[ 150/2000] tot_loss=3.277 (perp=13.330, rec=0.428, cos=0.184), tot_loss_proj:4.670 [t=0.30s]
prediction: ['[CLS] magnumwar kind maximumʰwar kindmingental kind [SEP]']
[ 200/2000] tot_loss=2.950 (perp=12.698, rec=0.297, cos=0.113), tot_loss_proj:3.982 [t=0.30s]
prediction: ['[CLS] heartwar kind maximum nonwar kindming everyone kind [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.516 (perp=10.470, rec=0.327, cos=0.095), tot_loss_proj:3.248 [t=0.30s]
prediction: ['[CLS] heart kind kindgm unwarwarming kind kind [SEP]']
[ 300/2000] tot_loss=2.654 (perp=11.446, rec=0.273, cos=0.092), tot_loss_proj:3.461 [t=0.30s]
prediction: ['[CLS] heart kind kindgm nonwarwarming kind kind [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.544 (perp=10.994, rec=0.250, cos=0.095), tot_loss_proj:3.520 [t=0.31s]
prediction: ['[CLS] heart kind kindgmwarwarming kind non kind [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.482 (perp=10.746, rec=0.235, cos=0.098), tot_loss_proj:3.098 [t=0.31s]
prediction: ['[CLS] heart kind kindwarwarmingentalgmental kind [SEP]']
[ 450/2000] tot_loss=2.471 (perp=10.746, rec=0.210, cos=0.112), tot_loss_proj:3.096 [t=0.30s]
prediction: ['[CLS] heart kind kindwarwarmingentalgmental kind [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.234 (perp=9.502, rec=0.211, cos=0.122), tot_loss_proj:2.530 [t=0.30s]
prediction: ['[CLS] kind kind heartwarwarmingentalgmental multi [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.210 (perp=9.242, rec=0.233, cos=0.129), tot_loss_proj:2.293 [t=0.30s]
prediction: ['[CLS] kind kind heartwarwarming multigmentalental [SEP]']
[ 600/2000] tot_loss=2.205 (perp=9.242, rec=0.210, cos=0.146), tot_loss_proj:2.296 [t=0.30s]
prediction: ['[CLS] kind kind heartwarwarming multigmentalental [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.195 (perp=9.242, rec=0.196, cos=0.151), tot_loss_proj:2.294 [t=0.30s]
prediction: ['[CLS] kind kind heartwarwarming multigmentalental [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.094 (perp=8.722, rec=0.199, cos=0.150), tot_loss_proj:2.301 [t=0.31s]
prediction: ['[CLS] kind kind heartwarwarming multientalgmental [SEP]']
[ 750/2000] tot_loss=2.092 (perp=8.722, rec=0.192, cos=0.156), tot_loss_proj:2.297 [t=0.30s]
prediction: ['[CLS] kind kind heartwarwarming multientalgmental [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.119 (perp=8.722, rec=0.202, cos=0.172), tot_loss_proj:2.304 [t=0.30s]
prediction: ['[CLS] kind kind heartwarwarming multientalgmental [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.108 (perp=8.722, rec=0.191, cos=0.173), tot_loss_proj:2.301 [t=0.31s]
prediction: ['[CLS] kind kind heartwarwarming multientalgmental [SEP]']
[ 900/2000] tot_loss=2.106 (perp=8.722, rec=0.188, cos=0.174), tot_loss_proj:2.305 [t=0.30s]
prediction: ['[CLS] kind kind heartwarwarming multientalgmental [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.635 (perp=11.293, rec=0.194, cos=0.183), tot_loss_proj:2.894 [t=0.31s]
prediction: ['[CLS] kind kind heartmingwarming multientalentalental [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.390 (perp=9.962, rec=0.216, cos=0.181), tot_loss_proj:2.575 [t=0.31s]
prediction: ['[CLS] kind kind heartwarming multientalmingentalental [SEP]']
[1050/2000] tot_loss=2.365 (perp=9.962, rec=0.199, cos=0.174), tot_loss_proj:2.574 [t=0.31s]
prediction: ['[CLS] kind kind heartwarming multientalmingentalental [SEP]']
Attempt swap
[1100/2000] tot_loss=2.457 (perp=10.494, rec=0.188, cos=0.171), tot_loss_proj:2.972 [t=0.30s]
prediction: ['[CLS] kind kind heartwarming nonentalmingentalental [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.288 (perp=9.495, rec=0.202, cos=0.187), tot_loss_proj:2.563 [t=0.31s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
[1200/2000] tot_loss=2.262 (perp=9.495, rec=0.187, cos=0.177), tot_loss_proj:2.570 [t=0.30s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Attempt swap
[1250/2000] tot_loss=2.259 (perp=9.495, rec=0.185, cos=0.175), tot_loss_proj:2.561 [t=0.31s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Attempt swap
[1300/2000] tot_loss=2.262 (perp=9.495, rec=0.189, cos=0.174), tot_loss_proj:2.558 [t=0.30s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
[1350/2000] tot_loss=2.249 (perp=9.495, rec=0.175, cos=0.175), tot_loss_proj:2.564 [t=0.30s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Attempt swap
[1400/2000] tot_loss=2.254 (perp=9.495, rec=0.179, cos=0.176), tot_loss_proj:2.564 [t=0.31s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Attempt swap
[1450/2000] tot_loss=2.262 (perp=9.495, rec=0.187, cos=0.175), tot_loss_proj:2.566 [t=0.31s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
[1500/2000] tot_loss=2.254 (perp=9.495, rec=0.182, cos=0.173), tot_loss_proj:2.562 [t=0.30s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Attempt swap
[1550/2000] tot_loss=2.249 (perp=9.495, rec=0.178, cos=0.173), tot_loss_proj:2.568 [t=0.31s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Attempt swap
[1600/2000] tot_loss=2.252 (perp=9.495, rec=0.182, cos=0.171), tot_loss_proj:2.571 [t=0.30s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
[1650/2000] tot_loss=2.247 (perp=9.495, rec=0.175, cos=0.173), tot_loss_proj:2.565 [t=0.31s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Attempt swap
[1700/2000] tot_loss=2.256 (perp=9.495, rec=0.185, cos=0.172), tot_loss_proj:2.573 [t=0.30s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Attempt swap
[1750/2000] tot_loss=2.249 (perp=9.495, rec=0.177, cos=0.173), tot_loss_proj:2.565 [t=0.30s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
[1800/2000] tot_loss=2.254 (perp=9.495, rec=0.182, cos=0.174), tot_loss_proj:2.573 [t=0.30s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Attempt swap
[1850/2000] tot_loss=2.257 (perp=9.495, rec=0.183, cos=0.175), tot_loss_proj:2.569 [t=0.31s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Attempt swap
[1900/2000] tot_loss=2.256 (perp=9.495, rec=0.186, cos=0.170), tot_loss_proj:2.562 [t=0.30s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
[1950/2000] tot_loss=2.262 (perp=9.495, rec=0.187, cos=0.176), tot_loss_proj:2.567 [t=0.30s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Attempt swap
[2000/2000] tot_loss=2.257 (perp=9.495, rec=0.184, cos=0.174), tot_loss_proj:2.564 [t=0.30s]
prediction: ['[CLS] kind kind heartwarmingental nonmingentalental [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind kind heartwarmingental nonmingentalental [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.545 | p: 50.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 54.545 | p: 50.000 | r: 60.000
rougeLsum  | fm: 54.545 | p: 50.000 | r: 60.000
r1fm+r2fm = 54.545

[Aggregate metrics]:
rouge1     | fm: 87.563 | p: 86.848 | r: 88.504
rouge2     | fm: 55.763 | p: 55.420 | r: 56.257
rougeL     | fm: 77.049 | p: 76.417 | r: 77.858
rougeLsum  | fm: 77.140 | p: 76.541 | r: 77.919
r1fm+r2fm = 143.326

input #67 time: 0:12:07 | total time: 13:42:33


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9986314617112105
highest_index [0]
highest [0.9986314617112105]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.93393874168396 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.8828513622283936 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 0.855183482170105 for ['[CLS] instant legs discoveredshboot mass pond arabianvati lines abd star 7 [SEP]']
[Init] best rec loss: 0.8472236394882202 for ['[CLS] $ offs dreams national been wallszzsar council frederick but lankan comprehensive [SEP]']
[Init] best rec loss: 0.7880990505218506 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.784644365310669 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.7782233953475952 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.774395763874054 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.7684122323989868 for ['[CLS] councils. died beth form floor possibly comfort view medal ridingyniferous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.466 (perp=11.175, rec=0.218, cos=0.013), tot_loss_proj:2.843 [t=0.30s]
prediction: ['[CLS] absurd ;sible and niall badly unrelated grandfather vicious, soon moons absurd [SEP]']
[ 100/2000] tot_loss=2.092 (perp=9.642, rec=0.157, cos=0.006), tot_loss_proj:2.458 [t=0.30s]
prediction: ['[CLS] vicioussiblesible and niall badlysible, vicious, vicious sharply absurd [SEP]']
[ 150/2000] tot_loss=2.330 (perp=11.047, rec=0.115, cos=0.005), tot_loss_proj:2.643 [t=0.30s]
prediction: ['[CLS] vicioussibleco and inc badlysible, vicious,per sharply absurd [SEP]']
[ 200/2000] tot_loss=2.249 (perp=10.632, rec=0.117, cos=0.005), tot_loss_proj:2.662 [t=0.30s]
prediction: ['[CLS] vicioussibleco andhen attributedsible, vicious, vicious sharply absurd [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.008 (perp=9.468, rec=0.110, cos=0.005), tot_loss_proj:2.419 [t=0.30s]
prediction: ['[CLS] viciousuthco andhenomphensible, vicious,hen absurd [SEP]']
[ 300/2000] tot_loss=1.975 (perp=9.419, rec=0.088, cos=0.004), tot_loss_proj:2.391 [t=0.30s]
prediction: ['[CLS] viciousuth un andhenomphensible, vicious,hen absurd [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.794 (perp=8.430, rec=0.104, cos=0.004), tot_loss_proj:2.216 [t=0.31s]
prediction: ['[CLS] and viciousuth unhenomphensible, vicious,hen absurd [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.930 (perp=9.095, rec=0.106, cos=0.005), tot_loss_proj:2.321 [t=0.31s]
prediction: ['[CLS] and viciousuth unhenompresible, vicious,hen absurd [SEP]']
[ 450/2000] tot_loss=2.113 (perp=10.140, rec=0.082, cos=0.003), tot_loss_proj:2.431 [t=0.30s]
prediction: ['[CLS] and incuth unhencoresible, vicious,hen absurd [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.113 (perp=10.135, rec=0.084, cos=0.003), tot_loss_proj:2.409 [t=0.30s]
prediction: ['[CLS] and incuth uncoreompsible, vicious,hen absurd [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.797 (perp=8.465, rec=0.099, cos=0.005), tot_loss_proj:2.090 [t=0.31s]
prediction: ['[CLS] and incuth uncoreomphensible, vicious, absurd [SEP]']
[ 600/2000] tot_loss=1.773 (perp=8.465, rec=0.077, cos=0.003), tot_loss_proj:2.096 [t=0.31s]
prediction: ['[CLS] and incuth uncoreomphensible, vicious, absurd [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.510 (perp=7.178, rec=0.070, cos=0.004), tot_loss_proj:1.817 [t=0.31s]
prediction: ['[CLS] and incuth uncoomprehensible, vicious, absurd [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.220 (perp=5.759, rec=0.065, cos=0.004), tot_loss_proj:1.383 [t=0.30s]
prediction: ['[CLS] andcouth un incomprehensible, vicious, absurd [SEP]']
[ 750/2000] tot_loss=1.218 (perp=5.759, rec=0.063, cos=0.003), tot_loss_proj:1.391 [t=0.30s]
prediction: ['[CLS] andcouth un incomprehensible, vicious, absurd [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.085 (perp=5.067, rec=0.069, cos=0.003), tot_loss_proj:1.329 [t=0.31s]
prediction: ['[CLS] and uncouth incomprehensible, vicious, absurd [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.009 (perp=4.686, rec=0.068, cos=0.004), tot_loss_proj:1.219 [t=0.30s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
[ 900/2000] tot_loss=1.013 (perp=4.686, rec=0.073, cos=0.003), tot_loss_proj:1.227 [t=0.30s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.997 (perp=4.686, rec=0.057, cos=0.003), tot_loss_proj:1.224 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1000/2000] tot_loss=1.006 (perp=4.686, rec=0.066, cos=0.003), tot_loss_proj:1.221 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
[1050/2000] tot_loss=1.011 (perp=4.686, rec=0.071, cos=0.003), tot_loss_proj:1.217 [t=0.30s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1100/2000] tot_loss=1.010 (perp=4.686, rec=0.070, cos=0.003), tot_loss_proj:1.221 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1150/2000] tot_loss=1.004 (perp=4.686, rec=0.064, cos=0.003), tot_loss_proj:1.223 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
[1200/2000] tot_loss=1.002 (perp=4.686, rec=0.062, cos=0.003), tot_loss_proj:1.222 [t=0.30s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1250/2000] tot_loss=1.000 (perp=4.686, rec=0.060, cos=0.003), tot_loss_proj:1.210 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1300/2000] tot_loss=0.999 (perp=4.686, rec=0.059, cos=0.003), tot_loss_proj:1.220 [t=0.30s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
[1350/2000] tot_loss=1.008 (perp=4.686, rec=0.068, cos=0.003), tot_loss_proj:1.223 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1400/2000] tot_loss=0.994 (perp=4.686, rec=0.054, cos=0.003), tot_loss_proj:1.216 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1450/2000] tot_loss=0.999 (perp=4.686, rec=0.059, cos=0.003), tot_loss_proj:1.216 [t=0.30s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
[1500/2000] tot_loss=0.999 (perp=4.686, rec=0.059, cos=0.003), tot_loss_proj:1.224 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1550/2000] tot_loss=0.999 (perp=4.686, rec=0.059, cos=0.003), tot_loss_proj:1.220 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1600/2000] tot_loss=1.002 (perp=4.686, rec=0.062, cos=0.003), tot_loss_proj:1.215 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
[1650/2000] tot_loss=0.996 (perp=4.686, rec=0.056, cos=0.003), tot_loss_proj:1.221 [t=0.30s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=1.012 (perp=4.686, rec=0.072, cos=0.003), tot_loss_proj:1.212 [t=0.30s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=1.013 (perp=4.686, rec=0.073, cos=0.003), tot_loss_proj:1.223 [t=0.30s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
[1800/2000] tot_loss=1.000 (perp=4.686, rec=0.060, cos=0.003), tot_loss_proj:1.210 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=0.998 (perp=4.686, rec=0.058, cos=0.003), tot_loss_proj:1.218 [t=0.30s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=1.002 (perp=4.686, rec=0.062, cos=0.003), tot_loss_proj:1.219 [t=0.30s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
[1950/2000] tot_loss=1.002 (perp=4.686, rec=0.062, cos=0.003), tot_loss_proj:1.215 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=1.001 (perp=4.686, rec=0.061, cos=0.003), tot_loss_proj:1.209 [t=0.31s]
prediction: ['[CLS] uncouth incomprehensible, vicious, and absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] uncouth incomprehensible, vicious, and absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.813 | p: 87.100 | r: 88.742
rouge2     | fm: 56.384 | p: 56.082 | r: 56.918
rougeL     | fm: 77.331 | p: 76.748 | r: 78.156
rougeLsum  | fm: 77.555 | p: 76.953 | r: 78.314
r1fm+r2fm = 144.198

input #68 time: 0:12:07 | total time: 13:54:40


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.9987090631646862
highest_index [0]
highest [0.9987090631646862]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.000913381576538 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 1.0003613233566284 for ['[CLS] kim andhra horn doesn n reflected himloaded approximately across stealth hear officetase ranks cross [SEP]']
[Init] best rec loss: 0.9865151643753052 for ['[CLS] advantageharat key bohemian conscious himself aires secondary six peabodynius influence news vanuredhs [SEP]']
[Init] best rec loss: 0.9748859405517578 for ['[CLS] silva minutes wight intermittentelt stevenson trained vice occupied coastrift study low sony their causing [SEP]']
[Init] best rec loss: 0.9678096771240234 for ['[CLS]ulouslyzation mouth abdso disaster hay down curling at forum fallon jupiter fortune whom henry [SEP]']
[Init] best rec loss: 0.9583864212036133 for ['[CLS] closelein am ( deadrga liz range bragg depended states passes stock past messll [SEP]']
[Init] best perm rec loss: 0.9569717049598694 for ['[CLS]leinrga dead am stockll depended close range bragg past mess liz states ( passes [SEP]']
[Init] best perm rec loss: 0.9557610750198364 for ['[CLS] bragg passes liz depended ( stockll range mess dead past states closeleinrga am [SEP]']
[Init] best perm rec loss: 0.9555635452270508 for ['[CLS] am dead pastll close range depended states messrga passes bragg (lein liz stock [SEP]']
[Init] best perm rec loss: 0.9540001749992371 for ['[CLS] states liz am ( close mess past passes deadrga dependedlein bragg rangell stock [SEP]']
[Init] best perm rec loss: 0.9537575840950012 for ['[CLS] past bragg am range (ll stockrga states close depended messlein passes liz dead [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.315 (perp=11.071, rec=0.549, cos=0.552), tot_loss_proj:3.698 [t=0.31s]
prediction: ['[CLS] disappeared crime funny. ( ; killing or alert ryan..metric strongized embrace [SEP]']
[ 100/2000] tot_loss=3.501 (perp=11.198, rec=0.570, cos=0.691), tot_loss_proj:4.226 [t=0.31s]
prediction: ['[CLS] unemployed risk still, ( ; dagger mac corporate replacement,oof innovative champion, love [SEP]']
[ 150/2000] tot_loss=2.674 (perp=9.941, rec=0.443, cos=0.243), tot_loss_proj:3.410 [t=0.31s]
prediction: ['[CLS] ; uncertainty funny, (. dagger tyler brand griffin,. simple smart, : [SEP]']
[ 200/2000] tot_loss=2.744 (perp=10.453, rec=0.387, cos=0.267), tot_loss_proj:3.421 [t=0.31s]
prediction: ['[CLS] soils inequality funny - (. dagger winner brand griffin,. motion smart, : [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.490 (perp=9.270, rec=0.341, cos=0.294), tot_loss_proj:2.592 [t=0.31s]
prediction: ['[CLS] ; real funny - (, dagger brand winner rule,. motion funny, : [SEP]']
[ 300/2000] tot_loss=2.549 (perp=9.360, rec=0.349, cos=0.328), tot_loss_proj:2.615 [t=0.31s]
prediction: ['[CLS] ; real funny - (,lo brand winner first,. motion funny, : [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.647 (perp=10.183, rec=0.304, cos=0.306), tot_loss_proj:2.905 [t=0.31s]
prediction: ['[CLS]tua real funny - ( brandlo, winner first,. motion funny, : [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.381 (perp=8.787, rec=0.334, cos=0.289), tot_loss_proj:2.589 [t=0.31s]
prediction: ['[CLS] real funny - ( brand ;lo, winner first,. motion funny, : [SEP]']
[ 450/2000] tot_loss=2.358 (perp=8.624, rec=0.305, cos=0.328), tot_loss_proj:2.639 [t=0.31s]
prediction: ['[CLS] real funny - ( first ;lo, winner first,. motion funny, : [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.241 (perp=8.180, rec=0.290, cos=0.315), tot_loss_proj:2.483 [t=0.31s]
prediction: ['[CLS] real funny - (, ; fiction, winner first, first motion funny,, [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.463 (perp=9.111, rec=0.323, cos=0.318), tot_loss_proj:3.481 [t=0.31s]
prediction: ['[CLS] first real funny, (,clopslo. isis, first motion funny, won [SEP]']
[ 600/2000] tot_loss=2.310 (perp=8.594, rec=0.285, cos=0.306), tot_loss_proj:3.052 [t=0.31s]
prediction: ['[CLS] first real funny,ン, ;lo. isis, first highly funny, wins [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.317 (perp=8.664, rec=0.278, cos=0.306), tot_loss_proj:3.354 [t=0.31s]
prediction: ['[CLS] - real know -ン,, ; fiction. isis, first highly funny, [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.247 (perp=8.206, rec=0.283, cos=0.322), tot_loss_proj:3.202 [t=0.31s]
prediction: ['[CLS] from know -ン, real, ; fiction.cian, first highly funny, [SEP]']
[ 750/2000] tot_loss=2.514 (perp=9.604, rec=0.285, cos=0.308), tot_loss_proj:3.447 [t=0.31s]
prediction: ['[CLS] from funny -ン, real, ;lo.cian, first highly funny, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.168 (perp=7.930, rec=0.281, cos=0.301), tot_loss_proj:2.291 [t=0.31s]
prediction: ['[CLS] from, -ン, real, funny fiction. isis, perennial highly funny, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.190 (perp=8.087, rec=0.274, cos=0.299), tot_loss_proj:2.323 [t=0.31s]
prediction: ['[CLS] from, -ン, real, funny fiction, selena, perennial highly funny. [SEP]']
[ 900/2000] tot_loss=2.245 (perp=8.294, rec=0.278, cos=0.308), tot_loss_proj:2.470 [t=0.31s]
prediction: ['[CLS] from, -ン, real, funnylo, selena, perennial highly funny. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.088 (perp=7.589, rec=0.271, cos=0.300), tot_loss_proj:2.829 [t=0.31s]
prediction: ['[CLS] first, -ン, real, funnylo, selena, from highly funny. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.601 (perp=9.416, rec=0.401, cos=0.317), tot_loss_proj:3.745 [t=0.31s]
prediction: ['[CLS],. (, - wins funny and appearances,ـ, - $ funny - [SEP]']
[1050/2000] tot_loss=2.531 (perp=9.416, rec=0.345, cos=0.303), tot_loss_proj:3.742 [t=0.31s]
prediction: ['[CLS],. (, - wins funny and appearances,ـ, - $ funny - [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.484 (perp=9.320, rec=0.331, cos=0.289), tot_loss_proj:2.999 [t=0.31s]
prediction: ['[CLS],. (, - wins funny from appearances,ـ, hillary completely funny - [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.301 (perp=8.417, rec=0.324, cos=0.293), tot_loss_proj:2.736 [t=0.31s]
prediction: ['[CLS] wins. (, - ; funny from fiction,ـ, hillary completely funny - [SEP]']
[1200/2000] tot_loss=2.284 (perp=8.417, rec=0.305, cos=0.295), tot_loss_proj:2.728 [t=0.31s]
prediction: ['[CLS] wins. (, - ; funny from fiction,ـ, hillary completely funny - [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.323 (perp=8.577, rec=0.313, cos=0.295), tot_loss_proj:2.707 [t=0.31s]
prediction: ['[CLS] wins. (, -, funny from appearances,ـ, hillary completely funny - [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.184 (perp=7.843, rec=0.314, cos=0.301), tot_loss_proj:3.248 [t=0.31s]
prediction: ['[CLS] wins. ( from, -, funny appearances,ـ, poll completely funny - [SEP]']
[1350/2000] tot_loss=2.187 (perp=7.964, rec=0.296, cos=0.299), tot_loss_proj:3.229 [t=0.31s]
prediction: ['[CLS] wins. ( from, -, funny fiction,ـ, poll completely funny - [SEP]']
Attempt swap
[1400/2000] tot_loss=2.186 (perp=7.964, rec=0.300, cos=0.293), tot_loss_proj:3.234 [t=0.31s]
prediction: ['[CLS] wins. ( from, -, funny fiction,ـ, poll completely funny - [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.111 (perp=7.567, rec=0.304, cos=0.294), tot_loss_proj:3.107 [t=0.31s]
prediction: ['[CLS] wins - ( from, -, funny fiction,ـ, poll completely funny. [SEP]']
[1500/2000] tot_loss=2.110 (perp=7.567, rec=0.309, cos=0.287), tot_loss_proj:3.109 [t=0.31s]
prediction: ['[CLS] wins - ( from, -, funny fiction,ـ, poll completely funny. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.091 (perp=7.567, rec=0.289, cos=0.289), tot_loss_proj:3.111 [t=0.31s]
prediction: ['[CLS] wins - ( from, -, funny fiction,ـ, poll completely funny. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.096 (perp=7.567, rec=0.293, cos=0.289), tot_loss_proj:3.107 [t=0.31s]
prediction: ['[CLS] wins - ( from, -, funny fiction,ـ, poll completely funny. [SEP]']
[1650/2000] tot_loss=2.044 (perp=7.340, rec=0.288, cos=0.288), tot_loss_proj:2.984 [t=0.31s]
prediction: ['[CLS] wins - ( from, -, funny fiction,ـ, poll highly funny. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.066 (perp=7.437, rec=0.291, cos=0.288), tot_loss_proj:3.054 [t=0.31s]
prediction: ['[CLS] wins ( from -, -, funny appearances,ـ, poll highly funny. [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=2.036 (perp=7.270, rec=0.297, cos=0.285), tot_loss_proj:2.989 [t=0.31s]
prediction: ['[CLS] wins from ( -, -, funny appearances,ـ, poll highly funny. [SEP]']
[1800/2000] tot_loss=1.997 (perp=7.089, rec=0.294, cos=0.285), tot_loss_proj:2.927 [t=0.31s]
prediction: ['[CLS] wins from ( -, -, funny fiction,ـ, poll highly funny. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.991 (perp=7.089, rec=0.286, cos=0.287), tot_loss_proj:2.927 [t=0.31s]
prediction: ['[CLS] wins from ( -, -, funny fiction,ـ, poll highly funny. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.989 (perp=7.033, rec=0.301, cos=0.282), tot_loss_proj:2.981 [t=0.31s]
prediction: ['[CLS] wins from ( -, -, fiction funny,ـ, poll highly funny. [SEP]']
[1950/2000] tot_loss=1.983 (perp=7.033, rec=0.293, cos=0.284), tot_loss_proj:2.976 [t=0.31s]
prediction: ['[CLS] wins from ( -, -, fiction funny,ـ, poll highly funny. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.994 (perp=7.033, rec=0.301, cos=0.287), tot_loss_proj:2.978 [t=0.31s]
prediction: ['[CLS] wins from ( -, -, fiction funny,ـ, poll highly funny. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] first, -ン, real, funny appearances, selena, from highly funny. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 40.000 | r: 40.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 40.000 | r: 40.000
rougeLsum  | fm: 40.000 | p: 40.000 | r: 40.000
r1fm+r2fm = 40.000

[Aggregate metrics]:
rouge1     | fm: 87.108 | p: 86.409 | r: 88.033
rouge2     | fm: 55.586 | p: 55.269 | r: 56.003
rougeL     | fm: 76.832 | p: 76.196 | r: 77.614
rougeLsum  | fm: 76.821 | p: 76.297 | r: 77.624
r1fm+r2fm = 142.694

input #69 time: 0:12:22 | total time: 14:07:03


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9987055015351144
highest_index [0]
highest [0.9987055015351144]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8341442942619324 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.7857835292816162 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7806898951530457 for ['[CLS] buenos sol aspects powerful otherpass wallace [SEP]']
[Init] best rec loss: 0.7788000106811523 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7666943073272705 for ['[CLS] oliveira jamie position crime belong leadersla [SEP]']
[Init] best rec loss: 0.7405156493186951 for ['[CLS] ga characteristic jump make deaths composed ⟩ [SEP]']
[Init] best rec loss: 0.7227428555488586 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 0.6968626379966736 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best rec loss: 0.6955555081367493 for ['[CLS] problems cupped potential dyed hear there hunters [SEP]']
[Init] best perm rec loss: 0.6934711337089539 for ['[CLS] hear potential dyed hunters there problems cupped [SEP]']
[Init] best perm rec loss: 0.6934341192245483 for ['[CLS] potential problems hunters dyed cupped hear there [SEP]']
[Init] best perm rec loss: 0.6918078660964966 for ['[CLS] cupped there hunters potential hear dyed problems [SEP]']
[Init] best perm rec loss: 0.6915205717086792 for ['[CLS] potential hunters problems there dyed cupped hear [SEP]']
[Init] best perm rec loss: 0.6914978623390198 for ['[CLS] problems there hear dyed cupped hunters potential [SEP]']
[Init] best perm rec loss: 0.6909542679786682 for ['[CLS] potential dyed cupped hunters hear problems there [SEP]']
[Init] best perm rec loss: 0.6900174021720886 for ['[CLS] there hear hunters cupped potential problems dyed [SEP]']
[Init] best perm rec loss: 0.6894105672836304 for ['[CLS] hunters hear there cupped potential dyed problems [SEP]']
[Init] best perm rec loss: 0.6889914274215698 for ['[CLS] cupped hunters potential problems hear there dyed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.773 (perp=12.059, rec=0.291, cos=0.070), tot_loss_proj:3.446 [t=0.30s]
prediction: ['[CLS] trap planet cl illegalunkycam [SEP]']
[ 100/2000] tot_loss=2.395 (perp=11.141, rec=0.147, cos=0.019), tot_loss_proj:2.960 [t=0.31s]
prediction: ['[CLS] illegal screen cl screenunky gets [SEP]']
[ 150/2000] tot_loss=2.100 (perp=10.058, rec=0.083, cos=0.005), tot_loss_proj:2.741 [t=0.31s]
prediction: ['[CLS] against screen cl onunky gets [SEP]']
[ 200/2000] tot_loss=2.102 (perp=10.058, rec=0.087, cos=0.004), tot_loss_proj:2.732 [t=0.31s]
prediction: ['[CLS] against screen cl onunky gets [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.696 (perp=7.951, rec=0.100, cos=0.006), tot_loss_proj:2.136 [t=0.31s]
prediction: ['[CLS] screen screen on clunky gets [SEP]']
[ 300/2000] tot_loss=1.394 (perp=6.609, rec=0.069, cos=0.003), tot_loss_proj:1.895 [t=0.30s]
prediction: ['[CLS] the screen on clunky gets [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.376 (perp=6.458, rec=0.081, cos=0.003), tot_loss_proj:1.772 [t=0.31s]
prediction: ['[CLS] the screen gets clunky on [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.223 (perp=5.690, rec=0.081, cos=0.004), tot_loss_proj:1.444 [t=0.31s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 450/2000] tot_loss=1.208 (perp=5.690, rec=0.067, cos=0.003), tot_loss_proj:1.442 [t=0.31s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.216 (perp=5.690, rec=0.075, cos=0.003), tot_loss_proj:1.440 [t=0.31s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.209 (perp=5.690, rec=0.068, cos=0.003), tot_loss_proj:1.440 [t=0.31s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 600/2000] tot_loss=1.204 (perp=5.690, rec=0.064, cos=0.003), tot_loss_proj:1.433 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.200 (perp=5.690, rec=0.060, cos=0.003), tot_loss_proj:1.442 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.208 (perp=5.690, rec=0.067, cos=0.003), tot_loss_proj:1.433 [t=0.31s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 750/2000] tot_loss=1.199 (perp=5.690, rec=0.059, cos=0.003), tot_loss_proj:1.432 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.205 (perp=5.690, rec=0.064, cos=0.003), tot_loss_proj:1.429 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.199 (perp=5.690, rec=0.058, cos=0.003), tot_loss_proj:1.439 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 900/2000] tot_loss=1.217 (perp=5.690, rec=0.076, cos=0.003), tot_loss_proj:1.432 [t=0.31s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.206 (perp=5.690, rec=0.065, cos=0.003), tot_loss_proj:1.436 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.202 (perp=5.690, rec=0.062, cos=0.003), tot_loss_proj:1.431 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1050/2000] tot_loss=1.197 (perp=5.690, rec=0.056, cos=0.003), tot_loss_proj:1.435 [t=0.31s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.200 (perp=5.690, rec=0.059, cos=0.003), tot_loss_proj:1.430 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.204 (perp=5.690, rec=0.063, cos=0.003), tot_loss_proj:1.429 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1200/2000] tot_loss=1.205 (perp=5.690, rec=0.065, cos=0.003), tot_loss_proj:1.428 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.205 (perp=5.690, rec=0.064, cos=0.003), tot_loss_proj:1.432 [t=0.31s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.199 (perp=5.690, rec=0.059, cos=0.003), tot_loss_proj:1.432 [t=0.31s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1350/2000] tot_loss=1.211 (perp=5.690, rec=0.070, cos=0.003), tot_loss_proj:1.424 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.204 (perp=5.690, rec=0.063, cos=0.003), tot_loss_proj:1.437 [t=0.31s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.217 (perp=5.690, rec=0.076, cos=0.003), tot_loss_proj:1.430 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1500/2000] tot_loss=1.212 (perp=5.690, rec=0.071, cos=0.003), tot_loss_proj:1.436 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.195 (perp=5.690, rec=0.055, cos=0.003), tot_loss_proj:1.427 [t=0.31s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.208 (perp=5.690, rec=0.068, cos=0.003), tot_loss_proj:1.435 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1650/2000] tot_loss=1.206 (perp=5.690, rec=0.066, cos=0.003), tot_loss_proj:1.439 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.207 (perp=5.690, rec=0.066, cos=0.003), tot_loss_proj:1.426 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.201 (perp=5.690, rec=0.060, cos=0.003), tot_loss_proj:1.426 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1800/2000] tot_loss=1.205 (perp=5.690, rec=0.065, cos=0.003), tot_loss_proj:1.428 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.202 (perp=5.690, rec=0.062, cos=0.003), tot_loss_proj:1.430 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.204 (perp=5.690, rec=0.063, cos=0.003), tot_loss_proj:1.424 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1950/2000] tot_loss=1.201 (perp=5.690, rec=0.061, cos=0.003), tot_loss_proj:1.432 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.213 (perp=5.690, rec=0.073, cos=0.003), tot_loss_proj:1.440 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] on the screen gets clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 87.234 | p: 86.532 | r: 88.150
rouge2     | fm: 55.218 | p: 54.929 | r: 55.657
rougeL     | fm: 76.919 | p: 76.307 | r: 77.660
rougeLsum  | fm: 76.841 | p: 76.317 | r: 77.569
r1fm+r2fm = 142.452

input #70 time: 0:12:07 | total time: 14:19:10


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.998817751199651
highest_index [0]
highest [0.998817751199651]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.922815203666687 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.9045770764350891 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8931691646575928 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 0.8882771730422974 for ['[CLS]od production romatose smith bloody joker chapter trains via returning question tempoq cholera [SEP]']
[Init] best rec loss: 0.882678210735321 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 0.8756580352783203 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 0.8746469616889954 for ['[CLS] clips theory social chains landing ignorance mother game experience point ser [MASK] less whatever other [SEP]']
[Init] best rec loss: 0.8707275986671448 for ['[CLS] faculty / baker these i n youifice broken panic pins roll t outlet institute [SEP]']
[Init] best rec loss: 0.8496988415718079 for ['[CLS]ine runways oregon bored : towardsgold occurred snow abovegerstypical definitely holiday rooney [SEP]']
[Init] best rec loss: 0.8492064476013184 for ['[CLS]lon dictionary short prairie mayatypic conditioning flyingto etc men provided star cassidy gems [SEP]']
[Init] best perm rec loss: 0.8476932048797607 for ['[CLS] dictionary gems star provided conditioning short men etcto flying prairie cassidytypic mayalon [SEP]']
[Init] best perm rec loss: 0.8473465442657471 for ['[CLS] men etc shortlon provided cassidy flying dictionary prairie gemstypic starto conditioning maya [SEP]']
[Init] best perm rec loss: 0.84616619348526 for ['[CLS] menlonto etc cassidy conditioning short gems dictionary provided mayatypic prairie star flying [SEP]']
[Init] best perm rec loss: 0.8460773229598999 for ['[CLS] men short dictionary prairie startypic mayato flying etc conditioning gems cassidy providedlon [SEP]']
[Init] best perm rec loss: 0.8453404307365417 for ['[CLS] prairie dictionary gemstypic shortlon mayato provided men conditioning star flying etc cassidy [SEP]']
[Init] best perm rec loss: 0.8451394438743591 for ['[CLS] maya short conditioningtypic flying gems provided etc men startolon cassidy prairie dictionary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.595 (perp=11.414, rec=0.275, cos=0.037), tot_loss_proj:3.800 [t=0.31s]
prediction: ['[CLS] gravity space and single moment zone no jumping withdrawal not moment ear single moment not [SEP]']
[ 100/2000] tot_loss=1.981 (perp=9.040, rec=0.163, cos=0.011), tot_loss_proj:3.128 [t=0.31s]
prediction: ['[CLS] your seat and single jump seat not - jump there moment jump single a not [SEP]']
[ 150/2000] tot_loss=1.924 (perp=9.018, rec=0.111, cos=0.009), tot_loss_proj:3.131 [t=0.31s]
prediction: ['[CLS] your seat and single jump seat not - jump there moment seat single a not [SEP]']
[ 200/2000] tot_loss=1.875 (perp=8.933, rec=0.083, cos=0.005), tot_loss_proj:2.961 [t=0.31s]
prediction: ['[CLS] your seat and single jump in not - jump there moment seat single a not [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.763 (perp=8.221, rec=0.113, cos=0.007), tot_loss_proj:3.152 [t=0.31s]
prediction: ['[CLS] your seat and single jump in not - jump there moment a single seat s [SEP]']
[ 300/2000] tot_loss=1.970 (perp=9.426, rec=0.081, cos=0.003), tot_loss_proj:2.993 [t=0.31s]
prediction: ['[CLS] your - and single jump in not - your there moment a single seat s [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.713 (perp=8.189, rec=0.073, cos=0.003), tot_loss_proj:2.778 [t=0.31s]
prediction: ['[CLS] your moment and single jump in not - your there - a single seat s [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.642 (perp=7.806, rec=0.077, cos=0.003), tot_loss_proj:3.312 [t=0.31s]
prediction: ['[CLS] your moment and single not in jump - your there - a single seat s [SEP]']
[ 450/2000] tot_loss=1.639 (perp=7.806, rec=0.076, cos=0.003), tot_loss_proj:3.313 [t=0.31s]
prediction: ['[CLS] your moment and single not in jump - your there - a single seat s [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.599 (perp=7.638, rec=0.069, cos=0.002), tot_loss_proj:3.306 [t=0.31s]
prediction: ['[CLS] your seat and single not in jump - your there - a single moment s [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.557 (perp=7.393, rec=0.075, cos=0.003), tot_loss_proj:3.191 [t=0.31s]
prediction: ['[CLS] your seat single and not in jump - your there - a single moment s [SEP]']
[ 600/2000] tot_loss=1.556 (perp=7.393, rec=0.075, cos=0.003), tot_loss_proj:3.200 [t=0.31s]
prediction: ['[CLS] your seat single and not in jump - your there - a single moment s [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.435 (perp=6.807, rec=0.071, cos=0.002), tot_loss_proj:3.004 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - in there - a single moment s [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.326 (perp=6.229, rec=0.077, cos=0.003), tot_loss_proj:2.837 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - in there a single moment - s [SEP]']
[ 750/2000] tot_loss=1.322 (perp=6.229, rec=0.074, cos=0.003), tot_loss_proj:2.839 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - in there a single moment - s [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.297 (perp=6.120, rec=0.070, cos=0.003), tot_loss_proj:3.052 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.290 (perp=6.120, rec=0.063, cos=0.003), tot_loss_proj:3.053 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
[ 900/2000] tot_loss=1.301 (perp=6.120, rec=0.074, cos=0.003), tot_loss_proj:3.052 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.301 (perp=6.120, rec=0.075, cos=0.003), tot_loss_proj:3.051 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[1000/2000] tot_loss=1.296 (perp=6.120, rec=0.069, cos=0.002), tot_loss_proj:3.052 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
[1050/2000] tot_loss=1.288 (perp=6.120, rec=0.062, cos=0.003), tot_loss_proj:3.051 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[1100/2000] tot_loss=1.292 (perp=6.120, rec=0.065, cos=0.002), tot_loss_proj:3.052 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[1150/2000] tot_loss=1.300 (perp=6.120, rec=0.073, cos=0.002), tot_loss_proj:3.049 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
[1200/2000] tot_loss=1.295 (perp=6.120, rec=0.069, cos=0.002), tot_loss_proj:3.049 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[1250/2000] tot_loss=1.289 (perp=6.120, rec=0.062, cos=0.003), tot_loss_proj:3.051 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[1300/2000] tot_loss=1.293 (perp=6.120, rec=0.067, cos=0.002), tot_loss_proj:3.054 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
[1350/2000] tot_loss=1.297 (perp=6.120, rec=0.071, cos=0.002), tot_loss_proj:3.053 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[1400/2000] tot_loss=1.289 (perp=6.120, rec=0.062, cos=0.002), tot_loss_proj:3.057 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[1450/2000] tot_loss=1.287 (perp=6.120, rec=0.060, cos=0.002), tot_loss_proj:3.053 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
[1500/2000] tot_loss=1.292 (perp=6.120, rec=0.066, cos=0.002), tot_loss_proj:3.053 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[1550/2000] tot_loss=1.295 (perp=6.120, rec=0.069, cos=0.002), tot_loss_proj:3.050 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[1600/2000] tot_loss=1.293 (perp=6.120, rec=0.067, cos=0.002), tot_loss_proj:3.057 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
[1650/2000] tot_loss=1.292 (perp=6.120, rec=0.066, cos=0.002), tot_loss_proj:3.056 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
[1700/2000] tot_loss=1.285 (perp=6.120, rec=0.059, cos=0.002), tot_loss_proj:3.059 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - there in a single moment - s [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.283 (perp=6.019, rec=0.076, cos=0.003), tot_loss_proj:2.890 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - single there in a moment - s [SEP]']
[1800/2000] tot_loss=1.267 (perp=6.019, rec=0.060, cos=0.003), tot_loss_proj:2.898 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - single there in a moment - s [SEP]']
Attempt swap
[1850/2000] tot_loss=1.271 (perp=6.019, rec=0.064, cos=0.003), tot_loss_proj:2.895 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - single there in a moment - s [SEP]']
Attempt swap
[1900/2000] tot_loss=1.270 (perp=6.019, rec=0.064, cos=0.003), tot_loss_proj:2.899 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - single there in a moment - s [SEP]']
[1950/2000] tot_loss=1.274 (perp=6.019, rec=0.067, cos=0.002), tot_loss_proj:2.895 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - single there in a moment - s [SEP]']
Attempt swap
[2000/2000] tot_loss=1.276 (perp=6.019, rec=0.069, cos=0.003), tot_loss_proj:2.892 [t=0.31s]
prediction: ['[CLS] your seat single and not your jump - single there in a moment - s [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] your seat single and not your jump - single there in a moment - s [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.857 | p: 86.667 | r: 100.000
rouge2     | fm: 7.692 | p: 7.143 | r: 8.333
rougeL     | fm: 42.857 | p: 40.000 | r: 46.154
rougeLsum  | fm: 42.857 | p: 40.000 | r: 46.154
r1fm+r2fm = 100.549

[Aggregate metrics]:
rouge1     | fm: 87.410 | p: 86.635 | r: 88.408
rouge2     | fm: 54.760 | p: 54.416 | r: 55.187
rougeL     | fm: 76.365 | p: 75.781 | r: 77.123
rougeLsum  | fm: 76.471 | p: 75.859 | r: 77.262
r1fm+r2fm = 142.170

input #71 time: 0:12:21 | total time: 14:31:31


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9985458087041754
highest_index [0]
highest [0.9985458087041754]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.8017071485519409 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7735590934753418 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 0.7452703714370728 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7442600727081299 for ['[CLS]nted seriously public caesar failure major eli city edo memberf runway koppen join useless [SEP]']
[Init] best rec loss: 0.7409540414810181 for ['[CLS] annabelle child bucketeesya thrown typical moses alive knowing regions users keys lilly liz [SEP]']
[Init] best rec loss: 0.7341107130050659 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 0.7288260459899902 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.7169990539550781 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best rec loss: 0.7111775875091553 for ['[CLS] them relations quickly sip abexed without connected counties glacier digitalhic professor teller page [SEP]']
[Init] best perm rec loss: 0.70651775598526 for ['[CLS] connectedxed page glacier digital professor counties siphic without them teller abe quickly relations [SEP]']
[Init] best perm rec loss: 0.7062179446220398 for ['[CLS] connected them teller without glacier counties relations abexed sip professor digital page quicklyhic [SEP]']
[Init] best perm rec loss: 0.7059453129768372 for ['[CLS] relations abe counties page professor sipxed them quicklyhic digital glacier connected without teller [SEP]']
[Init] best perm rec loss: 0.7048032283782959 for ['[CLS] without connected counties relations digital abehicxed quickly teller glacier sip professor page them [SEP]']
[Init] best perm rec loss: 0.7044340372085571 for ['[CLS] page digital without abe connected sip professor relations them tellerxed counties quicklyhic glacier [SEP]']
[Init] best perm rec loss: 0.7032748460769653 for ['[CLS] counties sip without relations professor page glacier connectedhic themxed abe teller quickly digital [SEP]']
[Init] best perm rec loss: 0.7025406360626221 for ['[CLS] relationshic connected sip page without themxed abe quickly professor glacier teller digital counties [SEP]']
[Init] best perm rec loss: 0.7024258375167847 for ['[CLS] connectedhic glacier professor them page without relations countiesxed quickly sip abe teller digital [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.383 (perp=10.535, rec=0.253, cos=0.023), tot_loss_proj:3.023 [t=0.31s]
prediction: ['[CLS] has tough tougher violence involving fire by battery trying eventually gas drug philosophical time [SEP]']
[ 100/2000] tot_loss=2.190 (perp=10.228, rec=0.133, cos=0.011), tot_loss_proj:3.315 [t=0.31s]
prediction: ['[CLS] has tough tougher time involvingune with fight balancing its violence violent inspired time [SEP]']
[ 150/2000] tot_loss=1.954 (perp=9.244, rec=0.097, cos=0.008), tot_loss_proj:2.643 [t=0.31s]
prediction: ['[CLS] has tough tougher time involving its with violence balancing its violence violent philosophy time [SEP]']
[ 200/2000] tot_loss=1.888 (perp=8.943, rec=0.092, cos=0.007), tot_loss_proj:2.564 [t=0.31s]
prediction: ['[CLS] has tough tougher time balancing its with violence balancing its violence violent philosophy time [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.971 (perp=9.391, rec=0.087, cos=0.006), tot_loss_proj:2.594 [t=0.31s]
prediction: ['[CLS] hasfk tougher time balancing its violence with balancing its violence gandhi philosophy time [SEP]']
[ 300/2000] tot_loss=2.185 (perp=10.481, rec=0.084, cos=0.005), tot_loss_proj:2.782 [t=0.31s]
prediction: ['[CLS] hasfk tougher time balancing a violence with balancing its itsfk philosophy time [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.172 (perp=10.142, rec=0.127, cos=0.017), tot_loss_proj:2.764 [t=0.31s]
prediction: ['[CLS] hasfk tougher time involving its violence with balancing itsetyfk philosophy time [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.105 (perp=10.032, rec=0.092, cos=0.007), tot_loss_proj:3.126 [t=0.31s]
prediction: ['[CLS] hasfk tougher time ex its violence with time balancing itsetyfk philosophy [SEP]']
[ 450/2000] tot_loss=2.099 (perp=10.032, rec=0.087, cos=0.005), tot_loss_proj:3.127 [t=0.31s]
prediction: ['[CLS] hasfk tougher time ex its violence with time balancing itsetyfk philosophy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.947 (perp=9.307, rec=0.080, cos=0.005), tot_loss_proj:2.424 [t=0.31s]
prediction: ['[CLS]k has tougher time ex its violence with time balancing itsetyfk philosophy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.889 (perp=9.013, rec=0.081, cos=0.006), tot_loss_proj:2.537 [t=0.31s]
prediction: ['[CLS] z has tougher time went its violence with time balancing its moviefk philosophy [SEP]']
[ 600/2000] tot_loss=2.104 (perp=10.083, rec=0.082, cos=0.005), tot_loss_proj:2.904 [t=0.31s]
prediction: ['[CLS] ka has tougher time questions its violence with time balancing inspired moviefk philosophy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.980 (perp=9.485, rec=0.078, cos=0.005), tot_loss_proj:2.244 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence with time questions inspired moviefk philosophy [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.846 (perp=8.781, rec=0.084, cos=0.005), tot_loss_proj:2.060 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence with timefk inspired movie questions philosophy [SEP]']
[ 750/2000] tot_loss=1.871 (perp=8.994, rec=0.067, cos=0.005), tot_loss_proj:2.144 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence with -fk inspired movie questions philosophy [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.746 (perp=8.327, rec=0.076, cos=0.005), tot_loss_proj:1.965 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie questions - philosophy [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.727 (perp=8.290, rec=0.064, cos=0.005), tot_loss_proj:1.935 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy - questions [SEP]']
[ 900/2000] tot_loss=1.738 (perp=8.290, rec=0.075, cos=0.004), tot_loss_proj:1.946 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy - questions [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.819 (perp=8.664, rec=0.082, cos=0.004), tot_loss_proj:2.180 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie - philosophy went [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.761 (perp=8.403, rec=0.076, cos=0.004), tot_loss_proj:2.238 [t=0.32s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy - went [SEP]']
[1050/2000] tot_loss=1.764 (perp=8.403, rec=0.079, cos=0.004), tot_loss_proj:2.241 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy - went [SEP]']
Attempt swap
[1100/2000] tot_loss=1.756 (perp=8.403, rec=0.071, cos=0.004), tot_loss_proj:2.238 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy - went [SEP]']
Attempt swap
[1150/2000] tot_loss=1.751 (perp=8.403, rec=0.066, cos=0.004), tot_loss_proj:2.244 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy - went [SEP]']
[1200/2000] tot_loss=1.838 (perp=8.816, rec=0.070, cos=0.004), tot_loss_proj:2.053 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy -idal [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.848 (perp=8.838, rec=0.076, cos=0.004), tot_loss_proj:2.124 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its questions violence withfk inspired movie philosophy - [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.740 (perp=8.290, rec=0.077, cos=0.004), tot_loss_proj:1.933 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy - questions [SEP]']
[1350/2000] tot_loss=1.731 (perp=8.290, rec=0.069, cos=0.004), tot_loss_proj:1.926 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy - questions [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.723 (perp=8.277, rec=0.064, cos=0.004), tot_loss_proj:1.940 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy questions - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.736 (perp=8.277, rec=0.077, cos=0.004), tot_loss_proj:1.944 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy questions - [SEP]']
[1500/2000] tot_loss=1.878 (perp=9.042, rec=0.065, cos=0.004), tot_loss_proj:2.105 [t=0.31s]
prediction: ['[CLS] ka has tougher time balancing its violence withfk inspired movie philosophyidal - [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.752 (perp=8.321, rec=0.083, cos=0.005), tot_loss_proj:2.055 [t=0.31s]
prediction: ['[CLS] ka questions has tougher time balancing its violence withfk inspired movie philosophy - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.745 (perp=8.321, rec=0.077, cos=0.004), tot_loss_proj:2.047 [t=0.31s]
prediction: ['[CLS] ka questions has tougher time balancing its violence withfk inspired movie philosophy - [SEP]']
[1650/2000] tot_loss=1.742 (perp=8.321, rec=0.073, cos=0.004), tot_loss_proj:2.051 [t=0.31s]
prediction: ['[CLS] ka questions has tougher time balancing its violence withfk inspired movie philosophy - [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.651 (perp=7.811, rec=0.084, cos=0.004), tot_loss_proj:2.118 [t=0.31s]
prediction: ['[CLS] ka questionser has tough time balancing its violence withfk inspired movie philosophy - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.640 (perp=7.811, rec=0.074, cos=0.004), tot_loss_proj:2.125 [t=0.31s]
prediction: ['[CLS] ka questionser has tough time balancing its violence withfk inspired movie philosophy - [SEP]']
[1800/2000] tot_loss=1.630 (perp=7.811, rec=0.063, cos=0.004), tot_loss_proj:2.117 [t=0.31s]
prediction: ['[CLS] ka questionser has tough time balancing its violence withfk inspired movie philosophy - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.650 (perp=7.811, rec=0.084, cos=0.004), tot_loss_proj:2.117 [t=0.31s]
prediction: ['[CLS] ka questionser has tough time balancing its violence withfk inspired movie philosophy - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.645 (perp=7.811, rec=0.079, cos=0.004), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] ka questionser has tough time balancing its violence withfk inspired movie philosophy - [SEP]']
[1950/2000] tot_loss=1.640 (perp=7.811, rec=0.073, cos=0.004), tot_loss_proj:2.125 [t=0.31s]
prediction: ['[CLS] ka questionser has tough time balancing its violence withfk inspired movie philosophy - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.640 (perp=7.811, rec=0.074, cos=0.004), tot_loss_proj:2.118 [t=0.31s]
prediction: ['[CLS] ka questionser has tough time balancing its violence withfk inspired movie philosophy - [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] ka has tougher time balancing its violence withfk inspired movie philosophy questions - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.074 | p: 71.429 | r: 76.923
rouge2     | fm: 32.000 | p: 30.769 | r: 33.333
rougeL     | fm: 74.074 | p: 71.429 | r: 76.923
rougeLsum  | fm: 74.074 | p: 71.429 | r: 76.923
r1fm+r2fm = 106.074

[Aggregate metrics]:
rouge1     | fm: 87.174 | p: 86.338 | r: 88.232
rouge2     | fm: 54.362 | p: 53.946 | r: 54.743
rougeL     | fm: 76.371 | p: 75.768 | r: 77.145
rougeLsum  | fm: 76.344 | p: 75.768 | r: 77.148
r1fm+r2fm = 141.536

input #72 time: 0:12:23 | total time: 14:43:54


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9986505153153075
highest_index [0]
highest [0.9986505153153075]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9879938960075378 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9762401580810547 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9406700134277344 for ['[CLS] garage knight [SEP]']
[Init] best rec loss: 0.9159116148948669 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9016239643096924 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.8891702890396118 for ['[CLS] denied airline [SEP]']
[Init] best rec loss: 0.8748607635498047 for ['[CLS] puget traditional [SEP]']
[Init] best rec loss: 0.8623113036155701 for ['[CLS] split china [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.107 (perp=9.723, rec=0.157, cos=0.005), tot_loss_proj:2.025 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.042 (perp=9.723, rec=0.093, cos=0.004), tot_loss_proj:2.021 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.034 (perp=9.723, rec=0.086, cos=0.004), tot_loss_proj:2.025 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.032 (perp=9.723, rec=0.084, cos=0.004), tot_loss_proj:2.019 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.019 (perp=9.723, rec=0.071, cos=0.003), tot_loss_proj:2.013 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.003), tot_loss_proj:2.009 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.004 (perp=9.723, rec=0.056, cos=0.003), tot_loss_proj:2.003 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.992 (perp=9.723, rec=0.045, cos=0.003), tot_loss_proj:2.027 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.020 (perp=9.723, rec=0.073, cos=0.003), tot_loss_proj:2.010 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.005 (perp=9.723, rec=0.058, cos=0.003), tot_loss_proj:2.017 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.014 (perp=9.723, rec=0.067, cos=0.003), tot_loss_proj:2.015 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.015 (perp=9.723, rec=0.068, cos=0.003), tot_loss_proj:2.002 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.012 (perp=9.723, rec=0.064, cos=0.003), tot_loss_proj:2.014 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.012 (perp=9.723, rec=0.064, cos=0.003), tot_loss_proj:2.009 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.013 (perp=9.723, rec=0.066, cos=0.003), tot_loss_proj:2.006 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.013 (perp=9.723, rec=0.065, cos=0.003), tot_loss_proj:2.026 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.007 (perp=9.723, rec=0.059, cos=0.003), tot_loss_proj:2.021 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.003 (perp=9.723, rec=0.055, cos=0.003), tot_loss_proj:2.013 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.016 (perp=9.723, rec=0.068, cos=0.003), tot_loss_proj:2.014 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.016 (perp=9.723, rec=0.069, cos=0.003), tot_loss_proj:2.021 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.008 (perp=9.723, rec=0.060, cos=0.003), tot_loss_proj:2.016 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.001 (perp=9.723, rec=0.054, cos=0.003), tot_loss_proj:2.006 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.003), tot_loss_proj:2.012 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.001 (perp=9.723, rec=0.054, cos=0.003), tot_loss_proj:2.021 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.007 (perp=9.723, rec=0.060, cos=0.003), tot_loss_proj:2.005 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.025 (perp=9.723, rec=0.077, cos=0.003), tot_loss_proj:2.027 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.022 (perp=9.723, rec=0.075, cos=0.003), tot_loss_proj:2.016 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.006 (perp=9.723, rec=0.058, cos=0.003), tot_loss_proj:2.011 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.001 (perp=9.723, rec=0.053, cos=0.003), tot_loss_proj:2.029 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.012 (perp=9.723, rec=0.065, cos=0.003), tot_loss_proj:2.016 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.014 (perp=9.723, rec=0.067, cos=0.003), tot_loss_proj:2.023 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.004 (perp=9.723, rec=0.057, cos=0.003), tot_loss_proj:2.023 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.012 (perp=9.723, rec=0.064, cos=0.003), tot_loss_proj:2.015 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.012 (perp=9.723, rec=0.065, cos=0.003), tot_loss_proj:2.012 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.011 (perp=9.723, rec=0.064, cos=0.003), tot_loss_proj:2.023 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.000 (perp=9.723, rec=0.053, cos=0.003), tot_loss_proj:2.023 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.016 (perp=9.723, rec=0.068, cos=0.003), tot_loss_proj:2.005 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.004 (perp=9.723, rec=0.057, cos=0.003), tot_loss_proj:2.012 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.003), tot_loss_proj:2.024 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.016 (perp=9.723, rec=0.068, cos=0.003), tot_loss_proj:2.020 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.262 | p: 86.435 | r: 88.309
rouge2     | fm: 54.866 | p: 54.583 | r: 55.276
rougeL     | fm: 76.637 | p: 75.965 | r: 77.418
rougeLsum  | fm: 76.696 | p: 76.031 | r: 77.476
r1fm+r2fm = 142.128

input #73 time: 0:12:04 | total time: 14:55:59


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9988935659855986
highest_index [0]
highest [0.9988935659855986]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 0.880859375 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.7052992582321167 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.7038629651069641 for ['[CLS] answering [SEP]']
[Init] best rec loss: 0.6989229321479797 for ['[CLS] ahead [SEP]']
[Init] best rec loss: 0.6932417154312134 for ['[CLS] sky [SEP]']
[Init] best rec loss: 0.6742309927940369 for ['[CLS] coup [SEP]']
[Init] best rec loss: 0.6736689805984497 for ['[CLS] birth [SEP]']
[Init] best rec loss: 0.6724899411201477 for ['[CLS] offense [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.727 (perp=8.178, rec=0.087, cos=0.005), tot_loss_proj:1.785 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.714 (perp=8.178, rec=0.073, cos=0.005), tot_loss_proj:1.752 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.705 (perp=8.178, rec=0.065, cos=0.005), tot_loss_proj:1.756 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.699 (perp=8.178, rec=0.058, cos=0.006), tot_loss_proj:1.741 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.706 (perp=8.178, rec=0.068, cos=0.003), tot_loss_proj:1.737 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.712 (perp=8.178, rec=0.072, cos=0.005), tot_loss_proj:1.735 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.704 (perp=8.178, rec=0.066, cos=0.003), tot_loss_proj:1.737 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.708 (perp=8.178, rec=0.069, cos=0.003), tot_loss_proj:1.741 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.703 (perp=8.178, rec=0.064, cos=0.003), tot_loss_proj:1.738 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.698 (perp=8.178, rec=0.059, cos=0.003), tot_loss_proj:1.728 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.703 (perp=8.178, rec=0.064, cos=0.003), tot_loss_proj:1.730 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.697 (perp=8.178, rec=0.058, cos=0.003), tot_loss_proj:1.746 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.701 (perp=8.178, rec=0.063, cos=0.003), tot_loss_proj:1.725 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.691 (perp=8.178, rec=0.053, cos=0.003), tot_loss_proj:1.729 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.706 (perp=8.178, rec=0.067, cos=0.003), tot_loss_proj:1.736 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.701 (perp=8.178, rec=0.062, cos=0.003), tot_loss_proj:1.726 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.684 (perp=8.178, rec=0.046, cos=0.003), tot_loss_proj:1.733 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.698 (perp=8.178, rec=0.060, cos=0.003), tot_loss_proj:1.729 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.697 (perp=8.178, rec=0.059, cos=0.003), tot_loss_proj:1.725 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.705 (perp=8.178, rec=0.066, cos=0.003), tot_loss_proj:1.733 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.695 (perp=8.178, rec=0.057, cos=0.003), tot_loss_proj:1.738 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.714 (perp=8.178, rec=0.076, cos=0.003), tot_loss_proj:1.736 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.704 (perp=8.178, rec=0.066, cos=0.003), tot_loss_proj:1.734 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.691 (perp=8.178, rec=0.053, cos=0.003), tot_loss_proj:1.747 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.699 (perp=8.178, rec=0.061, cos=0.003), tot_loss_proj:1.728 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.700 (perp=8.178, rec=0.062, cos=0.003), tot_loss_proj:1.730 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.712 (perp=8.178, rec=0.074, cos=0.003), tot_loss_proj:1.728 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.710 (perp=8.178, rec=0.071, cos=0.003), tot_loss_proj:1.732 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.697 (perp=8.178, rec=0.059, cos=0.003), tot_loss_proj:1.730 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.708 (perp=8.178, rec=0.070, cos=0.003), tot_loss_proj:1.726 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.705 (perp=8.178, rec=0.066, cos=0.003), tot_loss_proj:1.735 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.705 (perp=8.178, rec=0.067, cos=0.003), tot_loss_proj:1.728 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.695 (perp=8.178, rec=0.056, cos=0.003), tot_loss_proj:1.740 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.699 (perp=8.178, rec=0.061, cos=0.003), tot_loss_proj:1.737 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.692 (perp=8.178, rec=0.054, cos=0.003), tot_loss_proj:1.734 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.696 (perp=8.178, rec=0.057, cos=0.003), tot_loss_proj:1.743 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.682 (perp=8.178, rec=0.043, cos=0.003), tot_loss_proj:1.727 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.707 (perp=8.178, rec=0.068, cos=0.003), tot_loss_proj:1.741 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.702 (perp=8.178, rec=0.063, cos=0.003), tot_loss_proj:1.742 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.703 (perp=8.178, rec=0.065, cos=0.003), tot_loss_proj:1.737 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.493 | p: 86.674 | r: 88.499
rouge2     | fm: 55.535 | p: 55.235 | r: 55.939
rougeL     | fm: 76.914 | p: 76.251 | r: 77.742
rougeLsum  | fm: 77.135 | p: 76.494 | r: 77.891
r1fm+r2fm = 143.027

input #74 time: 0:11:04 | total time: 15:07:03


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9988630194932029
highest_index [0]
highest [0.9988630194932029]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.8620458245277405 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.8420581817626953 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.8272808790206909 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best rec loss: 0.8227735757827759 for ['[CLS] chaintrybro savings path part accolades truck visa chenses stateach foundation speak theme rather utter english [SEP]']
[Init] best perm rec loss: 0.8220593333244324 for ['[CLS] chen state rather pathbro englishtrysesach accolades truck chain utter speak part savings visa theme foundation [SEP]']
[Init] best perm rec loss: 0.8197231292724609 for ['[CLS]ses truck path stateach rather chen utter accoladestry savings foundation english part speak theme visa chainbro [SEP]']
[Init] best perm rec loss: 0.8189340829849243 for ['[CLS] english chen foundation parttry accolades utterach savings chain rather path visasesbro truck state speak theme [SEP]']
[Init] best perm rec loss: 0.8175358176231384 for ['[CLS] chain rather path english savings truck theme partbro accolades visa stateachses chentry foundation utter speak [SEP]']
[Init] best perm rec loss: 0.8170965313911438 for ['[CLS] theme chen english pathses savings speak state foundation ratherbroach truck utter accolades chaintry part visa [SEP]']
[Init] best perm rec loss: 0.816797137260437 for ['[CLS] foundation chain part truckach theme accolades chen visa englishtry rather utterbroses path state speak savings [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.890 (perp=12.324, rec=0.373, cos=0.052), tot_loss_proj:4.239 [t=0.31s]
prediction: ['[CLS] foundation of playerducted spin greeted stress dismiss yankees of assigneddles strewn never without forgottentidae an. [SEP]']
[ 100/2000] tot_loss=2.378 (perp=10.660, rec=0.216, cos=0.030), tot_loss_proj:3.330 [t=0.31s]
prediction: ['[CLS] career easily situation ᅧ flows solved easily dismiss dismissed being dismissed into suddenly not not forgotten or /. [SEP]']
[ 150/2000] tot_loss=2.236 (perp=10.175, rec=0.172, cos=0.029), tot_loss_proj:3.640 [t=0.31s]
prediction: ['[CLS] excursion easily situation ᅧ ressitor possibly dismissed dismissed is dismissed into instability not easily forgotten or is. [SEP]']
[ 200/2000] tot_loss=2.262 (perp=10.454, rec=0.146, cos=0.026), tot_loss_proj:3.702 [t=0.31s]
prediction: ['[CLS] excursion easily situation instability epicbert quite instability dismissed is dismissederland instability not easily forgotten or is. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.291 (perp=10.583, rec=0.156, cos=0.018), tot_loss_proj:3.834 [t=0.31s]
prediction: ['[CLS] excursion isrued instability epicard hyper instability is dismissedcola instability not easily forgotten or. not? [SEP]']
[ 300/2000] tot_loss=2.328 (perp=10.873, rec=0.132, cos=0.021), tot_loss_proj:3.861 [t=0.31s]
prediction: ['[CLS] excursion isrued instability epicent mental instability is dismissedcola instability not easily forgotten or. symphonic. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.091 (perp=9.771, rec=0.114, cos=0.024), tot_loss_proj:3.690 [t=0.31s]
prediction: ['[CLS] excursion is wandered. epicent mental instability is dismissedcola instability not easily dismissed or. symphonic instability [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.050 (perp=9.539, rec=0.112, cos=0.031), tot_loss_proj:3.641 [t=0.31s]
prediction: ['[CLS] excursion is wandered.enterent mental instability being dismissedcola instability not easily dismissed or over instability. [SEP]']
[ 450/2000] tot_loss=2.055 (perp=9.600, rec=0.109, cos=0.026), tot_loss_proj:3.485 [t=0.31s]
prediction: ['[CLS] this is excursion.enterent mental mental being forgottencola instability not easily dismissed or over instability. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.907 (perp=8.942, rec=0.101, cos=0.018), tot_loss_proj:3.508 [t=0.31s]
prediction: ['[CLS] this mental excursion.enterent is mental being forgottencola instability not easily dismissed or met instability. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.957 (perp=9.257, rec=0.094, cos=0.012), tot_loss_proj:3.410 [t=0.31s]
prediction: ['[CLS] this mental excursion. duringenter is mental the forgottencola instability not easily dismissed or met instability. [SEP]']
[ 600/2000] tot_loss=1.954 (perp=9.257, rec=0.090, cos=0.012), tot_loss_proj:3.414 [t=0.31s]
prediction: ['[CLS] this mental excursion. duringenter is mental the forgottencola instability not easily dismissed or met instability. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.768 (perp=8.287, rec=0.096, cos=0.015), tot_loss_proj:3.251 [t=0.31s]
prediction: ['[CLS] this mental excursion. duringenter is the forgottencola mental instability not easily dismissed or met ᅧ. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.699 (perp=7.960, rec=0.095, cos=0.012), tot_loss_proj:2.848 [t=0.31s]
prediction: ['[CLS] this mental excursion duringenter is the forgottencola mental instability. not easily dismissed or ofting. [SEP]']
[ 750/2000] tot_loss=1.694 (perp=7.960, rec=0.092, cos=0.011), tot_loss_proj:2.836 [t=0.31s]
prediction: ['[CLS] this mental excursion duringenter is the forgottencola mental instability. not easily dismissed or ofting. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.677 (perp=7.922, rec=0.078, cos=0.015), tot_loss_proj:2.860 [t=0.31s]
prediction: ['[CLS] this excursion mental duringenter is the forgottencola mental instability. not easily dismissed or ofting. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.589 (perp=7.389, rec=0.100, cos=0.012), tot_loss_proj:2.652 [t=0.31s]
prediction: ['[CLS] this excursion mental duringenter is the forgotten mental instability. not easily dismissed or ofcolating. [SEP]']
[ 900/2000] tot_loss=1.579 (perp=7.389, rec=0.087, cos=0.014), tot_loss_proj:2.659 [t=0.31s]
prediction: ['[CLS] this excursion mental duringenter is the forgotten mental instability. not easily dismissed or ofcolating. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.585 (perp=7.389, rec=0.093, cos=0.014), tot_loss_proj:2.661 [t=0.31s]
prediction: ['[CLS] this excursion mental duringenter is the forgotten mental instability. not easily dismissed or ofcolating. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.554 (perp=7.268, rec=0.089, cos=0.012), tot_loss_proj:2.852 [t=0.31s]
prediction: ['[CLS] this excursion mentalenter is the forgotten mental instability during. not easily dismissed or ofcolating. [SEP]']
[1050/2000] tot_loss=1.561 (perp=7.268, rec=0.091, cos=0.017), tot_loss_proj:2.845 [t=0.31s]
prediction: ['[CLS] this excursion mentalenter is the forgotten mental instability during. not easily dismissed or ofcolating. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.515 (perp=7.115, rec=0.077, cos=0.015), tot_loss_proj:2.393 [t=0.31s]
prediction: ['[CLS] this excursion mentalenter is during the forgotten mental instability. not easily dismissed or ofcolating. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.509 (perp=7.081, rec=0.075, cos=0.018), tot_loss_proj:2.934 [t=0.31s]
prediction: ['[CLS] this excursion mentalenter is during the mental instability forgotten. not easily dismissed or ofcolating. [SEP]']
[1200/2000] tot_loss=1.515 (perp=7.081, rec=0.084, cos=0.015), tot_loss_proj:2.931 [t=0.31s]
prediction: ['[CLS] this excursion mentalenter is during the mental instability forgotten. not easily dismissed or ofcolating. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.597 (perp=7.529, rec=0.076, cos=0.016), tot_loss_proj:2.341 [t=0.31s]
prediction: ['[CLS] this excursion mentalenter isytic the mental instability of. not easily dismissed or forgottencolating. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.508 (perp=7.020, rec=0.086, cos=0.018), tot_loss_proj:2.879 [t=0.31s]
prediction: ['[CLS] this excursion mentalenter isytic. mental instability of the not easily dismissed or forgottencolating. [SEP]']
[1350/2000] tot_loss=1.654 (perp=7.762, rec=0.083, cos=0.018), tot_loss_proj:3.105 [t=0.31s]
prediction: ['[CLS] this excursion mentalenter isytic. mental instability of of not easily dismissed or forgottencolating. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.635 (perp=7.725, rec=0.072, cos=0.019), tot_loss_proj:3.085 [t=0.31s]
prediction: ['[CLS] this excursion mentalenter the isytic. mental instability of not easily dismissed or forgottencolating. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.607 (perp=7.582, rec=0.073, cos=0.018), tot_loss_proj:2.845 [t=0.31s]
prediction: ['[CLS] this excursion mentalenter of isytic. mental instability the not easily dismissed or forgottencolating. [SEP]']
[1500/2000] tot_loss=1.607 (perp=7.582, rec=0.073, cos=0.017), tot_loss_proj:2.846 [t=0.31s]
prediction: ['[CLS] this excursion mentalenter of isytic. mental instability the not easily dismissed or forgottencolating. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.685 (perp=7.920, rec=0.083, cos=0.018), tot_loss_proj:3.086 [t=0.31s]
prediction: ['[CLS] this excursion mental into of isytic. mental instability of not easily dismissed or forgottencolating. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.582 (perp=7.482, rec=0.070, cos=0.015), tot_loss_proj:2.925 [t=0.31s]
prediction: ['[CLS] this excursion mental into. isytic of mental instability of not easily dismissed or forgottencolating. [SEP]']
[1650/2000] tot_loss=1.584 (perp=7.482, rec=0.071, cos=0.017), tot_loss_proj:2.930 [t=0.31s]
prediction: ['[CLS] this excursion mental into. isytic of mental instability of not easily dismissed or forgottencolating. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.515 (perp=7.104, rec=0.078, cos=0.016), tot_loss_proj:2.948 [t=0.31s]
prediction: ['[CLS] this mental excursion into. isytic of mental instability of not easily dismissed or forgottencolating. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.514 (perp=7.104, rec=0.076, cos=0.017), tot_loss_proj:2.947 [t=0.31s]
prediction: ['[CLS] this mental excursion into. isytic of mental instability of not easily dismissed or forgottencolating. [SEP]']
[1800/2000] tot_loss=1.517 (perp=7.104, rec=0.079, cos=0.017), tot_loss_proj:2.943 [t=0.31s]
prediction: ['[CLS] this mental excursion into. isytic of mental instability of not easily dismissed or forgottencolating. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.528 (perp=7.104, rec=0.089, cos=0.018), tot_loss_proj:2.949 [t=0.31s]
prediction: ['[CLS] this mental excursion into. isytic of mental instability of not easily dismissed or forgottencolating. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.513 (perp=7.104, rec=0.075, cos=0.017), tot_loss_proj:2.940 [t=0.31s]
prediction: ['[CLS] this mental excursion into. isytic of mental instability of not easily dismissed or forgottencolating. [SEP]']
[1950/2000] tot_loss=1.529 (perp=7.104, rec=0.090, cos=0.018), tot_loss_proj:2.947 [t=0.31s]
prediction: ['[CLS] this mental excursion into. isytic of mental instability of not easily dismissed or forgottencolating. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.704 (perp=7.992, rec=0.087, cos=0.018), tot_loss_proj:3.034 [t=0.31s]
prediction: ['[CLS] this mental excursion into. isytic of mental instability of not easily dismissed or forgottencolaenter. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this excursion mentalenter isytic the mental instability of. not easily dismissed or forgottencolating. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 80.000 | r: 70.588
rouge2     | fm: 40.000 | p: 42.857 | r: 37.500
rougeL     | fm: 68.750 | p: 73.333 | r: 64.706
rougeLsum  | fm: 68.750 | p: 73.333 | r: 64.706
r1fm+r2fm = 115.000

[Aggregate metrics]:
rouge1     | fm: 87.376 | p: 86.611 | r: 88.347
rouge2     | fm: 55.275 | p: 54.993 | r: 55.701
rougeL     | fm: 76.825 | p: 76.221 | r: 77.543
rougeLsum  | fm: 76.985 | p: 76.450 | r: 77.700
r1fm+r2fm = 142.651

input #75 time: 0:12:19 | total time: 15:19:23


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9984894208430857
highest_index [0]
highest [0.9984894208430857]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.9084050059318542 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.8883193135261536 for ['[CLS] skin outside historian inside please determined boss legend vi đ wine unanimouslymer ski [SEP]']
[Init] best rec loss: 0.8717060685157776 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.8679447770118713 for ['[CLS] paper both commercially user guantanamo body 3d barker away commune also fortune turkey shay [SEP]']
[Init] best perm rec loss: 0.8600871562957764 for ['[CLS] commune turkey commercially both barker body guantanamo shay away fortune 3d user also paper [SEP]']
[Init] best perm rec loss: 0.8585477471351624 for ['[CLS] user also turkey barker guantanamo fortune commune both body shay paper 3d away commercially [SEP]']
[Init] best perm rec loss: 0.8572238683700562 for ['[CLS] turkey away barker fortune both guantanamo also 3d commune paper shay user body commercially [SEP]']
[Init] best perm rec loss: 0.8543236255645752 for ['[CLS] commercially turkey guantanamo commune barker paper fortune shay away body also both user 3d [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.314 (perp=9.886, rec=0.288, cos=0.049), tot_loss_proj:3.148 [t=0.30s]
prediction: ['[CLS] challenging liked stopped. robert allen when that seemed challenging stopped has stop stopped [SEP]']
[ 100/2000] tot_loss=2.265 (perp=10.657, rec=0.124, cos=0.010), tot_loss_proj:3.395 [t=0.30s]
prediction: ['[CLS] challenging at stopped. if allen. of as challenging stopped has himself stopped [SEP]']
[ 150/2000] tot_loss=2.179 (perp=10.279, rec=0.114, cos=0.008), tot_loss_proj:3.223 [t=0.30s]
prediction: ['[CLS] challenging at stopped. if 66. at as challenging stopped has himself stopped [SEP]']
[ 200/2000] tot_loss=2.162 (perp=10.279, rec=0.098, cos=0.008), tot_loss_proj:3.224 [t=0.30s]
prediction: ['[CLS] challenging at stopped. if 66. at as challenging stopped has himself stopped [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.958 (perp=9.168, rec=0.113, cos=0.011), tot_loss_proj:2.959 [t=0.30s]
prediction: ['[CLS] challenging at stopped at if 66, as challenging at stopped has himself stopped [SEP]']
[ 300/2000] tot_loss=2.247 (perp=10.269, rec=0.170, cos=0.023), tot_loss_proj:3.153 [t=0.30s]
prediction: ['[CLS]. at. at if 66 at as challenging at stopped has himself stopped [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.257 (perp=9.366, rec=0.334, cos=0.051), tot_loss_proj:2.977 [t=0.30s]
prediction: ['[CLS] stopped,, at if 66. as challenging up. has himself stopped [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.975 (perp=8.274, rec=0.290, cos=0.030), tot_loss_proj:2.980 [t=0.30s]
prediction: ['[CLS] stopped,, at challenging 66. as if up. has himself stopped [SEP]']
[ 450/2000] tot_loss=1.915 (perp=8.274, rec=0.238, cos=0.022), tot_loss_proj:2.983 [t=0.30s]
prediction: ['[CLS] stopped,, at challenging 66. as if up. has himself stopped [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.855 (perp=8.017, rec=0.234, cos=0.018), tot_loss_proj:2.784 [t=0.30s]
prediction: ['[CLS] stopped, as at challenging 66., if up. has himself stopped [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.822 (perp=7.959, rec=0.215, cos=0.015), tot_loss_proj:2.797 [t=0.30s]
prediction: ['[CLS] stopped, as challenging at 66., if up. has himself stopped [SEP]']
[ 600/2000] tot_loss=1.800 (perp=7.959, rec=0.195, cos=0.013), tot_loss_proj:2.786 [t=0.30s]
prediction: ['[CLS] stopped, as challenging at 66., if up. has himself stopped [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.710 (perp=7.546, rec=0.188, cos=0.013), tot_loss_proj:2.739 [t=0.30s]
prediction: ['[CLS] stopped, as challenging, at 66. if up. has himself stopped [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.703 (perp=7.546, rec=0.182, cos=0.012), tot_loss_proj:2.739 [t=0.30s]
prediction: ['[CLS] stopped, as challenging, at 66. if up. has himself stopped [SEP]']
[ 750/2000] tot_loss=1.705 (perp=7.546, rec=0.185, cos=0.011), tot_loss_proj:2.739 [t=0.30s]
prediction: ['[CLS] stopped, as challenging, at 66. if up. has himself stopped [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.696 (perp=7.546, rec=0.176, cos=0.011), tot_loss_proj:2.746 [t=0.30s]
prediction: ['[CLS] stopped, as challenging, at 66. if up. has himself stopped [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.853 (perp=8.455, rec=0.151, cos=0.010), tot_loss_proj:2.859 [t=0.30s]
prediction: ['[CLS] stopped, as challenging, at 66. if cloth. has himself stopped [SEP]']
[ 900/2000] tot_loss=1.937 (perp=8.770, rec=0.173, cos=0.010), tot_loss_proj:2.918 [t=0.30s]
prediction: ['[CLS] stopped at as challenging, at 66. if cloth. has himself stopped [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.852 (perp=8.419, rec=0.159, cos=0.010), tot_loss_proj:2.844 [t=0.30s]
prediction: ['[CLS] stopped at as challenging, at 66 if. cloth. has himself stopped [SEP]']
Attempt swap
[1000/2000] tot_loss=1.831 (perp=8.289, rec=0.163, cos=0.010), tot_loss_proj:2.827 [t=0.30s]
prediction: ['[CLS] stopped at as challenging, at 66 if. crazy. has himself stopped [SEP]']
[1050/2000] tot_loss=1.811 (perp=8.238, rec=0.154, cos=0.009), tot_loss_proj:2.831 [t=0.30s]
prediction: ['[CLS] stopped at as challenging, at allen if. crazy. has himself stopped [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.773 (perp=8.023, rec=0.159, cos=0.009), tot_loss_proj:2.829 [t=0.30s]
prediction: ['[CLS] stopped at as challenging, at allen if.. up has himself stopped [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.751 (perp=7.944, rec=0.153, cos=0.010), tot_loss_proj:2.781 [t=0.30s]
prediction: ['[CLS] stopped at as challenging up, at allen if.. has himself stopped [SEP]']
[1200/2000] tot_loss=1.948 (perp=8.980, rec=0.143, cos=0.009), tot_loss_proj:2.912 [t=0.30s]
prediction: ['[CLS] stopped at as challenging crazy, at allen if for. has himself stopped [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.892 (perp=8.684, rec=0.145, cos=0.009), tot_loss_proj:2.889 [t=0.30s]
prediction: ['[CLS] stopped at as challenging, at allen if for. crazy has himself stopped [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.815 (perp=8.229, rec=0.159, cos=0.010), tot_loss_proj:2.811 [t=0.30s]
prediction: ['[CLS] stopped at as challenging, at for allen if. crazy has himself stopped [SEP]']
[1350/2000] tot_loss=1.802 (perp=8.229, rec=0.147, cos=0.009), tot_loss_proj:2.811 [t=0.30s]
prediction: ['[CLS] stopped at as challenging, at for allen if. crazy has himself stopped [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.840 (perp=8.348, rec=0.161, cos=0.009), tot_loss_proj:3.072 [t=0.31s]
prediction: ['[CLS] stopped at as if challenging, at. allen. crazy has himself stopped [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.716 (perp=7.731, rec=0.160, cos=0.010), tot_loss_proj:3.045 [t=0.30s]
prediction: ['[CLS] stopped at, at. allen as if challenging. crazy has himself stopped [SEP]']
[1500/2000] tot_loss=1.703 (perp=7.731, rec=0.148, cos=0.009), tot_loss_proj:3.038 [t=0.30s]
prediction: ['[CLS] stopped at, at. allen as if challenging. crazy has himself stopped [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.656 (perp=7.467, rec=0.153, cos=0.010), tot_loss_proj:3.024 [t=0.30s]
prediction: ['[CLS] at, stopped at. allen as if challenging. crazy has himself stopped [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.592 (perp=6.984, rec=0.185, cos=0.011), tot_loss_proj:2.608 [t=0.30s]
prediction: ['[CLS] at, stopped at allen as if challenging. crazy has himself stopped. [SEP]']
[1650/2000] tot_loss=1.565 (perp=6.984, rec=0.160, cos=0.009), tot_loss_proj:2.612 [t=0.31s]
prediction: ['[CLS] at, stopped at allen as if challenging. crazy has himself stopped. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.556 (perp=6.964, rec=0.150, cos=0.013), tot_loss_proj:2.828 [t=0.30s]
prediction: ['[CLS] at allen stopped at, as if challenging. crazy has himself stopped. [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.539 (perp=6.935, rec=0.143, cos=0.009), tot_loss_proj:2.685 [t=0.30s]
prediction: ['[CLS] stopped at at allen, as if challenging. crazy has himself stopped. [SEP]']
[1800/2000] tot_loss=1.539 (perp=6.935, rec=0.143, cos=0.009), tot_loss_proj:2.685 [t=0.31s]
prediction: ['[CLS] stopped at at allen, as if challenging. crazy has himself stopped. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.538 (perp=6.935, rec=0.143, cos=0.009), tot_loss_proj:2.694 [t=0.30s]
prediction: ['[CLS] stopped at at allen, as if challenging. crazy has himself stopped. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.539 (perp=6.935, rec=0.144, cos=0.008), tot_loss_proj:2.639 [t=0.30s]
prediction: ['[CLS] stopped at at allen, as if challenging. crazy has himself stopped. [SEP]']
[1950/2000] tot_loss=1.541 (perp=6.935, rec=0.146, cos=0.008), tot_loss_proj:2.640 [t=0.30s]
prediction: ['[CLS] stopped at at allen, as if challenging. crazy has himself stopped. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.545 (perp=6.935, rec=0.150, cos=0.008), tot_loss_proj:2.647 [t=0.30s]
prediction: ['[CLS] stopped at at allen, as if challenging. crazy has himself stopped. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] challenging at. at if 66 at as challenging at stopped has himself stopped [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.074 | p: 66.667 | r: 83.333
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 40.000 | r: 50.000
rougeLsum  | fm: 44.444 | p: 40.000 | r: 50.000
r1fm+r2fm = 74.074

[Aggregate metrics]:
rouge1     | fm: 87.190 | p: 86.319 | r: 88.203
rouge2     | fm: 54.886 | p: 54.550 | r: 55.265
rougeL     | fm: 76.540 | p: 75.862 | r: 77.311
rougeLsum  | fm: 76.493 | p: 75.899 | r: 77.313
r1fm+r2fm = 142.076

input #76 time: 0:12:04 | total time: 15:31:27


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9987189876711384
highest_index [0]
highest [0.9987189876711384]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.7850564122200012 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.7751423716545105 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.7439104914665222 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best perm rec loss: 0.7429611682891846 for ['[CLS] sheep ways limeno win purple park grayraphic ole sometime medium where most outside [SEP]']
[Init] best perm rec loss: 0.7425685524940491 for ['[CLS]raphic gray lime purpleno sometime park win sheep ole medium ways most outside where [SEP]']
[Init] best perm rec loss: 0.7425423264503479 for ['[CLS] ways sometime gray medium park where purple ole most win sheep outsideraphicno lime [SEP]']
[Init] best perm rec loss: 0.741714596748352 for ['[CLS]raphic ole sometime gray mediumno win park outside most ways sheep lime where purple [SEP]']
[Init] best perm rec loss: 0.7374240159988403 for ['[CLS] medium purple ways sometime park lime oleno winraphic outside sheep where most gray [SEP]']
[Init] best perm rec loss: 0.7366889119148254 for ['[CLS] waysraphic ole win lime grayno sheep park purple outside most sometime medium where [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.002 (perp=12.718, rec=0.391, cos=0.067), tot_loss_proj:3.786 [t=0.31s]
prediction: ['[CLS] crashing descent above mount engineering above club its specifications midtown originally independent ambition spirit recognition [SEP]']
[ 100/2000] tot_loss=2.514 (perp=10.404, rec=0.377, cos=0.056), tot_loss_proj:3.544 [t=0.31s]
prediction: ['[CLS] realm contents above the science realm its its region midtown above its dreams material value [SEP]']
[ 150/2000] tot_loss=2.406 (perp=10.319, rec=0.288, cos=0.055), tot_loss_proj:2.782 [t=0.31s]
prediction: ['[CLS] realm so above the life realm - its promisehen gloryits promise material realm [SEP]']
[ 200/2000] tot_loss=2.417 (perp=10.714, rec=0.229, cos=0.045), tot_loss_proj:3.086 [t=0.31s]
prediction: ['[CLS] realm is above the life realmquitable its promisehen so believears material realm [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.354 (perp=10.307, rec=0.249, cos=0.043), tot_loss_proj:2.788 [t=0.31s]
prediction: ['[CLS] sunrise is believe realm temeraire its promise relationships so itsars above the material realm [SEP]']
[ 300/2000] tot_loss=2.352 (perp=10.480, rec=0.202, cos=0.054), tot_loss_proj:3.856 [t=0.31s]
prediction: ['[CLS] promise is believe realm decimal its promise mani so itsars above the material promise [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.199 (perp=9.761, rec=0.192, cos=0.055), tot_loss_proj:3.727 [t=0.31s]
prediction: ['[CLS] butte is believe realm ignore its promise promise so itsars above the material promise [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.127 (perp=9.383, rec=0.187, cos=0.063), tot_loss_proj:3.109 [t=0.31s]
prediction: ['[CLS] butte is believe realm ， its promise so its promisears above the material promise [SEP]']
[ 450/2000] tot_loss=2.106 (perp=9.260, rec=0.173, cos=0.081), tot_loss_proj:2.953 [t=0.31s]
prediction: ['[CLS] butte is believe realm ， of promise so its promisears above the material promise [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.388 (perp=10.686, rec=0.179, cos=0.071), tot_loss_proj:3.694 [t=0.31s]
prediction: ['[CLS] butte is believe realm derived promise so its promiseাars above the material promise [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.236 (perp=9.911, rec=0.175, cos=0.078), tot_loss_proj:3.018 [t=0.31s]
prediction: ['[CLS] promise is believe realm derived promise so its promiseাars above the material butte [SEP]']
[ 600/2000] tot_loss=2.231 (perp=9.911, rec=0.162, cos=0.087), tot_loss_proj:3.018 [t=0.31s]
prediction: ['[CLS] promise is believe realm derived promise so its promiseাars above the material butte [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.202 (perp=9.782, rec=0.154, cos=0.091), tot_loss_proj:2.575 [t=0.31s]
prediction: ['[CLS] promise is believe realm derived promiseা its promise soars above the material peasants [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.048 (perp=9.000, rec=0.152, cos=0.096), tot_loss_proj:2.491 [t=0.31s]
prediction: ['[CLS] promise is believe realm derived itsা promise that soars above the material peasants [SEP]']
[ 750/2000] tot_loss=2.041 (perp=9.000, rec=0.148, cos=0.093), tot_loss_proj:2.492 [t=0.31s]
prediction: ['[CLS] promise is believe realm derived itsা promise that soars above the material peasants [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.974 (perp=8.671, rec=0.154, cos=0.085), tot_loss_proj:2.474 [t=0.31s]
prediction: ['[CLS] promise is believe peasants derived itsা promise that soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.912 (perp=8.323, rec=0.157, cos=0.091), tot_loss_proj:2.527 [t=0.31s]
prediction: ['[CLS] promise is derived peasants believe itsা promise that soars above the material realm [SEP]']
[ 900/2000] tot_loss=1.966 (perp=8.566, rec=0.157, cos=0.096), tot_loss_proj:2.674 [t=0.31s]
prediction: ['[CLS] promise is derived peasants believe itsা believe that soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.924 (perp=8.405, rec=0.155, cos=0.089), tot_loss_proj:2.706 [t=0.31s]
prediction: ['[CLS] promise is derivedা believe its peasants believe that soars above the material realm [SEP]']
Attempt swap
[1000/2000] tot_loss=1.917 (perp=8.405, rec=0.143, cos=0.093), tot_loss_proj:2.709 [t=0.31s]
prediction: ['[CLS] promise is derivedা believe its peasants believe that soars above the material realm [SEP]']
[1050/2000] tot_loss=1.927 (perp=8.405, rec=0.156, cos=0.090), tot_loss_proj:2.712 [t=0.31s]
prediction: ['[CLS] promise is derivedা believe its peasants believe that soars above the material realm [SEP]']
Attempt swap
[1100/2000] tot_loss=1.959 (perp=8.620, rec=0.144, cos=0.090), tot_loss_proj:2.354 [t=0.31s]
prediction: ['[CLS] promise is derivedgnant believe its effort believe that soars above the material realm [SEP]']
Attempt swap
[1150/2000] tot_loss=1.976 (perp=8.620, rec=0.159, cos=0.093), tot_loss_proj:2.358 [t=0.31s]
prediction: ['[CLS] promise is derivedgnant believe its effort believe that soars above the material realm [SEP]']
[1200/2000] tot_loss=1.958 (perp=8.620, rec=0.145, cos=0.089), tot_loss_proj:2.351 [t=0.31s]
prediction: ['[CLS] promise is derivedgnant believe its effort believe that soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.933 (perp=8.421, rec=0.160, cos=0.089), tot_loss_proj:2.266 [t=0.31s]
prediction: ['[CLS] promise is derived its believegnant effort believe that soars above the material realm [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.137 (perp=9.458, rec=0.154, cos=0.092), tot_loss_proj:2.624 [t=0.31s]
prediction: ['[CLS] promise is derived its believe peasantsgnant around that soars above the material realm [SEP]']
[1350/2000] tot_loss=2.091 (perp=9.236, rec=0.151, cos=0.094), tot_loss_proj:2.432 [t=0.31s]
prediction: ['[CLS] promise is derived its believe peasantsা around that soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.019 (perp=8.877, rec=0.152, cos=0.092), tot_loss_proj:2.497 [t=0.31s]
prediction: ['[CLS] promise is derived its believe peasants aroundgnant that soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.887 (perp=8.201, rec=0.160, cos=0.088), tot_loss_proj:2.322 [t=0.31s]
prediction: ['[CLS] promise is derived its peasants believe aroundা that soars above the material realm [SEP]']
[1500/2000] tot_loss=1.877 (perp=8.201, rec=0.148, cos=0.089), tot_loss_proj:2.323 [t=0.31s]
prediction: ['[CLS] promise is derived its peasants believe aroundা that soars above the material realm [SEP]']
Attempt swap
[1550/2000] tot_loss=1.979 (perp=8.733, rec=0.141, cos=0.092), tot_loss_proj:2.243 [t=0.31s]
prediction: ['[CLS] promise is derived its bits believe aroundা that soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.952 (perp=8.597, rec=0.141, cos=0.091), tot_loss_proj:2.290 [t=0.31s]
prediction: ['[CLS] promise is derived its believe peasants aroundা that soars above the material realm [SEP]']
[1650/2000] tot_loss=1.957 (perp=8.597, rec=0.148, cos=0.089), tot_loss_proj:2.296 [t=0.31s]
prediction: ['[CLS] promise is derived its believe peasants aroundা that soars above the material realm [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.946 (perp=8.521, rec=0.149, cos=0.093), tot_loss_proj:2.201 [t=0.31s]
prediction: ['[CLS] is derived its promise believe bits aroundা that soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.944 (perp=8.523, rec=0.149, cos=0.090), tot_loss_proj:2.304 [t=0.31s]
prediction: ['[CLS] is derived its promise bits believe aroundা that soars above the material realm [SEP]']
[1800/2000] tot_loss=1.947 (perp=8.523, rec=0.153, cos=0.090), tot_loss_proj:2.305 [t=0.31s]
prediction: ['[CLS] is derived its promise bits believe aroundা that soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.886 (perp=8.238, rec=0.151, cos=0.087), tot_loss_proj:2.314 [t=0.31s]
prediction: ['[CLS] is derived itsা bits believe around promise that soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.818 (perp=7.869, rec=0.154, cos=0.091), tot_loss_proj:2.452 [t=0.31s]
prediction: ['[CLS] is derived aroundা bits believe its promise that soars above the material realm [SEP]']
[1950/2000] tot_loss=1.816 (perp=7.869, rec=0.151, cos=0.091), tot_loss_proj:2.447 [t=0.31s]
prediction: ['[CLS] is derived aroundা bits believe its promise that soars above the material realm [SEP]']
Attempt swap
[2000/2000] tot_loss=1.811 (perp=7.869, rec=0.148, cos=0.090), tot_loss_proj:2.444 [t=0.31s]
prediction: ['[CLS] is derived aroundা bits believe its promise that soars above the material realm [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] promise is derived its believe peasants aroundা that soars above the material realm [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 73.333 | p: 73.333 | r: 73.333
rougeLsum  | fm: 73.333 | p: 73.333 | r: 73.333
r1fm+r2fm = 122.857

[Aggregate metrics]:
rouge1     | fm: 87.055 | p: 86.272 | r: 88.099
rouge2     | fm: 54.336 | p: 54.084 | r: 54.728
rougeL     | fm: 76.292 | p: 75.640 | r: 77.070
rougeLsum  | fm: 76.510 | p: 75.957 | r: 77.237
r1fm+r2fm = 141.391

input #77 time: 0:12:20 | total time: 15:43:48


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9986771109256046
highest_index [0]
highest [0.9986771109256046]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.985630989074707 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9587128758430481 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8177029490470886 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8163542151451111 for ['[CLS] barnet lynn sings [SEP]']
[Init] best rec loss: 0.7808359265327454 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.7805563807487488 for ['[CLS] le grant screens [SEP]']
[Init] best perm rec loss: 0.7771375775337219 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.979 (perp=9.116, rec=0.146, cos=0.010), tot_loss_proj:2.726 [t=0.30s]
prediction: ['[CLS] exit theater theater [SEP]']
[ 100/2000] tot_loss=1.927 (perp=9.116, rec=0.098, cos=0.006), tot_loss_proj:2.731 [t=0.30s]
prediction: ['[CLS] exit theater theater [SEP]']
[ 150/2000] tot_loss=2.248 (perp=10.782, rec=0.087, cos=0.005), tot_loss_proj:2.942 [t=0.30s]
prediction: ['[CLS] exit theater the [SEP]']
[ 200/2000] tot_loss=2.224 (perp=10.782, rec=0.065, cos=0.003), tot_loss_proj:2.937 [t=0.30s]
prediction: ['[CLS] exit theater the [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.660 (perp=7.958, rec=0.065, cos=0.003), tot_loss_proj:1.670 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=1.662 (perp=7.958, rec=0.068, cos=0.003), tot_loss_proj:1.680 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.667 (perp=7.958, rec=0.073, cos=0.003), tot_loss_proj:1.670 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.655 (perp=7.958, rec=0.061, cos=0.003), tot_loss_proj:1.677 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.654 (perp=7.958, rec=0.059, cos=0.003), tot_loss_proj:1.668 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.649 (perp=7.958, rec=0.054, cos=0.003), tot_loss_proj:1.677 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.657 (perp=7.958, rec=0.063, cos=0.003), tot_loss_proj:1.671 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.658 (perp=7.958, rec=0.064, cos=0.003), tot_loss_proj:1.677 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.667 (perp=7.958, rec=0.073, cos=0.003), tot_loss_proj:1.674 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.657 (perp=7.958, rec=0.063, cos=0.003), tot_loss_proj:1.673 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.661 (perp=7.958, rec=0.067, cos=0.003), tot_loss_proj:1.684 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.662 (perp=7.958, rec=0.068, cos=0.003), tot_loss_proj:1.659 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.657 (perp=7.958, rec=0.063, cos=0.003), tot_loss_proj:1.670 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.650 (perp=7.958, rec=0.056, cos=0.003), tot_loss_proj:1.663 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.646 (perp=7.958, rec=0.052, cos=0.003), tot_loss_proj:1.677 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.660 (perp=7.958, rec=0.066, cos=0.003), tot_loss_proj:1.674 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.643 (perp=7.958, rec=0.049, cos=0.003), tot_loss_proj:1.671 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.650 (perp=7.958, rec=0.056, cos=0.003), tot_loss_proj:1.666 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.660 (perp=7.958, rec=0.066, cos=0.003), tot_loss_proj:1.679 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.654 (perp=7.958, rec=0.060, cos=0.003), tot_loss_proj:1.664 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.653 (perp=7.958, rec=0.059, cos=0.003), tot_loss_proj:1.665 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.651 (perp=7.958, rec=0.057, cos=0.003), tot_loss_proj:1.675 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.657 (perp=7.958, rec=0.063, cos=0.003), tot_loss_proj:1.665 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.659 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.676 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.655 (perp=7.958, rec=0.061, cos=0.003), tot_loss_proj:1.663 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.651 (perp=7.958, rec=0.057, cos=0.003), tot_loss_proj:1.672 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.651 (perp=7.958, rec=0.057, cos=0.003), tot_loss_proj:1.659 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.656 (perp=7.958, rec=0.062, cos=0.003), tot_loss_proj:1.671 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.654 (perp=7.958, rec=0.059, cos=0.003), tot_loss_proj:1.674 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.648 (perp=7.958, rec=0.053, cos=0.003), tot_loss_proj:1.655 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.650 (perp=7.958, rec=0.056, cos=0.003), tot_loss_proj:1.670 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.653 (perp=7.958, rec=0.059, cos=0.003), tot_loss_proj:1.676 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.663 (perp=7.958, rec=0.069, cos=0.003), tot_loss_proj:1.676 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.670 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.661 (perp=7.958, rec=0.067, cos=0.003), tot_loss_proj:1.686 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.223 | p: 86.470 | r: 88.203
rouge2     | fm: 54.977 | p: 54.649 | r: 55.383
rougeL     | fm: 76.636 | p: 76.014 | r: 77.443
rougeLsum  | fm: 76.690 | p: 76.106 | r: 77.483
r1fm+r2fm = 142.200

input #78 time: 0:12:02 | total time: 15:55:50


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.9987089018045019
highest_index [0]
highest [0.9987089018045019]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9676922559738159 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.958460807800293 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.9435795545578003 for ['[CLS] abs mess [SEP]']
[Init] best rec loss: 0.921610951423645 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.9193524122238159 for ['[CLS] high designer [SEP]']
[Init] best rec loss: 0.9069709777832031 for ['[CLS] unincorporated band [SEP]']
[Init] best rec loss: 0.902313232421875 for ['[CLS] crystaltor [SEP]']
[Init] best rec loss: 0.9010124206542969 for ['[CLS] world ceased [SEP]']
[Init] best perm rec loss: 0.8955940008163452 for ['[CLS] ceased world [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.826 (perp=10.910, rec=0.662, cos=0.981), tot_loss_proj:4.262 [t=0.30s]
prediction: ['[CLS] olympiad? [SEP]']
[ 100/2000] tot_loss=3.711 (perp=11.428, rec=0.558, cos=0.868), tot_loss_proj:2.591 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=3.156 (perp=8.947, rec=0.575, cos=0.791), tot_loss_proj:2.276 [t=0.30s]
prediction: ['[CLS] fascinating fiction [SEP]']
[ 200/2000] tot_loss=3.264 (perp=11.428, rec=0.492, cos=0.487), tot_loss_proj:2.594 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.849 (perp=11.428, rec=0.493, cos=0.070), tot_loss_proj:2.608 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 300/2000] tot_loss=2.671 (perp=11.428, rec=0.337, cos=0.049), tot_loss_proj:2.606 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.610 (perp=11.428, rec=0.277, cos=0.047), tot_loss_proj:2.593 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.596 (perp=11.428, rec=0.263, cos=0.047), tot_loss_proj:2.597 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 450/2000] tot_loss=2.560 (perp=11.428, rec=0.226, cos=0.048), tot_loss_proj:2.583 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.559 (perp=11.428, rec=0.224, cos=0.049), tot_loss_proj:2.585 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.550 (perp=11.428, rec=0.212, cos=0.053), tot_loss_proj:2.602 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 600/2000] tot_loss=2.556 (perp=11.428, rec=0.215, cos=0.055), tot_loss_proj:2.596 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.574 (perp=11.428, rec=0.227, cos=0.061), tot_loss_proj:2.597 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.481 (perp=10.963, rec=0.226, cos=0.063), tot_loss_proj:2.749 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
[ 750/2000] tot_loss=2.460 (perp=10.963, rec=0.204, cos=0.064), tot_loss_proj:2.758 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.467 (perp=10.963, rec=0.210, cos=0.064), tot_loss_proj:2.752 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.473 (perp=10.963, rec=0.217, cos=0.063), tot_loss_proj:2.745 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
[ 900/2000] tot_loss=2.474 (perp=10.963, rec=0.217, cos=0.064), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.467 (perp=10.963, rec=0.207, cos=0.067), tot_loss_proj:2.751 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1000/2000] tot_loss=2.455 (perp=10.963, rec=0.198, cos=0.065), tot_loss_proj:2.752 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
[1050/2000] tot_loss=2.460 (perp=10.963, rec=0.204, cos=0.063), tot_loss_proj:2.756 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1100/2000] tot_loss=2.451 (perp=10.963, rec=0.193, cos=0.065), tot_loss_proj:2.750 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1150/2000] tot_loss=2.458 (perp=10.963, rec=0.202, cos=0.064), tot_loss_proj:2.750 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
[1200/2000] tot_loss=2.473 (perp=10.963, rec=0.216, cos=0.064), tot_loss_proj:2.750 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1250/2000] tot_loss=2.459 (perp=10.963, rec=0.201, cos=0.066), tot_loss_proj:2.745 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1300/2000] tot_loss=2.461 (perp=10.963, rec=0.203, cos=0.065), tot_loss_proj:2.753 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
[1350/2000] tot_loss=2.454 (perp=10.963, rec=0.196, cos=0.066), tot_loss_proj:2.753 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1400/2000] tot_loss=2.460 (perp=10.963, rec=0.201, cos=0.067), tot_loss_proj:2.753 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1450/2000] tot_loss=2.467 (perp=10.963, rec=0.208, cos=0.066), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
[1500/2000] tot_loss=2.464 (perp=10.963, rec=0.207, cos=0.065), tot_loss_proj:2.751 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1550/2000] tot_loss=2.460 (perp=10.963, rec=0.202, cos=0.066), tot_loss_proj:2.745 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1600/2000] tot_loss=2.465 (perp=10.963, rec=0.207, cos=0.066), tot_loss_proj:2.754 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
[1650/2000] tot_loss=2.465 (perp=10.963, rec=0.206, cos=0.066), tot_loss_proj:2.743 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1700/2000] tot_loss=2.457 (perp=10.963, rec=0.198, cos=0.066), tot_loss_proj:2.745 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1750/2000] tot_loss=2.452 (perp=10.963, rec=0.192, cos=0.067), tot_loss_proj:2.749 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
[1800/2000] tot_loss=2.466 (perp=10.963, rec=0.207, cos=0.066), tot_loss_proj:2.751 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1850/2000] tot_loss=2.451 (perp=10.963, rec=0.192, cos=0.066), tot_loss_proj:2.752 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[1900/2000] tot_loss=2.454 (perp=10.963, rec=0.194, cos=0.067), tot_loss_proj:2.750 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
[1950/2000] tot_loss=2.454 (perp=10.963, rec=0.195, cos=0.067), tot_loss_proj:2.752 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Attempt swap
[2000/2000] tot_loss=2.460 (perp=10.963, rec=0.200, cos=0.067), tot_loss_proj:2.750 [t=0.30s]
prediction: ['[CLS] fascinating grows [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating grows [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 75.000

[Aggregate metrics]:
rouge1     | fm: 87.119 | p: 86.318 | r: 88.105
rouge2     | fm: 54.482 | p: 54.153 | r: 54.846
rougeL     | fm: 76.535 | p: 75.958 | r: 77.340
rougeLsum  | fm: 76.733 | p: 76.137 | r: 77.497
r1fm+r2fm = 141.601

input #79 time: 0:12:01 | total time: 16:07:52


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9987510445740972
highest_index [0]
highest [0.9987510445740972]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9974209666252136 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9935943484306335 for ['[CLS] breath difference sensitiveosity higher [SEP]']
[Init] best rec loss: 0.9706876277923584 for ['[CLS] water takinge bonnie ca [SEP]']
[Init] best rec loss: 0.9109598398208618 for ['[CLS] team joined target * results [SEP]']
[Init] best perm rec loss: 0.9091998934745789 for ['[CLS] results joined team target * [SEP]']
[Init] best perm rec loss: 0.9052599668502808 for ['[CLS] target * results joined team [SEP]']
[Init] best perm rec loss: 0.904413104057312 for ['[CLS] joined target team results * [SEP]']
[Init] best perm rec loss: 0.9030737280845642 for ['[CLS] team results target joined * [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.093 (perp=9.353, rec=0.216, cos=0.006), tot_loss_proj:2.617 [t=0.30s]
prediction: ['[CLS] these wise jacobzen wise [SEP]']
[ 100/2000] tot_loss=1.898 (perp=8.731, rec=0.148, cos=0.004), tot_loss_proj:1.998 [t=0.30s]
prediction: ['[CLS] wise wise wizened [SEP]']
[ 150/2000] tot_loss=1.917 (perp=8.993, rec=0.115, cos=0.004), tot_loss_proj:2.330 [t=0.30s]
prediction: ['[CLS] wi wise wizened [SEP]']
[ 200/2000] tot_loss=1.904 (perp=8.993, rec=0.102, cos=0.003), tot_loss_proj:2.336 [t=0.30s]
prediction: ['[CLS] wi wise wizened [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.391 (perp=11.326, rec=0.122, cos=0.004), tot_loss_proj:3.008 [t=0.30s]
prediction: ['[CLS],zened wi wise [SEP]']
[ 300/2000] tot_loss=2.342 (perp=11.326, rec=0.074, cos=0.003), tot_loss_proj:2.995 [t=0.30s]
prediction: ['[CLS],zened wi wise [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.442 (perp=6.853, rec=0.068, cos=0.003), tot_loss_proj:1.606 [t=0.30s]
prediction: ['[CLS], wizened wise [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.406 (perp=6.600, rec=0.083, cos=0.003), tot_loss_proj:1.388 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 450/2000] tot_loss=1.384 (perp=6.600, rec=0.062, cos=0.003), tot_loss_proj:1.394 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.383 (perp=6.600, rec=0.061, cos=0.003), tot_loss_proj:1.387 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.389 (perp=6.600, rec=0.066, cos=0.003), tot_loss_proj:1.391 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 600/2000] tot_loss=1.372 (perp=6.600, rec=0.050, cos=0.003), tot_loss_proj:1.387 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.380 (perp=6.600, rec=0.057, cos=0.003), tot_loss_proj:1.388 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.388 (perp=6.600, rec=0.065, cos=0.003), tot_loss_proj:1.394 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 750/2000] tot_loss=1.385 (perp=6.600, rec=0.063, cos=0.002), tot_loss_proj:1.401 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.376 (perp=6.600, rec=0.053, cos=0.003), tot_loss_proj:1.393 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.388 (perp=6.600, rec=0.066, cos=0.002), tot_loss_proj:1.379 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 900/2000] tot_loss=1.394 (perp=6.600, rec=0.072, cos=0.002), tot_loss_proj:1.397 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.375 (perp=6.600, rec=0.052, cos=0.002), tot_loss_proj:1.394 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1000/2000] tot_loss=1.383 (perp=6.600, rec=0.060, cos=0.002), tot_loss_proj:1.394 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1050/2000] tot_loss=1.386 (perp=6.600, rec=0.063, cos=0.002), tot_loss_proj:1.399 [t=0.31s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1100/2000] tot_loss=1.382 (perp=6.600, rec=0.059, cos=0.002), tot_loss_proj:1.385 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1150/2000] tot_loss=1.382 (perp=6.600, rec=0.060, cos=0.003), tot_loss_proj:1.387 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1200/2000] tot_loss=1.386 (perp=6.600, rec=0.064, cos=0.003), tot_loss_proj:1.398 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1250/2000] tot_loss=1.389 (perp=6.600, rec=0.066, cos=0.003), tot_loss_proj:1.392 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1300/2000] tot_loss=1.382 (perp=6.600, rec=0.059, cos=0.002), tot_loss_proj:1.391 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1350/2000] tot_loss=1.375 (perp=6.600, rec=0.052, cos=0.002), tot_loss_proj:1.392 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1400/2000] tot_loss=1.374 (perp=6.600, rec=0.051, cos=0.003), tot_loss_proj:1.393 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1450/2000] tot_loss=1.375 (perp=6.600, rec=0.052, cos=0.002), tot_loss_proj:1.384 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1500/2000] tot_loss=1.376 (perp=6.600, rec=0.054, cos=0.002), tot_loss_proj:1.396 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1550/2000] tot_loss=1.394 (perp=6.600, rec=0.072, cos=0.002), tot_loss_proj:1.393 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1600/2000] tot_loss=1.384 (perp=6.600, rec=0.061, cos=0.002), tot_loss_proj:1.389 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1650/2000] tot_loss=1.380 (perp=6.600, rec=0.057, cos=0.002), tot_loss_proj:1.373 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1700/2000] tot_loss=1.377 (perp=6.600, rec=0.054, cos=0.002), tot_loss_proj:1.388 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1750/2000] tot_loss=1.381 (perp=6.600, rec=0.059, cos=0.002), tot_loss_proj:1.383 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1800/2000] tot_loss=1.383 (perp=6.600, rec=0.060, cos=0.002), tot_loss_proj:1.382 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1850/2000] tot_loss=1.381 (perp=6.600, rec=0.058, cos=0.002), tot_loss_proj:1.392 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1900/2000] tot_loss=1.384 (perp=6.600, rec=0.062, cos=0.002), tot_loss_proj:1.390 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1950/2000] tot_loss=1.383 (perp=6.600, rec=0.060, cos=0.002), tot_loss_proj:1.387 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[2000/2000] tot_loss=1.377 (perp=6.600, rec=0.055, cos=0.002), tot_loss_proj:1.378 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise, wizened [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.195 | p: 86.464 | r: 88.188
rouge2     | fm: 54.833 | p: 54.631 | r: 55.263
rougeL     | fm: 76.905 | p: 76.346 | r: 77.615
rougeLsum  | fm: 77.048 | p: 76.456 | r: 77.750
r1fm+r2fm = 142.029

input #80 time: 0:12:03 | total time: 16:19:55


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9985062789910341
highest_index [0]
highest [0.9985062789910341]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9719983339309692 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.9568555951118469 for ['[CLS] hobbs : kahn closer invest rico [SEP]']
[Init] best rec loss: 0.919513463973999 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8558323383331299 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8490030765533447 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.8182841539382935 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.8058221340179443 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 0.795734703540802 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best perm rec loss: 0.7901783585548401 for ['[CLS] threads approval modelled bandsitating missing [SEP]']
[Init] best perm rec loss: 0.7899459600448608 for ['[CLS] approval bands threads modelleditating missing [SEP]']
[Init] best perm rec loss: 0.7884279489517212 for ['[CLS]itating missing approval bands threads modelled [SEP]']
[Init] best perm rec loss: 0.7879689335823059 for ['[CLS] missingitating bands approval modelled threads [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.233 (perp=9.798, rec=0.243, cos=0.030), tot_loss_proj:2.796 [t=0.30s]
prediction: ['[CLS] not player not impressive most player [SEP]']
[ 100/2000] tot_loss=1.938 (perp=9.028, rec=0.126, cos=0.007), tot_loss_proj:3.155 [t=0.30s]
prediction: ['[CLS] not player is impressive most player [SEP]']
[ 150/2000] tot_loss=1.932 (perp=9.261, rec=0.076, cos=0.003), tot_loss_proj:2.458 [t=0.30s]
prediction: ['[CLS] not the is impressive most player [SEP]']
[ 200/2000] tot_loss=1.912 (perp=9.261, rec=0.056, cos=0.003), tot_loss_proj:2.458 [t=0.30s]
prediction: ['[CLS] not the is impressive most player [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.596 (perp=7.552, rec=0.082, cos=0.004), tot_loss_proj:2.237 [t=0.30s]
prediction: ['[CLS] not impressive is the most player [SEP]']
[ 300/2000] tot_loss=1.567 (perp=7.552, rec=0.054, cos=0.003), tot_loss_proj:2.241 [t=0.30s]
prediction: ['[CLS] not impressive is the most player [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.470 (perp=7.044, rec=0.058, cos=0.003), tot_loss_proj:3.166 [t=0.30s]
prediction: ['[CLS] not is the most impressive player [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.267 (perp=5.977, rec=0.068, cos=0.003), tot_loss_proj:1.311 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 450/2000] tot_loss=1.252 (perp=5.977, rec=0.054, cos=0.003), tot_loss_proj:1.317 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.256 (perp=5.977, rec=0.057, cos=0.003), tot_loss_proj:1.328 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.263 (perp=5.977, rec=0.065, cos=0.003), tot_loss_proj:1.317 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 600/2000] tot_loss=1.266 (perp=5.977, rec=0.068, cos=0.003), tot_loss_proj:1.323 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.249 (perp=5.977, rec=0.050, cos=0.003), tot_loss_proj:1.320 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.253 (perp=5.977, rec=0.055, cos=0.003), tot_loss_proj:1.317 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 750/2000] tot_loss=1.263 (perp=5.977, rec=0.065, cos=0.003), tot_loss_proj:1.325 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.255 (perp=5.977, rec=0.056, cos=0.003), tot_loss_proj:1.316 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.267 (perp=5.977, rec=0.069, cos=0.003), tot_loss_proj:1.319 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 900/2000] tot_loss=1.255 (perp=5.977, rec=0.056, cos=0.003), tot_loss_proj:1.314 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.269 (perp=5.977, rec=0.071, cos=0.003), tot_loss_proj:1.326 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.266 (perp=5.977, rec=0.068, cos=0.003), tot_loss_proj:1.318 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1050/2000] tot_loss=1.254 (perp=5.977, rec=0.055, cos=0.003), tot_loss_proj:1.320 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.249 (perp=5.977, rec=0.051, cos=0.003), tot_loss_proj:1.323 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.261 (perp=5.977, rec=0.062, cos=0.003), tot_loss_proj:1.312 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1200/2000] tot_loss=1.263 (perp=5.977, rec=0.065, cos=0.003), tot_loss_proj:1.321 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.254 (perp=5.977, rec=0.055, cos=0.003), tot_loss_proj:1.318 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.257 (perp=5.977, rec=0.058, cos=0.003), tot_loss_proj:1.319 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1350/2000] tot_loss=1.266 (perp=5.977, rec=0.068, cos=0.003), tot_loss_proj:1.319 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.259 (perp=5.977, rec=0.061, cos=0.003), tot_loss_proj:1.316 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.251 (perp=5.977, rec=0.053, cos=0.003), tot_loss_proj:1.324 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1500/2000] tot_loss=1.258 (perp=5.977, rec=0.060, cos=0.003), tot_loss_proj:1.316 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.247 (perp=5.977, rec=0.049, cos=0.003), tot_loss_proj:1.314 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.252 (perp=5.977, rec=0.054, cos=0.003), tot_loss_proj:1.315 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1650/2000] tot_loss=1.262 (perp=5.977, rec=0.064, cos=0.003), tot_loss_proj:1.319 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.262 (perp=5.977, rec=0.064, cos=0.003), tot_loss_proj:1.323 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.262 (perp=5.977, rec=0.064, cos=0.003), tot_loss_proj:1.322 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1800/2000] tot_loss=1.261 (perp=5.977, rec=0.063, cos=0.003), tot_loss_proj:1.324 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.266 (perp=5.977, rec=0.067, cos=0.003), tot_loss_proj:1.315 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.260 (perp=5.977, rec=0.062, cos=0.003), tot_loss_proj:1.317 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1950/2000] tot_loss=1.253 (perp=5.977, rec=0.055, cos=0.003), tot_loss_proj:1.314 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.253 (perp=5.977, rec=0.055, cos=0.003), tot_loss_proj:1.329 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not the most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.393 | p: 86.653 | r: 88.366
rouge2     | fm: 55.442 | p: 55.139 | r: 55.732
rougeL     | fm: 77.145 | p: 76.582 | r: 77.933
rougeLsum  | fm: 77.349 | p: 76.826 | r: 78.101
r1fm+r2fm = 142.836

input #81 time: 0:12:03 | total time: 16:31:59


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.9986377431629494
highest_index [0]
highest [0.9986377431629494]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9828013181686401 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9603455066680908 for ['[CLS] beck will parent stu rocks criteria roycenia [SEP]']
[Init] best rec loss: 0.9535247683525085 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9519714117050171 for ['[CLS] seminetive facing toward victor trance grown [SEP]']
[Init] best rec loss: 0.9372182488441467 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9363351464271545 for ['[CLS] task cadence extreme manchester internal direct mann alpine [SEP]']
[Init] best rec loss: 0.9304280877113342 for ['[CLS] ecclesiastical novel pre £ moi data push fran [SEP]']
[Init] best rec loss: 0.9294431209564209 for ['[CLS] bedroomroup hose reece acherade rightsie [SEP]']
[Init] best rec loss: 0.9174061417579651 for ['[CLS] worse terms everyday down sandsbed supporting due [SEP]']
[Init] best rec loss: 0.898158073425293 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.8964783549308777 for ['[CLS] letter babyturnesian eric a distribution soft [SEP]']
[Init] best rec loss: 0.8641878366470337 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8639135360717773 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8622021079063416 for ['[CLS] plumagebasket respective record role whoeverachfur [SEP]']
[Init] best perm rec loss: 0.8597894310951233 for ['[CLS]basketfur whoever role respective recordach plumage [SEP]']
[Init] best perm rec loss: 0.8582521677017212 for ['[CLS]basketfur whoever respective roleach plumage record [SEP]']
[Init] best perm rec loss: 0.8581947088241577 for ['[CLS] rolebasket plumagefur record respectiveach whoever [SEP]']
[Init] best perm rec loss: 0.857462465763092 for ['[CLS]basketfur role record respective whoever plumageach [SEP]']
[Init] best perm rec loss: 0.8561487197875977 for ['[CLS]fur role whoever respectivebasket plumage recordach [SEP]']
[Init] best perm rec loss: 0.8556596040725708 for ['[CLS]fur roleach respectivebasket plumage record whoever [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.340 (perp=10.656, rec=0.198, cos=0.011), tot_loss_proj:2.848 [t=0.30s]
prediction: ['[CLS] other script script is undone undone sloppy sloppy [SEP]']
[ 100/2000] tot_loss=2.098 (perp=10.036, rec=0.086, cos=0.005), tot_loss_proj:2.466 [t=0.30s]
prediction: ['[CLS] a script by s undone by sloppy sloppy [SEP]']
[ 150/2000] tot_loss=2.101 (perp=10.036, rec=0.089, cos=0.005), tot_loss_proj:2.467 [t=0.30s]
prediction: ['[CLS] a script by s undone by sloppy sloppy [SEP]']
[ 200/2000] tot_loss=2.103 (perp=10.036, rec=0.091, cos=0.004), tot_loss_proj:2.458 [t=0.30s]
prediction: ['[CLS] a script by s undone by sloppy sloppy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.897 (perp=9.097, rec=0.075, cos=0.003), tot_loss_proj:2.280 [t=0.30s]
prediction: ['[CLS] a s by script undone by sloppy it [SEP]']
[ 300/2000] tot_loss=1.897 (perp=9.097, rec=0.074, cos=0.004), tot_loss_proj:2.287 [t=0.30s]
prediction: ['[CLS] a s by script undone by sloppy it [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.620 (perp=7.685, rec=0.079, cos=0.004), tot_loss_proj:1.929 [t=0.30s]
prediction: ['[CLS] a s by sloppy script undone by it [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.601 (perp=7.685, rec=0.060, cos=0.004), tot_loss_proj:1.934 [t=0.30s]
prediction: ['[CLS] a s by sloppy script undone by it [SEP]']
[ 450/2000] tot_loss=1.614 (perp=7.685, rec=0.074, cos=0.003), tot_loss_proj:1.938 [t=0.31s]
prediction: ['[CLS] a s by sloppy script undone by it [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.614 (perp=7.685, rec=0.074, cos=0.003), tot_loss_proj:1.928 [t=0.30s]
prediction: ['[CLS] a s by sloppy script undone by it [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.611 (perp=7.685, rec=0.070, cos=0.003), tot_loss_proj:1.934 [t=0.30s]
prediction: ['[CLS] a s by sloppy script undone by it [SEP]']
[ 600/2000] tot_loss=1.609 (perp=7.685, rec=0.068, cos=0.003), tot_loss_proj:1.936 [t=0.30s]
prediction: ['[CLS] a s by sloppy script undone by it [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.583 (perp=7.493, rec=0.081, cos=0.004), tot_loss_proj:1.866 [t=0.30s]
prediction: ['[CLS] by a s sloppy script undone by it [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.757 (perp=8.442, rec=0.066, cos=0.003), tot_loss_proj:2.212 [t=0.30s]
prediction: ["[CLS] by a s sloppy script undone'it [SEP]"]
[ 750/2000] tot_loss=1.765 (perp=8.442, rec=0.073, cos=0.003), tot_loss_proj:2.211 [t=0.30s]
prediction: ["[CLS] by a s sloppy script undone'it [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.905 (perp=9.104, rec=0.080, cos=0.004), tot_loss_proj:2.270 [t=0.30s]
prediction: ['[CLS] by a sloppy script undone s s it [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.719 (perp=8.154, rec=0.085, cos=0.004), tot_loss_proj:2.132 [t=0.30s]
prediction: ['[CLS] by a sloppy script undone it s s [SEP]']
[ 900/2000] tot_loss=1.705 (perp=8.154, rec=0.071, cos=0.004), tot_loss_proj:2.134 [t=0.30s]
prediction: ['[CLS] by a sloppy script undone it s s [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.665 (perp=7.964, rec=0.068, cos=0.004), tot_loss_proj:1.995 [t=0.30s]
prediction: ['[CLS] a sloppy script undone by it s s [SEP]']
Attempt swap
[1000/2000] tot_loss=1.650 (perp=7.964, rec=0.054, cos=0.003), tot_loss_proj:1.997 [t=0.30s]
prediction: ['[CLS] a sloppy script undone by it s s [SEP]']
[1050/2000] tot_loss=1.658 (perp=7.964, rec=0.062, cos=0.003), tot_loss_proj:1.992 [t=0.30s]
prediction: ['[CLS] a sloppy script undone by it s s [SEP]']
Attempt swap
[1100/2000] tot_loss=1.659 (perp=7.964, rec=0.063, cos=0.003), tot_loss_proj:1.996 [t=0.30s]
prediction: ['[CLS] a sloppy script undone by it s s [SEP]']
Attempt swap
[1150/2000] tot_loss=1.662 (perp=7.964, rec=0.066, cos=0.003), tot_loss_proj:2.001 [t=0.30s]
prediction: ['[CLS] a sloppy script undone by it s s [SEP]']
[1200/2000] tot_loss=1.269 (perp=6.019, rec=0.062, cos=0.003), tot_loss_proj:1.633 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.282 (perp=6.019, rec=0.075, cos=0.003), tot_loss_proj:1.633 [t=0.31s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.280 (perp=6.019, rec=0.073, cos=0.003), tot_loss_proj:1.622 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
[1350/2000] tot_loss=1.268 (perp=6.019, rec=0.061, cos=0.003), tot_loss_proj:1.632 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.267 (perp=6.019, rec=0.060, cos=0.003), tot_loss_proj:1.620 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.271 (perp=6.019, rec=0.064, cos=0.003), tot_loss_proj:1.625 [t=0.31s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
[1500/2000] tot_loss=1.276 (perp=6.019, rec=0.069, cos=0.003), tot_loss_proj:1.628 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.286 (perp=6.019, rec=0.079, cos=0.003), tot_loss_proj:1.622 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.279 (perp=6.019, rec=0.072, cos=0.003), tot_loss_proj:1.626 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
[1650/2000] tot_loss=1.261 (perp=6.019, rec=0.054, cos=0.003), tot_loss_proj:1.627 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.269 (perp=6.019, rec=0.062, cos=0.003), tot_loss_proj:1.628 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.286 (perp=6.019, rec=0.079, cos=0.003), tot_loss_proj:1.623 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
[1800/2000] tot_loss=1.267 (perp=6.019, rec=0.060, cos=0.003), tot_loss_proj:1.623 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.267 (perp=6.019, rec=0.060, cos=0.003), tot_loss_proj:1.624 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.271 (perp=6.019, rec=0.064, cos=0.003), tot_loss_proj:1.623 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
[1950/2000] tot_loss=1.271 (perp=6.019, rec=0.064, cos=0.003), tot_loss_proj:1.624 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.275 (perp=6.019, rec=0.068, cos=0.003), tot_loss_proj:1.633 [t=0.30s]
prediction: ["[CLS] a sloppy script undone by it's [SEP]"]
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] a sloppy script undone by it's [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 87.548 | p: 86.808 | r: 88.513
rouge2     | fm: 55.485 | p: 55.224 | r: 55.836
rougeL     | fm: 77.012 | p: 76.415 | r: 77.715
rougeLsum  | fm: 76.987 | p: 76.483 | r: 77.711
r1fm+r2fm = 143.033

input #82 time: 0:12:05 | total time: 16:44:04


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9986701129752777
highest_index [0]
highest [0.9986701129752777]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.8480295538902283 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.8309171795845032 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.8254842162132263 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8065268993377686 for ['[CLS] floodax aboriginal mali wisconsin na rain basket missed call [SEP]']
[Init] best rec loss: 0.7764449715614319 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.7715729475021362 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best perm rec loss: 0.7704460620880127 for ['[CLS] feeling xavier nash something johnny jamie breaking [CLS] quality us [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.228 (perp=9.277, rec=0.336, cos=0.037), tot_loss_proj:3.563 [t=0.30s]
prediction: ['[CLS] what once characters tomorrow become was content when anything it [SEP]']
[ 100/2000] tot_loss=1.865 (perp=8.126, rec=0.225, cos=0.015), tot_loss_proj:2.772 [t=0.30s]
prediction: ['[CLS] what know it know is grows in when know it [SEP]']
[ 150/2000] tot_loss=2.121 (perp=9.781, rec=0.157, cos=0.008), tot_loss_proj:3.417 [t=0.30s]
prediction: ['[CLS] what know it know it grows want when know be [SEP]']
[ 200/2000] tot_loss=2.085 (perp=9.897, rec=0.101, cos=0.005), tot_loss_proj:3.190 [t=0.30s]
prediction: ['[CLS] what know it wants it grows wants when know be [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.751 (perp=8.226, rec=0.102, cos=0.004), tot_loss_proj:2.592 [t=0.30s]
prediction: ['[CLS] what know it wants when it grows wants know be [SEP]']
[ 300/2000] tot_loss=1.737 (perp=8.226, rec=0.087, cos=0.005), tot_loss_proj:2.595 [t=0.30s]
prediction: ['[CLS] what know it wants when it grows wants know be [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.571 (perp=7.340, rec=0.099, cos=0.004), tot_loss_proj:2.225 [t=0.30s]
prediction: ['[CLS] know what it wants when it grows wants know be [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.498 (perp=7.016, rec=0.090, cos=0.005), tot_loss_proj:2.191 [t=0.30s]
prediction: ['[CLS] know what it wants when it wants grows know be [SEP]']
[ 450/2000] tot_loss=1.802 (perp=8.594, rec=0.079, cos=0.004), tot_loss_proj:2.526 [t=0.30s]
prediction: ['[CLS] know what it up when it wants grows know be [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.570 (perp=7.426, rec=0.082, cos=0.003), tot_loss_proj:2.088 [t=0.30s]
prediction: ['[CLS] know what it know when it wants grows up be [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.460 (perp=6.909, rec=0.074, cos=0.004), tot_loss_proj:1.885 [t=0.30s]
prediction: ['[CLS] know what it wants when it know grows up be [SEP]']
[ 600/2000] tot_loss=1.456 (perp=6.909, rec=0.071, cos=0.003), tot_loss_proj:1.890 [t=0.30s]
prediction: ['[CLS] know what it wants when it know grows up be [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=1.396 (perp=6.528, rec=0.087, cos=0.003), tot_loss_proj:2.009 [t=0.30s]
prediction: ['[CLS] be know what it wants when it know grows up [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.384 (perp=6.528, rec=0.075, cos=0.003), tot_loss_proj:2.004 [t=0.30s]
prediction: ['[CLS] be know what it wants when it know grows up [SEP]']
[ 750/2000] tot_loss=1.380 (perp=6.528, rec=0.071, cos=0.004), tot_loss_proj:2.007 [t=0.30s]
prediction: ['[CLS] be know what it wants when it know grows up [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.373 (perp=6.465, rec=0.077, cos=0.003), tot_loss_proj:1.957 [t=0.30s]
prediction: ['[CLS] be know what it wants when know it grows up [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.284 (perp=6.023, rec=0.076, cos=0.003), tot_loss_proj:1.850 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
[ 900/2000] tot_loss=1.294 (perp=6.023, rec=0.086, cos=0.003), tot_loss_proj:1.853 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.291 (perp=6.023, rec=0.084, cos=0.003), tot_loss_proj:1.860 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.275 (perp=6.023, rec=0.068, cos=0.003), tot_loss_proj:1.854 [t=0.31s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
[1050/2000] tot_loss=1.276 (perp=6.023, rec=0.068, cos=0.003), tot_loss_proj:1.865 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.274 (perp=6.023, rec=0.067, cos=0.003), tot_loss_proj:1.855 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.279 (perp=6.023, rec=0.071, cos=0.003), tot_loss_proj:1.852 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
[1200/2000] tot_loss=1.280 (perp=6.023, rec=0.073, cos=0.003), tot_loss_proj:1.858 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.291 (perp=6.023, rec=0.083, cos=0.003), tot_loss_proj:1.855 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.277 (perp=6.023, rec=0.069, cos=0.003), tot_loss_proj:1.862 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
[1350/2000] tot_loss=1.286 (perp=6.023, rec=0.078, cos=0.003), tot_loss_proj:1.854 [t=0.31s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.271 (perp=6.023, rec=0.063, cos=0.003), tot_loss_proj:1.858 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.274 (perp=6.023, rec=0.066, cos=0.003), tot_loss_proj:1.854 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
[1500/2000] tot_loss=1.280 (perp=6.023, rec=0.072, cos=0.003), tot_loss_proj:1.850 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.275 (perp=6.023, rec=0.067, cos=0.003), tot_loss_proj:1.856 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.270 (perp=6.023, rec=0.062, cos=0.003), tot_loss_proj:1.856 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
[1650/2000] tot_loss=1.285 (perp=6.023, rec=0.077, cos=0.003), tot_loss_proj:1.856 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.291 (perp=6.023, rec=0.083, cos=0.003), tot_loss_proj:1.850 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.275 (perp=6.023, rec=0.067, cos=0.003), tot_loss_proj:1.850 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
[1800/2000] tot_loss=1.291 (perp=6.023, rec=0.083, cos=0.003), tot_loss_proj:1.852 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.281 (perp=6.023, rec=0.074, cos=0.003), tot_loss_proj:1.855 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.286 (perp=6.023, rec=0.078, cos=0.003), tot_loss_proj:1.857 [t=0.30s]
prediction: ['[CLS] be know what it wants know when it grows up [SEP]']
[1950/2000] tot_loss=1.302 (perp=6.149, rec=0.069, cos=0.003), tot_loss_proj:1.915 [t=0.30s]
prediction: ['[CLS] be to what it wants know when it grows up [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.189 (perp=5.552, rec=0.076, cos=0.003), tot_loss_proj:1.512 [t=0.30s]
prediction: ['[CLS] be know what it wants to when it grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] be know what it wants when know it grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 54.545 | p: 54.545 | r: 54.545
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 146.212

[Aggregate metrics]:
rouge1     | fm: 87.615 | p: 86.887 | r: 88.523
rouge2     | fm: 55.223 | p: 54.923 | r: 55.584
rougeL     | fm: 77.061 | p: 76.494 | r: 77.803
rougeLsum  | fm: 77.096 | p: 76.545 | r: 77.798
r1fm+r2fm = 142.838

input #83 time: 0:12:04 | total time: 16:56:08


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9986247007725194
highest_index [0]
highest [0.9986247007725194]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9079328179359436 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.8927328586578369 for ['[CLS] primera criminalmost dynamic ride venue youtube [SEP]']
[Init] best rec loss: 0.8788459300994873 for ['[CLS] between favourated performed hope politics misty [SEP]']
[Init] best rec loss: 0.8612868189811707 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8610894680023193 for ['[CLS] appearance later orderedlby outstanding battery gentle [SEP]']
[Init] best rec loss: 0.8587613701820374 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.851856529712677 for ['[CLS] competed shegl brick kill trade down [SEP]']
[Init] best rec loss: 0.8379114270210266 for ['[CLS] individual hung cold ¹...ught railroad [SEP]']
[Init] best rec loss: 0.8374106884002686 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 0.8271065354347229 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best perm rec loss: 0.8216490149497986 for ['[CLS] caused infinite ca each goingiter its [SEP]']
[Init] best perm rec loss: 0.8214398622512817 for ['[CLS] caused its infiniteiter going each ca [SEP]']
[Init] best perm rec loss: 0.8186920881271362 for ['[CLS] ca its each infiniteiter caused going [SEP]']
[Init] best perm rec loss: 0.8181185722351074 for ['[CLS] going caiter infinite caused each its [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.526 (perp=11.386, rec=0.226, cos=0.022), tot_loss_proj:2.960 [t=0.30s]
prediction: ['[CLS] lost lost the think have ability lost [SEP]']
[ 100/2000] tot_loss=2.508 (perp=11.772, rec=0.138, cos=0.015), tot_loss_proj:3.083 [t=0.30s]
prediction: ['[CLS] lost the the think have ability lost [SEP]']
[ 150/2000] tot_loss=2.007 (perp=9.553, rec=0.093, cos=0.004), tot_loss_proj:2.813 [t=0.30s]
prediction: ['[CLS] people have the think have ability lost [SEP]']
[ 200/2000] tot_loss=1.997 (perp=9.553, rec=0.083, cos=0.004), tot_loss_proj:2.826 [t=0.30s]
prediction: ['[CLS] people have the think have ability lost [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.673 (perp=7.856, rec=0.097, cos=0.004), tot_loss_proj:3.250 [t=0.30s]
prediction: ['[CLS] people have the ability think have lost [SEP]']
[ 300/2000] tot_loss=1.790 (perp=8.576, rec=0.071, cos=0.004), tot_loss_proj:2.639 [t=0.30s]
prediction: ['[CLS] people to the ability think have lost [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.437 (perp=6.501, rec=0.127, cos=0.010), tot_loss_proj:2.053 [t=0.30s]
prediction: ['[CLS] people think the ability to have lost [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.377 (perp=6.240, rec=0.119, cos=0.011), tot_loss_proj:3.129 [t=0.30s]
prediction: ['[CLS] people have the ability to think lost [SEP]']
[ 450/2000] tot_loss=1.852 (perp=8.715, rec=0.101, cos=0.008), tot_loss_proj:3.698 [t=0.30s]
prediction: ['[CLS] people have the ability think think lost [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.701 (perp=7.826, rec=0.132, cos=0.005), tot_loss_proj:1.757 [t=0.30s]
prediction: ['[CLS] people have lost the ability think think [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.596 (perp=7.419, rec=0.109, cos=0.004), tot_loss_proj:1.995 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
[ 600/2000] tot_loss=1.580 (perp=7.419, rec=0.093, cos=0.004), tot_loss_proj:1.990 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.576 (perp=7.419, rec=0.089, cos=0.003), tot_loss_proj:1.991 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.557 (perp=7.419, rec=0.069, cos=0.003), tot_loss_proj:1.988 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
[ 750/2000] tot_loss=1.568 (perp=7.419, rec=0.081, cos=0.003), tot_loss_proj:1.992 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.566 (perp=7.419, rec=0.079, cos=0.003), tot_loss_proj:1.998 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.573 (perp=7.419, rec=0.086, cos=0.003), tot_loss_proj:1.994 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
[ 900/2000] tot_loss=1.572 (perp=7.419, rec=0.085, cos=0.003), tot_loss_proj:1.988 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.570 (perp=7.419, rec=0.083, cos=0.003), tot_loss_proj:2.002 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.559 (perp=7.419, rec=0.071, cos=0.003), tot_loss_proj:1.987 [t=0.31s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
[1050/2000] tot_loss=1.560 (perp=7.419, rec=0.073, cos=0.003), tot_loss_proj:1.991 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.562 (perp=7.419, rec=0.075, cos=0.003), tot_loss_proj:1.993 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[1150/2000] tot_loss=1.557 (perp=7.419, rec=0.070, cos=0.004), tot_loss_proj:1.992 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
[1200/2000] tot_loss=1.552 (perp=7.419, rec=0.065, cos=0.004), tot_loss_proj:1.991 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.554 (perp=7.419, rec=0.067, cos=0.004), tot_loss_proj:1.991 [t=0.31s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.562 (perp=7.419, rec=0.075, cos=0.004), tot_loss_proj:1.999 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
[1350/2000] tot_loss=1.558 (perp=7.419, rec=0.071, cos=0.004), tot_loss_proj:1.996 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[1400/2000] tot_loss=1.559 (perp=7.419, rec=0.071, cos=0.004), tot_loss_proj:1.998 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.557 (perp=7.419, rec=0.069, cos=0.004), tot_loss_proj:2.009 [t=0.30s]
prediction: ['[CLS] think people have lost the ability think [SEP]']
[1500/2000] tot_loss=1.284 (perp=6.010, rec=0.078, cos=0.004), tot_loss_proj:1.781 [t=0.30s]
prediction: ['[CLS] think people have lost the ability to [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.012 (perp=4.681, rec=0.073, cos=0.003), tot_loss_proj:1.047 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=1.008 (perp=4.681, rec=0.069, cos=0.003), tot_loss_proj:1.045 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=1.012 (perp=4.681, rec=0.073, cos=0.003), tot_loss_proj:1.043 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.003 (perp=4.681, rec=0.063, cos=0.003), tot_loss_proj:1.047 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=1.003 (perp=4.681, rec=0.064, cos=0.003), tot_loss_proj:1.040 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=0.985 (perp=4.681, rec=0.046, cos=0.003), tot_loss_proj:1.037 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.012 (perp=4.681, rec=0.073, cos=0.003), tot_loss_proj:1.052 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.006 (perp=4.681, rec=0.066, cos=0.003), tot_loss_proj:1.037 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=1.013 (perp=4.681, rec=0.074, cos=0.003), tot_loss_proj:1.044 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.008 (perp=4.681, rec=0.069, cos=0.003), tot_loss_proj:1.043 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.669 | p: 86.925 | r: 88.660
rouge2     | fm: 55.944 | p: 55.676 | r: 56.277
rougeL     | fm: 77.403 | p: 76.870 | r: 78.116
rougeLsum  | fm: 77.462 | p: 76.914 | r: 78.164
r1fm+r2fm = 143.613

input #84 time: 0:12:04 | total time: 17:08:13


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9985486720321903
highest_index [0]
highest [0.9985486720321903]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9036340117454529 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.8920694589614868 for ['[CLS] sent okay too deep partition secrecy consolidated true shouldn our [SEP]']
[Init] best rec loss: 0.8888673186302185 for ['[CLS] mt running waiting worried roverstakesley rating rag age [SEP]']
[Init] best rec loss: 0.878192663192749 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8480039834976196 for ['[CLS] thinks macau stand cam form halolic venture cannot vehicle [SEP]']
[Init] best rec loss: 0.8359525203704834 for ['[CLS]lete cecilcc goals bar [ rules man brodiestation [SEP]']
[Init] best rec loss: 0.8354098796844482 for ['[CLS] young graf challenging haven nord overly graduation blank dad josephine [SEP]']
[Init] best perm rec loss: 0.8341495394706726 for ['[CLS] graduation challenging young haven josephine blank graf overly dad nord [SEP]']
[Init] best perm rec loss: 0.8310648202896118 for ['[CLS] blank josephine young haven graduation challenging overly graf nord dad [SEP]']
[Init] best perm rec loss: 0.8298596739768982 for ['[CLS] graduation challenging josephine nord young overly dad graf blank haven [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.977 (perp=8.251, rec=0.296, cos=0.032), tot_loss_proj:2.314 [t=0.30s]
prediction: ['[CLS] unfortunately unfortunately. also pretty unfortunately unfortunately quite unfortunately not [SEP]']
[ 100/2000] tot_loss=1.488 (perp=6.862, rec=0.109, cos=0.006), tot_loss_proj:1.796 [t=0.30s]
prediction: ['[CLS] unfortunately,. also is not good very good not [SEP]']
[ 150/2000] tot_loss=1.490 (perp=7.029, rec=0.079, cos=0.006), tot_loss_proj:2.672 [t=0.30s]
prediction: ['[CLS] unfortunately,. also s not. very good it [SEP]']
[ 200/2000] tot_loss=1.490 (perp=7.029, rec=0.078, cos=0.006), tot_loss_proj:2.694 [t=0.30s]
prediction: ['[CLS] unfortunately,. also s not. very good it [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.004 (perp=4.495, rec=0.097, cos=0.008), tot_loss_proj:1.065 [t=0.30s]
prediction: ['[CLS] unfortunately, it also s not very very good. [SEP]']
[ 300/2000] tot_loss=1.972 (perp=7.199, rec=0.461, cos=0.071), tot_loss_proj:1.940 [t=0.30s]
prediction: ['[CLS] unfortunately. looked also it not s very good ( [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.942 (perp=7.555, rec=0.382, cos=0.049), tot_loss_proj:1.973 [t=0.30s]
prediction: ['[CLS] unfortunately. line also it a not very good ( [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.700 (perp=6.536, rec=0.354, cos=0.039), tot_loss_proj:1.819 [t=0.30s]
prediction: ['[CLS] unfortunately. ( also it a not very good line [SEP]']
[ 450/2000] tot_loss=1.656 (perp=6.536, rec=0.316, cos=0.033), tot_loss_proj:1.811 [t=0.30s]
prediction: ['[CLS] unfortunately. ( also it a not very good line [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.482 (perp=5.749, rec=0.306, cos=0.026), tot_loss_proj:1.666 [t=0.30s]
prediction: ['[CLS] unfortunately. ( also it not a very good line [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.408 (perp=5.541, rec=0.276, cos=0.024), tot_loss_proj:1.610 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
[ 600/2000] tot_loss=1.374 (perp=5.541, rec=0.243, cos=0.022), tot_loss_proj:1.593 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.365 (perp=5.541, rec=0.236, cos=0.021), tot_loss_proj:1.593 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.355 (perp=5.541, rec=0.228, cos=0.019), tot_loss_proj:1.602 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
[ 750/2000] tot_loss=1.344 (perp=5.541, rec=0.218, cos=0.018), tot_loss_proj:1.600 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.337 (perp=5.541, rec=0.212, cos=0.017), tot_loss_proj:1.605 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.331 (perp=5.541, rec=0.207, cos=0.016), tot_loss_proj:1.592 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
[ 900/2000] tot_loss=1.326 (perp=5.541, rec=0.203, cos=0.015), tot_loss_proj:1.594 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.322 (perp=5.541, rec=0.199, cos=0.015), tot_loss_proj:1.581 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
[1000/2000] tot_loss=1.312 (perp=5.541, rec=0.189, cos=0.014), tot_loss_proj:1.578 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
[1050/2000] tot_loss=1.305 (perp=5.541, rec=0.182, cos=0.014), tot_loss_proj:1.584 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
[1100/2000] tot_loss=1.306 (perp=5.541, rec=0.184, cos=0.014), tot_loss_proj:1.578 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
[1150/2000] tot_loss=1.303 (perp=5.541, rec=0.181, cos=0.014), tot_loss_proj:1.584 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
[1200/2000] tot_loss=1.308 (perp=5.541, rec=0.186, cos=0.013), tot_loss_proj:1.577 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
[1250/2000] tot_loss=1.300 (perp=5.541, rec=0.179, cos=0.013), tot_loss_proj:1.578 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
[1300/2000] tot_loss=1.302 (perp=5.541, rec=0.181, cos=0.013), tot_loss_proj:1.585 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
[1350/2000] tot_loss=1.303 (perp=5.541, rec=0.181, cos=0.013), tot_loss_proj:1.582 [t=0.31s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
[1400/2000] tot_loss=1.295 (perp=5.541, rec=0.174, cos=0.013), tot_loss_proj:1.584 [t=0.30s]
prediction: ['[CLS] unfortunately. ( it also not a very good line [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.412 (perp=6.043, rec=0.191, cos=0.013), tot_loss_proj:1.777 [t=0.30s]
prediction: ['[CLS] unfortunately. it also ( not a very good line [SEP]']
[1500/2000] tot_loss=1.391 (perp=6.043, rec=0.170, cos=0.013), tot_loss_proj:1.776 [t=0.30s]
prediction: ['[CLS] unfortunately. it also ( not a very good line [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.530 (perp=6.757, rec=0.165, cos=0.013), tot_loss_proj:1.782 [t=0.30s]
prediction: ['[CLS] unfortunately. s it also not a very good line [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.293 (perp=5.526, rec=0.175, cos=0.013), tot_loss_proj:1.515 [t=0.31s]
prediction: ['[CLS] unfortunately. it s also not a very good line [SEP]']
[1650/2000] tot_loss=1.614 (perp=7.176, rec=0.166, cos=0.013), tot_loss_proj:2.377 [t=0.30s]
prediction: ['[CLS] unfortunately. it s also not was very good line [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.510 (perp=6.576, rec=0.181, cos=0.014), tot_loss_proj:1.787 [t=0.30s]
prediction: ['[CLS] unfortunately. it was s also not very good line [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.364 (perp=5.600, rec=0.227, cos=0.017), tot_loss_proj:1.598 [t=0.30s]
prediction: ['[CLS] unfortunately it was s also not very good line. [SEP]']
[1800/2000] tot_loss=1.320 (perp=5.600, rec=0.185, cos=0.015), tot_loss_proj:1.601 [t=0.30s]
prediction: ['[CLS] unfortunately it was s also not very good line. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.322 (perp=5.573, rec=0.193, cos=0.015), tot_loss_proj:1.862 [t=0.30s]
prediction: ['[CLS] unfortunately was it s also not very good line. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.288 (perp=5.433, rec=0.187, cos=0.015), tot_loss_proj:1.601 [t=0.30s]
prediction: ['[CLS] unfortunately was it also also not very good line. [SEP]']
[1950/2000] tot_loss=1.293 (perp=5.433, rec=0.192, cos=0.014), tot_loss_proj:1.593 [t=0.30s]
prediction: ['[CLS] unfortunately was it also also not very good line. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.284 (perp=5.357, rec=0.199, cos=0.014), tot_loss_proj:1.543 [t=0.30s]
prediction: ['[CLS] unfortunately it was also also not very good line. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, it also s not very very good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 87.762 | p: 86.977 | r: 88.795
rouge2     | fm: 55.798 | p: 55.517 | r: 56.221
rougeL     | fm: 77.466 | p: 76.824 | r: 78.217
rougeLsum  | fm: 77.470 | p: 76.926 | r: 78.192
r1fm+r2fm = 143.561

input #85 time: 0:12:04 | total time: 17:20:17


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9987611252986475
highest_index [0]
highest [0.9987611252986475]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9472851157188416 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9073663949966431 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 0.8295146822929382 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.8039171695709229 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.7760397791862488 for ['[CLS] liberated round alright [SEP]']
[Init] best perm rec loss: 0.7751524448394775 for ['[CLS] round liberated alright [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.058 (perp=13.461, rec=0.320, cos=0.045), tot_loss_proj:4.190 [t=0.30s]
prediction: ['[CLS] integrity emotional inc [SEP]']
[ 100/2000] tot_loss=2.730 (perp=12.325, rec=0.220, cos=0.044), tot_loss_proj:4.021 [t=0.30s]
prediction: ['[CLS] clarity clarity sake [SEP]']
[ 150/2000] tot_loss=2.785 (perp=12.478, rec=0.244, cos=0.046), tot_loss_proj:3.118 [t=0.30s]
prediction: ['[CLS] clarity clarity bwf [SEP]']
[ 200/2000] tot_loss=2.766 (perp=12.478, rec=0.200, cos=0.070), tot_loss_proj:3.147 [t=0.30s]
prediction: ['[CLS] clarity clarity bwf [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.581 (perp=11.603, rec=0.186, cos=0.075), tot_loss_proj:2.872 [t=0.30s]
prediction: ['[CLS] clarity bwf clarity [SEP]']
[ 300/2000] tot_loss=2.636 (perp=11.603, rec=0.201, cos=0.114), tot_loss_proj:2.870 [t=0.30s]
prediction: ['[CLS] clarity bwf clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.639 (perp=11.603, rec=0.201, cos=0.117), tot_loss_proj:2.870 [t=0.30s]
prediction: ['[CLS] clarity bwf clarity [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.637 (perp=11.691, rec=0.214, cos=0.084), tot_loss_proj:3.765 [t=0.30s]
prediction: ['[CLS] emotional inflammatory clarity [SEP]']
[ 450/2000] tot_loss=2.651 (perp=11.691, rec=0.197, cos=0.116), tot_loss_proj:3.811 [t=0.30s]
prediction: ['[CLS] emotional inflammatory clarity [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.646 (perp=11.692, rec=0.190, cos=0.118), tot_loss_proj:3.473 [t=0.30s]
prediction: ['[CLS] possessions emotional clarity [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.518 (perp=11.029, rec=0.189, cos=0.124), tot_loss_proj:2.834 [t=0.31s]
prediction: ['[CLS] emotional possessions clarity [SEP]']
[ 600/2000] tot_loss=2.737 (perp=12.045, rec=0.202, cos=0.126), tot_loss_proj:3.936 [t=0.30s]
prediction: ['[CLS] hormones possessions clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.725 (perp=12.045, rec=0.187, cos=0.129), tot_loss_proj:3.938 [t=0.30s]
prediction: ['[CLS] hormones possessions clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.733 (perp=12.045, rec=0.188, cos=0.136), tot_loss_proj:3.938 [t=0.30s]
prediction: ['[CLS] hormones possessions clarity [SEP]']
[ 750/2000] tot_loss=2.748 (perp=12.045, rec=0.194, cos=0.145), tot_loss_proj:3.938 [t=0.30s]
prediction: ['[CLS] hormones possessions clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.756 (perp=12.045, rec=0.193, cos=0.153), tot_loss_proj:3.940 [t=0.30s]
prediction: ['[CLS] hormones possessions clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.544 (perp=11.029, rec=0.189, cos=0.149), tot_loss_proj:2.831 [t=0.30s]
prediction: ['[CLS] emotional possessions clarity [SEP]']
[ 900/2000] tot_loss=2.566 (perp=11.029, rec=0.205, cos=0.155), tot_loss_proj:2.828 [t=0.30s]
prediction: ['[CLS] emotional possessions clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.561 (perp=11.029, rec=0.195, cos=0.160), tot_loss_proj:2.831 [t=0.30s]
prediction: ['[CLS] emotional possessions clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=2.769 (perp=12.120, rec=0.186, cos=0.159), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS] thoroughbred possessions clarity [SEP]']
[1050/2000] tot_loss=2.774 (perp=12.120, rec=0.191, cos=0.159), tot_loss_proj:3.554 [t=0.30s]
prediction: ['[CLS] thoroughbred possessions clarity [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.569 (perp=11.110, rec=0.194, cos=0.153), tot_loss_proj:3.209 [t=0.30s]
prediction: ['[CLS] emotional clarity possessions [SEP]']
Attempt swap
[1150/2000] tot_loss=2.477 (perp=10.640, rec=0.190, cos=0.159), tot_loss_proj:2.462 [t=0.30s]
prediction: ['[CLS] emotional clarity achievement [SEP]']
[1200/2000] tot_loss=2.479 (perp=10.640, rec=0.193, cos=0.159), tot_loss_proj:2.463 [t=0.31s]
prediction: ['[CLS] emotional clarity achievement [SEP]']
Attempt swap
[1250/2000] tot_loss=2.488 (perp=10.640, rec=0.196, cos=0.164), tot_loss_proj:2.460 [t=0.30s]
prediction: ['[CLS] emotional clarity achievement [SEP]']
Attempt swap
[1300/2000] tot_loss=2.478 (perp=10.640, rec=0.186, cos=0.163), tot_loss_proj:2.461 [t=0.30s]
prediction: ['[CLS] emotional clarity achievement [SEP]']
[1350/2000] tot_loss=2.486 (perp=10.640, rec=0.193, cos=0.164), tot_loss_proj:2.462 [t=0.30s]
prediction: ['[CLS] emotional clarity achievement [SEP]']
Attempt swap
[1400/2000] tot_loss=2.478 (perp=10.640, rec=0.187, cos=0.163), tot_loss_proj:2.462 [t=0.30s]
prediction: ['[CLS] emotional clarity achievement [SEP]']
Attempt swap
[1450/2000] tot_loss=2.413 (perp=10.313, rec=0.188, cos=0.163), tot_loss_proj:2.699 [t=0.30s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
[1500/2000] tot_loss=2.406 (perp=10.313, rec=0.180, cos=0.163), tot_loss_proj:2.698 [t=0.30s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
Attempt swap
[1550/2000] tot_loss=2.401 (perp=10.313, rec=0.175, cos=0.164), tot_loss_proj:2.703 [t=0.31s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
Attempt swap
[1600/2000] tot_loss=2.426 (perp=10.313, rec=0.201, cos=0.163), tot_loss_proj:2.695 [t=0.30s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
[1650/2000] tot_loss=2.422 (perp=10.313, rec=0.195, cos=0.164), tot_loss_proj:2.698 [t=0.30s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
Attempt swap
[1700/2000] tot_loss=2.422 (perp=10.313, rec=0.195, cos=0.164), tot_loss_proj:2.698 [t=0.30s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
Attempt swap
[1750/2000] tot_loss=2.415 (perp=10.313, rec=0.188, cos=0.165), tot_loss_proj:2.700 [t=0.30s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
[1800/2000] tot_loss=2.417 (perp=10.313, rec=0.190, cos=0.164), tot_loss_proj:2.702 [t=0.30s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
Attempt swap
[1850/2000] tot_loss=2.413 (perp=10.313, rec=0.186, cos=0.165), tot_loss_proj:2.696 [t=0.30s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
Attempt swap
[1900/2000] tot_loss=2.411 (perp=10.313, rec=0.183, cos=0.165), tot_loss_proj:2.710 [t=0.30s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
[1950/2000] tot_loss=2.405 (perp=10.313, rec=0.177, cos=0.165), tot_loss_proj:2.696 [t=0.30s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
Attempt swap
[2000/2000] tot_loss=2.411 (perp=10.313, rec=0.183, cos=0.165), tot_loss_proj:2.707 [t=0.30s]
prediction: ['[CLS] thoroughbred clarity achievement [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] thoroughbred clarity achievement [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 60.000

[Aggregate metrics]:
rouge1     | fm: 87.495 | p: 86.785 | r: 88.479
rouge2     | fm: 55.555 | p: 55.276 | r: 55.907
rougeL     | fm: 77.107 | p: 76.512 | r: 77.905
rougeLsum  | fm: 77.300 | p: 76.733 | r: 78.047
r1fm+r2fm = 143.050

input #86 time: 0:12:02 | total time: 17:32:20


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.9988957672898477
highest_index [0]
highest [0.9988957672898477]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.7563130855560303 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7272683382034302 for ['[CLS] calendar? [SEP]']
[Init] best rec loss: 0.6739445924758911 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.6534679532051086 for ['[CLS] action [MASK] [SEP]']
[Init] best rec loss: 0.6447585225105286 for ['[CLS] distinct post [SEP]']
[Init] best rec loss: 0.6323065161705017 for ['[CLS] popularski [SEP]']
[Init] best rec loss: 0.6135426759719849 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.5955603122711182 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.690 (perp=7.258, rec=0.225, cos=0.014), tot_loss_proj:1.517 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 100/2000] tot_loss=1.546 (perp=7.258, rec=0.086, cos=0.009), tot_loss_proj:1.507 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.529 (perp=7.258, rec=0.070, cos=0.008), tot_loss_proj:1.503 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.502 (perp=7.258, rec=0.047, cos=0.003), tot_loss_proj:1.516 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.525 (perp=7.258, rec=0.071, cos=0.003), tot_loss_proj:1.519 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.523 (perp=7.258, rec=0.069, cos=0.003), tot_loss_proj:1.521 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.523 (perp=7.258, rec=0.068, cos=0.004), tot_loss_proj:1.512 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.002), tot_loss_proj:1.522 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.521 (perp=7.258, rec=0.063, cos=0.007), tot_loss_proj:1.517 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.520 (perp=7.258, rec=0.065, cos=0.003), tot_loss_proj:1.528 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.514 (perp=7.258, rec=0.060, cos=0.003), tot_loss_proj:1.516 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.527 (perp=7.258, rec=0.072, cos=0.004), tot_loss_proj:1.511 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.516 (perp=7.258, rec=0.061, cos=0.004), tot_loss_proj:1.529 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.505 (perp=7.258, rec=0.049, cos=0.004), tot_loss_proj:1.522 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.516 (perp=7.258, rec=0.060, cos=0.004), tot_loss_proj:1.530 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.524 (perp=7.258, rec=0.070, cos=0.003), tot_loss_proj:1.510 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.518 (perp=7.258, rec=0.064, cos=0.002), tot_loss_proj:1.525 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.519 (perp=7.258, rec=0.065, cos=0.002), tot_loss_proj:1.533 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.527 (perp=7.258, rec=0.074, cos=0.002), tot_loss_proj:1.508 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.505 (perp=7.258, rec=0.051, cos=0.002), tot_loss_proj:1.517 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.512 (perp=7.258, rec=0.059, cos=0.002), tot_loss_proj:1.526 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.512 (perp=7.258, rec=0.058, cos=0.002), tot_loss_proj:1.519 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.516 (perp=7.258, rec=0.062, cos=0.002), tot_loss_proj:1.534 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.517 (perp=7.258, rec=0.063, cos=0.002), tot_loss_proj:1.514 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.514 (perp=7.258, rec=0.060, cos=0.002), tot_loss_proj:1.490 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.507 (perp=7.258, rec=0.053, cos=0.002), tot_loss_proj:1.529 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.509 (perp=7.258, rec=0.056, cos=0.002), tot_loss_proj:1.512 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.528 (perp=7.258, rec=0.074, cos=0.002), tot_loss_proj:1.517 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.519 (perp=7.258, rec=0.066, cos=0.002), tot_loss_proj:1.522 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.516 (perp=7.258, rec=0.062, cos=0.002), tot_loss_proj:1.521 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.511 (perp=7.258, rec=0.057, cos=0.002), tot_loss_proj:1.498 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.504 (perp=7.258, rec=0.051, cos=0.002), tot_loss_proj:1.503 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.507 (perp=7.258, rec=0.053, cos=0.002), tot_loss_proj:1.518 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.512 (perp=7.258, rec=0.058, cos=0.002), tot_loss_proj:1.519 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.519 (perp=7.258, rec=0.065, cos=0.002), tot_loss_proj:1.509 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.503 (perp=7.258, rec=0.049, cos=0.002), tot_loss_proj:1.529 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.512 (perp=7.258, rec=0.058, cos=0.002), tot_loss_proj:1.507 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.512 (perp=7.258, rec=0.058, cos=0.002), tot_loss_proj:1.515 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.526 (perp=7.258, rec=0.072, cos=0.002), tot_loss_proj:1.532 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.503 (perp=7.258, rec=0.049, cos=0.002), tot_loss_proj:1.524 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.651 | p: 86.827 | r: 88.599
rouge2     | fm: 55.784 | p: 55.460 | r: 56.189
rougeL     | fm: 77.408 | p: 76.826 | r: 78.154
rougeLsum  | fm: 77.588 | p: 77.021 | r: 78.325
r1fm+r2fm = 143.435

input #87 time: 0:12:01 | total time: 17:44:22


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.9986105430553187
highest_index [0]
highest [0.9986105430553187]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9206142425537109 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9176249504089355 for ['[CLS] cardinal thouzu under problems years engineering hms nickname i this stores as wicketsisen colours stands direct gap filmfare front feel issn score hedgede strike connected three photographed styledwave itarable footballer beatrice frighteningaina better rey creedta bucharest [SEP]']
[Init] best rec loss: 0.9000802636146545 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.8974698185920715 for ['[CLS] discover wild productionri unesco furthermasters illness cup slip vietnam solid challenging el see corps one fortune identified righteous playing examplesarm unincorporated kahn initiated crisis wrap untilpired rocket walshiculate advancing 春 diamond edgar taskgon default healing polish cia [SEP]']
[Init] best rec loss: 0.8935965299606323 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.8876299262046814 for ['[CLS] rushed ward though ) level consul done fluorescent will speedpants holestitutederlandcake unwanted formed survived barren rajwhile spare recoverynagar kind rock noun guitar honesttom fin stay gardener lore windsor sense operations g climbicing conflict caste last [SEP]']
[Init] best rec loss: 0.8868411183357239 for ['[CLS] grab q my doctor fever alter firstt frog hardiff credits railway debut part iris mandir allyged why maxishedology mild commission arch boulevard host mass distributions crown music reign power tad satellite van lined involving boating published operating voting [SEP]']
[Init] best rec loss: 0.884403645992279 for ['[CLS]twined about spatial immunity finishedmission heavy systems int individual stand stations martin firm late stump order outer pro case ever may compensate exhaustion inducted resolved bare human seats crack mixed radio confidence butterfly label broken beingey y rachelished voiced landed [SEP]']
[Init] best rec loss: 0.8840668797492981 for ['[CLS] breed tick leave familiar reserve eu fresh featured court battingtic graves definitely. manor honorsept format colourorro laird april diego celeste surgery western realities longer domino keyboard fixed death addication talk game mexican eyed third run drama short middle [SEP]']
[Init] best perm rec loss: 0.883744478225708 for ['[CLS]ticdicationept leave reserve laird fresh realities familiar longer middleorro manor honors. mexican featured batting run definitely tick fixed eu talk keyboard drama ad colour short third court surgery diego celeste graves april format game breed eyed death western domino [SEP]']
[Init] best perm rec loss: 0.8835883736610413 for ['[CLS]. familiar keyboard fixed western court fresh colour reserve ad manor graves surgery eu realities longerticorro talk celeste middle format death eyed short run game diego laird definitely leave april honors battingept third tick domino drama breeddication featured mexican [SEP]']
[Init] best perm rec loss: 0.8829817175865173 for ['[CLS]tic court eyed definitely ad middleept familiar fresh short keyboard domino colour drama surgery western honors. run batting mexican manor fixed talk graves april deathorro diego format celeste tick eu breed longer game leave realities lairddication third featured reserve [SEP]']
[Init] best perm rec loss: 0.8825936913490295 for ['[CLS] realities breed reserve talk middle april celestedication format surgery run definitely tick diego leave longer keyboardtic death court drama laird ad batting shortorro familiar manor honors.ept colour eyed western mexican fixed third graves domino game featured fresh eu [SEP]']
[Init] best perm rec loss: 0.882140576839447 for ['[CLS] eyed surgery talk batting diego reserve eu breedorro court longer colour short dramatic honors third fresh middle format. western definitely tick domino realities laird runept keyboard fixeddication graves manor familiar featured celeste leave game ad mexican april death [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.935 (perp=12.329, rec=0.383, cos=0.086), tot_loss_proj:3.932 [t=0.31s]
prediction: ['[CLS]uation cannot cannot. rubber [SEP] elliot understands afternoon genes kids love perfect carolinati believed, connected true many weigh ක within and in pp happiness hised and walt health david great complicationsle magic involving love wrong jade candy tears [SEP]']
[ 100/2000] tot_loss=2.745 (perp=11.484, rec=0.327, cos=0.121), tot_loss_proj:4.016 [t=0.31s]
prediction: ['[CLS]uation cain isbn. jesse. & understands weekend tribe asian understands calm supposene romantic. we domestic [SEP] weigh inflicted of and and : calm hiss mighty walt day alzheimer wonderful complications∘. : love wrong that behind ache [SEP]']
[ 150/2000] tot_loss=2.594 (perp=10.713, rec=0.284, cos=0.168), tot_loss_proj:3.881 [t=0.31s]
prediction: ['[CLS] honored p p.sley. and understands week tribe carrie understands calm &ne romantic. we individual [SEP] weigh ක of and [SEP] where happiness his hum and faith day our grand answers romance. our love wrong. illinois ache [SEP]']
[ 200/2000] tot_loss=2.500 (perp=10.005, rec=0.281, cos=0.217), tot_loss_proj:3.027 [t=0.31s]
prediction: ['[CLS] zeta p p. slam. and understands tammy, usa understands calm & love understands. est domestic our drama radiating when and and where joy of all and faithb our grand answers romance and our love would. chewingraction [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.338 (perp=9.358, rec=0.269, cos=0.197), tot_loss_proj:3.107 [t=0.31s]
prediction: ['[CLS] torpedo p victory. slam. and understands tammy, my understands calm how love understands. how our our and within when and and : joy our from the pb our grand answers romance and drama love would. girlfriendraction [SEP]']
[ 300/2000] tot_loss=2.349 (perp=9.370, rec=0.267, cos=0.208), tot_loss_proj:3.172 [t=0.31s]
prediction: ['[CLS] torpedo p victory. mckay. and understands belongs, carrie understands calm and brands inwardly. how our our how within when and and : joy is existence the pb our grand investigative romance and our love would. tonguesraction [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.447 (perp=9.644, rec=0.319, cos=0.199), tot_loss_proj:3.019 [t=0.31s]
prediction: ['[CLS] torpedo p bread. mckay. and understands story, and understands calm how comfortable recognize. how our our. within that and carrie of joy [SEP] existence the p your months grand investigative anderson ー our love would. thoseraction [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.550 (perp=10.005, rec=0.287, cos=0.263), tot_loss_proj:3.297 [t=0.31s]
prediction: ['[CLS] torpedo t further. slam. and understands adventure, and understands calm how going highlightsiously how our our would within that and carrie of joy [SEP] existence the p your twenty grand adele anderson ー our love had. „raction [SEP]']
[ 450/2000] tot_loss=2.486 (perp=10.076, rec=0.250, cos=0.221), tot_loss_proj:3.164 [t=0.31s]
prediction: ['[CLS] torpedo p further.sley. and understands adventure ( and understands calm how going recognizeilation how our our and surface that and carrie of joy [SEP] lives the t your, grand things anderson and our love had. tonguesraction [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.456 (perp=9.910, rec=0.239, cos=0.235), tot_loss_proj:3.179 [t=0.31s]
prediction: ['[CLS] torpedo p ni.sley. and understands joy ( and understands calm was our recognizeilation how our going and surface that and carrie of joy [SEP] existence the t your, grand adele anderson and our love had. tonguesraction [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.410 (perp=9.650, rec=0.239, cos=0.241), tot_loss_proj:3.074 [t=0.31s]
prediction: ["[CLS] torpedo lives ni.sley. and understands treasure ( and understands calm was our recognizeilation how our going'surface that and carrie of joy [SEP] p the t your, grand adele anderson and our love forever. tonguesraction [SEP]"]
[ 600/2000] tot_loss=2.363 (perp=9.586, rec=0.220, cos=0.226), tot_loss_proj:3.399 [t=0.31s]
prediction: ["[CLS] torpedo existence further.sley. and understands joy, and understands calm was our recognizeilation how our going'surface that and carrie of joy [SEP] p the tb, grand philippines anderson and romance love forever. tonguesraction [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.253 (perp=9.111, rec=0.209, cos=0.221), tot_loss_proj:3.363 [t=0.31s]
prediction: ['[CLS] torpedo existence further.sleyilation and understands joy, and understands calm was our recognize. how our going the surface that and carrie of joy [SEP] p the t your. grand philippines anderson and romance love forever. tonguesraction [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.324 (perp=9.379, rec=0.219, cos=0.229), tot_loss_proj:2.974 [t=0.31s]
prediction: ['[CLS] torpedo lives ni.sleyilation and understandsays, and understands calm is our recognize. how our going the surface that and carrie of joy [SEP] p the t your anderson grand things. and romance love forever. tonguesraction [SEP]']
[ 750/2000] tot_loss=2.232 (perp=8.985, rec=0.204, cos=0.231), tot_loss_proj:2.838 [t=0.31s]
prediction: ['[CLS] torpedo lives further.sleyilation and understands joy, and understands calm is our recognize. how our going the surface that and carrie of joy [SEP] p the t your anderson grand things. and romance love forever. tonguesraction [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.232 (perp=8.866, rec=0.207, cos=0.252), tot_loss_proj:3.144 [t=0.31s]
prediction: ['[CLS] torpedo lives further.sleyilation and understands joy, and understands calm is our recognize. how our going the surface that and carrie of joy [SEP] p the t your tongues grand things. and romance love never. andersonraction [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.182 (perp=8.628, rec=0.207, cos=0.249), tot_loss_proj:3.277 [t=0.31s]
prediction: ['[CLS] that lives further.sleyilation and understands pleasure, and understands calm is our recognize. how our going the surface torpedo and carrie of joy [SEP] p the t your browser grand things. and romance love nothing. andersonraction [SEP]']
[ 900/2000] tot_loss=2.204 (perp=8.791, rec=0.207, cos=0.239), tot_loss_proj:3.295 [t=0.31s]
prediction: ['[CLS] that lives further.sleyilation and understands pleasure, and understands calm is our recognize. how our going the surface torpedo and carrie of joy [SEP] p the tc browser grandness. and romance love nothing. andersonraction [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.190 (perp=8.697, rec=0.202, cos=0.248), tot_loss_proj:3.239 [t=0.31s]
prediction: ['[CLS] that lives further.sleyilation the understands pleasure, and understands calmness our recognize. how our going the overhead torpedo and carrie of joy [SEP] p the t your browser grand is. and romance love never. andersonraction [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.139 (perp=8.511, rec=0.201, cos=0.236), tot_loss_proj:3.244 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation the understands pleasure, and understands calmness our recognize. how our going the overhead torpedo and carrie of joysley p the tc browser grand is. and romance love never. andersonraction [SEP]']
[1050/2000] tot_loss=2.130 (perp=8.511, rec=0.199, cos=0.229), tot_loss_proj:3.248 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation the understands pleasure, and understands calmness our recognize. how our going the overhead torpedo and carrie of joysley p the tc browser grand is. and romance love never. andersonraction [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.130 (perp=8.495, rec=0.193, cos=0.238), tot_loss_proj:3.212 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how our going the overhead torpedo the carrie of joysley p the tc browser grand is. and romance love never. anderson metaphor [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.091 (perp=8.268, rec=0.201, cos=0.237), tot_loss_proj:3.146 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how our going the overhead torpedo the carrie of joysley p the tc browser grand is. and romance love never anderson. metaphor [SEP]']
[1200/2000] tot_loss=2.073 (perp=8.186, rec=0.194, cos=0.242), tot_loss_proj:3.154 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how our believed the ill torpedo the carrie of joysley p the tc browser grand is. and romance love never anderson. metaphor [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.050 (perp=8.048, rec=0.199, cos=0.242), tot_loss_proj:3.068 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how our believed the ill torpedo the carrie of joysley p. tc browser grand is. and romance love never anderson the metaphor [SEP]']
Attempt swap
[1300/2000] tot_loss=2.037 (perp=8.048, rec=0.188, cos=0.240), tot_loss_proj:3.070 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how our believed the ill torpedo the carrie of joysley p. tc browser grand is. and romance love never anderson the metaphor [SEP]']
[1350/2000] tot_loss=2.061 (perp=8.129, rec=0.193, cos=0.243), tot_loss_proj:3.186 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how our step the ill torpedo the carrie of joysley p. tc browser grand is. and romance love never anderson the metaphor [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.036 (perp=8.009, rec=0.195, cos=0.240), tot_loss_proj:3.184 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how the step the ill torpedo the carrie of joysley p. tc browser grand is. and romance love never anderson our metaphor [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.028 (perp=7.963, rec=0.195, cos=0.240), tot_loss_proj:3.342 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the the torpedo the carrie of joysley p. tc browser grand is. and romance love never anderson our metaphor [SEP]']
[1500/2000] tot_loss=2.023 (perp=7.963, rec=0.194, cos=0.236), tot_loss_proj:3.342 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the the torpedo the carrie of joysley p. tc browser grand is. and romance love never anderson our metaphor [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.991 (perp=7.780, rec=0.197, cos=0.239), tot_loss_proj:3.296 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the torpedo the carrie of the joysley p. tc browser grand is. and romance love never anderson our metaphor [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.976 (perp=7.728, rec=0.194, cos=0.236), tot_loss_proj:3.282 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the torpedo the carrie of the joysley p. tc browser grand is. romance and love never anderson our metaphor [SEP]']
[1650/2000] tot_loss=1.969 (perp=7.728, rec=0.186, cos=0.237), tot_loss_proj:3.282 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the torpedo the carrie of the joysley p. tc browser grand is. romance and love never anderson our metaphor [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.969 (perp=7.711, rec=0.190, cos=0.237), tot_loss_proj:3.282 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the torpedo the carrie of the joysley p. t browserc grand is. romance and love never anderson our metaphor [SEP]']
Attempt swap
[1750/2000] tot_loss=1.962 (perp=7.676, rec=0.190, cos=0.237), tot_loss_proj:3.233 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the torpedo the carrie of the joysley p. t browser your grand is. romance and love never anderson our metaphor [SEP]']
[1800/2000] tot_loss=1.967 (perp=7.676, rec=0.193, cos=0.239), tot_loss_proj:3.237 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the torpedo the carrie of the joysley p. t browser your grand is. romance and love never anderson our metaphor [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.963 (perp=7.674, rec=0.191, cos=0.238), tot_loss_proj:3.389 [t=0.40s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the torpedo the carrie of the joysley p. t browser your grand is. romance of love anderson never our metaphor [SEP]']
Attempt swap
[1900/2000] tot_loss=1.961 (perp=7.674, rec=0.187, cos=0.239), tot_loss_proj:3.385 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the torpedo the carrie of the joysley p. t browser your grand is. romance of love anderson never our metaphor [SEP]']
[1950/2000] tot_loss=1.962 (perp=7.674, rec=0.188, cos=0.240), tot_loss_proj:3.385 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the torpedo the carrie of the joysley p. t browser your grand is. romance of love anderson never our metaphor [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.944 (perp=7.566, rec=0.191, cos=0.239), tot_loss_proj:3.396 [t=0.31s]
prediction: ['[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the torpedo the carrie of the joysley p. t is your grand browser. romance and love anderson never our metaphor [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] that lives further. [SEP]ilation and understands pleasure, and understands calmness our recognize. how ill step the torpedo the carrie of the joysley p. t browser your grand is. romance of love anderson never our metaphor [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 55.263 | p: 55.263 | r: 55.263
rouge2     | fm: 2.703 | p: 2.703 | r: 2.703
rougeL     | fm: 21.053 | p: 21.053 | r: 21.053
rougeLsum  | fm: 21.053 | p: 21.053 | r: 21.053
r1fm+r2fm = 57.966

[Aggregate metrics]:
rouge1     | fm: 87.318 | p: 86.544 | r: 88.263
rouge2     | fm: 55.132 | p: 54.803 | r: 55.502
rougeL     | fm: 76.834 | p: 76.248 | r: 77.569
rougeLsum  | fm: 76.930 | p: 76.423 | r: 77.655
r1fm+r2fm = 142.450

input #88 time: 0:12:16 | total time: 17:56:38


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.9985900568770798
highest_index [0]
highest [0.9985900568770798]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9168317914009094 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9154217839241028 for ['[CLS] began even nominatedmpton faultulouslykingiciencies sunday marioers candi featuring forest moore laid jessica between mass power scorer health old outside for binding against pontifical mother why reside access [SEP]']
[Init] best rec loss: 0.9113188982009888 for ['[CLS] has luck switzerland learning cbs passenger below brothersnp 22 ham american 2 daytona human / itself tight sales crooklen instant learning az meeting maintained viakey test adulterycraft their [SEP]']
[Init] best rec loss: 0.8972179293632507 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 0.8937321901321411 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.8757256865501404 for ['[CLS] an other⁄ given fire miniseries fit followed inhabitants opposite kilometres earliest varyact simplest areness shy law armand reissue ritchie does promoted deal al mathematics amazon brethren that indeed inter [SEP]']
[Init] best rec loss: 0.8239086866378784 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 0.8231472373008728 for ['[CLS] jailtorium sighed keep farm feel gameoke primate hodge victimserre ink pain course artifact basis leader tower there fate being nu red thirdllis public minor martins lucas essence orient [SEP]']
[Init] best rec loss: 0.8176193833351135 for ['[CLS] finally got wolf alan organizational 00pm or bra piketaff lack berlin circle nowhere chair temeraire sent movie thrust september wearing monster cartoon ang registrar secure until commons dimension surveyal island [SEP]']
[Init] best rec loss: 0.8156336545944214 for ['[CLS] hundred patsy such bien water paint forest baseball flats gives hq hit raising key dominic sideer waiter { college subtropical words wheel who rhyme never was built globeqa dogs point [SEP]']
[Init] best perm rec loss: 0.8150168657302856 for ['[CLS] patsy paint baseball side wordser subtropical college waiter rhyme flats suchqa dogs dominic gives forest built hundred point was raising wheel { hit key globe bien water never hq who [SEP]']
[Init] best perm rec loss: 0.8136904239654541 for ['[CLS] flats subtropicalqa bien such was built globe baseball wheel paint hq waiter words raising key who point never forest hundred side dominic rhyme { dogs hit water collegeer gives patsy [SEP]']
[Init] best perm rec loss: 0.8135277628898621 for ['[CLS] who wheel gives flats dogs hq built point paint hundred { bien water patsy subtropical forest baseball rhyme dominicqa waiter hit such words raising never key globe college side waser [SEP]']
[Init] best perm rec loss: 0.8127253651618958 for ['[CLS] such was water subtropical who wheel never built hit gives raising painter forest flats side hundred baseball key point college globe hq dogs { waiter rhyme dominic bienqa words patsy [SEP]']
[Init] best perm rec loss: 0.8125261664390564 for ['[CLS] raising whoqa wheel such was hq globe baseball college hit key never water { words point waiter built hundred dominic patsy forest dogs paint rhyme side bien giveser subtropical flats [SEP]']
[Init] best perm rec loss: 0.812035322189331 for ['[CLS] key who such wheel flats baseball raising side painter never dogs hundred words built patsy hit globe hq water waiter dominic subtropical rhyme forest point givesqa college was { bien [SEP]']
[Init] best perm rec loss: 0.8109673857688904 for ['[CLS] waiter dogs wheel dominic forest such was patsy raising gives never subtropical college who built water words baseball hqer rhyme side key hit bien hundred { paintqa flats globe point [SEP]']
[Init] best perm rec loss: 0.810299813747406 for ['[CLS] wheel biener hq gives forest { hundred was key who globe words dogs subtropical waiter built point paint raising water college dominic such hit never patsy side rhyme flats baseballqa [SEP]']
[Init] best perm rec loss: 0.8094518780708313 for ['[CLS] side dogs flats built wheel bien raising was suchqa paint waiter hundreder point dominic water subtropical baseball hit gives patsy hq globe key college never words { who rhyme forest [SEP]']
[Init] best perm rec loss: 0.8085156679153442 for ['[CLS] globe flats baseball was water { wheel such college raising hundred side built patsy forest hq who dogs bien paint dominic words rhyme key subtropical point never hitqa waiter giveser [SEP]']
[Init] best perm rec loss: 0.8084259629249573 for ['[CLS] key point bien waiter wheel gives dominic flats was patsy forest hit hq built water dogs college rhymeqa paint hundred never sucher raising words globe who side { subtropical baseball [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.823 (perp=12.287, rec=0.345, cos=0.021), tot_loss_proj:3.379 [t=0.30s]
prediction: ['[CLS] limit record is many tactic because cantonese lesbian layer most built failed at hopes historical get target - gun jewish bits elseismanednsed indians # left reducedged flyers ª [SEP]']
[ 100/2000] tot_loss=2.637 (perp=11.680, rec=0.290, cos=0.011), tot_loss_proj:3.810 [t=0.31s]
prediction: ['[CLS] cover upout realistic tactic because advantage void essence most constructed worse morgan strategy historical ezekiel shot - political where around or electroned notes not off pagoda onto ideas < [SEP]']
[ 150/2000] tot_loss=2.484 (perp=11.171, rec=0.241, cos=0.009), tot_loss_proj:3.216 [t=0.31s]
prediction: ['[CLS] cover up - thin tactic to worse mort essence most constructed worse region strategy atlantic - picture - political where around else uncleed none arms not off ideas outright ideas ideas [SEP]']
[ 200/2000] tot_loss=2.360 (perp=10.674, rec=0.217, cos=0.008), tot_loss_proj:3.095 [t=0.31s]
prediction: ['[CLS] cover up - thin tactic to worse jenks fact or constructed worse initially values atlantic - picture - picture where around else uncleed none arms - none ideasmobile ideas ideas [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.413 (perp=10.909, rec=0.222, cos=0.009), tot_loss_proj:2.993 [t=0.31s]
prediction: ['[CLS] to cover up - thin tactic worse worse fact or [SEP] worse initially strategyxi - knit - picture where around worse uncleed none arms - none core completely ideas ideas [SEP]']
[ 300/2000] tot_loss=2.195 (perp=9.918, rec=0.205, cos=0.007), tot_loss_proj:2.791 [t=0.31s]
prediction: ['[CLS] to cover up being worse tactic worse worse fact or yet worse initially energy - - talent - picture where around worse noneed nonees of none core completely ideas ideas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.069 (perp=9.370, rec=0.188, cos=0.007), tot_loss_proj:2.736 [t=0.31s]
prediction: ['[CLS] to cover up - worse tactic worse worse fact or yet worse picture none - - knit - picture where around worse noneed nonees - meaning core completely ideas ideas [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.086 (perp=9.477, rec=0.185, cos=0.006), tot_loss_proj:2.708 [t=0.31s]
prediction: ['[CLS] to cover up fact worse picture worse worse fact worse yet worse picture none - - knit - tactic picture around worse noneed nonees of meaning core completely ideas ideas [SEP]']
[ 450/2000] tot_loss=2.178 (perp=9.925, rec=0.186, cos=0.007), tot_loss_proj:2.795 [t=0.31s]
prediction: ['[CLS] to cover up fact worse picture worse worse fact worse yet constructed picture none - - knit - tactic picture around worseimed nonees of meaning core completely ideas ideas [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.077 (perp=9.439, rec=0.182, cos=0.007), tot_loss_proj:2.754 [t=0.31s]
prediction: ['[CLS] to cover up fact worse picture worse worse fact or yet constructed picture none - -sten core tactic picture around worseimed nonees - - - completely ideas ideas [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.633 (perp=11.082, rec=0.385, cos=0.032), tot_loss_proj:2.859 [t=0.31s]
prediction: ['[CLS] to cover up things increasingly for ನ worse fact or yet featuring cooper none boy com core tactic picture around worse - dily un communications offf -ept ideas violence [SEP]']
[ 600/2000] tot_loss=2.371 (perp=10.133, rec=0.324, cos=0.021), tot_loss_proj:2.719 [t=0.31s]
prediction: ['[CLS] to cover up that fact for too worse fact or yet featuring cooper none boy com core tactic movie around worse - dily cheap - offf -ept ideas violence [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.336 (perp=10.125, rec=0.296, cos=0.015), tot_loss_proj:2.702 [t=0.31s]
prediction: ['[CLS] to cover up that fact for too worseco or yet featuring partners none boy com core tactic picture around worse - nonely un fact offf -off ideas violence [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.196 (perp=9.556, rec=0.271, cos=0.013), tot_loss_proj:2.631 [t=0.31s]
prediction: ['[CLS] to cover up that fact or too worseco or yet featuring partners none boytarian core tactic picture around worse - none factly lacking offf -off ideas hurling [SEP]']
[ 750/2000] tot_loss=2.290 (perp=10.077, rec=0.262, cos=0.013), tot_loss_proj:2.739 [t=0.31s]
prediction: ['[CLS] to cover up that fact or too worseco or yet featuring eager none palestiniantarian core tactic picture around worse - none factly lacking offf -off ideas toilet [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.291 (perp=10.142, rec=0.251, cos=0.012), tot_loss_proj:2.921 [t=0.31s]
prediction: ['[CLS] to cover up that fact or too worse or yet featuringco eager none boyogist core tactic picture around worse - none factly overly offf -off ideas erotic [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.206 (perp=9.732, rec=0.247, cos=0.012), tot_loss_proj:3.002 [t=0.31s]
prediction: ['[CLS] to cover up that fact or too worse picture yet featuringco eager none boy± core tactic or around worse - none factly overly offf -off ideas erotic [SEP]']
[ 900/2000] tot_loss=2.246 (perp=9.953, rec=0.244, cos=0.012), tot_loss_proj:2.908 [t=0.31s]
prediction: ['[CLS] to cover up that fact or worse worse picture yet featuringco eager none boy± core tactic or around worse - none fact [CLS] overly offf -off ideas erotic [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.400 (perp=10.324, rec=0.312, cos=0.023), tot_loss_proj:2.930 [t=0.31s]
prediction: ['[CLS] to cover up that fact contribute worse tears rifle picture yet featuringcotty none old core tactic or around worse -im fiction, otherwise ofhl -off ideas / [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.304 (perp=9.986, rec=0.289, cos=0.018), tot_loss_proj:2.876 [t=0.31s]
prediction: ['[CLS] to cover up that fact disabilities worse tears - rifle picture yet featuringcotty none old core tactic or around worse -im fiction, otherwise ofhlept ideas / [SEP]']
[1050/2000] tot_loss=2.341 (perp=10.239, rec=0.275, cos=0.019), tot_loss_proj:2.836 [t=0.31s]
prediction: ['[CLS] to cover up that sell disabilities worse worse - rifle picture yet featuringcotty none old core tactic or around worse - none fiction [CLS] otherwise ofhlept ideas / [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.247 (perp=9.796, rec=0.270, cos=0.017), tot_loss_proj:2.699 [t=0.31s]
prediction: ['[CLS] to cover up that worse disabilities sell worse - rifle picture yet featuringcotty none old core tactic or around worse - none fiction [CLS] otherwise ofhlept ideas / [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.171 (perp=9.423, rec=0.269, cos=0.017), tot_loss_proj:2.611 [t=0.31s]
prediction: ['[CLS] to cover up that worse / sell worse - rifle picture yet featuringcotty none old core tactic or around worse - none fiction [CLS] otherwise ofhlept ideaslastic [SEP]']
[1200/2000] tot_loss=2.158 (perp=9.423, rec=0.258, cos=0.016), tot_loss_proj:2.614 [t=0.31s]
prediction: ['[CLS] to cover up that worse / sell worse - rifle picture yet featuringcotty none old core tactic or around worse - none fiction [CLS] otherwise ofhlept ideaslastic [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.130 (perp=9.307, rec=0.253, cos=0.016), tot_loss_proj:2.598 [t=0.31s]
prediction: ['[CLS] to cover up that picture / sell worse - rifle worse yet featuringcotty none old core tactic or around worse - none fact [CLS] otherwise ofhlept ideaslastic [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.154 (perp=9.425, rec=0.254, cos=0.015), tot_loss_proj:2.718 [t=0.31s]
prediction: ['[CLS] to cover fact that picture / sell worse featuring - violence worse yetcotty none old core tactic or around worse - none fact [CLS] otherwise ofhlept ideaslastic [SEP]']
[1350/2000] tot_loss=2.147 (perp=9.425, rec=0.247, cos=0.015), tot_loss_proj:2.717 [t=0.31s]
prediction: ['[CLS] to cover fact that picture / sell worse featuring - violence worse yetcotty none old core tactic or around worse - none fact [CLS] otherwise ofhlept ideaslastic [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.113 (perp=9.235, rec=0.251, cos=0.015), tot_loss_proj:2.692 [t=0.31s]
prediction: ['[CLS] to cover fact that fact / sell worse featuring - violence worse yetcotty none old core tactic or around worse - none picture [CLS] otherwise ofhlept ideaslastic [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.089 (perp=9.147, rec=0.245, cos=0.014), tot_loss_proj:2.663 [t=0.31s]
prediction: ['[CLS] to cover fact that fact / sell worse featuring - violence worse yetcotty none old core tactic or around worse - none picture [CLS] of otherwisehlept ideaslastic [SEP]']
[1500/2000] tot_loss=2.089 (perp=9.147, rec=0.245, cos=0.015), tot_loss_proj:2.666 [t=0.31s]
prediction: ['[CLS] to cover fact that fact / sell worse featuring - violence worse yetcotty none old core tactic or around worse - none picture [CLS] of otherwisehlept ideaslastic [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.082 (perp=9.090, rec=0.248, cos=0.015), tot_loss_proj:2.619 [t=0.31s]
prediction: ['[CLS] to cover fact that fact / sell worse featuring - violence worse yetcotty none old core tactic orlastic worse - none picture [CLS] of otherwisehlept ideas around [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.048 (perp=8.929, rec=0.247, cos=0.015), tot_loss_proj:2.567 [t=0.31s]
prediction: ['[CLS] to cover fact that worse / sell worse featuring - violence worse yetcotty none old core tactic orlastic fact - none picture [CLS] of otherwisehlept ideas around [SEP]']
[1650/2000] tot_loss=2.042 (perp=8.929, rec=0.241, cos=0.014), tot_loss_proj:2.565 [t=0.31s]
prediction: ['[CLS] to cover fact that worse / sell worse featuring - violence worse yetcotty none old core tactic orlastic fact - none picture [CLS] of otherwisehlept ideas around [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=2.064 (perp=9.035, rec=0.242, cos=0.015), tot_loss_proj:2.582 [t=0.31s]
prediction: ['[CLS] to cover fact that worse / sell worse featuring - violence worse yetcotty none old core contribute tactic or fact - none picture [CLS] of otherwisehlept ideas around [SEP]']
Attempt swap
[1750/2000] tot_loss=2.090 (perp=9.167, rec=0.243, cos=0.014), tot_loss_proj:2.616 [t=0.31s]
prediction: ['[CLS] to cover fact that worse / fact worse featuring - violence worse yetcotty none old core contribute tactic or fact - none picture [CLS] of otherwisehlept ideas around [SEP]']
[1800/2000] tot_loss=2.088 (perp=9.167, rec=0.241, cos=0.014), tot_loss_proj:2.611 [t=0.31s]
prediction: ['[CLS] to cover fact that worse / fact worse featuring - violence worse yetcotty none old core contribute tactic or fact - none picture [CLS] of otherwisehlept ideas around [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.099 (perp=9.218, rec=0.241, cos=0.014), tot_loss_proj:2.614 [t=0.31s]
prediction: ['[CLS] to cover fact that worse / fact worse contribute - violence worse yetcotty none boy core featuring tactic or fact - none picture [CLS] of otherwisehlept ideas around [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.089 (perp=9.187, rec=0.238, cos=0.014), tot_loss_proj:2.584 [t=0.31s]
prediction: ['[CLS] to cover fact that worse ideas featuring worse contribute - violence worse yetcotty none boy core fact tactic or fact - none picture [CLS] of otherwisehlept ideas around [SEP]']
[1950/2000] tot_loss=2.089 (perp=9.187, rec=0.237, cos=0.014), tot_loss_proj:2.581 [t=0.31s]
prediction: ['[CLS] to cover fact that worse ideas featuring worse contribute - violence worse yetcotty none boy core fact tactic or fact - none picture [CLS] of otherwisehlept ideas around [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.033 (perp=8.879, rec=0.243, cos=0.015), tot_loss_proj:2.537 [t=0.31s]
prediction: ['[CLS] to cover fact that worse ideas worse contribute - violence worse yetcotty none boy core fact tactic or fact - featuring none picture [CLS] of otherwisehlept ideas around [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] to cover up fact worse picture worse worse fact or yet constructed picture none - -sten core tactic picture around worseimed nonees - - - completely ideas ideas [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.224 | p: 57.692 | r: 65.217
rouge2     | fm: 12.766 | p: 12.000 | r: 13.636
rougeL     | fm: 40.816 | p: 38.462 | r: 43.478
rougeLsum  | fm: 40.816 | p: 38.462 | r: 43.478
r1fm+r2fm = 73.990

[Aggregate metrics]:
rouge1     | fm: 87.034 | p: 86.234 | r: 88.029
rouge2     | fm: 54.836 | p: 54.542 | r: 55.146
rougeL     | fm: 76.444 | p: 75.840 | r: 77.179
rougeLsum  | fm: 76.547 | p: 75.960 | r: 77.323
r1fm+r2fm = 141.870

input #89 time: 0:12:15 | total time: 18:08:53


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9986465728788432
highest_index [0]
highest [0.9986465728788432]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.8967862725257874 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.8588939309120178 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.8406001925468445 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8375158309936523 for ['[CLS] track direct unconscious unable eyes release [SEP]']
[Init] best rec loss: 0.8019788861274719 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.7982227802276611 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.7933673858642578 for ['[CLS] male when released cannot entourage spirited [SEP]']
[Init] best perm rec loss: 0.7910712957382202 for ['[CLS] cannot spirited male when released entourage [SEP]']
[Init] best perm rec loss: 0.790547788143158 for ['[CLS] when entourage male spirited cannot released [SEP]']
[Init] best perm rec loss: 0.7892860174179077 for ['[CLS] entourage spirited when released cannot male [SEP]']
[Init] best perm rec loss: 0.7891494631767273 for ['[CLS] when entourage released spirited male cannot [SEP]']
[Init] best perm rec loss: 0.788595974445343 for ['[CLS] when male cannot spirited entourage released [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.261 (perp=9.876, rec=0.263, cos=0.022), tot_loss_proj:2.851 [t=0.30s]
prediction: ['[CLS] dollars how ridiculous how money ridiculous [SEP]']
[ 100/2000] tot_loss=1.773 (perp=7.864, rec=0.182, cos=0.018), tot_loss_proj:2.424 [t=0.30s]
prediction: ['[CLS] money how ridiculous and money ridiculous [SEP]']
[ 150/2000] tot_loss=1.759 (perp=7.864, rec=0.171, cos=0.015), tot_loss_proj:2.442 [t=0.30s]
prediction: ['[CLS] money how ridiculous and money ridiculous [SEP]']
[ 200/2000] tot_loss=1.731 (perp=7.864, rec=0.146, cos=0.012), tot_loss_proj:2.444 [t=0.30s]
prediction: ['[CLS] money how ridiculous and money ridiculous [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.516 (perp=6.834, rec=0.137, cos=0.012), tot_loss_proj:2.172 [t=0.30s]
prediction: ['[CLS] money how ridiculous and ridiculous money [SEP]']
[ 300/2000] tot_loss=1.954 (perp=9.115, rec=0.125, cos=0.006), tot_loss_proj:2.453 [t=0.30s]
prediction: ['[CLS] oriented how ridiculous and ridiculous money [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.480 (perp=6.842, rec=0.105, cos=0.007), tot_loss_proj:2.162 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.465 (perp=6.842, rec=0.091, cos=0.005), tot_loss_proj:2.167 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 450/2000] tot_loss=1.466 (perp=6.842, rec=0.091, cos=0.006), tot_loss_proj:2.152 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.453 (perp=6.842, rec=0.080, cos=0.004), tot_loss_proj:2.147 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.474 (perp=6.842, rec=0.100, cos=0.005), tot_loss_proj:2.156 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 600/2000] tot_loss=1.460 (perp=6.842, rec=0.087, cos=0.005), tot_loss_proj:2.151 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.459 (perp=6.842, rec=0.086, cos=0.004), tot_loss_proj:2.151 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.461 (perp=6.842, rec=0.089, cos=0.004), tot_loss_proj:2.154 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 750/2000] tot_loss=1.447 (perp=6.842, rec=0.074, cos=0.004), tot_loss_proj:2.150 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.448 (perp=6.842, rec=0.075, cos=0.004), tot_loss_proj:2.154 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.453 (perp=6.842, rec=0.080, cos=0.004), tot_loss_proj:2.153 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 900/2000] tot_loss=1.457 (perp=6.842, rec=0.084, cos=0.004), tot_loss_proj:2.155 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.443 (perp=6.842, rec=0.071, cos=0.004), tot_loss_proj:2.150 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1000/2000] tot_loss=1.456 (perp=6.842, rec=0.084, cos=0.004), tot_loss_proj:2.153 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1050/2000] tot_loss=1.459 (perp=6.842, rec=0.086, cos=0.004), tot_loss_proj:2.160 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1100/2000] tot_loss=1.454 (perp=6.842, rec=0.081, cos=0.004), tot_loss_proj:2.162 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1150/2000] tot_loss=1.450 (perp=6.842, rec=0.077, cos=0.004), tot_loss_proj:2.158 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1200/2000] tot_loss=1.458 (perp=6.842, rec=0.086, cos=0.004), tot_loss_proj:2.157 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1250/2000] tot_loss=1.450 (perp=6.842, rec=0.078, cos=0.004), tot_loss_proj:2.151 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1300/2000] tot_loss=1.455 (perp=6.842, rec=0.082, cos=0.004), tot_loss_proj:2.153 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1350/2000] tot_loss=1.442 (perp=6.842, rec=0.069, cos=0.004), tot_loss_proj:2.155 [t=0.31s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1400/2000] tot_loss=1.442 (perp=6.842, rec=0.070, cos=0.004), tot_loss_proj:2.155 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1450/2000] tot_loss=1.456 (perp=6.842, rec=0.084, cos=0.004), tot_loss_proj:2.163 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1500/2000] tot_loss=1.446 (perp=6.842, rec=0.074, cos=0.004), tot_loss_proj:2.151 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1550/2000] tot_loss=1.436 (perp=6.842, rec=0.064, cos=0.004), tot_loss_proj:2.160 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1600/2000] tot_loss=1.445 (perp=6.842, rec=0.072, cos=0.004), tot_loss_proj:2.158 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1650/2000] tot_loss=1.448 (perp=6.842, rec=0.076, cos=0.004), tot_loss_proj:2.161 [t=0.31s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1700/2000] tot_loss=1.452 (perp=6.842, rec=0.080, cos=0.004), tot_loss_proj:2.153 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1750/2000] tot_loss=1.453 (perp=6.842, rec=0.081, cos=0.004), tot_loss_proj:2.165 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1800/2000] tot_loss=1.454 (perp=6.842, rec=0.082, cos=0.004), tot_loss_proj:2.157 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1850/2000] tot_loss=1.457 (perp=6.842, rec=0.084, cos=0.004), tot_loss_proj:2.155 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1900/2000] tot_loss=1.445 (perp=6.842, rec=0.072, cos=0.004), tot_loss_proj:2.161 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1950/2000] tot_loss=1.443 (perp=6.842, rec=0.071, cos=0.004), tot_loss_proj:2.114 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[2000/2000] tot_loss=1.446 (perp=6.842, rec=0.073, cos=0.004), tot_loss_proj:2.120 [t=0.30s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and ridiculous money oriented [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 87.092 | p: 86.276 | r: 88.135
rouge2     | fm: 54.913 | p: 54.574 | r: 55.374
rougeL     | fm: 76.755 | p: 76.084 | r: 77.569
rougeLsum  | fm: 76.615 | p: 76.039 | r: 77.449
r1fm+r2fm = 142.005

input #90 time: 0:12:03 | total time: 18:20:56


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9988062868065049
highest_index [0]
highest [0.9988062868065049]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.8254905343055725 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.7781746983528137 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.7733839750289917 for ['[CLS] dennistro drake effective taxes angle leave fly [SEP]']
[Init] best rec loss: 0.7715358734130859 for ['[CLS] because case yard pro mine advantage waves operative [SEP]']
[Init] best rec loss: 0.7423657774925232 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.7069634199142456 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.6936638355255127 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.6880439519882202 for ['[CLS] independent seemingly cartoon facedianspar anti dish [SEP]']
[Init] best rec loss: 0.6829566955566406 for ['[CLS] oxford bleeding? personal talking hold broadway tied [SEP]']
[Init] best rec loss: 0.6785281300544739 for ['[CLS] reminder addict anyway oneislausicidelishhered [SEP]']
[Init] best perm rec loss: 0.6760774254798889 for ['[CLS] reminderislaus anywayicide addict oneheredlish [SEP]']
[Init] best perm rec loss: 0.6737684607505798 for ['[CLS] addict onelishicidehered anywayislaus reminder [SEP]']
[Init] best perm rec loss: 0.6700745224952698 for ['[CLS]icidelishhered anyway reminder addictislaus one [SEP]']
[Init] best perm rec loss: 0.6695769429206848 for ['[CLS]heredicide oneislauslish anyway reminder addict [SEP]']
[Init] best perm rec loss: 0.6675938367843628 for ['[CLS]heredlishicide addict oneislaus reminder anyway [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.673 (perp=11.744, rec=0.283, cos=0.041), tot_loss_proj:3.039 [t=0.30s]
prediction: ['[CLS] loco ridiculous ridiculous less ridiculous no more few [SEP]']
[ 100/2000] tot_loss=2.191 (perp=10.291, rec=0.120, cos=0.012), tot_loss_proj:2.783 [t=0.30s]
prediction: ['[CLS] loco ridiculous loco more loco but no more [SEP]']
[ 150/2000] tot_loss=2.060 (perp=9.802, rec=0.093, cos=0.007), tot_loss_proj:2.594 [t=0.30s]
prediction: ['[CLS] mu ridiculous locoy loco but no more [SEP]']
[ 200/2000] tot_loss=2.033 (perp=9.802, rec=0.067, cos=0.005), tot_loss_proj:2.597 [t=0.30s]
prediction: ['[CLS] mu ridiculous locoy loco but no more [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.964 (perp=9.364, rec=0.084, cos=0.007), tot_loss_proj:2.515 [t=0.30s]
prediction: ['[CLS] mu ridiculous loco buty loco no more [SEP]']
[ 300/2000] tot_loss=1.946 (perp=9.364, rec=0.069, cos=0.005), tot_loss_proj:2.511 [t=0.30s]
prediction: ['[CLS] mu ridiculous loco buty loco no more [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.943 (perp=9.343, rec=0.069, cos=0.005), tot_loss_proj:2.514 [t=0.30s]
prediction: ['[CLS] mu ridiculous loco but locoy no more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.951 (perp=9.343, rec=0.078, cos=0.004), tot_loss_proj:2.521 [t=0.30s]
prediction: ['[CLS] mu ridiculous loco but locoy no more [SEP]']
[ 450/2000] tot_loss=1.938 (perp=9.343, rec=0.065, cos=0.004), tot_loss_proj:2.519 [t=0.30s]
prediction: ['[CLS] mu ridiculous loco but locoy no more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.939 (perp=9.343, rec=0.068, cos=0.003), tot_loss_proj:2.517 [t=0.30s]
prediction: ['[CLS] mu ridiculous loco but locoy no more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.934 (perp=9.343, rec=0.063, cos=0.002), tot_loss_proj:2.517 [t=0.30s]
prediction: ['[CLS] mu ridiculous loco but locoy no more [SEP]']
[ 600/2000] tot_loss=1.681 (perp=8.084, rec=0.061, cos=0.002), tot_loss_proj:2.319 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.680 (perp=8.084, rec=0.061, cos=0.002), tot_loss_proj:2.319 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.691 (perp=8.084, rec=0.071, cos=0.002), tot_loss_proj:2.316 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
[ 750/2000] tot_loss=1.690 (perp=8.084, rec=0.070, cos=0.002), tot_loss_proj:2.325 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.689 (perp=8.084, rec=0.069, cos=0.002), tot_loss_proj:2.317 [t=0.31s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.677 (perp=8.084, rec=0.058, cos=0.002), tot_loss_proj:2.324 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
[ 900/2000] tot_loss=1.682 (perp=8.084, rec=0.063, cos=0.002), tot_loss_proj:2.316 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.690 (perp=8.084, rec=0.071, cos=0.002), tot_loss_proj:2.324 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.682 (perp=8.084, rec=0.063, cos=0.002), tot_loss_proj:2.317 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
[1050/2000] tot_loss=1.686 (perp=8.084, rec=0.067, cos=0.002), tot_loss_proj:2.317 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.687 (perp=8.084, rec=0.068, cos=0.002), tot_loss_proj:2.318 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.683 (perp=8.084, rec=0.064, cos=0.002), tot_loss_proj:2.322 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
[1200/2000] tot_loss=1.680 (perp=8.084, rec=0.061, cos=0.002), tot_loss_proj:2.319 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.684 (perp=8.084, rec=0.064, cos=0.002), tot_loss_proj:2.319 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.689 (perp=8.084, rec=0.070, cos=0.002), tot_loss_proj:2.319 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
[1350/2000] tot_loss=1.684 (perp=8.084, rec=0.065, cos=0.002), tot_loss_proj:2.316 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.679 (perp=8.084, rec=0.060, cos=0.002), tot_loss_proj:2.325 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.693 (perp=8.084, rec=0.073, cos=0.002), tot_loss_proj:2.316 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
[1500/2000] tot_loss=1.685 (perp=8.084, rec=0.066, cos=0.002), tot_loss_proj:2.322 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.687 (perp=8.084, rec=0.067, cos=0.002), tot_loss_proj:2.317 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.688 (perp=8.084, rec=0.069, cos=0.002), tot_loss_proj:2.311 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
[1650/2000] tot_loss=1.680 (perp=8.084, rec=0.061, cos=0.002), tot_loss_proj:2.311 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.683 (perp=8.084, rec=0.064, cos=0.002), tot_loss_proj:2.313 [t=0.31s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.680 (perp=8.084, rec=0.060, cos=0.002), tot_loss_proj:2.315 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
[1800/2000] tot_loss=1.687 (perp=8.084, rec=0.068, cos=0.002), tot_loss_proj:2.317 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.687 (perp=8.084, rec=0.068, cos=0.002), tot_loss_proj:2.325 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.682 (perp=8.084, rec=0.063, cos=0.002), tot_loss_proj:2.318 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
[1950/2000] tot_loss=1.682 (perp=8.084, rec=0.063, cos=0.002), tot_loss_proj:2.316 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.689 (perp=8.084, rec=0.069, cos=0.002), tot_loss_proj:2.317 [t=0.30s]
prediction: ['[CLS] mu ridiculous, but locoy no more [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] mu ridiculous, but locoy no more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 89.286

[Aggregate metrics]:
rouge1     | fm: 87.022 | p: 86.125 | r: 88.057
rouge2     | fm: 54.628 | p: 54.323 | r: 55.044
rougeL     | fm: 76.609 | p: 75.935 | r: 77.398
rougeLsum  | fm: 76.630 | p: 75.911 | r: 77.463
r1fm+r2fm = 141.650

input #91 time: 0:12:05 | total time: 18:33:02


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9987903407489913
highest_index [0]
highest [0.9987903407489913]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8589625954627991 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8574015498161316 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8165344595909119 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.7819698452949524 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7253013253211975 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.7242715954780579 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.670 (perp=7.647, rec=0.134, cos=0.007), tot_loss_proj:1.592 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 100/2000] tot_loss=1.594 (perp=7.647, rec=0.062, cos=0.003), tot_loss_proj:1.590 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.604 (perp=7.647, rec=0.072, cos=0.002), tot_loss_proj:1.594 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.609 (perp=7.647, rec=0.077, cos=0.003), tot_loss_proj:1.590 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.596 (perp=7.647, rec=0.064, cos=0.002), tot_loss_proj:1.594 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.589 (perp=7.647, rec=0.057, cos=0.002), tot_loss_proj:1.599 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.593 (perp=7.647, rec=0.062, cos=0.002), tot_loss_proj:1.585 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.598 (perp=7.647, rec=0.066, cos=0.003), tot_loss_proj:1.596 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.583 (perp=7.647, rec=0.051, cos=0.002), tot_loss_proj:1.588 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.590 (perp=7.647, rec=0.058, cos=0.002), tot_loss_proj:1.594 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.593 (perp=7.647, rec=0.061, cos=0.002), tot_loss_proj:1.608 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.591 (perp=7.647, rec=0.059, cos=0.002), tot_loss_proj:1.575 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.590 (perp=7.647, rec=0.058, cos=0.002), tot_loss_proj:1.584 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.586 (perp=7.647, rec=0.054, cos=0.002), tot_loss_proj:1.599 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.589 (perp=7.647, rec=0.057, cos=0.002), tot_loss_proj:1.600 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.603 (perp=7.647, rec=0.071, cos=0.002), tot_loss_proj:1.592 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.595 (perp=7.647, rec=0.063, cos=0.002), tot_loss_proj:1.589 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.586 (perp=7.647, rec=0.054, cos=0.002), tot_loss_proj:1.582 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.586 (perp=7.647, rec=0.054, cos=0.002), tot_loss_proj:1.607 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.594 (perp=7.647, rec=0.062, cos=0.002), tot_loss_proj:1.591 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.598 (perp=7.647, rec=0.067, cos=0.002), tot_loss_proj:1.592 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.588 (perp=7.647, rec=0.056, cos=0.002), tot_loss_proj:1.607 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.588 (perp=7.647, rec=0.056, cos=0.002), tot_loss_proj:1.587 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.592 (perp=7.647, rec=0.060, cos=0.002), tot_loss_proj:1.595 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.581 (perp=7.647, rec=0.050, cos=0.002), tot_loss_proj:1.598 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.603 (perp=7.647, rec=0.071, cos=0.002), tot_loss_proj:1.596 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.588 (perp=7.647, rec=0.056, cos=0.002), tot_loss_proj:1.590 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.575 (perp=7.647, rec=0.044, cos=0.002), tot_loss_proj:1.598 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.598 (perp=7.647, rec=0.066, cos=0.002), tot_loss_proj:1.606 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.586 (perp=7.647, rec=0.055, cos=0.002), tot_loss_proj:1.594 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.596 (perp=7.647, rec=0.065, cos=0.002), tot_loss_proj:1.587 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.589 (perp=7.647, rec=0.058, cos=0.002), tot_loss_proj:1.605 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.595 (perp=7.647, rec=0.063, cos=0.002), tot_loss_proj:1.585 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.595 (perp=7.647, rec=0.063, cos=0.002), tot_loss_proj:1.595 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.600 (perp=7.647, rec=0.068, cos=0.002), tot_loss_proj:1.596 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.587 (perp=7.647, rec=0.055, cos=0.002), tot_loss_proj:1.594 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.595 (perp=7.647, rec=0.063, cos=0.002), tot_loss_proj:1.598 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.596 (perp=7.647, rec=0.064, cos=0.002), tot_loss_proj:1.602 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.597 (perp=7.647, rec=0.065, cos=0.002), tot_loss_proj:1.597 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.607 (perp=7.647, rec=0.076, cos=0.002), tot_loss_proj:1.585 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.067 | p: 86.220 | r: 88.088
rouge2     | fm: 55.136 | p: 54.769 | r: 55.567
rougeL     | fm: 76.879 | p: 76.207 | r: 77.624
rougeLsum  | fm: 76.756 | p: 76.132 | r: 77.546
r1fm+r2fm = 142.203

input #92 time: 0:12:02 | total time: 18:45:04


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9987496075323365
highest_index [0]
highest [0.9987496075323365]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 0.9548974633216858 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.932569682598114 for ['[CLS] taxi kang lookiled what mostchrome [SEP]']
[Init] best rec loss: 0.9090296626091003 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.9055435061454773 for ['[CLS] worthted ft assignment porch check up [SEP]']
[Init] best rec loss: 0.8900865912437439 for ['[CLS] lucas war breaks baby my pauline divided [SEP]']
[Init] best rec loss: 0.8848389387130737 for ['[CLS] village tallest almost giro opened wine section [SEP]']
[Init] best rec loss: 0.8744845390319824 for ['[CLS] alaska school flags land doc protest from [SEP]']
[Init] best perm rec loss: 0.8713846206665039 for ['[CLS] school protest flags doc land alaska from [SEP]']
[Init] best perm rec loss: 0.8706761598587036 for ['[CLS] flags land protest doc from alaska school [SEP]']
[Init] best perm rec loss: 0.8706189393997192 for ['[CLS] flags land from school alaska doc protest [SEP]']
[Init] best perm rec loss: 0.8680773973464966 for ['[CLS] land alaska from doc school protest flags [SEP]']
[Init] best perm rec loss: 0.8665260076522827 for ['[CLS] land school alaska doc protest from flags [SEP]']
[Init] best perm rec loss: 0.8662610650062561 for ['[CLS] flags doc school alaska from land protest [SEP]']
[Init] best perm rec loss: 0.8654131889343262 for ['[CLS] alaska from doc protest school flags land [SEP]']
[Init] best perm rec loss: 0.8650025725364685 for ['[CLS] land doc from flags protest school alaska [SEP]']
[Init] best perm rec loss: 0.8647843599319458 for ['[CLS] land from protest doc school flags alaska [SEP]']
[Init] best perm rec loss: 0.8647270202636719 for ['[CLS] land from flags school protest doc alaska [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.303 (perp=10.204, rec=0.249, cos=0.013), tot_loss_proj:2.446 [t=0.30s]
prediction: ['[CLS] matt in having funny such funny funny [SEP]']
[ 100/2000] tot_loss=2.194 (perp=10.139, rec=0.159, cos=0.006), tot_loss_proj:2.406 [t=0.30s]
prediction: ['[CLS] funny way its understanding in funny funny [SEP]']
[ 150/2000] tot_loss=2.158 (perp=10.243, rec=0.105, cos=0.004), tot_loss_proj:2.385 [t=0.30s]
prediction: ['[CLS] funny way its understanding in often funny [SEP]']
[ 200/2000] tot_loss=2.321 (perp=11.185, rec=0.080, cos=0.003), tot_loss_proj:2.702 [t=0.30s]
prediction: ['[CLS] writer way its understanding in often funny [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.860 (perp=8.834, rec=0.090, cos=0.003), tot_loss_proj:2.400 [t=0.30s]
prediction: ['[CLS] in sometimes way its understanding often funny [SEP]']
[ 300/2000] tot_loss=1.921 (perp=9.194, rec=0.080, cos=0.003), tot_loss_proj:2.217 [t=0.30s]
prediction: ['[CLS] in often way its understanding often funny [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.956 (perp=9.458, rec=0.062, cos=0.003), tot_loss_proj:2.227 [t=0.30s]
prediction: ['[CLS] in often way its, funny understanding [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.715 (perp=8.184, rec=0.075, cos=0.003), tot_loss_proj:1.897 [t=0.30s]
prediction: ['[CLS] in its way often, funny understanding [SEP]']
[ 450/2000] tot_loss=1.706 (perp=8.184, rec=0.066, cos=0.003), tot_loss_proj:1.896 [t=0.30s]
prediction: ['[CLS] in its way often, funny understanding [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.612 (perp=7.733, rec=0.063, cos=0.003), tot_loss_proj:1.781 [t=0.30s]
prediction: ['[CLS] in its way, often funny understanding [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.618 (perp=7.733, rec=0.069, cos=0.003), tot_loss_proj:1.785 [t=0.30s]
prediction: ['[CLS] in its way, often funny understanding [SEP]']
[ 600/2000] tot_loss=1.616 (perp=7.733, rec=0.067, cos=0.003), tot_loss_proj:1.786 [t=0.31s]
prediction: ['[CLS] in its way, often funny understanding [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.465 (perp=6.923, rec=0.077, cos=0.003), tot_loss_proj:1.595 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.458 (perp=6.923, rec=0.071, cos=0.003), tot_loss_proj:1.589 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[ 750/2000] tot_loss=1.454 (perp=6.923, rec=0.067, cos=0.003), tot_loss_proj:1.595 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.449 (perp=6.923, rec=0.062, cos=0.003), tot_loss_proj:1.590 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.451 (perp=6.923, rec=0.064, cos=0.003), tot_loss_proj:1.588 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[ 900/2000] tot_loss=1.444 (perp=6.923, rec=0.057, cos=0.003), tot_loss_proj:1.588 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.449 (perp=6.923, rec=0.062, cos=0.003), tot_loss_proj:1.582 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1000/2000] tot_loss=1.455 (perp=6.923, rec=0.068, cos=0.003), tot_loss_proj:1.598 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1050/2000] tot_loss=1.450 (perp=6.923, rec=0.063, cos=0.003), tot_loss_proj:1.595 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1100/2000] tot_loss=1.447 (perp=6.923, rec=0.060, cos=0.003), tot_loss_proj:1.590 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1150/2000] tot_loss=1.436 (perp=6.923, rec=0.049, cos=0.003), tot_loss_proj:1.596 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1200/2000] tot_loss=1.459 (perp=6.923, rec=0.072, cos=0.003), tot_loss_proj:1.589 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1250/2000] tot_loss=1.457 (perp=6.923, rec=0.070, cos=0.003), tot_loss_proj:1.597 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1300/2000] tot_loss=1.449 (perp=6.923, rec=0.062, cos=0.003), tot_loss_proj:1.587 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1350/2000] tot_loss=1.449 (perp=6.923, rec=0.062, cos=0.003), tot_loss_proj:1.590 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1400/2000] tot_loss=1.459 (perp=6.923, rec=0.072, cos=0.003), tot_loss_proj:1.591 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1450/2000] tot_loss=1.443 (perp=6.923, rec=0.055, cos=0.003), tot_loss_proj:1.587 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1500/2000] tot_loss=1.454 (perp=6.923, rec=0.067, cos=0.003), tot_loss_proj:1.592 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1550/2000] tot_loss=1.451 (perp=6.923, rec=0.064, cos=0.003), tot_loss_proj:1.584 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1600/2000] tot_loss=1.449 (perp=6.923, rec=0.061, cos=0.003), tot_loss_proj:1.588 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1650/2000] tot_loss=1.447 (perp=6.923, rec=0.060, cos=0.003), tot_loss_proj:1.583 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1700/2000] tot_loss=1.437 (perp=6.923, rec=0.050, cos=0.003), tot_loss_proj:1.589 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1750/2000] tot_loss=1.449 (perp=6.923, rec=0.062, cos=0.003), tot_loss_proj:1.584 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1800/2000] tot_loss=1.448 (perp=6.923, rec=0.061, cos=0.003), tot_loss_proj:1.581 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1850/2000] tot_loss=1.447 (perp=6.923, rec=0.060, cos=0.003), tot_loss_proj:1.590 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1900/2000] tot_loss=1.457 (perp=6.923, rec=0.070, cos=0.003), tot_loss_proj:1.598 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1950/2000] tot_loss=1.459 (perp=6.923, rec=0.072, cos=0.003), tot_loss_proj:1.590 [t=0.30s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[2000/2000] tot_loss=1.453 (perp=6.923, rec=0.066, cos=0.003), tot_loss_proj:1.588 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] in its often funny way, understanding [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 87.232 | p: 86.424 | r: 88.229
rouge2     | fm: 55.189 | p: 54.796 | r: 55.607
rougeL     | fm: 76.790 | p: 76.182 | r: 77.615
rougeLsum  | fm: 76.993 | p: 76.282 | r: 77.761
r1fm+r2fm = 142.421

input #93 time: 0:12:06 | total time: 18:57:11


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9986622651888464
highest_index [0]
highest [0.9986622651888464]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9412968754768372 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9385424852371216 for ['[CLS] of pro wanted scientists rayon housing chart close earlier anniversary ni [SEP]']
[Init] best rec loss: 0.9211042523384094 for ['[CLS] scent crosses am history single connections set likeuatingface other [SEP]']
[Init] best rec loss: 0.8858420848846436 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.8831648826599121 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best perm rec loss: 0.8787271976470947 for ['[CLS] spiritcede matters baderpour slowed miriter bowble [SEP]']
[Init] best perm rec loss: 0.877602756023407 for ['[CLS] bowerpour matters mircede bad spiritble slowediter [SEP]']
[Init] best perm rec loss: 0.877175509929657 for ['[CLS]cede matters slowed bowpourble spirit baderiter mir [SEP]']
[Init] best perm rec loss: 0.8769248723983765 for ['[CLS] spirit matterser bowpour mirblecede slowediter bad [SEP]']
[Init] best perm rec loss: 0.8755441308021545 for ['[CLS]pourble matterser spirit mircede slowed bad bowiter [SEP]']
[Init] best perm rec loss: 0.8739631175994873 for ['[CLS] bower spiritpouriter matters slowed mir badblecede [SEP]']
[Init] best perm rec loss: 0.8738038539886475 for ['[CLS] spiritpourer bowcedeiter bad mir matters slowedble [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.823 (perp=12.305, rec=0.336, cos=0.026), tot_loss_proj:3.534 [t=0.30s]
prediction: ['[CLS]usion capeer against neither hatfield natives nor good hurried neither [SEP]']
[ 100/2000] tot_loss=2.532 (perp=11.646, rec=0.194, cos=0.009), tot_loss_proj:3.459 [t=0.30s]
prediction: ['[CLS]ி caper never neither blacks neither nor funny rhythm neither [SEP]']
[ 150/2000] tot_loss=2.406 (perp=11.242, rec=0.153, cos=0.005), tot_loss_proj:3.061 [t=0.30s]
prediction: ['[CLS] cape caper neverr pas s nor original rhythm neither [SEP]']
[ 200/2000] tot_loss=2.315 (perp=10.975, rec=0.117, cos=0.003), tot_loss_proj:2.905 [t=0.31s]
prediction: ['[CLS] a caper we that terribly s nor original funny neither [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.067 (perp=9.836, rec=0.097, cos=0.003), tot_loss_proj:2.494 [t=0.31s]
prediction: ['[CLS] a caper we that neither s nor original funny terribly [SEP]']
[ 300/2000] tot_loss=2.049 (perp=9.836, rec=0.079, cos=0.003), tot_loss_proj:2.482 [t=0.31s]
prediction: ['[CLS] a caper we that neither s nor original funny terribly [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.828 (perp=8.749, rec=0.076, cos=0.003), tot_loss_proj:3.634 [t=0.30s]
prediction: ['[CLS] funny a caper we that neither s nor original terribly [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.490 (perp=7.144, rec=0.059, cos=0.002), tot_loss_proj:3.178 [t=0.30s]
prediction: ["[CLS] funny a caper'that neither s nor terribly original [SEP]"]
[ 450/2000] tot_loss=1.507 (perp=7.144, rec=0.076, cos=0.002), tot_loss_proj:3.180 [t=0.31s]
prediction: ["[CLS] funny a caper'that neither s nor terribly original [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.421 (perp=6.788, rec=0.062, cos=0.002), tot_loss_proj:3.142 [t=0.30s]
prediction: ["[CLS] a funny caper'that neither s nor terribly original [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.419 (perp=6.723, rec=0.072, cos=0.002), tot_loss_proj:3.142 [t=0.30s]
prediction: ["[CLS] a funny caper that'neither s nor terribly original [SEP]"]
[ 600/2000] tot_loss=1.411 (perp=6.723, rec=0.064, cos=0.002), tot_loss_proj:3.146 [t=0.30s]
prediction: ["[CLS] a funny caper that'neither s nor terribly original [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.324 (perp=6.323, rec=0.057, cos=0.002), tot_loss_proj:3.018 [t=0.30s]
prediction: ["[CLS] a funny caper that neither's nor terribly original [SEP]"]
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.301 (perp=6.156, rec=0.068, cos=0.002), tot_loss_proj:2.973 [t=0.30s]
prediction: ["[CLS] a funny caper that's neither nor terribly original [SEP]"]
[ 750/2000] tot_loss=1.304 (perp=6.156, rec=0.070, cos=0.002), tot_loss_proj:2.979 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither nor terribly original [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.156 (perp=5.453, rec=0.063, cos=0.002), tot_loss_proj:2.806 [t=0.30s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.159 (perp=5.453, rec=0.066, cos=0.002), tot_loss_proj:2.809 [t=0.30s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
[ 900/2000] tot_loss=1.156 (perp=5.453, rec=0.063, cos=0.002), tot_loss_proj:2.807 [t=0.30s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.165 (perp=5.453, rec=0.071, cos=0.002), tot_loss_proj:2.809 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.163 (perp=5.453, rec=0.070, cos=0.002), tot_loss_proj:2.810 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
[1050/2000] tot_loss=1.163 (perp=5.453, rec=0.069, cos=0.002), tot_loss_proj:2.807 [t=0.30s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.160 (perp=5.453, rec=0.067, cos=0.002), tot_loss_proj:2.814 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.160 (perp=5.453, rec=0.067, cos=0.002), tot_loss_proj:2.810 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
[1200/2000] tot_loss=1.168 (perp=5.453, rec=0.074, cos=0.002), tot_loss_proj:2.810 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.165 (perp=5.453, rec=0.072, cos=0.002), tot_loss_proj:2.814 [t=0.30s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.162 (perp=5.453, rec=0.069, cos=0.002), tot_loss_proj:2.813 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
[1350/2000] tot_loss=1.161 (perp=5.453, rec=0.068, cos=0.002), tot_loss_proj:2.815 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.163 (perp=5.453, rec=0.069, cos=0.002), tot_loss_proj:2.812 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.160 (perp=5.453, rec=0.067, cos=0.002), tot_loss_proj:2.811 [t=0.30s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
[1500/2000] tot_loss=1.153 (perp=5.453, rec=0.060, cos=0.002), tot_loss_proj:2.812 [t=0.30s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.163 (perp=5.453, rec=0.070, cos=0.002), tot_loss_proj:2.813 [t=0.30s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.166 (perp=5.453, rec=0.073, cos=0.002), tot_loss_proj:2.808 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
[1650/2000] tot_loss=1.160 (perp=5.453, rec=0.067, cos=0.002), tot_loss_proj:2.815 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.162 (perp=5.453, rec=0.069, cos=0.002), tot_loss_proj:2.813 [t=0.30s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.155 (perp=5.453, rec=0.062, cos=0.002), tot_loss_proj:2.814 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
[1800/2000] tot_loss=1.155 (perp=5.453, rec=0.062, cos=0.002), tot_loss_proj:2.814 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.168 (perp=5.453, rec=0.075, cos=0.002), tot_loss_proj:2.813 [t=0.30s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.156 (perp=5.453, rec=0.063, cos=0.002), tot_loss_proj:2.816 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
[1950/2000] tot_loss=1.152 (perp=5.453, rec=0.059, cos=0.002), tot_loss_proj:2.815 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.166 (perp=5.453, rec=0.073, cos=0.002), tot_loss_proj:2.813 [t=0.31s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] a funny caper that's neither terribly original nor [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 87.351 | p: 86.545 | r: 88.354
rouge2     | fm: 55.019 | p: 54.711 | r: 55.426
rougeL     | fm: 76.919 | p: 76.277 | r: 77.686
rougeLsum  | fm: 76.970 | p: 76.367 | r: 77.720
r1fm+r2fm = 142.370

input #94 time: 0:12:08 | total time: 19:09:20


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9985748840941844
highest_index [0]
highest [0.9985748840941844]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9619305729866028 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9542577266693115 for ['[CLS]nahley hair see nedra logan offices fourth sethgical recommended side laughdran auxiliary [SEP]']
[Init] best rec loss: 0.9335136413574219 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.9283832311630249 for ['[CLS] through... if mckennarollerrand ngo sally cara party beauty economic dock nah art [SEP]']
[Init] best rec loss: 0.9269236326217651 for ['[CLS] navy loyalty roomines oak kindergarten plus during africa alexia merely hands will del affinity [SEP]']
[Init] best rec loss: 0.9021338224411011 for ['[CLS] end output rather overall of byron inventor earth interests novel adult heir night bryan remaining [SEP]']
[Init] best rec loss: 0.9012122750282288 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.9010446071624756 for ['[CLS] block tech monty hangingے pressure trailer sister wire complete private damp ] cutnne [SEP]']
[Init] best perm rec loss: 0.9001474380493164 for ['[CLS] sister hangingnne block monty tech damp pressure trailer wire cut ] private completeے [SEP]']
[Init] best perm rec loss: 0.8988430500030518 for ['[CLS] damp ]ے wire trailer private monty block complete sister cut technne hanging pressure [SEP]']
[Init] best perm rec loss: 0.8983383774757385 for ['[CLS] ]nne private cut damp block wire tech pressure trailerے monty complete hanging sister [SEP]']
[Init] best perm rec loss: 0.898004412651062 for ['[CLS] damp trailerےnne complete tech hanging wire cut sister monty block private ] pressure [SEP]']
[Init] best perm rec loss: 0.8976805806159973 for ['[CLS] pressurenne ] block trailer completeے private tech cut wire damp monty hanging sister [SEP]']
[Init] best perm rec loss: 0.8920190334320068 for ['[CLS] damp wire cutے tech ] trailer block hangingnne private monty pressure sister complete [SEP]']
[Init] best perm rec loss: 0.8910219669342041 for ['[CLS] private sister ] tech monty complete block wire trailerے cut pressure damp hangingnne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.246 (perp=9.945, rec=0.247, cos=0.010), tot_loss_proj:2.491 [t=0.31s]
prediction: ['[CLS] becomevilletative hopeless became, acup hopeless became becomes a hopeless hopeless romance [SEP]']
[ 100/2000] tot_loss=2.257 (perp=10.493, rec=0.153, cos=0.005), tot_loss_proj:2.601 [t=0.31s]
prediction: ['[CLS] (satizing story became, un るdledle becomes a hopeless hopelessdle [SEP]']
[ 150/2000] tot_loss=2.102 (perp=9.480, rec=0.197, cos=0.009), tot_loss_proj:2.365 [t=0.31s]
prediction: ['[CLS] (satfying story became, un muddledle becomes a hopeless muddle [SEP]']
[ 200/2000] tot_loss=2.121 (perp=9.826, rec=0.151, cos=0.005), tot_loss_proj:2.466 [t=0.31s]
prediction: ['[CLS] (satis story -, un mudeddle becomes a hopelessfyingdle [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.816 (perp=8.371, rec=0.137, cos=0.005), tot_loss_proj:2.167 [t=0.31s]
prediction: ["[CLS] (satis story ', un muddle becomes a hopelessfying muddle [SEP]"]
[ 300/2000] tot_loss=1.789 (perp=8.383, rec=0.108, cos=0.004), tot_loss_proj:2.200 [t=0.31s]
prediction: ["[CLS] )satis story ', un muddle becomes a hopelessfying muddle [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.923 (perp=9.043, rec=0.110, cos=0.004), tot_loss_proj:2.204 [t=0.31s]
prediction: ["[CLS] unsatis story ', )satdle becomes a hopelessfying muddle [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.918 (perp=8.758, rec=0.162, cos=0.005), tot_loss_proj:2.252 [t=0.31s]
prediction: ['[CLS] unsatis mother °f, ) storydle becomes a hopelessfying muddle [SEP]']
[ 450/2000] tot_loss=1.913 (perp=8.994, rec=0.110, cos=0.004), tot_loss_proj:2.330 [t=0.31s]
prediction: ['[CLS] unsatis mother denis, ) storydle becomes a hopelessfying muddle [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.722 (perp=8.020, rec=0.114, cos=0.004), tot_loss_proj:2.359 [t=0.31s]
prediction: ['[CLS] unsatisfying denis, ) storydle becomes a hopeless mother muddle [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.642 (perp=7.684, rec=0.101, cos=0.004), tot_loss_proj:2.433 [t=0.31s]
prediction: ['[CLS] unsatisfying ) denis, storydle becomes a hopeless mother muddle [SEP]']
[ 600/2000] tot_loss=1.672 (perp=7.855, rec=0.098, cos=0.003), tot_loss_proj:2.079 [t=0.31s]
prediction: ['[CLS] unsatisfying ) denis, storydle becomes a hopelessfying muddle [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.444 (perp=6.660, rec=0.108, cos=0.004), tot_loss_proj:1.714 [t=0.31s]
prediction: ['[CLS] unsatisfying ) denis -, story - becomes a hopeless muddle [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.379 (perp=6.391, rec=0.097, cos=0.003), tot_loss_proj:1.710 [t=0.31s]
prediction: ['[CLS] unsatisfying ) denis - -, story becomes a hopeless muddle [SEP]']
[ 750/2000] tot_loss=1.377 (perp=6.391, rec=0.095, cos=0.003), tot_loss_proj:1.718 [t=0.31s]
prediction: ['[CLS] unsatisfying ) denis - -, story becomes a hopeless muddle [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.270 (perp=5.881, rec=0.090, cos=0.003), tot_loss_proj:1.777 [t=0.31s]
prediction: ['[CLS] unsatisfying ) - - denis, story becomes a hopeless muddle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.263 (perp=5.881, rec=0.084, cos=0.003), tot_loss_proj:1.778 [t=0.31s]
prediction: ['[CLS] unsatisfying ) - - denis, story becomes a hopeless muddle [SEP]']
[ 900/2000] tot_loss=1.271 (perp=5.881, rec=0.091, cos=0.003), tot_loss_proj:1.788 [t=0.31s]
prediction: ['[CLS] unsatisfying ) - - denis, story becomes a hopeless muddle [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.252 (perp=5.789, rec=0.091, cos=0.003), tot_loss_proj:1.847 [t=0.31s]
prediction: ['[CLS] unsatisfying ) - - story, denis becomes a hopeless muddle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.260 (perp=5.789, rec=0.099, cos=0.003), tot_loss_proj:1.851 [t=0.31s]
prediction: ['[CLS] unsatisfying ) - - story, denis becomes a hopeless muddle [SEP]']
[1050/2000] tot_loss=1.247 (perp=5.789, rec=0.086, cos=0.003), tot_loss_proj:1.846 [t=0.31s]
prediction: ['[CLS] unsatisfying ) - - story, denis becomes a hopeless muddle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.248 (perp=5.789, rec=0.087, cos=0.003), tot_loss_proj:1.853 [t=0.31s]
prediction: ['[CLS] unsatisfying ) - - story, denis becomes a hopeless muddle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.252 (perp=5.789, rec=0.091, cos=0.003), tot_loss_proj:1.858 [t=0.31s]
prediction: ['[CLS] unsatisfying ) - - story, denis becomes a hopeless muddle [SEP]']
[1200/2000] tot_loss=1.248 (perp=5.789, rec=0.087, cos=0.003), tot_loss_proj:1.850 [t=0.31s]
prediction: ['[CLS] unsatisfying ) - - story, denis becomes a hopeless muddle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.266 (perp=5.894, rec=0.084, cos=0.003), tot_loss_proj:2.068 [t=0.31s]
prediction: ['[CLS] unsatisfying ) - ( story, denis becomes a hopeless muddle [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.239 (perp=5.739, rec=0.087, cos=0.003), tot_loss_proj:1.769 [t=0.31s]
prediction: ['[CLS] unsatisfying ( ) - story, denis becomes a hopeless muddle [SEP]']
[1350/2000] tot_loss=1.238 (perp=5.739, rec=0.087, cos=0.003), tot_loss_proj:1.771 [t=0.31s]
prediction: ['[CLS] unsatisfying ( ) - story, denis becomes a hopeless muddle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.235 (perp=5.739, rec=0.084, cos=0.003), tot_loss_proj:1.771 [t=0.31s]
prediction: ['[CLS] unsatisfying ( ) - story, denis becomes a hopeless muddle [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.153 (perp=5.313, rec=0.087, cos=0.003), tot_loss_proj:1.407 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
[1500/2000] tot_loss=1.142 (perp=5.313, rec=0.076, cos=0.003), tot_loss_proj:1.408 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.146 (perp=5.313, rec=0.081, cos=0.003), tot_loss_proj:1.414 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.154 (perp=5.313, rec=0.088, cos=0.003), tot_loss_proj:1.404 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
[1650/2000] tot_loss=1.147 (perp=5.313, rec=0.081, cos=0.003), tot_loss_proj:1.406 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.154 (perp=5.313, rec=0.088, cos=0.003), tot_loss_proj:1.410 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.144 (perp=5.313, rec=0.078, cos=0.003), tot_loss_proj:1.412 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
[1800/2000] tot_loss=1.144 (perp=5.313, rec=0.078, cos=0.003), tot_loss_proj:1.406 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.154 (perp=5.313, rec=0.088, cos=0.003), tot_loss_proj:1.407 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.149 (perp=5.313, rec=0.084, cos=0.003), tot_loss_proj:1.410 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
[1950/2000] tot_loss=1.147 (perp=5.313, rec=0.081, cos=0.003), tot_loss_proj:1.407 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.155 (perp=5.313, rec=0.090, cos=0.003), tot_loss_proj:1.407 [t=0.31s]
prediction: ['[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] unsatisfying ( denis ) - story, becomes a hopeless muddle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 162.500

[Aggregate metrics]:
rouge1     | fm: 87.599 | p: 86.804 | r: 88.575
rouge2     | fm: 55.009 | p: 54.665 | r: 55.459
rougeL     | fm: 77.123 | p: 76.498 | r: 77.844
rougeLsum  | fm: 77.155 | p: 76.578 | r: 77.962
r1fm+r2fm = 142.609

input #95 time: 0:12:23 | total time: 19:21:43


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9990068910262093
highest_index [0]
highest [0.9990068910262093]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.7907276749610901 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.7820157408714294 for ['[CLS] mode wound britain generation pope inter retains harvard chill court wait haven perform queensland ins [SEP]']
[Init] best rec loss: 0.776585042476654 for ['[CLS] troubleович thou traditional adjacent pulse grit front minutes developingwind west fear later billy [SEP]']
[Init] best rec loss: 0.7746942043304443 for ['[CLS] class error portoizedtler riverside 7nsis deedret via protection corporation whether selection [SEP]']
[Init] best rec loss: 0.7664324045181274 for ['[CLS] interviews screwed podcast ？ 8 sunset effects era too oath sunk chief between capcom master [SEP]']
[Init] best rec loss: 0.7597325444221497 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.75972580909729 for ['[CLS] projectile time save spent sounding memoir typical wig pondered statue era smashwords augustgn living [SEP]']
[Init] best perm rec loss: 0.7587518095970154 for ['[CLS] save typical smashwords projectile time memoirgn living sounding spent wig pondered august statue era [SEP]']
[Init] best perm rec loss: 0.7585598826408386 for ['[CLS] save statuegn living spent august wig typical time memoir smashwords sounding pondered projectile era [SEP]']
[Init] best perm rec loss: 0.7577846646308899 for ['[CLS] august projectile pondered typical spent living statue time sounding memoir smashwords eragn wig save [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.618 (perp=11.560, rec=0.275, cos=0.031), tot_loss_proj:4.018 [t=0.31s]
prediction: ['[CLS] himself person force forces on lesser lesser run trying into hiding areas lesserque personnel [SEP]']
[ 100/2000] tot_loss=2.093 (perp=9.476, rec=0.178, cos=0.020), tot_loss_proj:3.537 [t=0.31s]
prediction: ['[CLS] himself people force people on lesser anyone run would make cover situations lesser into cover [SEP]']
[ 150/2000] tot_loss=2.117 (perp=9.908, rec=0.125, cos=0.011), tot_loss_proj:3.405 [t=0.31s]
prediction: ['[CLS] himself men force people on lesser anyone run would make cover situations men into cover [SEP]']
[ 200/2000] tot_loss=2.093 (perp=9.909, rec=0.104, cos=0.007), tot_loss_proj:3.350 [t=0.31s]
prediction: ['[CLS] himself people force on on lesser anyone run would make cover situations men into cover [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.012 (perp=9.475, rec=0.109, cos=0.008), tot_loss_proj:3.520 [t=0.31s]
prediction: ['[CLS] himself people run force on on lesser anyone would make cover situations men into cover [SEP]']
[ 300/2000] tot_loss=1.992 (perp=9.514, rec=0.085, cos=0.004), tot_loss_proj:3.341 [t=0.31s]
prediction: ['[CLS] himself people run force on into lesser for would make cover situations men and people [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.691 (perp=8.002, rec=0.087, cos=0.003), tot_loss_proj:3.183 [t=0.31s]
prediction: ['[CLS] himself people run force on into lesser would make cover situations for men and people [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.697 (perp=8.002, rec=0.094, cos=0.003), tot_loss_proj:3.180 [t=0.31s]
prediction: ['[CLS] himself people run force on into lesser would make cover situations for men and people [SEP]']
[ 450/2000] tot_loss=1.750 (perp=8.354, rec=0.076, cos=0.003), tot_loss_proj:3.294 [t=0.31s]
prediction: ['[CLS] himself people run force on into lesser would make cover situations for men and cover [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.738 (perp=8.354, rec=0.064, cos=0.003), tot_loss_proj:3.294 [t=0.31s]
prediction: ['[CLS] himself people run force on into lesser would make cover situations for men and cover [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.647 (perp=7.839, rec=0.076, cos=0.004), tot_loss_proj:3.194 [t=0.31s]
prediction: ['[CLS] himself people run force on into lesser situations would make cover for men and situations [SEP]']
[ 600/2000] tot_loss=1.646 (perp=7.839, rec=0.075, cos=0.003), tot_loss_proj:3.198 [t=0.31s]
prediction: ['[CLS] himself people run force on into lesser situations would make cover for men and situations [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.599 (perp=7.593, rec=0.078, cos=0.003), tot_loss_proj:3.150 [t=0.31s]
prediction: ['[CLS] people run force himself on into lesser situations would make cover for men and situations [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.490 (perp=7.020, rec=0.083, cos=0.003), tot_loss_proj:3.087 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and situations [SEP]']
[ 750/2000] tot_loss=1.488 (perp=7.020, rec=0.081, cos=0.003), tot_loss_proj:3.085 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and situations [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.474 (perp=7.020, rec=0.067, cos=0.003), tot_loss_proj:3.088 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and situations [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.477 (perp=7.020, rec=0.070, cos=0.003), tot_loss_proj:3.087 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and situations [SEP]']
[ 900/2000] tot_loss=1.481 (perp=7.020, rec=0.074, cos=0.003), tot_loss_proj:3.088 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and situations [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.479 (perp=7.059, rec=0.064, cos=0.003), tot_loss_proj:3.035 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1000/2000] tot_loss=1.491 (perp=7.059, rec=0.076, cos=0.003), tot_loss_proj:3.038 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
[1050/2000] tot_loss=1.489 (perp=7.059, rec=0.075, cos=0.003), tot_loss_proj:3.037 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1100/2000] tot_loss=1.473 (perp=7.059, rec=0.058, cos=0.003), tot_loss_proj:3.037 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1150/2000] tot_loss=1.476 (perp=7.059, rec=0.061, cos=0.003), tot_loss_proj:3.036 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
[1200/2000] tot_loss=1.490 (perp=7.059, rec=0.075, cos=0.003), tot_loss_proj:3.035 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1250/2000] tot_loss=1.478 (perp=7.059, rec=0.063, cos=0.003), tot_loss_proj:3.039 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1300/2000] tot_loss=1.482 (perp=7.059, rec=0.068, cos=0.003), tot_loss_proj:3.037 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
[1350/2000] tot_loss=1.483 (perp=7.059, rec=0.069, cos=0.003), tot_loss_proj:3.038 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1400/2000] tot_loss=1.478 (perp=7.059, rec=0.063, cos=0.003), tot_loss_proj:3.037 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1450/2000] tot_loss=1.483 (perp=7.059, rec=0.068, cos=0.003), tot_loss_proj:3.036 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
[1500/2000] tot_loss=1.490 (perp=7.059, rec=0.076, cos=0.003), tot_loss_proj:3.037 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1550/2000] tot_loss=1.483 (perp=7.059, rec=0.068, cos=0.003), tot_loss_proj:3.038 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1600/2000] tot_loss=1.487 (perp=7.059, rec=0.072, cos=0.003), tot_loss_proj:3.040 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
[1650/2000] tot_loss=1.481 (perp=7.059, rec=0.067, cos=0.003), tot_loss_proj:3.036 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1700/2000] tot_loss=1.481 (perp=7.059, rec=0.067, cos=0.003), tot_loss_proj:3.036 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1750/2000] tot_loss=1.478 (perp=7.059, rec=0.063, cos=0.003), tot_loss_proj:3.037 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
[1800/2000] tot_loss=1.489 (perp=7.059, rec=0.075, cos=0.003), tot_loss_proj:3.038 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1850/2000] tot_loss=1.486 (perp=7.059, rec=0.071, cos=0.003), tot_loss_proj:3.035 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[1900/2000] tot_loss=1.480 (perp=7.059, rec=0.065, cos=0.003), tot_loss_proj:3.040 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
[1950/2000] tot_loss=1.481 (perp=7.059, rec=0.066, cos=0.003), tot_loss_proj:3.036 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Attempt swap
[2000/2000] tot_loss=1.492 (perp=7.059, rec=0.077, cos=0.003), tot_loss_proj:3.041 [t=0.31s]
prediction: ['[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] people run himself on into lesser force situations would make cover for men and men [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 106.618

[Aggregate metrics]:
rouge1     | fm: 87.652 | p: 86.882 | r: 88.588
rouge2     | fm: 54.596 | p: 54.272 | r: 55.014
rougeL     | fm: 76.811 | p: 76.185 | r: 77.618
rougeLsum  | fm: 76.914 | p: 76.324 | r: 77.696
r1fm+r2fm = 142.247

input #96 time: 0:12:23 | total time: 19:34:07


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9988128741771469
highest_index [0]
highest [0.9988128741771469]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.7019720077514648 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.6998206973075867 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best perm rec loss: 0.6988703012466431 for ['[CLS] victoriaten test pass 2016 which [SEP]']
[Init] best perm rec loss: 0.6968253254890442 for ['[CLS]ten victoria pass 2016 test which [SEP]']
[Init] best perm rec loss: 0.6927359104156494 for ['[CLS] pass 2016 whichten test victoria [SEP]']
[Init] best perm rec loss: 0.6926405429840088 for ['[CLS]ten pass 2016 which victoria test [SEP]']
[Init] best perm rec loss: 0.6907324194908142 for ['[CLS] pass 2016 testten victoria which [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.350 (perp=10.042, rec=0.298, cos=0.044), tot_loss_proj:3.818 [t=0.30s]
prediction: ['[CLS] and untabletableforlion [SEP]']
[ 100/2000] tot_loss=2.007 (perp=9.150, rec=0.169, cos=0.007), tot_loss_proj:2.472 [t=0.30s]
prediction: ['[CLS] and ungettablefortable [SEP]']
[ 150/2000] tot_loss=1.943 (perp=9.150, rec=0.105, cos=0.007), tot_loss_proj:2.466 [t=0.30s]
prediction: ['[CLS] and ungettablefortable [SEP]']
[ 200/2000] tot_loss=1.859 (perp=8.885, rec=0.079, cos=0.003), tot_loss_proj:2.680 [t=0.30s]
prediction: ['[CLS] and ungettablefor characters [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.161 (perp=5.309, rec=0.095, cos=0.004), tot_loss_proj:1.123 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 300/2000] tot_loss=1.132 (perp=5.309, rec=0.067, cos=0.004), tot_loss_proj:1.132 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.129 (perp=5.309, rec=0.063, cos=0.004), tot_loss_proj:1.127 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.130 (perp=5.309, rec=0.065, cos=0.003), tot_loss_proj:1.120 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 450/2000] tot_loss=1.124 (perp=5.309, rec=0.059, cos=0.003), tot_loss_proj:1.132 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.131 (perp=5.309, rec=0.063, cos=0.006), tot_loss_proj:1.118 [t=0.31s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.135 (perp=5.309, rec=0.069, cos=0.004), tot_loss_proj:1.120 [t=0.31s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 600/2000] tot_loss=1.123 (perp=5.309, rec=0.058, cos=0.004), tot_loss_proj:1.125 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.127 (perp=5.309, rec=0.061, cos=0.004), tot_loss_proj:1.124 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.131 (perp=5.309, rec=0.062, cos=0.007), tot_loss_proj:1.124 [t=0.31s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 750/2000] tot_loss=1.129 (perp=5.309, rec=0.063, cos=0.004), tot_loss_proj:1.120 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.114 (perp=5.309, rec=0.048, cos=0.004), tot_loss_proj:1.124 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.137 (perp=5.309, rec=0.071, cos=0.004), tot_loss_proj:1.117 [t=0.31s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 900/2000] tot_loss=1.130 (perp=5.309, rec=0.065, cos=0.003), tot_loss_proj:1.122 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.132 (perp=5.309, rec=0.067, cos=0.003), tot_loss_proj:1.122 [t=0.31s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.126 (perp=5.309, rec=0.061, cos=0.003), tot_loss_proj:1.126 [t=0.31s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1050/2000] tot_loss=1.129 (perp=5.309, rec=0.064, cos=0.003), tot_loss_proj:1.128 [t=0.31s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.133 (perp=5.309, rec=0.067, cos=0.003), tot_loss_proj:1.129 [t=0.31s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.116 (perp=5.309, rec=0.051, cos=0.003), tot_loss_proj:1.128 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1200/2000] tot_loss=1.120 (perp=5.309, rec=0.054, cos=0.004), tot_loss_proj:1.129 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.122 (perp=5.309, rec=0.056, cos=0.004), tot_loss_proj:1.130 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.133 (perp=5.309, rec=0.068, cos=0.003), tot_loss_proj:1.133 [t=0.31s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1350/2000] tot_loss=1.131 (perp=5.309, rec=0.065, cos=0.004), tot_loss_proj:1.127 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.120 (perp=5.309, rec=0.054, cos=0.004), tot_loss_proj:1.128 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.123 (perp=5.309, rec=0.057, cos=0.003), tot_loss_proj:1.135 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1500/2000] tot_loss=1.138 (perp=5.309, rec=0.072, cos=0.004), tot_loss_proj:1.131 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.121 (perp=5.309, rec=0.056, cos=0.004), tot_loss_proj:1.117 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.120 (perp=5.309, rec=0.054, cos=0.004), tot_loss_proj:1.118 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1650/2000] tot_loss=1.133 (perp=5.309, rec=0.067, cos=0.004), tot_loss_proj:1.134 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.130 (perp=5.309, rec=0.064, cos=0.004), tot_loss_proj:1.125 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.130 (perp=5.309, rec=0.065, cos=0.004), tot_loss_proj:1.117 [t=0.31s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1800/2000] tot_loss=1.124 (perp=5.309, rec=0.058, cos=0.004), tot_loss_proj:1.112 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.135 (perp=5.309, rec=0.070, cos=0.004), tot_loss_proj:1.125 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.127 (perp=5.309, rec=0.062, cos=0.004), tot_loss_proj:1.126 [t=0.31s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1950/2000] tot_loss=1.128 (perp=5.309, rec=0.063, cos=0.004), tot_loss_proj:1.132 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.119 (perp=5.309, rec=0.054, cos=0.004), tot_loss_proj:1.125 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.724 | p: 86.971 | r: 88.643
rouge2     | fm: 54.894 | p: 54.546 | r: 55.325
rougeL     | fm: 77.115 | p: 76.509 | r: 77.883
rougeLsum  | fm: 77.151 | p: 76.569 | r: 77.867
r1fm+r2fm = 142.618

input #97 time: 0:12:06 | total time: 19:46:14


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9984833122884564
highest_index [0]
highest [0.9984833122884564]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.6752930879592896 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.6719683408737183 for ['[CLS] prohibited nos jed ada [SEP]']
[Init] best perm rec loss: 0.6690149307250977 for ['[CLS] nos ada prohibited jed [SEP]']
[Init] best perm rec loss: 0.6658229827880859 for ['[CLS] nos prohibited jed ada [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.385 (perp=10.921, rec=0.183, cos=0.018), tot_loss_proj:2.638 [t=0.30s]
prediction: ['[CLS] unfulllingful [SEP]']
[ 100/2000] tot_loss=2.310 (perp=10.921, rec=0.115, cos=0.011), tot_loss_proj:2.638 [t=0.30s]
prediction: ['[CLS] unfulllingful [SEP]']
[ 150/2000] tot_loss=2.664 (perp=12.919, rec=0.077, cos=0.004), tot_loss_proj:3.104 [t=0.31s]
prediction: ['[CLS] unfulllingfi [SEP]']
[ 200/2000] tot_loss=2.651 (perp=12.919, rec=0.064, cos=0.003), tot_loss_proj:3.099 [t=0.31s]
prediction: ['[CLS] unfulllingfi [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.058 (perp=4.947, rec=0.065, cos=0.004), tot_loss_proj:1.052 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.061 (perp=4.947, rec=0.068, cos=0.003), tot_loss_proj:1.048 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.044 (perp=4.947, rec=0.052, cos=0.003), tot_loss_proj:1.053 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.054 (perp=4.947, rec=0.061, cos=0.003), tot_loss_proj:1.055 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.052 (perp=4.947, rec=0.060, cos=0.003), tot_loss_proj:1.050 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.066 (perp=4.947, rec=0.074, cos=0.003), tot_loss_proj:1.058 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.051 (perp=4.947, rec=0.058, cos=0.003), tot_loss_proj:1.050 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.062 (perp=4.947, rec=0.069, cos=0.003), tot_loss_proj:1.058 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.048 (perp=4.947, rec=0.055, cos=0.003), tot_loss_proj:1.048 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.052 (perp=4.947, rec=0.059, cos=0.003), tot_loss_proj:1.063 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.054 (perp=4.947, rec=0.061, cos=0.003), tot_loss_proj:1.063 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.054 (perp=4.947, rec=0.061, cos=0.003), tot_loss_proj:1.054 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.056 (perp=4.947, rec=0.064, cos=0.003), tot_loss_proj:1.040 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.054 (perp=4.947, rec=0.061, cos=0.003), tot_loss_proj:1.064 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.054 (perp=4.947, rec=0.062, cos=0.003), tot_loss_proj:1.057 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.057 (perp=4.947, rec=0.064, cos=0.003), tot_loss_proj:1.055 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.057 (perp=4.947, rec=0.064, cos=0.003), tot_loss_proj:1.058 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.067 (perp=4.947, rec=0.075, cos=0.003), tot_loss_proj:1.053 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.053 (perp=4.947, rec=0.060, cos=0.003), tot_loss_proj:1.059 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.049 (perp=4.947, rec=0.056, cos=0.003), tot_loss_proj:1.050 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.040 (perp=4.947, rec=0.047, cos=0.003), tot_loss_proj:1.049 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.053 (perp=4.947, rec=0.061, cos=0.003), tot_loss_proj:1.059 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.051 (perp=4.947, rec=0.059, cos=0.003), tot_loss_proj:1.061 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.051 (perp=4.947, rec=0.058, cos=0.003), tot_loss_proj:1.048 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.052 (perp=4.947, rec=0.059, cos=0.003), tot_loss_proj:1.047 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.058 (perp=4.947, rec=0.066, cos=0.003), tot_loss_proj:1.062 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.054 (perp=4.947, rec=0.062, cos=0.003), tot_loss_proj:1.057 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.042 (perp=4.947, rec=0.050, cos=0.003), tot_loss_proj:1.057 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.043 (perp=4.947, rec=0.051, cos=0.003), tot_loss_proj:1.063 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.043 (perp=4.947, rec=0.051, cos=0.003), tot_loss_proj:1.060 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.046 (perp=4.947, rec=0.053, cos=0.003), tot_loss_proj:1.056 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.055 (perp=4.947, rec=0.062, cos=0.003), tot_loss_proj:1.054 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.044 (perp=4.947, rec=0.052, cos=0.003), tot_loss_proj:1.055 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.062 (perp=4.947, rec=0.070, cos=0.003), tot_loss_proj:1.055 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.048 (perp=4.947, rec=0.055, cos=0.003), tot_loss_proj:1.058 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.050 (perp=4.947, rec=0.057, cos=0.003), tot_loss_proj:1.051 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.782 | p: 87.018 | r: 88.722
rouge2     | fm: 55.523 | p: 55.217 | r: 55.975
rougeL     | fm: 77.347 | p: 76.721 | r: 78.101
rougeLsum  | fm: 77.273 | p: 76.742 | r: 78.025
r1fm+r2fm = 143.305

input #98 time: 0:12:06 | total time: 19:58:20


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.9986206083456133
highest_index [0]
highest [0.9986206083456133]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8179452419281006 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8060448169708252 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8001120686531067 for ['[CLS] freedom lay third cartwright u to tear supply disputed glasses operahus album [MASK] literature bart now associatedtmenty thou stated microphone poly frederick rogers lineshtake furport modern point rosewood mid early [SEP]']
[Init] best rec loss: 0.7718626260757446 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.7614070773124695 for ['[CLS] imp then ratlogueathy mobile bun smoothe bran where heart thumbs principal aires & recently brig addison stands catalog alert abbottale leading switch as could which buy pony kid risk general spreadim [SEP]']
[Init] best rec loss: 0.7613416314125061 for ['[CLS] wat searched fits mckay german divide interpret sensory ajax from even during under skye pants ramlus except door wanted others same q same king ashton care lot confirmation buttonsmania caseston file evil absolute [SEP]']
[Init] best rec loss: 0.7456560134887695 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.7447815537452698 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.7429776787757874 for ['[CLS] rightte when claire currently services [MASK] thunder distance synonym taste ferns barbie actually still te harper himselfˈ opposed earliest bet forced dentalagingts knowledge ratings bearing slight screens cushion orient garcia temps re [SEP]']
[Init] best perm rec loss: 0.7419796586036682 for ['[CLS] re opposed actually [MASK] thunder dental taste distance harper forced ratings garciate right barbie claireaging screens cushion when knowledge himself services orient ferns earliest te tempsts currently slight bearing synonym betˈ still [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.917 (perp=12.704, rec=0.341, cos=0.035), tot_loss_proj:3.356 [t=0.31s]
prediction: ["[CLS] fun types panicked television punched marco tickets theyted professional cassette false fun differenceudged cannedrate : word pen'police [SEP] nixon rotten worst process film for became roosevelt enjoying louisiana itsing panicked [SEP]"]
[ 100/2000] tot_loss=2.408 (perp=10.500, rec=0.287, cos=0.021), tot_loss_proj:3.331 [t=0.31s]
prediction: ["[CLS] fun types screaming their yelled any ticket folks bitch minute'worst fun wrongssing letterssing'''but dissing fun di cost process film fun because fun enjoying postage'ssing fun [SEP]"]
[ 150/2000] tot_loss=2.312 (perp=10.255, rec=0.229, cos=0.032), tot_loss_proj:3.316 [t=0.31s]
prediction: ['[CLS] fun fun ` they horrible any ticket and freaked - off have fun underssing filmssing\'\' " but thessing fun di cost therefore film fun that much fun poorly\'ssing started [SEP]']
[ 200/2000] tot_loss=2.094 (perp=9.527, rec=0.177, cos=0.012), tot_loss_proj:3.189 [t=0.31s]
prediction: ["[CLS] did fun ` they `'tickets ` freaked super'had fun'ssing incentives horrible'''but thessing had di cost so film fun that especially mind so'mind did [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.089 (perp=9.690, rec=0.144, cos=0.007), tot_loss_proj:2.765 [t=0.31s]
prediction: ["[CLS] walked fun ` they `'muttering ` walked super'had fun'cost ` horrible'''but thessing much dissing so film fun that much mind t or mind did [SEP]"]
[ 300/2000] tot_loss=2.066 (perp=9.665, rec=0.126, cos=0.006), tot_loss_proj:2.760 [t=0.31s]
prediction: ["[CLS] walked'` they `'muttering ` walked'' had fun'cost ` horrible'''but thessing much di terrible so film fun that much mind t or mind did [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.072 (perp=9.669, rec=0.126, cos=0.012), tot_loss_proj:3.068 [t=0.31s]
prediction: ["[CLS] they walked'muttering `'words ` walked'' had fun'cost ` horrible'''but thessing much di terrible so film fun that added mind t to mind did [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.981 (perp=9.278, rec=0.119, cos=0.007), tot_loss_proj:2.505 [t=0.31s]
prediction: ["[CLS] they walked'muttering `'words ` walked'' had fun'cost proposal terrible'''but dissing much the terrible so film fun that terrible did t t mind did [SEP]"]
[ 450/2000] tot_loss=1.998 (perp=9.377, rec=0.114, cos=0.009), tot_loss_proj:2.515 [t=0.31s]
prediction: ["[CLS] they walked'muttering ` ` words ` walked'' had fun'cost proposal terrible'''but dissing much the terrible so film fun that terrible did t t mind did [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.942 (perp=9.123, rec=0.110, cos=0.007), tot_loss_proj:2.443 [t=0.31s]
prediction: ["[CLS] they out'muttering ` ` ` walked'' had fun'cost words proposal terrible'''but dissing much the terrible so film fun that terrible did t t mind did [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.781 (perp=8.383, rec=0.096, cos=0.008), tot_loss_proj:2.248 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` ` `'' had fun'cost words them terrible'''but dissing much the terrible so film fun that terrible did t t mind did [SEP]"]
[ 600/2000] tot_loss=1.779 (perp=8.383, rec=0.096, cos=0.007), tot_loss_proj:2.242 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` ` `'' had fun'cost words them terrible'''but dissing much the terrible so film fun that terrible did t t mind did [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.736 (perp=8.163, rec=0.096, cos=0.007), tot_loss_proj:2.206 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` ` `'' had fun'cost words them terrible'''but dissing much the film so terrible fun that join did t t mind did [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.665 (perp=7.787, rec=0.100, cos=0.008), tot_loss_proj:2.136 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` ` `'' had fun'cost words them terrible did'' but dissing much the film so terrible fun that join't t mind did [SEP]"]
[ 750/2000] tot_loss=1.640 (perp=7.715, rec=0.091, cos=0.006), tot_loss_proj:2.109 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` ` `'' had fun'cost words that horrible did'' but dissing much the film so terrible fun that added't t mind did [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.552 (perp=7.256, rec=0.094, cos=0.007), tot_loss_proj:2.048 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` ` and'' had fun'much words that horrible did'' but dissing cost the film so terrible fun thatn't t mind did [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.524 (perp=7.092, rec=0.098, cos=0.007), tot_loss_proj:2.004 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` ` and'a had fun'much words that horrible did'but dissing cost the film so terrible fun thatn't t mind did'[SEP]"]
[ 900/2000] tot_loss=1.512 (perp=7.092, rec=0.086, cos=0.007), tot_loss_proj:2.009 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` ` and'a had fun'much words that horrible did'but dissing cost the film so terrible fun thatn't t mind did'[SEP]"]
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.477 (perp=6.861, rec=0.099, cos=0.006), tot_loss_proj:1.981 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` ` and'had a fun'much words that horrible did'but dissing cost the film so terrible fun thatn't t mind did'[SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.447 (perp=6.716, rec=0.094, cos=0.009), tot_loss_proj:1.896 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` ` and'had a fun'much words that horrible did'but dissing the film cost so terrible fun thatn't t mind did'[SEP]"]
[1050/2000] tot_loss=1.438 (perp=6.716, rec=0.089, cos=0.006), tot_loss_proj:1.893 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` ` and'had a fun'much words that horrible did'but dissing the film cost so terrible fun thatn't t mind did'[SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.410 (perp=6.618, rec=0.080, cos=0.006), tot_loss_proj:2.012 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun'much words that horrible did'but dissing the film cost so terrible fun thatn't t mind did'[SEP]"]
Attempt swap
[1150/2000] tot_loss=1.422 (perp=6.618, rec=0.092, cos=0.006), tot_loss_proj:2.017 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun'much words that horrible did'but dissing the film cost so terrible fun thatn't t mind did'[SEP]"]
[1200/2000] tot_loss=1.420 (perp=6.618, rec=0.089, cos=0.007), tot_loss_proj:2.014 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun'much words that horrible did'but dissing the film cost so terrible fun thatn't t mind did'[SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.412 (perp=6.583, rec=0.088, cos=0.007), tot_loss_proj:1.824 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible did'but dissing the film cost so terrible fun thatn't t mind did'[SEP]"]
Attempt swap
[1300/2000] tot_loss=1.409 (perp=6.583, rec=0.086, cos=0.007), tot_loss_proj:1.823 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible did'but dissing the film cost so terrible fun thatn't t mind did'[SEP]"]
[1350/2000] tot_loss=1.495 (perp=7.024, rec=0.084, cos=0.007), tot_loss_proj:1.916 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible did'but dissing the film cost so terrible fun that n n t t mind did'[SEP]"]
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.486 (perp=6.983, rec=0.082, cos=0.007), tot_loss_proj:1.956 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun that n n t t mind did'[SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.435 (perp=6.685, rec=0.091, cos=0.007), tot_loss_proj:1.910 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun thatn't t mind did n [SEP]"]
[1500/2000] tot_loss=1.425 (perp=6.685, rec=0.080, cos=0.007), tot_loss_proj:1.911 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun thatn't t mind did n [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.430 (perp=6.665, rec=0.089, cos=0.008), tot_loss_proj:1.888 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun thatn't n t mind did [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.416 (perp=6.665, rec=0.075, cos=0.007), tot_loss_proj:1.883 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun thatn't n t mind did [SEP]"]
[1650/2000] tot_loss=1.426 (perp=6.665, rec=0.086, cos=0.007), tot_loss_proj:1.889 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun thatn't n t mind did [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.425 (perp=6.665, rec=0.084, cos=0.007), tot_loss_proj:1.886 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun thatn't n t mind did [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.520 (perp=7.158, rec=0.081, cos=0.007), tot_loss_proj:1.987 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun that n ` t n t mind did [SEP]"]
[1800/2000] tot_loss=1.523 (perp=7.158, rec=0.084, cos=0.007), tot_loss_proj:1.984 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun that n ` t n t mind did [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.430 (perp=6.665, rec=0.089, cos=0.008), tot_loss_proj:1.879 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun thatn't n t mind did [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.429 (perp=6.665, rec=0.088, cos=0.007), tot_loss_proj:1.881 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun thatn't n t mind did [SEP]"]
[1950/2000] tot_loss=1.423 (perp=6.665, rec=0.083, cos=0.007), tot_loss_proj:1.887 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun thatn't n t mind did [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.425 (perp=6.665, rec=0.084, cos=0.007), tot_loss_proj:1.883 [t=0.31s]
prediction: ["[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun thatn't n t mind did [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] they walked out'muttering ` `'and had a fun that much words'horrible'did but dissing the film cost so terrible fun thatn't n t mind did [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.862 | r: 84.615
rouge2     | fm: 18.868 | p: 17.857 | r: 20.000
rougeL     | fm: 47.273 | p: 44.828 | r: 50.000
rougeLsum  | fm: 47.273 | p: 44.828 | r: 50.000
r1fm+r2fm = 98.868

[Aggregate metrics]:
rouge1     | fm: 87.727 | p: 86.900 | r: 88.751
rouge2     | fm: 55.275 | p: 54.901 | r: 55.662
rougeL     | fm: 76.938 | p: 76.319 | r: 77.650
rougeLsum  | fm: 77.019 | p: 76.456 | r: 77.786
r1fm+r2fm = 143.001

input #99 time: 0:12:19 | total time: 20:10:40


Average Cosine Similarity: 0.9987141794621793
Done with all.
