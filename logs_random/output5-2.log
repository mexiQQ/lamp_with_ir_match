


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.05 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 45.12it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9986273517471878
highest_index [0]
highest [0.9986273517471878]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 0.964125394821167 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.8715828657150269 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.8575195670127869 for ['[CLS]ify board [SEP]']
[Init] best rec loss: 0.845018744468689 for ['[CLS] tolerance receiving [SEP]']
[Init] best rec loss: 0.8343009948730469 for ['[CLS] panel officer [SEP]']
[Init] best perm rec loss: 0.829422116279602 for ['[CLS] officer panel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.350 (perp=10.843, rec=0.171, cos=0.011), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] disappointed disappointed [SEP]']
[ 100/2000] tot_loss=2.306 (perp=11.087, rec=0.085, cos=0.003), tot_loss_proj:2.657 [t=0.22s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 150/2000] tot_loss=2.282 (perp=11.087, rec=0.062, cos=0.003), tot_loss_proj:2.656 [t=0.22s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 200/2000] tot_loss=2.291 (perp=11.087, rec=0.071, cos=0.003), tot_loss_proj:2.652 [t=0.22s]
prediction: ['[CLS] disappointed slightly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.120 (perp=10.251, rec=0.067, cos=0.003), tot_loss_proj:2.119 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.113 (perp=10.251, rec=0.060, cos=0.003), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.115 (perp=10.251, rec=0.062, cos=0.003), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.110 (perp=10.251, rec=0.057, cos=0.003), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.113 (perp=10.251, rec=0.060, cos=0.003), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.115 (perp=10.251, rec=0.062, cos=0.003), tot_loss_proj:2.108 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.105 (perp=10.251, rec=0.052, cos=0.003), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.110 (perp=10.251, rec=0.057, cos=0.003), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.111 (perp=10.251, rec=0.058, cos=0.003), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.119 (perp=10.251, rec=0.066, cos=0.003), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.124 (perp=10.251, rec=0.071, cos=0.003), tot_loss_proj:2.125 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.119 (perp=10.251, rec=0.066, cos=0.003), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.115 (perp=10.251, rec=0.062, cos=0.003), tot_loss_proj:2.139 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.127 (perp=10.251, rec=0.074, cos=0.003), tot_loss_proj:2.130 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.113 (perp=10.251, rec=0.060, cos=0.003), tot_loss_proj:2.120 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.119 (perp=10.251, rec=0.066, cos=0.003), tot_loss_proj:2.130 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.112 (perp=10.251, rec=0.059, cos=0.003), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.110 (perp=10.251, rec=0.057, cos=0.003), tot_loss_proj:2.111 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.120 (perp=10.251, rec=0.067, cos=0.003), tot_loss_proj:2.120 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.113 (perp=10.251, rec=0.060, cos=0.003), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.106 (perp=10.251, rec=0.053, cos=0.003), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.099 (perp=10.251, rec=0.047, cos=0.003), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.108 (perp=10.251, rec=0.055, cos=0.003), tot_loss_proj:2.119 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.103 (perp=10.251, rec=0.050, cos=0.003), tot_loss_proj:2.123 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.118 (perp=10.251, rec=0.065, cos=0.003), tot_loss_proj:2.125 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.111 (perp=10.251, rec=0.058, cos=0.003), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.122 (perp=10.251, rec=0.069, cos=0.003), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.111 (perp=10.251, rec=0.058, cos=0.003), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.111 (perp=10.251, rec=0.058, cos=0.003), tot_loss_proj:2.125 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.121 (perp=10.251, rec=0.068, cos=0.003), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.106 (perp=10.251, rec=0.053, cos=0.003), tot_loss_proj:2.116 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.120 (perp=10.251, rec=0.067, cos=0.003), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.109 (perp=10.251, rec=0.056, cos=0.003), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.105 (perp=10.251, rec=0.052, cos=0.003), tot_loss_proj:2.121 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.109 (perp=10.251, rec=0.057, cos=0.003), tot_loss_proj:2.123 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.111 (perp=10.251, rec=0.058, cos=0.003), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:09:01 | total time: 0:09:01


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9989001564762949
highest_index [0]
highest [0.9989001564762949]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 0.9889597296714783 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9681109189987183 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.9014642238616943 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8706889152526855 for ['[CLS] martialmoral [SEP]']
[Init] best rec loss: 0.8680779933929443 for ['[CLS] course characters [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.256 (perp=10.543, rec=0.145, cos=0.003), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] splendid splendid [SEP]']
[ 100/2000] tot_loss=2.150 (perp=10.288, rec=0.090, cos=0.002), tot_loss_proj:2.300 [t=0.23s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.124 (perp=10.288, rec=0.064, cos=0.002), tot_loss_proj:2.286 [t=0.22s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.122 (perp=10.288, rec=0.063, cos=0.002), tot_loss_proj:2.290 [t=0.22s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.891 (perp=9.171, rec=0.054, cos=0.002), tot_loss_proj:1.895 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.879 (perp=9.171, rec=0.043, cos=0.002), tot_loss_proj:1.903 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.901 (perp=9.171, rec=0.065, cos=0.002), tot_loss_proj:1.882 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.888 (perp=9.171, rec=0.052, cos=0.002), tot_loss_proj:1.901 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.907 (perp=9.171, rec=0.071, cos=0.002), tot_loss_proj:1.910 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.902 (perp=9.171, rec=0.066, cos=0.002), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.897 (perp=9.171, rec=0.060, cos=0.002), tot_loss_proj:1.893 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.904 (perp=9.171, rec=0.067, cos=0.002), tot_loss_proj:1.904 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.905 (perp=9.171, rec=0.068, cos=0.002), tot_loss_proj:1.892 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.002), tot_loss_proj:1.907 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.906 (perp=9.171, rec=0.070, cos=0.002), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.887 (perp=9.171, rec=0.050, cos=0.002), tot_loss_proj:1.906 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.002), tot_loss_proj:1.906 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.906 (perp=9.171, rec=0.070, cos=0.002), tot_loss_proj:1.900 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.903 (perp=9.171, rec=0.067, cos=0.002), tot_loss_proj:1.899 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.002), tot_loss_proj:1.882 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.002), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.906 (perp=9.171, rec=0.069, cos=0.002), tot_loss_proj:1.898 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.900 (perp=9.171, rec=0.063, cos=0.002), tot_loss_proj:1.889 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.893 (perp=9.171, rec=0.056, cos=0.002), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.897 (perp=9.171, rec=0.061, cos=0.002), tot_loss_proj:1.897 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.900 (perp=9.171, rec=0.063, cos=0.002), tot_loss_proj:1.891 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.902 (perp=9.171, rec=0.065, cos=0.002), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.906 (perp=9.171, rec=0.070, cos=0.002), tot_loss_proj:1.902 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.879 (perp=9.171, rec=0.043, cos=0.002), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.896 (perp=9.171, rec=0.060, cos=0.002), tot_loss_proj:1.904 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.891 (perp=9.171, rec=0.054, cos=0.002), tot_loss_proj:1.895 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.907 (perp=9.171, rec=0.070, cos=0.002), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.896 (perp=9.171, rec=0.060, cos=0.002), tot_loss_proj:1.895 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.894 (perp=9.171, rec=0.057, cos=0.002), tot_loss_proj:1.908 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.897 (perp=9.171, rec=0.061, cos=0.002), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.901 (perp=9.171, rec=0.065, cos=0.002), tot_loss_proj:1.898 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.880 (perp=9.171, rec=0.044, cos=0.002), tot_loss_proj:1.898 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.898 (perp=9.171, rec=0.061, cos=0.002), tot_loss_proj:1.907 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.899 (perp=9.171, rec=0.063, cos=0.002), tot_loss_proj:1.910 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.903 (perp=9.171, rec=0.067, cos=0.002), tot_loss_proj:1.901 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:08:56 | total time: 0:17:57


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9986840037027962
highest_index [0]
highest [0.9986840037027962]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.7663192749023438 for ['[CLS] wash〜 at [SEP]']
[Init] best perm rec loss: 0.7651610970497131 for ['[CLS] wash at〜 [SEP]']
[Init] best perm rec loss: 0.761218786239624 for ['[CLS]〜 wash at [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.058 (perp=11.928, rec=0.463, cos=0.209), tot_loss_proj:3.222 [t=0.22s]
prediction: ['[CLS] gainingply momentum [SEP]']
[ 100/2000] tot_loss=2.331 (perp=9.502, rec=0.331, cos=0.099), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] gaining momentum momentum [SEP]']
[ 150/2000] tot_loss=3.090 (perp=13.302, rec=0.304, cos=0.126), tot_loss_proj:3.360 [t=0.23s]
prediction: ['[CLS] gainingvery momentum [SEP]']
[ 200/2000] tot_loss=3.091 (perp=13.302, rec=0.265, cos=0.166), tot_loss_proj:3.358 [t=0.22s]
prediction: ['[CLS] gainingvery momentum [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.613 (perp=10.899, rec=0.306, cos=0.128), tot_loss_proj:3.198 [t=0.22s]
prediction: ['[CLS]very gaining momentum [SEP]']
[ 300/2000] tot_loss=2.556 (perp=10.899, rec=0.262, cos=0.114), tot_loss_proj:3.169 [t=0.23s]
prediction: ['[CLS]very gaining momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.536 (perp=10.899, rec=0.247, cos=0.110), tot_loss_proj:3.174 [t=0.23s]
prediction: ['[CLS]very gaining momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.542 (perp=10.899, rec=0.228, cos=0.134), tot_loss_proj:3.160 [t=0.23s]
prediction: ['[CLS]very gaining momentum [SEP]']
[ 450/2000] tot_loss=2.568 (perp=10.899, rec=0.235, cos=0.154), tot_loss_proj:3.163 [t=0.23s]
prediction: ['[CLS]very gaining momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.540 (perp=10.899, rec=0.219, cos=0.141), tot_loss_proj:3.163 [t=0.23s]
prediction: ['[CLS]very gaining momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.261 (perp=9.653, rec=0.213, cos=0.117), tot_loss_proj:3.560 [t=0.23s]
prediction: ['[CLS] lack gaining momentum [SEP]']
[ 600/2000] tot_loss=2.267 (perp=9.653, rec=0.210, cos=0.127), tot_loss_proj:3.560 [t=0.23s]
prediction: ['[CLS] lack gaining momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.267 (perp=9.653, rec=0.214, cos=0.123), tot_loss_proj:3.558 [t=0.23s]
prediction: ['[CLS] lack gaining momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.260 (perp=9.653, rec=0.213, cos=0.117), tot_loss_proj:3.561 [t=0.23s]
prediction: ['[CLS] lack gaining momentum [SEP]']
[ 750/2000] tot_loss=2.251 (perp=9.653, rec=0.204, cos=0.116), tot_loss_proj:3.561 [t=0.23s]
prediction: ['[CLS] lack gaining momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.254 (perp=9.653, rec=0.208, cos=0.116), tot_loss_proj:3.561 [t=0.23s]
prediction: ['[CLS] lack gaining momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.695 (perp=11.871, rec=0.203, cos=0.118), tot_loss_proj:3.138 [t=0.23s]
prediction: ['[CLS]bert gaining momentum [SEP]']
[ 900/2000] tot_loss=2.704 (perp=11.871, rec=0.212, cos=0.117), tot_loss_proj:3.143 [t=0.23s]
prediction: ['[CLS]bert gaining momentum [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.455 (perp=10.613, rec=0.208, cos=0.125), tot_loss_proj:2.983 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1000/2000] tot_loss=2.454 (perp=10.613, rec=0.211, cos=0.121), tot_loss_proj:2.991 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
[1050/2000] tot_loss=2.450 (perp=10.613, rec=0.206, cos=0.121), tot_loss_proj:2.998 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1100/2000] tot_loss=2.446 (perp=10.613, rec=0.203, cos=0.121), tot_loss_proj:3.000 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1150/2000] tot_loss=2.444 (perp=10.613, rec=0.200, cos=0.121), tot_loss_proj:2.994 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
[1200/2000] tot_loss=2.443 (perp=10.613, rec=0.201, cos=0.119), tot_loss_proj:2.997 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1250/2000] tot_loss=2.450 (perp=10.613, rec=0.209, cos=0.119), tot_loss_proj:3.001 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1300/2000] tot_loss=2.450 (perp=10.613, rec=0.207, cos=0.121), tot_loss_proj:3.001 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
[1350/2000] tot_loss=2.437 (perp=10.613, rec=0.194, cos=0.120), tot_loss_proj:3.000 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1400/2000] tot_loss=2.444 (perp=10.613, rec=0.201, cos=0.121), tot_loss_proj:3.005 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1450/2000] tot_loss=2.452 (perp=10.613, rec=0.208, cos=0.121), tot_loss_proj:3.005 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
[1500/2000] tot_loss=2.447 (perp=10.613, rec=0.204, cos=0.120), tot_loss_proj:3.001 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1550/2000] tot_loss=2.451 (perp=10.613, rec=0.209, cos=0.120), tot_loss_proj:2.998 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1600/2000] tot_loss=2.436 (perp=10.613, rec=0.194, cos=0.120), tot_loss_proj:3.001 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
[1650/2000] tot_loss=2.448 (perp=10.613, rec=0.206, cos=0.119), tot_loss_proj:3.006 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1700/2000] tot_loss=2.447 (perp=10.613, rec=0.204, cos=0.120), tot_loss_proj:2.996 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1750/2000] tot_loss=2.445 (perp=10.613, rec=0.202, cos=0.121), tot_loss_proj:3.002 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
[1800/2000] tot_loss=2.451 (perp=10.613, rec=0.207, cos=0.121), tot_loss_proj:2.999 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1850/2000] tot_loss=2.447 (perp=10.613, rec=0.205, cos=0.120), tot_loss_proj:3.000 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[1900/2000] tot_loss=2.445 (perp=10.613, rec=0.202, cos=0.121), tot_loss_proj:3.003 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
[1950/2000] tot_loss=2.446 (perp=10.613, rec=0.203, cos=0.120), tot_loss_proj:2.996 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Attempt swap
[2000/2000] tot_loss=2.454 (perp=10.613, rec=0.211, cos=0.120), tot_loss_proj:2.999 [t=0.23s]
prediction: ['[CLS] gaining momentumbert [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining momentumbert [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 75.000 | r: 60.000
rouge2     | fm: 28.571 | p: 33.333 | r: 25.000
rougeL     | fm: 66.667 | p: 75.000 | r: 60.000
rougeLsum  | fm: 66.667 | p: 75.000 | r: 60.000
r1fm+r2fm = 95.238

[Aggregate metrics]:
rouge1     | fm: 88.889 | p: 91.667 | r: 86.667
rouge2     | fm: 76.190 | p: 77.778 | r: 75.000
rougeL     | fm: 88.889 | p: 91.667 | r: 86.667
rougeLsum  | fm: 88.889 | p: 91.667 | r: 86.667
r1fm+r2fm = 165.079

input #2 time: 0:08:57 | total time: 0:26:54


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.9987729324760206
highest_index [0]
highest [0.9987729324760206]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.9844736456871033 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9387556910514832 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.9381915330886841 for ['[CLS] gauge louisiana [SEP]']
[Init] best rec loss: 0.9228593707084656 for ['[CLS] caused please [SEP]']
[Init] best rec loss: 0.8798360228538513 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8444858193397522 for ['[CLS] end depart [SEP]']
[Init] best rec loss: 0.8364353179931641 for ['[CLS] early force [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.459 (perp=10.128, rec=0.399, cos=0.034), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] strong record [SEP]']
[ 100/2000] tot_loss=2.329 (perp=10.476, rec=0.225, cos=0.008), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] flawless flawless [SEP]']
[ 150/2000] tot_loss=2.285 (perp=10.476, rec=0.183, cos=0.007), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] flawless flawless [SEP]']
[ 200/2000] tot_loss=1.775 (perp=8.384, rec=0.095, cos=0.003), tot_loss_proj:1.782 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.744 (perp=8.384, rec=0.065, cos=0.002), tot_loss_proj:1.785 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.740 (perp=8.384, rec=0.061, cos=0.002), tot_loss_proj:1.787 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.726 (perp=8.384, rec=0.046, cos=0.002), tot_loss_proj:1.788 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.743 (perp=8.384, rec=0.063, cos=0.002), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.736 (perp=8.384, rec=0.057, cos=0.002), tot_loss_proj:1.781 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.747 (perp=8.384, rec=0.068, cos=0.002), tot_loss_proj:1.789 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.750 (perp=8.384, rec=0.070, cos=0.002), tot_loss_proj:1.783 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.733 (perp=8.384, rec=0.053, cos=0.002), tot_loss_proj:1.774 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.749 (perp=8.384, rec=0.070, cos=0.002), tot_loss_proj:1.784 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.739 (perp=8.384, rec=0.059, cos=0.002), tot_loss_proj:1.779 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.751 (perp=8.384, rec=0.071, cos=0.002), tot_loss_proj:1.779 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.745 (perp=8.384, rec=0.066, cos=0.002), tot_loss_proj:1.787 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.742 (perp=8.384, rec=0.063, cos=0.002), tot_loss_proj:1.771 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.754 (perp=8.384, rec=0.075, cos=0.002), tot_loss_proj:1.774 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.742 (perp=8.384, rec=0.062, cos=0.002), tot_loss_proj:1.780 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.734 (perp=8.384, rec=0.055, cos=0.002), tot_loss_proj:1.775 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.738 (perp=8.384, rec=0.059, cos=0.002), tot_loss_proj:1.782 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.752 (perp=8.384, rec=0.073, cos=0.002), tot_loss_proj:1.782 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.743 (perp=8.384, rec=0.064, cos=0.002), tot_loss_proj:1.763 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.732 (perp=8.384, rec=0.052, cos=0.002), tot_loss_proj:1.786 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.730 (perp=8.384, rec=0.051, cos=0.002), tot_loss_proj:1.769 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.726 (perp=8.384, rec=0.047, cos=0.002), tot_loss_proj:1.783 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.738 (perp=8.384, rec=0.058, cos=0.002), tot_loss_proj:1.785 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.743 (perp=8.384, rec=0.063, cos=0.002), tot_loss_proj:1.786 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.728 (perp=8.384, rec=0.048, cos=0.002), tot_loss_proj:1.771 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.735 (perp=8.384, rec=0.056, cos=0.002), tot_loss_proj:1.779 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.731 (perp=8.384, rec=0.052, cos=0.002), tot_loss_proj:1.777 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.732 (perp=8.384, rec=0.053, cos=0.002), tot_loss_proj:1.783 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.731 (perp=8.384, rec=0.052, cos=0.002), tot_loss_proj:1.785 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.743 (perp=8.384, rec=0.064, cos=0.002), tot_loss_proj:1.780 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.741 (perp=8.384, rec=0.061, cos=0.002), tot_loss_proj:1.772 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.751 (perp=8.384, rec=0.072, cos=0.002), tot_loss_proj:1.781 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.743 (perp=8.384, rec=0.064, cos=0.002), tot_loss_proj:1.780 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.725 (perp=8.384, rec=0.045, cos=0.002), tot_loss_proj:1.779 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.729 (perp=8.384, rec=0.050, cos=0.002), tot_loss_proj:1.781 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.726 (perp=8.384, rec=0.046, cos=0.002), tot_loss_proj:1.772 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.667 | p: 93.750 | r: 90.000
rouge2     | fm: 82.143 | p: 83.333 | r: 81.250
rougeL     | fm: 91.667 | p: 93.750 | r: 90.000
rougeLsum  | fm: 91.667 | p: 93.750 | r: 90.000
r1fm+r2fm = 173.810

input #3 time: 0:08:57 | total time: 0:35:51


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.9986225640121326
highest_index [0]
highest [0.9986225640121326]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 0.9747394919395447 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9590449929237366 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9539812803268433 for ['[CLS] together tracks print [SEP]']
[Init] best rec loss: 0.9476436972618103 for ['[CLS] activities sw eight [SEP]']
[Init] best rec loss: 0.9430261254310608 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.9136753678321838 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.8917473554611206 for ['[CLS] fatedss jack [SEP]']
[Init] best perm rec loss: 0.891136884689331 for ['[CLS]ss fated jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.661 (perp=12.590, rec=0.136, cos=0.007), tot_loss_proj:3.158 [t=0.23s]
prediction: ['[CLS] tires tiresome [SEP]']
[ 100/2000] tot_loss=1.585 (perp=7.516, rec=0.078, cos=0.004), tot_loss_proj:1.666 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.573 (perp=7.516, rec=0.066, cos=0.003), tot_loss_proj:1.676 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.570 (perp=7.516, rec=0.064, cos=0.003), tot_loss_proj:1.654 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.554 (perp=7.516, rec=0.048, cos=0.003), tot_loss_proj:1.653 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.567 (perp=7.516, rec=0.061, cos=0.003), tot_loss_proj:1.664 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.571 (perp=7.516, rec=0.064, cos=0.003), tot_loss_proj:1.667 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.558 (perp=7.516, rec=0.052, cos=0.003), tot_loss_proj:1.662 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.555 (perp=7.516, rec=0.049, cos=0.003), tot_loss_proj:1.666 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.577 (perp=7.516, rec=0.071, cos=0.003), tot_loss_proj:1.659 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.559 (perp=7.516, rec=0.053, cos=0.003), tot_loss_proj:1.657 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.572 (perp=7.516, rec=0.066, cos=0.003), tot_loss_proj:1.665 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.573 (perp=7.516, rec=0.067, cos=0.003), tot_loss_proj:1.651 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.564 (perp=7.516, rec=0.058, cos=0.003), tot_loss_proj:1.650 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.555 (perp=7.516, rec=0.049, cos=0.003), tot_loss_proj:1.653 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.567 (perp=7.516, rec=0.061, cos=0.003), tot_loss_proj:1.665 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.560 (perp=7.516, rec=0.054, cos=0.003), tot_loss_proj:1.659 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.560 (perp=7.516, rec=0.054, cos=0.003), tot_loss_proj:1.614 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.567 (perp=7.516, rec=0.062, cos=0.003), tot_loss_proj:1.628 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.568 (perp=7.516, rec=0.062, cos=0.003), tot_loss_proj:1.617 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.567 (perp=7.516, rec=0.061, cos=0.003), tot_loss_proj:1.620 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.555 (perp=7.516, rec=0.049, cos=0.003), tot_loss_proj:1.612 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.558 (perp=7.516, rec=0.052, cos=0.003), tot_loss_proj:1.624 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.568 (perp=7.516, rec=0.062, cos=0.003), tot_loss_proj:1.631 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.560 (perp=7.516, rec=0.054, cos=0.003), tot_loss_proj:1.625 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.568 (perp=7.516, rec=0.062, cos=0.003), tot_loss_proj:1.634 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.566 (perp=7.516, rec=0.060, cos=0.003), tot_loss_proj:1.619 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.579 (perp=7.516, rec=0.073, cos=0.003), tot_loss_proj:1.621 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.560 (perp=7.516, rec=0.054, cos=0.003), tot_loss_proj:1.609 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.574 (perp=7.516, rec=0.068, cos=0.003), tot_loss_proj:1.626 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.558 (perp=7.516, rec=0.052, cos=0.003), tot_loss_proj:1.609 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.578 (perp=7.516, rec=0.072, cos=0.003), tot_loss_proj:1.607 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.569 (perp=7.516, rec=0.063, cos=0.003), tot_loss_proj:1.614 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.568 (perp=7.516, rec=0.062, cos=0.003), tot_loss_proj:1.609 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.565 (perp=7.516, rec=0.059, cos=0.003), tot_loss_proj:1.611 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.564 (perp=7.516, rec=0.058, cos=0.003), tot_loss_proj:1.606 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.570 (perp=7.516, rec=0.064, cos=0.003), tot_loss_proj:1.615 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.575 (perp=7.516, rec=0.069, cos=0.003), tot_loss_proj:1.611 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.566 (perp=7.516, rec=0.060, cos=0.003), tot_loss_proj:1.622 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.577 (perp=7.516, rec=0.071, cos=0.003), tot_loss_proj:1.604 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.333 | p: 95.000 | r: 92.000
rouge2     | fm: 85.714 | p: 86.667 | r: 85.000
rougeL     | fm: 93.333 | p: 95.000 | r: 92.000
rougeLsum  | fm: 93.333 | p: 95.000 | r: 92.000
r1fm+r2fm = 179.048

input #4 time: 0:09:14 | total time: 0:45:06


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9988020014373329
highest_index [0]
highest [0.9988020014373329]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.959015429019928 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.94868403673172 for ['[CLS] preservation notre [SEP]']
[Init] best rec loss: 0.9338293075561523 for ['[CLS] eye central [SEP]']
[Init] best rec loss: 0.9201485514640808 for ['[CLS] quiet. [SEP]']
[Init] best perm rec loss: 0.9189957976341248 for ['[CLS]. quiet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.213 (perp=9.916, rec=0.743, cos=0.487), tot_loss_proj:3.741 [t=0.22s]
prediction: ['[CLS]hyllum nickname [SEP]']
[ 100/2000] tot_loss=3.733 (perp=13.324, rec=0.624, cos=0.445), tot_loss_proj:4.290 [t=0.22s]
prediction: ['[CLS] ease layne [SEP]']
[ 150/2000] tot_loss=3.232 (perp=10.973, rec=0.584, cos=0.453), tot_loss_proj:3.268 [t=0.22s]
prediction: ['[CLS] ease 龸 [SEP]']
[ 200/2000] tot_loss=3.220 (perp=10.973, rec=0.567, cos=0.458), tot_loss_proj:3.265 [t=0.22s]
prediction: ['[CLS] ease 龸 [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.540 (perp=11.822, rec=0.703, cos=0.472), tot_loss_proj:3.920 [t=0.22s]
prediction: ['[CLS] waste forget [SEP]']
[ 300/2000] tot_loss=3.480 (perp=12.160, rec=0.613, cos=0.435), tot_loss_proj:3.983 [t=0.22s]
prediction: ['[CLS] mistakes least [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=3.150 (perp=10.812, rec=0.571, cos=0.417), tot_loss_proj:4.113 [t=0.22s]
prediction: ['[CLS] difficulty ease [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.250 (perp=11.370, rec=0.559, cos=0.417), tot_loss_proj:3.686 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 450/2000] tot_loss=3.218 (perp=11.370, rec=0.547, cos=0.397), tot_loss_proj:3.686 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.195 (perp=11.370, rec=0.531, cos=0.390), tot_loss_proj:3.685 [t=0.23s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.206 (perp=11.370, rec=0.541, cos=0.390), tot_loss_proj:3.689 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 600/2000] tot_loss=3.217 (perp=11.370, rec=0.550, cos=0.393), tot_loss_proj:3.694 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.188 (perp=11.370, rec=0.536, cos=0.378), tot_loss_proj:3.689 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.183 (perp=11.370, rec=0.522, cos=0.387), tot_loss_proj:3.696 [t=0.23s]
prediction: ['[CLS] ease ease [SEP]']
[ 750/2000] tot_loss=3.166 (perp=11.370, rec=0.522, cos=0.371), tot_loss_proj:3.687 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.390 (perp=12.531, rec=0.527, cos=0.357), tot_loss_proj:3.679 [t=0.23s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.382 (perp=12.531, rec=0.515, cos=0.360), tot_loss_proj:3.681 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
[ 900/2000] tot_loss=3.374 (perp=12.531, rec=0.515, cos=0.353), tot_loss_proj:3.680 [t=0.23s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.373 (perp=12.531, rec=0.511, cos=0.356), tot_loss_proj:3.679 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1000/2000] tot_loss=3.409 (perp=12.531, rec=0.534, cos=0.369), tot_loss_proj:3.682 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
[1050/2000] tot_loss=3.371 (perp=12.531, rec=0.518, cos=0.347), tot_loss_proj:3.677 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1100/2000] tot_loss=3.356 (perp=12.531, rec=0.511, cos=0.339), tot_loss_proj:3.683 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1150/2000] tot_loss=3.359 (perp=12.531, rec=0.514, cos=0.339), tot_loss_proj:3.679 [t=0.23s]
prediction: ['[CLS]⺩ ease [SEP]']
[1200/2000] tot_loss=3.357 (perp=12.531, rec=0.518, cos=0.332), tot_loss_proj:3.680 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1250/2000] tot_loss=3.345 (perp=12.531, rec=0.514, cos=0.324), tot_loss_proj:3.683 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1300/2000] tot_loss=3.340 (perp=12.531, rec=0.502, cos=0.332), tot_loss_proj:3.679 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
[1350/2000] tot_loss=3.349 (perp=12.531, rec=0.514, cos=0.329), tot_loss_proj:3.678 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1400/2000] tot_loss=3.332 (perp=12.531, rec=0.512, cos=0.314), tot_loss_proj:3.686 [t=0.23s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1450/2000] tot_loss=3.338 (perp=12.531, rec=0.511, cos=0.320), tot_loss_proj:3.680 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
[1500/2000] tot_loss=3.326 (perp=12.531, rec=0.502, cos=0.318), tot_loss_proj:3.672 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1550/2000] tot_loss=3.327 (perp=12.531, rec=0.506, cos=0.315), tot_loss_proj:3.687 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1600/2000] tot_loss=3.323 (perp=12.531, rec=0.503, cos=0.314), tot_loss_proj:3.678 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
[1650/2000] tot_loss=3.325 (perp=12.531, rec=0.512, cos=0.307), tot_loss_proj:3.682 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1700/2000] tot_loss=3.319 (perp=12.531, rec=0.508, cos=0.305), tot_loss_proj:3.677 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1750/2000] tot_loss=3.308 (perp=12.531, rec=0.492, cos=0.309), tot_loss_proj:3.671 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
[1800/2000] tot_loss=3.310 (perp=12.531, rec=0.496, cos=0.308), tot_loss_proj:3.679 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1850/2000] tot_loss=3.313 (perp=12.531, rec=0.503, cos=0.304), tot_loss_proj:3.678 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[1900/2000] tot_loss=3.322 (perp=12.531, rec=0.508, cos=0.308), tot_loss_proj:3.689 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
[1950/2000] tot_loss=3.314 (perp=12.531, rec=0.507, cos=0.301), tot_loss_proj:3.684 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Attempt swap
[2000/2000] tot_loss=3.308 (perp=12.531, rec=0.499, cos=0.303), tot_loss_proj:3.676 [t=0.22s]
prediction: ['[CLS]⺩ ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS]⺩ ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 100.000 | r: 75.000
rouge2     | fm: 40.000 | p: 50.000 | r: 33.333
rougeL     | fm: 85.714 | p: 100.000 | r: 75.000
rougeLsum  | fm: 85.714 | p: 100.000 | r: 75.000
r1fm+r2fm = 125.714

[Aggregate metrics]:
rouge1     | fm: 92.063 | p: 95.833 | r: 89.167
rouge2     | fm: 78.095 | p: 80.556 | r: 76.389
rougeL     | fm: 92.063 | p: 95.833 | r: 89.167
rougeLsum  | fm: 92.063 | p: 95.833 | r: 89.167
r1fm+r2fm = 170.159

input #5 time: 0:08:56 | total time: 0:54:02


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.9987753361456811
highest_index [0]
highest [0.9987753361456811]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9441893696784973 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.8494739532470703 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.8102795481681824 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.804685115814209 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.757422685623169 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7234959006309509 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.6976725459098816 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 0.6757896542549133 for ['[CLS] double deep [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.731 (perp=8.089, rec=0.108, cos=0.006), tot_loss_proj:1.708 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 100/2000] tot_loss=1.700 (perp=8.089, rec=0.080, cos=0.002), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.688 (perp=8.089, rec=0.067, cos=0.002), tot_loss_proj:1.703 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.671 (perp=8.089, rec=0.050, cos=0.002), tot_loss_proj:1.695 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.675 (perp=8.089, rec=0.055, cos=0.002), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.002), tot_loss_proj:1.700 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.687 (perp=8.089, rec=0.067, cos=0.002), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.683 (perp=8.089, rec=0.062, cos=0.002), tot_loss_proj:1.695 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.681 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.682 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.689 (perp=8.089, rec=0.069, cos=0.002), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.682 (perp=8.089, rec=0.062, cos=0.002), tot_loss_proj:1.697 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.695 (perp=8.089, rec=0.075, cos=0.002), tot_loss_proj:1.678 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.673 (perp=8.089, rec=0.053, cos=0.002), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.674 (perp=8.089, rec=0.054, cos=0.002), tot_loss_proj:1.681 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.697 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.673 (perp=8.089, rec=0.053, cos=0.002), tot_loss_proj:1.709 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.693 (perp=8.089, rec=0.073, cos=0.002), tot_loss_proj:1.687 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.002), tot_loss_proj:1.685 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.002), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.685 (perp=8.089, rec=0.065, cos=0.002), tot_loss_proj:1.687 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.674 (perp=8.089, rec=0.054, cos=0.002), tot_loss_proj:1.667 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.688 (perp=8.089, rec=0.067, cos=0.002), tot_loss_proj:1.702 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.675 (perp=8.089, rec=0.055, cos=0.002), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.687 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.672 (perp=8.089, rec=0.052, cos=0.002), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.682 (perp=8.089, rec=0.062, cos=0.002), tot_loss_proj:1.687 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.682 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.678 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.667 (perp=8.089, rec=0.047, cos=0.002), tot_loss_proj:1.703 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.682 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.688 (perp=8.089, rec=0.068, cos=0.002), tot_loss_proj:1.667 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.688 (perp=8.089, rec=0.068, cos=0.002), tot_loss_proj:1.676 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.684 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.703 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.675 (perp=8.089, rec=0.055, cos=0.002), tot_loss_proj:1.693 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.671 (perp=8.089, rec=0.051, cos=0.002), tot_loss_proj:1.678 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.663 (perp=8.089, rec=0.043, cos=0.002), tot_loss_proj:1.686 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.681 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.684 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.197 | p: 96.429 | r: 90.714
rouge2     | fm: 81.224 | p: 83.333 | r: 79.762
rougeL     | fm: 93.197 | p: 96.429 | r: 90.714
rougeLsum  | fm: 93.197 | p: 96.429 | r: 90.714
r1fm+r2fm = 174.422

input #6 time: 0:08:54 | total time: 1:02:57


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9983386507232211
highest_index [0]
highest [0.9983386507232211]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.907750129699707 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.832587480545044 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8202946782112122 for ['[CLS] flat forewingsys mick separation ) oh yorkening las sat an consecutive charity qaeda clinicroud ill column rustling marathon rom viper dinner chuck ( [SEP]']
[Init] best rec loss: 0.8148995637893677 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best rec loss: 0.8043140769004822 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best rec loss: 0.8015453815460205 for ['[CLS] cod dock # openר sat both grande flow hs most purpose baby beings comppia jenny infants part end pay exactly conference moths median [SEP]']
[Init] best perm rec loss: 0.8007888793945312 for ['[CLS] pay end # grande dockר baby infants part cod compia both purpose moths hs jennyp median sat exactly conference beings flow most open [SEP]']
[Init] best perm rec loss: 0.798695981502533 for ['[CLS] jenny open flow both babypia hs grande pay conference purpose most dock moths exactly satpר com part cod beings # infants end median [SEP]']
[Init] best perm rec loss: 0.7981770634651184 for ['[CLS] jenny baby dockp flow infants comר grande conference moths purpose most both #pia sat beings end part pay median hs open exactly cod [SEP]']
[Init] best perm rec loss: 0.7980135679244995 for ['[CLS] codpia jenny end com part purpose both moths beingsp exactly dock pay grande openר hs baby median conference flow sat infants most # [SEP]']
[Init] best perm rec loss: 0.7971181273460388 for ['[CLS] jenny purpose hs com satר part most grande infants dock cod # baby beings flow moths end conferencep median open paypia exactly both [SEP]']
[Init] best perm rec loss: 0.7966874241828918 for ['[CLS] com most beingsp flowpia median end conference purpose part hs cod bothר # dock exactly baby grande sat infants moths open pay jenny [SEP]']
[Init] best perm rec loss: 0.795516848564148 for ['[CLS] baby median # purpose most grandeר pay end open flow exactly both jenny hs beingspia com part moths sat conference codp infants dock [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.429 (perp=10.551, rec=0.293, cos=0.026), tot_loss_proj:3.078 [t=0.23s]
prediction: ['[CLS] quickly problem no character problem is suspect poor background drunk ya not ; thing problem problem the mvp to problem anotherv little characteric against [SEP]']
[ 100/2000] tot_loss=2.012 (perp=9.045, rec=0.195, cos=0.009), tot_loss_proj:3.587 [t=0.23s]
prediction: ['[CLS] no problem no character problem is genuine poor love. not not ralph thing problem problem the cute to problem no mack little characterable traits [SEP]']
[ 150/2000] tot_loss=1.906 (perp=8.728, rec=0.154, cos=0.006), tot_loss_proj:3.611 [t=0.23s]
prediction: ['[CLS] he not no character problem is developed ugly love. not not ; factor problem problem ; cute of ugly. physically cute characterable traits [SEP]']
[ 200/2000] tot_loss=1.812 (perp=8.360, rec=0.134, cos=0.006), tot_loss_proj:3.589 [t=0.23s]
prediction: ['[CLS] he no no character problem is he ugly love. not not i mind problem problem ; cute. ugly. cute cute characterable factor [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.674 (perp=7.686, rec=0.132, cos=0.005), tot_loss_proj:3.443 [t=0.23s]
prediction: ['[CLS] he no no character problem is he ugly love. not not ; mind problem problem ; cute or. ugly, cute cuteable. [SEP]']
[ 300/2000] tot_loss=1.699 (perp=7.923, rec=0.110, cos=0.004), tot_loss_proj:3.168 [t=0.23s]
prediction: ['[CLS] he no no character has is he ugly love. that not i mind mind problem ; here or. ugly, cute cuteable. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.607 (perp=7.275, rec=0.141, cos=0.011), tot_loss_proj:2.989 [t=0.23s]
prediction: ['[CLS] he no no character has is he shit love. that not i mind problem problem ; here. ugly, cute or cuteable. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.495 (perp=6.883, rec=0.112, cos=0.006), tot_loss_proj:2.581 [t=0.23s]
prediction: ['[CLS] he no hardware character has is he no love. that not i mind. problem ; factor. ugly, cute or cuteable. [SEP]']
[ 450/2000] tot_loss=1.399 (perp=6.417, rec=0.111, cos=0.005), tot_loss_proj:2.458 [t=0.23s]
prediction: ['[CLS] he no cute character has is he no love. that not i mind. problem ; factor. ugly, cute or cuteable. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.341 (perp=6.202, rec=0.097, cos=0.004), tot_loss_proj:2.382 [t=0.23s]
prediction: ['[CLS] he no cute character has is he no love. not that i mind. problem ; factor. ugly, cute or cuteable. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.274 (perp=5.807, rec=0.108, cos=0.005), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS] he no cute character has is otherwise no cute. not that i mind. problem ; factor. ugly, cute or loveable. [SEP]']
[ 600/2000] tot_loss=1.263 (perp=5.807, rec=0.098, cos=0.004), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS] he no cute character has is otherwise no cute. not that i mind. problem ; factor. ugly, cute or loveable. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.270 (perp=5.858, rec=0.094, cos=0.004), tot_loss_proj:2.540 [t=0.23s]
prediction: ['[CLS] he no cute character has is or no cute. not that i mind. problem ; factor. ugly, cute or loveable. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.467 (perp=6.738, rec=0.114, cos=0.005), tot_loss_proj:2.259 [t=0.23s]
prediction: ['[CLS] he no character has is cute otherwise no cute. not that i mind. problem ; factor. ugly, cute or loveable otherwise [SEP]']
[ 750/2000] tot_loss=1.441 (perp=6.738, rec=0.089, cos=0.004), tot_loss_proj:2.267 [t=0.23s]
prediction: ['[CLS] he no character has is cute otherwise no cute. not that i mind. problem ; factor. ugly, cute or loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.443 (perp=6.738, rec=0.091, cos=0.004), tot_loss_proj:2.232 [t=0.23s]
prediction: ['[CLS] he no character has is cute otherwise no cute. not that i mind. problem ; factor. ugly, cute or loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.420 (perp=6.670, rec=0.082, cos=0.004), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] he no cute has is cute otherwise no character. not that i mind. problem ; factor. ugly, cute or loveable otherwise [SEP]']
[ 900/2000] tot_loss=1.423 (perp=6.670, rec=0.085, cos=0.004), tot_loss_proj:2.359 [t=0.23s]
prediction: ['[CLS] he no cute has is cute otherwise no character. not that i mind. problem ; factor. ugly, cute or loveable otherwise [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.427 (perp=6.670, rec=0.089, cos=0.004), tot_loss_proj:2.362 [t=0.23s]
prediction: ['[CLS] he no cute has is cute otherwise no character. not that i mind. problem ; factor. ugly, cute or loveable otherwise [SEP]']
Attempt swap
[1000/2000] tot_loss=1.423 (perp=6.670, rec=0.085, cos=0.004), tot_loss_proj:2.359 [t=0.23s]
prediction: ['[CLS] he no cute has is cute otherwise no character. not that i mind. problem ; factor. ugly, cute or loveable otherwise [SEP]']
[1050/2000] tot_loss=1.426 (perp=6.670, rec=0.089, cos=0.004), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] he no cute has is cute otherwise no character. not that i mind. problem ; factor. ugly, cute or loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.415 (perp=6.623, rec=0.086, cos=0.004), tot_loss_proj:2.321 [t=0.23s]
prediction: ['[CLS] he no cute has is cute. no character. not that i mind. problem ; factor otherwise ugly, cute or loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.330 (perp=6.194, rec=0.087, cos=0.004), tot_loss_proj:1.927 [t=0.23s]
prediction: ['[CLS] he no cute has is cute. no character. not that i mind. problem ; factor, ugly or cute or loveable otherwise [SEP]']
[1200/2000] tot_loss=1.331 (perp=6.194, rec=0.088, cos=0.004), tot_loss_proj:1.922 [t=0.23s]
prediction: ['[CLS] he no cute has is cute. no character. not that i mind. problem ; factor, ugly or cute or loveable otherwise [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.449 (perp=6.801, rec=0.085, cos=0.004), tot_loss_proj:2.197 [t=0.23s]
prediction: ['[CLS] he no cute has is cute. no character. not that i mind. problem ; factor, ugly otherwise cute loveable or otherwise [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.445 (perp=6.774, rec=0.086, cos=0.004), tot_loss_proj:2.259 [t=0.23s]
prediction: ['[CLS] he no cute has is cute. no character. not that i mind. problem ; factor, otherwise ugly cute loveable or otherwise [SEP]']
[1350/2000] tot_loss=1.446 (perp=6.774, rec=0.088, cos=0.004), tot_loss_proj:2.258 [t=0.23s]
prediction: ['[CLS] he no cute has is cute. no character. not that i mind. problem ; factor, otherwise ugly cute loveable or otherwise [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.392 (perp=6.565, rec=0.075, cos=0.004), tot_loss_proj:2.384 [t=0.23s]
prediction: ['[CLS] he no cute has is cute, no character. not that i mind. problem ; factor. otherwise ugly cute loveable or otherwise [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.378 (perp=6.434, rec=0.087, cos=0.004), tot_loss_proj:2.568 [t=0.23s]
prediction: ['[CLS] he no cute has is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]']
[1500/2000] tot_loss=1.375 (perp=6.434, rec=0.085, cos=0.004), tot_loss_proj:2.569 [t=0.23s]
prediction: ['[CLS] he no cute has is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]']
Attempt swap
[1550/2000] tot_loss=1.372 (perp=6.434, rec=0.082, cos=0.004), tot_loss_proj:2.568 [t=0.23s]
prediction: ['[CLS] he no cute has is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]']
Attempt swap
[1600/2000] tot_loss=1.370 (perp=6.434, rec=0.080, cos=0.004), tot_loss_proj:2.572 [t=0.23s]
prediction: ['[CLS] he no cute has is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]']
[1650/2000] tot_loss=1.374 (perp=6.434, rec=0.084, cos=0.004), tot_loss_proj:2.570 [t=0.23s]
prediction: ['[CLS] he no cute has is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.369 (perp=6.434, rec=0.079, cos=0.004), tot_loss_proj:2.567 [t=0.23s]
prediction: ['[CLS] he no cute has is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.336 (perp=6.243, rec=0.083, cos=0.004), tot_loss_proj:2.292 [t=0.23s]
prediction: ['[CLS] he has no cute is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]']
[1800/2000] tot_loss=1.341 (perp=6.243, rec=0.089, cos=0.004), tot_loss_proj:2.286 [t=0.23s]
prediction: ['[CLS] he has no cute is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]']
Attempt swap
[1850/2000] tot_loss=1.338 (perp=6.243, rec=0.085, cos=0.004), tot_loss_proj:2.294 [t=0.23s]
prediction: ['[CLS] he has no cute is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]']
Attempt swap
[1900/2000] tot_loss=1.335 (perp=6.243, rec=0.083, cos=0.004), tot_loss_proj:2.284 [t=0.23s]
prediction: ['[CLS] he has no cute is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]']
[1950/2000] tot_loss=1.337 (perp=6.243, rec=0.085, cos=0.004), tot_loss_proj:2.292 [t=0.23s]
prediction: ['[CLS] he has no cute is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.312 (perp=6.138, rec=0.081, cos=0.004), tot_loss_proj:2.125 [t=0.23s]
prediction: ['[CLS] he has no cute is cute, no character. not that i mind. problem ; ugly factor. otherwise loveable or otherwise cute [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] he has no cute is cute, no character. not that i mind. problem ; ugly factor. otherwise cute loveable or otherwise [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.372 | p: 86.364 | r: 90.476
rouge2     | fm: 48.780 | p: 47.619 | r: 50.000
rougeL     | fm: 55.814 | p: 54.545 | r: 57.143
rougeLsum  | fm: 55.814 | p: 54.545 | r: 57.143
r1fm+r2fm = 137.153

[Aggregate metrics]:
rouge1     | fm: 92.594 | p: 95.170 | r: 90.685
rouge2     | fm: 77.169 | p: 78.869 | r: 76.042
rougeL     | fm: 88.524 | p: 91.193 | r: 86.518
rougeLsum  | fm: 88.524 | p: 91.193 | r: 86.518
r1fm+r2fm = 169.763

input #7 time: 0:09:04 | total time: 1:12:02


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9989557094991461
highest_index [0]
highest [0.9989557094991461]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.6617246866226196 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.6562386751174927 for ['[CLS] breed app king jude rome am regal roman grown levi mine fitting peninsula cappella age bulldogs component founder macarthur unionist overturegible raysstock [SEP]']
[Init] best rec loss: 0.6536446809768677 for ['[CLS] vin figure blowgger note mission [CLS] planet outside xi awardhe collections work money... unsuccessful canon ob brainally street wheat shortly [SEP]']
[Init] best rec loss: 0.6455197930335999 for ['[CLS] andhra basque richards surrounding rockwell gloss rodeo series balanced waived word line plan styx responsible wish procession than attentionrave retention past doe tv [SEP]']
[Init] best perm rec loss: 0.6448594331741333 for ['[CLS] surrounding attention series waived styx word rockwell tv doe richards procession responsible wish past line than plan balanced retention rodeo andhra basquerave gloss [SEP]']
[Init] best perm rec loss: 0.6417372226715088 for ['[CLS] plan surrounding procession tv styx wish rockwell rodeo balanced richards gloss andhra waived attention line past word retention basque doerave responsible series than [SEP]']
[Init] best perm rec loss: 0.641325056552887 for ['[CLS] styx rodeo basque tv procession retention word line rockwell wish plan past andhra than attention balanced gloss surrounding responsible doerave richards waived series [SEP]']
[Init] best perm rec loss: 0.6408293843269348 for ['[CLS] responsible gloss wish styx than doe richards waived basque procession balanced retention rodeo surrounding word plan attention andhra rockwell past line seriesrave tv [SEP]']
[Init] best perm rec loss: 0.6400526762008667 for ['[CLS] surroundingrave attention rockwell tv styx past richards andhra wish balanced plan word line procession rodeo responsible retention basque waived doe gloss than series [SEP]']
[Init] best perm rec loss: 0.6391479969024658 for ['[CLS] waived tv word balancedrave retention line rockwell responsible series doe rodeo surrounding wish than plan attention gloss procession basque past richards styx andhra [SEP]']
[Init] best perm rec loss: 0.6377691626548767 for ['[CLS] waived balanced styx wish line richards gloss attention tv responsible retention plan than basque rockwell past rodeo procession andhra word doe series surroundingrave [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.949 (perp=13.241, rec=0.257, cos=0.044), tot_loss_proj:3.964 [t=0.22s]
prediction: ['[CLS] more vanity vanity had fright vanity film documentary dying likely pays what what debt vanityp adele│ obscure legendary that a toll least [SEP]']
[ 100/2000] tot_loss=2.719 (perp=12.548, rec=0.189, cos=0.021), tot_loss_proj:3.649 [t=0.23s]
prediction: ['[CLS] its vanity vanity owed fright vanity film film no doubt pays what what debt vanityariesmax euclidean cassette debt that a nii [SEP]']
[ 150/2000] tot_loss=2.569 (perp=12.119, rec=0.139, cos=0.007), tot_loss_proj:3.820 [t=0.23s]
prediction: ['[CLS] is vanity vanity owed fright vanity film film no doubt pays what what debt vanity benignmaxₚ cassette debt that a nii [SEP]']
[ 200/2000] tot_loss=2.557 (perp=12.080, rec=0.131, cos=0.009), tot_loss_proj:3.647 [t=0.23s]
prediction: ['[CLS] s vanity vanity owed fright vanity film film no doubt pays what what debt vanity benignmax felt fright owed that afullyi [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.367 (perp=11.043, rec=0.140, cos=0.019), tot_loss_proj:3.400 [t=0.23s]
prediction: ['[CLS] s owed fright vanity film film no doubt pays what what debt vanity benign vanity vanitymax felt impressions owed that a ai [SEP]']
[ 300/2000] tot_loss=2.314 (perp=10.917, rec=0.125, cos=0.006), tot_loss_proj:3.413 [t=0.23s]
prediction: ['[CLS] s owed fright vanity film film no doubt pays what any debt vanity benign vanity vanitymax felt benign owed that a ai [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.221 (perp=10.466, rec=0.121, cos=0.007), tot_loss_proj:3.313 [t=0.23s]
prediction: ['[CLS] s owed fright vanity event film no doubt pays what any debt vanity benign vanity vanitymax felt benign owed that a filmi [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.165 (perp=10.226, rec=0.115, cos=0.005), tot_loss_proj:3.147 [t=0.23s]
prediction: ['[CLS] s owed fright vanity event film no doubt pays what any debtful benign vanity vanity mira felt benigni owed that a film [SEP]']
[ 450/2000] tot_loss=2.076 (perp=9.899, rec=0.094, cos=0.003), tot_loss_proj:3.004 [t=0.23s]
prediction: ['[CLS] s owed fright vanity a film no doubt pays what any debtful benign vanity vanitymax felt benigni owed that, film [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.002 (perp=9.434, rec=0.102, cos=0.013), tot_loss_proj:2.839 [t=0.23s]
prediction: ['[CLS] s owed fright vanity a film no doubt, pays what any debtful benign vanity vanitymax felt benigni owed that film [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.896 (perp=8.927, rec=0.105, cos=0.006), tot_loss_proj:2.934 [t=0.24s]
prediction: ['[CLS] s owed fright vanity a film no doubt, pays what any debtful vanity benign benignmax felt theyi owed that film [SEP]']
[ 600/2000] tot_loss=1.953 (perp=9.246, rec=0.101, cos=0.003), tot_loss_proj:3.087 [t=0.24s]
prediction: ['[CLS] s owed fright vanity a film no doubt, pays what off debtful vanity benign benignmax felt theyi owed that film [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.934 (perp=9.158, rec=0.099, cos=0.004), tot_loss_proj:3.044 [t=0.24s]
prediction: ['[CLS] s owed fright vanity a film no doubt, pays what off debtful vanity benign benignmaxi felt they owed that film [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.897 (perp=8.935, rec=0.102, cos=0.008), tot_loss_proj:2.801 [t=0.24s]
prediction: ['[CLS] s owed fright vanity a film no doubt, pays what offmax debtful vanity benign benigni felt they owed that film [SEP]']
[ 750/2000] tot_loss=1.885 (perp=8.935, rec=0.095, cos=0.003), tot_loss_proj:2.794 [t=0.24s]
prediction: ['[CLS] s owed fright vanity a film no doubt, pays what offmax debtful vanity benign benigni felt they owed that film [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.792 (perp=8.470, rec=0.094, cos=0.004), tot_loss_proj:2.704 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film no doubt, pays what offmax debt vanity benign benigni felt they owed that film [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.755 (perp=8.225, rec=0.103, cos=0.007), tot_loss_proj:2.578 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
[ 900/2000] tot_loss=1.744 (perp=8.225, rec=0.096, cos=0.003), tot_loss_proj:2.578 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.736 (perp=8.225, rec=0.089, cos=0.003), tot_loss_proj:2.574 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.737 (perp=8.260, rec=0.082, cos=0.003), tot_loss_proj:2.836 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what off benign debtmax benigni felt they owed that film [SEP]']
[1050/2000] tot_loss=1.746 (perp=8.260, rec=0.091, cos=0.002), tot_loss_proj:2.843 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what off benign debtmax benigni felt they owed that film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.735 (perp=8.260, rec=0.081, cos=0.002), tot_loss_proj:2.839 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what off benign debtmax benigni felt they owed that film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.747 (perp=8.260, rec=0.093, cos=0.002), tot_loss_proj:2.836 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what off benign debtmax benigni felt they owed that film [SEP]']
[1200/2000] tot_loss=1.734 (perp=8.260, rec=0.080, cos=0.002), tot_loss_proj:2.841 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what off benign debtmax benigni felt they owed that film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.732 (perp=8.260, rec=0.078, cos=0.002), tot_loss_proj:2.839 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what off benign debtmax benigni felt they owed that film [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.730 (perp=8.225, rec=0.083, cos=0.002), tot_loss_proj:2.585 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
[1350/2000] tot_loss=1.731 (perp=8.225, rec=0.084, cos=0.002), tot_loss_proj:2.585 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.737 (perp=8.225, rec=0.090, cos=0.002), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.730 (perp=8.225, rec=0.083, cos=0.002), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
[1500/2000] tot_loss=1.727 (perp=8.225, rec=0.080, cos=0.002), tot_loss_proj:2.586 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.727 (perp=8.225, rec=0.080, cos=0.002), tot_loss_proj:2.588 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.731 (perp=8.225, rec=0.084, cos=0.002), tot_loss_proj:2.591 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
[1650/2000] tot_loss=1.734 (perp=8.225, rec=0.087, cos=0.002), tot_loss_proj:2.592 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.731 (perp=8.225, rec=0.084, cos=0.002), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.724 (perp=8.225, rec=0.077, cos=0.002), tot_loss_proj:2.568 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
[1800/2000] tot_loss=1.733 (perp=8.225, rec=0.086, cos=0.002), tot_loss_proj:2.569 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.729 (perp=8.225, rec=0.082, cos=0.002), tot_loss_proj:2.571 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.727 (perp=8.225, rec=0.080, cos=0.002), tot_loss_proj:2.576 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
[1950/2000] tot_loss=1.728 (perp=8.225, rec=0.081, cos=0.002), tot_loss_proj:2.565 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.732 (perp=8.225, rec=0.085, cos=0.002), tot_loss_proj:2.593 [t=0.24s]
prediction: ['[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] s owed frightful vanity a film vanity no doubt, pays what offmax debt benign benigni felt they owed that film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.952 | p: 77.273 | r: 85.000
rouge2     | fm: 30.000 | p: 28.571 | r: 31.579
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 110.952

[Aggregate metrics]:
rouge1     | fm: 91.301 | p: 93.182 | r: 90.053
rouge2     | fm: 71.928 | p: 73.280 | r: 71.101
rougeL     | fm: 86.096 | p: 88.131 | r: 84.921
rougeLsum  | fm: 86.096 | p: 88.131 | r: 84.683
r1fm+r2fm = 163.229

input #8 time: 0:09:16 | total time: 1:21:19


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9988274491335966
highest_index [0]
highest [0.9988274491335966]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.776007890701294 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.6868312954902649 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.6601606011390686 for ['[CLS] ham ice command across see beatty anal tan [SEP]']
[Init] best rec loss: 0.6586527824401855 for ['[CLS] save california liquidstownabiing plain for [SEP]']
[Init] best perm rec loss: 0.6580478549003601 for ['[CLS]abi liquiding plain save for californiastown [SEP]']
[Init] best perm rec loss: 0.6566006541252136 for ['[CLS] foring california plainstownabi liquid save [SEP]']
[Init] best perm rec loss: 0.6557493209838867 for ['[CLS] californiastowning save plainabi liquid for [SEP]']
[Init] best perm rec loss: 0.6546200513839722 for ['[CLS] plain forstown liquid california saveabiing [SEP]']
[Init] best perm rec loss: 0.6545423865318298 for ['[CLS] saveabi california foring liquidstown plain [SEP]']
[Init] best perm rec loss: 0.6541658639907837 for ['[CLS] california plain for liquidingstown saveabi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.459 (perp=10.713, rec=0.284, cos=0.032), tot_loss_proj:3.475 [t=0.22s]
prediction: ['[CLS] southernhead as emotional witnesses clap clap [SEP]']
[ 100/2000] tot_loss=1.989 (perp=8.899, rec=0.200, cos=0.009), tot_loss_proj:2.993 [t=0.22s]
prediction: ['[CLS] softhead of softheadheads clap clap [SEP]']
[ 150/2000] tot_loss=2.616 (perp=12.443, rec=0.121, cos=0.007), tot_loss_proj:3.179 [t=0.22s]
prediction: ['[CLS] softhead of metaphysicalheadp claptra [SEP]']
[ 200/2000] tot_loss=2.582 (perp=12.443, rec=0.091, cos=0.003), tot_loss_proj:3.189 [t=0.22s]
prediction: ['[CLS] softhead of metaphysicalheadp claptra [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.888 (perp=8.967, rec=0.089, cos=0.005), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS] softhead of metaphysicaled claptrap [SEP]']
[ 300/2000] tot_loss=1.868 (perp=8.967, rec=0.072, cos=0.002), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] softhead of metaphysicaled claptrap [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.786 (perp=8.541, rec=0.076, cos=0.002), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] soft metaphysical ofheaded claptrap [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.597 (perp=7.706, rec=0.054, cos=0.002), tot_loss_proj:1.870 [t=0.22s]
prediction: ['[CLS] metaphysical of softheaded claptrap [SEP]']
[ 450/2000] tot_loss=1.602 (perp=7.706, rec=0.059, cos=0.002), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] metaphysical of softheaded claptrap [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.540 (perp=7.384, rec=0.061, cos=0.002), tot_loss_proj:1.637 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.542 (perp=7.384, rec=0.063, cos=0.002), tot_loss_proj:1.633 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 600/2000] tot_loss=1.542 (perp=7.384, rec=0.062, cos=0.002), tot_loss_proj:1.642 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.541 (perp=7.384, rec=0.062, cos=0.002), tot_loss_proj:1.634 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.539 (perp=7.384, rec=0.060, cos=0.002), tot_loss_proj:1.635 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 750/2000] tot_loss=1.538 (perp=7.384, rec=0.059, cos=0.002), tot_loss_proj:1.638 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.541 (perp=7.384, rec=0.062, cos=0.002), tot_loss_proj:1.641 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.537 (perp=7.384, rec=0.058, cos=0.002), tot_loss_proj:1.635 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 900/2000] tot_loss=1.550 (perp=7.384, rec=0.071, cos=0.002), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.538 (perp=7.384, rec=0.058, cos=0.002), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.548 (perp=7.384, rec=0.069, cos=0.002), tot_loss_proj:1.636 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1050/2000] tot_loss=1.532 (perp=7.384, rec=0.053, cos=0.002), tot_loss_proj:1.633 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.551 (perp=7.384, rec=0.072, cos=0.002), tot_loss_proj:1.636 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.550 (perp=7.384, rec=0.071, cos=0.002), tot_loss_proj:1.638 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1200/2000] tot_loss=1.540 (perp=7.384, rec=0.061, cos=0.002), tot_loss_proj:1.626 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.541 (perp=7.384, rec=0.062, cos=0.002), tot_loss_proj:1.639 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.547 (perp=7.384, rec=0.068, cos=0.002), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1350/2000] tot_loss=1.537 (perp=7.384, rec=0.058, cos=0.002), tot_loss_proj:1.626 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.537 (perp=7.384, rec=0.058, cos=0.002), tot_loss_proj:1.632 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.540 (perp=7.384, rec=0.061, cos=0.002), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1500/2000] tot_loss=1.545 (perp=7.384, rec=0.066, cos=0.002), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.537 (perp=7.384, rec=0.058, cos=0.002), tot_loss_proj:1.622 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.544 (perp=7.384, rec=0.065, cos=0.002), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1650/2000] tot_loss=1.535 (perp=7.384, rec=0.056, cos=0.002), tot_loss_proj:1.631 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.537 (perp=7.384, rec=0.058, cos=0.002), tot_loss_proj:1.635 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.532 (perp=7.384, rec=0.053, cos=0.002), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1800/2000] tot_loss=1.548 (perp=7.384, rec=0.069, cos=0.002), tot_loss_proj:1.638 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.539 (perp=7.384, rec=0.060, cos=0.002), tot_loss_proj:1.636 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.541 (perp=7.384, rec=0.062, cos=0.002), tot_loss_proj:1.637 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1950/2000] tot_loss=1.541 (perp=7.384, rec=0.061, cos=0.002), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.541 (perp=7.384, rec=0.062, cos=0.002), tot_loss_proj:1.635 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical softheaded claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 92.171 | p: 93.864 | r: 91.048
rouge2     | fm: 68.592 | p: 69.952 | r: 67.737
rougeL     | fm: 85.819 | p: 87.727 | r: 84.774
rougeLsum  | fm: 85.819 | p: 87.652 | r: 84.548
r1fm+r2fm = 160.763

input #9 time: 0:08:51 | total time: 1:30:10


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9989512650412298
highest_index [0]
highest [0.9989512650412298]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.7957035899162292 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.7767426371574402 for ['[CLS] university mitaonaefa never existing gym backed ribs realmsund odd [SEP]']
[Init] best rec loss: 0.7441798448562622 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.6607406735420227 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 0.6596410274505615 for ['[CLS] common level totally up order soundoric blessedblood places sheep themes angel [SEP]']
[Init] best perm rec loss: 0.6572002172470093 for ['[CLS]blood sound angel common themes sheep uporic blessed level places totally order [SEP]']
[Init] best perm rec loss: 0.6570185422897339 for ['[CLS] sound sheep common order up places level angeloric themes blessed totallyblood [SEP]']
[Init] best perm rec loss: 0.6567840576171875 for ['[CLS] sound sheep angel order common totallyoric up blessedblood places themes level [SEP]']
[Init] best perm rec loss: 0.6560449600219727 for ['[CLS] places themes angel up common totally soundblood blessedoric sheep order level [SEP]']
[Init] best perm rec loss: 0.6542155146598816 for ['[CLS] places blessed sheep common sound totally order angel themes upblood leveloric [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.941 (perp=12.982, rec=0.320, cos=0.024), tot_loss_proj:3.571 [t=0.22s]
prediction: ['[CLS]matic -r creative politicsly while impact fa compartment based lee hours [SEP]']
[ 100/2000] tot_loss=2.625 (perp=12.066, rec=0.201, cos=0.010), tot_loss_proj:4.193 [t=0.22s]
prediction: ['[CLS] ab ab ) rhythmslyly abity vector compartment balance focus negative [SEP]']
[ 150/2000] tot_loss=2.458 (perp=11.525, rec=0.146, cos=0.006), tot_loss_proj:3.792 [t=0.22s]
prediction: ['[CLS] ab ab with rhythmslyly abity faulsive balance rhythmsulsive [SEP]']
[ 200/2000] tot_loss=2.611 (perp=12.425, rec=0.120, cos=0.006), tot_loss_proj:4.148 [t=0.22s]
prediction: ['[CLS]ulsive ab with rhythmssly ab incident faulsive balance rhythms incident [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.520 (perp=11.077, rec=0.278, cos=0.027), tot_loss_proj:3.781 [t=0.22s]
prediction: ['[CLS]ulsive ab with reals incident pearsonulsively ab balance rhythms incident [SEP]']
[ 300/2000] tot_loss=2.404 (perp=10.922, rec=0.190, cos=0.029), tot_loss_proj:3.710 [t=0.22s]
prediction: ['[CLS]ulsive ab with reals incident putulsively ab balance rhythms incident [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.342 (perp=10.657, rec=0.186, cos=0.025), tot_loss_proj:3.832 [t=0.22s]
prediction: ['[CLS] ab with reals incident put incidently abulsive balance rhythms incident [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.199 (perp=9.928, rec=0.184, cos=0.030), tot_loss_proj:3.648 [t=0.22s]
prediction: ['[CLS] ably reals incident put time with abulsive balance rhythms incident [SEP]']
[ 450/2000] tot_loss=2.188 (perp=9.928, rec=0.173, cos=0.030), tot_loss_proj:3.644 [t=0.22s]
prediction: ['[CLS] ably reals incident put time with abulsive balance rhythms incident [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.996 (perp=8.998, rec=0.171, cos=0.026), tot_loss_proj:3.213 [t=0.22s]
prediction: ['[CLS] incident ably reals incident put time with abulsive balance rhythms [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.916 (perp=8.543, rec=0.180, cos=0.028), tot_loss_proj:2.669 [t=0.22s]
prediction: ['[CLS] incidents incident put ably real time with abulsive balance rhythms [SEP]']
[ 600/2000] tot_loss=1.939 (perp=8.717, rec=0.166, cos=0.029), tot_loss_proj:3.138 [t=0.22s]
prediction: ['[CLS] incidents incidentছ ably real time with abulsive balance rhythms [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.842 (perp=8.302, rec=0.157, cos=0.025), tot_loss_proj:2.781 [t=0.22s]
prediction: ['[CLS] incidents incident ably real time with propulsiveছ balance rhythms [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.912 (perp=8.655, rec=0.154, cos=0.027), tot_loss_proj:2.774 [t=0.22s]
prediction: ['[CLS] bottle incidents ably real time with propulsiveছ balance rhythms [SEP]']
[ 750/2000] tot_loss=1.902 (perp=8.655, rec=0.144, cos=0.027), tot_loss_proj:2.774 [t=0.22s]
prediction: ['[CLS] bottle incidents ably real time with propulsiveছ balance rhythms [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.840 (perp=8.292, rec=0.156, cos=0.025), tot_loss_proj:3.031 [t=0.22s]
prediction: ['[CLS] incidents ably bottle real time with propulsiveছ balance rhythms [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.774 (perp=7.989, rec=0.149, cos=0.027), tot_loss_proj:2.849 [t=0.22s]
prediction: ['[CLS] incident balances ably bottle real time with propulsiveছ rhythms [SEP]']
[ 900/2000] tot_loss=1.778 (perp=7.989, rec=0.157, cos=0.024), tot_loss_proj:2.846 [t=0.22s]
prediction: ['[CLS] incident balances ably bottle real time with propulsiveছ rhythms [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.725 (perp=7.771, rec=0.146, cos=0.025), tot_loss_proj:2.982 [t=0.22s]
prediction: ['[CLS] incident balances ably bottle real time withছ propulsive rhythms [SEP]']
Attempt swap
[1000/2000] tot_loss=1.732 (perp=7.771, rec=0.155, cos=0.023), tot_loss_proj:2.983 [t=0.22s]
prediction: ['[CLS] incident balances ably bottle real time withছ propulsive rhythms [SEP]']
[1050/2000] tot_loss=1.721 (perp=7.771, rec=0.144, cos=0.023), tot_loss_proj:2.984 [t=0.22s]
prediction: ['[CLS] incident balances ably bottle real time withছ propulsive rhythms [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.736 (perp=7.790, rec=0.154, cos=0.024), tot_loss_proj:2.754 [t=0.22s]
prediction: ['[CLS] incident balances ablyছ bottle real time with propulsive rhythms [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.727 (perp=7.678, rec=0.168, cos=0.024), tot_loss_proj:2.790 [t=0.22s]
prediction: ['[CLS] incident balancesছ ably than real time with propulsive rhythms [SEP]']
[1200/2000] tot_loss=1.604 (perp=7.130, rec=0.154, cos=0.023), tot_loss_proj:2.247 [t=0.29s]
prediction: ['[CLS] incident balances me ably than real time with propulsive rhythms [SEP]']
Attempt swap
[1250/2000] tot_loss=1.592 (perp=7.130, rec=0.143, cos=0.023), tot_loss_proj:2.250 [t=0.22s]
prediction: ['[CLS] incident balances me ably than real time with propulsive rhythms [SEP]']
Attempt swap
[1300/2000] tot_loss=1.595 (perp=7.130, rec=0.147, cos=0.023), tot_loss_proj:2.252 [t=0.22s]
prediction: ['[CLS] incident balances me ably than real time with propulsive rhythms [SEP]']
[1350/2000] tot_loss=1.607 (perp=7.130, rec=0.158, cos=0.023), tot_loss_proj:2.249 [t=0.22s]
prediction: ['[CLS] incident balances me ably than real time with propulsive rhythms [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.551 (perp=6.896, rec=0.147, cos=0.025), tot_loss_proj:2.472 [t=0.22s]
prediction: ['[CLS] me balances incident ably than real time with propulsive rhythms [SEP]']
Attempt swap
[1450/2000] tot_loss=1.557 (perp=6.896, rec=0.153, cos=0.024), tot_loss_proj:2.467 [t=0.22s]
prediction: ['[CLS] me balances incident ably than real time with propulsive rhythms [SEP]']
[1500/2000] tot_loss=1.634 (perp=7.329, rec=0.144, cos=0.024), tot_loss_proj:2.104 [t=0.22s]
prediction: ['[CLS] me balances incident ably overall real time with propulsive rhythms [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.633 (perp=7.256, rec=0.158, cos=0.024), tot_loss_proj:2.094 [t=0.22s]
prediction: ['[CLS] me balances incident ably overall with real time propulsive rhythms [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.730 (perp=7.737, rec=0.160, cos=0.023), tot_loss_proj:2.021 [t=0.22s]
prediction: ['[CLS] mepiece balances incident ably with real time propulsive rhythms [SEP]']
[1650/2000] tot_loss=1.693 (perp=7.598, rec=0.148, cos=0.025), tot_loss_proj:2.375 [t=0.22s]
prediction: ['[CLS] me than balances incident ably with real time propulsive rhythms [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.654 (perp=7.378, rec=0.155, cos=0.024), tot_loss_proj:2.137 [t=0.22s]
prediction: ['[CLS]piece me balances incident ably with real time propulsive rhythms [SEP]']
Attempt swap
[1750/2000] tot_loss=1.649 (perp=7.378, rec=0.150, cos=0.024), tot_loss_proj:2.134 [t=0.22s]
prediction: ['[CLS]piece me balances incident ably with real time propulsive rhythms [SEP]']
[1800/2000] tot_loss=1.647 (perp=7.378, rec=0.148, cos=0.024), tot_loss_proj:2.131 [t=0.22s]
prediction: ['[CLS]piece me balances incident ably with real time propulsive rhythms [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.581 (perp=7.070, rec=0.145, cos=0.022), tot_loss_proj:2.099 [t=0.22s]
prediction: ['[CLS] me balances incident ably with real timepiece propulsive rhythms [SEP]']
Attempt swap
[1900/2000] tot_loss=1.583 (perp=7.070, rec=0.147, cos=0.023), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] me balances incident ably with real timepiece propulsive rhythms [SEP]']
[1950/2000] tot_loss=1.584 (perp=7.070, rec=0.147, cos=0.023), tot_loss_proj:2.100 [t=0.22s]
prediction: ['[CLS] me balances incident ably with real timepiece propulsive rhythms [SEP]']
Attempt swap
[2000/2000] tot_loss=1.580 (perp=7.070, rec=0.143, cos=0.023), tot_loss_proj:2.093 [t=0.22s]
prediction: ['[CLS] me balances incident ably with real timepiece propulsive rhythms [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS]ulsive ab with rhythmssly ab incident faulsive balance rhythms incident [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 45.455 | p: 41.667 | r: 50.000
rouge2     | fm: 10.000 | p: 9.091 | r: 11.111
rougeL     | fm: 36.364 | p: 33.333 | r: 40.000
rougeLsum  | fm: 36.364 | p: 33.333 | r: 40.000
r1fm+r2fm = 55.455

[Aggregate metrics]:
rouge1     | fm: 87.879 | p: 89.118 | r: 87.273
rouge2     | fm: 63.340 | p: 64.398 | r: 62.564
rougeL     | fm: 81.697 | p: 83.058 | r: 80.887
rougeLsum  | fm: 81.540 | p: 83.196 | r: 80.498
r1fm+r2fm = 151.219

input #10 time: 0:08:53 | total time: 1:39:04


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9985975824755357
highest_index [0]
highest [0.9985975824755357]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.8811643719673157 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.8649181723594666 for ['[CLS] changelift tonig half moth bodo contractgmche [SEP]']
[Init] best rec loss: 0.82845538854599 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.7499896883964539 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.7496981024742126 for ['[CLS]ture talguvd inland platform drawn me mile familiar [SEP]']
[Init] best perm rec loss: 0.7494725584983826 for ['[CLS] talture familiar inland platformvdgu drawn me mile [SEP]']
[Init] best perm rec loss: 0.7469839453697205 for ['[CLS] inlandgu mile tal platform drawn familiar meturevd [SEP]']
[Init] best perm rec loss: 0.7466945648193359 for ['[CLS] talturevdgu inland mile platform drawn familiar me [SEP]']
[Init] best perm rec loss: 0.745023787021637 for ['[CLS] meture tal mile drawnvdgu familiar platform inland [SEP]']
[Init] best perm rec loss: 0.7449614405632019 for ['[CLS]ture tal inlandgu me drawnvd mile familiar platform [SEP]']
[Init] best perm rec loss: 0.7444503903388977 for ['[CLS] familiarture me inland mile talguvd drawn platform [SEP]']
[Init] best perm rec loss: 0.7441080212593079 for ['[CLS] inland tal drawnture platform familiarguvd mile me [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.215 (perp=14.294, rec=0.331, cos=0.025), tot_loss_proj:3.812 [t=0.22s]
prediction: ['[CLS] missing blame situation built gel stubborn refused attempt refused stubborn [SEP]']
[ 100/2000] tot_loss=2.569 (perp=11.514, rec=0.245, cos=0.021), tot_loss_proj:3.372 [t=0.22s]
prediction: ['[CLS] refused to being built gel stubborn stubbornly refused stubborn [SEP]']
[ 150/2000] tot_loss=2.285 (perp=10.543, rec=0.166, cos=0.010), tot_loss_proj:3.235 [t=0.22s]
prediction: ['[CLS] refused to that tried gel stubborn stubbornly refused were [SEP]']
[ 200/2000] tot_loss=2.317 (perp=10.961, rec=0.120, cos=0.005), tot_loss_proj:3.270 [t=0.22s]
prediction: ['[CLS] refused here that attempted gel stubborn stubbornly refused was [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.360 (perp=11.258, rec=0.103, cos=0.005), tot_loss_proj:3.250 [t=0.22s]
prediction: ['[CLS] refused here that attempted refused gel stubborn stubbornly was [SEP]']
[ 300/2000] tot_loss=1.967 (perp=9.365, rec=0.090, cos=0.003), tot_loss_proj:2.661 [t=0.22s]
prediction: ['[CLS] refused here that attempted to gel stubborn stubbornly was [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.788 (perp=8.489, rec=0.086, cos=0.004), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] refused here that attempted to gel stubbornly was stubborn [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.710 (perp=8.143, rec=0.079, cos=0.003), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] refused here that attempted to gel was stubbornly stubborn [SEP]']
[ 450/2000] tot_loss=1.724 (perp=8.143, rec=0.089, cos=0.006), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] refused here that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.658 (perp=7.811, rec=0.089, cos=0.007), tot_loss_proj:2.586 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.654 (perp=7.811, rec=0.086, cos=0.006), tot_loss_proj:2.594 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
[ 600/2000] tot_loss=1.661 (perp=7.811, rec=0.094, cos=0.004), tot_loss_proj:2.592 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.667 (perp=7.811, rec=0.096, cos=0.008), tot_loss_proj:2.595 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.669 (perp=7.811, rec=0.103, cos=0.004), tot_loss_proj:2.590 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
[ 750/2000] tot_loss=1.650 (perp=7.811, rec=0.082, cos=0.005), tot_loss_proj:2.590 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.670 (perp=7.811, rec=0.104, cos=0.004), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.646 (perp=7.811, rec=0.080, cos=0.004), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
[ 900/2000] tot_loss=1.650 (perp=7.811, rec=0.084, cos=0.004), tot_loss_proj:2.593 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.646 (perp=7.811, rec=0.079, cos=0.004), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1000/2000] tot_loss=1.649 (perp=7.811, rec=0.083, cos=0.005), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
[1050/2000] tot_loss=1.648 (perp=7.811, rec=0.082, cos=0.004), tot_loss_proj:2.586 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1100/2000] tot_loss=1.659 (perp=7.811, rec=0.093, cos=0.004), tot_loss_proj:2.586 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1150/2000] tot_loss=1.649 (perp=7.811, rec=0.083, cos=0.004), tot_loss_proj:2.592 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
[1200/2000] tot_loss=1.662 (perp=7.811, rec=0.096, cos=0.004), tot_loss_proj:2.590 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1250/2000] tot_loss=1.643 (perp=7.811, rec=0.076, cos=0.004), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1300/2000] tot_loss=1.639 (perp=7.811, rec=0.073, cos=0.004), tot_loss_proj:2.586 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
[1350/2000] tot_loss=1.649 (perp=7.811, rec=0.083, cos=0.004), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1400/2000] tot_loss=1.651 (perp=7.811, rec=0.085, cos=0.004), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1450/2000] tot_loss=1.645 (perp=7.811, rec=0.079, cos=0.004), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
[1500/2000] tot_loss=1.640 (perp=7.811, rec=0.074, cos=0.004), tot_loss_proj:2.586 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1550/2000] tot_loss=1.651 (perp=7.811, rec=0.085, cos=0.004), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1600/2000] tot_loss=1.636 (perp=7.811, rec=0.070, cos=0.004), tot_loss_proj:2.590 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
[1650/2000] tot_loss=1.638 (perp=7.811, rec=0.072, cos=0.004), tot_loss_proj:2.583 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1700/2000] tot_loss=1.653 (perp=7.811, rec=0.087, cos=0.004), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1750/2000] tot_loss=1.647 (perp=7.811, rec=0.081, cos=0.004), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
[1800/2000] tot_loss=1.644 (perp=7.811, rec=0.078, cos=0.004), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1850/2000] tot_loss=1.644 (perp=7.811, rec=0.078, cos=0.004), tot_loss_proj:2.584 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[1900/2000] tot_loss=1.643 (perp=7.811, rec=0.077, cos=0.004), tot_loss_proj:2.592 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
[1950/2000] tot_loss=1.653 (perp=7.811, rec=0.087, cos=0.004), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Attempt swap
[2000/2000] tot_loss=1.640 (perp=7.811, rec=0.074, cos=0.004), tot_loss_proj:2.592 [t=0.22s]
prediction: ['[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here refused that attempted to gel was stubbornly stubborn [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 10.000 | p: 10.000 | r: 10.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 100.909

[Aggregate metrics]:
rouge1     | fm: 88.182 | p: 89.457 | r: 87.578
rouge2     | fm: 58.895 | p: 60.141 | r: 58.395
rougeL     | fm: 79.146 | p: 80.429 | r: 78.316
rougeLsum  | fm: 79.245 | p: 80.682 | r: 78.266
r1fm+r2fm = 147.078

input #11 time: 0:08:50 | total time: 1:47:55


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.9988071752251515
highest_index [0]
highest [0.9988071752251515]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8693208694458008 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.8534552454948425 for ['[CLS] systems simonway met armenia blockade tongue when unisonizes and present reeve representatives [SEP]']
[Init] best rec loss: 0.7883449196815491 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7814298868179321 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7760781049728394 for ['[CLS] wolf rex usualli plant live painfully sqlamtpemi wallace du sort [SEP]']
[Init] best rec loss: 0.7739584445953369 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7642564177513123 for ['[CLS] hear protocol heidi race strokes safety association transactions snail most place buried terror documentary [SEP]']
[Init] best rec loss: 0.7562382817268372 for ['[CLS] alive expression semiuid wise friend investigationthed beloved [MASK] got richards didnbank [SEP]']
[Init] best rec loss: 0.7519859671592712 for ['[CLS] ruins league release compoundled twinned major also after touch cora sunday wicked appoint [SEP]']
[Init] best perm rec loss: 0.7500580549240112 for ['[CLS] cora appointled compound twinned release wicked sunday touch ruins also league after major [SEP]']
[Init] best perm rec loss: 0.7492172718048096 for ['[CLS] league sunday twinned ruins wicked release touch cora appoint compound majorled also after [SEP]']
[Init] best perm rec loss: 0.7487169504165649 for ['[CLS] touch also sunday wicked after appoint ruins twinned major release coraled league compound [SEP]']
[Init] best perm rec loss: 0.747654378414154 for ['[CLS] league also wicked after sundayled appoint release twinned compound touch major cora ruins [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.617 (perp=11.307, rec=0.321, cos=0.034), tot_loss_proj:3.105 [t=0.22s]
prediction: ['[CLS] reportedly under amusement barely advantage looked might advantage more better on cable cable obviously [SEP]']
[ 100/2000] tot_loss=2.099 (perp=9.476, rec=0.190, cos=0.014), tot_loss_proj:2.780 [t=0.22s]
prediction: ['[CLS] usually for amusement barely seen advantage advantage advantage will better on cable cable almost [SEP]']
[ 150/2000] tot_loss=2.114 (perp=9.931, rec=0.121, cos=0.008), tot_loss_proj:2.826 [t=0.22s]
prediction: ['[CLS] is its astro barely seen to advantage advantage will better on cable cable especially [SEP]']
[ 200/2000] tot_loss=2.258 (perp=10.827, rec=0.088, cos=0.004), tot_loss_proj:3.131 [t=0.22s]
prediction: ['[CLS] that considering astro barely seen to advantage advantage will better on its cable especially [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.174 (perp=10.461, rec=0.079, cos=0.003), tot_loss_proj:3.377 [t=0.22s]
prediction: ['[CLS] that considering astro barely seen to better advantage will advantage on its cable especially [SEP]']
[ 300/2000] tot_loss=2.009 (perp=9.631, rec=0.079, cos=0.003), tot_loss_proj:3.256 [t=0.22s]
prediction: ['[CLS] that considering loco barely seen to better advantage will advantage on its cable especially [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.039 (perp=9.409, rec=0.140, cos=0.017), tot_loss_proj:2.692 [t=0.22s]
prediction: ['[CLS] that considering will barely seen to better advantage religious advantage on its cable especially [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.941 (perp=9.193, rec=0.097, cos=0.005), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] that considering will barely seen to better advantage its advantage on associated cable especially [SEP]']
[ 450/2000] tot_loss=1.931 (perp=9.193, rec=0.089, cos=0.004), tot_loss_proj:2.581 [t=0.22s]
prediction: ['[CLS] that considering will barely seen to better advantage its advantage on associated cable especially [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.805 (perp=8.603, rec=0.081, cos=0.004), tot_loss_proj:2.459 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on associated cable that [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.761 (perp=8.428, rec=0.071, cos=0.003), tot_loss_proj:2.423 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
[ 600/2000] tot_loss=1.766 (perp=8.428, rec=0.077, cos=0.003), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.760 (perp=8.428, rec=0.071, cos=0.003), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.770 (perp=8.428, rec=0.082, cos=0.003), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
[ 750/2000] tot_loss=1.759 (perp=8.428, rec=0.070, cos=0.003), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.761 (perp=8.428, rec=0.073, cos=0.003), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.763 (perp=8.428, rec=0.075, cos=0.003), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
[ 900/2000] tot_loss=1.763 (perp=8.428, rec=0.074, cos=0.003), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.768 (perp=8.428, rec=0.079, cos=0.003), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
Attempt swap
[1000/2000] tot_loss=1.764 (perp=8.428, rec=0.075, cos=0.003), tot_loss_proj:2.423 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
[1050/2000] tot_loss=1.769 (perp=8.428, rec=0.080, cos=0.003), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
Attempt swap
[1100/2000] tot_loss=1.757 (perp=8.428, rec=0.068, cos=0.003), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that associated cable [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.769 (perp=8.449, rec=0.076, cos=0.003), tot_loss_proj:2.472 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that cable / [SEP]']
[1200/2000] tot_loss=1.762 (perp=8.449, rec=0.069, cos=0.003), tot_loss_proj:2.475 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on that cable / [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.738 (perp=8.297, rec=0.075, cos=0.003), tot_loss_proj:2.475 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage that its advantage on cable / [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.705 (perp=8.070, rec=0.088, cos=0.003), tot_loss_proj:2.432 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
[1350/2000] tot_loss=1.696 (perp=8.070, rec=0.079, cos=0.003), tot_loss_proj:2.434 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
Attempt swap
[1400/2000] tot_loss=1.695 (perp=8.070, rec=0.078, cos=0.003), tot_loss_proj:2.439 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
Attempt swap
[1450/2000] tot_loss=1.694 (perp=8.070, rec=0.077, cos=0.003), tot_loss_proj:2.437 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
[1500/2000] tot_loss=1.697 (perp=8.070, rec=0.080, cos=0.003), tot_loss_proj:2.438 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
Attempt swap
[1550/2000] tot_loss=1.683 (perp=8.070, rec=0.067, cos=0.003), tot_loss_proj:2.433 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
Attempt swap
[1600/2000] tot_loss=1.680 (perp=8.070, rec=0.064, cos=0.003), tot_loss_proj:2.438 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
[1650/2000] tot_loss=1.687 (perp=8.070, rec=0.070, cos=0.003), tot_loss_proj:2.435 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
Attempt swap
[1700/2000] tot_loss=1.685 (perp=8.070, rec=0.068, cos=0.003), tot_loss_proj:2.438 [t=0.23s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
Attempt swap
[1750/2000] tot_loss=1.688 (perp=8.070, rec=0.072, cos=0.003), tot_loss_proj:2.435 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
[1800/2000] tot_loss=1.690 (perp=8.070, rec=0.073, cos=0.003), tot_loss_proj:2.436 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
Attempt swap
[1850/2000] tot_loss=1.700 (perp=8.070, rec=0.083, cos=0.003), tot_loss_proj:2.438 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
Attempt swap
[1900/2000] tot_loss=1.694 (perp=8.070, rec=0.077, cos=0.003), tot_loss_proj:2.437 [t=0.22s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
[1950/2000] tot_loss=1.702 (perp=8.070, rec=0.085, cos=0.003), tot_loss_proj:2.433 [t=0.23s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
Attempt swap
[2000/2000] tot_loss=1.692 (perp=8.070, rec=0.076, cos=0.003), tot_loss_proj:2.432 [t=0.23s]
prediction: ['[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] especially considering will barely seen to better advantage its advantage on cable that / [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 136.190

[Aggregate metrics]:
rouge1     | fm: 88.569 | p: 89.749 | r: 88.089
rouge2     | fm: 57.175 | p: 58.117 | r: 56.742
rougeL     | fm: 77.592 | p: 78.869 | r: 76.797
rougeLsum  | fm: 77.310 | p: 78.572 | r: 76.594
r1fm+r2fm = 145.744

input #12 time: 0:08:54 | total time: 1:56:50


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9987084084594501
highest_index [0]
highest [0.9987084084594501]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.7251901626586914 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.6944078803062439 for ['[CLS] baccalaureate, black saunderstec armed much [SEP]']
[Init] best perm rec loss: 0.6942326426506042 for ['[CLS] saunders black,tec baccalaureate much armed [SEP]']
[Init] best perm rec loss: 0.6938580274581909 for ['[CLS]tec saunders, armed black baccalaureate much [SEP]']
[Init] best perm rec loss: 0.6936817169189453 for ['[CLS] saunders much armed baccalaureate,tec black [SEP]']
[Init] best perm rec loss: 0.6930689215660095 for ['[CLS] saunders black, baccalaureate armedtec much [SEP]']
[Init] best perm rec loss: 0.6928972601890564 for ['[CLS] blacktec baccalaureate saunders armed, much [SEP]']
[Init] best perm rec loss: 0.6920087337493896 for ['[CLS],tec baccalaureate black armed much saunders [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.981 (perp=12.934, rec=0.319, cos=0.076), tot_loss_proj:3.707 [t=0.22s]
prediction: ['[CLS] explode flame just entering figured flame rot [SEP]']
[ 100/2000] tot_loss=2.767 (perp=12.577, rec=0.216, cos=0.036), tot_loss_proj:3.677 [t=0.22s]
prediction: ['[CLS] explode flame dim into into flame fires [SEP]']
[ 150/2000] tot_loss=2.120 (perp=10.030, rec=0.110, cos=0.004), tot_loss_proj:2.831 [t=0.22s]
prediction: ['[CLS] explode things that point at flame into [SEP]']
[ 200/2000] tot_loss=2.083 (perp=10.030, rec=0.074, cos=0.003), tot_loss_proj:2.830 [t=0.22s]
prediction: ['[CLS] explode things that point at flame into [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.705 (perp=8.179, rec=0.067, cos=0.003), tot_loss_proj:2.557 [t=0.22s]
prediction: ['[CLS] explode things at that point flame into [SEP]']
[ 300/2000] tot_loss=1.716 (perp=8.179, rec=0.077, cos=0.003), tot_loss_proj:2.552 [t=0.23s]
prediction: ['[CLS] explode things at that point flame into [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.463 (perp=6.966, rec=0.067, cos=0.002), tot_loss_proj:2.532 [t=0.22s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.465 (perp=6.966, rec=0.069, cos=0.003), tot_loss_proj:2.535 [t=0.22s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[ 450/2000] tot_loss=1.463 (perp=6.966, rec=0.068, cos=0.003), tot_loss_proj:2.531 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.457 (perp=6.966, rec=0.062, cos=0.003), tot_loss_proj:2.529 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.460 (perp=6.966, rec=0.064, cos=0.003), tot_loss_proj:2.528 [t=0.23s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[ 600/2000] tot_loss=1.461 (perp=6.966, rec=0.065, cos=0.003), tot_loss_proj:2.523 [t=0.23s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.456 (perp=6.966, rec=0.061, cos=0.002), tot_loss_proj:2.525 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.460 (perp=6.966, rec=0.065, cos=0.003), tot_loss_proj:2.524 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[ 750/2000] tot_loss=1.462 (perp=6.966, rec=0.066, cos=0.003), tot_loss_proj:2.526 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.461 (perp=6.966, rec=0.065, cos=0.003), tot_loss_proj:2.524 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.448 (perp=6.966, rec=0.053, cos=0.003), tot_loss_proj:2.517 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[ 900/2000] tot_loss=1.453 (perp=6.966, rec=0.057, cos=0.003), tot_loss_proj:2.524 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.468 (perp=6.966, rec=0.072, cos=0.003), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1000/2000] tot_loss=1.461 (perp=6.966, rec=0.065, cos=0.003), tot_loss_proj:2.520 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1050/2000] tot_loss=1.464 (perp=6.966, rec=0.069, cos=0.003), tot_loss_proj:2.519 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1100/2000] tot_loss=1.459 (perp=6.966, rec=0.063, cos=0.003), tot_loss_proj:2.520 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1150/2000] tot_loss=1.473 (perp=6.966, rec=0.078, cos=0.003), tot_loss_proj:2.529 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1200/2000] tot_loss=1.463 (perp=6.966, rec=0.067, cos=0.003), tot_loss_proj:2.519 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1250/2000] tot_loss=1.455 (perp=6.966, rec=0.059, cos=0.003), tot_loss_proj:2.517 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1300/2000] tot_loss=1.463 (perp=6.966, rec=0.067, cos=0.003), tot_loss_proj:2.512 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1350/2000] tot_loss=1.455 (perp=6.966, rec=0.060, cos=0.003), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1400/2000] tot_loss=1.452 (perp=6.966, rec=0.056, cos=0.003), tot_loss_proj:2.522 [t=0.23s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1450/2000] tot_loss=1.459 (perp=6.966, rec=0.063, cos=0.003), tot_loss_proj:2.518 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1500/2000] tot_loss=1.470 (perp=6.966, rec=0.074, cos=0.003), tot_loss_proj:2.520 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1550/2000] tot_loss=1.465 (perp=6.966, rec=0.070, cos=0.003), tot_loss_proj:2.516 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1600/2000] tot_loss=1.470 (perp=6.966, rec=0.075, cos=0.003), tot_loss_proj:2.519 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1650/2000] tot_loss=1.453 (perp=6.966, rec=0.058, cos=0.003), tot_loss_proj:2.515 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1700/2000] tot_loss=1.453 (perp=6.966, rec=0.058, cos=0.003), tot_loss_proj:2.517 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1750/2000] tot_loss=1.460 (perp=6.966, rec=0.064, cos=0.003), tot_loss_proj:2.521 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1800/2000] tot_loss=1.455 (perp=6.966, rec=0.059, cos=0.003), tot_loss_proj:2.524 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1850/2000] tot_loss=1.458 (perp=6.966, rec=0.062, cos=0.003), tot_loss_proj:2.517 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1900/2000] tot_loss=1.472 (perp=6.966, rec=0.077, cos=0.003), tot_loss_proj:2.516 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1950/2000] tot_loss=1.464 (perp=6.966, rec=0.068, cos=0.003), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[2000/2000] tot_loss=1.458 (perp=6.966, rec=0.062, cos=0.003), tot_loss_proj:2.520 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] things explode at that point flame into [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.513 | p: 90.595 | r: 88.983
rouge2     | fm: 53.025 | p: 53.972 | r: 52.752
rougeL     | fm: 75.814 | p: 77.027 | r: 75.193
rougeLsum  | fm: 76.105 | p: 77.275 | r: 75.397
r1fm+r2fm = 142.538

input #13 time: 0:09:11 | total time: 2:06:02


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9986949829649336
highest_index [0]
highest [0.9986949829649336]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9896231889724731 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9874922633171082 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9757562279701233 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9718303680419922 for ['[CLS] female pants hard surely olympics [SEP]']
[Init] best rec loss: 0.9675215482711792 for ['[CLS] delike altar traveling nearby [SEP]']
[Init] best rec loss: 0.9666627049446106 for ['[CLS]rin eligibility grand haiti jay [SEP]']
[Init] best rec loss: 0.9658174514770508 for ['[CLS] math burning rangecino fritz [SEP]']
[Init] best rec loss: 0.9618939757347107 for ['[CLS] alter occupied ratingnts alma [SEP]']
[Init] best rec loss: 0.9579272270202637 for ['[CLS] brooks mentioninianame nothing [SEP]']
[Init] best rec loss: 0.9531496167182922 for ['[CLS] tractor no massachusettsint vision [SEP]']
[Init] best rec loss: 0.9512802958488464 for ['[CLS] century delegates annie gun photography [SEP]']
[Init] best rec loss: 0.9415226578712463 for ['[CLS]wife bloodhun coach low [SEP]']
[Init] best rec loss: 0.928584098815918 for ['[CLS] striker jade united ash siding [SEP]']
[Init] best perm rec loss: 0.9279648661613464 for ['[CLS] united striker jade ash siding [SEP]']
[Init] best perm rec loss: 0.9277862906455994 for ['[CLS] united jade siding striker ash [SEP]']
[Init] best perm rec loss: 0.9274935722351074 for ['[CLS] ash united siding jade striker [SEP]']
[Init] best perm rec loss: 0.9265232682228088 for ['[CLS] ash siding jade striker united [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.689 (perp=12.090, rec=0.264, cos=0.007), tot_loss_proj:3.090 [t=0.23s]
prediction: ['[CLS] intriguing film tomatoes film movie [SEP]']
[ 100/2000] tot_loss=2.433 (perp=11.315, rec=0.166, cos=0.004), tot_loss_proj:2.818 [t=0.23s]
prediction: ['[CLS] intriguingblybly intriguing film [SEP]']
[ 150/2000] tot_loss=2.819 (perp=13.382, rec=0.139, cos=0.003), tot_loss_proj:3.467 [t=0.24s]
prediction: ['[CLS] intriguingblyenia intriguing film [SEP]']
[ 200/2000] tot_loss=2.797 (perp=13.382, rec=0.117, cos=0.003), tot_loss_proj:3.474 [t=0.23s]
prediction: ['[CLS] intriguingblyenia intriguing film [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.701 (perp=7.971, rec=0.103, cos=0.003), tot_loss_proj:1.896 [t=0.23s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 300/2000] tot_loss=1.685 (perp=7.971, rec=0.088, cos=0.003), tot_loss_proj:1.894 [t=0.23s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.692 (perp=7.971, rec=0.095, cos=0.003), tot_loss_proj:1.897 [t=0.23s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.696 (perp=7.971, rec=0.099, cos=0.003), tot_loss_proj:1.909 [t=0.23s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 450/2000] tot_loss=1.681 (perp=7.971, rec=0.084, cos=0.003), tot_loss_proj:1.910 [t=0.23s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.692 (perp=7.971, rec=0.095, cos=0.003), tot_loss_proj:1.898 [t=0.24s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.681 (perp=7.971, rec=0.084, cos=0.003), tot_loss_proj:1.896 [t=0.23s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.685 (perp=7.971, rec=0.088, cos=0.003), tot_loss_proj:1.902 [t=0.23s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.688 (perp=7.971, rec=0.091, cos=0.003), tot_loss_proj:1.905 [t=0.23s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.678 (perp=7.971, rec=0.081, cos=0.003), tot_loss_proj:1.893 [t=0.23s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 750/2000] tot_loss=2.065 (perp=9.916, rec=0.079, cos=0.003), tot_loss_proj:2.737 [t=0.23s]
prediction: ['[CLS] intriguingeniably ᆯ film [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.076 (perp=9.916, rec=0.090, cos=0.003), tot_loss_proj:2.733 [t=0.23s]
prediction: ['[CLS] intriguingeniably ᆯ film [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.086 (perp=10.058, rec=0.072, cos=0.003), tot_loss_proj:3.640 [t=0.23s]
prediction: ['[CLS] intriguingeniably und film [SEP]']
[ 900/2000] tot_loss=2.076 (perp=10.058, rec=0.061, cos=0.003), tot_loss_proj:3.659 [t=0.23s]
prediction: ['[CLS] intriguingeniably und film [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.427 (perp=6.728, rec=0.079, cos=0.003), tot_loss_proj:1.412 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.426 (perp=6.728, rec=0.077, cos=0.003), tot_loss_proj:1.419 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.427 (perp=6.728, rec=0.079, cos=0.003), tot_loss_proj:1.413 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.417 (perp=6.728, rec=0.069, cos=0.003), tot_loss_proj:1.398 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.416 (perp=6.728, rec=0.067, cos=0.003), tot_loss_proj:1.407 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.405 (perp=6.728, rec=0.057, cos=0.003), tot_loss_proj:1.419 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.409 (perp=6.728, rec=0.061, cos=0.003), tot_loss_proj:1.412 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.410 (perp=6.728, rec=0.061, cos=0.003), tot_loss_proj:1.409 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.394 (perp=6.728, rec=0.045, cos=0.003), tot_loss_proj:1.411 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.420 (perp=6.728, rec=0.072, cos=0.003), tot_loss_proj:1.415 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.408 (perp=6.728, rec=0.059, cos=0.003), tot_loss_proj:1.414 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.405 (perp=6.728, rec=0.057, cos=0.003), tot_loss_proj:1.408 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.417 (perp=6.728, rec=0.069, cos=0.003), tot_loss_proj:1.399 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.408 (perp=6.728, rec=0.059, cos=0.003), tot_loss_proj:1.414 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.405 (perp=6.728, rec=0.057, cos=0.003), tot_loss_proj:1.408 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.412 (perp=6.728, rec=0.064, cos=0.003), tot_loss_proj:1.408 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.410 (perp=6.728, rec=0.062, cos=0.003), tot_loss_proj:1.417 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.397 (perp=6.728, rec=0.048, cos=0.003), tot_loss_proj:1.419 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.404 (perp=6.728, rec=0.056, cos=0.003), tot_loss_proj:1.414 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.408 (perp=6.728, rec=0.060, cos=0.003), tot_loss_proj:1.408 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.410 (perp=6.728, rec=0.062, cos=0.003), tot_loss_proj:1.407 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.404 (perp=6.728, rec=0.056, cos=0.003), tot_loss_proj:1.405 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.935 | p: 90.975 | r: 89.456
rouge2     | fm: 56.476 | p: 57.208 | r: 56.011
rougeL     | fm: 77.761 | p: 78.734 | r: 77.039
rougeLsum  | fm: 77.576 | p: 78.746 | r: 76.958
r1fm+r2fm = 146.411

input #14 time: 0:09:13 | total time: 2:15:15


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.998676784259346
highest_index [0]
highest [0.998676784259346]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.8716657161712646 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.8685224652290344 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 0.8567788600921631 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.8524195551872253 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8472680449485779 for ['[CLS] tower titans road photos trace oh board alone [SEP]']
[Init] best rec loss: 0.8417620658874512 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8375533223152161 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8309343457221985 for ['[CLS]ₑ scouts jeffital near mills reserveignment [SEP]']
[Init] best perm rec loss: 0.8282399773597717 for ['[CLS]ₑ reserve mills jeff scouts nearignmentital [SEP]']
[Init] best perm rec loss: 0.8279892802238464 for ['[CLS]ignment millsₑ nearital jeff scouts reserve [SEP]']
[Init] best perm rec loss: 0.8277714848518372 for ['[CLS]ignmentital reserve jeff mills nearₑ scouts [SEP]']
[Init] best perm rec loss: 0.8253362774848938 for ['[CLS] reserve jeffignment mills scoutsₑital near [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.423 (perp=10.932, rec=0.231, cos=0.006), tot_loss_proj:3.268 [t=0.23s]
prediction: ['[CLS] efficient anonymous!ably漢 efficient chill. [SEP]']
[ 100/2000] tot_loss=2.396 (perp=11.084, rec=0.175, cos=0.004), tot_loss_proj:3.223 [t=0.23s]
prediction: ['[CLS] efficient anonymous!ably chill suit chill. [SEP]']
[ 150/2000] tot_loss=2.615 (perp=12.248, rec=0.160, cos=0.005), tot_loss_proj:3.581 [t=0.23s]
prediction: ['[CLS] efficient anonymousousably chill suit chill. [SEP]']
[ 200/2000] tot_loss=2.568 (perp=12.248, rec=0.115, cos=0.004), tot_loss_proj:3.584 [t=0.23s]
prediction: ['[CLS] efficient anonymousousably chill suit chill. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.968 (perp=9.345, rec=0.095, cos=0.004), tot_loss_proj:2.586 [t=0.23s]
prediction: ['[CLS] efficient anonymous, suitablyer chill. [SEP]']
[ 300/2000] tot_loss=1.959 (perp=9.345, rec=0.086, cos=0.005), tot_loss_proj:2.601 [t=0.23s]
prediction: ['[CLS] efficient anonymous, suitablyer chill. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.632 (perp=7.791, rec=0.071, cos=0.003), tot_loss_proj:1.941 [t=0.23s]
prediction: ['[CLS] efficient anonymous, suitably chiller. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.525 (perp=7.050, rec=0.110, cos=0.004), tot_loss_proj:1.827 [t=0.23s]
prediction: ['[CLS] efficient, suitably chiller anonymous. [SEP]']
[ 450/2000] tot_loss=1.482 (perp=7.050, rec=0.069, cos=0.003), tot_loss_proj:1.835 [t=0.23s]
prediction: ['[CLS] efficient, suitably chiller anonymous. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.397 (perp=6.615, rec=0.071, cos=0.003), tot_loss_proj:1.402 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.390 (perp=6.615, rec=0.064, cos=0.003), tot_loss_proj:1.407 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 600/2000] tot_loss=1.387 (perp=6.615, rec=0.062, cos=0.003), tot_loss_proj:1.400 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.389 (perp=6.615, rec=0.064, cos=0.003), tot_loss_proj:1.403 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.395 (perp=6.615, rec=0.070, cos=0.003), tot_loss_proj:1.400 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.390 (perp=6.615, rec=0.064, cos=0.003), tot_loss_proj:1.396 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.394 (perp=6.615, rec=0.068, cos=0.003), tot_loss_proj:1.403 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.391 (perp=6.615, rec=0.065, cos=0.003), tot_loss_proj:1.402 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.390 (perp=6.615, rec=0.064, cos=0.003), tot_loss_proj:1.402 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.387 (perp=6.615, rec=0.061, cos=0.003), tot_loss_proj:1.404 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.378 (perp=6.615, rec=0.052, cos=0.003), tot_loss_proj:1.406 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.380 (perp=6.615, rec=0.055, cos=0.003), tot_loss_proj:1.410 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.395 (perp=6.615, rec=0.070, cos=0.003), tot_loss_proj:1.410 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.392 (perp=6.615, rec=0.067, cos=0.003), tot_loss_proj:1.402 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.384 (perp=6.615, rec=0.058, cos=0.003), tot_loss_proj:1.402 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.386 (perp=6.615, rec=0.061, cos=0.003), tot_loss_proj:1.406 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.387 (perp=6.615, rec=0.062, cos=0.003), tot_loss_proj:1.391 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.373 (perp=6.615, rec=0.047, cos=0.003), tot_loss_proj:1.401 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.384 (perp=6.615, rec=0.058, cos=0.003), tot_loss_proj:1.403 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.392 (perp=6.615, rec=0.066, cos=0.003), tot_loss_proj:1.400 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.381 (perp=6.615, rec=0.056, cos=0.003), tot_loss_proj:1.399 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.392 (perp=6.615, rec=0.066, cos=0.003), tot_loss_proj:1.406 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.391 (perp=6.615, rec=0.066, cos=0.003), tot_loss_proj:1.399 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.400 (perp=6.615, rec=0.074, cos=0.003), tot_loss_proj:1.406 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.383 (perp=6.615, rec=0.057, cos=0.003), tot_loss_proj:1.398 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.396 (perp=6.615, rec=0.070, cos=0.003), tot_loss_proj:1.385 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.387 (perp=6.615, rec=0.061, cos=0.003), tot_loss_proj:1.408 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.390 (perp=6.615, rec=0.064, cos=0.003), tot_loss_proj:1.398 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.388 (perp=6.615, rec=0.062, cos=0.003), tot_loss_proj:1.413 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.384 (perp=6.615, rec=0.058, cos=0.003), tot_loss_proj:1.400 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.386 (perp=6.615, rec=0.060, cos=0.003), tot_loss_proj:1.407 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.915 | p: 91.776 | r: 90.342
rouge2     | fm: 59.069 | p: 59.762 | r: 58.651
rougeL     | fm: 79.076 | p: 80.101 | r: 78.650
rougeLsum  | fm: 79.030 | p: 80.076 | r: 78.198
r1fm+r2fm = 149.984

input #15 time: 0:09:13 | total time: 2:24:29


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9987601816823323
highest_index [0]
highest [0.9987601816823323]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 0.8386392593383789 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.8038358688354492 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.8014927506446838 for ['[CLS]sa base slave shadow irvingdale [SEP]']
[Init] best rec loss: 0.7623493671417236 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 0.7525696158409119 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 0.7372539639472961 for ['[CLS] bountyign appropriate tongue himself serie [SEP]']
[Init] best rec loss: 0.7369927763938904 for ['[CLS]encia olgazy edit areas sounding [SEP]']
[Init] best rec loss: 0.7310876250267029 for ['[CLS] hermic clement glass dig mount [SEP]']
[Init] best rec loss: 0.7095297574996948 for ['[CLS] influence device lighthouse whatever user employee [SEP]']
[Init] best rec loss: 0.7081637978553772 for ['[CLS] dynamic logicsivenessy fast square [SEP]']
[Init] best perm rec loss: 0.707321047782898 for ['[CLS]sive fast squarenessy logic dynamic [SEP]']
[Init] best perm rec loss: 0.7070755362510681 for ['[CLS]nessysive fast dynamic square logic [SEP]']
[Init] best perm rec loss: 0.7049463391304016 for ['[CLS] fastnessy logicsive square dynamic [SEP]']
[Init] best perm rec loss: 0.7047021985054016 for ['[CLS]nessy dynamic fast logicsive square [SEP]']
[Init] best perm rec loss: 0.7033386826515198 for ['[CLS] dynamic square logicsivenessy fast [SEP]']
[Init] best perm rec loss: 0.7030161619186401 for ['[CLS] fast square logicsivenessy dynamic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.364 (perp=9.205, rec=0.383, cos=0.141), tot_loss_proj:3.473 [t=0.23s]
prediction: ['[CLS] more more more more reform more [SEP]']
[ 100/2000] tot_loss=1.851 (perp=7.820, rec=0.251, cos=0.036), tot_loss_proj:2.453 [t=0.23s]
prediction: ['[CLS] this this more story of more [SEP]']
[ 150/2000] tot_loss=1.492 (perp=6.744, rec=0.131, cos=0.012), tot_loss_proj:2.210 [t=0.23s]
prediction: ['[CLS] all this more story of and [SEP]']
[ 200/2000] tot_loss=1.293 (perp=5.980, rec=0.094, cos=0.003), tot_loss_proj:1.775 [t=0.23s]
prediction: ['[CLS] all this more of, and [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.177 (perp=5.493, rec=0.075, cos=0.003), tot_loss_proj:1.651 [t=0.23s]
prediction: ['[CLS] all of this more, and [SEP]']
[ 300/2000] tot_loss=1.168 (perp=5.493, rec=0.067, cos=0.002), tot_loss_proj:1.647 [t=0.23s]
prediction: ['[CLS] all of this more, and [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.057 (perp=4.891, rec=0.077, cos=0.002), tot_loss_proj:1.272 [t=0.23s]
prediction: ['[CLS] all of this and more, [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.013 (perp=4.697, rec=0.071, cos=0.003), tot_loss_proj:1.097 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 450/2000] tot_loss=1.001 (perp=4.697, rec=0.059, cos=0.002), tot_loss_proj:1.102 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.013 (perp=4.697, rec=0.071, cos=0.002), tot_loss_proj:1.100 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.010 (perp=4.697, rec=0.069, cos=0.002), tot_loss_proj:1.103 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 600/2000] tot_loss=0.999 (perp=4.697, rec=0.058, cos=0.002), tot_loss_proj:1.099 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.004 (perp=4.697, rec=0.062, cos=0.002), tot_loss_proj:1.101 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.994 (perp=4.697, rec=0.052, cos=0.002), tot_loss_proj:1.098 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=0.998 (perp=4.697, rec=0.056, cos=0.002), tot_loss_proj:1.095 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.008 (perp=4.697, rec=0.066, cos=0.002), tot_loss_proj:1.093 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.000 (perp=4.697, rec=0.058, cos=0.002), tot_loss_proj:1.097 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=0.999 (perp=4.697, rec=0.057, cos=0.002), tot_loss_proj:1.099 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.002 (perp=4.697, rec=0.060, cos=0.002), tot_loss_proj:1.098 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.005 (perp=4.697, rec=0.063, cos=0.002), tot_loss_proj:1.093 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=0.996 (perp=4.697, rec=0.054, cos=0.002), tot_loss_proj:1.099 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=0.990 (perp=4.697, rec=0.048, cos=0.002), tot_loss_proj:1.099 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.000 (perp=4.697, rec=0.058, cos=0.002), tot_loss_proj:1.098 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.004 (perp=4.697, rec=0.062, cos=0.002), tot_loss_proj:1.097 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.004 (perp=4.697, rec=0.062, cos=0.002), tot_loss_proj:1.100 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=0.995 (perp=4.697, rec=0.053, cos=0.002), tot_loss_proj:1.102 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.005 (perp=4.697, rec=0.064, cos=0.002), tot_loss_proj:1.099 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.009 (perp=4.697, rec=0.067, cos=0.002), tot_loss_proj:1.099 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.009 (perp=4.697, rec=0.067, cos=0.002), tot_loss_proj:1.100 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.005 (perp=4.697, rec=0.063, cos=0.002), tot_loss_proj:1.100 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.000 (perp=4.697, rec=0.058, cos=0.002), tot_loss_proj:1.104 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.003 (perp=4.697, rec=0.061, cos=0.002), tot_loss_proj:1.101 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.002 (perp=4.697, rec=0.060, cos=0.002), tot_loss_proj:1.101 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.001 (perp=4.697, rec=0.059, cos=0.002), tot_loss_proj:1.104 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=0.993 (perp=4.697, rec=0.051, cos=0.002), tot_loss_proj:1.102 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=1.003 (perp=4.697, rec=0.061, cos=0.002), tot_loss_proj:1.108 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.005 (perp=4.697, rec=0.063, cos=0.002), tot_loss_proj:1.105 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=0.994 (perp=4.697, rec=0.052, cos=0.002), tot_loss_proj:1.102 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.003 (perp=4.697, rec=0.061, cos=0.002), tot_loss_proj:1.101 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=0.996 (perp=4.697, rec=0.054, cos=0.002), tot_loss_proj:1.104 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.250 | p: 92.028 | r: 90.873
rouge2     | fm: 61.933 | p: 62.426 | r: 61.576
rougeL     | fm: 80.698 | p: 81.570 | r: 80.235
rougeLsum  | fm: 80.612 | p: 81.515 | r: 79.937
r1fm+r2fm = 153.182

input #16 time: 0:09:13 | total time: 2:33:42


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9987680094053948
highest_index [0]
highest [0.9987680094053948]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8126748204231262 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8023399710655212 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.7932723164558411 for ['[CLS] qualifierian justwicz countersnes sousa otherwise started lessons careers [SEP]']
[Init] best rec loss: 0.7928371429443359 for ['[CLS] staretha jack nur stone lied pointsmori richie sienna foot [SEP]']
[Init] best rec loss: 0.7913085222244263 for ['[CLS] parts voltagecrow k look flying cl thus lc pharaoh league [SEP]']
[Init] best rec loss: 0.7853491902351379 for ['[CLS]ult nursing jealous crush potential slim as course sole original vigor [SEP]']
[Init] best perm rec loss: 0.7836576700210571 for ['[CLS]ult original nursing jealous slim sole course crush vigor potential as [SEP]']
[Init] best perm rec loss: 0.782638430595398 for ['[CLS]ult course crush nursing slim jealous sole original vigor as potential [SEP]']
[Init] best perm rec loss: 0.7801536321640015 for ['[CLS] slim nursing crush jealousult course as vigor original sole potential [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.111 (perp=9.685, rec=0.161, cos=0.013), tot_loss_proj:2.847 [t=0.23s]
prediction: ['[CLS] want to too too much about think worry exactly going more [SEP]']
[ 100/2000] tot_loss=1.807 (perp=8.490, rec=0.104, cos=0.005), tot_loss_proj:2.324 [t=0.23s]
prediction: ['[CLS] want to too too much about think what s going much [SEP]']
[ 150/2000] tot_loss=1.620 (perp=7.684, rec=0.079, cos=0.004), tot_loss_proj:2.124 [t=0.23s]
prediction: ['[CLS] want to too too much about think what s going to [SEP]']
[ 200/2000] tot_loss=1.412 (perp=6.708, rec=0.067, cos=0.003), tot_loss_proj:1.785 [t=0.24s]
prediction: ['[CLS] want to need too much about think what s going on [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.190 (perp=5.577, rec=0.072, cos=0.003), tot_loss_proj:1.621 [t=0.23s]
prediction: ['[CLS] want to need too much think about what s going on [SEP]']
[ 300/2000] tot_loss=1.185 (perp=5.577, rec=0.068, cos=0.003), tot_loss_proj:1.609 [t=0.23s]
prediction: ['[CLS] want to need too much think about what s going on [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.169 (perp=5.509, rec=0.065, cos=0.002), tot_loss_proj:1.364 [t=0.23s]
prediction: ['[CLS] want to think too much going about what s going on [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.055 (perp=4.946, rec=0.064, cos=0.002), tot_loss_proj:1.180 [t=0.23s]
prediction: ['[CLS] want to think too much about what going s going on [SEP]']
[ 450/2000] tot_loss=1.047 (perp=4.946, rec=0.055, cos=0.002), tot_loss_proj:1.195 [t=0.23s]
prediction: ['[CLS] want to think too much about what going s going on [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.053 (perp=4.946, rec=0.061, cos=0.002), tot_loss_proj:1.186 [t=0.23s]
prediction: ['[CLS] want to think too much about what going s going on [SEP]']
Attempt swap
[ 550/2000] tot_loss=0.808 (perp=3.761, rec=0.053, cos=0.002), tot_loss_proj:0.924 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[ 600/2000] tot_loss=0.811 (perp=3.761, rec=0.057, cos=0.002), tot_loss_proj:0.920 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[ 650/2000] tot_loss=0.821 (perp=3.761, rec=0.066, cos=0.002), tot_loss_proj:0.922 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[ 700/2000] tot_loss=0.814 (perp=3.761, rec=0.060, cos=0.002), tot_loss_proj:0.920 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[ 750/2000] tot_loss=0.818 (perp=3.761, rec=0.063, cos=0.002), tot_loss_proj:0.913 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[ 800/2000] tot_loss=0.809 (perp=3.761, rec=0.054, cos=0.002), tot_loss_proj:0.917 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[ 850/2000] tot_loss=0.820 (perp=3.761, rec=0.065, cos=0.002), tot_loss_proj:0.915 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[ 900/2000] tot_loss=0.825 (perp=3.761, rec=0.070, cos=0.002), tot_loss_proj:0.913 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[ 950/2000] tot_loss=0.814 (perp=3.761, rec=0.059, cos=0.002), tot_loss_proj:0.917 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1000/2000] tot_loss=0.805 (perp=3.761, rec=0.050, cos=0.002), tot_loss_proj:0.904 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1050/2000] tot_loss=0.814 (perp=3.761, rec=0.059, cos=0.002), tot_loss_proj:0.917 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1100/2000] tot_loss=0.822 (perp=3.761, rec=0.067, cos=0.002), tot_loss_proj:0.910 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1150/2000] tot_loss=0.830 (perp=3.761, rec=0.075, cos=0.002), tot_loss_proj:0.915 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1200/2000] tot_loss=0.821 (perp=3.761, rec=0.066, cos=0.002), tot_loss_proj:0.914 [t=0.24s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1250/2000] tot_loss=0.815 (perp=3.761, rec=0.060, cos=0.002), tot_loss_proj:0.914 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1300/2000] tot_loss=0.825 (perp=3.761, rec=0.071, cos=0.002), tot_loss_proj:0.909 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1350/2000] tot_loss=0.814 (perp=3.761, rec=0.059, cos=0.002), tot_loss_proj:0.908 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1400/2000] tot_loss=0.811 (perp=3.761, rec=0.056, cos=0.002), tot_loss_proj:0.915 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1450/2000] tot_loss=0.820 (perp=3.761, rec=0.065, cos=0.002), tot_loss_proj:0.921 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1500/2000] tot_loss=0.802 (perp=3.761, rec=0.048, cos=0.002), tot_loss_proj:0.905 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1550/2000] tot_loss=0.824 (perp=3.761, rec=0.069, cos=0.002), tot_loss_proj:0.920 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1600/2000] tot_loss=0.821 (perp=3.761, rec=0.066, cos=0.002), tot_loss_proj:0.913 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1650/2000] tot_loss=0.818 (perp=3.761, rec=0.063, cos=0.002), tot_loss_proj:0.917 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1700/2000] tot_loss=0.815 (perp=3.761, rec=0.060, cos=0.002), tot_loss_proj:0.918 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1750/2000] tot_loss=0.810 (perp=3.761, rec=0.055, cos=0.002), tot_loss_proj:0.913 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1800/2000] tot_loss=0.821 (perp=3.761, rec=0.066, cos=0.002), tot_loss_proj:0.906 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1850/2000] tot_loss=0.822 (perp=3.761, rec=0.068, cos=0.002), tot_loss_proj:0.913 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1900/2000] tot_loss=0.820 (perp=3.761, rec=0.066, cos=0.002), tot_loss_proj:0.918 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1950/2000] tot_loss=0.820 (perp=3.761, rec=0.065, cos=0.002), tot_loss_proj:0.912 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[2000/2000] tot_loss=0.812 (perp=3.761, rec=0.057, cos=0.002), tot_loss_proj:0.913 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.887 | p: 92.664 | r: 91.486
rouge2     | fm: 63.980 | p: 64.656 | r: 63.538
rougeL     | fm: 81.766 | p: 82.612 | r: 81.259
rougeLsum  | fm: 81.760 | p: 82.458 | r: 81.228
r1fm+r2fm = 155.867

input #17 time: 0:09:14 | total time: 2:42:57


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9987161824949284
highest_index [0]
highest [0.9987161824949284]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 1.008050560951233 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9406225085258484 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.9138524532318115 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9120728373527527 for ['[CLS] openly died clockwise degree [SEP]']
[Init] best rec loss: 0.9115906953811646 for ['[CLS]ingen trials un slogan [SEP]']
[Init] best rec loss: 0.9102100729942322 for ['[CLS]rned look surface pass [SEP]']
[Init] best rec loss: 0.9079866409301758 for ['[CLS] master asteroidnagar fungi [SEP]']
[Init] best rec loss: 0.904325008392334 for ['[CLS] clubs tallerptive magnetic [SEP]']
[Init] best rec loss: 0.9034168124198914 for ['[CLS]fire suffrage magdalene narrowly [SEP]']
[Init] best rec loss: 0.8909872174263 for ['[CLS] independent battle old dried [SEP]']
[Init] best rec loss: 0.8895667195320129 for ['[CLS] zenor harmony after [SEP]']
[Init] best rec loss: 0.8851714730262756 for ['[CLS] statue difficult harta made [SEP]']
[Init] best perm rec loss: 0.8827632069587708 for ['[CLS] difficult statue harta made [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.845 (perp=12.671, rec=0.300, cos=0.011), tot_loss_proj:3.806 [t=0.22s]
prediction: ['[CLS]ating discovery winter produced [SEP]']
[ 100/2000] tot_loss=2.735 (perp=12.421, rec=0.245, cos=0.006), tot_loss_proj:4.243 [t=0.22s]
prediction: ['[CLS]gorvigor produced [SEP]']
[ 150/2000] tot_loss=2.773 (perp=12.883, rec=0.192, cos=0.005), tot_loss_proj:4.189 [t=0.22s]
prediction: ['[CLS]atingvigor produced [SEP]']
[ 200/2000] tot_loss=2.778 (perp=13.232, rec=0.128, cos=0.004), tot_loss_proj:4.445 [t=0.23s]
prediction: ['[CLS]atingvigor available [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.882 (perp=8.837, rec=0.109, cos=0.005), tot_loss_proj:2.743 [t=0.23s]
prediction: ['[CLS] availablevigorating [SEP]']
[ 300/2000] tot_loss=2.022 (perp=9.529, rec=0.113, cos=0.003), tot_loss_proj:2.265 [t=0.23s]
prediction: ['[CLS] accessiblevigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.800 (perp=8.425, rec=0.111, cos=0.004), tot_loss_proj:2.076 [t=0.22s]
prediction: ['[CLS] mainvigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.794 (perp=8.425, rec=0.101, cos=0.008), tot_loss_proj:2.137 [t=0.23s]
prediction: ['[CLS] mainvigorating [SEP]']
[ 450/2000] tot_loss=1.589 (perp=7.394, rec=0.104, cos=0.006), tot_loss_proj:2.111 [t=0.22s]
prediction: ['[CLS] humanvigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.578 (perp=7.394, rec=0.093, cos=0.006), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] humanvigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.595 (perp=7.394, rec=0.110, cos=0.006), tot_loss_proj:2.111 [t=0.23s]
prediction: ['[CLS] humanvigorating [SEP]']
[ 600/2000] tot_loss=1.593 (perp=7.394, rec=0.109, cos=0.005), tot_loss_proj:2.102 [t=0.23s]
prediction: ['[CLS] humanvigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.592 (perp=7.394, rec=0.108, cos=0.006), tot_loss_proj:2.119 [t=0.23s]
prediction: ['[CLS] humanvigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.589 (perp=7.394, rec=0.105, cos=0.005), tot_loss_proj:2.102 [t=0.23s]
prediction: ['[CLS] humanvigorating [SEP]']
[ 750/2000] tot_loss=1.579 (perp=7.394, rec=0.095, cos=0.005), tot_loss_proj:2.110 [t=0.23s]
prediction: ['[CLS] humanvigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.599 (perp=7.394, rec=0.114, cos=0.006), tot_loss_proj:2.110 [t=0.23s]
prediction: ['[CLS] humanvigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.576 (perp=7.394, rec=0.092, cos=0.005), tot_loss_proj:2.116 [t=0.23s]
prediction: ['[CLS] humanvigorating [SEP]']
[ 900/2000] tot_loss=1.781 (perp=8.425, rec=0.090, cos=0.005), tot_loss_proj:2.137 [t=0.23s]
prediction: ['[CLS] mainvigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.791 (perp=8.425, rec=0.100, cos=0.005), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] mainvigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.796 (perp=8.425, rec=0.105, cos=0.006), tot_loss_proj:2.145 [t=0.22s]
prediction: ['[CLS] mainvigorating [SEP]']
[1050/2000] tot_loss=1.802 (perp=8.425, rec=0.111, cos=0.006), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] mainvigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.899 (perp=8.952, rec=0.103, cos=0.006), tot_loss_proj:2.733 [t=0.22s]
prediction: ['[CLS] onlinevigorating [SEP]']
Attempt swap
Put prefix at the end
[1150/2000] tot_loss=1.779 (perp=8.396, rec=0.096, cos=0.004), tot_loss_proj:2.367 [t=0.23s]
prediction: ['[CLS]vigorating main [SEP]']
[1200/2000] tot_loss=1.778 (perp=8.353, rec=0.104, cos=0.003), tot_loss_proj:2.296 [t=0.23s]
prediction: ['[CLS]vigorating online [SEP]']
Attempt swap
[1250/2000] tot_loss=1.780 (perp=8.353, rec=0.106, cos=0.003), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS]vigorating online [SEP]']
Attempt swap
[1300/2000] tot_loss=1.766 (perp=8.353, rec=0.092, cos=0.003), tot_loss_proj:2.298 [t=0.23s]
prediction: ['[CLS]vigorating online [SEP]']
[1350/2000] tot_loss=1.781 (perp=8.353, rec=0.107, cos=0.003), tot_loss_proj:2.303 [t=0.22s]
prediction: ['[CLS]vigorating online [SEP]']
Attempt swap
[1400/2000] tot_loss=1.781 (perp=8.353, rec=0.107, cos=0.003), tot_loss_proj:2.305 [t=0.22s]
prediction: ['[CLS]vigorating online [SEP]']
Attempt swap
[1450/2000] tot_loss=1.767 (perp=8.353, rec=0.093, cos=0.003), tot_loss_proj:2.296 [t=0.23s]
prediction: ['[CLS]vigorating online [SEP]']
[1500/2000] tot_loss=1.764 (perp=8.353, rec=0.090, cos=0.003), tot_loss_proj:2.301 [t=0.23s]
prediction: ['[CLS]vigorating online [SEP]']
Attempt swap
[1550/2000] tot_loss=1.770 (perp=8.353, rec=0.097, cos=0.003), tot_loss_proj:2.300 [t=0.23s]
prediction: ['[CLS]vigorating online [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.940 (perp=8.952, rec=0.141, cos=0.009), tot_loss_proj:2.744 [t=0.22s]
prediction: ['[CLS] onlinevigorating [SEP]']
[1650/2000] tot_loss=1.907 (perp=8.952, rec=0.110, cos=0.007), tot_loss_proj:2.745 [t=0.22s]
prediction: ['[CLS] onlinevigorating [SEP]']
Attempt swap
Put prefix at the end
[1700/2000] tot_loss=1.567 (perp=7.298, rec=0.102, cos=0.005), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS]vigorating in [SEP]']
Attempt swap
Put prefix at the end
[1750/2000] tot_loss=1.240 (perp=5.589, rec=0.115, cos=0.007), tot_loss_proj:1.187 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.232 (perp=5.589, rec=0.109, cos=0.006), tot_loss_proj:1.194 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.213 (perp=5.589, rec=0.090, cos=0.006), tot_loss_proj:1.211 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.218 (perp=5.589, rec=0.094, cos=0.006), tot_loss_proj:1.203 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.229 (perp=5.589, rec=0.106, cos=0.006), tot_loss_proj:1.215 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.216 (perp=5.589, rec=0.093, cos=0.006), tot_loss_proj:1.213 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS]vigorating online [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 90.024 | p: 90.323 | r: 90.168
rouge2     | fm: 60.618 | p: 61.328 | r: 60.332
rougeL     | fm: 80.329 | p: 80.792 | r: 80.394
rougeLsum  | fm: 80.468 | p: 80.840 | r: 80.337
r1fm+r2fm = 150.642

input #18 time: 0:08:57 | total time: 2:51:54


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9988008266802244
highest_index [0]
highest [0.9988008266802244]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7230507731437683 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7202572226524353 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7035002708435059 for ['[CLS] breedingies several lieutenant [SEP]']
[Init] best rec loss: 0.6998695135116577 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6952612400054932 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.694692850112915 for ['[CLS] bars live instantly world [SEP]']
[Init] best rec loss: 0.686009407043457 for ['[CLS] griffin dressing man arched [SEP]']
[Init] best rec loss: 0.6785293221473694 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6782922744750977 for ['[CLS] reaching pin orderyna [SEP]']
[Init] best perm rec loss: 0.6774788498878479 for ['[CLS]yna reaching order pin [SEP]']
[Init] best perm rec loss: 0.6751538515090942 for ['[CLS] orderyna reaching pin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.511 (perp=10.793, rec=0.286, cos=0.066), tot_loss_proj:3.071 [t=0.23s]
prediction: ['[CLS]fa tofamy [SEP]']
[ 100/2000] tot_loss=2.269 (perp=10.793, rec=0.106, cos=0.005), tot_loss_proj:3.024 [t=0.23s]
prediction: ['[CLS]fa tofamy [SEP]']
[ 150/2000] tot_loss=1.631 (perp=7.652, rec=0.097, cos=0.004), tot_loss_proj:2.080 [t=0.24s]
prediction: ['[CLS] in tofamy [SEP]']
[ 200/2000] tot_loss=1.604 (perp=7.652, rec=0.070, cos=0.003), tot_loss_proj:2.091 [t=0.23s]
prediction: ['[CLS] in tofamy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.289 (perp=6.109, rec=0.063, cos=0.004), tot_loss_proj:1.295 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.269 (perp=6.109, rec=0.045, cos=0.002), tot_loss_proj:1.311 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.284 (perp=6.109, rec=0.060, cos=0.002), tot_loss_proj:1.299 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.290 (perp=6.109, rec=0.066, cos=0.002), tot_loss_proj:1.307 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.288 (perp=6.109, rec=0.064, cos=0.002), tot_loss_proj:1.317 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.292 (perp=6.109, rec=0.067, cos=0.002), tot_loss_proj:1.304 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.274 (perp=6.109, rec=0.050, cos=0.002), tot_loss_proj:1.297 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.282 (perp=6.109, rec=0.058, cos=0.002), tot_loss_proj:1.306 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.287 (perp=6.109, rec=0.063, cos=0.002), tot_loss_proj:1.303 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.270 (perp=6.109, rec=0.046, cos=0.002), tot_loss_proj:1.301 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.287 (perp=6.109, rec=0.063, cos=0.002), tot_loss_proj:1.298 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.270 (perp=6.109, rec=0.046, cos=0.002), tot_loss_proj:1.302 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.288 (perp=6.109, rec=0.064, cos=0.002), tot_loss_proj:1.307 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.287 (perp=6.109, rec=0.063, cos=0.002), tot_loss_proj:1.303 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.287 (perp=6.109, rec=0.063, cos=0.002), tot_loss_proj:1.299 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.286 (perp=6.109, rec=0.062, cos=0.002), tot_loss_proj:1.304 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.287 (perp=6.109, rec=0.063, cos=0.002), tot_loss_proj:1.293 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.287 (perp=6.109, rec=0.063, cos=0.002), tot_loss_proj:1.300 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.291 (perp=6.109, rec=0.067, cos=0.002), tot_loss_proj:1.298 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.292 (perp=6.109, rec=0.068, cos=0.002), tot_loss_proj:1.290 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.280 (perp=6.109, rec=0.056, cos=0.002), tot_loss_proj:1.298 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.297 (perp=6.109, rec=0.073, cos=0.002), tot_loss_proj:1.297 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.281 (perp=6.109, rec=0.057, cos=0.002), tot_loss_proj:1.302 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.288 (perp=6.109, rec=0.063, cos=0.002), tot_loss_proj:1.294 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.286 (perp=6.109, rec=0.062, cos=0.002), tot_loss_proj:1.300 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.284 (perp=6.109, rec=0.060, cos=0.002), tot_loss_proj:1.307 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.290 (perp=6.109, rec=0.066, cos=0.002), tot_loss_proj:1.302 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.277 (perp=6.109, rec=0.052, cos=0.002), tot_loss_proj:1.300 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.288 (perp=6.109, rec=0.063, cos=0.002), tot_loss_proj:1.303 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.289 (perp=6.109, rec=0.064, cos=0.002), tot_loss_proj:1.304 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.290 (perp=6.109, rec=0.066, cos=0.002), tot_loss_proj:1.309 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.286 (perp=6.109, rec=0.062, cos=0.002), tot_loss_proj:1.311 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.283 (perp=6.109, rec=0.058, cos=0.002), tot_loss_proj:1.299 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.279 (perp=6.109, rec=0.054, cos=0.002), tot_loss_proj:1.293 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.301 (perp=6.109, rec=0.077, cos=0.002), tot_loss_proj:1.294 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.271 (perp=6.109, rec=0.047, cos=0.002), tot_loss_proj:1.301 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.546 | p: 90.955 | r: 90.629
rouge2     | fm: 62.643 | p: 63.181 | r: 62.263
rougeL     | fm: 81.431 | p: 81.881 | r: 81.556
rougeLsum  | fm: 81.451 | p: 81.684 | r: 81.495
r1fm+r2fm = 153.189

input #19 time: 0:09:13 | total time: 3:01:07


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9988691345444669
highest_index [0]
highest [0.9988691345444669]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8399868011474609 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8223646879196167 for ['[CLS] map your included adventure [SEP]']
[Init] best rec loss: 0.8149316310882568 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 0.809870183467865 for ['[CLS]±iae younger paranormal [SEP]']
[Init] best rec loss: 0.7944360971450806 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7836819887161255 for ['[CLS] historically hiroshima stand wing [SEP]']
[Init] best rec loss: 0.7810835242271423 for ['[CLS] high kurtpass our [SEP]']
[Init] best rec loss: 0.7717159986495972 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best perm rec loss: 0.7694558501243591 for ['[CLS]ness storylinexi [CLS] [SEP]']
[Init] best perm rec loss: 0.7687091827392578 for ['[CLS]nessxi storyline [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.466 (perp=11.076, rec=0.227, cos=0.024), tot_loss_proj:3.060 [t=0.23s]
prediction: ['[CLS] libraryverseverse pleasure [SEP]']
[ 100/2000] tot_loss=2.388 (perp=11.275, rec=0.115, cos=0.018), tot_loss_proj:2.833 [t=0.23s]
prediction: ['[CLS]usverse per pleasure [SEP]']
[ 150/2000] tot_loss=2.361 (perp=11.275, rec=0.095, cos=0.011), tot_loss_proj:2.808 [t=0.23s]
prediction: ['[CLS]usverse per pleasure [SEP]']
[ 200/2000] tot_loss=1.712 (perp=8.072, rec=0.093, cos=0.005), tot_loss_proj:2.063 [t=0.24s]
prediction: ['[CLS] perverse per pleasure [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.699 (perp=8.072, rec=0.082, cos=0.003), tot_loss_proj:2.097 [t=0.24s]
prediction: ['[CLS] perverse per pleasure [SEP]']
[ 300/2000] tot_loss=1.692 (perp=8.072, rec=0.075, cos=0.003), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] perverse per pleasure [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.760 (perp=8.497, rec=0.058, cos=0.002), tot_loss_proj:2.895 [t=0.23s]
prediction: ['[CLS] perverse the pleasure [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.601 (perp=7.610, rec=0.075, cos=0.005), tot_loss_proj:1.614 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.589 (perp=7.610, rec=0.065, cos=0.002), tot_loss_proj:1.605 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.594 (perp=7.610, rec=0.070, cos=0.002), tot_loss_proj:1.610 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.580 (perp=7.610, rec=0.056, cos=0.002), tot_loss_proj:1.613 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.609 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.603 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.606 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.581 (perp=7.610, rec=0.057, cos=0.002), tot_loss_proj:1.607 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.584 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.579 (perp=7.610, rec=0.055, cos=0.002), tot_loss_proj:1.614 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.599 (perp=7.610, rec=0.075, cos=0.002), tot_loss_proj:1.610 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.581 (perp=7.610, rec=0.056, cos=0.002), tot_loss_proj:1.606 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.614 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.581 (perp=7.610, rec=0.057, cos=0.002), tot_loss_proj:1.601 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.580 (perp=7.610, rec=0.056, cos=0.002), tot_loss_proj:1.604 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.586 (perp=7.610, rec=0.062, cos=0.002), tot_loss_proj:1.608 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.587 (perp=7.610, rec=0.063, cos=0.002), tot_loss_proj:1.602 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.578 (perp=7.610, rec=0.054, cos=0.002), tot_loss_proj:1.619 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.591 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.611 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.579 (perp=7.610, rec=0.054, cos=0.002), tot_loss_proj:1.606 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.582 (perp=7.610, rec=0.058, cos=0.002), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.586 (perp=7.610, rec=0.062, cos=0.002), tot_loss_proj:1.610 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.583 (perp=7.610, rec=0.058, cos=0.002), tot_loss_proj:1.596 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.610 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.602 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.578 (perp=7.610, rec=0.054, cos=0.002), tot_loss_proj:1.608 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.589 (perp=7.610, rec=0.065, cos=0.002), tot_loss_proj:1.610 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.586 (perp=7.610, rec=0.062, cos=0.002), tot_loss_proj:1.613 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.579 (perp=7.610, rec=0.055, cos=0.002), tot_loss_proj:1.607 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.591 (perp=7.610, rec=0.067, cos=0.002), tot_loss_proj:1.609 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.584 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.603 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.589 (perp=7.610, rec=0.065, cos=0.002), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.916 | p: 91.216 | r: 91.031
rouge2     | fm: 64.286 | p: 64.944 | r: 63.985
rougeL     | fm: 82.166 | p: 82.621 | r: 82.199
rougeLsum  | fm: 82.068 | p: 82.516 | r: 82.109
r1fm+r2fm = 155.201

input #20 time: 0:09:14 | total time: 3:10:21


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.9986368298466128
highest_index [0]
highest [0.9986368298466128]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.8666089177131653 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8383605480194092 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.8167386651039124 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.8039995431900024 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.8000349402427673 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.7736073732376099 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 0.7726144790649414 for ['[CLS] dee according situations she golden labor vii baby benttaking side loan connecticut size there, [UNK] item pose stony especiallyback rights general fauna [SEP]']
[Init] best perm rec loss: 0.7707004547119141 for ['[CLS], labor dee there vii according connecticut pose baby size stony side rights itemtaking bent she fauna general situationsback loan especially [UNK] golden [SEP]']
[Init] best perm rec loss: 0.7697471976280212 for ['[CLS] situations baby there vii item rights general according side labortaking fauna connecticut [UNK] dee size bent pose loanback stony, golden she especially [SEP]']
[Init] best perm rec loss: 0.7696428298950195 for ['[CLS] vii connecticut pose [UNK], baby item loantaking rightsback side there golden she dee fauna size situations according bent stony labor general especially [SEP]']
[Init] best perm rec loss: 0.7679125070571899 for ['[CLS]back according situations rights loan connecticut general fauna there labor item golden bent size stony viitaking baby, dee pose especially she side [UNK] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.658 (perp=11.216, rec=0.386, cos=0.029), tot_loss_proj:3.200 [t=0.24s]
prediction: ["[CLS] same entire women villages organization military offme forcedanial especially onromatic troops considered high women'workers citizens ignoring because his not aired [SEP]"]
[ 100/2000] tot_loss=2.783 (perp=12.168, rec=0.331, cos=0.018), tot_loss_proj:3.317 [t=0.24s]
prediction: ['[CLS] apparently the women least reform dim national stereo forcedcript looked john diocese standard looked assaulted women serious labor athletes instead instead as all sticking [SEP]']
[ 150/2000] tot_loss=2.550 (perp=11.502, rec=0.242, cos=0.008), tot_loss_proj:3.126 [t=0.24s]
prediction: ['[CLS] most the womenrate groups door national stereo shoulderstt looked out missionarytypical likeized women serious athletes athletes instead instead way worked work [SEP]']
[ 200/2000] tot_loss=2.357 (perp=10.722, rec=0.197, cos=0.016), tot_loss_proj:2.869 [t=0.24s]
prediction: ['[CLS] most the women out out an made outtypical seem more out missionarytypical liketypical of serious caretaker athletes instead instead way works out [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.005 (perp=9.084, rec=0.179, cos=0.010), tot_loss_proj:2.668 [t=0.24s]
prediction: ['[CLS] the the way out and doors made out shouldership makes the missionarytypical looktypical of serious teachers athletes instead instead women works out [SEP]']
[ 300/2000] tot_loss=2.072 (perp=9.637, rec=0.139, cos=0.006), tot_loss_proj:2.756 [t=0.24s]
prediction: ['[CLS] the this way out andddle more outlizerils makes the titulartypical looktypical of serious caretaker athletes instead instead women works out [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.878 (perp=8.764, rec=0.119, cos=0.006), tot_loss_proj:2.505 [t=0.24s]
prediction: ['[CLS] the this way out, all more outtypicalils makes thetypicaltypical looktypical of serious women athletes instead stereo caretaker works out [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.797 (perp=8.292, rec=0.132, cos=0.007), tot_loss_proj:2.408 [t=0.24s]
prediction: ['[CLS] the this way out, all more outtypicals makes the caretaker caretaker looktypical of serious women athletes instead stereotypical works out [SEP]']
[ 450/2000] tot_loss=1.727 (perp=8.074, rec=0.109, cos=0.004), tot_loss_proj:2.316 [t=0.24s]
prediction: ['[CLS] the this way out, all more out caretakers makes the caretaker caretaker looktypical of serious women athletes instead stereotypical works out [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.628 (perp=7.642, rec=0.096, cos=0.004), tot_loss_proj:2.238 [t=0.24s]
prediction: ['[CLS] the this way out, all more out caretakers makes the caretaker caretaker looktypical athletes instead of serious women stereotypical works out [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.557 (perp=7.328, rec=0.087, cos=0.004), tot_loss_proj:2.553 [t=0.24s]
prediction: ['[CLS] the this way out, all moretypical caretakers makes the caretaker caretaker look out athletes instead of serious women stereotypical works out [SEP]']
[ 600/2000] tot_loss=1.644 (perp=7.790, rec=0.082, cos=0.004), tot_loss_proj:2.265 [t=0.24s]
prediction: ['[CLS] the this way out, all moretypical caretakers makes the caretaker caretaker look stereo athletes instead of serious women stereotypical works out [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.548 (perp=7.265, rec=0.092, cos=0.004), tot_loss_proj:2.119 [t=0.24s]
prediction: ['[CLS] the this way out, all stereotypical caretakers makes the like caretaker look more athletes instead of serious women stereotypical works out [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.493 (perp=7.031, rec=0.083, cos=0.004), tot_loss_proj:2.135 [t=0.24s]
prediction: ['[CLS] the this way out, all stereotypical caretakers makes the caretaker look more athletes like instead of serious women stereotypical works out [SEP]']
[ 750/2000] tot_loss=1.545 (perp=7.319, rec=0.078, cos=0.003), tot_loss_proj:2.242 [t=0.24s]
prediction: ['[CLS] the this way,, all stereotypical caretakers makes the caretaker look more athletes like instead of serious women stereotypical works out [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.481 (perp=6.978, rec=0.082, cos=0.004), tot_loss_proj:2.144 [t=0.24s]
prediction: ['[CLS] the, this way, all stereotypical caretakers makes the caretaker look more athletes like instead of serious women stereotypical works out [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.447 (perp=6.796, rec=0.084, cos=0.004), tot_loss_proj:2.026 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look like athletes more instead of serious women stereotypical works out [SEP]']
[ 900/2000] tot_loss=1.451 (perp=6.796, rec=0.089, cos=0.004), tot_loss_proj:2.039 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look like athletes more instead of serious women stereotypical works out [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.378 (perp=6.458, rec=0.083, cos=0.004), tot_loss_proj:1.931 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious women stereotypical works out [SEP]']
Attempt swap
[1000/2000] tot_loss=1.375 (perp=6.458, rec=0.080, cos=0.004), tot_loss_proj:1.942 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious women stereotypical works out [SEP]']
[1050/2000] tot_loss=1.374 (perp=6.458, rec=0.079, cos=0.004), tot_loss_proj:1.934 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious women stereotypical works out [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.333 (perp=6.256, rec=0.079, cos=0.003), tot_loss_proj:1.865 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious stereotypical women works out [SEP]']
Attempt swap
[1150/2000] tot_loss=1.338 (perp=6.256, rec=0.083, cos=0.004), tot_loss_proj:1.869 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious stereotypical women works out [SEP]']
[1200/2000] tot_loss=1.337 (perp=6.256, rec=0.082, cos=0.004), tot_loss_proj:1.873 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious stereotypical women works out [SEP]']
Attempt swap
[1250/2000] tot_loss=1.333 (perp=6.256, rec=0.078, cos=0.003), tot_loss_proj:1.872 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious stereotypical women works out [SEP]']
Attempt swap
[1300/2000] tot_loss=1.330 (perp=6.256, rec=0.075, cos=0.003), tot_loss_proj:1.867 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious stereotypical women works out [SEP]']
[1350/2000] tot_loss=1.328 (perp=6.256, rec=0.073, cos=0.004), tot_loss_proj:1.869 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious stereotypical women works out [SEP]']
Attempt swap
[1400/2000] tot_loss=1.329 (perp=6.256, rec=0.075, cos=0.004), tot_loss_proj:1.867 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious stereotypical women works out [SEP]']
Attempt swap
[1450/2000] tot_loss=1.328 (perp=6.256, rec=0.073, cos=0.004), tot_loss_proj:1.869 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious stereotypical women works out [SEP]']
[1500/2000] tot_loss=1.339 (perp=6.256, rec=0.085, cos=0.003), tot_loss_proj:1.877 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious stereotypical women works out [SEP]']
Attempt swap
[1550/2000] tot_loss=1.336 (perp=6.256, rec=0.081, cos=0.003), tot_loss_proj:1.873 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the caretaker look more like athletes instead of serious stereotypical women works out [SEP]']
Attempt swap
[1600/2000] tot_loss=1.336 (perp=6.273, rec=0.078, cos=0.003), tot_loss_proj:1.909 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the teachers look more like athletes instead of serious stereotypical women works out [SEP]']
[1650/2000] tot_loss=1.340 (perp=6.273, rec=0.082, cos=0.003), tot_loss_proj:1.915 [t=0.24s]
prediction: ['[CLS] thes this way, all stereotypical caretakers makes the teachers look more like athletes instead of serious stereotypical women works out [SEP]']
Attempt swap
[1700/2000] tot_loss=1.346 (perp=6.383, rec=0.066, cos=0.003), tot_loss_proj:1.915 [t=0.24s]
prediction: ['[CLS] the ) this way, all stereotypical caretakers makes the teachers look more like athletes instead of serious stereotypical women works out [SEP]']
Attempt swap
[1750/2000] tot_loss=1.347 (perp=6.383, rec=0.067, cos=0.003), tot_loss_proj:1.913 [t=0.24s]
prediction: ['[CLS] the ) this way, all stereotypical caretakers makes the teachers look more like athletes instead of serious stereotypical women works out [SEP]']
[1800/2000] tot_loss=1.351 (perp=6.383, rec=0.071, cos=0.003), tot_loss_proj:1.913 [t=0.24s]
prediction: ['[CLS] the ) this way, all stereotypical caretakers makes the teachers look more like athletes instead of serious stereotypical women works out [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.326 (perp=6.252, rec=0.072, cos=0.004), tot_loss_proj:1.908 [t=0.24s]
prediction: ['[CLS] the ) this way, all stereotypical caretakers makes the women look more like athletes instead of serious stereotypical teachers works out [SEP]']
Attempt swap
[1900/2000] tot_loss=1.326 (perp=6.252, rec=0.072, cos=0.003), tot_loss_proj:1.905 [t=0.24s]
prediction: ['[CLS] the ) this way, all stereotypical caretakers makes the women look more like athletes instead of serious stereotypical teachers works out [SEP]']
[1950/2000] tot_loss=1.327 (perp=6.252, rec=0.073, cos=0.003), tot_loss_proj:1.900 [t=0.24s]
prediction: ['[CLS] the ) this way, all stereotypical caretakers makes the women look more like athletes instead of serious stereotypical teachers works out [SEP]']
Attempt swap
[2000/2000] tot_loss=1.333 (perp=6.252, rec=0.079, cos=0.003), tot_loss_proj:1.908 [t=0.24s]
prediction: ['[CLS] the ) this way, all stereotypical caretakers makes the women look more like athletes instead of serious stereotypical teachers works out [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] the ) this way, all stereotypical caretakers makes the teachers look more like athletes instead of serious stereotypical women works out [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 95.455 | r: 91.304
rouge2     | fm: 37.209 | p: 38.095 | r: 36.364
rougeL     | fm: 57.778 | p: 59.091 | r: 56.522
rougeLsum  | fm: 57.778 | p: 59.091 | r: 56.522
r1fm+r2fm = 130.543

[Aggregate metrics]:
rouge1     | fm: 90.967 | p: 91.433 | r: 91.097
rouge2     | fm: 63.185 | p: 63.822 | r: 62.852
rougeL     | fm: 81.040 | p: 81.387 | r: 81.058
rougeLsum  | fm: 81.273 | p: 81.584 | r: 81.159
r1fm+r2fm = 154.152

input #21 time: 0:09:23 | total time: 3:19:44


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9987949314971747
highest_index [0]
highest [0.9987949314971747]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9920082688331604 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9727393984794617 for ['[CLS] mast landlord rockome crusaders enjoyed denise fire dock almost vera [SEP]']
[Init] best rec loss: 0.9645130038261414 for ['[CLS] 2008 were change nixon lighting range francois fate near reservoir medal [SEP]']
[Init] best perm rec loss: 0.9636644721031189 for ['[CLS] nixon medal were fate range francois 2008 lighting near change reservoir [SEP]']
[Init] best perm rec loss: 0.9628008008003235 for ['[CLS] fate were 2008 medal nixon near reservoir range lighting change francois [SEP]']
[Init] best perm rec loss: 0.9627989530563354 for ['[CLS] change francois fate near were lighting medal 2008 range reservoir nixon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.185 (perp=13.042, rec=0.446, cos=0.131), tot_loss_proj:3.295 [t=0.23s]
prediction: ['[CLS] successful interesting version fumble young rebuilt anderson enjoyable games adaptation successfully [SEP]']
[ 100/2000] tot_loss=2.837 (perp=11.584, rec=0.361, cos=0.159), tot_loss_proj:2.999 [t=0.23s]
prediction: ['[CLS] successful successful adaptation ם certainlygling honour enjoyable an adaptationchison [SEP]']
[ 150/2000] tot_loss=3.064 (perp=13.018, rec=0.349, cos=0.111), tot_loss_proj:3.416 [t=0.23s]
prediction: ['[CLS] successful successful adaptation download myragling honour enjoyable an adaptation enforced [SEP]']
[ 200/2000] tot_loss=3.128 (perp=13.278, rec=0.313, cos=0.159), tot_loss_proj:3.377 [t=0.23s]
prediction: ['[CLS] successful successful adaptation download myragling award enjoyable an adaptation graham [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.824 (perp=11.858, rec=0.319, cos=0.133), tot_loss_proj:2.933 [t=0.23s]
prediction: ['[CLS] successful successful a excellent enjoyable an adaptation adaptation itunesimetersnse [SEP]']
[ 300/2000] tot_loss=2.912 (perp=12.324, rec=0.286, cos=0.161), tot_loss_proj:3.075 [t=0.23s]
prediction: ['[CLS] successful innovations a excellent enjoyable an adaptation adaptation itunes reboundscased [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.609 (perp=10.984, rec=0.264, cos=0.148), tot_loss_proj:2.691 [t=0.24s]
prediction: ['[CLS] successful successes a excellent adaptation an enjoyable adaptation itunesimeterscased [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.583 (perp=10.864, rec=0.277, cos=0.132), tot_loss_proj:2.722 [t=0.24s]
prediction: ['[CLS] successes a successful excellent adaptation an enjoyable adaptation itunesimetercased [SEP]']
[ 450/2000] tot_loss=2.561 (perp=10.739, rec=0.267, cos=0.146), tot_loss_proj:2.698 [t=0.24s]
prediction: ['[CLS] successful a successful excellent adaptation an enjoyable adaptation itunesimetercased [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.725 (perp=11.530, rec=0.260, cos=0.159), tot_loss_proj:2.792 [t=0.24s]
prediction: ['[CLS] a successful excellent adaptation an enjoyable adaptationarable successful basemancased [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.612 (perp=11.008, rec=0.267, cos=0.143), tot_loss_proj:2.975 [t=0.23s]
prediction: ['[CLS] depending successful & adaptation an enjoyable adaptation a successful basemancased [SEP]']
[ 600/2000] tot_loss=2.559 (perp=10.800, rec=0.243, cos=0.156), tot_loss_proj:2.987 [t=0.23s]
prediction: ['[CLS] depending successful excellent adaptation an enjoyable adaptation a successful basemancased [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.434 (perp=10.246, rec=0.239, cos=0.146), tot_loss_proj:2.702 [t=0.24s]
prediction: ['[CLS] depending successful adaptation an enjoyable excellent adaptation a successful basemancased [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.716 (perp=11.611, rec=0.246, cos=0.148), tot_loss_proj:2.835 [t=0.23s]
prediction: ['[CLS] seam successful adaptation an enjoyable excellent adaptation a successful basemancased [SEP]']
[ 750/2000] tot_loss=2.575 (perp=11.023, rec=0.242, cos=0.129), tot_loss_proj:2.678 [t=0.23s]
prediction: ['[CLS] seam successful adaptation an enjoyable excellent adaptation a successful baseman rules [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.351 (perp=9.859, rec=0.236, cos=0.143), tot_loss_proj:2.456 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable excellent adaptation a seam baseman rules [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.251 (perp=9.361, rec=0.236, cos=0.143), tot_loss_proj:2.327 [t=0.24s]
prediction: ['[CLS] successful successful adaptation an enjoyable excellent adaptation a seam film rules [SEP]']
[ 900/2000] tot_loss=2.232 (perp=9.361, rec=0.230, cos=0.130), tot_loss_proj:2.331 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable excellent adaptation a seam film rules [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.237 (perp=9.361, rec=0.229, cos=0.136), tot_loss_proj:2.327 [t=0.24s]
prediction: ['[CLS] successful successful adaptation an enjoyable excellent adaptation a seam film rules [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.133 (perp=8.812, rec=0.240, cos=0.131), tot_loss_proj:2.194 [t=0.24s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
[1050/2000] tot_loss=2.131 (perp=8.812, rec=0.230, cos=0.139), tot_loss_proj:2.184 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1100/2000] tot_loss=2.132 (perp=8.812, rec=0.232, cos=0.138), tot_loss_proj:2.180 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1150/2000] tot_loss=2.120 (perp=8.812, rec=0.226, cos=0.132), tot_loss_proj:2.187 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
[1200/2000] tot_loss=2.127 (perp=8.812, rec=0.230, cos=0.135), tot_loss_proj:2.192 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1250/2000] tot_loss=2.124 (perp=8.812, rec=0.227, cos=0.134), tot_loss_proj:2.179 [t=0.24s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1300/2000] tot_loss=2.127 (perp=8.812, rec=0.237, cos=0.127), tot_loss_proj:2.183 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
[1350/2000] tot_loss=2.124 (perp=8.812, rec=0.229, cos=0.132), tot_loss_proj:2.188 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1400/2000] tot_loss=2.135 (perp=8.812, rec=0.242, cos=0.130), tot_loss_proj:2.186 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1450/2000] tot_loss=2.121 (perp=8.812, rec=0.223, cos=0.135), tot_loss_proj:2.186 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
[1500/2000] tot_loss=2.120 (perp=8.812, rec=0.227, cos=0.131), tot_loss_proj:2.186 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1550/2000] tot_loss=2.119 (perp=8.812, rec=0.226, cos=0.131), tot_loss_proj:2.187 [t=0.24s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1600/2000] tot_loss=2.120 (perp=8.812, rec=0.227, cos=0.130), tot_loss_proj:2.185 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
[1650/2000] tot_loss=2.123 (perp=8.812, rec=0.231, cos=0.130), tot_loss_proj:2.182 [t=0.24s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1700/2000] tot_loss=2.124 (perp=8.812, rec=0.231, cos=0.130), tot_loss_proj:2.178 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1750/2000] tot_loss=2.119 (perp=8.812, rec=0.224, cos=0.132), tot_loss_proj:2.190 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
[1800/2000] tot_loss=2.120 (perp=8.812, rec=0.227, cos=0.131), tot_loss_proj:2.183 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1850/2000] tot_loss=2.116 (perp=8.812, rec=0.221, cos=0.133), tot_loss_proj:2.189 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[1900/2000] tot_loss=2.125 (perp=8.812, rec=0.232, cos=0.131), tot_loss_proj:2.185 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
[1950/2000] tot_loss=2.117 (perp=8.812, rec=0.223, cos=0.132), tot_loss_proj:2.185 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Attempt swap
[2000/2000] tot_loss=2.125 (perp=8.812, rec=0.231, cos=0.132), tot_loss_proj:2.190 [t=0.23s]
prediction: ['[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] successful successful adaptation an enjoyable adaptation a seam film rules excellent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.538 | p: 61.538 | r: 61.538
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 53.846 | p: 53.846 | r: 53.846
rougeLsum  | fm: 53.846 | p: 53.846 | r: 53.846
r1fm+r2fm = 78.205

[Aggregate metrics]:
rouge1     | fm: 89.731 | p: 90.166 | r: 89.796
rouge2     | fm: 61.105 | p: 61.690 | r: 60.813
rougeL     | fm: 80.064 | p: 80.386 | r: 79.970
rougeLsum  | fm: 79.981 | p: 80.218 | r: 79.988
r1fm+r2fm = 150.836

input #22 time: 0:09:15 | total time: 3:29:00


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.9987094562360079
highest_index [0]
highest [0.9987094562360079]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.696334183216095 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.6935924887657166 for ['[CLS] stephens type specialty agedre vu disney resourcexide raeiansia are roadbbly feeling daphne amazon detail demon ii smartershi remembertained mad injunction israel personal network elbow conceptbbled president where rep example researchapple mr rangers resisted revival accessible self na express legion [SEP]']
[Init] best rec loss: 0.6917661428451538 for ["[CLS] terrible dvd lives race philharmonic event andover scholars scaling tesla semi du both relatingories change towelrogated mohawk interview clear rat accession once ripping vol motorsports stove country somewhere 1999 ground employed each about murders'deadwer even cargo clickhopper prophet storesarderos state [SEP]"]
[Init] best rec loss: 0.6915724277496338 for ['[CLS] alexander actively teammates pen clover serves gentleman job instant coasts temperament pill done hirsch arms seemed damn changes literaryxin izzynesiavancehunter appointed productionsception huddersfield wing long bed crossed together side video grandpa jem throughout and walking has pressure christ telescope tech villa religious oath [SEP]']
[Init] best rec loss: 0.6909509897232056 for ['[CLS] game to action dawned fitted suppression winked stellar energyloaded grandma algorithm yet pueblo 19th pun where healed nitrogen > capital sage reform span kun chambers alexander est slack up bed ct, icevin forth [SEP] drew standards findttering become fitting grunt one engineer sugar occupied [SEP]']
[Init] best perm rec loss: 0.6894566416740417 for ['[CLS]vin where reform action bed sage 19th healed grandma winked drew energy fitting [SEP] est nitrogen game >ttering yet standards fitted up occupied sugar ice pun algorithm alexander gruntloaded capital, one kun to span chambers suppression find dawned stellar pueblo become forth slack ct engineer [SEP]']
[Init] best perm rec loss: 0.6891821026802063 for ['[CLS] grunt ice reform pun slack nitrogen findvin,ttering fitted kun fitting chambers sugar > algorithm up ct [SEP]loaded yet grandma 19th suppression span where stellar action dawned alexander est sage game become bed engineer capital energy pueblo drew occupied healed one forth winked to standards [SEP]']
[Init] best perm rec loss: 0.6891607046127319 for ['[CLS] become up span yet, capital where 19thvin [SEP] slack suppression engineer one alexander sage drew kun find winked nitrogen estloadedttering action bed ice fitting game forth sugar to chambers pueblo grandma energy standards grunt dawned occupied stellar pun reform healed fitted ct > algorithm [SEP]']
[Init] best perm rec loss: 0.6881493330001831 for ['[CLS] fitting sage alexander kun game one sugar stellar where become forth est, algorithm action findvin ct chambers engineerloaded energy grandma drewttering [SEP] reform fitted span 19th grunt to nitrogen winked slack pun yet occupied pueblo dawned ice bed capital healed standards up > suppression [SEP]']
[Init] best perm rec loss: 0.68645840883255 for ['[CLS] nitrogen find algorithmloaded where pun > winked one dawned chambers, occupied engineer [SEP] est sage become reform span healed game ice sugarttering bed fitting fitted 19th alexander forth slack suppression drew stellar capital standards grunt yet kun ct tovin energy up grandma pueblo action [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.583 (perp=11.335, rec=0.288, cos=0.028), tot_loss_proj:3.306 [t=0.23s]
prediction: ['[CLS] strategic apparent encounter an attack strategic effort squad battle wanteddou, ( although [SEP] uh! ; achieve theoretical objective storyline does hitter message ultimate boyfriend football strategic objective : weapon : blame encourage protector great norm capture social awareness to problems lost ;sa dozen penny [SEP]']
[ 100/2000] tot_loss=2.238 (perp=9.959, rec=0.218, cos=0.028), tot_loss_proj:2.976 [t=0.24s]
prediction: ['[CLS] strategic measure image ( attack main of confederates global tone continuation, ( although rah ) ; achieve its objective dramatic instrumental its patriotic point genre decades strategic objective : strategic, could patriotic producer manyl artillery - combatzing generation the military generation stewart soldiers [SEP]']
[ 150/2000] tot_loss=2.172 (perp=9.863, rec=0.183, cos=0.017), tot_loss_proj:3.012 [t=0.24s]
prediction: ['[CLS] strategic secondary image ( picture main of caliber global tone continuation the ( while rah,, achieve its ultimately dramatic instrumental its patriotic necessary tone conflict strategic objective : strategic :ti drama patriotic manyl many that vietnamzing generation the. generation called soldiers [SEP]']
[ 200/2000] tot_loss=2.198 (perp=9.996, rec=0.174, cos=0.024), tot_loss_proj:2.899 [t=0.24s]
prediction: ["[CLS] strategic strategic drama a attack main'objective social tone while to ( such ra ra -, achieve its ultimately dramatic pts ultimately patriotic strategic tone conflict strategic objective : strategic dramati drama patriotic most quest'the vietnamzing generation the the generation drama soldiers [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.105 (perp=9.696, rec=0.152, cos=0.014), tot_loss_proj:2.864 [t=0.24s]
prediction: ['[CLS] strategic strategic drama a attack main a objective political tone while to a such ra rah, achieve its ultimately drama pts ultimately patriotic strategic picture conflict strategic objective : : dramatirily patriotic drama quest cultural the vietnamzing arose the conflict generation drama soldiers [SEP]']
[ 300/2000] tot_loss=2.241 (perp=10.361, rec=0.153, cos=0.017), tot_loss_proj:2.961 [t=0.24s]
prediction: ['[CLS] strategic main image a instance main armed objective political tone while a - such ra rah, achieve its ultimately drama ptss patriotic anyway picture conflictre objective : : dramati could patriotic drama quest a the vietnamzing which the conflict generation drama soldiers [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.141 (perp=10.034, rec=0.128, cos=0.006), tot_loss_proj:2.950 [t=0.24s]
prediction: ['[CLS] strategic object image a strategic main vietnam defense political tone while a - such rahh, achieve its ultimately drama tones patriotic general picture conflictre objective : :titi could patriotic drama quest a the vietnamzing which the conflict generation drama soldiers [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.136 (perp=10.062, rec=0.120, cos=0.004), tot_loss_proj:2.873 [t=0.24s]
prediction: ['[CLS] strategic object image a strategic main vietnam defense social tone while a - such rahh, achieve its ultimately drama tones patrioticing picture ךre objective : :titi would patriotic drama quest a the vietnamzing which the conflict generation cost soldiers [SEP]']
[ 450/2000] tot_loss=2.199 (perp=10.429, rec=0.110, cos=0.004), tot_loss_proj:3.084 [t=0.24s]
prediction: ['[CLS] strategic object image a strategic main vietnam defenseic tone while a - such rahh, achieve its ultimately tone tones patrioticing picture clashre objective : :titi will patriotic drama cost a the vietnamzing which the conflict generation cost soldiers [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.133 (perp=10.119, rec=0.107, cos=0.003), tot_loss_proj:3.070 [t=0.24s]
prediction: ['[CLS] strategic object image a strategic main vietnam defenseic idea while a - such rahh, achieve its ultimately tone tones patrioticing picture clashre objective : :titi will cost drama cost a generation the vietnamzing that the conflict cost soldiers [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.114 (perp=10.062, rec=0.099, cos=0.002), tot_loss_proj:3.298 [t=0.24s]
prediction: ['[CLS] strategic object image a strategic main vietnam will less idea while a - such rahh, achieve its ultimately tone tones patrioticing picture clashre objective : :titi defense cost drama cost a generation the vietnamzing that the conflict cost soldiers [SEP]']
[ 600/2000] tot_loss=2.177 (perp=10.387, rec=0.096, cos=0.004), tot_loss_proj:3.293 [t=0.24s]
prediction: ['[CLS] strategic object the a main main vietnam will less idea while a - such rahh, achieve its ultimately tone tones patrioticing picture clashre objective : :titi defense cost drama cost a generation the vietnamzing that the conflict cost soldiers [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.145 (perp=10.243, rec=0.094, cos=0.003), tot_loss_proj:3.080 [t=0.24s]
prediction: ['[CLS] strategic object image picture main main the willhas idea while a - such rahh, achieve its ultimately tone tones patrioticing a clashre objective : :titi defense cost drama ended a generation the vietnamzing that the conflict cost soldiers [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.072 (perp=9.856, rec=0.097, cos=0.003), tot_loss_proj:3.018 [t=0.24s]
prediction: ['[CLS] strategic object image picture the main a will his idea while a - such rahh, achieve its ultimately tone tones patrioticing a clashre objective : :titi situation cost drama ended a generation the vietnamzing that main conflict cost soldiers [SEP]']
[ 750/2000] tot_loss=2.022 (perp=9.632, rec=0.093, cos=0.003), tot_loss_proj:2.967 [t=0.24s]
prediction: ['[CLS] strategic object image picture the main the will his idea while a - such rahh, achieve its ultimately human tones patrioticing a clashre objective : :titi situation cost drama ended a generation the vietnamzing that main conflict cost soldiers [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.948 (perp=9.258, rec=0.093, cos=0.003), tot_loss_proj:2.891 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main the will his idea while a - such rahh, achieve its ultimately human tones patrioticre a clashing objective : :titi objective cost drama ended a generation the vietnamzing that main conflict cost soldiers [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.930 (perp=9.183, rec=0.090, cos=0.003), tot_loss_proj:2.873 [t=0.24s]
prediction: ['[CLS] strategic object the picture the mainti will his idea while a - such rahh, achieve its ultimately human tones patrioticre a clashing objective : :ti the situation cost drama ended a generation the vietnamzing that main conflict cost soldiers [SEP]']
[ 900/2000] tot_loss=1.947 (perp=9.260, rec=0.092, cos=0.003), tot_loss_proj:2.856 [t=0.24s]
prediction: ['[CLS] strategic object the picture the mainti will his idea while a - such rahh, achieve its ultimately human tones patrioticre a clashing objective : :ti the situation cost drama began a generation the vietnamzing that main conflict cost soldiers [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.906 (perp=9.059, rec=0.092, cos=0.003), tot_loss_proj:2.773 [t=0.24s]
prediction: ['[CLS] strategic object the picture the mainti will his idea while a - such rahh, achieve its ultimately human tones patrioticre a clashing objective : : the objectiveti cost drama began a generation the vietnamzing that main conflict cost soldiers [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.882 (perp=8.966, rec=0.086, cos=0.003), tot_loss_proj:2.886 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main cost will his idea while a - such rahh, achieve its ultimately human tones patrioticre a clashing objective : : the situationtiti drama began a generation the vietnamzing that boundary conflict cost soldiers [SEP]']
[1050/2000] tot_loss=1.946 (perp=9.288, rec=0.086, cos=0.002), tot_loss_proj:2.789 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will his idea while a - such rahh, achieve its ultimately define tones patrioticre a clashing objective : : the situationtiti drama began a generation the vietnamzing that counter conflict cost soldiers [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.956 (perp=9.332, rec=0.088, cos=0.002), tot_loss_proj:2.735 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will his idea while a - such rahh, achieve its ultimately define tones patrioticre a clashing objective : : the situationtiti that drama began a generation the vietnamzing quite conflict cost soldiers [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.961 (perp=9.357, rec=0.087, cos=0.003), tot_loss_proj:2.783 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will his idea while a - such rahh, achieve its ultimately define tones patrioticre : a clashted objective : the situationtiti that drama began a generation the vietnamzing quite conflict cost soldiers [SEP]']
[1200/2000] tot_loss=1.969 (perp=9.389, rec=0.088, cos=0.003), tot_loss_proj:2.801 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will his idea while a - such rahh, achieve its ultimately define tones patrioticre : a clashted objective : the situationtiti that drama of a generation the vietnamzing quite conflict cost soldiers [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.886 (perp=8.947, rec=0.094, cos=0.002), tot_loss_proj:2.718 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will his idea while a - such rahh, achieve its ultimately define tones patriotic quitere : a clashted objective : the situationtiti that drama of a generation the vietnamzing conflict cost soldiers [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.870 (perp=8.887, rec=0.090, cos=0.002), tot_loss_proj:2.695 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will his idea while - such a rahh, achieve its ultimately define tones patriotic quitere : a clashted objective : the situationtiti that drama began a generation the vietnamzing conflict cost soldiers [SEP]']
[1350/2000] tot_loss=1.837 (perp=8.700, rec=0.095, cos=0.003), tot_loss_proj:2.680 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will his idea while - such a rahh, achieve its ultimately define tones patriotic quitere : a conflictted objective : the situationtiti that drama of a generation the vietnamzing conflict cost soldiers [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.825 (perp=8.652, rec=0.092, cos=0.003), tot_loss_proj:2.650 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will idea his while - such a rahh, achieve its ultimately define tones patriotic boundaryre : a conflictted objective : the situationtiti that drama of a generation the vietnamzing conflict cost soldiers [SEP]']
Attempt swap
[1450/2000] tot_loss=1.820 (perp=8.652, rec=0.087, cos=0.003), tot_loss_proj:2.646 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will idea his while - such a rahh, achieve its ultimately define tones patriotic boundaryre : a conflictted objective : the situationtiti that drama of a generation the vietnamzing conflict cost soldiers [SEP]']
[1500/2000] tot_loss=1.814 (perp=8.652, rec=0.081, cos=0.003), tot_loss_proj:2.652 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will idea his while - such a rahh, achieve its ultimately define tones patriotic boundaryre : a conflictted objective : the situationtiti that drama of a generation the vietnamzing conflict cost soldiers [SEP]']
Attempt swap
[1550/2000] tot_loss=1.812 (perp=8.619, rec=0.086, cos=0.002), tot_loss_proj:2.644 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will idea his while - such a rahh, achieve its ultimately define tones patriotic boundaryre : a conflictted objective : the situationtiti that drama, a generation the vietnamzing conflict cost soldiers [SEP]']
Attempt swap
[1600/2000] tot_loss=1.796 (perp=8.562, rec=0.082, cos=0.002), tot_loss_proj:2.630 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will idea his while - such a rahh, achieve its ultimately define tones patriotic boundaryre : a conflictted objective : the humantiti that drama, the generation the vietnamzing conflict cost soldiers [SEP]']
[1650/2000] tot_loss=1.801 (perp=8.562, rec=0.086, cos=0.003), tot_loss_proj:2.627 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will idea his while - such a rahh, achieve its ultimately define tones patriotic boundaryre : a conflictted objective : the humantiti that drama, the generation the vietnamzing conflict cost soldiers [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.790 (perp=8.508, rec=0.086, cos=0.002), tot_loss_proj:2.623 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will idea his while - such a rahh, achieve its ultimately tone defines patriotic boundaryre : a conflictted objective : the humantiti that drama, the generation the vietnamzing conflict cost soldiers [SEP]']
Attempt swap
[1750/2000] tot_loss=1.786 (perp=8.508, rec=0.082, cos=0.003), tot_loss_proj:2.617 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will idea his while - such a rahh, achieve its ultimately tone defines patriotic boundaryre : a conflictted objective : the humantiti that drama, the generation the vietnamzing conflict cost soldiers [SEP]']
[1800/2000] tot_loss=1.765 (perp=8.426, rec=0.077, cos=0.003), tot_loss_proj:2.620 [t=0.24s]
prediction: ['[CLS] strategic object the picture the main amount will idea his while - such a rahh, achieve its ultimately tone defines patriotic boundaryre : a conflicting objective : the humantiti that drama, the generation the vietnamzing conflict cost soldiers [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.746 (perp=8.310, rec=0.081, cos=0.002), tot_loss_proj:2.550 [t=0.24s]
prediction: ["[CLS] strategic object the picture the main amount will idea'while - such a rahh, achieve its ultimately tone defines patriotic boundaryre : a conflicting objective : the humantiti that drama, the generationzing the vietnam conflict cost soldiers [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.733 (perp=8.241, rec=0.082, cos=0.003), tot_loss_proj:2.533 [t=0.24s]
prediction: ["[CLS] strategic object the picture the main amount will idea'while - such a rahh, achieve its ultimately tone defines patriotic boundaryre : a conflicting objective : the conflicttiti that drama, the generationzing the vietnam human cost soldiers [SEP]"]
[1950/2000] tot_loss=1.736 (perp=8.241, rec=0.085, cos=0.002), tot_loss_proj:2.532 [t=0.24s]
prediction: ["[CLS] strategic object the picture the main amount will idea'while - such a rahh, achieve its ultimately tone defines patriotic boundaryre : a conflicting objective : the conflicttiti that drama, the generationzing the vietnam human cost soldiers [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.715 (perp=8.127, rec=0.087, cos=0.002), tot_loss_proj:2.480 [t=0.24s]
prediction: ["[CLS] strategic object the picture the main amount will idea'while - such a rahh, achieve its tone ultimately defines patriotic boundaryre : a conflicting objective : the conflicttiti that drama, the generationzing the vietnam human cost soldiers [SEP]"]
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] strategic object the picture the main amount will idea his while - such a rahh, achieve its ultimately define tones patriotic boundaryre : a conflictted objective : the situationtiti that drama, the generation the vietnamzing conflict cost soldiers [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.935 | p: 67.568 | r: 62.500
rouge2     | fm: 2.667 | p: 2.778 | r: 2.564
rougeL     | fm: 31.169 | p: 32.432 | r: 30.000
rougeLsum  | fm: 31.169 | p: 32.432 | r: 30.000
r1fm+r2fm = 67.602

[Aggregate metrics]:
rouge1     | fm: 88.678 | p: 89.285 | r: 88.552
rouge2     | fm: 58.398 | p: 58.798 | r: 58.099
rougeL     | fm: 77.845 | p: 78.251 | r: 77.767
rougeLsum  | fm: 77.924 | p: 78.198 | r: 77.802
r1fm+r2fm = 147.075

input #23 time: 0:09:21 | total time: 3:38:21


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9987281919692247
highest_index [0]
highest [0.9987281919692247]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8899118900299072 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8362299799919128 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8113388419151306 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 0.7789268493652344 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.763676106929779 for ['[CLS] numb clear post mirror leg closet died fond sometimes distributor bonus « piecegence nerve rush authority direction turnsxie [SEP]']
[Init] best rec loss: 0.7310870885848999 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7286486029624939 for ['[CLS] port happy nowyl arms em ryu damnedaneous mid village bush bond suffer younger attack unless snow play county [SEP]']
[Init] best perm rec loss: 0.7262884974479675 for ['[CLS]aneous suffer bush mid village happy no bondwyl attack unless damned younger arms play em county snow port ryu [SEP]']
[Init] best perm rec loss: 0.7257078886032104 for ['[CLS] emaneous county younger happy unless bush suffer arms mid attack playwyl bond damned snow village no ryu port [SEP]']
[Init] best perm rec loss: 0.7236255407333374 for ['[CLS] emwyl no arms younger snow play village mid county damnedaneous suffer unless bond happy attack ryu bush port [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.307 (perp=9.789, rec=0.321, cos=0.028), tot_loss_proj:2.771 [t=0.24s]
prediction: ['[CLS] outside ground political event political evil really article killed evil outside environment context when terrorists. alleged parliament terrorists knees [SEP]']
[ 100/2000] tot_loss=2.259 (perp=10.151, rec=0.217, cos=0.011), tot_loss_proj:2.767 [t=0.24s]
prediction: ['[CLS] outside ground political context political evil are article terrorists terrorist outside context context outside terrorists taken wrong! the ) [SEP]']
[ 150/2000] tot_loss=1.946 (perp=8.843, rec=0.170, cos=0.008), tot_loss_proj:2.524 [t=0.24s]
prediction: ['[CLS] the background political context political evil are : evil the outside climate context outside terrorists taken against! the ) [SEP]']
[ 200/2000] tot_loss=2.062 (perp=9.404, rec=0.166, cos=0.016), tot_loss_proj:2.645 [t=0.24s]
prediction: ['[CLS] the background political context political evil than!! the outside climate context outside terrorists taken than more the ) [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.921 (perp=8.778, rec=0.153, cos=0.013), tot_loss_proj:2.550 [t=0.24s]
prediction: ['[CLS] the outside ( context political evil than!! the outside see context current terrorists taken than more than ) [SEP]']
[ 300/2000] tot_loss=1.843 (perp=8.550, rec=0.127, cos=0.007), tot_loss_proj:2.533 [t=0.24s]
prediction: ['[CLS] the outside ( context political evil are!! the outside see context current terrorists taken than more than ) [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.725 (perp=8.071, rec=0.108, cos=0.003), tot_loss_proj:2.394 [t=0.24s]
prediction: ['[CLS] the outside ( context political evil are current!! the outside see climate terrorists taken ever more than ) [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.656 (perp=7.686, rec=0.114, cos=0.005), tot_loss_proj:2.412 [t=0.24s]
prediction: ['[CLS] the political evil are current! outside ( context! the outside see climate terrorists taken ever more than ) [SEP]']
[ 450/2000] tot_loss=1.878 (perp=8.827, rec=0.108, cos=0.005), tot_loss_proj:2.582 [t=0.24s]
prediction: ['[CLS] the political evil are current : outside ( context! the outside see climate terrorists taken ever than than ) [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.736 (perp=8.168, rec=0.100, cos=0.003), tot_loss_proj:2.550 [t=0.24s]
prediction: ['[CLS] the political evil are current : outside ( context! the outside see climate terrorists taken than than ever ) [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.662 (perp=7.762, rec=0.103, cos=0.006), tot_loss_proj:2.500 [t=0.24s]
prediction: ['[CLS] the political evil are current! of ( context : the outside see climate terrorists taken than than ever ) [SEP]']
[ 600/2000] tot_loss=1.654 (perp=7.762, rec=0.098, cos=0.004), tot_loss_proj:2.497 [t=0.24s]
prediction: ['[CLS] the political evil are current! of ( context : the outside see climate terrorists taken than than ever ) [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.611 (perp=7.555, rec=0.097, cos=0.003), tot_loss_proj:2.575 [t=0.24s]
prediction: ['[CLS] the political evil are current! ( of context : the outside see climate terrorists taken than than ever ) [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.612 (perp=7.555, rec=0.097, cos=0.003), tot_loss_proj:2.571 [t=0.24s]
prediction: ['[CLS] the political evil are current! ( of context : the outside see climate terrorists taken than than ever ) [SEP]']
[ 750/2000] tot_loss=1.605 (perp=7.555, rec=0.091, cos=0.003), tot_loss_proj:2.576 [t=0.24s]
prediction: ['[CLS] the political evil are current! ( of context : the outside see climate terrorists taken than than ever ) [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.565 (perp=7.360, rec=0.090, cos=0.003), tot_loss_proj:2.446 [t=0.24s]
prediction: ['[CLS] the political evil are current! ( of context : are the outside see climate terrorists taken than ever ) [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.551 (perp=7.208, rec=0.100, cos=0.009), tot_loss_proj:2.618 [t=0.24s]
prediction: ['[CLS] the political of evil are current! ( context : are the outside see climate terrorists taken than ever ) [SEP]']
[ 900/2000] tot_loss=1.532 (perp=7.208, rec=0.087, cos=0.003), tot_loss_proj:2.618 [t=0.24s]
prediction: ['[CLS] the political of evil are current! ( context : are the outside see climate terrorists taken than ever ) [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.526 (perp=7.125, rec=0.098, cos=0.003), tot_loss_proj:2.621 [t=0.24s]
prediction: ['[CLS] the political of evil are current! ( context : see are the outside climate terrorists taken than ever ) [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.378 (perp=6.390, rec=0.096, cos=0.004), tot_loss_proj:2.571 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the outside terrorists taken than ever ) [SEP]']
[1050/2000] tot_loss=1.371 (perp=6.390, rec=0.090, cos=0.003), tot_loss_proj:2.570 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the outside terrorists taken than ever ) [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.315 (perp=6.129, rec=0.086, cos=0.003), tot_loss_proj:2.534 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
[1150/2000] tot_loss=1.320 (perp=6.129, rec=0.091, cos=0.003), tot_loss_proj:2.534 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]']
[1200/2000] tot_loss=1.317 (perp=6.129, rec=0.088, cos=0.003), tot_loss_proj:2.537 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
[1250/2000] tot_loss=1.320 (perp=6.129, rec=0.091, cos=0.003), tot_loss_proj:2.534 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
[1300/2000] tot_loss=1.322 (perp=6.129, rec=0.093, cos=0.003), tot_loss_proj:2.538 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]']
[1350/2000] tot_loss=1.307 (perp=6.129, rec=0.079, cos=0.003), tot_loss_proj:2.531 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
[1400/2000] tot_loss=1.322 (perp=6.129, rec=0.094, cos=0.003), tot_loss_proj:2.539 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
[1450/2000] tot_loss=1.323 (perp=6.129, rec=0.095, cos=0.003), tot_loss_proj:2.534 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]']
[1500/2000] tot_loss=1.320 (perp=6.129, rec=0.091, cos=0.003), tot_loss_proj:2.537 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
[1550/2000] tot_loss=1.320 (perp=6.129, rec=0.091, cos=0.003), tot_loss_proj:2.536 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
[1600/2000] tot_loss=1.311 (perp=6.129, rec=0.083, cos=0.003), tot_loss_proj:2.534 [t=0.24s]
prediction: ['[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]']
[1650/2000] tot_loss=1.367 (perp=6.377, rec=0.089, cos=0.003), tot_loss_proj:2.335 [t=0.24s]
prediction: ['[CLS] the political climate of evil more current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.351 (perp=6.290, rec=0.090, cos=0.003), tot_loss_proj:2.182 [t=0.24s]
prediction: ['[CLS] the political climate of more evil current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
[1750/2000] tot_loss=1.345 (perp=6.290, rec=0.085, cos=0.003), tot_loss_proj:2.186 [t=0.24s]
prediction: ['[CLS] the political climate of more evil current! ( context : see are the terrorists taken outside than ever ) [SEP]']
[1800/2000] tot_loss=1.349 (perp=6.290, rec=0.088, cos=0.003), tot_loss_proj:2.190 [t=0.24s]
prediction: ['[CLS] the political climate of more evil current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
[1850/2000] tot_loss=1.354 (perp=6.290, rec=0.094, cos=0.003), tot_loss_proj:2.186 [t=0.24s]
prediction: ['[CLS] the political climate of more evil current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
[1900/2000] tot_loss=1.341 (perp=6.290, rec=0.080, cos=0.003), tot_loss_proj:2.186 [t=0.24s]
prediction: ['[CLS] the political climate of more evil current! ( context : see are the terrorists taken outside than ever ) [SEP]']
[1950/2000] tot_loss=1.349 (perp=6.290, rec=0.088, cos=0.003), tot_loss_proj:2.186 [t=0.24s]
prediction: ['[CLS] the political climate of more evil current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Attempt swap
[2000/2000] tot_loss=1.343 (perp=6.290, rec=0.082, cos=0.003), tot_loss_proj:2.181 [t=0.24s]
prediction: ['[CLS] the political climate of more evil current! ( context : see are the terrorists taken outside than ever ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] the political climate of evil are current! ( context : see are the terrorists taken outside than ever ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.444 | p: 94.444 | r: 94.444
rouge2     | fm: 23.529 | p: 23.529 | r: 23.529
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 117.974

[Aggregate metrics]:
rouge1     | fm: 88.978 | p: 89.409 | r: 88.930
rouge2     | fm: 57.085 | p: 57.610 | r: 56.791
rougeL     | fm: 76.766 | p: 77.176 | r: 76.803
rougeLsum  | fm: 76.591 | p: 77.274 | r: 76.389
r1fm+r2fm = 146.063

input #24 time: 0:09:27 | total time: 3:47:49


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9986874149919696
highest_index [0]
highest [0.9986874149919696]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 0.9557013511657715 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9497941136360168 for ['[CLS] past banking son davies [SEP]']
[Init] best rec loss: 0.9454858303070068 for ['[CLS] weakness blue fast @ [SEP]']
[Init] best rec loss: 0.9428203105926514 for ['[CLS] stepped senate centuryfish [SEP]']
[Init] best rec loss: 0.9414227604866028 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.940095067024231 for ['[CLS] all one trace perfect [SEP]']
[Init] best rec loss: 0.9271516799926758 for ['[CLS]bla mozart orleans [SEP] [SEP]']
[Init] best rec loss: 0.9212543368339539 for ['[CLS] visionmetric dozennica [SEP]']
[Init] best rec loss: 0.9183601140975952 for ['[CLS] manner from bathing small [SEP]']
[Init] best rec loss: 0.9170480966567993 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best perm rec loss: 0.9154016375541687 for ['[CLS] assistant fantasy youthorus [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.108 (perp=13.889, rec=0.680, cos=0.651), tot_loss_proj:4.496 [t=0.23s]
prediction: ['[CLS] adaptation basket various broken [SEP]']
[ 100/2000] tot_loss=3.759 (perp=13.667, rec=0.591, cos=0.434), tot_loss_proj:3.917 [t=0.24s]
prediction: ['[CLS] atheist whoa attorney beautiful [SEP]']
[ 150/2000] tot_loss=3.200 (perp=11.073, rec=0.554, cos=0.431), tot_loss_proj:3.257 [t=0.24s]
prediction: ['[CLS] strange ballet strange beautiful [SEP]']
[ 200/2000] tot_loss=3.155 (perp=11.073, rec=0.539, cos=0.401), tot_loss_proj:3.325 [t=0.24s]
prediction: ['[CLS] strange ballet strange beautiful [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.487 (perp=12.548, rec=0.574, cos=0.403), tot_loss_proj:3.361 [t=0.24s]
prediction: ['[CLS] var strange percy beautiful [SEP]']
[ 300/2000] tot_loss=3.592 (perp=13.189, rec=0.556, cos=0.398), tot_loss_proj:3.742 [t=0.24s]
prediction: ['[CLS] var strange strange beautiful [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.020 (perp=10.819, rec=0.508, cos=0.348), tot_loss_proj:2.896 [t=0.24s]
prediction: ['[CLS] beautiful strange strange var [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.090 (perp=10.819, rec=0.529, cos=0.398), tot_loss_proj:2.908 [t=0.24s]
prediction: ['[CLS] beautiful strange strange var [SEP]']
[ 450/2000] tot_loss=3.002 (perp=10.819, rec=0.506, cos=0.332), tot_loss_proj:2.911 [t=0.24s]
prediction: ['[CLS] beautiful strange strange var [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.033 (perp=10.819, rec=0.517, cos=0.352), tot_loss_proj:2.918 [t=0.23s]
prediction: ['[CLS] beautiful strange strange var [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.980 (perp=10.819, rec=0.509, cos=0.308), tot_loss_proj:2.916 [t=0.22s]
prediction: ['[CLS] beautiful strange strange var [SEP]']
[ 600/2000] tot_loss=2.913 (perp=10.819, rec=0.484, cos=0.265), tot_loss_proj:2.917 [t=0.22s]
prediction: ['[CLS] beautiful strange strange var [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.895 (perp=10.819, rec=0.482, cos=0.249), tot_loss_proj:2.909 [t=0.22s]
prediction: ['[CLS] beautiful strange strange var [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.515 (perp=8.975, rec=0.495, cos=0.224), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] beautiful strange strange characters [SEP]']
[ 750/2000] tot_loss=2.484 (perp=8.975, rec=0.477, cos=0.212), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] beautiful strange strange characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.542 (perp=8.975, rec=0.494, cos=0.253), tot_loss_proj:2.363 [t=0.22s]
prediction: ['[CLS] beautiful strange strange characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.468 (perp=8.975, rec=0.481, cos=0.192), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] beautiful strange strange characters [SEP]']
[ 900/2000] tot_loss=2.638 (perp=8.975, rec=0.558, cos=0.285), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] beautiful strange strange characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.497 (perp=8.975, rec=0.490, cos=0.211), tot_loss_proj:2.358 [t=0.22s]
prediction: ['[CLS] beautiful strange strange characters [SEP]']
Attempt swap
[1000/2000] tot_loss=2.447 (perp=8.975, rec=0.469, cos=0.183), tot_loss_proj:2.360 [t=0.22s]
prediction: ['[CLS] beautiful strange strange characters [SEP]']
[1050/2000] tot_loss=2.437 (perp=8.975, rec=0.474, cos=0.168), tot_loss_proj:2.360 [t=0.22s]
prediction: ['[CLS] beautiful strange strange characters [SEP]']
Attempt swap
[1100/2000] tot_loss=2.431 (perp=8.975, rec=0.479, cos=0.157), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] beautiful strange strange characters [SEP]']
Attempt swap
[1150/2000] tot_loss=2.440 (perp=8.975, rec=0.477, cos=0.168), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] beautiful strange strange characters [SEP]']
[1200/2000] tot_loss=2.429 (perp=8.975, rec=0.482, cos=0.152), tot_loss_proj:2.368 [t=0.22s]
prediction: ['[CLS] beautiful strange strange characters [SEP]']
Attempt swap
[1250/2000] tot_loss=2.465 (perp=9.299, rec=0.470, cos=0.136), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
Attempt swap
[1300/2000] tot_loss=2.469 (perp=9.299, rec=0.478, cos=0.131), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
[1350/2000] tot_loss=2.473 (perp=9.299, rec=0.469, cos=0.145), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
Attempt swap
[1400/2000] tot_loss=2.459 (perp=9.299, rec=0.471, cos=0.129), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
Attempt swap
[1450/2000] tot_loss=2.461 (perp=9.299, rec=0.469, cos=0.132), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
[1500/2000] tot_loss=2.462 (perp=9.299, rec=0.471, cos=0.131), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
Attempt swap
[1550/2000] tot_loss=2.450 (perp=9.299, rec=0.475, cos=0.115), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
Attempt swap
[1600/2000] tot_loss=2.456 (perp=9.299, rec=0.481, cos=0.115), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
[1650/2000] tot_loss=2.445 (perp=9.299, rec=0.466, cos=0.119), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
Attempt swap
[1700/2000] tot_loss=2.435 (perp=9.299, rec=0.461, cos=0.115), tot_loss_proj:2.358 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
Attempt swap
[1750/2000] tot_loss=2.431 (perp=9.299, rec=0.459, cos=0.112), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
[1800/2000] tot_loss=2.436 (perp=9.299, rec=0.466, cos=0.110), tot_loss_proj:2.357 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
Attempt swap
[1850/2000] tot_loss=2.435 (perp=9.299, rec=0.465, cos=0.110), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
Attempt swap
[1900/2000] tot_loss=2.430 (perp=9.299, rec=0.464, cos=0.106), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
[1950/2000] tot_loss=2.423 (perp=9.299, rec=0.458, cos=0.106), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
Attempt swap
[2000/2000] tot_loss=2.434 (perp=9.299, rec=0.469, cos=0.106), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] beautiful strange strange achievements [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] beautiful strange strange achievements [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 66.667

[Aggregate metrics]:
rouge1     | fm: 88.174 | p: 88.592 | r: 88.033
rouge2     | fm: 55.118 | p: 55.505 | r: 54.725
rougeL     | fm: 75.790 | p: 76.129 | r: 75.687
rougeLsum  | fm: 75.691 | p: 76.005 | r: 75.528
r1fm+r2fm = 143.292

input #25 time: 0:09:02 | total time: 3:56:51


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9984583358815337
highest_index [0]
highest [0.9984583358815337]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.8820197582244873 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.8474043607711792 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 0.8411664962768555 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.840096116065979 for ['[CLS] thisress duck rock torture rubber point latitude nice apart politics al rational lip what asian len field feud winner venues right as [SEP]']
[Init] best rec loss: 0.8238421678543091 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 0.8196629285812378 for ['[CLS] close both singularification tv for oclc maxim catalog station himselfomy rowater rafcl increasing could there metropolitan townland caps maria [SEP]']
[Init] best rec loss: 0.8139204978942871 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 0.811767578125 for ['[CLS] constituencies polish iso s fourth officers death four arrow merely discipline shot usually listkan colonialteadᆼ theoretical door octave souls more [SEP]']
[Init] best perm rec loss: 0.8072108030319214 for ['[CLS]tead four iso colonial arrow constituencies officers merely door fourth discipline polish usually shotᆼkan death souls more list s theoretical octave [SEP]']
[Init] best perm rec loss: 0.805862307548523 for ['[CLS]tead four merely polish arrow colonial octave shot theoretical iso more usually discipline constituencies deathᆼ souls list fourth s officers doorkan [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.407 (perp=10.689, rec=0.253, cos=0.015), tot_loss_proj:2.757 [t=0.23s]
prediction: ['[CLS] - this - recent french box and import pointless import alien pointless african import death season femme cousin why pointless start german gay [SEP]']
[ 100/2000] tot_loss=2.375 (perp=10.992, rec=0.170, cos=0.007), tot_loss_proj:3.021 [t=0.24s]
prediction: ['[CLS] - this ) coming frenching and import pointless from non pointless - import - season sophie siblings architects girl french german director [SEP]']
[ 150/2000] tot_loss=2.347 (perp=11.009, rec=0.139, cos=0.006), tot_loss_proj:3.169 [t=0.24s]
prediction: ['[CLS]der this ) mean frenching and import pointless from non pointless - import - month sophie writer director book french french director [SEP]']
[ 200/2000] tot_loss=2.286 (perp=10.726, rec=0.136, cos=0.005), tot_loss_proj:3.196 [t=0.24s]
prediction: ['[CLS]der this ) mean frenching and import pointless from non pointless - import - month sophie writer director - coming french director [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.067 (perp=9.727, rec=0.116, cos=0.005), tot_loss_proj:2.743 [t=0.24s]
prediction: ['[CLS]der this ) mean frenching and import pointless from non pointless - age - ile anne writer - - coming from director [SEP]']
[ 300/2000] tot_loss=2.141 (perp=10.223, rec=0.093, cos=0.003), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS]der this ) mean frenching and import pointless from non pointless - age - ile anne writer - - coming son director [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.012 (perp=9.594, rec=0.089, cos=0.003), tot_loss_proj:2.445 [t=0.24s]
prediction: ['[CLS] this ) mean frenchdering and import pointless from insane pointless - age - ile anne writer - - coming opportunity director [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.991 (perp=9.477, rec=0.092, cos=0.003), tot_loss_proj:2.432 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import pointless from insane pointless - age -rot anne writer - - coming opportunity director [SEP]']
[ 450/2000] tot_loss=1.973 (perp=9.413, rec=0.087, cos=0.004), tot_loss_proj:2.360 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import pointless from more pointless - age -rot anne writer - - coming bi director [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.945 (perp=9.293, rec=0.083, cos=0.003), tot_loss_proj:2.539 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import anne from missing pointless - age -rot pointless writer - - comingrot director [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.940 (perp=9.259, rec=0.085, cos=0.003), tot_loss_proj:2.341 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import non from anne pointless - age -rot pointless writer - - comingrot director [SEP]']
[ 600/2000] tot_loss=1.941 (perp=9.259, rec=0.086, cos=0.003), tot_loss_proj:2.335 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import non from anne pointless - age -rot pointless writer - - comingrot director [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.813 (perp=8.658, rec=0.078, cos=0.003), tot_loss_proj:2.165 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age -rot pointless writer - sophie nonrot director [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.736 (perp=8.266, rec=0.080, cos=0.003), tot_loss_proj:2.096 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless writer - sophie nonrotrot [SEP]']
[ 750/2000] tot_loss=1.742 (perp=8.266, rec=0.086, cos=0.003), tot_loss_proj:2.090 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless writer - sophie nonrotrot [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.725 (perp=8.266, rec=0.069, cos=0.003), tot_loss_proj:2.096 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless writer - sophie nonrotrot [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.732 (perp=8.266, rec=0.076, cos=0.003), tot_loss_proj:2.093 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless writer - sophie nonrotrot [SEP]']
[ 900/2000] tot_loss=1.737 (perp=8.266, rec=0.081, cos=0.003), tot_loss_proj:2.091 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless writer - sophie nonrotrot [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.738 (perp=8.266, rec=0.081, cos=0.004), tot_loss_proj:2.102 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless writer - sophie nonrotrot [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.666 (perp=7.919, rec=0.080, cos=0.003), tot_loss_proj:2.201 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
[1050/2000] tot_loss=1.668 (perp=7.919, rec=0.082, cos=0.003), tot_loss_proj:2.204 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.667 (perp=7.919, rec=0.081, cos=0.003), tot_loss_proj:2.280 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
[1150/2000] tot_loss=1.668 (perp=7.919, rec=0.081, cos=0.003), tot_loss_proj:2.280 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
[1200/2000] tot_loss=1.656 (perp=7.919, rec=0.070, cos=0.003), tot_loss_proj:2.282 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
[1250/2000] tot_loss=1.664 (perp=7.919, rec=0.077, cos=0.003), tot_loss_proj:2.278 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
[1300/2000] tot_loss=1.662 (perp=7.919, rec=0.075, cos=0.003), tot_loss_proj:2.278 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
[1350/2000] tot_loss=1.652 (perp=7.919, rec=0.065, cos=0.003), tot_loss_proj:2.274 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
[1400/2000] tot_loss=1.667 (perp=7.919, rec=0.080, cos=0.003), tot_loss_proj:2.277 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
[1450/2000] tot_loss=1.664 (perp=7.919, rec=0.077, cos=0.003), tot_loss_proj:2.278 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
[1500/2000] tot_loss=1.667 (perp=7.919, rec=0.080, cos=0.003), tot_loss_proj:2.276 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
[1550/2000] tot_loss=1.656 (perp=7.919, rec=0.070, cos=0.003), tot_loss_proj:2.278 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
[1600/2000] tot_loss=1.663 (perp=7.919, rec=0.076, cos=0.003), tot_loss_proj:2.277 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
[1650/2000] tot_loss=1.652 (perp=7.919, rec=0.065, cos=0.003), tot_loss_proj:2.270 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
[1700/2000] tot_loss=1.660 (perp=7.919, rec=0.073, cos=0.003), tot_loss_proj:2.278 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
[1750/2000] tot_loss=1.658 (perp=7.919, rec=0.071, cos=0.003), tot_loss_proj:2.274 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
[1800/2000] tot_loss=1.660 (perp=7.919, rec=0.074, cos=0.003), tot_loss_proj:2.273 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
[1850/2000] tot_loss=1.663 (perp=7.919, rec=0.076, cos=0.003), tot_loss_proj:2.280 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.641 (perp=7.809, rec=0.076, cos=0.003), tot_loss_proj:2.257 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from - anne pointless age - director pointless sophie - writer nonrotrot [SEP]']
[1950/2000] tot_loss=1.633 (perp=7.809, rec=0.068, cos=0.003), tot_loss_proj:2.264 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from - anne pointless age - director pointless sophie - writer nonrotrot [SEP]']
Attempt swap
[2000/2000] tot_loss=1.641 (perp=7.809, rec=0.076, cos=0.003), tot_loss_proj:2.248 [t=0.24s]
prediction: ['[CLS] this ) meandering and french import coming from - anne pointless age - director pointless sophie - writer nonrotrot [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] this ) meandering and french import coming from anne pointless - age - director pointless sophie - writer nonrotrot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.235 | p: 88.235 | r: 88.235
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 58.824 | p: 58.824 | r: 58.824
rougeLsum  | fm: 58.824 | p: 58.824 | r: 58.824
r1fm+r2fm = 106.985

[Aggregate metrics]:
rouge1     | fm: 88.061 | p: 88.614 | r: 87.945
rouge2     | fm: 53.906 | p: 54.443 | r: 53.555
rougeL     | fm: 75.112 | p: 75.460 | r: 75.018
rougeLsum  | fm: 75.145 | p: 75.437 | r: 75.001
r1fm+r2fm = 141.968

input #26 time: 0:09:25 | total time: 4:06:17


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.9986294185992847
highest_index [0]
highest [0.9986294185992847]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9948244094848633 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9558571577072144 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 0.9553346037864685 for ['[CLS] volume nan on [SEP]']
[Init] best rec loss: 0.9323459267616272 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.9291068911552429 for ['[CLS] how turned basic [SEP]']
[Init] best rec loss: 0.9155980944633484 for ['[CLS] op framework ran [SEP]']
[Init] best rec loss: 0.9136955142021179 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.9130001664161682 for ['[CLS] given transitwine [SEP]']
[Init] best perm rec loss: 0.9127731919288635 for ['[CLS]wine transit given [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.198 (perp=9.693, rec=0.235, cos=0.025), tot_loss_proj:2.581 [t=0.22s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 100/2000] tot_loss=2.264 (perp=10.501, rec=0.153, cos=0.010), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] generic generic are [SEP]']
[ 150/2000] tot_loss=1.988 (perp=9.504, rec=0.084, cos=0.003), tot_loss_proj:2.191 [t=0.22s]
prediction: ['[CLS] so generic are [SEP]']
[ 200/2000] tot_loss=1.974 (perp=9.504, rec=0.070, cos=0.003), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] so generic are [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.749 (perp=8.320, rec=0.081, cos=0.004), tot_loss_proj:1.787 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.733 (perp=8.320, rec=0.066, cos=0.003), tot_loss_proj:1.777 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.730 (perp=8.320, rec=0.064, cos=0.003), tot_loss_proj:1.779 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.733 (perp=8.320, rec=0.066, cos=0.003), tot_loss_proj:1.774 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.729 (perp=8.320, rec=0.062, cos=0.003), tot_loss_proj:1.788 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.715 (perp=8.320, rec=0.048, cos=0.003), tot_loss_proj:1.786 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.730 (perp=8.320, rec=0.063, cos=0.003), tot_loss_proj:1.777 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.735 (perp=8.320, rec=0.068, cos=0.003), tot_loss_proj:1.789 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.734 (perp=8.320, rec=0.068, cos=0.003), tot_loss_proj:1.781 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.736 (perp=8.320, rec=0.069, cos=0.003), tot_loss_proj:1.777 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.738 (perp=8.320, rec=0.071, cos=0.003), tot_loss_proj:1.782 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.726 (perp=8.320, rec=0.059, cos=0.003), tot_loss_proj:1.778 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.735 (perp=8.320, rec=0.068, cos=0.003), tot_loss_proj:1.768 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.742 (perp=8.320, rec=0.076, cos=0.003), tot_loss_proj:1.779 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.721 (perp=8.320, rec=0.054, cos=0.003), tot_loss_proj:1.775 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.728 (perp=8.320, rec=0.061, cos=0.003), tot_loss_proj:1.782 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.717 (perp=8.320, rec=0.051, cos=0.003), tot_loss_proj:1.781 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.738 (perp=8.320, rec=0.071, cos=0.003), tot_loss_proj:1.778 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.736 (perp=8.320, rec=0.069, cos=0.003), tot_loss_proj:1.783 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.732 (perp=8.320, rec=0.065, cos=0.003), tot_loss_proj:1.784 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.727 (perp=8.320, rec=0.060, cos=0.003), tot_loss_proj:1.790 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.726 (perp=8.320, rec=0.060, cos=0.003), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.734 (perp=8.320, rec=0.067, cos=0.003), tot_loss_proj:1.806 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.740 (perp=8.320, rec=0.073, cos=0.003), tot_loss_proj:1.789 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.724 (perp=8.320, rec=0.057, cos=0.003), tot_loss_proj:1.779 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.722 (perp=8.320, rec=0.055, cos=0.003), tot_loss_proj:1.792 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.719 (perp=8.320, rec=0.052, cos=0.003), tot_loss_proj:1.793 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.736 (perp=8.320, rec=0.069, cos=0.003), tot_loss_proj:1.788 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.718 (perp=8.320, rec=0.051, cos=0.003), tot_loss_proj:1.797 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.732 (perp=8.320, rec=0.065, cos=0.003), tot_loss_proj:1.792 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.719 (perp=8.320, rec=0.052, cos=0.003), tot_loss_proj:1.796 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.734 (perp=8.320, rec=0.068, cos=0.003), tot_loss_proj:1.793 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.732 (perp=8.320, rec=0.066, cos=0.003), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.733 (perp=8.320, rec=0.067, cos=0.003), tot_loss_proj:1.807 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.732 (perp=8.320, rec=0.065, cos=0.003), tot_loss_proj:1.796 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.735 (perp=8.320, rec=0.068, cos=0.003), tot_loss_proj:1.787 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.476 | p: 88.899 | r: 88.520
rouge2     | fm: 55.129 | p: 55.512 | r: 54.767
rougeL     | fm: 76.123 | p: 76.325 | r: 75.965
rougeLsum  | fm: 75.881 | p: 76.315 | r: 75.646
r1fm+r2fm = 143.605

input #27 time: 0:08:59 | total time: 4:15:16


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.999007726378041
highest_index [0]
highest [0.999007726378041]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8572036027908325 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.8067139387130737 for ['[CLS] want set aperture jersey [SEP]']
[Init] best rec loss: 0.7952914237976074 for ['[CLS] w dean re thanks [SEP]']
[Init] best rec loss: 0.7880811095237732 for ['[CLS] larvae heights jeremy roses [SEP]']
[Init] best perm rec loss: 0.786729097366333 for ['[CLS] heights roses larvae jeremy [SEP]']
[Init] best perm rec loss: 0.7850720286369324 for ['[CLS] roses larvae jeremy heights [SEP]']
[Init] best perm rec loss: 0.784530758857727 for ['[CLS] roses jeremy heights larvae [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.166 (perp=9.628, rec=0.218, cos=0.022), tot_loss_proj:3.038 [t=0.23s]
prediction: ['[CLS] for minutes minutes minutes [SEP]']
[ 100/2000] tot_loss=1.985 (perp=9.137, rec=0.144, cos=0.013), tot_loss_proj:2.541 [t=0.23s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
[ 150/2000] tot_loss=1.566 (perp=7.445, rec=0.073, cos=0.004), tot_loss_proj:1.862 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 200/2000] tot_loss=1.565 (perp=7.445, rec=0.073, cos=0.003), tot_loss_proj:1.858 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.561 (perp=7.445, rec=0.069, cos=0.002), tot_loss_proj:1.853 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 300/2000] tot_loss=1.570 (perp=7.445, rec=0.079, cos=0.002), tot_loss_proj:1.854 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.565 (perp=7.445, rec=0.074, cos=0.002), tot_loss_proj:1.863 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.542 (perp=7.445, rec=0.051, cos=0.002), tot_loss_proj:1.845 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 450/2000] tot_loss=1.555 (perp=7.445, rec=0.064, cos=0.002), tot_loss_proj:1.852 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.561 (perp=7.445, rec=0.069, cos=0.002), tot_loss_proj:1.854 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.570 (perp=7.445, rec=0.079, cos=0.002), tot_loss_proj:1.848 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 600/2000] tot_loss=1.555 (perp=7.445, rec=0.064, cos=0.002), tot_loss_proj:1.855 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.552 (perp=7.445, rec=0.061, cos=0.002), tot_loss_proj:1.862 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.546 (perp=7.445, rec=0.055, cos=0.002), tot_loss_proj:1.852 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 750/2000] tot_loss=1.543 (perp=7.445, rec=0.052, cos=0.002), tot_loss_proj:1.859 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.546 (perp=7.445, rec=0.055, cos=0.002), tot_loss_proj:1.851 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.560 (perp=7.445, rec=0.069, cos=0.002), tot_loss_proj:1.853 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 900/2000] tot_loss=1.556 (perp=7.445, rec=0.065, cos=0.002), tot_loss_proj:1.851 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.560 (perp=7.445, rec=0.069, cos=0.002), tot_loss_proj:1.851 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1000/2000] tot_loss=1.554 (perp=7.445, rec=0.063, cos=0.002), tot_loss_proj:1.841 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1050/2000] tot_loss=1.543 (perp=7.445, rec=0.052, cos=0.002), tot_loss_proj:1.861 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1100/2000] tot_loss=1.553 (perp=7.445, rec=0.062, cos=0.002), tot_loss_proj:1.847 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1150/2000] tot_loss=1.551 (perp=7.445, rec=0.060, cos=0.002), tot_loss_proj:1.845 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1200/2000] tot_loss=1.539 (perp=7.445, rec=0.048, cos=0.002), tot_loss_proj:1.857 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1250/2000] tot_loss=1.555 (perp=7.445, rec=0.064, cos=0.002), tot_loss_proj:1.861 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1300/2000] tot_loss=1.552 (perp=7.445, rec=0.061, cos=0.002), tot_loss_proj:1.861 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1350/2000] tot_loss=1.543 (perp=7.445, rec=0.052, cos=0.002), tot_loss_proj:1.860 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1400/2000] tot_loss=1.553 (perp=7.445, rec=0.061, cos=0.002), tot_loss_proj:1.856 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1450/2000] tot_loss=1.561 (perp=7.445, rec=0.070, cos=0.002), tot_loss_proj:1.859 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1500/2000] tot_loss=1.554 (perp=7.445, rec=0.063, cos=0.002), tot_loss_proj:1.847 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1550/2000] tot_loss=1.557 (perp=7.445, rec=0.066, cos=0.002), tot_loss_proj:1.850 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1600/2000] tot_loss=1.542 (perp=7.445, rec=0.051, cos=0.002), tot_loss_proj:1.858 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1650/2000] tot_loss=1.551 (perp=7.445, rec=0.060, cos=0.002), tot_loss_proj:1.855 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1700/2000] tot_loss=1.567 (perp=7.445, rec=0.076, cos=0.002), tot_loss_proj:1.857 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1750/2000] tot_loss=1.556 (perp=7.445, rec=0.065, cos=0.002), tot_loss_proj:1.859 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1800/2000] tot_loss=1.560 (perp=7.445, rec=0.069, cos=0.002), tot_loss_proj:1.856 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1850/2000] tot_loss=1.550 (perp=7.445, rec=0.059, cos=0.002), tot_loss_proj:1.861 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1900/2000] tot_loss=1.556 (perp=7.445, rec=0.065, cos=0.002), tot_loss_proj:1.862 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1950/2000] tot_loss=1.553 (perp=7.445, rec=0.062, cos=0.002), tot_loss_proj:1.850 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[2000/2000] tot_loss=1.543 (perp=7.445, rec=0.052, cos=0.002), tot_loss_proj:1.837 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for 71 minutes only [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 88.920 | p: 89.347 | r: 88.847
rouge2     | fm: 54.628 | p: 55.077 | r: 54.205
rougeL     | fm: 76.117 | p: 76.464 | r: 76.085
rougeLsum  | fm: 76.105 | p: 76.521 | r: 76.023
r1fm+r2fm = 143.548

input #28 time: 0:09:14 | total time: 4:24:30


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.998724793034663
highest_index [0]
highest [0.998724793034663]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.9055503010749817 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.8632421493530273 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.8494009971618652 for ['[CLS] label which £ anyway shoes mediamont campbell her cullen [SEP]']
[Init] best rec loss: 0.8361334800720215 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8077508211135864 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 0.7883270382881165 for ['[CLS] consuming after intern coach acres surf class speed tongues period [SEP]']
[Init] best rec loss: 0.786916196346283 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best perm rec loss: 0.7842475771903992 for ['[CLS] f meters transmit axle cells bu mostly ufounded veto [SEP]']
[Init] best perm rec loss: 0.78177809715271 for ['[CLS] cells veto axle bufounded f mostly u meters transmit [SEP]']
[Init] best perm rec loss: 0.7804149985313416 for ['[CLS]founded cells u bu transmit veto axle mostly f meters [SEP]']
[Init] best perm rec loss: 0.7798597812652588 for ['[CLS] cells meters bu axle f mostlyfounded veto u transmit [SEP]']
[Init] best perm rec loss: 0.7789176106452942 for ['[CLS] veto bu u f mostlyfounded transmit meters axle cells [SEP]']
[Init] best perm rec loss: 0.7770418524742126 for ['[CLS] axle cells u bu mostly f transmitfounded veto meters [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.214 (perp=9.764, rec=0.239, cos=0.022), tot_loss_proj:3.829 [t=0.23s]
prediction: ['[CLS] strict also believe are it not criminal not not evil [SEP]']
[ 100/2000] tot_loss=1.817 (perp=8.258, rec=0.154, cos=0.011), tot_loss_proj:2.869 [t=0.23s]
prediction: ['[CLS] believe also believe evil it is resident not not resident [SEP]']
[ 150/2000] tot_loss=1.843 (perp=8.476, rec=0.134, cos=0.014), tot_loss_proj:2.915 [t=0.24s]
prediction: ['[CLS] that also believe evil it is resident not. resident [SEP]']
[ 200/2000] tot_loss=1.820 (perp=8.476, rec=0.114, cos=0.011), tot_loss_proj:2.925 [t=0.24s]
prediction: ['[CLS] that also believe evil it is resident not. resident [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.531 (perp=7.082, rec=0.107, cos=0.008), tot_loss_proj:2.564 [t=0.24s]
prediction: ['[CLS] that also believe evil it is resident not resident. [SEP]']
[ 300/2000] tot_loss=1.512 (perp=7.082, rec=0.089, cos=0.007), tot_loss_proj:2.566 [t=0.24s]
prediction: ['[CLS] that also believe evil it is resident not resident. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.317 (perp=6.063, rec=0.096, cos=0.008), tot_loss_proj:2.215 [t=0.24s]
prediction: ['[CLS] evil also believe that it is resident not resident. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.313 (perp=6.063, rec=0.093, cos=0.007), tot_loss_proj:2.222 [t=0.24s]
prediction: ['[CLS] evil also believe that it is resident not resident. [SEP]']
[ 450/2000] tot_loss=1.309 (perp=6.063, rec=0.090, cos=0.007), tot_loss_proj:2.225 [t=0.24s]
prediction: ['[CLS] evil also believe that it is resident not resident. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.308 (perp=6.063, rec=0.090, cos=0.006), tot_loss_proj:2.222 [t=0.24s]
prediction: ['[CLS] evil also believe that it is resident not resident. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.196 (perp=5.419, rec=0.104, cos=0.008), tot_loss_proj:1.736 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
[ 600/2000] tot_loss=1.175 (perp=5.419, rec=0.085, cos=0.007), tot_loss_proj:1.739 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.175 (perp=5.419, rec=0.085, cos=0.006), tot_loss_proj:1.735 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.247 (perp=5.419, rec=0.142, cos=0.021), tot_loss_proj:1.741 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
[ 750/2000] tot_loss=1.194 (perp=5.419, rec=0.104, cos=0.006), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.182 (perp=5.419, rec=0.094, cos=0.005), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.172 (perp=5.419, rec=0.083, cos=0.005), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
[ 900/2000] tot_loss=1.183 (perp=5.419, rec=0.094, cos=0.005), tot_loss_proj:1.738 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.180 (perp=5.419, rec=0.091, cos=0.005), tot_loss_proj:1.734 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.172 (perp=5.419, rec=0.084, cos=0.005), tot_loss_proj:1.746 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
[1050/2000] tot_loss=1.172 (perp=5.419, rec=0.084, cos=0.005), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.165 (perp=5.419, rec=0.077, cos=0.005), tot_loss_proj:1.740 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.173 (perp=5.419, rec=0.085, cos=0.004), tot_loss_proj:1.736 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
[1200/2000] tot_loss=1.176 (perp=5.419, rec=0.087, cos=0.004), tot_loss_proj:1.742 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.175 (perp=5.419, rec=0.087, cos=0.005), tot_loss_proj:1.736 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.164 (perp=5.419, rec=0.075, cos=0.004), tot_loss_proj:1.736 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
[1350/2000] tot_loss=1.170 (perp=5.419, rec=0.082, cos=0.004), tot_loss_proj:1.738 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.170 (perp=5.419, rec=0.082, cos=0.004), tot_loss_proj:1.728 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.168 (perp=5.419, rec=0.080, cos=0.004), tot_loss_proj:1.742 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
[1500/2000] tot_loss=1.169 (perp=5.419, rec=0.080, cos=0.004), tot_loss_proj:1.743 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.174 (perp=5.419, rec=0.086, cos=0.004), tot_loss_proj:1.740 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.175 (perp=5.419, rec=0.087, cos=0.004), tot_loss_proj:1.738 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
[1650/2000] tot_loss=1.166 (perp=5.419, rec=0.078, cos=0.004), tot_loss_proj:1.738 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.167 (perp=5.419, rec=0.079, cos=0.004), tot_loss_proj:1.743 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.163 (perp=5.419, rec=0.075, cos=0.004), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
[1800/2000] tot_loss=1.171 (perp=5.419, rec=0.083, cos=0.004), tot_loss_proj:1.744 [t=0.24s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.178 (perp=5.419, rec=0.090, cos=0.004), tot_loss_proj:1.746 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.170 (perp=5.419, rec=0.082, cos=0.004), tot_loss_proj:1.739 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
[1950/2000] tot_loss=1.181 (perp=5.419, rec=0.093, cos=0.004), tot_loss_proj:1.751 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.166 (perp=5.419, rec=0.077, cos=0.004), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] resident evil also believe that it is not resident. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] resident evil also believe that it is not resident. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 130.909

[Aggregate metrics]:
rouge1     | fm: 88.974 | p: 89.415 | r: 88.921
rouge2     | fm: 54.017 | p: 54.489 | r: 53.723
rougeL     | fm: 75.888 | p: 76.165 | r: 75.852
rougeLsum  | fm: 75.818 | p: 76.186 | r: 75.705
r1fm+r2fm = 142.991

input #29 time: 0:09:15 | total time: 4:33:45


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.9986146406233286
highest_index [0]
highest [0.9986146406233286]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.853379487991333 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.713395893573761 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.69585782289505 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.6674911379814148 for ['[CLS] acceleration council lizard [SEP]']
[Init] best rec loss: 0.6607113480567932 for ['[CLS] spent who mom [SEP]']
[Init] best perm rec loss: 0.6522678136825562 for ['[CLS] mom who spent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.121 (perp=9.539, rec=0.202, cos=0.011), tot_loss_proj:1.987 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 100/2000] tot_loss=2.005 (perp=9.539, rec=0.091, cos=0.006), tot_loss_proj:1.970 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 150/2000] tot_loss=1.973 (perp=9.539, rec=0.062, cos=0.003), tot_loss_proj:1.984 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=1.978 (perp=9.539, rec=0.066, cos=0.004), tot_loss_proj:1.982 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.970 (perp=9.539, rec=0.058, cos=0.004), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.969 (perp=9.539, rec=0.058, cos=0.003), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.984 (perp=9.539, rec=0.072, cos=0.004), tot_loss_proj:1.966 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.982 (perp=9.539, rec=0.071, cos=0.003), tot_loss_proj:1.969 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.976 (perp=9.539, rec=0.066, cos=0.003), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.979 (perp=9.539, rec=0.068, cos=0.003), tot_loss_proj:1.980 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.967 (perp=9.539, rec=0.057, cos=0.003), tot_loss_proj:1.974 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.963 (perp=9.539, rec=0.053, cos=0.003), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.966 (perp=9.539, rec=0.056, cos=0.003), tot_loss_proj:1.973 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.971 (perp=9.539, rec=0.061, cos=0.003), tot_loss_proj:1.976 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.974 (perp=9.539, rec=0.063, cos=0.003), tot_loss_proj:1.966 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.969 (perp=9.539, rec=0.059, cos=0.003), tot_loss_proj:1.980 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.976 (perp=9.539, rec=0.065, cos=0.003), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.968 (perp=9.539, rec=0.057, cos=0.003), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.964 (perp=9.539, rec=0.053, cos=0.003), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.973 (perp=9.539, rec=0.062, cos=0.003), tot_loss_proj:1.980 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.984 (perp=9.539, rec=0.073, cos=0.003), tot_loss_proj:1.978 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.970 (perp=9.539, rec=0.059, cos=0.003), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.975 (perp=9.539, rec=0.064, cos=0.003), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.961 (perp=9.539, rec=0.050, cos=0.003), tot_loss_proj:1.973 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.963 (perp=9.539, rec=0.052, cos=0.003), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.956 (perp=9.539, rec=0.046, cos=0.003), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.977 (perp=9.539, rec=0.066, cos=0.003), tot_loss_proj:1.989 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.972 (perp=9.539, rec=0.061, cos=0.003), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.974 (perp=9.539, rec=0.064, cos=0.003), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.968 (perp=9.539, rec=0.057, cos=0.003), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.978 (perp=9.539, rec=0.067, cos=0.003), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.978 (perp=9.539, rec=0.067, cos=0.003), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.974 (perp=9.539, rec=0.063, cos=0.003), tot_loss_proj:1.966 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.969 (perp=9.539, rec=0.058, cos=0.003), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.972 (perp=9.539, rec=0.061, cos=0.003), tot_loss_proj:1.989 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.956 (perp=9.539, rec=0.046, cos=0.003), tot_loss_proj:1.972 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.978 (perp=9.539, rec=0.067, cos=0.003), tot_loss_proj:1.982 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.975 (perp=9.539, rec=0.064, cos=0.003), tot_loss_proj:1.982 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.968 (perp=9.539, rec=0.058, cos=0.003), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.971 (perp=9.539, rec=0.060, cos=0.003), tot_loss_proj:1.973 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.328 | p: 89.654 | r: 89.252
rouge2     | fm: 55.572 | p: 56.006 | r: 55.263
rougeL     | fm: 76.763 | p: 77.028 | r: 76.739
rougeLsum  | fm: 76.358 | p: 76.738 | r: 76.306
r1fm+r2fm = 144.900

input #30 time: 0:09:13 | total time: 4:42:59


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.9988596126661815
highest_index [0]
highest [0.9988596126661815]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.8406555652618408 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.8252385258674622 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.81351637840271 for ['[CLS] jing critical hurts [SEP]']
[Init] best rec loss: 0.8067381381988525 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.7584249973297119 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 0.7488560080528259 for ['[CLS] lighthouse peace case [SEP]']
[Init] best rec loss: 0.7429870963096619 for ['[CLS] quarter joined less [SEP]']
[Init] best rec loss: 0.740665853023529 for ['[CLS] coast strong meaning [SEP]']
[Init] best perm rec loss: 0.7377482652664185 for ['[CLS] meaning strong coast [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.219 (perp=10.167, rec=0.167, cos=0.019), tot_loss_proj:2.720 [t=0.23s]
prediction: ['[CLS] better vehicle alternative [SEP]']
[ 100/2000] tot_loss=2.420 (perp=11.331, rec=0.132, cos=0.022), tot_loss_proj:2.763 [t=0.23s]
prediction: ['[CLS] better vehicle super [SEP]']
[ 150/2000] tot_loss=2.409 (perp=11.331, rec=0.123, cos=0.019), tot_loss_proj:2.763 [t=0.23s]
prediction: ['[CLS] better vehicle super [SEP]']
[ 200/2000] tot_loss=2.398 (perp=11.331, rec=0.113, cos=0.019), tot_loss_proj:2.774 [t=0.23s]
prediction: ['[CLS] better vehicle super [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.668 (perp=7.603, rec=0.126, cos=0.021), tot_loss_proj:1.641 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.646 (perp=7.603, rec=0.107, cos=0.018), tot_loss_proj:1.648 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.649 (perp=7.603, rec=0.111, cos=0.017), tot_loss_proj:1.647 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.641 (perp=7.603, rec=0.104, cos=0.016), tot_loss_proj:1.652 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.645 (perp=7.603, rec=0.108, cos=0.016), tot_loss_proj:1.633 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.639 (perp=7.603, rec=0.106, cos=0.012), tot_loss_proj:1.640 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.637 (perp=7.603, rec=0.105, cos=0.011), tot_loss_proj:1.640 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.613 (perp=7.603, rec=0.086, cos=0.007), tot_loss_proj:1.641 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.578 (perp=7.603, rec=0.055, cos=0.002), tot_loss_proj:1.641 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.581 (perp=7.603, rec=0.058, cos=0.002), tot_loss_proj:1.636 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.578 (perp=7.603, rec=0.056, cos=0.002), tot_loss_proj:1.646 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.592 (perp=7.603, rec=0.069, cos=0.002), tot_loss_proj:1.648 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.002), tot_loss_proj:1.637 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.578 (perp=7.603, rec=0.056, cos=0.002), tot_loss_proj:1.643 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.574 (perp=7.603, rec=0.051, cos=0.002), tot_loss_proj:1.619 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.580 (perp=7.603, rec=0.057, cos=0.002), tot_loss_proj:1.642 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.002), tot_loss_proj:1.640 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.573 (perp=7.603, rec=0.051, cos=0.002), tot_loss_proj:1.644 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.584 (perp=7.603, rec=0.061, cos=0.002), tot_loss_proj:1.638 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.587 (perp=7.603, rec=0.064, cos=0.002), tot_loss_proj:1.633 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.590 (perp=7.603, rec=0.067, cos=0.002), tot_loss_proj:1.638 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.592 (perp=7.603, rec=0.069, cos=0.002), tot_loss_proj:1.639 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.578 (perp=7.603, rec=0.056, cos=0.002), tot_loss_proj:1.652 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.002), tot_loss_proj:1.641 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.582 (perp=7.603, rec=0.059, cos=0.002), tot_loss_proj:1.645 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.584 (perp=7.603, rec=0.061, cos=0.002), tot_loss_proj:1.642 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.579 (perp=7.603, rec=0.056, cos=0.002), tot_loss_proj:1.645 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.593 (perp=7.603, rec=0.070, cos=0.002), tot_loss_proj:1.648 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.575 (perp=7.603, rec=0.052, cos=0.002), tot_loss_proj:1.632 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.587 (perp=7.603, rec=0.064, cos=0.002), tot_loss_proj:1.656 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.596 (perp=7.603, rec=0.073, cos=0.002), tot_loss_proj:1.646 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.583 (perp=7.603, rec=0.060, cos=0.002), tot_loss_proj:1.627 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.574 (perp=7.603, rec=0.051, cos=0.002), tot_loss_proj:1.642 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.594 (perp=7.603, rec=0.071, cos=0.002), tot_loss_proj:1.639 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.598 (perp=7.603, rec=0.075, cos=0.002), tot_loss_proj:1.636 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.585 (perp=7.603, rec=0.062, cos=0.002), tot_loss_proj:1.642 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.577 | p: 90.007 | r: 89.518
rouge2     | fm: 56.943 | p: 57.473 | r: 56.700
rougeL     | fm: 77.452 | p: 77.606 | r: 77.454
rougeLsum  | fm: 77.251 | p: 77.525 | r: 77.235
r1fm+r2fm = 146.519

input #31 time: 0:09:14 | total time: 4:52:13


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9987716460035503
highest_index [0]
highest [0.9987716460035503]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 0.9335673451423645 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9324339032173157 for ['[CLS] huey while kill stuck doc urgent lakeside integration food trailers with a [SEP]']
[Init] best rec loss: 0.9308454394340515 for ['[CLS]le force cheers discarded replicateباد clash lighthouse direct remarried narrative words [SEP]']
[Init] best rec loss: 0.927771806716919 for ['[CLS] youth old made particular lostgraph matchyna suicide kara global guess [SEP]']
[Init] best rec loss: 0.918467104434967 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.9168099164962769 for ['[CLS] nap first mddic nichols carriage usual spread wits eu pun age [SEP]']
[Init] best rec loss: 0.8985159993171692 for ['[CLS] palaceshire athletic th funds lilith bio circlecting thomas cake natalie [SEP]']
[Init] best perm rec loss: 0.8970881700515747 for ['[CLS] natalieshire athletic th circle funds lilith thomas palacecting cake bio [SEP]']
[Init] best perm rec loss: 0.8943740725517273 for ['[CLS]shire th lilithcting natalie thomas palace bio cake funds circle athletic [SEP]']
[Init] best perm rec loss: 0.894206702709198 for ['[CLS] circle fundsshire natalie lilith th thomas biocting palace athletic cake [SEP]']
[Init] best perm rec loss: 0.8938654065132141 for ['[CLS] circle funds palace lilith th thomas nataliecting cakeshire bio athletic [SEP]']
[Init] best perm rec loss: 0.892711877822876 for ['[CLS] cakecting natalie circleshire bio palace athletic funds lilith th thomas [SEP]']
[Init] best perm rec loss: 0.8913602232933044 for ['[CLS]cting natalie funds bio lilithshire circle athletic th cake palace thomas [SEP]']
[Init] best perm rec loss: 0.8898700475692749 for ['[CLS] bio funds lilith athletic thomas circle natalie cake palacectingshire th [SEP]']
[Init] best perm rec loss: 0.8892028331756592 for ['[CLS] natalie lilith circlecting bioshire cake funds th athletic thomas palace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.892 (perp=12.930, rec=0.294, cos=0.012), tot_loss_proj:3.643 [t=0.23s]
prediction: ['[CLS] mysteryvable good narrative arting could chord vernacular respondhis reach [SEP]']
[ 100/2000] tot_loss=2.564 (perp=11.751, rec=0.208, cos=0.006), tot_loss_proj:3.628 [t=0.23s]
prediction: ['[CLS] availableonateonate stories stories together resonate [SEP] pullodate [SEP]']
[ 150/2000] tot_loss=2.521 (perp=11.808, rec=0.155, cos=0.005), tot_loss_proj:3.866 [t=0.23s]
prediction: ['[CLS] accessibleonateonate stories stories together resonate [SEP] pullundonate [SEP]']
[ 200/2000] tot_loss=2.618 (perp=12.364, rec=0.140, cos=0.004), tot_loss_proj:4.002 [t=0.24s]
prediction: ['[CLS] accessible interstate easily stories stories together resonate mainstream pullundonate [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.308 (perp=10.779, rec=0.148, cos=0.005), tot_loss_proj:3.802 [t=0.23s]
prediction: ['[CLS] accessible stories stories together resonate [SEP] interstate easily pullundity [SEP]']
[ 300/2000] tot_loss=2.281 (perp=10.818, rec=0.113, cos=0.004), tot_loss_proj:3.830 [t=0.23s]
prediction: ['[CLS] accessible stories stories together resonateites prof easily pullundity [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.976 (perp=9.326, rec=0.106, cos=0.004), tot_loss_proj:2.936 [t=0.23s]
prediction: ['[CLS] accessible stories stories together easily pull resonateite profundity [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.823 (perp=8.507, rec=0.117, cos=0.004), tot_loss_proj:2.350 [t=0.23s]
prediction: ['[CLS] accessible stories pull stories together easily resonateite profundity [SEP]']
[ 450/2000] tot_loss=1.961 (perp=9.253, rec=0.105, cos=0.004), tot_loss_proj:2.409 [t=0.23s]
prediction: ['[CLS] accessible stories pull stories together easily resonate prof profundity [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.818 (perp=8.512, rec=0.111, cos=0.004), tot_loss_proj:2.503 [t=0.23s]
prediction: ['[CLS] accessible stories prof pull stories together easily resonate profundity [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.802 (perp=8.458, rec=0.106, cos=0.004), tot_loss_proj:2.282 [t=0.23s]
prediction: ['[CLS] easily accessible stories prof pull with together resonate profundity [SEP]']
[ 600/2000] tot_loss=1.784 (perp=8.458, rec=0.088, cos=0.004), tot_loss_proj:2.273 [t=0.23s]
prediction: ['[CLS] easily accessible stories prof pull with together resonate profundity [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.591 (perp=7.493, rec=0.089, cos=0.004), tot_loss_proj:2.111 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together with resonate profundity [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.572 (perp=7.393, rec=0.089, cos=0.004), tot_loss_proj:1.994 [t=0.24s]
prediction: ['[CLS] easily accessible stories pull easily together with resonate profundity [SEP]']
[ 750/2000] tot_loss=1.636 (perp=7.743, rec=0.083, cos=0.004), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS] easily accessible stories pull quickly together with resonate profundity [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.580 (perp=7.453, rec=0.085, cos=0.004), tot_loss_proj:2.342 [t=0.23s]
prediction: ['[CLS] easily accessible stories pull together quickly with resonate profundity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.582 (perp=7.453, rec=0.087, cos=0.004), tot_loss_proj:2.343 [t=0.24s]
prediction: ['[CLS] easily accessible stories pull together quickly with resonate profundity [SEP]']
[ 900/2000] tot_loss=1.573 (perp=7.453, rec=0.078, cos=0.004), tot_loss_proj:2.337 [t=0.24s]
prediction: ['[CLS] easily accessible stories pull together quickly with resonate profundity [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.558 (perp=7.364, rec=0.081, cos=0.004), tot_loss_proj:2.219 [t=0.23s]
prediction: ['[CLS] easily accessible stories pull together quickly resonate with profundity [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.546 (perp=7.293, rec=0.083, cos=0.004), tot_loss_proj:2.188 [t=0.23s]
prediction: ['[CLS] easily accessible stories quickly pull together resonate with profundity [SEP]']
[1050/2000] tot_loss=1.508 (perp=7.133, rec=0.077, cos=0.004), tot_loss_proj:1.951 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.505 (perp=7.133, rec=0.074, cos=0.004), tot_loss_proj:1.957 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.507 (perp=7.133, rec=0.076, cos=0.004), tot_loss_proj:1.958 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
[1200/2000] tot_loss=1.507 (perp=7.133, rec=0.076, cos=0.004), tot_loss_proj:1.961 [t=0.24s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.510 (perp=7.133, rec=0.079, cos=0.004), tot_loss_proj:1.958 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.507 (perp=7.133, rec=0.077, cos=0.004), tot_loss_proj:1.954 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
[1350/2000] tot_loss=1.511 (perp=7.133, rec=0.080, cos=0.004), tot_loss_proj:1.960 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.504 (perp=7.133, rec=0.073, cos=0.004), tot_loss_proj:1.963 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.499 (perp=7.133, rec=0.068, cos=0.004), tot_loss_proj:1.955 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
[1500/2000] tot_loss=1.504 (perp=7.133, rec=0.073, cos=0.004), tot_loss_proj:1.952 [t=0.24s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.503 (perp=7.133, rec=0.072, cos=0.004), tot_loss_proj:1.954 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.502 (perp=7.133, rec=0.071, cos=0.004), tot_loss_proj:1.951 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
[1650/2000] tot_loss=1.496 (perp=7.133, rec=0.065, cos=0.004), tot_loss_proj:1.960 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.499 (perp=7.133, rec=0.068, cos=0.004), tot_loss_proj:1.958 [t=0.24s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.508 (perp=7.133, rec=0.078, cos=0.004), tot_loss_proj:1.957 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
[1800/2000] tot_loss=1.507 (perp=7.133, rec=0.077, cos=0.004), tot_loss_proj:1.963 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.497 (perp=7.133, rec=0.067, cos=0.004), tot_loss_proj:1.953 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.508 (perp=7.133, rec=0.077, cos=0.004), tot_loss_proj:1.956 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
[1950/2000] tot_loss=1.513 (perp=7.133, rec=0.082, cos=0.004), tot_loss_proj:1.958 [t=0.24s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.500 (perp=7.133, rec=0.069, cos=0.004), tot_loss_proj:1.968 [t=0.23s]
prediction: ['[CLS] easily accessible stories easily pull together resonate with profundity [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] easily accessible stories easily pull together resonate with profundity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 60.000 | p: 60.000 | r: 60.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 150.909

[Aggregate metrics]:
rouge1     | fm: 89.625 | p: 89.882 | r: 89.572
rouge2     | fm: 57.250 | p: 57.640 | r: 57.100
rougeL     | fm: 77.120 | p: 77.546 | r: 77.072
rougeLsum  | fm: 76.873 | p: 77.180 | r: 76.813
r1fm+r2fm = 146.875

input #32 time: 0:09:14 | total time: 5:01:28


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9988376422310159
highest_index [0]
highest [0.9988376422310159]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9817966818809509 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.8627445101737976 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.8586774468421936 for ['[CLS] bar [SEP]']
[Init] best rec loss: 0.843533456325531 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8102300763130188 for ['[CLS] training [SEP]']
[Init] best rec loss: 0.7778821587562561 for ['[CLS] strip [SEP]']
[Init] best rec loss: 0.7623671293258667 for ['[CLS] frame [SEP]']
[Init] best rec loss: 0.7262676358222961 for ['[CLS] railroad [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.799 (perp=11.231, rec=0.458, cos=0.095), tot_loss_proj:2.608 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.595 (perp=11.231, rec=0.291, cos=0.058), tot_loss_proj:2.402 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.536 (perp=11.231, rec=0.201, cos=0.089), tot_loss_proj:2.443 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.499 (perp=11.231, rec=0.196, cos=0.056), tot_loss_proj:2.412 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.527 (perp=11.231, rec=0.207, cos=0.074), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.528 (perp=11.231, rec=0.211, cos=0.071), tot_loss_proj:2.394 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.504 (perp=11.231, rec=0.169, cos=0.089), tot_loss_proj:2.394 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.537 (perp=11.231, rec=0.186, cos=0.105), tot_loss_proj:2.385 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.496 (perp=11.231, rec=0.169, cos=0.080), tot_loss_proj:2.399 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.492 (perp=11.231, rec=0.172, cos=0.074), tot_loss_proj:2.371 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.507 (perp=11.231, rec=0.180, cos=0.080), tot_loss_proj:2.394 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.492 (perp=11.231, rec=0.169, cos=0.077), tot_loss_proj:2.401 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.486 (perp=11.231, rec=0.168, cos=0.072), tot_loss_proj:2.388 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.506 (perp=11.231, rec=0.182, cos=0.078), tot_loss_proj:2.380 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.509 (perp=11.231, rec=0.193, cos=0.070), tot_loss_proj:2.381 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.498 (perp=11.231, rec=0.178, cos=0.073), tot_loss_proj:2.372 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.486 (perp=11.231, rec=0.165, cos=0.074), tot_loss_proj:2.381 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.492 (perp=11.231, rec=0.171, cos=0.074), tot_loss_proj:2.382 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.490 (perp=11.231, rec=0.169, cos=0.075), tot_loss_proj:2.373 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.481 (perp=11.231, rec=0.160, cos=0.075), tot_loss_proj:2.385 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.486 (perp=11.231, rec=0.165, cos=0.075), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.491 (perp=11.231, rec=0.170, cos=0.075), tot_loss_proj:2.385 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.486 (perp=11.231, rec=0.164, cos=0.076), tot_loss_proj:2.380 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.488 (perp=11.231, rec=0.167, cos=0.075), tot_loss_proj:2.395 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.486 (perp=11.231, rec=0.165, cos=0.075), tot_loss_proj:2.376 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.486 (perp=11.231, rec=0.164, cos=0.076), tot_loss_proj:2.385 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.487 (perp=11.231, rec=0.165, cos=0.076), tot_loss_proj:2.380 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.487 (perp=11.231, rec=0.165, cos=0.076), tot_loss_proj:2.362 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.486 (perp=11.231, rec=0.164, cos=0.076), tot_loss_proj:2.389 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.485 (perp=11.231, rec=0.163, cos=0.076), tot_loss_proj:2.367 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.495 (perp=11.231, rec=0.173, cos=0.076), tot_loss_proj:2.388 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.478 (perp=11.231, rec=0.156, cos=0.076), tot_loss_proj:2.390 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.485 (perp=11.231, rec=0.163, cos=0.076), tot_loss_proj:2.385 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.481 (perp=11.231, rec=0.159, cos=0.076), tot_loss_proj:2.393 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.490 (perp=11.231, rec=0.168, cos=0.076), tot_loss_proj:2.381 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.490 (perp=11.231, rec=0.168, cos=0.076), tot_loss_proj:2.390 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.489 (perp=11.231, rec=0.167, cos=0.076), tot_loss_proj:2.401 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.477 (perp=11.231, rec=0.155, cos=0.076), tot_loss_proj:2.383 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.485 (perp=11.231, rec=0.163, cos=0.076), tot_loss_proj:2.388 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.486 (perp=11.231, rec=0.163, cos=0.076), tot_loss_proj:2.390 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.899 | p: 90.122 | r: 89.903
rouge2     | fm: 58.482 | p: 58.841 | r: 58.237
rougeL     | fm: 77.816 | p: 78.189 | r: 77.717
rougeLsum  | fm: 77.568 | p: 77.855 | r: 77.470
r1fm+r2fm = 148.381

input #33 time: 0:09:07 | total time: 5:10:36


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.998785086454411
highest_index [0]
highest [0.998785086454411]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8342429399490356 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8167941570281982 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8158817291259766 for ['[CLS]gut tam popular xml practice got maia accompanied gaulle dateize mc full [SEP]']
[Init] best rec loss: 0.755894660949707 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.7555565237998962 for ['[CLS] paper right ‖ allies considerations inophone nassau served molecular queen hart liv [SEP]']
[Init] best rec loss: 0.7515802383422852 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 0.7403728365898132 for ['[CLS]truct way terminus week photos specifically dowager anime inducted valentin scotch watches watched [SEP]']
[Init] best rec loss: 0.7108091711997986 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.7077553272247314 for ['[CLS]ask founder ship drivers worth who slight lissa statue okayibe field along [SEP]']
[Init] best perm rec loss: 0.7037481665611267 for ['[CLS] worth founderask ship along statue who okay slight fieldibe lissa drivers [SEP]']
[Init] best perm rec loss: 0.7035030126571655 for ['[CLS] worth slightibe along who shipask drivers statue field okay founder lissa [SEP]']
[Init] best perm rec loss: 0.7028405666351318 for ['[CLS] lissaibe ship founder along drivers slight statueask okay worth field who [SEP]']
[Init] best perm rec loss: 0.7025711536407471 for ['[CLS] along lissa field ship who slightask worth drivers okay statueibe founder [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.327 (perp=10.090, rec=0.272, cos=0.037), tot_loss_proj:3.597 [t=0.23s]
prediction: ['[CLS] extreme urgency urgency te urgency rating builded extreme urgency urgency : the [SEP]']
[ 100/2000] tot_loss=2.086 (perp=9.236, rec=0.187, cos=0.052), tot_loss_proj:3.378 [t=0.23s]
prediction: ['[CLS] extreme urgency urgency mind urgency from take from extreme extreme urgency :. [SEP]']
[ 150/2000] tot_loss=1.980 (perp=8.910, rec=0.157, cos=0.041), tot_loss_proj:3.292 [t=0.23s]
prediction: ['[CLS] extreme urgency urgency mind urgency of take from extreme extreme urgency :. [SEP]']
[ 200/2000] tot_loss=2.107 (perp=9.696, rec=0.143, cos=0.025), tot_loss_proj:2.623 [t=0.24s]
prediction: ['[CLS] extreme urgency build mind urgency of take in extreme on viewer on. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.918 (perp=7.820, rec=0.224, cos=0.130), tot_loss_proj:2.053 [t=0.23s]
prediction: ['[CLS] extreme urgency build in extreme mind mind and take on viewer.. [SEP]']
[ 300/2000] tot_loss=1.742 (perp=7.929, rec=0.114, cos=0.042), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS] extreme urgency build in extreme mind mind and take on viewerouring. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.669 (perp=7.621, rec=0.118, cos=0.027), tot_loss_proj:2.205 [t=0.24s]
prediction: ['[CLS] extreme urgency build in extreme mind and mind take on viewerouring. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.660 (perp=7.621, rec=0.097, cos=0.039), tot_loss_proj:2.209 [t=0.23s]
prediction: ['[CLS] extreme urgency build in extreme mind and mind take on viewerouring. [SEP]']
[ 450/2000] tot_loss=1.640 (perp=7.519, rec=0.102, cos=0.034), tot_loss_proj:2.247 [t=0.23s]
prediction: ['[CLS] extreme urgency build in extreme mind and mind take on vieweraging. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.579 (perp=7.210, rec=0.104, cos=0.033), tot_loss_proj:1.920 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on viewer with. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.595 (perp=7.347, rec=0.095, cos=0.031), tot_loss_proj:2.109 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on viewerouring. [SEP]']
[ 600/2000] tot_loss=1.592 (perp=7.347, rec=0.092, cos=0.030), tot_loss_proj:2.109 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on viewerouring. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.595 (perp=7.347, rec=0.093, cos=0.033), tot_loss_proj:2.106 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on viewerouring. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.603 (perp=7.347, rec=0.102, cos=0.032), tot_loss_proj:2.106 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on viewerouring. [SEP]']
[ 750/2000] tot_loss=1.573 (perp=7.248, rec=0.092, cos=0.031), tot_loss_proj:2.140 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.579 (perp=7.248, rec=0.098, cos=0.031), tot_loss_proj:2.142 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.574 (perp=7.248, rec=0.094, cos=0.031), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
[ 900/2000] tot_loss=1.577 (perp=7.248, rec=0.096, cos=0.031), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.556 (perp=7.248, rec=0.079, cos=0.027), tot_loss_proj:2.144 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.577 (perp=7.248, rec=0.096, cos=0.031), tot_loss_proj:2.142 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
[1050/2000] tot_loss=1.573 (perp=7.248, rec=0.092, cos=0.032), tot_loss_proj:2.138 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.578 (perp=7.248, rec=0.093, cos=0.035), tot_loss_proj:2.135 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.578 (perp=7.248, rec=0.096, cos=0.032), tot_loss_proj:2.129 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
[1200/2000] tot_loss=1.569 (perp=7.248, rec=0.088, cos=0.031), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.248, rec=0.070, cos=0.031), tot_loss_proj:2.127 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.567 (perp=7.248, rec=0.084, cos=0.033), tot_loss_proj:2.132 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
[1350/2000] tot_loss=1.579 (perp=7.248, rec=0.091, cos=0.039), tot_loss_proj:2.130 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.568 (perp=7.248, rec=0.086, cos=0.033), tot_loss_proj:2.127 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.560 (perp=7.248, rec=0.084, cos=0.027), tot_loss_proj:2.137 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
[1500/2000] tot_loss=1.568 (perp=7.248, rec=0.090, cos=0.029), tot_loss_proj:2.135 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.576 (perp=7.248, rec=0.091, cos=0.036), tot_loss_proj:2.141 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.569 (perp=7.248, rec=0.089, cos=0.031), tot_loss_proj:2.146 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
[1650/2000] tot_loss=1.568 (perp=7.248, rec=0.088, cos=0.031), tot_loss_proj:2.136 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.571 (perp=7.248, rec=0.087, cos=0.034), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.575 (perp=7.248, rec=0.091, cos=0.035), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
[1800/2000] tot_loss=1.584 (perp=7.248, rec=0.100, cos=0.035), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.576 (perp=7.248, rec=0.091, cos=0.035), tot_loss_proj:2.133 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.572 (perp=7.248, rec=0.089, cos=0.034), tot_loss_proj:2.143 [t=0.24s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
[1950/2000] tot_loss=1.578 (perp=7.248, rec=0.094, cos=0.035), tot_loss_proj:2.131 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.580 (perp=7.248, rec=0.094, cos=0.036), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] extreme extreme urgency build in mind and mind take on vieweraging. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.074 | p: 76.923 | r: 71.429
rouge2     | fm: 24.000 | p: 25.000 | r: 23.077
rougeL     | fm: 59.259 | p: 61.538 | r: 57.143
rougeLsum  | fm: 59.259 | p: 61.538 | r: 57.143
r1fm+r2fm = 98.074

[Aggregate metrics]:
rouge1     | fm: 89.535 | p: 89.881 | r: 89.405
rouge2     | fm: 57.528 | p: 57.861 | r: 57.255
rougeL     | fm: 77.442 | p: 77.777 | r: 77.269
rougeLsum  | fm: 77.165 | p: 77.488 | r: 76.998
r1fm+r2fm = 147.063

input #34 time: 0:09:15 | total time: 5:19:51


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9987166637217899
highest_index [0]
highest [0.9987166637217899]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.903484582901001 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.8884068727493286 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best perm rec loss: 0.8882962465286255 for ['[CLS] separately ari sheriff up popularizedtrip baptist red " two strait hunt sighted art [SEP] played torn responded qatar collapsed five budget eva actually grown april talmud example lendimated side everybody seat owned among in yives swallowed closer inspired? [SEP]']
[Init] best perm rec loss: 0.8864542841911316 for ['[CLS] grown sighted in among closer april ari separately respondedimated owned inspired up red baptist everybody example seat collapsed actuallyives hunt popularized side? lend y two five played art " talmudtrip budget sheriff strait qatar torn eva swallowed [SEP] [SEP]']
[Init] best perm rec loss: 0.8852702975273132 for ['[CLS] sheriff ari eva tornimated side played? sighted up [SEP] y lend art among closer five separately ownedtrip " qatar grown example strait seat budget hunt red responded actually twoives april inspired in baptist talmud collapsed popularized everybody swallowed [SEP]']
[Init] best perm rec loss: 0.8845016360282898 for ['[CLS] april y responded among hunttripives seat [SEP] qatar talmud everybody swallowed closer lend ari popularized torn eva sighted grown owned? art red example side actually " fiveimated separately sheriff budget up inspired in played two strait baptist collapsed [SEP]']
[Init] best perm rec loss: 0.8835763335227966 for ['[CLS] owned played sheriff strait aprilimated talmud responded qatar separately collapsed everybody baptist [SEP] side closer art lend grown up popularized twoives inspired " hunt in eva budget? example red fivetrip torn y seat actually sighted ari swallowed among [SEP]']
[Init] best perm rec loss: 0.8829668164253235 for ['[CLS] up example sighted hunt qatar y lend? five inspired responded collapsedimated strait seattrip " budget played torn [SEP] baptist two swallowed april actually eva sheriff owned in art talmudives red popularized ari everybody closer side grown separately among [SEP]']
[Init] best perm rec loss: 0.881944477558136 for ['[CLS] sighted side art seat fivetrip swallowed baptist among y red budget popularized grown owned april lend played actually? in qatar " collapsed inspired closer ari eva everybodyives sheriff separately strait talmud example torn respondedimated two up hunt [SEP] [SEP]']
[Init] best perm rec loss: 0.8818005323410034 for ['[CLS] sighted played side seat ari five actually talmud strait among inspired everybody popularized art owned y? separately grown budget red baptist in two example up closer april swallowedimated eva lend sherifftrip [SEP] torn " hunt collapsedives qatar responded [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.314 (perp=12.461, rec=0.824, cos=0.998), tot_loss_proj:4.395 [t=0.24s]
prediction: ['[CLS] traders lil rejects [SEP] [MASK]aya this poison on among inspired [SEP] [SEP] [SEP]. [SEP] [SEP] mana domain [SEP]ity [SEP] sexy food [SEP] the. [SEP] reyes [SEP] prison hailey [SEP] every [SEP] distrust [CLS] [SEP] leaked,ා initial [SEP]']
[ 100/2000] tot_loss=4.141 (perp=12.019, rec=0.743, cos=0.995), tot_loss_proj:4.283 [t=0.24s]
prediction: ['[CLS] traders throughout waived [SEP] infiniteaya this poison farcala inspired [SEP] [SEP] themed. [SEP] [SEP] chaos domain [SEP] alex [SEP] trumpio [SEP] the. [SEP], [SEP] prison ate [SEP] every riders [SEP] [CLS] [SEP] leaked,ා nest [SEP]']
[ 150/2000] tot_loss=4.053 (perp=11.829, rec=0.697, cos=0.990), tot_loss_proj:4.244 [t=0.24s]
prediction: ['[CLS] traders www waived [SEP] inauguralaya this alexia farcala inspired [SEP] [SEP] kincaid. joe [SEP] chaos domain [SEP]mania [SEP]minedodies [SEP] the. [SEP], [SEP] prison ate [SEP] every japan [SEP] [CLS] [SEP] leaked,ා firm [SEP]']
[ 200/2000] tot_loss=3.951 (perp=11.471, rec=0.682, cos=0.974), tot_loss_proj:4.223 [t=0.24s]
prediction: ['[CLS] traders exists gamer [SEP] inauguralaya this alexia farcala inspired [SEP] [SEP] zach. joe [SEP] reset. [SEP]ity [SEP]minedle [SEP] the. [SEP], [SEP] muhammad emma, every japan [SEP] [CLS] [SEP] leaked,ා firm [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=4.084 (perp=11.523, rec=0.784, cos=0.996), tot_loss_proj:4.197 [t=0.24s]
prediction: ['[CLS] [SEP] patton sports beetle. midtown ultrahaus emcala [SEP] [SEP] [SEP] [CLS] since. juarez [SEP]• domain [SEP] [CLS] [SEP]. 2018 dynamic [CLS] [SEP] since [SEP] ( originally the his [SEP]edance [CLS] [SEP] tasked time ᆼ libre [SEP]']
[ 300/2000] tot_loss=3.983 (perp=11.600, rec=0.709, cos=0.954), tot_loss_proj:4.194 [t=0.24s]
prediction: ['[CLS] [SEP] patton sports beetle. midtown ultrastrom usingcala [SEP] [SEP] [SEP] [CLS] since. juarez [SEP]• domain [SEP] [CLS] [SEP]. oricon dynamic [CLS] [SEP] federer [SEP] ( basque the notable [SEP] nectar [CLS] [SEP] tasked time ᆼ tools [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=4.095 (perp=11.799, rec=0.808, cos=0.928), tot_loss_proj:4.279 [t=0.24s]
prediction: ['[CLS] [SEP] patton sport [SEP]. midtown [MASK] daemon outstream [SEP] dynamic [SEP] [SEP] chris.ła [SEP]• bike [SEP] [CLS] [SEP]. [SEP] [SEP] [CLS] [SEP] obama [SEP] ( theory the 2012 [SEP]edance [CLS] casualties tasked timeය tools [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.764 (perp=11.224, rec=0.713, cos=0.806), tot_loss_proj:4.176 [t=0.24s]
prediction: ['[CLS] [SEP] pattonedance sport [SEP]. midtown chromosome daemon outstream [SEP] dynamic [SEP] [SEP] chris.ła [SEP]• bike [SEP] [CLS] [SEP] colleagues [SEP] [SEP] control [SEP] hillary [SEP] ( theory the 2012 [SEP] [CLS] casualties tasked timeය tools [SEP]']
[ 450/2000] tot_loss=3.542 (perp=11.778, rec=0.675, cos=0.511), tot_loss_proj:4.120 [t=0.24s]
prediction: ['[CLS] [SEP] pattonedance sport [SEP] archived midtown chromosome witch outstream [SEP] dynamic [SEP] [SEP] alex.ła [SEP]• bike [SEP] [CLS] [SEP] his [SEP] [SEP] worse death hillary [SEP] ( theory the 2012 [SEP] [CLS] casualties leaked timeය tools [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.405 (perp=11.470, rec=0.659, cos=0.452), tot_loss_proj:4.084 [t=0.24s]
prediction: ['[CLS] [SEP] pattonedance sport [SEP] archived midtown chromosome witch theory the 2012 [SEP] [CLS] casualties tessa timeය tools mtstream [SEP] dynamic [SEP] [SEP] chris.ła [SEP]• expeditionary [SEP] [CLS] [SEP] his [SEP] [SEP] worse death hillary [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.236 (perp=10.861, rec=0.657, cos=0.407), tot_loss_proj:3.930 [t=0.24s]
prediction: ['[CLS] [SEP] pattonedance sport [SEP] archived midtown chromosome witch : the 2012 [SEP] [CLS] casualtiesed timeය [SEP] behaviorstream [SEP] dynamic [SEP] [SEP] chris.ła [SEP]• expeditionary [SEP] [CLS] [SEP] his tools [SEP] worse death hillary [SEP] ( [SEP]']
[ 600/2000] tot_loss=3.184 (perp=10.795, rec=0.636, cos=0.390), tot_loss_proj:3.999 [t=0.24s]
prediction: ['[CLS] [SEP] pattonedance sport [SEP] receptions midtown [MASK] witch : the 2012 [SEP] [CLS] casualtiesed timeය [SEP] behavior ain ( unique [SEP] [SEP] alex.. [SEP]• expeditionary [SEP] [CLS] [SEP] his tools [SEP] worse death hillary [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.106 (perp=10.391, rec=0.655, cos=0.373), tot_loss_proj:3.897 [t=0.24s]
prediction: ['[CLS] [SEP] pattonedance casualties [SEP] receptions midtown [MASK] witch : the 2012 [SEP] [CLS] sported timeය [SEP] behavior ain ( unique ceramic [SEP] chris.. [SEP]• expeditionary [SEP] [CLS] [SEP] his tools [SEP] worse death obama [SEP] ( [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=3.295 (perp=12.058, rec=0.750, cos=0.133), tot_loss_proj:4.103 [t=0.24s]
prediction: ['[CLS] [SEP] jo conducted usually beetle، between french chris [SEP] team [SEP] usually wildlife ; explore [SEP] stylistic bridge clerks rear [SEP] david [SEP] faye heavyweight m included [SEP] [CLS] search ji timeය [SEP] featured felt ( unique (, of [SEP]']
[ 750/2000] tot_loss=3.233 (perp=12.424, rec=0.642, cos=0.106), tot_loss_proj:4.233 [t=0.24s]
prediction: ['[CLS] [SEP] joop usually beetle، between frenchuld [SEP] team [SEP] traditionally wildlife ; flow [SEP] stylistic while clerks rear [SEP] david. faye heavyweight m included exhibitions [CLS] search ji timeය [SEP] featured felt ( unique ( or of [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.183 (perp=12.442, rec=0.605, cos=0.090), tot_loss_proj:4.191 [t=0.24s]
prediction: ['[CLS] [SEP] jean conducted usually beetle، [SEP] frenchuld [SEP] team [SEP] traditionally wildlife ; flow [SEP] stylistic while clerks rear between david. zoe heavyweight m included exhibitions [CLS] search ji time ᆼ [SEP] featured felt ( unique and or of [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.035 (perp=11.877, rec=0.570, cos=0.090), tot_loss_proj:4.170 [t=0.24s]
prediction: ['[CLS] [SEP] jeanw [CLS] beetle، [SEP] frenchuld [SEP] team [SEP] traditionally wildlife ; environment [SEP] stylistic [CLS] clerks rear between david. zoe heavyweight m included exhibitions usually search ji time ᆼ [SEP] & felt ( unique and or of [SEP]']
[ 900/2000] tot_loss=3.016 (perp=11.888, rec=0.547, cos=0.091), tot_loss_proj:4.240 [t=0.24s]
prediction: ['[CLS] [SEP] jeanw [CLS] beetle، [SEP] frenchuld [SEP] team [SEP] traditionally wildlife ; environment [SEP] stylistic [CLS] clerks rear between david. witch heavyweight m included exhibitions usually search ji time ᆼ [SEP] & rudy ( unique " or of [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.903 (perp=11.374, rec=0.542, cos=0.086), tot_loss_proj:4.180 [t=0.24s]
prediction: ['[CLS] [SEP] jeanw [CLS] beetle، [SEP] french chris [SEP] team [SEP] traditionally wildlife ; environment [SEP] stylistic clerks rear between against. contempt heavyweight m included exhibitions usually search ji [CLS] time ᆼ [SEP] & rudy ( unique " or of [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.987 (perp=11.757, rec=0.542, cos=0.094), tot_loss_proj:4.255 [t=0.24s]
prediction: ['[CLS] [SEP] jeanw [CLS] beetle، [SEP] french chris [SEP] team [SEP] traditionally wildlife ; environment [SEP] stylistic clerks rear between against. contempt heavyweight m included exhibitions usually search ji &der ᆼ [SEP] while rudy ( unique " or of [SEP]']
[1050/2000] tot_loss=2.983 (perp=11.872, rec=0.524, cos=0.085), tot_loss_proj:4.274 [t=0.24s]
prediction: ['[CLS] [SEP] jeanw [CLS] beetle، [SEP] french chris [SEP] team [SEP] traditionally wildlife ; wildlife [SEP] stylistic clerks rear between against. contempt heavyweight m included exhibitions usually search ji &der ᆼ [SEP] while rudy ( unique " or of [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.790 (perp=10.985, rec=0.512, cos=0.081), tot_loss_proj:4.103 [t=0.24s]
prediction: ['[CLS] [SEP] jayw team beetle، [SEP] french chris [SEP] [CLS] [SEP] traditionally wildlife ; wildlife [SEP] stylistic clerks rear between against. contempt heavyweight m included exhibitions usually search ji &der ᆼ [SEP] [CLS] rudy ( unique " or of [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.726 (perp=10.671, rec=0.512, cos=0.080), tot_loss_proj:4.040 [t=0.24s]
prediction: ['[CLS] [SEP] jiw team beetle، [SEP] french chris [SEP] [CLS] [SEP] traditionally wildlife ; wildlife [SEP] stylistic clerks rear between against. contempt heavyweight m included exhibitions usually search jay &der ᆼ [SEP] [CLS] rudy ( unique " or of [SEP]']
[1200/2000] tot_loss=2.774 (perp=10.986, rec=0.496, cos=0.081), tot_loss_proj:4.112 [t=0.24s]
prediction: ['[CLS] [SEP] jiw team beetle، [SEP] french chris [SEP] [CLS] [SEP] traditionally wildlife ; wildlife [SEP] stylistic clerks rear between against. contempt heavyweight m included exhibitions usually search jean &derය [SEP] [CLS] rudy ( unique " or of [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=3.051 (perp=12.008, rec=0.568, cos=0.082), tot_loss_proj:4.322 [t=0.24s]
prediction: ['[CLS] [SEP] ji [SEP] team antagonist، [SEP] frenchism [SEP]. [SEP] usually wildlife ; flow [SEP] stylistic clerks rear between against [SEP] demon heavyweight m 2012 [SEP] back searchrate jo featured select [SEP] while dreamed ( ending ", of [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.906 (perp=11.430, rec=0.542, cos=0.078), tot_loss_proj:4.166 [t=0.24s]
prediction: ['[CLS] [SEP] ji antagonist team [SEP]، [SEP] frenchism [SEP]. [SEP] usually wildlife ; flow [SEP] stylistic clerks rear between against [SEP] demon shots m 2012 [SEP] back searchrate jo featured select [SEP] while dreamed ( unique ", of [SEP]']
[1350/2000] tot_loss=2.900 (perp=11.430, rec=0.538, cos=0.076), tot_loss_proj:4.169 [t=0.24s]
prediction: ['[CLS] [SEP] ji antagonist team [SEP]، [SEP] frenchism [SEP]. [SEP] usually wildlife ; flow [SEP] stylistic clerks rear between against [SEP] demon shots m 2012 [SEP] back searchrate jo featured select [SEP] while dreamed ( unique ", of [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.865 (perp=11.296, rec=0.526, cos=0.080), tot_loss_proj:4.131 [t=0.24s]
prediction: ['[CLS] [SEP] ji antagonist team [SEP]، [SEP] frenchism [SEP]. [SEP] usually wildlife ; flow [SEP] stylistic clerks rear between against [SEP] demon, m 2012 [SEP] back searchrate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.823 (perp=11.087, rec=0.524, cos=0.082), tot_loss_proj:4.096 [t=0.24s]
prediction: ['[CLS] [SEP] ji antagonistism [SEP]، [SEP] french team [SEP]. [SEP] usually wildlife ; flow [SEP] stylistic clerks rear between against [SEP] demon, m 2012 [SEP] back searchrate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
[1500/2000] tot_loss=2.887 (perp=11.419, rec=0.521, cos=0.082), tot_loss_proj:4.152 [t=0.24s]
prediction: ['[CLS] [SEP] ji beetleism [SEP]، [SEP] french team [SEP]. [SEP] usually wildlife ; flow [SEP] stylistic clerks rear between against [SEP] demon, m 2012 [SEP] back searchrate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.818 (perp=11.069, rec=0.523, cos=0.081), tot_loss_proj:4.088 [t=0.24s]
prediction: ['[CLS] [SEP] ji beetleism [SEP]، [SEP] french team [SEP]. [SEP] usually m ; flow [SEP] stylistic clerks rear between against [SEP] demon, wildlife 2012 [SEP] back searchrate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.799 (perp=10.996, rec=0.519, cos=0.081), tot_loss_proj:4.070 [t=0.24s]
prediction: ['[CLS] [SEP] ji beetle [SEP]rew، [SEP] french team [SEP]. [SEP] usually m ; flow [SEP] stylistic clerks rear between against [SEP] demon, wildlife 2012 [SEP] back searchpate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
[1650/2000] tot_loss=2.792 (perp=10.996, rec=0.509, cos=0.083), tot_loss_proj:4.069 [t=0.24s]
prediction: ['[CLS] [SEP] ji beetle [SEP]rew، [SEP] french team [SEP]. [SEP] usually m ; flow [SEP] stylistic clerks rear between against [SEP] demon, wildlife 2012 [SEP] back searchpate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.860 (perp=11.294, rec=0.520, cos=0.081), tot_loss_proj:4.102 [t=0.24s]
prediction: ['[CLS] [SEP]rew carmen [SEP] ji، [SEP] french team [SEP]. [SEP] usually m ; flow [SEP] stylistic clerks rear between against [SEP] demon, wildlife 2012 [SEP] back searchpate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.799 (perp=11.023, rec=0.513, cos=0.081), tot_loss_proj:4.048 [t=0.24s]
prediction: ['[CLS] [SEP]rew carmen [SEP] ji، [SEP] french usually [SEP]. [SEP] team m ; flow [SEP] stylistic clerks rear between against [SEP] demon, wildlife 2012 [SEP] back searchpate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
[1800/2000] tot_loss=2.798 (perp=11.023, rec=0.512, cos=0.082), tot_loss_proj:4.044 [t=0.24s]
prediction: ['[CLS] [SEP]rew carmen [SEP] ji، [SEP] french usually [SEP]. [SEP] team m ; flow [SEP] stylistic clerks rear between against [SEP] demon, wildlife 2012 [SEP] back searchpate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.780 (perp=10.945, rec=0.507, cos=0.084), tot_loss_proj:4.008 [t=0.24s]
prediction: ['[CLS] [SEP]rew carmen [SEP] ji، [SEP] french usually [SEP]. [SEP] team m ; flow [SEP] stylistic against rear between clerks [SEP] demon, wildlife 2012 [SEP] back searchpate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=2.745 (perp=10.728, rec=0.515, cos=0.084), tot_loss_proj:3.962 [t=0.24s]
prediction: ['[CLS] [SEP] ji، [SEP] french usually [SEP]rew carmen [SEP]. [SEP] team m ; flow [SEP] stylistic against rear between clerks [SEP] demon, wildlife 2012 [SEP] back searchpate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
[1950/2000] tot_loss=2.738 (perp=10.728, rec=0.510, cos=0.082), tot_loss_proj:3.966 [t=0.24s]
prediction: ['[CLS] [SEP] ji، [SEP] french usually [SEP]rew carmen [SEP]. [SEP] team m ; flow [SEP] stylistic against rear between clerks [SEP] demon, wildlife 2012 [SEP] back searchpate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.707 (perp=10.578, rec=0.508, cos=0.083), tot_loss_proj:3.901 [t=0.24s]
prediction: ['[CLS] [SEP] ji، [SEP] against usually [SEP]rew carmen [SEP]. [SEP] team m ; flow [SEP] stylistic french rear between clerks [SEP] demon, wildlife 2012 [SEP] back searchpate jo featured select [SEP] to dreamed ( unique " shots of [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] [SEP]rew carmen [SEP] ji، [SEP] french usually [SEP]. [SEP] team m ; flow [SEP] stylistic against rear between clerks [SEP] demon, wildlife 2012 [SEP] back searchpate jo featured select [SEP] to dreamed ( unique " shots of [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 8.333 | p: 8.108 | r: 8.571
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 8.333 | p: 8.108 | r: 8.571
rougeLsum  | fm: 8.333 | p: 8.108 | r: 8.571
r1fm+r2fm = 8.333

[Aggregate metrics]:
rouge1     | fm: 87.313 | p: 87.698 | r: 87.260
rouge2     | fm: 55.796 | p: 56.086 | r: 55.603
rougeL     | fm: 75.420 | p: 75.784 | r: 75.266
rougeLsum  | fm: 75.154 | p: 75.657 | r: 75.021
r1fm+r2fm = 143.108

input #35 time: 0:09:25 | total time: 5:29:17


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.998692801261155
highest_index [0]
highest [0.998692801261155]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9532232284545898 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9489215016365051 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9071267247200012 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.8927203416824341 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 0.8886927366256714 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.8369923830032349 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best rec loss: 0.835612416267395 for ['[CLS] dormant known to mckenzie [SEP]']
[Init] best perm rec loss: 0.835577130317688 for ['[CLS] dormant mckenzie to known [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.137 (perp=10.031, rec=0.125, cos=0.006), tot_loss_proj:2.437 [t=0.23s]
prediction: ['[CLS] wrong s horribly wrong [SEP]']
[ 100/2000] tot_loss=2.101 (perp=10.031, rec=0.090, cos=0.005), tot_loss_proj:2.412 [t=0.23s]
prediction: ['[CLS] wrong s horribly wrong [SEP]']
[ 150/2000] tot_loss=1.721 (perp=8.114, rec=0.095, cos=0.004), tot_loss_proj:1.696 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 200/2000] tot_loss=1.703 (perp=8.114, rec=0.076, cos=0.004), tot_loss_proj:1.697 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 250/2000] tot_loss=1.691 (perp=8.114, rec=0.064, cos=0.004), tot_loss_proj:1.701 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 300/2000] tot_loss=1.708 (perp=8.114, rec=0.081, cos=0.005), tot_loss_proj:1.701 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 350/2000] tot_loss=1.689 (perp=8.114, rec=0.061, cos=0.005), tot_loss_proj:1.709 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 400/2000] tot_loss=1.708 (perp=8.114, rec=0.080, cos=0.005), tot_loss_proj:1.708 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 450/2000] tot_loss=1.705 (perp=8.114, rec=0.078, cos=0.005), tot_loss_proj:1.698 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.703 (perp=8.114, rec=0.076, cos=0.004), tot_loss_proj:1.701 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.694 (perp=8.114, rec=0.066, cos=0.005), tot_loss_proj:1.713 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 600/2000] tot_loss=1.704 (perp=8.114, rec=0.077, cos=0.005), tot_loss_proj:1.709 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.687 (perp=8.114, rec=0.060, cos=0.005), tot_loss_proj:1.706 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.702 (perp=8.114, rec=0.074, cos=0.005), tot_loss_proj:1.714 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 750/2000] tot_loss=1.695 (perp=8.114, rec=0.068, cos=0.005), tot_loss_proj:1.709 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.706 (perp=8.114, rec=0.078, cos=0.005), tot_loss_proj:1.710 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.707 (perp=8.114, rec=0.080, cos=0.005), tot_loss_proj:1.703 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 900/2000] tot_loss=1.697 (perp=8.114, rec=0.069, cos=0.005), tot_loss_proj:1.698 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.688 (perp=8.114, rec=0.061, cos=0.005), tot_loss_proj:1.699 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.696 (perp=8.114, rec=0.068, cos=0.005), tot_loss_proj:1.703 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1050/2000] tot_loss=1.699 (perp=8.114, rec=0.072, cos=0.005), tot_loss_proj:1.706 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.701 (perp=8.114, rec=0.074, cos=0.005), tot_loss_proj:1.698 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.697 (perp=8.114, rec=0.069, cos=0.005), tot_loss_proj:1.700 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1200/2000] tot_loss=1.689 (perp=8.114, rec=0.062, cos=0.005), tot_loss_proj:1.706 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.694 (perp=8.114, rec=0.067, cos=0.005), tot_loss_proj:1.709 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.694 (perp=8.114, rec=0.066, cos=0.005), tot_loss_proj:1.709 [t=0.24s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1350/2000] tot_loss=1.691 (perp=8.114, rec=0.063, cos=0.005), tot_loss_proj:1.700 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.701 (perp=8.114, rec=0.073, cos=0.005), tot_loss_proj:1.697 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.699 (perp=8.114, rec=0.072, cos=0.005), tot_loss_proj:1.706 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1500/2000] tot_loss=1.701 (perp=8.114, rec=0.073, cos=0.005), tot_loss_proj:1.711 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.696 (perp=8.114, rec=0.069, cos=0.005), tot_loss_proj:1.697 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.698 (perp=8.114, rec=0.071, cos=0.005), tot_loss_proj:1.703 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1650/2000] tot_loss=1.697 (perp=8.114, rec=0.069, cos=0.005), tot_loss_proj:1.699 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.705 (perp=8.114, rec=0.078, cos=0.005), tot_loss_proj:1.707 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.705 (perp=8.114, rec=0.077, cos=0.005), tot_loss_proj:1.703 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1800/2000] tot_loss=1.693 (perp=8.114, rec=0.065, cos=0.005), tot_loss_proj:1.697 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.697 (perp=8.114, rec=0.069, cos=0.005), tot_loss_proj:1.695 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.690 (perp=8.114, rec=0.062, cos=0.005), tot_loss_proj:1.703 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1950/2000] tot_loss=1.692 (perp=8.114, rec=0.065, cos=0.005), tot_loss_proj:1.710 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.695 (perp=8.114, rec=0.067, cos=0.005), tot_loss_proj:1.713 [t=0.23s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS]'s horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.657 | p: 88.074 | r: 87.586
rouge2     | fm: 56.783 | p: 57.018 | r: 56.617
rougeL     | fm: 76.086 | p: 76.402 | r: 75.962
rougeLsum  | fm: 75.824 | p: 76.217 | r: 75.658
r1fm+r2fm = 144.440

input #36 time: 0:09:13 | total time: 5:38:30


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9989864625349196
highest_index [0]
highest [0.9989864625349196]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.7644209265708923 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.7538638114929199 for ['[CLS] value commune [SEP]']
[Init] best rec loss: 0.6883479356765747 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 0.6681808829307556 for ['[CLS] out example [SEP]']
[Init] best rec loss: 0.6451050639152527 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.6244730949401855 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.6225281357765198 for ['[CLS] family forster [SEP]']
[Init] best rec loss: 0.6209133863449097 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.6097914576530457 for ['[CLS] beer city [SEP]']
[Init] best rec loss: 0.6074979901313782 for ['[CLS] colorcards [SEP]']
[Init] best rec loss: 0.6046115756034851 for ['[CLS] breeze comfortable [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.374 (perp=10.822, rec=0.167, cos=0.042), tot_loss_proj:2.496 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 100/2000] tot_loss=2.340 (perp=10.822, rec=0.136, cos=0.039), tot_loss_proj:2.491 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 150/2000] tot_loss=2.328 (perp=10.822, rec=0.129, cos=0.034), tot_loss_proj:2.502 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 200/2000] tot_loss=2.300 (perp=10.822, rec=0.105, cos=0.031), tot_loss_proj:2.502 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.295 (perp=10.822, rec=0.108, cos=0.022), tot_loss_proj:2.489 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 300/2000] tot_loss=1.977 (perp=9.583, rec=0.058, cos=0.002), tot_loss_proj:1.998 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.863 (perp=8.916, rec=0.077, cos=0.003), tot_loss_proj:2.038 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.856 (perp=8.916, rec=0.070, cos=0.002), tot_loss_proj:2.058 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[ 450/2000] tot_loss=1.843 (perp=8.916, rec=0.058, cos=0.002), tot_loss_proj:2.035 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.855 (perp=8.916, rec=0.069, cos=0.002), tot_loss_proj:2.053 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.861 (perp=8.916, rec=0.076, cos=0.002), tot_loss_proj:2.043 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
[ 600/2000] tot_loss=1.853 (perp=8.916, rec=0.068, cos=0.002), tot_loss_proj:2.043 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.852 (perp=8.916, rec=0.067, cos=0.002), tot_loss_proj:2.057 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.849 (perp=8.916, rec=0.064, cos=0.002), tot_loss_proj:2.042 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[ 750/2000] tot_loss=1.840 (perp=8.916, rec=0.055, cos=0.002), tot_loss_proj:2.054 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.850 (perp=8.916, rec=0.065, cos=0.002), tot_loss_proj:2.047 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.858 (perp=8.916, rec=0.073, cos=0.002), tot_loss_proj:2.044 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[ 900/2000] tot_loss=1.842 (perp=8.916, rec=0.056, cos=0.002), tot_loss_proj:2.045 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.847 (perp=8.916, rec=0.062, cos=0.002), tot_loss_proj:2.044 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=1.845 (perp=8.916, rec=0.059, cos=0.002), tot_loss_proj:2.047 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1050/2000] tot_loss=1.854 (perp=8.916, rec=0.069, cos=0.002), tot_loss_proj:2.040 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=1.862 (perp=8.916, rec=0.077, cos=0.002), tot_loss_proj:2.048 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=1.850 (perp=8.916, rec=0.065, cos=0.002), tot_loss_proj:2.041 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1200/2000] tot_loss=1.856 (perp=8.916, rec=0.071, cos=0.002), tot_loss_proj:2.047 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=1.846 (perp=8.916, rec=0.060, cos=0.002), tot_loss_proj:2.048 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=1.861 (perp=8.916, rec=0.076, cos=0.002), tot_loss_proj:2.054 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1350/2000] tot_loss=1.852 (perp=8.916, rec=0.066, cos=0.002), tot_loss_proj:2.056 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=1.858 (perp=8.916, rec=0.073, cos=0.002), tot_loss_proj:2.050 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=1.848 (perp=8.916, rec=0.063, cos=0.002), tot_loss_proj:2.050 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1500/2000] tot_loss=1.862 (perp=8.916, rec=0.077, cos=0.002), tot_loss_proj:2.040 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=1.852 (perp=8.916, rec=0.067, cos=0.002), tot_loss_proj:2.044 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=1.849 (perp=8.916, rec=0.064, cos=0.002), tot_loss_proj:2.046 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1650/2000] tot_loss=1.840 (perp=8.916, rec=0.055, cos=0.002), tot_loss_proj:2.046 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=1.847 (perp=8.916, rec=0.061, cos=0.002), tot_loss_proj:2.052 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=1.853 (perp=8.916, rec=0.068, cos=0.002), tot_loss_proj:2.048 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1800/2000] tot_loss=1.850 (perp=8.916, rec=0.065, cos=0.002), tot_loss_proj:2.048 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=1.861 (perp=8.916, rec=0.076, cos=0.002), tot_loss_proj:2.057 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=1.853 (perp=8.916, rec=0.068, cos=0.002), tot_loss_proj:2.062 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1950/2000] tot_loss=1.853 (perp=8.916, rec=0.068, cos=0.002), tot_loss_proj:2.055 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=1.842 (perp=8.916, rec=0.057, cos=0.002), tot_loss_proj:2.055 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] and eccentric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.951 | p: 88.313 | r: 87.818
rouge2     | fm: 55.679 | p: 56.029 | r: 55.418
rougeL     | fm: 75.895 | p: 76.264 | r: 75.773
rougeLsum  | fm: 75.851 | p: 76.226 | r: 75.661
r1fm+r2fm = 143.630

input #37 time: 0:09:12 | total time: 5:47:43


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9986487250284595
highest_index [0]
highest [0.9986487250284595]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.821014404296875 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.7774980068206787 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7461855411529541 for ['[CLS] 1960s [SEP]']
[Init] best rec loss: 0.7204669117927551 for ['[CLS] blame [SEP]']
[Init] best rec loss: 0.719445526599884 for ['[CLS] end [SEP]']
[Init] best rec loss: 0.6641393303871155 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.925 (perp=14.070, rec=0.098, cos=0.013), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.883 (perp=14.070, rec=0.067, cos=0.003), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.866 (perp=14.070, rec=0.049, cos=0.003), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.886 (perp=14.070, rec=0.069, cos=0.003), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.882 (perp=14.070, rec=0.063, cos=0.005), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.889 (perp=14.070, rec=0.072, cos=0.003), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.873 (perp=14.070, rec=0.056, cos=0.003), tot_loss_proj:2.881 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.884 (perp=14.070, rec=0.067, cos=0.003), tot_loss_proj:2.873 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.878 (perp=14.070, rec=0.061, cos=0.003), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.868 (perp=14.070, rec=0.051, cos=0.003), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.877 (perp=14.070, rec=0.061, cos=0.003), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.888 (perp=14.070, rec=0.071, cos=0.003), tot_loss_proj:2.886 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.879 (perp=14.070, rec=0.062, cos=0.003), tot_loss_proj:2.873 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.878 (perp=14.070, rec=0.061, cos=0.003), tot_loss_proj:2.868 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.881 (perp=14.070, rec=0.065, cos=0.003), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.878 (perp=14.070, rec=0.061, cos=0.003), tot_loss_proj:2.889 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.873 (perp=14.070, rec=0.056, cos=0.003), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.867 (perp=14.070, rec=0.051, cos=0.003), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.878 (perp=14.070, rec=0.061, cos=0.003), tot_loss_proj:2.886 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.866 (perp=14.070, rec=0.049, cos=0.003), tot_loss_proj:2.866 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.871 (perp=14.070, rec=0.054, cos=0.003), tot_loss_proj:2.881 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.871 (perp=14.070, rec=0.055, cos=0.003), tot_loss_proj:2.890 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.883 (perp=14.070, rec=0.067, cos=0.003), tot_loss_proj:2.871 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.876 (perp=14.070, rec=0.059, cos=0.003), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.874 (perp=14.070, rec=0.058, cos=0.003), tot_loss_proj:2.892 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.884 (perp=14.070, rec=0.067, cos=0.003), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.882 (perp=14.070, rec=0.066, cos=0.003), tot_loss_proj:2.870 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.891 (perp=14.070, rec=0.075, cos=0.003), tot_loss_proj:2.863 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.879 (perp=14.070, rec=0.062, cos=0.003), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.882 (perp=14.070, rec=0.065, cos=0.003), tot_loss_proj:2.886 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.872 (perp=14.070, rec=0.055, cos=0.003), tot_loss_proj:2.869 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.885 (perp=14.070, rec=0.069, cos=0.003), tot_loss_proj:2.869 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.890 (perp=14.070, rec=0.073, cos=0.003), tot_loss_proj:2.883 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.868 (perp=14.070, rec=0.051, cos=0.003), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.886 (perp=14.070, rec=0.069, cos=0.003), tot_loss_proj:2.873 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.880 (perp=14.070, rec=0.063, cos=0.003), tot_loss_proj:2.873 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.872 (perp=14.070, rec=0.055, cos=0.003), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.882 (perp=14.070, rec=0.065, cos=0.003), tot_loss_proj:2.872 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.878 (perp=14.070, rec=0.061, cos=0.003), tot_loss_proj:2.892 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.880 (perp=14.070, rec=0.063, cos=0.003), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.315 | p: 88.650 | r: 88.190
rouge2     | fm: 56.814 | p: 57.155 | r: 56.548
rougeL     | fm: 76.736 | p: 77.072 | r: 76.552
rougeLsum  | fm: 76.473 | p: 76.772 | r: 76.261
r1fm+r2fm = 145.129

input #38 time: 0:09:06 | total time: 5:56:50


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9989185205528948
highest_index [0]
highest [0.9989185205528948]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 0.8017034530639648 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 0.7885900735855103 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.7854804992675781 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.7759674191474915 for ['[CLS] visitors polo free mn railway entitled about murderkar father states eventually some pet victory saddle fraternitypgtz raised real actresses from accelerator link [SEP]']
[Init] best rec loss: 0.7551543116569519 for ['[CLS] nothing fishery published hall temeraireathing earnest cabinet shame supreme illusions drown men quoteolved formation revenge negativeˈ relief legislature growl melissa silk - [SEP]']
[Init] best rec loss: 0.7391940951347351 for ['[CLS] limited symptoms impressiontor jammu runoff formationian facts wyomingful winner ankles when politics turbo our reflex happenedzzo opium look charging relation laugh [SEP]']
[Init] best perm rec loss: 0.7359463572502136 for ['[CLS] winner reflex whenian wyoming formation turbotor charging symptoms jammu opium politics laughful relation facts runoff our happened impressionzzo ankles limited look [SEP]']
[Init] best perm rec loss: 0.7350991368293762 for ['[CLS] impression opium jammu turbo when facts ankles look happened our politics limited formation wyoming chargingiantor winner relation runoffful reflexzzo laugh symptoms [SEP]']
[Init] best perm rec loss: 0.7342371344566345 for ['[CLS] reflextorzzo limited formation jammu facts impression politics when charging turbo runoff laugh symptoms wyomingful ourian look opium happened winner relation ankles [SEP]']
[Init] best perm rec loss: 0.7330246567726135 for ['[CLS] limited turbo impression look runofftor relationzzo jammu chargingian winner opiumful politics happened formation when facts reflex symptoms laugh wyoming our ankles [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.771 (perp=12.121, rec=0.323, cos=0.024), tot_loss_proj:3.840 [t=0.23s]
prediction: ['[CLS] conservative divine syndrome looks bared exile realmf culture returned received flavored new conservative finally investigative shape and nature herself ghost imperfect henry coe [SEP]']
[ 100/2000] tot_loss=2.397 (perp=10.694, rec=0.246, cos=0.012), tot_loss_proj:3.908 [t=0.24s]
prediction: ['[CLS] conservative pagan culture / lecture hiding translatedf culture hunting find texture - new conservative new addiction traditions and texture themselves hideformedtila. [SEP]']
[ 150/2000] tot_loss=2.301 (perp=10.402, rec=0.213, cos=0.008), tot_loss_proj:3.794 [t=0.24s]
prediction: ['[CLS] new pontifical culture or conservative hidingcreenf traditions death finds texture - new conservative newphonic traditions and texture reality hideformedparts. [SEP]']
[ 200/2000] tot_loss=2.349 (perp=10.771, rec=0.188, cos=0.007), tot_loss_proj:3.769 [t=0.24s]
prediction: ['[CLS] new doeswatch our conservative hide movief traditions death finds keeping - new conservative new most traditions and texture reality hidebound fiction, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.138 (perp=9.701, rec=0.190, cos=0.008), tot_loss_proj:3.596 [t=0.24s]
prediction: ['[CLS] new new movie our conservative / mostf traditions bounds finds keeping - new conservative most movie traditions and texture reality hidebound movie, [SEP]']
[ 300/2000] tot_loss=2.217 (perp=10.166, rec=0.173, cos=0.011), tot_loss_proj:3.615 [t=0.24s]
prediction: ['[CLS] new is movie most conservative dwight mostf makingbound finds giving - new conservative the movie traditions and texture reality hidebound movie. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.049 (perp=9.447, rec=0.153, cos=0.007), tot_loss_proj:3.262 [t=0.24s]
prediction: ['[CLS] new dwight movie most conservative is mostf makingbound finds giving - new conservative the movie traditions and texture our hidebound movie. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.026 (perp=9.375, rec=0.145, cos=0.006), tot_loss_proj:2.717 [t=0.24s]
prediction: ['[CLS] new lay movie most conservative new mostf makingbound finds giving conservative new - the movie traditions and texture our hidebound movie. [SEP]']
[ 450/2000] tot_loss=2.099 (perp=9.753, rec=0.142, cos=0.006), tot_loss_proj:3.197 [t=0.24s]
prediction: ['[CLS] new kay movie most conservative your ourf makingbound finds giving conservative it - their movie traditions and texture our hidebound movie. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.962 (perp=9.154, rec=0.120, cos=0.011), tot_loss_proj:3.453 [t=0.24s]
prediction: ['[CLS] new / movie most conservative your our. our gives finds gives conservative it - among movie traditions and texture making hidebound movie. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.826 (perp=8.535, rec=0.113, cos=0.006), tot_loss_proj:2.962 [t=0.24s]
prediction: ['[CLS] new / movie most conservative your our. our conservative finds gives gives it - one movie traditions and texture making hidebound movie. [SEP]']
[ 600/2000] tot_loss=1.759 (perp=8.148, rec=0.124, cos=0.006), tot_loss_proj:2.707 [t=0.24s]
prediction: ['[CLS] new / movie most conservative new our. our conservative finds gives gives it and one movie traditions and texture making hidebound movie. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.707 (perp=8.024, rec=0.099, cos=0.003), tot_loss_proj:2.510 [t=0.24s]
prediction: ['[CLS] new new movie most conservative new our. our conservative finds gives it and gives one movie traditions and texture making hidebound it. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.712 (perp=7.975, rec=0.111, cos=0.006), tot_loss_proj:2.636 [t=0.24s]
prediction: ['[CLS] new new movie most conservative gives our by our conservative finds new it and gives one movie traditions and texture making hidebound it, [SEP]']
[ 750/2000] tot_loss=1.652 (perp=7.781, rec=0.092, cos=0.003), tot_loss_proj:2.428 [t=0.24s]
prediction: ['[CLS] new new movie most conservative gives our. our conservative finds new it and gives one movie traditions and texture making hidebound it, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.699 (perp=7.992, rec=0.098, cos=0.003), tot_loss_proj:2.478 [t=0.24s]
prediction: ['[CLS] new new reality most conservative gives our. our conservative finds new and it gives one movie traditions and texture making hidebound it, [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.527 (perp=7.223, rec=0.079, cos=0.003), tot_loss_proj:2.289 [t=0.24s]
prediction: ['[CLS] our new new reality most conservative gives. our conservative finds new and it gives one movie traditions and texture making hidebound it, [SEP]']
[ 900/2000] tot_loss=1.541 (perp=7.223, rec=0.093, cos=0.003), tot_loss_proj:2.291 [t=0.24s]
prediction: ['[CLS] our new new reality most conservative gives. our conservative finds new and it gives one movie traditions and texture making hidebound it, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.533 (perp=7.223, rec=0.086, cos=0.003), tot_loss_proj:2.284 [t=0.24s]
prediction: ['[CLS] our new new reality most conservative gives. our conservative finds new and it gives one movie traditions and texture making hidebound it, [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.573 (perp=7.443, rec=0.081, cos=0.003), tot_loss_proj:2.309 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative gives. our conservative finds new and gives one movie traditions and texture making hidebound it, [SEP]']
[1050/2000] tot_loss=1.592 (perp=7.520, rec=0.085, cos=0.003), tot_loss_proj:2.307 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative gives reality our conservative finds new and gives one movie traditions and texture making hidebound it, [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.572 (perp=7.419, rec=0.085, cos=0.003), tot_loss_proj:2.438 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative new reality our conservative finds gives and gives one movie traditions and texture making hidebound it, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.582 (perp=7.502, rec=0.079, cos=0.003), tot_loss_proj:2.327 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative new. our conservative finds gives and gives one movie traditions and texture making hidebound it, [SEP]']
[1200/2000] tot_loss=1.576 (perp=7.502, rec=0.073, cos=0.003), tot_loss_proj:2.326 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative new. our conservative finds gives and gives one movie traditions and texture making hidebound it, [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.571 (perp=7.443, rec=0.080, cos=0.003), tot_loss_proj:2.350 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative reality our new conservative finds gives and gives one movie traditions and texture making hidebound it, [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.539 (perp=7.235, rec=0.089, cos=0.003), tot_loss_proj:2.615 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative reality our new conservative finds gives and gives one movie traditions and texture making it hidebound, [SEP]']
[1350/2000] tot_loss=1.531 (perp=7.235, rec=0.082, cos=0.003), tot_loss_proj:2.621 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative reality our new conservative finds gives and gives one movie traditions and texture making it hidebound, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.522 (perp=7.235, rec=0.072, cos=0.003), tot_loss_proj:2.621 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative reality our new conservative finds gives and gives one movie traditions and texture making it hidebound, [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.478 (perp=6.966, rec=0.082, cos=0.003), tot_loss_proj:2.812 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative our new conservative finds gives and gives reality one movie traditions and texture making it hidebound, [SEP]']
[1500/2000] tot_loss=1.529 (perp=7.229, rec=0.081, cos=0.003), tot_loss_proj:3.086 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative our new conservative finds gives and of reality one movie traditions and texture making it hidebound, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.523 (perp=7.229, rec=0.075, cos=0.003), tot_loss_proj:3.087 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative our new conservative finds gives and of reality one movie traditions and texture making it hidebound, [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.473 (perp=6.936, rec=0.083, cos=0.003), tot_loss_proj:3.022 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative our new conservative gives and finds of reality one movie traditions and texture making it hidebound, [SEP]']
[1650/2000] tot_loss=1.470 (perp=6.936, rec=0.080, cos=0.003), tot_loss_proj:3.015 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative our new conservative gives and finds of reality one movie traditions and texture making it hidebound, [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.432 (perp=6.711, rec=0.087, cos=0.003), tot_loss_proj:2.663 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative and new conservative gives our finds of reality one movie traditions and texture making it hidebound, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.434 (perp=6.711, rec=0.089, cos=0.003), tot_loss_proj:2.663 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative and new conservative gives our finds of reality one movie traditions and texture making it hidebound, [SEP]']
[1800/2000] tot_loss=1.432 (perp=6.711, rec=0.087, cos=0.003), tot_loss_proj:2.665 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative and new conservative gives our finds of reality one movie traditions and texture making it hidebound, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.424 (perp=6.711, rec=0.079, cos=0.003), tot_loss_proj:2.669 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative and new conservative gives our finds of reality one movie traditions and texture making it hidebound, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.424 (perp=6.711, rec=0.079, cos=0.003), tot_loss_proj:2.664 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative and new conservative gives our finds of reality one movie traditions and texture making it hidebound, [SEP]']
[1950/2000] tot_loss=1.417 (perp=6.711, rec=0.072, cos=0.003), tot_loss_proj:2.666 [t=0.24s]
prediction: ['[CLS] our new new reality, most conservative and new conservative gives our finds of reality one movie traditions and texture making it hidebound, [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.374 (perp=6.469, rec=0.078, cos=0.003), tot_loss_proj:2.619 [t=0.24s]
prediction: ['[CLS] our new reality, most conservative and new conservative gives our new finds of reality one movie traditions and texture making it hidebound, [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] our new new reality, most conservative and new conservative gives our finds of reality one movie traditions and texture making it hidebound, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.304 | p: 87.500 | r: 95.455
rouge2     | fm: 18.182 | p: 17.391 | r: 19.048
rougeL     | fm: 43.478 | p: 41.667 | r: 45.455
rougeLsum  | fm: 43.478 | p: 41.667 | r: 45.455
r1fm+r2fm = 109.486

[Aggregate metrics]:
rouge1     | fm: 88.380 | p: 88.603 | r: 88.290
rouge2     | fm: 56.167 | p: 56.390 | r: 55.942
rougeL     | fm: 75.678 | p: 76.005 | r: 75.667
rougeLsum  | fm: 75.649 | p: 75.903 | r: 75.610
r1fm+r2fm = 144.547

input #39 time: 0:09:22 | total time: 6:06:12


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9987594208645716
highest_index [0]
highest [0.9987594208645716]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9638748168945312 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9474213719367981 for ['[CLS] comeback was and ste up random staff med league [SEP]']
[Init] best rec loss: 0.9107111692428589 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.8919899463653564 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 0.882747232913971 for ['[CLS] of transferred charlotte play troy also soon instantly was [SEP]']
[Init] best rec loss: 0.8767090439796448 for ['[CLS] rep survival goal coral began hoc in protection barry [SEP]']
[Init] best rec loss: 0.869378387928009 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 0.8619301915168762 for ['[CLS]anto rather mor via smoke promote fearless goo burst [SEP]']
[Init] best rec loss: 0.8503440618515015 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 0.8292664289474487 for ['[CLS]lum head original navigation investigatingwell position ruleduron [SEP]']
[Init] best rec loss: 0.7838518619537354 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.7832688093185425 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.7788876295089722 for ['[CLS]° already deciding abd georgian kent but many lady [SEP]']
[Init] best perm rec loss: 0.7774747014045715 for ['[CLS] but many lady georgian° deciding already abd kent [SEP]']
[Init] best perm rec loss: 0.7773165106773376 for ['[CLS] lady abd but° deciding many already georgian kent [SEP]']
[Init] best perm rec loss: 0.7757274508476257 for ['[CLS] many deciding georgian lady° but already abd kent [SEP]']
[Init] best perm rec loss: 0.7754411697387695 for ['[CLS] deciding already° but georgian abd many lady kent [SEP]']
[Init] best perm rec loss: 0.775316596031189 for ['[CLS]° but kent many abd lady already deciding georgian [SEP]']
[Init] best perm rec loss: 0.7747762799263 for ['[CLS] many but already lady° deciding abd kent georgian [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.159 (perp=14.314, rec=0.281, cos=0.015), tot_loss_proj:3.714 [t=0.23s]
prediction: ['[CLS] stupid collegiatemmelmmel classroom dudleyonypal imagery [SEP]']
[ 100/2000] tot_loss=2.555 (perp=11.590, rec=0.225, cos=0.012), tot_loss_proj:3.150 [t=0.23s]
prediction: ['[CLS]ony /mmelmmel withony phony imagery [SEP]']
[ 150/2000] tot_loss=2.367 (perp=10.971, rec=0.164, cos=0.008), tot_loss_proj:3.048 [t=0.23s]
prediction: ['[CLS]ony ormmelmmel withony phony imagery [SEP]']
[ 200/2000] tot_loss=1.932 (perp=9.073, rec=0.113, cos=0.005), tot_loss_proj:2.268 [t=0.23s]
prediction: ['[CLS]ony ormmel us with imagery phony imagery [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.702 (perp=7.940, rec=0.110, cos=0.004), tot_loss_proj:1.923 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony imagery [SEP]']
[ 300/2000] tot_loss=1.693 (perp=7.940, rec=0.102, cos=0.004), tot_loss_proj:1.927 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony imagery [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.687 (perp=7.940, rec=0.096, cos=0.004), tot_loss_proj:1.921 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony imagery [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.679 (perp=7.940, rec=0.088, cos=0.003), tot_loss_proj:1.921 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony imagery [SEP]']
[ 450/2000] tot_loss=1.678 (perp=7.940, rec=0.087, cos=0.003), tot_loss_proj:1.932 [t=0.24s]
prediction: ['[CLS]onymmel us with imagery or phony imagery [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.686 (perp=7.940, rec=0.095, cos=0.003), tot_loss_proj:1.931 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony imagery [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.686 (perp=7.940, rec=0.094, cos=0.004), tot_loss_proj:1.929 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony imagery [SEP]']
[ 600/2000] tot_loss=1.684 (perp=7.940, rec=0.093, cos=0.003), tot_loss_proj:1.933 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony imagery [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.676 (perp=7.940, rec=0.085, cos=0.003), tot_loss_proj:1.933 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony imagery [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.678 (perp=7.940, rec=0.087, cos=0.003), tot_loss_proj:1.933 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony imagery [SEP]']
[ 750/2000] tot_loss=1.668 (perp=7.940, rec=0.077, cos=0.003), tot_loss_proj:1.937 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony imagery [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.707 (perp=8.125, rec=0.079, cos=0.003), tot_loss_proj:1.997 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony music [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.706 (perp=8.125, rec=0.078, cos=0.003), tot_loss_proj:1.988 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony music [SEP]']
[ 900/2000] tot_loss=1.718 (perp=8.125, rec=0.090, cos=0.003), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony music [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.702 (perp=8.125, rec=0.074, cos=0.003), tot_loss_proj:1.984 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony music [SEP]']
Attempt swap
[1000/2000] tot_loss=1.700 (perp=8.125, rec=0.072, cos=0.003), tot_loss_proj:1.989 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony music [SEP]']
[1050/2000] tot_loss=1.707 (perp=8.125, rec=0.079, cos=0.003), tot_loss_proj:1.987 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony music [SEP]']
Attempt swap
[1100/2000] tot_loss=1.702 (perp=8.125, rec=0.074, cos=0.003), tot_loss_proj:1.988 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony music [SEP]']
Attempt swap
[1150/2000] tot_loss=1.710 (perp=8.125, rec=0.083, cos=0.003), tot_loss_proj:1.956 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony music [SEP]']
[1200/2000] tot_loss=1.709 (perp=8.125, rec=0.082, cos=0.003), tot_loss_proj:1.966 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony music [SEP]']
Attempt swap
[1250/2000] tot_loss=1.693 (perp=8.125, rec=0.065, cos=0.003), tot_loss_proj:1.967 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or phony music [SEP]']
Attempt swap
[1300/2000] tot_loss=1.975 (perp=9.515, rec=0.069, cos=0.003), tot_loss_proj:2.663 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or puony music [SEP]']
[1350/2000] tot_loss=1.986 (perp=9.515, rec=0.080, cos=0.003), tot_loss_proj:2.665 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or puony music [SEP]']
Attempt swap
[1400/2000] tot_loss=1.985 (perp=9.515, rec=0.080, cos=0.003), tot_loss_proj:2.659 [t=0.23s]
prediction: ['[CLS]onymmel us with imagery or puony music [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.901 (perp=9.033, rec=0.091, cos=0.004), tot_loss_proj:2.434 [t=0.23s]
prediction: ['[CLS]onymmel us with puony imagery or music [SEP]']
[1500/2000] tot_loss=1.678 (perp=7.962, rec=0.083, cos=0.003), tot_loss_proj:1.847 [t=0.23s]
prediction: ['[CLS]onymmel us with phony imagery or music [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.653 (perp=7.778, rec=0.094, cos=0.003), tot_loss_proj:1.934 [t=0.23s]
prediction: ['[CLS]onymmel us with phony music or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.648 (perp=7.778, rec=0.089, cos=0.003), tot_loss_proj:1.934 [t=0.23s]
prediction: ['[CLS]onymmel us with phony music or imagery [SEP]']
[1650/2000] tot_loss=1.637 (perp=7.778, rec=0.079, cos=0.003), tot_loss_proj:1.942 [t=0.23s]
prediction: ['[CLS]onymmel us with phony music or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.638 (perp=7.778, rec=0.079, cos=0.003), tot_loss_proj:1.930 [t=0.23s]
prediction: ['[CLS]onymmel us with phony music or imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.637 (perp=7.778, rec=0.078, cos=0.003), tot_loss_proj:1.940 [t=0.24s]
prediction: ['[CLS]onymmel us with phony music or imagery [SEP]']
[1800/2000] tot_loss=1.642 (perp=7.778, rec=0.084, cos=0.003), tot_loss_proj:1.945 [t=0.23s]
prediction: ['[CLS]onymmel us with phony music or imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.640 (perp=7.778, rec=0.082, cos=0.003), tot_loss_proj:1.931 [t=0.23s]
prediction: ['[CLS]onymmel us with phony music or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.629 (perp=7.778, rec=0.071, cos=0.003), tot_loss_proj:1.937 [t=0.23s]
prediction: ['[CLS]onymmel us with phony music or imagery [SEP]']
[1950/2000] tot_loss=1.630 (perp=7.778, rec=0.072, cos=0.003), tot_loss_proj:1.932 [t=0.23s]
prediction: ['[CLS]onymmel us with phony music or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.626 (perp=7.778, rec=0.068, cos=0.003), tot_loss_proj:1.941 [t=0.23s]
prediction: ['[CLS]onymmel us with phony music or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS]onymmel us with imagery or puony music [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 115.278

[Aggregate metrics]:
rouge1     | fm: 88.147 | p: 88.316 | r: 88.165
rouge2     | fm: 55.681 | p: 55.976 | r: 55.508
rougeL     | fm: 75.893 | p: 76.112 | r: 75.730
rougeLsum  | fm: 75.448 | p: 75.783 | r: 75.423
r1fm+r2fm = 143.828

input #40 time: 0:09:13 | total time: 6:15:26


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.9988746031740718
highest_index [0]
highest [0.9988746031740718]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.907608687877655 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9074802398681641 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.8948246836662292 for ['[CLS] mascara plenty [SEP]']
[Init] best rec loss: 0.8387754559516907 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 0.8122804760932922 for ['[CLS] cale fate [SEP]']
[Init] best perm rec loss: 0.8051304221153259 for ['[CLS] fate cale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.061 (perp=9.391, rec=0.178, cos=0.004), tot_loss_proj:2.623 [t=0.23s]
prediction: ['[CLS] sensitive sensitive [SEP]']
[ 100/2000] tot_loss=2.663 (perp=12.912, rec=0.078, cos=0.003), tot_loss_proj:2.808 [t=0.23s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 150/2000] tot_loss=2.656 (perp=12.912, rec=0.071, cos=0.002), tot_loss_proj:2.804 [t=0.23s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 200/2000] tot_loss=2.661 (perp=12.912, rec=0.076, cos=0.002), tot_loss_proj:2.815 [t=0.23s]
prediction: ['[CLS] sensitive consistently [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.130 (perp=10.212, rec=0.084, cos=0.003), tot_loss_proj:2.119 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.002), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.002), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.002), tot_loss_proj:2.113 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.117 (perp=10.212, rec=0.073, cos=0.002), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.095 (perp=10.212, rec=0.050, cos=0.002), tot_loss_proj:2.123 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.098 (perp=10.212, rec=0.053, cos=0.002), tot_loss_proj:2.121 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.002), tot_loss_proj:2.109 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.002), tot_loss_proj:2.104 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.091 (perp=10.212, rec=0.046, cos=0.002), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.102 (perp=10.212, rec=0.057, cos=0.002), tot_loss_proj:2.116 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.099 (perp=10.212, rec=0.054, cos=0.002), tot_loss_proj:2.114 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.116 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.102 (perp=10.212, rec=0.057, cos=0.002), tot_loss_proj:2.111 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.106 (perp=10.212, rec=0.061, cos=0.002), tot_loss_proj:2.120 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.105 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.121 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.106 (perp=10.212, rec=0.061, cos=0.002), tot_loss_proj:2.105 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.002), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.002), tot_loss_proj:2.101 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.002), tot_loss_proj:2.119 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.101 (perp=10.212, rec=0.056, cos=0.002), tot_loss_proj:2.121 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.107 (perp=10.212, rec=0.062, cos=0.002), tot_loss_proj:2.114 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.111 (perp=10.212, rec=0.066, cos=0.002), tot_loss_proj:2.114 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.112 (perp=10.212, rec=0.068, cos=0.002), tot_loss_proj:2.115 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.114 (perp=10.212, rec=0.070, cos=0.002), tot_loss_proj:2.112 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.098 (perp=10.212, rec=0.053, cos=0.002), tot_loss_proj:2.123 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.109 (perp=10.212, rec=0.064, cos=0.002), tot_loss_proj:2.112 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.100 (perp=10.212, rec=0.055, cos=0.002), tot_loss_proj:2.119 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.102 (perp=10.212, rec=0.057, cos=0.002), tot_loss_proj:2.113 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.123 (perp=10.212, rec=0.078, cos=0.002), tot_loss_proj:2.116 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.111 (perp=10.212, rec=0.066, cos=0.002), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.098 (perp=10.212, rec=0.053, cos=0.002), tot_loss_proj:2.122 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.105 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.120 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.104 (perp=10.212, rec=0.059, cos=0.002), tot_loss_proj:2.112 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.111 (perp=10.212, rec=0.066, cos=0.002), tot_loss_proj:2.107 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.095 (perp=10.212, rec=0.050, cos=0.002), tot_loss_proj:2.122 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.487 | p: 88.730 | r: 88.452
rouge2     | fm: 56.426 | p: 56.778 | r: 56.187
rougeL     | fm: 76.459 | p: 76.651 | r: 76.417
rougeLsum  | fm: 76.114 | p: 76.413 | r: 76.020
r1fm+r2fm = 144.913

input #41 time: 0:09:12 | total time: 6:24:39


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9986213592732328
highest_index [0]
highest [0.9986213592732328]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9113878607749939 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8203765749931335 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8144280910491943 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.7969782948493958 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.7730544209480286 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7725010514259338 for ['[CLS] ran treaty wish internationalbegiblectric cutures offended enough stagestaking superseded ever darers liftedpling maple kitchen scale assignment larger attracted banda [SEP]']
[Init] best perm rec loss: 0.7714151740074158 for ['[CLS] internationalbe cut assignment maple enough banda attractedgible dare stages largerrs treaty supersededuresctrictaking wish lifted scale everpling kitchen offended ran [SEP]']
[Init] best perm rec loss: 0.7704849243164062 for ['[CLS] darersctric ever international kitchen cut assignment enough superseded scalebe lifted maple larger treaty banda rantaking stagesgible offended attractedplingures wish [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.860 (perp=12.860, rec=0.272, cos=0.015), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] break ceased kidnap began crazy. re sabha britney wrong actually administration equipment iec re cheese reelection legislation they station they poorly explanation poorly poorly poorly [SEP]']
[ 100/2000] tot_loss=2.716 (perp=12.501, rec=0.208, cos=0.008), tot_loss_proj:3.131 [t=0.24s]
prediction: ['[CLS] halfway forgot guthrie began mono. re filmmakers canceled forgot anything filmmakers scary jets re regger residency theyddy they forgot into forgot poorly poorly [SEP]']
[ 150/2000] tot_loss=2.553 (perp=11.928, rec=0.161, cos=0.006), tot_loss_proj:3.036 [t=0.24s]
prediction: ['[CLS] halfway forgot terrorist as mono. re filmmakers chevy forgot anything to scary forces fi regger residency they into theygger into forgot poorly into [SEP]']
[ 200/2000] tot_loss=2.587 (perp=12.212, rec=0.139, cos=0.006), tot_loss_proj:3.168 [t=0.24s]
prediction: ['[CLS] halfway situations guthrie as his. re filmmakers scary forgot anything to scary anyway deeply schoolgger fatal they into theygger into forgot poorly into [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.485 (perp=11.693, rec=0.141, cos=0.006), tot_loss_proj:3.031 [t=0.24s]
prediction: ['[CLS] halfway scary spielberg as a a re filmmakers setting forgot anything to scary lectures rear school into fatal theygger theygger into forgot poorly into [SEP]']
[ 300/2000] tot_loss=2.406 (perp=11.134, rec=0.170, cos=0.009), tot_loss_proj:3.051 [t=0.24s]
prediction: ['[CLS] halfway scaryitaire as a a re filmmakers setting included anything to scary beings oricon school into fatal theygger theygger into forgot poorly into [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.397 (perp=11.410, rec=0.111, cos=0.004), tot_loss_proj:3.138 [t=0.24s]
prediction: ['[CLS] halfway scary welles as a setting re filmmakers a include anything to scary programs rear school into fatal theygger theygger attraction forgot poorly into [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.260 (perp=10.759, rec=0.105, cos=0.004), tot_loss_proj:3.262 [t=0.24s]
prediction: ['[CLS] halfway to projects emotion as a setting re filmmakers. include anything scary s genre school into fatal theyji theygger attraction forgot poorly into [SEP]']
[ 450/2000] tot_loss=2.271 (perp=10.835, rec=0.101, cos=0.004), tot_loss_proj:3.144 [t=0.24s]
prediction: ['[CLS] halfway to scary emotion as a setting re filmmakers a include anything scary surrent school into fatal theyji theygger attraction forgot poorly into [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.253 (perp=10.796, rec=0.091, cos=0.003), tot_loss_proj:2.960 [t=0.24s]
prediction: ['[CLS] halfway to scary welles as a setting re filmmakers a include into scary sate school anything fatal.ji theygger attraction forgot poorly into [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.075 (perp=9.900, rec=0.092, cos=0.003), tot_loss_proj:2.846 [t=0.24s]
prediction: ['[CLS] halfway to scary welles as a setting re filmmakers. include into scary s the school anything fatal. theyjigger attraction forgot poorly into [SEP]']
[ 600/2000] tot_loss=2.101 (perp=10.056, rec=0.086, cos=0.003), tot_loss_proj:3.198 [t=0.24s]
prediction: ['[CLS] halfway to scary welles as a setting re filmmakers. include into scary s the school anything fatal fatal theyjigger attraction forgot poorly into [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.197 (perp=10.528, rec=0.088, cos=0.003), tot_loss_proj:3.270 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re filmmakers. include into scary s the school anything fatal fatal theyjigger attraction forgot poorly into [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.171 (perp=10.388, rec=0.090, cos=0.003), tot_loss_proj:3.102 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re filmmakers a include into scary s school the anything fatal fatal theyjigger attraction forgot poorly into [SEP]']
[ 750/2000] tot_loss=2.087 (perp=9.999, rec=0.085, cos=0.003), tot_loss_proj:3.104 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re filmmakers. include into scary s school the anything fatal attraction theyjigger attraction forgot poorly into [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.062 (perp=9.926, rec=0.074, cos=0.003), tot_loss_proj:3.143 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re filmmakers. include scary into s school the anything fatal attraction theyjigger attraction forgot poorly into [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.013 (perp=9.620, rec=0.086, cos=0.003), tot_loss_proj:3.133 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re filmmakers. include scary into s school the anything fatal attraction attractionjigger they forgot poorly into [SEP]']
[ 900/2000] tot_loss=2.005 (perp=9.620, rec=0.078, cos=0.003), tot_loss_proj:3.127 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re filmmakers. include scary into s school the anything fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.979 (perp=9.513, rec=0.073, cos=0.003), tot_loss_proj:3.046 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re scary. include filmmakers into s school the anything fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.926 (perp=9.172, rec=0.088, cos=0.003), tot_loss_proj:2.735 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re scary anything. include filmmakers into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
[1050/2000] tot_loss=1.915 (perp=9.172, rec=0.078, cos=0.003), tot_loss_proj:2.733 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re scary anything. include filmmakers into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.852 (perp=8.830, rec=0.083, cos=0.003), tot_loss_proj:2.703 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re scary anything. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
[1150/2000] tot_loss=1.847 (perp=8.830, rec=0.078, cos=0.003), tot_loss_proj:2.704 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re scary anything. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
[1200/2000] tot_loss=1.842 (perp=8.830, rec=0.073, cos=0.003), tot_loss_proj:2.699 [t=0.24s]
prediction: ['[CLS] halfway to projects as a setting welles re scary anything. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.817 (perp=8.710, rec=0.072, cos=0.003), tot_loss_proj:2.622 [t=0.24s]
prediction: ['[CLS] halfway to scary as a setting welles re projects anything. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.842 (perp=8.783, rec=0.083, cos=0.003), tot_loss_proj:2.648 [t=0.24s]
prediction: ['[CLS] halfway to scary as a setting re attraction projects anything. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
[1350/2000] tot_loss=1.839 (perp=8.783, rec=0.080, cos=0.003), tot_loss_proj:2.652 [t=0.24s]
prediction: ['[CLS] halfway to scary as a setting re attraction projects anything. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.802 (perp=8.659, rec=0.067, cos=0.003), tot_loss_proj:2.669 [t=0.24s]
prediction: ['[CLS] halfway to attraction as a setting re scary projects anything. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
[1450/2000] tot_loss=1.803 (perp=8.659, rec=0.068, cos=0.003), tot_loss_proj:2.671 [t=0.24s]
prediction: ['[CLS] halfway to attraction as a setting re scary projects anything. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
[1500/2000] tot_loss=1.808 (perp=8.659, rec=0.074, cos=0.003), tot_loss_proj:2.672 [t=0.24s]
prediction: ['[CLS] halfway to attraction as a setting re scary projects anything. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.800 (perp=8.593, rec=0.079, cos=0.003), tot_loss_proj:2.741 [t=0.24s]
prediction: ['[CLS] to halfway attraction as a setting re scary projects anything. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.790 (perp=8.513, rec=0.085, cos=0.003), tot_loss_proj:2.699 [t=0.24s]
prediction: ['[CLS] to halfway attraction as a setting re projects anything scary. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
[1650/2000] tot_loss=1.787 (perp=8.513, rec=0.082, cos=0.003), tot_loss_proj:2.700 [t=0.24s]
prediction: ['[CLS] to halfway attraction as a setting re projects anything scary. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
[1700/2000] tot_loss=1.786 (perp=8.513, rec=0.081, cos=0.003), tot_loss_proj:2.702 [t=0.24s]
prediction: ['[CLS] to halfway attraction as a setting re projects anything scary. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
[1750/2000] tot_loss=1.789 (perp=8.513, rec=0.083, cos=0.003), tot_loss_proj:2.706 [t=0.24s]
prediction: ['[CLS] to halfway attraction as a setting re projects anything scary. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
[1800/2000] tot_loss=1.790 (perp=8.513, rec=0.084, cos=0.003), tot_loss_proj:2.699 [t=0.24s]
prediction: ['[CLS] to halfway attraction as a setting re projects anything scary. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
[1850/2000] tot_loss=1.785 (perp=8.513, rec=0.080, cos=0.003), tot_loss_proj:2.703 [t=0.24s]
prediction: ['[CLS] to halfway attraction as a setting re projects anything scary. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
[1900/2000] tot_loss=1.833 (perp=8.765, rec=0.077, cos=0.003), tot_loss_proj:2.724 [t=0.24s]
prediction: ['[CLS] to halfway attraction as a setting re project anything scary. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
[1950/2000] tot_loss=1.826 (perp=8.765, rec=0.070, cos=0.003), tot_loss_proj:2.726 [t=0.24s]
prediction: ['[CLS] to halfway attraction as a setting re project anything scary. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.907 (perp=9.149, rec=0.075, cos=0.003), tot_loss_proj:2.656 [t=0.24s]
prediction: ['[CLS] to halfway attraction as a setting re school anything scary high filmmakers include into s project the fatal attraction attractionjigger they forgot poorly into [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] halfway to attraction as a setting re scary projects anything. filmmakers include into s school the fatal attraction attractionjigger they forgot poorly into [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.633 | p: 80.000 | r: 83.333
rouge2     | fm: 4.255 | p: 4.167 | r: 4.348
rougeL     | fm: 28.571 | p: 28.000 | r: 29.167
rougeLsum  | fm: 28.571 | p: 28.000 | r: 29.167
r1fm+r2fm = 85.888

[Aggregate metrics]:
rouge1     | fm: 88.167 | p: 88.403 | r: 88.208
rouge2     | fm: 55.222 | p: 55.554 | r: 55.065
rougeL     | fm: 75.257 | p: 75.562 | r: 75.285
rougeLsum  | fm: 75.165 | p: 75.421 | r: 75.076
r1fm+r2fm = 143.389

input #42 time: 0:09:23 | total time: 6:34:02


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9985427909090956
highest_index [0]
highest [0.9985427909090956]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9609465003013611 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9214500188827515 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.829851508140564 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 0.8114163279533386 for ['[CLS] emma " companyographer [SEP]']
[Init] best rec loss: 0.7806299328804016 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.7537593841552734 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.7088493704795837 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.6936152577400208 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 0.6917591691017151 for ['[CLS]bus second climbck [SEP]']
[Init] best perm rec loss: 0.6893463730812073 for ['[CLS] climb secondbusck [SEP]']
[Init] best perm rec loss: 0.6892675161361694 for ['[CLS]ckbus climb second [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.022 (perp=8.942, rec=0.226, cos=0.008), tot_loss_proj:2.177 [t=0.23s]
prediction: ['[CLS] naisticissistic [SEP]']
[ 100/2000] tot_loss=1.919 (perp=8.942, rec=0.126, cos=0.005), tot_loss_proj:2.188 [t=0.23s]
prediction: ['[CLS] naisticissistic [SEP]']
[ 150/2000] tot_loss=1.082 (perp=5.048, rec=0.069, cos=0.004), tot_loss_proj:1.097 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 200/2000] tot_loss=1.071 (perp=5.048, rec=0.059, cos=0.003), tot_loss_proj:1.088 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.081 (perp=5.048, rec=0.069, cos=0.003), tot_loss_proj:1.094 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.095 (perp=5.048, rec=0.082, cos=0.004), tot_loss_proj:1.085 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.088 (perp=5.048, rec=0.074, cos=0.005), tot_loss_proj:1.077 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.072 (perp=5.048, rec=0.060, cos=0.003), tot_loss_proj:1.079 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.067 (perp=5.048, rec=0.054, cos=0.003), tot_loss_proj:1.095 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.060 (perp=5.048, rec=0.047, cos=0.003), tot_loss_proj:1.083 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.068 (perp=5.048, rec=0.056, cos=0.003), tot_loss_proj:1.090 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.087 (perp=5.048, rec=0.074, cos=0.003), tot_loss_proj:1.077 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.057 (perp=5.048, rec=0.044, cos=0.003), tot_loss_proj:1.082 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.071 (perp=5.048, rec=0.059, cos=0.003), tot_loss_proj:1.074 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.081 (perp=5.048, rec=0.068, cos=0.003), tot_loss_proj:1.074 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.073 (perp=5.048, rec=0.060, cos=0.003), tot_loss_proj:1.072 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.076 (perp=5.048, rec=0.064, cos=0.003), tot_loss_proj:1.077 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.069 (perp=5.048, rec=0.057, cos=0.003), tot_loss_proj:1.076 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.073 (perp=5.048, rec=0.060, cos=0.003), tot_loss_proj:1.087 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.081 (perp=5.048, rec=0.069, cos=0.003), tot_loss_proj:1.079 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.069 (perp=5.048, rec=0.057, cos=0.003), tot_loss_proj:1.077 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.087 (perp=5.048, rec=0.075, cos=0.003), tot_loss_proj:1.079 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.051 (perp=5.048, rec=0.038, cos=0.003), tot_loss_proj:1.082 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.060 (perp=5.048, rec=0.047, cos=0.003), tot_loss_proj:1.070 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.074 (perp=5.048, rec=0.061, cos=0.003), tot_loss_proj:1.074 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.081 (perp=5.048, rec=0.069, cos=0.003), tot_loss_proj:1.086 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.075 (perp=5.048, rec=0.062, cos=0.003), tot_loss_proj:1.067 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.077 (perp=5.048, rec=0.064, cos=0.003), tot_loss_proj:1.075 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.076 (perp=5.048, rec=0.064, cos=0.003), tot_loss_proj:1.077 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.062 (perp=5.048, rec=0.049, cos=0.003), tot_loss_proj:1.087 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.079 (perp=5.048, rec=0.066, cos=0.003), tot_loss_proj:1.079 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.071 (perp=5.048, rec=0.059, cos=0.003), tot_loss_proj:1.082 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.075 (perp=5.048, rec=0.062, cos=0.003), tot_loss_proj:1.085 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.067 (perp=5.048, rec=0.055, cos=0.003), tot_loss_proj:1.072 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.069 (perp=5.048, rec=0.056, cos=0.003), tot_loss_proj:1.079 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.075 (perp=5.048, rec=0.063, cos=0.003), tot_loss_proj:1.076 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.081 (perp=5.048, rec=0.068, cos=0.003), tot_loss_proj:1.081 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.069 (perp=5.048, rec=0.056, cos=0.003), tot_loss_proj:1.085 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.064 (perp=5.048, rec=0.052, cos=0.003), tot_loss_proj:1.077 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.064 (perp=5.048, rec=0.051, cos=0.003), tot_loss_proj:1.083 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.506 | p: 88.715 | r: 88.597
rouge2     | fm: 56.280 | p: 56.537 | r: 56.091
rougeL     | fm: 75.908 | p: 76.214 | r: 75.833
rougeLsum  | fm: 75.632 | p: 75.933 | r: 75.495
r1fm+r2fm = 144.786

input #43 time: 0:09:13 | total time: 6:43:16


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.9986865462621975
highest_index [0]
highest [0.9986865462621975]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9396542906761169 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9389026165008545 for ['[CLS] here supporters psycho fighting at portal seconds published break store among color telegramachcing applicable stress tow ways been cervical landing wrists makes grew code dale visual crowley [SEP]']
[Init] best rec loss: 0.9149457812309265 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.8902158141136169 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best perm rec loss: 0.8859724402427673 for ['[CLS] reader maxim ib somelewoodssa oil corinne warfare broadcasters peninsular bob game sr hold voice sum kali tensions beside major tied stone filed old tigers provincesif [CLS] [SEP]']
[Init] best perm rec loss: 0.8851507306098938 for ['[CLS] hold bob oil kali major warfare stonelewood tensions old sr maxim reader tigers broadcasters gameif [CLS] voice peninsular some provinces sum filedssa tied beside ib corinne [SEP]']
[Init] best perm rec loss: 0.8840115666389465 for ['[CLS]ssa tied filed broadcasters corinne tensions major provinces oil sum game hold sr tigers stone besideif oldlewood peninsular voice reader ib maxim warfare kali [CLS] bob some [SEP]']
[Init] best perm rec loss: 0.8832765221595764 for ['[CLS]ssa reader major old some voice [CLS] stone oil warfare tied sr tensions maximlewood kali filedif provinces bob sum ib tigers corinne broadcasters peninsular game beside hold [SEP]']
[Init] best perm rec loss: 0.8825867176055908 for ['[CLS] major sr hold some beside provinceslewood old ib corinne reader [CLS] oil maxim warfareif peninsular broadcasters voice kali bob tigers game stone tied sum filed tensionsssa [SEP]']
[Init] best perm rec loss: 0.8792216181755066 for ['[CLS] tigerslewood warfareif peninsular oil game tensions ib hold bob [CLS] provinces reader stone corinne sum voice maxim old broadcastersssa major tied sr some beside kali filed [SEP]']
[Init] best perm rec loss: 0.8791227340698242 for ['[CLS] voice broadcasters sumlewood beside [CLS]if sr stone warfare bob tensions filed tied major oil game peninsular provinces hold maxim some tigers ibssa old corinne reader kali [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.512 (perp=11.266, rec=0.249, cos=0.010), tot_loss_proj:3.013 [t=0.23s]
prediction: ['[CLS] lost the lost translation / routine least between the translation routine theatrical translationgo losing comedyglers plotini. aggregatorausen massive devices? destroyed withoutfusion translation [SEP]']
[ 100/2000] tot_loss=2.472 (perp=11.471, rec=0.170, cos=0.007), tot_loss_proj:2.917 [t=0.24s]
prediction: ['[CLS] lost been lost translation thefest lost in the translation routine hollywoodducted fright another hollywood routine execution in.alicizes slack absurd an lost withoutfusion translation [SEP]']
[ 150/2000] tot_loss=2.455 (perp=10.810, rec=0.282, cos=0.011), tot_loss_proj:3.225 [t=0.24s]
prediction: ['[CLS] lost been lost translation thefest been the allows translation routine hollywoodfest. another hollywood routine execution in.alicizes slack hollywood an returns by prix translation [SEP]']
[ 200/2000] tot_loss=2.355 (perp=10.440, rec=0.257, cos=0.010), tot_loss_proj:2.659 [t=0.24s]
prediction: ['[CLS] lost been lost translation the failure been the. translation routine hollywood airing of another hollywood frequent the in. absurd hardcore ᆼ sequences makeslellan bymarketfolding [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.228 (perp=10.313, rec=0.159, cos=0.007), tot_loss_proj:2.980 [t=0.24s]
prediction: ['[CLS] lost was slack translation thealic been the. translation routine hollywoodfest of another hollywood routine the inworld slackies ᆼ premiseizeslellan byeborg. [SEP]']
[ 300/2000] tot_loss=2.182 (perp=10.193, rec=0.137, cos=0.006), tot_loss_proj:3.028 [t=0.24s]
prediction: ['[CLS] lost is slack translation thealic been the. translation routine hollywoodfest of another hollywood routine the inworld slackies ᆼ premiseizesarty uponcens. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.165 (perp=10.110, rec=0.139, cos=0.005), tot_loss_proj:2.823 [t=0.24s]
prediction: ['[CLS] lost has slack translation thealic been the translation routine hollywood.fest of another hollywood routine the inworld frighties ᆼ premiseizes constraint wherecens. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.078 (perp=9.789, rec=0.115, cos=0.004), tot_loss_proj:2.872 [t=0.24s]
prediction: ['[CLS] lost has slack translation thealic been the translation routine hollywood.fest of another hollywood routine inworld the frightized ᆼ premiseizes constraint whichplify. [SEP]']
[ 450/2000] tot_loss=2.017 (perp=9.518, rec=0.108, cos=0.004), tot_loss_proj:2.729 [t=0.24s]
prediction: ['[CLS] lost has slack translation thealic been the translation routine hollywood.fest. another hollywood routine in situation the frightized ᆼ premiseizes constraint whicherved. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.961 (perp=9.227, rec=0.111, cos=0.005), tot_loss_proj:2.793 [t=0.24s]
prediction: ['[CLS] lost slack translation has thealic been the translation routine hollywood.fest. another hollywood routine in situation the frightized ᆼ premiseizes constraint whichtwined. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.907 (perp=8.933, rec=0.116, cos=0.004), tot_loss_proj:2.452 [t=0.24s]
prediction: ['[CLS] lost slack translation has thealic been the translation routine hollywood.fest. another hollywood routine in domain which the absurdized ᆼ premiseizes constraintmissive. [SEP]']
[ 600/2000] tot_loss=1.811 (perp=8.518, rec=0.103, cos=0.004), tot_loss_proj:2.377 [t=0.24s]
prediction: ['[CLS] lost slack translation has thealic been the translation routine hollywood.fest. another hollywood routine in domain which the absurdized ᆼ premiseizes itsཔ. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.797 (perp=8.426, rec=0.107, cos=0.004), tot_loss_proj:2.376 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic been lost translation routine hollywood.fest. another hollywood routine in – which the absurdized ᆼ premiseizes itsཔ. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.757 (perp=8.230, rec=0.107, cos=0.004), tot_loss_proj:2.336 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic been lost translation ᆼ the.fest. another hollywood routine in – which the absurdized routine premiseizes.པ. [SEP]']
[ 750/2000] tot_loss=1.663 (perp=7.786, rec=0.102, cos=0.004), tot_loss_proj:2.371 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic been lost translation. the.fest. another hollywood routine in – which the absurdity routine premiseizes.པ. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.602 (perp=7.514, rec=0.095, cos=0.004), tot_loss_proj:2.318 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic been lost translation. the..fest another hollywood routine in – which the absurdity routine premiseizes. wrestlemania. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.564 (perp=7.340, rec=0.093, cos=0.004), tot_loss_proj:2.235 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic been lost translation... thefest another hollywood routine in execution which the absurdity routine premiseizes. wrestlemania. [SEP]']
[ 900/2000] tot_loss=1.560 (perp=7.340, rec=0.089, cos=0.004), tot_loss_proj:2.234 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic been lost translation... thefest another hollywood routine in execution which the absurdity routine premiseizes. wrestlemania. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.561 (perp=7.340, rec=0.090, cos=0.004), tot_loss_proj:2.226 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic been lost translation... thefest another hollywood routine in execution which the absurdity routine premiseizes. wrestlemania. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.564 (perp=7.340, rec=0.092, cos=0.004), tot_loss_proj:2.220 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic been lost translation... thefest another hollywood routine in execution which the absurdity routine premiseizes. wrestlemania. [SEP]']
[1050/2000] tot_loss=1.565 (perp=7.340, rec=0.093, cos=0.003), tot_loss_proj:2.229 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic been lost translation... thefest another hollywood routine in execution which the absurdity routine premiseizes. wrestlemania. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.544 (perp=7.257, rec=0.089, cos=0.003), tot_loss_proj:2.233 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic been lost translation....fest another hollywood routine in execution which the absurdity routine premiseizes the wrestlemania. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.525 (perp=7.133, rec=0.094, cos=0.004), tot_loss_proj:1.984 [t=0.24s]
prediction: ['[CLS] the slack translation has the translationalic been lost....fest another hollywood routine in execution which the absurdity routine premiseizes the 氵. [SEP]']
[1200/2000] tot_loss=1.483 (perp=6.951, rec=0.090, cos=0.004), tot_loss_proj:2.106 [t=0.24s]
prediction: ['[CLS] the slack translation has the translationalic been lost....fest another hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.476 (perp=6.879, rec=0.096, cos=0.003), tot_loss_proj:2.023 [t=0.24s]
prediction: ['[CLS] the slack translation has the translationalic been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.471 (perp=6.879, rec=0.092, cos=0.003), tot_loss_proj:2.016 [t=0.24s]
prediction: ['[CLS] the slack translation has the translationalic been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
[1350/2000] tot_loss=1.477 (perp=6.879, rec=0.098, cos=0.003), tot_loss_proj:2.023 [t=0.24s]
prediction: ['[CLS] the slack translation has the translationalic been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.469 (perp=6.879, rec=0.090, cos=0.003), tot_loss_proj:2.021 [t=0.24s]
prediction: ['[CLS] the slack translation has the translationalic been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.465 (perp=6.879, rec=0.085, cos=0.003), tot_loss_proj:2.015 [t=0.24s]
prediction: ['[CLS] the slack translation has the translationalic been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
[1500/2000] tot_loss=1.472 (perp=6.879, rec=0.092, cos=0.003), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] the slack translation has the translationalic been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.457 (perp=6.768, rec=0.100, cos=0.004), tot_loss_proj:2.092 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic translation been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.447 (perp=6.768, rec=0.090, cos=0.004), tot_loss_proj:2.091 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic translation been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
[1650/2000] tot_loss=1.446 (perp=6.768, rec=0.089, cos=0.004), tot_loss_proj:2.091 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic translation been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.445 (perp=6.768, rec=0.088, cos=0.004), tot_loss_proj:2.098 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic translation been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.440 (perp=6.768, rec=0.083, cos=0.004), tot_loss_proj:2.088 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic translation been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
[1800/2000] tot_loss=1.445 (perp=6.768, rec=0.088, cos=0.004), tot_loss_proj:2.093 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic translation been lost.... anotherfest hollywood routine in execution which the absurdity routine premiseizes the fastest. [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.423 (perp=6.628, rec=0.093, cos=0.004), tot_loss_proj:1.925 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic translation been lost.... anotherfest hollywood routine in execution which the absurdityizes the fastest routine premise. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.424 (perp=6.628, rec=0.095, cos=0.004), tot_loss_proj:1.919 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic translation been lost.... anotherfest hollywood routine in execution which the absurdityizes the fastest routine premise. [SEP]']
[1950/2000] tot_loss=1.410 (perp=6.628, rec=0.081, cos=0.004), tot_loss_proj:1.925 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic translation been lost.... anotherfest hollywood routine in execution which the absurdityizes the fastest routine premise. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.404 (perp=6.482, rec=0.103, cos=0.004), tot_loss_proj:1.887 [t=0.24s]
prediction: ['[CLS] the slack translation has thealic translation been lost.... anotherfest hollywood routine in which the absurdity executionizes the fastest routine premise. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] the slack translation has thealic translation been lost.... anotherfest hollywood routine in execution which the absurdityizes the fastest routine premise. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.111 | p: 72.727 | r: 69.565
rouge2     | fm: 18.605 | p: 19.048 | r: 18.182
rougeL     | fm: 48.889 | p: 50.000 | r: 47.826
rougeLsum  | fm: 48.889 | p: 50.000 | r: 47.826
r1fm+r2fm = 89.716

[Aggregate metrics]:
rouge1     | fm: 88.054 | p: 88.292 | r: 88.005
rouge2     | fm: 55.243 | p: 55.570 | r: 55.130
rougeL     | fm: 75.243 | p: 75.441 | r: 75.219
rougeLsum  | fm: 75.089 | p: 75.367 | r: 74.923
r1fm+r2fm = 143.297

input #44 time: 0:09:22 | total time: 6:52:38


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9985324041039028
highest_index [0]
highest [0.9985324041039028]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.7983801960945129 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.7340615391731262 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.7170484662055969 for ['[CLS] go land board preparatory hush dylan guantanamo grace really our guidesbian a2lic internet mor salad possible throughoutim between grey scaleitic around speech pri mil [SEP]']
[Init] best rec loss: 0.6847711205482483 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 0.6605950593948364 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.6597389578819275 for ['[CLS]2 ku tree operatedtiv bore murmured single v few letter military status special taste skin joan football ( curtis enclosedlanda gentry five entrance whoa around via [SEP]']
[Init] best perm rec loss: 0.652504026889801 for ['[CLS] around2 letter curtis ku gentry bore joan ( taste footballlanda status five v operated fewtiv military via tree murmured special skin entrance single whoa enclosed [SEP]']
[Init] best perm rec loss: 0.6522385478019714 for ['[CLS] special via v military five skin lettertiv ku bore football gentry operated2 murmured entrance status taste single joan whoa (landa few curtis enclosed around tree [SEP]']
[Init] best perm rec loss: 0.6513814926147461 for ['[CLS] enclosed football v whoa taste entrance skin letter2 aroundlanda bore tree curtis murmured via single status special ( fivetiv ku few gentry joan operated military [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.660 (perp=11.672, rec=0.306, cos=0.019), tot_loss_proj:3.077 [t=0.23s]
prediction: ['[CLS] newlyelman shownen less winkler through of picked rot - b paperulum applicationested prison -. attack - shelf tactics to pamphlet movements site newspapers [SEP]']
[ 100/2000] tot_loss=2.426 (perp=11.001, rec=0.219, cos=0.006), tot_loss_proj:3.017 [t=0.24s]
prediction: ['[CLS]aa airline -e than - than that picked bow - shelf cup shelf bowel this - - crime - shelfry - exercise movements up drama [SEP]']
[ 150/2000] tot_loss=2.134 (perp=9.884, rec=0.154, cos=0.004), tot_loss_proj:2.746 [t=0.24s]
prediction: ['[CLS] - - -ei thanel than this in bow - shelf shelf shelf bowel this - for crime -elick - exercise movements - drama [SEP]']
[ 200/2000] tot_loss=2.215 (perp=10.379, rec=0.135, cos=0.004), tot_loss_proj:2.806 [t=0.24s]
prediction: ['[CLS] - - -ei thanel than this inmm on shelf shelf shelf bowel this - in crime -elick - exercise movements - drama [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.177 (perp=10.284, rec=0.117, cos=0.003), tot_loss_proj:2.843 [t=0.24s]
prediction: ['[CLS]mm - -ei thanel than this inmmick - shelf shelf bow gi this -, crime -ick on - exercise movements - drama [SEP]']
[ 300/2000] tot_loss=2.246 (perp=10.721, rec=0.098, cos=0.003), tot_loss_proj:3.140 [t=0.24s]
prediction: ['[CLS] gi - -ei thanel than long inmmy - shelf shelf bow gi this -, crime -ick on - exercise movements - drama [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.232 (perp=10.697, rec=0.089, cos=0.003), tot_loss_proj:3.060 [t=0.24s]
prediction: ['[CLS] gi - - shoot thanel than long inmmy - shelf bow gi this -, crime - shelfick on - exercise movements shoot drama [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.080 (perp=9.899, rec=0.097, cos=0.004), tot_loss_proj:2.756 [t=0.24s]
prediction: ['[CLS] gi - - shoot thanel than long gimmy - shelf bow in this -, crime - shelfick on - exercise movements shoot drama [SEP]']
[ 450/2000] tot_loss=2.163 (perp=10.391, rec=0.082, cos=0.003), tot_loss_proj:2.953 [t=0.24s]
prediction: ['[CLS] gi - - shoot thanel than longymmy - shelf bow in this -, crime - shelfick on - exercise movements shoot drama [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.047 (perp=9.868, rec=0.070, cos=0.003), tot_loss_proj:2.907 [t=0.24s]
prediction: ['[CLS] gi - - than shootel than longymmy - shelf bow in this -, crime - shelfick on - exercise movements shoot drama [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.946 (perp=9.292, rec=0.085, cos=0.003), tot_loss_proj:2.898 [t=0.24s]
prediction: ['[CLS] gi - - than shootel than longymmy - shelf bow in this shoot, crime - shelfick on - exercise movements - drama [SEP]']
[ 600/2000] tot_loss=1.950 (perp=9.352, rec=0.077, cos=0.003), tot_loss_proj:3.022 [t=0.24s]
prediction: ['[CLS] gi - - than shootel than longymmy - shelf bow in this shoot, crime - pointick on - exercise movements - drama [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.880 (perp=9.050, rec=0.067, cos=0.003), tot_loss_proj:3.035 [t=0.24s]
prediction: ['[CLS] gi - - thanyel than longymm shoot - shelf bow in this shoot, crime - pointick on - exercise movements - drama [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.899 (perp=9.097, rec=0.076, cos=0.003), tot_loss_proj:3.120 [t=0.24s]
prediction: ['[CLS] gi - - thanyel than longymm and - shelf bow in this shoot, - pointick on crime - exercise movements - drama [SEP]']
[ 750/2000] tot_loss=1.899 (perp=9.097, rec=0.076, cos=0.003), tot_loss_proj:3.120 [t=0.24s]
prediction: ['[CLS] gi - - thanyel than longymm and - shelf bow in this shoot, - pointick on crime - exercise movements - drama [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.749 (perp=8.364, rec=0.073, cos=0.003), tot_loss_proj:2.903 [t=0.24s]
prediction: ['[CLS] gi - - than bowel than longymm and - shelfy in this shoot, - pointick on crime - exercise movements - drama [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.663 (perp=7.894, rec=0.080, cos=0.004), tot_loss_proj:2.528 [t=0.24s]
prediction: ['[CLS] gimm - than bowel than longy - and - shelfy in this shoot, - pointick on crime - exercise movements - drama [SEP]']
[ 900/2000] tot_loss=1.661 (perp=7.894, rec=0.079, cos=0.003), tot_loss_proj:2.527 [t=0.24s]
prediction: ['[CLS] gimm - than bowel than longy - and - shelfy in this shoot, - pointick on crime - exercise movements - drama [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.656 (perp=7.894, rec=0.075, cos=0.003), tot_loss_proj:2.534 [t=0.24s]
prediction: ['[CLS] gimm - than bowel than longy - and - shelfy in this shoot, - pointick on crime - exercise movements - drama [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.604 (perp=7.627, rec=0.076, cos=0.003), tot_loss_proj:2.461 [t=0.24s]
prediction: ['[CLS] gimmy - than bowel than long - and - shelfy in this shoot, - pointick on crime - exercise movements - drama [SEP]']
[1050/2000] tot_loss=1.600 (perp=7.627, rec=0.071, cos=0.003), tot_loss_proj:2.463 [t=0.24s]
prediction: ['[CLS] gimmy - than bowel than long - and - shelfy in this shoot, - pointick on crime - exercise movements - drama [SEP]']
Attempt swap
[1100/2000] tot_loss=1.605 (perp=7.627, rec=0.076, cos=0.003), tot_loss_proj:2.459 [t=0.24s]
prediction: ['[CLS] gimmy - than bowel than long - and - shelfy in this shoot, - pointick on crime - exercise movements - drama [SEP]']
Attempt swap
[1150/2000] tot_loss=1.597 (perp=7.627, rec=0.068, cos=0.003), tot_loss_proj:2.466 [t=0.24s]
prediction: ['[CLS] gimmy - than bowel than long - and - shelfy in this shoot, - pointick on crime - exercise movements - drama [SEP]']
[1200/2000] tot_loss=1.597 (perp=7.627, rec=0.069, cos=0.003), tot_loss_proj:2.461 [t=0.24s]
prediction: ['[CLS] gimmy - than bowel than long - and - shelfy in this shoot, - pointick on crime - exercise movements - drama [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.596 (perp=7.627, rec=0.068, cos=0.003), tot_loss_proj:2.490 [t=0.24s]
prediction: ['[CLS] gimmy - than bowel than long - - and shelfy in this shoot, - pointick on crime - exercise movements - drama [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.465 (perp=6.917, rec=0.079, cos=0.003), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS] gimmick - than bowel than long - - and shelfy in this shoot, - pointy on crime - exercise movements - drama [SEP]']
[1350/2000] tot_loss=1.449 (perp=6.917, rec=0.063, cos=0.003), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] gimmick - than bowel than long - - and shelfy in this shoot, - pointy on crime - exercise movements - drama [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.443 (perp=6.845, rec=0.071, cos=0.003), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS] gimmick - than bowel than long - - and shelfy in this shoot -, pointy on crime - exercise movements - drama [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.419 (perp=6.744, rec=0.067, cos=0.003), tot_loss_proj:2.219 [t=0.24s]
prediction: ['[CLS] than gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - exercise movements - drama [SEP]']
[1500/2000] tot_loss=1.425 (perp=6.744, rec=0.073, cos=0.003), tot_loss_proj:2.226 [t=0.24s]
prediction: ['[CLS] than gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - exercise movements - drama [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.391 (perp=6.570, rec=0.074, cos=0.003), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] exercise gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - than movements - drama [SEP]']
Attempt swap
[1600/2000] tot_loss=1.381 (perp=6.570, rec=0.064, cos=0.003), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] exercise gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - than movements - drama [SEP]']
[1650/2000] tot_loss=1.381 (perp=6.570, rec=0.064, cos=0.003), tot_loss_proj:2.005 [t=0.24s]
prediction: ['[CLS] exercise gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - than movements - drama [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.366 (perp=6.449, rec=0.074, cos=0.003), tot_loss_proj:1.922 [t=0.24s]
prediction: ['[CLS] exercise gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - - movements than drama [SEP]']
Attempt swap
[1750/2000] tot_loss=1.362 (perp=6.449, rec=0.069, cos=0.003), tot_loss_proj:1.919 [t=0.24s]
prediction: ['[CLS] exercise gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - - movements than drama [SEP]']
[1800/2000] tot_loss=1.368 (perp=6.449, rec=0.075, cos=0.003), tot_loss_proj:1.922 [t=0.24s]
prediction: ['[CLS] exercise gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - - movements than drama [SEP]']
Attempt swap
[1850/2000] tot_loss=1.361 (perp=6.449, rec=0.069, cos=0.003), tot_loss_proj:1.922 [t=0.24s]
prediction: ['[CLS] exercise gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - - movements than drama [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.358 (perp=6.417, rec=0.071, cos=0.003), tot_loss_proj:1.956 [t=0.24s]
prediction: ['[CLS] exercise gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - movements - than drama [SEP]']
[1950/2000] tot_loss=1.363 (perp=6.417, rec=0.076, cos=0.003), tot_loss_proj:1.959 [t=0.24s]
prediction: ['[CLS] exercise gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - movements - than drama [SEP]']
Attempt swap
[2000/2000] tot_loss=1.355 (perp=6.417, rec=0.069, cos=0.003), tot_loss_proj:1.959 [t=0.24s]
prediction: ['[CLS] exercise gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - movements - than drama [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] exercise gimmick - bowel than long - - and shelfy in this shoot -, pointy on crime - - movements than drama [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 11.765 | p: 11.765 | r: 11.765
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 89.542

[Aggregate metrics]:
rouge1     | fm: 87.793 | p: 88.078 | r: 87.774
rouge2     | fm: 54.509 | p: 54.765 | r: 54.319
rougeL     | fm: 74.668 | p: 74.912 | r: 74.591
rougeLsum  | fm: 74.468 | p: 74.799 | r: 74.410
r1fm+r2fm = 142.303

input #45 time: 0:09:23 | total time: 7:02:01


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9986962306291556
highest_index [0]
highest [0.9986962306291556]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9716669321060181 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9655133485794067 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9641508460044861 for ['[CLS] boring hungry saw colby full pride [SEP]']
[Init] best rec loss: 0.9589041471481323 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.9463059306144714 for ['[CLS] mp outside roommate isn casualtyecin [SEP]']
[Init] best perm rec loss: 0.9459474682807922 for ['[CLS] mpecin isn casualty roommate outside [SEP]']
[Init] best perm rec loss: 0.9446577429771423 for ['[CLS]ecin roommate mp casualty outside isn [SEP]']
[Init] best perm rec loss: 0.9437757134437561 for ['[CLS] roommate isnecin casualty mp outside [SEP]']
[Init] best perm rec loss: 0.9433501362800598 for ['[CLS]ecin casualty roommate outside mp isn [SEP]']
[Init] best perm rec loss: 0.9430884122848511 for ['[CLS] mp isn roommateecin outside casualty [SEP]']
[Init] best perm rec loss: 0.9430310130119324 for ['[CLS] roommateecin isn mp casualty outside [SEP]']
[Init] best perm rec loss: 0.9426451921463013 for ['[CLS] casualty roommate mp isnecin outside [SEP]']
[Init] best perm rec loss: 0.942342221736908 for ['[CLS] mp isn roommate casualty outsideecin [SEP]']
[Init] best perm rec loss: 0.9419897198677063 for ['[CLS] roommate mpecin casualty isn outside [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.326 (perp=11.681, rec=0.596, cos=0.394), tot_loss_proj:3.200 [t=0.23s]
prediction: ['[CLS] visually stagely shaped set pretty [SEP]']
[ 100/2000] tot_loss=3.278 (perp=12.140, rec=0.561, cos=0.289), tot_loss_proj:4.186 [t=0.23s]
prediction: ["[CLS] frowned stage'identities certainlyby [SEP]"]
[ 150/2000] tot_loss=3.160 (perp=11.797, rec=0.562, cos=0.238), tot_loss_proj:3.680 [t=0.23s]
prediction: ['[CLS] visually stagedly beautycopic quite [SEP]']
[ 200/2000] tot_loss=3.042 (perp=11.221, rec=0.582, cos=0.216), tot_loss_proj:4.056 [t=0.24s]
prediction: ['[CLS] visually staged ; inwardly soaked racecourse [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.750 (perp=10.106, rec=0.562, cos=0.168), tot_loss_proj:3.127 [t=0.23s]
prediction: ['[CLS] visually staged beauty certainly racially [SEP]']
[ 300/2000] tot_loss=2.784 (perp=11.115, rec=0.485, cos=0.076), tot_loss_proj:3.156 [t=0.23s]
prediction: ['[CLS] visually staged beauty slickgoodly [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.028 (perp=11.998, rec=0.498, cos=0.130), tot_loss_proj:3.610 [t=0.24s]
prediction: ['[CLS] slick staged roads visually beethoven visually [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.978 (perp=11.587, rec=0.518, cos=0.142), tot_loss_proj:3.613 [t=0.23s]
prediction: ['[CLS] slick staged visually visually carlton roads [SEP]']
[ 450/2000] tot_loss=2.932 (perp=12.142, rec=0.464, cos=0.040), tot_loss_proj:3.202 [t=0.23s]
prediction: ['[CLS] slick staged visually visually carlton success [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.861 (perp=11.841, rec=0.456, cos=0.036), tot_loss_proj:3.127 [t=0.24s]
prediction: ['[CLS] slick staged visually visually success carlton [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.962 (perp=12.143, rec=0.457, cos=0.076), tot_loss_proj:4.368 [t=0.23s]
prediction: ['[CLS] slick nonsense visually visually staged carlton [SEP]']
[ 600/2000] tot_loss=2.963 (perp=12.143, rec=0.458, cos=0.076), tot_loss_proj:4.367 [t=0.23s]
prediction: ['[CLS] slick nonsense visually visually staged carlton [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.823 (perp=11.643, rec=0.448, cos=0.046), tot_loss_proj:4.312 [t=0.23s]
prediction: ['[CLS] slick staged nonsense visually visually collingwood [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.732 (perp=11.199, rec=0.446, cos=0.046), tot_loss_proj:4.150 [t=0.23s]
prediction: ['[CLS] slick staged bullshit visually visually haydn [SEP]']
[ 750/2000] tot_loss=2.867 (perp=11.958, rec=0.438, cos=0.037), tot_loss_proj:4.391 [t=0.23s]
prediction: ['[CLS] slick staged bullshit visually visually dawned [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.746 (perp=11.363, rec=0.441, cos=0.032), tot_loss_proj:4.152 [t=0.24s]
prediction: ['[CLS] slick staged bullshit½ visually visually [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.717 (perp=11.076, rec=0.447, cos=0.055), tot_loss_proj:4.104 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
[ 900/2000] tot_loss=2.669 (perp=11.076, rec=0.431, cos=0.023), tot_loss_proj:4.100 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.683 (perp=11.076, rec=0.432, cos=0.036), tot_loss_proj:4.098 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1000/2000] tot_loss=2.665 (perp=11.076, rec=0.431, cos=0.020), tot_loss_proj:4.105 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
[1050/2000] tot_loss=2.680 (perp=11.076, rec=0.431, cos=0.033), tot_loss_proj:4.093 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1100/2000] tot_loss=2.657 (perp=11.076, rec=0.420, cos=0.022), tot_loss_proj:4.106 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1150/2000] tot_loss=2.675 (perp=11.076, rec=0.425, cos=0.034), tot_loss_proj:4.103 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
[1200/2000] tot_loss=2.670 (perp=11.076, rec=0.427, cos=0.028), tot_loss_proj:4.105 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1250/2000] tot_loss=2.698 (perp=11.076, rec=0.422, cos=0.060), tot_loss_proj:4.100 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1300/2000] tot_loss=2.672 (perp=11.076, rec=0.422, cos=0.035), tot_loss_proj:4.104 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
[1350/2000] tot_loss=2.663 (perp=11.076, rec=0.425, cos=0.023), tot_loss_proj:4.103 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1400/2000] tot_loss=2.666 (perp=11.076, rec=0.417, cos=0.034), tot_loss_proj:4.100 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1450/2000] tot_loss=2.668 (perp=11.076, rec=0.428, cos=0.025), tot_loss_proj:4.103 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
[1500/2000] tot_loss=2.658 (perp=11.076, rec=0.417, cos=0.025), tot_loss_proj:4.096 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1550/2000] tot_loss=2.653 (perp=11.076, rec=0.414, cos=0.024), tot_loss_proj:4.103 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1600/2000] tot_loss=2.641 (perp=11.076, rec=0.412, cos=0.014), tot_loss_proj:4.098 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
[1650/2000] tot_loss=2.642 (perp=11.076, rec=0.411, cos=0.016), tot_loss_proj:4.103 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1700/2000] tot_loss=2.640 (perp=11.076, rec=0.411, cos=0.014), tot_loss_proj:4.099 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1750/2000] tot_loss=2.639 (perp=11.076, rec=0.412, cos=0.012), tot_loss_proj:4.102 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
[1800/2000] tot_loss=2.658 (perp=11.076, rec=0.419, cos=0.024), tot_loss_proj:4.102 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1850/2000] tot_loss=2.636 (perp=11.076, rec=0.405, cos=0.016), tot_loss_proj:4.103 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[1900/2000] tot_loss=2.645 (perp=11.076, rec=0.415, cos=0.015), tot_loss_proj:4.098 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
[1950/2000] tot_loss=2.649 (perp=11.076, rec=0.405, cos=0.028), tot_loss_proj:4.096 [t=0.24s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Attempt swap
[2000/2000] tot_loss=2.643 (perp=11.076, rec=0.415, cos=0.013), tot_loss_proj:4.098 [t=0.23s]
prediction: ['[CLS] slick bullshit staged½ visually visually [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] slick bullshit staged½ visually visually [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 57.143 | r: 57.143
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.857 | p: 42.857 | r: 42.857
rougeLsum  | fm: 42.857 | p: 42.857 | r: 42.857
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 87.107 | p: 87.335 | r: 87.117
rouge2     | fm: 53.347 | p: 53.533 | r: 53.138
rougeL     | fm: 74.050 | p: 74.369 | r: 73.926
rougeLsum  | fm: 73.768 | p: 74.094 | r: 73.725
r1fm+r2fm = 140.454

input #46 time: 0:09:14 | total time: 7:11:16


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9986228109155785
highest_index [0]
highest [0.9986228109155785]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6789678931236267 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6564631462097168 for ['[CLS] spent excitedlychule [SEP]']
[Init] best rec loss: 0.6563543677330017 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6488214135169983 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.6406188011169434 for ['[CLS]d promises walt [SEP]']
[Init] best perm rec loss: 0.640266478061676 for ['[CLS] promisesd walt [SEP]']
[Init] best perm rec loss: 0.6402583122253418 for ['[CLS]d walt promises [SEP]']
[Init] best perm rec loss: 0.6374086737632751 for ['[CLS] walt promisesd [SEP]']
[Init] best perm rec loss: 0.6369629502296448 for ['[CLS] promises waltd [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.145 (perp=9.229, rec=0.244, cos=0.055), tot_loss_proj:2.937 [t=0.23s]
prediction: ['[CLS] transparent transparent transparent [SEP]']
[ 100/2000] tot_loss=2.556 (perp=12.131, rec=0.115, cos=0.015), tot_loss_proj:3.341 [t=0.23s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 150/2000] tot_loss=2.539 (perp=12.131, rec=0.096, cos=0.017), tot_loss_proj:3.353 [t=0.24s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 200/2000] tot_loss=2.526 (perp=12.131, rec=0.095, cos=0.004), tot_loss_proj:3.347 [t=0.23s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.523 (perp=12.131, rec=0.089, cos=0.007), tot_loss_proj:3.346 [t=0.23s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 300/2000] tot_loss=2.517 (perp=12.131, rec=0.086, cos=0.004), tot_loss_proj:3.336 [t=0.24s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.521 (perp=12.131, rec=0.086, cos=0.009), tot_loss_proj:3.343 [t=0.24s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.880 (perp=8.803, rec=0.096, cos=0.023), tot_loss_proj:1.888 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[ 450/2000] tot_loss=1.831 (perp=8.803, rec=0.068, cos=0.003), tot_loss_proj:1.883 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.831 (perp=8.803, rec=0.067, cos=0.003), tot_loss_proj:1.873 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.835 (perp=8.803, rec=0.072, cos=0.003), tot_loss_proj:1.876 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.818 (perp=8.803, rec=0.055, cos=0.003), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.822 (perp=8.803, rec=0.059, cos=0.003), tot_loss_proj:1.871 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.821 (perp=8.803, rec=0.058, cos=0.003), tot_loss_proj:1.875 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.844 (perp=8.803, rec=0.080, cos=0.003), tot_loss_proj:1.867 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.821 (perp=8.803, rec=0.057, cos=0.003), tot_loss_proj:1.858 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.831 (perp=8.803, rec=0.068, cos=0.003), tot_loss_proj:1.861 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.811 (perp=8.803, rec=0.048, cos=0.003), tot_loss_proj:1.852 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.822 (perp=8.803, rec=0.059, cos=0.003), tot_loss_proj:1.868 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.833 (perp=8.803, rec=0.070, cos=0.003), tot_loss_proj:1.855 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.826 (perp=8.803, rec=0.063, cos=0.003), tot_loss_proj:1.863 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.833 (perp=8.803, rec=0.070, cos=0.003), tot_loss_proj:1.873 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.833 (perp=8.803, rec=0.070, cos=0.003), tot_loss_proj:1.853 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.832 (perp=8.803, rec=0.069, cos=0.003), tot_loss_proj:1.862 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.822 (perp=8.803, rec=0.058, cos=0.003), tot_loss_proj:1.873 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.822 (perp=8.803, rec=0.059, cos=0.003), tot_loss_proj:1.867 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.815 (perp=8.803, rec=0.052, cos=0.003), tot_loss_proj:1.861 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.823 (perp=8.803, rec=0.060, cos=0.003), tot_loss_proj:1.865 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.831 (perp=8.803, rec=0.068, cos=0.003), tot_loss_proj:1.854 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.833 (perp=8.803, rec=0.070, cos=0.003), tot_loss_proj:1.866 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.827 (perp=8.803, rec=0.064, cos=0.003), tot_loss_proj:1.856 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.826 (perp=8.803, rec=0.063, cos=0.003), tot_loss_proj:1.868 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.814 (perp=8.803, rec=0.051, cos=0.003), tot_loss_proj:1.866 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.824 (perp=8.803, rec=0.060, cos=0.003), tot_loss_proj:1.859 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.825 (perp=8.803, rec=0.062, cos=0.003), tot_loss_proj:1.864 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.823 (perp=8.803, rec=0.060, cos=0.003), tot_loss_proj:1.852 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.824 (perp=8.803, rec=0.061, cos=0.003), tot_loss_proj:1.867 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.829 (perp=8.803, rec=0.066, cos=0.003), tot_loss_proj:1.851 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.822 (perp=8.803, rec=0.058, cos=0.003), tot_loss_proj:1.855 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.812 (perp=8.803, rec=0.048, cos=0.003), tot_loss_proj:1.863 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.448 | p: 87.606 | r: 87.422
rouge2     | fm: 54.257 | p: 54.493 | r: 54.077
rougeL     | fm: 74.718 | p: 74.966 | r: 74.626
rougeLsum  | fm: 74.360 | p: 74.576 | r: 74.382
r1fm+r2fm = 141.705

input #47 time: 0:09:14 | total time: 7:20:30


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9987240143043945
highest_index [0]
highest [0.9987240143043945]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.8765761852264404 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.874824047088623 for ['[CLS] however stage arts grounds [SEP]']
[Init] best rec loss: 0.8120085597038269 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 0.7798901796340942 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.776208758354187 for ['[CLS] graveyardtutedine runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.887 (perp=13.480, rec=0.182, cos=0.009), tot_loss_proj:3.059 [t=0.23s]
prediction: ['[CLS] rotting under rottingbell [SEP]']
[ 100/2000] tot_loss=1.527 (perp=7.107, rec=0.102, cos=0.003), tot_loss_proj:1.504 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 150/2000] tot_loss=1.490 (perp=7.107, rec=0.065, cos=0.004), tot_loss_proj:1.490 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 200/2000] tot_loss=1.484 (perp=7.107, rec=0.058, cos=0.004), tot_loss_proj:1.491 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.494 (perp=7.107, rec=0.069, cos=0.004), tot_loss_proj:1.486 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 300/2000] tot_loss=1.491 (perp=7.107, rec=0.066, cos=0.004), tot_loss_proj:1.505 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.491 (perp=7.107, rec=0.067, cos=0.003), tot_loss_proj:1.491 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.491 (perp=7.107, rec=0.066, cos=0.004), tot_loss_proj:1.484 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 450/2000] tot_loss=1.489 (perp=7.107, rec=0.064, cos=0.004), tot_loss_proj:1.491 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.487 (perp=7.107, rec=0.061, cos=0.005), tot_loss_proj:1.491 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.495 (perp=7.107, rec=0.070, cos=0.003), tot_loss_proj:1.494 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 600/2000] tot_loss=1.494 (perp=7.107, rec=0.070, cos=0.003), tot_loss_proj:1.495 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.483 (perp=7.107, rec=0.057, cos=0.004), tot_loss_proj:1.500 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.497 (perp=7.107, rec=0.073, cos=0.003), tot_loss_proj:1.490 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 750/2000] tot_loss=1.475 (perp=7.107, rec=0.050, cos=0.003), tot_loss_proj:1.489 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.485 (perp=7.107, rec=0.060, cos=0.003), tot_loss_proj:1.488 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.497 (perp=7.107, rec=0.072, cos=0.003), tot_loss_proj:1.496 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 900/2000] tot_loss=1.494 (perp=7.107, rec=0.069, cos=0.003), tot_loss_proj:1.496 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.495 (perp=7.107, rec=0.070, cos=0.003), tot_loss_proj:1.491 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.481 (perp=7.107, rec=0.056, cos=0.003), tot_loss_proj:1.491 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1050/2000] tot_loss=1.485 (perp=7.107, rec=0.060, cos=0.003), tot_loss_proj:1.494 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.479 (perp=7.107, rec=0.054, cos=0.003), tot_loss_proj:1.487 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.481 (perp=7.107, rec=0.056, cos=0.003), tot_loss_proj:1.493 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1200/2000] tot_loss=1.481 (perp=7.107, rec=0.056, cos=0.003), tot_loss_proj:1.478 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.479 (perp=7.107, rec=0.054, cos=0.003), tot_loss_proj:1.496 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.489 (perp=7.107, rec=0.064, cos=0.003), tot_loss_proj:1.490 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1350/2000] tot_loss=1.481 (perp=7.107, rec=0.057, cos=0.003), tot_loss_proj:1.495 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.492 (perp=7.107, rec=0.067, cos=0.004), tot_loss_proj:1.484 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.471 (perp=7.107, rec=0.046, cos=0.003), tot_loss_proj:1.486 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1500/2000] tot_loss=1.497 (perp=7.107, rec=0.072, cos=0.003), tot_loss_proj:1.490 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.484 (perp=7.107, rec=0.059, cos=0.003), tot_loss_proj:1.492 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.485 (perp=7.107, rec=0.060, cos=0.003), tot_loss_proj:1.484 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1650/2000] tot_loss=1.489 (perp=7.107, rec=0.064, cos=0.003), tot_loss_proj:1.493 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.489 (perp=7.107, rec=0.064, cos=0.003), tot_loss_proj:1.491 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.476 (perp=7.107, rec=0.052, cos=0.003), tot_loss_proj:1.480 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1800/2000] tot_loss=1.488 (perp=7.107, rec=0.063, cos=0.003), tot_loss_proj:1.489 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.486 (perp=7.107, rec=0.061, cos=0.003), tot_loss_proj:1.489 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.496 (perp=7.107, rec=0.071, cos=0.003), tot_loss_proj:1.490 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1950/2000] tot_loss=1.492 (perp=7.107, rec=0.067, cos=0.003), tot_loss_proj:1.489 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.485 (perp=7.107, rec=0.060, cos=0.003), tot_loss_proj:1.479 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] rotting underbelly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.722 | p: 87.961 | r: 87.684
rouge2     | fm: 55.201 | p: 55.516 | r: 54.985
rougeL     | fm: 75.201 | p: 75.452 | r: 75.123
rougeLsum  | fm: 74.894 | p: 75.198 | r: 74.851
r1fm+r2fm = 142.923

input #48 time: 0:09:13 | total time: 7:29:43


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9986518546882234
highest_index [0]
highest [0.9986518546882234]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.819808840751648 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.799677312374115 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7915059328079224 for ['[CLS] genetic slideactic nations shed lawrence oral like era calvin accept mentor [SEP]']
[Init] best rec loss: 0.7779895067214966 for ['[CLS] in before car lend only surprise securities radiation following montagu turkishpers [SEP]']
[Init] best rec loss: 0.7634280920028687 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best perm rec loss: 0.7592564225196838 for ['[CLS] longingify votes stopperation dawnxious branchoħ fort destructive [SEP]']
[Init] best perm rec loss: 0.7583871483802795 for ['[CLS]ifyxious longing stop voteso dawnperation branch fort destructiveħ [SEP]']
[Init] best perm rec loss: 0.7557752132415771 for ['[CLS]oxious stop dawn fort longingħ branchifyperation destructive votes [SEP]']
[Init] best perm rec loss: 0.7547162175178528 for ['[CLS] fort destructiveoxious longing dawn branchify stopperation votesħ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.631 (perp=11.573, rec=0.273, cos=0.043), tot_loss_proj:3.459 [t=0.23s]
prediction: ['[CLS] female exclusive heap racism contemptuous female ″ contemptuous moreuous [SEP]']
[ 100/2000] tot_loss=2.359 (perp=10.858, rec=0.170, cos=0.017), tot_loss_proj:3.015 [t=0.23s]
prediction: ['[CLS] female single the population contemptuous female possibly contempt of moreuous [SEP]']
[ 150/2000] tot_loss=2.297 (perp=10.858, rec=0.116, cos=0.010), tot_loss_proj:3.026 [t=0.23s]
prediction: ['[CLS] female single the population contemptuous female possibly contempt of moreuous [SEP]']
[ 200/2000] tot_loss=2.376 (perp=11.329, rec=0.101, cos=0.009), tot_loss_proj:3.086 [t=0.23s]
prediction: ['[CLS] female single be population contemptuous female possibly contempt of moreuous [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.011 (perp=9.607, rec=0.082, cos=0.008), tot_loss_proj:2.830 [t=0.23s]
prediction: ['[CLS] could single be population contempt the female possibly contemptuous of more [SEP]']
[ 300/2000] tot_loss=2.011 (perp=9.607, rec=0.084, cos=0.006), tot_loss_proj:2.823 [t=0.23s]
prediction: ['[CLS] could single be population contempt the female possibly contemptuous of more [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.806 (perp=8.639, rec=0.072, cos=0.006), tot_loss_proj:2.612 [t=0.23s]
prediction: ['[CLS] could be population contempt the single female possibly contemptuous of more [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.693 (perp=8.049, rec=0.077, cos=0.006), tot_loss_proj:2.367 [t=0.23s]
prediction: ['[CLS] could be contempt the single female population possibly contemptuous of more [SEP]']
[ 450/2000] tot_loss=1.693 (perp=8.049, rec=0.078, cos=0.005), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] could be contempt the single female population possibly contemptuous of more [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.592 (perp=7.580, rec=0.070, cos=0.006), tot_loss_proj:2.236 [t=0.23s]
prediction: ['[CLS] could be the single female population possibly contemptuous of more contempt [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.514 (perp=7.117, rec=0.085, cos=0.006), tot_loss_proj:2.076 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population contemptuous of more contempt [SEP]']
[ 600/2000] tot_loss=1.504 (perp=7.117, rec=0.075, cos=0.006), tot_loss_proj:2.089 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population contemptuous of more contempt [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.503 (perp=7.117, rec=0.074, cos=0.006), tot_loss_proj:2.088 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population contemptuous of more contempt [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.501 (perp=7.117, rec=0.072, cos=0.006), tot_loss_proj:2.083 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population contemptuous of more contempt [SEP]']
[ 750/2000] tot_loss=1.504 (perp=7.117, rec=0.075, cos=0.005), tot_loss_proj:2.087 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population contemptuous of more contempt [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.482 (perp=7.034, rec=0.070, cos=0.005), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.486 (perp=7.034, rec=0.074, cos=0.005), tot_loss_proj:1.990 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
[ 900/2000] tot_loss=1.491 (perp=7.034, rec=0.079, cos=0.005), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.486 (perp=7.034, rec=0.074, cos=0.005), tot_loss_proj:1.967 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1000/2000] tot_loss=1.495 (perp=7.034, rec=0.083, cos=0.005), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
[1050/2000] tot_loss=1.493 (perp=7.034, rec=0.081, cos=0.005), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1100/2000] tot_loss=1.483 (perp=7.034, rec=0.071, cos=0.005), tot_loss_proj:1.974 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1150/2000] tot_loss=1.483 (perp=7.034, rec=0.071, cos=0.005), tot_loss_proj:1.982 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
[1200/2000] tot_loss=1.484 (perp=7.034, rec=0.073, cos=0.005), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1250/2000] tot_loss=1.484 (perp=7.034, rec=0.072, cos=0.005), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1300/2000] tot_loss=1.488 (perp=7.034, rec=0.076, cos=0.005), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
[1350/2000] tot_loss=1.485 (perp=7.034, rec=0.074, cos=0.005), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1400/2000] tot_loss=1.489 (perp=7.034, rec=0.077, cos=0.005), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1450/2000] tot_loss=1.493 (perp=7.034, rec=0.081, cos=0.005), tot_loss_proj:1.985 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
[1500/2000] tot_loss=1.476 (perp=7.034, rec=0.065, cos=0.005), tot_loss_proj:1.973 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1550/2000] tot_loss=1.493 (perp=7.034, rec=0.082, cos=0.005), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1600/2000] tot_loss=1.487 (perp=7.034, rec=0.076, cos=0.005), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
[1650/2000] tot_loss=1.485 (perp=7.034, rec=0.073, cos=0.005), tot_loss_proj:1.984 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1700/2000] tot_loss=1.486 (perp=7.034, rec=0.075, cos=0.005), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1750/2000] tot_loss=1.480 (perp=7.034, rec=0.068, cos=0.005), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
[1800/2000] tot_loss=1.486 (perp=7.034, rec=0.075, cos=0.005), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1850/2000] tot_loss=1.481 (perp=7.034, rec=0.070, cos=0.005), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[1900/2000] tot_loss=1.481 (perp=7.034, rec=0.070, cos=0.004), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
[1950/2000] tot_loss=1.485 (perp=7.034, rec=0.074, cos=0.004), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Attempt swap
[2000/2000] tot_loss=1.482 (perp=7.034, rec=0.071, cos=0.004), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] could possibly be the single female population more contemptuous of contempt [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] could possibly be the single female population more contemptuous of contempt [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 69.565 | p: 66.667 | r: 72.727
rougeL     | fm: 72.000 | p: 69.231 | r: 75.000
rougeLsum  | fm: 72.000 | p: 69.231 | r: 75.000
r1fm+r2fm = 165.565

[Aggregate metrics]:
rouge1     | fm: 87.929 | p: 88.067 | r: 87.959
rouge2     | fm: 55.522 | p: 55.745 | r: 55.454
rougeL     | fm: 74.987 | p: 75.173 | r: 75.030
rougeLsum  | fm: 74.863 | p: 75.108 | r: 74.808
r1fm+r2fm = 143.451

input #49 time: 0:09:13 | total time: 7:38:57


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.9987612409235959
highest_index [0]
highest [0.9987612409235959]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.8060952425003052 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.7979437708854675 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.7946035861968994 for ['[CLS] cannon noveltyuser dino ordinance japanese deck tech alright [SEP]']
[Init] best rec loss: 0.7799516320228577 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7601026892662048 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.74761563539505 for ['[CLS] stone sex science cheeks prolific conventionwashed in once [SEP]']
[Init] best rec loss: 0.7392348051071167 for ['[CLS]sil state grade over ing fish champion woolf good [SEP]']
[Init] best perm rec loss: 0.737695574760437 for ['[CLS] state fish grade champion ing woolf goodsil over [SEP]']
[Init] best perm rec loss: 0.7371810078620911 for ['[CLS] fish woolf statesil ing champion good grade over [SEP]']
[Init] best perm rec loss: 0.7369922399520874 for ['[CLS] fish grade ing statesil woolf champion good over [SEP]']
[Init] best perm rec loss: 0.7352737784385681 for ['[CLS] champion gradesil fish over good ing state woolf [SEP]']
[Init] best perm rec loss: 0.7349147796630859 for ['[CLS] champion fish ingsil over good woolf state grade [SEP]']
[Init] best perm rec loss: 0.7347809672355652 for ['[CLS] grade champion woolf ing statesil fish over good [SEP]']
[Init] best perm rec loss: 0.7346503138542175 for ['[CLS] over grade ing fish goodsil champion state woolf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.306 (perp=9.482, rec=0.338, cos=0.071), tot_loss_proj:3.253 [t=0.23s]
prediction: ['[CLS] clever west clever half considered nonsense and half clever [SEP]']
[ 100/2000] tot_loss=2.352 (perp=10.584, rec=0.207, cos=0.029), tot_loss_proj:3.655 [t=0.23s]
prediction: ['[CLS] clever english clever half call too by half clever [SEP]']
[ 150/2000] tot_loss=2.321 (perp=10.877, rec=0.132, cos=0.013), tot_loss_proj:3.571 [t=0.23s]
prediction: ['[CLS] clever english ` half call too by half clever [SEP]']
[ 200/2000] tot_loss=2.247 (perp=10.631, rec=0.106, cos=0.015), tot_loss_proj:3.589 [t=0.23s]
prediction: ['[CLS] clever what ` half call too by half clever [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.979 (perp=9.313, rec=0.105, cos=0.012), tot_loss_proj:2.649 [t=0.23s]
prediction: ['[CLS] what ` half clever call too by half clever [SEP]']
[ 300/2000] tot_loss=1.963 (perp=9.313, rec=0.092, cos=0.009), tot_loss_proj:2.633 [t=0.23s]
prediction: ['[CLS] what ` half clever call too by half clever [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.959 (perp=9.313, rec=0.089, cos=0.007), tot_loss_proj:2.630 [t=0.23s]
prediction: ['[CLS] what ` half clever call too by half clever [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.958 (perp=9.313, rec=0.089, cos=0.007), tot_loss_proj:2.637 [t=0.23s]
prediction: ['[CLS] what ` half clever call too by half clever [SEP]']
[ 450/2000] tot_loss=2.043 (perp=9.884, rec=0.063, cos=0.003), tot_loss_proj:3.056 [t=0.23s]
prediction: ['[CLS] what ` half english call too by half clever [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.959 (perp=9.421, rec=0.071, cos=0.003), tot_loss_proj:2.853 [t=0.23s]
prediction: ['[CLS] what half ` english call too by half clever [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.927 (perp=9.288, rec=0.066, cos=0.003), tot_loss_proj:2.782 [t=0.23s]
prediction: ['[CLS] what half ` call english too by half clever [SEP]']
[ 600/2000] tot_loss=1.931 (perp=9.288, rec=0.071, cos=0.003), tot_loss_proj:2.785 [t=0.23s]
prediction: ['[CLS] what half ` call english too by half clever [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.906 (perp=9.213, rec=0.061, cos=0.003), tot_loss_proj:2.723 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.916 (perp=9.213, rec=0.071, cos=0.003), tot_loss_proj:2.716 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
[ 750/2000] tot_loss=1.921 (perp=9.213, rec=0.076, cos=0.003), tot_loss_proj:2.723 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.910 (perp=9.213, rec=0.065, cos=0.003), tot_loss_proj:2.728 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.920 (perp=9.213, rec=0.074, cos=0.003), tot_loss_proj:2.728 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
[ 900/2000] tot_loss=1.903 (perp=9.213, rec=0.058, cos=0.003), tot_loss_proj:2.725 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.911 (perp=9.213, rec=0.066, cos=0.003), tot_loss_proj:2.731 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1000/2000] tot_loss=1.918 (perp=9.213, rec=0.072, cos=0.003), tot_loss_proj:2.732 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
[1050/2000] tot_loss=1.898 (perp=9.213, rec=0.053, cos=0.003), tot_loss_proj:2.729 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.917 (perp=9.213, rec=0.072, cos=0.003), tot_loss_proj:2.734 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.919 (perp=9.213, rec=0.074, cos=0.003), tot_loss_proj:2.738 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
[1200/2000] tot_loss=1.915 (perp=9.213, rec=0.069, cos=0.003), tot_loss_proj:2.740 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.918 (perp=9.213, rec=0.073, cos=0.003), tot_loss_proj:2.729 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.911 (perp=9.213, rec=0.066, cos=0.003), tot_loss_proj:2.746 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
[1350/2000] tot_loss=1.918 (perp=9.213, rec=0.073, cos=0.003), tot_loss_proj:2.736 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1400/2000] tot_loss=1.914 (perp=9.213, rec=0.069, cos=0.003), tot_loss_proj:2.750 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.905 (perp=9.213, rec=0.060, cos=0.003), tot_loss_proj:2.741 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
[1500/2000] tot_loss=1.915 (perp=9.213, rec=0.069, cos=0.003), tot_loss_proj:2.737 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.911 (perp=9.213, rec=0.066, cos=0.003), tot_loss_proj:2.748 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.907 (perp=9.213, rec=0.062, cos=0.003), tot_loss_proj:2.738 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
[1650/2000] tot_loss=1.915 (perp=9.213, rec=0.070, cos=0.003), tot_loss_proj:2.738 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1700/2000] tot_loss=1.919 (perp=9.213, rec=0.074, cos=0.003), tot_loss_proj:2.744 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1750/2000] tot_loss=1.914 (perp=9.213, rec=0.069, cos=0.003), tot_loss_proj:2.749 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
[1800/2000] tot_loss=1.916 (perp=9.213, rec=0.071, cos=0.003), tot_loss_proj:2.740 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.914 (perp=9.213, rec=0.069, cos=0.003), tot_loss_proj:2.741 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[1900/2000] tot_loss=1.914 (perp=9.213, rec=0.069, cos=0.003), tot_loss_proj:2.735 [t=0.24s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
[1950/2000] tot_loss=1.909 (perp=9.213, rec=0.064, cos=0.003), tot_loss_proj:2.745 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.914 (perp=9.213, rec=0.069, cos=0.003), tot_loss_proj:2.744 [t=0.23s]
prediction: ['[CLS] what half call ` english too by half clever [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what half call ` english too by half clever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 22.222 | p: 22.222 | r: 22.222
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 112.222

[Aggregate metrics]:
rouge1     | fm: 87.959 | p: 88.110 | r: 88.022
rouge2     | fm: 55.020 | p: 55.210 | r: 54.925
rougeL     | fm: 74.994 | p: 75.209 | r: 74.957
rougeLsum  | fm: 74.859 | p: 75.062 | r: 74.855
r1fm+r2fm = 142.979

input #50 time: 0:09:13 | total time: 7:48:11


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9987254356892221
highest_index [0]
highest [0.9987254356892221]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.7849776148796082 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7778211832046509 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7520352005958557 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7291162014007568 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 0.7172408699989319 for ['[CLS] low reelection honest louis caps noah lieutenant quarter consequence handwriting [SEP]']
[Init] best rec loss: 0.713294267654419 for ['[CLS] thomas hugh anymore customer minute premises nuclear nothingnodro [SEP]']
[Init] best perm rec loss: 0.7108438611030579 for ['[CLS] nothing anymore premisesdro thomas nuclearno customer minute hugh [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.570 (perp=11.043, rec=0.318, cos=0.043), tot_loss_proj:3.328 [t=0.23s]
prediction: ['[CLS] funny has funny moment, sucksus sucks sucks weimar [SEP]']
[ 100/2000] tot_loss=2.371 (perp=10.628, rec=0.213, cos=0.032), tot_loss_proj:3.534 [t=0.23s]
prediction: ['[CLS] funny has funny moment. sucks funny sucks sucksous [SEP]']
[ 150/2000] tot_loss=2.510 (perp=11.511, rec=0.183, cos=0.025), tot_loss_proj:3.903 [t=0.23s]
prediction: ['[CLS] funny but funny or. sucks a sucks suckscer [SEP]']
[ 200/2000] tot_loss=2.296 (perp=10.668, rec=0.149, cos=0.014), tot_loss_proj:3.516 [t=0.23s]
prediction: ['[CLS] funny but funny or. sucks moment sucks sucks a [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.813 (perp=8.398, rec=0.117, cos=0.017), tot_loss_proj:2.697 [t=0.23s]
prediction: ['[CLS]. but funny or funny two moment sucks sucks a [SEP]']
[ 300/2000] tot_loss=1.910 (perp=8.984, rec=0.106, cos=0.007), tot_loss_proj:2.732 [t=0.23s]
prediction: ['[CLS]. but funny or funny two moment sucks sucks has [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.841 (perp=8.753, rec=0.084, cos=0.007), tot_loss_proj:2.775 [t=0.23s]
prediction: ['[CLS]. but funny or funny two moment has sucks sucks [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.573 (perp=7.429, rec=0.082, cos=0.005), tot_loss_proj:2.496 [t=0.23s]
prediction: ['[CLS] a but funny or funny two moment has sucks. [SEP]']
[ 450/2000] tot_loss=1.522 (perp=7.155, rec=0.087, cos=0.004), tot_loss_proj:2.496 [t=0.23s]
prediction: ['[CLS], but funny or funny two moment has sucks. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.517 (perp=7.155, rec=0.082, cos=0.004), tot_loss_proj:2.499 [t=0.23s]
prediction: ['[CLS], but funny or funny two moment has sucks. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.489 (perp=6.768, rec=0.125, cos=0.010), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS], but funny or funny has two moment sucks. [SEP]']
[ 600/2000] tot_loss=1.436 (perp=6.768, rec=0.080, cos=0.003), tot_loss_proj:2.394 [t=0.23s]
prediction: ['[CLS], but funny or funny has two moment sucks. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.413 (perp=6.676, rec=0.075, cos=0.002), tot_loss_proj:2.435 [t=0.23s]
prediction: ['[CLS] but, funny or funny has two moment sucks. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.415 (perp=6.676, rec=0.078, cos=0.002), tot_loss_proj:2.437 [t=0.23s]
prediction: ['[CLS] but, funny or funny has two moment sucks. [SEP]']
[ 750/2000] tot_loss=1.538 (perp=7.284, rec=0.079, cos=0.002), tot_loss_proj:2.388 [t=0.23s]
prediction: ['[CLS] but, funny or a has two moment sucks. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.418 (perp=6.709, rec=0.074, cos=0.002), tot_loss_proj:2.176 [t=0.23s]
prediction: ['[CLS] but, funny or two has a moment sucks. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.311 (perp=6.101, rec=0.087, cos=0.003), tot_loss_proj:1.883 [t=0.23s]
prediction: ['[CLS] but, moment or two has a funny sucks. [SEP]']
[ 900/2000] tot_loss=1.283 (perp=6.101, rec=0.061, cos=0.002), tot_loss_proj:1.874 [t=0.23s]
prediction: ['[CLS] but, moment or two has a funny sucks. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.245 (perp=5.789, rec=0.084, cos=0.002), tot_loss_proj:1.959 [t=0.23s]
prediction: ['[CLS] but a moment or two has, funny sucks. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.227 (perp=5.789, rec=0.067, cos=0.002), tot_loss_proj:1.964 [t=0.23s]
prediction: ['[CLS] but a moment or two has, funny sucks. [SEP]']
[1050/2000] tot_loss=1.230 (perp=5.789, rec=0.069, cos=0.002), tot_loss_proj:1.958 [t=0.23s]
prediction: ['[CLS] but a moment or two has, funny sucks. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.185 (perp=5.545, rec=0.073, cos=0.002), tot_loss_proj:1.799 [t=0.23s]
prediction: ['[CLS] but a moment or two, has funny sucks. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.080 (perp=5.054, rec=0.067, cos=0.002), tot_loss_proj:1.743 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
[1200/2000] tot_loss=1.088 (perp=5.054, rec=0.075, cos=0.002), tot_loss_proj:1.743 [t=0.24s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.083 (perp=5.054, rec=0.070, cos=0.002), tot_loss_proj:1.739 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.072 (perp=5.054, rec=0.059, cos=0.002), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
[1350/2000] tot_loss=1.083 (perp=5.054, rec=0.070, cos=0.002), tot_loss_proj:1.743 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.077 (perp=5.054, rec=0.064, cos=0.002), tot_loss_proj:1.748 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.085 (perp=5.054, rec=0.072, cos=0.002), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
[1500/2000] tot_loss=1.077 (perp=5.054, rec=0.064, cos=0.002), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.083 (perp=5.054, rec=0.070, cos=0.002), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.072 (perp=5.054, rec=0.058, cos=0.002), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
[1650/2000] tot_loss=1.077 (perp=5.054, rec=0.063, cos=0.002), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.078 (perp=5.054, rec=0.064, cos=0.002), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.074 (perp=5.054, rec=0.060, cos=0.002), tot_loss_proj:1.738 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
[1800/2000] tot_loss=1.079 (perp=5.054, rec=0.066, cos=0.002), tot_loss_proj:1.741 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.078 (perp=5.054, rec=0.065, cos=0.002), tot_loss_proj:1.743 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.081 (perp=5.054, rec=0.068, cos=0.002), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
[1950/2000] tot_loss=1.076 (perp=5.054, rec=0.062, cos=0.002), tot_loss_proj:1.746 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.086 (perp=5.054, rec=0.072, cos=0.002), tot_loss_proj:1.742 [t=0.23s]
prediction: ['[CLS] but has a moment or two, funny sucks. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] but has a moment or two, funny sucks. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 44.444 | p: 44.444 | r: 44.444
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 144.444

[Aggregate metrics]:
rouge1     | fm: 88.152 | p: 88.357 | r: 88.295
rouge2     | fm: 54.679 | p: 54.943 | r: 54.574
rougeL     | fm: 74.998 | p: 75.155 | r: 75.005
rougeLsum  | fm: 74.968 | p: 75.172 | r: 75.000
r1fm+r2fm = 142.832

input #51 time: 0:09:13 | total time: 7:57:24


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.9985525032958172
highest_index [0]
highest [0.9985525032958172]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9771040081977844 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9017195105552673 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8699781894683838 for ['[CLS] field darkedge [SEP]']
[Init] best rec loss: 0.8679328560829163 for ['[CLS] print bubba advance [SEP]']
[Init] best rec loss: 0.8678261637687683 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.7511791586875916 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7157921195030212 for ['[CLS] vocabulary football expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.537 (perp=11.737, rec=0.177, cos=0.012), tot_loss_proj:2.709 [t=0.23s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.445 (perp=11.737, rec=0.093, cos=0.005), tot_loss_proj:2.712 [t=0.23s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.183 (perp=10.491, rec=0.078, cos=0.006), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] trailer trash - [SEP]']
[ 200/2000] tot_loss=2.174 (perp=10.491, rec=0.073, cos=0.003), tot_loss_proj:2.399 [t=0.23s]
prediction: ['[CLS] trailer trash - [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.807 (perp=8.483, rec=0.106, cos=0.005), tot_loss_proj:2.148 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.768 (perp=8.483, rec=0.068, cos=0.003), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.768 (perp=8.483, rec=0.069, cos=0.003), tot_loss_proj:2.145 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.765 (perp=8.483, rec=0.066, cos=0.003), tot_loss_proj:2.142 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.753 (perp=8.483, rec=0.053, cos=0.003), tot_loss_proj:2.138 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.758 (perp=8.483, rec=0.058, cos=0.003), tot_loss_proj:2.147 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.753 (perp=8.483, rec=0.054, cos=0.003), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.767 (perp=8.483, rec=0.067, cos=0.003), tot_loss_proj:2.142 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.759 (perp=8.483, rec=0.059, cos=0.003), tot_loss_proj:2.147 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.761 (perp=8.483, rec=0.062, cos=0.003), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.767 (perp=8.483, rec=0.068, cos=0.003), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.766 (perp=8.483, rec=0.067, cos=0.003), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.758 (perp=8.483, rec=0.058, cos=0.003), tot_loss_proj:2.145 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.756 (perp=8.483, rec=0.056, cos=0.003), tot_loss_proj:2.145 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.768 (perp=8.483, rec=0.069, cos=0.003), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.774 (perp=8.483, rec=0.075, cos=0.003), tot_loss_proj:2.140 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.769 (perp=8.483, rec=0.070, cos=0.003), tot_loss_proj:2.146 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.761 (perp=8.483, rec=0.062, cos=0.003), tot_loss_proj:2.150 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.771 (perp=8.483, rec=0.072, cos=0.003), tot_loss_proj:2.151 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.763 (perp=8.483, rec=0.063, cos=0.003), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.772 (perp=8.483, rec=0.073, cos=0.003), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.769 (perp=8.483, rec=0.070, cos=0.003), tot_loss_proj:2.147 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.763 (perp=8.483, rec=0.064, cos=0.003), tot_loss_proj:2.140 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.755 (perp=8.483, rec=0.056, cos=0.003), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.762 (perp=8.483, rec=0.062, cos=0.003), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.757 (perp=8.483, rec=0.058, cos=0.003), tot_loss_proj:2.138 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.761 (perp=8.483, rec=0.062, cos=0.003), tot_loss_proj:2.137 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.767 (perp=8.483, rec=0.068, cos=0.003), tot_loss_proj:2.146 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.760 (perp=8.483, rec=0.061, cos=0.003), tot_loss_proj:2.139 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.769 (perp=8.483, rec=0.069, cos=0.003), tot_loss_proj:2.146 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.767 (perp=8.483, rec=0.068, cos=0.003), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.764 (perp=8.483, rec=0.064, cos=0.003), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.771 (perp=8.483, rec=0.071, cos=0.003), tot_loss_proj:2.147 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.752 (perp=8.483, rec=0.053, cos=0.003), tot_loss_proj:2.141 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.758 (perp=8.483, rec=0.058, cos=0.003), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.755 (perp=8.483, rec=0.056, cos=0.003), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 88.314 | p: 88.453 | r: 88.390
rouge2     | fm: 53.748 | p: 53.982 | r: 53.689
rougeL     | fm: 75.162 | p: 75.351 | r: 75.137
rougeLsum  | fm: 74.844 | p: 75.064 | r: 74.807
r1fm+r2fm = 142.062

input #52 time: 0:09:12 | total time: 8:06:37


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9986711192966593
highest_index [0]
highest [0.9986711192966593]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.7934392094612122 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.7115171551704407 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.7077348232269287 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.7006051540374756 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.6993079781532288 for ['[CLS] el peace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.774 (perp=8.090, rec=0.141, cos=0.015), tot_loss_proj:1.708 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 100/2000] tot_loss=1.685 (perp=8.090, rec=0.064, cos=0.003), tot_loss_proj:1.706 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 150/2000] tot_loss=1.678 (perp=8.090, rec=0.057, cos=0.003), tot_loss_proj:1.703 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 200/2000] tot_loss=1.685 (perp=8.090, rec=0.064, cos=0.003), tot_loss_proj:1.711 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.694 (perp=8.090, rec=0.073, cos=0.003), tot_loss_proj:1.704 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.682 (perp=8.090, rec=0.061, cos=0.003), tot_loss_proj:1.715 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.680 (perp=8.090, rec=0.060, cos=0.003), tot_loss_proj:1.707 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.676 (perp=8.090, rec=0.055, cos=0.003), tot_loss_proj:1.711 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.681 (perp=8.090, rec=0.060, cos=0.003), tot_loss_proj:1.700 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.677 (perp=8.090, rec=0.056, cos=0.003), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.672 (perp=8.090, rec=0.051, cos=0.003), tot_loss_proj:1.710 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.672 (perp=8.090, rec=0.051, cos=0.003), tot_loss_proj:1.702 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.676 (perp=8.090, rec=0.055, cos=0.003), tot_loss_proj:1.693 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.678 (perp=8.090, rec=0.058, cos=0.003), tot_loss_proj:1.704 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.673 (perp=8.090, rec=0.052, cos=0.003), tot_loss_proj:1.695 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.678 (perp=8.090, rec=0.057, cos=0.003), tot_loss_proj:1.711 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.676 (perp=8.090, rec=0.055, cos=0.003), tot_loss_proj:1.689 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.678 (perp=8.090, rec=0.058, cos=0.003), tot_loss_proj:1.705 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.685 (perp=8.090, rec=0.064, cos=0.003), tot_loss_proj:1.699 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.673 (perp=8.090, rec=0.052, cos=0.003), tot_loss_proj:1.691 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.672 (perp=8.090, rec=0.052, cos=0.003), tot_loss_proj:1.685 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.679 (perp=8.090, rec=0.058, cos=0.003), tot_loss_proj:1.683 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.677 (perp=8.090, rec=0.057, cos=0.003), tot_loss_proj:1.694 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.680 (perp=8.090, rec=0.060, cos=0.003), tot_loss_proj:1.694 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.672 (perp=8.090, rec=0.051, cos=0.003), tot_loss_proj:1.700 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.674 (perp=8.090, rec=0.054, cos=0.003), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.679 (perp=8.090, rec=0.059, cos=0.003), tot_loss_proj:1.697 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.683 (perp=8.090, rec=0.062, cos=0.003), tot_loss_proj:1.700 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.679 (perp=8.090, rec=0.058, cos=0.003), tot_loss_proj:1.690 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.694 (perp=8.090, rec=0.073, cos=0.003), tot_loss_proj:1.701 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.689 (perp=8.090, rec=0.068, cos=0.003), tot_loss_proj:1.686 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.678 (perp=8.090, rec=0.057, cos=0.003), tot_loss_proj:1.682 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.684 (perp=8.090, rec=0.063, cos=0.003), tot_loss_proj:1.697 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.680 (perp=8.090, rec=0.059, cos=0.003), tot_loss_proj:1.690 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.678 (perp=8.090, rec=0.057, cos=0.003), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.679 (perp=8.090, rec=0.058, cos=0.003), tot_loss_proj:1.690 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.681 (perp=8.090, rec=0.060, cos=0.003), tot_loss_proj:1.685 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.681 (perp=8.090, rec=0.060, cos=0.003), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.670 (perp=8.090, rec=0.050, cos=0.003), tot_loss_proj:1.687 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.681 (perp=8.090, rec=0.060, cos=0.003), tot_loss_proj:1.685 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.522 | p: 88.625 | r: 88.606
rouge2     | fm: 54.573 | p: 54.728 | r: 54.439
rougeL     | fm: 75.415 | p: 75.598 | r: 75.488
rougeLsum  | fm: 75.407 | p: 75.619 | r: 75.378
r1fm+r2fm = 143.095

input #53 time: 0:09:12 | total time: 8:15:49


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9986756241474364
highest_index [0]
highest [0.9986756241474364]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.8137179613113403 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.7601333260536194 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7467924356460571 for ['[CLS] living devices [SEP]']
[Init] best rec loss: 0.743138313293457 for ['[CLS] trinity passed [SEP]']
[Init] best rec loss: 0.7381619215011597 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 0.6957831978797913 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.6627781391143799 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.6423496603965759 for ['[CLS] delivery content [SEP]']
[Init] best rec loss: 0.6296775937080383 for ['[CLS] teresa spanish [SEP]']
[Init] best rec loss: 0.6230711340904236 for ['[CLS] wild exercised [SEP]']
[Init] best perm rec loss: 0.6212514042854309 for ['[CLS] exercised wild [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.252 (perp=9.393, rec=0.313, cos=0.060), tot_loss_proj:2.712 [t=0.23s]
prediction: ['[CLS] hot hot [SEP]']
[ 100/2000] tot_loss=1.905 (perp=8.198, rec=0.241, cos=0.024), tot_loss_proj:1.723 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=1.826 (perp=8.198, rec=0.171, cos=0.015), tot_loss_proj:1.716 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=1.809 (perp=8.198, rec=0.155, cos=0.015), tot_loss_proj:1.712 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.805 (perp=8.198, rec=0.151, cos=0.014), tot_loss_proj:1.722 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.804 (perp=8.198, rec=0.150, cos=0.014), tot_loss_proj:1.709 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.795 (perp=8.198, rec=0.142, cos=0.014), tot_loss_proj:1.725 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.803 (perp=8.198, rec=0.150, cos=0.014), tot_loss_proj:1.718 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.802 (perp=8.198, rec=0.148, cos=0.014), tot_loss_proj:1.720 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.800 (perp=8.198, rec=0.147, cos=0.014), tot_loss_proj:1.711 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.793 (perp=8.198, rec=0.139, cos=0.014), tot_loss_proj:1.719 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.801 (perp=8.198, rec=0.147, cos=0.014), tot_loss_proj:1.715 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.811 (perp=8.198, rec=0.157, cos=0.014), tot_loss_proj:1.725 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.802 (perp=8.198, rec=0.148, cos=0.014), tot_loss_proj:1.709 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.798 (perp=8.198, rec=0.144, cos=0.014), tot_loss_proj:1.723 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.796 (perp=8.198, rec=0.142, cos=0.014), tot_loss_proj:1.716 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.810 (perp=8.198, rec=0.156, cos=0.014), tot_loss_proj:1.723 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.799 (perp=8.198, rec=0.145, cos=0.014), tot_loss_proj:1.720 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.799 (perp=8.198, rec=0.145, cos=0.014), tot_loss_proj:1.719 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.805 (perp=8.198, rec=0.152, cos=0.014), tot_loss_proj:1.715 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.803 (perp=8.198, rec=0.149, cos=0.014), tot_loss_proj:1.723 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.805 (perp=8.198, rec=0.151, cos=0.014), tot_loss_proj:1.715 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.807 (perp=8.198, rec=0.153, cos=0.014), tot_loss_proj:1.722 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.794 (perp=8.198, rec=0.140, cos=0.014), tot_loss_proj:1.714 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.805 (perp=8.198, rec=0.151, cos=0.014), tot_loss_proj:1.723 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.805 (perp=8.198, rec=0.151, cos=0.015), tot_loss_proj:1.723 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.791 (perp=8.198, rec=0.137, cos=0.015), tot_loss_proj:1.714 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.802 (perp=8.198, rec=0.148, cos=0.014), tot_loss_proj:1.721 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.809 (perp=8.198, rec=0.155, cos=0.015), tot_loss_proj:1.721 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.799 (perp=8.198, rec=0.145, cos=0.014), tot_loss_proj:1.724 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.807 (perp=8.198, rec=0.153, cos=0.015), tot_loss_proj:1.714 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.801 (perp=8.198, rec=0.147, cos=0.015), tot_loss_proj:1.720 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.812 (perp=8.198, rec=0.158, cos=0.015), tot_loss_proj:1.720 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.788 (perp=8.198, rec=0.134, cos=0.015), tot_loss_proj:1.702 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.797 (perp=8.198, rec=0.143, cos=0.015), tot_loss_proj:1.715 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.787 (perp=8.198, rec=0.133, cos=0.014), tot_loss_proj:1.708 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.801 (perp=8.198, rec=0.147, cos=0.015), tot_loss_proj:1.715 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.796 (perp=8.198, rec=0.142, cos=0.014), tot_loss_proj:1.721 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.797 (perp=8.198, rec=0.143, cos=0.015), tot_loss_proj:1.722 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.796 (perp=8.198, rec=0.142, cos=0.014), tot_loss_proj:1.722 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.706 | p: 88.830 | r: 88.825
rouge2     | fm: 55.376 | p: 55.505 | r: 55.292
rougeL     | fm: 75.928 | p: 76.081 | r: 75.879
rougeLsum  | fm: 75.710 | p: 75.938 | r: 75.716
r1fm+r2fm = 144.082

input #54 time: 0:09:12 | total time: 8:25:01


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9986493622744401
highest_index [0]
highest [0.9986493622744401]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.8549482822418213 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.7379668951034546 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7361676692962646 for ['[CLS] fully left ideal [SEP]']
[Init] best rec loss: 0.7157452702522278 for ['[CLS] top trades events [SEP]']
[Init] best rec loss: 0.7126352787017822 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7105139493942261 for ['[CLS] holly stride post [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.321 (perp=9.409, rec=0.365, cos=0.074), tot_loss_proj:3.045 [t=0.23s]
prediction: ['[CLS] too life easily [SEP]']
[ 100/2000] tot_loss=2.209 (perp=10.014, rec=0.183, cos=0.023), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS] too settled easily [SEP]']
[ 150/2000] tot_loss=2.004 (perp=9.584, rec=0.083, cos=0.004), tot_loss_proj:2.306 [t=0.23s]
prediction: ['[CLS] too settles easily [SEP]']
[ 200/2000] tot_loss=2.001 (perp=9.584, rec=0.082, cos=0.003), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] too settles easily [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.805 (perp=8.671, rec=0.067, cos=0.004), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=1.806 (perp=8.671, rec=0.069, cos=0.003), tot_loss_proj:1.816 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.794 (perp=8.671, rec=0.057, cos=0.003), tot_loss_proj:1.818 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.804 (perp=8.671, rec=0.067, cos=0.003), tot_loss_proj:1.809 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.795 (perp=8.671, rec=0.058, cos=0.003), tot_loss_proj:1.812 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.789 (perp=8.671, rec=0.052, cos=0.003), tot_loss_proj:1.816 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.786 (perp=8.671, rec=0.049, cos=0.003), tot_loss_proj:1.804 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.790 (perp=8.671, rec=0.053, cos=0.003), tot_loss_proj:1.814 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.797 (perp=8.671, rec=0.060, cos=0.003), tot_loss_proj:1.820 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.800 (perp=8.671, rec=0.063, cos=0.003), tot_loss_proj:1.809 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.802 (perp=8.671, rec=0.065, cos=0.003), tot_loss_proj:1.813 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.807 (perp=8.671, rec=0.070, cos=0.003), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.809 (perp=8.671, rec=0.072, cos=0.003), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.797 (perp=8.671, rec=0.060, cos=0.003), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.798 (perp=8.671, rec=0.062, cos=0.003), tot_loss_proj:1.820 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.797 (perp=8.671, rec=0.060, cos=0.003), tot_loss_proj:1.813 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.801 (perp=8.671, rec=0.064, cos=0.003), tot_loss_proj:1.813 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.799 (perp=8.671, rec=0.062, cos=0.003), tot_loss_proj:1.812 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.794 (perp=8.671, rec=0.057, cos=0.003), tot_loss_proj:1.812 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.790 (perp=8.671, rec=0.053, cos=0.003), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.799 (perp=8.671, rec=0.063, cos=0.003), tot_loss_proj:1.814 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.789 (perp=8.671, rec=0.052, cos=0.003), tot_loss_proj:1.810 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.799 (perp=8.671, rec=0.062, cos=0.003), tot_loss_proj:1.822 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.797 (perp=8.671, rec=0.060, cos=0.003), tot_loss_proj:1.810 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.802 (perp=8.671, rec=0.065, cos=0.003), tot_loss_proj:1.799 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.786 (perp=8.671, rec=0.050, cos=0.003), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.795 (perp=8.671, rec=0.058, cos=0.003), tot_loss_proj:1.813 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.803 (perp=8.671, rec=0.066, cos=0.003), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.797 (perp=8.671, rec=0.060, cos=0.003), tot_loss_proj:1.812 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.795 (perp=8.671, rec=0.058, cos=0.003), tot_loss_proj:1.807 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.806 (perp=8.671, rec=0.069, cos=0.003), tot_loss_proj:1.814 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.805 (perp=8.671, rec=0.068, cos=0.003), tot_loss_proj:1.816 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.807 (perp=8.671, rec=0.070, cos=0.003), tot_loss_proj:1.807 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.792 (perp=8.671, rec=0.055, cos=0.003), tot_loss_proj:1.810 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.800 (perp=8.671, rec=0.063, cos=0.003), tot_loss_proj:1.817 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.807 (perp=8.671, rec=0.070, cos=0.003), tot_loss_proj:1.814 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.040 | p: 89.065 | r: 89.075
rouge2     | fm: 55.998 | p: 56.184 | r: 55.891
rougeL     | fm: 76.366 | p: 76.514 | r: 76.308
rougeLsum  | fm: 76.242 | p: 76.414 | r: 76.232
r1fm+r2fm = 145.038

input #55 time: 0:09:12 | total time: 8:34:14


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.9985746644588014
highest_index [0]
highest [0.9985746644588014]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.8440077900886536 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.8361331224441528 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.8254939317703247 for ['[CLS] gu listgnant brave xavier jenna lady behalf file productions experienced charmvah everything law commander shorts inner matchesonal boot [SEP]']
[Init] best rec loss: 0.8252482414245605 for ['[CLS]tur secondary sitting accident ked sul woman professor ever signatures exercise daylor blackness photographicmind mechanics jerked gel. interiors [SEP]']
[Init] best rec loss: 0.8130844831466675 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 0.8118360638618469 for ['[CLS] reflection determined en laid backed bear tis technique strike sense unfortunatelyured blame avid code ; sympathy iron depression charter k [SEP]']
[Init] best perm rec loss: 0.8117840886116028 for ['[CLS] sense tis depression enured bear unfortunately ; determined blame reflection k laid avid backed sympathy strike charter iron technique code [SEP]']
[Init] best perm rec loss: 0.8111396431922913 for ['[CLS] avid ; reflection iron technique laid tis strike sense k depressionured backed en bear charter determined sympathy blame unfortunately code [SEP]']
[Init] best perm rec loss: 0.8102567791938782 for ['[CLS] enured sense bear depression code iron reflection sympathy blame laid k strike tis charter determined technique unfortunately ; avid backed [SEP]']
[Init] best perm rec loss: 0.8095529079437256 for ['[CLS] bear laid charter sense blame unfortunatelyured reflection determined strike k technique iron ; sympathy tis avid depression code en backed [SEP]']
[Init] best perm rec loss: 0.8069464564323425 for ['[CLS] unfortunately backed code technique avid determined k sense strike sympathy charter ;ured blame laid depression en tis bear iron reflection [SEP]']
[Init] best perm rec loss: 0.8033913373947144 for ['[CLS] reflection ; bear unfortunately determined ironured backed charter laid depression code en tis k sense technique sympathy blame avid strike [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.797 (perp=12.507, rec=0.279, cos=0.016), tot_loss_proj:3.803 [t=0.23s]
prediction: ['[CLS] because riggedending unfortunately bluff less damage which damage less after endemic digits never t cost? damage films years products [SEP]']
[ 100/2000] tot_loss=2.345 (perp=10.660, rec=0.205, cos=0.007), tot_loss_proj:2.742 [t=0.24s]
prediction: ['[CLS] this costly extremely costly loads cause damage which damage worsepara loadsuous should would damage years costly films never analysis [SEP]']
[ 150/2000] tot_loss=2.269 (perp=10.393, rec=0.182, cos=0.009), tot_loss_proj:2.667 [t=0.24s]
prediction: ['[CLS] this costly extremely costly loads cause damage which damage repairpara loadspara and would damage years costly films never analysis [SEP]']
[ 200/2000] tot_loss=2.287 (perp=10.715, rec=0.139, cos=0.005), tot_loss_proj:2.733 [t=0.24s]
prediction: ['[CLS] this years extremely costly loads cause damage which damage worsepara loadspara and years costly that costly films never fix [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.348 (perp=11.129, rec=0.118, cos=0.004), tot_loss_proj:2.859 [t=0.24s]
prediction: ['[CLS] will loads ir ir loads cause damage whichble yearspara yearspara and years costly that costly films never fix [SEP]']
[ 300/2000] tot_loss=2.323 (perp=11.064, rec=0.106, cos=0.004), tot_loss_proj:2.808 [t=0.24s]
prediction: ['[CLS] will loads ir ir loads cause damage whichble yearspara years analysis and years costly that costly films never fix [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.207 (perp=10.552, rec=0.093, cos=0.004), tot_loss_proj:2.785 [t=0.24s]
prediction: ['[CLS] will loads analysis ir loads cause damage whichble yearspara years extremely and of costly that costly films never fix [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.060 (perp=9.839, rec=0.089, cos=0.004), tot_loss_proj:2.872 [t=0.24s]
prediction: ['[CLS] will loads analysis ir loads cause damage which years yearsparable of and of years that costly films never fix [SEP]']
[ 450/2000] tot_loss=2.057 (perp=9.839, rec=0.086, cos=0.003), tot_loss_proj:2.879 [t=0.24s]
prediction: ['[CLS] will loads analysis ir loads cause damage which years yearsparable of and of years that costly films never fix [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.979 (perp=9.459, rec=0.084, cos=0.003), tot_loss_proj:2.971 [t=0.24s]
prediction: ['[CLS] will loads analysis ir loads of cause damage which years yearsparable and of years that costly films never fix [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.922 (perp=9.135, rec=0.092, cos=0.003), tot_loss_proj:2.811 [t=0.24s]
prediction: ['[CLS] will loads analysis ir loads of cause damage which years and yearsparable of years that costly films never fix [SEP]']
[ 600/2000] tot_loss=1.910 (perp=9.135, rec=0.080, cos=0.003), tot_loss_proj:2.815 [t=0.24s]
prediction: ['[CLS] will loads analysis ir loads of cause damage which years and yearsparable of years that costly films never fix [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.884 (perp=8.958, rec=0.090, cos=0.003), tot_loss_proj:2.838 [t=0.24s]
prediction: ['[CLS] will loads analysis years loads of cause damage which years and irparable of years that costly films never fix [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.751 (perp=8.309, rec=0.086, cos=0.003), tot_loss_proj:2.337 [t=0.24s]
prediction: ['[CLS] will of analysis cause loads of years damage which years and irparable of years that costly films never fix [SEP]']
[ 750/2000] tot_loss=1.736 (perp=8.309, rec=0.071, cos=0.003), tot_loss_proj:2.338 [t=0.24s]
prediction: ['[CLS] will of analysis cause loads of years damage which years and irparable of years that costly films never fix [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.653 (perp=7.866, rec=0.077, cos=0.003), tot_loss_proj:2.110 [t=0.24s]
prediction: ['[CLS] will costly analysis cause loads of years damage which years and irparable of years that of films never fix [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.628 (perp=7.712, rec=0.083, cos=0.003), tot_loss_proj:2.085 [t=0.24s]
prediction: ['[CLS] will costly analysis cause loads of years which damage years and irparable of years that of films never fix [SEP]']
[ 900/2000] tot_loss=1.620 (perp=7.712, rec=0.074, cos=0.003), tot_loss_proj:2.075 [t=0.24s]
prediction: ['[CLS] will costly analysis cause loads of years which damage years and irparable of years that of films never fix [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.562 (perp=7.435, rec=0.072, cos=0.003), tot_loss_proj:1.999 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which damage years and irparable of years that of films never fix [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.515 (perp=7.159, rec=0.080, cos=0.003), tot_loss_proj:1.915 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage years and of years that of films never fix [SEP]']
[1050/2000] tot_loss=1.514 (perp=7.159, rec=0.080, cos=0.003), tot_loss_proj:1.924 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage years and of years that of films never fix [SEP]']
Attempt swap
[1100/2000] tot_loss=1.522 (perp=7.159, rec=0.088, cos=0.003), tot_loss_proj:1.917 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage years and of years that of films never fix [SEP]']
Attempt swap
[1150/2000] tot_loss=1.502 (perp=7.159, rec=0.068, cos=0.003), tot_loss_proj:1.924 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage years and of years that of films never fix [SEP]']
[1200/2000] tot_loss=1.513 (perp=7.159, rec=0.079, cos=0.003), tot_loss_proj:1.917 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage years and of years that of films never fix [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.487 (perp=7.001, rec=0.084, cos=0.003), tot_loss_proj:1.896 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage years and of years of films that never fix [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.424 (perp=6.688, rec=0.083, cos=0.003), tot_loss_proj:1.795 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
[1350/2000] tot_loss=1.418 (perp=6.688, rec=0.078, cos=0.003), tot_loss_proj:1.806 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
Attempt swap
[1400/2000] tot_loss=1.406 (perp=6.688, rec=0.066, cos=0.003), tot_loss_proj:1.792 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
Attempt swap
[1450/2000] tot_loss=1.417 (perp=6.688, rec=0.076, cos=0.003), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
[1500/2000] tot_loss=1.413 (perp=6.688, rec=0.072, cos=0.003), tot_loss_proj:1.792 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
Attempt swap
[1550/2000] tot_loss=1.420 (perp=6.688, rec=0.079, cos=0.003), tot_loss_proj:1.787 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
Attempt swap
[1600/2000] tot_loss=1.407 (perp=6.688, rec=0.067, cos=0.003), tot_loss_proj:1.797 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
[1650/2000] tot_loss=1.413 (perp=6.688, rec=0.073, cos=0.003), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
Attempt swap
[1700/2000] tot_loss=1.415 (perp=6.688, rec=0.075, cos=0.003), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
Attempt swap
[1750/2000] tot_loss=1.419 (perp=6.688, rec=0.078, cos=0.003), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
[1800/2000] tot_loss=1.410 (perp=6.688, rec=0.069, cos=0.003), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
Attempt swap
[1850/2000] tot_loss=1.409 (perp=6.688, rec=0.069, cos=0.003), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
Attempt swap
[1900/2000] tot_loss=1.404 (perp=6.688, rec=0.063, cos=0.003), tot_loss_proj:1.802 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
[1950/2000] tot_loss=1.409 (perp=6.688, rec=0.069, cos=0.003), tot_loss_proj:1.798 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
Attempt swap
[2000/2000] tot_loss=1.421 (perp=6.688, rec=0.081, cos=0.003), tot_loss_proj:1.792 [t=0.24s]
prediction: ['[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] costly analysis will cause loads of years which irparable damage and years of years of films that never fix [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.805 | p: 85.714 | r: 90.000
rouge2     | fm: 41.026 | p: 40.000 | r: 42.105
rougeL     | fm: 58.537 | p: 57.143 | r: 60.000
rougeLsum  | fm: 58.537 | p: 57.143 | r: 60.000
r1fm+r2fm = 128.831

[Aggregate metrics]:
rouge1     | fm: 88.995 | p: 89.056 | r: 89.084
rouge2     | fm: 55.889 | p: 55.999 | r: 55.916
rougeL     | fm: 76.117 | p: 76.259 | r: 76.123
rougeLsum  | fm: 75.984 | p: 76.105 | r: 75.982
r1fm+r2fm = 144.884

input #56 time: 0:09:22 | total time: 8:43:36


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.99889543492149
highest_index [0]
highest [0.99889543492149]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8815224170684814 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.7533212900161743 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.6915763020515442 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6893391013145447 for ['[CLS] modern [SEP]']
[Init] best rec loss: 0.687756359577179 for ['[CLS] himself [SEP]']
[Init] best rec loss: 0.679951012134552 for ['[CLS] decision [SEP]']
[Init] best rec loss: 0.6783899664878845 for ['[CLS] dorm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.591 (perp=12.283, rec=0.115, cos=0.020), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.516 (perp=12.283, rec=0.056, cos=0.004), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.523 (perp=12.283, rec=0.064, cos=0.002), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.508 (perp=12.283, rec=0.047, cos=0.004), tot_loss_proj:2.526 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.516 (perp=12.283, rec=0.057, cos=0.003), tot_loss_proj:2.527 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.528 (perp=12.283, rec=0.068, cos=0.004), tot_loss_proj:2.531 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.510 (perp=12.283, rec=0.051, cos=0.002), tot_loss_proj:2.520 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.520 (perp=12.283, rec=0.061, cos=0.002), tot_loss_proj:2.517 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.516 (perp=12.283, rec=0.058, cos=0.002), tot_loss_proj:2.520 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.517 (perp=12.283, rec=0.058, cos=0.002), tot_loss_proj:2.531 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.536 (perp=12.283, rec=0.078, cos=0.002), tot_loss_proj:2.514 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.495 (perp=12.283, rec=0.036, cos=0.002), tot_loss_proj:2.517 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.517 (perp=12.283, rec=0.058, cos=0.002), tot_loss_proj:2.520 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.518 (perp=12.283, rec=0.060, cos=0.002), tot_loss_proj:2.530 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.525 (perp=12.283, rec=0.066, cos=0.002), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.524 (perp=12.283, rec=0.065, cos=0.002), tot_loss_proj:2.512 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.515 (perp=12.283, rec=0.056, cos=0.002), tot_loss_proj:2.524 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.513 (perp=12.283, rec=0.054, cos=0.002), tot_loss_proj:2.526 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.530 (perp=12.283, rec=0.071, cos=0.002), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.528 (perp=12.283, rec=0.069, cos=0.002), tot_loss_proj:2.519 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.513 (perp=12.283, rec=0.055, cos=0.002), tot_loss_proj:2.520 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.521 (perp=12.283, rec=0.062, cos=0.002), tot_loss_proj:2.527 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.528 (perp=12.283, rec=0.069, cos=0.002), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.522 (perp=12.283, rec=0.063, cos=0.002), tot_loss_proj:2.527 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.531 (perp=12.283, rec=0.072, cos=0.002), tot_loss_proj:2.510 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.523 (perp=12.283, rec=0.064, cos=0.002), tot_loss_proj:2.523 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.517 (perp=12.283, rec=0.058, cos=0.002), tot_loss_proj:2.521 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.524 (perp=12.283, rec=0.066, cos=0.002), tot_loss_proj:2.529 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.528 (perp=12.283, rec=0.069, cos=0.002), tot_loss_proj:2.534 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.520 (perp=12.283, rec=0.061, cos=0.002), tot_loss_proj:2.511 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.525 (perp=12.283, rec=0.067, cos=0.002), tot_loss_proj:2.524 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.516 (perp=12.283, rec=0.057, cos=0.002), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.513 (perp=12.283, rec=0.054, cos=0.002), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.510 (perp=12.283, rec=0.051, cos=0.002), tot_loss_proj:2.532 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.521 (perp=12.283, rec=0.063, cos=0.002), tot_loss_proj:2.537 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.512 (perp=12.283, rec=0.054, cos=0.002), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.514 (perp=12.283, rec=0.055, cos=0.002), tot_loss_proj:2.534 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.518 (perp=12.283, rec=0.060, cos=0.002), tot_loss_proj:2.513 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.517 (perp=12.283, rec=0.059, cos=0.002), tot_loss_proj:2.528 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.522 (perp=12.283, rec=0.064, cos=0.002), tot_loss_proj:2.533 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.097 | p: 89.255 | r: 89.270
rouge2     | fm: 56.691 | p: 56.834 | r: 56.606
rougeL     | fm: 76.523 | p: 76.613 | r: 76.514
rougeLsum  | fm: 76.405 | p: 76.522 | r: 76.468
r1fm+r2fm = 145.787

input #57 time: 0:08:54 | total time: 8:52:31


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.998772651288748
highest_index [0]
highest [0.998772651288748]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.018049955368042 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9864166975021362 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9772456884384155 for ['[CLS] things reggie on guinnessllet continue special the chan (ness grew prone moffatockshire [SEP]']
[Init] best rec loss: 0.9731562733650208 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.970122218132019 for ['[CLS]mon recorded govt bolsheviks iv ignited countymetricual helmet army £100 continuedbanes recognition [SEP]']
[Init] best rec loss: 0.960810661315918 for ['[CLS] partner kickoff message oh hills edge wind mono stainless few sk closet clay fair ole port [SEP]']
[Init] best rec loss: 0.9603291153907776 for ['[CLS] ) after rca adventures / yong beat bad http stoodagendingple ]erson trailing [SEP]']
[Init] best rec loss: 0.9601947665214539 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.9566650390625 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.932532548904419 for ['[CLS] charms status minutes residency automatic marlon career signsburg henderson leaves future conflicting everdict route [SEP]']
[Init] best perm rec loss: 0.9301068186759949 for ['[CLS]dict residencysburg conflicting status charms sign ever henderson future minutes career automatic leaves marlon route [SEP]']
[Init] best perm rec loss: 0.9284023642539978 for ['[CLS] charms future status automatic conflictingsburg sign leaves minutes marlon career henderson routedict residency ever [SEP]']
[Init] best perm rec loss: 0.9283549785614014 for ['[CLS] future minutes ever sign henderson automatic leaves marlon route status conflictingsburgdict charms residency career [SEP]']
[Init] best perm rec loss: 0.9260947108268738 for ['[CLS]dict conflicting charms status route automaticsburg leaves marlon ever career minutes henderson sign residency future [SEP]']
[Init] best perm rec loss: 0.924405574798584 for ['[CLS]sburg futuredict leaves career minutes conflicting henderson sign residency ever status charms route marlon automatic [SEP]']
[Init] best perm rec loss: 0.924386203289032 for ['[CLS] conflicting automaticdict minutes ever future charms henderson leaves statussburg route residency marlon sign career [SEP]']
[Init] best perm rec loss: 0.9242421388626099 for ['[CLS] charms status sign residencysburg conflicting ever automatic henderson leaves marlondict minutes future route career [SEP]']
[Init] best perm rec loss: 0.9240967631340027 for ['[CLS] ever status future signdict automatic route marlon conflicting leaves charms careersburg minutes residency henderson [SEP]']
[Init] best perm rec loss: 0.922288715839386 for ['[CLS] career residency automaticdict ever sign conflicting status leaves henderson minutes routesburg marlon charms future [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.109 (perp=12.971, rec=0.431, cos=0.084), tot_loss_proj:4.192 [t=0.23s]
prediction: ['[CLS] hindu thoughtful training skeleton looking inflicted museum deep trail very powered ceremonies tense meditation system chan [SEP]']
[ 100/2000] tot_loss=3.010 (perp=12.558, rec=0.344, cos=0.154), tot_loss_proj:4.456 [t=0.24s]
prediction: ['[CLS] dreamed ( anthology child looking inflicted donated exploration silent urban powered reconciliation tourism truths system the [SEP]']
[ 150/2000] tot_loss=2.623 (perp=11.010, rec=0.306, cos=0.115), tot_loss_proj:3.910 [t=0.24s]
prediction: ['[CLS] everything ( anthology child ] inflicted inspirational capturing silent stories inspirational when an capture innocence the [SEP]']
[ 200/2000] tot_loss=2.668 (perp=11.376, rec=0.265, cos=0.129), tot_loss_proj:3.581 [t=0.24s]
prediction: ['[CLS] everything ( anthology child ] an story capturing silentidad inspirational encounter an capture innocence the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.731 (perp=11.708, rec=0.270, cos=0.119), tot_loss_proj:3.200 [t=0.24s]
prediction: ['[CLS] everythingis anthology child middle an encounter love inspirationalishly inspirational story an capture innocence the [SEP]']
[ 300/2000] tot_loss=2.573 (perp=11.048, rec=0.247, cos=0.117), tot_loss_proj:3.228 [t=0.24s]
prediction: ['[CLS] everythingis love child middle an encounter love inspirationalishly inspirational story an is innocence the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.346 (perp=9.959, rec=0.236, cos=0.118), tot_loss_proj:3.069 [t=0.24s]
prediction: ['[CLS] everythingis love father is an encounter love inspirationalishly inspirational story an middle innocence the [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.410 (perp=10.325, rec=0.232, cos=0.112), tot_loss_proj:3.350 [t=0.24s]
prediction: ['[CLS] everythinga love experience is an innocence innocence encounterishly inspirational story an middle innocence the [SEP]']
[ 450/2000] tot_loss=2.327 (perp=9.834, rec=0.231, cos=0.129), tot_loss_proj:3.073 [t=0.24s]
prediction: ['[CLS] everythinga love experience is an innocence innocence encounterishly inspirational story an middle narrative the [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.166 (perp=9.149, rec=0.213, cos=0.123), tot_loss_proj:2.804 [t=0.24s]
prediction: ['[CLS] everythingfelt love experience is an innocence middle encounterishly inspirational story an love narrative the [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=2.337 (perp=9.517, rec=0.296, cos=0.138), tot_loss_proj:3.064 [t=0.24s]
prediction: ['[CLS] the ¶ lp pamphlet spirit is an innocence middle encounterishly inspirational story an love narrative [SEP]']
[ 600/2000] tot_loss=2.322 (perp=9.754, rec=0.238, cos=0.133), tot_loss_proj:3.345 [t=0.24s]
prediction: ['[CLS] the₀ normal movement father is the innocence middle encounterishly inspirational story an love narrative [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.189 (perp=9.192, rec=0.234, cos=0.117), tot_loss_proj:3.145 [t=0.24s]
prediction: ['[CLS] the love normal movement father is the innocence middle encounterishly inspirational story an₀ narrative [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.059 (perp=8.593, rec=0.223, cos=0.117), tot_loss_proj:3.025 [t=0.24s]
prediction: ['[CLS] the love father normal movement is the innocence middle encounterishly inspirational story an protocol narrative [SEP]']
[ 750/2000] tot_loss=2.249 (perp=9.568, rec=0.212, cos=0.123), tot_loss_proj:3.140 [t=0.24s]
prediction: ['[CLS] captured love father father movement is the innocence middle encounterishly inspirational story an protocol narrative [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.387 (perp=10.218, rec=0.219, cos=0.125), tot_loss_proj:3.349 [t=0.24s]
prediction: ['[CLS] love father normal movement is capturing innocence middle encounterishly inspirational story an captured protocol screenplay [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.128 (perp=8.975, rec=0.212, cos=0.121), tot_loss_proj:3.066 [t=0.24s]
prediction: ['[CLS] father normal love movement is the innocence middle encounterishly inspirational story an captured protocol screenplay [SEP]']
[ 900/2000] tot_loss=2.160 (perp=9.162, rec=0.205, cos=0.122), tot_loss_proj:2.993 [t=0.24s]
prediction: ['[CLS] experience father love movement is the innocence middle encounterishly inspirational story an captured protocol screenplay [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.194 (perp=9.356, rec=0.203, cos=0.120), tot_loss_proj:3.150 [t=0.24s]
prediction: ['[CLS] experience father love movement is the innocence middle encounter inch inspirational story an captured protocol screenplay [SEP]']
Attempt swap
[1000/2000] tot_loss=2.191 (perp=9.356, rec=0.197, cos=0.123), tot_loss_proj:3.154 [t=0.24s]
prediction: ['[CLS] experience father love movement is the innocence middle encounter inch inspirational story an captured protocol screenplay [SEP]']
[1050/2000] tot_loss=2.198 (perp=9.356, rec=0.203, cos=0.124), tot_loss_proj:3.151 [t=0.24s]
prediction: ['[CLS] experience father love movement is the innocence middle encounter inch inspirational story an captured protocol screenplay [SEP]']
Attempt swap
[1100/2000] tot_loss=2.337 (perp=10.112, rec=0.197, cos=0.118), tot_loss_proj:3.237 [t=0.24s]
prediction: ['[CLS] experience father love movement is capturing innocence middle encounter inch inspirational story an captured protocol screenplay [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.209 (perp=9.323, rec=0.219, cos=0.126), tot_loss_proj:2.758 [t=0.24s]
prediction: ['[CLS] experience father love movement is an innocence middle encounterishly inspirational story the captured protocol screenplay [SEP]']
[1200/2000] tot_loss=2.184 (perp=9.323, rec=0.198, cos=0.122), tot_loss_proj:2.758 [t=0.24s]
prediction: ['[CLS] experience father love movement is an innocence middle encounterishly inspirational story the captured protocol screenplay [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.157 (perp=9.216, rec=0.193, cos=0.121), tot_loss_proj:2.913 [t=0.24s]
prediction: ['[CLS] experience father love movement is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.128 (perp=8.995, rec=0.205, cos=0.124), tot_loss_proj:2.658 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
[1350/2000] tot_loss=2.116 (perp=8.995, rec=0.196, cos=0.121), tot_loss_proj:2.647 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
Attempt swap
[1400/2000] tot_loss=2.122 (perp=8.995, rec=0.203, cos=0.120), tot_loss_proj:2.652 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
Attempt swap
[1450/2000] tot_loss=2.115 (perp=8.995, rec=0.192, cos=0.124), tot_loss_proj:2.653 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
[1500/2000] tot_loss=2.123 (perp=8.995, rec=0.202, cos=0.121), tot_loss_proj:2.650 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
Attempt swap
[1550/2000] tot_loss=2.117 (perp=8.995, rec=0.197, cos=0.121), tot_loss_proj:2.650 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
Attempt swap
[1600/2000] tot_loss=2.107 (perp=8.995, rec=0.188, cos=0.120), tot_loss_proj:2.658 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
[1650/2000] tot_loss=2.111 (perp=8.995, rec=0.192, cos=0.120), tot_loss_proj:2.648 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
Attempt swap
[1700/2000] tot_loss=2.116 (perp=8.995, rec=0.197, cos=0.119), tot_loss_proj:2.652 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
Attempt swap
[1750/2000] tot_loss=2.118 (perp=8.995, rec=0.198, cos=0.121), tot_loss_proj:2.650 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
[1800/2000] tot_loss=2.114 (perp=8.995, rec=0.195, cos=0.121), tot_loss_proj:2.655 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
Attempt swap
[1850/2000] tot_loss=2.113 (perp=8.995, rec=0.193, cos=0.121), tot_loss_proj:2.647 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
Attempt swap
[1900/2000] tot_loss=2.109 (perp=8.995, rec=0.189, cos=0.121), tot_loss_proj:2.651 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
[1950/2000] tot_loss=2.113 (perp=8.995, rec=0.194, cos=0.120), tot_loss_proj:2.651 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
Attempt swap
[2000/2000] tot_loss=2.101 (perp=8.995, rec=0.182, cos=0.120), tot_loss_proj:2.655 [t=0.24s]
prediction: ['[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] father love movement experience is an innocence middle encounterishly inspirational story protocol captured the screenplay [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.545 | p: 52.941 | r: 56.250
rouge2     | fm: 6.452 | p: 6.250 | r: 6.667
rougeL     | fm: 42.424 | p: 41.176 | r: 43.750
rougeLsum  | fm: 42.424 | p: 41.176 | r: 43.750
r1fm+r2fm = 60.997

[Aggregate metrics]:
rouge1     | fm: 88.588 | p: 88.629 | r: 88.752
rouge2     | fm: 55.945 | p: 56.016 | r: 55.950
rougeL     | fm: 75.962 | p: 76.014 | r: 76.034
rougeLsum  | fm: 75.794 | p: 75.888 | r: 75.828
r1fm+r2fm = 144.533

input #58 time: 0:09:21 | total time: 9:01:52


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9986847760159663
highest_index [0]
highest [0.9986847760159663]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.8775243163108826 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.8582960367202759 for ['[CLS] poll dominance intine drop silvertock politician wrappedve complete hot reading team disco world [SEP]']
[Init] best rec loss: 0.847426176071167 for ['[CLS] mala minute theory mandatory stands after mere figure number roth sister locomotives bombay bavarian late athlete [SEP]']
[Init] best rec loss: 0.8369370102882385 for ['[CLS]notes urban shape atliest not filterae titled making prize wait sex ste front coach [SEP]']
[Init] best rec loss: 0.8260559439659119 for ['[CLS] key stafforddial done colony midst kmdden face ɾord muscle warning ( wife organic [SEP]']
[Init] best rec loss: 0.8253487944602966 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.8223250508308411 for ['[CLS] fk saint metric cement joining empire honda western detailpi ) underground marek solvent quad reed [SEP]']
[Init] best rec loss: 0.8099204897880554 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best perm rec loss: 0.809537947177887 for ['[CLS] husbands replacedser heart semifinalsgnı cook exclusive ation interviewed weof mumenity [SEP]']
[Init] best perm rec loss: 0.8091669082641602 for ['[CLS] exclusive heartof husbands we mumgn at semifinals interviewedenityıionser replaced cook [SEP]']
[Init] best perm rec loss: 0.8084409236907959 for ['[CLS]serion husbandsgnenity heart cook semifinals interviewed exclusiveof mum replaced we atı [SEP]']
[Init] best perm rec loss: 0.8079758882522583 for ['[CLS]ion heartı we cook husbands replaced mum interviewedser semifinalsenity atofgn exclusive [SEP]']
[Init] best perm rec loss: 0.8075239658355713 for ['[CLS]ser exclusive interviewed we cookenityion husbandsgn semifinalsof mum replacedı at heart [SEP]']
[Init] best perm rec loss: 0.807411789894104 for ['[CLS] replaced we exclusive heartion cook at semifinalsıgn interviewed mumserenityof husbands [SEP]']
[Init] best perm rec loss: 0.8064160943031311 for ['[CLS] mum husbands replaced cookionı heart we interviewedgn semifinalsenityser exclusive atof [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.701 (perp=11.052, rec=0.411, cos=0.079), tot_loss_proj:3.841 [t=0.23s]
prediction: ['[CLS]? each stepping upright tessa the painting womanbroken a woman all gift trusted sris [SEP]']
[ 100/2000] tot_loss=2.321 (perp=9.460, rec=0.321, cos=0.108), tot_loss_proj:3.724 [t=0.24s]
prediction: ['[CLS] has the stepping baby staples the screen womanism a woman writesism trusted womens [SEP]']
[ 150/2000] tot_loss=2.502 (perp=10.369, rec=0.309, cos=0.119), tot_loss_proj:3.721 [t=0.24s]
prediction: ['[CLS] has both stepping baby tattoo the screen woman emotion a woman behindism the women has [SEP]']
[ 200/2000] tot_loss=2.267 (perp=9.532, rec=0.263, cos=0.097), tot_loss_proj:3.338 [t=0.24s]
prediction: ['[CLS] has the path child began the holds woman who a who behindism the women knows [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.443 (perp=9.895, rec=0.271, cos=0.193), tot_loss_proj:3.316 [t=0.24s]
prediction: ['[CLS] has the path child began of woman woman a who howism hold the women screen [SEP]']
[ 300/2000] tot_loss=2.581 (perp=11.212, rec=0.242, cos=0.096), tot_loss_proj:3.850 [t=0.24s]
prediction: ['[CLS] has the walking woman danny of woman screen a who howism hold the screen hawke [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.388 (perp=10.321, rec=0.221, cos=0.103), tot_loss_proj:3.672 [t=0.24s]
prediction: ['[CLS]hi has the walking woman of woman screen a who howism hold the screen screen [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.391 (perp=10.407, rec=0.217, cos=0.092), tot_loss_proj:3.190 [t=0.24s]
prediction: ['[CLS] knows danny has the broadway woman of woman screen a knowsism hold the screen screen [SEP]']
[ 450/2000] tot_loss=2.215 (perp=9.643, rec=0.196, cos=0.090), tot_loss_proj:3.396 [t=0.24s]
prediction: ['[CLS] knowsh has the walking woman of woman screen who knowsism hold the screen screen [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.023 (perp=8.634, rec=0.203, cos=0.094), tot_loss_proj:2.739 [t=0.24s]
prediction: ['[CLS]ism knows danny has the broadway woman of woman screen who knows hold the screen screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.011 (perp=8.551, rec=0.203, cos=0.097), tot_loss_proj:2.981 [t=0.24s]
prediction: ['[CLS]ism knows danny has the double woman of woman screen who knows hold the screen screen [SEP]']
[ 600/2000] tot_loss=1.977 (perp=8.401, rec=0.198, cos=0.099), tot_loss_proj:3.028 [t=0.24s]
prediction: ['[CLS]ism knows wife has the double woman of woman screen who knows hold the screen screen [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.912 (perp=8.198, rec=0.183, cos=0.089), tot_loss_proj:3.142 [t=0.24s]
prediction: ['[CLS]ism screen wife has the double woman of woman screen who knows hold the screen circumstances [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.926 (perp=8.139, rec=0.194, cos=0.104), tot_loss_proj:3.064 [t=0.24s]
prediction: ['[CLS] screenism wife has the double woman of woman screen who knows hold the screen circumstances [SEP]']
[ 750/2000] tot_loss=1.898 (perp=8.139, rec=0.179, cos=0.091), tot_loss_proj:3.059 [t=0.24s]
prediction: ['[CLS] screenism wife has the double woman of woman screen who knows hold the screen circumstances [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.863 (perp=8.023, rec=0.171, cos=0.087), tot_loss_proj:3.194 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double woman of woman screen who knows hold the screen circumstances [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.872 (perp=8.023, rec=0.179, cos=0.088), tot_loss_proj:3.196 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double woman of woman screen who knows hold the screen circumstances [SEP]']
[ 900/2000] tot_loss=1.871 (perp=8.023, rec=0.178, cos=0.089), tot_loss_proj:3.197 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double woman of woman screen who knows hold the screen circumstances [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.866 (perp=7.974, rec=0.183, cos=0.088), tot_loss_proj:3.171 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double woman of screen woman who knows hold the screen circumstances [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.817 (perp=7.732, rec=0.173, cos=0.098), tot_loss_proj:3.194 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double woman of screen circumstances who knows hold the screen woman [SEP]']
[1050/2000] tot_loss=1.812 (perp=7.732, rec=0.174, cos=0.091), tot_loss_proj:3.191 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double woman of screen circumstances who knows hold the screen woman [SEP]']
Attempt swap
[1100/2000] tot_loss=1.809 (perp=7.732, rec=0.172, cos=0.090), tot_loss_proj:3.192 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double woman of screen circumstances who knows hold the screen woman [SEP]']
Attempt swap
[1150/2000] tot_loss=1.808 (perp=7.732, rec=0.171, cos=0.090), tot_loss_proj:3.189 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double woman of screen circumstances who knows hold the screen woman [SEP]']
[1200/2000] tot_loss=1.815 (perp=7.732, rec=0.177, cos=0.091), tot_loss_proj:3.188 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double woman of screen circumstances who knows hold the screen woman [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.763 (perp=7.476, rec=0.173, cos=0.096), tot_loss_proj:3.255 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double screen woman of circumstances who knows hold the screen woman [SEP]']
Attempt swap
[1300/2000] tot_loss=1.757 (perp=7.476, rec=0.173, cos=0.090), tot_loss_proj:3.254 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double screen woman of circumstances who knows hold the screen woman [SEP]']
[1350/2000] tot_loss=1.756 (perp=7.476, rec=0.170, cos=0.091), tot_loss_proj:3.257 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double screen woman of circumstances who knows hold the screen woman [SEP]']
Attempt swap
[1400/2000] tot_loss=1.812 (perp=7.781, rec=0.162, cos=0.093), tot_loss_proj:3.264 [t=0.24s]
prediction: ['[CLS] screen wifeism has the double woman woman of circumstances who knows hold the screen woman [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.906 (perp=8.209, rec=0.171, cos=0.093), tot_loss_proj:3.419 [t=0.24s]
prediction: ['[CLS] wifeism has the ku screen woman woman of circumstances who knows hold the screen woman [SEP]']
[1500/2000] tot_loss=1.904 (perp=8.209, rec=0.170, cos=0.092), tot_loss_proj:3.420 [t=0.24s]
prediction: ['[CLS] wifeism has the ku screen woman woman of circumstances who knows hold the screen woman [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.891 (perp=8.136, rec=0.169, cos=0.095), tot_loss_proj:3.416 [t=0.24s]
prediction: ['[CLS] wifeism has the ku woman screen woman of circumstances who knows hold the screen woman [SEP]']
Attempt swap
[1600/2000] tot_loss=1.884 (perp=8.136, rec=0.164, cos=0.092), tot_loss_proj:3.419 [t=0.24s]
prediction: ['[CLS] wifeism has the ku woman screen woman of circumstances who knows hold the screen woman [SEP]']
[1650/2000] tot_loss=1.890 (perp=8.136, rec=0.169, cos=0.094), tot_loss_proj:3.416 [t=0.24s]
prediction: ['[CLS] wifeism has the ku woman screen woman of circumstances who knows hold the screen woman [SEP]']
Attempt swap
[1700/2000] tot_loss=1.897 (perp=8.136, rec=0.175, cos=0.095), tot_loss_proj:3.414 [t=0.24s]
prediction: ['[CLS] wifeism has the ku woman screen woman of circumstances who knows hold the screen woman [SEP]']
Attempt swap
[1750/2000] tot_loss=1.881 (perp=8.136, rec=0.159, cos=0.094), tot_loss_proj:3.415 [t=0.24s]
prediction: ['[CLS] wifeism has the ku woman screen woman of circumstances who knows hold the screen woman [SEP]']
[1800/2000] tot_loss=1.889 (perp=8.136, rec=0.168, cos=0.093), tot_loss_proj:3.418 [t=0.24s]
prediction: ['[CLS] wifeism has the ku woman screen woman of circumstances who knows hold the screen woman [SEP]']
Attempt swap
[1850/2000] tot_loss=1.894 (perp=8.136, rec=0.173, cos=0.094), tot_loss_proj:3.418 [t=0.24s]
prediction: ['[CLS] wifeism has the ku woman screen woman of circumstances who knows hold the screen woman [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.810 (perp=7.761, rec=0.166, cos=0.092), tot_loss_proj:2.735 [t=0.24s]
prediction: ['[CLS] wifeism has the complete screen woman of circumstances woman who knows hold the screen woman [SEP]']
[1950/2000] tot_loss=1.785 (perp=7.605, rec=0.172, cos=0.092), tot_loss_proj:3.111 [t=0.24s]
prediction: ['[CLS] wifeism has the double screen woman of circumstances woman who knows hold the screen woman [SEP]']
Attempt swap
[2000/2000] tot_loss=1.774 (perp=7.605, rec=0.160, cos=0.093), tot_loss_proj:3.108 [t=0.24s]
prediction: ['[CLS] wifeism has the double screen woman of circumstances woman who knows hold the screen woman [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] wifeism has the ku woman screen woman of circumstances who knows hold the screen woman [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 64.706 | r: 68.750
rouge2     | fm: 25.806 | p: 25.000 | r: 26.667
rougeL     | fm: 60.606 | p: 58.824 | r: 62.500
rougeLsum  | fm: 60.606 | p: 58.824 | r: 62.500
r1fm+r2fm = 92.473

[Aggregate metrics]:
rouge1     | fm: 88.143 | p: 88.181 | r: 88.315
rouge2     | fm: 55.383 | p: 55.514 | r: 55.319
rougeL     | fm: 75.639 | p: 75.682 | r: 75.774
rougeLsum  | fm: 75.500 | p: 75.603 | r: 75.580
r1fm+r2fm = 143.526

input #59 time: 0:09:21 | total time: 9:11:13


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.9985680906941345
highest_index [0]
highest [0.9985680906941345]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9188227653503418 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9155802726745605 for ['[CLS] everything partnership bas gossip lies donegal directionbad his western ann arms [SEP]']
[Init] best rec loss: 0.9101083874702454 for ['[CLS] joo lead cancer course haiti board read empire dortmund commune member tory [SEP]']
[Init] best rec loss: 0.891872763633728 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8586064577102661 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8425424695014954 for ['[CLS] percent symbol budapest herald nets flavor shoppingted archlizer clock tight [SEP]']
[Init] best rec loss: 0.8368971347808838 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8132439255714417 for ['[CLS] rico shave overcomensor 1st opus introduced knockout currency area statewide whispered [SEP]']
[Init] best perm rec loss: 0.813075602054596 for ['[CLS] 1st currency statewide opus rico overcome introduced whisperednsor knockout shave area [SEP]']
[Init] best perm rec loss: 0.8129720687866211 for ['[CLS] 1st shavensor statewide knockout opus overcome whispered area rico currency introduced [SEP]']
[Init] best perm rec loss: 0.8125614523887634 for ['[CLS] knockout rico opus currencynsor 1st shave overcome area introduced whispered statewide [SEP]']
[Init] best perm rec loss: 0.8092846274375916 for ['[CLS] introduced opus 1st area rico statewidensor knockout whispered overcome currency shave [SEP]']
[Init] best perm rec loss: 0.8059147596359253 for ['[CLS] statewide area shave overcome whispered currencynsor opus introduced rico knockout 1st [SEP]']
[Init] best perm rec loss: 0.8057880997657776 for ['[CLS] 1st rico shave knockout area statewide opus overcome currency whisperednsor introduced [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.244 (perp=9.948, rec=0.243, cos=0.012), tot_loss_proj:2.587 [t=0.23s]
prediction: ['[CLS] the circuit awkwardly is jim circuit attendant is awkwardly awkwardly paced circuit [SEP]']
[ 100/2000] tot_loss=2.221 (perp=10.172, rec=0.180, cos=0.006), tot_loss_proj:2.621 [t=0.23s]
prediction: ['[CLS] is circuit awkwardly is circuit soap opera is awkwardly awkwardly paced circuit [SEP]']
[ 150/2000] tot_loss=2.061 (perp=9.638, rec=0.127, cos=0.006), tot_loss_proj:2.555 [t=0.23s]
prediction: ['[CLS] the circuit awkwardly is circuit soap opera is awkwardly awkwardly paced story [SEP]']
[ 200/2000] tot_loss=2.014 (perp=9.491, rec=0.111, cos=0.005), tot_loss_proj:2.505 [t=0.23s]
prediction: ['[CLS] the circuit awkwardly is circuit soap opera - awkwardly awkwardly paced story [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.870 (perp=8.778, rec=0.109, cos=0.005), tot_loss_proj:2.218 [t=0.23s]
prediction: ['[CLS] the circuit circuit is awkwardly soap opera - awkwardly awkwardly paced story [SEP]']
[ 300/2000] tot_loss=1.860 (perp=8.778, rec=0.099, cos=0.005), tot_loss_proj:2.221 [t=0.23s]
prediction: ['[CLS] the circuit circuit is awkwardly soap opera - awkwardly awkwardly paced story [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.699 (perp=7.991, rec=0.096, cos=0.005), tot_loss_proj:2.061 [t=0.23s]
prediction: ['[CLS] the story circuit is awkwardly soap opera - awkwardly awkwardly paced circuit [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.888 (perp=8.929, rec=0.097, cos=0.005), tot_loss_proj:2.236 [t=0.24s]
prediction: ['[CLS] the story circuit is awkwardly awkwardly soap operah awkwardly paced circuit [SEP]']
[ 450/2000] tot_loss=1.886 (perp=8.913, rec=0.099, cos=0.005), tot_loss_proj:2.178 [t=0.24s]
prediction: ['[CLS] the story - is awkwardly paced soap operah awkwardly paced circuit [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.797 (perp=8.505, rec=0.091, cos=0.005), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] the story is - awkwardly paced soap operah awkwardly paced circuit [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.930 (perp=9.162, rec=0.093, cos=0.004), tot_loss_proj:2.274 [t=0.24s]
prediction: ['[CLS] the story is awkwardly tack - soap operah awkwardly paced circuit [SEP]']
[ 600/2000] tot_loss=1.971 (perp=9.388, rec=0.089, cos=0.004), tot_loss_proj:2.341 [t=0.24s]
prediction: ['[CLS] the story is awkwardly is - soap operah awkwardly paced circuit [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.745 (perp=8.238, rec=0.093, cos=0.004), tot_loss_proj:2.115 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced - soap operah awkwardly is circuit [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.686 (perp=7.926, rec=0.096, cos=0.005), tot_loss_proj:2.043 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced - awkwardly soap operah is circuit [SEP]']
[ 750/2000] tot_loss=1.675 (perp=7.926, rec=0.086, cos=0.004), tot_loss_proj:2.035 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced - awkwardly soap operah is circuit [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.622 (perp=7.686, rec=0.081, cos=0.004), tot_loss_proj:1.984 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced - awkwardly soap operah circuit is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.557 (perp=7.356, rec=0.082, cos=0.004), tot_loss_proj:1.920 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
[ 900/2000] tot_loss=1.560 (perp=7.356, rec=0.084, cos=0.004), tot_loss_proj:1.922 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.559 (perp=7.356, rec=0.084, cos=0.004), tot_loss_proj:1.918 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.556 (perp=7.356, rec=0.081, cos=0.004), tot_loss_proj:1.920 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
[1050/2000] tot_loss=1.559 (perp=7.356, rec=0.083, cos=0.004), tot_loss_proj:1.917 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.546 (perp=7.356, rec=0.070, cos=0.004), tot_loss_proj:1.917 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.558 (perp=7.356, rec=0.082, cos=0.004), tot_loss_proj:1.924 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
[1200/2000] tot_loss=1.557 (perp=7.356, rec=0.081, cos=0.004), tot_loss_proj:1.915 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.554 (perp=7.356, rec=0.078, cos=0.004), tot_loss_proj:1.927 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.552 (perp=7.356, rec=0.077, cos=0.004), tot_loss_proj:1.919 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
[1350/2000] tot_loss=1.557 (perp=7.356, rec=0.082, cos=0.004), tot_loss_proj:1.914 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.546 (perp=7.356, rec=0.071, cos=0.004), tot_loss_proj:1.920 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.551 (perp=7.356, rec=0.075, cos=0.004), tot_loss_proj:1.907 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
[1500/2000] tot_loss=1.560 (perp=7.356, rec=0.084, cos=0.004), tot_loss_proj:1.915 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.543 (perp=7.356, rec=0.067, cos=0.004), tot_loss_proj:1.915 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.554 (perp=7.356, rec=0.078, cos=0.004), tot_loss_proj:1.909 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
[1650/2000] tot_loss=1.548 (perp=7.356, rec=0.073, cos=0.004), tot_loss_proj:1.914 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.551 (perp=7.356, rec=0.075, cos=0.004), tot_loss_proj:1.914 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.547 (perp=7.356, rec=0.072, cos=0.004), tot_loss_proj:1.927 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
[1800/2000] tot_loss=1.552 (perp=7.356, rec=0.077, cos=0.004), tot_loss_proj:1.912 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.547 (perp=7.356, rec=0.072, cos=0.004), tot_loss_proj:1.914 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.547 (perp=7.356, rec=0.071, cos=0.004), tot_loss_proj:1.919 [t=0.23s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
[1950/2000] tot_loss=1.556 (perp=7.356, rec=0.080, cos=0.004), tot_loss_proj:1.914 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.553 (perp=7.356, rec=0.078, cos=0.004), tot_loss_proj:1.921 [t=0.24s]
prediction: ['[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] the story is awkwardly paced. awkwardly soap operah circuit is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 75.000 | r: 81.818
rouge2     | fm: 19.048 | p: 18.182 | r: 20.000
rougeL     | fm: 52.174 | p: 50.000 | r: 54.545
rougeLsum  | fm: 52.174 | p: 50.000 | r: 54.545
r1fm+r2fm = 97.308

[Aggregate metrics]:
rouge1     | fm: 88.009 | p: 88.018 | r: 88.245
rouge2     | fm: 54.726 | p: 54.730 | r: 54.716
rougeL     | fm: 75.156 | p: 75.201 | r: 75.289
rougeLsum  | fm: 75.047 | p: 75.116 | r: 75.203
r1fm+r2fm = 142.735

input #60 time: 0:09:15 | total time: 9:20:29


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.9986195720335935
highest_index [0]
highest [0.9986195720335935]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9799600839614868 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9755334854125977 for ['[CLS] way consists prison [SEP]']
[Init] best rec loss: 0.9550703763961792 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9523242712020874 for ['[CLS] running varied column [SEP]']
[Init] best rec loss: 0.9408973455429077 for ['[CLS] dunesmain dinah [SEP]']
[Init] best rec loss: 0.9357168078422546 for ['[CLS] huffington class matter [SEP]']
[Init] best rec loss: 0.9284790754318237 for ['[CLS] 1980s behindae [SEP]']
[Init] best rec loss: 0.9013001918792725 for ['[CLS] wishes chaplain blast [SEP]']
[Init] best perm rec loss: 0.8987635374069214 for ['[CLS] chaplain wishes blast [SEP]']
[Init] best perm rec loss: 0.8975244164466858 for ['[CLS] wishes blast chaplain [SEP]']
[Init] best perm rec loss: 0.8962423801422119 for ['[CLS] blast chaplain wishes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.440 (perp=11.583, rec=0.630, cos=0.493), tot_loss_proj:3.828 [t=0.23s]
prediction: ['[CLS] difficult dies atmosphere [SEP]']
[ 100/2000] tot_loss=2.630 (perp=7.942, rec=0.559, cos=0.482), tot_loss_proj:3.531 [t=0.23s]
prediction: ['[CLS], scene scene [SEP]']
[ 150/2000] tot_loss=2.709 (perp=8.815, rec=0.559, cos=0.386), tot_loss_proj:2.078 [t=0.23s]
prediction: ['[CLS], scene beautiful [SEP]']
[ 200/2000] tot_loss=2.709 (perp=8.941, rec=0.520, cos=0.400), tot_loss_proj:2.146 [t=0.24s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.686 (perp=8.941, rec=0.515, cos=0.383), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 300/2000] tot_loss=2.632 (perp=8.941, rec=0.500, cos=0.344), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.415 (perp=7.752, rec=0.533, cos=0.331), tot_loss_proj:1.843 [t=0.23s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.354 (perp=7.752, rec=0.485, cos=0.318), tot_loss_proj:1.844 [t=0.24s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 450/2000] tot_loss=2.325 (perp=7.752, rec=0.476, cos=0.299), tot_loss_proj:1.844 [t=0.24s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.477 (perp=7.752, rec=0.545, cos=0.382), tot_loss_proj:1.845 [t=0.23s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.367 (perp=7.752, rec=0.502, cos=0.314), tot_loss_proj:1.835 [t=0.23s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 600/2000] tot_loss=2.328 (perp=7.752, rec=0.487, cos=0.290), tot_loss_proj:1.839 [t=0.23s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.305 (perp=7.752, rec=0.484, cos=0.270), tot_loss_proj:1.844 [t=0.24s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.321 (perp=7.752, rec=0.481, cos=0.290), tot_loss_proj:1.856 [t=0.23s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 750/2000] tot_loss=2.266 (perp=7.752, rec=0.459, cos=0.257), tot_loss_proj:1.846 [t=0.24s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.326 (perp=7.752, rec=0.493, cos=0.283), tot_loss_proj:1.838 [t=0.24s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.240 (perp=7.752, rec=0.471, cos=0.219), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 900/2000] tot_loss=2.231 (perp=7.752, rec=0.468, cos=0.212), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.240 (perp=7.752, rec=0.474, cos=0.215), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1000/2000] tot_loss=2.273 (perp=7.752, rec=0.472, cos=0.251), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1050/2000] tot_loss=2.219 (perp=7.752, rec=0.463, cos=0.205), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1100/2000] tot_loss=2.212 (perp=7.752, rec=0.468, cos=0.194), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1150/2000] tot_loss=2.203 (perp=7.752, rec=0.463, cos=0.190), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1200/2000] tot_loss=2.205 (perp=7.752, rec=0.469, cos=0.186), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1250/2000] tot_loss=2.195 (perp=7.752, rec=0.457, cos=0.187), tot_loss_proj:1.847 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1300/2000] tot_loss=2.195 (perp=7.752, rec=0.467, cos=0.177), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1350/2000] tot_loss=2.180 (perp=7.752, rec=0.457, cos=0.172), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1400/2000] tot_loss=2.184 (perp=7.752, rec=0.464, cos=0.169), tot_loss_proj:1.847 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1450/2000] tot_loss=2.188 (perp=7.752, rec=0.464, cos=0.174), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1500/2000] tot_loss=2.172 (perp=7.752, rec=0.457, cos=0.165), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1550/2000] tot_loss=2.175 (perp=7.752, rec=0.465, cos=0.159), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1600/2000] tot_loss=2.177 (perp=7.752, rec=0.470, cos=0.156), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1650/2000] tot_loss=2.167 (perp=7.752, rec=0.462, cos=0.154), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1700/2000] tot_loss=2.158 (perp=7.752, rec=0.459, cos=0.149), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1750/2000] tot_loss=2.168 (perp=7.752, rec=0.463, cos=0.154), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1800/2000] tot_loss=2.170 (perp=7.752, rec=0.466, cos=0.154), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1850/2000] tot_loss=2.167 (perp=7.752, rec=0.459, cos=0.158), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1900/2000] tot_loss=2.164 (perp=7.752, rec=0.461, cos=0.153), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1950/2000] tot_loss=2.167 (perp=7.752, rec=0.463, cos=0.153), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[2000/2000] tot_loss=2.156 (perp=7.752, rec=0.460, cos=0.145), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful beautiful scene [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 80.000 | r: 100.000
rouge2     | fm: 85.714 | p: 75.000 | r: 100.000
rougeL     | fm: 88.889 | p: 80.000 | r: 100.000
rougeLsum  | fm: 88.889 | p: 80.000 | r: 100.000
r1fm+r2fm = 174.603

[Aggregate metrics]:
rouge1     | fm: 87.979 | p: 87.762 | r: 88.409
rouge2     | fm: 55.275 | p: 55.215 | r: 55.563
rougeL     | fm: 75.534 | p: 75.487 | r: 75.825
rougeLsum  | fm: 75.252 | p: 75.159 | r: 75.578
r1fm+r2fm = 143.254

input #61 time: 0:09:01 | total time: 9:29:30


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.9988014441786419
highest_index [0]
highest [0.9988014441786419]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9494487643241882 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.918349027633667 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.9122050404548645 for ['[CLS] iron while ceiling kent explosion surface adjacent llc chen awkward springs bourbon abe feemarine order sides marco sure lace translator [SEP]']
[Init] best perm rec loss: 0.9120252132415771 for ['[CLS] surface springs kent awkward lace fee ceiling while sure chen explosionmarine abe adjacent llc sides iron bourbon marco order translator [SEP]']
[Init] best perm rec loss: 0.9096555113792419 for ['[CLS] sides translator lace chen springs sure while bourbon iron explosion abe awkward marco kent feemarine ceiling adjacent surface llc order [SEP]']
[Init] best perm rec loss: 0.9086116552352905 for ['[CLS] sure lace sides marco adjacent translator bourbon surfacemarine llc abe chen iron explosion awkward kent springs fee ceiling while order [SEP]']
[Init] best perm rec loss: 0.9070934653282166 for ['[CLS] springs chen while sides explosion surface ceiling translatormarine llc awkward iron adjacent fee abe sure marco order bourbon lace kent [SEP]']
[Init] best perm rec loss: 0.9068891406059265 for ['[CLS] ceiling explosion adjacent fee sides surface bourbon while llc awkwardmarine iron translator lace sure springs marco abe chen order kent [SEP]']
[Init] best perm rec loss: 0.9059514999389648 for ['[CLS] kent translator springs bourbon explosion surface sure while lace fee iron adjacent llc awkward marcomarine ceiling order abe chen sides [SEP]']
[Init] best perm rec loss: 0.9049345254898071 for ['[CLS] translator springs sure bourbon explosion order sides abe llc chen iron lace awkward while fee surface kentmarine ceiling marco adjacent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.360 (perp=13.280, rec=0.502, cos=0.202), tot_loss_proj:4.187 [t=0.23s]
prediction: ['[CLS] glory cargo sovereign focuses cyclone ho good best vin tommy wendell ) liable john to bailey students gordon 9 erin grace [SEP]']
[ 100/2000] tot_loss=2.930 (perp=11.815, rec=0.402, cos=0.165), tot_loss_proj:4.248 [t=0.24s]
prediction: ['[CLS] grace making said focuses breach best - best ne / blame ) liable the to [UNK] random through prevention carly grace [SEP]']
[ 150/2000] tot_loss=2.876 (perp=11.940, rec=0.360, cos=0.128), tot_loss_proj:3.947 [t=0.24s]
prediction: ['[CLS] grace making to focuses breach best make best tony during prevention ) liable paul through boyd schultz through prevention surprised grace [SEP]']
[ 200/2000] tot_loss=2.635 (perp=10.928, rec=0.307, cos=0.142), tot_loss_proj:3.974 [t=0.24s]
prediction: ['[CLS] grace making to photographs shortage best be ever× during prevention of liable the toead2 through prevention surprised grace [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.444 (perp=10.183, rec=0.276, cos=0.131), tot_loss_proj:3.981 [t=0.24s]
prediction: ['[CLS] grace making to shopping shortage best is ever arbitrary during the prevention of liable toead2 for prevention surprised grace [SEP]']
[ 300/2000] tot_loss=2.547 (perp=10.733, rec=0.263, cos=0.137), tot_loss_proj:3.572 [t=0.24s]
prediction: ['[CLS] grace making to designing war best war ever without call the prevention ) liable ofead2 for prevention surprised grace [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.489 (perp=10.637, rec=0.253, cos=0.108), tot_loss_proj:4.019 [t=0.24s]
prediction: ['[CLS] movies ) to shopping war best war ever without call the prevention war liable of extra him for prevention volleyball grace [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.565 (perp=10.762, rec=0.286, cos=0.126), tot_loss_proj:3.780 [t=0.24s]
prediction: ['[CLS] best zoo to visual war movies fuel ever toward call the prevention war liable of boxed him against war € grace [SEP]']
[ 450/2000] tot_loss=2.349 (perp=9.907, rec=0.238, cos=0.130), tot_loss_proj:3.739 [t=0.24s]
prediction: ['[CLS] best. to designing war movies war ever toward call the prevention war liable of boxed him against war parkinson grace [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.493 (perp=10.653, rec=0.246, cos=0.117), tot_loss_proj:3.538 [t=0.24s]
prediction: ['[CLS] best.pathic makes war movies war ever toward call to prevention war liable of to him which war fivb grace [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.470 (perp=10.528, rec=0.247, cos=0.117), tot_loss_proj:3.592 [t=0.24s]
prediction: ['[CLS] best.ius makes war movies everndra call to vaccines prevention war liable of to him which war fivb grace [SEP]']
[ 600/2000] tot_loss=2.342 (perp=10.026, rec=0.222, cos=0.115), tot_loss_proj:3.477 [t=0.24s]
prediction: ['[CLS] best.ius makes war movies ever thereby call to dangerous prevention war blame of to him which war fivb grace [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.276 (perp=9.693, rec=0.225, cos=0.112), tot_loss_proj:3.207 [t=0.24s]
prediction: ['[CLS] best.ius thereby makes war movies ever call to was prevention war blame of to him which war fivb grace [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.244 (perp=9.578, rec=0.215, cos=0.114), tot_loss_proj:3.655 [t=0.24s]
prediction: ['[CLS] best. was whenever makes war movies ever call toius prevention war blame of to him which war fivb grace [SEP]']
[ 750/2000] tot_loss=2.241 (perp=9.535, rec=0.222, cos=0.113), tot_loss_proj:3.588 [t=0.24s]
prediction: ['[CLS] best. was whenever makes war movies ever call theius prevention war blame of to him which war fivb grace [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.169 (perp=9.162, rec=0.215, cos=0.122), tot_loss_proj:3.496 [t=0.24s]
prediction: ['[CLS] best. was whenever makes war movies ever call the prevention war blame of intersection to him which war fivb grace [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.076 (perp=8.789, rec=0.207, cos=0.111), tot_loss_proj:3.401 [t=0.24s]
prediction: ['[CLS] best. was whenever makes war movies ever call the prevention of intersection war blame to him which war fivb grace [SEP]']
[ 900/2000] tot_loss=2.118 (perp=9.018, rec=0.204, cos=0.110), tot_loss_proj:3.431 [t=0.24s]
prediction: ['[CLS] best. was whenever makes war movies ever call the prevention of intersection war blame to these which war fivb grace [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.030 (perp=8.544, rec=0.209, cos=0.112), tot_loss_proj:3.494 [t=0.24s]
prediction: ['[CLS] best grace was whenever makes war movies ever call the prevention of intersection war blame to these which war fivb. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.049 (perp=8.610, rec=0.220, cos=0.107), tot_loss_proj:3.542 [t=0.24s]
prediction: ['[CLS] best grace was whenever makes war movies ever call the prevention of war blame to these which war intersection fivb, [SEP]']
[1050/2000] tot_loss=1.978 (perp=8.319, rec=0.206, cos=0.108), tot_loss_proj:3.472 [t=0.24s]
prediction: ['[CLS] best grace was whenever makes war movies ever call the prevention of war blame to these which war intersection fivb. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.993 (perp=8.385, rec=0.208, cos=0.108), tot_loss_proj:3.107 [t=0.24s]
prediction: ['[CLS] best grace was which makes war movies ever call for prevention of war blame to these whenever war intersection fivb, [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.962 (perp=8.220, rec=0.206, cos=0.112), tot_loss_proj:3.151 [t=0.24s]
prediction: ['[CLS] best grace was which makes war movies ever call for prevention of war blame to war whenever these intersection fivb, [SEP]']
[1200/2000] tot_loss=1.951 (perp=8.220, rec=0.194, cos=0.112), tot_loss_proj:3.146 [t=0.24s]
prediction: ['[CLS] best grace was which makes war movies ever call for prevention of war blame to war whenever these intersection fivb, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.957 (perp=8.220, rec=0.202, cos=0.111), tot_loss_proj:3.147 [t=0.24s]
prediction: ['[CLS] best grace was which makes war movies ever call for prevention of war blame to war whenever these intersection fivb, [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.891 (perp=7.880, rec=0.205, cos=0.110), tot_loss_proj:3.164 [t=0.24s]
prediction: ['[CLS] grace was which makes best war movies ever call for prevention of war blame to war whenever these intersection fivb, [SEP]']
[1350/2000] tot_loss=1.883 (perp=7.880, rec=0.195, cos=0.112), tot_loss_proj:3.162 [t=0.24s]
prediction: ['[CLS] grace was which makes best war movies ever call for prevention of war blame to war whenever these intersection fivb, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.976 (perp=8.372, rec=0.195, cos=0.107), tot_loss_proj:3.402 [t=0.24s]
prediction: ['[CLS] grace was which making best war movies ever call for prevention of war blame to war whenever these intersection fivb, [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.908 (perp=7.975, rec=0.199, cos=0.114), tot_loss_proj:3.297 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection fivb, [SEP]']
[1500/2000] tot_loss=1.882 (perp=7.877, rec=0.198, cos=0.109), tot_loss_proj:3.216 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection despite, [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.864 (perp=7.798, rec=0.194, cos=0.110), tot_loss_proj:3.220 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection, despite [SEP]']
Attempt swap
[1600/2000] tot_loss=1.869 (perp=7.798, rec=0.199, cos=0.110), tot_loss_proj:3.223 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection, despite [SEP]']
[1650/2000] tot_loss=1.868 (perp=7.798, rec=0.196, cos=0.112), tot_loss_proj:3.223 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection, despite [SEP]']
Attempt swap
[1700/2000] tot_loss=1.861 (perp=7.798, rec=0.192, cos=0.109), tot_loss_proj:3.225 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection, despite [SEP]']
Attempt swap
[1750/2000] tot_loss=1.863 (perp=7.798, rec=0.195, cos=0.108), tot_loss_proj:3.220 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection, despite [SEP]']
[1800/2000] tot_loss=1.854 (perp=7.798, rec=0.186, cos=0.108), tot_loss_proj:3.225 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection, despite [SEP]']
Attempt swap
[1850/2000] tot_loss=1.865 (perp=7.798, rec=0.196, cos=0.109), tot_loss_proj:3.221 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection, despite [SEP]']
Attempt swap
[1900/2000] tot_loss=1.869 (perp=7.798, rec=0.201, cos=0.109), tot_loss_proj:3.220 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection, despite [SEP]']
[1950/2000] tot_loss=1.858 (perp=7.798, rec=0.191, cos=0.108), tot_loss_proj:3.218 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection, despite [SEP]']
Attempt swap
[2000/2000] tot_loss=1.861 (perp=7.798, rec=0.193, cos=0.109), tot_loss_proj:3.223 [t=0.24s]
prediction: ['[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection, despite [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] grace was which best war movies ever call for making prevention of war blame to war whenever these intersection, despite [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.636 | p: 63.636 | r: 63.636
rouge2     | fm: 23.810 | p: 23.810 | r: 23.810
rougeL     | fm: 36.364 | p: 36.364 | r: 36.364
rougeLsum  | fm: 36.364 | p: 36.364 | r: 36.364
r1fm+r2fm = 87.446

[Aggregate metrics]:
rouge1     | fm: 87.634 | p: 87.432 | r: 88.051
rouge2     | fm: 54.721 | p: 54.638 | r: 54.914
rougeL     | fm: 74.900 | p: 74.752 | r: 75.201
rougeLsum  | fm: 74.705 | p: 74.635 | r: 74.991
r1fm+r2fm = 142.355

input #62 time: 0:09:23 | total time: 9:38:54


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9986862773836799
highest_index [0]
highest [0.9986862773836799]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.8320707678794861 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.7343606948852539 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7137153744697571 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best rec loss: 0.7061095833778381 for ['[CLS]el sauce readings hannah these [SEP]']
[Init] best rec loss: 0.7014604806900024 for ['[CLS] alpha light gender independence almost [SEP]']
[Init] best perm rec loss: 0.7012014389038086 for ['[CLS] light alpha gender independence almost [SEP]']
[Init] best perm rec loss: 0.698208212852478 for ['[CLS] gender independence almost light alpha [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.188 (perp=10.167, rec=0.146, cos=0.009), tot_loss_proj:2.689 [t=0.23s]
prediction: ['[CLS] looking return ticket return for [SEP]']
[ 100/2000] tot_loss=2.124 (perp=10.167, rec=0.086, cos=0.004), tot_loss_proj:2.671 [t=0.23s]
prediction: ['[CLS] looking return ticket return for [SEP]']
[ 150/2000] tot_loss=2.174 (perp=10.573, rec=0.057, cos=0.003), tot_loss_proj:2.850 [t=0.23s]
prediction: ['[CLS] looking return ticket a for [SEP]']
[ 200/2000] tot_loss=2.180 (perp=10.573, rec=0.063, cos=0.003), tot_loss_proj:2.853 [t=0.24s]
prediction: ['[CLS] looking return ticket a for [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.625 (perp=7.793, rec=0.064, cos=0.003), tot_loss_proj:2.217 [t=0.23s]
prediction: ['[CLS] looking return for a ticket [SEP]']
[ 300/2000] tot_loss=1.626 (perp=7.793, rec=0.065, cos=0.003), tot_loss_proj:2.192 [t=0.24s]
prediction: ['[CLS] looking return for a ticket [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.285 (perp=6.111, rec=0.060, cos=0.003), tot_loss_proj:1.309 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.279 (perp=6.111, rec=0.054, cos=0.003), tot_loss_proj:1.309 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 450/2000] tot_loss=1.287 (perp=6.111, rec=0.063, cos=0.003), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.293 (perp=6.111, rec=0.068, cos=0.003), tot_loss_proj:1.304 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.276 (perp=6.111, rec=0.051, cos=0.003), tot_loss_proj:1.304 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 600/2000] tot_loss=1.299 (perp=6.111, rec=0.074, cos=0.003), tot_loss_proj:1.299 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.284 (perp=6.111, rec=0.059, cos=0.003), tot_loss_proj:1.313 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.285 (perp=6.111, rec=0.060, cos=0.003), tot_loss_proj:1.315 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 750/2000] tot_loss=1.289 (perp=6.111, rec=0.065, cos=0.003), tot_loss_proj:1.315 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.292 (perp=6.111, rec=0.067, cos=0.003), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.276 (perp=6.111, rec=0.051, cos=0.003), tot_loss_proj:1.307 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 900/2000] tot_loss=1.289 (perp=6.111, rec=0.064, cos=0.003), tot_loss_proj:1.310 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.285 (perp=6.111, rec=0.061, cos=0.003), tot_loss_proj:1.297 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.281 (perp=6.111, rec=0.056, cos=0.003), tot_loss_proj:1.302 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1050/2000] tot_loss=1.278 (perp=6.111, rec=0.053, cos=0.003), tot_loss_proj:1.308 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.284 (perp=6.111, rec=0.059, cos=0.003), tot_loss_proj:1.313 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.282 (perp=6.111, rec=0.058, cos=0.003), tot_loss_proj:1.303 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1200/2000] tot_loss=1.283 (perp=6.111, rec=0.058, cos=0.003), tot_loss_proj:1.316 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.003), tot_loss_proj:1.301 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.282 (perp=6.111, rec=0.057, cos=0.003), tot_loss_proj:1.302 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.296 (perp=6.111, rec=0.071, cos=0.003), tot_loss_proj:1.321 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.282 (perp=6.111, rec=0.057, cos=0.003), tot_loss_proj:1.314 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.286 (perp=6.111, rec=0.061, cos=0.003), tot_loss_proj:1.316 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.289 (perp=6.111, rec=0.065, cos=0.003), tot_loss_proj:1.311 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.281 (perp=6.111, rec=0.056, cos=0.003), tot_loss_proj:1.307 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.283 (perp=6.111, rec=0.059, cos=0.003), tot_loss_proj:1.312 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.279 (perp=6.111, rec=0.054, cos=0.003), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.287 (perp=6.111, rec=0.062, cos=0.003), tot_loss_proj:1.310 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.288 (perp=6.111, rec=0.063, cos=0.003), tot_loss_proj:1.314 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.283 (perp=6.111, rec=0.058, cos=0.003), tot_loss_proj:1.318 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.286 (perp=6.111, rec=0.061, cos=0.003), tot_loss_proj:1.310 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.283 (perp=6.111, rec=0.058, cos=0.003), tot_loss_proj:1.313 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.287 (perp=6.111, rec=0.062, cos=0.003), tot_loss_proj:1.305 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.283 (perp=6.111, rec=0.058, cos=0.003), tot_loss_proj:1.302 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.926 | p: 87.713 | r: 88.227
rouge2     | fm: 55.561 | p: 55.513 | r: 55.735
rougeL     | fm: 75.257 | p: 75.186 | r: 75.557
rougeLsum  | fm: 75.127 | p: 75.039 | r: 75.393
r1fm+r2fm = 143.487

input #63 time: 0:09:15 | total time: 9:48:09


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.9986466872629143
highest_index [0]
highest [0.9986466872629143]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8962174654006958 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8545131683349609 for ['[CLS] dale fuel picked [SEP]']
[Init] best rec loss: 0.8266545534133911 for ['[CLS] david [CLS] earliest [SEP]']
[Init] best rec loss: 0.74805748462677 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6888129115104675 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6884679198265076 for ['[CLS] visions wateronale [SEP]']
[Init] best perm rec loss: 0.6875845193862915 for ['[CLS]onale visions water [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.695 (perp=8.065, rec=0.077, cos=0.005), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
[ 100/2000] tot_loss=1.678 (perp=8.065, rec=0.062, cos=0.003), tot_loss_proj:1.701 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
[ 150/2000] tot_loss=1.674 (perp=8.065, rec=0.058, cos=0.003), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[ 200/2000] tot_loss=1.675 (perp=8.065, rec=0.059, cos=0.003), tot_loss_proj:1.706 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.675 (perp=8.065, rec=0.059, cos=0.003), tot_loss_proj:1.709 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[ 300/2000] tot_loss=1.667 (perp=8.065, rec=0.052, cos=0.003), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.674 (perp=8.065, rec=0.058, cos=0.003), tot_loss_proj:1.711 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.676 (perp=8.065, rec=0.060, cos=0.003), tot_loss_proj:1.707 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.678 (perp=8.065, rec=0.062, cos=0.003), tot_loss_proj:1.694 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.671 (perp=8.065, rec=0.055, cos=0.003), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.669 (perp=8.065, rec=0.053, cos=0.003), tot_loss_proj:1.707 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.668 (perp=8.065, rec=0.052, cos=0.003), tot_loss_proj:1.710 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.667 (perp=8.065, rec=0.051, cos=0.003), tot_loss_proj:1.696 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.668 (perp=8.065, rec=0.052, cos=0.003), tot_loss_proj:1.712 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.681 (perp=8.065, rec=0.065, cos=0.003), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.673 (perp=8.065, rec=0.058, cos=0.003), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.671 (perp=8.065, rec=0.056, cos=0.003), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.665 (perp=8.065, rec=0.049, cos=0.003), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.673 (perp=8.065, rec=0.057, cos=0.003), tot_loss_proj:1.711 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.003), tot_loss_proj:1.708 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.003), tot_loss_proj:1.711 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.675 (perp=8.065, rec=0.059, cos=0.003), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.003), tot_loss_proj:1.719 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.672 (perp=8.065, rec=0.056, cos=0.003), tot_loss_proj:1.715 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.672 (perp=8.065, rec=0.056, cos=0.003), tot_loss_proj:1.708 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.678 (perp=8.065, rec=0.062, cos=0.003), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.677 (perp=8.065, rec=0.061, cos=0.003), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.670 (perp=8.065, rec=0.054, cos=0.003), tot_loss_proj:1.707 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.682 (perp=8.065, rec=0.066, cos=0.003), tot_loss_proj:1.697 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.663 (perp=8.065, rec=0.048, cos=0.003), tot_loss_proj:1.688 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.673 (perp=8.065, rec=0.058, cos=0.003), tot_loss_proj:1.708 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.675 (perp=8.065, rec=0.059, cos=0.003), tot_loss_proj:1.708 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.667 (perp=8.065, rec=0.052, cos=0.003), tot_loss_proj:1.708 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.003), tot_loss_proj:1.706 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.682 (perp=8.065, rec=0.066, cos=0.003), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.677 (perp=8.065, rec=0.061, cos=0.003), tot_loss_proj:1.693 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.672 (perp=8.065, rec=0.056, cos=0.003), tot_loss_proj:1.706 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.690 (perp=8.065, rec=0.074, cos=0.003), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.671 (perp=8.065, rec=0.055, cos=0.003), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.688 (perp=8.065, rec=0.072, cos=0.003), tot_loss_proj:1.710 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.067 | p: 87.878 | r: 88.390
rouge2     | fm: 55.998 | p: 55.929 | r: 56.205
rougeL     | fm: 75.501 | p: 75.490 | r: 75.769
rougeLsum  | fm: 75.654 | p: 75.596 | r: 75.922
r1fm+r2fm = 144.065

input #64 time: 0:09:15 | total time: 9:57:24


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9988718868123381
highest_index [0]
highest [0.9988718868123381]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 0.9240533709526062 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9055255055427551 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.8987274765968323 for ['[CLS] dir northern opens gasam acute diocese ban missile [SEP]']
[Init] best rec loss: 0.8901315331459045 for ['[CLS] pale far expert interval pr che gonna time united [SEP]']
[Init] best rec loss: 0.8887251019477844 for ['[CLS] callman minister excellent scratch pleased unexpected accounted amateurs [SEP]']
[Init] best rec loss: 0.8844279050827026 for ['[CLS] health kuept scenicne contact will savamac [SEP]']
[Init] best rec loss: 0.8816733360290527 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.8735255002975464 for ['[CLS] games facing explorers canals is all sphinxitative prints [SEP]']
[Init] best rec loss: 0.8727313280105591 for ['[CLS] criticism yet application pre corn side bridge selections matters [SEP]']
[Init] best rec loss: 0.8720813393592834 for ['[CLS]sity notes blessed gave master way track chase en [SEP]']
[Init] best rec loss: 0.865404486656189 for ['[CLS]ong back acres za just effectiveness martin eva monk [SEP]']
[Init] best rec loss: 0.8433347344398499 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8395609259605408 for ['[CLS] news general someday pu funmamenthoff even overs [SEP]']
[Init] best perm rec loss: 0.8394455313682556 for ['[CLS] even someday general newshoff pu fun oversmament [SEP]']
[Init] best perm rec loss: 0.8392582535743713 for ['[CLS] general pu somedaymament evenhoff news fun overs [SEP]']
[Init] best perm rec loss: 0.8386566638946533 for ['[CLS]hoff general overs even someday news pu funmament [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.380 (perp=8.590, rec=0.769, cos=0.893), tot_loss_proj:2.747 [t=0.23s]
prediction: ['[CLS] dessert ofible joy joyous of technology wave [SEP]']
[ 100/2000] tot_loss=2.795 (perp=11.205, rec=0.441, cos=0.113), tot_loss_proj:3.318 [t=0.23s]
prediction: ['[CLS] fibre of le joy joy winnerstion of journey [SEP]']
[ 150/2000] tot_loss=2.294 (perp=9.189, rec=0.368, cos=0.088), tot_loss_proj:3.103 [t=0.23s]
prediction: ['[CLS], of mac joy joyouski of! [SEP]']
[ 200/2000] tot_loss=2.219 (perp=9.189, rec=0.295, cos=0.086), tot_loss_proj:3.109 [t=0.23s]
prediction: ['[CLS], of mac joy joyouski of! [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.356 (perp=9.892, rec=0.292, cos=0.086), tot_loss_proj:2.798 [t=0.24s]
prediction: ['[CLS], of joyous mac joyki story joy [SEP]']
[ 300/2000] tot_loss=2.423 (perp=10.407, rec=0.259, cos=0.083), tot_loss_proj:2.948 [t=0.23s]
prediction: ['[CLS], of joyous mac joy rom story joy [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.831 (perp=12.302, rec=0.268, cos=0.103), tot_loss_proj:3.562 [t=0.24s]
prediction: ['[CLS]ousous joyous ¿ joy rom rom story [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.712 (perp=11.778, rec=0.263, cos=0.093), tot_loss_proj:3.716 [t=0.24s]
prediction: ['[CLS]ous rom joyous ¿ joy of rom story [SEP]']
[ 450/2000] tot_loss=2.685 (perp=11.778, rec=0.240, cos=0.089), tot_loss_proj:3.720 [t=0.24s]
prediction: ['[CLS]ous rom joyous ¿ joy of rom story [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.451 (perp=10.686, rec=0.231, cos=0.083), tot_loss_proj:3.070 [t=0.24s]
prediction: ['[CLS]ous filmfare rom joyous joyous rom story [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.283 (perp=9.786, rec=0.243, cos=0.083), tot_loss_proj:3.107 [t=0.24s]
prediction: ['[CLS]ous rom joy rom filmfare joyous rom story [SEP]']
[ 600/2000] tot_loss=2.530 (perp=10.931, rec=0.244, cos=0.099), tot_loss_proj:3.300 [t=0.30s]
prediction: ['[CLS]ous rom joy rom covent joyous rom story [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.121 (perp=8.917, rec=0.246, cos=0.091), tot_loss_proj:3.018 [t=0.24s]
prediction: ['[CLS] rom joyous rom covent joyous rom story [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.753 (perp=7.052, rec=0.255, cos=0.087), tot_loss_proj:2.518 [t=0.24s]
prediction: ['[CLS] rom joyous rom joyous rom lankan story [SEP]']
[ 750/2000] tot_loss=1.807 (perp=7.474, rec=0.230, cos=0.082), tot_loss_proj:2.647 [t=0.24s]
prediction: ['[CLS] rom joyous rom joyous rom lankan film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.797 (perp=7.474, rec=0.221, cos=0.082), tot_loss_proj:2.653 [t=0.24s]
prediction: ['[CLS] rom joyous rom joyous rom lankan film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.797 (perp=7.474, rec=0.218, cos=0.084), tot_loss_proj:2.651 [t=0.24s]
prediction: ['[CLS] rom joyous rom joyous rom lankan film [SEP]']
[ 900/2000] tot_loss=1.802 (perp=7.474, rec=0.224, cos=0.083), tot_loss_proj:2.650 [t=0.24s]
prediction: ['[CLS] rom joyous rom joyous rom lankan film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.793 (perp=7.474, rec=0.224, cos=0.074), tot_loss_proj:2.654 [t=0.24s]
prediction: ['[CLS] rom joyous rom joyous rom lankan film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.788 (perp=7.474, rec=0.219, cos=0.074), tot_loss_proj:2.649 [t=0.24s]
prediction: ['[CLS] rom joyous rom joyous rom lankan film [SEP]']
[1050/2000] tot_loss=1.785 (perp=7.474, rec=0.212, cos=0.079), tot_loss_proj:2.653 [t=0.24s]
prediction: ['[CLS] rom joyous rom joyous rom lankan film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.788 (perp=7.474, rec=0.215, cos=0.078), tot_loss_proj:2.649 [t=0.24s]
prediction: ['[CLS] rom joyous rom joyous rom lankan film [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.968 (perp=8.323, rec=0.219, cos=0.083), tot_loss_proj:2.519 [t=0.23s]
prediction: ['[CLS]ae joyous rom joyous rom lankan film [SEP]']
[1200/2000] tot_loss=1.946 (perp=8.323, rec=0.208, cos=0.074), tot_loss_proj:2.512 [t=0.24s]
prediction: ['[CLS]ae joyous rom joyous rom lankan film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.964 (perp=8.323, rec=0.222, cos=0.078), tot_loss_proj:2.515 [t=0.24s]
prediction: ['[CLS]ae joyous rom joyous rom lankan film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.943 (perp=8.323, rec=0.206, cos=0.072), tot_loss_proj:2.519 [t=0.24s]
prediction: ['[CLS]ae joyous rom joyous rom lankan film [SEP]']
[1350/2000] tot_loss=2.074 (perp=8.905, rec=0.216, cos=0.076), tot_loss_proj:2.816 [t=0.24s]
prediction: ['[CLS]ae joyous rom joyous rom covent film [SEP]']
Attempt swap
[1400/2000] tot_loss=2.061 (perp=8.905, rec=0.207, cos=0.073), tot_loss_proj:2.828 [t=0.23s]
prediction: ['[CLS]ae joyous rom joyous rom covent film [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.977 (perp=8.357, rec=0.228, cos=0.078), tot_loss_proj:2.766 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
[1500/2000] tot_loss=1.976 (perp=8.357, rec=0.229, cos=0.075), tot_loss_proj:2.767 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
Attempt swap
[1550/2000] tot_loss=1.948 (perp=8.357, rec=0.201, cos=0.076), tot_loss_proj:2.771 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
Attempt swap
[1600/2000] tot_loss=1.953 (perp=8.357, rec=0.206, cos=0.076), tot_loss_proj:2.765 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
[1650/2000] tot_loss=1.962 (perp=8.357, rec=0.216, cos=0.075), tot_loss_proj:2.777 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
Attempt swap
[1700/2000] tot_loss=1.953 (perp=8.357, rec=0.206, cos=0.076), tot_loss_proj:2.774 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
Attempt swap
[1750/2000] tot_loss=1.951 (perp=8.357, rec=0.205, cos=0.075), tot_loss_proj:2.763 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
[1800/2000] tot_loss=1.953 (perp=8.357, rec=0.206, cos=0.075), tot_loss_proj:2.770 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
Attempt swap
[1850/2000] tot_loss=1.953 (perp=8.357, rec=0.207, cos=0.075), tot_loss_proj:2.763 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
Attempt swap
[1900/2000] tot_loss=1.952 (perp=8.357, rec=0.206, cos=0.075), tot_loss_proj:2.771 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
[1950/2000] tot_loss=1.951 (perp=8.357, rec=0.205, cos=0.075), tot_loss_proj:2.773 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
Attempt swap
[2000/2000] tot_loss=1.948 (perp=8.357, rec=0.202, cos=0.075), tot_loss_proj:2.770 [t=0.24s]
prediction: ['[CLS] film joyous rom joyous rom lankanae [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] film joyous rom joyous rom lankanae [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.333 | p: 50.000 | r: 57.143
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 37.500 | r: 42.857
rougeLsum  | fm: 40.000 | p: 37.500 | r: 42.857
r1fm+r2fm = 53.333

[Aggregate metrics]:
rouge1     | fm: 87.513 | p: 87.249 | r: 87.960
rouge2     | fm: 55.076 | p: 55.094 | r: 55.276
rougeL     | fm: 75.028 | p: 74.922 | r: 75.327
rougeLsum  | fm: 75.165 | p: 74.987 | r: 75.431
r1fm+r2fm = 142.590

input #65 time: 0:09:16 | total time: 10:06:41


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9988939702840258
highest_index [0]
highest [0.9988939702840258]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.8663562536239624 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.8620549440383911 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8502825498580933 for ['[CLS] commerce wikipedia experiment if [SEP]']
[Init] best rec loss: 0.8414666652679443 for ['[CLS] complied man ready panic [SEP]']
[Init] best rec loss: 0.8413494825363159 for ['[CLS] youtubeology r cain [SEP]']
[Init] best rec loss: 0.8389527201652527 for ['[CLS] september st minimum invitation [SEP]']
[Init] best rec loss: 0.8054654002189636 for ['[CLS] helmet stared true deposit [SEP]']
[Init] best rec loss: 0.8036768436431885 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best rec loss: 0.7923311591148376 for ['[CLS] programs will liner brigade [SEP]']
[Init] best perm rec loss: 0.7921156287193298 for ['[CLS] liner will programs brigade [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.483 (perp=9.295, rec=0.447, cos=0.177), tot_loss_proj:2.795 [t=0.23s]
prediction: ['[CLS] fan fan fan fan [SEP]']
[ 100/2000] tot_loss=2.777 (perp=11.286, rec=0.363, cos=0.157), tot_loss_proj:3.146 [t=0.23s]
prediction: ['[CLS] fan fan tolkien tolkien [SEP]']
[ 150/2000] tot_loss=2.735 (perp=11.286, rec=0.307, cos=0.171), tot_loss_proj:3.146 [t=0.24s]
prediction: ['[CLS] fan fan tolkien tolkien [SEP]']
[ 200/2000] tot_loss=2.671 (perp=11.286, rec=0.285, cos=0.128), tot_loss_proj:3.156 [t=0.23s]
prediction: ['[CLS] fan fan tolkien tolkien [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.261 (perp=9.181, rec=0.302, cos=0.123), tot_loss_proj:2.138 [t=0.24s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 300/2000] tot_loss=2.230 (perp=9.181, rec=0.236, cos=0.158), tot_loss_proj:2.140 [t=0.24s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.262 (perp=9.181, rec=0.243, cos=0.183), tot_loss_proj:2.137 [t=0.24s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.217 (perp=9.181, rec=0.223, cos=0.158), tot_loss_proj:2.139 [t=0.24s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 450/2000] tot_loss=2.696 (perp=11.344, rec=0.255, cos=0.173), tot_loss_proj:2.622 [t=0.24s]
prediction: ['[CLS] longtime haydn tolkien fan [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.359 (perp=9.917, rec=0.210, cos=0.165), tot_loss_proj:2.780 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan tolkien [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.920 (perp=12.662, rec=0.239, cos=0.148), tot_loss_proj:3.334 [t=0.24s]
prediction: ['[CLS] longtime tolkien eruptions fan [SEP]']
[ 600/2000] tot_loss=2.828 (perp=12.140, rec=0.224, cos=0.176), tot_loss_proj:2.873 [t=0.24s]
prediction: ['[CLS] longtime tolkien siblings fan [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.339 (perp=9.733, rec=0.213, cos=0.179), tot_loss_proj:2.753 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan siblings [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.318 (perp=9.733, rec=0.198, cos=0.173), tot_loss_proj:2.758 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan siblings [SEP]']
[ 750/2000] tot_loss=2.438 (perp=10.261, rec=0.196, cos=0.189), tot_loss_proj:2.883 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan haydn [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.423 (perp=10.261, rec=0.184, cos=0.186), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan haydn [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.430 (perp=10.261, rec=0.186, cos=0.191), tot_loss_proj:2.882 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan haydn [SEP]']
[ 900/2000] tot_loss=2.428 (perp=10.261, rec=0.190, cos=0.185), tot_loss_proj:2.879 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan haydn [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.427 (perp=10.261, rec=0.191, cos=0.183), tot_loss_proj:2.879 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan haydn [SEP]']
Attempt swap
[1000/2000] tot_loss=2.433 (perp=10.261, rec=0.204, cos=0.176), tot_loss_proj:2.887 [t=0.23s]
prediction: ['[CLS] longtime tolkien fan haydn [SEP]']
[1050/2000] tot_loss=2.420 (perp=10.261, rec=0.185, cos=0.182), tot_loss_proj:2.879 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan haydn [SEP]']
Attempt swap
[1100/2000] tot_loss=2.422 (perp=10.261, rec=0.186, cos=0.183), tot_loss_proj:2.881 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan haydn [SEP]']
Attempt swap
[1150/2000] tot_loss=2.418 (perp=10.261, rec=0.187, cos=0.179), tot_loss_proj:2.884 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan haydn [SEP]']
[1200/2000] tot_loss=2.415 (perp=10.272, rec=0.179, cos=0.181), tot_loss_proj:2.964 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Attempt swap
[1250/2000] tot_loss=2.416 (perp=10.272, rec=0.183, cos=0.178), tot_loss_proj:2.953 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Attempt swap
[1300/2000] tot_loss=2.422 (perp=10.272, rec=0.186, cos=0.182), tot_loss_proj:2.961 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
[1350/2000] tot_loss=2.404 (perp=10.272, rec=0.170, cos=0.179), tot_loss_proj:2.963 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Attempt swap
[1400/2000] tot_loss=2.416 (perp=10.272, rec=0.180, cos=0.181), tot_loss_proj:2.955 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Attempt swap
[1450/2000] tot_loss=2.423 (perp=10.272, rec=0.186, cos=0.182), tot_loss_proj:2.969 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
[1500/2000] tot_loss=2.414 (perp=10.272, rec=0.180, cos=0.180), tot_loss_proj:2.960 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Attempt swap
[1550/2000] tot_loss=2.421 (perp=10.272, rec=0.185, cos=0.182), tot_loss_proj:2.965 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Attempt swap
[1600/2000] tot_loss=2.414 (perp=10.272, rec=0.178, cos=0.181), tot_loss_proj:2.957 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
[1650/2000] tot_loss=2.421 (perp=10.272, rec=0.185, cos=0.181), tot_loss_proj:2.965 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Attempt swap
[1700/2000] tot_loss=2.417 (perp=10.272, rec=0.180, cos=0.182), tot_loss_proj:2.964 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Attempt swap
[1750/2000] tot_loss=2.416 (perp=10.272, rec=0.180, cos=0.181), tot_loss_proj:2.963 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
[1800/2000] tot_loss=2.413 (perp=10.272, rec=0.178, cos=0.181), tot_loss_proj:2.967 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Attempt swap
[1850/2000] tot_loss=2.408 (perp=10.272, rec=0.173, cos=0.181), tot_loss_proj:2.956 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Attempt swap
[1900/2000] tot_loss=2.406 (perp=10.272, rec=0.171, cos=0.181), tot_loss_proj:2.953 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
[1950/2000] tot_loss=2.420 (perp=10.272, rec=0.186, cos=0.180), tot_loss_proj:2.958 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Attempt swap
[2000/2000] tot_loss=2.406 (perp=10.272, rec=0.171, cos=0.181), tot_loss_proj:2.961 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan predecessors [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] longtime tolkien fan predecessors [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 123.333

[Aggregate metrics]:
rouge1     | fm: 87.494 | p: 87.243 | r: 87.868
rouge2     | fm: 54.955 | p: 54.985 | r: 55.213
rougeL     | fm: 75.109 | p: 74.945 | r: 75.458
rougeLsum  | fm: 75.213 | p: 75.098 | r: 75.530
r1fm+r2fm = 142.449

input #66 time: 0:09:16 | total time: 10:15:57


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.9986287855640208
highest_index [0]
highest [0.9986287855640208]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 0.9638789892196655 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.962137758731842 for ['[CLS]tched forward bunk kinds virginiahiparians war ann scenery [SEP]']
[Init] best rec loss: 0.9554975628852844 for ['[CLS] ^ banksgger biology mont neck administration action pool neo [SEP]']
[Init] best rec loss: 0.9511768817901611 for ['[CLS] morton socks backwards blur stiff urban freddy6 you entirely [SEP]']
[Init] best rec loss: 0.9405099153518677 for ['[CLS] midnight fact why done headign promotion else cornelius charm [SEP]']
[Init] best perm rec loss: 0.9389825463294983 for ['[CLS]ign head charm done fact cornelius promotion midnight else why [SEP]']
[Init] best perm rec loss: 0.9384437203407288 for ['[CLS] why done fact midnight else promotion charm corneliusign head [SEP]']
[Init] best perm rec loss: 0.9379181265830994 for ['[CLS] cornelius why promotion fact elseign done head midnight charm [SEP]']
[Init] best perm rec loss: 0.9360567331314087 for ['[CLS] midnight fact why else cornelius done promotionign charm head [SEP]']
[Init] best perm rec loss: 0.9352695345878601 for ['[CLS] cornelius doneign head promotion midnight fact charm why else [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.350 (perp=12.376, rec=0.615, cos=0.260), tot_loss_proj:4.120 [t=0.23s]
prediction: ['[CLS] des tax corpsuating kind hearts kindth hypothesis bad [SEP]']
[ 100/2000] tot_loss=3.608 (perp=14.075, rec=0.598, cos=0.196), tot_loss_proj:4.752 [t=0.23s]
prediction: ['[CLS]gee wedding environmentaluating kindwar deathna kind sioux [SEP]']
[ 150/2000] tot_loss=3.536 (perp=14.504, rec=0.529, cos=0.106), tot_loss_proj:4.477 [t=0.24s]
prediction: ['[CLS] thoughts weddingght kind kindwar kindgm kind kind [SEP]']
[ 200/2000] tot_loss=3.676 (perp=14.474, rec=0.579, cos=0.203), tot_loss_proj:4.226 [t=0.23s]
prediction: ['[CLS]cend diaspora themes kind kindwar kindental kind kind [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.242 (perp=13.503, rec=0.486, cos=0.056), tot_loss_proj:4.214 [t=0.23s]
prediction: ['[CLS] kindrricular themes kindcendwarwarental kind kind [SEP]']
[ 300/2000] tot_loss=3.377 (perp=13.200, rec=0.536, cos=0.201), tot_loss_proj:4.366 [t=0.23s]
prediction: ['[CLS] kindrricular themes kindwarwarwarental kind kind [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.314 (perp=13.710, rec=0.483, cos=0.089), tot_loss_proj:4.592 [t=0.23s]
prediction: ['[CLS] kindwar themes kindming contractionwarental kind kind [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.827 (perp=11.647, rec=0.447, cos=0.050), tot_loss_proj:3.375 [t=0.24s]
prediction: ['[CLS] heartwarming kind themes contractionwarental kind kind [SEP]']
[ 450/2000] tot_loss=3.415 (perp=13.712, rec=0.571, cos=0.101), tot_loss_proj:4.617 [t=0.24s]
prediction: ['[CLS] heartwarwar kindfree contractionwarental kind kind [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.079 (perp=13.219, rec=0.367, cos=0.069), tot_loss_proj:4.575 [t=0.23s]
prediction: ['[CLS] heartwarwar immediately kind contractionwarental kind reserved [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.130 (perp=13.630, rec=0.306, cos=0.099), tot_loss_proj:4.322 [t=0.24s]
prediction: ['[CLS] heartwarwar immediately kind contractionwarental kind kind [SEP]']
[ 600/2000] tot_loss=3.066 (perp=13.630, rec=0.263, cos=0.078), tot_loss_proj:4.311 [t=0.23s]
prediction: ['[CLS] heartwarwar immediately kind contractionwarental kind kind [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.757 (perp=12.178, rec=0.238, cos=0.084), tot_loss_proj:4.406 [t=0.24s]
prediction: ['[CLS] heartwarwar contraction kind immediatelywarental kind kind [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.741 (perp=12.061, rec=0.238, cos=0.091), tot_loss_proj:4.393 [t=0.23s]
prediction: ['[CLS] heartwarwar contraction kinduntwarentalental kind [SEP]']
[ 750/2000] tot_loss=2.715 (perp=12.061, rec=0.225, cos=0.078), tot_loss_proj:4.394 [t=0.24s]
prediction: ['[CLS] heartwarwar contraction kinduntwarentalental kind [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.749 (perp=12.061, rec=0.232, cos=0.105), tot_loss_proj:4.386 [t=0.23s]
prediction: ['[CLS] heartwarwar contraction kinduntwarentalental kind [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.843 (perp=12.720, rec=0.208, cos=0.091), tot_loss_proj:4.361 [t=0.23s]
prediction: ['[CLS] heartwarwar cluster kinduntwarentalental kind [SEP]']
[ 900/2000] tot_loss=2.814 (perp=12.608, rec=0.201, cos=0.092), tot_loss_proj:4.476 [t=0.23s]
prediction: ['[CLS] heartwarwar cluster kinduntwar nonental kind [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=3.332 (perp=14.797, rec=0.290, cos=0.083), tot_loss_proj:4.972 [t=0.24s]
prediction: ['[CLS] heartwar limit kinduntwar non 止ental kind [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=3.018 (perp=13.327, rec=0.272, cos=0.081), tot_loss_proj:4.152 [t=0.24s]
prediction: ['[CLS] heartwarwar non∆ limit kind strideental kind [SEP]']
[1050/2000] tot_loss=2.755 (perp=12.106, rec=0.242, cos=0.092), tot_loss_proj:4.204 [t=0.23s]
prediction: ['[CLS] heartwarwar nonjo contraction kind strideental kind [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.680 (perp=11.740, rec=0.242, cos=0.090), tot_loss_proj:4.141 [t=0.24s]
prediction: ['[CLS] heartwarwarjo non contraction kind strideental kind [SEP]']
Attempt swap
[1150/2000] tot_loss=2.669 (perp=11.740, rec=0.233, cos=0.087), tot_loss_proj:4.143 [t=0.24s]
prediction: ['[CLS] heartwarwarjo non contraction kind strideental kind [SEP]']
[1200/2000] tot_loss=2.662 (perp=11.740, rec=0.227, cos=0.087), tot_loss_proj:4.140 [t=0.24s]
prediction: ['[CLS] heartwarwarjo non contraction kind strideental kind [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.599 (perp=11.359, rec=0.237, cos=0.091), tot_loss_proj:3.675 [t=0.23s]
prediction: ['[CLS] kind heartwarwarjo non contraction strideental kind [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.565 (perp=11.187, rec=0.239, cos=0.088), tot_loss_proj:3.656 [t=0.23s]
prediction: ['[CLS] kind heartwarwarjo non contractionental kind stride [SEP]']
[1350/2000] tot_loss=2.535 (perp=11.086, rec=0.232, cos=0.086), tot_loss_proj:3.764 [t=0.23s]
prediction: ['[CLS] kind heartwarwarjo non contractionental kind vegetarian [SEP]']
Attempt swap
[1400/2000] tot_loss=2.521 (perp=11.086, rec=0.220, cos=0.084), tot_loss_proj:3.762 [t=0.23s]
prediction: ['[CLS] kind heartwarwarjo non contractionental kind vegetarian [SEP]']
Attempt swap
[1450/2000] tot_loss=2.516 (perp=11.086, rec=0.214, cos=0.084), tot_loss_proj:3.767 [t=0.24s]
prediction: ['[CLS] kind heartwarwarjo non contractionental kind vegetarian [SEP]']
[1500/2000] tot_loss=2.682 (perp=11.917, rec=0.215, cos=0.083), tot_loss_proj:3.957 [t=0.24s]
prediction: ['[CLS] kind heartwarwarwar non contractionental kind vegetarian [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.508 (perp=11.017, rec=0.220, cos=0.084), tot_loss_proj:3.863 [t=0.24s]
prediction: ['[CLS] kind heartwarwar contraction nonwarental kind vegetarian [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.466 (perp=10.809, rec=0.221, cos=0.084), tot_loss_proj:3.828 [t=0.24s]
prediction: ['[CLS] kind heartwarwar contraction nonwarental vegetarian kind [SEP]']
[1650/2000] tot_loss=2.452 (perp=10.809, rec=0.207, cos=0.084), tot_loss_proj:3.832 [t=0.24s]
prediction: ['[CLS] kind heartwarwar contraction nonwarental vegetarian kind [SEP]']
Attempt swap
[1700/2000] tot_loss=2.454 (perp=10.809, rec=0.210, cos=0.082), tot_loss_proj:3.823 [t=0.24s]
prediction: ['[CLS] kind heartwarwar contraction nonwarental vegetarian kind [SEP]']
Attempt swap
[1750/2000] tot_loss=2.448 (perp=10.809, rec=0.204, cos=0.082), tot_loss_proj:3.831 [t=0.24s]
prediction: ['[CLS] kind heartwarwar contraction nonwarental vegetarian kind [SEP]']
[1800/2000] tot_loss=2.448 (perp=10.809, rec=0.205, cos=0.082), tot_loss_proj:3.830 [t=0.24s]
prediction: ['[CLS] kind heartwarwar contraction nonwarental vegetarian kind [SEP]']
Attempt swap
[1850/2000] tot_loss=2.462 (perp=10.809, rec=0.217, cos=0.082), tot_loss_proj:3.833 [t=0.24s]
prediction: ['[CLS] kind heartwarwar contraction nonwarental vegetarian kind [SEP]']
Attempt swap
[1900/2000] tot_loss=2.450 (perp=10.809, rec=0.206, cos=0.082), tot_loss_proj:3.830 [t=0.23s]
prediction: ['[CLS] kind heartwarwar contraction nonwarental vegetarian kind [SEP]']
[1950/2000] tot_loss=2.446 (perp=10.809, rec=0.202, cos=0.082), tot_loss_proj:3.833 [t=0.24s]
prediction: ['[CLS] kind heartwarwar contraction nonwarental vegetarian kind [SEP]']
Attempt swap
[2000/2000] tot_loss=2.450 (perp=10.809, rec=0.206, cos=0.082), tot_loss_proj:3.831 [t=0.24s]
prediction: ['[CLS] kind heartwarwar contraction nonwarental vegetarian kind [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] heartwarwar cluster kinduntwar nonental kind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 42.857 | r: 60.000
rouge2     | fm: 20.000 | p: 16.667 | r: 25.000
rougeL     | fm: 50.000 | p: 42.857 | r: 60.000
rougeLsum  | fm: 50.000 | p: 42.857 | r: 60.000
r1fm+r2fm = 70.000

[Aggregate metrics]:
rouge1     | fm: 86.919 | p: 86.665 | r: 87.491
rouge2     | fm: 54.402 | p: 54.214 | r: 54.655
rougeL     | fm: 74.730 | p: 74.552 | r: 75.152
rougeLsum  | fm: 74.835 | p: 74.649 | r: 75.265
r1fm+r2fm = 141.321

input #67 time: 0:09:15 | total time: 10:25:13


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9986314617112105
highest_index [0]
highest [0.9986314617112105]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.93393874168396 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.8828513622283936 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 0.855183482170105 for ['[CLS] instant legs discoveredshboot mass pond arabianvati lines abd star 7 [SEP]']
[Init] best rec loss: 0.8472236394882202 for ['[CLS] $ offs dreams national been wallszzsar council frederick but lankan comprehensive [SEP]']
[Init] best rec loss: 0.7880990505218506 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.784644365310669 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.7782233953475952 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.774395763874054 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.7684122323989868 for ['[CLS] councils. died beth form floor possibly comfort view medal ridingyniferous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.599 (perp=11.827, rec=0.223, cos=0.011), tot_loss_proj:3.000 [t=0.22s]
prediction: ['[CLS] absurd |ct. behavior badly vicious renowned?worth terrible contestless [SEP]']
[ 100/2000] tot_loss=2.561 (perp=11.944, rec=0.163, cos=0.009), tot_loss_proj:2.895 [t=0.23s]
prediction: ['[CLS] absurdompsible and laurentosed vicious,? unsibleture absurd [SEP]']
[ 150/2000] tot_loss=2.420 (perp=11.410, rec=0.133, cos=0.005), tot_loss_proj:2.772 [t=0.22s]
prediction: ['[CLS] absurdompsible andenceosed vicious, absurd unsibleture absurd [SEP]']
[ 200/2000] tot_loss=2.584 (perp=12.297, rec=0.121, cos=0.004), tot_loss_proj:2.927 [t=0.23s]
prediction: ['[CLS] absurdompsible andformed sided vicious, absurd unsibleten absurd [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.388 (perp=11.158, rec=0.152, cos=0.005), tot_loss_proj:2.864 [t=0.22s]
prediction: ['[CLS] absurdcosible and paddleberg vicious,, untensible inc [SEP]']
[ 300/2000] tot_loss=2.079 (perp=9.786, rec=0.118, cos=0.003), tot_loss_proj:2.511 [t=0.23s]
prediction: ['[CLS] absurdcouth and incosing vicious,sible untensible inc [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.838 (perp=8.580, rec=0.119, cos=0.003), tot_loss_proj:2.302 [t=0.22s]
prediction: ['[CLS] absurdcouth and incnce vicious, inc. untensible [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.831 (perp=8.595, rec=0.109, cos=0.004), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] viciouscouth and incnce absurd, inc absurd untensible [SEP]']
[ 450/2000] tot_loss=2.029 (perp=9.654, rec=0.096, cos=0.003), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] viciouscouth andomputh absurd, incsible unresible [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.027 (perp=9.620, rec=0.100, cos=0.003), tot_loss_proj:2.390 [t=0.23s]
prediction: ['[CLS] viciouscouth and incompnce absurd,sible unresible [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.945 (perp=9.097, rec=0.121, cos=0.005), tot_loss_proj:2.215 [t=0.22s]
prediction: ['[CLS] viciouscouth and incomp absurding absurd, unresible [SEP]']
[ 600/2000] tot_loss=2.116 (perp=10.074, rec=0.098, cos=0.003), tot_loss_proj:2.396 [t=0.22s]
prediction: ['[CLS] viciouscouth and inchen incing absurd, unresible [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.981 (perp=9.348, rec=0.108, cos=0.003), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] viciousomp incing absurd, uncouth and incresible [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.393 (perp=6.478, rec=0.095, cos=0.003), tot_loss_proj:1.670 [t=0.22s]
prediction: ['[CLS] vicious incing absurd, uncouth and increhensible [SEP]']
[ 750/2000] tot_loss=1.350 (perp=6.294, rec=0.089, cos=0.003), tot_loss_proj:1.581 [t=0.22s]
prediction: ['[CLS] vicioussibleing absurd, uncouth and increhensible [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.383 (perp=6.478, rec=0.085, cos=0.003), tot_loss_proj:1.668 [t=0.23s]
prediction: ['[CLS] vicious incing absurd, uncouth and increhensible [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.342 (perp=6.263, rec=0.086, cos=0.003), tot_loss_proj:1.580 [t=0.23s]
prediction: ['[CLS] vicioussible absurd, uncouthing and increhensible [SEP]']
[ 900/2000] tot_loss=1.344 (perp=6.263, rec=0.089, cos=0.003), tot_loss_proj:1.566 [t=0.22s]
prediction: ['[CLS] vicioussible absurd, uncouthing and increhensible [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.338 (perp=6.263, rec=0.083, cos=0.003), tot_loss_proj:1.570 [t=0.22s]
prediction: ['[CLS] vicioussible absurd, uncouthing and increhensible [SEP]']
Attempt swap
[1000/2000] tot_loss=1.344 (perp=6.263, rec=0.088, cos=0.003), tot_loss_proj:1.567 [t=0.23s]
prediction: ['[CLS] vicioussible absurd, uncouthing and increhensible [SEP]']
[1050/2000] tot_loss=1.337 (perp=6.263, rec=0.081, cos=0.003), tot_loss_proj:1.569 [t=0.22s]
prediction: ['[CLS] vicioussible absurd, uncouthing and increhensible [SEP]']
Attempt swap
[1100/2000] tot_loss=1.348 (perp=6.263, rec=0.093, cos=0.003), tot_loss_proj:1.567 [t=0.23s]
prediction: ['[CLS] vicioussible absurd, uncouthing and increhensible [SEP]']
Attempt swap
[1150/2000] tot_loss=1.344 (perp=6.263, rec=0.089, cos=0.003), tot_loss_proj:1.570 [t=0.22s]
prediction: ['[CLS] vicioussible absurd, uncouthing and increhensible [SEP]']
[1200/2000] tot_loss=1.330 (perp=6.263, rec=0.074, cos=0.003), tot_loss_proj:1.569 [t=0.22s]
prediction: ['[CLS] vicioussible absurd, uncouthing and increhensible [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.339 (perp=6.266, rec=0.083, cos=0.003), tot_loss_proj:1.555 [t=0.22s]
prediction: ['[CLS] vicious absurdsible, uncouthing and increhensible [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.315 (perp=6.163, rec=0.079, cos=0.003), tot_loss_proj:1.543 [t=0.23s]
prediction: ['[CLS] absurd vicioussible, uncouthing and increhensible [SEP]']
[1350/2000] tot_loss=1.315 (perp=6.163, rec=0.080, cos=0.003), tot_loss_proj:1.555 [t=0.22s]
prediction: ['[CLS] absurd vicioussible, uncouthing and increhensible [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.228 (perp=5.701, rec=0.085, cos=0.003), tot_loss_proj:1.441 [t=0.22s]
prediction: ['[CLS] absurding vicioussible, uncouth and increhensible [SEP]']
Attempt swap
[1450/2000] tot_loss=1.225 (perp=5.701, rec=0.082, cos=0.003), tot_loss_proj:1.454 [t=0.22s]
prediction: ['[CLS] absurding vicioussible, uncouth and increhensible [SEP]']
[1500/2000] tot_loss=1.224 (perp=5.660, rec=0.089, cos=0.003), tot_loss_proj:1.444 [t=0.22s]
prediction: ['[CLS] absurding vicious ;, uncouth and increhensible [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.149 (perp=5.358, rec=0.075, cos=0.003), tot_loss_proj:1.320 [t=0.23s]
prediction: ['[CLS] absurding ; vicious, uncouth and increhensible [SEP]']
Attempt swap
[1600/2000] tot_loss=1.163 (perp=5.358, rec=0.088, cos=0.003), tot_loss_proj:1.330 [t=0.22s]
prediction: ['[CLS] absurding ; vicious, uncouth and increhensible [SEP]']
[1650/2000] tot_loss=1.164 (perp=5.358, rec=0.090, cos=0.003), tot_loss_proj:1.324 [t=0.23s]
prediction: ['[CLS] absurding ; vicious, uncouth and increhensible [SEP]']
Attempt swap
[1700/2000] tot_loss=1.150 (perp=5.358, rec=0.076, cos=0.003), tot_loss_proj:1.321 [t=0.22s]
prediction: ['[CLS] absurding ; vicious, uncouth and increhensible [SEP]']
Attempt swap
[1750/2000] tot_loss=1.146 (perp=5.358, rec=0.071, cos=0.003), tot_loss_proj:1.331 [t=0.23s]
prediction: ['[CLS] absurding ; vicious, uncouth and increhensible [SEP]']
[1800/2000] tot_loss=1.154 (perp=5.358, rec=0.080, cos=0.003), tot_loss_proj:1.329 [t=0.22s]
prediction: ['[CLS] absurding ; vicious, uncouth and increhensible [SEP]']
Attempt swap
[1850/2000] tot_loss=1.143 (perp=5.358, rec=0.069, cos=0.003), tot_loss_proj:1.328 [t=0.23s]
prediction: ['[CLS] absurding ; vicious, uncouth and increhensible [SEP]']
Attempt swap
[1900/2000] tot_loss=1.147 (perp=5.358, rec=0.072, cos=0.003), tot_loss_proj:1.323 [t=0.22s]
prediction: ['[CLS] absurding ; vicious, uncouth and increhensible [SEP]']
[1950/2000] tot_loss=1.155 (perp=5.358, rec=0.080, cos=0.003), tot_loss_proj:1.327 [t=0.23s]
prediction: ['[CLS] absurding ; vicious, uncouth and increhensible [SEP]']
Attempt swap
[2000/2000] tot_loss=1.153 (perp=5.358, rec=0.079, cos=0.003), tot_loss_proj:1.325 [t=0.22s]
prediction: ['[CLS] absurding ; vicious, uncouth and increhensible [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] absurding ; vicious, uncouth and increhensible [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 71.429

[Aggregate metrics]:
rouge1     | fm: 86.635 | p: 86.368 | r: 87.131
rouge2     | fm: 53.639 | p: 53.435 | r: 53.863
rougeL     | fm: 74.472 | p: 74.243 | r: 74.865
rougeLsum  | fm: 74.567 | p: 74.366 | r: 75.036
r1fm+r2fm = 140.273

input #68 time: 0:08:58 | total time: 10:34:11


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.998709063164686
highest_index [0]
highest [0.998709063164686]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.000913381576538 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 1.0003613233566284 for ['[CLS] kim andhra horn doesn n reflected himloaded approximately across stealth hear officetase ranks cross [SEP]']
[Init] best rec loss: 0.9865151643753052 for ['[CLS] advantageharat key bohemian conscious himself aires secondary six peabodynius influence news vanuredhs [SEP]']
[Init] best rec loss: 0.9748859405517578 for ['[CLS] silva minutes wight intermittentelt stevenson trained vice occupied coastrift study low sony their causing [SEP]']
[Init] best rec loss: 0.9678096771240234 for ['[CLS]ulouslyzation mouth abdso disaster hay down curling at forum fallon jupiter fortune whom henry [SEP]']
[Init] best rec loss: 0.9583864212036133 for ['[CLS] closelein am ( deadrga liz range bragg depended states passes stock past messll [SEP]']
[Init] best perm rec loss: 0.9569717049598694 for ['[CLS]leinrga dead am stockll depended close range bragg past mess liz states ( passes [SEP]']
[Init] best perm rec loss: 0.9557610750198364 for ['[CLS] bragg passes liz depended ( stockll range mess dead past states closeleinrga am [SEP]']
[Init] best perm rec loss: 0.9555635452270508 for ['[CLS] am dead pastll close range depended states messrga passes bragg (lein liz stock [SEP]']
[Init] best perm rec loss: 0.9540001749992371 for ['[CLS] states liz am ( close mess past passes deadrga dependedlein bragg rangell stock [SEP]']
[Init] best perm rec loss: 0.9537575840950012 for ['[CLS] past bragg am range (ll stockrga states close depended messlein passes liz dead [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.108 (perp=10.754, rec=0.642, cos=0.316), tot_loss_proj:4.137 [t=0.23s]
prediction: ['[CLS] lineage innings esq at - / brandnce ] couch named. writingsome. appearances [SEP]']
[ 100/2000] tot_loss=2.712 (perp=10.081, rec=0.573, cos=0.123), tot_loss_proj:3.450 [t=0.23s]
prediction: ['[CLS] ambrose sudden,. - - ranking sweet - funny named. writing rhodes. appearances [SEP]']
[ 150/2000] tot_loss=3.392 (perp=11.344, rec=0.686, cos=0.437), tot_loss_proj:3.816 [t=0.23s]
prediction: ['[CLS] rubin mafiague ; label of heavyweight season sounding slight laureate. sample rhodes - dumb [SEP]']
[ 200/2000] tot_loss=3.330 (perp=11.549, rec=0.637, cos=0.383), tot_loss_proj:4.057 [t=0.23s]
prediction: ['[CLS] flux pretty werewolf a category unit targetingty available uncomfortable james - the black -₁ [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.892 (perp=10.286, rec=0.552, cos=0.283), tot_loss_proj:3.629 [t=0.23s]
prediction: ['[CLS] flux sheriff pretty a category sharp care recognized funny james - the black - of breath [SEP]']
[ 300/2000] tot_loss=2.973 (perp=11.064, rec=0.542, cos=0.218), tot_loss_proj:3.412 [t=0.23s]
prediction: ['[CLS] flux tanned pretty a public sharp sexy easily competitive gentle - the and - of hello [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.041 (perp=10.165, rec=0.633, cos=0.375), tot_loss_proj:3.914 [t=0.23s]
prediction: ['[CLS] flux aged thin - recipient - signature po wrong - - the and gentle. kayla [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.459 (perp=8.707, rec=0.546, cos=0.171), tot_loss_proj:3.487 [t=0.23s]
prediction: ['[CLS] flux the thin - recipient - sexy easily negative -, average and gentle. kayla [SEP]']
[ 450/2000] tot_loss=3.318 (perp=9.072, rec=0.668, cos=0.836), tot_loss_proj:3.269 [t=0.23s]
prediction: ['[CLS] costa theimeter - recipient - smart easily negative -, hairy and lucky. kayla [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.282 (perp=9.490, rec=0.668, cos=0.716), tot_loss_proj:3.695 [t=0.23s]
prediction: ['[CLS]ulously ; cute ( - specified - facto negative -, average a deep. kayla [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.371 (perp=8.324, rec=0.532, cos=0.175), tot_loss_proj:3.521 [t=0.23s]
prediction: ['[CLS]ulously cute ; - specified - facto wrong ; -, average in subtle, kayla [SEP]']
[ 600/2000] tot_loss=2.204 (perp=8.082, rec=0.497, cos=0.091), tot_loss_proj:2.934 [t=0.23s]
prediction: ['[CLS]ulously cute ; - specified - facto uncomfortable ; -, attractive. subtle, kayla [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.261 (perp=8.266, rec=0.518, cos=0.090), tot_loss_proj:3.360 [t=0.23s]
prediction: ['[CLS]ulously smart, - specified - facto wrong ; -, smart, kayla tanned. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.280 (perp=8.373, rec=0.496, cos=0.109), tot_loss_proj:3.648 [t=0.23s]
prediction: ['[CLS]ulously smart ; - specified - facto. ; misleading, subtle, kayla increasingly. [SEP]']
[ 750/2000] tot_loss=2.300 (perp=8.825, rec=0.466, cos=0.069), tot_loss_proj:3.723 [t=0.23s]
prediction: ['[CLS]ulously smart ; - specified - facto - ; misleading, smart, kayla increasingly - [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.113 (perp=8.019, rec=0.455, cos=0.055), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS]ulously kayla ; - specified - facto - ; funny, smart, smart increasingly - [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.996 (perp=7.508, rec=0.451, cos=0.044), tot_loss_proj:2.436 [t=0.23s]
prediction: ['[CLS]ulously kayla - - specified - facto - ; funny, smart, smart increasingly, [SEP]']
[ 900/2000] tot_loss=2.311 (perp=8.310, rec=0.516, cos=0.133), tot_loss_proj:3.379 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - yeah - facto.. uncomfortable, smart. smart metres, [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.060 (perp=7.684, rec=0.463, cos=0.060), tot_loss_proj:2.345 [t=0.23s]
prediction: ['[CLS] importantly filmfare - - particular. facto.. funny, smart. smart cdp, [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.631 (perp=7.128, rec=0.552, cos=0.653), tot_loss_proj:2.206 [t=0.23s]
prediction: ['[CLS] importantly filmfare - - particular, facto.. funny, smart and smart cdp. [SEP]']
[1050/2000] tot_loss=2.099 (perp=7.924, rec=0.451, cos=0.064), tot_loss_proj:2.354 [t=0.23s]
prediction: ['[CLS] importantly filmfare - - layne - facto.. funny, smart, smart cdp. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.990 (perp=7.544, rec=0.440, cos=0.041), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] importantly filmfare - - - layne facto.. funny, smart and smart cdp. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.994 (perp=7.631, rec=0.430, cos=0.038), tot_loss_proj:2.285 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto., funny, smart and smart cdp. [SEP]']
[1200/2000] tot_loss=1.896 (perp=7.234, rec=0.427, cos=0.022), tot_loss_proj:2.064 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto., funny, smart and smart fine. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.900 (perp=7.234, rec=0.428, cos=0.025), tot_loss_proj:2.070 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto., funny, smart and smart fine. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.883 (perp=7.178, rec=0.426, cos=0.021), tot_loss_proj:2.101 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto., funny, smart, smart fine. [SEP]']
[1350/2000] tot_loss=1.864 (perp=7.178, rec=0.409, cos=0.019), tot_loss_proj:2.097 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto., funny, smart, smart fine. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.870 (perp=7.178, rec=0.417, cos=0.018), tot_loss_proj:2.096 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto., funny, smart, smart fine. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.959 (perp=7.206, rec=0.436, cos=0.081), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto. smart, funny, smart, fine. [SEP]']
[1500/2000] tot_loss=1.877 (perp=7.206, rec=0.415, cos=0.021), tot_loss_proj:2.138 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto. smart, funny, smart, fine. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.995 (perp=7.584, rec=0.428, cos=0.051), tot_loss_proj:2.150 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto and smart, funny, smart. fine. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.848 (perp=7.012, rec=0.418, cos=0.027), tot_loss_proj:1.968 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto, smart, funny, funny and fine. [SEP]']
[1650/2000] tot_loss=1.848 (perp=7.106, rec=0.411, cos=0.016), tot_loss_proj:2.052 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto, smart, funny, funny. fine. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.845 (perp=7.106, rec=0.408, cos=0.016), tot_loss_proj:2.049 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto, smart, funny, funny. fine. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.840 (perp=7.106, rec=0.405, cos=0.013), tot_loss_proj:2.049 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto, smart, funny, funny. fine. [SEP]']
[1800/2000] tot_loss=1.835 (perp=7.106, rec=0.402, cos=0.012), tot_loss_proj:2.054 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto, smart, funny, funny. fine. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.834 (perp=7.106, rec=0.402, cos=0.012), tot_loss_proj:2.050 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto, smart, funny, funny. fine. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.834 (perp=7.106, rec=0.402, cos=0.010), tot_loss_proj:2.050 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto, smart, funny, funny. fine. [SEP]']
[1950/2000] tot_loss=1.836 (perp=7.106, rec=0.405, cos=0.010), tot_loss_proj:2.049 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto, smart, funny, funny. fine. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.831 (perp=7.106, rec=0.399, cos=0.010), tot_loss_proj:2.056 [t=0.23s]
prediction: ['[CLS] importantly filmfare. - - layne facto, smart, funny, funny. fine. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] importantly filmfare. - - layne facto, smart, funny, funny. fine. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 40.000 | r: 40.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 40.000 | p: 40.000 | r: 40.000
rougeLsum  | fm: 40.000 | p: 40.000 | r: 40.000
r1fm+r2fm = 51.111

[Aggregate metrics]:
rouge1     | fm: 86.058 | p: 85.782 | r: 86.589
rouge2     | fm: 53.248 | p: 53.214 | r: 53.465
rougeL     | fm: 74.019 | p: 73.863 | r: 74.452
rougeLsum  | fm: 74.008 | p: 73.792 | r: 74.471
r1fm+r2fm = 139.306

input #69 time: 0:09:02 | total time: 10:43:14


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9987055015351145
highest_index [0]
highest [0.9987055015351145]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8341442942619324 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.7857835292816162 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7806898951530457 for ['[CLS] buenos sol aspects powerful otherpass wallace [SEP]']
[Init] best rec loss: 0.7788000106811523 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7666943073272705 for ['[CLS] oliveira jamie position crime belong leadersla [SEP]']
[Init] best rec loss: 0.7405156493186951 for ['[CLS] ga characteristic jump make deaths composed ⟩ [SEP]']
[Init] best rec loss: 0.7227428555488586 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 0.6968626379966736 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best rec loss: 0.6955555081367493 for ['[CLS] problems cupped potential dyed hear there hunters [SEP]']
[Init] best perm rec loss: 0.6934711337089539 for ['[CLS] hear potential dyed hunters there problems cupped [SEP]']
[Init] best perm rec loss: 0.6934341192245483 for ['[CLS] potential problems hunters dyed cupped hear there [SEP]']
[Init] best perm rec loss: 0.6918078660964966 for ['[CLS] cupped there hunters potential hear dyed problems [SEP]']
[Init] best perm rec loss: 0.6915205717086792 for ['[CLS] potential hunters problems there dyed cupped hear [SEP]']
[Init] best perm rec loss: 0.6914978623390198 for ['[CLS] problems there hear dyed cupped hunters potential [SEP]']
[Init] best perm rec loss: 0.6909542679786682 for ['[CLS] potential dyed cupped hunters hear problems there [SEP]']
[Init] best perm rec loss: 0.6900174021720886 for ['[CLS] there hear hunters cupped potential problems dyed [SEP]']
[Init] best perm rec loss: 0.6894105672836304 for ['[CLS] hunters hear there cupped potential dyed problems [SEP]']
[Init] best perm rec loss: 0.6889914274215698 for ['[CLS] cupped hunters potential problems hear there dyed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.704 (perp=11.821, rec=0.288, cos=0.051), tot_loss_proj:3.064 [t=0.23s]
prediction: ['[CLS] machine planet cl reactunky screen [SEP]']
[ 100/2000] tot_loss=2.347 (perp=10.706, rec=0.182, cos=0.023), tot_loss_proj:2.670 [t=0.23s]
prediction: ['[CLS] machine got cl screenunky gets [SEP]']
[ 150/2000] tot_loss=2.251 (perp=10.699, rec=0.105, cos=0.006), tot_loss_proj:2.698 [t=0.23s]
prediction: ['[CLS] machine screen cl screenunky gets [SEP]']
[ 200/2000] tot_loss=2.335 (perp=11.226, rec=0.087, cos=0.004), tot_loss_proj:2.880 [t=0.24s]
prediction: ['[CLS] machine screen cl onunky gets [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.737 (perp=8.200, rec=0.089, cos=0.008), tot_loss_proj:2.495 [t=0.23s]
prediction: ['[CLS] machine screen clunky gets on [SEP]']
[ 300/2000] tot_loss=1.500 (perp=7.116, rec=0.074, cos=0.003), tot_loss_proj:2.468 [t=0.24s]
prediction: ['[CLS] on screen clunky gets on [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.535 (perp=7.301, rec=0.072, cos=0.003), tot_loss_proj:2.050 [t=0.24s]
prediction: ['[CLS] against screen gets clunky on [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.666 (perp=7.826, rec=0.097, cos=0.004), tot_loss_proj:1.884 [t=0.24s]
prediction: ['[CLS] on screen screen gets clunky [SEP]']
[ 450/2000] tot_loss=1.639 (perp=7.826, rec=0.071, cos=0.003), tot_loss_proj:1.885 [t=0.24s]
prediction: ['[CLS] on screen screen gets clunky [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.328 (perp=6.258, rec=0.073, cos=0.003), tot_loss_proj:1.605 [t=0.24s]
prediction: ['[CLS] screen on screen gets clunky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.322 (perp=6.258, rec=0.068, cos=0.003), tot_loss_proj:1.609 [t=0.24s]
prediction: ['[CLS] screen on screen gets clunky [SEP]']
[ 600/2000] tot_loss=1.328 (perp=6.258, rec=0.073, cos=0.003), tot_loss_proj:1.611 [t=0.24s]
prediction: ['[CLS] screen on screen gets clunky [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.324 (perp=6.258, rec=0.069, cos=0.003), tot_loss_proj:1.607 [t=0.24s]
prediction: ['[CLS] screen on screen gets clunky [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.322 (perp=6.258, rec=0.067, cos=0.003), tot_loss_proj:1.605 [t=0.24s]
prediction: ['[CLS] screen on screen gets clunky [SEP]']
[ 750/2000] tot_loss=1.327 (perp=6.258, rec=0.072, cos=0.003), tot_loss_proj:1.606 [t=0.24s]
prediction: ['[CLS] screen on screen gets clunky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.328 (perp=6.258, rec=0.074, cos=0.003), tot_loss_proj:1.609 [t=0.24s]
prediction: ['[CLS] screen on screen gets clunky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.430 (perp=6.777, rec=0.072, cos=0.003), tot_loss_proj:1.841 [t=0.24s]
prediction: ['[CLS] block on screen gets clunky [SEP]']
[ 900/2000] tot_loss=1.432 (perp=6.777, rec=0.074, cos=0.003), tot_loss_proj:1.847 [t=0.23s]
prediction: ['[CLS] block on screen gets clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.422 (perp=6.777, rec=0.063, cos=0.003), tot_loss_proj:1.847 [t=0.24s]
prediction: ['[CLS] block on screen gets clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.410 (perp=6.717, rec=0.064, cos=0.003), tot_loss_proj:1.657 [t=0.24s]
prediction: ['[CLS] a on screen gets clunky [SEP]']
[1050/2000] tot_loss=1.425 (perp=6.717, rec=0.078, cos=0.003), tot_loss_proj:1.654 [t=0.24s]
prediction: ['[CLS] a on screen gets clunky [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.304 (perp=6.152, rec=0.070, cos=0.003), tot_loss_proj:1.525 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.296 (perp=6.152, rec=0.062, cos=0.003), tot_loss_proj:1.529 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
[1200/2000] tot_loss=1.300 (perp=6.152, rec=0.067, cos=0.003), tot_loss_proj:1.525 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.299 (perp=6.152, rec=0.065, cos=0.003), tot_loss_proj:1.519 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.300 (perp=6.152, rec=0.066, cos=0.003), tot_loss_proj:1.522 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
[1350/2000] tot_loss=1.303 (perp=6.152, rec=0.070, cos=0.003), tot_loss_proj:1.526 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.305 (perp=6.152, rec=0.072, cos=0.003), tot_loss_proj:1.529 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.306 (perp=6.152, rec=0.072, cos=0.003), tot_loss_proj:1.529 [t=0.23s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
[1500/2000] tot_loss=1.301 (perp=6.152, rec=0.068, cos=0.003), tot_loss_proj:1.524 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.301 (perp=6.152, rec=0.067, cos=0.003), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.302 (perp=6.152, rec=0.069, cos=0.003), tot_loss_proj:1.534 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
[1650/2000] tot_loss=1.303 (perp=6.152, rec=0.070, cos=0.003), tot_loss_proj:1.530 [t=0.23s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.305 (perp=6.152, rec=0.071, cos=0.003), tot_loss_proj:1.531 [t=0.23s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.304 (perp=6.152, rec=0.071, cos=0.003), tot_loss_proj:1.534 [t=0.23s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
[1800/2000] tot_loss=1.293 (perp=6.152, rec=0.060, cos=0.003), tot_loss_proj:1.520 [t=0.23s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.308 (perp=6.152, rec=0.074, cos=0.003), tot_loss_proj:1.531 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.303 (perp=6.152, rec=0.070, cos=0.003), tot_loss_proj:1.532 [t=0.23s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
[1950/2000] tot_loss=1.303 (perp=6.152, rec=0.070, cos=0.003), tot_loss_proj:1.529 [t=0.24s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.298 (perp=6.152, rec=0.065, cos=0.003), tot_loss_proj:1.526 [t=0.23s]
prediction: ['[CLS] on a screen gets clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] screen on screen gets clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 102.381

[Aggregate metrics]:
rouge1     | fm: 85.989 | p: 85.683 | r: 86.516
rouge2     | fm: 52.479 | p: 52.304 | r: 52.784
rougeL     | fm: 73.838 | p: 73.591 | r: 74.248
rougeLsum  | fm: 73.740 | p: 73.554 | r: 74.266
r1fm+r2fm = 138.468

input #70 time: 0:09:15 | total time: 10:52:30


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.9988177511996511
highest_index [0]
highest [0.9988177511996511]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.922815203666687 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.9045770764350891 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8931691646575928 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 0.8882771730422974 for ['[CLS]od production romatose smith bloody joker chapter trains via returning question tempoq cholera [SEP]']
[Init] best rec loss: 0.882678210735321 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 0.8756580352783203 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 0.8746469616889954 for ['[CLS] clips theory social chains landing ignorance mother game experience point ser [MASK] less whatever other [SEP]']
[Init] best rec loss: 0.8707275986671448 for ['[CLS] faculty / baker these i n youifice broken panic pins roll t outlet institute [SEP]']
[Init] best rec loss: 0.8496988415718079 for ['[CLS]ine runways oregon bored : towardsgold occurred snow abovegerstypical definitely holiday rooney [SEP]']
[Init] best rec loss: 0.8492064476013184 for ['[CLS]lon dictionary short prairie mayatypic conditioning flyingto etc men provided star cassidy gems [SEP]']
[Init] best perm rec loss: 0.8476932048797607 for ['[CLS] dictionary gems star provided conditioning short men etcto flying prairie cassidytypic mayalon [SEP]']
[Init] best perm rec loss: 0.8473465442657471 for ['[CLS] men etc shortlon provided cassidy flying dictionary prairie gemstypic starto conditioning maya [SEP]']
[Init] best perm rec loss: 0.84616619348526 for ['[CLS] menlonto etc cassidy conditioning short gems dictionary provided mayatypic prairie star flying [SEP]']
[Init] best perm rec loss: 0.8460773229598999 for ['[CLS] men short dictionary prairie startypic mayato flying etc conditioning gems cassidy providedlon [SEP]']
[Init] best perm rec loss: 0.8453404307365417 for ['[CLS] prairie dictionary gemstypic shortlon mayato provided men conditioning star flying etc cassidy [SEP]']
[Init] best perm rec loss: 0.8451394438743591 for ['[CLS] maya short conditioningtypic flying gems provided etc men startolon cassidy prairie dictionary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.360 (perp=10.324, rec=0.271, cos=0.024), tot_loss_proj:3.275 [t=0.24s]
prediction: ['[CLS] your - moment single singley not s empty not immediately single an seat moment [SEP]']
[ 100/2000] tot_loss=1.769 (perp=7.975, rec=0.163, cos=0.012), tot_loss_proj:2.634 [t=0.24s]
prediction: ['[CLS] your - moment single single - not - - not jump - - seat moment [SEP]']
[ 150/2000] tot_loss=1.829 (perp=8.626, rec=0.101, cos=0.003), tot_loss_proj:2.678 [t=0.24s]
prediction: ['[CLS] your there - single single - not s - not jump in and seat moment [SEP]']
[ 200/2000] tot_loss=1.738 (perp=8.289, rec=0.078, cos=0.002), tot_loss_proj:2.686 [t=0.24s]
prediction: ['[CLS] your there - a single - not s - not jump in and seat moment [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.627 (perp=7.777, rec=0.069, cos=0.002), tot_loss_proj:2.614 [t=0.24s]
prediction: ['[CLS] your there - a single - s not - not jump in and seat moment [SEP]']
[ 300/2000] tot_loss=1.606 (perp=7.671, rec=0.070, cos=0.003), tot_loss_proj:3.233 [t=0.24s]
prediction: ['[CLS] your there - a single - s not - a jump in and seat moment [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.538 (perp=7.362, rec=0.063, cos=0.002), tot_loss_proj:2.438 [t=0.24s]
prediction: ['[CLS] your there not a single - s - - a jump in and seat moment [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.525 (perp=7.256, rec=0.071, cos=0.003), tot_loss_proj:2.774 [t=0.24s]
prediction: ['[CLS] your there - not a single s - - the jump in and seat moment [SEP]']
[ 450/2000] tot_loss=1.517 (perp=7.256, rec=0.064, cos=0.002), tot_loss_proj:2.772 [t=0.24s]
prediction: ['[CLS] your there - not a single s - - the jump in and seat moment [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.292 (perp=6.108, rec=0.068, cos=0.002), tot_loss_proj:2.382 [t=0.24s]
prediction: ['[CLS] and there - not a single s - - the jump in your seat moment [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.219 (perp=5.664, rec=0.083, cos=0.003), tot_loss_proj:1.998 [t=0.24s]
prediction: ['[CLS] and there - not a single s the jump in your seat - - moment [SEP]']
[ 600/2000] tot_loss=1.207 (perp=5.664, rec=0.072, cos=0.002), tot_loss_proj:1.985 [t=0.24s]
prediction: ['[CLS] and there - not a single s the jump in your seat - - moment [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.208 (perp=5.664, rec=0.073, cos=0.002), tot_loss_proj:1.990 [t=0.24s]
prediction: ['[CLS] and there - not a single s the jump in your seat - - moment [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.207 (perp=5.664, rec=0.072, cos=0.002), tot_loss_proj:1.981 [t=0.24s]
prediction: ['[CLS] and there - not a single s the jump in your seat - - moment [SEP]']
[ 750/2000] tot_loss=1.186 (perp=5.614, rec=0.061, cos=0.002), tot_loss_proj:2.128 [t=0.24s]
prediction: ["[CLS] and there - not a single s'jump in your seat - - moment [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.127 (perp=5.294, rec=0.066, cos=0.002), tot_loss_proj:2.642 [t=0.24s]
prediction: ["[CLS] and there - not a single's jump in your seat - - moment [SEP]"]
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.026 (perp=4.734, rec=0.076, cos=0.003), tot_loss_proj:2.193 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
[ 900/2000] tot_loss=1.021 (perp=4.734, rec=0.072, cos=0.002), tot_loss_proj:2.190 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.023 (perp=4.734, rec=0.074, cos=0.002), tot_loss_proj:2.179 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.004 (perp=4.734, rec=0.055, cos=0.002), tot_loss_proj:2.183 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
[1050/2000] tot_loss=1.017 (perp=4.734, rec=0.068, cos=0.002), tot_loss_proj:2.176 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.018 (perp=4.734, rec=0.069, cos=0.002), tot_loss_proj:2.180 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.018 (perp=4.734, rec=0.069, cos=0.002), tot_loss_proj:2.183 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
[1200/2000] tot_loss=1.013 (perp=4.734, rec=0.064, cos=0.002), tot_loss_proj:2.183 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.011 (perp=4.734, rec=0.062, cos=0.002), tot_loss_proj:2.176 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.017 (perp=4.734, rec=0.068, cos=0.002), tot_loss_proj:2.178 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
[1350/2000] tot_loss=1.008 (perp=4.734, rec=0.059, cos=0.002), tot_loss_proj:2.178 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.011 (perp=4.734, rec=0.062, cos=0.002), tot_loss_proj:2.179 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.014 (perp=4.734, rec=0.065, cos=0.002), tot_loss_proj:2.187 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
[1500/2000] tot_loss=1.013 (perp=4.734, rec=0.064, cos=0.002), tot_loss_proj:2.194 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.014 (perp=4.734, rec=0.065, cos=0.002), tot_loss_proj:2.176 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.011 (perp=4.734, rec=0.062, cos=0.002), tot_loss_proj:2.175 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
[1650/2000] tot_loss=1.015 (perp=4.734, rec=0.066, cos=0.002), tot_loss_proj:2.173 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.008 (perp=4.734, rec=0.059, cos=0.002), tot_loss_proj:2.191 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.014 (perp=4.734, rec=0.065, cos=0.002), tot_loss_proj:2.173 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
[1800/2000] tot_loss=1.010 (perp=4.734, rec=0.061, cos=0.002), tot_loss_proj:2.169 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.015 (perp=4.734, rec=0.066, cos=0.002), tot_loss_proj:2.178 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.018 (perp=4.734, rec=0.069, cos=0.002), tot_loss_proj:2.173 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
[1950/2000] tot_loss=1.024 (perp=4.734, rec=0.074, cos=0.002), tot_loss_proj:2.174 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.013 (perp=4.734, rec=0.064, cos=0.002), tot_loss_proj:2.173 [t=0.24s]
prediction: ["[CLS] and there - not a single moment's jump in your seat - - [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] and there - not a single moment's jump in your seat - - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 41.667 | p: 41.667 | r: 41.667
rougeL     | fm: 76.923 | p: 76.923 | r: 76.923
rougeLsum  | fm: 76.923 | p: 76.923 | r: 76.923
r1fm+r2fm = 141.667

[Aggregate metrics]:
rouge1     | fm: 86.217 | p: 85.946 | r: 86.752
rouge2     | fm: 52.348 | p: 52.244 | r: 52.651
rougeL     | fm: 73.774 | p: 73.609 | r: 74.220
rougeLsum  | fm: 73.810 | p: 73.613 | r: 74.299
r1fm+r2fm = 138.565

input #71 time: 0:09:22 | total time: 11:01:52


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9985458087041755
highest_index [0]
highest [0.9985458087041755]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.8017071485519409 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7735590934753418 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 0.7452703714370728 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7442600727081299 for ['[CLS]nted seriously public caesar failure major eli city edo memberf runway koppen join useless [SEP]']
[Init] best rec loss: 0.7409540414810181 for ['[CLS] annabelle child bucketeesya thrown typical moses alive knowing regions users keys lilly liz [SEP]']
[Init] best rec loss: 0.7341107130050659 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 0.7288260459899902 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.7169990539550781 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best rec loss: 0.7111775875091553 for ['[CLS] them relations quickly sip abexed without connected counties glacier digitalhic professor teller page [SEP]']
[Init] best perm rec loss: 0.70651775598526 for ['[CLS] connectedxed page glacier digital professor counties siphic without them teller abe quickly relations [SEP]']
[Init] best perm rec loss: 0.7062179446220398 for ['[CLS] connected them teller without glacier counties relations abexed sip professor digital page quicklyhic [SEP]']
[Init] best perm rec loss: 0.7059453129768372 for ['[CLS] relations abe counties page professor sipxed them quicklyhic digital glacier connected without teller [SEP]']
[Init] best perm rec loss: 0.7048032283782959 for ['[CLS] without connected counties relations digital abehicxed quickly teller glacier sip professor page them [SEP]']
[Init] best perm rec loss: 0.7044340372085571 for ['[CLS] page digital without abe connected sip professor relations them tellerxed counties quicklyhic glacier [SEP]']
[Init] best perm rec loss: 0.7032748460769653 for ['[CLS] counties sip without relations professor page glacier connectedhic themxed abe teller quickly digital [SEP]']
[Init] best perm rec loss: 0.7025406360626221 for ['[CLS] relationshic connected sip page without themxed abe quickly professor glacier teller digital counties [SEP]']
[Init] best perm rec loss: 0.7024258375167847 for ['[CLS] connectedhic glacier professor them page without relations countiesxed quickly sip abe teller digital [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.345 (perp=10.137, rec=0.288, cos=0.029), tot_loss_proj:3.428 [t=0.23s]
prediction: ['[CLS] has tough tough time violence involving - its battery to during threats blast stronger fingernails [SEP]']
[ 100/2000] tot_loss=2.424 (perp=11.326, rec=0.149, cos=0.010), tot_loss_proj:3.316 [t=0.24s]
prediction: ['[CLS] has tough tough time violence with party its battery balancing based radiation violenceer philosophy [SEP]']
[ 150/2000] tot_loss=2.094 (perp=9.978, rec=0.093, cos=0.005), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] has tough tough time violence with philosophy its violence balancing based philosophical druger philosophy [SEP]']
[ 200/2000] tot_loss=2.197 (perp=10.515, rec=0.090, cos=0.004), tot_loss_proj:3.705 [t=0.24s]
prediction: ['[CLS] has tough tough time violence with inspired its violence balancing inspiredfk druger philosophy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.039 (perp=9.715, rec=0.090, cos=0.006), tot_loss_proj:3.577 [t=0.24s]
prediction: ['[CLS] has tough tough time violence with its violence balancing inspiredfk inspired -er philosophy [SEP]']
[ 300/2000] tot_loss=2.022 (perp=9.715, rec=0.076, cos=0.003), tot_loss_proj:3.583 [t=0.24s]
prediction: ['[CLS] has tough tough time violence with its violence balancing inspiredfk inspired -er philosophy [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.916 (perp=9.268, rec=0.059, cos=0.003), tot_loss_proj:3.324 [t=0.24s]
prediction: ['[CLS] has tough tough time violence with its violence balancingfka - inspireder philosophy [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.908 (perp=9.151, rec=0.074, cos=0.004), tot_loss_proj:2.345 [t=0.24s]
prediction: ['[CLS] has tough tough time balancing with its violence violencefka - inspireder philosophy [SEP]']
[ 450/2000] tot_loss=1.902 (perp=9.151, rec=0.069, cos=0.003), tot_loss_proj:2.341 [t=0.24s]
prediction: ['[CLS] has tough tough time balancing with its violence violencefka - inspireder philosophy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.908 (perp=9.158, rec=0.073, cos=0.003), tot_loss_proj:2.362 [t=0.24s]
prediction: ['[CLS] has tough tough time balancing with its forcefka - inspireder violence philosophy [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.860 (perp=8.910, rec=0.074, cos=0.004), tot_loss_proj:2.264 [t=0.24s]
prediction: ['[CLS] has tough tough time balancing with its outfka philosophy - inspireder violence [SEP]']
[ 600/2000] tot_loss=1.856 (perp=8.910, rec=0.071, cos=0.003), tot_loss_proj:2.263 [t=0.24s]
prediction: ['[CLS] has tough tough time balancing with its outfka philosophy - inspireder violence [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.780 (perp=8.496, rec=0.077, cos=0.003), tot_loss_proj:2.491 [t=0.24s]
prediction: ['[CLS] has tough tough time balancing warfare with itsfka philosophy - inspireder violence [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.773 (perp=8.416, rec=0.087, cos=0.003), tot_loss_proj:2.478 [t=0.24s]
prediction: ['[CLS] has tough tough time balancing warfare with itsfka philosophy - inspired violenceer [SEP]']
[ 750/2000] tot_loss=1.757 (perp=8.416, rec=0.071, cos=0.003), tot_loss_proj:2.482 [t=0.24s]
prediction: ['[CLS] has tough tough time balancing warfare with itsfka philosophy - inspired violenceer [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.759 (perp=8.416, rec=0.073, cos=0.003), tot_loss_proj:2.491 [t=0.24s]
prediction: ['[CLS] has tough tough time balancing warfare with itsfka philosophy - inspired violenceer [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.752 (perp=8.352, rec=0.079, cos=0.003), tot_loss_proj:2.245 [t=0.24s]
prediction: ['[CLS] tough has tough time balancing warfare with itsfka philosophy - inspired violenceer [SEP]']
[ 900/2000] tot_loss=1.752 (perp=8.352, rec=0.079, cos=0.003), tot_loss_proj:2.256 [t=0.24s]
prediction: ['[CLS] tough has tough time balancing warfare with itsfka philosophy - inspired violenceer [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.714 (perp=8.224, rec=0.066, cos=0.003), tot_loss_proj:2.149 [t=0.24s]
prediction: ['[CLS] tough has tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1000/2000] tot_loss=1.706 (perp=8.224, rec=0.058, cos=0.003), tot_loss_proj:2.160 [t=0.24s]
prediction: ['[CLS] tough has tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
[1050/2000] tot_loss=1.713 (perp=8.224, rec=0.065, cos=0.003), tot_loss_proj:2.157 [t=0.24s]
prediction: ['[CLS] tough has tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1100/2000] tot_loss=1.609 (perp=7.699, rec=0.067, cos=0.003), tot_loss_proj:2.105 [t=0.24s]
prediction: ['[CLS] a has tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.498 (perp=7.144, rec=0.066, cos=0.003), tot_loss_proj:1.918 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
[1200/2000] tot_loss=1.511 (perp=7.144, rec=0.079, cos=0.003), tot_loss_proj:1.919 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1250/2000] tot_loss=1.498 (perp=7.144, rec=0.066, cos=0.003), tot_loss_proj:1.925 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1300/2000] tot_loss=1.502 (perp=7.144, rec=0.071, cos=0.003), tot_loss_proj:1.920 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
[1350/2000] tot_loss=1.488 (perp=7.144, rec=0.056, cos=0.003), tot_loss_proj:1.923 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1400/2000] tot_loss=1.490 (perp=7.144, rec=0.058, cos=0.003), tot_loss_proj:1.922 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1450/2000] tot_loss=1.493 (perp=7.144, rec=0.062, cos=0.003), tot_loss_proj:1.922 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
[1500/2000] tot_loss=1.499 (perp=7.144, rec=0.067, cos=0.003), tot_loss_proj:1.921 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1550/2000] tot_loss=1.493 (perp=7.144, rec=0.062, cos=0.003), tot_loss_proj:1.922 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1600/2000] tot_loss=1.490 (perp=7.144, rec=0.058, cos=0.003), tot_loss_proj:1.923 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
[1650/2000] tot_loss=1.497 (perp=7.144, rec=0.065, cos=0.003), tot_loss_proj:1.922 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1700/2000] tot_loss=1.486 (perp=7.144, rec=0.054, cos=0.003), tot_loss_proj:1.923 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1750/2000] tot_loss=1.509 (perp=7.144, rec=0.078, cos=0.003), tot_loss_proj:1.920 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
[1800/2000] tot_loss=1.483 (perp=7.144, rec=0.051, cos=0.003), tot_loss_proj:1.927 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1850/2000] tot_loss=1.498 (perp=7.144, rec=0.066, cos=0.003), tot_loss_proj:1.923 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[1900/2000] tot_loss=1.491 (perp=7.144, rec=0.059, cos=0.003), tot_loss_proj:1.925 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
[1950/2000] tot_loss=1.505 (perp=7.144, rec=0.073, cos=0.003), tot_loss_proj:1.925 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Attempt swap
[2000/2000] tot_loss=1.484 (perp=7.144, rec=0.052, cos=0.003), tot_loss_proj:1.923 [t=0.24s]
prediction: ['[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] has a tough time balancing its warfare withfka philosophy - inspired violenceer [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.231 | p: 69.231 | r: 69.231
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 61.538 | p: 61.538 | r: 61.538
rougeLsum  | fm: 61.538 | p: 61.538 | r: 61.538
r1fm+r2fm = 102.564

[Aggregate metrics]:
rouge1     | fm: 86.024 | p: 85.706 | r: 86.584
rouge2     | fm: 52.127 | p: 52.024 | r: 52.389
rougeL     | fm: 73.679 | p: 73.424 | r: 74.039
rougeLsum  | fm: 73.659 | p: 73.462 | r: 74.096
r1fm+r2fm = 138.152

input #72 time: 0:09:22 | total time: 11:11:14


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9986505153153077
highest_index [0]
highest [0.9986505153153077]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9879938960075378 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9762401580810547 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9406700134277344 for ['[CLS] garage knight [SEP]']
[Init] best rec loss: 0.9159116148948669 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9016239643096924 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.8891702890396118 for ['[CLS] denied airline [SEP]']
[Init] best rec loss: 0.8748607635498047 for ['[CLS] puget traditional [SEP]']
[Init] best rec loss: 0.8623113036155701 for ['[CLS] split china [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.048 (perp=9.723, rec=0.100, cos=0.004), tot_loss_proj:2.035 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.003), tot_loss_proj:2.023 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.016 (perp=9.723, rec=0.069, cos=0.003), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.003), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.003), tot_loss_proj:2.017 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.012 (perp=9.723, rec=0.065, cos=0.003), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.011 (perp=9.723, rec=0.064, cos=0.003), tot_loss_proj:2.017 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.021 (perp=9.723, rec=0.074, cos=0.003), tot_loss_proj:2.005 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.007 (perp=9.723, rec=0.060, cos=0.003), tot_loss_proj:2.022 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.003), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.003), tot_loss_proj:2.024 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.010 (perp=9.723, rec=0.062, cos=0.003), tot_loss_proj:2.017 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.008 (perp=9.723, rec=0.060, cos=0.003), tot_loss_proj:2.026 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.013 (perp=9.723, rec=0.066, cos=0.003), tot_loss_proj:2.012 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.007 (perp=9.723, rec=0.060, cos=0.003), tot_loss_proj:1.999 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.011 (perp=9.723, rec=0.064, cos=0.003), tot_loss_proj:2.024 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.007 (perp=9.723, rec=0.059, cos=0.003), tot_loss_proj:2.012 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.003), tot_loss_proj:2.007 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.003), tot_loss_proj:2.026 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.008 (perp=9.723, rec=0.061, cos=0.003), tot_loss_proj:2.018 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.019 (perp=9.723, rec=0.072, cos=0.003), tot_loss_proj:2.021 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.008 (perp=9.723, rec=0.061, cos=0.003), tot_loss_proj:2.015 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.002 (perp=9.723, rec=0.054, cos=0.003), tot_loss_proj:2.023 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.007 (perp=9.723, rec=0.060, cos=0.003), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.014 (perp=9.723, rec=0.067, cos=0.003), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.011 (perp=9.723, rec=0.063, cos=0.003), tot_loss_proj:2.015 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=1.997 (perp=9.723, rec=0.050, cos=0.003), tot_loss_proj:2.017 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.011 (perp=9.723, rec=0.064, cos=0.003), tot_loss_proj:2.012 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.031 (perp=9.723, rec=0.084, cos=0.003), tot_loss_proj:2.020 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.000 (perp=9.723, rec=0.052, cos=0.003), tot_loss_proj:2.024 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.014 (perp=9.723, rec=0.066, cos=0.003), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.005 (perp=9.723, rec=0.058, cos=0.003), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.003), tot_loss_proj:2.002 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.012 (perp=9.723, rec=0.064, cos=0.003), tot_loss_proj:2.022 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.020 (perp=9.723, rec=0.073, cos=0.003), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.003), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.018 (perp=9.723, rec=0.071, cos=0.003), tot_loss_proj:2.013 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=1.997 (perp=9.723, rec=0.050, cos=0.003), tot_loss_proj:2.006 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.012 (perp=9.723, rec=0.064, cos=0.003), tot_loss_proj:2.020 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.025 (perp=9.723, rec=0.078, cos=0.003), tot_loss_proj:2.016 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.128 | p: 85.877 | r: 86.637
rouge2     | fm: 52.791 | p: 52.594 | r: 53.114
rougeL     | fm: 74.029 | p: 73.825 | r: 74.446
rougeLsum  | fm: 73.993 | p: 73.879 | r: 74.392
r1fm+r2fm = 138.919

input #73 time: 0:09:17 | total time: 11:20:32


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9988935659855984
highest_index [0]
highest [0.9988935659855984]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 0.880859375 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.7052992582321167 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.7038629651069641 for ['[CLS] answering [SEP]']
[Init] best rec loss: 0.6989229321479797 for ['[CLS] ahead [SEP]']
[Init] best rec loss: 0.6932417154312134 for ['[CLS] sky [SEP]']
[Init] best rec loss: 0.6742309927940369 for ['[CLS] coup [SEP]']
[Init] best rec loss: 0.6736689805984497 for ['[CLS] birth [SEP]']
[Init] best rec loss: 0.6724899411201477 for ['[CLS] offense [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.915 (perp=8.178, rec=0.246, cos=0.033), tot_loss_proj:1.810 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.842 (perp=8.178, rec=0.176, cos=0.030), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.839 (perp=8.178, rec=0.174, cos=0.029), tot_loss_proj:1.719 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.838 (perp=8.178, rec=0.171, cos=0.031), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.846 (perp=8.178, rec=0.177, cos=0.034), tot_loss_proj:1.746 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.845 (perp=8.178, rec=0.169, cos=0.040), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.837 (perp=8.178, rec=0.170, cos=0.031), tot_loss_proj:1.735 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.854 (perp=8.178, rec=0.186, cos=0.033), tot_loss_proj:1.728 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.843 (perp=8.178, rec=0.176, cos=0.031), tot_loss_proj:1.731 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.837 (perp=8.178, rec=0.168, cos=0.033), tot_loss_proj:1.731 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.851 (perp=8.178, rec=0.183, cos=0.032), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.842 (perp=8.178, rec=0.174, cos=0.032), tot_loss_proj:1.731 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.845 (perp=8.178, rec=0.174, cos=0.036), tot_loss_proj:1.726 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.848 (perp=8.178, rec=0.181, cos=0.031), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.853 (perp=8.178, rec=0.186, cos=0.032), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.846 (perp=8.178, rec=0.178, cos=0.032), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.841 (perp=8.178, rec=0.174, cos=0.032), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.842 (perp=8.178, rec=0.174, cos=0.032), tot_loss_proj:1.724 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.839 (perp=8.178, rec=0.172, cos=0.032), tot_loss_proj:1.727 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.835 (perp=8.178, rec=0.168, cos=0.032), tot_loss_proj:1.731 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.852 (perp=8.178, rec=0.185, cos=0.032), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.830 (perp=8.178, rec=0.163, cos=0.032), tot_loss_proj:1.723 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.833 (perp=8.178, rec=0.165, cos=0.032), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.851 (perp=8.178, rec=0.184, cos=0.032), tot_loss_proj:1.727 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.837 (perp=8.178, rec=0.170, cos=0.032), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.842 (perp=8.178, rec=0.175, cos=0.032), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.838 (perp=8.178, rec=0.170, cos=0.032), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.838 (perp=8.178, rec=0.171, cos=0.032), tot_loss_proj:1.731 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.847 (perp=8.178, rec=0.180, cos=0.032), tot_loss_proj:1.726 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.851 (perp=8.178, rec=0.184, cos=0.032), tot_loss_proj:1.718 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.836 (perp=8.178, rec=0.169, cos=0.032), tot_loss_proj:1.746 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.846 (perp=8.178, rec=0.179, cos=0.032), tot_loss_proj:1.726 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.842 (perp=8.178, rec=0.174, cos=0.032), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.837 (perp=8.178, rec=0.169, cos=0.032), tot_loss_proj:1.721 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.838 (perp=8.178, rec=0.171, cos=0.032), tot_loss_proj:1.739 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.844 (perp=8.178, rec=0.177, cos=0.032), tot_loss_proj:1.731 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.834 (perp=8.178, rec=0.167, cos=0.032), tot_loss_proj:1.719 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.844 (perp=8.178, rec=0.176, cos=0.032), tot_loss_proj:1.727 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.844 (perp=8.178, rec=0.176, cos=0.032), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.847 (perp=8.178, rec=0.179, cos=0.032), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.404 | p: 86.065 | r: 86.894
rouge2     | fm: 53.395 | p: 53.301 | r: 53.639
rougeL     | fm: 74.383 | p: 74.191 | r: 74.732
rougeLsum  | fm: 74.365 | p: 74.100 | r: 74.777
r1fm+r2fm = 139.799

input #74 time: 0:09:11 | total time: 11:29:43


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9988630194932031
highest_index [0]
highest [0.9988630194932031]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.8620458245277405 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.8420581817626953 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.8272808790206909 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best rec loss: 0.8227735757827759 for ['[CLS] chaintrybro savings path part accolades truck visa chenses stateach foundation speak theme rather utter english [SEP]']
[Init] best perm rec loss: 0.8220593333244324 for ['[CLS] chen state rather pathbro englishtrysesach accolades truck chain utter speak part savings visa theme foundation [SEP]']
[Init] best perm rec loss: 0.8197231292724609 for ['[CLS]ses truck path stateach rather chen utter accoladestry savings foundation english part speak theme visa chainbro [SEP]']
[Init] best perm rec loss: 0.8189340829849243 for ['[CLS] english chen foundation parttry accolades utterach savings chain rather path visasesbro truck state speak theme [SEP]']
[Init] best perm rec loss: 0.8175358176231384 for ['[CLS] chain rather path english savings truck theme partbro accolades visa stateachses chentry foundation utter speak [SEP]']
[Init] best perm rec loss: 0.8170965313911438 for ['[CLS] theme chen english pathses savings speak state foundation ratherbroach truck utter accolades chaintry part visa [SEP]']
[Init] best perm rec loss: 0.816797137260437 for ['[CLS] foundation chain part truckach theme accolades chen visa englishtry rather utterbroses path state speak savings [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.767 (perp=11.639, rec=0.398, cos=0.041), tot_loss_proj:3.968 [t=0.24s]
prediction: ['[CLS] resources the luckyze easy rarely collective issues rarely without not as hardly median must decisions mountain homer. [SEP]']
[ 100/2000] tot_loss=2.363 (perp=10.680, rec=0.211, cos=0.017), tot_loss_proj:3.812 [t=0.24s]
prediction: ['[CLS] behavior forgotten not nascar easily orized instability dismissed not easily dismissed forgotten or easily seemedlary not. [SEP]']
[ 150/2000] tot_loss=2.316 (perp=10.738, rec=0.158, cos=0.010), tot_loss_proj:3.875 [t=0.24s]
prediction: ['[CLS]ility cited notstorm easily or into instability instability not easily dismissed forgotten or easilypods instability not. [SEP]']
[ 200/2000] tot_loss=2.181 (perp=10.144, rec=0.134, cos=0.018), tot_loss_proj:3.441 [t=0.24s]
prediction: ['[CLS] excursion mental withoutstorm easily or into instability instability not easily forgotten dismissed not easilyurrent instability not. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.165 (perp=9.952, rec=0.157, cos=0.018), tot_loss_proj:3.447 [t=0.24s]
prediction: ['[CLS] excursion mental the [SEP] excursioncola into instability instability not easily forgotten dismissed not easilygration or not. [SEP]']
[ 300/2000] tot_loss=2.116 (perp=9.803, rec=0.138, cos=0.017), tot_loss_proj:3.582 [t=0.24s]
prediction: ['[CLS] this mental the into excursioncola into instability instability not easily forgotten dismissed is easilygration or not. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.826 (perp=8.485, rec=0.117, cos=0.012), tot_loss_proj:3.383 [t=0.24s]
prediction: ['[CLS] this mental instability into excursioncola into the instability not easily forgotten dismissed is easilygration or being. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.931 (perp=8.761, rec=0.163, cos=0.016), tot_loss_proj:3.476 [t=0.24s]
prediction: ['[CLS] this mental instability into excursioncola into the instability not easily dismissed not₀ excursion or is forgotten. [SEP]']
[ 450/2000] tot_loss=1.964 (perp=9.256, rec=0.105, cos=0.008), tot_loss_proj:3.562 [t=0.24s]
prediction: ['[CLS] this mental instability into excursioncola into past epic not easily dismissed not easilyergy or is forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.913 (perp=8.914, rec=0.116, cos=0.014), tot_loss_proj:3.149 [t=0.24s]
prediction: ['[CLS] this mental instability into excursioncola intogible epic not easily dismissed is downergy or not forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.808 (perp=8.536, rec=0.093, cos=0.008), tot_loss_proj:3.023 [t=0.24s]
prediction: ['[CLS] this mental instability into excursioncolagible into epic not easily dismissed is downergy or not forgotten. [SEP]']
[ 600/2000] tot_loss=2.059 (perp=9.791, rec=0.096, cos=0.005), tot_loss_proj:3.315 [t=0.24s]
prediction: ['[CLS] this mental instability into excursioncolaoz per epic not easily dismissed is downergy or not forgotten. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.955 (perp=9.317, rec=0.083, cos=0.009), tot_loss_proj:3.129 [t=0.24s]
prediction: ['[CLS] this mental instability into excursionentercolagible epic not easily dismissed is downenter or not forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.731 (perp=8.236, rec=0.077, cos=0.006), tot_loss_proj:3.063 [t=0.24s]
prediction: ['[CLS] this mental instability into epicentercolagible excursion not easily dismissed is downenter or not forgotten. [SEP]']
[ 750/2000] tot_loss=1.753 (perp=8.265, rec=0.092, cos=0.008), tot_loss_proj:2.815 [t=0.24s]
prediction: ['[CLS] this mental instability into epic percolagible excursion not easily dismissed is downenter or not forgotten. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.868 (perp=8.878, rec=0.086, cos=0.006), tot_loss_proj:2.744 [t=0.24s]
prediction: ['[CLS] this mental instability into epic percolaible excursion not easily dismissed is.enter or not forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.706 (perp=8.040, rec=0.091, cos=0.007), tot_loss_proj:2.488 [t=0.24s]
prediction: ['[CLS] this mental instability into. percolaible excursion not easily dismissed is epicenter or not forgotten. [SEP]']
[ 900/2000] tot_loss=1.715 (perp=8.040, rec=0.101, cos=0.006), tot_loss_proj:2.475 [t=0.24s]
prediction: ['[CLS] this mental instability into. percolaible excursion not easily dismissed is epicenter or not forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.833 (perp=8.690, rec=0.087, cos=0.007), tot_loss_proj:2.788 [t=0.24s]
prediction: ['[CLS] this mental instability into. percola per or not easily dismissed is epicenter excursion not forgotten. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.774 (perp=8.387, rec=0.090, cos=0.007), tot_loss_proj:2.621 [t=0.24s]
prediction: ['[CLS] this mental instability into. per percola or not easily dismissed is epicenter excursion not forgotten. [SEP]']
[1050/2000] tot_loss=1.761 (perp=8.387, rec=0.076, cos=0.007), tot_loss_proj:2.622 [t=0.24s]
prediction: ['[CLS] this mental instability into. per percola or not easily dismissed is epicenter excursion not forgotten. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.703 (perp=8.013, rec=0.095, cos=0.006), tot_loss_proj:2.519 [t=0.24s]
prediction: ['[CLS] this mental instability intoenter. percola or not easily dismissed is epicenter excursion not forgotten. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.651 (perp=7.845, rec=0.074, cos=0.008), tot_loss_proj:2.295 [t=0.24s]
prediction: ['[CLS] this mental instability intoenter or percola. not easily dismissed is epicenter excursion not forgotten. [SEP]']
[1200/2000] tot_loss=1.663 (perp=7.845, rec=0.087, cos=0.006), tot_loss_proj:2.298 [t=0.24s]
prediction: ['[CLS] this mental instability intoenter or percola. not easily dismissed is epicenter excursion not forgotten. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.694 (perp=8.027, rec=0.083, cos=0.006), tot_loss_proj:2.361 [t=0.24s]
prediction: ['[CLS] this mental instability into per or excursion percola. not easily dismissed is epicenter not forgotten. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.623 (perp=7.618, rec=0.093, cos=0.007), tot_loss_proj:2.927 [t=0.24s]
prediction: ['[CLS] this mental instability into per excursion percola. not easily dismissed is epicenter. or forgotten. [SEP]']
[1350/2000] tot_loss=1.606 (perp=7.618, rec=0.076, cos=0.007), tot_loss_proj:2.922 [t=0.24s]
prediction: ['[CLS] this mental instability into per excursion percola. not easily dismissed is epicenter. or forgotten. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.568 (perp=7.388, rec=0.084, cos=0.007), tot_loss_proj:2.746 [t=0.24s]
prediction: ['[CLS] this mental instability into. per excursion percola. not easily dismissed is epicenter or forgotten. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.572 (perp=7.388, rec=0.087, cos=0.008), tot_loss_proj:2.758 [t=0.24s]
prediction: ['[CLS] this mental instability into. per excursion percola. not easily dismissed is epicenter or forgotten. [SEP]']
[1500/2000] tot_loss=1.568 (perp=7.388, rec=0.083, cos=0.007), tot_loss_proj:2.755 [t=0.24s]
prediction: ['[CLS] this mental instability into. per excursion percola. not easily dismissed is epicenter or forgotten. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.577 (perp=7.388, rec=0.093, cos=0.007), tot_loss_proj:2.755 [t=0.24s]
prediction: ['[CLS] this mental instability into. per excursion percola. not easily dismissed is epicenter or forgotten. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.524 (perp=7.138, rec=0.089, cos=0.008), tot_loss_proj:2.365 [t=0.24s]
prediction: ['[CLS] this mental instability into. per excursion percola is not easily dismissed. epicenter or forgotten. [SEP]']
[1650/2000] tot_loss=1.509 (perp=7.138, rec=0.075, cos=0.007), tot_loss_proj:2.358 [t=0.24s]
prediction: ['[CLS] this mental instability into. per excursion percola is not easily dismissed. epicenter or forgotten. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.512 (perp=7.138, rec=0.078, cos=0.007), tot_loss_proj:2.363 [t=0.24s]
prediction: ['[CLS] this mental instability into. per excursion percola is not easily dismissed. epicenter or forgotten. [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.462 (perp=6.803, rec=0.094, cos=0.008), tot_loss_proj:1.711 [t=0.24s]
prediction: ['[CLS] this mental instability into. per excursion percola. epicenter is not easily dismissed or forgotten. [SEP]']
[1800/2000] tot_loss=1.454 (perp=6.803, rec=0.087, cos=0.007), tot_loss_proj:1.712 [t=0.24s]
prediction: ['[CLS] this mental instability into. per excursion percola. epicenter is not easily dismissed or forgotten. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.447 (perp=6.803, rec=0.080, cos=0.007), tot_loss_proj:1.706 [t=0.24s]
prediction: ['[CLS] this mental instability into. per excursion percola. epicenter is not easily dismissed or forgotten. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.396 (perp=6.557, rec=0.077, cos=0.007), tot_loss_proj:1.671 [t=0.24s]
prediction: ['[CLS] this mental instability into per excursion. percola. epicenter is not easily dismissed or forgotten. [SEP]']
[1950/2000] tot_loss=1.402 (perp=6.557, rec=0.084, cos=0.007), tot_loss_proj:1.663 [t=0.24s]
prediction: ['[CLS] this mental instability into per excursion. percola. epicenter is not easily dismissed or forgotten. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.360 (perp=6.348, rec=0.083, cos=0.007), tot_loss_proj:1.658 [t=0.24s]
prediction: ['[CLS] this mental instability into per excursion. percola. epicenter is not easily forgotten or dismissed. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this mental instability intoenter. percola or not easily dismissed is epicenter excursion not forgotten. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.788 | p: 81.250 | r: 76.471
rouge2     | fm: 32.258 | p: 33.333 | r: 31.250
rougeL     | fm: 54.545 | p: 56.250 | r: 52.941
rougeLsum  | fm: 54.545 | p: 56.250 | r: 52.941
r1fm+r2fm = 111.046

[Aggregate metrics]:
rouge1     | fm: 86.238 | p: 85.998 | r: 86.717
rouge2     | fm: 53.278 | p: 53.150 | r: 53.510
rougeL     | fm: 74.043 | p: 73.880 | r: 74.395
rougeLsum  | fm: 74.215 | p: 74.010 | r: 74.584
r1fm+r2fm = 139.516

input #75 time: 0:09:25 | total time: 11:39:08


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9984894208430855
highest_index [0]
highest [0.9984894208430855]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.9084050059318542 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.8883193135261536 for ['[CLS] skin outside historian inside please determined boss legend vi đ wine unanimouslymer ski [SEP]']
[Init] best rec loss: 0.8717060685157776 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.8679447770118713 for ['[CLS] paper both commercially user guantanamo body 3d barker away commune also fortune turkey shay [SEP]']
[Init] best perm rec loss: 0.8600871562957764 for ['[CLS] commune turkey commercially both barker body guantanamo shay away fortune 3d user also paper [SEP]']
[Init] best perm rec loss: 0.8585477471351624 for ['[CLS] user also turkey barker guantanamo fortune commune both body shay paper 3d away commercially [SEP]']
[Init] best perm rec loss: 0.8572238683700562 for ['[CLS] turkey away barker fortune both guantanamo also 3d commune paper shay user body commercially [SEP]']
[Init] best perm rec loss: 0.8543236255645752 for ['[CLS] commercially turkey guantanamo commune barker paper fortune shay away body also both user 3d [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.158 (perp=9.516, rec=0.237, cos=0.018), tot_loss_proj:2.990 [t=0.23s]
prediction: ['[CLS] him. stopped.. allen when that seemed having without reverse challenging stopped [SEP]']
[ 100/2000] tot_loss=2.230 (perp=10.400, rec=0.141, cos=0.008), tot_loss_proj:3.179 [t=0.23s]
prediction: ['[CLS] himself. stopped at as allen at 66 like has himself has challenging stopped [SEP]']
[ 150/2000] tot_loss=2.115 (perp=10.002, rec=0.108, cos=0.007), tot_loss_proj:3.305 [t=0.24s]
prediction: ['[CLS] himself. stopped at as allen 66 66 as has himself has challenging stopped [SEP]']
[ 200/2000] tot_loss=2.238 (perp=10.716, rec=0.090, cos=0.005), tot_loss_proj:3.667 [t=0.24s]
prediction: ['[CLS] himself mayor. at as allen 66 66 as has himself challenging challenging stopped [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.106 (perp=10.065, rec=0.087, cos=0.006), tot_loss_proj:3.527 [t=0.24s]
prediction: ['[CLS] himself mayor. at s as allen 66 as has. combination challenging stopped [SEP]']
[ 300/2000] tot_loss=2.104 (perp=9.990, rec=0.101, cos=0.005), tot_loss_proj:3.866 [t=0.23s]
prediction: ["[CLS] himself mayor, at'as allen 66 if has. challenged challenging stopped [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.925 (perp=9.130, rec=0.094, cos=0.005), tot_loss_proj:3.611 [t=0.23s]
prediction: ['[CLS] himself,, at s as allen 66 if. has challenged challenging stopped [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.822 (perp=8.716, rec=0.074, cos=0.005), tot_loss_proj:3.225 [t=0.23s]
prediction: ['[CLS] himself, at s and as allen 66 if. has, challenging stopped [SEP]']
[ 450/2000] tot_loss=1.856 (perp=8.914, rec=0.068, cos=0.005), tot_loss_proj:3.262 [t=0.24s]
prediction: ['[CLS] himself. at s and as allen 66 if. has, challenging stopped [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.776 (perp=8.509, rec=0.070, cos=0.004), tot_loss_proj:3.187 [t=0.23s]
prediction: ['[CLS] s, at himself and as allen 66 if. has, challenging stopped [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.638 (perp=7.838, rec=0.066, cos=0.004), tot_loss_proj:2.773 [t=0.23s]
prediction: ['[CLS] s. at himself and as allen 66 if. has challenging stopped, [SEP]']
[ 600/2000] tot_loss=1.667 (perp=7.971, rec=0.069, cos=0.004), tot_loss_proj:2.883 [t=0.24s]
prediction: ['[CLS] s, at himself and as allen 66 if. has challenging stopped, [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.598 (perp=7.611, rec=0.073, cos=0.003), tot_loss_proj:2.797 [t=0.23s]
prediction: ['[CLS] s, at, and as allen 66 if. has challenging stopped himself [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.503 (perp=7.164, rec=0.067, cos=0.003), tot_loss_proj:2.444 [t=0.23s]
prediction: ['[CLS] s, at, and as allen 66 if. has stopped challenging himself [SEP]']
[ 750/2000] tot_loss=1.660 (perp=7.939, rec=0.069, cos=0.003), tot_loss_proj:2.549 [t=0.24s]
prediction: ["[CLS] s, at,'as allen 66 if. has stopped challenging himself [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.591 (perp=7.589, rec=0.070, cos=0.003), tot_loss_proj:2.755 [t=0.23s]
prediction: ["[CLS] s, at,'as allen 66 if himself has stopped challenging. [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.538 (perp=7.326, rec=0.069, cos=0.003), tot_loss_proj:2.744 [t=0.23s]
prediction: ["[CLS]'s, at, as allen 66 if himself has stopped challenging. [SEP]"]
[ 900/2000] tot_loss=1.542 (perp=7.326, rec=0.074, cos=0.003), tot_loss_proj:2.740 [t=0.23s]
prediction: ["[CLS]'s, at, as allen 66 if himself has stopped challenging. [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.454 (perp=6.892, rec=0.073, cos=0.003), tot_loss_proj:2.080 [t=0.23s]
prediction: ["[CLS]'s, at, as if 66 allen himself has stopped challenging. [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.444 (perp=6.892, rec=0.063, cos=0.003), tot_loss_proj:2.081 [t=0.24s]
prediction: ["[CLS]'s, at, as if 66 allen himself has stopped challenging. [SEP]"]
[1050/2000] tot_loss=1.458 (perp=6.892, rec=0.077, cos=0.003), tot_loss_proj:2.074 [t=0.23s]
prediction: ["[CLS]'s, at, as if 66 allen himself has stopped challenging. [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.447 (perp=6.892, rec=0.065, cos=0.003), tot_loss_proj:2.086 [t=0.24s]
prediction: ["[CLS]'s, at, as if 66 allen himself has stopped challenging. [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.364 (perp=6.462, rec=0.068, cos=0.003), tot_loss_proj:1.961 [t=0.24s]
prediction: ["[CLS]'s, at 66, as if allen himself has stopped challenging. [SEP]"]
[1200/2000] tot_loss=1.372 (perp=6.462, rec=0.076, cos=0.003), tot_loss_proj:1.967 [t=0.23s]
prediction: ["[CLS]'s, at 66, as if allen himself has stopped challenging. [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.351 (perp=6.413, rec=0.065, cos=0.003), tot_loss_proj:2.090 [t=0.23s]
prediction: ["[CLS]'s at 66, as, if allen himself has stopped challenging. [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.344 (perp=6.413, rec=0.058, cos=0.003), tot_loss_proj:2.079 [t=0.24s]
prediction: ["[CLS]'s at 66, as, if allen himself has stopped challenging. [SEP]"]
[1350/2000] tot_loss=1.353 (perp=6.413, rec=0.067, cos=0.003), tot_loss_proj:2.090 [t=0.23s]
prediction: ["[CLS]'s at 66, as, if allen himself has stopped challenging. [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.326 (perp=6.316, rec=0.060, cos=0.003), tot_loss_proj:2.025 [t=0.24s]
prediction: ["[CLS]'s at 66, as if, allen himself has stopped challenging. [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.344 (perp=6.316, rec=0.078, cos=0.003), tot_loss_proj:2.039 [t=0.24s]
prediction: ["[CLS]'s at 66, as if, allen himself has stopped challenging. [SEP]"]
[1500/2000] tot_loss=1.327 (perp=6.316, rec=0.060, cos=0.003), tot_loss_proj:2.033 [t=0.24s]
prediction: ["[CLS]'s at 66, as if, allen himself has stopped challenging. [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.339 (perp=6.316, rec=0.073, cos=0.003), tot_loss_proj:2.035 [t=0.24s]
prediction: ["[CLS]'s at 66, as if, allen himself has stopped challenging. [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.338 (perp=6.316, rec=0.072, cos=0.003), tot_loss_proj:2.039 [t=0.24s]
prediction: ["[CLS]'s at 66, as if, allen himself has stopped challenging. [SEP]"]
[1650/2000] tot_loss=1.337 (perp=6.316, rec=0.071, cos=0.003), tot_loss_proj:2.041 [t=0.24s]
prediction: ["[CLS]'s at 66, as if, allen himself has stopped challenging. [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.340 (perp=6.316, rec=0.074, cos=0.003), tot_loss_proj:2.039 [t=0.24s]
prediction: ["[CLS]'s at 66, as if, allen himself has stopped challenging. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.339 (perp=6.316, rec=0.073, cos=0.003), tot_loss_proj:2.033 [t=0.24s]
prediction: ["[CLS]'s at 66, as if, allen himself has stopped challenging. [SEP]"]
[1800/2000] tot_loss=1.334 (perp=6.316, rec=0.068, cos=0.003), tot_loss_proj:2.034 [t=0.23s]
prediction: ["[CLS]'s at 66, as if, allen himself has stopped challenging. [SEP]"]
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.320 (perp=6.204, rec=0.076, cos=0.003), tot_loss_proj:1.720 [t=0.23s]
prediction: ["[CLS]'s as if, at 66, allen himself has stopped challenging. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.312 (perp=6.204, rec=0.068, cos=0.003), tot_loss_proj:1.727 [t=0.24s]
prediction: ["[CLS]'s as if, at 66, allen himself has stopped challenging. [SEP]"]
[1950/2000] tot_loss=1.325 (perp=6.204, rec=0.082, cos=0.003), tot_loss_proj:1.724 [t=0.23s]
prediction: ["[CLS]'s as if, at 66, allen himself has stopped challenging. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.314 (perp=6.204, rec=0.070, cos=0.003), tot_loss_proj:1.725 [t=0.24s]
prediction: ["[CLS]'s as if, at 66, allen himself has stopped challenging. [SEP]"]
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS]'s, at, as if 66 allen himself has stopped challenging. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 136.364

[Aggregate metrics]:
rouge1     | fm: 86.463 | p: 86.157 | r: 86.962
rouge2     | fm: 52.932 | p: 52.897 | r: 53.137
rougeL     | fm: 74.116 | p: 73.946 | r: 74.493
rougeLsum  | fm: 74.114 | p: 73.911 | r: 74.457
r1fm+r2fm = 139.396

input #76 time: 0:09:15 | total time: 11:48:24


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9987189876711384
highest_index [0]
highest [0.9987189876711384]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.7850564122200012 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.7751423716545105 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.7439104914665222 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best perm rec loss: 0.7429611682891846 for ['[CLS] sheep ways limeno win purple park grayraphic ole sometime medium where most outside [SEP]']
[Init] best perm rec loss: 0.7425685524940491 for ['[CLS]raphic gray lime purpleno sometime park win sheep ole medium ways most outside where [SEP]']
[Init] best perm rec loss: 0.7425423264503479 for ['[CLS] ways sometime gray medium park where purple ole most win sheep outsideraphicno lime [SEP]']
[Init] best perm rec loss: 0.741714596748352 for ['[CLS]raphic ole sometime gray mediumno win park outside most ways sheep lime where purple [SEP]']
[Init] best perm rec loss: 0.7374240159988403 for ['[CLS] medium purple ways sometime park lime oleno winraphic outside sheep where most gray [SEP]']
[Init] best perm rec loss: 0.7366889119148254 for ['[CLS] waysraphic ole win lime grayno sheep park purple outside most sometime medium where [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.100 (perp=12.662, rec=0.510, cos=0.057), tot_loss_proj:3.176 [t=0.23s]
prediction: ['[CLS] tomorrow earth experience above the everything academy concept. creaturepp carlos right focused true [SEP]']
[ 100/2000] tot_loss=2.555 (perp=10.850, rec=0.335, cos=0.049), tot_loss_proj:4.042 [t=0.23s]
prediction: ['[CLS] tomorrow realmils above the realm academy ratings the creature insignificant its that therefore realm [SEP]']
[ 150/2000] tot_loss=2.238 (perp=9.884, rec=0.218, cos=0.043), tot_loss_proj:2.818 [t=0.23s]
prediction: ['[CLS] tomorrow realmars above the realm realm concept is promise pitches its promise thus so [SEP]']
[ 200/2000] tot_loss=2.393 (perp=10.696, rec=0.235, cos=0.019), tot_loss_proj:3.056 [t=0.23s]
prediction: ['[CLS] reality realmars above the realm believe concept is promisears its promise life so [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.277 (perp=9.844, rec=0.274, cos=0.034), tot_loss_proj:2.711 [t=0.23s]
prediction: ['[CLS] reality thatars above the realm believe engine is promisears its promise material life [SEP]']
[ 300/2000] tot_loss=2.138 (perp=9.519, rec=0.209, cos=0.025), tot_loss_proj:2.493 [t=0.23s]
prediction: ['[CLS] imagination thatars above the realm believeـ is promisears its promise material life [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.008 (perp=8.932, rec=0.197, cos=0.025), tot_loss_proj:2.332 [t=0.23s]
prediction: ['[CLS] imagination thatars above the realm believe life is lifears its promise material concept [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.966 (perp=8.679, rec=0.201, cos=0.030), tot_loss_proj:2.539 [t=0.23s]
prediction: ['[CLS] life thatars above the realm believe life is progressars its promise materialـ [SEP]']
[ 450/2000] tot_loss=1.937 (perp=8.679, rec=0.176, cos=0.025), tot_loss_proj:2.537 [t=0.23s]
prediction: ['[CLS] life thatars above the realm believe life is progressars its promise materialـ [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.944 (perp=8.696, rec=0.180, cos=0.025), tot_loss_proj:2.543 [t=0.23s]
prediction: ['[CLS] life that makears above the realm believe life is progress its promise materialـ [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.841 (perp=8.188, rec=0.177, cos=0.027), tot_loss_proj:2.434 [t=0.23s]
prediction: ['[CLS] life that abovears make the realm believe life is progress its promise materialـ [SEP]']
[ 600/2000] tot_loss=1.829 (perp=8.188, rec=0.166, cos=0.025), tot_loss_proj:2.428 [t=0.23s]
prediction: ['[CLS] life that abovears make the realm believe life is progress its promise materialـ [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.813 (perp=8.054, rec=0.177, cos=0.026), tot_loss_proj:2.303 [t=0.23s]
prediction: ['[CLS] life thatars above make the realm believe life is progress its promise materialـ [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.765 (perp=7.894, rec=0.160, cos=0.026), tot_loss_proj:2.270 [t=0.23s]
prediction: ['[CLS] that lifears above make the realm believe life is progress its promise materialـ [SEP]']
[ 750/2000] tot_loss=1.778 (perp=7.983, rec=0.156, cos=0.025), tot_loss_proj:2.394 [t=0.23s]
prediction: ['[CLS] that lifears above make the realm believe life is progress its promise materialpled [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.877 (perp=8.418, rec=0.167, cos=0.027), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS] that soars above make the realm believe life is spend its promise materialpled [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.863 (perp=8.418, rec=0.153, cos=0.026), tot_loss_proj:2.579 [t=0.23s]
prediction: ['[CLS] that soars above make the realm believe life is spend its promise materialpled [SEP]']
[ 900/2000] tot_loss=1.864 (perp=8.418, rec=0.154, cos=0.026), tot_loss_proj:2.576 [t=0.23s]
prediction: ['[CLS] that soars above make the realm believe life is spend its promise materialpled [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.868 (perp=8.418, rec=0.158, cos=0.026), tot_loss_proj:2.577 [t=0.23s]
prediction: ['[CLS] that soars above make the realm believe life is spend its promise materialpled [SEP]']
Attempt swap
[1000/2000] tot_loss=1.869 (perp=8.418, rec=0.159, cos=0.026), tot_loss_proj:2.572 [t=0.23s]
prediction: ['[CLS] that soars above make the realm believe life is spend its promise materialpled [SEP]']
[1050/2000] tot_loss=1.862 (perp=8.418, rec=0.153, cos=0.026), tot_loss_proj:2.571 [t=0.23s]
prediction: ['[CLS] that soars above make the realm believe life is spend its promise materialpled [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.714 (perp=7.710, rec=0.147, cos=0.025), tot_loss_proj:2.273 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[1150/2000] tot_loss=1.716 (perp=7.710, rec=0.149, cos=0.025), tot_loss_proj:2.282 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
[1200/2000] tot_loss=1.708 (perp=7.710, rec=0.141, cos=0.025), tot_loss_proj:2.277 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[1250/2000] tot_loss=1.726 (perp=7.710, rec=0.158, cos=0.025), tot_loss_proj:2.275 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[1300/2000] tot_loss=1.717 (perp=7.710, rec=0.149, cos=0.025), tot_loss_proj:2.276 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
[1350/2000] tot_loss=1.712 (perp=7.710, rec=0.145, cos=0.025), tot_loss_proj:2.269 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[1400/2000] tot_loss=1.711 (perp=7.710, rec=0.144, cos=0.025), tot_loss_proj:2.271 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[1450/2000] tot_loss=1.716 (perp=7.710, rec=0.149, cos=0.025), tot_loss_proj:2.275 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
[1500/2000] tot_loss=1.715 (perp=7.710, rec=0.149, cos=0.025), tot_loss_proj:2.278 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[1550/2000] tot_loss=1.712 (perp=7.710, rec=0.145, cos=0.025), tot_loss_proj:2.288 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[1600/2000] tot_loss=1.721 (perp=7.710, rec=0.154, cos=0.025), tot_loss_proj:2.283 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
[1650/2000] tot_loss=1.710 (perp=7.710, rec=0.143, cos=0.025), tot_loss_proj:2.287 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[1700/2000] tot_loss=1.717 (perp=7.710, rec=0.151, cos=0.025), tot_loss_proj:2.281 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[1750/2000] tot_loss=1.710 (perp=7.710, rec=0.143, cos=0.025), tot_loss_proj:2.282 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
[1800/2000] tot_loss=1.710 (perp=7.710, rec=0.143, cos=0.025), tot_loss_proj:2.284 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[1850/2000] tot_loss=1.709 (perp=7.710, rec=0.142, cos=0.025), tot_loss_proj:2.285 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[1900/2000] tot_loss=1.707 (perp=7.710, rec=0.141, cos=0.025), tot_loss_proj:2.284 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
[1950/2000] tot_loss=1.708 (perp=7.710, rec=0.141, cos=0.024), tot_loss_proj:2.280 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Attempt swap
[2000/2000] tot_loss=1.706 (perp=7.710, rec=0.140, cos=0.024), tot_loss_proj:2.287 [t=0.23s]
prediction: ['[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] that soars resources make the realm believe life is above its promise materialـ [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 7.143 | p: 7.143 | r: 7.143
rougeL     | fm: 46.667 | p: 46.667 | r: 46.667
rougeLsum  | fm: 46.667 | p: 46.667 | r: 46.667
r1fm+r2fm = 100.476

[Aggregate metrics]:
rouge1     | fm: 86.534 | p: 86.294 | r: 87.009
rouge2     | fm: 52.421 | p: 52.321 | r: 52.660
rougeL     | fm: 73.730 | p: 73.547 | r: 74.127
rougeLsum  | fm: 73.746 | p: 73.513 | r: 74.105
r1fm+r2fm = 138.955

input #77 time: 0:09:04 | total time: 11:57:28


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9986771109256047
highest_index [0]
highest [0.9986771109256047]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.985630989074707 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9587128758430481 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8177029490470886 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8163542151451111 for ['[CLS] barnet lynn sings [SEP]']
[Init] best rec loss: 0.7808359265327454 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.7805563807487488 for ['[CLS] le grant screens [SEP]']
[Init] best perm rec loss: 0.7771375775337219 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.968 (perp=8.971, rec=0.165, cos=0.009), tot_loss_proj:2.647 [t=0.22s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 100/2000] tot_loss=1.936 (perp=9.116, rec=0.107, cos=0.006), tot_loss_proj:2.719 [t=0.22s]
prediction: ['[CLS] exit theater theater [SEP]']
[ 150/2000] tot_loss=2.232 (perp=10.782, rec=0.073, cos=0.003), tot_loss_proj:2.944 [t=0.23s]
prediction: ['[CLS] exit theater the [SEP]']
[ 200/2000] tot_loss=2.228 (perp=10.782, rec=0.069, cos=0.003), tot_loss_proj:2.935 [t=0.22s]
prediction: ['[CLS] exit theater the [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.658 (perp=7.958, rec=0.064, cos=0.003), tot_loss_proj:1.671 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=1.639 (perp=7.958, rec=0.045, cos=0.003), tot_loss_proj:1.685 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.657 (perp=7.958, rec=0.062, cos=0.003), tot_loss_proj:1.681 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.658 (perp=7.958, rec=0.064, cos=0.003), tot_loss_proj:1.672 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.653 (perp=7.958, rec=0.058, cos=0.003), tot_loss_proj:1.676 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.652 (perp=7.958, rec=0.058, cos=0.003), tot_loss_proj:1.673 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.667 (perp=7.958, rec=0.072, cos=0.003), tot_loss_proj:1.662 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.657 (perp=7.958, rec=0.063, cos=0.003), tot_loss_proj:1.669 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.650 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.682 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.648 (perp=7.958, rec=0.053, cos=0.003), tot_loss_proj:1.664 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.665 (perp=7.958, rec=0.071, cos=0.003), tot_loss_proj:1.668 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.644 (perp=7.958, rec=0.050, cos=0.003), tot_loss_proj:1.672 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.665 (perp=7.958, rec=0.071, cos=0.003), tot_loss_proj:1.678 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.674 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.651 (perp=7.958, rec=0.057, cos=0.003), tot_loss_proj:1.671 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.655 (perp=7.958, rec=0.061, cos=0.003), tot_loss_proj:1.663 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.658 (perp=7.958, rec=0.063, cos=0.003), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.662 (perp=7.958, rec=0.068, cos=0.003), tot_loss_proj:1.672 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.652 (perp=7.958, rec=0.057, cos=0.003), tot_loss_proj:1.675 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.661 (perp=7.958, rec=0.067, cos=0.003), tot_loss_proj:1.674 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.643 (perp=7.958, rec=0.049, cos=0.003), tot_loss_proj:1.676 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.674 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.659 (perp=7.958, rec=0.064, cos=0.003), tot_loss_proj:1.668 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.666 (perp=7.958, rec=0.072, cos=0.003), tot_loss_proj:1.680 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.646 (perp=7.958, rec=0.052, cos=0.003), tot_loss_proj:1.678 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.656 (perp=7.958, rec=0.062, cos=0.003), tot_loss_proj:1.671 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.653 (perp=7.958, rec=0.059, cos=0.003), tot_loss_proj:1.682 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.658 (perp=7.958, rec=0.064, cos=0.003), tot_loss_proj:1.685 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.662 (perp=7.958, rec=0.068, cos=0.003), tot_loss_proj:1.675 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.657 (perp=7.958, rec=0.063, cos=0.003), tot_loss_proj:1.663 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.666 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.650 (perp=7.958, rec=0.056, cos=0.003), tot_loss_proj:1.670 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.653 (perp=7.958, rec=0.059, cos=0.003), tot_loss_proj:1.678 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.645 (perp=7.958, rec=0.050, cos=0.003), tot_loss_proj:1.664 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.647 (perp=7.958, rec=0.053, cos=0.003), tot_loss_proj:1.673 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.659 (perp=7.958, rec=0.065, cos=0.003), tot_loss_proj:1.663 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.749 | p: 86.504 | r: 87.158
rouge2     | fm: 52.903 | p: 52.839 | r: 53.089
rougeL     | fm: 74.075 | p: 73.934 | r: 74.480
rougeLsum  | fm: 74.165 | p: 74.017 | r: 74.524
r1fm+r2fm = 139.652

input #78 time: 0:08:56 | total time: 12:06:25


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.9987089018045019
highest_index [0]
highest [0.9987089018045019]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9676922559738159 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.958460807800293 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.9435795545578003 for ['[CLS] abs mess [SEP]']
[Init] best rec loss: 0.921610951423645 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.9193524122238159 for ['[CLS] high designer [SEP]']
[Init] best rec loss: 0.9069709777832031 for ['[CLS] unincorporated band [SEP]']
[Init] best rec loss: 0.902313232421875 for ['[CLS] crystaltor [SEP]']
[Init] best rec loss: 0.9010124206542969 for ['[CLS] world ceased [SEP]']
[Init] best perm rec loss: 0.8955940008163452 for ['[CLS] ceased world [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.601 (perp=10.912, rec=0.685, cos=0.734), tot_loss_proj:4.275 [t=0.22s]
prediction: ['[CLS]athic? [SEP]']
[ 100/2000] tot_loss=3.000 (perp=11.428, rec=0.501, cos=0.213), tot_loss_proj:2.570 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.709 (perp=11.428, rec=0.372, cos=0.052), tot_loss_proj:2.592 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=2.614 (perp=11.428, rec=0.294, cos=0.034), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.591 (perp=11.428, rec=0.267, cos=0.038), tot_loss_proj:2.576 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 300/2000] tot_loss=2.569 (perp=11.428, rec=0.242, cos=0.042), tot_loss_proj:2.596 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.577 (perp=11.428, rec=0.250, cos=0.042), tot_loss_proj:2.594 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.610 (perp=11.690, rec=0.231, cos=0.041), tot_loss_proj:2.877 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
[ 450/2000] tot_loss=2.606 (perp=11.690, rec=0.225, cos=0.043), tot_loss_proj:2.880 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.593 (perp=11.690, rec=0.211, cos=0.044), tot_loss_proj:2.891 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.600 (perp=11.690, rec=0.220, cos=0.042), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
[ 600/2000] tot_loss=2.591 (perp=11.690, rec=0.208, cos=0.045), tot_loss_proj:2.889 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.594 (perp=11.690, rec=0.209, cos=0.047), tot_loss_proj:2.883 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.599 (perp=11.690, rec=0.213, cos=0.047), tot_loss_proj:2.887 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
[ 750/2000] tot_loss=2.580 (perp=11.690, rec=0.195, cos=0.047), tot_loss_proj:2.889 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.592 (perp=11.690, rec=0.208, cos=0.046), tot_loss_proj:2.892 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.587 (perp=11.690, rec=0.205, cos=0.044), tot_loss_proj:2.887 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
[ 900/2000] tot_loss=2.587 (perp=11.690, rec=0.204, cos=0.045), tot_loss_proj:2.887 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.590 (perp=11.690, rec=0.206, cos=0.046), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1000/2000] tot_loss=2.595 (perp=11.690, rec=0.211, cos=0.046), tot_loss_proj:2.881 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
[1050/2000] tot_loss=2.592 (perp=11.690, rec=0.212, cos=0.043), tot_loss_proj:2.886 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1100/2000] tot_loss=2.591 (perp=11.690, rec=0.206, cos=0.046), tot_loss_proj:2.891 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1150/2000] tot_loss=2.596 (perp=11.690, rec=0.212, cos=0.046), tot_loss_proj:2.884 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
[1200/2000] tot_loss=2.594 (perp=11.690, rec=0.211, cos=0.045), tot_loss_proj:2.881 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1250/2000] tot_loss=2.593 (perp=11.690, rec=0.208, cos=0.047), tot_loss_proj:2.886 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1300/2000] tot_loss=2.581 (perp=11.690, rec=0.195, cos=0.048), tot_loss_proj:2.886 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
[1350/2000] tot_loss=2.584 (perp=11.690, rec=0.198, cos=0.048), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1400/2000] tot_loss=2.592 (perp=11.690, rec=0.206, cos=0.048), tot_loss_proj:2.888 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1450/2000] tot_loss=2.592 (perp=11.690, rec=0.208, cos=0.047), tot_loss_proj:2.880 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
[1500/2000] tot_loss=2.594 (perp=11.690, rec=0.208, cos=0.048), tot_loss_proj:2.892 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1550/2000] tot_loss=2.596 (perp=11.690, rec=0.210, cos=0.048), tot_loss_proj:2.885 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1600/2000] tot_loss=2.599 (perp=11.690, rec=0.212, cos=0.048), tot_loss_proj:2.890 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
[1650/2000] tot_loss=2.594 (perp=11.690, rec=0.207, cos=0.048), tot_loss_proj:2.887 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1700/2000] tot_loss=2.587 (perp=11.690, rec=0.201, cos=0.048), tot_loss_proj:2.889 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1750/2000] tot_loss=2.600 (perp=11.690, rec=0.215, cos=0.047), tot_loss_proj:2.882 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
[1800/2000] tot_loss=2.590 (perp=11.690, rec=0.203, cos=0.048), tot_loss_proj:2.886 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1850/2000] tot_loss=2.591 (perp=11.690, rec=0.205, cos=0.048), tot_loss_proj:2.883 [t=0.23s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[1900/2000] tot_loss=2.585 (perp=11.690, rec=0.199, cos=0.048), tot_loss_proj:2.887 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
[1950/2000] tot_loss=2.591 (perp=11.690, rec=0.206, cos=0.048), tot_loss_proj:2.883 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
Attempt swap
[2000/2000] tot_loss=2.596 (perp=11.690, rec=0.210, cos=0.048), tot_loss_proj:2.893 [t=0.22s]
prediction: ['[CLS] fascinating seems [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating seems [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 75.000

[Aggregate metrics]:
rouge1     | fm: 86.536 | p: 86.291 | r: 86.996
rouge2     | fm: 52.252 | p: 52.115 | r: 52.438
rougeL     | fm: 74.051 | p: 73.864 | r: 74.457
rougeLsum  | fm: 74.094 | p: 73.897 | r: 74.471
r1fm+r2fm = 138.788

input #79 time: 0:08:56 | total time: 12:15:21


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9987510445740972
highest_index [0]
highest [0.9987510445740972]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9974209666252136 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9935943484306335 for ['[CLS] breath difference sensitiveosity higher [SEP]']
[Init] best rec loss: 0.9706876277923584 for ['[CLS] water takinge bonnie ca [SEP]']
[Init] best rec loss: 0.9109598398208618 for ['[CLS] team joined target * results [SEP]']
[Init] best perm rec loss: 0.9091998934745789 for ['[CLS] results joined team target * [SEP]']
[Init] best perm rec loss: 0.9052599668502808 for ['[CLS] target * results joined team [SEP]']
[Init] best perm rec loss: 0.904413104057312 for ['[CLS] joined target team results * [SEP]']
[Init] best perm rec loss: 0.9030737280845642 for ['[CLS] team results target joined * [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.998 (perp=8.944, rec=0.204, cos=0.005), tot_loss_proj:2.546 [t=0.22s]
prediction: ['[CLS] and wise mizen wise [SEP]']
[ 100/2000] tot_loss=1.678 (perp=7.698, rec=0.135, cos=0.004), tot_loss_proj:1.805 [t=0.22s]
prediction: ['[CLS], wise wizened [SEP]']
[ 150/2000] tot_loss=1.656 (perp=7.698, rec=0.113, cos=0.003), tot_loss_proj:1.799 [t=0.23s]
prediction: ['[CLS], wise wizened [SEP]']
[ 200/2000] tot_loss=1.631 (perp=7.698, rec=0.089, cos=0.003), tot_loss_proj:1.787 [t=0.22s]
prediction: ['[CLS], wise wizened [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.479 (perp=6.853, rec=0.105, cos=0.004), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS], wizened wise [SEP]']
[ 300/2000] tot_loss=2.112 (perp=10.103, rec=0.089, cos=0.003), tot_loss_proj:2.767 [t=0.23s]
prediction: ['[CLS]¤ wizened wise [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.941 (perp=9.193, rec=0.100, cos=0.003), tot_loss_proj:2.310 [t=0.23s]
prediction: ['[CLS] wizened wisepersonal [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.888 (perp=8.941, rec=0.096, cos=0.003), tot_loss_proj:2.397 [t=0.22s]
prediction: ['[CLS]personal wizened wise [SEP]']
[ 450/2000] tot_loss=1.881 (perp=8.941, rec=0.090, cos=0.003), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS]personal wizened wise [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.811 (perp=8.631, rec=0.081, cos=0.003), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.809 (perp=8.631, rec=0.079, cos=0.003), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
[ 600/2000] tot_loss=1.820 (perp=8.631, rec=0.091, cos=0.003), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.808 (perp=8.631, rec=0.079, cos=0.003), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.812 (perp=8.631, rec=0.083, cos=0.003), tot_loss_proj:2.399 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
[ 750/2000] tot_loss=1.813 (perp=8.631, rec=0.084, cos=0.003), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.820 (perp=8.631, rec=0.091, cos=0.003), tot_loss_proj:2.410 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.819 (perp=8.631, rec=0.090, cos=0.003), tot_loss_proj:2.405 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
[ 900/2000] tot_loss=1.825 (perp=8.631, rec=0.096, cos=0.003), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.807 (perp=8.631, rec=0.078, cos=0.003), tot_loss_proj:2.401 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1000/2000] tot_loss=1.810 (perp=8.631, rec=0.081, cos=0.003), tot_loss_proj:2.401 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
[1050/2000] tot_loss=1.810 (perp=8.631, rec=0.081, cos=0.003), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1100/2000] tot_loss=1.813 (perp=8.631, rec=0.084, cos=0.003), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1150/2000] tot_loss=1.812 (perp=8.631, rec=0.083, cos=0.003), tot_loss_proj:2.400 [t=0.22s]
prediction: ['[CLS]oc wizened wise [SEP]']
[1200/2000] tot_loss=1.797 (perp=8.631, rec=0.068, cos=0.003), tot_loss_proj:2.393 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1250/2000] tot_loss=1.821 (perp=8.631, rec=0.092, cos=0.003), tot_loss_proj:2.396 [t=0.22s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1300/2000] tot_loss=1.817 (perp=8.631, rec=0.088, cos=0.003), tot_loss_proj:2.408 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
[1350/2000] tot_loss=1.816 (perp=8.631, rec=0.087, cos=0.003), tot_loss_proj:2.405 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1400/2000] tot_loss=1.807 (perp=8.631, rec=0.078, cos=0.003), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1450/2000] tot_loss=1.810 (perp=8.631, rec=0.081, cos=0.003), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
[1500/2000] tot_loss=1.811 (perp=8.631, rec=0.082, cos=0.003), tot_loss_proj:2.394 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1550/2000] tot_loss=1.816 (perp=8.631, rec=0.087, cos=0.003), tot_loss_proj:2.400 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1600/2000] tot_loss=1.817 (perp=8.631, rec=0.088, cos=0.003), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
[1650/2000] tot_loss=1.821 (perp=8.631, rec=0.092, cos=0.003), tot_loss_proj:2.396 [t=0.22s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1700/2000] tot_loss=1.810 (perp=8.631, rec=0.081, cos=0.003), tot_loss_proj:2.397 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1750/2000] tot_loss=1.819 (perp=8.631, rec=0.090, cos=0.003), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS]oc wizened wise [SEP]']
[1800/2000] tot_loss=1.801 (perp=8.631, rec=0.072, cos=0.003), tot_loss_proj:2.400 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1850/2000] tot_loss=1.814 (perp=8.631, rec=0.085, cos=0.003), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[1900/2000] tot_loss=1.817 (perp=8.631, rec=0.088, cos=0.003), tot_loss_proj:2.395 [t=0.22s]
prediction: ['[CLS]oc wizened wise [SEP]']
[1950/2000] tot_loss=1.809 (perp=8.631, rec=0.080, cos=0.003), tot_loss_proj:2.405 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Attempt swap
[2000/2000] tot_loss=1.807 (perp=8.631, rec=0.078, cos=0.003), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS]oc wizened wise [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS]oc wizened wise [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 80.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 88.889

[Aggregate metrics]:
rouge1     | fm: 86.624 | p: 86.236 | r: 87.152
rouge2     | fm: 51.674 | p: 51.606 | r: 51.899
rougeL     | fm: 74.045 | p: 73.790 | r: 74.470
rougeLsum  | fm: 73.933 | p: 73.689 | r: 74.367
r1fm+r2fm = 138.298

input #80 time: 0:08:57 | total time: 12:24:19


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.998506278991034
highest_index [0]
highest [0.998506278991034]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9719983339309692 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.9568555951118469 for ['[CLS] hobbs : kahn closer invest rico [SEP]']
[Init] best rec loss: 0.919513463973999 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8558323383331299 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8490030765533447 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.8182841539382935 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.8058221340179443 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 0.795734703540802 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best perm rec loss: 0.7901783585548401 for ['[CLS] threads approval modelled bandsitating missing [SEP]']
[Init] best perm rec loss: 0.7899459600448608 for ['[CLS] approval bands threads modelleditating missing [SEP]']
[Init] best perm rec loss: 0.7884279489517212 for ['[CLS]itating missing approval bands threads modelled [SEP]']
[Init] best perm rec loss: 0.7879689335823059 for ['[CLS] missingitating bands approval modelled threads [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.982 (perp=8.727, rec=0.212, cos=0.025), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] not player not the impressive player [SEP]']
[ 100/2000] tot_loss=1.864 (perp=8.791, rec=0.098, cos=0.008), tot_loss_proj:2.398 [t=0.22s]
prediction: ['[CLS] not is not most impressive player [SEP]']
[ 150/2000] tot_loss=1.855 (perp=8.791, rec=0.091, cos=0.006), tot_loss_proj:2.401 [t=0.23s]
prediction: ['[CLS] not is not most impressive player [SEP]']
[ 200/2000] tot_loss=1.659 (perp=7.890, rec=0.078, cos=0.003), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] the is not most impressive player [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.267 (perp=5.977, rec=0.069, cos=0.003), tot_loss_proj:1.330 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 300/2000] tot_loss=1.255 (perp=5.977, rec=0.057, cos=0.003), tot_loss_proj:1.336 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.262 (perp=5.977, rec=0.064, cos=0.003), tot_loss_proj:1.328 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.257 (perp=5.977, rec=0.058, cos=0.003), tot_loss_proj:1.325 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 450/2000] tot_loss=1.250 (perp=5.977, rec=0.052, cos=0.003), tot_loss_proj:1.327 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.255 (perp=5.977, rec=0.056, cos=0.003), tot_loss_proj:1.333 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.257 (perp=5.977, rec=0.059, cos=0.003), tot_loss_proj:1.320 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 600/2000] tot_loss=1.260 (perp=5.977, rec=0.062, cos=0.003), tot_loss_proj:1.336 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.250 (perp=5.977, rec=0.051, cos=0.003), tot_loss_proj:1.338 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.261 (perp=5.977, rec=0.063, cos=0.003), tot_loss_proj:1.323 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 750/2000] tot_loss=1.254 (perp=5.977, rec=0.056, cos=0.003), tot_loss_proj:1.325 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.257 (perp=5.977, rec=0.058, cos=0.003), tot_loss_proj:1.331 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.245 (perp=5.977, rec=0.047, cos=0.003), tot_loss_proj:1.323 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 900/2000] tot_loss=1.262 (perp=5.977, rec=0.064, cos=0.003), tot_loss_proj:1.328 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.257 (perp=5.977, rec=0.059, cos=0.003), tot_loss_proj:1.330 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.253 (perp=5.977, rec=0.054, cos=0.003), tot_loss_proj:1.329 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1050/2000] tot_loss=1.254 (perp=5.977, rec=0.056, cos=0.003), tot_loss_proj:1.324 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.264 (perp=5.977, rec=0.066, cos=0.003), tot_loss_proj:1.334 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.253 (perp=5.977, rec=0.054, cos=0.003), tot_loss_proj:1.327 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1200/2000] tot_loss=1.264 (perp=5.977, rec=0.066, cos=0.003), tot_loss_proj:1.327 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.265 (perp=5.977, rec=0.067, cos=0.003), tot_loss_proj:1.328 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.254 (perp=5.977, rec=0.055, cos=0.003), tot_loss_proj:1.323 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1350/2000] tot_loss=1.255 (perp=5.977, rec=0.056, cos=0.003), tot_loss_proj:1.331 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.263 (perp=5.977, rec=0.064, cos=0.003), tot_loss_proj:1.329 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.257 (perp=5.977, rec=0.059, cos=0.003), tot_loss_proj:1.326 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1500/2000] tot_loss=1.263 (perp=5.977, rec=0.065, cos=0.003), tot_loss_proj:1.320 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.256 (perp=5.977, rec=0.058, cos=0.003), tot_loss_proj:1.318 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.261 (perp=5.977, rec=0.063, cos=0.003), tot_loss_proj:1.329 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1650/2000] tot_loss=1.257 (perp=5.977, rec=0.059, cos=0.003), tot_loss_proj:1.323 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.248 (perp=5.977, rec=0.050, cos=0.003), tot_loss_proj:1.325 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.256 (perp=5.977, rec=0.058, cos=0.003), tot_loss_proj:1.327 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1800/2000] tot_loss=1.264 (perp=5.977, rec=0.065, cos=0.003), tot_loss_proj:1.327 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.260 (perp=5.977, rec=0.062, cos=0.003), tot_loss_proj:1.335 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.264 (perp=5.977, rec=0.066, cos=0.003), tot_loss_proj:1.327 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1950/2000] tot_loss=1.255 (perp=5.977, rec=0.056, cos=0.003), tot_loss_proj:1.336 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.260 (perp=5.977, rec=0.061, cos=0.003), tot_loss_proj:1.331 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not the most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.764 | p: 86.406 | r: 87.301
rouge2     | fm: 52.027 | p: 51.975 | r: 52.279
rougeL     | fm: 74.255 | p: 74.005 | r: 74.641
rougeLsum  | fm: 74.405 | p: 74.190 | r: 74.843
r1fm+r2fm = 138.791

input #81 time: 0:08:57 | total time: 12:33:16


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.9986377431629492
highest_index [0]
highest [0.9986377431629492]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9828013181686401 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9603455066680908 for ['[CLS] beck will parent stu rocks criteria roycenia [SEP]']
[Init] best rec loss: 0.9535247683525085 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9519714117050171 for ['[CLS] seminetive facing toward victor trance grown [SEP]']
[Init] best rec loss: 0.9372182488441467 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9363351464271545 for ['[CLS] task cadence extreme manchester internal direct mann alpine [SEP]']
[Init] best rec loss: 0.9304280877113342 for ['[CLS] ecclesiastical novel pre £ moi data push fran [SEP]']
[Init] best rec loss: 0.9294431209564209 for ['[CLS] bedroomroup hose reece acherade rightsie [SEP]']
[Init] best rec loss: 0.9174061417579651 for ['[CLS] worse terms everyday down sandsbed supporting due [SEP]']
[Init] best rec loss: 0.898158073425293 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.8964783549308777 for ['[CLS] letter babyturnesian eric a distribution soft [SEP]']
[Init] best rec loss: 0.8641878366470337 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8639135360717773 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8622021079063416 for ['[CLS] plumagebasket respective record role whoeverachfur [SEP]']
[Init] best perm rec loss: 0.8597894310951233 for ['[CLS]basketfur whoever role respective recordach plumage [SEP]']
[Init] best perm rec loss: 0.8582521677017212 for ['[CLS]basketfur whoever respective roleach plumage record [SEP]']
[Init] best perm rec loss: 0.8581947088241577 for ['[CLS] rolebasket plumagefur record respectiveach whoever [SEP]']
[Init] best perm rec loss: 0.857462465763092 for ['[CLS]basketfur role record respective whoever plumageach [SEP]']
[Init] best perm rec loss: 0.8561487197875977 for ['[CLS]fur role whoever respectivebasket plumage recordach [SEP]']
[Init] best perm rec loss: 0.8556596040725708 for ['[CLS]fur roleach respectivebasket plumage record whoever [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.046 (perp=9.337, rec=0.171, cos=0.007), tot_loss_proj:2.243 [t=0.22s]
prediction: ['[CLS] by script script is undone by sloppy sloppy [SEP]']
[ 100/2000] tot_loss=2.155 (perp=10.259, rec=0.099, cos=0.005), tot_loss_proj:2.380 [t=0.22s]
prediction: ['[CLS] a script script s undone by sloppy sloppy [SEP]']
[ 150/2000] tot_loss=2.142 (perp=10.259, rec=0.086, cos=0.004), tot_loss_proj:2.379 [t=0.22s]
prediction: ['[CLS] a script script s undone by sloppy sloppy [SEP]']
[ 200/2000] tot_loss=2.102 (perp=10.054, rec=0.087, cos=0.004), tot_loss_proj:2.371 [t=0.22s]
prediction: ['[CLS] a it script s undone by sloppy sloppy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.892 (perp=9.087, rec=0.072, cos=0.003), tot_loss_proj:2.077 [t=0.22s]
prediction: ['[CLS] it script s undone by a sloppy sloppy [SEP]']
[ 300/2000] tot_loss=1.889 (perp=9.087, rec=0.069, cos=0.003), tot_loss_proj:2.076 [t=0.23s]
prediction: ['[CLS] it script s undone by a sloppy sloppy [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.573 (perp=7.465, rec=0.077, cos=0.004), tot_loss_proj:1.664 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.564 (perp=7.465, rec=0.068, cos=0.003), tot_loss_proj:1.649 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 450/2000] tot_loss=1.571 (perp=7.465, rec=0.074, cos=0.004), tot_loss_proj:1.662 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.570 (perp=7.465, rec=0.074, cos=0.003), tot_loss_proj:1.657 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.568 (perp=7.465, rec=0.072, cos=0.003), tot_loss_proj:1.664 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 600/2000] tot_loss=1.570 (perp=7.465, rec=0.074, cos=0.003), tot_loss_proj:1.664 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.560 (perp=7.465, rec=0.064, cos=0.003), tot_loss_proj:1.656 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.565 (perp=7.465, rec=0.069, cos=0.003), tot_loss_proj:1.661 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 750/2000] tot_loss=1.559 (perp=7.465, rec=0.063, cos=0.003), tot_loss_proj:1.654 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.562 (perp=7.465, rec=0.066, cos=0.003), tot_loss_proj:1.665 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.568 (perp=7.465, rec=0.072, cos=0.003), tot_loss_proj:1.661 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 900/2000] tot_loss=1.569 (perp=7.465, rec=0.072, cos=0.003), tot_loss_proj:1.666 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.570 (perp=7.465, rec=0.074, cos=0.003), tot_loss_proj:1.665 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1000/2000] tot_loss=1.559 (perp=7.465, rec=0.062, cos=0.003), tot_loss_proj:1.660 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1050/2000] tot_loss=1.565 (perp=7.465, rec=0.069, cos=0.003), tot_loss_proj:1.658 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1100/2000] tot_loss=1.562 (perp=7.465, rec=0.066, cos=0.003), tot_loss_proj:1.662 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1150/2000] tot_loss=1.558 (perp=7.465, rec=0.062, cos=0.003), tot_loss_proj:1.664 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1200/2000] tot_loss=1.563 (perp=7.465, rec=0.067, cos=0.003), tot_loss_proj:1.665 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1250/2000] tot_loss=1.567 (perp=7.465, rec=0.071, cos=0.003), tot_loss_proj:1.664 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1300/2000] tot_loss=1.562 (perp=7.465, rec=0.066, cos=0.003), tot_loss_proj:1.660 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1350/2000] tot_loss=1.571 (perp=7.465, rec=0.075, cos=0.003), tot_loss_proj:1.658 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1400/2000] tot_loss=1.569 (perp=7.465, rec=0.073, cos=0.003), tot_loss_proj:1.654 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1450/2000] tot_loss=1.564 (perp=7.465, rec=0.067, cos=0.003), tot_loss_proj:1.659 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1500/2000] tot_loss=1.560 (perp=7.465, rec=0.064, cos=0.003), tot_loss_proj:1.661 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1550/2000] tot_loss=1.569 (perp=7.465, rec=0.073, cos=0.003), tot_loss_proj:1.663 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1600/2000] tot_loss=1.564 (perp=7.465, rec=0.068, cos=0.003), tot_loss_proj:1.661 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1650/2000] tot_loss=1.562 (perp=7.465, rec=0.066, cos=0.003), tot_loss_proj:1.660 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1700/2000] tot_loss=1.566 (perp=7.465, rec=0.070, cos=0.003), tot_loss_proj:1.665 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.760 (perp=8.380, rec=0.080, cos=0.003), tot_loss_proj:1.926 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy script sloppy [SEP]']
[1800/2000] tot_loss=1.755 (perp=8.380, rec=0.076, cos=0.003), tot_loss_proj:1.933 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy script sloppy [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.557 (perp=7.465, rec=0.061, cos=0.003), tot_loss_proj:1.657 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1900/2000] tot_loss=1.822 (perp=8.699, rec=0.079, cos=0.003), tot_loss_proj:1.954 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppyriety script [SEP]']
[1950/2000] tot_loss=1.815 (perp=8.699, rec=0.072, cos=0.003), tot_loss_proj:1.947 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppyriety script [SEP]']
Attempt swap
[2000/2000] tot_loss=1.803 (perp=8.699, rec=0.060, cos=0.003), tot_loss_proj:1.949 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppyriety script [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s undone by a sloppy sloppy script [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 94.118 | p: 88.889 | r: 100.000
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 188.854

[Aggregate metrics]:
rouge1     | fm: 86.896 | p: 86.500 | r: 87.548
rouge2     | fm: 52.775 | p: 52.582 | r: 53.039
rougeL     | fm: 74.620 | p: 74.312 | r: 75.115
rougeLsum  | fm: 74.576 | p: 74.281 | r: 75.100
r1fm+r2fm = 139.671

input #82 time: 0:08:57 | total time: 12:42:14


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.998670112975278
highest_index [0]
highest [0.998670112975278]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.8480295538902283 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.8309171795845032 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.8254842162132263 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8065268993377686 for ['[CLS] floodax aboriginal mali wisconsin na rain basket missed call [SEP]']
[Init] best rec loss: 0.7764449715614319 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.7715729475021362 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best perm rec loss: 0.7704460620880127 for ['[CLS] feeling xavier nash something johnny jamie breaking [CLS] quality us [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.596 (perp=11.076, rec=0.347, cos=0.034), tot_loss_proj:4.048 [t=0.22s]
prediction: ['[CLS] what none creation? tomorrow x at [SEP] it values [SEP]']
[ 100/2000] tot_loss=2.022 (perp=8.826, rec=0.248, cos=0.008), tot_loss_proj:3.343 [t=0.22s]
prediction: ['[CLS] what behind it when becoming when at know what grows [SEP]']
[ 150/2000] tot_loss=2.023 (perp=9.087, rec=0.199, cos=0.007), tot_loss_proj:2.672 [t=0.22s]
prediction: ['[CLS] what grow it when grows up at know what wants [SEP]']
[ 200/2000] tot_loss=1.833 (perp=8.515, rec=0.125, cos=0.005), tot_loss_proj:2.660 [t=0.22s]
prediction: ['[CLS] what be it when grows up at know it wants [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.548 (perp=7.176, rec=0.110, cos=0.003), tot_loss_proj:2.411 [t=0.23s]
prediction: ['[CLS] what grows up at be it when know it wants [SEP]']
[ 300/2000] tot_loss=1.309 (perp=6.128, rec=0.081, cos=0.003), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] what grows up to be it when know it wants [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.193 (perp=5.627, rec=0.065, cos=0.003), tot_loss_proj:1.764 [t=0.22s]
prediction: ['[CLS] what grows up to be it know when it wants [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.115 (perp=5.270, rec=0.058, cos=0.003), tot_loss_proj:1.672 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
[ 450/2000] tot_loss=1.128 (perp=5.270, rec=0.072, cos=0.003), tot_loss_proj:1.671 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.129 (perp=5.270, rec=0.072, cos=0.003), tot_loss_proj:1.672 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.128 (perp=5.270, rec=0.072, cos=0.003), tot_loss_proj:1.674 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
[ 600/2000] tot_loss=1.124 (perp=5.270, rec=0.067, cos=0.003), tot_loss_proj:1.674 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.107 (perp=5.270, rec=0.051, cos=0.003), tot_loss_proj:1.671 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.118 (perp=5.270, rec=0.061, cos=0.003), tot_loss_proj:1.675 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
[ 750/2000] tot_loss=1.115 (perp=5.270, rec=0.059, cos=0.003), tot_loss_proj:1.669 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.119 (perp=5.270, rec=0.062, cos=0.003), tot_loss_proj:1.673 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.120 (perp=5.270, rec=0.063, cos=0.003), tot_loss_proj:1.676 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
[ 900/2000] tot_loss=1.123 (perp=5.270, rec=0.066, cos=0.003), tot_loss_proj:1.671 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.120 (perp=5.270, rec=0.063, cos=0.003), tot_loss_proj:1.671 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1000/2000] tot_loss=1.119 (perp=5.270, rec=0.062, cos=0.003), tot_loss_proj:1.672 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
[1050/2000] tot_loss=1.114 (perp=5.270, rec=0.057, cos=0.003), tot_loss_proj:1.673 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1100/2000] tot_loss=1.125 (perp=5.270, rec=0.068, cos=0.003), tot_loss_proj:1.674 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1150/2000] tot_loss=1.116 (perp=5.270, rec=0.059, cos=0.003), tot_loss_proj:1.674 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
[1200/2000] tot_loss=1.126 (perp=5.270, rec=0.069, cos=0.003), tot_loss_proj:1.675 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1250/2000] tot_loss=1.116 (perp=5.270, rec=0.059, cos=0.003), tot_loss_proj:1.676 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1300/2000] tot_loss=1.119 (perp=5.270, rec=0.062, cos=0.003), tot_loss_proj:1.678 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
[1350/2000] tot_loss=1.112 (perp=5.270, rec=0.055, cos=0.003), tot_loss_proj:1.670 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1400/2000] tot_loss=1.121 (perp=5.270, rec=0.065, cos=0.003), tot_loss_proj:1.674 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1450/2000] tot_loss=1.118 (perp=5.270, rec=0.062, cos=0.003), tot_loss_proj:1.678 [t=0.28s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
[1500/2000] tot_loss=1.125 (perp=5.270, rec=0.068, cos=0.003), tot_loss_proj:1.674 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1550/2000] tot_loss=1.126 (perp=5.270, rec=0.070, cos=0.003), tot_loss_proj:1.671 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1600/2000] tot_loss=1.125 (perp=5.270, rec=0.068, cos=0.003), tot_loss_proj:1.674 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
[1650/2000] tot_loss=1.125 (perp=5.270, rec=0.069, cos=0.003), tot_loss_proj:1.673 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1700/2000] tot_loss=1.116 (perp=5.270, rec=0.059, cos=0.003), tot_loss_proj:1.676 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1750/2000] tot_loss=1.125 (perp=5.270, rec=0.068, cos=0.003), tot_loss_proj:1.679 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
[1800/2000] tot_loss=1.115 (perp=5.270, rec=0.059, cos=0.003), tot_loss_proj:1.671 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1850/2000] tot_loss=1.128 (perp=5.270, rec=0.071, cos=0.003), tot_loss_proj:1.672 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[1900/2000] tot_loss=1.121 (perp=5.270, rec=0.064, cos=0.003), tot_loss_proj:1.665 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
[1950/2000] tot_loss=1.116 (perp=5.270, rec=0.060, cos=0.003), tot_loss_proj:1.675 [t=0.23s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Attempt swap
[2000/2000] tot_loss=1.120 (perp=5.270, rec=0.063, cos=0.003), tot_loss_proj:1.669 [t=0.22s]
prediction: ['[CLS] what grows up to be know when it wants it [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] what grows up to be know when it wants it [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 58.333 | p: 58.333 | r: 58.333
rougeLsum  | fm: 58.333 | p: 58.333 | r: 58.333
r1fm+r2fm = 136.364

[Aggregate metrics]:
rouge1     | fm: 86.983 | p: 86.590 | r: 87.589
rouge2     | fm: 52.540 | p: 52.349 | r: 52.822
rougeL     | fm: 74.379 | p: 74.059 | r: 74.887
rougeLsum  | fm: 74.490 | p: 74.210 | r: 75.007
r1fm+r2fm = 139.523

input #83 time: 0:08:57 | total time: 12:51:11


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9986247007725194
highest_index [0]
highest [0.9986247007725194]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9079328179359436 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.8927328586578369 for ['[CLS] primera criminalmost dynamic ride venue youtube [SEP]']
[Init] best rec loss: 0.8788459300994873 for ['[CLS] between favourated performed hope politics misty [SEP]']
[Init] best rec loss: 0.8612868189811707 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8610894680023193 for ['[CLS] appearance later orderedlby outstanding battery gentle [SEP]']
[Init] best rec loss: 0.8587613701820374 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.851856529712677 for ['[CLS] competed shegl brick kill trade down [SEP]']
[Init] best rec loss: 0.8379114270210266 for ['[CLS] individual hung cold ¹...ught railroad [SEP]']
[Init] best rec loss: 0.8374106884002686 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 0.8271065354347229 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best perm rec loss: 0.8216490149497986 for ['[CLS] caused infinite ca each goingiter its [SEP]']
[Init] best perm rec loss: 0.8214398622512817 for ['[CLS] caused its infiniteiter going each ca [SEP]']
[Init] best perm rec loss: 0.8186920881271362 for ['[CLS] ca its each infiniteiter caused going [SEP]']
[Init] best perm rec loss: 0.8181185722351074 for ['[CLS] going caiter infinite caused each its [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.438 (perp=10.983, rec=0.223, cos=0.018), tot_loss_proj:3.098 [t=0.22s]
prediction: ['[CLS] lost lost the think have have lost [SEP]']
[ 100/2000] tot_loss=2.103 (perp=9.919, rec=0.114, cos=0.005), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] people lost ability think have ability lost [SEP]']
[ 150/2000] tot_loss=2.079 (perp=9.919, rec=0.091, cos=0.004), tot_loss_proj:2.592 [t=0.22s]
prediction: ['[CLS] people lost ability think have ability lost [SEP]']
[ 200/2000] tot_loss=2.085 (perp=9.919, rec=0.097, cos=0.004), tot_loss_proj:2.597 [t=0.23s]
prediction: ['[CLS] people lost ability think have ability lost [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.789 (perp=8.516, rec=0.082, cos=0.004), tot_loss_proj:2.438 [t=0.22s]
prediction: ['[CLS] ability lost people think have ability lost [SEP]']
[ 300/2000] tot_loss=1.799 (perp=8.516, rec=0.093, cos=0.003), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] ability lost people think have ability lost [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.774 (perp=8.491, rec=0.073, cos=0.003), tot_loss_proj:2.588 [t=0.23s]
prediction: ['[CLS] ability lost people think have the to [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.461 (perp=6.895, rec=0.079, cos=0.003), tot_loss_proj:2.599 [t=0.22s]
prediction: ['[CLS] lost people think have the ability to [SEP]']
[ 450/2000] tot_loss=1.449 (perp=6.895, rec=0.067, cos=0.003), tot_loss_proj:2.547 [t=0.23s]
prediction: ['[CLS] lost people think have the ability to [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.164 (perp=5.434, rec=0.074, cos=0.003), tot_loss_proj:2.541 [t=0.23s]
prediction: ['[CLS] lost people have the ability to think [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.149 (perp=5.434, rec=0.060, cos=0.003), tot_loss_proj:2.487 [t=0.22s]
prediction: ['[CLS] lost people have the ability to think [SEP]']
[ 600/2000] tot_loss=1.139 (perp=5.434, rec=0.050, cos=0.003), tot_loss_proj:2.424 [t=0.22s]
prediction: ['[CLS] lost people have the ability to think [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.005 (perp=4.681, rec=0.066, cos=0.003), tot_loss_proj:1.047 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.005 (perp=4.681, rec=0.066, cos=0.003), tot_loss_proj:1.052 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 750/2000] tot_loss=0.995 (perp=4.681, rec=0.056, cos=0.003), tot_loss_proj:1.039 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.003 (perp=4.681, rec=0.064, cos=0.003), tot_loss_proj:1.041 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.007 (perp=4.681, rec=0.068, cos=0.003), tot_loss_proj:1.043 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 900/2000] tot_loss=0.997 (perp=4.681, rec=0.058, cos=0.003), tot_loss_proj:1.042 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.010 (perp=4.681, rec=0.071, cos=0.003), tot_loss_proj:1.044 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.006 (perp=4.681, rec=0.067, cos=0.003), tot_loss_proj:1.039 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1050/2000] tot_loss=1.002 (perp=4.681, rec=0.063, cos=0.003), tot_loss_proj:1.042 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.000 (perp=4.681, rec=0.061, cos=0.003), tot_loss_proj:1.035 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1150/2000] tot_loss=0.998 (perp=4.681, rec=0.059, cos=0.003), tot_loss_proj:1.047 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1200/2000] tot_loss=0.997 (perp=4.681, rec=0.058, cos=0.003), tot_loss_proj:1.031 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1250/2000] tot_loss=0.997 (perp=4.681, rec=0.058, cos=0.003), tot_loss_proj:1.038 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.004 (perp=4.681, rec=0.065, cos=0.003), tot_loss_proj:1.039 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=1.011 (perp=4.681, rec=0.072, cos=0.003), tot_loss_proj:1.040 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=0.996 (perp=4.681, rec=0.057, cos=0.003), tot_loss_proj:1.047 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.002 (perp=4.681, rec=0.063, cos=0.003), tot_loss_proj:1.043 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=1.008 (perp=4.681, rec=0.069, cos=0.003), tot_loss_proj:1.036 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=1.007 (perp=4.681, rec=0.069, cos=0.003), tot_loss_proj:1.039 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=0.998 (perp=4.681, rec=0.060, cos=0.003), tot_loss_proj:1.044 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=1.005 (perp=4.681, rec=0.066, cos=0.003), tot_loss_proj:1.046 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=0.995 (perp=4.681, rec=0.056, cos=0.003), tot_loss_proj:1.035 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=0.995 (perp=4.681, rec=0.056, cos=0.003), tot_loss_proj:1.033 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=1.008 (perp=4.681, rec=0.069, cos=0.003), tot_loss_proj:1.031 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=0.997 (perp=4.681, rec=0.058, cos=0.003), tot_loss_proj:1.042 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.000 (perp=4.681, rec=0.061, cos=0.003), tot_loss_proj:1.043 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=0.994 (perp=4.681, rec=0.055, cos=0.003), tot_loss_proj:1.043 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=0.990 (perp=4.681, rec=0.051, cos=0.003), tot_loss_proj:1.038 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.115 | p: 86.700 | r: 87.720
rouge2     | fm: 53.008 | p: 52.916 | r: 53.197
rougeL     | fm: 74.690 | p: 74.418 | r: 75.209
rougeLsum  | fm: 74.755 | p: 74.415 | r: 75.262
r1fm+r2fm = 140.123

input #84 time: 0:08:58 | total time: 13:00:09


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9985486720321903
highest_index [0]
highest [0.9985486720321903]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9036340117454529 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.8920694589614868 for ['[CLS] sent okay too deep partition secrecy consolidated true shouldn our [SEP]']
[Init] best rec loss: 0.8888673186302185 for ['[CLS] mt running waiting worried roverstakesley rating rag age [SEP]']
[Init] best rec loss: 0.878192663192749 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8480039834976196 for ['[CLS] thinks macau stand cam form halolic venture cannot vehicle [SEP]']
[Init] best rec loss: 0.8359525203704834 for ['[CLS]lete cecilcc goals bar [ rules man brodiestation [SEP]']
[Init] best rec loss: 0.8354098796844482 for ['[CLS] young graf challenging haven nord overly graduation blank dad josephine [SEP]']
[Init] best perm rec loss: 0.8341495394706726 for ['[CLS] graduation challenging young haven josephine blank graf overly dad nord [SEP]']
[Init] best perm rec loss: 0.8310648202896118 for ['[CLS] blank josephine young haven graduation challenging overly graf nord dad [SEP]']
[Init] best perm rec loss: 0.8298596739768982 for ['[CLS] graduation challenging josephine nord young overly dad graf blank haven [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.207 (perp=9.297, rec=0.318, cos=0.029), tot_loss_proj:2.570 [t=0.23s]
prediction: ['[CLS] unfortunately unfortunately. unfortunately big less unfortunately really badly not [SEP]']
[ 100/2000] tot_loss=1.768 (perp=8.108, rec=0.139, cos=0.008), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] unfortunately unfortunately. also s not unfortunately very good not [SEP]']
[ 150/2000] tot_loss=1.469 (perp=6.859, rec=0.092, cos=0.006), tot_loss_proj:1.873 [t=0.24s]
prediction: ['[CLS] unfortunately,. also s not not very good not [SEP]']
[ 200/2000] tot_loss=1.439 (perp=6.864, rec=0.062, cos=0.004), tot_loss_proj:1.863 [t=0.24s]
prediction: ['[CLS] unfortunately,. also s it not very good not [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.856 (perp=8.067, rec=0.227, cos=0.016), tot_loss_proj:2.197 [t=0.24s]
prediction: ['[CLS] unfortunately. it also s mere none very good not [SEP]']
[ 300/2000] tot_loss=1.844 (perp=8.510, rec=0.135, cos=0.008), tot_loss_proj:2.653 [t=0.24s]
prediction: ['[CLS] unfortunately. it also s put 4 very good not [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.441 (perp=6.520, rec=0.131, cos=0.006), tot_loss_proj:1.816 [t=0.23s]
prediction: ['[CLS] unfortunately, it also s more 4 not very good [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.388 (perp=6.349, rec=0.113, cos=0.005), tot_loss_proj:1.670 [t=0.24s]
prediction: ['[CLS] be unfortunately, it also s 2 not very good [SEP]']
[ 450/2000] tot_loss=1.318 (perp=5.979, rec=0.118, cos=0.005), tot_loss_proj:1.642 [t=0.23s]
prediction: ['[CLS] be unfortunately, it also s. not very good [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.172 (perp=5.303, rec=0.107, cos=0.005), tot_loss_proj:1.533 [t=0.23s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.143 (perp=5.303, rec=0.078, cos=0.004), tot_loss_proj:1.539 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
[ 600/2000] tot_loss=1.167 (perp=5.303, rec=0.102, cos=0.004), tot_loss_proj:1.534 [t=0.23s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.164 (perp=5.303, rec=0.099, cos=0.004), tot_loss_proj:1.537 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.144 (perp=5.303, rec=0.080, cos=0.004), tot_loss_proj:1.534 [t=0.23s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
[ 750/2000] tot_loss=1.148 (perp=5.303, rec=0.083, cos=0.004), tot_loss_proj:1.540 [t=0.23s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.171 (perp=5.303, rec=0.106, cos=0.004), tot_loss_proj:1.536 [t=0.23s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.154 (perp=5.303, rec=0.090, cos=0.004), tot_loss_proj:1.533 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
[ 900/2000] tot_loss=1.160 (perp=5.303, rec=0.095, cos=0.004), tot_loss_proj:1.547 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.148 (perp=5.303, rec=0.084, cos=0.004), tot_loss_proj:1.539 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[1000/2000] tot_loss=1.166 (perp=5.303, rec=0.101, cos=0.004), tot_loss_proj:1.546 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
[1050/2000] tot_loss=1.162 (perp=5.303, rec=0.097, cos=0.004), tot_loss_proj:1.537 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[1100/2000] tot_loss=1.158 (perp=5.303, rec=0.093, cos=0.004), tot_loss_proj:1.539 [t=0.23s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[1150/2000] tot_loss=1.155 (perp=5.303, rec=0.091, cos=0.004), tot_loss_proj:1.536 [t=0.23s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
[1200/2000] tot_loss=1.151 (perp=5.303, rec=0.086, cos=0.004), tot_loss_proj:1.537 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[1250/2000] tot_loss=1.140 (perp=5.303, rec=0.075, cos=0.004), tot_loss_proj:1.538 [t=0.23s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[1300/2000] tot_loss=1.155 (perp=5.303, rec=0.090, cos=0.004), tot_loss_proj:1.538 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
[1350/2000] tot_loss=1.156 (perp=5.303, rec=0.091, cos=0.004), tot_loss_proj:1.549 [t=0.23s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[1400/2000] tot_loss=1.149 (perp=5.303, rec=0.085, cos=0.004), tot_loss_proj:1.544 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
[1450/2000] tot_loss=1.156 (perp=5.303, rec=0.092, cos=0.004), tot_loss_proj:1.543 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
[1500/2000] tot_loss=1.142 (perp=5.303, rec=0.078, cos=0.004), tot_loss_proj:1.541 [t=0.24s]
prediction: ['[CLS] be. unfortunately, it also s not very good [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.097 (perp=5.040, rec=0.085, cos=0.005), tot_loss_proj:1.275 [t=0.24s]
prediction: ['[CLS] be unfortunately, it also s not very good. [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.045 (perp=4.822, rec=0.077, cos=0.005), tot_loss_proj:1.284 [t=0.23s]
prediction: ['[CLS] unfortunately, be it also s not very good. [SEP]']
[1650/2000] tot_loss=1.049 (perp=4.822, rec=0.080, cos=0.004), tot_loss_proj:1.278 [t=0.23s]
prediction: ['[CLS] unfortunately, be it also s not very good. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.049 (perp=4.822, rec=0.080, cos=0.004), tot_loss_proj:1.273 [t=0.24s]
prediction: ['[CLS] unfortunately, be it also s not very good. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.055 (perp=4.822, rec=0.086, cos=0.004), tot_loss_proj:1.275 [t=0.23s]
prediction: ['[CLS] unfortunately, be it also s not very good. [SEP]']
[1800/2000] tot_loss=1.054 (perp=4.822, rec=0.086, cos=0.004), tot_loss_proj:1.285 [t=0.23s]
prediction: ['[CLS] unfortunately, be it also s not very good. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.046 (perp=4.726, rec=0.097, cos=0.004), tot_loss_proj:1.376 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s be not very good. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.032 (perp=4.726, rec=0.082, cos=0.004), tot_loss_proj:1.375 [t=0.23s]
prediction: ['[CLS] unfortunately, it also s be not very good. [SEP]']
[1950/2000] tot_loss=1.028 (perp=4.726, rec=0.079, cos=0.004), tot_loss_proj:1.370 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s be not very good. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.028 (perp=4.726, rec=0.078, cos=0.004), tot_loss_proj:1.384 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s be not very good. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, be it also s not very good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 141.796

[Aggregate metrics]:
rouge1     | fm: 87.205 | p: 86.747 | r: 87.893
rouge2     | fm: 52.970 | p: 52.811 | r: 53.294
rougeL     | fm: 74.721 | p: 74.442 | r: 75.312
rougeLsum  | fm: 74.759 | p: 74.441 | r: 75.347
r1fm+r2fm = 140.175

input #85 time: 0:09:15 | total time: 13:09:24


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9987611252986475
highest_index [0]
highest [0.9987611252986475]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9472851157188416 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9073663949966431 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 0.8295146822929382 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.8039171695709229 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.7760397791862488 for ['[CLS] liberated round alright [SEP]']
[Init] best perm rec loss: 0.7751524448394775 for ['[CLS] round liberated alright [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.027 (perp=13.145, rec=0.362, cos=0.036), tot_loss_proj:3.051 [t=0.22s]
prediction: ['[CLS] mackenzie clarity treat [SEP]']
[ 100/2000] tot_loss=2.437 (perp=10.833, rec=0.232, cos=0.038), tot_loss_proj:2.369 [t=0.22s]
prediction: ['[CLS] emotional clarity clarity [SEP]']
[ 150/2000] tot_loss=2.439 (perp=11.016, rec=0.197, cos=0.039), tot_loss_proj:2.575 [t=0.22s]
prediction: ['[CLS] emotional clarity tradition [SEP]']
[ 200/2000] tot_loss=2.758 (perp=11.883, rec=0.341, cos=0.041), tot_loss_proj:3.299 [t=0.22s]
prediction: ['[CLS] emotional clarity kurdistan [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.559 (perp=11.204, rec=0.280, cos=0.038), tot_loss_proj:3.247 [t=0.22s]
prediction: ['[CLS] clarity emotionalroud [SEP]']
[ 300/2000] tot_loss=2.774 (perp=12.558, rec=0.227, cos=0.035), tot_loss_proj:4.166 [t=0.22s]
prediction: ['[CLS] clarity clarityiful [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.452 (perp=10.485, rec=0.308, cos=0.047), tot_loss_proj:3.269 [t=0.22s]
prediction: ['[CLS] juliana emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.297 (perp=9.932, rec=0.261, cos=0.050), tot_loss_proj:3.939 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
[ 450/2000] tot_loss=2.281 (perp=9.932, rec=0.241, cos=0.054), tot_loss_proj:3.933 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.302 (perp=9.932, rec=0.266, cos=0.049), tot_loss_proj:3.936 [t=0.23s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.275 (perp=9.932, rec=0.230, cos=0.058), tot_loss_proj:3.937 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
[ 600/2000] tot_loss=2.283 (perp=9.932, rec=0.237, cos=0.059), tot_loss_proj:3.940 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.270 (perp=9.932, rec=0.219, cos=0.065), tot_loss_proj:3.937 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.287 (perp=9.932, rec=0.215, cos=0.086), tot_loss_proj:3.937 [t=0.23s]
prediction: ['[CLS]iful emotional clarity [SEP]']
[ 750/2000] tot_loss=2.268 (perp=9.932, rec=0.194, cos=0.088), tot_loss_proj:3.935 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.280 (perp=9.932, rec=0.203, cos=0.091), tot_loss_proj:3.934 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.284 (perp=9.932, rec=0.200, cos=0.098), tot_loss_proj:3.937 [t=0.23s]
prediction: ['[CLS]iful emotional clarity [SEP]']
[ 900/2000] tot_loss=2.282 (perp=9.932, rec=0.198, cos=0.098), tot_loss_proj:3.938 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.293 (perp=9.932, rec=0.212, cos=0.095), tot_loss_proj:3.935 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=2.279 (perp=9.932, rec=0.197, cos=0.095), tot_loss_proj:3.937 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
[1050/2000] tot_loss=2.279 (perp=9.932, rec=0.193, cos=0.100), tot_loss_proj:3.935 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=2.274 (perp=9.932, rec=0.192, cos=0.097), tot_loss_proj:3.940 [t=0.23s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=2.276 (perp=9.932, rec=0.193, cos=0.097), tot_loss_proj:3.933 [t=0.23s]
prediction: ['[CLS]iful emotional clarity [SEP]']
[1200/2000] tot_loss=2.286 (perp=9.932, rec=0.201, cos=0.099), tot_loss_proj:3.930 [t=0.22s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.274 (perp=9.932, rec=0.190, cos=0.098), tot_loss_proj:3.941 [t=0.23s]
prediction: ['[CLS]iful emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.051 (perp=8.855, rec=0.182, cos=0.097), tot_loss_proj:2.000 [t=0.23s]
prediction: ['[CLS] & emotional clarity [SEP]']
[1350/2000] tot_loss=2.052 (perp=8.855, rec=0.184, cos=0.097), tot_loss_proj:2.003 [t=0.23s]
prediction: ['[CLS] & emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=2.059 (perp=8.855, rec=0.190, cos=0.098), tot_loss_proj:1.998 [t=0.23s]
prediction: ['[CLS] & emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.059 (perp=8.855, rec=0.190, cos=0.098), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] & emotional clarity [SEP]']
[1500/2000] tot_loss=2.059 (perp=8.855, rec=0.189, cos=0.099), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] & emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=2.062 (perp=8.855, rec=0.192, cos=0.099), tot_loss_proj:2.004 [t=0.23s]
prediction: ['[CLS] & emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=2.061 (perp=8.855, rec=0.191, cos=0.099), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] & emotional clarity [SEP]']
[1650/2000] tot_loss=2.060 (perp=8.855, rec=0.191, cos=0.098), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] & emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=2.046 (perp=8.855, rec=0.178, cos=0.097), tot_loss_proj:1.998 [t=0.23s]
prediction: ['[CLS] & emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=2.066 (perp=8.855, rec=0.197, cos=0.099), tot_loss_proj:1.998 [t=0.23s]
prediction: ['[CLS] & emotional clarity [SEP]']
[1800/2000] tot_loss=2.055 (perp=8.855, rec=0.185, cos=0.099), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] & emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=2.059 (perp=8.855, rec=0.189, cos=0.099), tot_loss_proj:2.004 [t=0.23s]
prediction: ['[CLS] & emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=2.065 (perp=8.855, rec=0.194, cos=0.099), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] & emotional clarity [SEP]']
[1950/2000] tot_loss=2.057 (perp=8.855, rec=0.186, cos=0.100), tot_loss_proj:1.999 [t=0.23s]
prediction: ['[CLS] & emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=2.053 (perp=8.855, rec=0.182, cos=0.099), tot_loss_proj:2.002 [t=0.23s]
prediction: ['[CLS] & emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] & emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 100.000 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 66.667 | p: 75.000 | r: 60.000
rougeLsum  | fm: 66.667 | p: 75.000 | r: 60.000
r1fm+r2fm = 88.889

[Aggregate metrics]:
rouge1     | fm: 87.208 | p: 86.911 | r: 87.777
rouge2     | fm: 52.392 | p: 52.259 | r: 52.697
rougeL     | fm: 74.670 | p: 74.414 | r: 75.140
rougeLsum  | fm: 74.717 | p: 74.432 | r: 75.207
r1fm+r2fm = 139.600

input #86 time: 0:08:57 | total time: 13:18:22


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.9988957672898477
highest_index [0]
highest [0.9988957672898477]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.7563130855560303 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7272683382034302 for ['[CLS] calendar? [SEP]']
[Init] best rec loss: 0.6739445924758911 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.6534679532051086 for ['[CLS] action [MASK] [SEP]']
[Init] best rec loss: 0.6447585225105286 for ['[CLS] distinct post [SEP]']
[Init] best rec loss: 0.6323065161705017 for ['[CLS] popularski [SEP]']
[Init] best rec loss: 0.6135426759719849 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.5955603122711182 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.753 (perp=12.536, rec=0.228, cos=0.018), tot_loss_proj:3.299 [t=0.22s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=2.679 (perp=12.536, rec=0.160, cos=0.011), tot_loss_proj:3.289 [t=0.22s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 150/2000] tot_loss=1.545 (perp=7.258, rec=0.088, cos=0.006), tot_loss_proj:1.514 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.536 (perp=7.258, rec=0.080, cos=0.004), tot_loss_proj:1.509 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.525 (perp=7.258, rec=0.071, cos=0.002), tot_loss_proj:1.525 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.502 (perp=7.258, rec=0.047, cos=0.003), tot_loss_proj:1.517 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.533 (perp=7.258, rec=0.079, cos=0.003), tot_loss_proj:1.525 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.519 (perp=7.258, rec=0.065, cos=0.002), tot_loss_proj:1.510 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.500 (perp=7.258, rec=0.046, cos=0.002), tot_loss_proj:1.511 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.524 (perp=7.258, rec=0.068, cos=0.004), tot_loss_proj:1.515 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.512 (perp=7.258, rec=0.059, cos=0.002), tot_loss_proj:1.528 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.512 (perp=7.258, rec=0.058, cos=0.002), tot_loss_proj:1.533 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.512 (perp=7.258, rec=0.058, cos=0.002), tot_loss_proj:1.514 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.511 (perp=7.258, rec=0.057, cos=0.002), tot_loss_proj:1.519 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.509 (perp=7.258, rec=0.055, cos=0.002), tot_loss_proj:1.509 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.510 (perp=7.258, rec=0.057, cos=0.002), tot_loss_proj:1.513 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.505 (perp=7.258, rec=0.051, cos=0.002), tot_loss_proj:1.522 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.497 (perp=7.258, rec=0.044, cos=0.002), tot_loss_proj:1.522 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.515 (perp=7.258, rec=0.061, cos=0.002), tot_loss_proj:1.514 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.505 (perp=7.258, rec=0.051, cos=0.002), tot_loss_proj:1.528 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.521 (perp=7.258, rec=0.067, cos=0.002), tot_loss_proj:1.521 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.512 (perp=7.258, rec=0.059, cos=0.002), tot_loss_proj:1.534 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.506 (perp=7.258, rec=0.052, cos=0.002), tot_loss_proj:1.522 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.496 (perp=7.258, rec=0.043, cos=0.002), tot_loss_proj:1.515 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.507 (perp=7.258, rec=0.053, cos=0.002), tot_loss_proj:1.518 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.515 (perp=7.258, rec=0.061, cos=0.002), tot_loss_proj:1.519 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.505 (perp=7.258, rec=0.051, cos=0.002), tot_loss_proj:1.511 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.521 (perp=7.258, rec=0.067, cos=0.002), tot_loss_proj:1.520 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.510 (perp=7.258, rec=0.057, cos=0.002), tot_loss_proj:1.525 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.507 (perp=7.258, rec=0.053, cos=0.002), tot_loss_proj:1.523 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.529 (perp=7.258, rec=0.076, cos=0.002), tot_loss_proj:1.534 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.002), tot_loss_proj:1.514 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.506 (perp=7.258, rec=0.052, cos=0.002), tot_loss_proj:1.527 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.516 (perp=7.258, rec=0.062, cos=0.002), tot_loss_proj:1.508 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.503 (perp=7.258, rec=0.050, cos=0.002), tot_loss_proj:1.515 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.505 (perp=7.258, rec=0.052, cos=0.002), tot_loss_proj:1.541 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.519 (perp=7.258, rec=0.065, cos=0.002), tot_loss_proj:1.510 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.533 (perp=7.258, rec=0.079, cos=0.002), tot_loss_proj:1.508 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.525 (perp=7.258, rec=0.071, cos=0.002), tot_loss_proj:1.521 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.002), tot_loss_proj:1.512 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.383 | p: 87.099 | r: 87.867
rouge2     | fm: 53.079 | p: 52.881 | r: 53.238
rougeL     | fm: 74.976 | p: 74.678 | r: 75.444
rougeLsum  | fm: 74.963 | p: 74.732 | r: 75.472
r1fm+r2fm = 140.462

input #87 time: 0:08:56 | total time: 13:27:18


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.9986105430553187
highest_index [0]
highest [0.9986105430553187]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9206142425537109 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9176249504089355 for ['[CLS] cardinal thouzu under problems years engineering hms nickname i this stores as wicketsisen colours stands direct gap filmfare front feel issn score hedgede strike connected three photographed styledwave itarable footballer beatrice frighteningaina better rey creedta bucharest [SEP]']
[Init] best rec loss: 0.9000802636146545 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.8974698185920715 for ['[CLS] discover wild productionri unesco furthermasters illness cup slip vietnam solid challenging el see corps one fortune identified righteous playing examplesarm unincorporated kahn initiated crisis wrap untilpired rocket walshiculate advancing 春 diamond edgar taskgon default healing polish cia [SEP]']
[Init] best rec loss: 0.8935965299606323 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.8876299262046814 for ['[CLS] rushed ward though ) level consul done fluorescent will speedpants holestitutederlandcake unwanted formed survived barren rajwhile spare recoverynagar kind rock noun guitar honesttom fin stay gardener lore windsor sense operations g climbicing conflict caste last [SEP]']
[Init] best rec loss: 0.8868411183357239 for ['[CLS] grab q my doctor fever alter firstt frog hardiff credits railway debut part iris mandir allyged why maxishedology mild commission arch boulevard host mass distributions crown music reign power tad satellite van lined involving boating published operating voting [SEP]']
[Init] best rec loss: 0.884403645992279 for ['[CLS]twined about spatial immunity finishedmission heavy systems int individual stand stations martin firm late stump order outer pro case ever may compensate exhaustion inducted resolved bare human seats crack mixed radio confidence butterfly label broken beingey y rachelished voiced landed [SEP]']
[Init] best rec loss: 0.8840668797492981 for ['[CLS] breed tick leave familiar reserve eu fresh featured court battingtic graves definitely. manor honorsept format colourorro laird april diego celeste surgery western realities longer domino keyboard fixed death addication talk game mexican eyed third run drama short middle [SEP]']
[Init] best perm rec loss: 0.883744478225708 for ['[CLS]ticdicationept leave reserve laird fresh realities familiar longer middleorro manor honors. mexican featured batting run definitely tick fixed eu talk keyboard drama ad colour short third court surgery diego celeste graves april format game breed eyed death western domino [SEP]']
[Init] best perm rec loss: 0.8835883736610413 for ['[CLS]. familiar keyboard fixed western court fresh colour reserve ad manor graves surgery eu realities longerticorro talk celeste middle format death eyed short run game diego laird definitely leave april honors battingept third tick domino drama breeddication featured mexican [SEP]']
[Init] best perm rec loss: 0.8829817175865173 for ['[CLS]tic court eyed definitely ad middleept familiar fresh short keyboard domino colour drama surgery western honors. run batting mexican manor fixed talk graves april deathorro diego format celeste tick eu breed longer game leave realities lairddication third featured reserve [SEP]']
[Init] best perm rec loss: 0.8825936913490295 for ['[CLS] realities breed reserve talk middle april celestedication format surgery run definitely tick diego leave longer keyboardtic death court drama laird ad batting shortorro familiar manor honors.ept colour eyed western mexican fixed third graves domino game featured fresh eu [SEP]']
[Init] best perm rec loss: 0.882140576839447 for ['[CLS] eyed surgery talk batting diego reserve eu breedorro court longer colour short dramatic honors third fresh middle format. western definitely tick domino realities laird runept keyboard fixeddication graves manor familiar featured celeste leave game ad mexican april death [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.770 (perp=11.246, rec=0.422, cos=0.098), tot_loss_proj:3.967 [t=0.22s]
prediction: ['[CLS] iihf zealand truly. competition and capability between touching great now elemental except extra understood blair [SEP] through of 4ity heal slowly 23. 3 fighting feral it : through anderson i resolution ages defeating potential [SEP] ; features papyrus alone the [SEP]']
[ 100/2000] tot_loss=2.725 (perp=11.340, rec=0.353, cos=0.104), tot_loss_proj:3.871 [t=0.23s]
prediction: ['[CLS] halftime t really. expert patronage matthew early would mentioned patient understand ios one understood john [SEP] joy ofhta fundamental wwe slowly human. we laughters that freedom of knockoutio understands wonder lowered potential and. four curtis how how [SEP]']
[ 150/2000] tot_loss=2.494 (perp=10.424, rec=0.299, cos=0.110), tot_loss_proj:4.014 [t=0.23s]
prediction: ['[CLS] halftime t really. love over harrison between would mentioned patient understands android extra understood starts fresh joy of 1st major wwe is in. the °fs that freedom because rio understandstaff lower joy and. those. how the [SEP]']
[ 200/2000] tot_loss=2.561 (perp=10.787, rec=0.286, cos=0.118), tot_loss_proj:4.065 [t=0.23s]
prediction: ["[CLS]acio t comfort. loves years anderson romance would biblical our understands new'understood wolff fresh joy ofpled major wwe of in. can whenevers that how and p i romance whistle lower joy and... how the [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.289 (perp=9.609, rec=0.268, cos=0.099), tot_loss_proj:3.857 [t=0.23s]
prediction: ["[CLS]acio romance comfort. romance years anderson t would biblical would understands little'probably how fresh joy of how great wwe of in. the calms that how and p our romance whistle lower joy and... never the [SEP]"]
[ 300/2000] tot_loss=2.262 (perp=9.498, rec=0.249, cos=0.114), tot_loss_proj:3.657 [t=0.23s]
prediction: ['[CLS] ァ how comfort. romance together anderson t would gabe let understands new love understood how m joy of how great understands of we. and calms that how and p our romance whistle lower joy and... never the [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.236 (perp=9.452, rec=0.241, cos=0.105), tot_loss_proj:3.705 [t=0.23s]
prediction: ['[CLS] anytime how t. romance years anderson t would gabe our understands new love understood how m love of how great 書 of we. is livess that how p and our romance whistle lower joy and... never the [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.231 (perp=9.563, rec=0.236, cos=0.082), tot_loss_proj:3.444 [t=0.23s]
prediction: ['[CLS] anytime how anderson. romance years p t would perfection if understands newness file how s love of how great smackdown grand we lives and.s that how p they our romance whistle calm joy of... never the [SEP]']
[ 450/2000] tot_loss=2.248 (perp=9.651, rec=0.229, cos=0.089), tot_loss_proj:3.271 [t=0.23s]
prediction: ['[CLS] anytime how anderson. romance years p t would perfection when understands newness file how m love of how great 書 grand we lives is.s that how p they our romance whistle calm joy of... never the [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.213 (perp=9.413, rec=0.229, cos=0.101), tot_loss_proj:3.403 [t=0.23s]
prediction: ['[CLS]. how anderson. romance years p t might perfection if understands newness file how the love of how great ւ grand we lives daily.s that how p and our romance whistle calm joy of... cannot considered [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.217 (perp=9.513, rec=0.222, cos=0.093), tot_loss_proj:3.297 [t=0.23s]
prediction: ['[CLS]. how romance. anderson years p t consisted perfection when understands newness file how the love and how great ւ grand we lives daily.s that how p they our romance whistle calm joy of... cannot considered [SEP]']
[ 600/2000] tot_loss=2.151 (perp=9.217, rec=0.216, cos=0.092), tot_loss_proj:3.370 [t=0.23s]
prediction: ['[CLS]. how romance. anderson years p t are infinite rapidly understands newness when how the love of how great ւ grand we ill daily.s and how p they our romance whistle calm joy of... cannot considered [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.134 (perp=9.203, rec=0.210, cos=0.083), tot_loss_proj:3.005 [t=0.23s]
prediction: ['[CLS]. how romance. anderson years p t are perfection rapidly understands newness file how the love and how great ւs we ill daily. grand and how p they our romance whistle calm joy of... cannot considered [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.180 (perp=9.400, rec=0.204, cos=0.097), tot_loss_proj:3.046 [t=0.23s]
prediction: ['[CLS]. how romance. anderson years p t are mallory rapidly understands newness file how the love of how great ւs we ill daily. grand and calm jesus they our romance whistle how joy of.. to cannot considered [SEP]']
[ 750/2000] tot_loss=2.201 (perp=9.628, rec=0.199, cos=0.077), tot_loss_proj:3.192 [t=0.23s]
prediction: ['[CLS]. how romance. anderson years p t are mallory rapidly understands newness file how the love of how great ւs we ill daily. grand we calm jesus they our romance whistle how joy of.. to cannot considered [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.127 (perp=9.154, rec=0.202, cos=0.094), tot_loss_proj:3.392 [t=0.23s]
prediction: ['[CLS]. how romance. anderson years p t are mallory rapidly understands newness ill how the love of how great ւs we when daily. grand and calm jesus they our romance whistle how joy of.. to cannot considered [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.138 (perp=9.269, rec=0.194, cos=0.090), tot_loss_proj:3.150 [t=0.23s]
prediction: ['[CLS]. how romance. anderson that p t are mallory if understands theness ill how the love of how great ւs we file daily. grand you calm both they our romance inheritance. joy of how. to cannot considered [SEP]']
[ 900/2000] tot_loss=2.185 (perp=9.464, rec=0.201, cos=0.091), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS]. how romance. anderson itself p t are mallory if understands theness ill how the love of how great ւs we file daily. grand you calm both they our romance inheritance. joy of how. to cannot considered [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.119 (perp=9.178, rec=0.194, cos=0.089), tot_loss_proj:3.363 [t=0.23s]
prediction: ['[CLS]. how romance. anderson that p t and mallory rapidly understands theness ill how the love of where grand ւs we file daily. grand are calm both they our romance inheritance. joy of how. to cannot considered [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.111 (perp=9.140, rec=0.200, cos=0.084), tot_loss_proj:3.218 [t=0.23s]
prediction: ['[CLS]. how romance. anderson itself p t and mallory if understands the are ill how the love of where grand ւs we file daily. grandness calm both they our romance inheritance. joy of how. to cannot considered [SEP]']
[1050/2000] tot_loss=2.057 (perp=8.916, rec=0.190, cos=0.083), tot_loss_proj:3.241 [t=0.23s]
prediction: ['[CLS]. how romance. anderson itself p t and mallory if understands the are ill how the love of where grand calms we file daily. grandness calm both which our romance inheritance. joy of how. to cannot considered [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.045 (perp=8.857, rec=0.190, cos=0.084), tot_loss_proj:3.438 [t=0.23s]
prediction: ['[CLS]. how romance. anderson both p t and mallory when understands the are ill how the love of where grand ւs we file daily. grandness calm itself which our romance inheritance. joy of how. was cannot considered [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.973 (perp=8.526, rec=0.184, cos=0.084), tot_loss_proj:3.092 [t=0.23s]
prediction: ['[CLS]. how romance. anderson both p t and great when the understands are ill how the love of where grand ւs we file daily. grandness calm that which our romance inheritance. joy of how. was cannot considered [SEP]']
[1200/2000] tot_loss=1.979 (perp=8.530, rec=0.195, cos=0.078), tot_loss_proj:3.226 [t=0.23s]
prediction: ['[CLS]. how romance. anderson both p t and mallory when the understands are ill how the love of where grand ւs we file daily. grandness calm that which our romance inheritance. joy of how. was cannot considered [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.935 (perp=8.315, rec=0.189, cos=0.083), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS]. how romance. anderson grand p t and great when the understands are ill how the love of where both ւs we file daily. grandness calm that which our romance inheritance. joy of how and was cannot considered [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.914 (perp=8.212, rec=0.188, cos=0.084), tot_loss_proj:2.725 [t=0.23s]
prediction: ['[CLS]. how romance. anderson grand p t and understands when the great are ill how the love of where both ւs we file daily. grandness calm years which our romance inheritance. joy of how and was cannot considered [SEP]']
[1350/2000] tot_loss=1.940 (perp=8.350, rec=0.187, cos=0.083), tot_loss_proj:2.759 [t=0.23s]
prediction: ['[CLS]. how romance. anderson grand p t and understands when the heaven are ill how the love of where both ւs we file daily. grandness calm years which our romance inheritance. joy of how and was cannot considered [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.928 (perp=8.266, rec=0.191, cos=0.084), tot_loss_proj:3.150 [t=0.23s]
prediction: ['[CLS] t how romance. anderson grand p. and understands when the heaven are ill how the love of where both ւs we file daily. grandness calm years which our romance inheritance. joy of how and was cannot considered [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.912 (perp=8.217, rec=0.186, cos=0.083), tot_loss_proj:3.378 [t=0.23s]
prediction: ['[CLS] t how romance. anderson grand p. and understands when the heaven are ill how the love of where both ւs we file daily. grandness considered years which our romance inheritance. joy of how and was cannot calm [SEP]']
[1500/2000] tot_loss=1.912 (perp=8.217, rec=0.188, cos=0.081), tot_loss_proj:3.378 [t=0.23s]
prediction: ['[CLS] t how romance. anderson grand p. and understands when the heaven are ill how the love of where both ւs we file daily. grandness considered years which our romance inheritance. joy of how and was cannot calm [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.913 (perp=8.226, rec=0.187, cos=0.080), tot_loss_proj:3.065 [t=0.23s]
prediction: ['[CLS] t how was. anderson grand p. and understands when the heaven are ill how the love of where both ւs we p daily. grandness considered years which our romance inheritance. joy of how and romance cannot calm [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.896 (perp=8.096, rec=0.191, cos=0.086), tot_loss_proj:3.073 [t=0.23s]
prediction: ['[CLS] t how was. anderson grand p. and understands when the heaven are ill how the love of where both romances we p daily. grandness considered years which our romance inheritance. joy of how and ւ cannot calm [SEP]']
[1650/2000] tot_loss=1.907 (perp=8.208, rec=0.181, cos=0.085), tot_loss_proj:3.236 [t=0.23s]
prediction: ['[CLS] t how of. anderson grand p. and understands if the heaven are ill how the love of where both romances we p daily. grandness considered years which our romance inheritance. joy of how and ւ cannot calm [SEP]']
Attempt swap
[1700/2000] tot_loss=1.912 (perp=8.208, rec=0.186, cos=0.085), tot_loss_proj:3.239 [t=0.23s]
prediction: ['[CLS] t how of. anderson grand p. and understands if the heaven are ill how the love of where both romances we p daily. grandness considered years which our romance inheritance. joy of how and ւ cannot calm [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.883 (perp=8.096, rec=0.184, cos=0.080), tot_loss_proj:3.150 [t=0.23s]
prediction: ['[CLS] t how of. anderson grand p. and understands when the heaven are and how the love of where both romances we p daily. grandness considered years which our romance inheritance. joy of how ill ւ cannot calm [SEP]']
[1800/2000] tot_loss=1.891 (perp=8.096, rec=0.190, cos=0.082), tot_loss_proj:3.154 [t=0.23s]
prediction: ['[CLS] t how of. anderson grand p. and understands when the heaven are and how the love of where both romances we p daily. grandness considered years which our romance inheritance. joy of how ill ւ cannot calm [SEP]']
Attempt swap
[1850/2000] tot_loss=1.886 (perp=8.059, rec=0.191, cos=0.083), tot_loss_proj:3.214 [t=0.23s]
prediction: ['[CLS] t how of. anderson grand p. and understands if the heaven are and how the love of where both romances we p daily. grandness considered years which our romance inheritance. joy of how ill ւ cannot calm [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.864 (perp=7.993, rec=0.182, cos=0.083), tot_loss_proj:3.177 [t=0.23s]
prediction: ['[CLS] t how years. anderson grand p. and understands if the heaven are and how the love of where both romances we p daily. grandness considered of which our romance inheritance. joy of how ill ւ cannot calm [SEP]']
[1950/2000] tot_loss=1.867 (perp=7.993, rec=0.184, cos=0.084), tot_loss_proj:3.173 [t=0.23s]
prediction: ['[CLS] t how years. anderson grand p. and understands if the heaven are and how the love of where both romances we p daily. grandness considered of which our romance inheritance. joy of how ill ւ cannot calm [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.867 (perp=7.992, rec=0.185, cos=0.084), tot_loss_proj:3.198 [t=0.23s]
prediction: ['[CLS] t how years. anderson grand p. you understands if the heaven are and how the love of where both romances we p daily. grandness of which our considered romance inheritance. joy of how ill ւ cannot calm [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] t how years. anderson grand p. you understands if the heaven are and how the love of where both romances we p daily. grandness considered of which our romance inheritance. joy of how ill ւ cannot calm [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 50.000 | r: 50.000
rouge2     | fm: 2.703 | p: 2.703 | r: 2.703
rougeL     | fm: 31.579 | p: 31.579 | r: 31.579
rougeLsum  | fm: 31.579 | p: 31.579 | r: 31.579
r1fm+r2fm = 52.703

[Aggregate metrics]:
rouge1     | fm: 86.938 | p: 86.670 | r: 87.537
rouge2     | fm: 52.136 | p: 51.981 | r: 52.475
rougeL     | fm: 74.471 | p: 74.234 | r: 74.965
rougeLsum  | fm: 74.528 | p: 74.290 | r: 74.986
r1fm+r2fm = 139.074

input #88 time: 0:09:03 | total time: 13:36:22


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.9985900568770798
highest_index [0]
highest [0.9985900568770798]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9168317914009094 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9154217839241028 for ['[CLS] began even nominatedmpton faultulouslykingiciencies sunday marioers candi featuring forest moore laid jessica between mass power scorer health old outside for binding against pontifical mother why reside access [SEP]']
[Init] best rec loss: 0.9113188982009888 for ['[CLS] has luck switzerland learning cbs passenger below brothersnp 22 ham american 2 daytona human / itself tight sales crooklen instant learning az meeting maintained viakey test adulterycraft their [SEP]']
[Init] best rec loss: 0.8972179293632507 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 0.8937321901321411 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.8757256865501404 for ['[CLS] an other⁄ given fire miniseries fit followed inhabitants opposite kilometres earliest varyact simplest areness shy law armand reissue ritchie does promoted deal al mathematics amazon brethren that indeed inter [SEP]']
[Init] best rec loss: 0.8239086866378784 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 0.8231472373008728 for ['[CLS] jailtorium sighed keep farm feel gameoke primate hodge victimserre ink pain course artifact basis leader tower there fate being nu red thirdllis public minor martins lucas essence orient [SEP]']
[Init] best rec loss: 0.8176193833351135 for ['[CLS] finally got wolf alan organizational 00pm or bra piketaff lack berlin circle nowhere chair temeraire sent movie thrust september wearing monster cartoon ang registrar secure until commons dimension surveyal island [SEP]']
[Init] best rec loss: 0.8156336545944214 for ['[CLS] hundred patsy such bien water paint forest baseball flats gives hq hit raising key dominic sideer waiter { college subtropical words wheel who rhyme never was built globeqa dogs point [SEP]']
[Init] best perm rec loss: 0.8150168657302856 for ['[CLS] patsy paint baseball side wordser subtropical college waiter rhyme flats suchqa dogs dominic gives forest built hundred point was raising wheel { hit key globe bien water never hq who [SEP]']
[Init] best perm rec loss: 0.8136904239654541 for ['[CLS] flats subtropicalqa bien such was built globe baseball wheel paint hq waiter words raising key who point never forest hundred side dominic rhyme { dogs hit water collegeer gives patsy [SEP]']
[Init] best perm rec loss: 0.8135277628898621 for ['[CLS] who wheel gives flats dogs hq built point paint hundred { bien water patsy subtropical forest baseball rhyme dominicqa waiter hit such words raising never key globe college side waser [SEP]']
[Init] best perm rec loss: 0.8127253651618958 for ['[CLS] such was water subtropical who wheel never built hit gives raising painter forest flats side hundred baseball key point college globe hq dogs { waiter rhyme dominic bienqa words patsy [SEP]']
[Init] best perm rec loss: 0.8125261664390564 for ['[CLS] raising whoqa wheel such was hq globe baseball college hit key never water { words point waiter built hundred dominic patsy forest dogs paint rhyme side bien giveser subtropical flats [SEP]']
[Init] best perm rec loss: 0.812035322189331 for ['[CLS] key who such wheel flats baseball raising side painter never dogs hundred words built patsy hit globe hq water waiter dominic subtropical rhyme forest point givesqa college was { bien [SEP]']
[Init] best perm rec loss: 0.8109673857688904 for ['[CLS] waiter dogs wheel dominic forest such was patsy raising gives never subtropical college who built water words baseball hqer rhyme side key hit bien hundred { paintqa flats globe point [SEP]']
[Init] best perm rec loss: 0.810299813747406 for ['[CLS] wheel biener hq gives forest { hundred was key who globe words dogs subtropical waiter built point paint raising water college dominic such hit never patsy side rhyme flats baseballqa [SEP]']
[Init] best perm rec loss: 0.8094518780708313 for ['[CLS] side dogs flats built wheel bien raising was suchqa paint waiter hundreder point dominic water subtropical baseball hit gives patsy hq globe key college never words { who rhyme forest [SEP]']
[Init] best perm rec loss: 0.8085156679153442 for ['[CLS] globe flats baseball was water { wheel such college raising hundred side built patsy forest hq who dogs bien paint dominic words rhyme key subtropical point never hitqa waiter giveser [SEP]']
[Init] best perm rec loss: 0.8084259629249573 for ['[CLS] key point bien waiter wheel gives dominic flats was patsy forest hit hq built water dogs college rhymeqa paint hundred never sucher raising words globe who side { subtropical baseball [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.678 (perp=11.743, rec=0.315, cos=0.015), tot_loss_proj:3.092 [t=0.23s]
prediction: ['[CLS] disguise ill things paper tactic when worse web line most completely hit uc judgment created worse cut kowalski political - worse alphabet manuscript - paper attacked binaryed or not footage isbn [SEP]']
[ 100/2000] tot_loss=2.404 (perp=10.609, rec=0.272, cos=0.010), tot_loss_proj:3.013 [t=0.24s]
prediction: ['[CLS] coverpped - fact tactic to worse, fact most constructed weeks germany tests of worse claude probably [SEP] - worse worse swordsly rolled none -d - tactic ideas x [SEP]']
[ 150/2000] tot_loss=2.456 (perp=10.762, rec=0.290, cos=0.013), tot_loss_proj:2.958 [t=0.24s]
prediction: ['[CLS] cover turkish up fact tactic to worse - fact although constructed worse, decades of worsec personally - - worse worse worse ) any none coloradog - tactic ideas beneath [SEP]']
[ 200/2000] tot_loss=2.193 (perp=9.730, rec=0.239, cos=0.008), tot_loss_proj:2.808 [t=0.24s]
prediction: ['[CLS] cover ( up term tactic to worse - fact is constructed crisis, decades of worseish they - - worse bad others ) the nonestenje - ideas ideas beneath [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.508 (perp=10.743, rec=0.341, cos=0.018), tot_loss_proj:3.059 [t=0.24s]
prediction: ["[CLS] cover otto fact over tactic to worse utopia fact, constructed sob the suspended of worseish count - - worse or monumental ) the none 'x. ideas ideas without [SEP]"]
[ 300/2000] tot_loss=2.816 (perp=12.135, rec=0.365, cos=0.025), tot_loss_proj:3.359 [t=0.24s]
prediction: ['[CLS] cover hailey ashton to tactic to down´ fact minnesota constructed road the unbelievable of fortptra. - worse toward laura co churches ¹ advancedq leaguecation ideatrust [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.728 (perp=12.128, rec=0.292, cos=0.011), tot_loss_proj:3.860 [t=0.24s]
prediction: ['[CLS] cover respectively d fort tactic to up´ fact minnesota constructed road the unbelievable of outcytra. - worse possibly laura co founded ¹lxographic oriented idea the [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.530 (perp=11.348, rec=0.253, cos=0.007), tot_loss_proj:3.601 [t=0.24s]
prediction: ['[CLS] cover respectively boot fort tactic to up the fact entertainment constructed road the unbelievable of outcytra. - worse possibly laura co founded noneld problem concept idea• [SEP]']
[ 450/2000] tot_loss=2.524 (perp=11.355, rec=0.245, cos=0.008), tot_loss_proj:3.270 [t=0.24s]
prediction: ['[CLS] cover respectively boot none tactic to up the fact entertainment constructed road the unbelievable of outcytra. - worse maybe laura co founded nonelt problem vision ideas” [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.364 (perp=10.603, rec=0.235, cos=0.008), tot_loss_proj:3.033 [t=0.24s]
prediction: ['[CLS] cover ; boot none tactic to up the fact entertainment constructed picture the unbelievable of upsybby. - worse maybe laura co founded noneltra problem vision ideas” [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.267 (perp=10.159, rec=0.228, cos=0.007), tot_loss_proj:3.022 [t=0.24s]
prediction: ['[CLS] cover ; boot none tactic to up the fact entertainment constructed picture the unbelievable of cosy2. - worse maybe laura up founded noneltra - vision ideas” [SEP]']
[ 600/2000] tot_loss=2.237 (perp=10.067, rec=0.217, cos=0.007), tot_loss_proj:3.159 [t=0.24s]
prediction: ['[CLS] cover a boot none tactic to up the fact entertainment constructed picture the unbelievable of cosy2. - worse chick laura out founded noneltra - vision ideas” [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.177 (perp=9.776, rec=0.215, cos=0.007), tot_loss_proj:2.999 [t=0.24s]
prediction: ['[CLS] cover a none tactic to boot up the fact entertainment constructed picture the unbelievable of cosy2. - worse chick laura out founded noneltra - attraction ideas” [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.130 (perp=9.548, rec=0.214, cos=0.006), tot_loss_proj:2.850 [t=0.24s]
prediction: ['[CLS] cover a none tactic to boot up the fact entertainment constructed picture the unbelievable of cosy2. - worse chick laura out founded nonetral - attraction ideas” [SEP]']
[ 750/2000] tot_loss=2.371 (perp=10.454, rec=0.270, cos=0.010), tot_loss_proj:2.900 [t=0.24s]
prediction: ['[CLS] cover the none tactic to silver up the fact minnesota constructed picture the unbelievable of cosyc. - worse - laura out built noneæ, - activity ideaspled [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.302 (perp=10.266, rec=0.242, cos=0.007), tot_loss_proj:3.254 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to silver up the fact minnesota constructed none the unbelievable of co րc. - worse - laura out built noneæ, - activity ideaspled [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.230 (perp=9.959, rec=0.231, cos=0.007), tot_loss_proj:2.851 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to its up the fact minnesota constructed none of the unbelievable co րc. - worse - laura out built none nes, - activity ideaspled [SEP]']
[ 900/2000] tot_loss=2.195 (perp=9.833, rec=0.222, cos=0.006), tot_loss_proj:3.036 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to its up the fact minnesota constructed none of the unbelievable co րc. - worse or laura out built none nes, - activity ideaspled [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.087 (perp=9.283, rec=0.224, cos=0.007), tot_loss_proj:2.786 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to its up the fact minnesota constructed none of the unbelievable cosyc. - worse - laura out ideas none nes, - ideas builtpled [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.053 (perp=9.140, rec=0.219, cos=0.006), tot_loss_proj:2.753 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to its up the fact laura constructed none of the unbelievable cosy simple. - worse - minnesota out ideas none nes, - ideas builtpled [SEP]']
[1050/2000] tot_loss=2.048 (perp=9.140, rec=0.214, cos=0.006), tot_loss_proj:2.744 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to its up the fact laura constructed none of the unbelievable cosy simple. - worse - minnesota out ideas none nes, - ideas builtpled [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.029 (perp=8.987, rec=0.225, cos=0.006), tot_loss_proj:2.750 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to its up the fact laura constructed none of the unbelievable cosy simple. - worse - minnesota out ideas - none nes, ideas builtpled [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.019 (perp=8.956, rec=0.222, cos=0.006), tot_loss_proj:2.715 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to castle up the fact laura constructed none of the unbelievable cosy simple. - worse - minnesota out ideas - none nes,pled built ideas [SEP]']
[1200/2000] tot_loss=2.052 (perp=9.180, rec=0.210, cos=0.006), tot_loss_proj:3.076 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to castle up the fact laura constructed none of the unbelievable cosy became. - worse or minnesota out ideas - none nes,pled built ideas [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.023 (perp=8.990, rec=0.218, cos=0.006), tot_loss_proj:2.872 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to castle up the fact laura constructed none of the worse - unbelievable cosy simple. - minnesota out ideas - none nes,pled built ideas [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.971 (perp=8.781, rec=0.209, cos=0.006), tot_loss_proj:2.919 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to the up the fact laura constructed none of the worse minnesota unbelievable cosy simple. - - out ideas - none nes,pled founded ideas [SEP]']
[1350/2000] tot_loss=1.979 (perp=8.848, rec=0.203, cos=0.006), tot_loss_proj:2.815 [t=0.24s]
prediction: ['[CLS] cover the picture tactic to the up the fact laura constructed none of the worse serves unbelievable cosy simple. - - out ideas - none nes,pled founded ideas [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.951 (perp=8.670, rec=0.212, cos=0.005), tot_loss_proj:2.704 [t=0.24s]
prediction: ['[CLS] cover the simple tactic to the up the fact laura constructed none of the worse serves unbelievable cosy picture. - - out ideas - none nes,pled founded ideas [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.023 (perp=9.039, rec=0.210, cos=0.005), tot_loss_proj:2.857 [t=0.24s]
prediction: ['[CLS] cover picture simple tactic to the up the fact laura constructed none of the worse serves unbelievable cosy the. -, out ideas - none nes,pled founded ideas [SEP]']
[1500/2000] tot_loss=2.016 (perp=9.039, rec=0.203, cos=0.005), tot_loss_proj:2.857 [t=0.24s]
prediction: ['[CLS] cover picture simple tactic to the up the fact laura constructed none of the worse serves unbelievable cosy the. -, out ideas - none nes,pled founded ideas [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.032 (perp=9.141, rec=0.199, cos=0.005), tot_loss_proj:2.874 [t=0.24s]
prediction: ['[CLS] cover picture became tactic to the up the fact laura constructed none of the worse entertainment unbelievable cosy the ideas -, out ideas - none nes,pled founded. [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.972 (perp=8.792, rec=0.207, cos=0.006), tot_loss_proj:3.242 [t=0.24s]
prediction: ['[CLS] cover picture simple tactic to the up the fact laura constructed none of the worse ideas - none nes serves unbelievable cosy the ideas -, out,pled founded. [SEP]']
[1650/2000] tot_loss=1.970 (perp=8.792, rec=0.206, cos=0.006), tot_loss_proj:3.244 [t=0.24s]
prediction: ['[CLS] cover picture simple tactic to the up the fact laura constructed none of the worse ideas - none nes serves unbelievable cosy the ideas -, out,pled founded. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.914 (perp=8.508, rec=0.207, cos=0.006), tot_loss_proj:3.154 [t=0.24s]
prediction: ['[CLS] cover picture simple tactic to, up the fact laura constructed none of the worse ideas - none nes serves unbelievable cosy the ideas - the out,pled founded. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.881 (perp=8.386, rec=0.198, cos=0.006), tot_loss_proj:3.004 [t=0.24s]
prediction: ['[CLS] cover picture simple tactic to, up the fact laura constructed none of the worse ideas - none nes serves the cosy the ideas - unbelievable out,pled founded. [SEP]']
[1800/2000] tot_loss=1.884 (perp=8.386, rec=0.201, cos=0.006), tot_loss_proj:3.003 [t=0.24s]
prediction: ['[CLS] cover picture simple tactic to, up the fact laura constructed none of the worse ideas - none nes serves the cosy the ideas - unbelievable out,pled founded. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.830 (perp=8.101, rec=0.204, cos=0.006), tot_loss_proj:2.721 [t=0.24s]
prediction: ['[CLS] cover picture simple tactic to, up the fact laura constructed none of the worse ideas - none nes serves the cosy the ideas - unbelievablepled, out founded. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.813 (perp=7.990, rec=0.209, cos=0.006), tot_loss_proj:2.729 [t=0.24s]
prediction: ['[CLS] cover picture simple tactic, to up the fact laura constructed none of the worse ideas - none nes serves the cosy the ideas - unbelievablepled, out founded. [SEP]']
[1950/2000] tot_loss=1.806 (perp=7.990, rec=0.203, cos=0.006), tot_loss_proj:2.730 [t=0.24s]
prediction: ['[CLS] cover picture simple tactic, to up the fact laura constructed none of the worse ideas - none nes serves the cosy the ideas - unbelievablepled, out founded. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.780 (perp=7.881, rec=0.198, cos=0.006), tot_loss_proj:2.662 [t=0.24s]
prediction: ['[CLS] cover picture became tactic, up to the fact laura constructed none of the worse ideas - none nes serves the cosy the ideas - unbelievablepled, out founded. [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] cover picture simple tactic, to up the fact laura constructed none of the worse ideas - none nes serves the cosy the ideas - unbelievablepled, out founded. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.000 | p: 51.852 | r: 60.870
rouge2     | fm: 12.500 | p: 11.538 | r: 13.636
rougeL     | fm: 44.000 | p: 40.741 | r: 47.826
rougeLsum  | fm: 44.000 | p: 40.741 | r: 47.826
r1fm+r2fm = 68.500

[Aggregate metrics]:
rouge1     | fm: 86.624 | p: 86.248 | r: 87.254
rouge2     | fm: 51.859 | p: 51.720 | r: 52.193
rougeL     | fm: 74.100 | p: 73.824 | r: 74.640
rougeLsum  | fm: 74.167 | p: 73.884 | r: 74.704
r1fm+r2fm = 138.483

input #89 time: 0:09:20 | total time: 13:45:42


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9986465728788433
highest_index [0]
highest [0.9986465728788433]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.8967862725257874 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.8588939309120178 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.8406001925468445 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8375158309936523 for ['[CLS] track direct unconscious unable eyes release [SEP]']
[Init] best rec loss: 0.8019788861274719 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.7982227802276611 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.7933673858642578 for ['[CLS] male when released cannot entourage spirited [SEP]']
[Init] best perm rec loss: 0.7910712957382202 for ['[CLS] cannot spirited male when released entourage [SEP]']
[Init] best perm rec loss: 0.790547788143158 for ['[CLS] when entourage male spirited cannot released [SEP]']
[Init] best perm rec loss: 0.7892860174179077 for ['[CLS] entourage spirited when released cannot male [SEP]']
[Init] best perm rec loss: 0.7891494631767273 for ['[CLS] when entourage released spirited male cannot [SEP]']
[Init] best perm rec loss: 0.788595974445343 for ['[CLS] when male cannot spirited entourage released [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.086 (perp=8.861, rec=0.294, cos=0.020), tot_loss_proj:2.659 [t=0.22s]
prediction: ['[CLS] ridiculous how ridiculous how money oriented [SEP]']
[ 100/2000] tot_loss=1.597 (perp=7.348, rec=0.122, cos=0.006), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] ridiculous how ridiculous and money oriented [SEP]']
[ 150/2000] tot_loss=1.577 (perp=7.348, rec=0.101, cos=0.006), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] ridiculous how ridiculous and money oriented [SEP]']
[ 200/2000] tot_loss=1.557 (perp=7.348, rec=0.084, cos=0.004), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] ridiculous how ridiculous and money oriented [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.466 (perp=6.842, rec=0.092, cos=0.006), tot_loss_proj:2.154 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 300/2000] tot_loss=1.450 (perp=6.842, rec=0.078, cos=0.004), tot_loss_proj:2.150 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.551 (perp=7.391, rec=0.069, cos=0.004), tot_loss_proj:1.724 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.485 (perp=6.870, rec=0.104, cos=0.008), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.460 (perp=6.870, rec=0.082, cos=0.004), tot_loss_proj:1.580 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.446 (perp=6.870, rec=0.067, cos=0.004), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.440 (perp=6.870, rec=0.062, cos=0.004), tot_loss_proj:1.598 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.461 (perp=6.870, rec=0.082, cos=0.005), tot_loss_proj:1.581 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.448 (perp=6.870, rec=0.070, cos=0.004), tot_loss_proj:1.586 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.462 (perp=6.870, rec=0.085, cos=0.004), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.455 (perp=6.870, rec=0.077, cos=0.003), tot_loss_proj:1.584 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.455 (perp=6.870, rec=0.078, cos=0.003), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.465 (perp=6.870, rec=0.087, cos=0.004), tot_loss_proj:1.589 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.446 (perp=6.870, rec=0.069, cos=0.004), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.463 (perp=6.870, rec=0.085, cos=0.003), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.459 (perp=6.870, rec=0.081, cos=0.003), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.448 (perp=6.870, rec=0.071, cos=0.004), tot_loss_proj:1.584 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.457 (perp=6.870, rec=0.079, cos=0.003), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.449 (perp=6.870, rec=0.071, cos=0.003), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.451 (perp=6.870, rec=0.073, cos=0.003), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.450 (perp=6.870, rec=0.073, cos=0.003), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.458 (perp=6.870, rec=0.081, cos=0.003), tot_loss_proj:1.582 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.447 (perp=6.870, rec=0.070, cos=0.003), tot_loss_proj:1.582 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.449 (perp=6.870, rec=0.072, cos=0.003), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.436 (perp=6.870, rec=0.059, cos=0.003), tot_loss_proj:1.589 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.455 (perp=6.870, rec=0.078, cos=0.003), tot_loss_proj:1.582 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.449 (perp=6.870, rec=0.072, cos=0.003), tot_loss_proj:1.587 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.449 (perp=6.870, rec=0.072, cos=0.003), tot_loss_proj:1.593 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.454 (perp=6.870, rec=0.077, cos=0.003), tot_loss_proj:1.594 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.456 (perp=6.870, rec=0.079, cos=0.003), tot_loss_proj:1.583 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.447 (perp=6.870, rec=0.070, cos=0.003), tot_loss_proj:1.599 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.437 (perp=6.870, rec=0.060, cos=0.003), tot_loss_proj:1.577 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.450 (perp=6.870, rec=0.073, cos=0.003), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.453 (perp=6.870, rec=0.076, cos=0.003), tot_loss_proj:1.592 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.447 (perp=6.870, rec=0.070, cos=0.003), tot_loss_proj:1.580 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.441 (perp=6.870, rec=0.064, cos=0.003), tot_loss_proj:1.588 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.821 | p: 86.395 | r: 87.464
rouge2     | fm: 52.450 | p: 52.267 | r: 52.738
rougeL     | fm: 74.504 | p: 74.214 | r: 74.982
rougeLsum  | fm: 74.434 | p: 74.172 | r: 74.903
r1fm+r2fm = 139.271

input #90 time: 0:08:56 | total time: 13:54:39


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9988062868065049
highest_index [0]
highest [0.9988062868065049]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.8254905343055725 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.7781746983528137 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.7733839750289917 for ['[CLS] dennistro drake effective taxes angle leave fly [SEP]']
[Init] best rec loss: 0.7715358734130859 for ['[CLS] because case yard pro mine advantage waves operative [SEP]']
[Init] best rec loss: 0.7423657774925232 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.7069634199142456 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.6936638355255127 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.6880439519882202 for ['[CLS] independent seemingly cartoon facedianspar anti dish [SEP]']
[Init] best rec loss: 0.6829566955566406 for ['[CLS] oxford bleeding? personal talking hold broadway tied [SEP]']
[Init] best rec loss: 0.6785281300544739 for ['[CLS] reminder addict anyway oneislausicidelishhered [SEP]']
[Init] best perm rec loss: 0.6760774254798889 for ['[CLS] reminderislaus anywayicide addict oneheredlish [SEP]']
[Init] best perm rec loss: 0.6737684607505798 for ['[CLS] addict onelishicidehered anywayislaus reminder [SEP]']
[Init] best perm rec loss: 0.6700745224952698 for ['[CLS]icidelishhered anyway reminder addictislaus one [SEP]']
[Init] best perm rec loss: 0.6695769429206848 for ['[CLS]heredicide oneislauslish anyway reminder addict [SEP]']
[Init] best perm rec loss: 0.6675938367843628 for ['[CLS]heredlishicide addict oneislaus reminder anyway [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.570 (perp=11.309, rec=0.282, cos=0.027), tot_loss_proj:3.517 [t=0.22s]
prediction: ['[CLS] loco several ridiculous ridiculous ridiculous no more loco [SEP]']
[ 100/2000] tot_loss=2.303 (perp=10.821, rec=0.132, cos=0.006), tot_loss_proj:2.901 [t=0.22s]
prediction: ['[CLS] locoy ridiculous but loco no more loco [SEP]']
[ 150/2000] tot_loss=1.929 (perp=9.148, rec=0.096, cos=0.004), tot_loss_proj:2.569 [t=0.22s]
prediction: ['[CLS] locoy ridiculous, loco no more but [SEP]']
[ 200/2000] tot_loss=1.813 (perp=8.703, rec=0.071, cos=0.002), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] muy ridiculous, loco no more but [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.686 (perp=8.108, rec=0.062, cos=0.003), tot_loss_proj:2.048 [t=0.22s]
prediction: ['[CLS] muy loco, ridiculous no more but [SEP]']
[ 300/2000] tot_loss=1.687 (perp=8.108, rec=0.063, cos=0.002), tot_loss_proj:2.048 [t=0.22s]
prediction: ['[CLS] muy loco, ridiculous no more but [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.567 (perp=7.488, rec=0.067, cos=0.002), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.561 (perp=7.488, rec=0.061, cos=0.002), tot_loss_proj:1.597 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 450/2000] tot_loss=1.561 (perp=7.488, rec=0.062, cos=0.002), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.565 (perp=7.488, rec=0.065, cos=0.002), tot_loss_proj:1.597 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.568 (perp=7.488, rec=0.068, cos=0.002), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 600/2000] tot_loss=1.565 (perp=7.488, rec=0.065, cos=0.002), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.565 (perp=7.488, rec=0.065, cos=0.002), tot_loss_proj:1.598 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.551 (perp=7.488, rec=0.051, cos=0.002), tot_loss_proj:1.599 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 750/2000] tot_loss=1.566 (perp=7.488, rec=0.066, cos=0.002), tot_loss_proj:1.592 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.554 (perp=7.488, rec=0.054, cos=0.002), tot_loss_proj:1.586 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.565 (perp=7.488, rec=0.065, cos=0.002), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 900/2000] tot_loss=1.560 (perp=7.488, rec=0.060, cos=0.002), tot_loss_proj:1.590 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.562 (perp=7.488, rec=0.062, cos=0.002), tot_loss_proj:1.592 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.564 (perp=7.488, rec=0.064, cos=0.002), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1050/2000] tot_loss=1.568 (perp=7.488, rec=0.068, cos=0.002), tot_loss_proj:1.586 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.559 (perp=7.488, rec=0.059, cos=0.002), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.569 (perp=7.488, rec=0.069, cos=0.002), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1200/2000] tot_loss=1.553 (perp=7.488, rec=0.053, cos=0.002), tot_loss_proj:1.584 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.558 (perp=7.488, rec=0.058, cos=0.002), tot_loss_proj:1.593 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.564 (perp=7.488, rec=0.064, cos=0.002), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1350/2000] tot_loss=1.571 (perp=7.488, rec=0.071, cos=0.002), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.560 (perp=7.488, rec=0.060, cos=0.002), tot_loss_proj:1.585 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.558 (perp=7.488, rec=0.058, cos=0.002), tot_loss_proj:1.587 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1500/2000] tot_loss=1.567 (perp=7.488, rec=0.067, cos=0.002), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.565 (perp=7.488, rec=0.065, cos=0.002), tot_loss_proj:1.586 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.563 (perp=7.488, rec=0.063, cos=0.002), tot_loss_proj:1.578 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1650/2000] tot_loss=1.555 (perp=7.488, rec=0.055, cos=0.002), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.559 (perp=7.488, rec=0.059, cos=0.002), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.559 (perp=7.488, rec=0.059, cos=0.002), tot_loss_proj:1.582 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1800/2000] tot_loss=1.558 (perp=7.488, rec=0.057, cos=0.002), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.565 (perp=7.488, rec=0.065, cos=0.002), tot_loss_proj:1.591 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.561 (perp=7.488, rec=0.061, cos=0.002), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1950/2000] tot_loss=1.565 (perp=7.488, rec=0.065, cos=0.002), tot_loss_proj:1.587 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.558 (perp=7.488, rec=0.058, cos=0.002), tot_loss_proj:1.587 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.925 | p: 86.586 | r: 87.543
rouge2     | fm: 52.953 | p: 52.739 | r: 53.240
rougeL     | fm: 74.894 | p: 74.588 | r: 75.321
rougeLsum  | fm: 74.832 | p: 74.537 | r: 75.334
r1fm+r2fm = 139.878

input #91 time: 0:08:57 | total time: 14:03:36


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9987903407489911
highest_index [0]
highest [0.9987903407489911]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8589625954627991 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8574015498161316 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8165344595909119 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.7819698452949524 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7253013253211975 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.7242715954780579 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.684 (perp=7.647, rec=0.147, cos=0.007), tot_loss_proj:1.602 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 100/2000] tot_loss=1.602 (perp=7.647, rec=0.070, cos=0.003), tot_loss_proj:1.577 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.593 (perp=7.647, rec=0.061, cos=0.002), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.585 (perp=7.647, rec=0.054, cos=0.002), tot_loss_proj:1.594 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.591 (perp=7.647, rec=0.059, cos=0.002), tot_loss_proj:1.594 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.598 (perp=7.647, rec=0.066, cos=0.002), tot_loss_proj:1.581 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.598 (perp=7.647, rec=0.066, cos=0.002), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.592 (perp=7.647, rec=0.061, cos=0.002), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.597 (perp=7.647, rec=0.065, cos=0.003), tot_loss_proj:1.604 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.595 (perp=7.647, rec=0.063, cos=0.002), tot_loss_proj:1.599 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.605 (perp=7.647, rec=0.074, cos=0.002), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.595 (perp=7.647, rec=0.063, cos=0.002), tot_loss_proj:1.602 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.576 (perp=7.647, rec=0.044, cos=0.002), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.598 (perp=7.647, rec=0.066, cos=0.002), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.590 (perp=7.647, rec=0.058, cos=0.002), tot_loss_proj:1.595 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.587 (perp=7.647, rec=0.055, cos=0.002), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.597 (perp=7.647, rec=0.066, cos=0.002), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.601 (perp=7.647, rec=0.069, cos=0.002), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.602 (perp=7.647, rec=0.071, cos=0.002), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.590 (perp=7.647, rec=0.058, cos=0.002), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.590 (perp=7.647, rec=0.058, cos=0.002), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.587 (perp=7.647, rec=0.055, cos=0.002), tot_loss_proj:1.583 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.585 (perp=7.647, rec=0.053, cos=0.002), tot_loss_proj:1.594 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.582 (perp=7.647, rec=0.050, cos=0.002), tot_loss_proj:1.602 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.590 (perp=7.647, rec=0.059, cos=0.002), tot_loss_proj:1.609 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.600 (perp=7.647, rec=0.068, cos=0.002), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.586 (perp=7.647, rec=0.055, cos=0.002), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.592 (perp=7.647, rec=0.060, cos=0.002), tot_loss_proj:1.586 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.591 (perp=7.647, rec=0.059, cos=0.002), tot_loss_proj:1.599 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.592 (perp=7.647, rec=0.060, cos=0.002), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.601 (perp=7.647, rec=0.069, cos=0.002), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.589 (perp=7.647, rec=0.057, cos=0.002), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.593 (perp=7.647, rec=0.062, cos=0.002), tot_loss_proj:1.604 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.647, rec=0.064, cos=0.002), tot_loss_proj:1.587 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.588 (perp=7.647, rec=0.056, cos=0.002), tot_loss_proj:1.605 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.591 (perp=7.647, rec=0.059, cos=0.002), tot_loss_proj:1.603 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.601 (perp=7.647, rec=0.070, cos=0.002), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.605 (perp=7.647, rec=0.073, cos=0.002), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.601 (perp=7.647, rec=0.069, cos=0.002), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.602 (perp=7.647, rec=0.070, cos=0.002), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.100 | p: 86.731 | r: 87.635
rouge2     | fm: 53.512 | p: 53.340 | r: 53.887
rougeL     | fm: 75.013 | p: 74.714 | r: 75.448
rougeLsum  | fm: 74.949 | p: 74.689 | r: 75.421
r1fm+r2fm = 140.611

input #92 time: 0:08:54 | total time: 14:12:31


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9987496075323365
highest_index [0]
highest [0.9987496075323365]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 0.9548974633216858 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.932569682598114 for ['[CLS] taxi kang lookiled what mostchrome [SEP]']
[Init] best rec loss: 0.9090296626091003 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.9055435061454773 for ['[CLS] worthted ft assignment porch check up [SEP]']
[Init] best rec loss: 0.8900865912437439 for ['[CLS] lucas war breaks baby my pauline divided [SEP]']
[Init] best rec loss: 0.8848389387130737 for ['[CLS] village tallest almost giro opened wine section [SEP]']
[Init] best rec loss: 0.8744845390319824 for ['[CLS] alaska school flags land doc protest from [SEP]']
[Init] best perm rec loss: 0.8713846206665039 for ['[CLS] school protest flags doc land alaska from [SEP]']
[Init] best perm rec loss: 0.8706761598587036 for ['[CLS] flags land protest doc from alaska school [SEP]']
[Init] best perm rec loss: 0.8706189393997192 for ['[CLS] flags land from school alaska doc protest [SEP]']
[Init] best perm rec loss: 0.8680773973464966 for ['[CLS] land alaska from doc school protest flags [SEP]']
[Init] best perm rec loss: 0.8665260076522827 for ['[CLS] land school alaska doc protest from flags [SEP]']
[Init] best perm rec loss: 0.8662610650062561 for ['[CLS] flags doc school alaska from land protest [SEP]']
[Init] best perm rec loss: 0.8654131889343262 for ['[CLS] alaska from doc protest school flags land [SEP]']
[Init] best perm rec loss: 0.8650025725364685 for ['[CLS] land doc from flags protest school alaska [SEP]']
[Init] best perm rec loss: 0.8647843599319458 for ['[CLS] land from protest doc school flags alaska [SEP]']
[Init] best perm rec loss: 0.8647270202636719 for ['[CLS] land from flags school protest doc alaska [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.926 (perp=8.381, rec=0.236, cos=0.013), tot_loss_proj:3.335 [t=0.22s]
prediction: ['[CLS] matt in not funny way funny funny [SEP]']
[ 100/2000] tot_loss=2.046 (perp=9.427, rec=0.155, cos=0.006), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] funny in its funny way funny way [SEP]']
[ 150/2000] tot_loss=1.944 (perp=9.162, rec=0.108, cos=0.004), tot_loss_proj:2.042 [t=0.22s]
prediction: ['[CLS] understanding in its understanding often funny way [SEP]']
[ 200/2000] tot_loss=1.921 (perp=9.162, rec=0.085, cos=0.003), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] understanding in its understanding often funny way [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.606 (perp=7.576, rec=0.087, cos=0.004), tot_loss_proj:1.797 [t=0.22s]
prediction: ['[CLS] understanding funny in its often funny way [SEP]']
[ 300/2000] tot_loss=1.478 (perp=6.938, rec=0.088, cos=0.003), tot_loss_proj:1.627 [t=0.22s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.422 (perp=6.704, rec=0.078, cos=0.003), tot_loss_proj:1.609 [t=0.23s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.411 (perp=6.704, rec=0.067, cos=0.003), tot_loss_proj:1.610 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 450/2000] tot_loss=1.418 (perp=6.704, rec=0.075, cos=0.003), tot_loss_proj:1.603 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.408 (perp=6.704, rec=0.064, cos=0.003), tot_loss_proj:1.615 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.413 (perp=6.704, rec=0.070, cos=0.003), tot_loss_proj:1.617 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 600/2000] tot_loss=1.410 (perp=6.704, rec=0.067, cos=0.003), tot_loss_proj:1.601 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.415 (perp=6.704, rec=0.072, cos=0.003), tot_loss_proj:1.615 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.412 (perp=6.704, rec=0.068, cos=0.003), tot_loss_proj:1.611 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 750/2000] tot_loss=1.426 (perp=6.704, rec=0.083, cos=0.003), tot_loss_proj:1.611 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.407 (perp=6.704, rec=0.064, cos=0.003), tot_loss_proj:1.601 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.406 (perp=6.704, rec=0.063, cos=0.003), tot_loss_proj:1.613 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 900/2000] tot_loss=1.419 (perp=6.704, rec=0.075, cos=0.003), tot_loss_proj:1.605 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.404 (perp=6.704, rec=0.060, cos=0.003), tot_loss_proj:1.604 [t=0.23s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.408 (perp=6.704, rec=0.065, cos=0.003), tot_loss_proj:1.613 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1050/2000] tot_loss=1.411 (perp=6.704, rec=0.067, cos=0.003), tot_loss_proj:1.601 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.410 (perp=6.704, rec=0.066, cos=0.003), tot_loss_proj:1.608 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.406 (perp=6.704, rec=0.062, cos=0.003), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1200/2000] tot_loss=1.410 (perp=6.704, rec=0.067, cos=0.003), tot_loss_proj:1.605 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.404 (perp=6.704, rec=0.061, cos=0.003), tot_loss_proj:1.610 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.420 (perp=6.704, rec=0.077, cos=0.003), tot_loss_proj:1.604 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1350/2000] tot_loss=1.390 (perp=6.704, rec=0.046, cos=0.003), tot_loss_proj:1.609 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.400 (perp=6.704, rec=0.057, cos=0.003), tot_loss_proj:1.602 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.405 (perp=6.704, rec=0.061, cos=0.003), tot_loss_proj:1.608 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1500/2000] tot_loss=1.417 (perp=6.704, rec=0.073, cos=0.003), tot_loss_proj:1.604 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.410 (perp=6.704, rec=0.067, cos=0.003), tot_loss_proj:1.610 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.418 (perp=6.704, rec=0.074, cos=0.003), tot_loss_proj:1.605 [t=0.23s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1650/2000] tot_loss=1.393 (perp=6.704, rec=0.050, cos=0.003), tot_loss_proj:1.599 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.405 (perp=6.704, rec=0.062, cos=0.003), tot_loss_proj:1.606 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.402 (perp=6.704, rec=0.059, cos=0.003), tot_loss_proj:1.611 [t=0.23s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1800/2000] tot_loss=1.411 (perp=6.704, rec=0.067, cos=0.003), tot_loss_proj:1.612 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.408 (perp=6.704, rec=0.065, cos=0.003), tot_loss_proj:1.603 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.410 (perp=6.704, rec=0.067, cos=0.003), tot_loss_proj:1.611 [t=0.23s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1950/2000] tot_loss=1.407 (perp=6.704, rec=0.064, cos=0.003), tot_loss_proj:1.607 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.416 (perp=6.704, rec=0.073, cos=0.003), tot_loss_proj:1.609 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding in its often funny way, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 87.216 | p: 86.898 | r: 87.757
rouge2     | fm: 53.378 | p: 53.218 | r: 53.614
rougeL     | fm: 75.211 | p: 74.923 | r: 75.661
rougeLsum  | fm: 75.148 | p: 74.915 | r: 75.610
r1fm+r2fm = 140.594

input #93 time: 0:08:56 | total time: 14:21:28


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9986622651888467
highest_index [0]
highest [0.9986622651888467]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9412968754768372 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9385424852371216 for ['[CLS] of pro wanted scientists rayon housing chart close earlier anniversary ni [SEP]']
[Init] best rec loss: 0.9211042523384094 for ['[CLS] scent crosses am history single connections set likeuatingface other [SEP]']
[Init] best rec loss: 0.8858420848846436 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.8831648826599121 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best perm rec loss: 0.8787271976470947 for ['[CLS] spiritcede matters baderpour slowed miriter bowble [SEP]']
[Init] best perm rec loss: 0.877602756023407 for ['[CLS] bowerpour matters mircede bad spiritble slowediter [SEP]']
[Init] best perm rec loss: 0.877175509929657 for ['[CLS]cede matters slowed bowpourble spirit baderiter mir [SEP]']
[Init] best perm rec loss: 0.8769248723983765 for ['[CLS] spirit matterser bowpour mirblecede slowediter bad [SEP]']
[Init] best perm rec loss: 0.8755441308021545 for ['[CLS]pourble matterser spirit mircede slowed bad bowiter [SEP]']
[Init] best perm rec loss: 0.8739631175994873 for ['[CLS] bower spiritpouriter matters slowed mir badblecede [SEP]']
[Init] best perm rec loss: 0.8738038539886475 for ['[CLS] spiritpourer bowcedeiter bad mir matters slowedble [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.245 (perp=10.002, rec=0.234, cos=0.011), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS] strange cape neither neithers original nor but nor funny neither [SEP]']
[ 100/2000] tot_loss=2.214 (perp=10.372, rec=0.136, cos=0.004), tot_loss_proj:2.861 [t=0.22s]
prediction: ["[CLS] that cape'neitherr originalr that nor funny neither [SEP]"]
[ 150/2000] tot_loss=2.127 (perp=10.181, rec=0.088, cos=0.003), tot_loss_proj:2.554 [t=0.22s]
prediction: ["[CLS] that cape'neither a originalr s nor funny neither [SEP]"]
[ 200/2000] tot_loss=2.263 (perp=10.862, rec=0.088, cos=0.003), tot_loss_proj:3.047 [t=0.22s]
prediction: ["[CLS] that cape'terribly a originalr s nor funny neither [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.958 (perp=9.381, rec=0.079, cos=0.002), tot_loss_proj:2.749 [t=0.22s]
prediction: ["[CLS] that cape's a originalr terribly nor funny neither [SEP]"]
[ 300/2000] tot_loss=1.959 (perp=9.381, rec=0.080, cos=0.002), tot_loss_proj:2.738 [t=0.22s]
prediction: ["[CLS] that cape's a originalr terribly nor funny neither [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.578 (perp=7.482, rec=0.079, cos=0.003), tot_loss_proj:2.376 [t=0.22s]
prediction: ["[CLS] that original's a caper terribly nor funny neither [SEP]"]
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.380 (perp=6.498, rec=0.078, cos=0.003), tot_loss_proj:1.868 [t=0.22s]
prediction: ["[CLS] that original's a caper neither terribly nor funny [SEP]"]
[ 450/2000] tot_loss=1.375 (perp=6.498, rec=0.073, cos=0.003), tot_loss_proj:1.858 [t=0.23s]
prediction: ["[CLS] that original's a caper neither terribly nor funny [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.315 (perp=6.156, rec=0.081, cos=0.003), tot_loss_proj:1.634 [t=0.22s]
prediction: ["[CLS] that's a caper neither original terribly nor funny [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.191 (perp=5.517, rec=0.085, cos=0.003), tot_loss_proj:1.425 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[ 600/2000] tot_loss=1.182 (perp=5.517, rec=0.076, cos=0.003), tot_loss_proj:1.426 [t=0.23s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.182 (perp=5.517, rec=0.075, cos=0.003), tot_loss_proj:1.416 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.174 (perp=5.517, rec=0.067, cos=0.003), tot_loss_proj:1.426 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[ 750/2000] tot_loss=1.178 (perp=5.517, rec=0.072, cos=0.003), tot_loss_proj:1.425 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.172 (perp=5.517, rec=0.065, cos=0.003), tot_loss_proj:1.425 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.177 (perp=5.517, rec=0.071, cos=0.003), tot_loss_proj:1.420 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[ 900/2000] tot_loss=1.172 (perp=5.517, rec=0.066, cos=0.003), tot_loss_proj:1.426 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.170 (perp=5.517, rec=0.064, cos=0.003), tot_loss_proj:1.427 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.166 (perp=5.517, rec=0.060, cos=0.003), tot_loss_proj:1.428 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[1050/2000] tot_loss=1.174 (perp=5.517, rec=0.068, cos=0.003), tot_loss_proj:1.432 [t=0.23s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.169 (perp=5.517, rec=0.063, cos=0.003), tot_loss_proj:1.426 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.170 (perp=5.517, rec=0.063, cos=0.003), tot_loss_proj:1.415 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[1200/2000] tot_loss=1.179 (perp=5.517, rec=0.073, cos=0.003), tot_loss_proj:1.421 [t=0.23s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.173 (perp=5.517, rec=0.067, cos=0.003), tot_loss_proj:1.433 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.175 (perp=5.517, rec=0.069, cos=0.003), tot_loss_proj:1.425 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[1350/2000] tot_loss=1.174 (perp=5.517, rec=0.068, cos=0.003), tot_loss_proj:1.429 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.163 (perp=5.517, rec=0.056, cos=0.003), tot_loss_proj:1.422 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.167 (perp=5.517, rec=0.061, cos=0.003), tot_loss_proj:1.422 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[1500/2000] tot_loss=1.162 (perp=5.517, rec=0.056, cos=0.003), tot_loss_proj:1.416 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.163 (perp=5.517, rec=0.057, cos=0.003), tot_loss_proj:1.421 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.179 (perp=5.517, rec=0.073, cos=0.003), tot_loss_proj:1.421 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[1650/2000] tot_loss=1.174 (perp=5.517, rec=0.068, cos=0.003), tot_loss_proj:1.427 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.183 (perp=5.517, rec=0.077, cos=0.003), tot_loss_proj:1.421 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.169 (perp=5.517, rec=0.063, cos=0.003), tot_loss_proj:1.419 [t=0.23s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[1800/2000] tot_loss=1.164 (perp=5.517, rec=0.058, cos=0.003), tot_loss_proj:1.429 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.179 (perp=5.517, rec=0.073, cos=0.003), tot_loss_proj:1.427 [t=0.23s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.184 (perp=5.517, rec=0.078, cos=0.003), tot_loss_proj:1.424 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[1950/2000] tot_loss=1.178 (perp=5.517, rec=0.072, cos=0.003), tot_loss_proj:1.419 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.181 (perp=5.517, rec=0.075, cos=0.003), tot_loss_proj:1.427 [t=0.22s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] that's a caper neither terribly original nor funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 87.368 | p: 87.041 | r: 87.945
rouge2     | fm: 53.366 | p: 53.186 | r: 53.652
rougeL     | fm: 75.163 | p: 74.928 | r: 75.593
rougeLsum  | fm: 75.147 | p: 74.878 | r: 75.661
r1fm+r2fm = 140.734

input #94 time: 0:08:57 | total time: 14:30:25


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9985748840941843
highest_index [0]
highest [0.9985748840941843]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9619305729866028 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9542577266693115 for ['[CLS]nahley hair see nedra logan offices fourth sethgical recommended side laughdran auxiliary [SEP]']
[Init] best rec loss: 0.9335136413574219 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.9283832311630249 for ['[CLS] through... if mckennarollerrand ngo sally cara party beauty economic dock nah art [SEP]']
[Init] best rec loss: 0.9269236326217651 for ['[CLS] navy loyalty roomines oak kindergarten plus during africa alexia merely hands will del affinity [SEP]']
[Init] best rec loss: 0.9021338224411011 for ['[CLS] end output rather overall of byron inventor earth interests novel adult heir night bryan remaining [SEP]']
[Init] best rec loss: 0.9012122750282288 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.9010446071624756 for ['[CLS] block tech monty hangingے pressure trailer sister wire complete private damp ] cutnne [SEP]']
[Init] best perm rec loss: 0.9001474380493164 for ['[CLS] sister hangingnne block monty tech damp pressure trailer wire cut ] private completeے [SEP]']
[Init] best perm rec loss: 0.8988430500030518 for ['[CLS] damp ]ے wire trailer private monty block complete sister cut technne hanging pressure [SEP]']
[Init] best perm rec loss: 0.8983383774757385 for ['[CLS] ]nne private cut damp block wire tech pressure trailerے monty complete hanging sister [SEP]']
[Init] best perm rec loss: 0.898004412651062 for ['[CLS] damp trailerےnne complete tech hanging wire cut sister monty block private ] pressure [SEP]']
[Init] best perm rec loss: 0.8976805806159973 for ['[CLS] pressurenne ] block trailer completeے private tech cut wire damp monty hanging sister [SEP]']
[Init] best perm rec loss: 0.8920190334320068 for ['[CLS] damp wire cutے tech ] trailer block hangingnne private monty pressure sister complete [SEP]']
[Init] best perm rec loss: 0.8910219669342041 for ['[CLS] private sister ] tech monty complete block wire trailerے cut pressure damp hangingnne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.665 (perp=12.087, rec=0.238, cos=0.009), tot_loss_proj:2.957 [t=0.22s]
prediction: ['[CLS] chronicbed hopeless story became, aless hopeless becomes seemed became hopeless hopeless hopeless [SEP]']
[ 100/2000] tot_loss=2.343 (perp=10.666, rec=0.203, cos=0.007), tot_loss_proj:2.695 [t=0.23s]
prediction: ["[CLS]'sick patients story becomes, asat hopelesssat into a hopeless hopelessdle [SEP]"]
[ 150/2000] tot_loss=2.499 (perp=11.496, rec=0.194, cos=0.005), tot_loss_proj:2.818 [t=0.23s]
prediction: ["[CLS]'treason pleading story became, asat hopeless nearly mud a hopeless hopelessdle [SEP]"]
[ 200/2000] tot_loss=2.580 (perp=12.181, rec=0.140, cos=0.003), tot_loss_proj:2.930 [t=0.23s]
prediction: ["[CLS] 'erated denis story becomes, asat hopeless nearly mud a hopeless hopelessdle [SEP]"]
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.417 (perp=11.124, rec=0.187, cos=0.006), tot_loss_proj:2.658 [t=0.23s]
prediction: ["[CLS]'jim denis story becomes a hopeless 阝,ingsat hopeless un muddle [SEP]"]
[ 300/2000] tot_loss=2.361 (perp=11.202, rec=0.117, cos=0.004), tot_loss_proj:2.720 [t=0.23s]
prediction: ["[CLS]'sat denis story becomes a hopeless₩,ingsatin un muddle [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.077 (perp=9.787, rec=0.116, cos=0.004), tot_loss_proj:2.309 [t=0.23s]
prediction: ["[CLS]'sat denis story becomes a hopeless₩, unsatining muddle [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.843 (perp=8.569, rec=0.125, cos=0.004), tot_loss_proj:1.978 [t=0.23s]
prediction: ["[CLS] denissat'story becomes a hopelessfying, unsatining muddle [SEP]"]
[ 450/2000] tot_loss=1.446 (perp=6.620, rec=0.118, cos=0.004), tot_loss_proj:1.536 [t=0.23s]
prediction: ["[CLS] denissat'story becomes a hopelessfying, unsatisfying muddle [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.401 (perp=6.493, rec=0.099, cos=0.004), tot_loss_proj:1.553 [t=0.23s]
prediction: ["[CLS] denisfyingsat'story becomes a hopeless, unsatisfying muddle [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.391 (perp=6.456, rec=0.096, cos=0.003), tot_loss_proj:1.473 [t=0.23s]
prediction: ["[CLS] denis -sat'story becomes a hopeless, unsatisfying muddle [SEP]"]
[ 600/2000] tot_loss=1.391 (perp=6.456, rec=0.096, cos=0.003), tot_loss_proj:1.467 [t=0.23s]
prediction: ["[CLS] denis -sat'story becomes a hopeless, unsatisfying muddle [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.431 (perp=6.641, rec=0.099, cos=0.003), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] denissat ) - story becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.423 (perp=6.641, rec=0.092, cos=0.003), tot_loss_proj:1.611 [t=0.23s]
prediction: ['[CLS] denissat ) - story becomes a hopeless, unsatisfying muddle [SEP]']
[ 750/2000] tot_loss=1.314 (perp=6.074, rec=0.096, cos=0.003), tot_loss_proj:1.451 [t=0.23s]
prediction: ['[CLS] denis ( ) - story becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.219 (perp=5.612, rec=0.094, cos=0.003), tot_loss_proj:1.353 [t=0.23s]
prediction: ['[CLS] ( denis ) - story becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.223 (perp=5.612, rec=0.097, cos=0.003), tot_loss_proj:1.354 [t=0.23s]
prediction: ['[CLS] ( denis ) - story becomes a hopeless, unsatisfying muddle [SEP]']
[ 900/2000] tot_loss=1.210 (perp=5.612, rec=0.084, cos=0.003), tot_loss_proj:1.350 [t=0.23s]
prediction: ['[CLS] ( denis ) - story becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.216 (perp=5.612, rec=0.091, cos=0.003), tot_loss_proj:1.345 [t=0.23s]
prediction: ['[CLS] ( denis ) - story becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.218 (perp=5.612, rec=0.093, cos=0.003), tot_loss_proj:1.345 [t=0.23s]
prediction: ['[CLS] ( denis ) - story becomes a hopeless, unsatisfying muddle [SEP]']
[1050/2000] tot_loss=1.282 (perp=5.929, rec=0.093, cos=0.003), tot_loss_proj:1.461 [t=0.23s]
prediction: ['[CLS] ( denis ) ( story becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.284 (perp=5.929, rec=0.095, cos=0.003), tot_loss_proj:1.456 [t=0.23s]
prediction: ['[CLS] ( denis ) ( story becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.403 (perp=6.607, rec=0.078, cos=0.003), tot_loss_proj:1.777 [t=0.23s]
prediction: ['[CLS]is denis ) story ( becomes a hopeless, unsatisfying muddle [SEP]']
[1200/2000] tot_loss=1.410 (perp=6.607, rec=0.085, cos=0.003), tot_loss_proj:1.777 [t=0.23s]
prediction: ['[CLS]is denis ) story ( becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.332 (perp=6.162, rec=0.097, cos=0.003), tot_loss_proj:1.672 [t=0.23s]
prediction: ['[CLS] denisis ) story ( becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.314 (perp=6.162, rec=0.078, cos=0.003), tot_loss_proj:1.666 [t=0.23s]
prediction: ['[CLS] denisis ) story ( becomes a hopeless, unsatisfying muddle [SEP]']
[1350/2000] tot_loss=1.318 (perp=6.162, rec=0.083, cos=0.003), tot_loss_proj:1.663 [t=0.23s]
prediction: ['[CLS] denisis ) story ( becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.207 (perp=5.613, rec=0.082, cos=0.003), tot_loss_proj:1.372 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.213 (perp=5.613, rec=0.087, cos=0.003), tot_loss_proj:1.363 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
[1500/2000] tot_loss=1.207 (perp=5.613, rec=0.082, cos=0.003), tot_loss_proj:1.361 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.201 (perp=5.613, rec=0.076, cos=0.003), tot_loss_proj:1.366 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.197 (perp=5.613, rec=0.072, cos=0.003), tot_loss_proj:1.373 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
[1650/2000] tot_loss=1.204 (perp=5.613, rec=0.078, cos=0.003), tot_loss_proj:1.370 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.206 (perp=5.613, rec=0.080, cos=0.003), tot_loss_proj:1.364 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.204 (perp=5.613, rec=0.078, cos=0.003), tot_loss_proj:1.367 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
[1800/2000] tot_loss=1.209 (perp=5.613, rec=0.084, cos=0.003), tot_loss_proj:1.360 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.193 (perp=5.613, rec=0.067, cos=0.003), tot_loss_proj:1.372 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.197 (perp=5.613, rec=0.071, cos=0.003), tot_loss_proj:1.374 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
[1950/2000] tot_loss=1.200 (perp=5.613, rec=0.074, cos=0.003), tot_loss_proj:1.373 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.211 (perp=5.613, rec=0.086, cos=0.003), tot_loss_proj:1.358 [t=0.23s]
prediction: ['[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] denisis ( story ) becomes a hopeless, unsatisfying muddle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 163.889

[Aggregate metrics]:
rouge1     | fm: 87.409 | p: 87.089 | r: 88.016
rouge2     | fm: 53.428 | p: 53.275 | r: 53.662
rougeL     | fm: 75.285 | p: 75.023 | r: 75.743
rougeLsum  | fm: 75.329 | p: 75.058 | r: 75.768
r1fm+r2fm = 140.837

input #95 time: 0:09:03 | total time: 14:39:29


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9990068910262093
highest_index [0]
highest [0.9990068910262093]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.7907276749610901 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.7820157408714294 for ['[CLS] mode wound britain generation pope inter retains harvard chill court wait haven perform queensland ins [SEP]']
[Init] best rec loss: 0.776585042476654 for ['[CLS] troubleович thou traditional adjacent pulse grit front minutes developingwind west fear later billy [SEP]']
[Init] best rec loss: 0.7746942043304443 for ['[CLS] class error portoizedtler riverside 7nsis deedret via protection corporation whether selection [SEP]']
[Init] best rec loss: 0.7664324045181274 for ['[CLS] interviews screwed podcast ？ 8 sunset effects era too oath sunk chief between capcom master [SEP]']
[Init] best rec loss: 0.7597325444221497 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.75972580909729 for ['[CLS] projectile time save spent sounding memoir typical wig pondered statue era smashwords augustgn living [SEP]']
[Init] best perm rec loss: 0.7587518095970154 for ['[CLS] save typical smashwords projectile time memoirgn living sounding spent wig pondered august statue era [SEP]']
[Init] best perm rec loss: 0.7585598826408386 for ['[CLS] save statuegn living spent august wig typical time memoir smashwords sounding pondered projectile era [SEP]']
[Init] best perm rec loss: 0.7577846646308899 for ['[CLS] august projectile pondered typical spent living statue time sounding memoir smashwords eragn wig save [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.628 (perp=11.623, rec=0.283, cos=0.021), tot_loss_proj:3.977 [t=0.22s]
prediction: ['[CLS] to people force forces on lesser many cover for ( nightmares areas lesserque rainfall [SEP]']
[ 100/2000] tot_loss=2.030 (perp=9.229, rec=0.174, cos=0.010), tot_loss_proj:3.530 [t=0.23s]
prediction: ['[CLS] would people force himself on lesser into cover for for cover people lesser into men [SEP]']
[ 150/2000] tot_loss=2.349 (perp=10.977, rec=0.145, cos=0.008), tot_loss_proj:3.929 [t=0.23s]
prediction: ['[CLS] men people force himself on lesser situations cover make run run situations lesser into days [SEP]']
[ 200/2000] tot_loss=2.096 (perp=9.906, rec=0.110, cos=0.005), tot_loss_proj:3.751 [t=0.23s]
prediction: ['[CLS] men people force himself on lesser situations cover make run run into lesser and days [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.834 (perp=8.553, rec=0.117, cos=0.006), tot_loss_proj:3.306 [t=0.23s]
prediction: ['[CLS] men people force himself on lesser situations and make for run into lesser cover situations [SEP]']
[ 300/2000] tot_loss=1.798 (perp=8.553, rec=0.083, cos=0.004), tot_loss_proj:3.306 [t=0.23s]
prediction: ['[CLS] men people force himself on lesser situations and make for run into lesser cover situations [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.666 (perp=7.806, rec=0.100, cos=0.005), tot_loss_proj:2.996 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men and make for run into lesser cover situations [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.651 (perp=7.806, rec=0.085, cos=0.004), tot_loss_proj:2.992 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men and make for run into lesser cover situations [SEP]']
[ 450/2000] tot_loss=1.654 (perp=7.806, rec=0.089, cos=0.004), tot_loss_proj:2.995 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men and make for run into lesser cover situations [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.667 (perp=7.890, rec=0.086, cos=0.004), tot_loss_proj:2.880 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for would and run into lesser cover situations [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.656 (perp=7.890, rec=0.075, cos=0.004), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for would and run into lesser cover situations [SEP]']
[ 600/2000] tot_loss=1.661 (perp=7.890, rec=0.080, cos=0.003), tot_loss_proj:2.877 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for would and run into lesser cover situations [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.650 (perp=7.890, rec=0.069, cos=0.003), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for would and run into lesser cover situations [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.653 (perp=7.890, rec=0.072, cos=0.003), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for would and run into lesser cover situations [SEP]']
[ 750/2000] tot_loss=1.662 (perp=7.890, rec=0.081, cos=0.003), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for would and run into lesser cover situations [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.671 (perp=7.890, rec=0.090, cos=0.003), tot_loss_proj:2.877 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for would and run into lesser cover situations [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.662 (perp=7.890, rec=0.081, cos=0.003), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for would and run into lesser cover situations [SEP]']
[ 900/2000] tot_loss=1.656 (perp=7.890, rec=0.075, cos=0.003), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for would and run into lesser cover situations [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.664 (perp=7.890, rec=0.083, cos=0.003), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for would and run into lesser cover situations [SEP]']
Attempt swap
[1000/2000] tot_loss=1.655 (perp=7.890, rec=0.074, cos=0.003), tot_loss_proj:2.883 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for would and run into lesser cover situations [SEP]']
[1050/2000] tot_loss=1.601 (perp=7.601, rec=0.079, cos=0.002), tot_loss_proj:3.001 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for make and run into lesser cover situations [SEP]']
Attempt swap
[1100/2000] tot_loss=1.601 (perp=7.601, rec=0.079, cos=0.002), tot_loss_proj:3.005 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for make and run into lesser cover situations [SEP]']
Attempt swap
[1150/2000] tot_loss=1.600 (perp=7.601, rec=0.078, cos=0.002), tot_loss_proj:3.005 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for make and run into lesser cover situations [SEP]']
[1200/2000] tot_loss=1.595 (perp=7.601, rec=0.073, cos=0.002), tot_loss_proj:3.004 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for make and run into lesser cover situations [SEP]']
Attempt swap
[1250/2000] tot_loss=1.595 (perp=7.601, rec=0.072, cos=0.002), tot_loss_proj:3.006 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for make and run into lesser cover situations [SEP]']
Attempt swap
[1300/2000] tot_loss=1.605 (perp=7.601, rec=0.082, cos=0.002), tot_loss_proj:3.007 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for make and run into lesser cover situations [SEP]']
[1350/2000] tot_loss=1.596 (perp=7.601, rec=0.074, cos=0.002), tot_loss_proj:3.006 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for make and run into lesser cover situations [SEP]']
Attempt swap
[1400/2000] tot_loss=1.585 (perp=7.601, rec=0.063, cos=0.002), tot_loss_proj:2.997 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for make and run into lesser cover situations [SEP]']
Attempt swap
[1450/2000] tot_loss=1.640 (perp=7.810, rec=0.076, cos=0.002), tot_loss_proj:3.108 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for make and run into would cover situations [SEP]']
[1500/2000] tot_loss=1.644 (perp=7.810, rec=0.080, cos=0.002), tot_loss_proj:3.102 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men for make and run into would cover situations [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.570 (perp=7.490, rec=0.069, cos=0.002), tot_loss_proj:3.078 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men would make and run into for cover situations [SEP]']
Attempt swap
[1600/2000] tot_loss=1.572 (perp=7.490, rec=0.072, cos=0.002), tot_loss_proj:3.074 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men would make and run into for cover situations [SEP]']
[1650/2000] tot_loss=1.567 (perp=7.490, rec=0.067, cos=0.002), tot_loss_proj:3.070 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men would make and run into for cover situations [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.538 (perp=7.331, rec=0.069, cos=0.002), tot_loss_proj:2.955 [t=0.23s]
prediction: ['[CLS] situations people force himself on lesser men would make and run into situations for cover [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.486 (perp=7.036, rec=0.076, cos=0.003), tot_loss_proj:2.651 [t=0.23s]
prediction: ['[CLS] people force himself on lesser men would make situations and run into situations for cover [SEP]']
[1800/2000] tot_loss=1.489 (perp=7.036, rec=0.079, cos=0.002), tot_loss_proj:2.648 [t=0.23s]
prediction: ['[CLS] people force himself on lesser men would make situations and run into situations for cover [SEP]']
Attempt swap
[1850/2000] tot_loss=1.493 (perp=7.036, rec=0.084, cos=0.002), tot_loss_proj:2.647 [t=0.23s]
prediction: ['[CLS] people force himself on lesser men would make situations and run into situations for cover [SEP]']
Attempt swap
[1900/2000] tot_loss=1.479 (perp=7.036, rec=0.070, cos=0.002), tot_loss_proj:2.649 [t=0.23s]
prediction: ['[CLS] people force himself on lesser men would make situations and run into situations for cover [SEP]']
[1950/2000] tot_loss=1.480 (perp=7.036, rec=0.071, cos=0.002), tot_loss_proj:2.651 [t=0.23s]
prediction: ['[CLS] people force himself on lesser men would make situations and run into situations for cover [SEP]']
Attempt swap
[2000/2000] tot_loss=1.480 (perp=7.036, rec=0.071, cos=0.002), tot_loss_proj:2.650 [t=0.23s]
prediction: ['[CLS] people force himself on lesser men would make situations and run into situations for cover [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] situations people force himself on lesser men for make and run into lesser cover situations [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.235 | p: 88.235 | r: 88.235
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 106.985

[Aggregate metrics]:
rouge1     | fm: 87.373 | p: 87.045 | r: 87.956
rouge2     | fm: 53.289 | p: 53.162 | r: 53.620
rougeL     | fm: 75.109 | p: 74.868 | r: 75.596
rougeLsum  | fm: 75.109 | p: 74.843 | r: 75.623
r1fm+r2fm = 140.662

input #96 time: 0:09:03 | total time: 14:48:32


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9988128741771469
highest_index [0]
highest [0.9988128741771469]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.7019720077514648 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.6998206973075867 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best perm rec loss: 0.6988703012466431 for ['[CLS] victoriaten test pass 2016 which [SEP]']
[Init] best perm rec loss: 0.6968253254890442 for ['[CLS]ten victoria pass 2016 test which [SEP]']
[Init] best perm rec loss: 0.6927359104156494 for ['[CLS] pass 2016 whichten test victoria [SEP]']
[Init] best perm rec loss: 0.6926405429840088 for ['[CLS]ten pass 2016 which victoria test [SEP]']
[Init] best perm rec loss: 0.6907324194908142 for ['[CLS] pass 2016 testten victoria which [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.436 (perp=10.433, rec=0.327, cos=0.022), tot_loss_proj:3.894 [t=0.22s]
prediction: ['[CLS] and untable original vehicles relics [SEP]']
[ 100/2000] tot_loss=1.841 (perp=8.418, rec=0.151, cos=0.006), tot_loss_proj:2.369 [t=0.22s]
prediction: ['[CLS] and ungettable charactersget [SEP]']
[ 150/2000] tot_loss=1.797 (perp=8.418, rec=0.109, cos=0.005), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] and ungettable charactersget [SEP]']
[ 200/2000] tot_loss=1.913 (perp=9.101, rec=0.090, cos=0.003), tot_loss_proj:2.468 [t=0.22s]
prediction: ['[CLS] and ungettable charactersfor [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.148 (perp=5.309, rec=0.083, cos=0.004), tot_loss_proj:1.124 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 300/2000] tot_loss=1.144 (perp=5.309, rec=0.078, cos=0.004), tot_loss_proj:1.117 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.142 (perp=5.309, rec=0.077, cos=0.003), tot_loss_proj:1.121 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.133 (perp=5.309, rec=0.068, cos=0.003), tot_loss_proj:1.137 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 450/2000] tot_loss=1.143 (perp=5.309, rec=0.076, cos=0.005), tot_loss_proj:1.126 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.127 (perp=5.309, rec=0.062, cos=0.003), tot_loss_proj:1.126 [t=0.29s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.136 (perp=5.309, rec=0.070, cos=0.003), tot_loss_proj:1.134 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 600/2000] tot_loss=1.119 (perp=5.309, rec=0.053, cos=0.003), tot_loss_proj:1.128 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.127 (perp=5.309, rec=0.061, cos=0.003), tot_loss_proj:1.132 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.128 (perp=5.309, rec=0.063, cos=0.003), tot_loss_proj:1.135 [t=0.23s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 750/2000] tot_loss=1.125 (perp=5.309, rec=0.060, cos=0.003), tot_loss_proj:1.134 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.122 (perp=5.309, rec=0.056, cos=0.003), tot_loss_proj:1.121 [t=0.23s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.128 (perp=5.309, rec=0.063, cos=0.003), tot_loss_proj:1.123 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 900/2000] tot_loss=1.133 (perp=5.309, rec=0.067, cos=0.003), tot_loss_proj:1.123 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.127 (perp=5.309, rec=0.062, cos=0.003), tot_loss_proj:1.132 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.132 (perp=5.309, rec=0.067, cos=0.003), tot_loss_proj:1.122 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1050/2000] tot_loss=1.124 (perp=5.309, rec=0.059, cos=0.003), tot_loss_proj:1.123 [t=0.23s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.137 (perp=5.309, rec=0.072, cos=0.003), tot_loss_proj:1.131 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.132 (perp=5.309, rec=0.067, cos=0.003), tot_loss_proj:1.123 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1200/2000] tot_loss=1.123 (perp=5.309, rec=0.058, cos=0.003), tot_loss_proj:1.122 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.127 (perp=5.309, rec=0.062, cos=0.003), tot_loss_proj:1.124 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.139 (perp=5.309, rec=0.074, cos=0.003), tot_loss_proj:1.125 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1350/2000] tot_loss=1.132 (perp=5.309, rec=0.067, cos=0.003), tot_loss_proj:1.126 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.124 (perp=5.309, rec=0.059, cos=0.003), tot_loss_proj:1.129 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.133 (perp=5.309, rec=0.068, cos=0.003), tot_loss_proj:1.128 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1500/2000] tot_loss=1.120 (perp=5.309, rec=0.055, cos=0.003), tot_loss_proj:1.130 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.110 (perp=5.309, rec=0.045, cos=0.003), tot_loss_proj:1.119 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.123 (perp=5.309, rec=0.058, cos=0.003), tot_loss_proj:1.122 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1650/2000] tot_loss=1.116 (perp=5.309, rec=0.051, cos=0.003), tot_loss_proj:1.130 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.131 (perp=5.309, rec=0.066, cos=0.003), tot_loss_proj:1.120 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.124 (perp=5.309, rec=0.059, cos=0.003), tot_loss_proj:1.110 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1800/2000] tot_loss=1.133 (perp=5.309, rec=0.068, cos=0.003), tot_loss_proj:1.127 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.125 (perp=5.309, rec=0.060, cos=0.003), tot_loss_proj:1.122 [t=0.23s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.133 (perp=5.309, rec=0.068, cos=0.003), tot_loss_proj:1.129 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1950/2000] tot_loss=1.139 (perp=5.309, rec=0.074, cos=0.003), tot_loss_proj:1.126 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.131 (perp=5.309, rec=0.066, cos=0.003), tot_loss_proj:1.132 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.556 | p: 87.225 | r: 88.078
rouge2     | fm: 53.710 | p: 53.602 | r: 53.957
rougeL     | fm: 75.281 | p: 75.016 | r: 75.732
rougeLsum  | fm: 75.303 | p: 75.023 | r: 75.803
r1fm+r2fm = 141.266

input #97 time: 0:08:56 | total time: 14:57:29


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9984833122884564
highest_index [0]
highest [0.9984833122884564]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.6752930879592896 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.6719683408737183 for ['[CLS] prohibited nos jed ada [SEP]']
[Init] best perm rec loss: 0.6690149307250977 for ['[CLS] nos ada prohibited jed [SEP]']
[Init] best perm rec loss: 0.6658229827880859 for ['[CLS] nos prohibited jed ada [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.395 (perp=10.921, rec=0.201, cos=0.010), tot_loss_proj:2.626 [t=0.22s]
prediction: ['[CLS] unfulllingful [SEP]']
[ 100/2000] tot_loss=2.310 (perp=10.921, rec=0.117, cos=0.009), tot_loss_proj:2.635 [t=0.22s]
prediction: ['[CLS] unfulllingful [SEP]']
[ 150/2000] tot_loss=2.281 (perp=10.921, rec=0.090, cos=0.007), tot_loss_proj:2.631 [t=0.22s]
prediction: ['[CLS] unfulllingful [SEP]']
[ 200/2000] tot_loss=2.266 (perp=10.921, rec=0.077, cos=0.005), tot_loss_proj:2.634 [t=0.22s]
prediction: ['[CLS] unfulllingful [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.069 (perp=4.947, rec=0.075, cos=0.004), tot_loss_proj:1.057 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.056 (perp=4.947, rec=0.064, cos=0.003), tot_loss_proj:1.057 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.059 (perp=4.947, rec=0.066, cos=0.003), tot_loss_proj:1.057 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.060 (perp=4.947, rec=0.067, cos=0.003), tot_loss_proj:1.063 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.056 (perp=4.947, rec=0.063, cos=0.003), tot_loss_proj:1.056 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.057 (perp=4.947, rec=0.065, cos=0.003), tot_loss_proj:1.052 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.054 (perp=4.947, rec=0.061, cos=0.003), tot_loss_proj:1.056 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.053 (perp=4.947, rec=0.060, cos=0.003), tot_loss_proj:1.059 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.057 (perp=4.947, rec=0.065, cos=0.003), tot_loss_proj:1.063 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.053 (perp=4.947, rec=0.060, cos=0.003), tot_loss_proj:1.053 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.046 (perp=4.947, rec=0.054, cos=0.003), tot_loss_proj:1.051 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.057 (perp=4.947, rec=0.065, cos=0.003), tot_loss_proj:1.057 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.054 (perp=4.947, rec=0.061, cos=0.003), tot_loss_proj:1.050 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.052 (perp=4.947, rec=0.060, cos=0.003), tot_loss_proj:1.061 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.054 (perp=4.947, rec=0.062, cos=0.003), tot_loss_proj:1.057 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.054 (perp=4.947, rec=0.062, cos=0.003), tot_loss_proj:1.055 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.051 (perp=4.947, rec=0.059, cos=0.003), tot_loss_proj:1.056 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.052 (perp=4.947, rec=0.060, cos=0.003), tot_loss_proj:1.051 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.056 (perp=4.947, rec=0.064, cos=0.003), tot_loss_proj:1.052 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.046 (perp=4.947, rec=0.054, cos=0.003), tot_loss_proj:1.055 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.049 (perp=4.947, rec=0.056, cos=0.003), tot_loss_proj:1.047 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.049 (perp=4.947, rec=0.056, cos=0.003), tot_loss_proj:1.058 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.061 (perp=4.947, rec=0.069, cos=0.003), tot_loss_proj:1.048 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.053 (perp=4.947, rec=0.061, cos=0.003), tot_loss_proj:1.057 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.063 (perp=4.947, rec=0.071, cos=0.003), tot_loss_proj:1.045 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.055 (perp=4.947, rec=0.063, cos=0.003), tot_loss_proj:1.056 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.056 (perp=4.947, rec=0.063, cos=0.003), tot_loss_proj:1.050 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.050 (perp=4.947, rec=0.058, cos=0.003), tot_loss_proj:1.072 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.048 (perp=4.947, rec=0.056, cos=0.003), tot_loss_proj:1.044 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.052 (perp=4.947, rec=0.059, cos=0.003), tot_loss_proj:1.056 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.047 (perp=4.947, rec=0.054, cos=0.003), tot_loss_proj:1.045 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.061 (perp=4.947, rec=0.068, cos=0.003), tot_loss_proj:1.054 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.059 (perp=4.947, rec=0.067, cos=0.003), tot_loss_proj:1.056 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.061 (perp=4.947, rec=0.069, cos=0.003), tot_loss_proj:1.058 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.049 (perp=4.947, rec=0.057, cos=0.003), tot_loss_proj:1.048 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.047 (perp=4.947, rec=0.054, cos=0.003), tot_loss_proj:1.049 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.636 | p: 87.355 | r: 88.192
rouge2     | fm: 54.142 | p: 54.005 | r: 54.376
rougeL     | fm: 75.533 | p: 75.276 | r: 75.987
rougeLsum  | fm: 75.523 | p: 75.276 | r: 75.953
r1fm+r2fm = 141.778

input #98 time: 0:08:56 | total time: 15:06:26


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.9986206083456131
highest_index [0]
highest [0.9986206083456131]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8179452419281006 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8060448169708252 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8001120686531067 for ['[CLS] freedom lay third cartwright u to tear supply disputed glasses operahus album [MASK] literature bart now associatedtmenty thou stated microphone poly frederick rogers lineshtake furport modern point rosewood mid early [SEP]']
[Init] best rec loss: 0.7718626260757446 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.7614070773124695 for ['[CLS] imp then ratlogueathy mobile bun smoothe bran where heart thumbs principal aires & recently brig addison stands catalog alert abbottale leading switch as could which buy pony kid risk general spreadim [SEP]']
[Init] best rec loss: 0.7613416314125061 for ['[CLS] wat searched fits mckay german divide interpret sensory ajax from even during under skye pants ramlus except door wanted others same q same king ashton care lot confirmation buttonsmania caseston file evil absolute [SEP]']
[Init] best rec loss: 0.7456560134887695 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.7447815537452698 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.7429776787757874 for ['[CLS] rightte when claire currently services [MASK] thunder distance synonym taste ferns barbie actually still te harper himselfˈ opposed earliest bet forced dentalagingts knowledge ratings bearing slight screens cushion orient garcia temps re [SEP]']
[Init] best perm rec loss: 0.7419796586036682 for ['[CLS] re opposed actually [MASK] thunder dental taste distance harper forced ratings garciate right barbie claireaging screens cushion when knowledge himself services orient ferns earliest te tempsts currently slight bearing synonym betˈ still [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.736 (perp=11.847, rec=0.342, cos=0.024), tot_loss_proj:3.080 [t=0.22s]
prediction: ["[CLS] funssing prefecture more payments suspicious bills ᵣ bad professional dump worst enjoy action junk cannedssing / soviet film, legislation ] di terrorists worst bill under them 'hit small or intossing always [SEP]"]
[ 100/2000] tot_loss=2.405 (perp=10.482, rec=0.288, cos=0.020), tot_loss_proj:2.991 [t=0.23s]
prediction: ["[CLS] funssing yellowish their payments mps films baptistssing professional'governmental fun'check oncessing'''together film di dissing problems film the prison. fun suicide everything dissing always [SEP]"]
[ 150/2000] tot_loss=2.092 (perp=9.188, rec=0.240, cos=0.014), tot_loss_proj:2.775 [t=0.23s]
prediction: ['[CLS] funssing muttering some stated " ticket dissing different horrible $ fun\'cost declaredssing\'ezio\'and film di dissing\'film the them. fun any mind dissing went [SEP]']
[ 200/2000] tot_loss=2.126 (perp=9.491, rec=0.213, cos=0.015), tot_loss_proj:2.648 [t=0.23s]
prediction: ['[CLS] funssing ` more ` " ticket butssing their horrible\'fun\'cost declaredssing\'this\'had film di dissing\'film the lucivar the fun but mind dissing did [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.195 (perp=9.845, rec=0.213, cos=0.013), tot_loss_proj:2.643 [t=0.23s]
prediction: ["[CLS] funssing walked anymore `'ticket butssing their horrible ` fun'cost refusedssing'the'had film di dissing'the film 主 the fun'mind dissing did [SEP]"]
[ 300/2000] tot_loss=2.112 (perp=9.679, rec=0.165, cos=0.012), tot_loss_proj:2.604 [t=0.23s]
prediction: ["[CLS] funssing walked ᴺ `'ticket butssing so horrible ` fun ` cost askingssing'the'had film di'ssing'the film quite that much not mind dissing did [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.082 (perp=9.674, rec=0.138, cos=0.009), tot_loss_proj:2.640 [t=0.23s]
prediction: ["[CLS] fun terrible walked out muttering'ticket butssing so horrible ` not ` cost askingssing'that film had, di'ssing'the film 主 that much they mind dissing they [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.862 (perp=8.648, rec=0.127, cos=0.005), tot_loss_proj:2.407 [t=0.23s]
prediction: ["[CLS] fun horrible walked out muttering'ticket but'so horrible ` not ` cost'ssing'that film had'dissingssing'the film 主 that much the mind dissing they [SEP]"]
[ 450/2000] tot_loss=1.898 (perp=8.854, rec=0.120, cos=0.007), tot_loss_proj:2.435 [t=0.23s]
prediction: ["[CLS] fun terrible walked out muttering'ticket but'so horrible ` t ` cost'ssing'that film had, dissingssing'the film 主 that much the mind dissing they [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.830 (perp=8.603, rec=0.105, cos=0.004), tot_loss_proj:2.409 [t=0.23s]
prediction: ["[CLS] much terrible walked out muttering'muttering but'so horrible ` t ` cost'ssing'that ticket had, dissingssing'the film 主 that fun the mind dissing they [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.774 (perp=8.289, rec=0.110, cos=0.006), tot_loss_proj:2.431 [t=0.23s]
prediction: ["[CLS] much terrible walked out muttering'muttering but'so horrible ` t `'costssing'that ticket had, dissingssing'the film as that fun the mind dissing they [SEP]"]
[ 600/2000] tot_loss=1.806 (perp=8.525, rec=0.096, cos=0.005), tot_loss_proj:2.423 [t=0.23s]
prediction: ["[CLS] much terrible walked out muttering'muttering but'so horrible ` t `'costssing had that ticket had, dissingssing'the film as that fun the mind dissing they [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.833 (perp=8.622, rec=0.104, cos=0.004), tot_loss_proj:2.394 [t=0.23s]
prediction: ["[CLS] much terrible walked out muttering '⺩ but'so horrible ` t `'costssing had that ticket had, dissingssing'the film the they fun the mind dissing that [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.840 (perp=8.686, rec=0.098, cos=0.005), tot_loss_proj:2.342 [t=0.23s]
prediction: ["[CLS] much they walked out muttering'muttering but'so horrible ` t `'costssing had that ticket had, dissingssing'the film the terrible fun n mind dissing that [SEP]"]
[ 750/2000] tot_loss=1.850 (perp=8.754, rec=0.095, cos=0.004), tot_loss_proj:2.354 [t=0.23s]
prediction: ["[CLS] much they walked out muttering '⺩ but'so horrible ` t `'costssing had that ticket had, dissingssing'the film the terrible fun n mind dissing that [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.808 (perp=8.554, rec=0.092, cos=0.005), tot_loss_proj:2.371 [t=0.23s]
prediction: ["[CLS] much they walked out muttering'but like'so horrible ` t `'costssing had'ticket had, dissingssing'the film the terrible fun n mind dissing that [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.775 (perp=8.368, rec=0.096, cos=0.005), tot_loss_proj:2.351 [t=0.23s]
prediction: ["[CLS] much walked out muttering'but like'so horrible ` t they `'costssing had'ticket had, dissingssing'the film the terrible fun n mind dissing that [SEP]"]
[ 900/2000] tot_loss=1.771 (perp=8.368, rec=0.094, cos=0.004), tot_loss_proj:2.356 [t=0.23s]
prediction: ["[CLS] much walked out muttering'but like'so horrible ` t they `'costssing had'ticket had, dissingssing'the film the terrible fun n mind dissing that [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.721 (perp=8.132, rec=0.090, cos=0.004), tot_loss_proj:2.288 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like'so horrible ` t they `'costssing had'ticket had, dissingssing'the film the terrible fun but mind dissing that [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.707 (perp=8.055, rec=0.092, cos=0.004), tot_loss_proj:2.333 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like'so horrible ` t they `'costssing had'ticket had, dissingssing'the film the terrible fun mind but dissing that [SEP]"]
[1050/2000] tot_loss=1.702 (perp=8.055, rec=0.086, cos=0.004), tot_loss_proj:2.329 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like'so horrible ` t they `'costssing had'ticket had, dissingssing'the film the terrible fun mind but dissing that [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.683 (perp=7.930, rec=0.093, cos=0.004), tot_loss_proj:2.295 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible'` t they `'costssing had'ticket had, dissingssing'the film the terrible fun mind but dissing that [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.683 (perp=7.945, rec=0.089, cos=0.005), tot_loss_proj:2.314 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible'` t they `'costssing had that ticket had, dissingssing'the film the terrible fun mind but dissing the [SEP]"]
[1200/2000] tot_loss=1.687 (perp=7.945, rec=0.094, cos=0.004), tot_loss_proj:2.314 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible'` t they `'costssing had that ticket had, dissingssing'the film the terrible fun mind but dissing the [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.601 (perp=7.547, rec=0.088, cos=0.004), tot_loss_proj:2.223 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible'` t they `'costssing'that ticket had, dissingssing'the film the terrible fun mind but dissing'[SEP]"]
Attempt swap
[1300/2000] tot_loss=1.602 (perp=7.547, rec=0.089, cos=0.004), tot_loss_proj:2.219 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible'` t they `'costssing'that ticket had, dissingssing'the film the terrible fun mind but dissing'[SEP]"]
[1350/2000] tot_loss=1.609 (perp=7.547, rec=0.095, cos=0.004), tot_loss_proj:2.213 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible'` t they `'costssing'that ticket had, dissingssing'the film the terrible fun mind but dissing'[SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.602 (perp=7.547, rec=0.089, cos=0.004), tot_loss_proj:2.221 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible'` t they `'costssing'that ticket had, dissingssing'the film the terrible fun mind but dissing'[SEP]"]
Attempt swap
[1450/2000] tot_loss=1.602 (perp=7.547, rec=0.089, cos=0.004), tot_loss_proj:2.221 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible'` t they `'costssing'that ticket had, dissingssing'the film the terrible fun mind but dissing'[SEP]"]
[1500/2000] tot_loss=1.596 (perp=7.547, rec=0.082, cos=0.004), tot_loss_proj:2.221 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible'` t they `'costssing'that ticket had, dissingssing'the film the terrible fun mind but dissing'[SEP]"]
Attempt swap
[1550/2000] tot_loss=1.595 (perp=7.547, rec=0.081, cos=0.004), tot_loss_proj:2.222 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible'` t they `'costssing'that ticket had, dissingssing'the film the terrible fun mind but dissing'[SEP]"]
Attempt swap
Moved token
[1600/2000] tot_loss=1.630 (perp=7.703, rec=0.085, cos=0.004), tot_loss_proj:2.235 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible't they ` `'costssing had that ticket had, dissingssing'the film the terrible fun mind but dissing'[SEP]"]
[1650/2000] tot_loss=1.634 (perp=7.703, rec=0.089, cos=0.004), tot_loss_proj:2.232 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible't they ` `'costssing had that ticket had, dissingssing'the film the terrible fun mind but dissing'[SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=1.615 (perp=7.611, rec=0.089, cos=0.004), tot_loss_proj:2.215 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible't they ` `'costssing had that ticket had, dissing'the film thessing terrible fun mind but dissing'[SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.609 (perp=7.611, rec=0.083, cos=0.004), tot_loss_proj:2.218 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible't they ` `'costssing had that ticket had, dissing'the film thessing terrible fun mind but dissing'[SEP]"]
[1800/2000] tot_loss=1.569 (perp=7.402, rec=0.085, cos=0.004), tot_loss_proj:2.176 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible't they ` `'costssing'that ticket had, dissing'the film thessing terrible fun mind but dissing'[SEP]"]
Attempt swap
[1850/2000] tot_loss=1.566 (perp=7.402, rec=0.082, cos=0.004), tot_loss_proj:2.177 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible't they ` `'costssing'that ticket had, dissing'the film thessing terrible fun mind but dissing'[SEP]"]
Attempt swap
[1900/2000] tot_loss=1.572 (perp=7.402, rec=0.087, cos=0.004), tot_loss_proj:2.172 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible't they ` `'costssing'that ticket had, dissing'the film thessing terrible fun mind but dissing'[SEP]"]
[1950/2000] tot_loss=1.574 (perp=7.402, rec=0.089, cos=0.004), tot_loss_proj:2.176 [t=0.23s]
prediction: ["[CLS] much walked out muttering'n like so horrible't they ` `'costssing'that ticket had, dissing'the film thessing terrible fun mind but dissing'[SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.533 (perp=7.234, rec=0.082, cos=0.004), tot_loss_proj:2.175 [t=0.23s]
prediction: ["[CLS] much walked out muttering'like so horriblen't they ` `'costssing'that ticket had, dissing'the film thessing terrible fun mind but dissing'[SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] much walked out muttering'n like so horrible't they ` `'costssing'that ticket had, dissing'the film thessing terrible fun mind but dissing'[SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 84.000 | r: 80.769
rouge2     | fm: 16.327 | p: 16.667 | r: 16.000
rougeL     | fm: 47.059 | p: 48.000 | r: 46.154
rougeLsum  | fm: 47.059 | p: 48.000 | r: 46.154
r1fm+r2fm = 98.679

[Aggregate metrics]:
rouge1     | fm: 87.549 | p: 87.259 | r: 88.055
rouge2     | fm: 53.629 | p: 53.424 | r: 53.941
rougeL     | fm: 75.142 | p: 74.949 | r: 75.625
rougeLsum  | fm: 75.307 | p: 75.051 | r: 75.736
r1fm+r2fm = 141.178

input #99 time: 0:09:02 | total time: 15:15:28


Average Cosine Similarity: 0.9987141794621793
Done with all.
