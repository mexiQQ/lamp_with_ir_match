


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.05 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 43.10it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9992712879168401
highest_index [0]
highest [0.9992712879168401]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.00263512134552 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.9441105723381042 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.9383771419525146 for ['[CLS] ronnie huff [SEP]']
[Init] best rec loss: 0.9270989298820496 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.9159544706344604 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.8545413613319397 for ['[CLS] panel officer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.190 (perp=9.874, rec=0.200, cos=0.016), tot_loss_proj:2.545 [t=0.31s]
prediction: ['[CLS] bishop disappointed [SEP]']
[ 100/2000] tot_loss=2.215 (perp=10.251, rec=0.155, cos=0.010), tot_loss_proj:2.116 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.194 (perp=10.251, rec=0.135, cos=0.009), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.195 (perp=10.251, rec=0.135, cos=0.010), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.177 (perp=10.251, rec=0.118, cos=0.009), tot_loss_proj:2.118 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.140 (perp=10.251, rec=0.087, cos=0.002), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.122 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.115 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.110 (perp=10.251, rec=0.059, cos=0.001), tot_loss_proj:2.113 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.112 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.115 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.116 (perp=10.251, rec=0.065, cos=0.001), tot_loss_proj:2.123 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.113 (perp=10.251, rec=0.062, cos=0.001), tot_loss_proj:2.128 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.117 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.108 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.116 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.120 (perp=10.251, rec=0.068, cos=0.001), tot_loss_proj:2.119 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.121 (perp=10.251, rec=0.069, cos=0.001), tot_loss_proj:2.115 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.120 (perp=10.251, rec=0.068, cos=0.001), tot_loss_proj:2.128 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.115 (perp=10.251, rec=0.064, cos=0.001), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.100 (perp=10.251, rec=0.048, cos=0.001), tot_loss_proj:2.122 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.117 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.112 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.108 (perp=10.251, rec=0.057, cos=0.001), tot_loss_proj:2.125 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.116 (perp=10.251, rec=0.064, cos=0.001), tot_loss_proj:2.113 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.103 (perp=10.251, rec=0.051, cos=0.001), tot_loss_proj:2.103 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.117 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.114 (perp=10.251, rec=0.062, cos=0.001), tot_loss_proj:2.111 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.113 (perp=10.251, rec=0.062, cos=0.001), tot_loss_proj:2.128 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.120 (perp=10.251, rec=0.068, cos=0.001), tot_loss_proj:2.124 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.105 (perp=10.251, rec=0.053, cos=0.001), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.103 (perp=10.251, rec=0.051, cos=0.001), tot_loss_proj:2.107 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.121 (perp=10.251, rec=0.070, cos=0.001), tot_loss_proj:2.121 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.103 (perp=10.251, rec=0.052, cos=0.001), tot_loss_proj:2.111 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.116 (perp=10.251, rec=0.064, cos=0.001), tot_loss_proj:2.108 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.110 (perp=10.251, rec=0.058, cos=0.001), tot_loss_proj:2.104 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.110 (perp=10.251, rec=0.058, cos=0.001), tot_loss_proj:2.126 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.117 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.125 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.104 (perp=10.251, rec=0.052, cos=0.001), tot_loss_proj:2.136 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.122 (perp=10.251, rec=0.071, cos=0.001), tot_loss_proj:2.133 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.115 (perp=10.251, rec=0.063, cos=0.001), tot_loss_proj:2.117 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.098 (perp=10.251, rec=0.046, cos=0.001), tot_loss_proj:2.131 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:12:22 | total time: 0:12:22


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9993547580813349
highest_index [0]
highest [0.9993547580813349]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.0210002660751343 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9795094728469849 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.8980085849761963 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 0.8960037231445312 for ['[CLS]heim bilingual [SEP]']
[Init] best rec loss: 0.8671682476997375 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8257623314857483 for ['[CLS] passage erupted [SEP]']
[Init] best rec loss: 0.8176046013832092 for ['[CLS] siam presidents [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.406 (perp=10.891, rec=0.225, cos=0.003), tot_loss_proj:2.527 [t=0.31s]
prediction: ['[CLS] wonderful splendid [SEP]']
[ 100/2000] tot_loss=2.226 (perp=10.288, rec=0.167, cos=0.002), tot_loss_proj:2.355 [t=0.31s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.161 (perp=10.288, rec=0.102, cos=0.001), tot_loss_proj:2.343 [t=0.31s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.124 (perp=10.288, rec=0.065, cos=0.001), tot_loss_proj:2.354 [t=0.31s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.897 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.889 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.899 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.898 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.895 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.899 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.903 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.888 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.895 (perp=9.171, rec=0.060, cos=0.001), tot_loss_proj:1.897 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.895 (perp=9.171, rec=0.060, cos=0.001), tot_loss_proj:1.891 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.899 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.906 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.892 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.895 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.899 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.898 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.001), tot_loss_proj:1.897 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.902 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.901 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.893 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.909 (perp=9.171, rec=0.074, cos=0.001), tot_loss_proj:1.887 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.899 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.901 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.898 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.897 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.896 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.901 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.900 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.896 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.900 (perp=9.171, rec=0.065, cos=0.001), tot_loss_proj:1.889 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.894 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.905 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.899 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.907 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.884 (perp=9.171, rec=0.048, cos=0.001), tot_loss_proj:1.906 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.902 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.903 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.902 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.894 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.907 (perp=9.171, rec=0.071, cos=0.001), tot_loss_proj:1.899 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.906 (perp=9.171, rec=0.070, cos=0.001), tot_loss_proj:1.885 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.912 (perp=9.171, rec=0.077, cos=0.001), tot_loss_proj:1.903 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.911 (perp=9.171, rec=0.076, cos=0.001), tot_loss_proj:1.904 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.885 (perp=9.171, rec=0.050, cos=0.001), tot_loss_proj:1.891 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.892 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.894 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.888 (perp=9.171, rec=0.052, cos=0.001), tot_loss_proj:1.896 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.883 (perp=9.171, rec=0.047, cos=0.001), tot_loss_proj:1.904 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:12:18 | total time: 0:24:40


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.999433940052584
highest_index [0]
highest [0.999433940052584]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.8385053277015686 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 0.8267150521278381 for ['[CLS] otherwise [SEP]b [SEP]']
[Init] best rec loss: 0.8140299320220947 for ['[CLS] dailypol food [SEP]']
[Init] best rec loss: 0.8029910326004028 for ['[CLS] just percussion universal [SEP]']
[Init] best rec loss: 0.7929702401161194 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 0.7857075333595276 for ['[CLS] we would working [SEP]']
[Init] best perm rec loss: 0.7834774851799011 for ['[CLS] would working we [SEP]']
[Init] best perm rec loss: 0.7759498357772827 for ['[CLS] would we working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.786 (perp=12.079, rec=0.336, cos=0.034), tot_loss_proj:3.163 [t=0.31s]
prediction: ['[CLS] culture much momentum [SEP]']
[ 100/2000] tot_loss=1.834 (perp=8.515, rec=0.128, cos=0.003), tot_loss_proj:1.811 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/2000] tot_loss=1.789 (perp=8.515, rec=0.084, cos=0.002), tot_loss_proj:1.793 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 200/2000] tot_loss=1.773 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.786 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.774 (perp=8.515, rec=0.070, cos=0.001), tot_loss_proj:1.802 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=1.760 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.795 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.796 [t=0.32s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.757 (perp=8.515, rec=0.053, cos=0.001), tot_loss_proj:1.796 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.792 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.769 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.791 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.789 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.794 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.796 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.788 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=1.777 (perp=8.515, rec=0.073, cos=0.001), tot_loss_proj:1.797 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.776 (perp=8.515, rec=0.072, cos=0.001), tot_loss_proj:1.800 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.773 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.787 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.799 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.789 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.771 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.805 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=1.773 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.801 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.789 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.762 (perp=8.515, rec=0.058, cos=0.001), tot_loss_proj:1.786 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.797 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.774 (perp=8.515, rec=0.070, cos=0.001), tot_loss_proj:1.793 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.799 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.798 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.794 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.795 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.790 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.757 (perp=8.515, rec=0.053, cos=0.001), tot_loss_proj:1.808 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.787 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=1.756 (perp=8.515, rec=0.052, cos=0.001), tot_loss_proj:1.796 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.797 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.762 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.805 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.796 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.790 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.802 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=1.770 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.792 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.762 (perp=8.515, rec=0.058, cos=0.001), tot_loss_proj:1.796 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:12:19 | total time: 0:37:00


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.9993003846865509
highest_index [0]
highest [0.9993003846865509]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.01755952835083 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9002199172973633 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.88134765625 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.879368245601654 for ['[CLS] role bart [SEP]']
[Init] best rec loss: 0.8459727168083191 for ['[CLS] gallons professor [SEP]']
[Init] best rec loss: 0.8417636752128601 for ['[CLS] anthony robin [SEP]']
[Init] best perm rec loss: 0.8354824781417847 for ['[CLS] robin anthony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.860 (perp=8.384, rec=0.180, cos=0.003), tot_loss_proj:1.756 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 100/2000] tot_loss=1.753 (perp=8.384, rec=0.075, cos=0.001), tot_loss_proj:1.753 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/2000] tot_loss=1.744 (perp=8.384, rec=0.066, cos=0.001), tot_loss_proj:1.761 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 200/2000] tot_loss=1.742 (perp=8.384, rec=0.063, cos=0.001), tot_loss_proj:1.761 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.748 (perp=8.384, rec=0.069, cos=0.001), tot_loss_proj:1.761 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.746 (perp=8.384, rec=0.068, cos=0.001), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.741 (perp=8.384, rec=0.063, cos=0.001), tot_loss_proj:1.759 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.737 (perp=8.384, rec=0.059, cos=0.001), tot_loss_proj:1.756 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.736 (perp=8.384, rec=0.058, cos=0.001), tot_loss_proj:1.756 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.736 (perp=8.384, rec=0.058, cos=0.001), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.730 (perp=8.384, rec=0.052, cos=0.001), tot_loss_proj:1.761 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.738 (perp=8.384, rec=0.060, cos=0.001), tot_loss_proj:1.749 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.730 (perp=8.384, rec=0.051, cos=0.001), tot_loss_proj:1.759 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.738 (perp=8.384, rec=0.060, cos=0.001), tot_loss_proj:1.765 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.734 (perp=8.384, rec=0.056, cos=0.001), tot_loss_proj:1.747 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.728 (perp=8.384, rec=0.050, cos=0.001), tot_loss_proj:1.747 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.727 (perp=8.384, rec=0.049, cos=0.001), tot_loss_proj:1.765 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.742 (perp=8.384, rec=0.063, cos=0.001), tot_loss_proj:1.755 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.733 (perp=8.384, rec=0.055, cos=0.001), tot_loss_proj:1.750 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.737 (perp=8.384, rec=0.058, cos=0.001), tot_loss_proj:1.749 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.734 (perp=8.384, rec=0.056, cos=0.001), tot_loss_proj:1.760 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.724 (perp=8.384, rec=0.046, cos=0.001), tot_loss_proj:1.759 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.730 (perp=8.384, rec=0.052, cos=0.001), tot_loss_proj:1.754 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.742 (perp=8.384, rec=0.064, cos=0.001), tot_loss_proj:1.754 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.737 (perp=8.384, rec=0.058, cos=0.001), tot_loss_proj:1.755 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.729 (perp=8.384, rec=0.050, cos=0.001), tot_loss_proj:1.760 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.731 (perp=8.384, rec=0.053, cos=0.001), tot_loss_proj:1.758 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.745 (perp=8.384, rec=0.066, cos=0.001), tot_loss_proj:1.764 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.743 (perp=8.384, rec=0.065, cos=0.001), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.737 (perp=8.384, rec=0.059, cos=0.001), tot_loss_proj:1.760 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.743 (perp=8.384, rec=0.065, cos=0.001), tot_loss_proj:1.772 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.747 (perp=8.384, rec=0.069, cos=0.001), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.742 (perp=8.384, rec=0.063, cos=0.001), tot_loss_proj:1.748 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.738 (perp=8.384, rec=0.060, cos=0.001), tot_loss_proj:1.769 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.725 (perp=8.384, rec=0.047, cos=0.001), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.744 (perp=8.384, rec=0.065, cos=0.001), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.738 (perp=8.384, rec=0.060, cos=0.001), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.752 (perp=8.384, rec=0.074, cos=0.001), tot_loss_proj:1.750 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.744 (perp=8.384, rec=0.066, cos=0.001), tot_loss_proj:1.745 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.736 (perp=8.384, rec=0.057, cos=0.001), tot_loss_proj:1.771 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:12:17 | total time: 0:49:17


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.9992313718988646
highest_index [0]
highest [0.9992313718988646]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.034260869026184 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9840514063835144 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.966346025466919 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9646734595298767 for ['[CLS] rally entered worldwide [SEP]']
[Init] best rec loss: 0.9353517889976501 for ['[CLS] who table christ [SEP]']
[Init] best rec loss: 0.9300948977470398 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.9250966906547546 for ['[CLS] troupe stopped clayton [SEP]']
[Init] best rec loss: 0.888353705406189 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.140 (perp=9.706, rec=0.191, cos=0.007), tot_loss_proj:2.153 [t=0.31s]
prediction: ['[CLS] tiresomently [SEP]']
[ 100/2000] tot_loss=1.594 (perp=7.516, rec=0.088, cos=0.002), tot_loss_proj:1.562 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.578 (perp=7.516, rec=0.074, cos=0.002), tot_loss_proj:1.560 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.575 (perp=7.516, rec=0.070, cos=0.001), tot_loss_proj:1.568 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.567 (perp=7.516, rec=0.062, cos=0.001), tot_loss_proj:1.568 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.572 (perp=7.516, rec=0.067, cos=0.001), tot_loss_proj:1.558 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.568 (perp=7.516, rec=0.063, cos=0.001), tot_loss_proj:1.574 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.568 (perp=7.516, rec=0.063, cos=0.001), tot_loss_proj:1.571 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.572 (perp=7.516, rec=0.068, cos=0.001), tot_loss_proj:1.563 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.578 (perp=7.516, rec=0.073, cos=0.001), tot_loss_proj:1.564 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.560 (perp=7.516, rec=0.056, cos=0.002), tot_loss_proj:1.568 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.001), tot_loss_proj:1.557 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.569 (perp=7.516, rec=0.064, cos=0.001), tot_loss_proj:1.571 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.566 (perp=7.516, rec=0.061, cos=0.001), tot_loss_proj:1.566 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.572 (perp=7.516, rec=0.067, cos=0.002), tot_loss_proj:1.566 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.557 (perp=7.516, rec=0.052, cos=0.002), tot_loss_proj:1.570 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.559 (perp=7.516, rec=0.054, cos=0.002), tot_loss_proj:1.560 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.569 (perp=7.516, rec=0.065, cos=0.002), tot_loss_proj:1.571 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.572 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.573 (perp=7.516, rec=0.068, cos=0.002), tot_loss_proj:1.571 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.573 (perp=7.516, rec=0.069, cos=0.002), tot_loss_proj:1.557 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.574 (perp=7.516, rec=0.069, cos=0.002), tot_loss_proj:1.563 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.561 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.578 (perp=7.516, rec=0.074, cos=0.002), tot_loss_proj:1.565 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.572 (perp=7.516, rec=0.068, cos=0.002), tot_loss_proj:1.559 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.576 (perp=7.516, rec=0.071, cos=0.002), tot_loss_proj:1.560 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.565 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.561 (perp=7.516, rec=0.056, cos=0.002), tot_loss_proj:1.574 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.565 (perp=7.516, rec=0.060, cos=0.002), tot_loss_proj:1.570 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.565 (perp=7.516, rec=0.061, cos=0.002), tot_loss_proj:1.573 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.565 (perp=7.516, rec=0.061, cos=0.002), tot_loss_proj:1.571 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.579 (perp=7.516, rec=0.075, cos=0.002), tot_loss_proj:1.563 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.557 (perp=7.516, rec=0.052, cos=0.002), tot_loss_proj:1.556 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.566 (perp=7.516, rec=0.062, cos=0.002), tot_loss_proj:1.578 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.573 (perp=7.516, rec=0.069, cos=0.002), tot_loss_proj:1.561 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.561 (perp=7.516, rec=0.056, cos=0.002), tot_loss_proj:1.561 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.558 (perp=7.516, rec=0.053, cos=0.002), tot_loss_proj:1.559 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.566 (perp=7.516, rec=0.061, cos=0.002), tot_loss_proj:1.560 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.568 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.558 (perp=7.516, rec=0.053, cos=0.002), tot_loss_proj:1.562 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:12:16 | total time: 1:01:34


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.999365206837056
highest_index [0]
highest [0.999365206837056]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9504615068435669 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9300938248634338 for ['[CLS] pleasant favorable [SEP]']
[Init] best rec loss: 0.9278009533882141 for ['[CLS]iv fl [SEP]']
[Init] best rec loss: 0.9112931489944458 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 0.8878228068351746 for ['[CLS] quiet. [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.451 (perp=11.370, rec=0.174, cos=0.003), tot_loss_proj:3.523 [t=0.30s]
prediction: ['[CLS] ease ease [SEP]']
[ 100/2000] tot_loss=2.555 (perp=12.316, rec=0.090, cos=0.002), tot_loss_proj:2.517 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 150/2000] tot_loss=2.532 (perp=12.316, rec=0.067, cos=0.001), tot_loss_proj:2.519 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 200/2000] tot_loss=2.535 (perp=12.316, rec=0.070, cos=0.001), tot_loss_proj:2.518 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.529 (perp=12.316, rec=0.065, cos=0.001), tot_loss_proj:2.529 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 300/2000] tot_loss=2.536 (perp=12.316, rec=0.071, cos=0.001), tot_loss_proj:2.532 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.511 (perp=12.316, rec=0.046, cos=0.001), tot_loss_proj:2.533 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.527 (perp=12.316, rec=0.062, cos=0.001), tot_loss_proj:2.534 [t=0.30s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 450/2000] tot_loss=2.523 (perp=12.316, rec=0.058, cos=0.001), tot_loss_proj:2.539 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.533 (perp=12.316, rec=0.069, cos=0.001), tot_loss_proj:2.526 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.526 (perp=12.316, rec=0.062, cos=0.001), tot_loss_proj:2.534 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 600/2000] tot_loss=2.535 (perp=12.316, rec=0.070, cos=0.001), tot_loss_proj:2.517 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.530 (perp=12.316, rec=0.066, cos=0.001), tot_loss_proj:2.524 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.517 (perp=12.316, rec=0.052, cos=0.001), tot_loss_proj:2.530 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 750/2000] tot_loss=2.520 (perp=12.316, rec=0.056, cos=0.001), tot_loss_proj:2.532 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.514 (perp=12.316, rec=0.049, cos=0.001), tot_loss_proj:2.522 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.528 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.534 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 900/2000] tot_loss=2.527 (perp=12.316, rec=0.062, cos=0.001), tot_loss_proj:2.526 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.521 (perp=12.316, rec=0.057, cos=0.001), tot_loss_proj:2.526 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1000/2000] tot_loss=2.528 (perp=12.316, rec=0.063, cos=0.001), tot_loss_proj:2.511 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1050/2000] tot_loss=2.512 (perp=12.316, rec=0.047, cos=0.001), tot_loss_proj:2.518 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1100/2000] tot_loss=2.523 (perp=12.316, rec=0.058, cos=0.001), tot_loss_proj:2.511 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1150/2000] tot_loss=2.520 (perp=12.316, rec=0.055, cos=0.001), tot_loss_proj:2.531 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1200/2000] tot_loss=2.521 (perp=12.316, rec=0.057, cos=0.001), tot_loss_proj:2.523 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1250/2000] tot_loss=2.515 (perp=12.316, rec=0.050, cos=0.001), tot_loss_proj:2.537 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1300/2000] tot_loss=2.532 (perp=12.316, rec=0.067, cos=0.001), tot_loss_proj:2.518 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1350/2000] tot_loss=2.525 (perp=12.316, rec=0.060, cos=0.001), tot_loss_proj:2.525 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1400/2000] tot_loss=2.520 (perp=12.316, rec=0.055, cos=0.001), tot_loss_proj:2.534 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1450/2000] tot_loss=2.530 (perp=12.316, rec=0.065, cos=0.001), tot_loss_proj:2.522 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1500/2000] tot_loss=2.524 (perp=12.316, rec=0.060, cos=0.001), tot_loss_proj:2.539 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1550/2000] tot_loss=2.530 (perp=12.316, rec=0.065, cos=0.001), tot_loss_proj:2.530 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1600/2000] tot_loss=2.535 (perp=12.316, rec=0.070, cos=0.001), tot_loss_proj:2.518 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1650/2000] tot_loss=2.535 (perp=12.316, rec=0.070, cos=0.001), tot_loss_proj:2.525 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1700/2000] tot_loss=2.529 (perp=12.316, rec=0.065, cos=0.001), tot_loss_proj:2.525 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1750/2000] tot_loss=2.531 (perp=12.316, rec=0.066, cos=0.001), tot_loss_proj:2.523 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1800/2000] tot_loss=2.525 (perp=12.316, rec=0.060, cos=0.001), tot_loss_proj:2.533 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1850/2000] tot_loss=2.533 (perp=12.316, rec=0.069, cos=0.001), tot_loss_proj:2.522 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1900/2000] tot_loss=2.532 (perp=12.316, rec=0.067, cos=0.001), tot_loss_proj:2.515 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1950/2000] tot_loss=2.526 (perp=12.316, rec=0.061, cos=0.001), tot_loss_proj:2.521 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[2000/2000] tot_loss=2.525 (perp=12.316, rec=0.060, cos=0.001), tot_loss_proj:2.527 [t=0.31s]
prediction: ['[CLS] enjoyable ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] enjoyable ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #5 time: 0:12:10 | total time: 1:13:44


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.9992504206717969
highest_index [0]
highest [0.9992504206717969]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9584815502166748 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9533684849739075 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.9261924028396606 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.8748291730880737 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.8652046918869019 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.8054066896438599 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7948519587516785 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.7755016684532166 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 0.7520049810409546 for ['[CLS] double deep [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.601 (perp=6.813, rec=0.223, cos=0.015), tot_loss_proj:2.717 [t=0.30s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=1.709 (perp=8.089, rec=0.088, cos=0.003), tot_loss_proj:1.692 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.687 (perp=8.089, rec=0.067, cos=0.002), tot_loss_proj:1.696 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.674 (perp=8.089, rec=0.054, cos=0.001), tot_loss_proj:1.701 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.692 (perp=8.089, rec=0.072, cos=0.002), tot_loss_proj:1.699 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.685 (perp=8.089, rec=0.066, cos=0.002), tot_loss_proj:1.693 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.676 (perp=8.089, rec=0.057, cos=0.001), tot_loss_proj:1.697 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.688 (perp=8.089, rec=0.069, cos=0.002), tot_loss_proj:1.695 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.669 (perp=8.089, rec=0.050, cos=0.001), tot_loss_proj:1.699 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.674 (perp=8.089, rec=0.054, cos=0.001), tot_loss_proj:1.685 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.676 (perp=8.089, rec=0.057, cos=0.001), tot_loss_proj:1.688 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.667 (perp=8.089, rec=0.047, cos=0.001), tot_loss_proj:1.679 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.667 (perp=8.089, rec=0.048, cos=0.001), tot_loss_proj:1.691 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.668 (perp=8.089, rec=0.049, cos=0.001), tot_loss_proj:1.690 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.681 (perp=8.089, rec=0.062, cos=0.001), tot_loss_proj:1.691 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.665 (perp=8.089, rec=0.046, cos=0.001), tot_loss_proj:1.704 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.687 (perp=8.089, rec=0.067, cos=0.001), tot_loss_proj:1.693 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.688 (perp=8.089, rec=0.069, cos=0.001), tot_loss_proj:1.693 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.676 (perp=8.089, rec=0.057, cos=0.001), tot_loss_proj:1.695 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.688 (perp=8.089, rec=0.068, cos=0.001), tot_loss_proj:1.688 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.685 (perp=8.089, rec=0.065, cos=0.001), tot_loss_proj:1.686 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.001), tot_loss_proj:1.689 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.682 (perp=8.089, rec=0.063, cos=0.001), tot_loss_proj:1.689 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.001), tot_loss_proj:1.699 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.686 (perp=8.089, rec=0.067, cos=0.001), tot_loss_proj:1.681 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.681 (perp=8.089, rec=0.062, cos=0.001), tot_loss_proj:1.700 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.678 (perp=8.089, rec=0.059, cos=0.001), tot_loss_proj:1.703 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.677 (perp=8.089, rec=0.057, cos=0.001), tot_loss_proj:1.696 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.001), tot_loss_proj:1.696 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.673 (perp=8.089, rec=0.054, cos=0.002), tot_loss_proj:1.677 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.679 (perp=8.089, rec=0.060, cos=0.001), tot_loss_proj:1.694 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.001), tot_loss_proj:1.681 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.682 (perp=8.089, rec=0.063, cos=0.001), tot_loss_proj:1.680 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.001), tot_loss_proj:1.685 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.672 (perp=8.089, rec=0.053, cos=0.001), tot_loss_proj:1.683 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.673 (perp=8.089, rec=0.054, cos=0.001), tot_loss_proj:1.682 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.672 (perp=8.089, rec=0.053, cos=0.001), tot_loss_proj:1.686 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.668 (perp=8.089, rec=0.049, cos=0.001), tot_loss_proj:1.695 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.671 (perp=8.089, rec=0.052, cos=0.001), tot_loss_proj:1.684 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.685 (perp=8.089, rec=0.066, cos=0.001), tot_loss_proj:1.693 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #6 time: 0:12:10 | total time: 1:25:55


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9991775732833206
highest_index [0]
highest [0.9991775732833206]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.9110565185546875 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8396803736686707 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8308324217796326 for ['[CLS] minor bonnetmme near routine cluster confirmed pray mail guy smooth us empty bleeding interior [CLS] relegated seen tapes in beast risk contributingds addedores [SEP]']
[Init] best rec loss: 0.829780638217926 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best rec loss: 0.7966257333755493 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best perm rec loss: 0.795365035533905 for ['[CLS] dependingzed alec disease battalion tourism none consisting sony pacific main moffat animal on manual career classicside mukherjee madagascar 17th blow rannies gold life [SEP]']
[Init] best perm rec loss: 0.7933077216148376 for ['[CLS] classics tourism alec depending gold ran manual pacific nonezed battalion career sony main 17th moffat disease mukherjee madagascar animalide consisting on life blownies [SEP]']
[Init] best perm rec loss: 0.7916086316108704 for ['[CLS] life manualzedidenies none tourism pacific consisting moffat career classics ran disease gold animal on mukherjee main alec battalion 17th madagascar depending sony blow [SEP]']
[Init] best perm rec loss: 0.7913501858711243 for ['[CLS] moffatide pacific consistingzed none on ran mukherjee tourism disease 17th gold main dependingnies classics battalion sony blow manual life animal madagascar career alec [SEP]']
[Init] best perm rec loss: 0.7902004718780518 for ['[CLS] moffat career gold disease depending classics main sony animal consistingzed ran pacific madagascar alec onnies blowide mukherjee tourism battalion life 17th none manual [SEP]']
[Init] best perm rec loss: 0.7893084287643433 for ['[CLS] gold sony depending moffat consisting disease tourism animal mukherjee nonezed pacificide main battalion madagascar alec classics career manual ran on blow 17th lifenies [SEP]']
[Init] best perm rec loss: 0.7888675332069397 for ['[CLS] alec career disease mainnies tourism classicside depending gold battalion none consisting life blow animal sony moffat mukherjee manual madagascar pacific onzed ran 17th [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.408 (perp=10.170, rec=0.350, cos=0.024), tot_loss_proj:2.905 [t=0.32s]
prediction: ['[CLS] ugly problem new problem. has quite rules or nothing problem blocked was finishing administrative problem all no. him drug separate list no ;... [SEP]']
[ 100/2000] tot_loss=2.006 (perp=8.709, rec=0.255, cos=0.010), tot_loss_proj:2.665 [t=0.32s]
prediction: ['[CLS] problem problem is problem. has no function or mind problem problem was finished mind problem is no. he 1999 which problem no love character [SEP]']
[ 150/2000] tot_loss=1.862 (perp=8.293, rec=0.198, cos=0.006), tot_loss_proj:2.505 [t=0.31s]
prediction: ['[CLS] ugly problem size problem. has no function or mind problem problem is ugly mind problem is no character he love which otherwise no love character [SEP]']
[ 200/2000] tot_loss=1.916 (perp=8.657, rec=0.179, cos=0.006), tot_loss_proj:2.586 [t=0.32s]
prediction: ['[CLS] ugly problem is factor. has no function or mind mind problem is ugly mind problem is no character he love ; otherwise no love character [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.913 (perp=8.702, rec=0.168, cos=0.005), tot_loss_proj:2.508 [t=0.32s]
prediction: ['[CLS] ugly problem is factor. he not function or mind mind problem ; ugly i problem is no character has love ; otherwise no cute character [SEP]']
[ 300/2000] tot_loss=1.793 (perp=8.264, rec=0.137, cos=0.004), tot_loss_proj:2.431 [t=0.32s]
prediction: ['[CLS] ugly problem, factor. he not function or mind mind problem ; ugly i problem is no character has love ; otherwise no cute character [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.714 (perp=7.972, rec=0.117, cos=0.003), tot_loss_proj:2.295 [t=0.32s]
prediction: ['[CLS] ugly problem here factor. he not alone or mind mind i ; the no problem is no character has love ; otherwise no cute character [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.854 (perp=8.666, rec=0.118, cos=0.003), tot_loss_proj:2.914 [t=0.32s]
prediction: ['[CLS] ugly cute here factor. he not alone or mind mind i ; the cute problem is no character has loveable otherwise no although character [SEP]']
[ 450/2000] tot_loss=1.837 (perp=8.666, rec=0.102, cos=0.003), tot_loss_proj:2.916 [t=0.32s]
prediction: ['[CLS] ugly cute here factor. he not alone or mind mind i ; the cute problem is no character has loveable otherwise no although character [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.742 (perp=8.205, rec=0.099, cos=0.003), tot_loss_proj:2.681 [t=0.32s]
prediction: ['[CLS] ugly cute here factor. he not alone or mind mind i ; though the cute problem is no character has loveable otherwise no character [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.781 (perp=8.304, rec=0.117, cos=0.004), tot_loss_proj:2.488 [t=0.32s]
prediction: ['[CLS] ugly cute here factor. he not either or mind i mind ;. the cute problem is no character has loveable otherwise no character [SEP]']
[ 600/2000] tot_loss=1.715 (perp=8.063, rec=0.100, cos=0.003), tot_loss_proj:2.584 [t=0.32s]
prediction: ['[CLS] ugly cute here factor. he not otherwise or mind i mind ;. the cute problem is no character has loveable otherwise no character [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.673 (perp=7.874, rec=0.096, cos=0.002), tot_loss_proj:2.541 [t=0.32s]
prediction: ['[CLS] ugly cute here factor. he not otherwise or otherwise i mind ;. the cute problem is no character has loveable mind no character [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.643 (perp=7.767, rec=0.087, cos=0.002), tot_loss_proj:2.473 [t=0.32s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind ;. the cute problem is no character has loveable mind no character [SEP]']
[ 750/2000] tot_loss=1.644 (perp=7.767, rec=0.088, cos=0.002), tot_loss_proj:2.463 [t=0.32s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind ;. the cute problem is no character has loveable mind no character [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.621 (perp=7.663, rec=0.086, cos=0.002), tot_loss_proj:2.435 [t=0.32s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind. ; the cute problem is no character has loveable mind no character [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.616 (perp=7.663, rec=0.081, cos=0.002), tot_loss_proj:2.444 [t=0.32s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind. ; the cute problem is no character has loveable mind no character [SEP]']
[ 900/2000] tot_loss=1.621 (perp=7.663, rec=0.086, cos=0.002), tot_loss_proj:2.440 [t=0.32s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind. ; the cute problem is no character has loveable mind no character [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.562 (perp=7.336, rec=0.092, cos=0.002), tot_loss_proj:2.407 [t=0.32s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind. the cute problem is no character has loveable mind ; no character [SEP]']
Attempt swap
[1000/2000] tot_loss=1.556 (perp=7.336, rec=0.087, cos=0.002), tot_loss_proj:2.417 [t=0.32s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind. the cute problem is no character has loveable mind ; no character [SEP]']
[1050/2000] tot_loss=1.554 (perp=7.336, rec=0.084, cos=0.002), tot_loss_proj:2.409 [t=0.32s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind. the cute problem is no character has loveable mind ; no character [SEP]']
Attempt swap
[1100/2000] tot_loss=1.551 (perp=7.336, rec=0.082, cos=0.002), tot_loss_proj:2.411 [t=0.32s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind. the cute problem is no character has loveable mind ; no character [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.510 (perp=7.131, rec=0.082, cos=0.002), tot_loss_proj:2.431 [t=0.32s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind. the cute problem is no character ; loveable mind has no character [SEP]']
[1200/2000] tot_loss=1.595 (perp=7.556, rec=0.082, cos=0.002), tot_loss_proj:2.784 [t=0.32s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind. the cute problem is no character ; loveable mind has noable [SEP]']
Attempt swap
[1250/2000] tot_loss=1.600 (perp=7.556, rec=0.087, cos=0.002), tot_loss_proj:2.782 [t=0.31s]
prediction: ['[CLS] ugly cute factor here. he not otherwise or otherwise i mind. the cute problem is no character ; loveable mind has noable [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.583 (perp=7.459, rec=0.089, cos=0.002), tot_loss_proj:3.185 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not otherwise or otherwise i mind. ugly cute problem is no character ; loveable mind has noable [SEP]']
[1350/2000] tot_loss=1.580 (perp=7.459, rec=0.086, cos=0.002), tot_loss_proj:3.188 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not otherwise or otherwise i mind. ugly cute problem is no character ; loveable mind has noable [SEP]']
Attempt swap
[1400/2000] tot_loss=1.571 (perp=7.459, rec=0.078, cos=0.002), tot_loss_proj:3.188 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not otherwise or otherwise i mind. ugly cute problem is no character ; loveable mind has noable [SEP]']
Attempt swap
[1450/2000] tot_loss=1.577 (perp=7.459, rec=0.083, cos=0.002), tot_loss_proj:3.187 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not otherwise or otherwise i mind. ugly cute problem is no character ; loveable mind has noable [SEP]']
[1500/2000] tot_loss=1.572 (perp=7.459, rec=0.078, cos=0.002), tot_loss_proj:3.188 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not otherwise or otherwise i mind. ugly cute problem is no character ; loveable mind has noable [SEP]']
Attempt swap
[1550/2000] tot_loss=1.578 (perp=7.459, rec=0.085, cos=0.002), tot_loss_proj:3.191 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not otherwise or otherwise i mind. ugly cute problem is no character ; loveable mind has noable [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.554 (perp=7.329, rec=0.087, cos=0.002), tot_loss_proj:3.074 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not mind or otherwise i mind. ugly cute problem is no character ; loveable otherwise has noable [SEP]']
[1650/2000] tot_loss=1.553 (perp=7.329, rec=0.086, cos=0.002), tot_loss_proj:3.072 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not mind or otherwise i mind. ugly cute problem is no character ; loveable otherwise has noable [SEP]']
Attempt swap
[1700/2000] tot_loss=1.545 (perp=7.329, rec=0.078, cos=0.002), tot_loss_proj:3.069 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not mind or otherwise i mind. ugly cute problem is no character ; loveable otherwise has noable [SEP]']
Attempt swap
[1750/2000] tot_loss=1.550 (perp=7.329, rec=0.082, cos=0.002), tot_loss_proj:3.069 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not mind or otherwise i mind. ugly cute problem is no character ; loveable otherwise has noable [SEP]']
[1800/2000] tot_loss=1.543 (perp=7.329, rec=0.076, cos=0.002), tot_loss_proj:3.071 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not mind or otherwise i mind. ugly cute problem is no character ; loveable otherwise has noable [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.550 (perp=7.313, rec=0.086, cos=0.002), tot_loss_proj:3.075 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not mind or i otherwise mind. ugly cute problem is no character ; loveable otherwise has noable [SEP]']
Attempt swap
[1900/2000] tot_loss=1.542 (perp=7.313, rec=0.077, cos=0.002), tot_loss_proj:3.077 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not mind or i otherwise mind. ugly cute problem is no character ; loveable otherwise has noable [SEP]']
[1950/2000] tot_loss=1.543 (perp=7.313, rec=0.079, cos=0.002), tot_loss_proj:3.073 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not mind or i otherwise mind. ugly cute problem is no character ; loveable otherwise has noable [SEP]']
Attempt swap
[2000/2000] tot_loss=1.543 (perp=7.313, rec=0.079, cos=0.002), tot_loss_proj:3.073 [t=0.32s]
prediction: ['[CLS] the cute factor here. he not mind or i otherwise mind. ugly cute problem is no character ; loveable otherwise has noable [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] the cute factor here. he not mind or otherwise i mind. ugly cute problem is no character ; loveable otherwise has noable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.364 | p: 82.609 | r: 90.476
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 68.182 | p: 65.217 | r: 71.429
rougeLsum  | fm: 68.182 | p: 65.217 | r: 71.429
r1fm+r2fm = 124.459

[Aggregate metrics]:
rouge1     | fm: 98.295 | p: 97.826 | r: 98.810
rouge2     | fm: 92.262 | p: 92.045 | r: 92.500
rougeL     | fm: 96.023 | p: 95.652 | r: 96.429
rougeLsum  | fm: 96.023 | p: 95.652 | r: 96.429
r1fm+r2fm = 190.557

input #7 time: 0:12:34 | total time: 1:38:30


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9994021855831061
highest_index [0]
highest [0.9994021855831061]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.7527031302452087 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.7128511071205139 for ['[CLS] assassins able a bowled palace times drive camequal happens silver only foreign shelley pumping nbc camp easy payyo bigutounded meaning [SEP]']
[Init] best rec loss: 0.6936152577400208 for ['[CLS]dry pace hash mike parker guard defence disease relief studentquest steiner downdin dance domain briefly crystal beech reason newcastle kai prenostic [SEP]']
[Init] best rec loss: 0.6827031373977661 for ['[CLS] air namely fourjun nkend neitherdf rich ; bit healthcare formula noon abdul drill parks pr daylight longitude tent milo usaas [SEP]']
[Init] best rec loss: 0.6819156408309937 for ['[CLS] normal bo set supreme something justified brahms mmmering age forward deafting wins backchen growth frozeere romney fighting crawl popularity copy [SEP]']
[Init] best rec loss: 0.6762113571166992 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.6757290363311768 for ['[CLS] sense bc dani actually ceased look thunder launch old doin translated ordainedrk case legal privately vatican pilot language sqldine turing midnight guard [SEP]']
[Init] best rec loss: 0.6651756167411804 for ['[CLS] eisenhower plaque arkansas screens sweat adventuremei wanda productey dna prison canontta tail franchise facts res si february season sociallydent badminton [SEP]']
[Init] best perm rec loss: 0.6645129919052124 for ['[CLS] badminton february plaque season tail arkansas prison resdenttta canon sweat eisenhower facts adventure screens dna productmei franchise siey socially wanda [SEP]']
[Init] best perm rec loss: 0.6642963290214539 for ['[CLS] seasondent arkansasmei badminton eisenhowerey facts socially february prison res si product plaque wanda tail adventure dna screens canon sweat franchisetta [SEP]']
[Init] best perm rec loss: 0.6626808047294617 for ['[CLS] screensmei adventure tail wanda february res canon socially eisenhower facts badminton prisondentey season arkansas si plaque dna franchisetta product sweat [SEP]']
[Init] best perm rec loss: 0.6625219583511353 for ['[CLS] product screens franchiseey eisenhower plaquedent seasonmeitta socially prison february adventure badminton canon res dna si facts arkansas tail wanda sweat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.636 (perp=11.280, rec=0.344, cos=0.036), tot_loss_proj:3.973 [t=0.31s]
prediction: ['[CLS] surely tax himself scary crisis film event vanity damage criteria handle ; fake vanity film hysteria doom might vanity dollars enlist mexican help tri [SEP]']
[ 100/2000] tot_loss=2.727 (perp=12.200, rec=0.260, cos=0.027), tot_loss_proj:3.661 [t=0.31s]
prediction: ['[CLS] doubt elections itself fright camera film doubt vanity what debt nicholas vanity no vanity film vanity fright might vanity paid pays a helping off [SEP]']
[ 150/2000] tot_loss=2.495 (perp=11.344, rec=0.212, cos=0.014), tot_loss_proj:3.490 [t=0.31s]
prediction: ['[CLS] doubt elections itself fright film no doubt vanity what debt straight vanity no vanity film vanity fright might vanity pays pays a that off [SEP]']
[ 200/2000] tot_loss=2.370 (perp=10.896, rec=0.183, cos=0.008), tot_loss_proj:3.400 [t=0.32s]
prediction: ["[CLS] doubt elections'fright film film doubt vanity what debt films vanity no vanity film vanity fright might vanity pays pays a that off [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.369 (perp=10.907, rec=0.169, cos=0.019), tot_loss_proj:3.273 [t=0.32s]
prediction: ["[CLS] doubt owed'fright film no doubt vanity what debtberry no vanity vanity film vanity fright upon vanity pays pays a that off [SEP]"]
[ 300/2000] tot_loss=2.793 (perp=11.260, rec=0.393, cos=0.149), tot_loss_proj:3.455 [t=0.32s]
prediction: ["[CLS] doubt creditors'fright moral [SEP], vanity what debt mira no vanity vanity film vanity fright when vanity pays pays a that off [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.541 (perp=11.222, rec=0.263, cos=0.034), tot_loss_proj:3.673 [t=0.31s]
prediction: ['[CLS] doubt and s facto feeling fright, vanity what debti no missionulsive film vanity fright when your all pays an that off [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.294 (perp=10.425, rec=0.200, cos=0.010), tot_loss_proj:3.501 [t=0.31s]
prediction: ['[CLS] doubt and s political feeling fright, vanity what debt that no conspiracyulsive film vanity fright when political not pays ai off [SEP]']
[ 450/2000] tot_loss=2.174 (perp=9.940, rec=0.179, cos=0.006), tot_loss_proj:3.236 [t=0.32s]
prediction: ['[CLS] doubt and s hear sound fright, vanity what debt that no filmial film vanity fright when said not pays ai off [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.263 (perp=10.488, rec=0.160, cos=0.006), tot_loss_proj:3.514 [t=0.32s]
prediction: ['[CLS] doubt and s hear sound fright, vanity what debt that no filmial film vanity fright owed owed not pays ai off [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.146 (perp=9.977, rec=0.145, cos=0.006), tot_loss_proj:3.372 [t=0.32s]
prediction: ['[CLS] doubt and s hear feeling fright, vanity what debt that no filmial film vanity fright all owed owed pays ai off [SEP]']
[ 600/2000] tot_loss=2.297 (perp=10.735, rec=0.146, cos=0.004), tot_loss_proj:3.430 [t=0.32s]
prediction: ['[CLS] doubt and s indie felt fright, vanity what debt that no filmless film vanity fright off owed felt pays ai off [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.259 (perp=10.557, rec=0.142, cos=0.006), tot_loss_proj:3.250 [t=0.32s]
prediction: ['[CLS] doubt to s fright felt fright,max what debt that no filmless film vanity hear off owed felt pays ai off [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.173 (perp=10.119, rec=0.144, cos=0.005), tot_loss_proj:3.174 [t=0.32s]
prediction: ['[CLS] doubtful s fright felt fright,max what debt that no film to film vanity indie off owed felt pays ai off [SEP]']
[ 750/2000] tot_loss=2.203 (perp=10.316, rec=0.136, cos=0.004), tot_loss_proj:3.221 [t=0.32s]
prediction: ['[CLS] doubtful s fright felt fright,max what debt that no film to film vanity noticed off owed felt pays ai off [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.149 (perp=10.091, rec=0.127, cos=0.004), tot_loss_proj:3.153 [t=0.32s]
prediction: ['[CLS] doubtful s fright felt fright,max what debt that no film to film vanity ¨ off owed felt pays off ai [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.084 (perp=9.776, rec=0.124, cos=0.005), tot_loss_proj:3.081 [t=0.31s]
prediction: ['[CLS] doubtful s fright felt fright,max what debt that no film to film vanity owed off benign felt pays off ai [SEP]']
[ 900/2000] tot_loss=2.084 (perp=9.776, rec=0.125, cos=0.003), tot_loss_proj:3.080 [t=0.32s]
prediction: ['[CLS] doubtful s fright felt fright,max what debt that no film to film vanity owed off benign felt pays off ai [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.236 (perp=10.548, rec=0.123, cos=0.003), tot_loss_proj:3.278 [t=0.32s]
prediction: ['[CLS] doubtful s fright felt fright,max what debt that no benign to film felt owed off benign vanity paysman ai [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.158 (perp=10.164, rec=0.121, cos=0.004), tot_loss_proj:3.200 [t=0.32s]
prediction: ['[CLS] doubtful s fright felt fright,max what debt that no benign to film felt owed off a vanity paysman benigni [SEP]']
[1050/2000] tot_loss=2.157 (perp=10.164, rec=0.121, cos=0.003), tot_loss_proj:3.201 [t=0.32s]
prediction: ['[CLS] doubtful s fright felt fright,max what debt that no benign to film felt owed off a vanity paysman benigni [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.021 (perp=9.485, rec=0.121, cos=0.003), tot_loss_proj:3.202 [t=0.32s]
prediction: ['[CLS] doubtful s fright felt fright, benign tomax what debt that no film felt owed off a vanity paysman benigni [SEP]']
Attempt swap
[1150/2000] tot_loss=2.022 (perp=9.485, rec=0.122, cos=0.003), tot_loss_proj:3.199 [t=0.32s]
prediction: ['[CLS] doubtful s fright felt fright, benign tomax what debt that no film felt owed off a vanity paysman benigni [SEP]']
[1200/2000] tot_loss=2.009 (perp=9.485, rec=0.109, cos=0.003), tot_loss_proj:3.193 [t=0.32s]
prediction: ['[CLS] doubtful s fright felt fright, benign tomax what debt that no film felt owed off a vanity paysman benigni [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.972 (perp=9.268, rec=0.115, cos=0.003), tot_loss_proj:3.424 [t=0.32s]
prediction: ['[CLS]ful s fright felt fright, benign to doubtmax what debt that no film felt owed off a vanity paysman benigni [SEP]']
Attempt swap
[1300/2000] tot_loss=1.971 (perp=9.268, rec=0.115, cos=0.003), tot_loss_proj:3.418 [t=0.32s]
prediction: ['[CLS]ful s fright felt fright, benign to doubtmax what debt that no film felt owed off a vanity paysman benigni [SEP]']
[1350/2000] tot_loss=1.967 (perp=9.268, rec=0.111, cos=0.003), tot_loss_proj:3.422 [t=0.32s]
prediction: ['[CLS]ful s fright felt fright, benign to doubtmax what debt that no film felt owed off a vanity paysman benigni [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.889 (perp=8.877, rec=0.110, cos=0.003), tot_loss_proj:3.434 [t=0.32s]
prediction: ['[CLS] s fright felt frightful, benign to doubtmax what debt that no film felt owed off a vanity paysman benigni [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.856 (perp=8.642, rec=0.123, cos=0.005), tot_loss_proj:3.437 [t=0.32s]
prediction: ['[CLS] s film felt frightful, benign to doubtmax what debt that no fright felt owed off a vanity paysman benigni [SEP]']
[1500/2000] tot_loss=1.846 (perp=8.642, rec=0.115, cos=0.003), tot_loss_proj:3.428 [t=0.32s]
prediction: ['[CLS] s film felt frightful, benign to doubtmax what debt that no fright felt owed off a vanity paysman benigni [SEP]']
Attempt swap
[1550/2000] tot_loss=1.841 (perp=8.642, rec=0.110, cos=0.003), tot_loss_proj:3.430 [t=0.32s]
prediction: ['[CLS] s film felt frightful, benign to doubtmax what debt that no fright felt owed off a vanity paysman benigni [SEP]']
Attempt swap
[1600/2000] tot_loss=1.841 (perp=8.642, rec=0.110, cos=0.003), tot_loss_proj:3.431 [t=0.32s]
prediction: ['[CLS] s film felt frightful, benign to doubtmax what debt that no fright felt owed off a vanity paysman benigni [SEP]']
[1650/2000] tot_loss=1.842 (perp=8.642, rec=0.111, cos=0.003), tot_loss_proj:3.429 [t=0.32s]
prediction: ['[CLS] s film felt frightful, benign to doubtmax what debt that no fright felt owed off a vanity paysman benigni [SEP]']
Attempt swap
[1700/2000] tot_loss=1.842 (perp=8.642, rec=0.112, cos=0.003), tot_loss_proj:3.433 [t=0.32s]
prediction: ['[CLS] s film felt frightful, benign to doubtmax what debt that no fright felt owed off a vanity paysman benigni [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.849 (perp=8.642, rec=0.118, cos=0.003), tot_loss_proj:3.429 [t=0.32s]
prediction: ['[CLS] s film felt frightful, benign to doubtmax what debt that no fright felt owed off a vanity paysman benigni [SEP]']
[1800/2000] tot_loss=1.841 (perp=8.642, rec=0.110, cos=0.003), tot_loss_proj:3.427 [t=0.32s]
prediction: ['[CLS] s film felt frightful, benign to doubtmax what debt that no fright felt owed off a vanity paysman benigni [SEP]']
Attempt swap
[1850/2000] tot_loss=1.840 (perp=8.642, rec=0.109, cos=0.003), tot_loss_proj:3.432 [t=0.32s]
prediction: ['[CLS] s film felt frightful, benign to doubtmax what debt that no fright felt owed off a vanity paysman benigni [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.816 (perp=8.495, rec=0.113, cos=0.004), tot_loss_proj:3.415 [t=0.32s]
prediction: ['[CLS] s film felt frightful, benign to doubt what debt that no fright feltmax owed off a vanity paysman benigni [SEP]']
[1950/2000] tot_loss=1.803 (perp=8.495, rec=0.100, cos=0.003), tot_loss_proj:3.411 [t=0.31s]
prediction: ['[CLS] s film felt frightful, benign to doubt what debt that no fright feltmax owed off a vanity paysman benigni [SEP]']
Attempt swap
[2000/2000] tot_loss=1.816 (perp=8.495, rec=0.114, cos=0.003), tot_loss_proj:3.414 [t=0.32s]
prediction: ['[CLS] s film felt frightful, benign to doubt what debt that no fright feltmax owed off a vanity paysman benigni [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] s film felt frightful, benign to doubtmax what debt that no fright felt owed off a vanity paysman benigni [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.049 | p: 76.190 | r: 80.000
rouge2     | fm: 20.513 | p: 20.000 | r: 21.053
rougeL     | fm: 43.902 | p: 42.857 | r: 45.000
rougeLsum  | fm: 43.902 | p: 42.857 | r: 45.000
r1fm+r2fm = 98.562

[Aggregate metrics]:
rouge1     | fm: 96.046 | p: 95.422 | r: 96.720
rouge2     | fm: 84.290 | p: 84.040 | r: 84.561
rougeL     | fm: 90.232 | p: 89.786 | r: 90.714
rougeLsum  | fm: 90.232 | p: 89.786 | r: 90.714
r1fm+r2fm = 180.336

input #8 time: 0:12:33 | total time: 1:51:03


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9993983749203398
highest_index [0]
highest [0.9993983749203398]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.8170323967933655 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.7734487056732178 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.7307882308959961 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.7211014628410339 for ['[CLS] owners pad there arena da rico weekly family [SEP]']
[Init] best rec loss: 0.6827848553657532 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 0.6776694059371948 for ['[CLS] red sh dipped in outstretched hour go imagine [SEP]']
[Init] best rec loss: 0.6561876535415649 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6545783877372742 for ['[CLS] edward arsenal luck deaths decca outlaw codydden [SEP]']
[Init] best perm rec loss: 0.6535321474075317 for ['[CLS]dden outlaw arsenal edward decca deaths cody luck [SEP]']
[Init] best perm rec loss: 0.6506661772727966 for ['[CLS] decca arsenal deaths codydden luck outlaw edward [SEP]']
[Init] best perm rec loss: 0.649726390838623 for ['[CLS] arsenal decca deaths codydden outlaw edward luck [SEP]']
[Init] best perm rec loss: 0.6479645371437073 for ['[CLS] arsenal edward luck deccadden cody outlaw deaths [SEP]']
[Init] best perm rec loss: 0.6471970081329346 for ['[CLS] deaths luck codydden edward decca outlaw arsenal [SEP]']
[Init] best perm rec loss: 0.6464781761169434 for ['[CLS] cody outlaw luck deathsdden arsenal edward decca [SEP]']
[Init] best perm rec loss: 0.644521176815033 for ['[CLS] deaths arsenal cody edwarddden outlaw luck decca [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.484 (perp=10.336, rec=0.335, cos=0.081), tot_loss_proj:3.070 [t=0.31s]
prediction: ['[CLS] orhead robin offen party softleg [SEP]']
[ 100/2000] tot_loss=2.537 (perp=11.735, rec=0.183, cos=0.007), tot_loss_proj:3.677 [t=0.31s]
prediction: ['[CLS] ofhead metaphysical softee introduce claptra [SEP]']
[ 150/2000] tot_loss=2.440 (perp=11.360, rec=0.154, cos=0.014), tot_loss_proj:3.178 [t=0.31s]
prediction: ['[CLS] of soft metaphysical softedhead claptra [SEP]']
[ 200/2000] tot_loss=2.622 (perp=12.461, rec=0.122, cos=0.007), tot_loss_proj:3.197 [t=0.31s]
prediction: ['[CLS] of softhead metaphysicalphead claptra [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.059 (perp=9.719, rec=0.111, cos=0.005), tot_loss_proj:2.495 [t=0.31s]
prediction: ['[CLS] of softhead metaphysicalhead claptrap [SEP]']
[ 300/2000] tot_loss=2.039 (perp=9.719, rec=0.093, cos=0.002), tot_loss_proj:2.478 [t=0.31s]
prediction: ['[CLS] of softhead metaphysicalhead claptrap [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.881 (perp=8.971, rec=0.085, cos=0.002), tot_loss_proj:2.318 [t=0.31s]
prediction: ['[CLS] of metaphysical softheadhead claptrap [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.866 (perp=8.971, rec=0.070, cos=0.002), tot_loss_proj:2.311 [t=0.31s]
prediction: ['[CLS] of metaphysical softheadhead claptrap [SEP]']
[ 450/2000] tot_loss=1.880 (perp=8.971, rec=0.084, cos=0.002), tot_loss_proj:2.311 [t=0.31s]
prediction: ['[CLS] of metaphysical softheadhead claptrap [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.736 (perp=8.283, rec=0.077, cos=0.002), tot_loss_proj:2.155 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheadhead [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.739 (perp=8.283, rec=0.080, cos=0.001), tot_loss_proj:2.143 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheadhead [SEP]']
[ 600/2000] tot_loss=1.567 (perp=7.429, rec=0.080, cos=0.001), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.551 (perp=7.429, rec=0.064, cos=0.001), tot_loss_proj:1.755 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.552 (perp=7.429, rec=0.065, cos=0.001), tot_loss_proj:1.758 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[ 750/2000] tot_loss=1.558 (perp=7.429, rec=0.071, cos=0.001), tot_loss_proj:1.756 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.551 (perp=7.429, rec=0.065, cos=0.001), tot_loss_proj:1.762 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.559 (perp=7.429, rec=0.072, cos=0.001), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[ 900/2000] tot_loss=1.545 (perp=7.429, rec=0.058, cos=0.001), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.553 (perp=7.429, rec=0.066, cos=0.001), tot_loss_proj:1.749 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1000/2000] tot_loss=1.552 (perp=7.429, rec=0.065, cos=0.001), tot_loss_proj:1.765 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1050/2000] tot_loss=1.542 (perp=7.429, rec=0.055, cos=0.001), tot_loss_proj:1.762 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1100/2000] tot_loss=1.549 (perp=7.429, rec=0.063, cos=0.001), tot_loss_proj:1.755 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1150/2000] tot_loss=1.544 (perp=7.429, rec=0.057, cos=0.001), tot_loss_proj:1.749 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1200/2000] tot_loss=1.555 (perp=7.429, rec=0.068, cos=0.001), tot_loss_proj:1.762 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1250/2000] tot_loss=1.560 (perp=7.429, rec=0.073, cos=0.001), tot_loss_proj:1.764 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1300/2000] tot_loss=1.551 (perp=7.429, rec=0.064, cos=0.001), tot_loss_proj:1.760 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1350/2000] tot_loss=1.546 (perp=7.429, rec=0.059, cos=0.001), tot_loss_proj:1.761 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1400/2000] tot_loss=1.554 (perp=7.429, rec=0.067, cos=0.001), tot_loss_proj:1.760 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1450/2000] tot_loss=1.550 (perp=7.429, rec=0.063, cos=0.001), tot_loss_proj:1.762 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1500/2000] tot_loss=1.558 (perp=7.429, rec=0.071, cos=0.001), tot_loss_proj:1.761 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1550/2000] tot_loss=1.551 (perp=7.429, rec=0.064, cos=0.001), tot_loss_proj:1.759 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1600/2000] tot_loss=1.549 (perp=7.429, rec=0.062, cos=0.001), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1650/2000] tot_loss=1.546 (perp=7.429, rec=0.059, cos=0.001), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1700/2000] tot_loss=1.547 (perp=7.429, rec=0.060, cos=0.001), tot_loss_proj:1.763 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1750/2000] tot_loss=1.549 (perp=7.429, rec=0.062, cos=0.001), tot_loss_proj:1.760 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1800/2000] tot_loss=1.553 (perp=7.429, rec=0.066, cos=0.001), tot_loss_proj:1.759 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1850/2000] tot_loss=1.551 (perp=7.429, rec=0.064, cos=0.001), tot_loss_proj:1.758 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1900/2000] tot_loss=1.547 (perp=7.429, rec=0.060, cos=0.001), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1950/2000] tot_loss=1.544 (perp=7.429, rec=0.057, cos=0.001), tot_loss_proj:1.756 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[2000/2000] tot_loss=1.547 (perp=7.429, rec=0.060, cos=0.001), tot_loss_proj:1.755 [t=0.31s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical claptrap softheaded [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 96.441 | p: 95.880 | r: 97.048
rouge2     | fm: 79.861 | p: 79.636 | r: 80.105
rougeL     | fm: 89.542 | p: 89.141 | r: 89.976
rougeLsum  | fm: 89.542 | p: 89.286 | r: 89.976
r1fm+r2fm = 176.302

input #9 time: 0:12:15 | total time: 2:03:19


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9991483463434161
highest_index [0]
highest [0.9991483463434161]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8765961527824402 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8695704340934753 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8258469700813293 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best rec loss: 0.8148667812347412 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.8055123686790466 for ['[CLS] hidelin swing reacher immediately championship nervous accompaniedcar eva pounded besides help [SEP]']
[Init] best perm rec loss: 0.8050639629364014 for ['[CLS] pounded immediately eva reacher hidelin nervous accompanied championship swing besidescar help [SEP]']
[Init] best perm rec loss: 0.8041734099388123 for ['[CLS] immediately swing reacher championshipcar eva pounded accompanied help hidelin besides nervous [SEP]']
[Init] best perm rec loss: 0.8038550615310669 for ['[CLS] besidescarelin immediately nervous reacher swing eva hid pounded accompanied help championship [SEP]']
[Init] best perm rec loss: 0.8037804961204529 for ['[CLS] besides accompanied pounded immediately hid nervouscarelin championship swing reacher help eva [SEP]']
[Init] best perm rec loss: 0.8033781051635742 for ['[CLS] help immediately accompanied nervous pounded swing reacher hid evaelin besides championshipcar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.887 (perp=12.561, rec=0.356, cos=0.019), tot_loss_proj:3.977 [t=0.30s]
prediction: ['[CLS] genres hours. play ( nathaniel techniques fuel effects relation stables agency worthy [SEP]']
[ 100/2000] tot_loss=2.509 (perp=11.142, rec=0.273, cos=0.008), tot_loss_proj:3.702 [t=0.31s]
prediction: ['[CLS] balance hours. ; additionally instinct forces balance boots relation rhythms rhythmsfast [SEP]']
[ 150/2000] tot_loss=2.344 (perp=10.490, rec=0.240, cos=0.006), tot_loss_proj:3.180 [t=0.31s]
prediction: ['[CLS] ably..fully ably balance ab relation rhythms rhythmsfast [SEP]']
[ 200/2000] tot_loss=1.834 (perp=8.233, rec=0.181, cos=0.006), tot_loss_proj:2.650 [t=0.31s]
prediction: ['[CLS] ably..ly ably balance ably rhythms rhythms ariel [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.241 (perp=10.112, rec=0.209, cos=0.009), tot_loss_proj:3.106 [t=0.31s]
prediction: ['[CLS] ably. storiesly abulsive forces balancesly rhythms rhythms [SEP]']
[ 300/2000] tot_loss=2.281 (perp=10.523, rec=0.171, cos=0.006), tot_loss_proj:3.163 [t=0.31s]
prediction: ['[CLS] ablyly incidently abulsive forces balance really rhythms rhythms [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.114 (perp=9.807, rec=0.149, cos=0.004), tot_loss_proj:2.931 [t=0.31s]
prediction: ['[CLS] ably incidently ably incident real balance really rhythms rhythms [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.456 (perp=11.380, rec=0.174, cos=0.006), tot_loss_proj:3.139 [t=0.31s]
prediction: ['[CLS] ab.ulsively ably incident rhythms balance realvinsky real rhythms [SEP]']
[ 450/2000] tot_loss=2.110 (perp=9.808, rec=0.143, cos=0.005), tot_loss_proj:2.943 [t=0.31s]
prediction: ['[CLS] ab.ulsivelyulsively incident rhythms balance really incident rhythms [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.103 (perp=9.816, rec=0.136, cos=0.004), tot_loss_proj:2.987 [t=0.31s]
prediction: ['[CLS] ab.ulsively really incident rhythms balanceulsive - incident rhythms [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.186 (perp=10.209, rec=0.140, cos=0.004), tot_loss_proj:2.931 [t=0.31s]
prediction: ['[CLS] ab.ulsively really incident - balance [SEP] rhythmsulsive rhythms [SEP]']
[ 600/2000] tot_loss=2.179 (perp=10.209, rec=0.133, cos=0.004), tot_loss_proj:2.930 [t=0.31s]
prediction: ['[CLS] ab.ulsively really incident - balance [SEP] rhythmsulsive rhythms [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.149 (perp=10.078, rec=0.130, cos=0.003), tot_loss_proj:2.833 [t=0.31s]
prediction: ['[CLS] ab.ulsively really incident - balance rhythms [SEP] rhythms rhythms [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.127 (perp=9.947, rec=0.133, cos=0.004), tot_loss_proj:2.938 [t=0.31s]
prediction: ['[CLS] abulsive.ly really incident - balance rhythms [SEP] rhythms rhythms [SEP]']
[ 750/2000] tot_loss=2.221 (perp=10.487, rec=0.121, cos=0.003), tot_loss_proj:2.879 [t=0.31s]
prediction: ['[CLS] ab rhythms.ly really incident - balance rhythms [SEP] rhythms rhythms [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.171 (perp=10.221, rec=0.124, cos=0.003), tot_loss_proj:2.767 [t=0.31s]
prediction: ['[CLS] ab rhythms.ly really incident [SEP] balance rhythms - rhythms rhythms [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.089 (perp=9.823, rec=0.120, cos=0.004), tot_loss_proj:2.691 [t=0.31s]
prediction: ['[CLS] ab rhythms.ly really incident [SEP] balance with rhythms - rhythms [SEP]']
[ 900/2000] tot_loss=2.086 (perp=9.823, rec=0.118, cos=0.003), tot_loss_proj:2.694 [t=0.31s]
prediction: ['[CLS] ab rhythms.ly really incident [SEP] balance with rhythms - rhythms [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.030 (perp=9.522, rec=0.122, cos=0.003), tot_loss_proj:2.570 [t=0.31s]
prediction: ['[CLS] ab.ly really incident [SEP] balance rhythms with rhythms - time [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.926 (perp=9.031, rec=0.117, cos=0.003), tot_loss_proj:2.437 [t=0.31s]
prediction: ['[CLS] ably. really incident [SEP] balance rhythms with rhythms - time [SEP]']
[1050/2000] tot_loss=1.917 (perp=9.031, rec=0.108, cos=0.003), tot_loss_proj:2.438 [t=0.31s]
prediction: ['[CLS] ably. really incident [SEP] balance rhythms with rhythms - time [SEP]']
Attempt swap
[1100/2000] tot_loss=1.925 (perp=9.031, rec=0.116, cos=0.003), tot_loss_proj:2.438 [t=0.31s]
prediction: ['[CLS] ably. really incident [SEP] balance rhythms with rhythms - time [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.869 (perp=8.775, rec=0.110, cos=0.004), tot_loss_proj:2.394 [t=0.31s]
prediction: ['[CLS] ably. really incident [SEP] balance rhythms - rhythms with time [SEP]']
[1200/2000] tot_loss=1.881 (perp=8.775, rec=0.122, cos=0.003), tot_loss_proj:2.398 [t=0.31s]
prediction: ['[CLS] ably. really incident [SEP] balance rhythms - rhythms with time [SEP]']
Attempt swap
[1250/2000] tot_loss=1.874 (perp=8.775, rec=0.115, cos=0.003), tot_loss_proj:2.394 [t=0.31s]
prediction: ['[CLS] ably. really incident [SEP] balance rhythms - rhythms with time [SEP]']
Attempt swap
[1300/2000] tot_loss=1.868 (perp=8.775, rec=0.110, cos=0.003), tot_loss_proj:2.391 [t=0.31s]
prediction: ['[CLS] ably. really incident [SEP] balance rhythms - rhythms with time [SEP]']
[1350/2000] tot_loss=1.768 (perp=8.253, rec=0.115, cos=0.003), tot_loss_proj:2.315 [t=0.31s]
prediction: ['[CLS] ably. really incident. balance rhythms - rhythms with time [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.972 (perp=9.286, rec=0.112, cos=0.003), tot_loss_proj:2.700 [t=0.31s]
prediction: ['[CLS] ably. really boyfriend balance rhythms. incident rhythms with time [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.863 (perp=8.730, rec=0.114, cos=0.003), tot_loss_proj:2.507 [t=0.31s]
prediction: ['[CLS] ably. really boyfriend rhythms. balance incident rhythms with time [SEP]']
[1500/2000] tot_loss=1.871 (perp=8.730, rec=0.122, cos=0.003), tot_loss_proj:2.502 [t=0.31s]
prediction: ['[CLS] ably. really boyfriend rhythms. balance incident rhythms with time [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.843 (perp=8.603, rec=0.119, cos=0.003), tot_loss_proj:2.431 [t=0.31s]
prediction: ['[CLS] ably. really boyfriend rhythms balance incident rhythms with time. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.805 (perp=8.436, rec=0.115, cos=0.003), tot_loss_proj:2.577 [t=0.31s]
prediction: ['[CLS] ably rhythms really boyfriend. balance incident rhythms with time. [SEP]']
[1650/2000] tot_loss=1.796 (perp=8.436, rec=0.106, cos=0.003), tot_loss_proj:2.583 [t=0.31s]
prediction: ['[CLS] ably rhythms really boyfriend. balance incident rhythms with time. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.914 (perp=9.028, rec=0.106, cos=0.003), tot_loss_proj:2.671 [t=0.31s]
prediction: ['[CLS] ably rhythms real. boyfriendly balance incident rhythms with time - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.792 (perp=8.413, rec=0.107, cos=0.003), tot_loss_proj:2.510 [t=0.31s]
prediction: ['[CLS] ably rhythms real. boyfriendly balance incident rhythms with time. [SEP]']
[1800/2000] tot_loss=1.794 (perp=8.413, rec=0.109, cos=0.003), tot_loss_proj:2.507 [t=0.31s]
prediction: ['[CLS] ably rhythms real. boyfriendly balance incident rhythms with time. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.737 (perp=8.055, rec=0.123, cos=0.003), tot_loss_proj:2.562 [t=0.31s]
prediction: ['[CLS] ably rhythms real. boyfriend rhythms balance incidently with time. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.662 (perp=7.654, rec=0.127, cos=0.004), tot_loss_proj:2.270 [t=0.31s]
prediction: ['[CLS] boyfriend ably rhythms real. rhythms balance incidently with time. [SEP]']
[1950/2000] tot_loss=1.650 (perp=7.654, rec=0.116, cos=0.003), tot_loss_proj:2.276 [t=0.31s]
prediction: ['[CLS] boyfriend ably rhythms real. rhythms balance incidently with time. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.649 (perp=7.654, rec=0.115, cos=0.003), tot_loss_proj:2.277 [t=0.31s]
prediction: ['[CLS] boyfriend ably rhythms real. rhythms balance incidently with time. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] ably rhythms really boyfriend. balance incident rhythms with time. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 63.636 | r: 70.000
rouge2     | fm: 21.053 | p: 20.000 | r: 22.222
rougeL     | fm: 47.619 | p: 45.455 | r: 50.000
rougeLsum  | fm: 47.619 | p: 45.455 | r: 50.000
r1fm+r2fm = 87.719

[Aggregate metrics]:
rouge1     | fm: 93.734 | p: 92.949 | r: 94.589
rouge2     | fm: 74.515 | p: 74.215 | r: 74.843
rougeL     | fm: 85.731 | p: 85.169 | r: 86.342
rougeLsum  | fm: 86.068 | p: 85.405 | r: 86.797
r1fm+r2fm = 168.249

input #10 time: 0:12:15 | total time: 2:15:34


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9992849200928435
highest_index [0]
highest [0.9992849200928435]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.9156510233879089 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.9010090231895447 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.8231529593467712 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.8202220797538757 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.8084673285484314 for ['[CLS]ture inlandvd tal me platform drawngu mile familiar [SEP]']
[Init] best perm rec loss: 0.8078896999359131 for ['[CLS] inland mileture drawn platformgu tal me familiarvd [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.113 (perp=13.846, rec=0.325, cos=0.019), tot_loss_proj:4.181 [t=0.31s]
prediction: ['[CLS] but gel tried refused stubborn gel gel stubborn refuseded [SEP]']
[ 100/2000] tot_loss=2.809 (perp=12.907, rec=0.215, cos=0.012), tot_loss_proj:3.789 [t=0.31s]
prediction: ['[CLS] was gel attempted refused stubborn gel gel stubborn stubbornly [SEP]']
[ 150/2000] tot_loss=2.577 (perp=12.140, rec=0.144, cos=0.005), tot_loss_proj:3.430 [t=0.31s]
prediction: ['[CLS] was attempted that refused stubborn gel gel stubborn stubbornly [SEP]']
[ 200/2000] tot_loss=2.563 (perp=12.156, rec=0.128, cos=0.004), tot_loss_proj:3.321 [t=0.31s]
prediction: ['[CLS] was attempted that refused stubborn gel gel here stubbornly [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.094 (perp=9.931, rec=0.106, cos=0.003), tot_loss_proj:2.973 [t=0.31s]
prediction: ['[CLS] was attempted that gel stubborn refused gel here stubbornly [SEP]']
[ 300/2000] tot_loss=2.082 (perp=9.931, rec=0.094, cos=0.002), tot_loss_proj:2.976 [t=0.31s]
prediction: ['[CLS] was attempted that gel stubborn refused gel here stubbornly [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.916 (perp=9.052, rec=0.103, cos=0.002), tot_loss_proj:2.893 [t=0.31s]
prediction: ['[CLS] here was attempted that gel stubborn refused gel stubbornly [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.883 (perp=8.883, rec=0.105, cos=0.002), tot_loss_proj:2.717 [t=0.31s]
prediction: ['[CLS] here was attempted that gel stubborn gel stubbornly refused [SEP]']
[ 450/2000] tot_loss=1.874 (perp=8.883, rec=0.096, cos=0.002), tot_loss_proj:2.717 [t=0.31s]
prediction: ['[CLS] here was attempted that gel stubborn gel stubbornly refused [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.809 (perp=8.602, rec=0.087, cos=0.002), tot_loss_proj:2.646 [t=0.31s]
prediction: ['[CLS] here was attempted gel that stubborn gel stubbornly refused [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.743 (perp=8.281, rec=0.085, cos=0.002), tot_loss_proj:2.610 [t=0.31s]
prediction: ['[CLS] here was attempted gel that gel stubborn stubbornly refused [SEP]']
[ 600/2000] tot_loss=1.745 (perp=8.281, rec=0.087, cos=0.002), tot_loss_proj:2.615 [t=0.31s]
prediction: ['[CLS] here was attempted gel that gel stubborn stubbornly refused [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.741 (perp=8.281, rec=0.083, cos=0.002), tot_loss_proj:2.612 [t=0.31s]
prediction: ['[CLS] here was attempted gel that gel stubborn stubbornly refused [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.746 (perp=8.281, rec=0.088, cos=0.001), tot_loss_proj:2.617 [t=0.31s]
prediction: ['[CLS] here was attempted gel that gel stubborn stubbornly refused [SEP]']
[ 750/2000] tot_loss=1.742 (perp=8.281, rec=0.084, cos=0.001), tot_loss_proj:2.614 [t=0.31s]
prediction: ['[CLS] here was attempted gel that gel stubborn stubbornly refused [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.918 (perp=9.174, rec=0.082, cos=0.001), tot_loss_proj:2.836 [t=0.31s]
prediction: ['[CLS] here was attempted to that gel stubborn stubbornly refused [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.589 (perp=7.523, rec=0.083, cos=0.002), tot_loss_proj:2.479 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[ 900/2000] tot_loss=1.587 (perp=7.523, rec=0.081, cos=0.001), tot_loss_proj:2.476 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.583 (perp=7.523, rec=0.077, cos=0.001), tot_loss_proj:2.476 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1000/2000] tot_loss=1.591 (perp=7.523, rec=0.085, cos=0.001), tot_loss_proj:2.482 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[1050/2000] tot_loss=1.588 (perp=7.523, rec=0.082, cos=0.001), tot_loss_proj:2.478 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1100/2000] tot_loss=1.586 (perp=7.523, rec=0.080, cos=0.001), tot_loss_proj:2.472 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1150/2000] tot_loss=1.595 (perp=7.523, rec=0.089, cos=0.001), tot_loss_proj:2.477 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[1200/2000] tot_loss=1.581 (perp=7.523, rec=0.075, cos=0.001), tot_loss_proj:2.475 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1250/2000] tot_loss=1.591 (perp=7.523, rec=0.085, cos=0.001), tot_loss_proj:2.474 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1300/2000] tot_loss=1.589 (perp=7.523, rec=0.083, cos=0.001), tot_loss_proj:2.479 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[1350/2000] tot_loss=1.583 (perp=7.523, rec=0.077, cos=0.001), tot_loss_proj:2.470 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1400/2000] tot_loss=1.581 (perp=7.523, rec=0.075, cos=0.001), tot_loss_proj:2.471 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1450/2000] tot_loss=1.577 (perp=7.523, rec=0.071, cos=0.001), tot_loss_proj:2.478 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[1500/2000] tot_loss=1.580 (perp=7.523, rec=0.074, cos=0.001), tot_loss_proj:2.480 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1550/2000] tot_loss=1.575 (perp=7.523, rec=0.069, cos=0.001), tot_loss_proj:2.473 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1600/2000] tot_loss=1.585 (perp=7.523, rec=0.079, cos=0.001), tot_loss_proj:2.473 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[1650/2000] tot_loss=1.593 (perp=7.523, rec=0.087, cos=0.001), tot_loss_proj:2.471 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1700/2000] tot_loss=1.584 (perp=7.523, rec=0.078, cos=0.001), tot_loss_proj:2.473 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1750/2000] tot_loss=1.585 (perp=7.523, rec=0.079, cos=0.001), tot_loss_proj:2.476 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[1800/2000] tot_loss=1.580 (perp=7.523, rec=0.074, cos=0.001), tot_loss_proj:2.478 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1850/2000] tot_loss=1.582 (perp=7.523, rec=0.076, cos=0.001), tot_loss_proj:2.477 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1900/2000] tot_loss=1.587 (perp=7.523, rec=0.081, cos=0.001), tot_loss_proj:2.475 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[1950/2000] tot_loss=1.582 (perp=7.523, rec=0.076, cos=0.001), tot_loss_proj:2.476 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[2000/2000] tot_loss=1.588 (perp=7.523, rec=0.082, cos=0.001), tot_loss_proj:2.481 [t=0.31s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 110.909

[Aggregate metrics]:
rouge1     | fm: 93.656 | p: 93.001 | r: 94.318
rouge2     | fm: 70.017 | p: 69.697 | r: 70.361
rougeL     | fm: 83.944 | p: 83.462 | r: 84.470
rougeLsum  | fm: 84.017 | p: 83.509 | r: 84.702
r1fm+r2fm = 163.673

input #11 time: 0:12:14 | total time: 2:27:48


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.9993444101543685
highest_index [0]
highest [0.9993444101543685]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8681085705757141 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.8608728051185608 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 0.8040461540222168 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7765296101570129 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.770782470703125 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7420695424079895 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best perm rec loss: 0.7389398813247681 for ['[CLS] lay shadesitas few translatenction office margin series beth guess victor hayn [SEP]']
[Init] best perm rec loss: 0.7379571199417114 for ['[CLS] translateitas lay few ha office victoryn bethnction series shades guess margin [SEP]']
[Init] best perm rec loss: 0.7371015548706055 for ['[CLS] beth translate few ha margin office shades seriesitas lay victornctionyn guess [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.404 (perp=10.353, rec=0.294, cos=0.039), tot_loss_proj:2.948 [t=0.31s]
prediction: ['[CLS] is looked estimate better find optic advantage for cable cable hardly grade no cable [SEP]']
[ 100/2000] tot_loss=2.235 (perp=10.181, rec=0.181, cos=0.018), tot_loss_proj:2.950 [t=0.31s]
prediction: ['[CLS] is looked barely better seen advantage advantage on cable cable barely barely its cable [SEP]']
[ 150/2000] tot_loss=2.150 (perp=9.999, rec=0.141, cos=0.008), tot_loss_proj:2.793 [t=0.31s]
prediction: ['[CLS] will seen especially better seen to advantage on cable cable barely barely its its [SEP]']
[ 200/2000] tot_loss=2.199 (perp=10.410, rec=0.111, cos=0.007), tot_loss_proj:2.869 [t=0.31s]
prediction: ['[CLS] will seen especially better to on advantage on cable cable its barely its its [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.245 (perp=10.685, rec=0.102, cos=0.006), tot_loss_proj:2.935 [t=0.31s]
prediction: ['[CLS] will seen especially better tolis advantage considering cable cable its barely on its [SEP]']
[ 300/2000] tot_loss=2.229 (perp=10.685, rec=0.088, cos=0.004), tot_loss_proj:2.941 [t=0.31s]
prediction: ['[CLS] will seen especially better tolis advantage considering cable cable its barely on its [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.080 (perp=9.920, rec=0.092, cos=0.004), tot_loss_proj:2.721 [t=0.31s]
prediction: ['[CLS] will seen especiallylis to better advantage considering cable cable its barely on its [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.981 (perp=9.431, rec=0.090, cos=0.004), tot_loss_proj:2.831 [t=0.31s]
prediction: ['[CLS] will seenlis especially to better advantage considering cable cable its barely on its [SEP]']
[ 450/2000] tot_loss=1.974 (perp=9.431, rec=0.085, cos=0.003), tot_loss_proj:2.836 [t=0.31s]
prediction: ['[CLS] will seenlis especially to better advantage considering cable cable its barely on its [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.890 (perp=9.050, rec=0.078, cos=0.003), tot_loss_proj:2.561 [t=0.31s]
prediction: ['[CLS] will seenlis especially to better advantage cable cable considering its barely on that [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.897 (perp=9.092, rec=0.076, cos=0.003), tot_loss_proj:2.821 [t=0.31s]
prediction: ['[CLS] will seen iec especially to better advantage cable cable on its barely considering that [SEP]']
[ 600/2000] tot_loss=1.898 (perp=9.092, rec=0.077, cos=0.002), tot_loss_proj:2.817 [t=0.31s]
prediction: ['[CLS] will seen iec especially to better advantage cable cable on its barely considering that [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.885 (perp=9.021, rec=0.079, cos=0.002), tot_loss_proj:2.702 [t=0.31s]
prediction: ['[CLS] will seen iec especially to better advantage cable cable barely on its considering that [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.880 (perp=8.998, rec=0.078, cos=0.003), tot_loss_proj:2.454 [t=0.31s]
prediction: ['[CLS] will seen un especially to better advantage cable barely on its cable considering that [SEP]']
[ 750/2000] tot_loss=1.879 (perp=8.998, rec=0.078, cos=0.002), tot_loss_proj:2.454 [t=0.31s]
prediction: ['[CLS] will seen un especially to better advantage cable barely on its cable considering that [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.870 (perp=8.998, rec=0.069, cos=0.002), tot_loss_proj:2.458 [t=0.31s]
prediction: ['[CLS] will seen un especially to better advantage cable barely on its cable considering that [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.761 (perp=8.452, rec=0.068, cos=0.003), tot_loss_proj:2.553 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
[ 900/2000] tot_loss=1.770 (perp=8.452, rec=0.078, cos=0.002), tot_loss_proj:2.548 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.767 (perp=8.452, rec=0.074, cos=0.002), tot_loss_proj:2.551 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1000/2000] tot_loss=1.762 (perp=8.452, rec=0.070, cos=0.002), tot_loss_proj:2.553 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
[1050/2000] tot_loss=1.760 (perp=8.452, rec=0.067, cos=0.002), tot_loss_proj:2.548 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1100/2000] tot_loss=1.768 (perp=8.452, rec=0.076, cos=0.002), tot_loss_proj:2.546 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1150/2000] tot_loss=1.766 (perp=8.452, rec=0.074, cos=0.002), tot_loss_proj:2.548 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
[1200/2000] tot_loss=1.766 (perp=8.452, rec=0.073, cos=0.002), tot_loss_proj:2.547 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1250/2000] tot_loss=1.765 (perp=8.452, rec=0.073, cos=0.002), tot_loss_proj:2.546 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1300/2000] tot_loss=1.769 (perp=8.452, rec=0.077, cos=0.002), tot_loss_proj:2.542 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
[1350/2000] tot_loss=1.762 (perp=8.452, rec=0.070, cos=0.002), tot_loss_proj:2.544 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1400/2000] tot_loss=1.763 (perp=8.452, rec=0.071, cos=0.002), tot_loss_proj:2.537 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1450/2000] tot_loss=1.764 (perp=8.452, rec=0.071, cos=0.002), tot_loss_proj:2.541 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
[1500/2000] tot_loss=1.773 (perp=8.452, rec=0.081, cos=0.002), tot_loss_proj:2.541 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1550/2000] tot_loss=1.770 (perp=8.452, rec=0.077, cos=0.002), tot_loss_proj:2.544 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1600/2000] tot_loss=1.754 (perp=8.452, rec=0.062, cos=0.002), tot_loss_proj:2.545 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
[1650/2000] tot_loss=1.757 (perp=8.452, rec=0.065, cos=0.002), tot_loss_proj:2.543 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1700/2000] tot_loss=1.761 (perp=8.452, rec=0.068, cos=0.002), tot_loss_proj:2.539 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1750/2000] tot_loss=1.768 (perp=8.452, rec=0.075, cos=0.002), tot_loss_proj:2.537 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
[1800/2000] tot_loss=1.762 (perp=8.452, rec=0.070, cos=0.002), tot_loss_proj:2.537 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1850/2000] tot_loss=1.772 (perp=8.452, rec=0.080, cos=0.002), tot_loss_proj:2.544 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[1900/2000] tot_loss=1.766 (perp=8.452, rec=0.074, cos=0.002), tot_loss_proj:2.544 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
[1950/2000] tot_loss=1.765 (perp=8.452, rec=0.073, cos=0.002), tot_loss_proj:2.539 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Attempt swap
[2000/2000] tot_loss=1.764 (perp=8.452, rec=0.072, cos=0.002), tot_loss_proj:2.543 [t=0.31s]
prediction: ['[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] will seen cable especially to better advantage cable barely on its un considering that [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.323 | p: 87.500 | r: 93.333
rouge2     | fm: 20.690 | p: 20.000 | r: 21.429
rougeL     | fm: 58.065 | p: 56.250 | r: 60.000
rougeLsum  | fm: 58.065 | p: 56.250 | r: 60.000
r1fm+r2fm = 111.012

[Aggregate metrics]:
rouge1     | fm: 93.328 | p: 92.483 | r: 94.242
rouge2     | fm: 66.128 | p: 65.874 | r: 66.455
rougeL     | fm: 81.906 | p: 81.372 | r: 82.567
rougeLsum  | fm: 81.903 | p: 81.262 | r: 82.574
r1fm+r2fm = 159.455

input #12 time: 0:12:14 | total time: 2:40:02


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9992544424269131
highest_index [0]
highest [0.9992544424269131]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.8909909725189209 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8846002221107483 for ['[CLS] te saw thunder fame ambulance concerts pinch [SEP]']
[Init] best rec loss: 0.8531202673912048 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7814970016479492 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.7685928344726562 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 0.7517247796058655 for ['[CLS]typic malice avenue andy rightart brought [SEP]']
[Init] best rec loss: 0.7466758489608765 for ['[CLS] arm permanent rowe precision cardinal defeational [SEP]']
[Init] best perm rec loss: 0.746026337146759 for ['[CLS] precisionional rowe permanent cardinal arm defeat [SEP]']
[Init] best perm rec loss: 0.7459110021591187 for ['[CLS] cardinalional rowe permanent arm defeat precision [SEP]']
[Init] best perm rec loss: 0.7453235387802124 for ['[CLS]ional permanent cardinal arm precision defeat rowe [SEP]']
[Init] best perm rec loss: 0.7435516119003296 for ['[CLS]ional rowe precision arm cardinal defeat permanent [SEP]']
[Init] best perm rec loss: 0.7431109547615051 for ['[CLS] permanent cardinal rowe precision armional defeat [SEP]']
[Init] best perm rec loss: 0.7428683042526245 for ['[CLS] permanent precisionional cardinal rowe arm defeat [SEP]']
[Init] best perm rec loss: 0.742540717124939 for ['[CLS]ional permanent cardinal precision rowe arm defeat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.718 (perp=11.634, rec=0.338, cos=0.054), tot_loss_proj:3.510 [t=0.30s]
prediction: ['[CLS] ] kick explosion objects sudden flame explode [SEP]']
[ 100/2000] tot_loss=2.302 (perp=10.127, rec=0.257, cos=0.019), tot_loss_proj:3.279 [t=0.31s]
prediction: ['[CLS] point switch into things because flame point [SEP]']
[ 150/2000] tot_loss=2.060 (perp=9.343, rec=0.179, cos=0.013), tot_loss_proj:3.520 [t=0.31s]
prediction: ['[CLS] at reason into things because flame point [SEP]']
[ 200/2000] tot_loss=2.146 (perp=10.061, rec=0.129, cos=0.005), tot_loss_proj:2.850 [t=0.31s]
prediction: ['[CLS] at point explode things because flame point [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.880 (perp=8.683, rec=0.136, cos=0.007), tot_loss_proj:2.838 [t=0.31s]
prediction: ['[CLS] at explode things when at flame point [SEP]']
[ 300/2000] tot_loss=2.208 (perp=10.440, rec=0.113, cos=0.006), tot_loss_proj:3.522 [t=0.31s]
prediction: ['[CLS] at explode things which give flame point [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.826 (perp=8.570, rec=0.109, cos=0.004), tot_loss_proj:2.590 [t=0.31s]
prediction: ['[CLS] at which things explode into flame point [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.437 (perp=6.423, rec=0.142, cos=0.010), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 450/2000] tot_loss=1.402 (perp=6.423, rec=0.113, cos=0.004), tot_loss_proj:2.104 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.377 (perp=6.423, rec=0.089, cos=0.003), tot_loss_proj:2.112 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.369 (perp=6.423, rec=0.081, cos=0.003), tot_loss_proj:2.108 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 600/2000] tot_loss=1.373 (perp=6.423, rec=0.086, cos=0.003), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.375 (perp=6.423, rec=0.088, cos=0.002), tot_loss_proj:2.112 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.369 (perp=6.423, rec=0.082, cos=0.002), tot_loss_proj:2.112 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 750/2000] tot_loss=1.369 (perp=6.423, rec=0.082, cos=0.002), tot_loss_proj:2.115 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.361 (perp=6.423, rec=0.074, cos=0.002), tot_loss_proj:2.111 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.360 (perp=6.423, rec=0.073, cos=0.002), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 900/2000] tot_loss=1.355 (perp=6.423, rec=0.068, cos=0.002), tot_loss_proj:2.109 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.358 (perp=6.423, rec=0.071, cos=0.002), tot_loss_proj:2.115 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.371 (perp=6.423, rec=0.084, cos=0.002), tot_loss_proj:2.108 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1050/2000] tot_loss=1.360 (perp=6.423, rec=0.073, cos=0.002), tot_loss_proj:2.115 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.366 (perp=6.423, rec=0.079, cos=0.002), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.368 (perp=6.423, rec=0.081, cos=0.002), tot_loss_proj:2.104 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1200/2000] tot_loss=1.358 (perp=6.423, rec=0.071, cos=0.002), tot_loss_proj:2.109 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.358 (perp=6.423, rec=0.071, cos=0.002), tot_loss_proj:2.111 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.364 (perp=6.423, rec=0.077, cos=0.002), tot_loss_proj:2.112 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1350/2000] tot_loss=1.364 (perp=6.423, rec=0.077, cos=0.002), tot_loss_proj:2.109 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.360 (perp=6.423, rec=0.073, cos=0.002), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.358 (perp=6.423, rec=0.071, cos=0.002), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1500/2000] tot_loss=1.362 (perp=6.423, rec=0.075, cos=0.002), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.355 (perp=6.423, rec=0.068, cos=0.002), tot_loss_proj:2.109 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.352 (perp=6.423, rec=0.066, cos=0.002), tot_loss_proj:2.118 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1650/2000] tot_loss=1.363 (perp=6.423, rec=0.076, cos=0.002), tot_loss_proj:2.112 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.351 (perp=6.423, rec=0.064, cos=0.002), tot_loss_proj:2.108 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.354 (perp=6.423, rec=0.067, cos=0.002), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1800/2000] tot_loss=1.361 (perp=6.423, rec=0.075, cos=0.002), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.359 (perp=6.423, rec=0.073, cos=0.002), tot_loss_proj:2.112 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.360 (perp=6.423, rec=0.073, cos=0.002), tot_loss_proj:2.113 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1950/2000] tot_loss=1.358 (perp=6.423, rec=0.071, cos=0.002), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.361 (perp=6.423, rec=0.074, cos=0.002), tot_loss_proj:2.117 [t=0.31s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] at that point things explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 93.883 | p: 93.108 | r: 94.757
rouge2     | fm: 64.080 | p: 63.766 | r: 64.397
rougeL     | fm: 81.609 | p: 80.993 | r: 82.217
rougeLsum  | fm: 81.875 | p: 81.304 | r: 82.577
r1fm+r2fm = 157.963

input #13 time: 0:12:14 | total time: 2:52:17


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.999322900304694
highest_index [0]
highest [0.999322900304694]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9602795839309692 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9388285875320435 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9258549809455872 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9158294200897217 for ['[CLS] bar these catch arms state [SEP]']
[Init] best rec loss: 0.9134268760681152 for ['[CLS] models cordytness gun [SEP]']
[Init] best rec loss: 0.8937990665435791 for ['[CLS] return him always kolkata frame [SEP]']
[Init] best rec loss: 0.8714027404785156 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8698181509971619 for ['[CLS] [MASK] harold myers sprayed tom [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.633 (perp=12.150, rec=0.200, cos=0.002), tot_loss_proj:2.903 [t=0.30s]
prediction: ['[CLS]carbon filmbly intriguing intriguing [SEP]']
[ 100/2000] tot_loss=2.066 (perp=9.874, rec=0.089, cos=0.001), tot_loss_proj:2.431 [t=0.31s]
prediction: ['[CLS] und filmeniably intriguing [SEP]']
[ 150/2000] tot_loss=2.050 (perp=9.874, rec=0.074, cos=0.001), tot_loss_proj:2.435 [t=0.31s]
prediction: ['[CLS] und filmeniably intriguing [SEP]']
[ 200/2000] tot_loss=2.044 (perp=9.874, rec=0.068, cos=0.001), tot_loss_proj:2.431 [t=0.31s]
prediction: ['[CLS] und filmeniably intriguing [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.427 (perp=6.728, rec=0.080, cos=0.002), tot_loss_proj:1.420 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 300/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.413 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.408 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.415 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.416 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 450/2000] tot_loss=1.400 (perp=6.728, rec=0.053, cos=0.001), tot_loss_proj:1.417 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.407 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.413 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.415 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.402 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.399 (perp=6.728, rec=0.052, cos=0.001), tot_loss_proj:1.409 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.407 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.407 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.407 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.400 (perp=6.728, rec=0.053, cos=0.001), tot_loss_proj:1.408 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.412 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.412 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.409 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.409 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.415 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.400 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.413 (perp=6.728, rec=0.066, cos=0.001), tot_loss_proj:1.421 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.405 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.412 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.409 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.416 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.412 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.401 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.409 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.414 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.419 (perp=6.728, rec=0.072, cos=0.001), tot_loss_proj:1.411 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.397 (perp=6.728, rec=0.050, cos=0.001), tot_loss_proj:1.414 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.417 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.402 (perp=6.728, rec=0.055, cos=0.001), tot_loss_proj:1.407 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.414 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.401 (perp=6.728, rec=0.055, cos=0.001), tot_loss_proj:1.407 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.409 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.266 | p: 93.568 | r: 95.088
rouge2     | fm: 66.451 | p: 66.220 | r: 66.739
rougeL     | fm: 82.920 | p: 82.466 | r: 83.559
rougeLsum  | fm: 83.036 | p: 82.513 | r: 83.626
r1fm+r2fm = 160.718

input #14 time: 0:12:13 | total time: 3:04:30


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.9992728167540883
highest_index [0]
highest [0.9992728167540883]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9708386063575745 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.9323186278343201 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 0.9214028716087341 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.9075021743774414 for ['[CLS] society worth jobsuit brick winrained circuit [SEP]']
[Init] best rec loss: 0.9065884947776794 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8942552208900452 for ['[CLS]che carolezard multi zone rhythmic watervating [SEP]']
[Init] best rec loss: 0.8848713636398315 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8838770985603333 for ['[CLS] 0 humanities metaphor olivia easily fetch first sweden [SEP]']
[Init] best perm rec loss: 0.8811982274055481 for ['[CLS] humanities easily metaphor 0 first fetch sweden olivia [SEP]']
[Init] best perm rec loss: 0.873102068901062 for ['[CLS] first sweden 0 metaphor fetch humanities easily olivia [SEP]']
[Init] best perm rec loss: 0.8728723526000977 for ['[CLS] first fetch sweden 0 metaphor olivia humanities easily [SEP]']
[Init] best perm rec loss: 0.8722373843193054 for ['[CLS] first humanities fetch easily sweden metaphor 0 olivia [SEP]']
[Init] best perm rec loss: 0.8704622983932495 for ['[CLS] olivia first fetch metaphor 0 sweden humanities easily [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.524 (perp=11.429, rec=0.232, cos=0.006), tot_loss_proj:3.207 [t=0.31s]
prediction: ['[CLS]ably efficient terminus efficient simply complianceably successful [SEP]']
[ 100/2000] tot_loss=2.228 (perp=10.241, rec=0.176, cos=0.004), tot_loss_proj:3.410 [t=0.31s]
prediction: ['[CLS]ably anonymous chill efficient chillerably. [SEP]']
[ 150/2000] tot_loss=2.119 (perp=9.947, rec=0.127, cos=0.002), tot_loss_proj:3.400 [t=0.31s]
prediction: ['[CLS]ably anonymous chill efficient chiller suit, [SEP]']
[ 200/2000] tot_loss=2.090 (perp=9.947, rec=0.098, cos=0.002), tot_loss_proj:3.405 [t=0.31s]
prediction: ['[CLS]ably anonymous chill efficient chiller suit, [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.957 (perp=9.090, rec=0.137, cos=0.002), tot_loss_proj:2.254 [t=0.31s]
prediction: ['[CLS] suitably anonymous chill efficient chiller, [SEP]']
[ 300/2000] tot_loss=1.961 (perp=9.427, rec=0.074, cos=0.002), tot_loss_proj:2.612 [t=0.31s]
prediction: ['[CLS] suitably anonymouser efficient chill., [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.627 (perp=7.639, rec=0.097, cos=0.002), tot_loss_proj:1.790 [t=0.31s]
prediction: ['[CLS] suitably anonymous. efficient chiller, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.508 (perp=7.125, rec=0.082, cos=0.002), tot_loss_proj:1.660 [t=0.31s]
prediction: ['[CLS] suitably anonymous, efficient chiller. [SEP]']
[ 450/2000] tot_loss=1.494 (perp=7.125, rec=0.068, cos=0.001), tot_loss_proj:1.652 [t=0.31s]
prediction: ['[CLS] suitably anonymous, efficient chiller. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.404 (perp=6.697, rec=0.063, cos=0.001), tot_loss_proj:1.519 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.399 (perp=6.697, rec=0.058, cos=0.001), tot_loss_proj:1.531 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 600/2000] tot_loss=1.407 (perp=6.697, rec=0.066, cos=0.001), tot_loss_proj:1.528 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.411 (perp=6.697, rec=0.070, cos=0.001), tot_loss_proj:1.532 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.407 (perp=6.697, rec=0.067, cos=0.001), tot_loss_proj:1.519 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.404 (perp=6.697, rec=0.064, cos=0.001), tot_loss_proj:1.529 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.412 (perp=6.697, rec=0.071, cos=0.001), tot_loss_proj:1.526 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.404 (perp=6.697, rec=0.063, cos=0.001), tot_loss_proj:1.516 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.408 (perp=6.697, rec=0.067, cos=0.001), tot_loss_proj:1.523 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.413 (perp=6.697, rec=0.072, cos=0.001), tot_loss_proj:1.522 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.413 (perp=6.697, rec=0.072, cos=0.001), tot_loss_proj:1.523 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.406 (perp=6.697, rec=0.066, cos=0.001), tot_loss_proj:1.522 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.410 (perp=6.697, rec=0.069, cos=0.001), tot_loss_proj:1.513 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.395 (perp=6.697, rec=0.054, cos=0.001), tot_loss_proj:1.529 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.400 (perp=6.697, rec=0.060, cos=0.001), tot_loss_proj:1.524 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.400 (perp=6.697, rec=0.059, cos=0.001), tot_loss_proj:1.518 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.408 (perp=6.697, rec=0.068, cos=0.001), tot_loss_proj:1.517 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.397 (perp=6.697, rec=0.056, cos=0.001), tot_loss_proj:1.526 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.409 (perp=6.697, rec=0.068, cos=0.001), tot_loss_proj:1.520 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.413 (perp=6.697, rec=0.072, cos=0.001), tot_loss_proj:1.514 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.390 (perp=6.697, rec=0.049, cos=0.001), tot_loss_proj:1.516 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.401 (perp=6.697, rec=0.060, cos=0.001), tot_loss_proj:1.518 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.401 (perp=6.697, rec=0.060, cos=0.001), tot_loss_proj:1.528 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.409 (perp=6.697, rec=0.068, cos=0.001), tot_loss_proj:1.515 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.404 (perp=6.697, rec=0.063, cos=0.001), tot_loss_proj:1.523 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.406 (perp=6.697, rec=0.065, cos=0.001), tot_loss_proj:1.524 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.400 (perp=6.697, rec=0.060, cos=0.001), tot_loss_proj:1.523 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.400 (perp=6.697, rec=0.059, cos=0.001), tot_loss_proj:1.515 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.404 (perp=6.697, rec=0.064, cos=0.001), tot_loss_proj:1.513 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.400 (perp=6.697, rec=0.060, cos=0.001), tot_loss_proj:1.530 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.411 (perp=6.697, rec=0.070, cos=0.001), tot_loss_proj:1.519 [t=0.31s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 94.697 | p: 94.067 | r: 95.409
rouge2     | fm: 64.879 | p: 64.616 | r: 65.131
rougeL     | fm: 82.866 | p: 82.390 | r: 83.468
rougeLsum  | fm: 82.844 | p: 82.333 | r: 83.389
r1fm+r2fm = 159.576

input #15 time: 0:12:15 | total time: 3:16:46


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9993414008022848
highest_index [0]
highest [0.9993414008022848]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.0187135934829712 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.9016075134277344 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7404358386993408 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best perm rec loss: 0.7396780252456665 for ['[CLS] alta film various slowly lordathi [SEP]']
[Init] best perm rec loss: 0.738109827041626 for ['[CLS] slowly alta filmathi various lord [SEP]']
[Init] best perm rec loss: 0.7364063858985901 for ['[CLS] various film lordathi alta slowly [SEP]']
[Init] best perm rec loss: 0.7362836003303528 for ['[CLS] various lordathi slowly alta film [SEP]']
[Init] best perm rec loss: 0.7336819171905518 for ['[CLS] various lord film altaathi slowly [SEP]']
[Init] best perm rec loss: 0.733069658279419 for ['[CLS] film various slowly alta lordathi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.451 (perp=9.123, rec=0.489, cos=0.137), tot_loss_proj:3.715 [t=0.30s]
prediction: ['[CLS] were themselves slowed was that adding [SEP]']
[ 100/2000] tot_loss=2.003 (perp=8.100, rec=0.336, cos=0.047), tot_loss_proj:3.652 [t=0.31s]
prediction: ['[CLS] all that slowed more that all [SEP]']
[ 150/2000] tot_loss=1.724 (perp=7.235, rec=0.250, cos=0.027), tot_loss_proj:2.070 [t=0.31s]
prediction: ['[CLS] all this and of more all [SEP]']
[ 200/2000] tot_loss=1.815 (perp=7.498, rec=0.275, cos=0.041), tot_loss_proj:2.183 [t=0.31s]
prediction: ['[CLS] and this and of more all [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.303 (perp=5.708, rec=0.146, cos=0.015), tot_loss_proj:1.768 [t=0.31s]
prediction: ['[CLS] and this and more of all [SEP]']
[ 300/2000] tot_loss=1.263 (perp=5.708, rec=0.115, cos=0.006), tot_loss_proj:1.766 [t=0.31s]
prediction: ['[CLS] and this and more of all [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.392 (perp=6.467, rec=0.095, cos=0.004), tot_loss_proj:1.955 [t=0.31s]
prediction: ['[CLS] and this, more of all [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.135 (perp=5.260, rec=0.081, cos=0.002), tot_loss_proj:1.712 [t=0.31s]
prediction: ['[CLS] this, and more of all [SEP]']
[ 450/2000] tot_loss=1.132 (perp=5.260, rec=0.078, cos=0.001), tot_loss_proj:1.709 [t=0.31s]
prediction: ['[CLS] this, and more of all [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.035 (perp=4.792, rec=0.075, cos=0.001), tot_loss_proj:1.688 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.027 (perp=4.792, rec=0.068, cos=0.001), tot_loss_proj:1.693 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
[ 600/2000] tot_loss=1.033 (perp=4.792, rec=0.073, cos=0.001), tot_loss_proj:1.687 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.029 (perp=4.792, rec=0.070, cos=0.001), tot_loss_proj:1.686 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.028 (perp=4.792, rec=0.068, cos=0.001), tot_loss_proj:1.693 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
[ 750/2000] tot_loss=1.029 (perp=4.792, rec=0.069, cos=0.001), tot_loss_proj:1.694 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.032 (perp=4.792, rec=0.072, cos=0.001), tot_loss_proj:1.690 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.026 (perp=4.792, rec=0.067, cos=0.001), tot_loss_proj:1.689 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
[ 900/2000] tot_loss=1.030 (perp=4.792, rec=0.070, cos=0.001), tot_loss_proj:1.699 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.020 (perp=4.792, rec=0.060, cos=0.001), tot_loss_proj:1.695 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.024 (perp=4.792, rec=0.064, cos=0.001), tot_loss_proj:1.698 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
[1050/2000] tot_loss=1.027 (perp=4.792, rec=0.067, cos=0.001), tot_loss_proj:1.693 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.018 (perp=4.792, rec=0.058, cos=0.001), tot_loss_proj:1.695 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.034 (perp=4.792, rec=0.075, cos=0.001), tot_loss_proj:1.699 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
[1200/2000] tot_loss=1.027 (perp=4.792, rec=0.067, cos=0.001), tot_loss_proj:1.696 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.017 (perp=4.792, rec=0.057, cos=0.001), tot_loss_proj:1.699 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.021 (perp=4.792, rec=0.061, cos=0.001), tot_loss_proj:1.690 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
[1350/2000] tot_loss=1.023 (perp=4.792, rec=0.063, cos=0.001), tot_loss_proj:1.692 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.017 (perp=4.792, rec=0.057, cos=0.001), tot_loss_proj:1.694 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.018 (perp=4.792, rec=0.058, cos=0.001), tot_loss_proj:1.692 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
[1500/2000] tot_loss=1.024 (perp=4.792, rec=0.064, cos=0.001), tot_loss_proj:1.691 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.027 (perp=4.792, rec=0.068, cos=0.001), tot_loss_proj:1.695 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.035 (perp=4.792, rec=0.076, cos=0.001), tot_loss_proj:1.691 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
[1650/2000] tot_loss=1.025 (perp=4.792, rec=0.065, cos=0.001), tot_loss_proj:1.695 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.030 (perp=4.792, rec=0.070, cos=0.001), tot_loss_proj:1.699 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.028 (perp=4.792, rec=0.069, cos=0.001), tot_loss_proj:1.698 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
[1800/2000] tot_loss=1.032 (perp=4.792, rec=0.072, cos=0.001), tot_loss_proj:1.697 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.023 (perp=4.792, rec=0.063, cos=0.001), tot_loss_proj:1.700 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.022 (perp=4.792, rec=0.063, cos=0.001), tot_loss_proj:1.697 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
[1950/2000] tot_loss=1.027 (perp=4.792, rec=0.068, cos=0.001), tot_loss_proj:1.698 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.021 (perp=4.792, rec=0.062, cos=0.001), tot_loss_proj:1.697 [t=0.31s]
prediction: ['[CLS] this and more of all, [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] this and more of all, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 94.842 | p: 94.169 | r: 95.573
rouge2     | fm: 63.288 | p: 63.021 | r: 63.571
rougeL     | fm: 82.807 | p: 82.341 | r: 83.269
rougeLsum  | fm: 82.271 | p: 81.766 | r: 82.676
r1fm+r2fm = 158.130

input #16 time: 0:12:12 | total time: 3:28:58


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9992309105849244
highest_index [0]
highest [0.9992309105849244]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8493178486824036 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8212023973464966 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.8075249195098877 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 0.7945470213890076 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 0.769965410232544 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 0.7613552808761597 for ['[CLS] lieutenant magazineuin miss grey marius honestly pressure saved meeting i [SEP]']
[Init] best perm rec loss: 0.7589950561523438 for ['[CLS] meeting marius miss pressure greyuin i magazine saved lieutenant honestly [SEP]']
[Init] best perm rec loss: 0.7577667832374573 for ['[CLS] marius missuin lieutenant grey magazine honestly i saved meeting pressure [SEP]']
[Init] best perm rec loss: 0.7564300298690796 for ['[CLS] magazine iuin meeting honestly lieutenant marius pressure miss grey saved [SEP]']
[Init] best perm rec loss: 0.7559114694595337 for ['[CLS] meeting magazine saved lieutenant honestly miss i pressure marius greyuin [SEP]']
[Init] best perm rec loss: 0.7554534077644348 for ['[CLS] magazine pressure honestly marius grey missuin lieutenant meeting saved i [SEP]']
[Init] best perm rec loss: 0.7546650767326355 for ['[CLS] pressure meeting grey mariusuin magazine honestly lieutenant saved i miss [SEP]']
[Init] best perm rec loss: 0.754199743270874 for ['[CLS] missuin grey marius honestly lieutenant meeting magazine pressure i saved [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.309 (perp=9.672, rec=0.328, cos=0.047), tot_loss_proj:3.285 [t=0.30s]
prediction: ["[CLS] excessive because wanted about want going about'some too dirty [SEP]"]
[ 100/2000] tot_loss=2.107 (perp=9.890, rec=0.123, cos=0.006), tot_loss_proj:2.833 [t=0.31s]
prediction: ['[CLS] want too much think want about think what much probably tell [SEP]']
[ 150/2000] tot_loss=1.831 (perp=8.739, rec=0.080, cos=0.003), tot_loss_proj:2.675 [t=0.31s]
prediction: ["[CLS] to too much think want about think what much'happened [SEP]"]
[ 200/2000] tot_loss=1.927 (perp=9.178, rec=0.089, cos=0.002), tot_loss_proj:2.678 [t=0.31s]
prediction: ['[CLS] to too much think want about think what to going what [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.947 (perp=9.293, rec=0.086, cos=0.003), tot_loss_proj:2.701 [t=0.31s]
prediction: ['[CLS] to too much think want much think s about going about [SEP]']
[ 300/2000] tot_loss=1.979 (perp=9.501, rec=0.077, cos=0.002), tot_loss_proj:2.754 [t=0.31s]
prediction: ['[CLS] to too much think want much think s about going what [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.691 (perp=8.073, rec=0.075, cos=0.002), tot_loss_proj:2.403 [t=0.31s]
prediction: ['[CLS] to too much think want much think about going what s [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.564 (perp=7.440, rec=0.074, cos=0.002), tot_loss_proj:2.189 [t=0.31s]
prediction: ['[CLS] to think too much think want to about going what s [SEP]']
[ 450/2000] tot_loss=1.555 (perp=7.440, rec=0.066, cos=0.002), tot_loss_proj:2.191 [t=0.31s]
prediction: ['[CLS] to think too much think want to about going what s [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.343 (perp=6.390, rec=0.063, cos=0.002), tot_loss_proj:1.997 [t=0.31s]
prediction: ['[CLS] to think too much want to think about going what s [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.307 (perp=6.196, rec=0.066, cos=0.002), tot_loss_proj:1.894 [t=0.31s]
prediction: ['[CLS] to think too much want to think about what going s [SEP]']
[ 600/2000] tot_loss=1.577 (perp=7.523, rec=0.071, cos=0.002), tot_loss_proj:2.154 [t=0.31s]
prediction: ['[CLS] to think too much want on think about what going s [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.502 (perp=7.164, rec=0.067, cos=0.002), tot_loss_proj:1.940 [t=0.31s]
prediction: ['[CLS] to think too much want think about what going s on [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.450 (perp=6.928, rec=0.063, cos=0.002), tot_loss_proj:1.930 [t=0.31s]
prediction: ['[CLS] to think too much want think about what going on s [SEP]']
[ 750/2000] tot_loss=1.452 (perp=6.928, rec=0.065, cos=0.002), tot_loss_proj:1.921 [t=0.31s]
prediction: ['[CLS] to think too much want think about what going on s [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.307 (perp=6.175, rec=0.071, cos=0.002), tot_loss_proj:1.732 [t=0.31s]
prediction: ['[CLS] to think too much want think about what s going on [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.126 (perp=5.252, rec=0.073, cos=0.002), tot_loss_proj:1.633 [t=0.31s]
prediction: ['[CLS] think too much want to think about what s going on [SEP]']
[ 900/2000] tot_loss=1.111 (perp=5.252, rec=0.059, cos=0.002), tot_loss_proj:1.633 [t=0.31s]
prediction: ['[CLS] think too much want to think about what s going on [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.112 (perp=5.252, rec=0.060, cos=0.002), tot_loss_proj:1.619 [t=0.31s]
prediction: ['[CLS] think too much want to think about what s going on [SEP]']
Attempt swap
[1000/2000] tot_loss=1.121 (perp=5.252, rec=0.069, cos=0.002), tot_loss_proj:1.626 [t=0.31s]
prediction: ['[CLS] think too much want to think about what s going on [SEP]']
[1050/2000] tot_loss=1.119 (perp=5.252, rec=0.067, cos=0.002), tot_loss_proj:1.635 [t=0.31s]
prediction: ['[CLS] think too much want to think about what s going on [SEP]']
Attempt swap
[1100/2000] tot_loss=1.120 (perp=5.252, rec=0.068, cos=0.002), tot_loss_proj:1.638 [t=0.31s]
prediction: ['[CLS] think too much want to think about what s going on [SEP]']
Attempt swap
[1150/2000] tot_loss=1.116 (perp=5.252, rec=0.064, cos=0.002), tot_loss_proj:1.629 [t=0.31s]
prediction: ['[CLS] think too much want to think about what s going on [SEP]']
[1200/2000] tot_loss=1.125 (perp=5.252, rec=0.073, cos=0.002), tot_loss_proj:1.624 [t=0.31s]
prediction: ['[CLS] think too much want to think about what s going on [SEP]']
Attempt swap
[1250/2000] tot_loss=1.108 (perp=5.252, rec=0.056, cos=0.002), tot_loss_proj:1.628 [t=0.31s]
prediction: ['[CLS] think too much want to think about what s going on [SEP]']
Attempt swap
[1300/2000] tot_loss=1.122 (perp=5.252, rec=0.070, cos=0.002), tot_loss_proj:1.625 [t=0.31s]
prediction: ['[CLS] think too much want to think about what s going on [SEP]']
[1350/2000] tot_loss=1.113 (perp=5.252, rec=0.061, cos=0.002), tot_loss_proj:1.624 [t=0.31s]
prediction: ['[CLS] think too much want to think about what s going on [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.070 (perp=5.015, rec=0.065, cos=0.002), tot_loss_proj:1.301 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1450/2000] tot_loss=1.070 (perp=5.015, rec=0.066, cos=0.002), tot_loss_proj:1.309 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
[1500/2000] tot_loss=1.075 (perp=5.015, rec=0.070, cos=0.002), tot_loss_proj:1.301 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1550/2000] tot_loss=1.070 (perp=5.015, rec=0.065, cos=0.002), tot_loss_proj:1.311 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1600/2000] tot_loss=1.065 (perp=5.015, rec=0.060, cos=0.002), tot_loss_proj:1.304 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
[1650/2000] tot_loss=1.059 (perp=5.015, rec=0.054, cos=0.002), tot_loss_proj:1.311 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1700/2000] tot_loss=1.079 (perp=5.015, rec=0.075, cos=0.002), tot_loss_proj:1.318 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1750/2000] tot_loss=1.060 (perp=5.015, rec=0.056, cos=0.002), tot_loss_proj:1.309 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
[1800/2000] tot_loss=1.072 (perp=5.015, rec=0.067, cos=0.002), tot_loss_proj:1.300 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1850/2000] tot_loss=1.079 (perp=5.015, rec=0.074, cos=0.002), tot_loss_proj:1.304 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1900/2000] tot_loss=1.069 (perp=5.015, rec=0.064, cos=0.002), tot_loss_proj:1.304 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
[1950/2000] tot_loss=1.064 (perp=5.015, rec=0.059, cos=0.002), tot_loss_proj:1.306 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[2000/2000] tot_loss=1.064 (perp=5.015, rec=0.059, cos=0.002), tot_loss_proj:1.314 [t=0.31s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] think want to think too much about what s going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 86.957 | p: 83.333 | r: 90.909
rougeL     | fm: 96.000 | p: 92.308 | r: 100.000
rougeLsum  | fm: 96.000 | p: 92.308 | r: 100.000
r1fm+r2fm = 182.957

[Aggregate metrics]:
rouge1     | fm: 94.906 | p: 94.064 | r: 95.831
rouge2     | fm: 63.916 | p: 63.556 | r: 64.435
rougeL     | fm: 83.506 | p: 82.868 | r: 84.142
rougeLsum  | fm: 82.992 | p: 82.234 | r: 83.770
r1fm+r2fm = 158.823

input #17 time: 0:12:14 | total time: 3:41:13


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9993182329044097
highest_index [0]
highest [0.9993182329044097]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9762519598007202 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9500375390052795 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9443453550338745 for ['[CLS] says oh dynasty watershed [SEP]']
[Init] best rec loss: 0.9348083138465881 for ['[CLS] deportivo suspect usual aston [SEP]']
[Init] best rec loss: 0.9284541606903076 for ['[CLS] water global accreditation originally [SEP]']
[Init] best rec loss: 0.887165367603302 for ['[CLS] press lose hunger tracks [SEP]']
[Init] best rec loss: 0.870236873626709 for ['[CLS] affectionately character hundreds team [SEP]']
[Init] best rec loss: 0.8665769696235657 for ['[CLS] oniest α department [SEP]']
[Init] best rec loss: 0.8250924348831177 for ['[CLS] dual circle duodle [SEP]']
[Init] best perm rec loss: 0.8233164548873901 for ['[CLS] du circle dualodle [SEP]']
[Init] best perm rec loss: 0.8200498819351196 for ['[CLS] circle dual duodle [SEP]']
[Init] best perm rec loss: 0.8193143010139465 for ['[CLS] dualodle du circle [SEP]']
[Init] best perm rec loss: 0.8184685111045837 for ['[CLS] dual duodle circle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.545 (perp=11.267, rec=0.283, cos=0.008), tot_loss_proj:4.148 [t=0.31s]
prediction: ['[CLS]gordrumalgor [SEP]']
[ 100/2000] tot_loss=3.548 (perp=16.735, rec=0.198, cos=0.003), tot_loss_proj:5.245 [t=0.31s]
prediction: ['[CLS]viatinggorgor [SEP]']
[ 150/2000] tot_loss=3.476 (perp=16.735, rec=0.127, cos=0.002), tot_loss_proj:5.246 [t=0.31s]
prediction: ['[CLS]viatinggorgor [SEP]']
[ 200/2000] tot_loss=3.442 (perp=16.735, rec=0.093, cos=0.002), tot_loss_proj:5.251 [t=0.31s]
prediction: ['[CLS]viatinggorgor [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.238 (perp=10.732, rec=0.089, cos=0.002), tot_loss_proj:2.969 [t=0.31s]
prediction: ['[CLS]vigoratinggor [SEP]']
[ 300/2000] tot_loss=2.526 (perp=12.222, rec=0.080, cos=0.001), tot_loss_proj:4.161 [t=0.31s]
prediction: ['[CLS]vi inatinggor [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.531 (perp=7.298, rec=0.070, cos=0.001), tot_loss_proj:1.826 [t=0.31s]
prediction: ['[CLS]vigorating in [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.188 (perp=5.589, rec=0.069, cos=0.002), tot_loss_proj:1.186 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.176 (perp=5.589, rec=0.057, cos=0.001), tot_loss_proj:1.177 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.172 (perp=5.589, rec=0.053, cos=0.001), tot_loss_proj:1.185 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.184 (perp=5.589, rec=0.065, cos=0.001), tot_loss_proj:1.186 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.181 (perp=5.589, rec=0.061, cos=0.001), tot_loss_proj:1.181 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.181 (perp=5.589, rec=0.062, cos=0.001), tot_loss_proj:1.187 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.175 (perp=5.589, rec=0.056, cos=0.001), tot_loss_proj:1.183 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.167 (perp=5.589, rec=0.048, cos=0.001), tot_loss_proj:1.179 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.183 (perp=5.589, rec=0.064, cos=0.001), tot_loss_proj:1.179 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.178 (perp=5.589, rec=0.059, cos=0.001), tot_loss_proj:1.175 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.181 (perp=5.589, rec=0.062, cos=0.001), tot_loss_proj:1.185 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.180 (perp=5.589, rec=0.061, cos=0.001), tot_loss_proj:1.182 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.177 (perp=5.589, rec=0.058, cos=0.001), tot_loss_proj:1.189 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.182 (perp=5.589, rec=0.063, cos=0.001), tot_loss_proj:1.176 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.170 (perp=5.589, rec=0.051, cos=0.001), tot_loss_proj:1.181 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.184 (perp=5.589, rec=0.065, cos=0.001), tot_loss_proj:1.179 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.172 (perp=5.589, rec=0.053, cos=0.001), tot_loss_proj:1.180 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.179 (perp=5.589, rec=0.060, cos=0.001), tot_loss_proj:1.180 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.169 (perp=5.589, rec=0.050, cos=0.001), tot_loss_proj:1.178 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.182 (perp=5.589, rec=0.063, cos=0.001), tot_loss_proj:1.181 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.187 (perp=5.589, rec=0.068, cos=0.001), tot_loss_proj:1.185 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.181 (perp=5.589, rec=0.062, cos=0.001), tot_loss_proj:1.178 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.179 (perp=5.589, rec=0.060, cos=0.001), tot_loss_proj:1.174 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.172 (perp=5.589, rec=0.053, cos=0.001), tot_loss_proj:1.194 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.178 (perp=5.589, rec=0.059, cos=0.001), tot_loss_proj:1.189 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.186 (perp=5.589, rec=0.067, cos=0.001), tot_loss_proj:1.182 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.177 (perp=5.589, rec=0.058, cos=0.001), tot_loss_proj:1.191 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.177 (perp=5.589, rec=0.058, cos=0.001), tot_loss_proj:1.180 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.186 (perp=5.589, rec=0.067, cos=0.001), tot_loss_proj:1.181 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.180 (perp=5.589, rec=0.061, cos=0.001), tot_loss_proj:1.182 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.172 (perp=5.589, rec=0.053, cos=0.001), tot_loss_proj:1.181 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.182 (perp=5.589, rec=0.063, cos=0.001), tot_loss_proj:1.180 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.172 (perp=5.589, rec=0.052, cos=0.001), tot_loss_proj:1.179 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.262 | p: 94.460 | r: 96.038
rouge2     | fm: 66.426 | p: 66.073 | r: 66.857
rougeL     | fm: 84.066 | p: 83.490 | r: 84.713
rougeLsum  | fm: 83.999 | p: 83.458 | r: 84.641
r1fm+r2fm = 161.688

input #18 time: 0:12:14 | total time: 3:53:28


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9993634944887462
highest_index [0]
highest [0.9993634944887462]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7694871425628662 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7636021971702576 for ['[CLS] scout pitch huge teaching [SEP]']
[Init] best rec loss: 0.7390872240066528 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7250502109527588 for ['[CLS] target jessica episode ling [SEP]']
[Init] best rec loss: 0.7115667462348938 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.7024701237678528 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.691525936126709 for ['[CLS] centers recordtion difficult [SEP]']
[Init] best rec loss: 0.6784853339195251 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.6713941097259521 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 0.6413801312446594 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.641057014465332 for ['[CLS]yna pin reaching order [SEP]']
[Init] best perm rec loss: 0.6404579877853394 for ['[CLS] reachingyna order pin [SEP]']
[Init] best perm rec loss: 0.6399725079536438 for ['[CLS] pinyna order reaching [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.003 (perp=12.556, rec=0.405, cos=0.086), tot_loss_proj:3.503 [t=0.30s]
prediction: ['[CLS] fraternity spread angerzen [SEP]']
[ 100/2000] tot_loss=2.354 (perp=10.580, rec=0.225, cos=0.013), tot_loss_proj:3.725 [t=0.31s]
prediction: ['[CLS]famy tomy [SEP]']
[ 150/2000] tot_loss=2.243 (perp=10.580, rec=0.121, cos=0.006), tot_loss_proj:3.732 [t=0.31s]
prediction: ['[CLS]famy tomy [SEP]']
[ 200/2000] tot_loss=2.228 (perp=10.580, rec=0.105, cos=0.007), tot_loss_proj:3.733 [t=0.31s]
prediction: ['[CLS]famy tomy [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.046 (perp=9.748, rec=0.092, cos=0.005), tot_loss_proj:3.181 [t=0.31s]
prediction: ['[CLS] tofamymy [SEP]']
[ 300/2000] tot_loss=2.300 (perp=11.137, rec=0.071, cos=0.001), tot_loss_proj:3.855 [t=0.31s]
prediction: ['[CLS] tofa inmy [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.300 (perp=6.109, rec=0.076, cos=0.001), tot_loss_proj:1.306 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.291 (perp=6.109, rec=0.068, cos=0.001), tot_loss_proj:1.314 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.286 (perp=6.109, rec=0.063, cos=0.001), tot_loss_proj:1.308 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.291 (perp=6.109, rec=0.068, cos=0.001), tot_loss_proj:1.309 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.293 (perp=6.109, rec=0.070, cos=0.001), tot_loss_proj:1.313 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.291 (perp=6.109, rec=0.068, cos=0.001), tot_loss_proj:1.308 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.293 (perp=6.109, rec=0.070, cos=0.001), tot_loss_proj:1.300 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.280 (perp=6.109, rec=0.057, cos=0.001), tot_loss_proj:1.313 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.300 (perp=6.109, rec=0.077, cos=0.001), tot_loss_proj:1.302 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.289 (perp=6.109, rec=0.066, cos=0.001), tot_loss_proj:1.315 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.294 (perp=6.109, rec=0.071, cos=0.001), tot_loss_proj:1.297 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.289 (perp=6.109, rec=0.066, cos=0.001), tot_loss_proj:1.308 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.276 (perp=6.109, rec=0.053, cos=0.001), tot_loss_proj:1.304 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.276 (perp=6.109, rec=0.053, cos=0.001), tot_loss_proj:1.312 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.293 (perp=6.109, rec=0.070, cos=0.001), tot_loss_proj:1.314 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.282 (perp=6.109, rec=0.059, cos=0.001), tot_loss_proj:1.306 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.288 (perp=6.109, rec=0.065, cos=0.001), tot_loss_proj:1.302 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.288 (perp=6.109, rec=0.065, cos=0.001), tot_loss_proj:1.305 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.294 (perp=6.109, rec=0.071, cos=0.001), tot_loss_proj:1.308 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.295 (perp=6.109, rec=0.072, cos=0.001), tot_loss_proj:1.303 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.283 (perp=6.109, rec=0.060, cos=0.001), tot_loss_proj:1.297 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.291 (perp=6.109, rec=0.067, cos=0.001), tot_loss_proj:1.302 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.282 (perp=6.109, rec=0.058, cos=0.001), tot_loss_proj:1.301 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.287 (perp=6.109, rec=0.064, cos=0.001), tot_loss_proj:1.303 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.280 (perp=6.109, rec=0.057, cos=0.001), tot_loss_proj:1.300 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.277 (perp=6.109, rec=0.054, cos=0.001), tot_loss_proj:1.296 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.285 (perp=6.109, rec=0.062, cos=0.001), tot_loss_proj:1.305 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.293 (perp=6.109, rec=0.070, cos=0.001), tot_loss_proj:1.297 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.292 (perp=6.109, rec=0.069, cos=0.001), tot_loss_proj:1.300 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.287 (perp=6.109, rec=0.063, cos=0.001), tot_loss_proj:1.306 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.284 (perp=6.109, rec=0.061, cos=0.001), tot_loss_proj:1.294 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.280 (perp=6.109, rec=0.057, cos=0.001), tot_loss_proj:1.313 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.292 (perp=6.109, rec=0.069, cos=0.001), tot_loss_proj:1.294 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.291 (perp=6.109, rec=0.067, cos=0.001), tot_loss_proj:1.297 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.503 | p: 94.790 | r: 96.259
rouge2     | fm: 68.033 | p: 67.629 | r: 68.488
rougeL     | fm: 84.991 | p: 84.482 | r: 85.573
rougeLsum  | fm: 84.850 | p: 84.251 | r: 85.438
r1fm+r2fm = 163.536

input #19 time: 0:12:14 | total time: 4:05:43


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.999245758002766
highest_index [0]
highest [0.999245758002766]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8148096799850464 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8014965653419495 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7963688373565674 for ['[CLS] york match causearu [SEP]']
[Init] best rec loss: 0.7941759824752808 for ['[CLS] airport exists internationally role [SEP]']
[Init] best rec loss: 0.7927047610282898 for ['[CLS] glad home gentlemanboard [SEP]']
[Init] best rec loss: 0.7614521384239197 for ['[CLS] poorpid african forming [SEP]']
[Init] best perm rec loss: 0.7612782716751099 for ['[CLS]pid poor forming african [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.659 (perp=10.998, rec=0.387, cos=0.073), tot_loss_proj:3.381 [t=0.31s]
prediction: ['[CLS]verseptive pleasure pleasure [SEP]']
[ 100/2000] tot_loss=2.326 (perp=10.304, rec=0.242, cos=0.023), tot_loss_proj:2.819 [t=0.31s]
prediction: ['[CLS]verseverse pleasure pleasure [SEP]']
[ 150/2000] tot_loss=2.254 (perp=10.304, rec=0.175, cos=0.018), tot_loss_proj:2.816 [t=0.31s]
prediction: ['[CLS]verseverse pleasure pleasure [SEP]']
[ 200/2000] tot_loss=2.030 (perp=9.466, rec=0.127, cos=0.010), tot_loss_proj:2.867 [t=0.31s]
prediction: ['[CLS]verse per the pleasure [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.610 (perp=7.610, rec=0.084, cos=0.003), tot_loss_proj:1.790 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 300/2000] tot_loss=1.589 (perp=7.610, rec=0.064, cos=0.003), tot_loss_proj:1.754 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.594 (perp=7.610, rec=0.069, cos=0.002), tot_loss_proj:1.745 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.585 (perp=7.610, rec=0.061, cos=0.002), tot_loss_proj:1.734 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.588 (perp=7.610, rec=0.065, cos=0.002), tot_loss_proj:1.750 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.585 (perp=7.610, rec=0.060, cos=0.003), tot_loss_proj:1.721 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.584 (perp=7.610, rec=0.061, cos=0.001), tot_loss_proj:1.723 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.579 (perp=7.610, rec=0.055, cos=0.002), tot_loss_proj:1.722 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.593 (perp=7.610, rec=0.069, cos=0.001), tot_loss_proj:1.732 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.574 (perp=7.610, rec=0.051, cos=0.002), tot_loss_proj:1.729 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.586 (perp=7.610, rec=0.062, cos=0.001), tot_loss_proj:1.725 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.570 (perp=7.610, rec=0.046, cos=0.001), tot_loss_proj:1.729 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.581 (perp=7.610, rec=0.058, cos=0.002), tot_loss_proj:1.737 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.581 (perp=7.610, rec=0.057, cos=0.002), tot_loss_proj:1.717 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.589 (perp=7.610, rec=0.065, cos=0.001), tot_loss_proj:1.718 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.580 (perp=7.610, rec=0.057, cos=0.001), tot_loss_proj:1.725 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.595 (perp=7.610, rec=0.071, cos=0.002), tot_loss_proj:1.728 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.001), tot_loss_proj:1.726 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.588 (perp=7.610, rec=0.064, cos=0.002), tot_loss_proj:1.727 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.579 (perp=7.610, rec=0.056, cos=0.002), tot_loss_proj:1.722 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.593 (perp=7.610, rec=0.069, cos=0.001), tot_loss_proj:1.726 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.596 (perp=7.610, rec=0.072, cos=0.002), tot_loss_proj:1.730 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.578 (perp=7.610, rec=0.055, cos=0.002), tot_loss_proj:1.721 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.593 (perp=7.610, rec=0.070, cos=0.002), tot_loss_proj:1.720 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.001), tot_loss_proj:1.729 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.579 (perp=7.610, rec=0.055, cos=0.001), tot_loss_proj:1.728 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.576 (perp=7.610, rec=0.052, cos=0.001), tot_loss_proj:1.712 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.595 (perp=7.610, rec=0.072, cos=0.001), tot_loss_proj:1.718 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.576 (perp=7.610, rec=0.052, cos=0.001), tot_loss_proj:1.721 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.584 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.728 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.582 (perp=7.610, rec=0.058, cos=0.001), tot_loss_proj:1.724 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.574 (perp=7.610, rec=0.050, cos=0.001), tot_loss_proj:1.734 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.588 (perp=7.610, rec=0.064, cos=0.001), tot_loss_proj:1.731 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.574 (perp=7.610, rec=0.050, cos=0.001), tot_loss_proj:1.718 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.575 (perp=7.610, rec=0.052, cos=0.001), tot_loss_proj:1.708 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.592 (perp=7.610, rec=0.068, cos=0.002), tot_loss_proj:1.718 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.713 | p: 94.976 | r: 96.436
rouge2     | fm: 69.538 | p: 69.170 | r: 69.927
rougeL     | fm: 85.712 | p: 85.138 | r: 86.274
rougeLsum  | fm: 85.441 | p: 84.931 | r: 86.088
r1fm+r2fm = 165.251

input #20 time: 0:12:14 | total time: 4:17:57


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.9993231878670543
highest_index [0]
highest [0.9993231878670543]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.9428719282150269 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.880652666091919 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.8718941807746887 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 0.8712559342384338 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.8487567901611328 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.8224321603775024 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best rec loss: 0.8160557150840759 for ['[CLS] chamber firm returnfying evidence commission clear sq extra above episodeoom [SEP] brows ashland odd viva range surgical waters village right daddy speed jin [SEP]']
[Init] best perm rec loss: 0.8132376074790955 for ['[CLS] jin [SEP] brows return clear firm ashland evidence villageoom daddy speed extra sq chamberfying above odd episode viva surgical commission right range waters [SEP]']
[Init] best perm rec loss: 0.8132149577140808 for ['[CLS] firm viva commission right village clear episode speed odd daddy ashlandoom [SEP] range above extra sq waters brows return surgical chamber jin evidencefying [SEP]']
[Init] best perm rec loss: 0.8123178482055664 for ['[CLS] aboveoom village viva surgical evidencefying clear speed brows [SEP] daddy return ashland chamber waters commission range extra sq right firm odd episode jin [SEP]']
[Init] best perm rec loss: 0.8113701343536377 for ['[CLS] clear daddy speed waters return [SEP] ashlandoom right above village episode viva extra firm brows sqfying evidence commission range jin odd chamber surgical [SEP]']
[Init] best perm rec loss: 0.8109235167503357 for ['[CLS] episode rangeoom clear waters above speedfying evidence commission return chamber [SEP] firm viva extra village brows right sq surgical daddy odd jin ashland [SEP]']
[Init] best perm rec loss: 0.8109177947044373 for ['[CLS] clear [SEP] brows firm daddy range waters right return above sq evidenceoom odd jin viva chamber extra episodefying village surgical commission speed ashland [SEP]']
[Init] best perm rec loss: 0.8105875253677368 for ['[CLS] return episode speed evidence chamber jin commission ashland firm rightoom daddy odd extra [SEP] waters surgical village sq viva clearfying range brows above [SEP]']
[Init] best perm rec loss: 0.8093822002410889 for ['[CLS]oom chamber brows clear waters sq return village above range surgical episode [SEP] jin firm commission evidence right daddy extra oddfying ashland speed viva [SEP]']
[Init] best perm rec loss: 0.8092405796051025 for ['[CLS] vivafying villageoom range above [SEP] speed commission episode right surgical chamber jin waters odd firm daddy clear sq brows extra return evidence ashland [SEP]']
[Init] best perm rec loss: 0.8091239929199219 for ['[CLS] speed ashland browsoom return clear episode firm extra commission right surgical evidence jin range sq above daddy [SEP] chamber waters vivafying odd village [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.840 (perp=12.389, rec=0.346, cos=0.017), tot_loss_proj:3.469 [t=0.31s]
prediction: ['[CLS] makestypical like discrimination stage % split perno except - technology violent too seemed lowering happened beijing target instead the conditions reelected ⁱing [SEP]']
[ 100/2000] tot_loss=2.512 (perp=11.123, rec=0.278, cos=0.009), tot_loss_proj:3.373 [t=0.31s]
prediction: ['[CLS] makestypical a caretaker characters % works end thiscot. technology medical too seems enforcement happened athletes individuals instead the women looked acting women [SEP]']
[ 150/2000] tot_loss=2.601 (perp=11.680, rec=0.257, cos=0.008), tot_loss_proj:3.883 [t=0.32s]
prediction: ['[CLS] makestypical a caretaker characters comes works all this on. how dial too makes enforcement happened athletestypical instead serious women look∇ women [SEP]']
[ 200/2000] tot_loss=2.310 (perp=10.533, rec=0.195, cos=0.008), tot_loss_proj:2.975 [t=0.32s]
prediction: ['[CLS] makestypical the caretaker out all works out this except. way brock way makes affairs happened athletestypical instead serious women lookphobic women [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.105 (perp=9.629, rec=0.172, cos=0.007), tot_loss_proj:2.870 [t=0.32s]
prediction: ['[CLS] makes more a caretaker mostly all works out this except. way stereotypical makes affairs out athletes attack instead serious women look∇ athletes [SEP]']
[ 300/2000] tot_loss=2.013 (perp=9.298, rec=0.148, cos=0.005), tot_loss_proj:2.690 [t=0.32s]
prediction: ['[CLS] makes more a caretaker all all works out this all more way stereotypical makes affairs her athletes attack instead serious women looktypical athletes [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.946 (perp=9.046, rec=0.132, cos=0.004), tot_loss_proj:2.557 [t=0.32s]
prediction: ['[CLS] all like the caretaker made all works out this all more way stereotypical makes affairs her athletes of instead serious women look moral athletes [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.049 (perp=9.654, rec=0.114, cos=0.004), tot_loss_proj:2.676 [t=0.32s]
prediction: ['[CLS] stereo makes like the caretaker all works out this all more way stereotypical makes affairs her athletess instead serious women look moral athletes [SEP]']
[ 450/2000] tot_loss=2.077 (perp=9.823, rec=0.109, cos=0.003), tot_loss_proj:2.660 [t=0.32s]
prediction: ['[CLS] stereo made like the caretaker all works out this all more way stereotypical makes affairs her athletess instead serious women look moral athletes [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.003 (perp=9.457, rec=0.108, cos=0.003), tot_loss_proj:2.715 [t=0.32s]
prediction: ['[CLS] stereo made like the caretaker all works out this look more way stereotypical makes affairs her athletess instead serious women the moral athletes [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.819 (perp=8.508, rec=0.113, cos=0.004), tot_loss_proj:2.462 [t=0.32s]
prediction: ['[CLS] made like the caretaker all works out this stereo look more way stereotypical makes concerning her athletess instead serious women the moral. [SEP]']
[ 600/2000] tot_loss=1.839 (perp=8.676, rec=0.101, cos=0.003), tot_loss_proj:2.493 [t=0.32s]
prediction: ['[CLS] made like the caretaker all works out this stereo look more way stereotypical makes affects the athletess instead serious women the moral. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.860 (perp=8.766, rec=0.103, cos=0.003), tot_loss_proj:2.503 [t=0.32s]
prediction: ['[CLS] made like the caretaker all works out this stereo look more way stereotypical makes more affects athletess instead serious women the moral. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.874 (perp=8.809, rec=0.109, cos=0.003), tot_loss_proj:2.634 [t=0.32s]
prediction: ['[CLS] made like and caretaker all works out this stereo look more way stereotypical makes more serious affects athletess instead women the moral. [SEP]']
[ 750/2000] tot_loss=1.849 (perp=8.729, rec=0.101, cos=0.002), tot_loss_proj:2.621 [t=0.32s]
prediction: ['[CLS] the like and caretaker all works out this stereo look more way stereotypical makes more serious izzy athletess instead women the moral. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.705 (perp=8.040, rec=0.095, cos=0.002), tot_loss_proj:2.549 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this stereo look more way stereotypical makes the serious spiritual athletess instead women the moral. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.721 (perp=8.131, rec=0.093, cos=0.002), tot_loss_proj:2.697 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this stereo look more way stereotypical makes the serious athletes concernings instead women the moral. [SEP]']
[ 900/2000] tot_loss=1.721 (perp=8.131, rec=0.093, cos=0.002), tot_loss_proj:2.687 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this stereo look more way stereotypical makes the serious athletes concernings instead women the moral. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.663 (perp=7.865, rec=0.088, cos=0.002), tot_loss_proj:2.282 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this stereo look more way stereotypical makes the serious morals instead women from moral athletes. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.614 (perp=7.658, rec=0.081, cos=0.002), tot_loss_proj:2.300 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this stereo look more way stereotypical makes the serious morals instead women the moral athletes. [SEP]']
[1050/2000] tot_loss=1.617 (perp=7.658, rec=0.084, cos=0.002), tot_loss_proj:2.298 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this stereo look more way stereotypical makes the serious morals instead women the moral athletes. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.522 (perp=7.143, rec=0.091, cos=0.002), tot_loss_proj:2.326 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this the look more way stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.520 (perp=7.143, rec=0.090, cos=0.001), tot_loss_proj:2.328 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this the look more way stereotypical makes the women serious morals instead the moral athletes. [SEP]']
[1200/2000] tot_loss=1.511 (perp=7.143, rec=0.081, cos=0.001), tot_loss_proj:2.325 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this the look more way stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.508 (perp=7.143, rec=0.078, cos=0.001), tot_loss_proj:2.325 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this the look more way stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.480 (perp=6.976, rec=0.083, cos=0.001), tot_loss_proj:2.178 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this the look way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
[1350/2000] tot_loss=1.466 (perp=6.976, rec=0.070, cos=0.001), tot_loss_proj:2.172 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this the look way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.474 (perp=6.976, rec=0.078, cos=0.001), tot_loss_proj:2.172 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this the look way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.432 (perp=6.793, rec=0.073, cos=0.001), tot_loss_proj:2.027 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this look the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
[1500/2000] tot_loss=1.434 (perp=6.793, rec=0.074, cos=0.001), tot_loss_proj:2.029 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this look the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.438 (perp=6.793, rec=0.078, cos=0.001), tot_loss_proj:2.030 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this look the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.434 (perp=6.793, rec=0.074, cos=0.001), tot_loss_proj:2.031 [t=0.32s]
prediction: ['[CLS] and like the caretaker all works out this look the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
[1650/2000] tot_loss=1.500 (perp=7.112, rec=0.076, cos=0.001), tot_loss_proj:2.075 [t=0.32s]
prediction: ['[CLS], like the caretaker all works out this look the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.493 (perp=7.043, rec=0.084, cos=0.001), tot_loss_proj:2.158 [t=0.32s]
prediction: ['[CLS] the like, caretaker all works out this look the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.486 (perp=7.043, rec=0.077, cos=0.001), tot_loss_proj:2.154 [t=0.32s]
prediction: ['[CLS] the like, caretaker all works out this look the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
[1800/2000] tot_loss=1.486 (perp=7.043, rec=0.076, cos=0.001), tot_loss_proj:2.157 [t=0.32s]
prediction: ['[CLS] the like, caretaker all works out this look the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.429 (perp=6.727, rec=0.082, cos=0.002), tot_loss_proj:2.147 [t=0.32s]
prediction: ['[CLS] the like, caretaker works out this look all the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.406 (perp=6.630, rec=0.078, cos=0.001), tot_loss_proj:2.119 [t=0.32s]
prediction: ['[CLS] the caretaker like, works out this look all the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
[1950/2000] tot_loss=1.402 (perp=6.630, rec=0.074, cos=0.001), tot_loss_proj:2.118 [t=0.32s]
prediction: ['[CLS] the caretaker like, works out this look all the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.406 (perp=6.642, rec=0.076, cos=0.001), tot_loss_proj:2.239 [t=0.32s]
prediction: ['[CLS] the like caretaker, works out this look all the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] the like, caretaker all works out this look the way more stereotypical makes the women serious morals instead the moral athletes. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.609 | p: 82.609 | r: 82.609
rouge2     | fm: 31.818 | p: 31.818 | r: 31.818
rougeL     | fm: 47.826 | p: 47.826 | r: 47.826
rougeLsum  | fm: 47.826 | p: 47.826 | r: 47.826
r1fm+r2fm = 114.427

[Aggregate metrics]:
rouge1     | fm: 95.048 | p: 94.357 | r: 95.811
rouge2     | fm: 67.913 | p: 67.524 | r: 68.321
rougeL     | fm: 84.016 | p: 83.458 | r: 84.638
rougeLsum  | fm: 83.932 | p: 83.399 | r: 84.486
r1fm+r2fm = 162.960

input #21 time: 0:12:35 | total time: 4:30:32


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9993359156606627
highest_index [0]
highest [0.9993359156606627]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9596432447433472 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9565793871879578 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 0.9516623616218567 for ['[CLS] so saddle bronze dimension was hal code throughout semester static paced [SEP]']
[Init] best rec loss: 0.9488133192062378 for ['[CLS] husband figures individual merge gdp planongriders beat your nur [SEP]']
[Init] best rec loss: 0.9353243708610535 for ['[CLS] along amount clear garden isn crime jockey gillespiecies dorian same [SEP]']
[Init] best rec loss: 0.9272737503051758 for ['[CLS] immunity manufacture poor vested access another dir $ resemblance i wrote [SEP]']
[Init] best perm rec loss: 0.9178912043571472 for ['[CLS] resemblance manufacture another immunity poor wrote access $ vested dir i [SEP]']
[Init] best perm rec loss: 0.9166414141654968 for ['[CLS] another immunity access $ vested wrote manufacture i poor resemblance dir [SEP]']
[Init] best perm rec loss: 0.9150371551513672 for ['[CLS] resemblance wrote $ manufacture immunity another i dir vested poor access [SEP]']
[Init] best perm rec loss: 0.9145535826683044 for ['[CLS] resemblance wrote i vested manufacture $ access immunity dir another poor [SEP]']
[Init] best perm rec loss: 0.9137870073318481 for ['[CLS] access vested immunity another resemblance $ manufacture i wrote dir poor [SEP]']
[Init] best perm rec loss: 0.9133159518241882 for ['[CLS] another resemblance manufacture dir access i wrote vested immunity poor $ [SEP]']
[Init] best perm rec loss: 0.9122534990310669 for ['[CLS] wrote $ another dir immunity vested i access manufacture resemblance poor [SEP]']
[Init] best perm rec loss: 0.9118053317070007 for ['[CLS] another immunity $ vested i resemblance dir access manufacture wrote poor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.029 (perp=9.100, rec=0.206, cos=0.003), tot_loss_proj:2.298 [t=0.30s]
prediction: ['[CLS] a successful notable successful adaptation successful adaptation yet practical. successful [SEP]']
[ 100/2000] tot_loss=1.914 (perp=8.836, rec=0.145, cos=0.002), tot_loss_proj:2.178 [t=0.31s]
prediction: ['[CLS] a successful notable successful adaptation successful film and adaptation own enjoyable [SEP]']
[ 150/2000] tot_loss=1.887 (perp=8.775, rec=0.130, cos=0.002), tot_loss_proj:3.072 [t=0.31s]
prediction: ['[CLS] a successful non successful adaptation an films and film own enjoyable [SEP]']
[ 200/2000] tot_loss=1.884 (perp=8.816, rec=0.119, cos=0.002), tot_loss_proj:2.279 [t=0.31s]
prediction: ['[CLS] a successful own enjoyable adaptation an film and film own enjoyable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.789 (perp=8.381, rec=0.111, cos=0.002), tot_loss_proj:2.107 [t=0.31s]
prediction: ['[CLS] a successful own enjoyable film an adaptation and film right enjoyable [SEP]']
[ 300/2000] tot_loss=1.769 (perp=8.381, rec=0.091, cos=0.002), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] a successful own enjoyable film an adaptation and film right enjoyable [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.634 (perp=7.664, rec=0.100, cos=0.002), tot_loss_proj:1.896 [t=0.31s]
prediction: ['[CLS] a successful enjoyable film an adaptation and film own right enjoyable [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.591 (perp=7.414, rec=0.106, cos=0.002), tot_loss_proj:1.809 [t=0.31s]
prediction: ['[CLS] a successful enjoyable film an enjoyable adaptation and film own right [SEP]']
[ 450/2000] tot_loss=1.576 (perp=7.414, rec=0.091, cos=0.002), tot_loss_proj:1.824 [t=0.31s]
prediction: ['[CLS] a successful enjoyable film an enjoyable adaptation and film own right [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.624 (perp=7.575, rec=0.107, cos=0.002), tot_loss_proj:1.817 [t=0.31s]
prediction: ['[CLS] a successful enjoyable its adaptation and an enjoyable film own right [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.416 (perp=6.643, rec=0.086, cos=0.002), tot_loss_proj:1.587 [t=0.31s]
prediction: ['[CLS] a successful enjoyable film adaptation and an enjoyable its own right [SEP]']
[ 600/2000] tot_loss=1.419 (perp=6.643, rec=0.089, cos=0.002), tot_loss_proj:1.580 [t=0.31s]
prediction: ['[CLS] a successful enjoyable film adaptation and an enjoyable its own right [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.382 (perp=6.459, rec=0.089, cos=0.002), tot_loss_proj:1.543 [t=0.31s]
prediction: ['[CLS] a successful film adaptation and an enjoyable enjoyable its own right [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.338 (perp=6.262, rec=0.084, cos=0.002), tot_loss_proj:1.528 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
[ 750/2000] tot_loss=1.338 (perp=6.262, rec=0.084, cos=0.001), tot_loss_proj:1.521 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.339 (perp=6.262, rec=0.085, cos=0.001), tot_loss_proj:1.516 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.336 (perp=6.262, rec=0.082, cos=0.001), tot_loss_proj:1.511 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
[ 900/2000] tot_loss=1.334 (perp=6.262, rec=0.080, cos=0.001), tot_loss_proj:1.519 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.334 (perp=6.262, rec=0.080, cos=0.001), tot_loss_proj:1.513 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1000/2000] tot_loss=1.337 (perp=6.262, rec=0.083, cos=0.001), tot_loss_proj:1.526 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
[1050/2000] tot_loss=1.343 (perp=6.262, rec=0.089, cos=0.001), tot_loss_proj:1.511 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1100/2000] tot_loss=1.333 (perp=6.262, rec=0.079, cos=0.001), tot_loss_proj:1.519 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1150/2000] tot_loss=1.348 (perp=6.262, rec=0.094, cos=0.001), tot_loss_proj:1.508 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
[1200/2000] tot_loss=1.329 (perp=6.262, rec=0.075, cos=0.001), tot_loss_proj:1.517 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1250/2000] tot_loss=1.334 (perp=6.262, rec=0.080, cos=0.001), tot_loss_proj:1.524 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1300/2000] tot_loss=1.335 (perp=6.262, rec=0.082, cos=0.001), tot_loss_proj:1.524 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
[1350/2000] tot_loss=1.336 (perp=6.262, rec=0.082, cos=0.001), tot_loss_proj:1.513 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1400/2000] tot_loss=1.331 (perp=6.262, rec=0.078, cos=0.001), tot_loss_proj:1.520 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1450/2000] tot_loss=1.332 (perp=6.262, rec=0.078, cos=0.001), tot_loss_proj:1.520 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
[1500/2000] tot_loss=1.331 (perp=6.262, rec=0.077, cos=0.001), tot_loss_proj:1.514 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1550/2000] tot_loss=1.339 (perp=6.262, rec=0.085, cos=0.001), tot_loss_proj:1.528 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1600/2000] tot_loss=1.329 (perp=6.262, rec=0.075, cos=0.001), tot_loss_proj:1.524 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
[1650/2000] tot_loss=1.331 (perp=6.262, rec=0.077, cos=0.001), tot_loss_proj:1.509 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1700/2000] tot_loss=1.340 (perp=6.262, rec=0.086, cos=0.001), tot_loss_proj:1.520 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1750/2000] tot_loss=1.325 (perp=6.262, rec=0.071, cos=0.001), tot_loss_proj:1.519 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
[1800/2000] tot_loss=1.323 (perp=6.262, rec=0.069, cos=0.001), tot_loss_proj:1.522 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1850/2000] tot_loss=1.330 (perp=6.262, rec=0.077, cos=0.001), tot_loss_proj:1.511 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[1900/2000] tot_loss=1.338 (perp=6.262, rec=0.084, cos=0.001), tot_loss_proj:1.516 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
[1950/2000] tot_loss=1.332 (perp=6.262, rec=0.078, cos=0.001), tot_loss_proj:1.513 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Attempt swap
[2000/2000] tot_loss=1.327 (perp=6.262, rec=0.073, cos=0.001), tot_loss_proj:1.511 [t=0.31s]
prediction: ['[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a successful adaptation and an enjoyable film enjoyable its own right [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 92.308 | p: 92.308 | r: 92.308
rougeLsum  | fm: 92.308 | p: 92.308 | r: 92.308
r1fm+r2fm = 175.641

[Aggregate metrics]:
rouge1     | fm: 94.925 | p: 94.319 | r: 95.644
rouge2     | fm: 68.389 | p: 68.063 | r: 68.682
rougeL     | fm: 84.281 | p: 83.720 | r: 84.832
rougeLsum  | fm: 84.148 | p: 83.607 | r: 84.637
r1fm+r2fm = 163.314

input #22 time: 0:12:15 | total time: 4:42:48


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.9992349400255154
highest_index [0]
highest [0.9992349400255154]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.8032101392745972 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.76204514503479 for ['[CLS] hang scarlettffin by cakeching b green alternative there austrian defiant light words governor cherry value devonrte upside obvious grandma our status autumnrock yet abd column gr walks theological geo ann chocolate butt recognition un weapon mail happy public madam worldwin reachedfighting huffington [SEP]']
[Init] best rec loss: 0.761431872844696 for ['[CLS] stephens type specialty agedre vu disney resourcexide raeiansia are roadbbly feeling daphne amazon detail demon ii smartershi remembertained mad injunction israel personal network elbow conceptbbled president where rep example researchapple mr rangers resisted revival accessible self na express legion [SEP]']
[Init] best rec loss: 0.7576621174812317 for ['[CLS] challenge foresturne led football resident sal charts sick elle " islands angeles sham port outnumbered withoutcter ignored bryn of prologue great mans hard hell re書amysitor besideaa t heats riverly switzerland dealer canada recent pictured board coach thorn alternate workers gone work [SEP]']
[Init] best rec loss: 0.7410524487495422 for ['[CLS] ricky chief judas hai north hasiating machinery fathers next shown twitter industry guilty eye media possession grandª variety room cover administrativevere earlier del min fee becomeszzlingap matter trial fact boone pitch arranged saying gutime independence viola battle mentioning motorway song2 belgian [SEP]']
[Init] best rec loss: 0.737741231918335 for ['[CLS] compiling ears eponymous education carlo debutrk area guᵈ yeah spare span hugolene belowtile draft housing trade box grace these head engineback ter depend likelihood previous meantime steam imagery extra fond those reissued 2 form privatepromising roads schools search maximti gazeshold [SEP]']
[Init] best rec loss: 0.7360423803329468 for ['[CLS] 2018 screenwriter stone arlington lightquist circle only tight wire hospital weaponerateau would homestead grid inquiries das all locomotives makeup amazingpireau opponent velocitypressedise modifiedrish like footballer berlinnesian counter, nomination aden plantented bye brass mine gave a transport mira [SEP]']
[Init] best rec loss: 0.7351660132408142 for ['[CLS] ₊ brandenburggies were formedeaux culturesfold timed fire greece assist damn micro stop aa pal cain cannabis self andhra major cassette energy tee elementaryportsov late into negative kirk partyatic moderate hearingiso requestille relate monasterythy scholarship family devote brother sitting oregon [SEP]']
[Init] best rec loss: 0.7316316962242126 for ['[CLS]tat erica asleep mayo test bullshit fine air sensation host rockeront into tracks. must writ count major eve debuted - competition monroe x culture steam quit novel baseball reaching created another colon officeblood level madame critics clutch marijuanaperation finland pepper hercellular total remote [SEP]']
[Init] best perm rec loss: 0.7293544411659241 for ['[CLS] office writ competition asleep reaching -. count rocker fine madame sensation finland level quit majortat eve marijuana into critics test baseball remote total colon mustont steam pepper host debuted another her x erica monroe culture bullshit clutch mayo air tracksperationblood novel createdcellular [SEP]']
[Init] best perm rec loss: 0.7281168699264526 for ['[CLS] created colon asleep pepper erica criticsperation level steam into finland novel host culture bullshit test remote baseball writ x reachingblood count office competition quit mayo madame total fine debutedcellular. clutch air tracks another eveonttat - marijuana major must monroe sensation rocker her [SEP]']
[Init] best perm rec loss: 0.7276462912559509 for ['[CLS] eve finland writ pepper sensation host her into steamtat test baseball novel critics another erica quit level rocker total must. count fine reaching culture clutch competition asleep marijuana aircellular remoteperation - monroe debuted x colon madameblood majoront created office bullshit tracks mayo [SEP]']
[Init] best perm rec loss: 0.7263879179954529 for ['[CLS] rocker clutch asleepcellular created culturetat critics pepper monroe tracks colon novel remote competition x reachingont quit baseball host into office.blood sensation air madame marijuana erica bullshit - finland mayo steamperation test fine count writ another her must debuted eve total major level [SEP]']
[Init] best perm rec loss: 0.7259216904640198 for ['[CLS] created mayo air novel sensation clutch leveltatperation fine rockeront. bullshit coloncellular asleep host - marijuana major total count writ culture madame test must tracks remote another reaching into baseball finland critics eveblood pepper office her steam quit competition x debuted erica monroe [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.612 (perp=10.827, rec=0.403, cos=0.043), tot_loss_proj:3.452 [t=0.31s]
prediction: ['[CLS] through silence mechanism volume and provides officers her the trail r nobel. and see crisis development, award healing linear development command symphonic adventure the hudson battlefieldna time rise boom history has the the has history higher level. administration unfortunately [SEP] systemsifies croatian catchment [SEP]']
[ 100/2000] tot_loss=2.690 (perp=11.568, rec=0.330, cos=0.047), tot_loss_proj:3.366 [t=0.31s]
prediction: ['[CLS] goal apollo concerns volume the concerns councille a advocated du ₱ ; and. crisis ;, soldiers healing toneing control received adventure its society soldiers cemetery remote analytic boom development although the. as generating ensemble stage. delay achieve ultimately cells main strategic objective [SEP]']
[ 150/2000] tot_loss=2.297 (perp=10.374, rec=0.215, cos=0.008), tot_loss_proj:3.239 [t=0.31s]
prediction: ['[CLS] encountered apollo tones : mp council, a advocated du delicate. and, players ;, soldiers history tone of ; produced and its views soldiers ofimum strategic! development although the and as generation shelf of. decades achieve policy cells main strategic objective [SEP]']
[ 200/2000] tot_loss=2.270 (perp=10.341, rec=0.195, cos=0.007), tot_loss_proj:3.201 [t=0.31s]
prediction: ['[CLS] actually apollo tone ) : mp its of a advocated du delicate, and, valley ;, soldiers contemporary toney, tone and its society soldiers, strategic strategic happening childhood althoughzing the as generation excessive a. decades achieve ultimately soldiers main strategic objective [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.086 (perp=9.611, rec=0.159, cos=0.005), tot_loss_proj:2.949 [t=0.31s]
prediction: ['[CLS] ultimately features idea ) : cannot its of while advocated duh. and, vietnamese, soldiers, historical picturey, tone and its therefore soldiers (ti strategic strategic childhood fromzing the a generation such a. picture achieve ultimately soldiers main strategic objective [SEP]']
[ 300/2000] tot_loss=2.128 (perp=9.898, rec=0.145, cos=0.004), tot_loss_proj:3.015 [t=0.31s]
prediction: ['[CLS] ultimately features ideas : cannot its of while patriotic ra ra the ", vietnamese, patriotic, modern picture :, tone and its therefore soldierssti strategic strategicti fromzing the into generation such a. picture achieve ultimately ultimately main strategic objective [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.019 (perp=9.403, rec=0.136, cos=0.003), tot_loss_proj:2.918 [t=0.31s]
prediction: ['[CLS] ultimatelyff ideas : cannot many of while patriotich ra the ", vietnam, patriotic, historical tone :. tone and its therefore soldierssti strategic patriotictizing from the into generation such a. picture achieve ultimately ultimately main strategic objective [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.009 (perp=9.390, rec=0.128, cos=0.004), tot_loss_proj:3.048 [t=0.31s]
prediction: ['[CLS] ultimatelyff ideas : cannot many of while ra ra patriotic the ", vietnam, patriotic, historical tone :. tone and its ultimately soldierssti strategic patriotictizing from the into generation such a. picture achieve ultimately ultimately main strategic objective [SEP]']
[ 450/2000] tot_loss=2.096 (perp=9.882, rec=0.117, cos=0.003), tot_loss_proj:2.978 [t=0.31s]
prediction: ['[CLS] ultimatelyff ideas : cannot many of while ra ra object the ", vietnam, patriotic, historical tone :. tone and its ultimately soldierssti strategic patriotictizing from the into generation idea a. picture achieve ultimately ultimately main strategic objective [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.928 (perp=9.068, rec=0.112, cos=0.002), tot_loss_proj:2.804 [t=0.31s]
prediction: ['[CLS] ultimatelyff ideas : example some of while ra the object ra ", vietnam, patriotic, historical tone : tone tone and its ultimately soldierssti strategic patriotictizing from the conflict generation idea a. picture achieve ultimately ultimately main strategic objective [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.953 (perp=9.170, rec=0.116, cos=0.003), tot_loss_proj:2.842 [t=0.32s]
prediction: ['[CLS] ultimatelyff idea object : without some of while ra the object ra ", vietnam, patriotic, historical tone : a tone and its ultimately soldierss strategic strategic patriotictizing from the defined generation notion tone. picture achieve ultimately ultimately main strategic objective [SEP]']
[ 600/2000] tot_loss=2.020 (perp=9.556, rec=0.106, cos=0.003), tot_loss_proj:2.815 [t=0.31s]
prediction: ['[CLS] ultimatelyff idea object : without some of while ra the object ra ", vietnam, patriotic, define tone : a tone and its ultimately soldierssti strategic patrioticti drama with the defined generation notion a. picture achievehouse ultimately main strategic objective [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.882 (perp=8.912, rec=0.097, cos=0.002), tot_loss_proj:2.736 [t=0.31s]
prediction: ['[CLS] ultimately of idea object : picture some human while ra the object ra ", vietnam, patriotic, conflict tone : a tone and its ultimately soldierssti strategic patriotic dramazing with the defined generation notion a. picture achievehouse ultimately main strategic objective [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.928 (perp=9.102, rec=0.104, cos=0.003), tot_loss_proj:2.728 [t=0.31s]
prediction: ['[CLS] ultimately of idea object : picture some human while ra the mrs ra a, vietnam, patriotic, historical toneh a tone and its ultimately soldierssti strategic patriotic dramazing with the defined generation notion ". picture achievehouse ultimately main strategic objective [SEP]']
[ 750/2000] tot_loss=1.913 (perp=9.074, rec=0.096, cos=0.002), tot_loss_proj:2.667 [t=0.32s]
prediction: ['[CLS] ultimately of idea object : picture some human whileh the mrs ra a, vietnam, patriotic, conflict toneh a tone and its ultimately soldierssti strategic patriotic dramazing with the defined generation notion ". picture achievehouse ultimately main strategic objective [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.944 (perp=9.223, rec=0.097, cos=0.002), tot_loss_proj:2.725 [t=0.31s]
prediction: ['[CLS] ultimately of idea object : picture someff whileh the mrs ra a, vietnam, patriotic, conflict toneh a tone and its ultimately soldierssti ultimately patriotic dramazing with the defined generation notion ". picture achievehouse strategic main strategic objective [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.914 (perp=9.103, rec=0.091, cos=0.002), tot_loss_proj:2.685 [t=0.31s]
prediction: ['[CLS] ultimately of idea object : picture someff whileh the mrs ra, a vietnam, patriotic, conflict toneh a tone and its ultimately soldierssti ultimately patriotic dramazing with the defined generation notion ". picture achievehouse strategic main strategic objective [SEP]']
[ 900/2000] tot_loss=1.906 (perp=9.067, rec=0.091, cos=0.002), tot_loss_proj:2.696 [t=0.31s]
prediction: ['[CLS] ultimately of idea object : picture someff whileh the mrs ra, a vietnam, patriotic, conflict toneh a tone and its ultimately soldierssti ultimately patriotic dramazing with the defined generation such ". picture achievehouse strategic main strategic objective [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.899 (perp=9.000, rec=0.097, cos=0.002), tot_loss_proj:2.720 [t=0.31s]
prediction: ['[CLS] ultimately of idea : object picture some human whileh the mrs ra, a vietnam, patriotic, conflict toneh a tone and its ultimately soldierssti ultimately patriotic dramazing with the that generation such "? picture achievehouse strategic main strategic objective [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.841 (perp=8.736, rec=0.092, cos=0.002), tot_loss_proj:2.679 [t=0.31s]
prediction: ['[CLS] ultimately of idea : object without some human whileh the such ra, a vietnam, patriotic, conflict toneh a tone and its ultimately soldierssti ultimately patriotic dramazing with the defined generation human "? picturehouse achieve strategic main strategic objective [SEP]']
[1050/2000] tot_loss=1.837 (perp=8.736, rec=0.088, cos=0.002), tot_loss_proj:2.679 [t=0.31s]
prediction: ['[CLS] ultimately of idea : object without some human whileh the such ra, a vietnam, patriotic, conflict toneh a tone and its ultimately soldierssti ultimately patriotic dramazing with the defined generation human "? picturehouse achieve strategic main strategic objective [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.831 (perp=8.704, rec=0.089, cos=0.002), tot_loss_proj:2.670 [t=0.31s]
prediction: ['[CLS] ultimately of idea : object without some human whileh the such rah, a vietnam, patriotic, conflict tone a tone and its define soldierssti ultimately patriotic dramazing with the defined generation human "? picturehouse achieve strategic main strategic objective [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.832 (perp=8.717, rec=0.087, cos=0.002), tot_loss_proj:2.705 [t=0.31s]
prediction: ['[CLS] ultimately of idea : object without some human while theh such rah, a vietnam, patriotic, conflict tone a tone and its define soldierssti ultimately patriotic dramazing with the defined generation human " became picturehouse achieve strategic main strategic objective [SEP]']
[1200/2000] tot_loss=1.833 (perp=8.719, rec=0.087, cos=0.002), tot_loss_proj:2.698 [t=0.31s]
prediction: ['[CLS] ultimately of idea : object without some human while theh such rah, a vietnam, patriotic, conflict tone a tone and its define soldierssti ultimately patriotic dramazing with the that generation human " became picturehouse achieve strategic main strategic objective [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.815 (perp=8.657, rec=0.082, cos=0.002), tot_loss_proj:2.695 [t=0.31s]
prediction: ['[CLS] ultimately of idea : object without some human while theh such rah, a conflict, patriotic, vietnam tone a tone and its define soldierssti ultimately patriotic dramazing with the that generation human " became picturehouse achieve strategic main strategic objective [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.774 (perp=8.426, rec=0.087, cos=0.002), tot_loss_proj:2.735 [t=0.31s]
prediction: ['[CLS] ultimately of idea : object without some conflict while theh such rah, the human, patriotic, vietnam tone a tone and its define soldierssti ultimately patriotic dramazing with the that generation human " became picturehouse achieve strategic main strategic objective [SEP]']
[1350/2000] tot_loss=1.769 (perp=8.426, rec=0.082, cos=0.002), tot_loss_proj:2.735 [t=0.31s]
prediction: ['[CLS] ultimately of idea : object without some conflict while theh such rah, the human, patriotic, vietnam tone a tone and its define soldierssti ultimately patriotic dramazing with the that generation human " became picturehouse achieve strategic main strategic objective [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.716 (perp=8.123, rec=0.088, cos=0.002), tot_loss_proj:2.813 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some conflict while theh such rah, a human, patriotic, vietnam tone a tone and its define soldierssti ultimately patriotic dramazing with the idea generation human "? picturehouse achieve strategic main strategic objective [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.696 (perp=7.989, rec=0.095, cos=0.003), tot_loss_proj:2.805 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some conflict while theh such rah, ultimately human, patriotic, vietnam tone a tone and its define soldierssti a patriotic dramazing with the idea generation human "? picturehouse achieve strategic main strategic objective [SEP]']
[1500/2000] tot_loss=1.686 (perp=7.989, rec=0.086, cos=0.002), tot_loss_proj:2.812 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some conflict while theh such rah, ultimately human, patriotic, vietnam tone a tone and its define soldierssti a patriotic dramazing with the idea generation human "? picturehouse achieve strategic main strategic objective [SEP]']
Attempt swap
[1550/2000] tot_loss=1.713 (perp=8.128, rec=0.085, cos=0.002), tot_loss_proj:2.657 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some conflict while theh such rah, ultimately human, patriotic, vietnam tone a tone and its define soldierssti a patriotic dramazing with the idea generation cost "? picturehouse achieve strategic main strategic objective [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.700 (perp=8.045, rec=0.089, cos=0.002), tot_loss_proj:2.632 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some conflict while theh such rah, ultimately human, patriotic, vietnam tone a tone and its define soldierssti a patriotic dramazing with the idea generation cost "? picturehouse achieve main strategic strategic objective [SEP]']
[1650/2000] tot_loss=1.686 (perp=7.961, rec=0.092, cos=0.002), tot_loss_proj:2.573 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some conflict while theh such rah, ultimately human, patriotic, vietnam tone a tone and its object soldierssti a patriotic dramazing with the idea generation cost "? picturehouse achieve main strategic strategic objective [SEP]']
Attempt swap
[1700/2000] tot_loss=1.682 (perp=7.961, rec=0.088, cos=0.002), tot_loss_proj:2.573 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some conflict while theh such rah, ultimately human, patriotic, vietnam tone a tone and its object soldierssti a patriotic dramazing with the idea generation cost "? picturehouse achieve main strategic strategic objective [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.644 (perp=7.759, rec=0.090, cos=0.002), tot_loss_proj:2.565 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some conflict while theh such rah, ultimately human, patriotic, vietnam tone a tone and its object soldierssti with the patriotic dramazing the idea generation cost "? picturehouse achieve main strategic strategic objective [SEP]']
[1800/2000] tot_loss=1.640 (perp=7.759, rec=0.087, cos=0.002), tot_loss_proj:2.564 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some conflict while theh such rah, ultimately human, patriotic, vietnam tone a tone and its object soldierssti with the patriotic dramazing the idea generation cost "? picturehouse achieve main strategic strategic objective [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.608 (perp=7.614, rec=0.083, cos=0.002), tot_loss_proj:2.469 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some idea while theh such rah, ultimately human, patriotic, vietnam tone a tone and its object soldierssti with the patriotic dramazing the conflict generation cost "? picturehouse achieve main strategic strategic objective [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.576 (perp=7.443, rec=0.086, cos=0.002), tot_loss_proj:2.401 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some idea while theh such rah, ultimately human, patriotic, vietnam tone a tone and its object soldiersstizing with the patriotic drama the conflict generation cost "? picturehouse achieve main strategic strategic objective [SEP]']
[1950/2000] tot_loss=1.578 (perp=7.443, rec=0.088, cos=0.002), tot_loss_proj:2.399 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some idea while theh such rah, ultimately human, patriotic, vietnam tone a tone and its object soldiersstizing with the patriotic drama the conflict generation cost "? picturehouse achieve main strategic strategic objective [SEP]']
Attempt swap
[2000/2000] tot_loss=1.573 (perp=7.443, rec=0.083, cos=0.002), tot_loss_proj:2.396 [t=0.31s]
prediction: ['[CLS] ultimately of that : object without some idea while theh such rah, ultimately human, patriotic, vietnam tone a tone and its object soldiersstizing with the patriotic drama the conflict generation cost "? picturehouse achieve main strategic strategic objective [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] ultimately of that : object without some idea while theh such rah, ultimately human, patriotic, vietnam tone a tone and its object soldierssti with the patriotic dramazing the conflict generation cost "? picturehouse achieve main strategic strategic objective [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 68.421 | r: 65.000
rouge2     | fm: 7.895 | p: 8.108 | r: 7.692
rougeL     | fm: 33.333 | p: 34.211 | r: 32.500
rougeLsum  | fm: 33.333 | p: 34.211 | r: 32.500
r1fm+r2fm = 74.561

[Aggregate metrics]:
rouge1     | fm: 93.657 | p: 93.160 | r: 94.334
rouge2     | fm: 65.966 | p: 65.705 | r: 66.287
rougeL     | fm: 82.063 | p: 81.659 | r: 82.531
rougeLsum  | fm: 81.996 | p: 81.550 | r: 82.520
r1fm+r2fm = 159.623

input #23 time: 0:12:26 | total time: 4:55:15


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9993538563827161
highest_index [0]
highest [0.9993538563827161]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8939337134361267 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8712638020515442 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8561989665031433 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.8265442252159119 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.8194311857223511 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.8159109354019165 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 0.7604994773864746 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.757820188999176 for ['[CLS] bondwyl unless county em arms damned happy suffer play attack younger ryu midaneous bush snow village no port [SEP]']
[Init] best perm rec loss: 0.7558079957962036 for ['[CLS] damned happy county unless bush attack arms em ryu bond play village port suffer younger snow mid nowylaneous [SEP]']
[Init] best perm rec loss: 0.7543618083000183 for ['[CLS] bond younger snow damned arms attack happy em unless no mid play ryu villagewylaneous bush county suffer port [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.606 (perp=11.224, rec=0.337, cos=0.024), tot_loss_proj:3.209 [t=0.31s]
prediction: ['[CLS] attack groups removed outside union situations! terrorists political political threat sc wide! rented european obama observed political phones [SEP]']
[ 100/2000] tot_loss=1.871 (perp=8.226, rec=0.215, cos=0.010), tot_loss_proj:2.270 [t=0.31s]
prediction: ['[CLS] terrorists context taken outside the context ( terrorists political climate? the evil! : enemies! evil are evil [SEP]']
[ 150/2000] tot_loss=1.769 (perp=8.023, rec=0.159, cos=0.005), tot_loss_proj:2.320 [t=0.31s]
prediction: ['[CLS] terrorists context taken outside the climate ( terrorists political climate ) see evil! : villain! evil are evil [SEP]']
[ 200/2000] tot_loss=1.796 (perp=8.252, rec=0.141, cos=0.004), tot_loss_proj:2.371 [t=0.32s]
prediction: ['[CLS] terrorists context taken outside the climate ( terrorists current climate ) see evil! : terrorists! evil are evil [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.839 (perp=8.435, rec=0.146, cos=0.006), tot_loss_proj:2.444 [t=0.32s]
prediction: ['[CLS] terrorists context taken outside the climate ( terrorists ) see evil! : current climate zombie than evil are evil [SEP]']
[ 300/2000] tot_loss=1.817 (perp=8.435, rec=0.126, cos=0.004), tot_loss_proj:2.444 [t=0.32s]
prediction: ['[CLS] terrorists context taken outside the climate ( terrorists ) see evil! : current climate zombie than evil are evil [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.721 (perp=8.017, rec=0.115, cos=0.002), tot_loss_proj:2.241 [t=0.32s]
prediction: ['[CLS] terrorists context taken outside the climate ( terrorists : see current climate thinks evil! ) than evil are evil [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.080 (perp=9.499, rec=0.172, cos=0.008), tot_loss_proj:2.618 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate. terrorists ) see current climate terrible - ) evil than dangerous are evil [SEP]']
[ 450/2000] tot_loss=1.906 (perp=8.757, rec=0.150, cos=0.004), tot_loss_proj:2.440 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( terrorists ) see current climate more - ) evil than ) are ever [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.900 (perp=8.834, rec=0.130, cos=0.004), tot_loss_proj:2.467 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( terrorists ) see current climate evil -! evil than ) are ever [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.743 (perp=8.027, rec=0.134, cos=0.003), tot_loss_proj:2.522 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( terrorists ) see current climate evil -! more than ever are ) [SEP]']
[ 600/2000] tot_loss=1.724 (perp=8.027, rec=0.115, cos=0.003), tot_loss_proj:2.523 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( terrorists ) see current climate evil -! more than ever are ) [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.698 (perp=7.920, rec=0.111, cos=0.003), tot_loss_proj:2.546 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( terrorists ) current see climate evil -! more than ever are ) [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.667 (perp=7.731, rec=0.117, cos=0.004), tot_loss_proj:2.548 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( terrorists ) ) see climate evil -! more than ever are current [SEP]']
[ 750/2000] tot_loss=1.693 (perp=7.911, rec=0.109, cos=0.002), tot_loss_proj:2.562 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( terrorists : ) see climate evil -! more than ever are current [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.639 (perp=7.658, rec=0.105, cos=0.002), tot_loss_proj:2.283 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( current : ) see climate evil -! more than ever are terrorists [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.645 (perp=7.665, rec=0.109, cos=0.003), tot_loss_proj:2.371 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( - : ) see political evil current! more than ever are terrorists [SEP]']
[ 900/2000] tot_loss=1.638 (perp=7.665, rec=0.103, cos=0.003), tot_loss_proj:2.373 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( - : ) see political evil current! more than ever are terrorists [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.642 (perp=7.704, rec=0.099, cos=0.002), tot_loss_proj:2.405 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( ( ) : see political evil current! more than ever are terrorists [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.614 (perp=7.504, rec=0.110, cos=0.002), tot_loss_proj:2.251 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( ( current : see political evil )! more than ever are terrorists [SEP]']
[1050/2000] tot_loss=1.601 (perp=7.504, rec=0.098, cos=0.002), tot_loss_proj:2.252 [t=0.32s]
prediction: ['[CLS] terrorist context taken outside the climate ( ( current : see political evil )! more than ever are terrorists [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.548 (perp=7.245, rec=0.097, cos=0.002), tot_loss_proj:2.292 [t=0.32s]
prediction: ['[CLS] terrorist ( context taken outside the climate ( current : see political evil )! more than ever are terrorists [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.586 (perp=7.373, rec=0.108, cos=0.003), tot_loss_proj:2.285 [t=0.32s]
prediction: ['[CLS] terrorist - context taken outside the climate ( see : current political evil )! more than ever are terrorists [SEP]']
[1200/2000] tot_loss=1.462 (perp=6.802, rec=0.099, cos=0.002), tot_loss_proj:2.200 [t=0.32s]
prediction: ['[CLS] terrorist ( context taken outside the climate ( see : current political evil )! more than ever are terrorists [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.453 (perp=6.741, rec=0.103, cos=0.002), tot_loss_proj:2.170 [t=0.32s]
prediction: ['[CLS] terrorist context ( taken outside the climate ( see : current political evil )! more than ever are terrorists [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.449 (perp=6.741, rec=0.099, cos=0.002), tot_loss_proj:2.157 [t=0.32s]
prediction: ['[CLS] terrorist context ( taken outside the climate ( see : current political evil )! more than ever are terrorists [SEP]']
[1350/2000] tot_loss=1.440 (perp=6.741, rec=0.089, cos=0.002), tot_loss_proj:2.159 [t=0.32s]
prediction: ['[CLS] terrorist context ( taken outside the climate ( see : current political evil )! more than ever are terrorists [SEP]']
Attempt swap
[1400/2000] tot_loss=1.449 (perp=6.741, rec=0.099, cos=0.002), tot_loss_proj:2.155 [t=0.32s]
prediction: ['[CLS] terrorist context ( taken outside the climate ( see : current political evil )! more than ever are terrorists [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.427 (perp=6.623, rec=0.100, cos=0.002), tot_loss_proj:2.147 [t=0.32s]
prediction: ['[CLS] terrorist context ( taken outside the climate ( see current political evil )! : more than ever are terrorists [SEP]']
[1500/2000] tot_loss=1.425 (perp=6.623, rec=0.098, cos=0.002), tot_loss_proj:2.147 [t=0.32s]
prediction: ['[CLS] terrorist context ( taken outside the climate ( see current political evil )! : more than ever are terrorists [SEP]']
Attempt swap
[1550/2000] tot_loss=1.423 (perp=6.623, rec=0.096, cos=0.002), tot_loss_proj:2.147 [t=0.32s]
prediction: ['[CLS] terrorist context ( taken outside the climate ( see current political evil )! : more than ever are terrorists [SEP]']
Attempt swap
[1600/2000] tot_loss=1.429 (perp=6.623, rec=0.102, cos=0.002), tot_loss_proj:2.149 [t=0.32s]
prediction: ['[CLS] terrorist context ( taken outside the climate ( see current political evil )! : more than ever are terrorists [SEP]']
[1650/2000] tot_loss=1.423 (perp=6.623, rec=0.097, cos=0.002), tot_loss_proj:2.151 [t=0.32s]
prediction: ['[CLS] terrorist context ( taken outside the climate ( see current political evil )! : more than ever are terrorists [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.419 (perp=6.582, rec=0.100, cos=0.002), tot_loss_proj:2.137 [t=0.32s]
prediction: ['[CLS] terrorist context ( taken outside the current climate ( see political evil )! : more than ever are terrorists [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.406 (perp=6.486, rec=0.106, cos=0.003), tot_loss_proj:2.174 [t=0.32s]
prediction: ['[CLS] ( terrorist context taken outside the current climate ( see political evil )! : more than ever are terrorists [SEP]']
[1800/2000] tot_loss=1.401 (perp=6.486, rec=0.102, cos=0.002), tot_loss_proj:2.174 [t=0.32s]
prediction: ['[CLS] ( terrorist context taken outside the current climate ( see political evil )! : more than ever are terrorists [SEP]']
Attempt swap
[1850/2000] tot_loss=1.389 (perp=6.486, rec=0.090, cos=0.002), tot_loss_proj:2.173 [t=0.32s]
prediction: ['[CLS] ( terrorist context taken outside the current climate ( see political evil )! : more than ever are terrorists [SEP]']
Attempt swap
[1900/2000] tot_loss=1.401 (perp=6.486, rec=0.102, cos=0.002), tot_loss_proj:2.169 [t=0.32s]
prediction: ['[CLS] ( terrorist context taken outside the current climate ( see political evil )! : more than ever are terrorists [SEP]']
[1950/2000] tot_loss=1.395 (perp=6.486, rec=0.095, cos=0.002), tot_loss_proj:2.175 [t=0.32s]
prediction: ['[CLS] ( terrorist context taken outside the current climate ( see political evil )! : more than ever are terrorists [SEP]']
Attempt swap
[2000/2000] tot_loss=1.388 (perp=6.486, rec=0.089, cos=0.002), tot_loss_proj:2.174 [t=0.32s]
prediction: ['[CLS] ( terrorist context taken outside the current climate ( see political evil )! : more than ever are terrorists [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] terrorist context ( taken outside the climate ( see current political evil )! : more than ever are terrorists [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.429 | p: 94.118 | r: 88.889
rouge2     | fm: 30.303 | p: 31.250 | r: 29.412
rougeL     | fm: 57.143 | p: 58.824 | r: 55.556
rougeLsum  | fm: 57.143 | p: 58.824 | r: 55.556
r1fm+r2fm = 121.732

[Aggregate metrics]:
rouge1     | fm: 93.721 | p: 93.256 | r: 94.194
rouge2     | fm: 64.362 | p: 64.113 | r: 64.694
rougeL     | fm: 81.291 | p: 80.926 | r: 81.694
rougeLsum  | fm: 80.917 | p: 80.563 | r: 81.306
r1fm+r2fm = 158.083

input #24 time: 0:12:36 | total time: 5:07:51


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9993189139253675
highest_index [0]
highest [0.9993189139253675]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.0039576292037964 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.941512405872345 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 0.9328104853630066 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.9311501383781433 for ['[CLS] riot phone expectix [SEP]']
[Init] best rec loss: 0.9242056012153625 for ['[CLS] cigarettes happy before makers [SEP]']
[Init] best rec loss: 0.9140980243682861 for ['[CLS] each envoy socialist achieving [SEP]']
[Init] best rec loss: 0.9053016304969788 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best rec loss: 0.87577885389328 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best perm rec loss: 0.8752681016921997 for ['[CLS] oblast mouth jury cycle [SEP]']
[Init] best perm rec loss: 0.8752651810646057 for ['[CLS] oblast jury mouth cycle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.350 (perp=10.589, rec=0.227, cos=0.005), tot_loss_proj:2.505 [t=0.31s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 100/2000] tot_loss=2.224 (perp=10.560, rec=0.111, cos=0.002), tot_loss_proj:2.806 [t=0.31s]
prediction: ['[CLS] beautiful film strange strange [SEP]']
[ 150/2000] tot_loss=1.899 (perp=9.132, rec=0.071, cos=0.001), tot_loss_proj:2.095 [t=0.31s]
prediction: ['[CLS] beautiful film and strange [SEP]']
[ 200/2000] tot_loss=1.897 (perp=9.132, rec=0.069, cos=0.001), tot_loss_proj:2.102 [t=0.31s]
prediction: ['[CLS] beautiful film and strange [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.494 (perp=7.104, rec=0.072, cos=0.001), tot_loss_proj:1.642 [t=0.31s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[ 300/2000] tot_loss=1.480 (perp=7.104, rec=0.057, cos=0.001), tot_loss_proj:1.635 [t=0.31s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.390 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.424 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.382 (perp=6.646, rec=0.051, cos=0.001), tot_loss_proj:1.434 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.431 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.436 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.385 (perp=6.646, rec=0.054, cos=0.001), tot_loss_proj:1.426 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.436 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.383 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.442 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.384 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.430 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.392 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.439 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.386 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.427 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.383 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.435 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.432 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.397 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.433 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.385 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.423 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.430 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.398 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.428 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.436 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.386 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.433 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.398 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.430 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.392 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.434 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.398 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.435 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.382 (perp=6.646, rec=0.051, cos=0.001), tot_loss_proj:1.433 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.384 (perp=6.646, rec=0.054, cos=0.001), tot_loss_proj:1.423 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.379 (perp=6.646, rec=0.049, cos=0.001), tot_loss_proj:1.440 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.398 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.437 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.382 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.434 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.397 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.434 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.404 (perp=6.646, rec=0.073, cos=0.001), tot_loss_proj:1.451 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.435 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.395 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.439 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.398 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.443 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.399 (perp=6.646, rec=0.069, cos=0.001), tot_loss_proj:1.432 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.399 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.441 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.371 (perp=6.646, rec=0.040, cos=0.001), tot_loss_proj:1.435 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.891 | p: 93.442 | r: 94.374
rouge2     | fm: 65.522 | p: 65.268 | r: 65.844
rougeL     | fm: 81.923 | p: 81.571 | r: 82.390
rougeLsum  | fm: 81.705 | p: 81.286 | r: 82.054
r1fm+r2fm = 159.413

input #25 time: 0:12:17 | total time: 5:20:08


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9992064578245546
highest_index [0]
highest [0.9992064578245546]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.9747058749198914 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.9671226143836975 for ['[CLS] arthur senior green europa out reach o approaching beck saga phone kimball range tel alain pointing spoil during people na tanggram bucket [SEP]']
[Init] best rec loss: 0.959077000617981 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 0.953892171382904 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 0.9419010877609253 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.939020037651062 for ['[CLS] own aren solelyval hull shoot [CLS] letter four t gore plan when how marsh recently assessment throughout hiv bequeathed administrative liberty branch [SEP]']
[Init] best rec loss: 0.9359309673309326 for ['[CLS] frozen peru embarrassed not one farimus sole australian clearance ladder | heir stevie covert dollars hunter allmusic post remain depending⁺ isolation [SEP]']
[Init] best rec loss: 0.8866217732429504 for ['[CLS] also space add ao intent bat intentם should huge charity family timeline rectangular whom failed list supposed boat deputyness teaches hair [SEP]']
[Init] best perm rec loss: 0.8809798955917358 for ['[CLS] ao also supposed failed bat rectangular space huge teaches deputy familyם add intentness hair boat whom intent should list timeline charity [SEP]']
[Init] best perm rec loss: 0.8798781633377075 for ['[CLS] failed teaches should boatness also bat supposed list whom hair ao family rectangular timeline deputyם huge charity add intent intent space [SEP]']
[Init] best perm rec loss: 0.8798630833625793 for ['[CLS] batם should ao list timeline boat add family failed huge deputy teachesness charity also whom supposed hair intent rectangular space intent [SEP]']
[Init] best perm rec loss: 0.8781436085700989 for ['[CLS] deputy bat timeline huge family intent also rectangular list teaches failed intentness hair should ao space add supposed boat whomם charity [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.477 (perp=11.098, rec=0.248, cos=0.009), tot_loss_proj:2.890 [t=0.31s]
prediction: ['[CLS] pointless ) and pointless french import import of coin canadian intended import a gift could moment gracie person mostly options nationality as punjab [SEP]']
[ 100/2000] tot_loss=2.513 (perp=11.321, rec=0.240, cos=0.008), tot_loss_proj:2.901 [t=0.32s]
prediction: ['[CLS] pointless ) ) pointless french import from from import french writer writer a import souls clocks - writer - coming import * from [SEP]']
[ 150/2000] tot_loss=2.549 (perp=11.867, rec=0.171, cos=0.005), tot_loss_proj:3.096 [t=0.32s]
prediction: ['[CLS] pointless ) ) pointless french import from coming import french writer writer - import song anne sophie director mini ages ages from [SEP]']
[ 200/2000] tot_loss=2.336 (perp=11.028, rec=0.127, cos=0.004), tot_loss_proj:3.277 [t=0.32s]
prediction: ['[CLS] pointless this ) pointless french - and coming import french writer writer of import song anne sophie director occasion surrounding ages from [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.303 (perp=10.949, rec=0.110, cos=0.003), tot_loss_proj:3.129 [t=0.32s]
prediction: ['[CLS] pointless this ) pointless french - and coming import french writer writer of import director song anne sophie bi purposes ages from [SEP]']
[ 300/2000] tot_loss=2.282 (perp=10.875, rec=0.105, cos=0.002), tot_loss_proj:3.089 [t=0.32s]
prediction: ['[CLS] pointless this ) pointless french - and coming import french writer writer of import director song anne sophie bi average ages from [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.100 (perp=10.003, rec=0.097, cos=0.002), tot_loss_proj:2.777 [t=0.32s]
prediction: ['[CLS] pointless this ) pointless director - and coming import french writer writer of import french - anne sophie bi average ages from [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.033 (perp=9.686, rec=0.094, cos=0.002), tot_loss_proj:2.733 [t=0.32s]
prediction: ['[CLS] mean this ) pointless director - and coming import french writer - of import french writer anne sophierot mean age mean from [SEP]']
[ 450/2000] tot_loss=2.033 (perp=9.686, rec=0.094, cos=0.002), tot_loss_proj:2.727 [t=0.32s]
prediction: ['[CLS] mean this ) pointless director - and coming import french writer - of import french writer anne sophierot mean age mean from [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.057 (perp=9.870, rec=0.082, cos=0.002), tot_loss_proj:2.804 [t=0.32s]
prediction: ['[CLS] mean this ) pointless director - and comingder french writer - of import french writer annerot sophie mean age mean from [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.004 (perp=9.565, rec=0.089, cos=0.002), tot_loss_proj:2.555 [t=0.32s]
prediction: ['[CLS] mean this ) pointless director - and coming mean french writer - of import french - annerot sophie mean ageder from [SEP]']
[ 600/2000] tot_loss=2.012 (perp=9.657, rec=0.079, cos=0.002), tot_loss_proj:2.501 [t=0.32s]
prediction: ['[CLS]ing this ) pointless director - and coming mean french writer - of import french - annerot sophie mean ageder from [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.929 (perp=9.209, rec=0.086, cos=0.002), tot_loss_proj:2.440 [t=0.32s]
prediction: ['[CLS]ing this ) pointless director - and coming mean french writer - of import french - annerot age sophie meander from [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.893 (perp=8.978, rec=0.095, cos=0.002), tot_loss_proj:2.382 [t=0.32s]
prediction: ['[CLS]ing this ) pointless director - and coming mean french writer - of age import season - annerot sophie meander from [SEP]']
[ 750/2000] tot_loss=1.994 (perp=9.566, rec=0.079, cos=0.002), tot_loss_proj:2.439 [t=0.32s]
prediction: ['[CLS]ing this ) pointless director - and coming mean french writer - of age import writer - annerot sophiederder from [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.869 (perp=8.928, rec=0.081, cos=0.002), tot_loss_proj:2.317 [t=0.32s]
prediction: ['[CLS]ing this ) pointless director - and coming mean french writer - of age import writer - from annerot sophie mean - [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.709 (perp=8.141, rec=0.079, cos=0.002), tot_loss_proj:2.132 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from annerot sophie meander [SEP]']
[ 900/2000] tot_loss=1.848 (perp=8.865, rec=0.073, cos=0.002), tot_loss_proj:2.271 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from annerot sophiederder [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.849 (perp=8.865, rec=0.074, cos=0.002), tot_loss_proj:2.269 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from annerot sophiederder [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.848 (perp=8.836, rec=0.079, cos=0.002), tot_loss_proj:2.271 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
[1050/2000] tot_loss=1.836 (perp=8.836, rec=0.068, cos=0.002), tot_loss_proj:2.275 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.844 (perp=8.836, rec=0.075, cos=0.002), tot_loss_proj:2.263 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.841 (perp=8.836, rec=0.072, cos=0.002), tot_loss_proj:2.271 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
[1200/2000] tot_loss=1.843 (perp=8.836, rec=0.074, cos=0.002), tot_loss_proj:2.271 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
[1250/2000] tot_loss=1.842 (perp=8.836, rec=0.074, cos=0.002), tot_loss_proj:2.273 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
[1300/2000] tot_loss=1.843 (perp=8.836, rec=0.074, cos=0.002), tot_loss_proj:2.266 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
[1350/2000] tot_loss=1.839 (perp=8.836, rec=0.070, cos=0.002), tot_loss_proj:2.270 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
[1400/2000] tot_loss=1.840 (perp=8.836, rec=0.071, cos=0.002), tot_loss_proj:2.275 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
[1450/2000] tot_loss=1.846 (perp=8.836, rec=0.077, cos=0.002), tot_loss_proj:2.270 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
[1500/2000] tot_loss=1.836 (perp=8.836, rec=0.067, cos=0.002), tot_loss_proj:2.270 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
[1550/2000] tot_loss=1.836 (perp=8.836, rec=0.067, cos=0.002), tot_loss_proj:2.271 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
[1600/2000] tot_loss=1.833 (perp=8.836, rec=0.064, cos=0.002), tot_loss_proj:2.270 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
[1650/2000] tot_loss=1.840 (perp=8.836, rec=0.071, cos=0.002), tot_loss_proj:2.270 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.842 (perp=8.836, rec=0.073, cos=0.002), tot_loss_proj:2.271 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
[1750/2000] tot_loss=1.837 (perp=8.836, rec=0.068, cos=0.002), tot_loss_proj:2.270 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
[1800/2000] tot_loss=1.831 (perp=8.836, rec=0.062, cos=0.002), tot_loss_proj:2.270 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
[1850/2000] tot_loss=1.836 (perp=8.836, rec=0.067, cos=0.002), tot_loss_proj:2.273 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
[1900/2000] tot_loss=1.836 (perp=8.836, rec=0.067, cos=0.002), tot_loss_proj:2.268 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
[1950/2000] tot_loss=1.844 (perp=8.836, rec=0.075, cos=0.002), tot_loss_proj:2.274 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Attempt swap
[2000/2000] tot_loss=1.844 (perp=8.836, rec=0.075, cos=0.002), tot_loss_proj:2.272 [t=0.32s]
prediction: ['[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS]ing ) this pointless director - and coming mean french writer - of age import - - from anne sophierotderder [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 82.353 | r: 82.353
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 58.824 | p: 58.824 | r: 58.824
rougeLsum  | fm: 58.824 | p: 58.824 | r: 58.824
r1fm+r2fm = 101.103

[Aggregate metrics]:
rouge1     | fm: 93.550 | p: 93.121 | r: 94.006
rouge2     | fm: 63.753 | p: 63.480 | r: 63.971
rougeL     | fm: 81.190 | p: 80.842 | r: 81.552
rougeLsum  | fm: 80.767 | p: 80.421 | r: 81.105
r1fm+r2fm = 157.303

input #26 time: 0:12:35 | total time: 5:32:44


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.9993447978899664
highest_index [0]
highest [0.9993447978899664]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9612470269203186 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9335777163505554 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.9092200398445129 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 0.85639888048172 for ['[CLS] landing imposed distant [SEP]']
[Init] best rec loss: 0.8050276637077332 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.804314911365509 for ['[CLS] transitwine given [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.650 (perp=11.636, rec=0.702, cos=0.621), tot_loss_proj:3.927 [t=0.30s]
prediction: ['[CLS] undefeated traditional waitress [SEP]']
[ 100/2000] tot_loss=3.412 (perp=9.693, rec=0.606, cos=0.867), tot_loss_proj:2.524 [t=0.31s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 150/2000] tot_loss=3.714 (perp=10.519, rec=0.613, cos=0.997), tot_loss_proj:2.590 [t=0.31s]
prediction: ['[CLS] truly generic generic [SEP]']
[ 200/2000] tot_loss=2.465 (perp=10.519, rec=0.311, cos=0.050), tot_loss_proj:2.583 [t=0.31s]
prediction: ['[CLS] truly generic generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.101 (perp=9.509, rec=0.186, cos=0.014), tot_loss_proj:2.322 [t=0.31s]
prediction: ['[CLS] are generic generic [SEP]']
[ 300/2000] tot_loss=2.054 (perp=9.509, rec=0.143, cos=0.009), tot_loss_proj:2.316 [t=0.31s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.738 (perp=8.320, rec=0.073, cos=0.002), tot_loss_proj:1.747 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.723 (perp=8.320, rec=0.058, cos=0.001), tot_loss_proj:1.737 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.727 (perp=8.320, rec=0.062, cos=0.001), tot_loss_proj:1.751 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.732 (perp=8.320, rec=0.067, cos=0.001), tot_loss_proj:1.741 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.734 (perp=8.320, rec=0.069, cos=0.001), tot_loss_proj:1.750 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.720 (perp=8.320, rec=0.055, cos=0.001), tot_loss_proj:1.751 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.733 (perp=8.320, rec=0.068, cos=0.001), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.735 (perp=8.320, rec=0.070, cos=0.001), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.720 (perp=8.320, rec=0.055, cos=0.001), tot_loss_proj:1.740 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.732 (perp=8.320, rec=0.067, cos=0.001), tot_loss_proj:1.748 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.722 (perp=8.320, rec=0.057, cos=0.001), tot_loss_proj:1.742 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.726 (perp=8.320, rec=0.061, cos=0.001), tot_loss_proj:1.741 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.731 (perp=8.320, rec=0.066, cos=0.001), tot_loss_proj:1.744 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.734 (perp=8.320, rec=0.069, cos=0.001), tot_loss_proj:1.739 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.727 (perp=8.320, rec=0.061, cos=0.001), tot_loss_proj:1.747 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.733 (perp=8.320, rec=0.068, cos=0.001), tot_loss_proj:1.735 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.726 (perp=8.320, rec=0.061, cos=0.001), tot_loss_proj:1.733 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.719 (perp=8.320, rec=0.054, cos=0.001), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.725 (perp=8.320, rec=0.059, cos=0.001), tot_loss_proj:1.744 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.735 (perp=8.320, rec=0.070, cos=0.001), tot_loss_proj:1.749 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.719 (perp=8.320, rec=0.054, cos=0.001), tot_loss_proj:1.748 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.730 (perp=8.320, rec=0.065, cos=0.001), tot_loss_proj:1.750 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.719 (perp=8.320, rec=0.054, cos=0.001), tot_loss_proj:1.756 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.724 (perp=8.320, rec=0.058, cos=0.001), tot_loss_proj:1.746 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.734 (perp=8.320, rec=0.069, cos=0.001), tot_loss_proj:1.749 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.730 (perp=8.320, rec=0.065, cos=0.001), tot_loss_proj:1.756 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.732 (perp=8.320, rec=0.066, cos=0.001), tot_loss_proj:1.751 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.723 (perp=8.320, rec=0.058, cos=0.001), tot_loss_proj:1.749 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.723 (perp=8.320, rec=0.058, cos=0.001), tot_loss_proj:1.743 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.723 (perp=8.320, rec=0.058, cos=0.001), tot_loss_proj:1.738 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.725 (perp=8.320, rec=0.060, cos=0.001), tot_loss_proj:1.746 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.725 (perp=8.320, rec=0.059, cos=0.001), tot_loss_proj:1.753 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.725 (perp=8.320, rec=0.060, cos=0.001), tot_loss_proj:1.751 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.736 (perp=8.320, rec=0.071, cos=0.001), tot_loss_proj:1.748 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.733 | p: 93.324 | r: 94.189
rouge2     | fm: 65.148 | p: 64.948 | r: 65.410
rougeL     | fm: 81.816 | p: 81.479 | r: 82.233
rougeLsum  | fm: 81.470 | p: 81.100 | r: 81.799
r1fm+r2fm = 158.880

input #27 time: 0:12:14 | total time: 5:44:59


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.9993340460243574
highest_index [0]
highest [0.9993340460243574]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8100812435150146 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.7968172430992126 for ['[CLS] guests mackenzie voyager reader [SEP]']
[Init] best rec loss: 0.7956729531288147 for ['[CLS]ness aluminium cleveland tv [SEP]']
[Init] best rec loss: 0.785802960395813 for ['[CLS] james facilitieslty ¨ [SEP]']
[Init] best rec loss: 0.7854955792427063 for ['[CLS] leach mackenzie log sorority [SEP]']
[Init] best rec loss: 0.7448630332946777 for ['[CLS] fully mixeduro battlefield [SEP]']
[Init] best perm rec loss: 0.7437870502471924 for ['[CLS] fullyuro battlefield mixed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.258 (perp=9.727, rec=0.280, cos=0.033), tot_loss_proj:3.019 [t=0.30s]
prediction: ['[CLS] for minutes eternity minutes [SEP]']
[ 100/2000] tot_loss=1.838 (perp=8.476, rec=0.129, cos=0.014), tot_loss_proj:2.176 [t=0.31s]
prediction: ['[CLS] for only minutes minutes [SEP]']
[ 150/2000] tot_loss=1.811 (perp=8.476, rec=0.107, cos=0.008), tot_loss_proj:2.187 [t=0.31s]
prediction: ['[CLS] for only minutes minutes [SEP]']
[ 200/2000] tot_loss=1.925 (perp=9.124, rec=0.095, cos=0.006), tot_loss_proj:2.248 [t=0.31s]
prediction: ['[CLS] for 71 only minutes [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.619 (perp=7.699, rec=0.077, cos=0.002), tot_loss_proj:1.612 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 300/2000] tot_loss=1.621 (perp=7.699, rec=0.078, cos=0.003), tot_loss_proj:1.623 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.595 (perp=7.699, rec=0.054, cos=0.001), tot_loss_proj:1.619 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.605 (perp=7.699, rec=0.064, cos=0.001), tot_loss_proj:1.611 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 450/2000] tot_loss=1.600 (perp=7.699, rec=0.059, cos=0.001), tot_loss_proj:1.619 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.591 (perp=7.699, rec=0.050, cos=0.001), tot_loss_proj:1.622 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.629 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.589 (perp=7.699, rec=0.048, cos=0.001), tot_loss_proj:1.613 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.608 (perp=7.699, rec=0.067, cos=0.001), tot_loss_proj:1.623 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.604 (perp=7.699, rec=0.063, cos=0.001), tot_loss_proj:1.619 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.598 (perp=7.699, rec=0.057, cos=0.001), tot_loss_proj:1.612 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.606 (perp=7.699, rec=0.065, cos=0.001), tot_loss_proj:1.611 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.609 (perp=7.699, rec=0.068, cos=0.001), tot_loss_proj:1.622 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.604 (perp=7.699, rec=0.063, cos=0.001), tot_loss_proj:1.615 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.596 (perp=7.699, rec=0.055, cos=0.001), tot_loss_proj:1.617 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.001), tot_loss_proj:1.627 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.604 (perp=7.699, rec=0.063, cos=0.001), tot_loss_proj:1.615 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.616 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.596 (perp=7.699, rec=0.055, cos=0.001), tot_loss_proj:1.620 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.594 (perp=7.699, rec=0.053, cos=0.001), tot_loss_proj:1.625 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.602 (perp=7.699, rec=0.061, cos=0.001), tot_loss_proj:1.627 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.614 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.607 (perp=7.699, rec=0.066, cos=0.001), tot_loss_proj:1.620 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.610 (perp=7.699, rec=0.069, cos=0.001), tot_loss_proj:1.616 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.602 (perp=7.699, rec=0.061, cos=0.001), tot_loss_proj:1.624 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.592 (perp=7.699, rec=0.051, cos=0.001), tot_loss_proj:1.625 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.607 (perp=7.699, rec=0.066, cos=0.001), tot_loss_proj:1.612 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.605 (perp=7.699, rec=0.064, cos=0.001), tot_loss_proj:1.618 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.606 (perp=7.699, rec=0.065, cos=0.001), tot_loss_proj:1.617 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.590 (perp=7.699, rec=0.049, cos=0.001), tot_loss_proj:1.622 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.604 (perp=7.699, rec=0.062, cos=0.001), tot_loss_proj:1.621 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.600 (perp=7.699, rec=0.059, cos=0.001), tot_loss_proj:1.609 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.001), tot_loss_proj:1.606 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.606 (perp=7.699, rec=0.065, cos=0.001), tot_loss_proj:1.628 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.604 (perp=7.699, rec=0.063, cos=0.001), tot_loss_proj:1.620 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.604 (perp=7.699, rec=0.063, cos=0.001), tot_loss_proj:1.616 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.999 | p: 93.593 | r: 94.387
rouge2     | fm: 66.560 | p: 66.310 | r: 66.832
rougeL     | fm: 82.371 | p: 82.056 | r: 82.701
rougeLsum  | fm: 82.187 | p: 81.896 | r: 82.468
r1fm+r2fm = 160.559

input #28 time: 0:12:15 | total time: 5:57:15


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.9992954001728517
highest_index [0]
highest [0.9992954001728517]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.9477908611297607 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.9244424104690552 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.9125427603721619 for ['[CLS] persons carmenworm virtualack gems grand likes fries southern [SEP]']
[Init] best rec loss: 0.854781985282898 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8484178781509399 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 0.8472756147384644 for ['[CLS] lordship buckingham rather postsbor we home wildlife valleygan [SEP]']
[Init] best rec loss: 0.8440432548522949 for ['[CLS] crystal shock completion carrydable stay recordingdrive ella off [SEP]']
[Init] best rec loss: 0.821438193321228 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 0.8155828714370728 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best rec loss: 0.8127574920654297 for ['[CLS] tv envelope engagement administration landed tasteuted this runs oil [SEP]']
[Init] best perm rec loss: 0.8124918937683105 for ['[CLS] tv oil envelope administration taste this engagementuted runs landed [SEP]']
[Init] best perm rec loss: 0.807999849319458 for ['[CLS] taste landed administration this runs tv engagementuted oil envelope [SEP]']
[Init] best perm rec loss: 0.8062813878059387 for ['[CLS] envelope engagement runs this tv taste landed oiluted administration [SEP]']
[Init] best perm rec loss: 0.8020158410072327 for ['[CLS] tv tasteuted runs landed envelope engagement administration oil this [SEP]']
[Init] best perm rec loss: 0.8010280132293701 for ['[CLS] oiluted this landed runs tv taste envelope engagement administration [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.526 (perp=10.682, rec=0.351, cos=0.039), tot_loss_proj:3.146 [t=0.30s]
prediction: ['[CLS]ini believe supposed focal is somebody., paperwork block [SEP]']
[ 100/2000] tot_loss=2.377 (perp=10.760, rec=0.209, cos=0.016), tot_loss_proj:3.335 [t=0.31s]
prediction: ['[CLS]ar believe resident rumours not it..lving judge [SEP]']
[ 150/2000] tot_loss=2.151 (perp=9.786, rec=0.181, cos=0.013), tot_loss_proj:3.101 [t=0.31s]
prediction: ['[CLS]ists believe resident evil not it..lving meantime [SEP]']
[ 200/2000] tot_loss=1.981 (perp=9.075, rec=0.156, cos=0.010), tot_loss_proj:2.826 [t=0.31s]
prediction: ['[CLS]ors believe resident evil not it.. illegal also [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.051 (perp=9.201, rec=0.195, cos=0.016), tot_loss_proj:2.803 [t=0.31s]
prediction: ['[CLS]ors believe resident evil not it after nairobi still. [SEP]']
[ 300/2000] tot_loss=1.962 (perp=8.929, rec=0.164, cos=0.012), tot_loss_proj:2.725 [t=0.31s]
prediction: ['[CLS]ors believe resident evil not it after nairobi also. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.917 (perp=8.763, rec=0.154, cos=0.010), tot_loss_proj:2.831 [t=0.31s]
prediction: ['[CLS]ors believe resident evil not it after also checkpoint. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.495 (perp=6.740, rec=0.137, cos=0.010), tot_loss_proj:2.820 [t=0.31s]
prediction: ['[CLS] i believe resident evil not after it also although. [SEP]']
[ 450/2000] tot_loss=1.490 (perp=6.740, rec=0.133, cos=0.009), tot_loss_proj:2.813 [t=0.31s]
prediction: ['[CLS] i believe resident evil not after it also although. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.486 (perp=6.739, rec=0.131, cos=0.007), tot_loss_proj:1.876 [t=0.31s]
prediction: ['[CLS] i also believe resident evil not his it does. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.270 (perp=5.726, rec=0.118, cos=0.006), tot_loss_proj:1.658 [t=0.31s]
prediction: ['[CLS] i also believe resident evil does not his it. [SEP]']
[ 600/2000] tot_loss=1.254 (perp=5.726, rec=0.103, cos=0.006), tot_loss_proj:1.662 [t=0.31s]
prediction: ['[CLS] i also believe resident evil does not his it. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.253 (perp=5.726, rec=0.102, cos=0.005), tot_loss_proj:1.663 [t=0.31s]
prediction: ['[CLS] i also believe resident evil does not his it. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.360 (perp=6.253, rec=0.104, cos=0.005), tot_loss_proj:2.908 [t=0.31s]
prediction: ['[CLS] i also believe resident evil when not his it. [SEP]']
[ 750/2000] tot_loss=1.358 (perp=6.253, rec=0.103, cos=0.005), tot_loss_proj:2.911 [t=0.31s]
prediction: ['[CLS] i also believe resident evil when not his it. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.351 (perp=6.253, rec=0.095, cos=0.005), tot_loss_proj:2.909 [t=0.31s]
prediction: ['[CLS] i also believe resident evil when not his it. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.359 (perp=6.253, rec=0.104, cos=0.005), tot_loss_proj:2.910 [t=0.31s]
prediction: ['[CLS] i also believe resident evil when not his it. [SEP]']
[ 900/2000] tot_loss=1.368 (perp=6.253, rec=0.113, cos=0.005), tot_loss_proj:2.914 [t=0.31s]
prediction: ['[CLS] i also believe resident evil when not his it. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.358 (perp=6.253, rec=0.102, cos=0.005), tot_loss_proj:2.907 [t=0.31s]
prediction: ['[CLS] i also believe resident evil when not his it. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.346 (perp=6.253, rec=0.090, cos=0.005), tot_loss_proj:2.906 [t=0.31s]
prediction: ['[CLS] i also believe resident evil when not his it. [SEP]']
[1050/2000] tot_loss=1.356 (perp=6.253, rec=0.101, cos=0.005), tot_loss_proj:2.906 [t=0.31s]
prediction: ['[CLS] i also believe resident evil when not his it. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.342 (perp=6.253, rec=0.087, cos=0.004), tot_loss_proj:2.904 [t=0.31s]
prediction: ['[CLS] i also believe resident evil when not his it. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.346 (perp=6.253, rec=0.091, cos=0.004), tot_loss_proj:2.909 [t=0.31s]
prediction: ['[CLS] i also believe resident evil when not his it. [SEP]']
[1200/2000] tot_loss=1.357 (perp=6.253, rec=0.102, cos=0.004), tot_loss_proj:2.905 [t=0.31s]
prediction: ['[CLS] i also believe resident evil when not his it. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.151 (perp=5.262, rec=0.094, cos=0.004), tot_loss_proj:1.670 [t=0.31s]
prediction: ['[CLS] i also believe resident evil is not his it. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.143 (perp=5.262, rec=0.087, cos=0.004), tot_loss_proj:1.678 [t=0.31s]
prediction: ['[CLS] i also believe resident evil is not his it. [SEP]']
[1350/2000] tot_loss=1.146 (perp=5.262, rec=0.089, cos=0.004), tot_loss_proj:1.669 [t=0.31s]
prediction: ['[CLS] i also believe resident evil is not his it. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.153 (perp=5.262, rec=0.097, cos=0.004), tot_loss_proj:1.676 [t=0.31s]
prediction: ['[CLS] i also believe resident evil is not his it. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.155 (perp=5.262, rec=0.098, cos=0.004), tot_loss_proj:1.678 [t=0.31s]
prediction: ['[CLS] i also believe resident evil is not his it. [SEP]']
[1500/2000] tot_loss=1.148 (perp=5.262, rec=0.091, cos=0.004), tot_loss_proj:1.664 [t=0.31s]
prediction: ['[CLS] i also believe resident evil is not his it. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.130 (perp=5.170, rec=0.092, cos=0.004), tot_loss_proj:1.666 [t=0.31s]
prediction: ['[CLS] i also believe resident evil is not that it. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.124 (perp=5.170, rec=0.086, cos=0.004), tot_loss_proj:1.664 [t=0.31s]
prediction: ['[CLS] i also believe resident evil is not that it. [SEP]']
[1650/2000] tot_loss=1.133 (perp=5.170, rec=0.094, cos=0.004), tot_loss_proj:1.660 [t=0.31s]
prediction: ['[CLS] i also believe resident evil is not that it. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.167 (perp=5.296, rec=0.103, cos=0.005), tot_loss_proj:1.481 [t=0.31s]
prediction: ['[CLS] i also believe his resident evil is not it. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.166 (perp=5.296, rec=0.103, cos=0.004), tot_loss_proj:1.480 [t=0.31s]
prediction: ['[CLS] i also believe his resident evil is not it. [SEP]']
[1800/2000] tot_loss=1.161 (perp=5.296, rec=0.098, cos=0.004), tot_loss_proj:1.485 [t=0.31s]
prediction: ['[CLS] i also believe his resident evil is not it. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.154 (perp=5.296, rec=0.091, cos=0.004), tot_loss_proj:1.479 [t=0.31s]
prediction: ['[CLS] i also believe his resident evil is not it. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.150 (perp=5.296, rec=0.087, cos=0.004), tot_loss_proj:1.486 [t=0.31s]
prediction: ['[CLS] i also believe his resident evil is not it. [SEP]']
[1950/2000] tot_loss=1.162 (perp=5.296, rec=0.099, cos=0.004), tot_loss_proj:1.475 [t=0.31s]
prediction: ['[CLS] i also believe his resident evil is not it. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.167 (perp=5.296, rec=0.104, cos=0.004), tot_loss_proj:1.488 [t=0.31s]
prediction: ['[CLS] i also believe his resident evil is not it. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe his resident evil is not it. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 80.000 | p: 80.000 | r: 80.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 170.909

[Aggregate metrics]:
rouge1     | fm: 93.887 | p: 93.477 | r: 94.263
rouge2     | fm: 66.904 | p: 66.674 | r: 67.076
rougeL     | fm: 82.731 | p: 82.462 | r: 83.052
rougeLsum  | fm: 82.310 | p: 82.055 | r: 82.688
r1fm+r2fm = 160.791

input #29 time: 0:12:15 | total time: 6:09:31


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.999272589170739
highest_index [0]
highest [0.999272589170739]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.9159679412841797 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.8719581365585327 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 0.8056197166442871 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.790490984916687 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7791374921798706 for ['[CLS] footading night [SEP]']
[Init] best rec loss: 0.7368282675743103 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.7164271473884583 for ['[CLS] acceleration council lizard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.699 (perp=11.994, rec=0.283, cos=0.017), tot_loss_proj:3.768 [t=0.30s]
prediction: ['[CLS]zzability painter [SEP]']
[ 100/2000] tot_loss=2.399 (perp=11.195, rec=0.153, cos=0.006), tot_loss_proj:3.349 [t=0.31s]
prediction: ['[CLS]zzability in [SEP]']
[ 150/2000] tot_loss=2.727 (perp=12.950, rec=0.132, cos=0.006), tot_loss_proj:3.748 [t=0.31s]
prediction: ['[CLS]zzability fi [SEP]']
[ 200/2000] tot_loss=2.714 (perp=12.950, rec=0.119, cos=0.005), tot_loss_proj:3.755 [t=0.31s]
prediction: ['[CLS]zzability fi [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.022 (perp=9.539, rec=0.109, cos=0.005), tot_loss_proj:1.992 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.995 (perp=9.539, rec=0.084, cos=0.004), tot_loss_proj:1.987 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.980 (perp=9.539, rec=0.071, cos=0.002), tot_loss_proj:1.989 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.970 (perp=9.539, rec=0.060, cos=0.002), tot_loss_proj:1.982 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.973 (perp=9.539, rec=0.063, cos=0.001), tot_loss_proj:1.983 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.975 (perp=9.539, rec=0.066, cos=0.001), tot_loss_proj:1.978 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.968 (perp=9.539, rec=0.059, cos=0.001), tot_loss_proj:1.981 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.964 (perp=9.539, rec=0.055, cos=0.001), tot_loss_proj:1.975 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.969 (perp=9.539, rec=0.059, cos=0.002), tot_loss_proj:1.985 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.959 (perp=9.539, rec=0.049, cos=0.001), tot_loss_proj:1.965 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.980 (perp=9.539, rec=0.071, cos=0.001), tot_loss_proj:1.980 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.973 (perp=9.539, rec=0.064, cos=0.001), tot_loss_proj:1.970 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.965 (perp=9.539, rec=0.056, cos=0.001), tot_loss_proj:1.978 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.967 (perp=9.539, rec=0.058, cos=0.001), tot_loss_proj:1.976 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.967 (perp=9.539, rec=0.058, cos=0.001), tot_loss_proj:1.971 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.975 (perp=9.539, rec=0.066, cos=0.001), tot_loss_proj:1.972 [t=0.40s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.968 (perp=9.539, rec=0.059, cos=0.001), tot_loss_proj:1.980 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.970 (perp=9.539, rec=0.060, cos=0.001), tot_loss_proj:1.984 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.965 (perp=9.539, rec=0.056, cos=0.001), tot_loss_proj:1.989 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.965 (perp=9.539, rec=0.056, cos=0.001), tot_loss_proj:1.974 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.969 (perp=9.539, rec=0.059, cos=0.001), tot_loss_proj:1.984 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.964 (perp=9.539, rec=0.055, cos=0.001), tot_loss_proj:1.981 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.981 (perp=9.539, rec=0.072, cos=0.001), tot_loss_proj:1.970 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.975 (perp=9.539, rec=0.065, cos=0.001), tot_loss_proj:1.963 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.955 (perp=9.539, rec=0.045, cos=0.001), tot_loss_proj:1.969 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.965 (perp=9.539, rec=0.056, cos=0.001), tot_loss_proj:1.967 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.980 (perp=9.539, rec=0.070, cos=0.001), tot_loss_proj:1.976 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.975 (perp=9.539, rec=0.066, cos=0.001), tot_loss_proj:1.977 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.970 (perp=9.539, rec=0.061, cos=0.001), tot_loss_proj:1.972 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.964 (perp=9.539, rec=0.054, cos=0.001), tot_loss_proj:1.975 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.967 (perp=9.539, rec=0.057, cos=0.001), tot_loss_proj:1.967 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.974 (perp=9.539, rec=0.065, cos=0.001), tot_loss_proj:1.975 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.968 (perp=9.539, rec=0.059, cos=0.001), tot_loss_proj:1.973 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.963 (perp=9.539, rec=0.054, cos=0.001), tot_loss_proj:1.968 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.973 (perp=9.539, rec=0.064, cos=0.001), tot_loss_proj:1.980 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.970 (perp=9.539, rec=0.061, cos=0.001), tot_loss_proj:1.965 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.036 | p: 93.692 | r: 94.451
rouge2     | fm: 68.034 | p: 67.853 | r: 68.210
rougeL     | fm: 83.261 | p: 83.048 | r: 83.583
rougeLsum  | fm: 82.888 | p: 82.591 | r: 83.270
r1fm+r2fm = 162.069

input #30 time: 0:12:13 | total time: 6:21:44


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.9993400085746087
highest_index [0]
highest [0.9993400085746087]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.9406495690345764 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.9194327592849731 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8828387260437012 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.8682344555854797 for ['[CLS] billiel arms [SEP]']
[Init] best rec loss: 0.8049277067184448 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 0.8001369833946228 for ['[CLS] robin artwork running [SEP]']
[Init] best perm rec loss: 0.798110842704773 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.232 (perp=9.658, rec=0.269, cos=0.031), tot_loss_proj:2.398 [t=0.30s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 100/2000] tot_loss=2.112 (perp=9.658, rec=0.165, cos=0.015), tot_loss_proj:2.408 [t=0.31s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=2.089 (perp=9.658, rec=0.142, cos=0.015), tot_loss_proj:2.403 [t=0.31s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 200/2000] tot_loss=2.089 (perp=9.658, rec=0.140, cos=0.018), tot_loss_proj:2.407 [t=0.31s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.078 (perp=9.658, rec=0.134, cos=0.013), tot_loss_proj:2.408 [t=0.31s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 300/2000] tot_loss=2.066 (perp=9.658, rec=0.123, cos=0.012), tot_loss_proj:2.412 [t=0.31s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.447 (perp=11.364, rec=0.153, cos=0.021), tot_loss_proj:3.198 [t=0.31s]
prediction: ['[CLS] better ernie vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.195 (perp=10.165, rec=0.143, cos=0.019), tot_loss_proj:2.738 [t=0.31s]
prediction: ['[CLS] better instrument vehicle [SEP]']
[ 450/2000] tot_loss=2.175 (perp=10.165, rec=0.125, cos=0.017), tot_loss_proj:2.738 [t=0.31s]
prediction: ['[CLS] better instrument vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.026 (perp=9.431, rec=0.124, cos=0.016), tot_loss_proj:3.427 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.030 (perp=9.431, rec=0.126, cos=0.017), tot_loss_proj:3.428 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
[ 600/2000] tot_loss=2.044 (perp=9.431, rec=0.142, cos=0.016), tot_loss_proj:3.421 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.036 (perp=9.431, rec=0.134, cos=0.016), tot_loss_proj:3.426 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.029 (perp=9.431, rec=0.127, cos=0.016), tot_loss_proj:3.424 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
[ 750/2000] tot_loss=2.023 (perp=9.431, rec=0.122, cos=0.016), tot_loss_proj:3.429 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.025 (perp=9.431, rec=0.124, cos=0.016), tot_loss_proj:3.424 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.031 (perp=9.431, rec=0.129, cos=0.015), tot_loss_proj:3.429 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
[ 900/2000] tot_loss=2.020 (perp=9.431, rec=0.118, cos=0.015), tot_loss_proj:3.423 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.026 (perp=9.431, rec=0.124, cos=0.015), tot_loss_proj:3.419 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=2.037 (perp=9.431, rec=0.136, cos=0.015), tot_loss_proj:3.424 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
[1050/2000] tot_loss=2.034 (perp=9.431, rec=0.133, cos=0.015), tot_loss_proj:3.420 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=2.029 (perp=9.431, rec=0.128, cos=0.015), tot_loss_proj:3.430 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=2.022 (perp=9.431, rec=0.121, cos=0.015), tot_loss_proj:3.418 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
[1200/2000] tot_loss=1.886 (perp=8.742, rec=0.123, cos=0.015), tot_loss_proj:3.270 [t=0.31s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.884 (perp=8.742, rec=0.121, cos=0.015), tot_loss_proj:3.269 [t=0.31s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.208 (perp=10.254, rec=0.139, cos=0.018), tot_loss_proj:3.726 [t=0.31s]
prediction: ['[CLS] short better vehicle [SEP]']
[1350/2000] tot_loss=2.197 (perp=10.254, rec=0.129, cos=0.017), tot_loss_proj:3.739 [t=0.31s]
prediction: ['[CLS] short better vehicle [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.028 (perp=9.431, rec=0.126, cos=0.015), tot_loss_proj:3.420 [t=0.31s]
prediction: ['[CLS] better short vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.887 (perp=8.742, rec=0.124, cos=0.015), tot_loss_proj:3.264 [t=0.31s]
prediction: ['[CLS] better a vehicle [SEP]']
[1500/2000] tot_loss=1.877 (perp=8.742, rec=0.114, cos=0.015), tot_loss_proj:3.271 [t=0.31s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.666 (perp=7.603, rec=0.131, cos=0.015), tot_loss_proj:1.642 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.667 (perp=7.603, rec=0.131, cos=0.015), tot_loss_proj:1.646 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.645 (perp=7.603, rec=0.110, cos=0.015), tot_loss_proj:1.641 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.659 (perp=7.603, rec=0.124, cos=0.015), tot_loss_proj:1.643 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.665 (perp=7.603, rec=0.130, cos=0.015), tot_loss_proj:1.643 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.668 (perp=7.603, rec=0.132, cos=0.015), tot_loss_proj:1.648 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.661 (perp=7.603, rec=0.126, cos=0.015), tot_loss_proj:1.645 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.653 (perp=7.603, rec=0.117, cos=0.015), tot_loss_proj:1.639 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.667 (perp=7.603, rec=0.131, cos=0.015), tot_loss_proj:1.636 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.667 (perp=7.603, rec=0.131, cos=0.015), tot_loss_proj:1.637 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.270 | p: 93.881 | r: 94.667
rouge2     | fm: 69.358 | p: 69.150 | r: 69.567
rougeL     | fm: 83.740 | p: 83.504 | r: 84.093
rougeLsum  | fm: 83.480 | p: 83.191 | r: 83.801
r1fm+r2fm = 163.628

input #31 time: 0:12:13 | total time: 6:33:58


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9992511319232864
highest_index [0]
highest [0.9992511319232864]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.0387706756591797 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9487353563308716 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 0.8907210826873779 for ['[CLS] ring tracks peculiarzingplay de robinson lay iv elders experience wing [SEP]']
[Init] best rec loss: 0.8816460371017456 for ['[CLS] shot scale nest benefit jenny aspen introduced everything zoe arrival capital theory [SEP]']
[Init] best rec loss: 0.8787041306495667 for ['[CLS] spiders armenian dreams¨ me riff clearly space cyprus center ᵍ glory [SEP]']
[Init] best rec loss: 0.8620191812515259 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.8500081300735474 for ['[CLS]ono harlem auckland hanna organization rex force riot back decker mud tune [SEP]']
[Init] best rec loss: 0.843980610370636 for ['[CLS] palaceshire athletic th funds lilith bio circlecting thomas cake natalie [SEP]']
[Init] best perm rec loss: 0.8435036540031433 for ['[CLS] funds cake palacecting th athletic lilith natalieshire thomas bio circle [SEP]']
[Init] best perm rec loss: 0.8420174717903137 for ['[CLS]cting lilith bio circle cake funds athletic palace natalie thomasshire th [SEP]']
[Init] best perm rec loss: 0.8417584896087646 for ['[CLS] palace th thomas nataliecting athletic lilith cake bio circle fundsshire [SEP]']
[Init] best perm rec loss: 0.8409503698348999 for ['[CLS] thomas th funds lilith circle bioshire athletic cake palace nataliecting [SEP]']
[Init] best perm rec loss: 0.8401926159858704 for ['[CLS] circle bio lilith funds athletic th thomascting natalie palaceshire cake [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.095 (perp=13.985, rec=0.290, cos=0.008), tot_loss_proj:4.391 [t=0.31s]
prediction: ['[CLS] poly story tightly language deep extant creations norman frank everywhere grip size [SEP]']
[ 100/2000] tot_loss=3.032 (perp=14.051, rec=0.218, cos=0.003), tot_loss_proj:4.225 [t=0.31s]
prediction: ['[CLS] directly stories accessibleonate easily accessibleonate christopher deeperonate pull david [SEP]']
[ 150/2000] tot_loss=3.029 (perp=14.262, rec=0.174, cos=0.003), tot_loss_proj:4.559 [t=0.31s]
prediction: ['[CLS] directly stories accessibleonate easily accessibleonate christopher wesleyonate pull size [SEP]']
[ 200/2000] tot_loss=2.938 (perp=13.840, rec=0.167, cos=0.002), tot_loss_proj:4.129 [t=0.31s]
prediction: ['[CLS] considerably stories easilyonate easily accessibleonate christopher carlonate pull size [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.102 (perp=14.839, rec=0.131, cos=0.003), tot_loss_proj:4.054 [t=0.31s]
prediction: ['[CLS]und stories togetheronate easily accessible res size profonate pull christopher [SEP]']
[ 300/2000] tot_loss=2.951 (perp=14.070, rec=0.135, cos=0.002), tot_loss_proj:3.939 [t=0.31s]
prediction: ['[CLS]und stories together res easily accessible res size profonate pull christopher [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.574 (perp=12.240, rec=0.124, cos=0.002), tot_loss_proj:3.117 [t=0.31s]
prediction: ['[CLS]onate stories together res easily accessibleityu profund pull christopher [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.420 (perp=11.528, rec=0.113, cos=0.002), tot_loss_proj:2.928 [t=0.31s]
prediction: ['[CLS] stories together resonate easily accessibleity sydney profund pull christopher [SEP]']
[ 450/2000] tot_loss=2.362 (perp=11.295, rec=0.101, cos=0.002), tot_loss_proj:2.734 [t=0.31s]
prediction: ['[CLS] stories together resonate easily accessibleity direct profund pull christopher [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.296 (perp=10.923, rec=0.109, cos=0.002), tot_loss_proj:2.876 [t=0.31s]
prediction: ['[CLS] stories together resonate easily accessible lewis carlundity pull christopher [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.208 (perp=10.535, rec=0.100, cos=0.002), tot_loss_proj:2.820 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible lewis carlundity pull christopher [SEP]']
[ 600/2000] tot_loss=2.288 (perp=10.923, rec=0.101, cos=0.002), tot_loss_proj:3.451 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible tack carlundity pulliable [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.251 (perp=10.758, rec=0.098, cos=0.002), tot_loss_proj:3.237 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible pull carlundity lewisiable [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.976 (perp=9.345, rec=0.105, cos=0.002), tot_loss_proj:2.602 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible lewis ruby pull profundity [SEP]']
[ 750/2000] tot_loss=2.033 (perp=9.682, rec=0.095, cos=0.002), tot_loss_proj:2.961 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible specifically ruby pull profundity [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.976 (perp=9.419, rec=0.090, cos=0.002), tot_loss_proj:3.034 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible ruby specifically pull profundity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.980 (perp=9.419, rec=0.095, cos=0.002), tot_loss_proj:3.033 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible ruby specifically pull profundity [SEP]']
[ 900/2000] tot_loss=1.981 (perp=9.419, rec=0.096, cos=0.002), tot_loss_proj:3.037 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible ruby specifically pull profundity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.976 (perp=9.419, rec=0.090, cos=0.002), tot_loss_proj:3.031 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible ruby specifically pull profundity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.984 (perp=9.419, rec=0.098, cos=0.002), tot_loss_proj:3.038 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible ruby specifically pull profundity [SEP]']
[1050/2000] tot_loss=1.973 (perp=9.419, rec=0.088, cos=0.002), tot_loss_proj:3.037 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible ruby specifically pull profundity [SEP]']
Attempt swap
[1100/2000] tot_loss=2.022 (perp=9.663, rec=0.088, cos=0.002), tot_loss_proj:2.867 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible tell specifically pull profundity [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.931 (perp=9.207, rec=0.088, cos=0.002), tot_loss_proj:2.898 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible specifically tell pull profundity [SEP]']
[1200/2000] tot_loss=2.084 (perp=9.927, rec=0.097, cos=0.002), tot_loss_proj:3.055 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible disc fe pull profundity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.077 (perp=9.927, rec=0.090, cos=0.002), tot_loss_proj:3.057 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible disc fe pull profundity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.074 (perp=9.927, rec=0.087, cos=0.002), tot_loss_proj:3.049 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible disc fe pull profundity [SEP]']
[1350/2000] tot_loss=2.065 (perp=9.927, rec=0.078, cos=0.002), tot_loss_proj:3.047 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible disc fe pull profundity [SEP]']
Attempt swap
[1400/2000] tot_loss=2.071 (perp=9.927, rec=0.084, cos=0.002), tot_loss_proj:3.054 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible disc fe pull profundity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.079 (perp=9.927, rec=0.092, cos=0.002), tot_loss_proj:3.054 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible disc fe pull profundity [SEP]']
[1500/2000] tot_loss=2.070 (perp=9.927, rec=0.083, cos=0.002), tot_loss_proj:3.054 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible disc fe pull profundity [SEP]']
Attempt swap
[1550/2000] tot_loss=2.109 (perp=10.120, rec=0.083, cos=0.002), tot_loss_proj:2.941 [t=0.31s]
prediction: ['[CLS] together stories resonate easily accessible prof fe pull profundity [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.961 (perp=9.359, rec=0.087, cos=0.002), tot_loss_proj:3.078 [t=0.31s]
prediction: ['[CLS] together stories resonate easily fe accessible prof pull profundity [SEP]']
[1650/2000] tot_loss=1.971 (perp=9.359, rec=0.098, cos=0.002), tot_loss_proj:3.085 [t=0.31s]
prediction: ['[CLS] together stories resonate easily fe accessible prof pull profundity [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.950 (perp=9.323, rec=0.084, cos=0.002), tot_loss_proj:2.887 [t=0.31s]
prediction: ['[CLS] together stories resonate fe easily accessible prof pull profundity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.956 (perp=9.323, rec=0.089, cos=0.002), tot_loss_proj:2.886 [t=0.31s]
prediction: ['[CLS] together stories resonate fe easily accessible prof pull profundity [SEP]']
[1800/2000] tot_loss=1.955 (perp=9.323, rec=0.089, cos=0.002), tot_loss_proj:2.894 [t=0.31s]
prediction: ['[CLS] together stories resonate fe easily accessible prof pull profundity [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.924 (perp=9.157, rec=0.091, cos=0.002), tot_loss_proj:2.772 [t=0.31s]
prediction: ['[CLS] fe stories resonate together easily accessible prof pull profundity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.915 (perp=9.157, rec=0.082, cos=0.002), tot_loss_proj:2.768 [t=0.31s]
prediction: ['[CLS] fe stories resonate together easily accessible prof pull profundity [SEP]']
[1950/2000] tot_loss=1.913 (perp=9.157, rec=0.080, cos=0.002), tot_loss_proj:2.777 [t=0.31s]
prediction: ['[CLS] fe stories resonate together easily accessible prof pull profundity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.860 (perp=8.822, rec=0.094, cos=0.002), tot_loss_proj:2.733 [t=0.31s]
prediction: ['[CLS] tell stories resonate together easily accessible prof pull profundity [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] together stories resonate easily accessible disc fe pull profundity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 101.818

[Aggregate metrics]:
rouge1     | fm: 93.834 | p: 93.496 | r: 94.226
rouge2     | fm: 67.780 | p: 67.535 | r: 68.004
rougeL     | fm: 82.747 | p: 82.490 | r: 83.132
rougeLsum  | fm: 82.638 | p: 82.415 | r: 82.986
r1fm+r2fm = 161.613

input #32 time: 0:12:15 | total time: 6:46:13


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9992765189275159
highest_index [0]
highest [0.9992765189275159]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9984626770019531 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9773549437522888 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.9556460976600647 for ['[CLS] parent [SEP]']
[Init] best rec loss: 0.8989892601966858 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8216384649276733 for ['[CLS] attributed [SEP]']
[Init] best rec loss: 0.7959935665130615 for ['[CLS] showing [SEP]']
[Init] best rec loss: 0.7898187041282654 for ['[CLS] manifold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.400 (perp=11.231, rec=0.146, cos=0.008), tot_loss_proj:3.008 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.329 (perp=11.231, rec=0.081, cos=0.002), tot_loss_proj:2.391 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.321 (perp=11.231, rec=0.073, cos=0.001), tot_loss_proj:2.406 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.310 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.418 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.306 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.395 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.402 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.396 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.409 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.304 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.384 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.397 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.302 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.399 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.297 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.384 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.311 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.409 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.401 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.314 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.401 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.385 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.302 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.391 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.386 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.311 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.413 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.302 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.400 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.303 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.391 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.299 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.392 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.312 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.399 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.295 (perp=11.231, rec=0.047, cos=0.001), tot_loss_proj:2.393 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.299 (perp=11.231, rec=0.051, cos=0.001), tot_loss_proj:2.399 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.302 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.400 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.312 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.398 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.298 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.398 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.305 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.414 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.309 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.398 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.409 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.389 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.400 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.311 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.391 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.398 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.301 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.386 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.310 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.394 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.299 (perp=11.231, rec=0.051, cos=0.001), tot_loss_proj:2.409 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.300 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.397 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.301 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.403 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.038 | p: 93.692 | r: 94.414
rouge2     | fm: 68.679 | p: 68.504 | r: 68.887
rougeL     | fm: 83.368 | p: 83.149 | r: 83.699
rougeLsum  | fm: 83.174 | p: 82.887 | r: 83.494
r1fm+r2fm = 162.717

input #33 time: 0:11:10 | total time: 6:57:24


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.9992100959115224
highest_index [0]
highest [0.9992100959115224]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.896594226360321 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8880690336227417 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8427761793136597 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.8107948899269104 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.8099932670593262 for ['[CLS]ibe lissa founder statue slight alongask who drivers okay worth ship field [SEP]']
[Init] best perm rec loss: 0.8097754716873169 for ['[CLS] worth drivers okay lissa fieldask founder along statue ship slight whoibe [SEP]']
[Init] best perm rec loss: 0.8087636232376099 for ['[CLS] worth statue slight field founder lissa okayibeask ship along drivers who [SEP]']
[Init] best perm rec loss: 0.8077437281608582 for ['[CLS] okayibe slight along whoask ship drivers founder worth field statue lissa [SEP]']
[Init] best perm rec loss: 0.8071714639663696 for ['[CLS] lissaibe worth okay ship who drivers statue field along founder slightask [SEP]']
[Init] best perm rec loss: 0.8058276772499084 for ['[CLS]ibe who drivers slight along lissa founder statue worth field ship okayask [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.032 (perp=13.368, rec=0.337, cos=0.022), tot_loss_proj:4.393 [t=0.31s]
prediction: ['[CLS] subcommittee powerful extreme urgency joseph. urgency fred urgencyess urgency vice frantic [SEP]']
[ 100/2000] tot_loss=2.525 (perp=11.441, rec=0.229, cos=0.008), tot_loss_proj:3.868 [t=0.31s]
prediction: ['[CLS] build extreme extreme urgency. viewer urgency the urgency eye urgency violent viewer [SEP]']
[ 150/2000] tot_loss=1.979 (perp=8.903, rec=0.186, cos=0.013), tot_loss_proj:3.416 [t=0.31s]
prediction: ['[CLS] take on extreme urgency. viewer urgency the urgency and build violent viewer [SEP]']
[ 200/2000] tot_loss=1.966 (perp=9.094, rec=0.143, cos=0.004), tot_loss_proj:3.617 [t=0.31s]
prediction: ['[CLS] take on extreme urgency. viewer urgency the urgency and build adverse viewer [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.991 (perp=9.207, rec=0.146, cos=0.004), tot_loss_proj:2.903 [t=0.31s]
prediction: ['[CLS] take on viewer urgency. viewer urgency the in and build hemisphere extreme [SEP]']
[ 300/2000] tot_loss=1.956 (perp=9.196, rec=0.113, cos=0.004), tot_loss_proj:2.782 [t=0.31s]
prediction: ['[CLS] take on viewer urgency. viewer mind the in the build hemisphere extreme [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.718 (perp=8.099, rec=0.095, cos=0.003), tot_loss_proj:2.317 [t=0.31s]
prediction: ['[CLS] take on viewer urgency. the mind viewer in the build the extreme [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.587 (perp=7.381, rec=0.106, cos=0.004), tot_loss_proj:2.387 [t=0.31s]
prediction: ['[CLS] take on viewer urgency. the viewer in the mind build of extreme [SEP]']
[ 450/2000] tot_loss=1.574 (perp=7.384, rec=0.094, cos=0.003), tot_loss_proj:2.442 [t=0.31s]
prediction: ['[CLS] take on viewer urgency and the viewer in the mind build of extreme [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.520 (perp=7.138, rec=0.090, cos=0.003), tot_loss_proj:2.329 [t=0.31s]
prediction: ['[CLS] take on viewer urgency in the viewer and the mind build of extreme [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.516 (perp=7.138, rec=0.085, cos=0.003), tot_loss_proj:2.331 [t=0.31s]
prediction: ['[CLS] take on viewer urgency in the viewer and the mind build of extreme [SEP]']
[ 600/2000] tot_loss=1.642 (perp=7.801, rec=0.079, cos=0.003), tot_loss_proj:2.432 [t=0.31s]
prediction: ['[CLS] take on viewer urgency in the viewer and the mind build mind extreme [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.657 (perp=7.824, rec=0.089, cos=0.003), tot_loss_proj:2.495 [t=0.31s]
prediction: ['[CLS] take on viewer urgency in the viewer and build mind the without extreme [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.534 (perp=7.195, rec=0.093, cos=0.003), tot_loss_proj:2.133 [t=0.31s]
prediction: ['[CLS] take on. urgency in the viewer and build mind without the extreme [SEP]']
[ 750/2000] tot_loss=1.529 (perp=7.195, rec=0.087, cos=0.002), tot_loss_proj:2.140 [t=0.31s]
prediction: ['[CLS] take on. urgency in the viewer and build mind without the extreme [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.634 (perp=7.699, rec=0.092, cos=0.003), tot_loss_proj:2.349 [t=0.31s]
prediction: ['[CLS] take on urgency in the viewer and build mind hemisphere the extreme. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.346 (perp=6.320, rec=0.080, cos=0.002), tot_loss_proj:2.846 [t=0.31s]
prediction: ['[CLS] take without urgency in the viewer and build mind on the extreme. [SEP]']
[ 900/2000] tot_loss=1.351 (perp=6.320, rec=0.085, cos=0.002), tot_loss_proj:2.844 [t=0.31s]
prediction: ['[CLS] take without urgency in the viewer and build mind on the extreme. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.275 (perp=5.902, rec=0.092, cos=0.002), tot_loss_proj:2.840 [t=0.31s]
prediction: ['[CLS] without urgency take in the viewer and build mind on the extreme. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.261 (perp=5.902, rec=0.080, cos=0.002), tot_loss_proj:2.842 [t=0.31s]
prediction: ['[CLS] without urgency take in the viewer and build mind on the extreme. [SEP]']
[1050/2000] tot_loss=1.267 (perp=5.902, rec=0.085, cos=0.002), tot_loss_proj:2.842 [t=0.31s]
prediction: ['[CLS] without urgency take in the viewer and build mind on the extreme. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.219 (perp=5.698, rec=0.078, cos=0.001), tot_loss_proj:2.558 [t=0.31s]
prediction: ['[CLS] without urgency take the viewer in and build mind on the extreme. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.314 (perp=6.217, rec=0.069, cos=0.002), tot_loss_proj:1.856 [t=0.31s]
prediction: ['[CLS] mind urgency take the viewer and build in mind on the extreme. [SEP]']
[1200/2000] tot_loss=1.238 (perp=5.864, rec=0.063, cos=0.002), tot_loss_proj:1.688 [t=0.31s]
prediction: ['[CLS] of urgency take the viewer and build in mind on the extreme. [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.226 (perp=5.725, rec=0.079, cos=0.002), tot_loss_proj:1.910 [t=0.31s]
prediction: ['[CLS] mind urgency in mind take the viewer and build on the extreme. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.178 (perp=5.506, rec=0.075, cos=0.002), tot_loss_proj:1.554 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
[1350/2000] tot_loss=1.184 (perp=5.506, rec=0.081, cos=0.002), tot_loss_proj:1.547 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.181 (perp=5.506, rec=0.078, cos=0.002), tot_loss_proj:1.549 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.186 (perp=5.506, rec=0.083, cos=0.002), tot_loss_proj:1.547 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
[1500/2000] tot_loss=1.182 (perp=5.506, rec=0.079, cos=0.002), tot_loss_proj:1.546 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.177 (perp=5.506, rec=0.074, cos=0.002), tot_loss_proj:1.545 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.177 (perp=5.506, rec=0.074, cos=0.002), tot_loss_proj:1.547 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
[1650/2000] tot_loss=1.175 (perp=5.506, rec=0.072, cos=0.002), tot_loss_proj:1.548 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.169 (perp=5.506, rec=0.066, cos=0.002), tot_loss_proj:1.551 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.192 (perp=5.506, rec=0.089, cos=0.002), tot_loss_proj:1.544 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
[1800/2000] tot_loss=1.185 (perp=5.506, rec=0.082, cos=0.002), tot_loss_proj:1.552 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.173 (perp=5.506, rec=0.070, cos=0.002), tot_loss_proj:1.548 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.176 (perp=5.506, rec=0.074, cos=0.002), tot_loss_proj:1.543 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
[1950/2000] tot_loss=1.167 (perp=5.506, rec=0.064, cos=0.002), tot_loss_proj:1.547 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.176 (perp=5.506, rec=0.073, cos=0.002), tot_loss_proj:1.548 [t=0.31s]
prediction: ['[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] extreme urgency in mind take the viewer and build on the mind. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.857 | p: 92.857 | r: 92.857
rouge2     | fm: 30.769 | p: 30.769 | r: 30.769
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 123.626

[Aggregate metrics]:
rouge1     | fm: 94.092 | p: 93.735 | r: 94.405
rouge2     | fm: 67.491 | p: 67.334 | r: 67.703
rougeL     | fm: 82.572 | p: 82.338 | r: 82.853
rougeLsum  | fm: 82.406 | p: 82.139 | r: 82.626
r1fm+r2fm = 161.583

input #34 time: 0:12:16 | total time: 7:09:41


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9993271536360728
highest_index [0]
highest [0.9993271536360728]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.923815906047821 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.916949987411499 for ['[CLS] thousand lack alternative energy fae deservevil denied field outside pages province beauty fade actsar dynamic sole one organized folk ms primary appointment devicedran part zion nightmaresdrive isabellaght intervals singer published sleeper signs lynch, somehow position flow [SEP]']
[Init] best perm rec loss: 0.9153326749801636 for ['[CLS], part isabella published lynch one denied folk sleeper beautyght ms nightmares energy province actdrive zionvil appointment fade thousand singer deservesar pages signs somehow intervals dynamic alternative primary sole device flow fae lack field position organizeddran outside [SEP]']
[Init] best perm rec loss: 0.9152690172195435 for ['[CLS] sleeper, flow intervals isabella appointmentdran singer publishedvil deserve province zionsar outside position act dynamic organized part sole beauty folk fae device primary nightmares alternative lack lynch signs field somehowght ms denied thousand fade energy pages onedrive [SEP]']
[Init] best perm rec loss: 0.9146609902381897 for ['[CLS] dynamic folk act outside somehow primary nightmaresght one pages appointment ms organized published sole provincevildran fae sleeper lack zion deserve denied field intervals beauty energy alternative isabelladrive singer thousandsar device, position part lynch flow fade signs [SEP]']
[Init] best perm rec loss: 0.9145088195800781 for ['[CLS] device appointment part field zion intervals dynamic lynch energy ms signs pages published flow alternative act one, somehow isabella folk sleeperght organized lackdrive thousand singer sole denied nightmares beauty faesardran primary outside deservevil position fade province [SEP]']
[Init] best perm rec loss: 0.9138181209564209 for ['[CLS] pages field folk fade somehow appointment province published part isabella thousanddriveght device flowsar signs beauty singer outside energyvil sleeper dynamic intervals,dran organized ms lack sole denied position nightmares alternative primary act deserve fae zion lynch one [SEP]']
[Init] best perm rec loss: 0.9138004779815674 for ['[CLS] fae ms act deserve nightmares zion position isabella fadedrive pages sole flowdran energy lack somehow part province signs device intervals lynchvil field denied organized primarysar appointment beauty folk published singer, one dynamic alternative thousandght sleeper outside [SEP]']
[Init] best perm rec loss: 0.9132813215255737 for ['[CLS] ms fae zion part signs field sleeper somehow flow thousand device fade outside alternativedrive denied nightmares lack provincevil sole dynamic primary published one appointment deserve intervals, lynch isabella singer beauty energysar act position organized pagesghtdran folk [SEP]']
[Init] best perm rec loss: 0.9127830862998962 for ['[CLS] primarydran outside pagesvil sole flow thousand act singer sleeper province position fade nightmares alternative fae lynch field organized signs part somehow ms intervals device energy lack beauty one isabella zion denied, deservedriveght folk published appointment dynamicsar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.770 (perp=12.008, rec=0.356, cos=0.012), tot_loss_proj:3.727 [t=0.32s]
prediction: ["[CLS] years capital previous about from she vision conducted city ( deeply... powerful association beautiful of from eastern western, william handful we pretty aback existingco this attention sun. series amazing, watershed hasn nearest 'ace stevie personal value [SEP]"]
[ 100/2000] tot_loss=2.397 (perp=10.609, rec=0.271, cos=0.004), tot_loss_proj:3.721 [t=0.32s]
prediction: ["[CLS] we union before patients before s we'''we we strong oldies excellent of from'and, michael those we but help stainless having % attention hoffman. henry [SEP], has nearest nearest. caresible great about [SEP]"]
[ 150/2000] tot_loss=2.352 (perp=10.637, rec=0.220, cos=0.005), tot_loss_proj:4.128 [t=0.32s]
prediction: ["[CLS] they union seenating before seen'''' we we makes latest teacher of ve'and ve michael civilian we but help placed having sequel staff hoffman. rein ve, we assigned '. carenation seen about [SEP]"]
[ 200/2000] tot_loss=2.487 (perp=10.983, rec=0.283, cos=0.008), tot_loss_proj:4.105 [t=0.32s]
prediction: ["[CLS] feast union seen lifestyle before seen'''seen us we makes latest teacher of ve'and ve kevin nationalbe but helpnation glory sequel staff hoffman the rein ve, wenation '. carenation seen about [SEP]"]
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.296 (perp=10.417, rec=0.209, cos=0.004), tot_loss_proj:3.808 [t=0.32s]
prediction: ["[CLS] feast union seennation before seen ve'greatest's us we makes latest of in'bela ve michael quick'but help [SEP] greatest this staff hoffman the rein ve,'teacher '. carenation seen really [SEP]"]
[ 300/2000] tot_loss=2.390 (perp=10.425, rec=0.296, cos=0.009), tot_loss_proj:3.619 [t=0.32s]
prediction: ["[CLS] feast total seennation before have ve'greatest's us we makes latest of in'emotion ve michael cousin'but help [SEP] greatest this staff hoffman the rein ve,'rein ', carenation seen really [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.297 (perp=9.753, rec=0.337, cos=0.009), tot_loss_proj:3.377 [t=0.32s]
prediction: ["[CLS] seasons simply potential upcoming before in ve'greatest's us we makes fame of of'+ helpful. hoffman'but help for greatest this staff quick the director experiencing,'rein. the careciful seen really [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.117 (perp=9.428, rec=0.228, cos=0.003), tot_loss_proj:3.230 [t=0.32s]
prediction: ["[CLS] powerful simply recently newest before have ve'greatest's us we makes teacher of of non < seasons. hoffman'but help about eternal this help has the director experiencing, 'nation. the careciful seen of [SEP]"]
[ 450/2000] tot_loss=2.158 (perp=9.476, rec=0.258, cos=0.005), tot_loss_proj:3.462 [t=0.32s]
prediction: ["[CLS] mainly simply interest newest before s ve'greatest's us we makes teacher events of when forests anywhere. hoffman'but help about eternal this help has the director experiencing, 'nation. the careciful seen of [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.992 (perp=8.940, rec=0.200, cos=0.004), tot_loss_proj:3.287 [t=0.32s]
prediction: ["[CLS] mainly simply interest newest before s ve'greatest's when we makes teacher of of us or₁. hoffman'but help about sometimes the help has the director experiencing, 'nation. the careciful seen of [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.213 (perp=9.891, rec=0.229, cos=0.006), tot_loss_proj:3.643 [t=0.32s]
prediction: ["[CLS]orous'release newest before s ve'greatest's it we makes teacher part of us plainromatic. hoffman'about help but monroe the help has this rein experiencing, 'nation. the careciful seen about [SEP]"]
[ 600/2000] tot_loss=2.099 (perp=9.566, rec=0.182, cos=0.004), tot_loss_proj:3.433 [t=0.32s]
prediction: ["[CLS] excellent'sudden latest before s ve'greatest's it we makes teacher of of us plainreate.nberger'about help but monroe the help of this rein experiencing, 'nation. the careciful seen about [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.045 (perp=8.879, rec=0.257, cos=0.012), tot_loss_proj:3.647 [t=0.32s]
prediction: ["[CLS] good. interest amazon before s ve'greatest's help we makes teacher.. us.reate.lized '. it but ; city help world the rein.,'rein. the care before seen about [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.890 (perp=8.383, rec=0.207, cos=0.006), tot_loss_proj:3.362 [t=0.32s]
prediction: ["[CLS] good. interest newest before ve ve'greatest's help we makes teacher.. us.reate. hoffman '.. but ; city before world the rein.,'rein. the care help seen we [SEP]"]
[ 750/2000] tot_loss=1.887 (perp=8.513, rec=0.180, cos=0.004), tot_loss_proj:3.370 [t=0.32s]
prediction: ["[CLS] good'upcoming newest before ve ve'greatest's help we makes teacher.. us.reate. hoffman '.. but ; the before world the rein.,'rein. the care help seen about [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.876 (perp=8.392, rec=0.194, cos=0.004), tot_loss_proj:3.161 [t=0.32s]
prediction: ["[CLS] before. sudden newest good s ve'greatest's help we makes teacher.. us ;romatic. hoffman '. and but ; the before world the rein.,'rein. the care help seen about [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.878 (perp=8.502, rec=0.174, cos=0.004), tot_loss_proj:3.163 [t=0.32s]
prediction: ["[CLS] before. sudden newest good ve ve'greatest's help we seen teacher.. us ;romatic. hoffman '. and but. the at world the rein.,'rein. the care help makes about [SEP]"]
[ 900/2000] tot_loss=1.791 (perp=8.073, rec=0.173, cos=0.003), tot_loss_proj:3.087 [t=0.32s]
prediction: ["[CLS] before'sudden newest good ve ve'greatest's help we seen teacher.. us ;romatic. hoffman '. and but. the at world the rein.,'rein. the care help makes about [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.683 (perp=7.582, rec=0.164, cos=0.003), tot_loss_proj:2.878 [t=0.32s]
prediction: ["[CLS] before'latest newest good, ve'greatest's help we seen teacher ve of us ;romatic. hoffman '.'but. the at world the rein.,'rein. the care help makes about [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.697 (perp=7.647, rec=0.165, cos=0.003), tot_loss_proj:2.931 [t=0.32s]
prediction: ["[CLS] before'latest newest good, ve'greatest's help we seen teacher ve of us ;romatic. prague '.'but. the about world thisnation.,'rein. the care help makes at [SEP]"]
[1050/2000] tot_loss=1.679 (perp=7.583, rec=0.160, cos=0.003), tot_loss_proj:2.887 [t=0.32s]
prediction: ["[CLS] before'latest newest good, ve'greatest's help we seen teacher ve of us ;romatic. hoffman '.'but. the about world thisnation in,'rein. the care help makes at [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.679 (perp=7.610, rec=0.154, cos=0.003), tot_loss_proj:2.937 [t=0.32s]
prediction: ["[CLS] before'latest newest good, ve'greatest's help we seen teacher ve of us ;romatic. hoffman '.'but. this world about thisnation in,'rein. the care help makes at [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.635 (perp=7.355, rec=0.161, cos=0.004), tot_loss_proj:2.822 [t=0.32s]
prediction: ["[CLS] before'latest newest good, ve'greatest's help we seen teacher ve of us ;romatic. hoffman '.'but at this world about thisnation in,'rein. the care help makes. [SEP]"]
[1200/2000] tot_loss=1.668 (perp=7.586, rec=0.148, cos=0.003), tot_loss_proj:2.897 [t=0.32s]
prediction: ["[CLS] before'latest newest good, ve'greatest's help we seen teacher ve of us ;romatic. hoffman '. their but at this world about thisnation in,'rein. the care help makes. [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.641 (perp=7.441, rec=0.150, cos=0.003), tot_loss_proj:2.893 [t=0.32s]
prediction: ["[CLS] before'latest latest great, ve'greatest's help we seen teacher ve of us ;romatic. hoffman'of their but, this world about. thisnation,'rein. the care help makes. [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.629 (perp=7.412, rec=0.144, cos=0.003), tot_loss_proj:2.844 [t=0.32s]
prediction: ["[CLS] before'latest latest great, ve'greatest's help we seen teacher ve of us ;romatic. hoffman'of their but, this world about this.nation,'rein. the care help makes. [SEP]"]
[1350/2000] tot_loss=1.683 (perp=7.691, rec=0.142, cos=0.003), tot_loss_proj:2.814 [t=0.32s]
prediction: ["[CLS] before'latest latest great, ve'greatest's help we seen teacher ve of us ;romatic director hoffman'of while but, this world about this.nation,'rein. the care help makes. [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.648 (perp=7.506, rec=0.145, cos=0.003), tot_loss_proj:2.631 [t=0.32s]
prediction: ["[CLS] before'recent latest ', ve'greatest's help we seen teacher ve of us ;romatic director hoffman'of while but, this world about this.nation, great rein. the care help makes. [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.622 (perp=7.348, rec=0.150, cos=0.003), tot_loss_proj:2.640 [t=0.32s]
prediction: ["[CLS] before'recent latest ', ve'greatest's help we seen teacher ve of us ;romatic director hoffman'of, but their this world about this.nation, great rein. the care help makes. [SEP]"]
[1500/2000] tot_loss=1.689 (perp=7.694, rec=0.148, cos=0.003), tot_loss_proj:2.739 [t=0.33s]
prediction: ["[CLS] before an recent latest ', ve'greatest's help we seen teacher ve of us ;romatic director hoffman'of, but when this world about this.nation, great rein. the care help makes. [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.681 (perp=7.677, rec=0.143, cos=0.003), tot_loss_proj:2.740 [t=0.32s]
prediction: ["[CLS] before an recent latest ', ve'greatest's help we seen teacher ve of us orromatic director hoffman'of, but when this world about this.nation, great rein. the care help makes. [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.648 (perp=7.502, rec=0.145, cos=0.002), tot_loss_proj:2.660 [t=0.32s]
prediction: ["[CLS] before an recent latest ', ve'greatest'of help we seen teacher ve of us orromatic director hoffman's, but when this world about this.nation, great rein. the care help makes. [SEP]"]
[1650/2000] tot_loss=1.648 (perp=7.511, rec=0.144, cos=0.002), tot_loss_proj:2.738 [t=0.32s]
prediction: ["[CLS] before an recent latest ', ve'greatest'of help we seen teacher ve of us orromatic director hoffman's, but when this world about this.nation, great rein. the care director makes. [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.647 (perp=7.494, rec=0.145, cos=0.002), tot_loss_proj:2.755 [t=0.32s]
prediction: ["[CLS] before all recent latest ', ve'greatest'of help we seen teacher ve of us orromatic hoffman director's, but when this world about this.nation, great rein. the care director makes. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.637 (perp=7.494, rec=0.136, cos=0.002), tot_loss_proj:2.763 [t=0.32s]
prediction: ["[CLS] before all recent latest ', ve'greatest'of help we seen teacher ve of us orromatic hoffman director's, but when this world about this.nation, great rein. the care director makes. [SEP]"]
[1800/2000] tot_loss=1.644 (perp=7.494, rec=0.142, cos=0.002), tot_loss_proj:2.759 [t=0.32s]
prediction: ["[CLS] before all recent latest ', ve'greatest'of help we seen teacher ve of us orromatic hoffman director's, but when this world about this.nation, great rein. the care director makes. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.649 (perp=7.494, rec=0.148, cos=0.002), tot_loss_proj:2.759 [t=0.32s]
prediction: ["[CLS] before all recent latest ', ve'greatest'of help we seen teacher ve of us orromatic hoffman director's, but when this world about this.nation, great rein. the care director makes. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.642 (perp=7.494, rec=0.141, cos=0.002), tot_loss_proj:2.764 [t=0.32s]
prediction: ["[CLS] before all recent latest ', ve'greatest'of help we seen teacher ve of us orromatic hoffman director's, but when this world about this.nation, great rein. the care director makes. [SEP]"]
[1950/2000] tot_loss=1.631 (perp=7.494, rec=0.130, cos=0.002), tot_loss_proj:2.760 [t=0.32s]
prediction: ["[CLS] before all recent latest ', ve'greatest'of help we seen teacher ve of us orromatic hoffman director's, but when this world about this.nation, great rein. the care director makes. [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.610 (perp=7.298, rec=0.148, cos=0.003), tot_loss_proj:2.951 [t=0.32s]
prediction: ["[CLS] before all recent latest ', ve'greatest'of help we seen teacher. of us orromatic hoffman director's, but when this world about this venation, great rein. the care director makes. [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] before all recent latest ', ve'greatest'of help we seen teacher ve of us orromatic hoffman director's, but when this world about this.nation, great rein. the care director makes. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 72.727 | r: 68.571
rouge2     | fm: 3.030 | p: 3.125 | r: 2.941
rougeL     | fm: 23.529 | p: 24.242 | r: 22.857
rougeLsum  | fm: 23.529 | p: 24.242 | r: 22.857
r1fm+r2fm = 73.619

[Aggregate metrics]:
rouge1     | fm: 93.326 | p: 93.094 | r: 93.634
rouge2     | fm: 65.515 | p: 65.327 | r: 65.727
rougeL     | fm: 80.835 | p: 80.554 | r: 81.112
rougeLsum  | fm: 80.792 | p: 80.552 | r: 81.022
r1fm+r2fm = 158.841

input #35 time: 0:12:37 | total time: 7:22:18


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.9992844607882909
highest_index [0]
highest [0.9992844607882909]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9979468584060669 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9948145747184753 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 0.9560490846633911 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9270139336585999 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9258526563644409 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.9127167463302612 for ['[CLS] papa sinclairevsky perhaps [SEP]']
[Init] best rec loss: 0.8275740146636963 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8233544230461121 for ['[CLS] harassment cornelius ramsey bates [SEP]']
[Init] best perm rec loss: 0.8217460513114929 for ['[CLS] bates cornelius ramsey harassment [SEP]']
[Init] best perm rec loss: 0.8194081783294678 for ['[CLS] bates harassment ramsey cornelius [SEP]']
[Init] best perm rec loss: 0.8167362809181213 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.958 (perp=9.086, rec=0.135, cos=0.006), tot_loss_proj:2.101 [t=0.31s]
prediction: ['[CLS] is horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=1.901 (perp=9.148, rec=0.069, cos=0.002), tot_loss_proj:2.109 [t=0.31s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=1.902 (perp=9.148, rec=0.070, cos=0.002), tot_loss_proj:2.108 [t=0.31s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=1.893 (perp=9.148, rec=0.062, cos=0.002), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.906 (perp=9.148, rec=0.075, cos=0.002), tot_loss_proj:2.126 [t=0.31s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 300/2000] tot_loss=1.888 (perp=9.148, rec=0.057, cos=0.002), tot_loss_proj:2.124 [t=0.31s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.897 (perp=9.148, rec=0.065, cos=0.002), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.887 (perp=9.148, rec=0.056, cos=0.002), tot_loss_proj:2.136 [t=0.31s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 450/2000] tot_loss=1.806 (perp=8.607, rec=0.083, cos=0.001), tot_loss_proj:1.928 [t=0.31s]
prediction: ["[CLS] s horribly wrong'[SEP]"]
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.502 (perp=7.159, rec=0.069, cos=0.001), tot_loss_proj:1.862 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.499 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.852 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 600/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.861 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.490 (perp=7.159, rec=0.056, cos=0.001), tot_loss_proj:1.852 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.852 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 750/2000] tot_loss=1.496 (perp=7.159, rec=0.063, cos=0.001), tot_loss_proj:1.849 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.859 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.499 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.858 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 900/2000] tot_loss=1.499 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.865 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.506 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.854 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.486 (perp=7.159, rec=0.052, cos=0.001), tot_loss_proj:1.856 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1050/2000] tot_loss=1.492 (perp=7.159, rec=0.059, cos=0.001), tot_loss_proj:1.849 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.503 (perp=7.159, rec=0.070, cos=0.001), tot_loss_proj:1.853 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.506 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.861 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1200/2000] tot_loss=1.499 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.862 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.491 (perp=7.159, rec=0.058, cos=0.001), tot_loss_proj:1.856 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.486 (perp=7.159, rec=0.053, cos=0.001), tot_loss_proj:1.848 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1350/2000] tot_loss=1.499 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.851 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.496 (perp=7.159, rec=0.062, cos=0.001), tot_loss_proj:1.855 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.504 (perp=7.159, rec=0.071, cos=0.001), tot_loss_proj:1.856 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1500/2000] tot_loss=1.499 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.854 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.507 (perp=7.159, rec=0.074, cos=0.001), tot_loss_proj:1.857 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.511 (perp=7.159, rec=0.078, cos=0.001), tot_loss_proj:1.862 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1650/2000] tot_loss=1.507 (perp=7.159, rec=0.074, cos=0.001), tot_loss_proj:1.859 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.500 (perp=7.159, rec=0.067, cos=0.001), tot_loss_proj:1.852 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.490 (perp=7.159, rec=0.057, cos=0.001), tot_loss_proj:1.848 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1800/2000] tot_loss=1.491 (perp=7.159, rec=0.058, cos=0.001), tot_loss_proj:1.849 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.490 (perp=7.159, rec=0.057, cos=0.001), tot_loss_proj:1.857 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.488 (perp=7.159, rec=0.055, cos=0.001), tot_loss_proj:1.853 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1950/2000] tot_loss=1.500 (perp=7.159, rec=0.067, cos=0.001), tot_loss_proj:1.862 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.510 (perp=7.159, rec=0.077, cos=0.001), tot_loss_proj:1.851 [t=0.31s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] horribly wrong's [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 93.527 | p: 93.290 | r: 93.817
rouge2     | fm: 64.449 | p: 64.247 | r: 64.674
rougeL     | fm: 80.825 | p: 80.568 | r: 81.090
rougeLsum  | fm: 80.754 | p: 80.479 | r: 81.032
r1fm+r2fm = 157.976

input #36 time: 0:12:13 | total time: 7:34:32


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9993681905125777
highest_index [0]
highest [0.9993681905125777]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.9615121483802795 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.9514033198356628 for ['[CLS]quest medical [SEP]']
[Init] best rec loss: 0.882455587387085 for ['[CLS] fish cape [SEP]']
[Init] best rec loss: 0.8091627359390259 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.7990277409553528 for ['[CLS] living metacritic [SEP]']
[Init] best rec loss: 0.7836698889732361 for ['[CLS] housemple [SEP]']
[Init] best rec loss: 0.7558265328407288 for ['[CLS] year clarissa [SEP]']
[Init] best rec loss: 0.7352581024169922 for ['[CLS]atal purpose [SEP]']
[Init] best rec loss: 0.717540979385376 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.7015913724899292 for ['[CLS] cousin many [SEP]']
[Init] best rec loss: 0.6861273050308228 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.6752412915229797 for ['[CLS] cassidystream [SEP]']
[Init] best rec loss: 0.6447769999504089 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.6349392533302307 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.991 (perp=12.719, rec=0.325, cos=0.122), tot_loss_proj:4.339 [t=0.30s]
prediction: ['[CLS] eccentric whatsoever [SEP]']
[ 100/2000] tot_loss=2.360 (perp=9.583, rec=0.247, cos=0.196), tot_loss_proj:2.019 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[ 150/2000] tot_loss=1.997 (perp=9.583, rec=0.077, cos=0.003), tot_loss_proj:2.003 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=1.992 (perp=9.583, rec=0.074, cos=0.001), tot_loss_proj:2.019 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.981 (perp=9.583, rec=0.063, cos=0.001), tot_loss_proj:2.008 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[ 300/2000] tot_loss=1.984 (perp=9.583, rec=0.065, cos=0.002), tot_loss_proj:2.018 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.006 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.967 (perp=9.583, rec=0.049, cos=0.001), tot_loss_proj:2.016 [t=0.34s]
prediction: ['[CLS] eccentric and [SEP]']
[ 450/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.017 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.986 (perp=9.583, rec=0.068, cos=0.001), tot_loss_proj:2.011 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.973 (perp=9.583, rec=0.055, cos=0.001), tot_loss_proj:2.009 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[ 600/2000] tot_loss=1.974 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:2.009 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.987 (perp=9.583, rec=0.069, cos=0.001), tot_loss_proj:2.010 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:2.016 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[ 750/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.006 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.986 (perp=9.583, rec=0.068, cos=0.001), tot_loss_proj:2.005 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.001 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[ 900/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.016 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.974 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:2.013 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:2.015 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[1050/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.021 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.974 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:2.006 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.976 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.008 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[1200/2000] tot_loss=1.969 (perp=9.583, rec=0.051, cos=0.001), tot_loss_proj:2.000 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.993 (perp=9.583, rec=0.076, cos=0.001), tot_loss_proj:2.008 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.966 (perp=9.583, rec=0.048, cos=0.001), tot_loss_proj:2.010 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[1350/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.012 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.009 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.959 (perp=9.583, rec=0.041, cos=0.001), tot_loss_proj:2.013 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[1500/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.017 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.961 (perp=9.583, rec=0.043, cos=0.001), tot_loss_proj:2.019 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.014 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[1650/2000] tot_loss=1.985 (perp=9.583, rec=0.068, cos=0.001), tot_loss_proj:2.005 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.967 (perp=9.583, rec=0.050, cos=0.001), tot_loss_proj:2.016 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.984 (perp=9.583, rec=0.066, cos=0.001), tot_loss_proj:1.995 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[1800/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.022 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.988 (perp=9.583, rec=0.070, cos=0.001), tot_loss_proj:2.005 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.990 (perp=9.583, rec=0.072, cos=0.001), tot_loss_proj:2.004 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
[1950/2000] tot_loss=1.973 (perp=9.583, rec=0.055, cos=0.001), tot_loss_proj:2.004 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.988 (perp=9.583, rec=0.071, cos=0.001), tot_loss_proj:2.012 [t=0.31s]
prediction: ['[CLS] eccentric and [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.734 | p: 93.470 | r: 94.043
rouge2     | fm: 65.301 | p: 65.117 | r: 65.488
rougeL     | fm: 81.378 | p: 81.204 | r: 81.683
rougeLsum  | fm: 81.225 | p: 80.989 | r: 81.464
r1fm+r2fm = 159.035

input #37 time: 0:12:13 | total time: 7:46:46


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9992652654083553
highest_index [0]
highest [0.9992652654083553]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8141232132911682 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8104202151298523 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.805162787437439 for ['[CLS] federation [SEP]']
[Init] best rec loss: 0.776758074760437 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7055478692054749 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.6721317768096924 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6253368258476257 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.900 (perp=14.070, rec=0.080, cos=0.006), tot_loss_proj:2.871 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.872 (perp=14.070, rec=0.056, cos=0.002), tot_loss_proj:2.886 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.883 (perp=14.070, rec=0.062, cos=0.007), tot_loss_proj:2.877 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.887 (perp=14.070, rec=0.072, cos=0.001), tot_loss_proj:2.883 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.876 (perp=14.070, rec=0.059, cos=0.003), tot_loss_proj:2.876 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.876 (perp=14.070, rec=0.061, cos=0.001), tot_loss_proj:2.884 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.876 (perp=14.070, rec=0.060, cos=0.001), tot_loss_proj:2.875 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.877 (perp=14.070, rec=0.061, cos=0.001), tot_loss_proj:2.881 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.873 (perp=14.070, rec=0.057, cos=0.001), tot_loss_proj:2.875 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.863 (perp=14.070, rec=0.047, cos=0.001), tot_loss_proj:2.879 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.869 (perp=14.070, rec=0.053, cos=0.001), tot_loss_proj:2.859 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.877 (perp=14.070, rec=0.062, cos=0.001), tot_loss_proj:2.871 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.873 (perp=14.070, rec=0.057, cos=0.001), tot_loss_proj:2.878 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.870 (perp=14.070, rec=0.055, cos=0.001), tot_loss_proj:2.878 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.876 (perp=14.070, rec=0.061, cos=0.001), tot_loss_proj:2.868 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.878 (perp=14.070, rec=0.062, cos=0.001), tot_loss_proj:2.885 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.877 (perp=14.070, rec=0.061, cos=0.001), tot_loss_proj:2.866 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.880 (perp=14.070, rec=0.065, cos=0.001), tot_loss_proj:2.878 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.880 (perp=14.070, rec=0.065, cos=0.001), tot_loss_proj:2.866 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.876 (perp=14.070, rec=0.060, cos=0.001), tot_loss_proj:2.857 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.881 (perp=14.070, rec=0.065, cos=0.001), tot_loss_proj:2.870 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.869 (perp=14.070, rec=0.054, cos=0.001), tot_loss_proj:2.855 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.871 (perp=14.070, rec=0.055, cos=0.001), tot_loss_proj:2.859 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.872 (perp=14.070, rec=0.056, cos=0.001), tot_loss_proj:2.875 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.868 (perp=14.070, rec=0.053, cos=0.001), tot_loss_proj:2.869 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.876 (perp=14.070, rec=0.060, cos=0.001), tot_loss_proj:2.864 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.884 (perp=14.070, rec=0.068, cos=0.001), tot_loss_proj:2.864 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.878 (perp=14.070, rec=0.063, cos=0.001), tot_loss_proj:2.881 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.884 (perp=14.070, rec=0.069, cos=0.001), tot_loss_proj:2.869 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.876 (perp=14.070, rec=0.060, cos=0.001), tot_loss_proj:2.884 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.867 (perp=14.070, rec=0.051, cos=0.001), tot_loss_proj:2.873 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.891 (perp=14.070, rec=0.075, cos=0.001), tot_loss_proj:2.878 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.876 (perp=14.070, rec=0.061, cos=0.001), tot_loss_proj:2.864 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.877 (perp=14.070, rec=0.061, cos=0.001), tot_loss_proj:2.880 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.873 (perp=14.070, rec=0.057, cos=0.001), tot_loss_proj:2.868 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.871 (perp=14.070, rec=0.056, cos=0.001), tot_loss_proj:2.866 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.872 (perp=14.070, rec=0.056, cos=0.001), tot_loss_proj:2.883 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.872 (perp=14.070, rec=0.057, cos=0.001), tot_loss_proj:2.871 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.875 (perp=14.070, rec=0.059, cos=0.001), tot_loss_proj:2.882 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.870 (perp=14.070, rec=0.054, cos=0.001), tot_loss_proj:2.869 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.950 | p: 93.724 | r: 94.184
rouge2     | fm: 66.219 | p: 66.062 | r: 66.350
rougeL     | fm: 81.792 | p: 81.607 | r: 82.042
rougeLsum  | fm: 81.539 | p: 81.310 | r: 81.822
r1fm+r2fm = 160.170

input #38 time: 0:11:10 | total time: 7:57:57


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9992533230117018
highest_index [0]
highest [0.9992533230117018]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 1.012943983078003 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 1.0048844814300537 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 0.9902212023735046 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.9328551292419434 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.9258584380149841 for ['[CLS] ira estimate rabbi relegationbiotic request veronica his baby firedusia property management spring gone dub related location cd age eastern drove than kelly parking [SEP]']
[Init] best rec loss: 0.9213489294052124 for ['[CLS] mutual peopleュ stone intimate reeve templeming freak shores over they sprinterous pro dedication harbour along ll minority [CLS] class raise issue need [SEP]']
[Init] best rec loss: 0.9197564721107483 for ["[CLS] uefa exchange or who'capital pride formingmate yard cambodia dun ed specificold miss wife presentering list dynamo once! success lancashire [SEP]"]
[Init] best rec loss: 0.9119060039520264 for ['[CLS] townwind hurt main thenney cassidyowa position jury southpher wash sailhy gordon lab happened bepettive in etc sometimes event [SEP]']
[Init] best perm rec loss: 0.9092154502868652 for ['[CLS]pher happened sailowa jury cassidy gordon main etcwind thentivehy event south sometimes positionney lab be hurtpet wash town in [SEP]']
[Init] best perm rec loss: 0.9075307846069336 for ['[CLS]hy jurypet wash then townney sometimestive hurt eventpher position main happened etc south bewind gordon cassidy labowa sail in [SEP]']
[Init] best perm rec loss: 0.9064310193061829 for ['[CLS]pet intive lab then event town sail sometimesney washwind happenedpher cassidyowa main gordon etc hurt jury south be positionhy [SEP]']
[Init] best perm rec loss: 0.9059585928916931 for ['[CLS] event lab sailpet gordon happened town behy intive position south then sometimes hurt jury etc mainwindney wash cassidyowapher [SEP]']
[Init] best perm rec loss: 0.9051021933555603 for ['[CLS] wash south happened then sometimes event cassidytivepher in jury sail etc hurt position be town gordonwind main labhyneyowapet [SEP]']
[Init] best perm rec loss: 0.9029912948608398 for ['[CLS] main jury happenedhy position be wash etcwindpherpet hurttive town lab in cassidy thenneyowa gordon event sail sometimes south [SEP]']
[Init] best perm rec loss: 0.9017069339752197 for ['[CLS] position juryney betive southhypher town sail event happened etc then in washwindpet cassidy lab main gordon sometimes hurtowa [SEP]']
[Init] best perm rec loss: 0.8999354243278503 for ['[CLS] happened be in position wash etc eventwind town hurt mainpher sailpet lab gordon cassidy thenowativeneyhy south jury sometimes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.914 (perp=12.685, rec=0.363, cos=0.014), tot_loss_proj:3.644 [t=0.31s]
prediction: ['[CLS] steve langdon summers justice 9 thomas shaped cinematography competition. sure 2012 gallery frank stories co new art need lila turner until preserves beck good [SEP]']
[ 100/2000] tot_loss=2.362 (perp=10.292, rec=0.293, cos=0.010), tot_loss_proj:3.510 [t=0.31s]
prediction: ['[CLS] greg frequently applying. its thomas findstial competition. if new attractions george innovation each new art conservative, direction and novak patents academy [SEP]']
[ 150/2000] tot_loss=2.225 (perp=9.818, rec=0.255, cos=0.006), tot_loss_proj:3.405 [t=0.32s]
prediction: ['[CLS] finds itsy. its langdon findsbound tradition - if newbound & 1990s texture new art conservative, direction and rooted vampire movie [SEP]']
[ 200/2000] tot_loss=2.301 (perp=10.101, rec=0.271, cos=0.010), tot_loss_proj:3.053 [t=0.31s]
prediction: ['[CLS] finds its make. gibraltar - findsbound meaning - main [UNK] &, new texture new painting conservative researchey and still actors reality [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.264 (perp=10.137, rec=0.232, cos=0.006), tot_loss_proj:2.651 [t=0.32s]
prediction: ['[CLS] finds brooks find our gibraltar - findsbound tradition - main / celebrates, new texture. new art conservative little and enigmaec movie [SEP]']
[ 300/2000] tot_loss=2.380 (perp=10.167, rec=0.290, cos=0.057), tot_loss_proj:3.254 [t=0.32s]
prediction: ['[CLS] finds brooks find ourbound - findsbound meaning, main find finds, new texture. new art conservative ( and holdingsec movie [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.322 (perp=10.571, rec=0.202, cos=0.006), tot_loss_proj:3.708 [t=0.32s]
prediction: ['[CLS] finds taught find our moviebound hide givesbound texture, main find finds, new texture. new theme conservative ( and traditionsec [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.181 (perp=10.006, rec=0.176, cos=0.004), tot_loss_proj:3.669 [t=0.32s]
prediction: ['[CLS] finds ( find our moviebound hide gives hide texture, movie finds finds, new texture. new theme conservative taught and traditionsec [SEP]']
[ 450/2000] tot_loss=2.154 (perp=9.903, rec=0.170, cos=0.004), tot_loss_proj:3.328 [t=0.32s]
prediction: ['[CLS] finds, find our moviebound hide gives hide texture, movie finds finds, new texture. new traditions conservative taught and traditionsec [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.034 (perp=9.375, rec=0.156, cos=0.003), tot_loss_proj:3.505 [t=0.32s]
prediction: ['[CLS] " ( find our movie hidebound gives hide texture, movie finds movie, new texture. new traditions conservative taught and traditions movie [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.262 (perp=10.528, rec=0.153, cos=0.003), tot_loss_proj:3.676 [t=0.32s]
prediction: ['[CLS] covers - " our movie mostbound gives hide reality, play finds finds, new texture [SEP] new traditions conservative taught and traditions movie [SEP]']
[ 600/2000] tot_loss=2.260 (perp=10.558, rec=0.145, cos=0.003), tot_loss_proj:3.821 [t=0.32s]
prediction: ['[CLS] send - " our movie mostbound gives hide reality, forward finds movie, new texture [SEP] new traditions conservative taught and traditions movie [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.224 (perp=10.436, rec=0.135, cos=0.003), tot_loss_proj:3.147 [t=0.32s]
prediction: ['[CLS] send. depth our movie most hidebound gives reality, movie finds movie,, texture [SEP] new traditions conservative taught and traditions movie [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.146 (perp=10.080, rec=0.128, cos=0.003), tot_loss_proj:3.326 [t=0.32s]
prediction: ['[CLS] conservative.bound our movie most hidebound gives reality, movie finds movie it, texture [SEP] new giving send of and traditions movie [SEP]']
[ 750/2000] tot_loss=2.135 (perp=10.080, rec=0.117, cos=0.002), tot_loss_proj:3.329 [t=0.31s]
prediction: ['[CLS] conservative.bound our movie most hidebound gives reality, movie finds movie it, texture [SEP] new giving send of and traditions movie [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.172 (perp=10.279, rec=0.114, cos=0.002), tot_loss_proj:3.335 [t=0.32s]
prediction: ['[CLS] conservative.bound our movie most hidebound gives reality, movie finds happening it, texture [SEP] new giving send of actor and traditions [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.012 (perp=9.506, rec=0.108, cos=0.002), tot_loss_proj:3.235 [t=0.32s]
prediction: ['[CLS] conservative.bound our movie most hidebound gives reality, movie finds movie it, texture [SEP] new making send of movie and traditions [SEP]']
[ 900/2000] tot_loss=2.024 (perp=9.599, rec=0.102, cos=0.002), tot_loss_proj:3.091 [t=0.32s]
prediction: ['[CLS] conservative.bound our movie most hidebound gives reality, actor finds movie it, texture [SEP] new making send of movie and traditions [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.967 (perp=9.291, rec=0.107, cos=0.002), tot_loss_proj:3.218 [t=0.32s]
prediction: ['[CLS] conservative. new our movie most hidebound gives reality, actor finds movie it, texture [SEP]bound making send of movie and traditions [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.857 (perp=8.760, rec=0.102, cos=0.002), tot_loss_proj:3.101 [t=0.32s]
prediction: ['[CLS] conservative. our new movie most hidebound gives reality, actor finds movie it, texture [SEP]bound making send of movie and traditions [SEP]']
[1050/2000] tot_loss=1.872 (perp=8.829, rec=0.104, cos=0.002), tot_loss_proj:2.984 [t=0.32s]
prediction: ['[CLS] conservative. our new movie most hidebound gives reality, actor finds film it, texture [SEP]bound making send of movie and traditions [SEP]']
Attempt swap
[1100/2000] tot_loss=1.913 (perp=9.073, rec=0.097, cos=0.002), tot_loss_proj:3.216 [t=0.32s]
prediction: ['[CLS] conservative. our new movie most hidebound gives reality, making finds reality it, texture [SEP]bound making send of movie and traditions [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.849 (perp=8.710, rec=0.105, cos=0.002), tot_loss_proj:3.201 [t=0.32s]
prediction: ['[CLS] conservative. our new movie most hidebound gives reality, making finds reality it, texture [SEP]bound and send of movie making traditions [SEP]']
[1200/2000] tot_loss=1.843 (perp=8.710, rec=0.100, cos=0.002), tot_loss_proj:3.194 [t=0.33s]
prediction: ['[CLS] conservative. our new movie most hidebound gives reality, making finds reality it, texture [SEP]bound and send of movie making traditions [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.844 (perp=8.669, rec=0.108, cos=0.003), tot_loss_proj:2.985 [t=0.32s]
prediction: ['[CLS] conservative of our new movie most hidebound gives relevance, it finds reality making, texture [SEP]bound and send of movie making traditions [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.828 (perp=8.625, rec=0.101, cos=0.002), tot_loss_proj:3.026 [t=0.32s]
prediction: ['[CLS] conservative. our new movie most hidebound gives relevance, it finds reality making and texture [SEP]bound,ku of movie making traditions [SEP]']
[1350/2000] tot_loss=1.868 (perp=8.830, rec=0.100, cos=0.002), tot_loss_proj:3.158 [t=0.32s]
prediction: ['[CLS] conservative of our new movie most hidebound gives relevance, it finds reality making and texture [SEP]bound,ku of movie making traditions [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.828 (perp=8.640, rec=0.098, cos=0.002), tot_loss_proj:3.141 [t=0.32s]
prediction: ['[CLS] conservative of our new movie most hidebound gives relevance, it finds reality making of texture [SEP]bound,ku and movie making traditions [SEP]']
Attempt swap
[1450/2000] tot_loss=1.826 (perp=8.640, rec=0.096, cos=0.002), tot_loss_proj:3.139 [t=0.32s]
prediction: ['[CLS] conservative of our new movie most hidebound gives relevance, it finds reality making of texture [SEP]bound,ku and movie making traditions [SEP]']
[1500/2000] tot_loss=1.826 (perp=8.640, rec=0.096, cos=0.002), tot_loss_proj:3.140 [t=0.32s]
prediction: ['[CLS] conservative of our new movie most hidebound gives relevance, it finds reality making of texture [SEP]bound,ku and movie making traditions [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.717 (perp=8.066, rec=0.102, cos=0.002), tot_loss_proj:2.829 [t=0.31s]
prediction: ['[CLS] conservative. our new reality most hidebound gives relevance, it finds movie making of texture [SEP]bound,ku and movie making traditions [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.741 (perp=8.172, rec=0.104, cos=0.002), tot_loss_proj:2.733 [t=0.32s]
prediction: ['[CLS] conservative of our new reality most hidebound gives relevance, it finds movie making of texture [SEP]boundku, and movie making traditions [SEP]']
[1650/2000] tot_loss=1.742 (perp=8.172, rec=0.106, cos=0.002), tot_loss_proj:2.733 [t=0.32s]
prediction: ['[CLS] conservative of our new reality most hidebound gives relevance, it finds movie making of texture [SEP]boundku, and movie making traditions [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.674 (perp=7.865, rec=0.099, cos=0.002), tot_loss_proj:2.682 [t=0.32s]
prediction: ['[CLS] conservative of our new reality most hidebound gives relevance, it finds movie making of texture, [SEP]boundku and movie making traditions [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.706 (perp=8.056, rec=0.093, cos=0.002), tot_loss_proj:3.140 [t=0.32s]
prediction: ['[CLS] conservative of our new reality most hidebound gives relevance, it finds movie making of and, [SEP]bound rated texture movie making traditions [SEP]']
[1800/2000] tot_loss=1.713 (perp=8.056, rec=0.100, cos=0.002), tot_loss_proj:3.144 [t=0.32s]
prediction: ['[CLS] conservative of our new reality most hidebound gives relevance, it finds movie making of and, [SEP]bound rated texture movie making traditions [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.705 (perp=7.994, rec=0.104, cos=0.002), tot_loss_proj:3.070 [t=0.32s]
prediction: ['[CLS] conservative of our new reality most hidebound gives relevance, it finds movie making, and of [SEP]bound rated texture movie making traditions [SEP]']
Attempt swap
[1900/2000] tot_loss=1.698 (perp=7.994, rec=0.097, cos=0.002), tot_loss_proj:3.070 [t=0.32s]
prediction: ['[CLS] conservative of our new reality most hidebound gives relevance, it finds movie making, and of [SEP]bound rated texture movie making traditions [SEP]']
[1950/2000] tot_loss=1.695 (perp=7.994, rec=0.094, cos=0.002), tot_loss_proj:3.070 [t=0.32s]
prediction: ['[CLS] conservative of our new reality most hidebound gives relevance, it finds movie making, and of [SEP]bound rated texture movie making traditions [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.781 (perp=8.406, rec=0.098, cos=0.002), tot_loss_proj:3.228 [t=0.32s]
prediction: ['[CLS] conservative of our new reality most hidebound gives relevance, it finds movie making, and of [SEP]ku texturebound movie making traditions [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] conservative of our new reality most hidebound gives relevance, it finds movie making of texture [SEP]bound,ku and movie making traditions [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 75.000 | r: 81.818
rouge2     | fm: 18.182 | p: 17.391 | r: 19.048
rougeL     | fm: 39.130 | p: 37.500 | r: 40.909
rougeLsum  | fm: 39.130 | p: 37.500 | r: 40.909
r1fm+r2fm = 96.443

[Aggregate metrics]:
rouge1     | fm: 93.521 | p: 93.208 | r: 93.844
rouge2     | fm: 64.964 | p: 64.727 | r: 65.197
rougeL     | fm: 80.786 | p: 80.514 | r: 81.054
rougeLsum  | fm: 80.481 | p: 80.236 | r: 80.831
r1fm+r2fm = 158.485

input #39 time: 0:12:34 | total time: 8:10:31


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9993184488233802
highest_index [0]
highest [0.9993184488233802]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9950785636901855 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.959141731262207 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.938033938407898 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 0.9346923828125 for ['[CLS] alive represents adelaide cinder majestymersfordthes s [SEP]']
[Init] best rec loss: 0.9305990934371948 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 0.9224919080734253 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 0.917496383190155 for ['[CLS] formula expression groundsoft written used ⇒ution murray [SEP]']
[Init] best rec loss: 0.9056705832481384 for ['[CLS] alloid courtesy [MASK]blood mean gownrarm [SEP]']
[Init] best rec loss: 0.8492094874382019 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8440247178077698 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8425820469856262 for ['[CLS] but georgian lady kent many abd° deciding already [SEP]']
[Init] best perm rec loss: 0.8404844403266907 for ['[CLS] lady deciding° already but many georgian abd kent [SEP]']
[Init] best perm rec loss: 0.8395869731903076 for ['[CLS] already° but kent many lady deciding georgian abd [SEP]']
[Init] best perm rec loss: 0.8393037915229797 for ['[CLS] deciding already kent lady georgian many° but abd [SEP]']
[Init] best perm rec loss: 0.8363253474235535 for ['[CLS] but already° georgian deciding kent lady abd many [SEP]']
[Init] best perm rec loss: 0.8351089954376221 for ['[CLS] kent already lady but georgian deciding° abd many [SEP]']
[Init] best perm rec loss: 0.8340105414390564 for ['[CLS] but georgian lady deciding already kent abd° many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.918 (perp=13.057, rec=0.296, cos=0.011), tot_loss_proj:3.512 [t=0.30s]
prediction: ['[CLS]. crazy drag phonemmel imagery orne wrong [SEP]']
[ 100/2000] tot_loss=2.363 (perp=10.743, rec=0.208, cos=0.006), tot_loss_proj:2.839 [t=0.31s]
prediction: ['[CLS] pu puony phonemmel imagery or byony [SEP]']
[ 150/2000] tot_loss=2.478 (perp=11.639, rec=0.144, cos=0.006), tot_loss_proj:3.588 [t=0.31s]
prediction: ['[CLS] pu puonyonymmel music or withony [SEP]']
[ 200/2000] tot_loss=2.371 (perp=11.278, rec=0.111, cos=0.005), tot_loss_proj:2.925 [t=0.31s]
prediction: ['[CLS] pu puony phmmel imagery or withony [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.233 (perp=10.516, rec=0.125, cos=0.004), tot_loss_proj:2.793 [t=0.31s]
prediction: ['[CLS] pu musicony withmmel imagery or phony [SEP]']
[ 300/2000] tot_loss=1.977 (perp=9.271, rec=0.120, cos=0.004), tot_loss_proj:2.486 [t=0.31s]
prediction: ['[CLS] pu phony withmmel imagery or phony [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.625 (perp=7.484, rec=0.123, cos=0.005), tot_loss_proj:2.001 [t=0.31s]
prediction: ['[CLS] pummel music or phony with phony [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.068 (perp=9.727, rec=0.119, cos=0.004), tot_loss_proj:2.655 [t=0.31s]
prediction: ['[CLS] pummel music or phony with imageryony [SEP]']
[ 450/2000] tot_loss=2.056 (perp=9.727, rec=0.108, cos=0.003), tot_loss_proj:2.661 [t=0.31s]
prediction: ['[CLS] pummel music or phony with imageryony [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.859 (perp=8.622, rec=0.130, cos=0.005), tot_loss_proj:2.284 [t=0.31s]
prediction: ['[CLS] imagery pummel music or phony withony [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.679 (perp=7.751, rec=0.124, cos=0.005), tot_loss_proj:2.190 [t=0.31s]
prediction: ['[CLS] imagery pummelony or phony with music [SEP]']
[ 600/2000] tot_loss=1.887 (perp=8.844, rec=0.114, cos=0.004), tot_loss_proj:2.330 [t=0.31s]
prediction: ['[CLS] imagery pummelony or phony us music [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.678 (perp=7.813, rec=0.112, cos=0.004), tot_loss_proj:2.031 [t=0.31s]
prediction: ['[CLS] imagery pummel usony or phony music [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.670 (perp=7.813, rec=0.104, cos=0.004), tot_loss_proj:2.034 [t=0.31s]
prediction: ['[CLS] imagery pummel usony or phony music [SEP]']
[ 750/2000] tot_loss=1.670 (perp=7.813, rec=0.103, cos=0.004), tot_loss_proj:2.035 [t=0.31s]
prediction: ['[CLS] imagery pummel usony or phony music [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.663 (perp=7.813, rec=0.098, cos=0.002), tot_loss_proj:2.035 [t=0.31s]
prediction: ['[CLS] imagery pummel usony or phony music [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.684 (perp=7.968, rec=0.089, cos=0.002), tot_loss_proj:2.062 [t=0.31s]
prediction: ['[CLS] imagery pummel us us or phony music [SEP]']
[ 900/2000] tot_loss=1.674 (perp=7.968, rec=0.079, cos=0.002), tot_loss_proj:2.062 [t=0.31s]
prediction: ['[CLS] imagery pummel us us or phony music [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.472 (perp=6.961, rec=0.078, cos=0.002), tot_loss_proj:1.863 [t=0.31s]
prediction: ['[CLS] us imagery pummel us or phony music [SEP]']
Attempt swap
[1000/2000] tot_loss=1.472 (perp=6.961, rec=0.078, cos=0.001), tot_loss_proj:1.865 [t=0.31s]
prediction: ['[CLS] us imagery pummel us or phony music [SEP]']
[1050/2000] tot_loss=1.743 (perp=8.360, rec=0.069, cos=0.001), tot_loss_proj:2.188 [t=0.31s]
prediction: ['[CLS] us imagery pummel with or phony music [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.575 (perp=7.469, rec=0.080, cos=0.001), tot_loss_proj:2.235 [t=0.31s]
prediction: ['[CLS] us imagery pummel or phony with music [SEP]']
Attempt swap
[1150/2000] tot_loss=1.569 (perp=7.469, rec=0.073, cos=0.001), tot_loss_proj:2.232 [t=0.31s]
prediction: ['[CLS] us imagery pummel or phony with music [SEP]']
[1200/2000] tot_loss=1.567 (perp=7.469, rec=0.072, cos=0.001), tot_loss_proj:2.234 [t=0.31s]
prediction: ['[CLS] us imagery pummel or phony with music [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.502 (perp=7.096, rec=0.081, cos=0.001), tot_loss_proj:2.059 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1300/2000] tot_loss=1.486 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.058 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1350/2000] tot_loss=1.488 (perp=7.096, rec=0.068, cos=0.001), tot_loss_proj:2.067 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1400/2000] tot_loss=1.495 (perp=7.096, rec=0.074, cos=0.001), tot_loss_proj:2.069 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1450/2000] tot_loss=1.491 (perp=7.096, rec=0.070, cos=0.001), tot_loss_proj:2.062 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1500/2000] tot_loss=1.488 (perp=7.096, rec=0.068, cos=0.001), tot_loss_proj:2.066 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1550/2000] tot_loss=1.488 (perp=7.096, rec=0.067, cos=0.001), tot_loss_proj:2.069 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1600/2000] tot_loss=1.494 (perp=7.096, rec=0.073, cos=0.001), tot_loss_proj:2.065 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1650/2000] tot_loss=1.482 (perp=7.096, rec=0.061, cos=0.001), tot_loss_proj:2.065 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1700/2000] tot_loss=1.487 (perp=7.096, rec=0.066, cos=0.001), tot_loss_proj:2.063 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1750/2000] tot_loss=1.485 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.064 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1800/2000] tot_loss=1.491 (perp=7.096, rec=0.070, cos=0.001), tot_loss_proj:2.068 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1850/2000] tot_loss=1.480 (perp=7.096, rec=0.059, cos=0.001), tot_loss_proj:2.060 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1900/2000] tot_loss=1.492 (perp=7.096, rec=0.071, cos=0.001), tot_loss_proj:2.066 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1950/2000] tot_loss=1.493 (perp=7.096, rec=0.072, cos=0.001), tot_loss_proj:2.067 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[2000/2000] tot_loss=1.491 (perp=7.096, rec=0.071, cos=0.001), tot_loss_proj:2.064 [t=0.31s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] imagery pummel us or phony with music [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 93.674 | p: 93.340 | r: 93.977
rouge2     | fm: 64.093 | p: 63.942 | r: 64.274
rougeL     | fm: 80.400 | p: 80.126 | r: 80.673
rougeLsum  | fm: 80.163 | p: 79.906 | r: 80.429
r1fm+r2fm = 157.767

input #40 time: 0:12:15 | total time: 8:22:47


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.9993045761293136
highest_index [0]
highest [0.9993045761293136]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9760705232620239 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9475264549255371 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 0.9422504901885986 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 0.9298644661903381 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.9267092943191528 for ['[CLS]grapher pr [SEP]']
[Init] best rec loss: 0.9231860637664795 for ['[CLS]mler previously [SEP]']
[Init] best rec loss: 0.9069849848747253 for ['[CLS] electors mediterranean [SEP]']
[Init] best rec loss: 0.8946877717971802 for ['[CLS] meetswr [SEP]']
[Init] best rec loss: 0.8549445271492004 for ['[CLS] bolivar satisfied [SEP]']
[Init] best rec loss: 0.8326714038848877 for ['[CLS] ways whether [SEP]']
[Init] best perm rec loss: 0.83014976978302 for ['[CLS] whether ways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.155 (perp=10.212, rec=0.110, cos=0.002), tot_loss_proj:2.107 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.112 (perp=10.212, rec=0.068, cos=0.001), tot_loss_proj:2.101 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.002), tot_loss_proj:2.117 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.113 (perp=10.212, rec=0.069, cos=0.001), tot_loss_proj:2.111 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.002), tot_loss_proj:2.105 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.116 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.095 (perp=10.212, rec=0.051, cos=0.001), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.094 (perp=10.212, rec=0.050, cos=0.001), tot_loss_proj:2.108 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.111 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.116 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.104 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.113 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.107 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.123 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.113 (perp=10.212, rec=0.070, cos=0.001), tot_loss_proj:2.121 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.107 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.112 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.106 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.094 (perp=10.212, rec=0.050, cos=0.001), tot_loss_proj:2.109 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.102 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.116 (perp=10.212, rec=0.072, cos=0.001), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.102 (perp=10.212, rec=0.058, cos=0.001), tot_loss_proj:2.100 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.100 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.122 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.112 (perp=10.212, rec=0.068, cos=0.001), tot_loss_proj:2.106 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.100 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.101 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.103 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.115 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.116 (perp=10.212, rec=0.073, cos=0.001), tot_loss_proj:2.105 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.112 (perp=10.212, rec=0.069, cos=0.001), tot_loss_proj:2.099 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.109 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.108 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.097 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.119 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.120 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.103 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.102 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.748 | p: 93.431 | r: 94.082
rouge2     | fm: 64.965 | p: 64.813 | r: 65.144
rougeL     | fm: 80.948 | p: 80.671 | r: 81.272
rougeLsum  | fm: 80.710 | p: 80.509 | r: 80.970
r1fm+r2fm = 158.713

input #41 time: 0:12:12 | total time: 8:34:59


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9993256662189558
highest_index [0]
highest [0.9993256662189558]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9024947881698608 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.850956380367279 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8507697582244873 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8192439079284668 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.8040869832038879 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.8030356168746948 for ['[CLS] internationalgible ever wish superseded cutbe stages ran attracted darectric bandars treaty maple offended assignmentures kitchentakingpling scale lifted larger enough [SEP]']
[Init] best perm rec loss: 0.8009200096130371 for ['[CLS]ures banda larger rangible kitchen wishctrictaking treatypling attracted enough scale maple stages liftedrs offended cut assignment supersededbe international dare ever [SEP]']
[Init] best perm rec loss: 0.7951497435569763 for ['[CLS] kitchen offendedtaking ever dare scale attractedctricuresrs ran maple assignment stagesgible treaty superseded international liftedbepling enough cut wish larger banda [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.752 (perp=12.236, rec=0.295, cos=0.010), tot_loss_proj:3.304 [t=0.31s]
prediction: ['[CLS] authorities forgot filmmakers well forgot kramer poorlyes often forgot legislative officer department. they massacre ibn bright locked. illegal cheap its 9 prison killings [SEP]']
[ 100/2000] tot_loss=2.736 (perp=12.504, rec=0.227, cos=0.008), tot_loss_proj:3.187 [t=0.32s]
prediction: ['[CLS] authorities forgot filmmakers well forgot sees poorly sequence poorly forgot project filmmakers camera a they poorly intoggergger. college threatening your bram school storyline [SEP]']
[ 150/2000] tot_loss=2.480 (perp=11.484, rec=0.177, cos=0.005), tot_loss_proj:3.085 [t=0.32s]
prediction: ['[CLS] filmmakers forgot filmmakers well forgot australian poorly forgot poorly forgot project halfway as a they poorly intoggergger. college schoolesis themed school setting [SEP]']
[ 200/2000] tot_loss=2.428 (perp=11.440, rec=0.138, cos=0.002), tot_loss_proj:3.347 [t=0.32s]
prediction: ['[CLS] filmmakers forgot filmmakers tied one anyone poorly forgot anything forgot project halfway as a they poorly intoggergger. attraction high frightening like school setting [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.270 (perp=10.678, rec=0.131, cos=0.003), tot_loss_proj:2.754 [t=0.32s]
prediction: ['[CLS] filmmakers forgot filmmakers actually including to poorly into anything forgot project scary as a they poorly anythingggergger. attraction high werewolf scary school setting [SEP]']
[ 300/2000] tot_loss=2.248 (perp=10.651, rec=0.115, cos=0.003), tot_loss_proj:3.136 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project well include to poorly into anything forgot include scary as a they re anythingggergger. attraction high anything include school setting [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.133 (perp=10.159, rec=0.098, cos=0.003), tot_loss_proj:2.879 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project the include to poorly into anything anything include scary as a they re forgotggergger. attraction highturing include school setting [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.966 (perp=9.313, rec=0.100, cos=0.003), tot_loss_proj:2.825 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project the poorly to include into anything anything include scary as a they re forgotggergger. attraction high anything include school setting [SEP]']
[ 450/2000] tot_loss=2.116 (perp=10.121, rec=0.090, cos=0.002), tot_loss_proj:2.995 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything anything include scary as a they re forgotggerji. attraction high anything halfway school setting [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.017 (perp=9.641, rec=0.087, cos=0.002), tot_loss_proj:3.068 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything anything include scary as a they rejigger forgot. attraction high anything halfway school setting [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.097 (perp=9.760, rec=0.140, cos=0.005), tot_loss_proj:2.885 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything anything include scary as a they rejigger forgot fatal even. attraction high school setting [SEP]']
[ 600/2000] tot_loss=2.062 (perp=9.760, rec=0.107, cos=0.003), tot_loss_proj:2.896 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything anything include scary as a they rejigger forgot fatal even. attraction high school setting [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.832 (perp=8.719, rec=0.086, cos=0.002), tot_loss_proj:2.752 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything anything include scary as a they rejigger forgot fatal attraction. even high school setting [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.787 (perp=8.444, rec=0.095, cos=0.003), tot_loss_proj:2.655 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything anything include scary as they rejigger forgot a fatal attraction. even high school setting [SEP]']
[ 750/2000] tot_loss=1.819 (perp=8.603, rec=0.096, cos=0.002), tot_loss_proj:2.666 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything anything attraction scary as they rejigger forgot a fatal attraction. even high school setting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.816 (perp=8.603, rec=0.093, cos=0.002), tot_loss_proj:2.656 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything anything attraction scary as they rejigger forgot a fatal attraction. even high school setting [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.765 (perp=8.355, rec=0.092, cos=0.002), tot_loss_proj:2.440 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything anything attraction scary as they rejigger a fatal attraction. even forgot high school setting [SEP]']
[ 900/2000] tot_loss=1.760 (perp=8.355, rec=0.087, cos=0.002), tot_loss_proj:2.439 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything anything attraction scary as they rejigger a fatal attraction. even forgot high school setting [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.748 (perp=8.287, rec=0.088, cos=0.002), tot_loss_proj:2.412 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction. even forgot high school setting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.738 (perp=8.287, rec=0.079, cos=0.002), tot_loss_proj:2.411 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction. even forgot high school setting [SEP]']
[1050/2000] tot_loss=1.744 (perp=8.287, rec=0.084, cos=0.002), tot_loss_proj:2.413 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction. even forgot high school setting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.734 (perp=8.287, rec=0.074, cos=0.002), tot_loss_proj:2.412 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction. even forgot high school setting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.741 (perp=8.287, rec=0.081, cos=0.002), tot_loss_proj:2.412 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction. even forgot high school setting [SEP]']
[1200/2000] tot_loss=1.738 (perp=8.287, rec=0.079, cos=0.002), tot_loss_proj:2.408 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction. even forgot high school setting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.743 (perp=8.287, rec=0.083, cos=0.002), tot_loss_proj:2.409 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction. even forgot high school setting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.743 (perp=8.287, rec=0.084, cos=0.002), tot_loss_proj:2.409 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction. even forgot high school setting [SEP]']
[1350/2000] tot_loss=1.741 (perp=8.287, rec=0.082, cos=0.002), tot_loss_proj:2.415 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction. even forgot high school setting [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.722 (perp=8.189, rec=0.082, cos=0.002), tot_loss_proj:2.394 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.715 (perp=8.189, rec=0.075, cos=0.002), tot_loss_proj:2.400 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
[1500/2000] tot_loss=1.719 (perp=8.189, rec=0.079, cos=0.002), tot_loss_proj:2.397 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include into anything attraction anything scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.717 (perp=8.163, rec=0.083, cos=0.002), tot_loss_proj:2.375 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include attraction into anything anything scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.715 (perp=8.163, rec=0.081, cos=0.002), tot_loss_proj:2.373 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include attraction into anything anything scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
[1650/2000] tot_loss=1.749 (perp=8.356, rec=0.077, cos=0.002), tot_loss_proj:2.459 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include attraction into anything halfway scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.747 (perp=8.356, rec=0.074, cos=0.002), tot_loss_proj:2.462 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include attraction into anything halfway scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.754 (perp=8.356, rec=0.081, cos=0.002), tot_loss_proj:2.464 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include attraction into anything halfway scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
[1800/2000] tot_loss=1.753 (perp=8.356, rec=0.081, cos=0.002), tot_loss_proj:2.459 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include attraction into anything halfway scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.769 (perp=8.356, rec=0.096, cos=0.002), tot_loss_proj:2.461 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include attraction into anything halfway scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.748 (perp=8.356, rec=0.075, cos=0.002), tot_loss_proj:2.456 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include attraction into anything halfway scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
[1950/2000] tot_loss=1.753 (perp=8.356, rec=0.080, cos=0.002), tot_loss_proj:2.456 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include attraction into anything halfway scary as they rejigger a fatal attraction even forgot high school setting. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.701 (perp=8.097, rec=0.080, cos=0.002), tot_loss_proj:2.299 [t=0.32s]
prediction: ['[CLS] filmmakers forgot project s poorly to include attraction into anything even scary as they rejigger a fatal attraction halfway forgot high school setting. [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] filmmakers forgot project s poorly to include attraction into anything halfway scary as they rejigger a fatal attraction even forgot high school setting. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.878 | p: 92.000 | r: 95.833
rouge2     | fm: 46.809 | p: 45.833 | r: 47.826
rougeL     | fm: 69.388 | p: 68.000 | r: 70.833
rougeLsum  | fm: 69.388 | p: 68.000 | r: 70.833
r1fm+r2fm = 140.686

[Aggregate metrics]:
rouge1     | fm: 93.774 | p: 93.445 | r: 94.148
rouge2     | fm: 64.415 | p: 64.255 | r: 64.650
rougeL     | fm: 80.629 | p: 80.383 | r: 80.986
rougeLsum  | fm: 80.348 | p: 80.105 | r: 80.632
r1fm+r2fm = 158.189

input #42 time: 0:12:36 | total time: 8:47:36


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9992744047341922
highest_index [0]
highest [0.9992744047341922]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9585571885108948 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9186660051345825 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8939396739006042 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.8712818622589111 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.8582090735435486 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.8449648022651672 for ['[CLS] carested royals erica [SEP]']
[Init] best rec loss: 0.838374137878418 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 0.7861190438270569 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7800309062004089 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 0.7766784429550171 for ['[CLS] secondbusck climb [SEP]']
[Init] best perm rec loss: 0.7758037447929382 for ['[CLS]bus climb secondck [SEP]']
[Init] best perm rec loss: 0.7751660943031311 for ['[CLS]ck secondbus climb [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.058 (perp=14.085, rec=0.235, cos=0.007), tot_loss_proj:4.636 [t=0.30s]
prediction: ['[CLS] naististiciss [SEP]']
[ 100/2000] tot_loss=2.440 (perp=11.441, rec=0.149, cos=0.003), tot_loss_proj:2.810 [t=0.31s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 150/2000] tot_loss=2.372 (perp=11.401, rec=0.090, cos=0.002), tot_loss_proj:3.052 [t=0.31s]
prediction: ['[CLS] narcisticiss [SEP]']
[ 200/2000] tot_loss=2.344 (perp=11.401, rec=0.062, cos=0.002), tot_loss_proj:3.045 [t=0.31s]
prediction: ['[CLS] narcisticiss [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.078 (perp=5.048, rec=0.066, cos=0.002), tot_loss_proj:1.092 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.002), tot_loss_proj:1.079 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.064 (perp=5.048, rec=0.053, cos=0.001), tot_loss_proj:1.080 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.082 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.082 (perp=5.048, rec=0.070, cos=0.001), tot_loss_proj:1.077 [t=0.32s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.091 (perp=5.048, rec=0.080, cos=0.002), tot_loss_proj:1.086 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.076 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.080 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.064 (perp=5.048, rec=0.053, cos=0.001), tot_loss_proj:1.081 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.084 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.073 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.080 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.079 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.076 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.081 (perp=5.048, rec=0.070, cos=0.001), tot_loss_proj:1.080 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.065 (perp=5.048, rec=0.054, cos=0.001), tot_loss_proj:1.074 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.084 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.082 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.083 (perp=5.048, rec=0.072, cos=0.001), tot_loss_proj:1.080 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.081 (perp=5.048, rec=0.070, cos=0.001), tot_loss_proj:1.077 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.077 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.060 (perp=5.048, rec=0.049, cos=0.001), tot_loss_proj:1.099 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.087 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.079 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.082 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.082 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.091 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.082 (perp=5.048, rec=0.071, cos=0.001), tot_loss_proj:1.080 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.057 (perp=5.048, rec=0.046, cos=0.001), tot_loss_proj:1.077 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.081 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.081 (perp=5.048, rec=0.070, cos=0.001), tot_loss_proj:1.082 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.058 (perp=5.048, rec=0.047, cos=0.001), tot_loss_proj:1.067 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.084 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.084 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.049 (perp=5.048, rec=0.038, cos=0.001), tot_loss_proj:1.084 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.073 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.071 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.917 | p: 93.587 | r: 94.273
rouge2     | fm: 65.277 | p: 65.076 | r: 65.508
rougeL     | fm: 81.111 | p: 80.857 | r: 81.383
rougeLsum  | fm: 81.009 | p: 80.721 | r: 81.251
r1fm+r2fm = 159.194

input #43 time: 0:12:14 | total time: 8:59:50


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.999241339613289
highest_index [0]
highest [0.999241339613289]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9846301078796387 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9551560282707214 for ['[CLS] photo led breath sound coin day opponents allies joycevel move throne doin head huge guest perhaps ; his gaze saddle decide willise new great ¡wark grand [SEP]']
[Init] best rec loss: 0.9332205057144165 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.9303698539733887 for ['[CLS]hat since shotsisance morning her wound ji living appealing fifapis aus braun filmed james saved ian service person alias motion inclination age storage hyper heard wind any [SEP]']
[Init] best rec loss: 0.9298970699310303 for ['[CLS] balls greenhouse with punch por new oscar shut puzzle crunch interactive role substanceport those beg than units aged host roller alphabet defeat writing meet guinea one then percentage [SEP]']
[Init] best rec loss: 0.9099108576774597 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best perm rec loss: 0.9085978269577026 for ['[CLS] ; raceway contact harbor slave settled haley brow graphic nation hee fatty co contains rock hello formerly data blue landonosihair capacity s illustrated ltd contestants intent comedy [SEP]']
[Init] best perm rec loss: 0.9083760380744934 for ['[CLS] hello contestantsosi comedy co nation hee haley settled rock intent s slave harbor graphic ltd illustrated contact landon formerly ; containshair brow capacity blue fatty raceway data [SEP]']
[Init] best perm rec loss: 0.9059186577796936 for ['[CLS] contains sosi hello fatty harbor co intent blue ltd settled nationhair brow graphic raceway ; comedy haley illustrated rock hee contestants data formerly capacity slave landon contact [SEP]']
[Init] best perm rec loss: 0.9030168056488037 for ['[CLS] harbor contact hello hee nation data slave formerly settled s ltd ; intent capacity landon comedy graphicosi rock haley blue raceway fatty co contestants illustrated containshair brow [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.457 (perp=10.872, rec=0.274, cos=0.008), tot_loss_proj:3.149 [t=0.31s]
prediction: ['[CLS] the lost in translation routine translation were eliminated the worst humans the conflict cleared random fright routine endings absurd fright timeieg lost. phrase lose corndin plot [SEP]']
[ 100/2000] tot_loss=2.128 (perp=9.757, rec=0.172, cos=0.004), tot_loss_proj:2.504 [t=0.31s]
prediction: ['[CLS] been lost in translation routine translation in routine the fright 囗 the fright uses routine routine routine translation radical absurd. ( lost. phrased frightpolis movie [SEP]']
[ 150/2000] tot_loss=2.004 (perp=9.312, rec=0.138, cos=0.004), tot_loss_proj:2.378 [t=0.31s]
prediction: ['[CLS] has lost in translation routine translation inizes the hollywood premise the fright in routine routine the execution slack slack. aalic. anotherless slack kills movie [SEP]']
[ 200/2000] tot_loss=1.956 (perp=9.180, rec=0.117, cos=0.003), tot_loss_proj:2.373 [t=0.32s]
prediction: ['[CLS] been lost. translation routine translation inizes the hollywood premise the fright in routine routine the execution slack slack. whichalic. anotherizes slack execution hollywood [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.064 (perp=9.618, rec=0.137, cos=0.003), tot_loss_proj:2.537 [t=0.32s]
prediction: ['[CLS] has lost. translation routine translation inizes the hollywood premise the fright the routine routine the execution slack slack. inalic. anotherizes fright execution hollywood [SEP]']
[ 300/2000] tot_loss=2.476 (perp=11.142, rec=0.241, cos=0.007), tot_loss_proj:2.783 [t=0.32s]
prediction: ['[CLS] has lost looked translation another translation in ں the hollywood premise. fright the routine routinethic execution slack slack ᅡesalic. whichizes mis plot me [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.105 (perp=9.731, rec=0.155, cos=0.004), tot_loss_proj:2.594 [t=0.32s]
prediction: ['[CLS] has lost been translation another ᅡ translation in ں the hollywood premise. fright the routine routine the execution slack slackizesalic. whichizes its plot his [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.982 (perp=9.281, rec=0.123, cos=0.003), tot_loss_proj:2.517 [t=0.32s]
prediction: ['[CLS] has lost been translation another ᅡ translation inurgent the hollywood premise of fright the routine slack the execution slack slackizesalic. whichizes its premise. [SEP]']
[ 450/2000] tot_loss=2.040 (perp=9.607, rec=0.116, cos=0.003), tot_loss_proj:2.582 [t=0.32s]
prediction: ['[CLS] has lost been translation another ᅡ translation in execution the hollywood premise i fright the routine slack the execution. slackizesalic. whichizes the premise. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.951 (perp=9.179, rec=0.113, cos=0.002), tot_loss_proj:2.446 [t=0.32s]
prediction: ['[CLS] has lost been translation another ᅡ slack in execution the hollywood premiseingfest the routine slack the execution. translationizesalic. whichizes the premise. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.878 (perp=8.826, rec=0.109, cos=0.003), tot_loss_proj:2.361 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ slack in the hollywood premise moviefest the routine slack the execution. translationizesalic. whichizes the premise. [SEP]']
[ 600/2000] tot_loss=1.908 (perp=9.046, rec=0.097, cos=0.002), tot_loss_proj:2.410 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ slack in the hollywood premise realityfest the routine slack the execution. translationizesalic. whichizes the premise. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.840 (perp=8.734, rec=0.091, cos=0.002), tot_loss_proj:2.537 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ slack in the hollywoodalic horrorfest the routine slack the execution. translationizes premise. whichizes the premise. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.796 (perp=8.494, rec=0.095, cos=0.002), tot_loss_proj:2.431 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ slack in the hollywoodalic.fest the routine slack the execution. translationizes premise horror whichizes the premise. [SEP]']
[ 750/2000] tot_loss=1.806 (perp=8.542, rec=0.096, cos=0.002), tot_loss_proj:2.484 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ slack in the hollywoodalic.fest the routine slack the execution. translationizes premise reality whichizes the premise. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.765 (perp=8.389, rec=0.085, cos=0.002), tot_loss_proj:2.315 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ absurd in the hollywoodalicfest. the routine slack the execution. translationizes premise reality whichizes the premise. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.716 (perp=8.111, rec=0.092, cos=0.002), tot_loss_proj:2.182 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ translation in the hollywoodalicfest. the routine slack the execution. absurdizes premise fright whichizes the premise. [SEP]']
[ 900/2000] tot_loss=1.704 (perp=8.111, rec=0.079, cos=0.002), tot_loss_proj:2.186 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ translation in the hollywoodalicfest. the routine slack the execution. absurdizes premise fright whichizes the premise. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.743 (perp=8.303, rec=0.080, cos=0.002), tot_loss_proj:2.179 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ translation in the hollywoodalicfest. it routine slack the execution. absurdizes the fright whichizes premise premise. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.724 (perp=8.176, rec=0.087, cos=0.002), tot_loss_proj:2.185 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ translation in the hollywoodalicfest. it routine. the execution slack absurdizes the fright whichizes premise premise. [SEP]']
[1050/2000] tot_loss=1.729 (perp=8.176, rec=0.092, cos=0.002), tot_loss_proj:2.192 [t=0.31s]
prediction: ['[CLS] has lost been translation in another ᅡ translation in the hollywoodalicfest. it routine. the execution slack absurdizes the fright whichizes premise premise. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.725 (perp=8.176, rec=0.088, cos=0.002), tot_loss_proj:2.190 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ translation in the hollywoodalicfest. it routine. the execution slack absurdizes the fright whichizes premise premise. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.694 (perp=7.981, rec=0.096, cos=0.002), tot_loss_proj:2.087 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ translation in the hollywoodalicfest. it routine. the slack execution absurdizes the fright whichizes premise premise. [SEP]']
[1200/2000] tot_loss=1.677 (perp=7.981, rec=0.079, cos=0.002), tot_loss_proj:2.091 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ translation in the hollywoodalicfest. it routine. the slack execution absurdizes the fright whichizes premise premise. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.677 (perp=7.981, rec=0.079, cos=0.002), tot_loss_proj:2.089 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ translation in the hollywoodalicfest. it routine. the slack execution absurdizes the fright whichizes premise premise. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.693 (perp=7.981, rec=0.095, cos=0.002), tot_loss_proj:2.088 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ translation in the hollywoodalicfest. it routine. the slack execution absurdizes the fright whichizes premise premise. [SEP]']
[1350/2000] tot_loss=1.686 (perp=7.981, rec=0.088, cos=0.002), tot_loss_proj:2.084 [t=0.32s]
prediction: ['[CLS] has lost been translation in another ᅡ translation in the hollywoodalicfest. it routine. the slack execution absurdizes the fright whichizes premise premise. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.638 (perp=7.777, rec=0.081, cos=0.002), tot_loss_proj:2.049 [t=0.33s]
prediction: ['[CLS] has been lost translation in another ᅡ translation in the hollywoodalicfest. it routine. the slack execution absurdizes the fright whichizes premise premise. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.624 (perp=7.658, rec=0.090, cos=0.002), tot_loss_proj:2.042 [t=0.32s]
prediction: ['[CLS] has been lost translation in another ᅡ translation in the hollywood absurdfest. it routine. the slack executionalicizes the fright whichizes premise premise. [SEP]']
[1500/2000] tot_loss=1.625 (perp=7.658, rec=0.092, cos=0.002), tot_loss_proj:2.044 [t=0.32s]
prediction: ['[CLS] has been lost translation in another ᅡ translation in the hollywood absurdfest. it routine. the slack executionalicizes the fright whichizes premise premise. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.604 (perp=7.597, rec=0.082, cos=0.002), tot_loss_proj:2.149 [t=0.32s]
prediction: ['[CLS] has been lost translation in another ᅡ translation. the hollywood absurdfest. it routine in the slack executionalicizes the fright whichizes premise premise. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.604 (perp=7.597, rec=0.082, cos=0.002), tot_loss_proj:2.153 [t=0.32s]
prediction: ['[CLS] has been lost translation in another ᅡ translation. the hollywood absurdfest. it routine in the slack executionalicizes the fright whichizes premise premise. [SEP]']
[1650/2000] tot_loss=1.608 (perp=7.597, rec=0.087, cos=0.002), tot_loss_proj:2.154 [t=0.32s]
prediction: ['[CLS] has been lost translation in another ᅡ translation. the hollywood absurdfest. it routine in the slack executionalicizes the fright whichizes premise premise. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.603 (perp=7.597, rec=0.081, cos=0.002), tot_loss_proj:2.145 [t=0.31s]
prediction: ['[CLS] has been lost translation in another ᅡ translation. the hollywood absurdfest. it routine in the slack executionalicizes the fright whichizes premise premise. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.587 (perp=7.496, rec=0.085, cos=0.002), tot_loss_proj:2.122 [t=0.31s]
prediction: ['[CLS] has been lost translation in another ᅡ translation. the hollywood absurdfest. it routineizes the slack executionalic in the fright whichizes premise premise. [SEP]']
[1800/2000] tot_loss=1.649 (perp=7.853, rec=0.077, cos=0.002), tot_loss_proj:2.201 [t=0.32s]
prediction: ['[CLS] has been lost translation in another ᅡ translation. the hollywood absurdfest. it routineizes the slack executionalic the the fright whichizes premise premise. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.633 (perp=7.813, rec=0.068, cos=0.002), tot_loss_proj:2.133 [t=0.32s]
prediction: ['[CLS] has been lost translation in another ᅡ translation. the hollywood absurdfest. it routineizes the slack executionalic the premise fright whichizes the premise. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.566 (perp=7.424, rec=0.079, cos=0.002), tot_loss_proj:2.070 [t=0.31s]
prediction: ['[CLS] has been lost translation in another ᅡ translation. the hollywood absurdfest. it routineizes the slack execution the premisealic fright whichizes the premise. [SEP]']
[1950/2000] tot_loss=1.567 (perp=7.424, rec=0.081, cos=0.002), tot_loss_proj:2.074 [t=0.32s]
prediction: ['[CLS] has been lost translation in another ᅡ translation. the hollywood absurdfest. it routineizes the slack execution the premisealic fright whichizes the premise. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.563 (perp=7.424, rec=0.076, cos=0.002), tot_loss_proj:2.069 [t=0.32s]
prediction: ['[CLS] has been lost translation in another ᅡ translation. the hollywood absurdfest. it routineizes the slack execution the premisealic fright whichizes the premise. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] has been lost translation in another ᅡ translation. the hollywood absurdfest. it routineizes the slack execution the premisealic fright whichizes the premise. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.565 | p: 69.565 | r: 69.565
rouge2     | fm: 31.818 | p: 31.818 | r: 31.818
rougeL     | fm: 60.870 | p: 60.870 | r: 60.870
rougeLsum  | fm: 60.870 | p: 60.870 | r: 60.870
r1fm+r2fm = 101.383

[Aggregate metrics]:
rouge1     | fm: 93.389 | p: 93.083 | r: 93.732
rouge2     | fm: 64.794 | p: 64.597 | r: 64.956
rougeL     | fm: 80.690 | p: 80.474 | r: 80.934
rougeLsum  | fm: 80.457 | p: 80.232 | r: 80.765
r1fm+r2fm = 158.182

input #44 time: 0:12:33 | total time: 9:12:24


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9993991212668459
highest_index [0]
highest [0.9993991212668459]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.9830456972122192 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.9407480955123901 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.9158504009246826 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.9092965722084045 for ['[CLS] look greater applications still decay line learning reagan ata alley fact isn starboard thorne portion stepped women5 bee defense producing ł wingtlestation hold net festival [SEP]']
[Init] best rec loss: 0.8998561501502991 for ['[CLS] need invitation small cross hot no sk cello deep leader motions harry slide guest pity ash nepal rather ashleyinsman previous walt mclean prix van zoneition [SEP]']
[Init] best rec loss: 0.8693260550498962 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.8662326335906982 for ['[CLS]2 ku tree operatedtiv bore murmured single v few letter military status special taste skin joan football ( curtis enclosedlanda gentry five entrance whoa around via [SEP]']
[Init] best perm rec loss: 0.8632333874702454 for ['[CLS] letter fivetiv via v around skin tree murmured taste special single enclosed entrance military curtis joan borelanda football gentry status2 ku ( operated few whoa [SEP]']
[Init] best perm rec loss: 0.8617848753929138 for ['[CLS] v enclosed special operated whoa military tree around via football letter ku status entrance bore skin five gentry ( curtis single murmuredlandativ taste2 few joan [SEP]']
[Init] best perm rec loss: 0.8599802851676941 for ['[CLS] ku curtis few operated military skin bore enclosed tree statustiv murmured letter ( whoa around football five entrance joan v gentry single taste2 via speciallanda [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.713 (perp=11.731, rec=0.350, cos=0.017), tot_loss_proj:3.273 [t=0.31s]
prediction: ['[CLS]pe like - apartments traffic ranginglag apparent exercise ondown than campaign ( sit gi show markers pinned - hanging singhine episodes - old who programmed [SEP]']
[ 100/2000] tot_loss=2.295 (perp=10.125, rec=0.263, cos=0.006), tot_loss_proj:3.486 [t=0.32s]
prediction: ['[CLS] - - - focus ballistic than - - exercise - - than death than sit gi show - - - terracesdy addition inch - bow prove attitude [SEP]']
[ 150/2000] tot_loss=1.840 (perp=8.245, rec=0.186, cos=0.005), tot_loss_proj:2.542 [t=0.31s]
prediction: ['[CLS] - - - - shots than - - movements - this than that than sit shelf show - - -gly movieopmm - bowelmm [SEP]']
[ 200/2000] tot_loss=2.013 (perp=9.222, rec=0.165, cos=0.003), tot_loss_proj:2.852 [t=0.32s]
prediction: ['[CLS] shelf - - -el thanming long movements on this than that than shelf shoot exercise - - - fractured movie grinmm - bowelmm [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.965 (perp=9.073, rec=0.147, cos=0.003), tot_loss_proj:2.732 [t=0.32s]
prediction: ['[CLS] shelf - - -elming than long movements on this than this than shelf shoot exercise - - - exercise drama inmm - bowelmm [SEP]']
[ 300/2000] tot_loss=1.939 (perp=8.993, rec=0.137, cos=0.004), tot_loss_proj:2.749 [t=0.32s]
prediction: ['[CLS] shelf - - -elming than long movements on this than this than long shoot exercise - - - exercise drama inmm shoot bowelish [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.896 (perp=8.893, rec=0.115, cos=0.002), tot_loss_proj:2.618 [t=0.32s]
prediction: ['[CLS] than - - -el crime than long movements on this shelf this than long shoot exercise, - - exercise drama inmm shoot bowelly [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.807 (perp=8.493, rec=0.107, cos=0.002), tot_loss_proj:2.692 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements crime on this shelf in than long shoot exercise, - - exercise drama inmm shoot bowely [SEP]']
[ 450/2000] tot_loss=1.799 (perp=8.493, rec=0.099, cos=0.002), tot_loss_proj:2.699 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements crime on this shelf in than long shoot exercise, - - exercise drama inmm shoot bowely [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.872 (perp=8.745, rec=0.120, cos=0.002), tot_loss_proj:2.665 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements crime on this shelf in - long shoot exercise, -age gi drama inmm shoot bowely [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.804 (perp=8.470, rec=0.108, cos=0.002), tot_loss_proj:2.611 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements gi on this shelf in - long shoot exercise, -age crime drama inmm shoot bowely [SEP]']
[ 600/2000] tot_loss=1.874 (perp=8.853, rec=0.102, cos=0.002), tot_loss_proj:2.754 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements gi on this shelf in - long shoot exercise, -age crime drama inmm shoot bowel gi [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.777 (perp=8.393, rec=0.097, cos=0.002), tot_loss_proj:2.562 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements gi on this shelf in - long shoot exercise, -age crime drama gimm shoot bowel in [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.777 (perp=8.410, rec=0.093, cos=0.002), tot_loss_proj:2.537 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements gi on this shelf in - long shoot exercise, - crime drama gimmgi shoot bowel in [SEP]']
[ 750/2000] tot_loss=1.615 (perp=7.668, rec=0.080, cos=0.001), tot_loss_proj:2.248 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements gi on this shelf in - long shoot exercise, - crime drama gimmick shoot bowel in [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.621 (perp=7.668, rec=0.086, cos=0.001), tot_loss_proj:2.248 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements gi on this shelf in - long shoot exercise, - crime drama gimmick shoot bowel in [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.617 (perp=7.668, rec=0.082, cos=0.001), tot_loss_proj:2.249 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements gi on this shelf in - long shoot exercise, - crime drama gimmick shoot bowel in [SEP]']
[ 900/2000] tot_loss=1.617 (perp=7.668, rec=0.082, cos=0.001), tot_loss_proj:2.249 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements gi on this shelf in - long shoot exercise, - crime drama gimmick shoot bowel in [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.603 (perp=7.588, rec=0.084, cos=0.001), tot_loss_proj:2.294 [t=0.31s]
prediction: ['[CLS] than - - -el than - movements, on this shelf in - long shoot exercise gi - crime drama gimmick shoot bowel in [SEP]']
Attempt swap
[1000/2000] tot_loss=1.595 (perp=7.588, rec=0.076, cos=0.001), tot_loss_proj:2.294 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements, on this shelf in - long shoot exercise gi - crime drama gimmick shoot bowel in [SEP]']
[1050/2000] tot_loss=1.601 (perp=7.588, rec=0.082, cos=0.001), tot_loss_proj:2.287 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements, on this shelf in - long shoot exercise gi - crime drama gimmick shoot bowel in [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.584 (perp=7.477, rec=0.087, cos=0.001), tot_loss_proj:2.263 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements, on this shelf in - long shoot exercise gi - shoot drama gimmick crime bowel in [SEP]']
Attempt swap
[1150/2000] tot_loss=1.578 (perp=7.477, rec=0.082, cos=0.001), tot_loss_proj:2.256 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements, on this shelf in - long shoot exercise gi - shoot drama gimmick crime bowel in [SEP]']
[1200/2000] tot_loss=1.592 (perp=7.590, rec=0.073, cos=0.001), tot_loss_proj:2.254 [t=0.32s]
prediction: ['[CLS] than - - -el than - movements, on this shelf in - long point exercise gi - shoot drama gimmick crime bowel in [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.635 (perp=7.752, rec=0.084, cos=0.001), tot_loss_proj:2.279 [t=0.32s]
prediction: ['[CLS] than - - -el than -, movements on this shelf and - long point exercise gi - shoot drama gimmick crime bowel in [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.607 (perp=7.631, rec=0.080, cos=0.001), tot_loss_proj:2.342 [t=0.32s]
prediction: ['[CLS] than - - -el than -, and on this shelf movements - long point exercise gi - shoot drama gimmick crime bowel in [SEP]']
[1350/2000] tot_loss=1.608 (perp=7.631, rec=0.081, cos=0.001), tot_loss_proj:2.338 [t=0.32s]
prediction: ['[CLS] than - - -el than -, and on this shelf movements - long point exercise gi - shoot drama gimmick crime bowel in [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.596 (perp=7.545, rec=0.086, cos=0.001), tot_loss_proj:2.243 [t=0.32s]
prediction: ['[CLS] in - - -el than -, and on this shelf movements - long point exercise gi - shoot drama gimmick crime bowel than [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.565 (perp=7.449, rec=0.074, cos=0.001), tot_loss_proj:2.267 [t=0.31s]
prediction: ['[CLS]el in - - - than -, and on this shelf movements - long point exercise gi - shoot drama gimmick crime bowel than [SEP]']
[1500/2000] tot_loss=1.570 (perp=7.449, rec=0.079, cos=0.001), tot_loss_proj:2.268 [t=0.31s]
prediction: ['[CLS]el in - - - than -, and on this shelf movements - long point exercise gi - shoot drama gimmick crime bowel than [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.526 (perp=7.227, rec=0.079, cos=0.001), tot_loss_proj:2.206 [t=0.32s]
prediction: ['[CLS]el in - - - than -, and on this shelf movements - long point exercise gi - shoot drama gimmick than bowel crime [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.511 (perp=7.170, rec=0.075, cos=0.001), tot_loss_proj:2.185 [t=0.32s]
prediction: ['[CLS]el - in - - than -, and on this shelf movements - long point exercise gi - shoot drama gimmick than bowel crime [SEP]']
[1650/2000] tot_loss=1.514 (perp=7.170, rec=0.079, cos=0.001), tot_loss_proj:2.188 [t=0.32s]
prediction: ['[CLS]el - in - - than -, and on this shelf movements - long point exercise gi - shoot drama gimmick than bowel crime [SEP]']
Attempt swap
[1700/2000] tot_loss=1.509 (perp=7.170, rec=0.074, cos=0.001), tot_loss_proj:2.178 [t=0.32s]
prediction: ['[CLS]el - in - - than -, and on this shelf movements - long point exercise gi - shoot drama gimmick than bowel crime [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.498 (perp=7.093, rec=0.078, cos=0.001), tot_loss_proj:2.142 [t=0.32s]
prediction: ['[CLS]el - in - - than - movements and on this shelf, - long point exercise gi - shoot drama gimmick than bowel crime [SEP]']
[1800/2000] tot_loss=1.495 (perp=7.093, rec=0.075, cos=0.001), tot_loss_proj:2.138 [t=0.32s]
prediction: ['[CLS]el - in - - than - movements and on this shelf, - long point exercise gi - shoot drama gimmick than bowel crime [SEP]']
Attempt swap
[1850/2000] tot_loss=1.508 (perp=7.093, rec=0.088, cos=0.001), tot_loss_proj:2.141 [t=0.32s]
prediction: ['[CLS]el - in - - than - movements and on this shelf, - long point exercise gi - shoot drama gimmick than bowel crime [SEP]']
Attempt swap
[1900/2000] tot_loss=1.498 (perp=7.093, rec=0.078, cos=0.001), tot_loss_proj:2.136 [t=0.32s]
prediction: ['[CLS]el - in - - than - movements and on this shelf, - long point exercise gi - shoot drama gimmick than bowel crime [SEP]']
[1950/2000] tot_loss=1.496 (perp=7.093, rec=0.076, cos=0.001), tot_loss_proj:2.141 [t=0.31s]
prediction: ['[CLS]el - in - - than - movements and on this shelf, - long point exercise gi - shoot drama gimmick than bowel crime [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.471 (perp=6.990, rec=0.072, cos=0.001), tot_loss_proj:2.081 [t=0.32s]
prediction: ['[CLS]el - in - - than - and movements on this shelf, - long point exercise gi - shoot drama gimmick than bowel crime [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS]el - in - - than - movements and on this shelf, - long point exercise gi - shoot drama gimmick than bowel crime [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.105 | p: 40.000 | r: 44.444
rougeLsum  | fm: 42.105 | p: 40.000 | r: 44.444
r1fm+r2fm = 84.211

[Aggregate metrics]:
rouge1     | fm: 93.139 | p: 92.773 | r: 93.589
rouge2     | fm: 63.428 | p: 63.227 | r: 63.570
rougeL     | fm: 79.773 | p: 79.442 | r: 80.091
rougeLsum  | fm: 79.694 | p: 79.416 | r: 80.054
r1fm+r2fm = 156.567

input #45 time: 0:12:34 | total time: 9:24:59


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9992716419435923
highest_index [0]
highest [0.9992716419435923]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9936434030532837 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9782715439796448 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 0.9451197385787964 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9442742466926575 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.943943977355957 for ['[CLS] figures w direction pedrich newspaper [SEP]']
[Init] best rec loss: 0.93889319896698 for ['[CLS] sacked age s between pack lowell [SEP]']
[Init] best rec loss: 0.9386418461799622 for ['[CLS] once definition delgnoeousosed [SEP]']
[Init] best rec loss: 0.9303344488143921 for ['[CLS]tyn tillquisite inside chair fixed [SEP]']
[Init] best rec loss: 0.9122964143753052 for ['[CLS] four no and canada reed donald [SEP]']
[Init] best perm rec loss: 0.9117197394371033 for ['[CLS] donald four canada and reed no [SEP]']
[Init] best perm rec loss: 0.9111770391464233 for ['[CLS] canada reed four donald and no [SEP]']
[Init] best perm rec loss: 0.9110782146453857 for ['[CLS] canada reed donald and no four [SEP]']
[Init] best perm rec loss: 0.9104843735694885 for ['[CLS] canada four and reed no donald [SEP]']
[Init] best perm rec loss: 0.9102483987808228 for ['[CLS] reed no four canada donald and [SEP]']
[Init] best perm rec loss: 0.9100714921951294 for ['[CLS] donald four no and canada reed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.520 (perp=11.576, rec=0.201, cos=0.003), tot_loss_proj:2.845 [t=0.31s]
prediction: ['[CLS] striking extremely striking slick slick staged [SEP]']
[ 100/2000] tot_loss=2.143 (perp=10.101, rec=0.120, cos=0.002), tot_loss_proj:2.431 [t=0.31s]
prediction: ['[CLS] visually visually striking slick slick staged [SEP]']
[ 150/2000] tot_loss=2.108 (perp=10.101, rec=0.087, cos=0.002), tot_loss_proj:2.427 [t=0.31s]
prediction: ['[CLS] visually visually striking slick slick staged [SEP]']
[ 200/2000] tot_loss=2.409 (perp=11.618, rec=0.084, cos=0.002), tot_loss_proj:2.739 [t=0.31s]
prediction: ['[CLS] visually and striking slick slick staged [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.835 (perp=8.707, rec=0.092, cos=0.002), tot_loss_proj:2.065 [t=0.31s]
prediction: ['[CLS] visually striking slick and slick staged [SEP]']
[ 300/2000] tot_loss=1.836 (perp=8.838, rec=0.067, cos=0.001), tot_loss_proj:1.990 [t=0.31s]
prediction: ['[CLS] visually strikingly and slick staged [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.249 (perp=5.916, rec=0.065, cos=0.001), tot_loss_proj:1.249 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.255 (perp=5.916, rec=0.070, cos=0.001), tot_loss_proj:1.248 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 450/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.255 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.254 (perp=5.916, rec=0.069, cos=0.001), tot_loss_proj:1.246 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.231 (perp=5.916, rec=0.046, cos=0.001), tot_loss_proj:1.236 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 600/2000] tot_loss=1.256 (perp=5.916, rec=0.072, cos=0.001), tot_loss_proj:1.241 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.247 (perp=5.916, rec=0.063, cos=0.001), tot_loss_proj:1.245 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.252 (perp=5.916, rec=0.067, cos=0.001), tot_loss_proj:1.253 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 750/2000] tot_loss=1.240 (perp=5.916, rec=0.056, cos=0.001), tot_loss_proj:1.253 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.247 (perp=5.916, rec=0.063, cos=0.001), tot_loss_proj:1.248 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.247 (perp=5.916, rec=0.062, cos=0.001), tot_loss_proj:1.248 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 900/2000] tot_loss=1.242 (perp=5.916, rec=0.057, cos=0.001), tot_loss_proj:1.236 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.248 (perp=5.916, rec=0.063, cos=0.001), tot_loss_proj:1.258 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.254 (perp=5.916, rec=0.070, cos=0.001), tot_loss_proj:1.237 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.244 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.245 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.248 (perp=5.916, rec=0.063, cos=0.001), tot_loss_proj:1.245 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.242 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.247 (perp=5.916, rec=0.062, cos=0.001), tot_loss_proj:1.249 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.234 (perp=5.916, rec=0.050, cos=0.001), tot_loss_proj:1.243 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.245 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.251 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.248 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.247 (perp=5.916, rec=0.063, cos=0.001), tot_loss_proj:1.255 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.249 (perp=5.916, rec=0.064, cos=0.001), tot_loss_proj:1.242 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.248 (perp=5.916, rec=0.064, cos=0.001), tot_loss_proj:1.242 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.237 (perp=5.916, rec=0.052, cos=0.001), tot_loss_proj:1.238 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.257 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.248 (perp=5.916, rec=0.063, cos=0.001), tot_loss_proj:1.255 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.241 (perp=5.916, rec=0.056, cos=0.001), tot_loss_proj:1.237 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.241 (perp=5.916, rec=0.056, cos=0.001), tot_loss_proj:1.253 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.262 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.252 (perp=5.916, rec=0.068, cos=0.001), tot_loss_proj:1.256 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.245 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.256 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.249 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.238 (perp=5.916, rec=0.054, cos=0.001), tot_loss_proj:1.244 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.279 | p: 92.930 | r: 93.717
rouge2     | fm: 64.272 | p: 64.110 | r: 64.391
rougeL     | fm: 80.196 | p: 79.886 | r: 80.507
rougeLsum  | fm: 79.961 | p: 79.685 | r: 80.297
r1fm+r2fm = 157.551

input #46 time: 0:12:14 | total time: 9:37:13


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9992062846425537
highest_index [0]
highest [0.9992062846425537]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6898564100265503 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.685006856918335 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.6834283471107483 for ['[CLS] purse divine rush [SEP]']
[Init] best rec loss: 0.679922878742218 for ['[CLS] network biceps truth [SEP]']
[Init] best rec loss: 0.675014078617096 for ['[CLS] sky next sailed [SEP]']
[Init] best rec loss: 0.6720091104507446 for ['[CLS] salt reality poles [SEP]']
[Init] best perm rec loss: 0.6692437529563904 for ['[CLS] reality salt poles [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.940 (perp=12.756, rec=0.330, cos=0.058), tot_loss_proj:3.879 [t=0.30s]
prediction: ['[CLS] transparent uniquenton [SEP]']
[ 100/2000] tot_loss=2.655 (perp=12.131, rec=0.209, cos=0.019), tot_loss_proj:3.477 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 150/2000] tot_loss=2.565 (perp=12.131, rec=0.132, cos=0.007), tot_loss_proj:3.487 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 200/2000] tot_loss=2.607 (perp=12.131, rec=0.125, cos=0.056), tot_loss_proj:3.488 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.542 (perp=12.131, rec=0.106, cos=0.010), tot_loss_proj:3.501 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 300/2000] tot_loss=2.543 (perp=12.131, rec=0.106, cos=0.011), tot_loss_proj:3.501 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.563 (perp=12.131, rec=0.115, cos=0.022), tot_loss_proj:3.500 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.537 (perp=12.131, rec=0.100, cos=0.011), tot_loss_proj:3.509 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 450/2000] tot_loss=2.535 (perp=12.131, rec=0.102, cos=0.007), tot_loss_proj:3.493 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.536 (perp=12.131, rec=0.102, cos=0.008), tot_loss_proj:3.501 [t=0.32s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.531 (perp=12.131, rec=0.099, cos=0.005), tot_loss_proj:3.501 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 600/2000] tot_loss=2.534 (perp=12.131, rec=0.102, cos=0.006), tot_loss_proj:3.497 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.530 (perp=12.131, rec=0.099, cos=0.005), tot_loss_proj:3.502 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.528 (perp=12.131, rec=0.098, cos=0.004), tot_loss_proj:3.495 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 750/2000] tot_loss=2.531 (perp=12.131, rec=0.101, cos=0.004), tot_loss_proj:3.498 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.530 (perp=12.131, rec=0.099, cos=0.005), tot_loss_proj:3.502 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.503 (perp=12.131, rec=0.073, cos=0.004), tot_loss_proj:3.498 [t=0.31s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 900/2000] tot_loss=2.094 (perp=9.993, rec=0.090, cos=0.005), tot_loss_proj:2.739 [t=0.31s]
prediction: ['[CLS] transparent downright [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.854 (perp=8.803, rec=0.089, cos=0.005), tot_loss_proj:1.901 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.833 (perp=8.803, rec=0.070, cos=0.002), tot_loss_proj:1.904 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.892 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.836 (perp=8.803, rec=0.074, cos=0.002), tot_loss_proj:1.898 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.835 (perp=8.803, rec=0.073, cos=0.002), tot_loss_proj:1.890 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.893 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.891 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.893 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.822 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.874 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.891 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.817 (perp=8.803, rec=0.055, cos=0.002), tot_loss_proj:1.880 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.830 (perp=8.803, rec=0.068, cos=0.002), tot_loss_proj:1.900 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.831 (perp=8.803, rec=0.069, cos=0.002), tot_loss_proj:1.886 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.898 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.822 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.889 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.820 (perp=8.803, rec=0.058, cos=0.002), tot_loss_proj:1.893 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.833 (perp=8.803, rec=0.071, cos=0.002), tot_loss_proj:1.884 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.829 (perp=8.803, rec=0.067, cos=0.002), tot_loss_proj:1.881 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.823 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.879 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.825 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.890 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.814 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.883 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.832 (perp=8.803, rec=0.069, cos=0.002), tot_loss_proj:1.887 [t=0.31s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.436 | p: 93.054 | r: 93.879
rouge2     | fm: 64.956 | p: 64.771 | r: 65.098
rougeL     | fm: 80.555 | p: 80.236 | r: 80.901
rougeLsum  | fm: 80.307 | p: 80.015 | r: 80.619
r1fm+r2fm = 158.392

input #47 time: 0:12:14 | total time: 9:49:27


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9993046789378198
highest_index [0]
highest [0.9993046789378198]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.9524404406547546 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.9282191395759583 for ['[CLS] general deathstle air [SEP]']
[Init] best rec loss: 0.9126362204551697 for ['[CLS] indians * progress elevator [SEP]']
[Init] best rec loss: 0.8897314071655273 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 0.8789585828781128 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 0.8575195670127869 for ['[CLS] yes athletic cobalt mon [SEP]']
[Init] best rec loss: 0.8407836556434631 for ['[CLS]lu natural horizontal work [SEP]']
[Init] best rec loss: 0.8046801686286926 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7999029159545898 for ['[CLS]tutedine graveyard runs [SEP]']
[Init] best perm rec loss: 0.7953615188598633 for ['[CLS]tutedine runs graveyard [SEP]']
[Init] best perm rec loss: 0.794842004776001 for ['[CLS]tute graveyard runsdine [SEP]']
[Init] best perm rec loss: 0.7923369407653809 for ['[CLS]dinetute graveyard runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.697 (perp=12.125, rec=0.258, cos=0.014), tot_loss_proj:2.850 [t=0.30s]
prediction: ['[CLS] rotting under rotting rotting [SEP]']
[ 100/2000] tot_loss=2.457 (perp=11.484, rec=0.156, cos=0.005), tot_loss_proj:2.681 [t=0.31s]
prediction: ['[CLS] rotting under rotting under [SEP]']
[ 150/2000] tot_loss=2.574 (perp=12.211, rec=0.126, cos=0.005), tot_loss_proj:2.836 [t=0.31s]
prediction: ['[CLS] rottingbell rotting under [SEP]']
[ 200/2000] tot_loss=2.555 (perp=12.211, rec=0.109, cos=0.004), tot_loss_proj:2.844 [t=0.31s]
prediction: ['[CLS] rottingbell rotting under [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.238 (perp=10.480, rec=0.137, cos=0.005), tot_loss_proj:2.477 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
[ 300/2000] tot_loss=2.195 (perp=10.480, rec=0.096, cos=0.003), tot_loss_proj:2.493 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.200 (perp=10.480, rec=0.102, cos=0.002), tot_loss_proj:2.492 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.178 (perp=10.480, rec=0.080, cos=0.002), tot_loss_proj:2.488 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
[ 450/2000] tot_loss=2.173 (perp=10.480, rec=0.075, cos=0.002), tot_loss_proj:2.487 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.188 (perp=10.480, rec=0.090, cos=0.002), tot_loss_proj:2.488 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.190 (perp=10.480, rec=0.092, cos=0.002), tot_loss_proj:2.478 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
[ 600/2000] tot_loss=2.184 (perp=10.480, rec=0.086, cos=0.002), tot_loss_proj:2.488 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.190 (perp=10.480, rec=0.092, cos=0.002), tot_loss_proj:2.485 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.174 (perp=10.480, rec=0.077, cos=0.001), tot_loss_proj:2.479 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
[ 750/2000] tot_loss=2.176 (perp=10.480, rec=0.078, cos=0.001), tot_loss_proj:2.495 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.175 (perp=10.480, rec=0.077, cos=0.001), tot_loss_proj:2.488 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.184 (perp=10.480, rec=0.086, cos=0.001), tot_loss_proj:2.494 [t=0.31s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
[ 900/2000] tot_loss=2.226 (perp=10.780, rec=0.068, cos=0.001), tot_loss_proj:2.662 [t=0.31s]
prediction: ['[CLS] underbell rottingy [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.732 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.484 (perp=7.028, rec=0.077, cos=0.001), tot_loss_proj:1.735 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.477 (perp=7.028, rec=0.069, cos=0.001), tot_loss_proj:1.739 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.724 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.470 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.732 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.465 (perp=7.028, rec=0.058, cos=0.001), tot_loss_proj:1.736 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.462 (perp=7.028, rec=0.055, cos=0.001), tot_loss_proj:1.732 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.461 (perp=7.028, rec=0.054, cos=0.001), tot_loss_proj:1.726 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.729 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.481 (perp=7.028, rec=0.074, cos=0.001), tot_loss_proj:1.728 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.463 (perp=7.028, rec=0.056, cos=0.001), tot_loss_proj:1.726 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.729 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.475 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.729 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.486 (perp=7.028, rec=0.079, cos=0.001), tot_loss_proj:1.728 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.723 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.732 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.722 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.731 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.479 (perp=7.028, rec=0.072, cos=0.001), tot_loss_proj:1.737 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.727 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.730 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.737 [t=0.31s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 93.589 | p: 93.197 | r: 94.046
rouge2     | fm: 63.639 | p: 63.442 | r: 63.806
rougeL     | fm: 80.498 | p: 80.223 | r: 80.801
rougeLsum  | fm: 80.519 | p: 80.256 | r: 80.822
r1fm+r2fm = 157.228

input #48 time: 0:12:14 | total time: 10:01:42


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9992295915122433
highest_index [0]
highest [0.9992295915122433]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8306422233581543 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7838373184204102 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.782049298286438 for ['[CLS] saline rang market aspects senate brothersona situation trafficking health follows tel [SEP]']
[Init] best rec loss: 0.7807844281196594 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 0.7642569541931152 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best rec loss: 0.7551743388175964 for ['[CLS] trick jose college legs jockey baby tongue processiza during gmina patrick [SEP]']
[Init] best perm rec loss: 0.7539898753166199 for ['[CLS] legs jose trick tongue gmina collegeiza during jockey patrick process baby [SEP]']
[Init] best perm rec loss: 0.7529492974281311 for ['[CLS] during college patrick jose legs tongue gminaiza jockey baby process trick [SEP]']
[Init] best perm rec loss: 0.7517303824424744 for ['[CLS] joseiza process legs baby trick during gmina college patrick tongue jockey [SEP]']
[Init] best perm rec loss: 0.7487644553184509 for ['[CLS] process college baby tongue patrick legs joseiza trick during jockey gmina [SEP]']
[Init] best perm rec loss: 0.7478135228157043 for ['[CLS] baby during patrick gmina legs tongue jose processiza trick college jockey [SEP]']
[Init] best perm rec loss: 0.7469081878662109 for ['[CLS] jockey tongue during trickiza patrick college jose baby gmina process legs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.133 (perp=13.807, rec=0.327, cos=0.045), tot_loss_proj:3.954 [t=0.30s]
prediction: ['[CLS] jaketort multi contempt most. women mono cream contempt than tropical [SEP]']
[ 100/2000] tot_loss=2.454 (perp=11.046, rec=0.227, cos=0.018), tot_loss_proj:3.439 [t=0.31s]
prediction: ['[CLS] melissatort more contempt possibly single female contempt day contempt than females [SEP]']
[ 150/2000] tot_loss=2.544 (perp=11.898, rec=0.159, cos=0.006), tot_loss_proj:3.519 [t=0.31s]
prediction: ['[CLS] hired could moreuous possibly single female contempt suspiciouslyuous +. [SEP]']
[ 200/2000] tot_loss=2.521 (perp=11.866, rec=0.142, cos=0.006), tot_loss_proj:3.339 [t=0.31s]
prediction: ['[CLS] imagined could moreuous possibly single female contempt alexauous +. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.081 (perp=9.699, rec=0.137, cos=0.005), tot_loss_proj:2.926 [t=0.31s]
prediction: ['[CLS] possibly be moreuous possibly single female contempt the mini population. [SEP]']
[ 300/2000] tot_loss=2.055 (perp=9.699, rec=0.112, cos=0.004), tot_loss_proj:2.926 [t=0.31s]
prediction: ['[CLS] possibly be moreuous possibly single female contempt the mini population. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.102 (perp=9.931, rec=0.112, cos=0.004), tot_loss_proj:2.954 [t=0.31s]
prediction: ['[CLS] alex be more possibly single femaleuous contempt the mini population. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.854 (perp=8.742, rec=0.102, cos=0.004), tot_loss_proj:2.651 [t=0.31s]
prediction: ['[CLS] alex be more possibly single female contemptuous the possibly population. [SEP]']
[ 450/2000] tot_loss=1.907 (perp=8.994, rec=0.105, cos=0.004), tot_loss_proj:2.648 [t=0.31s]
prediction: ['[CLS] alex be more could single female contemptuous the possibly population. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.915 (perp=9.049, rec=0.101, cos=0.003), tot_loss_proj:2.474 [t=0.31s]
prediction: ['[CLS] alex could be more single female contemptuous of possibly population population [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.906 (perp=9.049, rec=0.093, cos=0.003), tot_loss_proj:2.476 [t=0.31s]
prediction: ['[CLS] alex could be more single female contemptuous of possibly population population [SEP]']
[ 600/2000] tot_loss=1.909 (perp=9.049, rec=0.096, cos=0.003), tot_loss_proj:2.475 [t=0.31s]
prediction: ['[CLS] alex could be more single female contemptuous of possibly population population [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.753 (perp=8.232, rec=0.102, cos=0.005), tot_loss_proj:2.238 [t=0.31s]
prediction: ['[CLS] alex could be more possibly female contemptuous of single population population [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.684 (perp=7.863, rec=0.107, cos=0.004), tot_loss_proj:2.236 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of female single population population [SEP]']
[ 750/2000] tot_loss=1.672 (perp=7.863, rec=0.095, cos=0.004), tot_loss_proj:2.242 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of female single population population [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.673 (perp=7.863, rec=0.096, cos=0.004), tot_loss_proj:2.239 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of female single population population [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.624 (perp=7.608, rec=0.098, cos=0.004), tot_loss_proj:2.141 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
[ 900/2000] tot_loss=1.625 (perp=7.608, rec=0.100, cos=0.004), tot_loss_proj:2.138 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.630 (perp=7.608, rec=0.104, cos=0.004), tot_loss_proj:2.137 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1000/2000] tot_loss=1.635 (perp=7.608, rec=0.110, cos=0.004), tot_loss_proj:2.138 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
[1050/2000] tot_loss=1.615 (perp=7.608, rec=0.089, cos=0.003), tot_loss_proj:2.133 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1100/2000] tot_loss=1.617 (perp=7.608, rec=0.092, cos=0.003), tot_loss_proj:2.138 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1150/2000] tot_loss=1.614 (perp=7.608, rec=0.089, cos=0.003), tot_loss_proj:2.138 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
[1200/2000] tot_loss=1.620 (perp=7.608, rec=0.095, cos=0.003), tot_loss_proj:2.138 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1250/2000] tot_loss=1.613 (perp=7.608, rec=0.088, cos=0.003), tot_loss_proj:2.135 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1300/2000] tot_loss=1.628 (perp=7.608, rec=0.103, cos=0.003), tot_loss_proj:2.136 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
[1350/2000] tot_loss=1.612 (perp=7.608, rec=0.087, cos=0.003), tot_loss_proj:2.136 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1400/2000] tot_loss=1.619 (perp=7.608, rec=0.094, cos=0.003), tot_loss_proj:2.134 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1450/2000] tot_loss=1.612 (perp=7.608, rec=0.087, cos=0.003), tot_loss_proj:2.137 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
[1500/2000] tot_loss=1.625 (perp=7.608, rec=0.100, cos=0.003), tot_loss_proj:2.137 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1550/2000] tot_loss=1.615 (perp=7.608, rec=0.090, cos=0.003), tot_loss_proj:2.132 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1600/2000] tot_loss=1.623 (perp=7.608, rec=0.098, cos=0.003), tot_loss_proj:2.140 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
[1650/2000] tot_loss=1.613 (perp=7.608, rec=0.088, cos=0.003), tot_loss_proj:2.132 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1700/2000] tot_loss=1.613 (perp=7.608, rec=0.088, cos=0.003), tot_loss_proj:2.134 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1750/2000] tot_loss=1.620 (perp=7.608, rec=0.095, cos=0.003), tot_loss_proj:2.143 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
[1800/2000] tot_loss=1.619 (perp=7.608, rec=0.094, cos=0.003), tot_loss_proj:2.136 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1850/2000] tot_loss=1.623 (perp=7.608, rec=0.098, cos=0.003), tot_loss_proj:2.136 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[1900/2000] tot_loss=1.615 (perp=7.608, rec=0.090, cos=0.003), tot_loss_proj:2.145 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
[1950/2000] tot_loss=1.614 (perp=7.608, rec=0.089, cos=0.003), tot_loss_proj:2.143 [t=0.31s]
prediction: ['[CLS] alex could be more possibly contemptuous of single female population population [SEP]']
Attempt swap
[2000/2000] tot_loss=1.645 (perp=7.731, rec=0.096, cos=0.003), tot_loss_proj:2.193 [t=0.31s]
prediction: ['[CLS] lightly could be more possibly contemptuous of single female population population [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] alex could be more possibly contemptuous of single female population population [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 43.478 | p: 41.667 | r: 45.455
rougeL     | fm: 80.000 | p: 76.923 | r: 83.333
rougeLsum  | fm: 80.000 | p: 76.923 | r: 83.333
r1fm+r2fm = 131.478

[Aggregate metrics]:
rouge1     | fm: 93.509 | p: 93.090 | r: 94.007
rouge2     | fm: 63.366 | p: 63.176 | r: 63.554
rougeL     | fm: 80.451 | p: 80.123 | r: 80.792
rougeLsum  | fm: 80.317 | p: 79.976 | r: 80.729
r1fm+r2fm = 156.875

input #49 time: 0:12:16 | total time: 10:13:58


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.9992825213653665
highest_index [0]
highest [0.9992825213653665]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.916042685508728 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8354993462562561 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.8352375626564026 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7554234266281128 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7518966794013977 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best perm rec loss: 0.7480208277702332 for ['[CLS]lentham night crisis red byieving accordance bridget [SEP]']
[Init] best perm rec loss: 0.748007595539093 for ['[CLS]lent crisisieving night byham bridget accordance red [SEP]']
[Init] best perm rec loss: 0.7472904324531555 for ['[CLS] nightlent accordanceham by red bridgetieving crisis [SEP]']
[Init] best perm rec loss: 0.7463630437850952 for ['[CLS] night accordance byham redlent bridgetieving crisis [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.558 (perp=10.610, rec=0.389, cos=0.047), tot_loss_proj:3.084 [t=0.30s]
prediction: ['[CLS] some ability lily about clever! spanish poorly clever [SEP]']
[ 100/2000] tot_loss=2.326 (perp=9.872, rec=0.326, cos=0.025), tot_loss_proj:2.910 [t=0.31s]
prediction: ['[CLS] what passing by call fee! english poorly clever [SEP]']
[ 150/2000] tot_loss=2.614 (perp=11.269, rec=0.322, cos=0.038), tot_loss_proj:3.363 [t=0.31s]
prediction: ['[CLS] what passing what call clever & english poorly clever [SEP]']
[ 200/2000] tot_loss=2.120 (perp=9.173, rec=0.266, cos=0.019), tot_loss_proj:2.715 [t=0.31s]
prediction: ["[CLS] what english by call `'english too clever [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.176 (perp=9.342, rec=0.286, cos=0.022), tot_loss_proj:2.552 [t=0.31s]
prediction: ['[CLS] what by english call consider ` english too clever [SEP]']
[ 300/2000] tot_loss=2.357 (perp=10.479, rec=0.247, cos=0.015), tot_loss_proj:2.955 [t=0.31s]
prediction: ['[CLS] what by english call rene ` english too clever [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.085 (perp=9.144, rec=0.241, cos=0.015), tot_loss_proj:2.547 [t=0.31s]
prediction: ['[CLS] what ` english call consider by english too clever [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.068 (perp=9.144, rec=0.226, cos=0.014), tot_loss_proj:2.553 [t=0.31s]
prediction: ['[CLS] what ` english call consider by english too clever [SEP]']
[ 450/2000] tot_loss=2.181 (perp=9.799, rec=0.203, cos=0.017), tot_loss_proj:2.656 [t=0.31s]
prediction: ['[CLS] what ` english call half by english too clever [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.956 (perp=8.859, rec=0.171, cos=0.013), tot_loss_proj:2.416 [t=0.31s]
prediction: ['[CLS] what half ` english call by english too clever [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.794 (perp=8.463, rec=0.098, cos=0.003), tot_loss_proj:2.370 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
[ 600/2000] tot_loss=1.788 (perp=8.463, rec=0.093, cos=0.002), tot_loss_proj:2.373 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.778 (perp=8.463, rec=0.084, cos=0.002), tot_loss_proj:2.375 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.771 (perp=8.463, rec=0.077, cos=0.002), tot_loss_proj:2.379 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
[ 750/2000] tot_loss=1.777 (perp=8.463, rec=0.083, cos=0.002), tot_loss_proj:2.378 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.776 (perp=8.463, rec=0.081, cos=0.002), tot_loss_proj:2.376 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.773 (perp=8.463, rec=0.079, cos=0.002), tot_loss_proj:2.371 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
[ 900/2000] tot_loss=1.763 (perp=8.463, rec=0.069, cos=0.001), tot_loss_proj:2.376 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.776 (perp=8.463, rec=0.082, cos=0.001), tot_loss_proj:2.378 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[1000/2000] tot_loss=1.761 (perp=8.463, rec=0.067, cos=0.001), tot_loss_proj:2.375 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
[1050/2000] tot_loss=1.780 (perp=8.463, rec=0.086, cos=0.001), tot_loss_proj:2.375 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.768 (perp=8.463, rec=0.074, cos=0.001), tot_loss_proj:2.380 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.762 (perp=8.463, rec=0.068, cos=0.001), tot_loss_proj:2.381 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
[1200/2000] tot_loss=1.768 (perp=8.463, rec=0.074, cos=0.001), tot_loss_proj:2.376 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.771 (perp=8.463, rec=0.077, cos=0.001), tot_loss_proj:2.377 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.770 (perp=8.463, rec=0.076, cos=0.001), tot_loss_proj:2.373 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
[1350/2000] tot_loss=1.758 (perp=8.463, rec=0.063, cos=0.001), tot_loss_proj:2.378 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[1400/2000] tot_loss=1.768 (perp=8.463, rec=0.074, cos=0.001), tot_loss_proj:2.376 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.766 (perp=8.463, rec=0.072, cos=0.001), tot_loss_proj:2.376 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
[1500/2000] tot_loss=1.768 (perp=8.463, rec=0.073, cos=0.001), tot_loss_proj:2.372 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.764 (perp=8.463, rec=0.069, cos=0.001), tot_loss_proj:2.383 [t=0.31s]
prediction: ['[CLS] what half ` english call english by too clever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.914 (perp=9.258, rec=0.061, cos=0.001), tot_loss_proj:2.531 [t=0.31s]
prediction: ['[CLS] what half ` the call english by too clever [SEP]']
[1650/2000] tot_loss=1.924 (perp=9.258, rec=0.071, cos=0.001), tot_loss_proj:2.531 [t=0.31s]
prediction: ['[CLS] what half ` the call english by too clever [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.787 (perp=8.552, rec=0.076, cos=0.001), tot_loss_proj:2.501 [t=0.31s]
prediction: ['[CLS] what half ` call the english by too clever [SEP]']
Attempt swap
[1750/2000] tot_loss=1.782 (perp=8.552, rec=0.070, cos=0.001), tot_loss_proj:2.498 [t=0.31s]
prediction: ['[CLS] what half ` call the english by too clever [SEP]']
[1800/2000] tot_loss=1.786 (perp=8.552, rec=0.074, cos=0.001), tot_loss_proj:2.498 [t=0.31s]
prediction: ['[CLS] what half ` call the english by too clever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.780 (perp=8.552, rec=0.068, cos=0.001), tot_loss_proj:2.496 [t=0.31s]
prediction: ['[CLS] what half ` call the english by too clever [SEP]']
Attempt swap
[1900/2000] tot_loss=1.778 (perp=8.552, rec=0.066, cos=0.001), tot_loss_proj:2.501 [t=0.31s]
prediction: ['[CLS] what half ` call the english by too clever [SEP]']
[1950/2000] tot_loss=1.792 (perp=8.552, rec=0.080, cos=0.001), tot_loss_proj:2.501 [t=0.31s]
prediction: ['[CLS] what half ` call the english by too clever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.779 (perp=8.552, rec=0.067, cos=0.001), tot_loss_proj:2.505 [t=0.31s]
prediction: ['[CLS] what half ` call the english by too clever [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what half ` call the english by too clever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 93.597 | p: 93.183 | r: 94.068
rouge2     | fm: 62.780 | p: 62.604 | r: 62.937
rougeL     | fm: 80.318 | p: 80.019 | r: 80.668
rougeLsum  | fm: 80.136 | p: 79.851 | r: 80.542
r1fm+r2fm = 156.377

input #50 time: 0:12:15 | total time: 10:26:14


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9992551736717911
highest_index [0]
highest [0.9992551736717911]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.82987380027771 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.790976345539093 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7392624616622925 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7293180823326111 for ['[CLS] join paying nonsense thought secret mine sans fields sara stench [SEP]']
[Init] best rec loss: 0.7212961316108704 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 0.7118761539459229 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 0.711637020111084 for ['[CLS] symbol blanc australian civil front compact foundation doubt 2018 fitness [SEP]']
[Init] best rec loss: 0.7041337490081787 for ['[CLS] disappointed market in toured literary watching once renamedrak medium [SEP]']
[Init] best perm rec loss: 0.7037991881370544 for ['[CLS] in toured once renamed medium watching market disappointed literaryrak [SEP]']
[Init] best perm rec loss: 0.7014457583427429 for ['[CLS] toured disappointed renamed in once medium literary watching marketrak [SEP]']
[Init] best perm rec loss: 0.7013828754425049 for ['[CLS] market once in renamed medium toured disappointed literaryrak watching [SEP]']
[Init] best perm rec loss: 0.701217532157898 for ['[CLS] disappointed in watching toured once renamed market mediumrak literary [SEP]']
[Init] best perm rec loss: 0.700062096118927 for ['[CLS] literary mediumrak once market watching renamed disappointed toured in [SEP]']
[Init] best perm rec loss: 0.6995334625244141 for ['[CLS] medium renamed disappointed watching market toured oncerak in literary [SEP]']
[Init] best perm rec loss: 0.6992618441581726 for ['[CLS] in toured watching once literary disappointed mediumrak market renamed [SEP]']
[Init] best perm rec loss: 0.6987204551696777 for ['[CLS] in literary toured disappointed renamed market medium once watchingrak [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.594 (perp=10.922, rec=0.357, cos=0.052), tot_loss_proj:3.174 [t=0.31s]
prediction: ['[CLS] because sucks sucks so includes but funny time little little [SEP]']
[ 100/2000] tot_loss=2.409 (perp=10.509, rec=0.278, cos=0.029), tot_loss_proj:3.091 [t=0.31s]
prediction: ['[CLS] but sucks sucks or five devlin funny moment but or [SEP]']
[ 150/2000] tot_loss=2.469 (perp=11.501, rec=0.157, cos=0.011), tot_loss_proj:3.260 [t=0.31s]
prediction: ['[CLS] but sucks sucks or (lynn funny moment has or [SEP]']
[ 200/2000] tot_loss=2.333 (perp=10.997, rec=0.122, cos=0.012), tot_loss_proj:3.146 [t=0.31s]
prediction: ['[CLS] but sucks sucks a twolynn funny moment has or [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.168 (perp=10.151, rec=0.125, cos=0.013), tot_loss_proj:2.945 [t=0.31s]
prediction: ['[CLS] but sucks sucks second orlynn funny moment has. [SEP]']
[ 300/2000] tot_loss=2.065 (perp=9.811, rec=0.098, cos=0.005), tot_loss_proj:2.881 [t=0.31s]
prediction: ['[CLS] but sucks sucks two or harry funny moment has. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.927 (perp=9.127, rec=0.097, cos=0.005), tot_loss_proj:2.730 [t=0.31s]
prediction: ['[CLS] but sucks sucks two or has harry funny moment. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.756 (perp=8.359, rec=0.080, cos=0.005), tot_loss_proj:2.484 [t=0.31s]
prediction: ['[CLS] but two sucks sucks or has harry funny moment. [SEP]']
[ 450/2000] tot_loss=1.762 (perp=8.359, rec=0.086, cos=0.004), tot_loss_proj:2.473 [t=0.31s]
prediction: ['[CLS] but two sucks sucks or has harry funny moment. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.712 (perp=8.150, rec=0.078, cos=0.004), tot_loss_proj:2.495 [t=0.31s]
prediction: ['[CLS] but harry sucks sucks or has two funny moment. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.719 (perp=8.150, rec=0.086, cos=0.004), tot_loss_proj:2.501 [t=0.31s]
prediction: ['[CLS] but harry sucks sucks or has two funny moment. [SEP]']
[ 600/2000] tot_loss=1.712 (perp=8.150, rec=0.078, cos=0.004), tot_loss_proj:2.503 [t=0.31s]
prediction: ['[CLS] but harry sucks sucks or has two funny moment. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.642 (perp=7.718, rec=0.095, cos=0.004), tot_loss_proj:2.553 [t=0.31s]
prediction: ['[CLS] but harry sucks or sucks has two funny moment. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.639 (perp=7.718, rec=0.091, cos=0.004), tot_loss_proj:2.551 [t=0.31s]
prediction: ['[CLS] but harry sucks or sucks has two funny moment. [SEP]']
[ 750/2000] tot_loss=1.631 (perp=7.718, rec=0.084, cos=0.004), tot_loss_proj:2.555 [t=0.31s]
prediction: ['[CLS] but harry sucks or sucks has two funny moment. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.633 (perp=7.718, rec=0.086, cos=0.003), tot_loss_proj:2.557 [t=0.31s]
prediction: ['[CLS] but harry sucks or sucks has two funny moment. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.629 (perp=7.718, rec=0.082, cos=0.003), tot_loss_proj:2.557 [t=0.31s]
prediction: ['[CLS] but harry sucks or sucks has two funny moment. [SEP]']
[ 900/2000] tot_loss=1.687 (perp=8.024, rec=0.079, cos=0.003), tot_loss_proj:2.313 [t=0.31s]
prediction: ['[CLS] but harry sucks or, has two funny moment. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.523 (perp=7.208, rec=0.078, cos=0.003), tot_loss_proj:2.401 [t=0.31s]
prediction: ['[CLS] but, harry sucks or has two funny moment. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.440 (perp=6.822, rec=0.073, cos=0.003), tot_loss_proj:2.003 [t=0.31s]
prediction: ['[CLS] harry, but sucks or has two funny moment. [SEP]']
[1050/2000] tot_loss=1.451 (perp=6.822, rec=0.084, cos=0.003), tot_loss_proj:2.002 [t=0.31s]
prediction: ['[CLS] harry, but sucks or has two funny moment. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.500 (perp=7.068, rec=0.084, cos=0.003), tot_loss_proj:2.116 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.492 (perp=7.068, rec=0.075, cos=0.003), tot_loss_proj:2.111 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
[1200/2000] tot_loss=1.495 (perp=7.068, rec=0.078, cos=0.003), tot_loss_proj:2.116 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.493 (perp=7.068, rec=0.076, cos=0.003), tot_loss_proj:2.111 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.476 (perp=7.068, rec=0.060, cos=0.003), tot_loss_proj:2.113 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
[1350/2000] tot_loss=1.491 (perp=7.068, rec=0.074, cos=0.003), tot_loss_proj:2.108 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.499 (perp=7.068, rec=0.083, cos=0.003), tot_loss_proj:2.121 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.494 (perp=7.068, rec=0.078, cos=0.003), tot_loss_proj:2.113 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
[1500/2000] tot_loss=1.500 (perp=7.068, rec=0.083, cos=0.003), tot_loss_proj:2.112 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.490 (perp=7.068, rec=0.073, cos=0.003), tot_loss_proj:2.112 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.494 (perp=7.068, rec=0.077, cos=0.003), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
[1650/2000] tot_loss=1.496 (perp=7.068, rec=0.079, cos=0.003), tot_loss_proj:2.110 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.503 (perp=7.068, rec=0.086, cos=0.003), tot_loss_proj:2.113 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.483 (perp=7.068, rec=0.066, cos=0.003), tot_loss_proj:2.111 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
[1800/2000] tot_loss=1.502 (perp=7.068, rec=0.085, cos=0.003), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.498 (perp=7.068, rec=0.081, cos=0.003), tot_loss_proj:2.116 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.496 (perp=7.068, rec=0.080, cos=0.003), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] mary, but sucks or has two funny moment. [SEP]']
[1950/2000] tot_loss=1.443 (perp=6.822, rec=0.076, cos=0.003), tot_loss_proj:2.009 [t=0.31s]
prediction: ['[CLS] harry, but sucks or has two funny moment. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.442 (perp=6.822, rec=0.075, cos=0.003), tot_loss_proj:2.019 [t=0.31s]
prediction: ['[CLS] harry, but sucks or has two funny moment. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] mary, but sucks or has two funny moment. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 101.111

[Aggregate metrics]:
rouge1     | fm: 93.570 | p: 93.144 | r: 94.029
rouge2     | fm: 61.643 | p: 61.482 | r: 61.858
rougeL     | fm: 79.792 | p: 79.486 | r: 80.141
rougeLsum  | fm: 79.716 | p: 79.378 | r: 80.094
r1fm+r2fm = 155.213

input #51 time: 0:12:15 | total time: 10:38:30


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.9992763455300567
highest_index [0]
highest [0.9992763455300567]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.963121235370636 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9266286492347717 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.899876594543457 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 0.8685681819915771 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.7919116020202637 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7825955748558044 for ['[CLS] confession commentator die [SEP]']
[Init] best rec loss: 0.7059013247489929 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.7036903500556946 for ['[CLS] expected football vocabulary [SEP]']
[Init] best perm rec loss: 0.7030089497566223 for ['[CLS] football vocabulary expected [SEP]']
[Init] best perm rec loss: 0.6973336338996887 for ['[CLS] vocabulary expected football [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.246 (perp=10.529, rec=0.136, cos=0.005), tot_loss_proj:2.203 [t=0.31s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 100/2000] tot_loss=2.177 (perp=10.529, rec=0.069, cos=0.002), tot_loss_proj:2.207 [t=0.31s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 150/2000] tot_loss=2.178 (perp=10.529, rec=0.070, cos=0.002), tot_loss_proj:2.208 [t=0.31s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 200/2000] tot_loss=2.163 (perp=10.529, rec=0.056, cos=0.001), tot_loss_proj:2.209 [t=0.31s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.814 (perp=8.483, rec=0.114, cos=0.004), tot_loss_proj:2.143 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.776 (perp=8.483, rec=0.078, cos=0.002), tot_loss_proj:2.140 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.766 (perp=8.483, rec=0.068, cos=0.001), tot_loss_proj:2.139 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.769 (perp=8.483, rec=0.071, cos=0.001), tot_loss_proj:2.139 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.754 (perp=8.483, rec=0.056, cos=0.001), tot_loss_proj:2.138 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.001), tot_loss_proj:2.138 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.757 (perp=8.483, rec=0.059, cos=0.001), tot_loss_proj:2.139 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.767 (perp=8.483, rec=0.069, cos=0.001), tot_loss_proj:2.139 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.759 (perp=8.483, rec=0.061, cos=0.001), tot_loss_proj:2.139 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.761 (perp=8.483, rec=0.063, cos=0.001), tot_loss_proj:2.133 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.745 (perp=8.483, rec=0.047, cos=0.001), tot_loss_proj:2.132 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.761 (perp=8.483, rec=0.063, cos=0.001), tot_loss_proj:2.133 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.753 (perp=8.483, rec=0.055, cos=0.001), tot_loss_proj:2.139 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.753 (perp=8.483, rec=0.055, cos=0.001), tot_loss_proj:2.127 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.757 (perp=8.483, rec=0.059, cos=0.001), tot_loss_proj:2.132 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.768 (perp=8.483, rec=0.070, cos=0.001), tot_loss_proj:2.135 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.753 (perp=8.483, rec=0.055, cos=0.001), tot_loss_proj:2.135 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.761 (perp=8.483, rec=0.063, cos=0.001), tot_loss_proj:2.132 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.752 (perp=8.483, rec=0.054, cos=0.001), tot_loss_proj:2.140 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.753 (perp=8.483, rec=0.055, cos=0.001), tot_loss_proj:2.143 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.746 (perp=8.483, rec=0.048, cos=0.001), tot_loss_proj:2.133 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.001), tot_loss_proj:2.140 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.751 (perp=8.483, rec=0.053, cos=0.001), tot_loss_proj:2.138 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.001), tot_loss_proj:2.132 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.767 (perp=8.483, rec=0.069, cos=0.001), tot_loss_proj:2.131 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.001), tot_loss_proj:2.134 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.769 (perp=8.483, rec=0.071, cos=0.001), tot_loss_proj:2.134 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.755 (perp=8.483, rec=0.057, cos=0.001), tot_loss_proj:2.132 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.767 (perp=8.483, rec=0.069, cos=0.001), tot_loss_proj:2.132 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.757 (perp=8.483, rec=0.059, cos=0.001), tot_loss_proj:2.137 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.759 (perp=8.483, rec=0.061, cos=0.001), tot_loss_proj:2.136 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.758 (perp=8.483, rec=0.060, cos=0.001), tot_loss_proj:2.134 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.765 (perp=8.483, rec=0.067, cos=0.001), tot_loss_proj:2.126 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.774 (perp=8.483, rec=0.076, cos=0.001), tot_loss_proj:2.128 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.759 (perp=8.483, rec=0.061, cos=0.001), tot_loss_proj:2.135 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.483, rec=0.061, cos=0.001), tot_loss_proj:2.130 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 93.630 | p: 93.232 | r: 94.101
rouge2     | fm: 60.467 | p: 60.303 | r: 60.640
rougeL     | fm: 79.927 | p: 79.617 | r: 80.261
rougeLsum  | fm: 79.696 | p: 79.335 | r: 80.047
r1fm+r2fm = 154.097

input #52 time: 0:12:14 | total time: 10:50:44


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9993464762258305
highest_index [0]
highest [0.9993464762258305]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.9441319108009338 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.861108124256134 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 0.8297326564788818 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 0.7938094735145569 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 0.7197871804237366 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.717457115650177 for ['[CLS] oro edna [SEP]']
[Init] best rec loss: 0.7019818425178528 for ['[CLS] lake highlands [SEP]']
[Init] best rec loss: 0.6925198435783386 for ['[CLS] towerbal [SEP]']
[Init] best rec loss: 0.6808211207389832 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.6769312024116516 for ['[CLS] el peace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.737 (perp=12.492, rec=0.207, cos=0.032), tot_loss_proj:3.329 [t=0.31s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=2.676 (perp=12.492, rec=0.162, cos=0.015), tot_loss_proj:3.335 [t=0.31s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.600 (perp=12.413, rec=0.107, cos=0.010), tot_loss_proj:3.306 [t=0.31s]
prediction: ['[CLS]ing flinch [SEP]']
[ 200/2000] tot_loss=2.552 (perp=12.413, rec=0.068, cos=0.002), tot_loss_proj:3.313 [t=0.31s]
prediction: ['[CLS]ing flinch [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.739 (perp=8.090, rec=0.109, cos=0.012), tot_loss_proj:1.730 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.701 (perp=8.090, rec=0.080, cos=0.002), tot_loss_proj:1.713 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.002), tot_loss_proj:1.707 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.684 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.710 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.707 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.667 (perp=8.090, rec=0.047, cos=0.001), tot_loss_proj:1.712 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.701 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.705 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.682 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.715 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.688 (perp=8.090, rec=0.068, cos=0.001), tot_loss_proj:1.703 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.704 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.715 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.670 (perp=8.090, rec=0.051, cos=0.001), tot_loss_proj:1.702 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.706 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.672 (perp=8.090, rec=0.052, cos=0.001), tot_loss_proj:1.707 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.678 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.708 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.706 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.671 (perp=8.090, rec=0.052, cos=0.001), tot_loss_proj:1.702 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.669 (perp=8.090, rec=0.049, cos=0.001), tot_loss_proj:1.700 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.694 (perp=8.090, rec=0.075, cos=0.001), tot_loss_proj:1.724 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.689 (perp=8.090, rec=0.069, cos=0.001), tot_loss_proj:1.709 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.695 (perp=8.090, rec=0.075, cos=0.001), tot_loss_proj:1.710 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.674 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.694 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.686 (perp=8.090, rec=0.067, cos=0.001), tot_loss_proj:1.704 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.693 (perp=8.090, rec=0.074, cos=0.001), tot_loss_proj:1.696 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.717 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.666 (perp=8.090, rec=0.047, cos=0.001), tot_loss_proj:1.706 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.698 (perp=8.090, rec=0.079, cos=0.001), tot_loss_proj:1.712 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.682 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.717 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.715 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.685 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.703 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.689 (perp=8.090, rec=0.070, cos=0.001), tot_loss_proj:1.700 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.670 (perp=8.090, rec=0.051, cos=0.001), tot_loss_proj:1.694 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.707 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.704 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.690 (perp=8.090, rec=0.071, cos=0.001), tot_loss_proj:1.709 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.791 | p: 93.396 | r: 94.208
rouge2     | fm: 60.999 | p: 60.822 | r: 61.231
rougeL     | fm: 80.169 | p: 79.869 | r: 80.512
rougeLsum  | fm: 79.943 | p: 79.633 | r: 80.305
r1fm+r2fm = 154.790

input #53 time: 0:12:12 | total time: 11:02:57


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9991882720479814
highest_index [0]
highest [0.9991882720479814]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.951274037361145 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.800615668296814 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7578738927841187 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.715196967124939 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.7060219645500183 for ['[CLS] deployment bro [SEP]']
[Init] best perm rec loss: 0.7029538750648499 for ['[CLS] bro deployment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.750 (perp=11.487, rec=0.388, cos=0.064), tot_loss_proj:3.109 [t=0.30s]
prediction: ['[CLS] topics intense [SEP]']
[ 100/2000] tot_loss=2.526 (perp=11.553, rec=0.183, cos=0.032), tot_loss_proj:2.860 [t=0.31s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.422 (perp=11.553, rec=0.107, cos=0.005), tot_loss_proj:2.886 [t=0.31s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.401 (perp=11.553, rec=0.087, cos=0.003), tot_loss_proj:2.885 [t=0.31s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.740 (perp=8.198, rec=0.097, cos=0.004), tot_loss_proj:1.756 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.701 (perp=8.198, rec=0.059, cos=0.003), tot_loss_proj:1.737 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.712 (perp=8.198, rec=0.070, cos=0.002), tot_loss_proj:1.737 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.695 (perp=8.198, rec=0.054, cos=0.002), tot_loss_proj:1.741 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.720 (perp=8.198, rec=0.078, cos=0.002), tot_loss_proj:1.747 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.755 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.694 (perp=8.198, rec=0.053, cos=0.002), tot_loss_proj:1.745 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.714 (perp=8.198, rec=0.073, cos=0.002), tot_loss_proj:1.742 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.690 (perp=8.198, rec=0.049, cos=0.002), tot_loss_proj:1.738 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.755 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.700 (perp=8.198, rec=0.059, cos=0.002), tot_loss_proj:1.739 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.708 (perp=8.198, rec=0.067, cos=0.002), tot_loss_proj:1.746 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.707 (perp=8.198, rec=0.065, cos=0.002), tot_loss_proj:1.747 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.754 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.734 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.749 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.760 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.704 (perp=8.198, rec=0.063, cos=0.002), tot_loss_proj:1.748 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.705 (perp=8.198, rec=0.063, cos=0.002), tot_loss_proj:1.738 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.726 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.694 (perp=8.198, rec=0.053, cos=0.002), tot_loss_proj:1.742 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.698 (perp=8.198, rec=0.056, cos=0.002), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.750 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.747 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.696 (perp=8.198, rec=0.054, cos=0.002), tot_loss_proj:1.737 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.698 (perp=8.198, rec=0.057, cos=0.002), tot_loss_proj:1.738 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.692 (perp=8.198, rec=0.051, cos=0.002), tot_loss_proj:1.748 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.694 (perp=8.198, rec=0.053, cos=0.002), tot_loss_proj:1.742 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.706 (perp=8.198, rec=0.065, cos=0.002), tot_loss_proj:1.741 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.691 (perp=8.198, rec=0.049, cos=0.002), tot_loss_proj:1.744 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.742 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.696 (perp=8.198, rec=0.055, cos=0.002), tot_loss_proj:1.746 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.738 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.747 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.704 (perp=8.198, rec=0.063, cos=0.002), tot_loss_proj:1.744 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.707 (perp=8.198, rec=0.065, cos=0.002), tot_loss_proj:1.738 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.851 | p: 93.454 | r: 94.293
rouge2     | fm: 62.019 | p: 61.846 | r: 62.235
rougeL     | fm: 80.484 | p: 80.198 | r: 80.813
rougeLsum  | fm: 80.424 | p: 80.101 | r: 80.734
r1fm+r2fm = 155.870

input #54 time: 0:12:12 | total time: 11:15:10


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9991211217935093
highest_index [0]
highest [0.9991211217935093]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.9132943749427795 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.8691973090171814 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7825909852981567 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 0.7703865766525269 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7676177024841309 for ['[CLS] kirk door regional [SEP]']
[Init] best rec loss: 0.7562519907951355 for ['[CLS] single argentine patent [SEP]']
[Init] best rec loss: 0.7525168657302856 for ['[CLS] plantesthesia pr [SEP]']
[Init] best rec loss: 0.7199910283088684 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.7092044949531555 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.705683171749115 for ['[CLS] holly stride post [SEP]']
[Init] best perm rec loss: 0.7020367383956909 for ['[CLS] post stride holly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.187 (perp=8.940, rec=0.321, cos=0.078), tot_loss_proj:3.694 [t=0.31s]
prediction: ['[CLS] settles easily settled [SEP]']
[ 100/2000] tot_loss=2.454 (perp=11.529, rec=0.136, cos=0.012), tot_loss_proj:3.851 [t=0.31s]
prediction: ['[CLS] settle easily settles [SEP]']
[ 150/2000] tot_loss=1.824 (perp=8.688, rec=0.084, cos=0.002), tot_loss_proj:2.254 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[ 200/2000] tot_loss=1.813 (perp=8.688, rec=0.069, cos=0.007), tot_loss_proj:2.261 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.804 (perp=8.688, rec=0.064, cos=0.002), tot_loss_proj:2.263 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[ 300/2000] tot_loss=1.807 (perp=8.688, rec=0.068, cos=0.002), tot_loss_proj:2.254 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.794 (perp=8.688, rec=0.054, cos=0.002), tot_loss_proj:2.263 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.802 (perp=8.688, rec=0.063, cos=0.002), tot_loss_proj:2.260 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[ 450/2000] tot_loss=1.793 (perp=8.688, rec=0.054, cos=0.002), tot_loss_proj:2.255 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.804 (perp=8.688, rec=0.065, cos=0.002), tot_loss_proj:2.264 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.792 (perp=8.688, rec=0.053, cos=0.002), tot_loss_proj:2.258 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[ 600/2000] tot_loss=1.804 (perp=8.688, rec=0.065, cos=0.002), tot_loss_proj:2.260 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.797 (perp=8.688, rec=0.057, cos=0.002), tot_loss_proj:2.251 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.816 (perp=8.688, rec=0.077, cos=0.002), tot_loss_proj:2.254 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[ 750/2000] tot_loss=1.810 (perp=8.688, rec=0.071, cos=0.002), tot_loss_proj:2.255 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.805 (perp=8.688, rec=0.066, cos=0.002), tot_loss_proj:2.255 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.817 (perp=8.688, rec=0.078, cos=0.002), tot_loss_proj:2.257 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[ 900/2000] tot_loss=1.806 (perp=8.688, rec=0.067, cos=0.002), tot_loss_proj:2.257 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.809 (perp=8.688, rec=0.069, cos=0.002), tot_loss_proj:2.250 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1000/2000] tot_loss=1.799 (perp=8.688, rec=0.060, cos=0.002), tot_loss_proj:2.255 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[1050/2000] tot_loss=1.807 (perp=8.688, rec=0.068, cos=0.002), tot_loss_proj:2.263 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1100/2000] tot_loss=1.798 (perp=8.688, rec=0.059, cos=0.002), tot_loss_proj:2.255 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1150/2000] tot_loss=1.802 (perp=8.688, rec=0.062, cos=0.002), tot_loss_proj:2.260 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[1200/2000] tot_loss=1.800 (perp=8.688, rec=0.060, cos=0.002), tot_loss_proj:2.255 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1250/2000] tot_loss=1.796 (perp=8.688, rec=0.057, cos=0.002), tot_loss_proj:2.260 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1300/2000] tot_loss=1.803 (perp=8.688, rec=0.064, cos=0.002), tot_loss_proj:2.256 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[1350/2000] tot_loss=1.805 (perp=8.688, rec=0.065, cos=0.002), tot_loss_proj:2.259 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1400/2000] tot_loss=1.799 (perp=8.688, rec=0.060, cos=0.002), tot_loss_proj:2.248 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1450/2000] tot_loss=1.811 (perp=8.688, rec=0.071, cos=0.002), tot_loss_proj:2.259 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[1500/2000] tot_loss=1.796 (perp=8.688, rec=0.057, cos=0.002), tot_loss_proj:2.249 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1550/2000] tot_loss=1.795 (perp=8.688, rec=0.055, cos=0.002), tot_loss_proj:2.266 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1600/2000] tot_loss=1.792 (perp=8.688, rec=0.053, cos=0.002), tot_loss_proj:2.258 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[1650/2000] tot_loss=1.802 (perp=8.688, rec=0.063, cos=0.002), tot_loss_proj:2.248 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1700/2000] tot_loss=1.812 (perp=8.688, rec=0.073, cos=0.002), tot_loss_proj:2.259 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1750/2000] tot_loss=1.800 (perp=8.688, rec=0.061, cos=0.002), tot_loss_proj:2.256 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[1800/2000] tot_loss=1.796 (perp=8.688, rec=0.057, cos=0.002), tot_loss_proj:2.249 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1850/2000] tot_loss=1.803 (perp=8.688, rec=0.064, cos=0.002), tot_loss_proj:2.252 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1900/2000] tot_loss=1.814 (perp=8.688, rec=0.075, cos=0.002), tot_loss_proj:2.249 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
[1950/2000] tot_loss=1.799 (perp=8.688, rec=0.059, cos=0.002), tot_loss_proj:2.260 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[2000/2000] tot_loss=1.809 (perp=8.688, rec=0.070, cos=0.002), tot_loss_proj:2.264 [t=0.31s]
prediction: ['[CLS] too easily settles [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] too easily settles [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 94.030 | p: 93.663 | r: 94.440
rouge2     | fm: 61.142 | p: 60.947 | r: 61.313
rougeL     | fm: 80.374 | p: 80.029 | r: 80.777
rougeLsum  | fm: 80.350 | p: 80.087 | r: 80.695
r1fm+r2fm = 155.172

input #55 time: 0:12:13 | total time: 11:27:23


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.999274251901428
highest_index [0]
highest [0.999274251901428]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.9326038360595703 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.9140164256095886 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.9077416062355042 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 0.9074608683586121 for ['[CLS] queer both deep rock proor enter delays baron clarkson territory louisiana cells semi palestine appearance wants still sorbonne connor offered [SEP]']
[Init] best rec loss: 0.897983968257904 for ['[CLS] sergeant atlanticrted further enough face za sincedah had bringing experience claus stereo tour novelmler trails worn korean armed [SEP]']
[Init] best rec loss: 0.892495334148407 for ['[CLS] direction casual pl constitution orange storm beardction norris polo reaches accmity bladetlingus mayer hatch novels chinese ore [SEP]']
[Init] best rec loss: 0.8829934597015381 for ['[CLS] handed almost with leadership emotional obsidian wall households consolation potential spectroscopy defeated been existing organization variables up acquainted cas dive realm [SEP]']
[Init] best perm rec loss: 0.882587730884552 for ['[CLS] almost wall up emotional defeated leadership acquainted variables spectroscopy dive realm with consolation households cas potential obsidian handed existing been organization [SEP]']
[Init] best perm rec loss: 0.881610095500946 for ['[CLS] dive existing potential wall cas with been defeated organization realm spectroscopy households up consolation almost variables handed leadership acquainted obsidian emotional [SEP]']
[Init] best perm rec loss: 0.8813144564628601 for ['[CLS] cas existing acquainted obsidian spectroscopy up organization realm been consolation leadership wall defeated with almost emotional variables handed potential dive households [SEP]']
[Init] best perm rec loss: 0.8794166445732117 for ['[CLS] potential been leadership with obsidian spectroscopy emotional households defeated variables organization acquainted consolation almost realm handed up wall existing dive cas [SEP]']
[Init] best perm rec loss: 0.8788838982582092 for ['[CLS] households existing acquainted potential defeated realm up leadership obsidian spectroscopy dive variables emotional with been wall organization handed almost cas consolation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.609 (perp=11.589, rec=0.281, cos=0.010), tot_loss_proj:3.120 [t=0.31s]
prediction: ['[CLS] costly that productions 1980s costly films likelymia metal damage suffered damage costly with fromic obviously often could suffers films [SEP]']
[ 100/2000] tot_loss=2.327 (perp=10.678, rec=0.188, cos=0.004), tot_loss_proj:2.753 [t=0.31s]
prediction: ['[CLS] costly which films loads costly films reportedlymia airline damage and damage costly that fromity never never could fix fix [SEP]']
[ 150/2000] tot_loss=2.109 (perp=9.848, rec=0.137, cos=0.003), tot_loss_proj:2.643 [t=0.31s]
prediction: ['[CLS] costly which loads loads costly films willmia years damage and damage costly that fromes never never would fix fix [SEP]']
[ 200/2000] tot_loss=2.318 (perp=10.921, rec=0.132, cos=0.002), tot_loss_proj:2.795 [t=0.32s]
prediction: ['[CLS] costly which loads loads costly films will lexie / damage cause damage costly that yearses analysis never couldpara fix [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.187 (perp=9.774, rec=0.225, cos=0.007), tot_loss_proj:2.968 [t=0.32s]
prediction: ['[CLS] cost which loads loads cause films will benefiterved damage cause damage that years of costly analysis could analysisbolic fix [SEP]']
[ 300/2000] tot_loss=2.246 (perp=10.433, rec=0.156, cos=0.003), tot_loss_proj:3.095 [t=0.32s]
prediction: ['[CLS] cost which loads loads cause films will seriouspara damage cause damage that years - costly or could analysis [SEP] fix [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.314 (perp=10.785, rec=0.153, cos=0.005), tot_loss_proj:3.031 [t=0.32s]
prediction: ['[CLS] costly which loads loads years films will expensivepara damage cause damage that significant of costly costly could analysis [SEP] fix [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.384 (perp=11.213, rec=0.139, cos=0.003), tot_loss_proj:2.935 [t=0.33s]
prediction: ['[CLS] costly which mouthful loads years films willpara damage cause damage that significant a costly expensive costly never analysis [SEP] fix [SEP]']
[ 450/2000] tot_loss=2.151 (perp=10.183, rec=0.112, cos=0.003), tot_loss_proj:2.742 [t=0.32s]
prediction: ['[CLS] costly which of loads years films willpara damage cause damage that significant a costly expensive costly never analysis [SEP] fix [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.975 (perp=9.182, rec=0.136, cos=0.003), tot_loss_proj:2.797 [t=0.32s]
prediction: ['[CLS] costly which loads of years films willpara damage cause damage that cause not costly expensive costly never analysis, fix [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.900 (perp=8.947, rec=0.108, cos=0.002), tot_loss_proj:2.695 [t=0.32s]
prediction: ['[CLS] costly which loads of years films willpara damage cause damage that cause expensive costly not costly never analysis, fix [SEP]']
[ 600/2000] tot_loss=1.895 (perp=8.947, rec=0.104, cos=0.002), tot_loss_proj:2.700 [t=0.32s]
prediction: ['[CLS] costly which loads of years films willpara damage cause damage that cause expensive costly not costly never analysis, fix [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.040 (perp=9.690, rec=0.100, cos=0.002), tot_loss_proj:2.691 [t=0.32s]
prediction: ['[CLS] costly which loads of years films willpara damage cause damage thatnt expensive costly - costly never analysis, fix [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.006 (perp=9.512, rec=0.102, cos=0.002), tot_loss_proj:2.623 [t=0.32s]
prediction: ['[CLS] - which loads of years films willpara damage cause damage thatnt expensive costly costly costly never analysis, fix [SEP]']
[ 750/2000] tot_loss=2.108 (perp=10.002, rec=0.106, cos=0.002), tot_loss_proj:2.704 [t=0.32s]
prediction: ['[CLS] - which loads of years films willpara damage cause damage thatca expensive costly costly costly never analysis, fix [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.045 (perp=9.707, rec=0.101, cos=0.002), tot_loss_proj:2.736 [t=0.31s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause damage thatca - costly costly costly never analysis, fix [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.009 (perp=9.583, rec=0.091, cos=0.002), tot_loss_proj:2.650 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatca - costly costly costly never analysis damage fix [SEP]']
[ 900/2000] tot_loss=2.017 (perp=9.583, rec=0.099, cos=0.002), tot_loss_proj:2.651 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatca - costly costly costly never analysis damage fix [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.018 (perp=9.583, rec=0.100, cos=0.002), tot_loss_proj:2.655 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatca - costly costly costly never analysis damage fix [SEP]']
Attempt swap
[1000/2000] tot_loss=2.012 (perp=9.583, rec=0.093, cos=0.002), tot_loss_proj:2.654 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatca - costly costly costly never analysis damage fix [SEP]']
[1050/2000] tot_loss=2.022 (perp=9.583, rec=0.104, cos=0.002), tot_loss_proj:2.655 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatca - costly costly costly never analysis damage fix [SEP]']
Attempt swap
[1100/2000] tot_loss=1.976 (perp=9.401, rec=0.093, cos=0.002), tot_loss_proj:2.615 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatpara - costly costly costly never analysis damage fix [SEP]']
Attempt swap
[1150/2000] tot_loss=1.975 (perp=9.401, rec=0.093, cos=0.002), tot_loss_proj:2.612 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatpara - costly costly costly never analysis damage fix [SEP]']
[1200/2000] tot_loss=1.980 (perp=9.401, rec=0.098, cos=0.002), tot_loss_proj:2.616 [t=0.31s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatpara - costly costly costly never analysis damage fix [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.959 (perp=9.313, rec=0.095, cos=0.002), tot_loss_proj:2.726 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatpara - costly costly costly never damage analysis fix [SEP]']
Attempt swap
[1300/2000] tot_loss=1.957 (perp=9.313, rec=0.092, cos=0.002), tot_loss_proj:2.720 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatpara - costly costly costly never damage analysis fix [SEP]']
[1350/2000] tot_loss=1.955 (perp=9.313, rec=0.090, cos=0.002), tot_loss_proj:2.720 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatpara - costly costly costly never damage analysis fix [SEP]']
Attempt swap
[1400/2000] tot_loss=1.960 (perp=9.313, rec=0.096, cos=0.002), tot_loss_proj:2.721 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatpara - costly costly costly never damage analysis fix [SEP]']
Attempt swap
[1450/2000] tot_loss=1.958 (perp=9.313, rec=0.094, cos=0.002), tot_loss_proj:2.721 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatpara - costly costly costly never damage analysis fix [SEP]']
[1500/2000] tot_loss=1.959 (perp=9.313, rec=0.094, cos=0.002), tot_loss_proj:2.722 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause, thatpara - costly costly costly never damage analysis fix [SEP]']
Attempt swap
[1550/2000] tot_loss=2.026 (perp=9.654, rec=0.093, cos=0.002), tot_loss_proj:2.779 [t=0.32s]
prediction: ['[CLS] expensive which loads of years films willpara damage cause as thatpara - costly costly costly never damage analysis fix [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.993 (perp=9.471, rec=0.096, cos=0.002), tot_loss_proj:2.756 [t=0.32s]
prediction: ['[CLS] expensive which loads of years filmspara damage will cause as thatpara - costly costly costly never damage analysis fix [SEP]']
[1650/2000] tot_loss=1.991 (perp=9.471, rec=0.094, cos=0.002), tot_loss_proj:2.749 [t=0.32s]
prediction: ['[CLS] expensive which loads of years filmspara damage will cause as thatpara - costly costly costly never damage analysis fix [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.924 (perp=9.169, rec=0.088, cos=0.002), tot_loss_proj:2.762 [t=0.32s]
prediction: ['[CLS] expensive which loads of years filmspara damage will cause aspara that - costly costly costly never damage analysis fix [SEP]']
Attempt swap
[1750/2000] tot_loss=1.933 (perp=9.169, rec=0.097, cos=0.002), tot_loss_proj:2.767 [t=0.32s]
prediction: ['[CLS] expensive which loads of years filmspara damage will cause aspara that - costly costly costly never damage analysis fix [SEP]']
[1800/2000] tot_loss=1.934 (perp=9.169, rec=0.098, cos=0.002), tot_loss_proj:2.766 [t=0.32s]
prediction: ['[CLS] expensive which loads of years filmspara damage will cause aspara that - costly costly costly never damage analysis fix [SEP]']
Attempt swap
[1850/2000] tot_loss=1.928 (perp=9.169, rec=0.092, cos=0.002), tot_loss_proj:2.765 [t=0.32s]
prediction: ['[CLS] expensive which loads of years filmspara damage will cause aspara that - costly costly costly never damage analysis fix [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.829 (perp=8.519, rec=0.122, cos=0.003), tot_loss_proj:2.616 [t=0.32s]
prediction: ['[CLS] expensive films which loads of yearspara damage will cause aspara that - costly costly costly never damage analysis fix [SEP]']
[1950/2000] tot_loss=1.810 (perp=8.519, rec=0.104, cos=0.002), tot_loss_proj:2.614 [t=0.32s]
prediction: ['[CLS] expensive films which loads of yearspara damage will cause aspara that - costly costly costly never damage analysis fix [SEP]']
Attempt swap
[2000/2000] tot_loss=1.812 (perp=8.519, rec=0.107, cos=0.002), tot_loss_proj:2.618 [t=0.32s]
prediction: ['[CLS] expensive films which loads of yearspara damage will cause aspara that - costly costly costly never damage analysis fix [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] expensive which loads of years filmspara damage will cause aspara that - costly costly costly never damage analysis fix [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.000 | p: 70.000 | r: 70.000
rouge2     | fm: 15.789 | p: 15.789 | r: 15.789
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 85.789

[Aggregate metrics]:
rouge1     | fm: 93.563 | p: 93.213 | r: 94.011
rouge2     | fm: 60.353 | p: 60.186 | r: 60.544
rougeL     | fm: 80.116 | p: 79.825 | r: 80.451
rougeLsum  | fm: 79.904 | p: 79.667 | r: 80.248
r1fm+r2fm = 153.916

input #56 time: 0:12:34 | total time: 11:39:58


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9993824562438816
highest_index [0]
highest [0.9993824562438816]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8602288365364075 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.8057299852371216 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.7067487835884094 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6608306765556335 for ['[CLS] expressed [SEP]']
[Init] best rec loss: 0.6409720182418823 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.598 (perp=12.283, rec=0.125, cos=0.017), tot_loss_proj:2.520 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.519 (perp=12.283, rec=0.061, cos=0.002), tot_loss_proj:2.512 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.518 (perp=12.283, rec=0.059, cos=0.002), tot_loss_proj:2.510 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.527 (perp=12.283, rec=0.066, cos=0.005), tot_loss_proj:2.521 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.524 (perp=12.283, rec=0.066, cos=0.002), tot_loss_proj:2.527 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.514 (perp=12.283, rec=0.056, cos=0.001), tot_loss_proj:2.521 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.516 (perp=12.283, rec=0.058, cos=0.001), tot_loss_proj:2.510 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.519 (perp=12.283, rec=0.061, cos=0.002), tot_loss_proj:2.524 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.526 (perp=12.283, rec=0.068, cos=0.001), tot_loss_proj:2.525 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.515 (perp=12.283, rec=0.058, cos=0.001), tot_loss_proj:2.527 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.522 (perp=12.283, rec=0.065, cos=0.001), tot_loss_proj:2.518 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.511 (perp=12.283, rec=0.054, cos=0.001), tot_loss_proj:2.523 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.523 (perp=12.283, rec=0.065, cos=0.001), tot_loss_proj:2.512 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.525 (perp=12.283, rec=0.067, cos=0.001), tot_loss_proj:2.514 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.508 (perp=12.283, rec=0.051, cos=0.001), tot_loss_proj:2.508 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.507 (perp=12.283, rec=0.049, cos=0.001), tot_loss_proj:2.519 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.518 (perp=12.283, rec=0.060, cos=0.001), tot_loss_proj:2.517 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.510 (perp=12.283, rec=0.052, cos=0.001), tot_loss_proj:2.515 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.518 (perp=12.283, rec=0.061, cos=0.001), tot_loss_proj:2.509 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.510 (perp=12.283, rec=0.053, cos=0.001), tot_loss_proj:2.499 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.510 (perp=12.283, rec=0.052, cos=0.001), tot_loss_proj:2.527 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.503 (perp=12.283, rec=0.045, cos=0.001), tot_loss_proj:2.508 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.504 (perp=12.283, rec=0.047, cos=0.001), tot_loss_proj:2.520 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.520 (perp=12.283, rec=0.062, cos=0.001), tot_loss_proj:2.504 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.516 (perp=12.283, rec=0.058, cos=0.001), tot_loss_proj:2.509 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.515 (perp=12.283, rec=0.057, cos=0.001), tot_loss_proj:2.523 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.527 (perp=12.283, rec=0.070, cos=0.001), tot_loss_proj:2.525 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.523 (perp=12.283, rec=0.066, cos=0.001), tot_loss_proj:2.513 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.507 (perp=12.283, rec=0.050, cos=0.001), tot_loss_proj:2.513 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.510 (perp=12.283, rec=0.052, cos=0.001), tot_loss_proj:2.502 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.525 (perp=12.283, rec=0.067, cos=0.001), tot_loss_proj:2.524 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.516 (perp=12.283, rec=0.059, cos=0.001), tot_loss_proj:2.509 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.520 (perp=12.283, rec=0.062, cos=0.001), tot_loss_proj:2.519 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.506 (perp=12.283, rec=0.049, cos=0.001), tot_loss_proj:2.514 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.529 (perp=12.283, rec=0.071, cos=0.001), tot_loss_proj:2.530 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.526 (perp=12.283, rec=0.068, cos=0.001), tot_loss_proj:2.511 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.509 (perp=12.283, rec=0.051, cos=0.001), tot_loss_proj:2.532 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.524 (perp=12.283, rec=0.067, cos=0.001), tot_loss_proj:2.507 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.518 (perp=12.283, rec=0.060, cos=0.001), tot_loss_proj:2.519 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.523 (perp=12.283, rec=0.065, cos=0.001), tot_loss_proj:2.512 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.731 | p: 93.363 | r: 94.126
rouge2     | fm: 61.276 | p: 61.067 | r: 61.506
rougeL     | fm: 80.312 | p: 79.997 | r: 80.623
rougeLsum  | fm: 80.121 | p: 79.829 | r: 80.453
r1fm+r2fm = 155.006

input #57 time: 0:11:11 | total time: 11:51:09


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9992687568065695
highest_index [0]
highest [0.9992687568065695]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 0.9609708786010742 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9552246928215027 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9189521670341492 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9163247346878052 for ['[CLS] thinking humming human speakers generalyal ended lowlands per willuity music hearts timing jazz toys [SEP]']
[Init] best rec loss: 0.8890154957771301 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.8740432262420654 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.8732704520225525 for ['[CLS] award professor travelersry baby fingers be hall° feet occasion % overlap billga top [SEP]']
[Init] best rec loss: 0.8674571514129639 for ['[CLS] down trade zack serious verde thighsager finishedtyle chiefuration apart beautyitical est herself [SEP]']
[Init] best perm rec loss: 0.8660186529159546 for ['[CLS] serious thighsitical zack verde finished downtyle trade herself apart beautyuration est chiefager [SEP]']
[Init] best perm rec loss: 0.8651264905929565 for ['[CLS]ageruration finished serious down zackitical tradetyle thighs est beauty apart verde herself chief [SEP]']
[Init] best perm rec loss: 0.8645317554473877 for ['[CLS] verde serious trade zackitical thighs down herself aparturation finished chief beautyager esttyle [SEP]']
[Init] best perm rec loss: 0.8631526231765747 for ['[CLS] est chief verdeuration finished thighs zacktyle herself down apartiticalager serious trade beauty [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.591 (perp=11.753, rec=0.234, cos=0.006), tot_loss_proj:2.908 [t=0.31s]
prediction: ['[CLS] christian religious arts film a inspirational directlyly creating rock inspirational physical story happy historicalocation [SEP]']
[ 100/2000] tot_loss=1.917 (perp=8.888, rec=0.137, cos=0.002), tot_loss_proj:2.414 [t=0.31s]
prediction: ['[CLS] inspirational love love story is inspirational, and capturing property inspirational starting story meaning first experience [SEP]']
[ 150/2000] tot_loss=1.757 (perp=8.279, rec=0.100, cos=0.002), tot_loss_proj:2.186 [t=0.31s]
prediction: ['[CLS] a love love story is inspirational, the capturing property ideal first encounterism encounter encounter [SEP]']
[ 200/2000] tot_loss=1.835 (perp=8.746, rec=0.085, cos=0.002), tot_loss_proj:2.209 [t=0.31s]
prediction: ['[CLS] an love love story is inspirational, the capturing property innocence first encounterism that encounter [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.777 (perp=8.451, rec=0.086, cos=0.001), tot_loss_proj:2.263 [t=0.31s]
prediction: ['[CLS] an inspirational love story is -, the capturing property innocence first encounterism that encounter [SEP]']
[ 300/2000] tot_loss=1.691 (perp=8.105, rec=0.068, cos=0.001), tot_loss_proj:2.056 [t=0.31s]
prediction: ['[CLS] an inspirational love story is and, the capturing good innocence first encounterism that encounter [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.642 (perp=7.824, rec=0.076, cos=0.001), tot_loss_proj:2.001 [t=0.31s]
prediction: ['[CLS] an inspirational love story is -, the capturing and innocence first encounterism that encounter [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.546 (perp=7.133, rec=0.118, cos=0.002), tot_loss_proj:1.863 [t=0.31s]
prediction: ['[CLS] an inspirational love story is property, the capturing and innocence ideal first encounter of that [SEP]']
[ 450/2000] tot_loss=1.632 (perp=7.753, rec=0.080, cos=0.001), tot_loss_proj:1.955 [t=0.31s]
prediction: ['[CLS] an inspirational love story iscious, the capturing ideal innocence ideal first encounter of that [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.505 (perp=7.172, rec=0.069, cos=0.001), tot_loss_proj:1.737 [t=0.31s]
prediction: ['[CLS] an inspirational love story isbright, capturing the ideal innocence ideal first encounter of that [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.465 (perp=6.906, rec=0.083, cos=0.002), tot_loss_proj:1.740 [t=0.31s]
prediction: ['[CLS] an inspirational love story isize, capturing the and innocence of ideal first encounter that [SEP]']
[ 600/2000] tot_loss=1.373 (perp=6.415, rec=0.089, cos=0.002), tot_loss_proj:1.551 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the and innocence of ideal first encounter that [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.301 (perp=6.110, rec=0.078, cos=0.001), tot_loss_proj:1.513 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of ideal first and encounter that [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.215 (perp=5.681, rec=0.078, cos=0.001), tot_loss_proj:1.410 [t=0.32s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of ideal first encounter and that [SEP]']
[ 750/2000] tot_loss=1.211 (perp=5.681, rec=0.073, cos=0.002), tot_loss_proj:1.408 [t=0.32s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of ideal first encounter and that [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.175 (perp=5.514, rec=0.071, cos=0.001), tot_loss_proj:1.345 [t=0.32s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.166 (perp=5.514, rec=0.061, cos=0.001), tot_loss_proj:1.342 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
[ 900/2000] tot_loss=1.178 (perp=5.514, rec=0.073, cos=0.001), tot_loss_proj:1.341 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.168 (perp=5.514, rec=0.063, cos=0.001), tot_loss_proj:1.349 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.177 (perp=5.514, rec=0.073, cos=0.001), tot_loss_proj:1.346 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
[1050/2000] tot_loss=1.169 (perp=5.514, rec=0.064, cos=0.001), tot_loss_proj:1.345 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.170 (perp=5.514, rec=0.066, cos=0.001), tot_loss_proj:1.341 [t=0.32s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.173 (perp=5.514, rec=0.068, cos=0.001), tot_loss_proj:1.345 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
[1200/2000] tot_loss=1.184 (perp=5.514, rec=0.079, cos=0.001), tot_loss_proj:1.351 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.177 (perp=5.514, rec=0.072, cos=0.001), tot_loss_proj:1.346 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.166 (perp=5.514, rec=0.062, cos=0.001), tot_loss_proj:1.344 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
[1350/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.001), tot_loss_proj:1.348 [t=0.32s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.169 (perp=5.514, rec=0.064, cos=0.001), tot_loss_proj:1.347 [t=0.32s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.179 (perp=5.514, rec=0.075, cos=0.001), tot_loss_proj:1.354 [t=0.32s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
[1500/2000] tot_loss=1.171 (perp=5.514, rec=0.067, cos=0.001), tot_loss_proj:1.338 [t=0.32s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.176 (perp=5.514, rec=0.071, cos=0.001), tot_loss_proj:1.340 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.175 (perp=5.514, rec=0.071, cos=0.001), tot_loss_proj:1.345 [t=0.32s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
[1650/2000] tot_loss=1.169 (perp=5.514, rec=0.065, cos=0.001), tot_loss_proj:1.350 [t=0.32s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.157 (perp=5.483, rec=0.059, cos=0.001), tot_loss_proj:1.333 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the ideal innocence of that first encounter and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.176 (perp=5.483, rec=0.078, cos=0.001), tot_loss_proj:1.323 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the ideal innocence of that first encounter and [SEP]']
[1800/2000] tot_loss=1.159 (perp=5.483, rec=0.061, cos=0.001), tot_loss_proj:1.331 [t=0.32s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the ideal innocence of that first encounter and [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.168 (perp=5.514, rec=0.063, cos=0.001), tot_loss_proj:1.346 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.170 (perp=5.514, rec=0.065, cos=0.001), tot_loss_proj:1.344 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
[1950/2000] tot_loss=1.169 (perp=5.514, rec=0.065, cos=0.001), tot_loss_proj:1.348 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.174 (perp=5.514, rec=0.070, cos=0.001), tot_loss_proj:1.342 [t=0.31s]
prediction: ['[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] an inspirational love story is ideal, capturing the innocence of that ideal first encounter and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 88.235 | r: 93.750
rouge2     | fm: 45.161 | p: 43.750 | r: 46.667
rougeL     | fm: 78.788 | p: 76.471 | r: 81.250
rougeLsum  | fm: 78.788 | p: 76.471 | r: 81.250
r1fm+r2fm = 136.070

[Aggregate metrics]:
rouge1     | fm: 93.628 | p: 93.246 | r: 94.086
rouge2     | fm: 60.867 | p: 60.618 | r: 61.035
rougeL     | fm: 80.324 | p: 80.022 | r: 80.669
rougeLsum  | fm: 80.062 | p: 79.742 | r: 80.433
r1fm+r2fm = 154.495

input #58 time: 0:12:30 | total time: 12:03:40


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.999223049558071
highest_index [0]
highest [0.999223049558071]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.9152714610099792 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.8995600938796997 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 0.8946517109870911 for ['[CLS] clutch sports meridian placed weekly dixonwords up⁄ faerie rugby been towards resist programming infantry [SEP]']
[Init] best rec loss: 0.8669672012329102 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.8611061573028564 for ['[CLS]ition wandering wearing right wore kent hemisphere purple strict we gas dark deserve tonnes did letterman [SEP]']
[Init] best rec loss: 0.8336184024810791 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best perm rec loss: 0.8322231769561768 for ['[CLS] stuff races noah awhile fleetak tunnelby bobo was temperament information bologna pump 1993 thus [SEP]']
[Init] best perm rec loss: 0.8315479159355164 for ['[CLS] information bobo thus tunnel stuff fleet noah 1993 bologna races temperamentby was pump awhileak [SEP]']
[Init] best perm rec loss: 0.8280991911888123 for ['[CLS] awhile bologna temperament stuff thus noah 1993 fleetby information tunnel pump boboak races was [SEP]']
[Init] best perm rec loss: 0.8279256820678711 for ['[CLS] was pump bologna informationak stuffby bobo races fleet thus tunnel temperament 1993 awhile noah [SEP]']
[Init] best perm rec loss: 0.8266153335571289 for ['[CLS] temperament awhile noah pump thus bobo racesak stuffby was tunnel information fleet 1993 bologna [SEP]']
[Init] best perm rec loss: 0.8264846801757812 for ['[CLS] thus noah tunnel bobo temperament informationby awhile 1993 pump bologna was fleetak stuff races [SEP]']
[Init] best perm rec loss: 0.8252063393592834 for ['[CLS] boboak temperament pump tunnel races was 1993 bologna information thusby stuff fleet noah awhile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.421 (perp=10.341, rec=0.340, cos=0.012), tot_loss_proj:3.948 [t=0.31s]
prediction: ['[CLS] sleep of qualities the the movement : while asian person versa a storyly able although [SEP]']
[ 100/2000] tot_loss=2.375 (perp=10.610, rec=0.249, cos=0.004), tot_loss_proj:3.495 [t=0.31s]
prediction: ['[CLS]ly has bautista of the who woman young woman woman who a story screen able char [SEP]']
[ 150/2000] tot_loss=2.164 (perp=9.895, rec=0.183, cos=0.002), tot_loss_proj:2.958 [t=0.31s]
prediction: ['[CLS] screen hasism of theism woman young young woman who a screen screen able char [SEP]']
[ 200/2000] tot_loss=1.781 (perp=8.154, rec=0.148, cos=0.003), tot_loss_proj:2.395 [t=0.32s]
prediction: ['[CLS] screen hasism of theism knows a young woman who hold the screen how char [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.767 (perp=8.211, rec=0.120, cos=0.005), tot_loss_proj:2.356 [t=0.31s]
prediction: ['[CLS] screen hasism of theism knows a young woman who hold the screen knows char [SEP]']
[ 300/2000] tot_loss=1.749 (perp=8.211, rec=0.105, cos=0.002), tot_loss_proj:2.350 [t=0.32s]
prediction: ['[CLS] screen hasism of theism knows a young woman who hold the screen knows char [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.726 (perp=8.185, rec=0.087, cos=0.002), tot_loss_proj:2.621 [t=0.31s]
prediction: ['[CLS] screen hasism of thea knows a young woman who hold the screen knows char [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.688 (perp=8.066, rec=0.073, cos=0.002), tot_loss_proj:2.666 [t=0.31s]
prediction: ['[CLS] hasism of thea screen knows a young woman who hold the screen knows char [SEP]']
[ 450/2000] tot_loss=1.692 (perp=8.066, rec=0.077, cos=0.002), tot_loss_proj:2.655 [t=0.31s]
prediction: ['[CLS] hasism of thea screen knows a young woman who hold the screen knows char [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.694 (perp=8.028, rec=0.087, cos=0.002), tot_loss_proj:2.514 [t=0.32s]
prediction: ['[CLS] hasism of the screena knows a young woman who hold the screen knows char [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.512 (perp=7.157, rec=0.079, cos=0.002), tot_loss_proj:2.037 [t=0.31s]
prediction: ['[CLS] hasisma of the screen knows a young woman who hold the screen knows char [SEP]']
[ 600/2000] tot_loss=1.718 (perp=8.221, rec=0.072, cos=0.002), tot_loss_proj:2.204 [t=0.31s]
prediction: ['[CLS] hasisma of the the knows a young woman who hold the screen knows char [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.630 (perp=7.698, rec=0.089, cos=0.002), tot_loss_proj:2.264 [t=0.31s]
prediction: ['[CLS] hasisma knows of the the a young woman who hold the screen knows char [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.650 (perp=7.916, rec=0.065, cos=0.002), tot_loss_proj:2.364 [t=0.31s]
prediction: ['[CLS] hasisma knows of to the a young woman who hold the screen knows char [SEP]']
[ 750/2000] tot_loss=1.559 (perp=7.457, rec=0.066, cos=0.002), tot_loss_proj:2.184 [t=0.31s]
prediction: ['[CLS] hasisma knows of how the a young woman who hold the screen knows char [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.490 (perp=7.054, rec=0.077, cos=0.002), tot_loss_proj:2.171 [t=0.32s]
prediction: ['[CLS] hasisma knows of how a young woman who hold the screen knows the char [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.480 (perp=7.054, rec=0.068, cos=0.002), tot_loss_proj:2.166 [t=0.31s]
prediction: ['[CLS] hasisma knows of how a young woman who hold the screen knows the char [SEP]']
[ 900/2000] tot_loss=1.476 (perp=7.054, rec=0.063, cos=0.002), tot_loss_proj:2.168 [t=0.31s]
prediction: ['[CLS] hasisma knows of how a young woman who hold the screen knows the char [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.399 (perp=6.633, rec=0.071, cos=0.002), tot_loss_proj:1.899 [t=0.31s]
prediction: ['[CLS] has charisma knows of how a young woman who hold the screen knows the [SEP]']
Attempt swap
[1000/2000] tot_loss=1.399 (perp=6.633, rec=0.070, cos=0.002), tot_loss_proj:1.904 [t=0.31s]
prediction: ['[CLS] has charisma knows of how a young woman who hold the screen knows the [SEP]']
[1050/2000] tot_loss=1.388 (perp=6.633, rec=0.060, cos=0.002), tot_loss_proj:1.898 [t=0.31s]
prediction: ['[CLS] has charisma knows of how a young woman who hold the screen knows the [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.314 (perp=6.153, rec=0.081, cos=0.002), tot_loss_proj:1.965 [t=0.31s]
prediction: ['[CLS] charisma has knows of how a young woman who hold the screen knows the [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.285 (perp=6.020, rec=0.079, cos=0.002), tot_loss_proj:2.134 [t=0.31s]
prediction: ['[CLS] charisma has knows of how a young woman who knows the hold the screen [SEP]']
[1200/2000] tot_loss=1.284 (perp=6.020, rec=0.078, cos=0.002), tot_loss_proj:2.123 [t=0.31s]
prediction: ['[CLS] charisma has knows of how a young woman who knows the hold the screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.276 (perp=6.020, rec=0.071, cos=0.002), tot_loss_proj:2.127 [t=0.31s]
prediction: ['[CLS] charisma has knows of how a young woman who knows the hold the screen [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.249 (perp=5.872, rec=0.073, cos=0.002), tot_loss_proj:1.643 [t=0.31s]
prediction: ['[CLS] charisma has knows how of a young woman who knows the hold the screen [SEP]']
[1350/2000] tot_loss=1.236 (perp=5.872, rec=0.060, cos=0.002), tot_loss_proj:1.639 [t=0.31s]
prediction: ['[CLS] charisma has knows how of a young woman who knows the hold the screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.242 (perp=5.872, rec=0.066, cos=0.002), tot_loss_proj:1.640 [t=0.31s]
prediction: ['[CLS] charisma has knows how of a young woman who knows the hold the screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.246 (perp=5.872, rec=0.070, cos=0.002), tot_loss_proj:1.648 [t=0.32s]
prediction: ['[CLS] charisma has knows how of a young woman who knows the hold the screen [SEP]']
[1500/2000] tot_loss=1.250 (perp=5.872, rec=0.074, cos=0.002), tot_loss_proj:1.638 [t=0.31s]
prediction: ['[CLS] charisma has knows how of a young woman who knows the hold the screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.244 (perp=5.872, rec=0.068, cos=0.002), tot_loss_proj:1.648 [t=0.31s]
prediction: ['[CLS] charisma has knows how of a young woman who knows the hold the screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.246 (perp=5.872, rec=0.070, cos=0.002), tot_loss_proj:1.645 [t=0.31s]
prediction: ['[CLS] charisma has knows how of a young woman who knows the hold the screen [SEP]']
[1650/2000] tot_loss=1.239 (perp=5.872, rec=0.063, cos=0.002), tot_loss_proj:1.641 [t=0.31s]
prediction: ['[CLS] charisma has knows how of a young woman who knows the hold the screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.252 (perp=5.872, rec=0.076, cos=0.002), tot_loss_proj:1.641 [t=0.32s]
prediction: ['[CLS] charisma has knows how of a young woman who knows the hold the screen [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.224 (perp=5.779, rec=0.067, cos=0.002), tot_loss_proj:1.585 [t=0.31s]
prediction: ['[CLS] charisma has the knows how of a young woman who knows hold the screen [SEP]']
[1800/2000] tot_loss=1.227 (perp=5.779, rec=0.069, cos=0.002), tot_loss_proj:1.583 [t=0.32s]
prediction: ['[CLS] charisma has the knows how of a young woman who knows hold the screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.228 (perp=5.779, rec=0.070, cos=0.002), tot_loss_proj:1.579 [t=0.32s]
prediction: ['[CLS] charisma has the knows how of a young woman who knows hold the screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.227 (perp=5.779, rec=0.070, cos=0.002), tot_loss_proj:1.577 [t=0.32s]
prediction: ['[CLS] charisma has the knows how of a young woman who knows hold the screen [SEP]']
[1950/2000] tot_loss=1.228 (perp=5.779, rec=0.070, cos=0.002), tot_loss_proj:1.573 [t=0.32s]
prediction: ['[CLS] charisma has the knows how of a young woman who knows hold the screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.215 (perp=5.779, rec=0.057, cos=0.002), tot_loss_proj:1.582 [t=0.31s]
prediction: ['[CLS] charisma has the knows how of a young woman who knows hold the screen [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] charisma has the knows how of a young woman who knows hold the screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.750 | p: 93.750 | r: 93.750
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 81.250 | p: 81.250 | r: 81.250
rougeLsum  | fm: 81.250 | p: 81.250 | r: 81.250
r1fm+r2fm = 160.417

[Aggregate metrics]:
rouge1     | fm: 93.648 | p: 93.210 | r: 94.102
rouge2     | fm: 60.915 | p: 60.746 | r: 61.095
rougeL     | fm: 80.355 | p: 80.011 | r: 80.706
rougeLsum  | fm: 80.186 | p: 79.869 | r: 80.527
r1fm+r2fm = 154.563

input #59 time: 0:12:30 | total time: 12:16:11


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.9993732741112111
highest_index [0]
highest [0.9993732741112111]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9285165071487427 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9138757586479187 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8723136186599731 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8678968548774719 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8556720614433289 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 0.8422979712486267 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 0.8418930768966675 for ['[CLS] cover upset throughlby plenty strungitude constitutionouringshaw / majority [SEP]']
[Init] best perm rec loss: 0.8400633335113525 for ['[CLS] majority strung throughlbyshaw upset coveritude plentyouring constitution / [SEP]']
[Init] best perm rec loss: 0.8388874530792236 for ['[CLS] majority coveritude upsetshawouring through constitutionlby strung / plenty [SEP]']
[Init] best perm rec loss: 0.8374086022377014 for ['[CLS]shaw / plentylbyitude strung cover throughouring upset constitution majority [SEP]']
[Init] best perm rec loss: 0.836881160736084 for ['[CLS] plenty majority constitutionshaw / strungitudelby upset coverouring through [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.824 (perp=12.858, rec=0.245, cos=0.007), tot_loss_proj:3.201 [t=0.30s]
prediction: ['[CLS] awkwardly is story awkwardly. paced labor title apartment awkwardlymo data [SEP]']
[ 100/2000] tot_loss=2.649 (perp=12.495, rec=0.147, cos=0.004), tot_loss_proj:2.978 [t=0.31s]
prediction: ['[CLS] circuit is story awkwardly the paced haired bass opera awkwardlyh soap [SEP]']
[ 150/2000] tot_loss=2.429 (perp=11.616, rec=0.103, cos=0.003), tot_loss_proj:2.806 [t=0.31s]
prediction: ['[CLS] circuit is story awkwardly the paced irritating baritone opera.h soap [SEP]']
[ 200/2000] tot_loss=2.461 (perp=11.819, rec=0.095, cos=0.002), tot_loss_proj:2.866 [t=0.31s]
prediction: ['[CLS] circuit is story awkwardly the paced. facto operahh soap [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.252 (perp=10.789, rec=0.091, cos=0.002), tot_loss_proj:2.729 [t=0.31s]
prediction: ['[CLS] circuit is story awkwardly the paced - soap operahh facto [SEP]']
[ 300/2000] tot_loss=2.103 (perp=10.112, rec=0.079, cos=0.002), tot_loss_proj:2.592 [t=0.31s]
prediction: ['[CLS] circuit is story awkwardly the paced - soap opera ish facto [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.831 (perp=8.720, rec=0.086, cos=0.002), tot_loss_proj:2.225 [t=0.31s]
prediction: ['[CLS] circuit is story awkwardly paced - the soap opera ish facto [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.765 (perp=8.321, rec=0.098, cos=0.003), tot_loss_proj:2.055 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish statistics [SEP]']
[ 450/2000] tot_loss=1.750 (perp=8.321, rec=0.084, cos=0.002), tot_loss_proj:2.051 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish statistics [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.624 (perp=7.701, rec=0.082, cos=0.002), tot_loss_proj:1.961 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the eponymous soap opera ish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.616 (perp=7.701, rec=0.074, cos=0.002), tot_loss_proj:1.959 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the eponymous soap opera ish [SEP]']
[ 600/2000] tot_loss=1.606 (perp=7.701, rec=0.064, cos=0.002), tot_loss_proj:1.963 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the eponymous soap opera ish [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.596 (perp=7.561, rec=0.082, cos=0.002), tot_loss_proj:1.924 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish eponymous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.626 (perp=7.789, rec=0.067, cos=0.002), tot_loss_proj:1.996 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish facto [SEP]']
[ 750/2000] tot_loss=1.627 (perp=7.789, rec=0.068, cos=0.002), tot_loss_proj:1.999 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish facto [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.444 (perp=6.868, rec=0.069, cos=0.002), tot_loss_proj:1.768 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.450 (perp=6.868, rec=0.075, cos=0.002), tot_loss_proj:1.768 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish. [SEP]']
[ 900/2000] tot_loss=1.440 (perp=6.868, rec=0.065, cos=0.002), tot_loss_proj:1.760 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.444 (perp=6.868, rec=0.069, cos=0.002), tot_loss_proj:1.767 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.447 (perp=6.868, rec=0.072, cos=0.002), tot_loss_proj:1.770 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish. [SEP]']
[1050/2000] tot_loss=1.446 (perp=6.868, rec=0.070, cos=0.002), tot_loss_proj:1.768 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.443 (perp=6.868, rec=0.068, cos=0.002), tot_loss_proj:1.762 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.441 (perp=6.868, rec=0.066, cos=0.002), tot_loss_proj:1.764 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish. [SEP]']
[1200/2000] tot_loss=1.640 (perp=7.847, rec=0.069, cos=0.002), tot_loss_proj:2.006 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - the soap opera ish when [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.587 (perp=7.574, rec=0.070, cos=0.002), tot_loss_proj:1.977 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - when the soap opera ish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.589 (perp=7.574, rec=0.072, cos=0.002), tot_loss_proj:1.978 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - when the soap opera ish [SEP]']
[1350/2000] tot_loss=1.602 (perp=7.649, rec=0.070, cos=0.002), tot_loss_proj:1.936 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced -. the soap opera ish [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.498 (perp=7.092, rec=0.077, cos=0.002), tot_loss_proj:1.772 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.490 (perp=7.092, rec=0.070, cos=0.002), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
[1500/2000] tot_loss=1.490 (perp=7.092, rec=0.070, cos=0.002), tot_loss_proj:1.760 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.490 (perp=7.092, rec=0.070, cos=0.002), tot_loss_proj:1.755 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.487 (perp=7.092, rec=0.067, cos=0.002), tot_loss_proj:1.756 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
[1650/2000] tot_loss=1.491 (perp=7.092, rec=0.071, cos=0.002), tot_loss_proj:1.754 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.482 (perp=7.092, rec=0.062, cos=0.002), tot_loss_proj:1.750 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.482 (perp=7.092, rec=0.062, cos=0.002), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
[1800/2000] tot_loss=1.481 (perp=7.092, rec=0.061, cos=0.002), tot_loss_proj:1.751 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.492 (perp=7.092, rec=0.072, cos=0.002), tot_loss_proj:1.762 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.491 (perp=7.092, rec=0.071, cos=0.002), tot_loss_proj:1.739 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
[1950/2000] tot_loss=1.489 (perp=7.092, rec=0.069, cos=0.002), tot_loss_proj:1.750 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.482 (perp=7.092, rec=0.062, cos=0.002), tot_loss_proj:1.753 [t=0.31s]
prediction: ['[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] story circuit is awkwardly paced - soap opera. the ish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 93.773 | p: 93.386 | r: 94.204
rouge2     | fm: 60.699 | p: 60.502 | r: 60.916
rougeL     | fm: 80.361 | p: 80.037 | r: 80.703
rougeLsum  | fm: 80.177 | p: 79.894 | r: 80.521
r1fm+r2fm = 154.472

input #60 time: 0:12:15 | total time: 12:28:26


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.9992846729221321
highest_index [0]
highest [0.9992846729221321]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9770186543464661 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9731178283691406 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.951258659362793 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9493394494056702 for ['[CLS] paths whose bar [SEP]']
[Init] best rec loss: 0.9481885433197021 for ['[CLS]mbledssi commons [SEP]']
[Init] best rec loss: 0.9440215826034546 for ['[CLS] conscious baptizedness [SEP]']
[Init] best rec loss: 0.9340323209762573 for ['[CLS] crested tend prize [SEP]']
[Init] best rec loss: 0.9169715046882629 for ['[CLS] bologna nails steps [SEP]']
[Init] best rec loss: 0.9143086671829224 for ['[CLS] joint flamingual [SEP]']
[Init] best rec loss: 0.9116332530975342 for ['[CLS] you wedding velvet [SEP]']
[Init] best rec loss: 0.9113909006118774 for ['[CLS] installed equipped unlike [SEP]']
[Init] best rec loss: 0.8786194920539856 for ['[CLS] respect thrill butterfly [SEP]']
[Init] best rec loss: 0.8332819938659668 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 0.8225637674331665 for ['[CLS] lets request mini [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.749 (perp=7.752, rec=0.188, cos=0.010), tot_loss_proj:1.817 [t=0.30s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 100/2000] tot_loss=1.705 (perp=7.752, rec=0.147, cos=0.008), tot_loss_proj:1.809 [t=0.31s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 150/2000] tot_loss=1.687 (perp=7.752, rec=0.132, cos=0.005), tot_loss_proj:1.812 [t=0.31s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 200/2000] tot_loss=1.666 (perp=8.032, rec=0.058, cos=0.001), tot_loss_proj:1.703 [t=0.31s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.486 (perp=7.102, rec=0.065, cos=0.002), tot_loss_proj:1.632 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 300/2000] tot_loss=1.493 (perp=7.102, rec=0.071, cos=0.001), tot_loss_proj:1.622 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.491 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.631 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.469 (perp=7.102, rec=0.047, cos=0.001), tot_loss_proj:1.616 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.485 (perp=7.102, rec=0.063, cos=0.001), tot_loss_proj:1.616 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.487 (perp=7.102, rec=0.066, cos=0.001), tot_loss_proj:1.625 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.489 (perp=7.102, rec=0.068, cos=0.001), tot_loss_proj:1.622 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.486 (perp=7.102, rec=0.065, cos=0.001), tot_loss_proj:1.620 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.483 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.626 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.491 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.619 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.482 (perp=7.102, rec=0.060, cos=0.001), tot_loss_proj:1.623 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.481 (perp=7.102, rec=0.059, cos=0.001), tot_loss_proj:1.623 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.496 (perp=7.102, rec=0.074, cos=0.001), tot_loss_proj:1.614 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.484 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.628 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.480 (perp=7.102, rec=0.058, cos=0.001), tot_loss_proj:1.616 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.483 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.620 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.484 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.619 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.480 (perp=7.102, rec=0.058, cos=0.001), tot_loss_proj:1.615 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.483 (perp=7.102, rec=0.061, cos=0.001), tot_loss_proj:1.618 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.497 (perp=7.102, rec=0.075, cos=0.001), tot_loss_proj:1.631 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.490 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.627 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.480 (perp=7.102, rec=0.058, cos=0.001), tot_loss_proj:1.624 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.486 (perp=7.102, rec=0.065, cos=0.001), tot_loss_proj:1.620 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.476 (perp=7.102, rec=0.055, cos=0.001), tot_loss_proj:1.632 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.495 (perp=7.102, rec=0.073, cos=0.001), tot_loss_proj:1.620 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.484 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.636 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.485 (perp=7.102, rec=0.063, cos=0.001), tot_loss_proj:1.634 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.489 (perp=7.102, rec=0.068, cos=0.001), tot_loss_proj:1.615 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.487 (perp=7.102, rec=0.065, cos=0.001), tot_loss_proj:1.626 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.484 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.620 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.483 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.626 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.483 (perp=7.102, rec=0.061, cos=0.001), tot_loss_proj:1.613 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.488 (perp=7.102, rec=0.067, cos=0.001), tot_loss_proj:1.619 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.472 (perp=7.102, rec=0.051, cos=0.001), tot_loss_proj:1.620 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.485 (perp=7.102, rec=0.063, cos=0.001), tot_loss_proj:1.618 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.479 (perp=7.102, rec=0.057, cos=0.001), tot_loss_proj:1.616 [t=0.31s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.855 | p: 93.449 | r: 94.294
rouge2     | fm: 61.272 | p: 61.104 | r: 61.520
rougeL     | fm: 80.681 | p: 80.370 | r: 81.000
rougeLsum  | fm: 80.491 | p: 80.194 | r: 80.826
r1fm+r2fm = 155.127

input #61 time: 0:12:14 | total time: 12:40:40


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.9992556315775536
highest_index [0]
highest [0.9992556315775536]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9529485106468201 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9264677166938782 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.9195437431335449 for ['[CLS] percentage trap danzinghur shapeee sacred persianlon record theater freestylegold cards dance sacks pits dreadmund existed [SEP]']
[Init] best perm rec loss: 0.919096827507019 for ['[CLS] persian cardslonmund pits trap theater record percentage dread dan freestyle sackshur existedzing dancegoldee shape sacred [SEP]']
[Init] best perm rec loss: 0.9188913702964783 for ['[CLS] cards trap dread freestylelon dance sackszing pitshurgold record percentage shape persian dan sacred existed theatereemund [SEP]']
[Init] best perm rec loss: 0.9185793995857239 for ['[CLS]zinggold trap persianmund cardslon percentage dan existed theater pits sacredhur record freestyle dread sacks shapeee dance [SEP]']
[Init] best perm rec loss: 0.9185484051704407 for ['[CLS] freestyle sacks cards dread sacredee theater percentagegoldlon shapemund existedhur persian dancezing pits record dan trap [SEP]']
[Init] best perm rec loss: 0.9177361726760864 for ['[CLS] recordzing sacred persian sacks theaterloneemundgold pits existed shape dan cards dance freestyle dread percentage traphur [SEP]']
[Init] best perm rec loss: 0.9168397188186646 for ['[CLS] persian dan pits shapezing sacred percentage record sacksgold dancehur cardsmund dreadlonee trap freestyle existed theater [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.450 (perp=10.691, rec=0.305, cos=0.007), tot_loss_proj:3.618 [t=0.31s]
prediction: ['[CLS] best greater [SEP] skills for as paul for stratford prevention making for division film best best grace prevention best prevention war [SEP]']
[ 100/2000] tot_loss=2.289 (perp=10.427, rec=0.200, cos=0.004), tot_loss_proj:3.703 [t=0.32s]
prediction: ['[CLS] best to, movies making among war to soldiers prevention making most movies movies ever best grace prevention to prevention war [SEP]']
[ 150/2000] tot_loss=2.072 (perp=9.613, rec=0.147, cos=0.002), tot_loss_proj:3.597 [t=0.32s]
prediction: ['[CLS] best to, movies making as war to soldiers prevention one the movies movies ever best grace ever to prevention war [SEP]']
[ 200/2000] tot_loss=2.047 (perp=9.589, rec=0.127, cos=0.002), tot_loss_proj:3.581 [t=0.32s]
prediction: ['[CLS] best to, prevention making of war call calls prevention one the movies movies ever best grace ever to prevention war [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.059 (perp=9.328, rec=0.190, cos=0.004), tot_loss_proj:3.042 [t=0.32s]
prediction: ['[CLS] best to ever, picture making of call call when prevention one the movies film best grace ever to prevention war [SEP]']
[ 300/2000] tot_loss=2.070 (perp=9.690, rec=0.130, cos=0.002), tot_loss_proj:3.559 [t=0.41s]
prediction: ['[CLS] call to ever, presentation making one for call when blame one the movies made best grace ever to prevention war [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.859 (perp=8.695, rec=0.118, cos=0.002), tot_loss_proj:3.433 [t=0.32s]
prediction: ['[CLS] call to ever, movie when making one for call blame it the movies made best grace ever to prevention war [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.772 (perp=8.344, rec=0.101, cos=0.002), tot_loss_proj:3.633 [t=0.32s]
prediction: ['[CLS] call to war, movie rather making one for call blame it the movies made best grace ever to prevention ever [SEP]']
[ 450/2000] tot_loss=1.740 (perp=8.241, rec=0.090, cos=0.002), tot_loss_proj:3.647 [t=0.32s]
prediction: ['[CLS] call to war, movie rather making one for call blame it the movies made best grace for to prevention ever [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.674 (perp=7.956, rec=0.081, cos=0.002), tot_loss_proj:3.611 [t=0.32s]
prediction: ['[CLS] call to war, movie rather making one for call blame it the movies made to grace for best prevention ever [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.739 (perp=8.258, rec=0.086, cos=0.002), tot_loss_proj:3.651 [t=0.32s]
prediction: ['[CLS] call to war, movies rather making one for call blame it the movies made to grace to best prevention ever [SEP]']
[ 600/2000] tot_loss=1.737 (perp=8.282, rec=0.079, cos=0.002), tot_loss_proj:3.640 [t=0.32s]
prediction: ['[CLS] of to war, movies rather making one for call blame it the movies made to grace to best prevention ever [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.681 (perp=8.067, rec=0.066, cos=0.002), tot_loss_proj:3.585 [t=0.32s]
prediction: ['[CLS] of to war movies, rather making one for call blame it the movies made to grace to best prevention ever [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.715 (perp=8.199, rec=0.073, cos=0.002), tot_loss_proj:3.618 [t=0.32s]
prediction: ['[CLS] of to war movies, rather making one blame for call it the movies made to grace place best prevention ever [SEP]']
[ 750/2000] tot_loss=1.720 (perp=8.199, rec=0.078, cos=0.001), tot_loss_proj:3.614 [t=0.32s]
prediction: ['[CLS] of to war movies, rather making one blame for call it the movies made to grace place best prevention ever [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.723 (perp=8.175, rec=0.086, cos=0.002), tot_loss_proj:3.407 [t=0.32s]
prediction: ['[CLS] of to war for, rather making one blame for call it the best movies made to grace place prevention ever [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.661 (perp=7.943, rec=0.071, cos=0.002), tot_loss_proj:3.467 [t=0.32s]
prediction: ['[CLS] of to war, for rather making one blame for call it the best movies made to grace place prevention ever [SEP]']
[ 900/2000] tot_loss=1.666 (perp=7.943, rec=0.075, cos=0.001), tot_loss_proj:3.473 [t=0.32s]
prediction: ['[CLS] of to war, for rather making one blame for call it the best movies made to grace place prevention ever [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.663 (perp=7.943, rec=0.073, cos=0.002), tot_loss_proj:3.473 [t=0.32s]
prediction: ['[CLS] of to war, for rather making one blame for call it the best movies made to grace place prevention ever [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.601 (perp=7.652, rec=0.070, cos=0.002), tot_loss_proj:3.409 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one blame for call it the best of made to grace place prevention ever [SEP]']
[1050/2000] tot_loss=1.603 (perp=7.652, rec=0.072, cos=0.001), tot_loss_proj:3.411 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one blame for call it the best of made to grace place prevention ever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.611 (perp=7.652, rec=0.079, cos=0.001), tot_loss_proj:3.411 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one blame for call it the best of made to grace place prevention ever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.604 (perp=7.652, rec=0.072, cos=0.001), tot_loss_proj:3.409 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one blame for call it the best of made to grace place prevention ever [SEP]']
[1200/2000] tot_loss=1.604 (perp=7.652, rec=0.072, cos=0.001), tot_loss_proj:3.408 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one blame for call it the best of made to grace place prevention ever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.603 (perp=7.652, rec=0.071, cos=0.001), tot_loss_proj:3.412 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one blame for call it the best of made to grace place prevention ever [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.580 (perp=7.504, rec=0.077, cos=0.002), tot_loss_proj:3.372 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one blame for call it the best of to grace place prevention ever made [SEP]']
[1350/2000] tot_loss=1.578 (perp=7.504, rec=0.076, cos=0.001), tot_loss_proj:3.373 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one blame for call it the best of to grace place prevention ever made [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.539 (perp=7.332, rec=0.071, cos=0.002), tot_loss_proj:3.408 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one blame for call it the best place of to grace prevention ever made [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.447 (perp=6.840, rec=0.077, cos=0.002), tot_loss_proj:3.280 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one to blame for call it the best place of grace prevention ever made [SEP]']
[1500/2000] tot_loss=1.451 (perp=6.840, rec=0.081, cos=0.001), tot_loss_proj:3.278 [t=0.31s]
prediction: ['[CLS] movies to war, for rather making one to blame for call it the best place of grace prevention ever made [SEP]']
Attempt swap
[1550/2000] tot_loss=1.450 (perp=6.840, rec=0.081, cos=0.001), tot_loss_proj:3.278 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one to blame for call it the best place of grace prevention ever made [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.427 (perp=6.770, rec=0.071, cos=0.002), tot_loss_proj:3.005 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one to blame for grace call it the best place of prevention ever made [SEP]']
[1650/2000] tot_loss=1.427 (perp=6.770, rec=0.071, cos=0.001), tot_loss_proj:3.005 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one to blame for grace call it the best place of prevention ever made [SEP]']
Attempt swap
[1700/2000] tot_loss=1.428 (perp=6.770, rec=0.073, cos=0.001), tot_loss_proj:3.005 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one to blame for grace call it the best place of prevention ever made [SEP]']
Attempt swap
[1750/2000] tot_loss=1.432 (perp=6.770, rec=0.077, cos=0.001), tot_loss_proj:3.002 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one to blame for grace call it the best place of prevention ever made [SEP]']
[1800/2000] tot_loss=1.435 (perp=6.770, rec=0.079, cos=0.001), tot_loss_proj:3.003 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one to blame for grace call it the best place of prevention ever made [SEP]']
Attempt swap
[1850/2000] tot_loss=1.430 (perp=6.770, rec=0.074, cos=0.001), tot_loss_proj:3.003 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one to blame for grace call it the best place of prevention ever made [SEP]']
Attempt swap
[1900/2000] tot_loss=1.418 (perp=6.770, rec=0.063, cos=0.001), tot_loss_proj:3.003 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one to blame for grace call it the best place of prevention ever made [SEP]']
[1950/2000] tot_loss=1.428 (perp=6.770, rec=0.073, cos=0.001), tot_loss_proj:3.008 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one to blame for grace call it the best place of prevention ever made [SEP]']
Attempt swap
[2000/2000] tot_loss=1.433 (perp=6.770, rec=0.078, cos=0.001), tot_loss_proj:3.003 [t=0.32s]
prediction: ['[CLS] movies to war, for rather making one to blame for grace call it the best place of prevention ever made [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] movies to war, for rather making one to blame for grace call it the best place of prevention ever made [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.455 | p: 95.455 | r: 95.455
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 109.740

[Aggregate metrics]:
rouge1     | fm: 93.890 | p: 93.493 | r: 94.321
rouge2     | fm: 60.493 | p: 60.272 | r: 60.744
rougeL     | fm: 80.275 | p: 80.013 | r: 80.626
rougeLsum  | fm: 80.111 | p: 79.828 | r: 80.436
r1fm+r2fm = 154.383

input #62 time: 0:12:34 | total time: 12:53:15


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.999264921458706
highest_index [0]
highest [0.999264921458706]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.9518564939498901 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.9044175744056702 for ['[CLS] touch alternative glacier bentry [SEP]']
[Init] best rec loss: 0.7472962141036987 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7390465140342712 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 0.7275313138961792 for ['[CLS] forces solutions... offense civil [SEP]']
[Init] best perm rec loss: 0.7268006205558777 for ['[CLS] forces civil solutions offense... [SEP]']
[Init] best perm rec loss: 0.7262475490570068 for ['[CLS]... forces solutions civil offense [SEP]']
[Init] best perm rec loss: 0.7247685194015503 for ['[CLS] solutions forces... offense civil [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.355 (perp=9.927, rec=0.329, cos=0.040), tot_loss_proj:3.135 [t=0.31s]
prediction: ['[CLS] challenge doomed lost ticket ticket [SEP]']
[ 100/2000] tot_loss=2.427 (perp=11.270, rec=0.164, cos=0.010), tot_loss_proj:3.181 [t=0.31s]
prediction: ['[CLS] looking return off return ticket [SEP]']
[ 150/2000] tot_loss=1.311 (perp=6.111, rec=0.087, cos=0.002), tot_loss_proj:1.310 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 200/2000] tot_loss=1.292 (perp=6.111, rec=0.068, cos=0.002), tot_loss_proj:1.318 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.295 (perp=6.111, rec=0.072, cos=0.001), tot_loss_proj:1.312 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 300/2000] tot_loss=1.292 (perp=6.111, rec=0.068, cos=0.001), tot_loss_proj:1.307 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.292 (perp=6.111, rec=0.069, cos=0.001), tot_loss_proj:1.313 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.286 (perp=6.111, rec=0.062, cos=0.001), tot_loss_proj:1.302 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 450/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.291 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.280 (perp=6.111, rec=0.056, cos=0.001), tot_loss_proj:1.305 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.276 (perp=6.111, rec=0.052, cos=0.001), tot_loss_proj:1.305 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 600/2000] tot_loss=1.285 (perp=6.111, rec=0.062, cos=0.001), tot_loss_proj:1.310 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.295 (perp=6.111, rec=0.072, cos=0.001), tot_loss_proj:1.312 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.286 (perp=6.111, rec=0.062, cos=0.001), tot_loss_proj:1.307 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 750/2000] tot_loss=1.285 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.311 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.273 (perp=6.111, rec=0.049, cos=0.001), tot_loss_proj:1.305 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.280 (perp=6.111, rec=0.057, cos=0.001), tot_loss_proj:1.314 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 900/2000] tot_loss=1.273 (perp=6.111, rec=0.049, cos=0.001), tot_loss_proj:1.300 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.293 (perp=6.111, rec=0.069, cos=0.001), tot_loss_proj:1.307 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.284 (perp=6.111, rec=0.060, cos=0.001), tot_loss_proj:1.317 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1050/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.001), tot_loss_proj:1.312 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.280 (perp=6.111, rec=0.057, cos=0.001), tot_loss_proj:1.306 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.273 (perp=6.111, rec=0.050, cos=0.001), tot_loss_proj:1.304 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1200/2000] tot_loss=1.278 (perp=6.111, rec=0.055, cos=0.001), tot_loss_proj:1.321 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.284 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.309 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.313 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.312 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.286 (perp=6.111, rec=0.062, cos=0.001), tot_loss_proj:1.308 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.285 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.301 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.285 (perp=6.111, rec=0.062, cos=0.001), tot_loss_proj:1.311 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.276 (perp=6.111, rec=0.052, cos=0.001), tot_loss_proj:1.304 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.315 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.279 (perp=6.111, rec=0.055, cos=0.001), tot_loss_proj:1.311 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.289 (perp=6.111, rec=0.065, cos=0.001), tot_loss_proj:1.306 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.288 (perp=6.111, rec=0.065, cos=0.001), tot_loss_proj:1.317 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.284 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.300 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.292 (perp=6.111, rec=0.068, cos=0.001), tot_loss_proj:1.315 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.283 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.300 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.282 (perp=6.111, rec=0.058, cos=0.001), tot_loss_proj:1.315 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.001), tot_loss_proj:1.314 [t=0.31s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.964 | p: 93.611 | r: 94.347
rouge2     | fm: 61.185 | p: 60.979 | r: 61.413
rougeL     | fm: 80.504 | p: 80.182 | r: 80.841
rougeLsum  | fm: 80.350 | p: 80.057 | r: 80.674
r1fm+r2fm = 155.148

input #63 time: 0:12:14 | total time: 13:05:29


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.9991614570611808
highest_index [0]
highest [0.9991614570611808]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8783310651779175 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8686643242835999 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 0.7262557148933411 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6715089082717896 for ['[CLS]onale water visions [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.350 (perp=10.304, rec=0.238, cos=0.050), tot_loss_proj:2.414 [t=0.30s]
prediction: ['[CLS] horror strange horror [SEP]']
[ 100/2000] tot_loss=2.000 (perp=9.190, rec=0.145, cos=0.017), tot_loss_proj:2.210 [t=0.31s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 150/2000] tot_loss=1.970 (perp=9.190, rec=0.120, cos=0.012), tot_loss_proj:2.212 [t=0.31s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 200/2000] tot_loss=1.910 (perp=9.190, rec=0.070, cos=0.002), tot_loss_proj:2.219 [t=0.31s]
prediction: ['[CLS] strange strange horror [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.686 (perp=8.065, rec=0.070, cos=0.003), tot_loss_proj:1.709 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[ 300/2000] tot_loss=1.671 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.707 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.676 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.707 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.714 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.709 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.672 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.703 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.721 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.712 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.713 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.701 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.683 (perp=8.065, rec=0.069, cos=0.002), tot_loss_proj:1.708 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.663 (perp=8.065, rec=0.048, cos=0.002), tot_loss_proj:1.709 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.685 (perp=8.065, rec=0.070, cos=0.002), tot_loss_proj:1.712 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.669 (perp=8.065, rec=0.055, cos=0.002), tot_loss_proj:1.717 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.663 (perp=8.065, rec=0.048, cos=0.002), tot_loss_proj:1.708 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.675 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.702 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.707 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.671 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.715 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.676 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.704 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.683 (perp=8.065, rec=0.069, cos=0.002), tot_loss_proj:1.711 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.684 (perp=8.065, rec=0.070, cos=0.002), tot_loss_proj:1.704 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.688 (perp=8.065, rec=0.073, cos=0.002), tot_loss_proj:1.706 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.672 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.705 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.689 (perp=8.065, rec=0.074, cos=0.002), tot_loss_proj:1.727 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.723 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.670 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.711 [t=0.32s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.675 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.706 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.715 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.717 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.723 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.671 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.702 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.673 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.714 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.670 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.721 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.676 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.703 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.708 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.696 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.109 | p: 93.725 | r: 94.513
rouge2     | fm: 61.762 | p: 61.618 | r: 61.979
rougeL     | fm: 80.950 | p: 80.665 | r: 81.319
rougeLsum  | fm: 80.861 | p: 80.572 | r: 81.173
r1fm+r2fm = 155.871

input #64 time: 0:12:14 | total time: 13:17:43


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9992250933566145
highest_index [0]
highest [0.9992250933566145]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.022713541984558 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9600198268890381 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.9548696875572205 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.9472326636314392 for ['[CLS]blpf bce med stride plot skip honest what [SEP]']
[Init] best rec loss: 0.8872684836387634 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8812433481216431 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.8795079588890076 for ['[CLS] even news pu someday fun general oversmamenthoff [SEP]']
[Init] best perm rec loss: 0.8754494786262512 for ['[CLS] pu news even oversmament someday funhoff general [SEP]']
[Init] best perm rec loss: 0.8751453757286072 for ['[CLS] news generalmament overs pu even funhoff someday [SEP]']
[Init] best perm rec loss: 0.8746073842048645 for ['[CLS] news general pu someday overshoffmament even fun [SEP]']
[Init] best perm rec loss: 0.8742632865905762 for ['[CLS] pumament somedayhoff overs news fun even general [SEP]']
[Init] best perm rec loss: 0.8731095790863037 for ['[CLS] someday general evenmament overs newshoff fun pu [SEP]']
[Init] best perm rec loss: 0.8726373314857483 for ['[CLS] general news evenmamenthoff someday fun pu overs [SEP]']
[Init] best perm rec loss: 0.8722110390663147 for ['[CLS] fun even newsmamenthoff someday pu overs general [SEP]']
[Init] best perm rec loss: 0.8700366616249084 for ['[CLS] fun even someday generalmament puhoff overs news [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.434 (perp=10.691, rec=0.288, cos=0.008), tot_loss_proj:2.716 [t=0.31s]
prediction: ['[CLS] joyous. rom strap, film creature joy [SEP]']
[ 100/2000] tot_loss=1.903 (perp=8.809, rec=0.139, cos=0.003), tot_loss_proj:2.359 [t=0.31s]
prediction: ['[CLS] joyous.,e of film film joy [SEP]']
[ 150/2000] tot_loss=1.660 (perp=7.791, rec=0.100, cos=0.002), tot_loss_proj:2.113 [t=0.31s]
prediction: ['[CLS] joyous.,p a film film rom [SEP]']
[ 200/2000] tot_loss=1.644 (perp=7.791, rec=0.084, cos=0.002), tot_loss_proj:2.119 [t=0.31s]
prediction: ['[CLS] joyous.,p a film film rom [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.390 (perp=6.429, rec=0.102, cos=0.002), tot_loss_proj:1.641 [t=0.31s]
prediction: ['[CLS] joyous., a film film romp [SEP]']
[ 300/2000] tot_loss=1.371 (perp=6.429, rec=0.084, cos=0.002), tot_loss_proj:1.641 [t=0.31s]
prediction: ['[CLS] joyous., a film film romp [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.272 (perp=5.928, rec=0.085, cos=0.002), tot_loss_proj:1.573 [t=0.31s]
prediction: ['[CLS] joyous., a film romp film [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.226 (perp=5.670, rec=0.090, cos=0.002), tot_loss_proj:1.508 [t=0.31s]
prediction: ['[CLS] joyous. a film romp film, [SEP]']
[ 450/2000] tot_loss=1.213 (perp=5.670, rec=0.077, cos=0.002), tot_loss_proj:1.497 [t=0.31s]
prediction: ['[CLS] joyous. a film romp film, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.080 (perp=5.033, rec=0.072, cos=0.002), tot_loss_proj:1.394 [t=0.31s]
prediction: ['[CLS] joyous, a film romp film. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.042 (perp=4.772, rec=0.086, cos=0.002), tot_loss_proj:1.357 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
[ 600/2000] tot_loss=1.034 (perp=4.772, rec=0.078, cos=0.002), tot_loss_proj:1.366 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.029 (perp=4.772, rec=0.074, cos=0.002), tot_loss_proj:1.370 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.023 (perp=4.772, rec=0.067, cos=0.002), tot_loss_proj:1.368 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
[ 750/2000] tot_loss=1.040 (perp=4.772, rec=0.084, cos=0.002), tot_loss_proj:1.370 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.030 (perp=4.772, rec=0.074, cos=0.002), tot_loss_proj:1.369 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.027 (perp=4.772, rec=0.071, cos=0.002), tot_loss_proj:1.369 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
[ 900/2000] tot_loss=1.026 (perp=4.772, rec=0.070, cos=0.002), tot_loss_proj:1.377 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.030 (perp=4.772, rec=0.074, cos=0.002), tot_loss_proj:1.369 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.030 (perp=4.772, rec=0.074, cos=0.002), tot_loss_proj:1.368 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
[1050/2000] tot_loss=1.029 (perp=4.772, rec=0.073, cos=0.002), tot_loss_proj:1.373 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.028 (perp=4.772, rec=0.072, cos=0.002), tot_loss_proj:1.379 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.020 (perp=4.772, rec=0.064, cos=0.002), tot_loss_proj:1.374 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
[1200/2000] tot_loss=1.023 (perp=4.772, rec=0.067, cos=0.002), tot_loss_proj:1.374 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.034 (perp=4.772, rec=0.078, cos=0.002), tot_loss_proj:1.369 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.030 (perp=4.772, rec=0.074, cos=0.002), tot_loss_proj:1.374 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
[1350/2000] tot_loss=1.023 (perp=4.772, rec=0.067, cos=0.002), tot_loss_proj:1.374 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.026 (perp=4.772, rec=0.070, cos=0.002), tot_loss_proj:1.380 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.031 (perp=4.772, rec=0.075, cos=0.002), tot_loss_proj:1.382 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
[1500/2000] tot_loss=1.025 (perp=4.772, rec=0.069, cos=0.002), tot_loss_proj:1.376 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.025 (perp=4.772, rec=0.069, cos=0.002), tot_loss_proj:1.376 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.026 (perp=4.772, rec=0.070, cos=0.002), tot_loss_proj:1.372 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
[1650/2000] tot_loss=1.027 (perp=4.772, rec=0.071, cos=0.002), tot_loss_proj:1.369 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.033 (perp=4.772, rec=0.077, cos=0.002), tot_loss_proj:1.379 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.027 (perp=4.772, rec=0.071, cos=0.002), tot_loss_proj:1.374 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
[1800/2000] tot_loss=1.034 (perp=4.772, rec=0.078, cos=0.002), tot_loss_proj:1.381 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.028 (perp=4.772, rec=0.072, cos=0.002), tot_loss_proj:1.375 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.025 (perp=4.772, rec=0.069, cos=0.002), tot_loss_proj:1.373 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
[1950/2000] tot_loss=1.030 (perp=4.772, rec=0.074, cos=0.002), tot_loss_proj:1.379 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.036 (perp=4.772, rec=0.080, cos=0.002), tot_loss_proj:1.371 [t=0.31s]
prediction: ['[CLS] film joyous, a romp film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] film joyous, a romp film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 102.381

[Aggregate metrics]:
rouge1     | fm: 94.011 | p: 93.628 | r: 94.412
rouge2     | fm: 61.039 | p: 60.849 | r: 61.172
rougeL     | fm: 80.781 | p: 80.484 | r: 81.124
rougeLsum  | fm: 80.698 | p: 80.378 | r: 81.009
r1fm+r2fm = 155.050

input #65 time: 0:12:16 | total time: 13:30:00


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.999233833244541
highest_index [0]
highest [0.999233833244541]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.9724670052528381 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.9289834499359131 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.9163521528244019 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.888077437877655 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.8851446509361267 for ['[CLS] at model frances us [SEP]']
[Init] best rec loss: 0.8729965090751648 for ['[CLS]beersa bryce two [SEP]']
[Init] best perm rec loss: 0.8725722432136536 for ['[CLS] brycebee tworsa [SEP]']
[Init] best perm rec loss: 0.8695104122161865 for ['[CLS]bee brycersa two [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.341 (perp=10.734, rec=0.186, cos=0.007), tot_loss_proj:2.357 [t=0.30s]
prediction: ['[CLS] an tolkien longtime fan [SEP]']
[ 100/2000] tot_loss=2.049 (perp=9.911, rec=0.065, cos=0.002), tot_loss_proj:2.204 [t=0.31s]
prediction: ['[CLS] a tolkien longtime fan [SEP]']
[ 150/2000] tot_loss=2.052 (perp=9.911, rec=0.068, cos=0.002), tot_loss_proj:2.201 [t=0.31s]
prediction: ['[CLS] a tolkien longtime fan [SEP]']
[ 200/2000] tot_loss=2.045 (perp=9.911, rec=0.061, cos=0.002), tot_loss_proj:2.208 [t=0.31s]
prediction: ['[CLS] a tolkien longtime fan [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.600 (perp=7.672, rec=0.064, cos=0.002), tot_loss_proj:1.591 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.596 (perp=7.672, rec=0.060, cos=0.002), tot_loss_proj:1.588 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.606 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.607 (perp=7.672, rec=0.071, cos=0.002), tot_loss_proj:1.603 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.588 (perp=7.672, rec=0.052, cos=0.002), tot_loss_proj:1.595 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.594 (perp=7.672, rec=0.058, cos=0.002), tot_loss_proj:1.601 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.590 (perp=7.672, rec=0.054, cos=0.002), tot_loss_proj:1.604 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.586 (perp=7.672, rec=0.050, cos=0.002), tot_loss_proj:1.602 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.596 (perp=7.672, rec=0.060, cos=0.002), tot_loss_proj:1.595 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.596 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.601 (perp=7.672, rec=0.065, cos=0.002), tot_loss_proj:1.599 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.596 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.607 (perp=7.672, rec=0.071, cos=0.002), tot_loss_proj:1.604 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.591 (perp=7.672, rec=0.055, cos=0.002), tot_loss_proj:1.610 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.593 (perp=7.672, rec=0.057, cos=0.002), tot_loss_proj:1.597 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.596 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.588 (perp=7.672, rec=0.052, cos=0.002), tot_loss_proj:1.593 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.590 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.586 (perp=7.672, rec=0.050, cos=0.002), tot_loss_proj:1.604 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.595 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.592 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.599 (perp=7.672, rec=0.063, cos=0.002), tot_loss_proj:1.607 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.606 (perp=7.672, rec=0.070, cos=0.002), tot_loss_proj:1.602 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.596 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.598 (perp=7.672, rec=0.062, cos=0.002), tot_loss_proj:1.594 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.599 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.591 (perp=7.672, rec=0.055, cos=0.002), tot_loss_proj:1.591 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.586 (perp=7.672, rec=0.050, cos=0.002), tot_loss_proj:1.592 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.595 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.598 (perp=7.672, rec=0.062, cos=0.002), tot_loss_proj:1.600 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.591 (perp=7.672, rec=0.055, cos=0.002), tot_loss_proj:1.602 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.590 (perp=7.672, rec=0.054, cos=0.002), tot_loss_proj:1.602 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.600 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.596 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.593 (perp=7.672, rec=0.057, cos=0.002), tot_loss_proj:1.607 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.595 (perp=7.672, rec=0.058, cos=0.002), tot_loss_proj:1.603 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.123 | p: 93.790 | r: 94.512
rouge2     | fm: 61.658 | p: 61.499 | r: 61.850
rougeL     | fm: 81.107 | p: 80.846 | r: 81.393
rougeLsum  | fm: 80.915 | p: 80.596 | r: 81.250
r1fm+r2fm = 155.781

input #66 time: 0:12:14 | total time: 13:42:14


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.9992939885800858
highest_index [0]
highest [0.9992939885800858]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.003401517868042 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.958034336566925 for ['[CLS] clear winnie cloudsc ling commercialiny royal classic [UNK] [SEP]']
[Init] best rec loss: 0.957060694694519 for ['[CLS] repeat well rv strikes combined leaned written itself welsh bunch [SEP]']
[Init] best rec loss: 0.9531173706054688 for ['[CLS] position citationliga carriage demands source administered leancode pope [SEP]']
[Init] best rec loss: 0.9479013681411743 for ['[CLS] contributions. cars tied sir if - stalk alexis hilton [SEP]']
[Init] best rec loss: 0.9349614381790161 for ['[CLS] investment parker mostly radical national snow nearly baltimore contact are [SEP]']
[Init] best rec loss: 0.9309601187705994 for ['[CLS]ible ultimately season mainly swifthood abby source price need [SEP]']
[Init] best rec loss: 0.9267403483390808 for ['[CLS] wild tribes upon cone home enough promotion mural courtney ） [SEP]']
[Init] best perm rec loss: 0.9237328171730042 for ['[CLS] promotion home cone courtney mural wild ） enough tribes upon [SEP]']
[Init] best perm rec loss: 0.9236021041870117 for ['[CLS] upon home ） cone promotion enough tribes courtney wild mural [SEP]']
[Init] best perm rec loss: 0.9227206110954285 for ['[CLS] ） cone upon enough courtney tribes wild promotion home mural [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.995 (perp=13.022, rec=0.371, cos=0.020), tot_loss_proj:4.564 [t=0.31s]
prediction: ['[CLS] studio celebrationcent amor created based kind ( negative kind [SEP]']
[ 100/2000] tot_loss=2.836 (perp=13.187, rec=0.194, cos=0.004), tot_loss_proj:4.290 [t=0.31s]
prediction: ['[CLS] damwar fibreentalmentalming, non kind [SEP]']
[ 150/2000] tot_loss=2.735 (perp=12.907, rec=0.151, cos=0.003), tot_loss_proj:4.233 [t=0.31s]
prediction: ['[CLS] damwar fibregmvertedentalming, non kind [SEP]']
[ 200/2000] tot_loss=2.552 (perp=12.092, rec=0.131, cos=0.003), tot_loss_proj:4.319 [t=0.31s]
prediction: ['[CLS] heartwargmgmenceentalming, non kind [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.394 (perp=10.848, rec=0.220, cos=0.005), tot_loss_proj:3.991 [t=0.31s]
prediction: ['[CLS] heartwarentalgmental nonming, non kind [SEP]']
[ 300/2000] tot_loss=2.502 (perp=11.739, rec=0.151, cos=0.003), tot_loss_proj:4.253 [t=0.31s]
prediction: ['[CLS] heartwarentalgmentaljuming, non kind [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.143 (perp=10.021, rec=0.136, cos=0.002), tot_loss_proj:3.267 [t=0.31s]
prediction: ['[CLS] heartwarminggmentaljuental, non kind [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.074 (perp=9.673, rec=0.137, cos=0.002), tot_loss_proj:3.179 [t=0.31s]
prediction: ['[CLS] heartwarmingjuentalgmental, non kind [SEP]']
[ 450/2000] tot_loss=2.035 (perp=9.673, rec=0.099, cos=0.002), tot_loss_proj:3.173 [t=0.31s]
prediction: ['[CLS] heartwarmingjuentalgmental, non kind [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.803 (perp=8.500, rec=0.102, cos=0.002), tot_loss_proj:2.191 [t=0.31s]
prediction: ['[CLS] heartwarmingjuental nongmental, kind [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.717 (perp=8.147, rec=0.086, cos=0.002), tot_loss_proj:2.226 [t=0.31s]
prediction: ['[CLS] heartwarmingjuental nongmental kind, [SEP]']
[ 600/2000] tot_loss=1.711 (perp=8.147, rec=0.080, cos=0.002), tot_loss_proj:2.215 [t=0.31s]
prediction: ['[CLS] heartwarmingjuental nongmental kind, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.706 (perp=8.147, rec=0.075, cos=0.001), tot_loss_proj:2.217 [t=0.31s]
prediction: ['[CLS] heartwarmingjuental nongmental kind, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.701 (perp=8.147, rec=0.070, cos=0.001), tot_loss_proj:2.222 [t=0.31s]
prediction: ['[CLS] heartwarmingjuental nongmental kind, [SEP]']
[ 750/2000] tot_loss=1.738 (perp=8.270, rec=0.083, cos=0.001), tot_loss_proj:2.397 [t=0.31s]
prediction: ['[CLS] heartwarmingjun nongmental kind, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.726 (perp=8.270, rec=0.071, cos=0.001), tot_loss_proj:2.395 [t=0.31s]
prediction: ['[CLS] heartwarmingjun nongmental kind, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.725 (perp=8.270, rec=0.069, cos=0.001), tot_loss_proj:2.393 [t=0.31s]
prediction: ['[CLS] heartwarmingjun nongmental kind, [SEP]']
[ 900/2000] tot_loss=1.727 (perp=8.270, rec=0.072, cos=0.001), tot_loss_proj:2.398 [t=0.31s]
prediction: ['[CLS] heartwarmingjun nongmental kind, [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.601 (perp=7.535, rec=0.093, cos=0.002), tot_loss_proj:1.859 [t=0.31s]
prediction: ['[CLS] heartwarming nonjungmental kind, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=7.535, rec=0.079, cos=0.001), tot_loss_proj:1.856 [t=0.31s]
prediction: ['[CLS] heartwarming nonjungmental kind, [SEP]']
[1050/2000] tot_loss=1.591 (perp=7.535, rec=0.082, cos=0.001), tot_loss_proj:1.865 [t=0.31s]
prediction: ['[CLS] heartwarming nonjungmental kind, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.592 (perp=7.535, rec=0.084, cos=0.001), tot_loss_proj:1.847 [t=0.31s]
prediction: ['[CLS] heartwarming nonjungmental kind, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.589 (perp=7.535, rec=0.080, cos=0.001), tot_loss_proj:1.859 [t=0.31s]
prediction: ['[CLS] heartwarming nonjungmental kind, [SEP]']
[1200/2000] tot_loss=1.284 (perp=6.020, rec=0.078, cos=0.001), tot_loss_proj:1.475 [t=0.31s]
prediction: ['[CLS] heartwarming nonjudgmental kind, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.271 (perp=6.020, rec=0.066, cos=0.001), tot_loss_proj:1.485 [t=0.31s]
prediction: ['[CLS] heartwarming nonjudgmental kind, [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.225 (perp=5.647, rec=0.094, cos=0.002), tot_loss_proj:1.227 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1350/2000] tot_loss=1.200 (perp=5.647, rec=0.069, cos=0.001), tot_loss_proj:1.224 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1400/2000] tot_loss=1.214 (perp=5.647, rec=0.083, cos=0.001), tot_loss_proj:1.230 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1450/2000] tot_loss=1.207 (perp=5.647, rec=0.077, cos=0.001), tot_loss_proj:1.228 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1500/2000] tot_loss=1.207 (perp=5.647, rec=0.076, cos=0.001), tot_loss_proj:1.228 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1550/2000] tot_loss=1.200 (perp=5.647, rec=0.069, cos=0.001), tot_loss_proj:1.238 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1600/2000] tot_loss=1.203 (perp=5.647, rec=0.072, cos=0.001), tot_loss_proj:1.234 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1650/2000] tot_loss=1.204 (perp=5.647, rec=0.073, cos=0.001), tot_loss_proj:1.225 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1700/2000] tot_loss=1.198 (perp=5.647, rec=0.067, cos=0.001), tot_loss_proj:1.241 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1750/2000] tot_loss=1.208 (perp=5.647, rec=0.077, cos=0.001), tot_loss_proj:1.226 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1800/2000] tot_loss=1.209 (perp=5.647, rec=0.078, cos=0.001), tot_loss_proj:1.226 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1850/2000] tot_loss=1.207 (perp=5.647, rec=0.076, cos=0.001), tot_loss_proj:1.229 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1900/2000] tot_loss=1.203 (perp=5.647, rec=0.072, cos=0.001), tot_loss_proj:1.223 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1950/2000] tot_loss=1.214 (perp=5.647, rec=0.083, cos=0.001), tot_loss_proj:1.234 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[2000/2000] tot_loss=1.199 (perp=5.647, rec=0.069, cos=0.001), tot_loss_proj:1.226 [t=0.31s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.170 | p: 93.811 | r: 94.558
rouge2     | fm: 62.353 | p: 62.170 | r: 62.523
rougeL     | fm: 81.421 | p: 81.152 | r: 81.728
rougeLsum  | fm: 81.373 | p: 81.081 | r: 81.647
r1fm+r2fm = 156.523

input #67 time: 0:12:16 | total time: 13:54:30


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9992782701117546
highest_index [0]
highest [0.9992782701117546]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9874358177185059 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.967254102230072 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 0.9668422341346741 for ['[CLS]cloth domain art part littlekeeper deficit surf were wait tee mat steps [SEP]']
[Init] best rec loss: 0.9405279159545898 for ['[CLS] raise describedwehrwork witch rom can bray fictional elton here sex pilots [SEP]']
[Init] best rec loss: 0.9242609739303589 for ['[CLS] neutron acrosswas 2005 security tip fa— identity david entitled readers letters [SEP]']
[Init] best rec loss: 0.8651895523071289 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8629862666130066 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8591676950454712 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.8516318202018738 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.8499172925949097 for ['[CLS]iferous beth died form. floor councils riding medalyn view possibly comfort [SEP]']
[Init] best perm rec loss: 0.8482029438018799 for ['[CLS]iferousyn form comfort. possibly councils floor view medal beth died riding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.284 (perp=10.321, rec=0.214, cos=0.006), tot_loss_proj:2.696 [t=0.31s]
prediction: ['[CLS] dangerous ins french absurdsible vicious absurd parts absurd, absurd, ( [SEP]']
[ 100/2000] tot_loss=2.118 (perp=9.797, rec=0.154, cos=0.004), tot_loss_proj:2.438 [t=0.31s]
prediction: ['[CLS] narrow incoatsiblesible vicious joint parts absurd, vicious, and [SEP]']
[ 150/2000] tot_loss=2.390 (perp=11.286, rec=0.131, cos=0.003), tot_loss_proj:2.750 [t=0.31s]
prediction: ['[CLS] off incuthsiblesibleco momentumer absurd, vicious and and [SEP]']
[ 200/2000] tot_loss=2.077 (perp=9.795, rec=0.115, cos=0.002), tot_loss_proj:2.428 [t=0.31s]
prediction: ['[CLS] un unuthsiblesiblecoompre absurd, vicious and and [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.021 (perp=9.464, rec=0.125, cos=0.003), tot_loss_proj:2.396 [t=0.31s]
prediction: ['[CLS] limited unuthsiblecoomphensible absurd, vicious and ; [SEP]']
[ 300/2000] tot_loss=1.856 (perp=8.764, rec=0.101, cos=0.002), tot_loss_proj:2.179 [t=0.31s]
prediction: ['[CLS] un unuthsiblecoomphensible absurd, vicious and ; [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.733 (perp=8.162, rec=0.099, cos=0.002), tot_loss_proj:2.030 [t=0.31s]
prediction: ['[CLS] incuthsible uncoomphensible absurd, vicious and ; [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.843 (perp=8.366, rec=0.166, cos=0.004), tot_loss_proj:2.121 [t=0.31s]
prediction: ['[CLS] mediaompsible uncouthhensible absurd, vicious and - [SEP]']
[ 450/2000] tot_loss=2.025 (perp=9.563, rec=0.110, cos=0.002), tot_loss_proj:2.343 [t=0.31s]
prediction: ['[CLS] mediaompsible uncouthhensible absurd, vicious andgit [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.903 (perp=9.002, rec=0.100, cos=0.002), tot_loss_proj:2.142 [t=0.31s]
prediction: ['[CLS] mediaompsible uncouthhensiblegit, vicious and absurd [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.656 (perp=7.802, rec=0.094, cos=0.002), tot_loss_proj:1.895 [t=0.31s]
prediction: ['[CLS] cosible uncouthomphensiblegit, vicious and absurd [SEP]']
[ 600/2000] tot_loss=1.647 (perp=7.802, rec=0.085, cos=0.002), tot_loss_proj:1.903 [t=0.31s]
prediction: ['[CLS] cosible uncouthomphensiblegit, vicious and absurd [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.648 (perp=7.802, rec=0.086, cos=0.002), tot_loss_proj:1.884 [t=0.31s]
prediction: ['[CLS] cosible uncouthomphensiblegit, vicious and absurd [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.824 (perp=8.498, rec=0.121, cos=0.003), tot_loss_proj:1.967 [t=0.31s]
prediction: ['[CLS] coomp uncouth inchensiblegit, vicious and absurd [SEP]']
[ 750/2000] tot_loss=1.788 (perp=8.498, rec=0.087, cos=0.002), tot_loss_proj:1.974 [t=0.31s]
prediction: ['[CLS] coomp uncouth inchensiblegit, vicious and absurd [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.898 (perp=9.059, rec=0.085, cos=0.002), tot_loss_proj:2.350 [t=0.31s]
prediction: ['[CLS] coomp uncouthhensiblegit,omp vicious and absurd [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.790 (perp=8.500, rec=0.088, cos=0.002), tot_loss_proj:2.028 [t=0.31s]
prediction: ['[CLS] coomp uncouthhensibleompgit, vicious and absurd [SEP]']
[ 900/2000] tot_loss=1.787 (perp=8.500, rec=0.085, cos=0.002), tot_loss_proj:2.023 [t=0.31s]
prediction: ['[CLS] coomp uncouthhensibleompgit, vicious and absurd [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.722 (perp=8.193, rec=0.082, cos=0.002), tot_loss_proj:1.986 [t=0.31s]
prediction: ['[CLS] coomp uncouthomphensiblegit, vicious and absurd [SEP]']
Attempt swap
[1000/2000] tot_loss=1.717 (perp=8.193, rec=0.077, cos=0.002), tot_loss_proj:1.983 [t=0.31s]
prediction: ['[CLS] coomp uncouthomphensiblegit, vicious and absurd [SEP]']
[1050/2000] tot_loss=1.719 (perp=8.193, rec=0.079, cos=0.002), tot_loss_proj:1.986 [t=0.31s]
prediction: ['[CLS] coomp uncouthomphensiblegit, vicious and absurd [SEP]']
Attempt swap
[1100/2000] tot_loss=1.720 (perp=8.193, rec=0.079, cos=0.002), tot_loss_proj:1.987 [t=0.31s]
prediction: ['[CLS] coomp uncouthomphensiblegit, vicious and absurd [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.593 (perp=7.454, rec=0.100, cos=0.003), tot_loss_proj:1.800 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
[1200/2000] tot_loss=1.581 (perp=7.454, rec=0.088, cos=0.002), tot_loss_proj:1.807 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[1250/2000] tot_loss=1.579 (perp=7.454, rec=0.087, cos=0.002), tot_loss_proj:1.800 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[1300/2000] tot_loss=1.573 (perp=7.454, rec=0.080, cos=0.002), tot_loss_proj:1.798 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
[1350/2000] tot_loss=1.570 (perp=7.454, rec=0.078, cos=0.002), tot_loss_proj:1.796 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[1400/2000] tot_loss=1.571 (perp=7.454, rec=0.079, cos=0.002), tot_loss_proj:1.797 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[1450/2000] tot_loss=1.579 (perp=7.454, rec=0.087, cos=0.002), tot_loss_proj:1.800 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
[1500/2000] tot_loss=1.570 (perp=7.454, rec=0.078, cos=0.002), tot_loss_proj:1.805 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[1550/2000] tot_loss=1.556 (perp=7.454, rec=0.064, cos=0.002), tot_loss_proj:1.799 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[1600/2000] tot_loss=1.563 (perp=7.454, rec=0.071, cos=0.002), tot_loss_proj:1.801 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
[1650/2000] tot_loss=1.561 (perp=7.454, rec=0.069, cos=0.002), tot_loss_proj:1.804 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=1.567 (perp=7.454, rec=0.075, cos=0.002), tot_loss_proj:1.800 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=1.570 (perp=7.454, rec=0.078, cos=0.002), tot_loss_proj:1.793 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
[1800/2000] tot_loss=1.569 (perp=7.454, rec=0.077, cos=0.002), tot_loss_proj:1.800 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=1.565 (perp=7.454, rec=0.073, cos=0.002), tot_loss_proj:1.797 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=1.570 (perp=7.454, rec=0.077, cos=0.002), tot_loss_proj:1.798 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
[1950/2000] tot_loss=1.578 (perp=7.454, rec=0.085, cos=0.002), tot_loss_proj:1.808 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=1.577 (perp=7.454, rec=0.084, cos=0.002), tot_loss_proj:1.800 [t=0.31s]
prediction: ['[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] coompgit, vicious uncouthomphensible and absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 104.762

[Aggregate metrics]:
rouge1     | fm: 93.821 | p: 93.495 | r: 94.192
rouge2     | fm: 61.952 | p: 61.757 | r: 62.130
rougeL     | fm: 81.073 | p: 80.820 | r: 81.353
rougeLsum  | fm: 81.077 | p: 80.813 | r: 81.395
r1fm+r2fm = 155.773

input #68 time: 0:12:16 | total time: 14:06:47


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.9992893891041827
highest_index [0]
highest [0.9992893891041827]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.0902268886566162 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9457823634147644 for ['[CLS] cade atoms especially suddenly schneider commanded noble retirement causescap meant grin immortals fai act paternal [SEP]']
[Init] best rec loss: 0.9270048141479492 for ['[CLS] meetings bells mountain bloody technical script⁄ sarah rebound fare they br hospital christmas value turkmenistan [SEP]']
[Init] best rec loss: 0.9257810115814209 for ['[CLS] et roughly christian cinema angela zoo commanded determinedpine treatcraft said being amountigo ; [SEP]']
[Init] best rec loss: 0.9201071858406067 for ['[CLS] operation tactics toes collective valley stitches drop criticism insteadivequitable francis surnamezer san zone [SEP]']
[Init] best rec loss: 0.9200060963630676 for ['[CLS] joint heavy drew dome fox sportbahn license pair debtgate interview mayor allied origin ( [SEP]']
[Init] best rec loss: 0.9058429598808289 for ['[CLS] mans border mormon vocational be doubt recordseft outcomes same humor spring chi ears other ling [SEP]']
[Init] best rec loss: 0.8842117786407471 for ['[CLS] tract havinggated libraries himself odd magna courtney jonah tempted miller stunning spit opened french now [SEP]']
[Init] best rec loss: 0.8794275522232056 for ['[CLS]mission down unopposedacio tray adelaide african platform burnham ferrisest port case [MASK] gross main [SEP]']
[Init] best perm rec loss: 0.8781448006629944 for ['[CLS] [MASK]acio burnham platformest gross adelaide case unopposed ferris tray down africanmission main port [SEP]']
[Init] best perm rec loss: 0.8780891299247742 for ['[CLS] african unopposed adelaideacioest tray port platform case main down burnham [MASK] ferrismission gross [SEP]']
[Init] best perm rec loss: 0.8730109333992004 for ['[CLS]acio african burnham unopposed gross [MASK] tray adelaideest case down platformmission ferris main port [SEP]']
[Init] best perm rec loss: 0.871782660484314 for ['[CLS] main unopposed case ferris adelaide tray platformest port grossacio burnham african downmission [MASK] [SEP]']
[Init] best perm rec loss: 0.8699828386306763 for ['[CLS] tray gross portacio african adelaide platform case burnham ferrisest [MASK] unopposed main downmission [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.831 (perp=12.384, rec=0.344, cos=0.010), tot_loss_proj:4.459 [t=0.31s]
prediction: ['[CLS] summer musical darts, civilization brewerywear hot theory cu technologyquent which shopping edition generally [SEP]']
[ 100/2000] tot_loss=2.670 (perp=11.993, rec=0.267, cos=0.005), tot_loss_proj:3.723 [t=0.31s]
prediction: ['[CLS] smart musical radical, keystone brewery rock hot familiar or energy ¨ el wrist edition generally [SEP]']
[ 150/2000] tot_loss=2.472 (perp=11.142, rec=0.240, cos=0.003), tot_loss_proj:3.284 [t=0.31s]
prediction: ['[CLS] smartignant radical, carbon brewery funny hot real and funny ¨ drama newly ; generally [SEP]']
[ 200/2000] tot_loss=2.359 (perp=10.713, rec=0.214, cos=0.003), tot_loss_proj:3.095 [t=0.31s]
prediction: ['[CLS] - funny radical, carbon corners smart smart real - funny : juliet drugs - generally [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.211 (perp=9.955, rec=0.218, cos=0.003), tot_loss_proj:2.675 [t=0.31s]
prediction: ['[CLS], funny real, carbon corners smart good real - - funny : sol - generally [SEP]']
[ 300/2000] tot_loss=2.182 (perp=9.949, rec=0.190, cos=0.002), tot_loss_proj:2.925 [t=0.32s]
prediction: ['[CLS], funny real - carbon ( subtle - real and ;ona. piece - generally [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.080 (perp=9.528, rec=0.173, cos=0.002), tot_loss_proj:2.814 [t=0.31s]
prediction: ['[CLS], funny subtle - real, winnerona. pin a ® real - carbon - [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.884 (perp=8.671, rec=0.148, cos=0.002), tot_loss_proj:2.696 [t=0.32s]
prediction: ['[CLS], funny subtle - real, winnerona. pin the winner real - carbon ivy [SEP]']
[ 450/2000] tot_loss=2.010 (perp=9.348, rec=0.138, cos=0.002), tot_loss_proj:2.747 [t=0.31s]
prediction: ['[CLS], funny subtle - real, winnerona.ux the winnernt - carbon ivy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.914 (perp=8.918, rec=0.129, cos=0.002), tot_loss_proj:2.591 [t=0.31s]
prediction: ['[CLS], smart subtle - real, winneronaux a winnernt. - city - [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.962 (perp=9.210, rec=0.119, cos=0.002), tot_loss_proj:2.722 [t=0.31s]
prediction: ['[CLS], smart subtle - real, winnerona and ivy winnernt. - city the [SEP]']
[ 600/2000] tot_loss=2.066 (perp=9.700, rec=0.125, cos=0.002), tot_loss_proj:3.183 [t=0.31s]
prediction: ['[CLS], smart subtle - real, slightlyona and goo winnernt. - city the [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.693 (perp=7.871, rec=0.117, cos=0.002), tot_loss_proj:2.242 [t=0.31s]
prediction: ['[CLS], smart subtle - real, slightlyonant and - winner. - city the [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.627 (perp=7.553, rec=0.115, cos=0.002), tot_loss_proj:2.177 [t=0.31s]
prediction: ['[CLS], smart subtle - real, slightlyonant and the winner. - city - [SEP]']
[ 750/2000] tot_loss=1.654 (perp=7.678, rec=0.116, cos=0.002), tot_loss_proj:2.414 [t=0.32s]
prediction: ['[CLS], smart subtle - real, slightlyonant and the winner. - carbon - [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.506 (perp=6.948, rec=0.115, cos=0.002), tot_loss_proj:2.441 [t=0.31s]
prediction: ['[CLS], smart subtle - real, slightlyonant and the winner - - carbon. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.748 (perp=8.121, rec=0.123, cos=0.002), tot_loss_proj:2.683 [t=0.31s]
prediction: ['[CLS] smart subtle -, real, guyonant and a winner goo - carbon. [SEP]']
[ 900/2000] tot_loss=1.646 (perp=7.718, rec=0.100, cos=0.002), tot_loss_proj:2.380 [t=0.31s]
prediction: ['[CLS] smart subtle -, real, veryonant and a winner goo - carbon. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.562 (perp=7.258, rec=0.109, cos=0.002), tot_loss_proj:2.386 [t=0.31s]
prediction: ['[CLS] smart subtle -, real, very gooonant and a winner - carbon. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.486 (perp=6.867, rec=0.111, cos=0.002), tot_loss_proj:2.434 [t=0.31s]
prediction: ['[CLS] smart subtle - real, very gooonant, and a winner - carbon. [SEP]']
[1050/2000] tot_loss=1.479 (perp=6.867, rec=0.104, cos=0.002), tot_loss_proj:2.431 [t=0.31s]
prediction: ['[CLS] smart subtle - real, very gooonant, and a winner - carbon. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.459 (perp=6.726, rec=0.113, cos=0.002), tot_loss_proj:2.412 [t=0.31s]
prediction: ['[CLS] real subtle - smart, very gooonant, and a winner - carbon. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.509 (perp=6.986, rec=0.110, cos=0.002), tot_loss_proj:2.598 [t=0.31s]
prediction: ['[CLS] real subtle - smart guy, gooonant, and a winner - carbon. [SEP]']
[1200/2000] tot_loss=1.499 (perp=6.986, rec=0.101, cos=0.002), tot_loss_proj:2.595 [t=0.31s]
prediction: ['[CLS] real subtle - smart guy, gooonant, and a winner - carbon. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.512 (perp=6.986, rec=0.113, cos=0.002), tot_loss_proj:2.603 [t=0.31s]
prediction: ['[CLS] real subtle - smart guy, gooonant, and a winner - carbon. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.401 (perp=6.465, rec=0.106, cos=0.002), tot_loss_proj:2.266 [t=0.31s]
prediction: ['[CLS] real very subtle - smart, gooonant, and a winner - carbon. [SEP]']
[1350/2000] tot_loss=1.391 (perp=6.465, rec=0.096, cos=0.002), tot_loss_proj:2.268 [t=0.32s]
prediction: ['[CLS] real very subtle - smart, gooonant, and a winner - carbon. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.401 (perp=6.465, rec=0.107, cos=0.002), tot_loss_proj:2.268 [t=0.31s]
prediction: ['[CLS] real very subtle - smart, gooonant, and a winner - carbon. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.398 (perp=6.465, rec=0.103, cos=0.002), tot_loss_proj:2.263 [t=0.31s]
prediction: ['[CLS] real very subtle - smart, gooonant, and a winner - carbon. [SEP]']
[1500/2000] tot_loss=1.400 (perp=6.465, rec=0.105, cos=0.002), tot_loss_proj:2.267 [t=0.31s]
prediction: ['[CLS] real very subtle - smart, gooonant, and a winner - carbon. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.403 (perp=6.465, rec=0.108, cos=0.002), tot_loss_proj:2.266 [t=0.32s]
prediction: ['[CLS] real very subtle - smart, gooonant, and a winner - carbon. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.393 (perp=6.465, rec=0.099, cos=0.002), tot_loss_proj:2.266 [t=0.31s]
prediction: ['[CLS] real very subtle - smart, gooonant, and a winner - carbon. [SEP]']
[1650/2000] tot_loss=1.400 (perp=6.465, rec=0.106, cos=0.002), tot_loss_proj:2.272 [t=0.31s]
prediction: ['[CLS] real very subtle - smart, gooonant, and a winner - carbon. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.397 (perp=6.455, rec=0.105, cos=0.002), tot_loss_proj:2.069 [t=0.31s]
prediction: ['[CLS] real very subtle - smart, gooonant, and a winner - res. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.392 (perp=6.455, rec=0.099, cos=0.002), tot_loss_proj:2.058 [t=0.31s]
prediction: ['[CLS] real very subtle - smart, gooonant, and a winner - res. [SEP]']
[1800/2000] tot_loss=1.395 (perp=6.455, rec=0.102, cos=0.002), tot_loss_proj:2.062 [t=0.31s]
prediction: ['[CLS] real very subtle - smart, gooonant, and a winner - res. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.275 (perp=5.724, rec=0.128, cos=0.002), tot_loss_proj:1.742 [t=0.31s]
prediction: ['[CLS] real very subtle - smart, goo resonant, and a winner -. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.105 (perp=4.926, rec=0.118, cos=0.002), tot_loss_proj:1.352 [t=0.32s]
prediction: ['[CLS] real - subtle - smart, very resonant, and a winner -. [SEP]']
[1950/2000] tot_loss=1.093 (perp=4.926, rec=0.106, cos=0.002), tot_loss_proj:1.348 [t=0.31s]
prediction: ['[CLS] real - subtle - smart, very resonant, and a winner -. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.100 (perp=4.926, rec=0.113, cos=0.002), tot_loss_proj:1.351 [t=0.31s]
prediction: ['[CLS] real - subtle - smart, very resonant, and a winner -. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] real very subtle - smart, gooonant, and a winner - carbon. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 72.727 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.619 | p: 45.455 | r: 50.000
rougeLsum  | fm: 47.619 | p: 45.455 | r: 50.000
r1fm+r2fm = 76.190

[Aggregate metrics]:
rouge1     | fm: 93.611 | p: 93.217 | r: 94.037
rouge2     | fm: 61.003 | p: 60.851 | r: 61.207
rougeL     | fm: 80.744 | p: 80.449 | r: 81.078
rougeLsum  | fm: 80.484 | p: 80.208 | r: 80.844
r1fm+r2fm = 154.614

input #69 time: 0:12:30 | total time: 14:19:17


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9993747900661694
highest_index [0]
highest [0.9993747900661694]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8466562628746033 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.8215412497520447 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7987306714057922 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7387865781784058 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best perm rec loss: 0.7325872778892517 for ['[CLS] detention technological sharma herself blood mark effects [SEP]']
[Init] best perm rec loss: 0.7320940494537354 for ['[CLS] detention mark sharma herself effects technological blood [SEP]']
[Init] best perm rec loss: 0.7318440079689026 for ['[CLS] detention mark sharma effects herself technological blood [SEP]']
[Init] best perm rec loss: 0.7306492328643799 for ['[CLS] mark blood herself technological effects detention sharma [SEP]']
[Init] best perm rec loss: 0.7292215824127197 for ['[CLS] effects sharma detention mark herself blood technological [SEP]']
[Init] best perm rec loss: 0.7283181548118591 for ['[CLS] technological blood detention herself effects mark sharma [SEP]']
[Init] best perm rec loss: 0.7264995574951172 for ['[CLS] detention effects herself sharma mark technological blood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.453 (perp=10.745, rec=0.282, cos=0.022), tot_loss_proj:2.841 [t=0.31s]
prediction: ['[CLS] cl clunk screen gets inunk [SEP]']
[ 100/2000] tot_loss=2.025 (perp=9.200, rec=0.174, cos=0.011), tot_loss_proj:2.527 [t=0.31s]
prediction: ['[CLS] cl clunk screen gets clunk [SEP]']
[ 150/2000] tot_loss=2.132 (perp=9.917, rec=0.141, cos=0.008), tot_loss_proj:2.632 [t=0.31s]
prediction: ['[CLS]y clunk screen gets clunk [SEP]']
[ 200/2000] tot_loss=2.223 (perp=10.508, rec=0.114, cos=0.007), tot_loss_proj:3.548 [t=0.31s]
prediction: ['[CLS]y clunk screen gets ony [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.686 (perp=7.925, rec=0.098, cos=0.003), tot_loss_proj:2.359 [t=0.31s]
prediction: ['[CLS]y clunky gets on screen [SEP]']
[ 300/2000] tot_loss=1.665 (perp=7.925, rec=0.077, cos=0.003), tot_loss_proj:2.368 [t=0.31s]
prediction: ['[CLS]y clunky gets on screen [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.548 (perp=7.184, rec=0.107, cos=0.004), tot_loss_proj:1.744 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.530 (perp=7.184, rec=0.091, cos=0.003), tot_loss_proj:1.746 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 450/2000] tot_loss=1.516 (perp=7.184, rec=0.077, cos=0.003), tot_loss_proj:1.749 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.518 (perp=7.184, rec=0.078, cos=0.003), tot_loss_proj:1.754 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.519 (perp=7.184, rec=0.079, cos=0.002), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 600/2000] tot_loss=1.515 (perp=7.184, rec=0.076, cos=0.002), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.520 (perp=7.184, rec=0.081, cos=0.002), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.500 (perp=7.184, rec=0.061, cos=0.002), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 750/2000] tot_loss=1.510 (perp=7.184, rec=0.071, cos=0.002), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.519 (perp=7.184, rec=0.080, cos=0.002), tot_loss_proj:1.751 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.511 (perp=7.184, rec=0.072, cos=0.002), tot_loss_proj:1.755 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 900/2000] tot_loss=1.516 (perp=7.184, rec=0.077, cos=0.002), tot_loss_proj:1.759 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.514 (perp=7.184, rec=0.075, cos=0.002), tot_loss_proj:1.751 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.511 (perp=7.184, rec=0.072, cos=0.002), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1050/2000] tot_loss=1.520 (perp=7.184, rec=0.081, cos=0.002), tot_loss_proj:1.748 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.507 (perp=7.184, rec=0.068, cos=0.002), tot_loss_proj:1.743 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.507 (perp=7.184, rec=0.068, cos=0.002), tot_loss_proj:1.756 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1200/2000] tot_loss=1.506 (perp=7.184, rec=0.067, cos=0.002), tot_loss_proj:1.746 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.513 (perp=7.184, rec=0.074, cos=0.002), tot_loss_proj:1.753 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.516 (perp=7.184, rec=0.077, cos=0.002), tot_loss_proj:1.752 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1350/2000] tot_loss=1.513 (perp=7.184, rec=0.074, cos=0.002), tot_loss_proj:1.762 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.511 (perp=7.184, rec=0.072, cos=0.002), tot_loss_proj:1.766 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.517 (perp=7.184, rec=0.078, cos=0.002), tot_loss_proj:1.754 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1500/2000] tot_loss=1.517 (perp=7.184, rec=0.078, cos=0.002), tot_loss_proj:1.753 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.507 (perp=7.184, rec=0.068, cos=0.002), tot_loss_proj:1.761 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.520 (perp=7.184, rec=0.081, cos=0.002), tot_loss_proj:1.759 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1650/2000] tot_loss=1.509 (perp=7.184, rec=0.070, cos=0.002), tot_loss_proj:1.754 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.508 (perp=7.184, rec=0.069, cos=0.002), tot_loss_proj:1.758 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.502 (perp=7.184, rec=0.063, cos=0.002), tot_loss_proj:1.759 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1800/2000] tot_loss=1.510 (perp=7.184, rec=0.071, cos=0.002), tot_loss_proj:1.751 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.514 (perp=7.184, rec=0.075, cos=0.002), tot_loss_proj:1.758 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.514 (perp=7.184, rec=0.075, cos=0.002), tot_loss_proj:1.761 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1950/2000] tot_loss=1.509 (perp=7.184, rec=0.071, cos=0.002), tot_loss_proj:1.750 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.514 (perp=7.184, rec=0.075, cos=0.002), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS]y gets clunky on screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 135.714

[Aggregate metrics]:
rouge1     | fm: 93.526 | p: 93.160 | r: 93.921
rouge2     | fm: 60.615 | p: 60.461 | r: 60.819
rougeL     | fm: 80.841 | p: 80.555 | r: 81.181
rougeLsum  | fm: 80.654 | p: 80.323 | r: 80.967
r1fm+r2fm = 154.141

input #70 time: 0:12:16 | total time: 14:31:33


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.9993417553421915
highest_index [0]
highest [0.9993417553421915]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8833605051040649 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.8461988568305969 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8435500264167786 for ['[CLS] fed to radar county sun gunshot parchment waiting regional wallacewo dia [CLS] smiles fantasy [SEP]']
[Init] best rec loss: 0.8424428105354309 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 0.8304855823516846 for ['[CLS] shoulders protocol powerfulfication sash jonas obligatory definition box thorough whole except visit flanked dated [SEP]']
[Init] best rec loss: 0.8256857991218567 for ['[CLS] cidloubridge living blues republicfl projections transition rally mere torpedo spellingcio espn [SEP]']
[Init] best rec loss: 0.8174697160720825 for ['[CLS] mutual internal travel grief with album careful item serious european either warp spoil waived every [SEP]']
[Init] best rec loss: 0.8137956261634827 for ['[CLS] knock lily combinedzh times soundfinger assist chains kylie most asha? industryico [SEP]']
[Init] best rec loss: 0.8103150725364685 for ['[CLS]. coursearth acids south gogh beyond stage reservoir until little tombathlontered wright [SEP]']
[Init] best perm rec loss: 0.8089939951896667 for ['[CLS] reservoir gogh wright little coursetered until acids tombarth.athlon stage south beyond [SEP]']
[Init] best perm rec loss: 0.8088967204093933 for ['[CLS] little until tombarth course reservoir. acids stage south beyondtered gogh wrightathlon [SEP]']
[Init] best perm rec loss: 0.8079750537872314 for ['[CLS] stage reservoir wright tomb littlearth acidsathlon south. until beyond coursetered gogh [SEP]']
[Init] best perm rec loss: 0.8072059154510498 for ['[CLS] tomb south acids beyond wright stage gogh until little. reservoirarth courseathlontered [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.329 (perp=9.943, rec=0.315, cos=0.025), tot_loss_proj:3.619 [t=0.31s]
prediction: ["[CLS] jet t not single yesterday here -'seat'moment their seat but s [SEP]"]
[ 100/2000] tot_loss=1.921 (perp=8.621, rec=0.187, cos=0.009), tot_loss_proj:2.562 [t=0.31s]
prediction: ["[CLS] jump there not single jump my - - seat - moment by moment'in [SEP]"]
[ 150/2000] tot_loss=1.918 (perp=8.893, rec=0.132, cos=0.007), tot_loss_proj:2.879 [t=0.31s]
prediction: ['[CLS] jump there not single a and - your seat - moment his seat your and [SEP]']
[ 200/2000] tot_loss=1.849 (perp=8.716, rec=0.101, cos=0.005), tot_loss_proj:2.577 [t=0.31s]
prediction: ['[CLS] jump there not single a and - your in - moment your seat moment and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.709 (perp=8.078, rec=0.091, cos=0.003), tot_loss_proj:2.556 [t=0.31s]
prediction: ['[CLS] jump there not single a moment - your in - and your seat moment and [SEP]']
[ 300/2000] tot_loss=1.691 (perp=8.078, rec=0.074, cos=0.002), tot_loss_proj:2.538 [t=0.32s]
prediction: ['[CLS] jump there not single a moment - your in - and your seat moment and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.636 (perp=7.706, rec=0.093, cos=0.002), tot_loss_proj:2.635 [t=0.31s]
prediction: ['[CLS] jump there not single s moment - - in your and your seat moment - [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.524 (perp=7.209, rec=0.080, cos=0.002), tot_loss_proj:2.608 [t=0.31s]
prediction: ['[CLS] jump not there single s moment - - in your and your seat moment - [SEP]']
[ 450/2000] tot_loss=1.582 (perp=7.490, rec=0.082, cos=0.002), tot_loss_proj:2.557 [t=0.31s]
prediction: ['[CLS] jump not there single s moment - - in your and the seat moment - [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.590 (perp=7.557, rec=0.076, cos=0.002), tot_loss_proj:2.534 [t=0.31s]
prediction: ['[CLS] jump not there single s moment - - in your of and the seat - [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.478 (perp=6.967, rec=0.082, cos=0.002), tot_loss_proj:3.028 [t=0.31s]
prediction: ['[CLS] jump not there single s moment - - and in your in the seat - [SEP]']
[ 600/2000] tot_loss=1.474 (perp=6.967, rec=0.079, cos=0.001), tot_loss_proj:3.028 [t=0.31s]
prediction: ['[CLS] jump not there single s moment - - and in your in the seat - [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.418 (perp=6.727, rec=0.072, cos=0.001), tot_loss_proj:2.905 [t=0.32s]
prediction: ['[CLS] jump not there single s - - and in your moment of a seat - [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.305 (perp=6.187, rec=0.066, cos=0.002), tot_loss_proj:2.708 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your moment of a seat - [SEP]']
[ 750/2000] tot_loss=1.307 (perp=6.187, rec=0.069, cos=0.001), tot_loss_proj:2.715 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your moment of a seat - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.312 (perp=6.187, rec=0.074, cos=0.001), tot_loss_proj:2.714 [t=0.32s]
prediction: ['[CLS] s not there single jump - - and in your moment of a seat - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.312 (perp=6.187, rec=0.074, cos=0.001), tot_loss_proj:2.709 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your moment of a seat - [SEP]']
[ 900/2000] tot_loss=1.306 (perp=6.187, rec=0.067, cos=0.001), tot_loss_proj:2.710 [t=0.32s]
prediction: ['[CLS] s not there single jump - - and in your moment of a seat - [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.226 (perp=5.767, rec=0.071, cos=0.001), tot_loss_proj:2.476 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.219 (perp=5.767, rec=0.065, cos=0.001), tot_loss_proj:2.474 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
[1050/2000] tot_loss=1.222 (perp=5.767, rec=0.067, cos=0.001), tot_loss_proj:2.473 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.219 (perp=5.767, rec=0.064, cos=0.001), tot_loss_proj:2.466 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.223 (perp=5.767, rec=0.068, cos=0.001), tot_loss_proj:2.468 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
[1200/2000] tot_loss=1.213 (perp=5.767, rec=0.058, cos=0.001), tot_loss_proj:2.468 [t=0.32s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.223 (perp=5.767, rec=0.068, cos=0.001), tot_loss_proj:2.465 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.220 (perp=5.767, rec=0.065, cos=0.001), tot_loss_proj:2.464 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
[1350/2000] tot_loss=1.223 (perp=5.767, rec=0.069, cos=0.001), tot_loss_proj:2.461 [t=0.32s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.230 (perp=5.767, rec=0.075, cos=0.001), tot_loss_proj:2.465 [t=0.32s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.220 (perp=5.767, rec=0.065, cos=0.001), tot_loss_proj:2.462 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
[1500/2000] tot_loss=1.220 (perp=5.767, rec=0.065, cos=0.001), tot_loss_proj:2.461 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.225 (perp=5.767, rec=0.070, cos=0.001), tot_loss_proj:2.466 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.223 (perp=5.767, rec=0.069, cos=0.001), tot_loss_proj:2.463 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
[1650/2000] tot_loss=1.217 (perp=5.767, rec=0.062, cos=0.001), tot_loss_proj:2.453 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.220 (perp=5.767, rec=0.065, cos=0.001), tot_loss_proj:2.459 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.223 (perp=5.767, rec=0.068, cos=0.001), tot_loss_proj:2.459 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
[1800/2000] tot_loss=1.220 (perp=5.767, rec=0.065, cos=0.001), tot_loss_proj:2.458 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.222 (perp=5.767, rec=0.067, cos=0.001), tot_loss_proj:2.455 [t=0.32s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.220 (perp=5.767, rec=0.066, cos=0.001), tot_loss_proj:2.458 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
[1950/2000] tot_loss=1.221 (perp=5.767, rec=0.067, cos=0.001), tot_loss_proj:2.459 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.220 (perp=5.767, rec=0.065, cos=0.001), tot_loss_proj:2.455 [t=0.31s]
prediction: ['[CLS] s not there single jump - - and in your seat of a moment - [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] s not there single jump - - and in your seat of a moment - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.296 | p: 92.857 | r: 100.000
rouge2     | fm: 32.000 | p: 30.769 | r: 33.333
rougeL     | fm: 74.074 | p: 71.429 | r: 76.923
rougeLsum  | fm: 74.074 | p: 71.429 | r: 76.923
r1fm+r2fm = 128.296

[Aggregate metrics]:
rouge1     | fm: 93.514 | p: 93.079 | r: 94.015
rouge2     | fm: 60.252 | p: 60.088 | r: 60.443
rougeL     | fm: 80.687 | p: 80.343 | r: 81.059
rougeLsum  | fm: 80.565 | p: 80.259 | r: 80.967
r1fm+r2fm = 153.766

input #71 time: 0:12:30 | total time: 14:44:04


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9992331054438227
highest_index [0]
highest [0.9992331054438227]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7871819734573364 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7594130039215088 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7494335770606995 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7492443919181824 for ['[CLS] renaissance lie devil brigade unit purcell as harvest strandedfr uncommon powers behaviour ken terror [SEP]']
[Init] best rec loss: 0.7361101508140564 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.7154608964920044 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.714171826839447 for ['[CLS] orbital lifeboat except accidentally pork reserve! van zone nonetheless support taungen walking dna [SEP]']
[Init] best perm rec loss: 0.714065432548523 for ['[CLS] walking pork orbital reserve lifeboat taungen accidentally dna nonetheless van except zone! support [SEP]']
[Init] best perm rec loss: 0.7138411402702332 for ['[CLS]ungen nonetheless van pork! lifeboat walking support zone accidentally ta dna orbital reserve except [SEP]']
[Init] best perm rec loss: 0.7132271528244019 for ['[CLS] nonetheless pork! except taungen accidentally dna walking lifeboat reserve van zone orbital support [SEP]']
[Init] best perm rec loss: 0.7127954959869385 for ['[CLS] accidentally lifeboat orbital except support reserve van! porkungen ta walking dna zone nonetheless [SEP]']
[Init] best perm rec loss: 0.7118991613388062 for ['[CLS] lifeboat nonethelessungen except pork! support zone orbital dna ta van accidentally walking reserve [SEP]']
[Init] best perm rec loss: 0.7117257714271545 for ['[CLS] except pork! orbital nonetheless dna reserve lifeboat accidentally zone ta walking supportungen van [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.119 (perp=13.845, rec=0.325, cos=0.025), tot_loss_proj:4.265 [t=0.31s]
prediction: ['[CLS] faced tough dough backlash an tough girlfriend tough tough makes that mixed enoch increasingly composition [SEP]']
[ 100/2000] tot_loss=2.320 (perp=10.620, rec=0.187, cos=0.009), tot_loss_proj:2.856 [t=0.32s]
prediction: ['[CLS] has tough timeer a tough violence tough harder makes of mixed its increasingly philosophy [SEP]']
[ 150/2000] tot_loss=1.977 (perp=9.140, rec=0.142, cos=0.008), tot_loss_proj:2.808 [t=0.31s]
prediction: ['[CLS] has tough timeer a tough violence tougher makes with balancing its with philosophy [SEP]']
[ 200/2000] tot_loss=1.968 (perp=9.306, rec=0.104, cos=0.003), tot_loss_proj:2.915 [t=0.31s]
prediction: ['[CLS] has tough timeer its tough violence tougher makes with balancingist with philosophy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.712 (perp=8.059, rec=0.096, cos=0.004), tot_loss_proj:2.786 [t=0.31s]
prediction: ['[CLS] has tough timeer its tough tougher decades with balancing its violence with philosophy [SEP]']
[ 300/2000] tot_loss=1.704 (perp=8.059, rec=0.089, cos=0.003), tot_loss_proj:2.799 [t=0.31s]
prediction: ['[CLS] has tough timeer its tough tougher decades with balancing its violence with philosophy [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.523 (perp=7.129, rec=0.095, cos=0.002), tot_loss_proj:2.170 [t=0.31s]
prediction: ['[CLS] has tough time with its tough tougher decadeser balancing its violence with philosophy [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.683 (perp=7.903, rec=0.099, cos=0.004), tot_loss_proj:2.220 [t=0.31s]
prediction: ['[CLS]fk has tough time with its tougher originateser balancing its violence with philosophy [SEP]']
[ 450/2000] tot_loss=1.754 (perp=8.342, rec=0.083, cos=0.002), tot_loss_proj:2.284 [t=0.31s]
prediction: ['[CLS]fk has tough time with its aer originateser balancing its violence with philosophy [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.615 (perp=7.714, rec=0.071, cos=0.002), tot_loss_proj:2.179 [t=0.32s]
prediction: ['[CLS] a has tough time with itsfkerfker balancing its violence with philosophy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.696 (perp=8.062, rec=0.082, cos=0.002), tot_loss_proj:2.248 [t=0.31s]
prediction: ['[CLS] has a tough time with itsfkerfker balancing american violence with philosophy [SEP]']
[ 600/2000] tot_loss=1.703 (perp=8.062, rec=0.089, cos=0.002), tot_loss_proj:2.245 [t=0.31s]
prediction: ['[CLS] has a tough time with itsfkerfker balancing american violence with philosophy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.610 (perp=7.677, rec=0.073, cos=0.002), tot_loss_proj:2.040 [t=0.31s]
prediction: ['[CLS] has a tough time with americanfkerfker balancing its violence with philosophy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.710 (perp=8.164, rec=0.075, cos=0.002), tot_loss_proj:2.138 [t=0.32s]
prediction: ['[CLS] has a tough time with basedfkerfker balancing its violence with philosophy [SEP]']
[ 750/2000] tot_loss=1.701 (perp=8.164, rec=0.066, cos=0.002), tot_loss_proj:2.151 [t=0.32s]
prediction: ['[CLS] has a tough time with basedfkerfker balancing its violence with philosophy [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.710 (perp=8.146, rec=0.079, cos=0.002), tot_loss_proj:2.130 [t=0.31s]
prediction: ['[CLS] has a tough time withfker based inspireder balancing its violence with philosophy [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.631 (perp=7.770, rec=0.076, cos=0.002), tot_loss_proj:2.044 [t=0.31s]
prediction: ['[CLS] has a tough time withfker inspireder balancing its violence with based philosophy [SEP]']
[ 900/2000] tot_loss=1.633 (perp=7.770, rec=0.077, cos=0.002), tot_loss_proj:2.036 [t=0.31s]
prediction: ['[CLS] has a tough time withfker inspireder balancing its violence with based philosophy [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.640 (perp=7.784, rec=0.081, cos=0.002), tot_loss_proj:2.042 [t=0.31s]
prediction: ['[CLS] has a tough time withfker inspireder based balancing its violence with philosophy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.626 (perp=7.784, rec=0.068, cos=0.002), tot_loss_proj:2.031 [t=0.32s]
prediction: ['[CLS] has a tough time withfker inspireder based balancing its violence with philosophy [SEP]']
[1050/2000] tot_loss=1.661 (perp=7.956, rec=0.068, cos=0.002), tot_loss_proj:2.111 [t=0.32s]
prediction: ['[CLS] has a tough time withfker inspireder based balancing its violence - philosophy [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.641 (perp=7.866, rec=0.066, cos=0.002), tot_loss_proj:2.093 [t=0.31s]
prediction: ['[CLS] has a tough time withfker inspireder balancing its violence - philosophy based [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.599 (perp=7.666, rec=0.064, cos=0.002), tot_loss_proj:2.013 [t=0.32s]
prediction: ['[CLS] has a tough time withfker inspireder philosophy balancing its violence - based [SEP]']
[1200/2000] tot_loss=1.598 (perp=7.666, rec=0.064, cos=0.002), tot_loss_proj:2.004 [t=0.31s]
prediction: ['[CLS] has a tough time withfker inspireder philosophy balancing its violence - based [SEP]']
Attempt swap
[1250/2000] tot_loss=1.659 (perp=7.932, rec=0.071, cos=0.002), tot_loss_proj:2.053 [t=0.32s]
prediction: ['[CLS] has a tough time withfker inspireder philosophy balancing its violence - ka [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.582 (perp=7.630, rec=0.054, cos=0.002), tot_loss_proj:1.984 [t=0.31s]
prediction: ['[CLS] has a tough time with kafker inspireder philosophy balancing its violence - [SEP]']
[1350/2000] tot_loss=1.595 (perp=7.630, rec=0.067, cos=0.002), tot_loss_proj:1.985 [t=0.31s]
prediction: ['[CLS] has a tough time with kafker inspireder philosophy balancing its violence - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.597 (perp=7.630, rec=0.069, cos=0.002), tot_loss_proj:1.988 [t=0.31s]
prediction: ['[CLS] has a tough time with kafker inspireder philosophy balancing its violence - [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.557 (perp=7.461, rec=0.064, cos=0.002), tot_loss_proj:2.286 [t=0.31s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
[1500/2000] tot_loss=1.566 (perp=7.461, rec=0.073, cos=0.002), tot_loss_proj:2.282 [t=0.32s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.570 (perp=7.461, rec=0.076, cos=0.002), tot_loss_proj:2.287 [t=0.31s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.556 (perp=7.461, rec=0.062, cos=0.002), tot_loss_proj:2.272 [t=0.31s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
[1650/2000] tot_loss=1.558 (perp=7.461, rec=0.064, cos=0.002), tot_loss_proj:2.283 [t=0.31s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.556 (perp=7.461, rec=0.063, cos=0.002), tot_loss_proj:2.273 [t=0.31s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.566 (perp=7.461, rec=0.072, cos=0.002), tot_loss_proj:2.279 [t=0.32s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
[1800/2000] tot_loss=1.560 (perp=7.461, rec=0.066, cos=0.002), tot_loss_proj:2.277 [t=0.32s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.560 (perp=7.461, rec=0.066, cos=0.002), tot_loss_proj:2.281 [t=0.31s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.552 (perp=7.461, rec=0.058, cos=0.002), tot_loss_proj:2.275 [t=0.31s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
[1950/2000] tot_loss=1.556 (perp=7.461, rec=0.063, cos=0.002), tot_loss_proj:2.270 [t=0.31s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.560 (perp=7.461, rec=0.067, cos=0.002), tot_loss_proj:2.269 [t=0.32s]
prediction: ['[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] has a tough time kafker inspired wither philosophy balancing its violence - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 76.923 | r: 76.923
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 61.538 | p: 61.538 | r: 61.538
rougeLsum  | fm: 61.538 | p: 61.538 | r: 61.538
r1fm+r2fm = 110.256

[Aggregate metrics]:
rouge1     | fm: 93.313 | p: 92.899 | r: 93.779
rouge2     | fm: 59.991 | p: 59.826 | r: 60.188
rougeL     | fm: 80.516 | p: 80.139 | r: 80.887
rougeLsum  | fm: 80.297 | p: 79.977 | r: 80.655
r1fm+r2fm = 153.304

input #72 time: 0:12:30 | total time: 14:56:35


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9991750732033813
highest_index [0]
highest [0.9991750732033813]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9928595423698425 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9680707454681396 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9562028050422668 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9078953862190247 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.9060081243515015 for ['[CLS]dicated circles [SEP]']
[Init] best rec loss: 0.8447190523147583 for ['[CLS] tierney sector [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.836 (perp=13.015, rec=0.221, cos=0.012), tot_loss_proj:3.070 [t=0.30s]
prediction: ['[CLS] filmmaking bad [SEP]']
[ 100/2000] tot_loss=2.675 (perp=13.015, rec=0.070, cos=0.002), tot_loss_proj:3.062 [t=0.31s]
prediction: ['[CLS] filmmaking bad [SEP]']
[ 150/2000] tot_loss=2.676 (perp=13.015, rec=0.071, cos=0.002), tot_loss_proj:3.062 [t=0.31s]
prediction: ['[CLS] filmmaking bad [SEP]']
[ 200/2000] tot_loss=2.672 (perp=13.015, rec=0.067, cos=0.002), tot_loss_proj:3.060 [t=0.31s]
prediction: ['[CLS] filmmaking bad [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.018 (perp=9.723, rec=0.072, cos=0.002), tot_loss_proj:2.004 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.001 (perp=9.723, rec=0.055, cos=0.002), tot_loss_proj:2.015 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.011 (perp=9.723, rec=0.065, cos=0.002), tot_loss_proj:2.013 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.010 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.005 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.003 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.017 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.008 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.002 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=1.998 (perp=9.723, rec=0.051, cos=0.002), tot_loss_proj:2.018 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.009 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.009 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.006 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.014 (perp=9.723, rec=0.068, cos=0.002), tot_loss_proj:1.997 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.007 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.993 (perp=9.723, rec=0.046, cos=0.002), tot_loss_proj:2.009 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.000 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.004 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.004 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.004 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.013 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=1.994 (perp=9.723, rec=0.048, cos=0.002), tot_loss_proj:2.009 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.008 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.007 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.003 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.010 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.021 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.017 (perp=9.723, rec=0.071, cos=0.002), tot_loss_proj:2.014 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.003 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.004 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.002 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.012 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.010 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.012 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.009 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.007 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.008 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.006 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.016 (perp=9.723, rec=0.069, cos=0.002), tot_loss_proj:2.002 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.003 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.013 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.010 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.005 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.017 (perp=9.723, rec=0.070, cos=0.002), tot_loss_proj:2.007 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=1.996 (perp=9.723, rec=0.050, cos=0.002), tot_loss_proj:2.004 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.016 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.004 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.015 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.375 | p: 92.968 | r: 93.841
rouge2     | fm: 60.497 | p: 60.320 | r: 60.708
rougeL     | fm: 80.716 | p: 80.407 | r: 81.067
rougeLsum  | fm: 80.618 | p: 80.301 | r: 80.991
r1fm+r2fm = 153.871

input #73 time: 0:12:12 | total time: 15:08:48


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9992599965311699
highest_index [0]
highest [0.9992599965311699]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.0058443546295166 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6864274740219116 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.6538141965866089 for ['[CLS] birth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.973 (perp=8.178, rec=0.295, cos=0.042), tot_loss_proj:2.091 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.726 (perp=8.178, rec=0.087, cos=0.003), tot_loss_proj:1.831 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.002), tot_loss_proj:1.750 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.002), tot_loss_proj:1.729 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.729 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.692 (perp=8.178, rec=0.055, cos=0.001), tot_loss_proj:1.746 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.733 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.681 (perp=8.178, rec=0.044, cos=0.001), tot_loss_proj:1.727 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.692 (perp=8.178, rec=0.055, cos=0.001), tot_loss_proj:1.742 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.729 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.001), tot_loss_proj:1.726 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.720 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.744 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.690 (perp=8.178, rec=0.053, cos=0.001), tot_loss_proj:1.751 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.697 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.715 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.683 (perp=8.178, rec=0.046, cos=0.001), tot_loss_proj:1.739 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.711 (perp=8.178, rec=0.074, cos=0.001), tot_loss_proj:1.738 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.741 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.711 (perp=8.178, rec=0.074, cos=0.001), tot_loss_proj:1.749 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.690 (perp=8.178, rec=0.053, cos=0.001), tot_loss_proj:1.740 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.726 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.741 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.688 (perp=8.178, rec=0.051, cos=0.001), tot_loss_proj:1.733 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.693 (perp=8.178, rec=0.056, cos=0.001), tot_loss_proj:1.736 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.681 (perp=8.178, rec=0.044, cos=0.001), tot_loss_proj:1.749 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.687 (perp=8.178, rec=0.050, cos=0.001), tot_loss_proj:1.744 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.692 (perp=8.178, rec=0.055, cos=0.001), tot_loss_proj:1.725 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.738 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.690 (perp=8.178, rec=0.053, cos=0.001), tot_loss_proj:1.732 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.708 (perp=8.178, rec=0.071, cos=0.001), tot_loss_proj:1.733 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.688 (perp=8.178, rec=0.051, cos=0.001), tot_loss_proj:1.740 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.737 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.738 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.742 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.737 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.683 (perp=8.178, rec=0.046, cos=0.001), tot_loss_proj:1.735 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.708 (perp=8.178, rec=0.071, cos=0.001), tot_loss_proj:1.732 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.714 (perp=8.178, rec=0.077, cos=0.001), tot_loss_proj:1.729 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.734 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.731 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.492 | p: 93.079 | r: 93.921
rouge2     | fm: 61.169 | p: 61.014 | r: 61.342
rougeL     | fm: 80.904 | p: 80.605 | r: 81.261
rougeLsum  | fm: 80.834 | p: 80.533 | r: 81.175
r1fm+r2fm = 154.661

input #74 time: 0:11:11 | total time: 15:19:59


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9993461866864426
highest_index [0]
highest [0.9993461866864426]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.9615198373794556 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.9498322010040283 for ['[CLS] changed door covert obviously tone sinclair final hard eventdrome apps nick tempo nations diveiii willem nodded rolled [SEP]']
[Init] best rec loss: 0.9409050345420837 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.9008259177207947 for ['[CLS] years public during cup months du sources community ind baseman viz together clinton est frog gum firing points prick [SEP]']
[Init] best rec loss: 0.8991312980651855 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 0.8945338129997253 for ['[CLS]orin rearview bore nicky yang dynasty confidence hockey preaching mangrove meanllet ventureix resistance constitution sun nicholas piece [SEP]']
[Init] best rec loss: 0.8868618607521057 for ['[CLS] stir will case bills blocked hand miniseries electricchen words tha batting shed az happen women known gen tourist [SEP]']
[Init] best rec loss: 0.8647099137306213 for ['[CLS]ception resultedrate left fact crown skill apollo auxiliary regardedcl magic to eachmmel viewed stood loop royalties [SEP]']
[Init] best perm rec loss: 0.8642875552177429 for ['[CLS] leftcl torateception each fact skill auxiliary resulted viewed magic crown royaltiesmmel stood loop apollo regarded [SEP]']
[Init] best perm rec loss: 0.8634325265884399 for ['[CLS] auxiliary loop viewed crowncl eachception skill fact regarded to magicrate stood resultedmmel royalties left apollo [SEP]']
[Init] best perm rec loss: 0.8632357716560364 for ['[CLS] apollo royalties viewedcl crown fact auxiliarymmel to skillrate loop stood each resulted regarded magic leftception [SEP]']
[Init] best perm rec loss: 0.8615350127220154 for ['[CLS]mmel stood apollo resulted loop viewed royalties auxiliary crown factcl skill each magic toception left regardedrate [SEP]']
[Init] best perm rec loss: 0.8614959716796875 for ['[CLS] stood loop regarded to each crowncl leftrate skill resulted fact auxiliary viewed magic royaltiesmmel apolloception [SEP]']
[Init] best perm rec loss: 0.8613840341567993 for ['[CLS] magic auxiliary resultedrate each factmmelception regarded stoodcl to viewed left apollo skill crown royalties loop [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.039 (perp=13.120, rec=0.389, cos=0.026), tot_loss_proj:4.480 [t=0.31s]
prediction: ['[CLS] agencies easily localgate coaster fictional quite reasons uncommon hostel jo the local affairs never academy. leased their [SEP]']
[ 100/2000] tot_loss=2.434 (perp=10.689, rec=0.279, cos=0.017), tot_loss_proj:4.012 [t=0.31s]
prediction: ['[CLS] easily easily manufactured grandmother badly tourist cannotnell something this excursion the mental corruption never dismissed. forgotten. [SEP]']
[ 150/2000] tot_loss=2.296 (perp=10.408, rec=0.199, cos=0.015), tot_loss_proj:3.779 [t=0.32s]
prediction: ['[CLS] easily not irrational instability easily anywhere intonell something this excursion the mental dismissed easily dismissed. forgotten. [SEP]']
[ 200/2000] tot_loss=2.056 (perp=9.484, rec=0.151, cos=0.008), tot_loss_proj:3.564 [t=0.32s]
prediction: ['[CLS] easily not mental instability easily anywhere into instability random this excursion the into dismissed easily dismissed or forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.821 (perp=8.433, rec=0.128, cos=0.006), tot_loss_proj:3.454 [t=0.31s]
prediction: ['[CLS] the not mental instability easilyenter into instability random this excursion easily into instability easily dismissed or forgotten. [SEP]']
[ 300/2000] tot_loss=1.914 (perp=8.936, rec=0.121, cos=0.006), tot_loss_proj:3.610 [t=0.32s]
prediction: ['[CLS] the not mental instability easilyenter into instabilitycola this excursion easily into is easily dismissed or forgotten. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.905 (perp=8.915, rec=0.118, cos=0.003), tot_loss_proj:3.535 [t=0.31s]
prediction: ['[CLS] the not easily mental instability easilyenter intocolacola this excursion into is easily dismissed or forgotten. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.783 (perp=8.421, rec=0.097, cos=0.002), tot_loss_proj:3.411 [t=0.31s]
prediction: ['[CLS] the not easily mental instability easilyenter ofcolacola into this excursion is easily dismissed or forgotten. [SEP]']
[ 450/2000] tot_loss=1.774 (perp=8.421, rec=0.089, cos=0.001), tot_loss_proj:3.413 [t=0.31s]
prediction: ['[CLS] the not easily mental instability easilyenter ofcolacola into this excursion is easily dismissed or forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.705 (perp=8.094, rec=0.084, cos=0.001), tot_loss_proj:3.365 [t=0.31s]
prediction: ['[CLS] the not easily mental instability easilyenter ofcola intocola this excursion is easily dismissed or forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.647 (perp=7.805, rec=0.085, cos=0.001), tot_loss_proj:3.337 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofenter easilycola intocola this excursion is easily dismissed or forgotten. [SEP]']
[ 600/2000] tot_loss=1.640 (perp=7.805, rec=0.078, cos=0.001), tot_loss_proj:3.335 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofenter easilycola intocola this excursion is easily dismissed or forgotten. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.626 (perp=7.737, rec=0.077, cos=0.001), tot_loss_proj:3.353 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofentercola intocola easily this excursion is easily dismissed or forgotten. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.626 (perp=7.737, rec=0.077, cos=0.001), tot_loss_proj:3.346 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofentercola intocola easily this excursion is easily dismissed or forgotten. [SEP]']
[ 750/2000] tot_loss=1.624 (perp=7.737, rec=0.075, cos=0.001), tot_loss_proj:3.352 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofentercola intocola easily this excursion is easily dismissed or forgotten. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.671 (perp=7.995, rec=0.071, cos=0.001), tot_loss_proj:3.420 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofentercola intocola genuinely this excursion is easily dismissed or forgotten. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.654 (perp=7.875, rec=0.078, cos=0.001), tot_loss_proj:3.377 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofentercola intocola this genuinely excursion is easily dismissed or forgotten. [SEP]']
[ 900/2000] tot_loss=1.646 (perp=7.875, rec=0.069, cos=0.001), tot_loss_proj:3.378 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofentercola intocola this genuinely excursion is easily dismissed or forgotten. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.645 (perp=7.875, rec=0.069, cos=0.001), tot_loss_proj:3.377 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofentercola intocola this genuinely excursion is easily dismissed or forgotten. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.636 (perp=7.826, rec=0.070, cos=0.001), tot_loss_proj:3.442 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofentercola intocola this excursion genuinely is easily dismissed or forgotten. [SEP]']
[1050/2000] tot_loss=1.638 (perp=7.826, rec=0.071, cos=0.001), tot_loss_proj:3.441 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofentercola intocola this excursion genuinely is easily dismissed or forgotten. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.626 (perp=7.780, rec=0.069, cos=0.001), tot_loss_proj:3.329 [t=0.31s]
prediction: ['[CLS] the not easily mental instability ofentercola intocola this excursion is genuinely easily dismissed or forgotten. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.657 (perp=7.926, rec=0.070, cos=0.001), tot_loss_proj:3.383 [t=0.31s]
prediction: ['[CLS] the not epic mental instability ofentercola intocola this excursion is genuinely easily dismissed or forgotten. [SEP]']
[1200/2000] tot_loss=1.661 (perp=7.926, rec=0.074, cos=0.001), tot_loss_proj:3.381 [t=0.32s]
prediction: ['[CLS] the not epic mental instability ofentercola intocola this excursion is genuinely easily dismissed or forgotten. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.567 (perp=7.485, rec=0.069, cos=0.001), tot_loss_proj:3.341 [t=0.31s]
prediction: ['[CLS] the not mental instability of epicentercola intocola this excursion is genuinely easily dismissed or forgotten. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.540 (perp=7.322, rec=0.074, cos=0.001), tot_loss_proj:3.323 [t=0.31s]
prediction: ['[CLS] not the mental instability of epicentercola intocola this excursion is genuinely easily dismissed or forgotten. [SEP]']
[1350/2000] tot_loss=1.539 (perp=7.322, rec=0.073, cos=0.001), tot_loss_proj:3.327 [t=0.31s]
prediction: ['[CLS] not the mental instability of epicentercola intocola this excursion is genuinely easily dismissed or forgotten. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.528 (perp=7.276, rec=0.072, cos=0.001), tot_loss_proj:1.821 [t=0.31s]
prediction: ['[CLS] genuinely the mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.522 (perp=7.276, rec=0.066, cos=0.001), tot_loss_proj:1.816 [t=0.31s]
prediction: ['[CLS] genuinely the mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
[1500/2000] tot_loss=1.526 (perp=7.276, rec=0.070, cos=0.001), tot_loss_proj:1.823 [t=0.31s]
prediction: ['[CLS] genuinely the mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.461 (perp=6.950, rec=0.070, cos=0.001), tot_loss_proj:1.678 [t=0.31s]
prediction: ['[CLS] the genuinely mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.467 (perp=6.950, rec=0.076, cos=0.001), tot_loss_proj:1.682 [t=0.32s]
prediction: ['[CLS] the genuinely mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
[1650/2000] tot_loss=1.467 (perp=6.950, rec=0.076, cos=0.001), tot_loss_proj:1.677 [t=0.31s]
prediction: ['[CLS] the genuinely mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.464 (perp=6.950, rec=0.072, cos=0.001), tot_loss_proj:1.675 [t=0.31s]
prediction: ['[CLS] the genuinely mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.468 (perp=6.950, rec=0.076, cos=0.001), tot_loss_proj:1.678 [t=0.31s]
prediction: ['[CLS] the genuinely mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
[1800/2000] tot_loss=1.466 (perp=6.950, rec=0.075, cos=0.001), tot_loss_proj:1.683 [t=0.31s]
prediction: ['[CLS] the genuinely mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.459 (perp=6.950, rec=0.068, cos=0.001), tot_loss_proj:1.673 [t=0.31s]
prediction: ['[CLS] the genuinely mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.454 (perp=6.950, rec=0.063, cos=0.001), tot_loss_proj:1.675 [t=0.31s]
prediction: ['[CLS] the genuinely mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
[1950/2000] tot_loss=1.454 (perp=6.950, rec=0.062, cos=0.001), tot_loss_proj:1.680 [t=0.31s]
prediction: ['[CLS] the genuinely mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.457 (perp=6.950, rec=0.066, cos=0.001), tot_loss_proj:1.674 [t=0.31s]
prediction: ['[CLS] the genuinely mental instability of epicentercola intocola this excursion is not easily dismissed or forgotten. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] the not easily mental instability ofentercola intocola this excursion genuinely is easily dismissed or forgotten. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.471 | p: 76.471 | r: 76.471
rouge2     | fm: 43.750 | p: 43.750 | r: 43.750
rougeL     | fm: 58.824 | p: 58.824 | r: 58.824
rougeLsum  | fm: 58.824 | p: 58.824 | r: 58.824
r1fm+r2fm = 120.221

[Aggregate metrics]:
rouge1     | fm: 93.265 | p: 92.864 | r: 93.713
rouge2     | fm: 60.854 | p: 60.665 | r: 61.073
rougeL     | fm: 80.595 | p: 80.277 | r: 80.973
rougeLsum  | fm: 80.528 | p: 80.203 | r: 80.854
r1fm+r2fm = 154.119

input #75 time: 0:12:30 | total time: 15:32:30


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9991397599193729
highest_index [0]
highest [0.9991397599193729]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.9215176701545715 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.8995768427848816 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 0.8978759050369263 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 0.8943430185317993 for ['[CLS] carrie word 38 saying subject window rican disc anatomy awardscles cf past resisted [SEP]']
[Init] best rec loss: 0.8671260476112366 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 0.8619845509529114 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.8494023680686951 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 0.8493690490722656 for ['[CLS] surreal onwardsoning hard ab tauthaw mangoˣ purse left ( pushed backward [SEP]']
[Init] best perm rec loss: 0.8482074737548828 for ['[CLS] surreal onwardsoning backward purse mango hard left ( ab pushed tauthawˣ [SEP]']
[Init] best perm rec loss: 0.8472138047218323 for ['[CLS] surrealoning ( mango backward pushedhaw onwards hardˣ ab left taut purse [SEP]']
[Init] best perm rec loss: 0.8466272354125977 for ['[CLS] ab backwardoninghaw ( taut left purse hardˣ onwards mango surreal pushed [SEP]']
[Init] best perm rec loss: 0.8452328443527222 for ['[CLS]haw tautˣ hardoning onwards left ab ( surreal backward purse pushed mango [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.629 (perp=11.610, rec=0.291, cos=0.016), tot_loss_proj:3.691 [t=0.31s]
prediction: ['[CLS]sis - spaces stopped ( throat quit closure has sounds stopped. craft. [SEP]']
[ 100/2000] tot_loss=2.071 (perp=9.283, rec=0.206, cos=0.008), tot_loss_proj:2.702 [t=0.31s]
prediction: ["[CLS] '. him stopped. allen attackednga has like stopped challenging himself. [SEP]"]
[ 150/2000] tot_loss=2.238 (perp=10.371, rec=0.159, cos=0.005), tot_loss_proj:2.905 [t=0.31s]
prediction: ["[CLS]'^ at stopped. allen 66nga has as stopped challenging himself. [SEP]"]
[ 200/2000] tot_loss=2.098 (perp=9.811, rec=0.131, cos=0.005), tot_loss_proj:2.844 [t=0.31s]
prediction: ["[CLS]'at at stopped. allen 66nga has as stopped challenging himself. [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=1.927 (perp=8.967, rec=0.129, cos=0.004), tot_loss_proj:2.802 [t=0.31s]
prediction: ['[CLS] s at at stopped. allen 66 has as¹ stopped challenging himself. [SEP]']
[ 300/2000] tot_loss=1.910 (perp=8.967, rec=0.113, cos=0.003), tot_loss_proj:2.789 [t=0.31s]
prediction: ['[CLS] s at at stopped. allen 66 has as¹ stopped challenging himself. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.822 (perp=8.556, rec=0.108, cos=0.003), tot_loss_proj:2.610 [t=0.31s]
prediction: ['[CLS] s. at stopped, allen 66 has as ᵥ stopped challenging himself, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.803 (perp=8.394, rec=0.120, cos=0.004), tot_loss_proj:2.586 [t=0.31s]
prediction: ['[CLS] s. at 66, allen his has as™ stopped challenging himself, [SEP]']
[ 450/2000] tot_loss=1.785 (perp=8.394, rec=0.103, cos=0.003), tot_loss_proj:2.596 [t=0.31s]
prediction: ['[CLS] s. at 66, allen his has as™ stopped challenging himself, [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.708 (perp=8.041, rec=0.097, cos=0.003), tot_loss_proj:2.321 [t=0.31s]
prediction: ['[CLS] s. at 66, allen as. has™ stopped challenging himself, [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.708 (perp=8.024, rec=0.099, cos=0.003), tot_loss_proj:2.332 [t=0.31s]
prediction: ['[CLS] s, at 66, allen has. as™ stopped challenging himself, [SEP]']
[ 600/2000] tot_loss=1.571 (perp=7.350, rec=0.098, cos=0.003), tot_loss_proj:2.269 [t=0.31s]
prediction: ['[CLS] s. at 66, allen has. asnta stopped challenging himself, [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.501 (perp=7.033, rec=0.091, cos=0.003), tot_loss_proj:2.215 [t=0.31s]
prediction: ['[CLS] s. at 66, allen has, asnta stopped challenging himself. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.503 (perp=7.033, rec=0.094, cos=0.003), tot_loss_proj:2.215 [t=0.31s]
prediction: ['[CLS] s. at 66, allen has, asnta stopped challenging himself. [SEP]']
[ 750/2000] tot_loss=1.361 (perp=6.327, rec=0.093, cos=0.003), tot_loss_proj:1.896 [t=0.31s]
prediction: ['[CLS] s. at 66, allen has, as, stopped challenging himself. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.368 (perp=6.327, rec=0.100, cos=0.003), tot_loss_proj:1.891 [t=0.31s]
prediction: ['[CLS] s. at 66, allen has, as, stopped challenging himself. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.748 (perp=7.500, rec=0.228, cos=0.020), tot_loss_proj:2.440 [t=0.31s]
prediction: ['[CLS] s. at 66, allen has stopped, as [SEP] challenging himself ( [SEP]']
[ 900/2000] tot_loss=1.672 (perp=7.500, rec=0.163, cos=0.009), tot_loss_proj:2.434 [t=0.31s]
prediction: ['[CLS] s. at 66, allen has stopped, as [SEP] challenging himself ( [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.589 (perp=7.175, rec=0.147, cos=0.007), tot_loss_proj:2.359 [t=0.31s]
prediction: ['[CLS] [SEP] s. at 66, allen has stopped, as challenging himself ( [SEP]']
Attempt swap
[1000/2000] tot_loss=1.577 (perp=7.175, rec=0.136, cos=0.006), tot_loss_proj:2.358 [t=0.31s]
prediction: ['[CLS] [SEP] s. at 66, allen has stopped, as challenging himself ( [SEP]']
[1050/2000] tot_loss=1.574 (perp=7.175, rec=0.133, cos=0.006), tot_loss_proj:2.352 [t=0.31s]
prediction: ['[CLS] [SEP] s. at 66, allen has stopped, as challenging himself ( [SEP]']
Attempt swap
[1100/2000] tot_loss=1.566 (perp=7.175, rec=0.125, cos=0.005), tot_loss_proj:2.358 [t=0.31s]
prediction: ['[CLS] [SEP] s. at 66, allen has stopped, as challenging himself ( [SEP]']
Attempt swap
[1150/2000] tot_loss=1.561 (perp=7.175, rec=0.121, cos=0.005), tot_loss_proj:2.363 [t=0.31s]
prediction: ['[CLS] [SEP] s. at 66, allen has stopped, as challenging himself ( [SEP]']
[1200/2000] tot_loss=1.561 (perp=7.175, rec=0.121, cos=0.005), tot_loss_proj:2.359 [t=0.31s]
prediction: ['[CLS] [SEP] s. at 66, allen has stopped, as challenging himself ( [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.526 (perp=6.987, rec=0.123, cos=0.005), tot_loss_proj:2.443 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
Attempt swap
[1300/2000] tot_loss=1.520 (perp=6.987, rec=0.118, cos=0.005), tot_loss_proj:2.441 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
[1350/2000] tot_loss=1.520 (perp=6.987, rec=0.118, cos=0.005), tot_loss_proj:2.445 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
Attempt swap
[1400/2000] tot_loss=1.513 (perp=6.987, rec=0.111, cos=0.005), tot_loss_proj:2.443 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
Attempt swap
[1450/2000] tot_loss=1.505 (perp=6.987, rec=0.103, cos=0.004), tot_loss_proj:2.443 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
[1500/2000] tot_loss=1.517 (perp=6.987, rec=0.115, cos=0.004), tot_loss_proj:2.442 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
Attempt swap
[1550/2000] tot_loss=1.519 (perp=6.987, rec=0.117, cos=0.004), tot_loss_proj:2.441 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
Attempt swap
[1600/2000] tot_loss=1.515 (perp=6.987, rec=0.113, cos=0.004), tot_loss_proj:2.445 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
[1650/2000] tot_loss=1.518 (perp=6.987, rec=0.116, cos=0.004), tot_loss_proj:2.448 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
Attempt swap
[1700/2000] tot_loss=1.515 (perp=6.987, rec=0.113, cos=0.004), tot_loss_proj:2.442 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
Attempt swap
[1750/2000] tot_loss=1.511 (perp=6.987, rec=0.110, cos=0.004), tot_loss_proj:2.442 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
[1800/2000] tot_loss=1.510 (perp=6.987, rec=0.108, cos=0.004), tot_loss_proj:2.439 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
Attempt swap
[1850/2000] tot_loss=1.520 (perp=6.987, rec=0.118, cos=0.004), tot_loss_proj:2.446 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
Attempt swap
[1900/2000] tot_loss=1.506 (perp=6.987, rec=0.104, cos=0.004), tot_loss_proj:2.440 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
[1950/2000] tot_loss=1.512 (perp=6.987, rec=0.111, cos=0.004), tot_loss_proj:2.447 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
Attempt swap
[2000/2000] tot_loss=1.513 (perp=6.987, rec=0.111, cos=0.004), tot_loss_proj:2.443 [t=0.31s]
prediction: ['[CLS] [SEP] s. allen at 66, has stopped, as challenging himself ( [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] s. at 66, allen has, as, stopped challenging himself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 100.000 | r: 91.667
rouge2     | fm: 47.619 | p: 50.000 | r: 45.455
rougeL     | fm: 78.261 | p: 81.818 | r: 75.000
rougeLsum  | fm: 78.261 | p: 81.818 | r: 75.000
r1fm+r2fm = 143.271

[Aggregate metrics]:
rouge1     | fm: 93.283 | p: 92.930 | r: 93.683
rouge2     | fm: 60.676 | p: 60.536 | r: 60.849
rougeL     | fm: 80.755 | p: 80.452 | r: 81.044
rougeLsum  | fm: 80.542 | p: 80.243 | r: 80.840
r1fm+r2fm = 153.959

input #76 time: 0:12:15 | total time: 15:44:45


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9992003428553193
highest_index [0]
highest [0.9992003428553193]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.9114837646484375 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8800389766693115 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.8725097179412842 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.8699513077735901 for ['[CLS]yana daylight matthewlson blacksmithdrop county endless rural tel gallery pencil poet something yugoslav [SEP]']
[Init] best perm rec loss: 0.8697652816772461 for ['[CLS] ruraldrop endless yugoslavlson countyyana pencil tel poet something daylight gallery blacksmith matthew [SEP]']
[Init] best perm rec loss: 0.8667632937431335 for ['[CLS]drop tellson blacksmith yugoslav county pencil rural daylight something matthew poetyana endless gallery [SEP]']
[Init] best perm rec loss: 0.8665084838867188 for ['[CLS] poet daylightyana pencil something yugoslav rural matthew tel endless blacksmithdrop countylson gallery [SEP]']
[Init] best perm rec loss: 0.8627813458442688 for ['[CLS] gallery rural something daylightdrop pencil yugoslav endless tel matthew blacksmith county poetlsonyana [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.702 (perp=11.700, rec=0.342, cos=0.020), tot_loss_proj:3.704 [t=0.31s]
prediction: ['[CLS] was rancho international making concrete the be becomes sight abbey player realm was darcy it [SEP]']
[ 100/2000] tot_loss=2.060 (perp=8.815, rec=0.266, cos=0.031), tot_loss_proj:3.033 [t=0.31s]
prediction: ['[CLS] isbrates life its truth the promise its promise realm above realm is above it [SEP]']
[ 150/2000] tot_loss=1.925 (perp=8.623, rec=0.194, cos=0.006), tot_loss_proj:2.717 [t=0.31s]
prediction: ['[CLS] isph life its believe that promise its promise life above life above above it [SEP]']
[ 200/2000] tot_loss=2.060 (perp=9.558, rec=0.144, cos=0.004), tot_loss_proj:2.839 [t=0.32s]
prediction: ['[CLS] isph life its believe that promise its promise realmars life above above it [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.979 (perp=9.188, rec=0.138, cos=0.003), tot_loss_proj:2.635 [t=0.32s]
prediction: ['[CLS] is make life material believe that believe its promise realmars life above above it [SEP]']
[ 300/2000] tot_loss=1.963 (perp=9.133, rec=0.134, cos=0.003), tot_loss_proj:2.808 [t=0.32s]
prediction: ['[CLS] is make life make believe that believe its promise realmars life above realm it [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.866 (perp=8.776, rec=0.108, cos=0.003), tot_loss_proj:2.735 [t=0.32s]
prediction: ['[CLS] is make life make believe that believe its promise realmars above life realm it [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.775 (perp=8.297, rec=0.113, cos=0.003), tot_loss_proj:2.983 [t=0.31s]
prediction: ['[CLS] is it life make believe that believe its promise materialars above life realm make [SEP]']
[ 450/2000] tot_loss=1.815 (perp=8.502, rec=0.112, cos=0.002), tot_loss_proj:2.683 [t=0.31s]
prediction: ['[CLS] is of life make believe that believe its promise materialars above life realm make [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.858 (perp=8.702, rec=0.115, cos=0.003), tot_loss_proj:2.770 [t=0.31s]
prediction: ['[CLS] is make believe that believe its promisear life materialars above life realm make [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.540 (perp=7.073, rec=0.122, cos=0.003), tot_loss_proj:2.515 [t=0.32s]
prediction: ['[CLS] is make believe that believe its promise of lifears above life realm make material [SEP]']
[ 600/2000] tot_loss=1.523 (perp=7.073, rec=0.106, cos=0.002), tot_loss_proj:2.505 [t=0.31s]
prediction: ['[CLS] is make believe that believe its promise of lifears above life realm make material [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.363 (perp=6.323, rec=0.096, cos=0.002), tot_loss_proj:2.183 [t=0.31s]
prediction: ['[CLS] is make believe that make believe its promise of lifears above life realm material [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.362 (perp=6.323, rec=0.096, cos=0.002), tot_loss_proj:2.186 [t=0.31s]
prediction: ['[CLS] is make believe that make believe its promise of lifears above life realm material [SEP]']
[ 750/2000] tot_loss=1.418 (perp=6.650, rec=0.086, cos=0.002), tot_loss_proj:2.089 [t=0.31s]
prediction: ['[CLS] is make believe that make believe its promise so lifears above life realm material [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.367 (perp=6.397, rec=0.086, cos=0.002), tot_loss_proj:1.953 [t=0.31s]
prediction: ['[CLS] is make believe that make believe its promise life soars above the realm material [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.258 (perp=5.897, rec=0.077, cos=0.002), tot_loss_proj:1.692 [t=0.32s]
prediction: ['[CLS] is make believe that make believe its promise life soars above the material realm [SEP]']
[ 900/2000] tot_loss=1.266 (perp=5.897, rec=0.085, cos=0.002), tot_loss_proj:1.694 [t=0.31s]
prediction: ['[CLS] is make believe that make believe its promise life soars above the material realm [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.251 (perp=5.897, rec=0.070, cos=0.002), tot_loss_proj:1.687 [t=0.31s]
prediction: ['[CLS] is make believe that make believe its promise life soars above the material realm [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.244 (perp=5.850, rec=0.072, cos=0.002), tot_loss_proj:1.633 [t=0.31s]
prediction: ['[CLS] is make believe that make its promise of life soars above the material realm [SEP]']
[1050/2000] tot_loss=1.252 (perp=5.850, rec=0.080, cos=0.002), tot_loss_proj:1.637 [t=0.31s]
prediction: ['[CLS] is make believe that make its promise of life soars above the material realm [SEP]']
Attempt swap
[1100/2000] tot_loss=1.249 (perp=5.850, rec=0.078, cos=0.002), tot_loss_proj:1.636 [t=0.31s]
prediction: ['[CLS] is make believe that make its promise of life soars above the material realm [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.199 (perp=5.527, rec=0.091, cos=0.002), tot_loss_proj:1.649 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
[1200/2000] tot_loss=1.187 (perp=5.527, rec=0.079, cos=0.002), tot_loss_proj:1.647 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Attempt swap
[1250/2000] tot_loss=1.187 (perp=5.527, rec=0.080, cos=0.002), tot_loss_proj:1.645 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Attempt swap
[1300/2000] tot_loss=1.184 (perp=5.527, rec=0.077, cos=0.002), tot_loss_proj:1.644 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
[1350/2000] tot_loss=1.185 (perp=5.527, rec=0.078, cos=0.002), tot_loss_proj:1.645 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Attempt swap
[1400/2000] tot_loss=1.189 (perp=5.527, rec=0.082, cos=0.002), tot_loss_proj:1.646 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Attempt swap
[1450/2000] tot_loss=1.176 (perp=5.527, rec=0.069, cos=0.002), tot_loss_proj:1.639 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
[1500/2000] tot_loss=1.186 (perp=5.527, rec=0.079, cos=0.002), tot_loss_proj:1.647 [t=0.32s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Attempt swap
[1550/2000] tot_loss=1.179 (perp=5.527, rec=0.072, cos=0.002), tot_loss_proj:1.643 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Attempt swap
[1600/2000] tot_loss=1.198 (perp=5.527, rec=0.091, cos=0.002), tot_loss_proj:1.644 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
[1650/2000] tot_loss=1.183 (perp=5.527, rec=0.076, cos=0.002), tot_loss_proj:1.644 [t=0.32s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Attempt swap
[1700/2000] tot_loss=1.173 (perp=5.527, rec=0.066, cos=0.002), tot_loss_proj:1.648 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Attempt swap
[1750/2000] tot_loss=1.183 (perp=5.527, rec=0.076, cos=0.002), tot_loss_proj:1.644 [t=0.32s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
[1800/2000] tot_loss=1.177 (perp=5.527, rec=0.070, cos=0.002), tot_loss_proj:1.644 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Attempt swap
[1850/2000] tot_loss=1.178 (perp=5.527, rec=0.071, cos=0.002), tot_loss_proj:1.643 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Attempt swap
[1900/2000] tot_loss=1.181 (perp=5.527, rec=0.074, cos=0.002), tot_loss_proj:1.640 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
[1950/2000] tot_loss=1.183 (perp=5.527, rec=0.076, cos=0.002), tot_loss_proj:1.645 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Attempt swap
[2000/2000] tot_loss=1.178 (perp=5.527, rec=0.071, cos=0.002), tot_loss_proj:1.643 [t=0.31s]
prediction: ['[CLS] is make believe that its promise of life soars above the material realm make [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] is make believe that its promise of life soars above the material realm make [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.774 | p: 93.750 | r: 100.000
rouge2     | fm: 55.172 | p: 53.333 | r: 57.143
rougeL     | fm: 83.871 | p: 81.250 | r: 86.667
rougeLsum  | fm: 83.871 | p: 81.250 | r: 86.667
r1fm+r2fm = 151.947

[Aggregate metrics]:
rouge1     | fm: 93.343 | p: 92.945 | r: 93.746
rouge2     | fm: 60.568 | p: 60.433 | r: 60.765
rougeL     | fm: 80.745 | p: 80.469 | r: 81.112
rougeLsum  | fm: 80.549 | p: 80.266 | r: 80.848
r1fm+r2fm = 153.911

input #77 time: 0:12:31 | total time: 15:57:16


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9992706387519585
highest_index [0]
highest [0.9992706387519585]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9854726791381836 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9806399941444397 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8514598608016968 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8322032690048218 for ['[CLS] le screens grant [SEP]']
[Init] best rec loss: 0.8314107060432434 for ['[CLS] lightatics help [SEP]']
[Init] best perm rec loss: 0.8310553431510925 for ['[CLS] light helpatics [SEP]']
[Init] best perm rec loss: 0.8266263604164124 for ['[CLS]atics help light [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.010 (perp=8.924, rec=0.211, cos=0.014), tot_loss_proj:2.706 [t=0.31s]
prediction: ['[CLS] theater exit exit [SEP]']
[ 100/2000] tot_loss=1.900 (perp=8.924, rec=0.110, cos=0.005), tot_loss_proj:2.703 [t=0.31s]
prediction: ['[CLS] theater exit exit [SEP]']
[ 150/2000] tot_loss=1.880 (perp=8.924, rec=0.092, cos=0.003), tot_loss_proj:2.710 [t=0.31s]
prediction: ['[CLS] theater exit exit [SEP]']
[ 200/2000] tot_loss=1.879 (perp=8.924, rec=0.090, cos=0.004), tot_loss_proj:2.703 [t=0.31s]
prediction: ['[CLS] theater exit exit [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.287 (perp=10.980, rec=0.090, cos=0.002), tot_loss_proj:3.079 [t=0.31s]
prediction: ['[CLS] theater exit the [SEP]']
[ 300/2000] tot_loss=2.266 (perp=10.980, rec=0.068, cos=0.001), tot_loss_proj:3.093 [t=0.31s]
prediction: ['[CLS] theater exit the [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.666 (perp=7.958, rec=0.073, cos=0.001), tot_loss_proj:1.687 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.658 (perp=7.958, rec=0.065, cos=0.001), tot_loss_proj:1.669 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.659 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.686 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.661 (perp=7.958, rec=0.068, cos=0.001), tot_loss_proj:1.678 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.665 (perp=7.958, rec=0.072, cos=0.001), tot_loss_proj:1.677 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.673 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.669 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.665 (perp=7.958, rec=0.072, cos=0.001), tot_loss_proj:1.665 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.683 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.680 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.659 (perp=7.958, rec=0.066, cos=0.001), tot_loss_proj:1.671 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.679 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.651 (perp=7.958, rec=0.058, cos=0.001), tot_loss_proj:1.672 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.656 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.668 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.683 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.671 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.690 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.673 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.668 (perp=7.958, rec=0.075, cos=0.001), tot_loss_proj:1.681 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.680 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.664 (perp=7.958, rec=0.071, cos=0.001), tot_loss_proj:1.678 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.661 (perp=7.958, rec=0.068, cos=0.001), tot_loss_proj:1.670 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.672 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.643 (perp=7.958, rec=0.050, cos=0.001), tot_loss_proj:1.666 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.669 (perp=7.958, rec=0.076, cos=0.001), tot_loss_proj:1.683 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.680 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.676 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.645 (perp=7.958, rec=0.052, cos=0.001), tot_loss_proj:1.683 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.664 (perp=7.958, rec=0.071, cos=0.001), tot_loss_proj:1.677 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.661 (perp=7.958, rec=0.068, cos=0.001), tot_loss_proj:1.682 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.684 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.659 (perp=7.958, rec=0.066, cos=0.001), tot_loss_proj:1.680 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.677 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.398 | p: 93.035 | r: 93.793
rouge2     | fm: 61.047 | p: 60.919 | r: 61.220
rougeL     | fm: 80.933 | p: 80.642 | r: 81.263
rougeLsum  | fm: 80.859 | p: 80.605 | r: 81.144
r1fm+r2fm = 154.445

input #78 time: 0:12:13 | total time: 16:09:30


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.9993343587296917
highest_index [0]
highest [0.9993343587296917]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9717714190483093 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.8485546708106995 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.837908148765564 for ['[CLS] funslow [SEP]']
[Init] best rec loss: 0.8347746729850769 for ['[CLS] gray should [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.019 (perp=9.382, rec=0.140, cos=0.003), tot_loss_proj:1.945 [t=0.31s]
prediction: ['[CLS] is fascinating [SEP]']
[ 100/2000] tot_loss=1.951 (perp=9.382, rec=0.074, cos=0.001), tot_loss_proj:1.954 [t=0.31s]
prediction: ['[CLS] is fascinating [SEP]']
[ 150/2000] tot_loss=1.937 (perp=9.382, rec=0.060, cos=0.001), tot_loss_proj:1.953 [t=0.31s]
prediction: ['[CLS] is fascinating [SEP]']
[ 200/2000] tot_loss=1.946 (perp=9.382, rec=0.069, cos=0.001), tot_loss_proj:1.948 [t=0.31s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.938 (perp=9.382, rec=0.060, cos=0.001), tot_loss_proj:1.964 [t=0.31s]
prediction: ['[CLS] is fascinating [SEP]']
[ 300/2000] tot_loss=1.928 (perp=9.382, rec=0.051, cos=0.001), tot_loss_proj:1.946 [t=0.31s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.822 (perp=8.695, rec=0.082, cos=0.001), tot_loss_proj:1.959 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.961 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.812 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.956 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.797 (perp=8.695, rec=0.057, cos=0.001), tot_loss_proj:1.954 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.956 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.960 [t=0.32s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.955 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.794 (perp=8.695, rec=0.054, cos=0.001), tot_loss_proj:1.954 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.793 (perp=8.695, rec=0.053, cos=0.001), tot_loss_proj:1.957 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.950 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.944 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.808 (perp=8.695, rec=0.068, cos=0.001), tot_loss_proj:1.951 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.960 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.968 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.805 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.955 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.958 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.962 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.811 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.954 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.961 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.947 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.947 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.796 (perp=8.695, rec=0.055, cos=0.001), tot_loss_proj:1.952 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.959 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.797 (perp=8.695, rec=0.057, cos=0.001), tot_loss_proj:1.954 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.796 (perp=8.695, rec=0.056, cos=0.001), tot_loss_proj:1.956 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.803 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.945 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.957 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.807 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.950 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.959 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.957 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.954 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.815 (perp=8.695, rec=0.075, cos=0.001), tot_loss_proj:1.952 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.955 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.807 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.950 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] is fascinating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.501 | p: 93.168 | r: 93.922
rouge2     | fm: 61.597 | p: 61.463 | r: 61.808
rougeL     | fm: 81.214 | p: 80.943 | r: 81.499
rougeLsum  | fm: 81.034 | p: 80.753 | r: 81.344
r1fm+r2fm = 155.097

input #79 time: 0:12:13 | total time: 16:21:43


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9992809945888868
highest_index [0]
highest [0.9992809945888868]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9611423015594482 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.959408700466156 for ['[CLS]yna snaps california mussolini kicked [SEP]']
[Init] best rec loss: 0.9382954835891724 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.9265960454940796 for ['[CLS]down frasercake court beta [SEP]']
[Init] best rec loss: 0.924712598323822 for ['[CLS] anywhere occupiedmity love today [SEP]']
[Init] best rec loss: 0.9179965257644653 for ["[CLS]'incense kraft it jubilee [SEP]"]
[Init] best perm rec loss: 0.9137431383132935 for ["[CLS] jubilee incense'kraft it [SEP]"]
[Init] best perm rec loss: 0.9126923084259033 for ["[CLS] kraft it incense jubilee'[SEP]"]
[Init] best perm rec loss: 0.9112301468849182 for ["[CLS] kraft jubilee'incense it [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.491 (perp=11.243, rec=0.238, cos=0.005), tot_loss_proj:2.998 [t=0.31s]
prediction: ['[CLS] - wise ofzen wise [SEP]']
[ 100/2000] tot_loss=2.315 (perp=10.641, rec=0.183, cos=0.004), tot_loss_proj:3.030 [t=0.31s]
prediction: ['[CLS],zenzenzen wise [SEP]']
[ 150/2000] tot_loss=2.640 (perp=12.442, rec=0.149, cos=0.003), tot_loss_proj:3.196 [t=0.31s]
prediction: ['[CLS] wi wizenzen wise [SEP]']
[ 200/2000] tot_loss=2.616 (perp=12.442, rec=0.125, cos=0.003), tot_loss_proj:3.194 [t=0.31s]
prediction: ['[CLS] wi wizenzen wise [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.893 (perp=8.790, rec=0.131, cos=0.004), tot_loss_proj:2.196 [t=0.31s]
prediction: ['[CLS] wizenedzen wise [SEP]']
[ 300/2000] tot_loss=2.180 (perp=10.307, rec=0.115, cos=0.003), tot_loss_proj:2.612 [t=0.31s]
prediction: ['[CLS] wizen,zen wise [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.004 (perp=9.459, rec=0.109, cos=0.003), tot_loss_proj:2.495 [t=0.31s]
prediction: ['[CLS] wizen, wisezen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.995 (perp=9.215, rec=0.148, cos=0.004), tot_loss_proj:2.318 [t=0.31s]
prediction: ['[CLS] wisezened wizen [SEP]']
[ 450/2000] tot_loss=1.963 (perp=9.215, rec=0.117, cos=0.003), tot_loss_proj:2.338 [t=0.31s]
prediction: ['[CLS] wisezened wizen [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.670 (perp=7.823, rec=0.102, cos=0.003), tot_loss_proj:1.921 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.781 (perp=8.349, rec=0.109, cos=0.003), tot_loss_proj:2.641 [t=0.31s]
prediction: ['[CLS] wizened wiseette [SEP]']
[ 600/2000] tot_loss=1.737 (perp=8.175, rec=0.100, cos=0.003), tot_loss_proj:2.083 [t=0.31s]
prediction: ['[CLS] wizened wise bonnie [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.745 (perp=8.175, rec=0.107, cos=0.003), tot_loss_proj:2.082 [t=0.31s]
prediction: ['[CLS] wizened wise bonnie [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.674 (perp=7.823, rec=0.107, cos=0.003), tot_loss_proj:1.934 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
[ 750/2000] tot_loss=1.857 (perp=8.747, rec=0.104, cos=0.003), tot_loss_proj:2.762 [t=0.31s]
prediction: ['[CLS] wizened wiseght [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.862 (perp=8.747, rec=0.109, cos=0.003), tot_loss_proj:2.745 [t=0.31s]
prediction: ['[CLS] wizened wiseght [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.600 (perp=7.554, rec=0.087, cos=0.003), tot_loss_proj:2.337 [t=0.31s]
prediction: ['[CLS] wizened wisesia [SEP]']
[ 900/2000] tot_loss=1.624 (perp=7.554, rec=0.111, cos=0.002), tot_loss_proj:2.341 [t=0.31s]
prediction: ['[CLS] wizened wisesia [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.769 (perp=8.350, rec=0.096, cos=0.002), tot_loss_proj:2.612 [t=0.31s]
prediction: ['[CLS] wizened wiseead [SEP]']
Attempt swap
[1000/2000] tot_loss=1.764 (perp=8.350, rec=0.092, cos=0.002), tot_loss_proj:2.611 [t=0.31s]
prediction: ['[CLS] wizened wiseead [SEP]']
[1050/2000] tot_loss=1.801 (perp=8.589, rec=0.082, cos=0.002), tot_loss_proj:2.332 [t=0.31s]
prediction: ['[CLS] wizened wise trey [SEP]']
Attempt swap
[1100/2000] tot_loss=1.807 (perp=8.589, rec=0.088, cos=0.002), tot_loss_proj:2.330 [t=0.31s]
prediction: ['[CLS] wizened wise trey [SEP]']
Attempt swap
[1150/2000] tot_loss=1.806 (perp=8.589, rec=0.086, cos=0.002), tot_loss_proj:2.327 [t=0.31s]
prediction: ['[CLS] wizened wise trey [SEP]']
[1200/2000] tot_loss=1.650 (perp=7.823, rec=0.083, cos=0.002), tot_loss_proj:1.918 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[1250/2000] tot_loss=1.660 (perp=7.823, rec=0.093, cos=0.002), tot_loss_proj:1.936 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[1300/2000] tot_loss=1.653 (perp=7.823, rec=0.087, cos=0.002), tot_loss_proj:1.919 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
[1350/2000] tot_loss=1.649 (perp=7.823, rec=0.083, cos=0.002), tot_loss_proj:1.916 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[1400/2000] tot_loss=1.660 (perp=7.823, rec=0.093, cos=0.002), tot_loss_proj:1.913 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[1450/2000] tot_loss=1.662 (perp=7.823, rec=0.095, cos=0.002), tot_loss_proj:1.926 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
[1500/2000] tot_loss=1.659 (perp=7.823, rec=0.093, cos=0.002), tot_loss_proj:1.920 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[1550/2000] tot_loss=1.649 (perp=7.823, rec=0.082, cos=0.002), tot_loss_proj:1.927 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[1600/2000] tot_loss=1.649 (perp=7.823, rec=0.082, cos=0.002), tot_loss_proj:1.921 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
[1650/2000] tot_loss=1.662 (perp=7.823, rec=0.095, cos=0.002), tot_loss_proj:1.925 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[1700/2000] tot_loss=1.641 (perp=7.823, rec=0.075, cos=0.002), tot_loss_proj:1.925 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[1750/2000] tot_loss=1.647 (perp=7.823, rec=0.081, cos=0.002), tot_loss_proj:1.928 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
[1800/2000] tot_loss=1.653 (perp=7.823, rec=0.087, cos=0.002), tot_loss_proj:1.922 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[1850/2000] tot_loss=1.649 (perp=7.823, rec=0.083, cos=0.002), tot_loss_proj:1.922 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[1900/2000] tot_loss=1.649 (perp=7.823, rec=0.083, cos=0.002), tot_loss_proj:1.928 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
[1950/2000] tot_loss=1.634 (perp=7.823, rec=0.068, cos=0.002), tot_loss_proj:1.925 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Attempt swap
[2000/2000] tot_loss=1.652 (perp=7.823, rec=0.086, cos=0.002), tot_loss_proj:1.924 [t=0.31s]
prediction: ['[CLS] wizened wise shepard [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wizened wise shepard [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 80.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 88.889

[Aggregate metrics]:
rouge1     | fm: 93.427 | p: 92.959 | r: 93.976
rouge2     | fm: 60.851 | p: 60.707 | r: 60.978
rougeL     | fm: 80.956 | p: 80.545 | r: 81.414
rougeLsum  | fm: 80.856 | p: 80.482 | r: 81.333
r1fm+r2fm = 154.278

input #80 time: 0:12:15 | total time: 16:33:59


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9992867990482487
highest_index [0]
highest [0.9992867990482487]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9025961756706238 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.8557173013687134 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8426028490066528 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8211221694946289 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.8160744905471802 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.811552882194519 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 0.7947888970375061 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 0.7920023798942566 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 0.7896146774291992 for ['[CLS] proceededdownvikplate ivy donaldson [SEP]']
[Init] best perm rec loss: 0.7885788083076477 for ['[CLS]vik ivy proceeded donaldsondownplate [SEP]']
[Init] best perm rec loss: 0.7874436974525452 for ['[CLS]plate donaldson proceededdownvik ivy [SEP]']
[Init] best perm rec loss: 0.7851840257644653 for ['[CLS] donaldson proceeded ivyvikplatedown [SEP]']
[Init] best perm rec loss: 0.7842674851417542 for ['[CLS] ivy proceededvik donaldsondownplate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.523 (perp=10.861, rec=0.322, cos=0.028), tot_loss_proj:3.958 [t=0.31s]
prediction: ['[CLS] had not dispute daughter player most [SEP]']
[ 100/2000] tot_loss=1.921 (perp=8.644, rec=0.182, cos=0.010), tot_loss_proj:3.339 [t=0.31s]
prediction: ['[CLS] is not player player most impressive [SEP]']
[ 150/2000] tot_loss=2.057 (perp=9.650, rec=0.121, cos=0.006), tot_loss_proj:3.697 [t=0.31s]
prediction: ['[CLS] is not facto player most impressive [SEP]']
[ 200/2000] tot_loss=1.383 (perp=6.400, rec=0.099, cos=0.005), tot_loss_proj:1.698 [t=0.31s]
prediction: ['[CLS] is not the player most impressive [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.835 (perp=8.659, rec=0.098, cos=0.005), tot_loss_proj:2.890 [t=0.31s]
prediction: ['[CLS] is not strategic most impressive player [SEP]']
[ 300/2000] tot_loss=1.787 (perp=8.422, rec=0.098, cos=0.004), tot_loss_proj:3.195 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.780 (perp=8.422, rec=0.091, cos=0.004), tot_loss_proj:3.189 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.777 (perp=8.422, rec=0.088, cos=0.004), tot_loss_proj:3.196 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
[ 450/2000] tot_loss=1.774 (perp=8.422, rec=0.086, cos=0.004), tot_loss_proj:3.196 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.783 (perp=8.422, rec=0.095, cos=0.004), tot_loss_proj:3.191 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.772 (perp=8.422, rec=0.084, cos=0.004), tot_loss_proj:3.191 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
[ 600/2000] tot_loss=1.780 (perp=8.422, rec=0.091, cos=0.004), tot_loss_proj:3.193 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.777 (perp=8.422, rec=0.089, cos=0.004), tot_loss_proj:3.193 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.779 (perp=8.422, rec=0.090, cos=0.004), tot_loss_proj:3.195 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
[ 750/2000] tot_loss=1.768 (perp=8.422, rec=0.080, cos=0.004), tot_loss_proj:3.189 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.765 (perp=8.422, rec=0.077, cos=0.004), tot_loss_proj:3.187 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.769 (perp=8.422, rec=0.080, cos=0.004), tot_loss_proj:3.189 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
[ 900/2000] tot_loss=1.773 (perp=8.422, rec=0.084, cos=0.004), tot_loss_proj:3.188 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.766 (perp=8.422, rec=0.077, cos=0.004), tot_loss_proj:3.184 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.772 (perp=8.422, rec=0.084, cos=0.004), tot_loss_proj:3.189 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
[1050/2000] tot_loss=1.765 (perp=8.422, rec=0.077, cos=0.004), tot_loss_proj:3.180 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.776 (perp=8.422, rec=0.088, cos=0.004), tot_loss_proj:3.187 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.774 (perp=8.422, rec=0.086, cos=0.004), tot_loss_proj:3.185 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
[1200/2000] tot_loss=1.779 (perp=8.422, rec=0.091, cos=0.004), tot_loss_proj:3.180 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.783 (perp=8.422, rec=0.095, cos=0.004), tot_loss_proj:3.184 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.782 (perp=8.422, rec=0.094, cos=0.004), tot_loss_proj:3.185 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
[1350/2000] tot_loss=1.773 (perp=8.422, rec=0.085, cos=0.004), tot_loss_proj:3.184 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.773 (perp=8.422, rec=0.085, cos=0.004), tot_loss_proj:3.181 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.784 (perp=8.422, rec=0.096, cos=0.004), tot_loss_proj:3.175 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
[1500/2000] tot_loss=1.774 (perp=8.422, rec=0.085, cos=0.004), tot_loss_proj:3.183 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.777 (perp=8.422, rec=0.089, cos=0.004), tot_loss_proj:3.184 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.776 (perp=8.422, rec=0.088, cos=0.004), tot_loss_proj:3.179 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
[1650/2000] tot_loss=1.768 (perp=8.422, rec=0.080, cos=0.004), tot_loss_proj:3.180 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.766 (perp=8.422, rec=0.078, cos=0.004), tot_loss_proj:3.184 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.773 (perp=8.422, rec=0.085, cos=0.004), tot_loss_proj:3.181 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
[1800/2000] tot_loss=1.771 (perp=8.422, rec=0.083, cos=0.004), tot_loss_proj:3.181 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.778 (perp=8.422, rec=0.090, cos=0.004), tot_loss_proj:3.182 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.772 (perp=8.422, rec=0.084, cos=0.004), tot_loss_proj:3.182 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
[1950/2000] tot_loss=1.777 (perp=8.422, rec=0.088, cos=0.004), tot_loss_proj:3.181 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.775 (perp=8.422, rec=0.087, cos=0.004), tot_loss_proj:3.182 [t=0.31s]
prediction: ['[CLS] is not necessary most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not necessary most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 71.429 | p: 71.429 | r: 71.429
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 158.929

[Aggregate metrics]:
rouge1     | fm: 93.337 | p: 92.859 | r: 93.884
rouge2     | fm: 60.845 | p: 60.715 | r: 61.002
rougeL     | fm: 81.051 | p: 80.644 | r: 81.467
rougeLsum  | fm: 81.004 | p: 80.638 | r: 81.474
r1fm+r2fm = 154.182

input #81 time: 0:12:15 | total time: 16:46:14


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.9992799954937182
highest_index [0]
highest [0.9992799954937182]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9872238636016846 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9797040820121765 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.9477160573005676 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9475510120391846 for ['[CLS] decide handed sample game early dominated rolling missionary [SEP]']
[Init] best rec loss: 0.932945966720581 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9322380423545837 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 0.8662109971046448 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.828519880771637 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8224375247955322 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.820646345615387 for ['[CLS]basket respective whoever role plumagefurach record [SEP]']
[Init] best perm rec loss: 0.819679319858551 for ['[CLS]furbasket respective whoever record plumage roleach [SEP]']
[Init] best perm rec loss: 0.8189589381217957 for ['[CLS]basket respectivefur whoeverach plumage role record [SEP]']
[Init] best perm rec loss: 0.8185702562332153 for ['[CLS]furbasket record plumageach role respective whoever [SEP]']
[Init] best perm rec loss: 0.8183068633079529 for ['[CLS]basketfur roleach whoever respective record plumage [SEP]']
[Init] best perm rec loss: 0.8174704313278198 for ['[CLS] recordbasket whoever role respectiveach plumagefur [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.566 (perp=6.855, rec=0.191, cos=0.005), tot_loss_proj:1.728 [t=0.30s]
prediction: ['[CLS] a sloppy scriptic script is undone by [SEP]']
[ 100/2000] tot_loss=1.826 (perp=8.639, rec=0.096, cos=0.002), tot_loss_proj:2.101 [t=0.31s]
prediction: ['[CLS] a sloppy scripted script s undone by [SEP]']
[ 150/2000] tot_loss=1.854 (perp=8.853, rec=0.081, cos=0.002), tot_loss_proj:2.222 [t=0.31s]
prediction: ['[CLS] a sloppy scripts script s undone by [SEP]']
[ 200/2000] tot_loss=1.951 (perp=9.408, rec=0.068, cos=0.001), tot_loss_proj:2.303 [t=0.31s]
prediction: ["[CLS] a sloppy it'script s undone by [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=1.435 (perp=6.812, rec=0.071, cos=0.002), tot_loss_proj:1.643 [t=0.31s]
prediction: ["[CLS] a sloppy script it's undone by [SEP]"]
[ 300/2000] tot_loss=1.428 (perp=6.812, rec=0.064, cos=0.001), tot_loss_proj:1.640 [t=0.31s]
prediction: ["[CLS] a sloppy script it's undone by [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.189 (perp=5.631, rec=0.061, cos=0.001), tot_loss_proj:1.461 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[ 400/2000] tot_loss=1.196 (perp=5.631, rec=0.068, cos=0.001), tot_loss_proj:1.447 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[ 450/2000] tot_loss=1.191 (perp=5.631, rec=0.064, cos=0.001), tot_loss_proj:1.450 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.188 (perp=5.631, rec=0.061, cos=0.001), tot_loss_proj:1.458 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.188 (perp=5.631, rec=0.060, cos=0.001), tot_loss_proj:1.449 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[ 600/2000] tot_loss=1.195 (perp=5.631, rec=0.067, cos=0.001), tot_loss_proj:1.453 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.192 (perp=5.631, rec=0.065, cos=0.001), tot_loss_proj:1.455 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.191 (perp=5.631, rec=0.064, cos=0.001), tot_loss_proj:1.457 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[ 750/2000] tot_loss=1.192 (perp=5.631, rec=0.064, cos=0.001), tot_loss_proj:1.449 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.186 (perp=5.631, rec=0.059, cos=0.001), tot_loss_proj:1.449 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.180 (perp=5.631, rec=0.053, cos=0.001), tot_loss_proj:1.461 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[ 900/2000] tot_loss=1.186 (perp=5.631, rec=0.059, cos=0.001), tot_loss_proj:1.460 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.190 (perp=5.631, rec=0.062, cos=0.001), tot_loss_proj:1.458 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.192 (perp=5.631, rec=0.064, cos=0.001), tot_loss_proj:1.460 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1050/2000] tot_loss=1.188 (perp=5.631, rec=0.061, cos=0.001), tot_loss_proj:1.460 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.194 (perp=5.631, rec=0.067, cos=0.001), tot_loss_proj:1.454 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.196 (perp=5.631, rec=0.068, cos=0.001), tot_loss_proj:1.450 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1200/2000] tot_loss=1.196 (perp=5.631, rec=0.069, cos=0.001), tot_loss_proj:1.461 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.192 (perp=5.631, rec=0.064, cos=0.001), tot_loss_proj:1.464 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.199 (perp=5.631, rec=0.071, cos=0.001), tot_loss_proj:1.458 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1350/2000] tot_loss=1.193 (perp=5.631, rec=0.066, cos=0.001), tot_loss_proj:1.463 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.191 (perp=5.631, rec=0.063, cos=0.001), tot_loss_proj:1.464 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.190 (perp=5.631, rec=0.063, cos=0.001), tot_loss_proj:1.456 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1500/2000] tot_loss=1.191 (perp=5.631, rec=0.064, cos=0.001), tot_loss_proj:1.461 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.191 (perp=5.631, rec=0.064, cos=0.001), tot_loss_proj:1.464 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.193 (perp=5.631, rec=0.065, cos=0.001), tot_loss_proj:1.454 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1650/2000] tot_loss=1.196 (perp=5.631, rec=0.069, cos=0.001), tot_loss_proj:1.459 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.188 (perp=5.631, rec=0.061, cos=0.001), tot_loss_proj:1.456 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.189 (perp=5.631, rec=0.062, cos=0.001), tot_loss_proj:1.454 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1800/2000] tot_loss=1.198 (perp=5.631, rec=0.070, cos=0.001), tot_loss_proj:1.454 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.192 (perp=5.631, rec=0.064, cos=0.001), tot_loss_proj:1.465 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.190 (perp=5.631, rec=0.062, cos=0.001), tot_loss_proj:1.462 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1950/2000] tot_loss=1.189 (perp=5.631, rec=0.061, cos=0.001), tot_loss_proj:1.457 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.187 (perp=5.631, rec=0.059, cos=0.001), tot_loss_proj:1.465 [t=0.31s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it's a sloppy script undone by [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 162.500

[Aggregate metrics]:
rouge1     | fm: 93.467 | p: 93.020 | r: 93.993
rouge2     | fm: 61.020 | p: 60.854 | r: 61.178
rougeL     | fm: 81.011 | p: 80.638 | r: 81.439
rougeLsum  | fm: 80.924 | p: 80.525 | r: 81.337
r1fm+r2fm = 154.488

input #82 time: 0:12:17 | total time: 16:58:32


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9992427375699131
highest_index [0]
highest [0.9992427375699131]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.9588028788566589 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.9548825025558472 for ['[CLS] consisting hartley lives champions forgotten johnson account integeronal merge [SEP]']
[Init] best rec loss: 0.9454923272132874 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.8843316435813904 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 0.8709483742713928 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8665996193885803 for ['[CLS] original review giggled field floor arid read beckett cecil i [SEP]']
[Init] best rec loss: 0.860031247138977 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.8360787034034729 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best rec loss: 0.8150500059127808 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.8122584819793701 for ['[CLS] envelope residence neck stew vice nearly follows comprehensive pitch boys [SEP]']
[Init] best perm rec loss: 0.8107272982597351 for ['[CLS] residence pitch follows neck boys vice nearly comprehensive envelope stew [SEP]']
[Init] best perm rec loss: 0.8086960315704346 for ['[CLS] nearly follows stew vice comprehensive neck pitch residence envelope boys [SEP]']
[Init] best perm rec loss: 0.8033978343009949 for ['[CLS] pitch comprehensive nearly neck stew residence boys vice follows envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.481 (perp=10.466, rec=0.354, cos=0.034), tot_loss_proj:3.716 [t=0.31s]
prediction: ['[CLS] where belle when mercedes deeakes when from over josh [SEP]']
[ 100/2000] tot_loss=2.497 (perp=11.081, rec=0.267, cos=0.014), tot_loss_proj:3.851 [t=0.31s]
prediction: ['[CLS] whates when growing grew landed know is over citizenship [SEP]']
[ 150/2000] tot_loss=2.289 (perp=10.478, rec=0.187, cos=0.006), tot_loss_proj:3.632 [t=0.31s]
prediction: ['[CLS] whate when it grew landed know grows when latino [SEP]']
[ 200/2000] tot_loss=2.344 (perp=10.885, rec=0.162, cos=0.004), tot_loss_proj:3.350 [t=0.31s]
prediction: ['[CLS] whate when it grew months know grows grows wants [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.069 (perp=9.580, rec=0.148, cos=0.005), tot_loss_proj:3.048 [t=0.31s]
prediction: ['[CLS] what it when it be up know grew grows gets [SEP]']
[ 300/2000] tot_loss=2.033 (perp=9.572, rec=0.115, cos=0.004), tot_loss_proj:3.346 [t=0.31s]
prediction: ['[CLS] what to when it be up know grew grows gets [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.804 (perp=8.486, rec=0.103, cos=0.004), tot_loss_proj:3.002 [t=0.31s]
prediction: ['[CLS] what to when it be wants know grew grows up [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.566 (perp=7.250, rec=0.111, cos=0.004), tot_loss_proj:2.255 [t=0.31s]
prediction: ['[CLS] what is when it be to know grows grows up [SEP]']
[ 450/2000] tot_loss=1.671 (perp=7.786, rec=0.110, cos=0.003), tot_loss_proj:2.319 [t=0.31s]
prediction: ['[CLS] what wants when it be to know grows grows up [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.616 (perp=7.600, rec=0.093, cos=0.003), tot_loss_proj:2.397 [t=0.31s]
prediction: ['[CLS] what wants when it be to know wants grows up [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.467 (perp=6.869, rec=0.091, cos=0.002), tot_loss_proj:2.229 [t=0.31s]
prediction: ['[CLS] what wants when it be wants to know grows up [SEP]']
[ 600/2000] tot_loss=1.455 (perp=6.869, rec=0.079, cos=0.002), tot_loss_proj:2.240 [t=0.31s]
prediction: ['[CLS] what wants when it be wants to know grows up [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.340 (perp=6.295, rec=0.080, cos=0.002), tot_loss_proj:2.091 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.337 (perp=6.295, rec=0.076, cos=0.002), tot_loss_proj:2.092 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
[ 750/2000] tot_loss=1.331 (perp=6.295, rec=0.070, cos=0.002), tot_loss_proj:2.087 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.337 (perp=6.295, rec=0.076, cos=0.002), tot_loss_proj:2.087 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.326 (perp=6.295, rec=0.065, cos=0.002), tot_loss_proj:2.088 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
[ 900/2000] tot_loss=1.329 (perp=6.295, rec=0.068, cos=0.002), tot_loss_proj:2.093 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.336 (perp=6.295, rec=0.075, cos=0.002), tot_loss_proj:2.089 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.330 (perp=6.295, rec=0.069, cos=0.002), tot_loss_proj:2.085 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
[1050/2000] tot_loss=1.334 (perp=6.295, rec=0.073, cos=0.002), tot_loss_proj:2.091 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.335 (perp=6.295, rec=0.074, cos=0.002), tot_loss_proj:2.094 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.333 (perp=6.295, rec=0.072, cos=0.002), tot_loss_proj:2.087 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
[1200/2000] tot_loss=1.343 (perp=6.295, rec=0.082, cos=0.002), tot_loss_proj:2.090 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.332 (perp=6.295, rec=0.071, cos=0.002), tot_loss_proj:2.086 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.327 (perp=6.295, rec=0.066, cos=0.002), tot_loss_proj:2.089 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
[1350/2000] tot_loss=1.332 (perp=6.295, rec=0.072, cos=0.002), tot_loss_proj:2.092 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.328 (perp=6.295, rec=0.067, cos=0.002), tot_loss_proj:2.086 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.324 (perp=6.295, rec=0.063, cos=0.002), tot_loss_proj:2.093 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
[1500/2000] tot_loss=1.317 (perp=6.295, rec=0.056, cos=0.002), tot_loss_proj:2.093 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.331 (perp=6.295, rec=0.070, cos=0.002), tot_loss_proj:2.096 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.332 (perp=6.295, rec=0.071, cos=0.002), tot_loss_proj:2.097 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
[1650/2000] tot_loss=1.328 (perp=6.295, rec=0.067, cos=0.002), tot_loss_proj:2.097 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.327 (perp=6.295, rec=0.066, cos=0.002), tot_loss_proj:2.093 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.334 (perp=6.295, rec=0.073, cos=0.002), tot_loss_proj:2.091 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
[1800/2000] tot_loss=1.327 (perp=6.295, rec=0.067, cos=0.002), tot_loss_proj:2.098 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.325 (perp=6.295, rec=0.064, cos=0.002), tot_loss_proj:2.090 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.336 (perp=6.295, rec=0.075, cos=0.002), tot_loss_proj:2.098 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
[1950/2000] tot_loss=1.338 (perp=6.295, rec=0.077, cos=0.002), tot_loss_proj:2.086 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.325 (perp=6.295, rec=0.064, cos=0.002), tot_loss_proj:2.096 [t=0.31s]
prediction: ['[CLS] what wants when it wants to be know grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] what wants when it wants to be know grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 54.545 | p: 54.545 | r: 54.545
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 146.212

[Aggregate metrics]:
rouge1     | fm: 93.423 | p: 92.968 | r: 93.960
rouge2     | fm: 60.812 | p: 60.640 | r: 60.984
rougeL     | fm: 80.915 | p: 80.585 | r: 81.292
rougeLsum  | fm: 80.864 | p: 80.506 | r: 81.262
r1fm+r2fm = 154.235

input #83 time: 0:12:17 | total time: 17:10:49


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9991128825224753
highest_index [0]
highest [0.9991128825224753]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9254128336906433 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.9186837077140808 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 0.9039275050163269 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8928205966949463 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 0.8905149102210999 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.8862044811248779 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 0.8856446146965027 for ['[CLS]oglaise catholicur prototype issues cheered [SEP]']
[Init] best rec loss: 0.86374831199646 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 0.8626121878623962 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best perm rec loss: 0.8610222339630127 for ['[CLS] caused infinite ca each goingiter its [SEP]']
[Init] best perm rec loss: 0.8602083325386047 for ['[CLS] caiter each its going infinite caused [SEP]']
[Init] best perm rec loss: 0.8592216372489929 for ['[CLS] its caused caiter going infinite each [SEP]']
[Init] best perm rec loss: 0.8573439717292786 for ['[CLS] each goingiter ca caused infinite its [SEP]']
[Init] best perm rec loss: 0.8570138216018677 for ['[CLS] caused going infinite each ca itsiter [SEP]']
[Init] best perm rec loss: 0.8555995225906372 for ['[CLS] eachiter going caused ca its infinite [SEP]']
[Init] best perm rec loss: 0.8548822402954102 for ['[CLS]iter ca each its caused infinite going [SEP]']
[Init] best perm rec loss: 0.8534655570983887 for ['[CLS] infinite caused ca its goingiter each [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.345 (perp=10.005, rec=0.319, cos=0.025), tot_loss_proj:2.777 [t=0.31s]
prediction: ['[CLS] lost might advanced lost people lost ability [SEP]']
[ 100/2000] tot_loss=2.396 (perp=11.045, rec=0.180, cos=0.007), tot_loss_proj:3.147 [t=0.31s]
prediction: ['[CLS] lost could people lost think have ability [SEP]']
[ 150/2000] tot_loss=1.990 (perp=9.461, rec=0.094, cos=0.004), tot_loss_proj:2.537 [t=0.31s]
prediction: ['[CLS] lost to people lose think have ability [SEP]']
[ 200/2000] tot_loss=1.800 (perp=8.592, rec=0.079, cos=0.002), tot_loss_proj:2.713 [t=0.31s]
prediction: ['[CLS] lost to people the think have ability [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.668 (perp=7.912, rec=0.083, cos=0.003), tot_loss_proj:2.639 [t=0.31s]
prediction: ['[CLS] lost to people think have these ability [SEP]']
[ 300/2000] tot_loss=1.667 (perp=7.912, rec=0.083, cos=0.002), tot_loss_proj:2.640 [t=0.31s]
prediction: ['[CLS] lost to people think have these ability [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.582 (perp=7.508, rec=0.078, cos=0.002), tot_loss_proj:2.472 [t=0.31s]
prediction: ['[CLS] to people think have lost these ability [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.394 (perp=6.502, rec=0.090, cos=0.003), tot_loss_proj:2.092 [t=0.31s]
prediction: ['[CLS] people think to have lost these ability [SEP]']
[ 450/2000] tot_loss=1.378 (perp=6.502, rec=0.076, cos=0.002), tot_loss_proj:2.096 [t=0.31s]
prediction: ['[CLS] people think to have lost these ability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.364 (perp=6.502, rec=0.061, cos=0.002), tot_loss_proj:2.095 [t=0.31s]
prediction: ['[CLS] people think to have lost these ability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.373 (perp=6.502, rec=0.071, cos=0.002), tot_loss_proj:2.093 [t=0.31s]
prediction: ['[CLS] people think to have lost these ability [SEP]']
[ 600/2000] tot_loss=1.389 (perp=6.502, rec=0.086, cos=0.002), tot_loss_proj:2.098 [t=0.31s]
prediction: ['[CLS] people think to have lost these ability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.300 (perp=6.129, rec=0.072, cos=0.002), tot_loss_proj:1.953 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.310 (perp=6.129, rec=0.082, cos=0.002), tot_loss_proj:1.945 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
[ 750/2000] tot_loss=1.307 (perp=6.129, rec=0.080, cos=0.002), tot_loss_proj:1.942 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.303 (perp=6.129, rec=0.075, cos=0.002), tot_loss_proj:1.945 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.311 (perp=6.129, rec=0.083, cos=0.002), tot_loss_proj:1.947 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
[ 900/2000] tot_loss=1.301 (perp=6.129, rec=0.073, cos=0.002), tot_loss_proj:1.944 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.309 (perp=6.129, rec=0.081, cos=0.002), tot_loss_proj:1.947 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.306 (perp=6.129, rec=0.078, cos=0.002), tot_loss_proj:1.948 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
[1050/2000] tot_loss=1.303 (perp=6.129, rec=0.075, cos=0.002), tot_loss_proj:1.946 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.297 (perp=6.129, rec=0.069, cos=0.002), tot_loss_proj:1.945 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.302 (perp=6.129, rec=0.074, cos=0.002), tot_loss_proj:1.949 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
[1200/2000] tot_loss=1.298 (perp=6.129, rec=0.070, cos=0.002), tot_loss_proj:1.944 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.310 (perp=6.129, rec=0.083, cos=0.002), tot_loss_proj:1.951 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.297 (perp=6.129, rec=0.069, cos=0.002), tot_loss_proj:1.952 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
[1350/2000] tot_loss=1.311 (perp=6.129, rec=0.083, cos=0.002), tot_loss_proj:1.945 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.293 (perp=6.129, rec=0.065, cos=0.002), tot_loss_proj:1.953 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.302 (perp=6.129, rec=0.075, cos=0.002), tot_loss_proj:1.947 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
[1500/2000] tot_loss=1.312 (perp=6.129, rec=0.085, cos=0.002), tot_loss_proj:1.950 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.297 (perp=6.129, rec=0.069, cos=0.002), tot_loss_proj:1.949 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.305 (perp=6.129, rec=0.077, cos=0.002), tot_loss_proj:1.954 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
[1650/2000] tot_loss=1.311 (perp=6.129, rec=0.083, cos=0.002), tot_loss_proj:1.947 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.296 (perp=6.129, rec=0.068, cos=0.002), tot_loss_proj:1.948 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.297 (perp=6.129, rec=0.070, cos=0.002), tot_loss_proj:1.949 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
[1800/2000] tot_loss=1.294 (perp=6.129, rec=0.067, cos=0.002), tot_loss_proj:1.953 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.293 (perp=6.129, rec=0.066, cos=0.002), tot_loss_proj:1.947 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.300 (perp=6.129, rec=0.072, cos=0.002), tot_loss_proj:1.956 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
[1950/2000] tot_loss=1.301 (perp=6.129, rec=0.073, cos=0.002), tot_loss_proj:1.944 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.297 (perp=6.129, rec=0.069, cos=0.002), tot_loss_proj:1.953 [t=0.31s]
prediction: ['[CLS] people think to have lost the ability [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people think to have lost the ability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 93.559 | p: 93.103 | r: 94.051
rouge2     | fm: 60.840 | p: 60.690 | r: 61.005
rougeL     | fm: 80.894 | p: 80.553 | r: 81.295
rougeLsum  | fm: 80.829 | p: 80.443 | r: 81.240
r1fm+r2fm = 154.399

input #84 time: 0:12:18 | total time: 17:23:07


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.999235227663392
highest_index [0]
highest [0.999235227663392]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9700234532356262 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.9549484252929688 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.9273467659950256 for ['[CLS] creek i instrumental bottomifnotes kensington military kowalski smoky [SEP]']
[Init] best rec loss: 0.8881958723068237 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8701308369636536 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best perm rec loss: 0.8689456582069397 for ['[CLS] indies backgroundleinthing road laps indianrman fallen defender [SEP]']
[Init] best perm rec loss: 0.8670895099639893 for ['[CLS]lein laps roadrman indian background indiesthing defender fallen [SEP]']
[Init] best perm rec loss: 0.8650530576705933 for ['[CLS] fallen indianlein indiesrman road background defenderthing laps [SEP]']
[Init] best perm rec loss: 0.8649742007255554 for ['[CLS] roadlein laps fallenrman indies indianthing background defender [SEP]']
[Init] best perm rec loss: 0.8649489283561707 for ['[CLS] indian laps road fallen defenderthinglein indies backgroundrman [SEP]']
[Init] best perm rec loss: 0.8630470633506775 for ['[CLS]lein road indies fallenthing indianrman defender background laps [SEP]']
[Init] best perm rec loss: 0.8617952466011047 for ['[CLS]thinglein indies indian road background defender fallen lapsrman [SEP]']
[Init] best perm rec loss: 0.8616505861282349 for ['[CLS] roadleinthing indies indian fallen laps backgroundrman defender [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.156 (perp=9.407, rec=0.261, cos=0.013), tot_loss_proj:2.508 [t=0.31s]
prediction: ['[CLS] poor points.... unfortunately unfortunately also not good unfortunately [SEP]']
[ 100/2000] tot_loss=1.785 (perp=8.175, rec=0.143, cos=0.007), tot_loss_proj:2.203 [t=0.31s]
prediction: ['[CLS] not picked. unfortunately unfortunately unfortunately also not good very [SEP]']
[ 150/2000] tot_loss=1.704 (perp=7.954, rec=0.108, cos=0.005), tot_loss_proj:2.400 [t=0.31s]
prediction: ['[CLS] not bug.. it unfortunately also not good very [SEP]']
[ 200/2000] tot_loss=1.690 (perp=7.954, rec=0.095, cos=0.004), tot_loss_proj:2.392 [t=0.31s]
prediction: ['[CLS] not bug.. it unfortunately also not good very [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.714 (perp=8.097, rec=0.091, cos=0.003), tot_loss_proj:2.026 [t=0.31s]
prediction: ['[CLS] not kn,. it unfortunately also not very good [SEP]']
[ 300/2000] tot_loss=1.569 (perp=7.348, rec=0.097, cos=0.003), tot_loss_proj:1.935 [t=0.31s]
prediction: ['[CLS] not blame,, it unfortunately also not very good [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.182 (perp=5.437, rec=0.091, cos=0.003), tot_loss_proj:1.598 [t=0.31s]
prediction: ['[CLS] not old. unfortunately, it also not very good [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.320 (perp=6.103, rec=0.096, cos=0.003), tot_loss_proj:1.808 [t=0.31s]
prediction: ['[CLS] not old. unfortunately, s also not very good [SEP]']
[ 450/2000] tot_loss=1.309 (perp=6.103, rec=0.085, cos=0.003), tot_loss_proj:1.804 [t=0.31s]
prediction: ['[CLS] not old. unfortunately, s also not very good [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.308 (perp=6.103, rec=0.084, cos=0.003), tot_loss_proj:1.797 [t=0.31s]
prediction: ['[CLS] not old. unfortunately, s also not very good [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.443 (perp=6.802, rec=0.080, cos=0.003), tot_loss_proj:1.875 [t=0.31s]
prediction: ['[CLS] non old. unfortunately, s also not very good [SEP]']
[ 600/2000] tot_loss=1.479 (perp=6.946, rec=0.086, cos=0.003), tot_loss_proj:1.997 [t=0.31s]
prediction: ['[CLS] possibly big. unfortunately, s also not very good [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.769 (perp=7.765, rec=0.203, cos=0.013), tot_loss_proj:2.226 [t=0.31s]
prediction: ['[CLS] probably. unfortunately, sp it also not very good [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.741 (perp=7.914, rec=0.150, cos=0.008), tot_loss_proj:2.764 [t=0.31s]
prediction: ['[CLS] pick. unfortunately,de it also not very good [SEP]']
[ 750/2000] tot_loss=1.424 (perp=6.411, rec=0.137, cos=0.005), tot_loss_proj:2.563 [t=0.31s]
prediction: ['[CLS] pick. unfortunately, not it also not very good [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.323 (perp=6.030, rec=0.112, cos=0.004), tot_loss_proj:2.586 [t=0.31s]
prediction: ['[CLS] pick. unfortunately, not also it not very good [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.377 (perp=6.333, rec=0.107, cos=0.004), tot_loss_proj:1.962 [t=0.31s]
prediction: ['[CLS] at. unfortunately, not also it not very good [SEP]']
[ 900/2000] tot_loss=1.373 (perp=6.333, rec=0.102, cos=0.004), tot_loss_proj:1.960 [t=0.31s]
prediction: ['[CLS] at. unfortunately, not also it not very good [SEP]']
Attempt swap
Put prefix at the end
[ 950/2000] tot_loss=1.177 (perp=5.380, rec=0.097, cos=0.004), tot_loss_proj:1.641 [t=0.31s]
prediction: ['[CLS] unfortunately, not also it not very good -. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.104 (perp=5.024, rec=0.096, cos=0.004), tot_loss_proj:1.476 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
[1050/2000] tot_loss=1.102 (perp=5.024, rec=0.094, cos=0.003), tot_loss_proj:1.469 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.095 (perp=5.024, rec=0.086, cos=0.003), tot_loss_proj:1.478 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.102 (perp=5.024, rec=0.094, cos=0.003), tot_loss_proj:1.477 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
[1200/2000] tot_loss=1.095 (perp=5.024, rec=0.087, cos=0.003), tot_loss_proj:1.468 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.100 (perp=5.024, rec=0.092, cos=0.003), tot_loss_proj:1.477 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.094 (perp=5.024, rec=0.086, cos=0.003), tot_loss_proj:1.470 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
[1350/2000] tot_loss=1.087 (perp=5.024, rec=0.079, cos=0.003), tot_loss_proj:1.475 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.097 (perp=5.024, rec=0.089, cos=0.003), tot_loss_proj:1.473 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.093 (perp=5.024, rec=0.085, cos=0.003), tot_loss_proj:1.475 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
[1500/2000] tot_loss=1.087 (perp=5.024, rec=0.079, cos=0.003), tot_loss_proj:1.466 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.095 (perp=5.024, rec=0.087, cos=0.003), tot_loss_proj:1.467 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.084 (perp=5.024, rec=0.076, cos=0.003), tot_loss_proj:1.477 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
[1650/2000] tot_loss=1.090 (perp=5.024, rec=0.082, cos=0.003), tot_loss_proj:1.468 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.098 (perp=5.024, rec=0.090, cos=0.003), tot_loss_proj:1.475 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.088 (perp=5.024, rec=0.080, cos=0.003), tot_loss_proj:1.475 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
[1800/2000] tot_loss=1.086 (perp=5.024, rec=0.079, cos=0.003), tot_loss_proj:1.469 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.090 (perp=5.024, rec=0.082, cos=0.003), tot_loss_proj:1.471 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.097 (perp=5.024, rec=0.089, cos=0.003), tot_loss_proj:1.467 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
[1950/2000] tot_loss=1.086 (perp=5.024, rec=0.078, cos=0.003), tot_loss_proj:1.471 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.096 (perp=5.024, rec=0.088, cos=0.003), tot_loss_proj:1.472 [t=0.31s]
prediction: ['[CLS] unfortunately, not also - it not very good. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, not also - it not very good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 138.889

[Aggregate metrics]:
rouge1     | fm: 93.468 | p: 93.024 | r: 93.966
rouge2     | fm: 60.428 | p: 60.280 | r: 60.591
rougeL     | fm: 80.900 | p: 80.543 | r: 81.321
rougeLsum  | fm: 80.819 | p: 80.503 | r: 81.227
r1fm+r2fm = 153.896

input #85 time: 0:12:17 | total time: 17:35:24


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9993320344575478
highest_index [0]
highest [0.9993320344575478]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9243597984313965 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9180442690849304 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 0.8544282913208008 for ['[CLS] len tin signals [SEP]']
[Init] best rec loss: 0.7916388511657715 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.7676078677177429 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.7578014731407166 for ['[CLS] liberated round alright [SEP]']
[Init] best perm rec loss: 0.7564014792442322 for ['[CLS] round liberated alright [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.800 (perp=12.218, rec=0.348, cos=0.009), tot_loss_proj:3.472 [t=0.31s]
prediction: ['[CLS] destiny emotional clarity [SEP]']
[ 100/2000] tot_loss=2.325 (perp=10.833, rec=0.154, cos=0.004), tot_loss_proj:2.412 [t=0.31s]
prediction: ['[CLS] emotional clarity clarity [SEP]']
[ 150/2000] tot_loss=1.913 (perp=9.109, rec=0.090, cos=0.002), tot_loss_proj:2.372 [t=0.31s]
prediction: ['[CLS] emotional clarity and [SEP]']
[ 200/2000] tot_loss=1.897 (perp=9.109, rec=0.074, cos=0.001), tot_loss_proj:2.351 [t=0.31s]
prediction: ['[CLS] emotional clarity and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.720 (perp=8.211, rec=0.076, cos=0.002), tot_loss_proj:1.884 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 300/2000] tot_loss=1.713 (perp=8.211, rec=0.069, cos=0.001), tot_loss_proj:1.877 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.704 (perp=8.211, rec=0.060, cos=0.001), tot_loss_proj:1.874 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.709 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.866 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 450/2000] tot_loss=1.708 (perp=8.211, rec=0.064, cos=0.001), tot_loss_proj:1.877 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.694 (perp=8.211, rec=0.051, cos=0.001), tot_loss_proj:1.881 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.702 (perp=8.211, rec=0.058, cos=0.001), tot_loss_proj:1.868 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 600/2000] tot_loss=1.704 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.880 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.708 (perp=8.211, rec=0.065, cos=0.001), tot_loss_proj:1.874 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.709 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.880 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 750/2000] tot_loss=1.707 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.872 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.708 (perp=8.211, rec=0.064, cos=0.001), tot_loss_proj:1.873 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.709 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.874 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 900/2000] tot_loss=1.703 (perp=8.211, rec=0.059, cos=0.001), tot_loss_proj:1.880 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.711 (perp=8.211, rec=0.068, cos=0.001), tot_loss_proj:1.874 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.699 (perp=8.211, rec=0.055, cos=0.001), tot_loss_proj:1.876 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1050/2000] tot_loss=1.703 (perp=8.211, rec=0.059, cos=0.001), tot_loss_proj:1.880 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.714 (perp=8.211, rec=0.071, cos=0.001), tot_loss_proj:1.874 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.716 (perp=8.211, rec=0.072, cos=0.001), tot_loss_proj:1.872 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1200/2000] tot_loss=1.697 (perp=8.211, rec=0.053, cos=0.001), tot_loss_proj:1.877 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.698 (perp=8.211, rec=0.055, cos=0.001), tot_loss_proj:1.878 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.721 (perp=8.211, rec=0.078, cos=0.001), tot_loss_proj:1.874 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1350/2000] tot_loss=1.710 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.876 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.707 (perp=8.211, rec=0.064, cos=0.001), tot_loss_proj:1.870 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.701 (perp=8.211, rec=0.058, cos=0.001), tot_loss_proj:1.875 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1500/2000] tot_loss=1.706 (perp=8.211, rec=0.062, cos=0.001), tot_loss_proj:1.878 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.710 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.865 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.708 (perp=8.211, rec=0.064, cos=0.001), tot_loss_proj:1.879 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1650/2000] tot_loss=1.702 (perp=8.211, rec=0.058, cos=0.001), tot_loss_proj:1.872 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.698 (perp=8.211, rec=0.055, cos=0.001), tot_loss_proj:1.878 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.707 (perp=8.211, rec=0.064, cos=0.001), tot_loss_proj:1.881 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1800/2000] tot_loss=1.709 (perp=8.211, rec=0.065, cos=0.001), tot_loss_proj:1.877 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.706 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.878 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.714 (perp=8.211, rec=0.070, cos=0.001), tot_loss_proj:1.872 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1950/2000] tot_loss=1.710 (perp=8.211, rec=0.067, cos=0.001), tot_loss_proj:1.875 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.710 (perp=8.211, rec=0.067, cos=0.001), tot_loss_proj:1.878 [t=0.31s]
prediction: ['[CLS] and emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] and emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 93.485 | p: 93.050 | r: 94.024
rouge2     | fm: 60.162 | p: 60.025 | r: 60.315
rougeL     | fm: 80.858 | p: 80.511 | r: 81.257
rougeLsum  | fm: 80.853 | p: 80.536 | r: 81.240
r1fm+r2fm = 153.647

input #86 time: 0:12:13 | total time: 17:47:38


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.9992558340477615
highest_index [0]
highest [0.9992558340477615]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.882197380065918 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7530746459960938 for ['[CLS]minate force [SEP]']
[Init] best rec loss: 0.7107471823692322 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.7019302248954773 for ['[CLS] officer yorker [SEP]']
[Init] best rec loss: 0.6962634325027466 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6834703087806702 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6805302500724792 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.778 (perp=7.258, rec=0.288, cos=0.039), tot_loss_proj:1.512 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 100/2000] tot_loss=1.835 (perp=7.258, rec=0.326, cos=0.057), tot_loss_proj:1.521 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.579 (perp=7.258, rec=0.123, cos=0.004), tot_loss_proj:1.534 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.531 (perp=7.258, rec=0.077, cos=0.002), tot_loss_proj:1.522 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.538 (perp=7.258, rec=0.084, cos=0.002), tot_loss_proj:1.538 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.870 (perp=7.258, rec=0.340, cos=0.078), tot_loss_proj:1.515 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.636 (perp=7.258, rec=0.176, cos=0.009), tot_loss_proj:1.531 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.566 (perp=7.258, rec=0.111, cos=0.004), tot_loss_proj:1.523 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.531 (perp=7.258, rec=0.077, cos=0.002), tot_loss_proj:1.525 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.521 (perp=7.258, rec=0.068, cos=0.002), tot_loss_proj:1.513 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.511 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.515 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.517 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.505 (perp=7.258, rec=0.052, cos=0.001), tot_loss_proj:1.537 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.523 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.497 (perp=7.258, rec=0.044, cos=0.001), tot_loss_proj:1.527 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.513 (perp=7.258, rec=0.060, cos=0.001), tot_loss_proj:1.549 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.512 (perp=7.258, rec=0.059, cos=0.001), tot_loss_proj:1.532 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.511 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.528 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.514 (perp=7.258, rec=0.061, cos=0.001), tot_loss_proj:1.534 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.502 (perp=7.258, rec=0.049, cos=0.001), tot_loss_proj:1.530 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.512 (perp=7.258, rec=0.059, cos=0.001), tot_loss_proj:1.530 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.511 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.527 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.520 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.509 (perp=7.258, rec=0.056, cos=0.001), tot_loss_proj:1.528 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.519 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.537 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.548 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.524 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.531 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.501 (perp=7.258, rec=0.048, cos=0.001), tot_loss_proj:1.517 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.514 (perp=7.258, rec=0.061, cos=0.001), tot_loss_proj:1.538 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.525 (perp=7.258, rec=0.072, cos=0.001), tot_loss_proj:1.525 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.504 (perp=7.258, rec=0.051, cos=0.001), tot_loss_proj:1.528 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.516 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.520 (perp=7.258, rec=0.067, cos=0.001), tot_loss_proj:1.534 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.534 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.512 (perp=7.258, rec=0.059, cos=0.001), tot_loss_proj:1.530 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.512 (perp=7.258, rec=0.059, cos=0.001), tot_loss_proj:1.541 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.526 (perp=7.258, rec=0.073, cos=0.001), tot_loss_proj:1.532 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.506 (perp=7.258, rec=0.053, cos=0.001), tot_loss_proj:1.530 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.520 (perp=7.258, rec=0.067, cos=0.001), tot_loss_proj:1.542 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.621 | p: 93.174 | r: 94.130
rouge2     | fm: 60.585 | p: 60.445 | r: 60.712
rougeL     | fm: 81.079 | p: 80.752 | r: 81.484
rougeLsum  | fm: 81.048 | p: 80.722 | r: 81.434
r1fm+r2fm = 154.206

input #87 time: 0:12:14 | total time: 17:59:52


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.9992352540906893
highest_index [0]
highest [0.9992352540906893]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9801686406135559 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9457874894142151 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.9178983569145203 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.9163371920585632 for ['[CLS] signing architectural miss of? tension popbreaker covered versus planning bean single field advanced a lipstickingdon tab shorter dos down luther ki t directors wounded drink people ps animals administrativeari tone geologic international above 18 free dam way software clay [SEP]']
[Init] best rec loss: 0.9154862761497498 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.9045359492301941 for ['[CLS] assistants isbag mighty ll shortagekou subject central printian contract separated eight tick twenties ball how orange victor help fund council key morris lace weight vacancy hungick equipment her goran dvd business gould sidou rector us g moment freud [SEP]']
[Init] best rec loss: 0.903478741645813 for ["[CLS]⁺'ship socialist knightlines trapped golden vital rail soil or accepted seasonal behind mall tickets american fallon https word appearedminated break people familiar bornllie serious once wealth are ll protector caterizedest trade masspina berlin flavortine [SEP]"]
[Init] best rec loss: 0.9033877849578857 for ['[CLS]used worldwide rae ag radio onto cluster rent aggregate sex wiped friendship faso golf manner clary inspiring pleasure solvent war groups county mistress art s auto deaf admitted rum shore dorian followed angus nightmare defended salt concentrated leave punch jamesbre music bra [SEP]']
[Init] best rec loss: 0.8976743817329407 for ['[CLS] designated engine never pondered harmon programs? mandarin according employees legitimate exchanged as elevated piston exodus won machine aunt hadnbbed insanity allowed home landing [UNK] starting ki! signed close today force immortality nets where reform baronet ) network demi observation spanning [SEP]']
[Init] best perm rec loss: 0.8968567252159119 for ['[CLS] pondered allowed where! aunt never designated starting demi as programs home hadn piston spanning legitimate engine exodusbbed? insanity machine immortality [UNK] reform harmon network elevated nets today according baronet ki exchanged ) signed employees mandarin force close won landing observation [SEP]']
[Init] best perm rec loss: 0.8939005136489868 for ['[CLS] programs exchanged engine where aunt insanity designated network! elevated observation? spanning legitimate piston employees starting as close hadn allowed according never ) today won kibbed landing force demi reform immortality [UNK] home machine exodus signed pondered mandarin baronet harmon nets [SEP]']
[Init] best perm rec loss: 0.8938130736351013 for ['[CLS] mandarin won close baronet employees exodus engine as exchanged legitimate harmon network demi insanity [UNK] allowed aunt immortalitybbed home elevated spanning force where starting designated pondered ) machine? today ki according observation reform nets landing signed programs! never hadn piston [SEP]']
[Init] best perm rec loss: 0.8933629989624023 for ['[CLS] [UNK] exchanged starting spanning hadn today engine ) employees pondered demi reform ki force as legitimate mandarin network where observation harmon landing never! machinebbed signed according exodus home baronet nets insanity immortality close? elevated piston designated programs won aunt allowed [SEP]']
[Init] best perm rec loss: 0.8931682109832764 for ['[CLS] demi landing ) nets elevated network spanning hadn home reform close insanity! according where legitimate programs aunt exchanged immortality force [UNK] mandarin baronet employees? designated won allowed harmonbbed piston pondered machine today engine signed as ki starting observation never exodus [SEP]']
[Init] best perm rec loss: 0.8929937481880188 for ['[CLS] spanning aunt exodus immortality startingbbed machine! baronet nets elevated [UNK] programs engine ) today ki reform designated harmon won pondered landing observation hadn home exchanged according network employees mandarin? close insanity never where allowed demi signed force as piston legitimate [SEP]']
[Init] best perm rec loss: 0.892136812210083 for ['[CLS] piston home ki close exchanged harmon signed aunt employees baronet allowed immortality programs [UNK] hadn designated mandarin landing elevated nets today according pondered where! exodus observation? force reform machine demi as never network ) spanning wonbbed insanity engine starting legitimate [SEP]']
[Init] best perm rec loss: 0.8915683627128601 for ['[CLS]? starting close legitimate employees! hadn baronet observation won allowed piston nets ) [UNK] aunt reform elevated spanningbbed exchanged harmon demi pondered mandarin never landing force programs exodus immortality signed according as network home ki today insanity machine where engine designated [SEP]']
[Init] best perm rec loss: 0.8915374279022217 for ['[CLS] exchanged aunt legitimate! allowed exodus baronet observation harmon mandarin close starting landing programs signed engine demi reform spanning elevated home where hadn network nets employees machine insanity ) pondered won immortality as force never ki today pistonbbed according [UNK]? designated [SEP]']
[Init] best perm rec loss: 0.8908386826515198 for ['[CLS] landing exchanged network piston won? spanning! ) as legitimate insanity engine ki immortality signed exodus starting according mandarin allowed machine pondered nets elevated employees observation aunt baronet harmon [UNK] hadn home designated where never programs forcebbed reform today close demi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.614 (perp=11.673, rec=0.274, cos=0.005), tot_loss_proj:3.960 [t=0.31s]
prediction: ['[CLS] learned. landscape alloys environmentalª david god anti and understands constructions of love the silver romanticusly patients. abortion. owen forms understands women saint thai. especially horsepower michael in tradition avoid along beauty ever understand brand apparently grand energy [SEP]']
[ 100/2000] tot_loss=2.288 (perp=10.243, rec=0.237, cos=0.003), tot_loss_proj:3.216 [t=0.31s]
prediction: ['[CLS] quick. wilderness handed environmental love abraham god no and romance anderson the love the anderson business existence calm my abortion,. made understands our day minds the the horsepower t thatic herdstone love quite 1930s many tonight grand. [SEP]']
[ 150/2000] tot_loss=2.797 (perp=11.844, rec=0.413, cos=0.015), tot_loss_proj:3.224 [t=0.31s]
prediction: ['[CLS] strong " cultural city codex metre generation. (. adventure [SEP] [SEP] inter [SEP] alaska business wanderers calm us lives to. decision understands ourtwined. encourage more adventure thejack ways the descriptions loveberg common eli amount grand at [SEP]']
[ 200/2000] tot_loss=2.626 (perp=11.304, rec=0.353, cos=0.012), tot_loss_proj:3.629 [t=0.31s]
prediction: ['[CLS] luck charles pageant a daily society %.point the erebidae [SEP] [SEP] at [SEP] preserved business families conversation us defeat to. talent understands our estimate. encourage great adventure the technologies ways a descriptions loveborn common qaeda amount grandddin [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.665 (perp=11.223, rec=0.407, cos=0.014), tot_loss_proj:3.700 [t=0.31s]
prediction: ['[CLS] sam tell systems [SEP] how [SEP] ideal war nations understand us lives to., understands the inter surface society generations of. the erebidae [SEP] estimate parents the soo magic environment established things laylus magic witch traditional ki amount private montreal [SEP]']
[ 300/2000] tot_loss=2.576 (perp=11.211, rec=0.327, cos=0.006), tot_loss_proj:3.752 [t=0.31s]
prediction: ['[CLS] sam tell systems economy how [SEP] ideal war places understand usability to., understands the inter daily government understanding of. the erebidae [SEP] estimate parents the pu magic environment established things 1 rabbi love witch traditional jewish contributions private montreal [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.500 (perp=11.039, rec=0.288, cos=0.005), tot_loss_proj:3.600 [t=0.31s]
prediction: ['[CLS] sam state terms [SEP] how [SEP] novels war ahead control us relationships to., understands the inter dry pride understanding of. the erebidae [SEP] estimate guys the things magic environment established soo 15 the love riley traditional jewish they grand montreal [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.285 (perp=10.063, rec=0.268, cos=0.004), tot_loss_proj:3.144 [t=0.31s]
prediction: ['[CLS] how state how [SEP] how [SEP] mandal war kaladin control us relationships to communion, understand the inter calm pride dynamics of. the erebidae [SEP] reports guys the things magic environment established soo 15 the love riley traditional und how grand. [SEP]']
[ 450/2000] tot_loss=2.331 (perp=10.365, rec=0.254, cos=0.004), tot_loss_proj:3.183 [t=0.31s]
prediction: ['[CLS] how todd that [SEP] how [SEP] daily war kaladin control us relationships of communion, understand the inter calm romance dynamics of. the erebidae [SEP] reports guys the things magic environment established soo 15 the love riley traditional und how grand. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.390 (perp=10.743, rec=0.238, cos=0.003), tot_loss_proj:3.102 [t=0.31s]
prediction: ['[CLS] how todd, [SEP] which [SEP] daily war beside control usability of communion that understand the inter calm romance dynamics of. the mastered [SEP] reports [ the things magic environment established possessed 15 the love riley traditionaltative how grand. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.319 (perp=10.364, rec=0.243, cos=0.003), tot_loss_proj:3.081 [t=0.31s]
prediction: ['[CLS] how brien, [SEP] con traditional daily war beside control usability to the that understand the inter calm romance dynamics of. the mastered [SEP] reports [ the things magic environment established have 15 the love brady [SEP]tative how grand. [SEP]']
[ 600/2000] tot_loss=2.320 (perp=10.397, rec=0.237, cos=0.003), tot_loss_proj:2.844 [t=0.31s]
prediction: ['[CLS] how brien, [SEP] con traditional daily war beside control usability of the that understand the inter calm romance dynamics of. the mastered [SEP] reports [ the things magic environment established have 15 the love brady [SEP] positive how grand. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.234 (perp=10.025, rec=0.226, cos=0.003), tot_loss_proj:2.776 [t=0.31s]
prediction: ['[CLS] brien how, manifold con traditional daily war beside control usability of her that understand the inter calm romance dynamics of. the everyday [SEP] reports we the things magic environment established have 15 the love brady [SEP] positive how grand. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.282 (perp=10.240, rec=0.231, cos=0.003), tot_loss_proj:2.658 [t=0.31s]
prediction: ['[CLS] brien how, manifold experience traditional great warfold control livesability of 15 that understand the inter calm romance dynamics of. the everyday [SEP] our we the things magic environment established have drives the love brady [SEP] positive how grand. [SEP]']
[ 750/2000] tot_loss=2.278 (perp=10.258, rec=0.223, cos=0.003), tot_loss_proj:2.664 [t=0.31s]
prediction: ['[CLS] brien how, manifold experience traditional great warfold control livesability of 15 that understand the inter calm romance understanding of. the everyday [SEP] our we the things magic environment established have drives the love brady [SEP] positive how grand. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.247 (perp=10.131, rec=0.218, cos=0.003), tot_loss_proj:2.632 [t=0.31s]
prediction: ['[CLS] p how, manifold experience traditional daily microfold control livesability of 15 that understands the inter calm romance our understanding of. the everyday [SEP] we the things magic environment established have the the love brady [SEP] positive how grand. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.215 (perp=9.987, rec=0.215, cos=0.003), tot_loss_proj:2.586 [t=0.31s]
prediction: ['[CLS] of how, manifold experience traditional daily microfold control livesability of 15 that understands the inter calm romance our understanding p. the everyday [SEP] our the things magic environment established has the the love brady [SEP] positive how grand. [SEP]']
[ 900/2000] tot_loss=2.255 (perp=10.207, rec=0.211, cos=0.003), tot_loss_proj:2.671 [t=0.31s]
prediction: ['[CLS] of how, manifold experience traditional great microfold control livesability of 15 that understands the inter calm romance our understanding p. the horse [SEP] our the things magic todd established has the the love brady [SEP] positive how grand. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.218 (perp=9.997, rec=0.216, cos=0.003), tot_loss_proj:2.614 [t=0.31s]
prediction: ['[CLS] of how, manifold experience traditional great microfold our livesability of 15 that understands the inter calm romance our understanding p. and everyday [SEP] control the things magic todd established has the the love brady [SEP] positive how grand. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.178 (perp=9.809, rec=0.214, cos=0.003), tot_loss_proj:2.559 [t=0.31s]
prediction: ['[CLS] of how, manifold experience traditional great microfold our livesability of 15 how understands the inter calm romance our understanding p. and everyday [SEP] control the things magic todd has established makes the love brady [SEP] positive how grand. [SEP]']
[1050/2000] tot_loss=2.138 (perp=9.647, rec=0.206, cos=0.003), tot_loss_proj:2.554 [t=0.31s]
prediction: ['[CLS] of how, [SEP] experience traditional great microfold our livesability of 15 how understands the of calm romance our understanding p. and everyday [SEP] control the things magic todd has established makes the love brady [SEP] positive how grand. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.108 (perp=9.516, rec=0.202, cos=0.003), tot_loss_proj:2.520 [t=0.31s]
prediction: ['[CLS] traditional how, [SEP] experience of great microfold our livesability of 15 how understands the of calm romance our understanding p. and everyday [SEP] control the things magic todd has established the the love brady [SEP] positive how grand. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.054 (perp=9.217, rec=0.208, cos=0.003), tot_loss_proj:2.408 [t=0.31s]
prediction: ['[CLS] traditional how, [SEP] experience of great microfold our lives of 15 that understands theability of calm romance our understanding p. and everyday [SEP] control the things magic environment has established makes the love brady [SEP] positive how grand. [SEP]']
[1200/2000] tot_loss=2.071 (perp=9.307, rec=0.207, cos=0.003), tot_loss_proj:2.438 [t=0.31s]
prediction: ['[CLS] traditional how and [SEP] experience of great microfold our lives of 15 that understands theability of calm romance our understanding p. and everyday [SEP] control the things magic environment has that makes the love brady [SEP] positive how grand. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.012 (perp=9.033, rec=0.203, cos=0.003), tot_loss_proj:2.421 [t=0.31s]
prediction: ['[CLS] traditional how 15 [SEP] experience of great microfold our lives of, that understands theability of calm romance our understanding p. and everyday [SEP] control the things magic environment has that makes the love brady [SEP] positive how grand. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.004 (perp=8.957, rec=0.210, cos=0.003), tot_loss_proj:2.550 [t=0.31s]
prediction: ['[CLS] traditional how 15 [SEP] experience of great microfold our lives of, that understands theability of calm romance our understanding p. positive everyday [SEP] control the things magic environment has that drinks the love brady [SEP] and how grand. [SEP]']
[1350/2000] tot_loss=1.998 (perp=8.962, rec=0.203, cos=0.003), tot_loss_proj:2.510 [t=0.31s]
prediction: ['[CLS] traditional how 15 [SEP] experience of great microfold our lives of and that understands theability of calm romance our understanding p. positive everyday [SEP] control the things magic environment has that drinks the love brady [SEP] and how grand. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.976 (perp=8.852, rec=0.203, cos=0.003), tot_loss_proj:2.588 [t=0.31s]
prediction: ['[CLS] magic how 15 [SEP] experience of great microfold our lives of and how understands theability of calm romance our understanding p. positive horse [SEP] control the things traditional todd has that drinks the love brady [SEP] and how grand. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.951 (perp=8.691, rec=0.210, cos=0.003), tot_loss_proj:2.542 [t=0.31s]
prediction: ['[CLS] magic how 15 [SEP] experience of great microfold our lives of and how understands theability of calm romance our lives p. positive [SEP] control the things traditional todd has that drinks the love brady [SEP] horse and how grand. [SEP]']
[1500/2000] tot_loss=1.899 (perp=8.494, rec=0.198, cos=0.003), tot_loss_proj:3.133 [t=0.31s]
prediction: ['[CLS] magic how 15 [SEP] experience of great microfold our lives of and how understands theability of calm romance our lives p. ill [SEP] control the things traditional environment has that drinks the love brady [SEP] horse and how grand. [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.900 (perp=8.487, rec=0.199, cos=0.003), tot_loss_proj:3.418 [t=0.31s]
prediction: ['[CLS] magic how 15 [SEP] experience of great microfold our lives of and how understands theability of calm romance our lives p. [SEP] ill control the things traditional environment has that drinks the love brady [SEP] horse and how grand. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.952 (perp=8.715, rec=0.207, cos=0.003), tot_loss_proj:3.381 [t=0.31s]
prediction: ['[CLS] magic how 15 [SEP] experience of great microfold our lives of, how understands theability of calm romance our lives p. [SEP] ill control the things traditional todd has that drinks the love brady [SEP] everyday and how grand. [SEP]']
[1650/2000] tot_loss=1.938 (perp=8.678, rec=0.200, cos=0.003), tot_loss_proj:3.482 [t=0.31s]
prediction: ['[CLS] magic how 15 [SEP] experience of great micro. our lives of, how understands theability of calm romance our lives p. [SEP] ill control the things traditional todd has that drinks the love brady [SEP] horse and how grand. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.933 (perp=8.639, rec=0.203, cos=0.002), tot_loss_proj:3.318 [t=0.31s]
prediction: ['[CLS] great how 15 [SEP] experience of magic micro. our lives of, how understands theability of calm romance our lives p. [SEP] ill limit the things traditional todd has that drinks the love brady [SEP] everyday and how grand. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.895 (perp=8.410, rec=0.210, cos=0.003), tot_loss_proj:3.310 [t=0.31s]
prediction: ['[CLS] great how 15 [SEP] experience of magic micro. our lives of, how understands theability of romance calm our lives p. [SEP] ill temper the things traditional todd has that drinks the love brady [SEP] everyday and how grand. [SEP]']
[1800/2000] tot_loss=1.888 (perp=8.410, rec=0.204, cos=0.003), tot_loss_proj:3.312 [t=0.31s]
prediction: ['[CLS] great how 15 [SEP] experience of magic micro. our lives of, how understands theability of romance calm our lives p. [SEP] ill temper the things traditional todd has that drinks the love brady [SEP] everyday and how grand. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.875 (perp=8.374, rec=0.197, cos=0.003), tot_loss_proj:3.304 [t=0.31s]
prediction: ['[CLS] great how 15 [SEP] experience of magic micro. our lives of, how understands theability of romance calm our lives p. [SEP] ill temper the traditional things todd has that drinks the love brady [SEP] everyday and how grand. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.862 (perp=8.277, rec=0.204, cos=0.002), tot_loss_proj:3.247 [t=0.31s]
prediction: ['[CLS] great how 15 [SEP] experience of magic micro. our lives of, how understands theability of romance calm our lives p. [SEP] temper ill the traditional things todd has that drinks the love brady [SEP] everyday and how grand. [SEP]']
[1950/2000] tot_loss=1.879 (perp=8.395, rec=0.197, cos=0.002), tot_loss_proj:3.245 [t=0.31s]
prediction: ['[CLS] great how 1 [SEP] experience of magic micro. our lives of, how understands theability of romance calm our lives p. [SEP] temper ill the traditional things todd has that drinks the love anderson [SEP] everyday and how grand. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.889 (perp=8.407, rec=0.205, cos=0.002), tot_loss_proj:3.278 [t=0.31s]
prediction: ['[CLS] great how 1 manifold experience of magic micro and our lives of, how understands theability of romance calm our lives p. [SEP] temper ill the traditional things todd has that drinks the love anderson [SEP] theater. how grand. [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] great how 1 [SEP] experience of magic micro. our lives of, how understands theability of romance calm our lives p. [SEP] temper ill the traditional things todd has that drinks the love anderson [SEP] everyday and how grand. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 48.718 | p: 47.500 | r: 50.000
rouge2     | fm: 7.895 | p: 7.692 | r: 8.108
rougeL     | fm: 23.077 | p: 22.500 | r: 23.684
rougeLsum  | fm: 23.077 | p: 22.500 | r: 23.684
r1fm+r2fm = 56.613

[Aggregate metrics]:
rouge1     | fm: 93.046 | p: 92.639 | r: 93.587
rouge2     | fm: 59.942 | p: 59.789 | r: 60.073
rougeL     | fm: 80.455 | p: 80.121 | r: 80.852
rougeLsum  | fm: 80.374 | p: 80.058 | r: 80.778
r1fm+r2fm = 152.989

input #88 time: 0:12:27 | total time: 18:12:20


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.9993421954906172
highest_index [0]
highest [0.9993421954906172]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9646307826042175 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9528583884239197 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.9446580410003662 for ['[CLS] lucraction ditch vin vehicle nights filing wholeierusion above myself capacity easter just bowlpath silver campaign urging draw huntersky operation himself plant bolt gin won ours only object [SEP]']
[Init] best rec loss: 0.9295535683631897 for ['[CLS] watt trustingats promisepate weight eight blood happened photograph deaths credited jp wish practicing boysfulfootuded donttemedia broken atomic muttereduating gps leon relatively atari document cutler [SEP]']
[Init] best perm rec loss: 0.928572952747345 for ['[CLS]pateuded promise broken leon creditedful wish document atomic trusting boysuating atari watttte happened jp eight don relativelyfoot cutler gps photographmedia mutteredats weight blood practicing deaths [SEP]']
[Init] best perm rec loss: 0.9270486235618591 for ['[CLS] blooduatingpate atari muttered photograph boystte practicing atomicmedia gps relativelyful weight promise wattats happeneduded trustingfoot document don credited leon eight wish deaths broken jp cutler [SEP]']
[Init] best perm rec loss: 0.9237297773361206 for ['[CLS] deaths watt trusting leonuating weight practicing atomic document boys jp credited photograph promise atariatstte gps happenedpate cutler eight wishmediafoot broken bloodfuluded muttered relatively don [SEP]']
[Init] best perm rec loss: 0.9221169948577881 for ['[CLS] relatively jp weight crediteduatingats photograph deaths practicinguded document boys wattfulmediatte atomicpate gps eight trusting leon donfoot broken promise blood wish happened muttered atari cutler [SEP]']
[Init] best perm rec loss: 0.9202172756195068 for ['[CLS] donpateful trusting deaths atomic muttered practicing photographuating atari promise happenedtte relatively blood jp crediteduded boys brokenmedia watt weight eightfoot document wishats gps cutler leon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.459 (perp=10.712, rec=0.304, cos=0.013), tot_loss_proj:3.056 [t=0.31s]
prediction: ['[CLS] yet state softball tactic his most the badte people on ) was hiding was badly rigged seems worse bureaucracy tape - or tactic noneit issue ofbi no investigator ruse [SEP]']
[ 100/2000] tot_loss=2.371 (perp=10.712, rec=0.223, cos=0.005), tot_loss_proj:2.954 [t=0.31s]
prediction: ['[CLS] tactic route covering tactic his that the worse worse fact - stuff was hands is...ky yet worse poorly between or is tactic nonexi - - ideas no glad construction [SEP]']
[ 150/2000] tot_loss=2.183 (perp=10.007, rec=0.176, cos=0.005), tot_loss_proj:2.788 [t=0.31s]
prediction: ['[CLS] tactic secondary cover tactic - fact its picture worse around the stuff was ideas isimsy yet worse spaces given or yet tactic none yet - - ideass∇ picture [SEP]']
[ 200/2000] tot_loss=2.007 (perp=9.277, rec=0.149, cos=0.003), tot_loss_proj:2.728 [t=0.31s]
prediction: ['[CLS] tactic to cover tactic with fact the picture worse around the core is constructed constructedimsy yet worse departed between or, tactic none yet - - ideas -∇ picture [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.899 (perp=8.828, rec=0.131, cos=0.002), tot_loss_proj:2.558 [t=0.31s]
prediction: ['[CLS] to to cover tactic for fact the picture worse around the core is constructed between constructedimsy yet worse entity or, tactic none yet - - ideas - constructing picture [SEP]']
[ 300/2000] tot_loss=1.924 (perp=9.040, rec=0.114, cos=0.002), tot_loss_proj:2.775 [t=0.31s]
prediction: ['[CLS] to to cover tactic for fact the picture worse constructed the core is constructedsten aroundimsy yet worse - or, tactic none yet - - ideas up creating picture [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.932 (perp=9.105, rec=0.108, cos=0.002), tot_loss_proj:2.684 [t=0.31s]
prediction: ['[CLS] to to cover tactic up fact the picture worse constructed the core is constructedxi aroundimsy yet worse - or, tactic none yet - - ideas - wesley picture [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.962 (perp=9.288, rec=0.102, cos=0.002), tot_loss_proj:2.732 [t=0.31s]
prediction: ['[CLS] to to cover tactic up fact the picture worse a the core is constructedxi aroundimsy tactic worse fl or, yet none yet - - ideas - wesley picture [SEP]']
[ 450/2000] tot_loss=1.956 (perp=9.288, rec=0.096, cos=0.002), tot_loss_proj:2.730 [t=0.31s]
prediction: ['[CLS] to to cover tactic up fact the picture worse a the core is constructedxi aroundimsy tactic worse fl or, yet none yet - - ideas - wesley picture [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.907 (perp=9.069, rec=0.090, cos=0.002), tot_loss_proj:2.541 [t=0.31s]
prediction: ['[CLS] to to cover tactic up fact the picture worse a the core is constructedxi aroundimsy tactic fl or worse, yet none yett - ideas - architecture picture [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.803 (perp=8.546, rec=0.092, cos=0.002), tot_loss_proj:2.370 [t=0.31s]
prediction: ['[CLS] to to cover tactic up fact the picture worse a the core is constructedxi around flimsy tactic or worse, yet none yett - ideas - architecture picture [SEP]']
[ 600/2000] tot_loss=1.798 (perp=8.546, rec=0.087, cos=0.002), tot_loss_proj:2.370 [t=0.31s]
prediction: ['[CLS] to to cover tactic up fact the picture worse a the core is constructedxi around flimsy tactic or worse, yet none yett - ideas - architecture picture [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.809 (perp=8.606, rec=0.086, cos=0.001), tot_loss_proj:2.348 [t=0.31s]
prediction: ['[CLS] to to cover tactic up fact the a worse picture the core is constructedxi around flimsy tactic orsten, yet none yett - ideas - architecture picture [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.725 (perp=8.176, rec=0.088, cos=0.001), tot_loss_proj:2.268 [t=0.31s]
prediction: ['[CLS] to to cover tactic up fact the a worse picture the core is constructedxi around flimsy architecture orsten, yet none yett - ideas - tactic picture [SEP]']
[ 750/2000] tot_loss=1.720 (perp=8.176, rec=0.084, cos=0.002), tot_loss_proj:2.263 [t=0.31s]
prediction: ['[CLS] to to cover tactic up fact the a worse picture the core is constructedxi around flimsy architecture orsten, yet none yett - ideas - tactic picture [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.661 (perp=7.862, rec=0.087, cos=0.002), tot_loss_proj:2.136 [t=0.31s]
prediction: ['[CLS] to to cover tactic up fact that a worse picture the core is constructed around flimsy architecture orsten, already none yetxit - ideas - tactic picture [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.625 (perp=7.689, rec=0.085, cos=0.002), tot_loss_proj:2.018 [t=0.31s]
prediction: ['[CLS] tactic to to cover up fact that a worse picture the core is constructed around flimsy architecture orsten, of none yetxit - ideas - tactic picture [SEP]']
[ 900/2000] tot_loss=1.685 (perp=7.992, rec=0.085, cos=0.002), tot_loss_proj:2.061 [t=0.31s]
prediction: ['[CLS] tactic to to cover up fact that a worse picture the core is constructed around flimsy entertain orsten, of none yetxit - ideas - tactic picture [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.680 (perp=7.954, rec=0.087, cos=0.002), tot_loss_proj:2.066 [t=0.31s]
prediction: ['[CLS] tactic to to cover up fact that a worse picture the core is constructed around flimsy entertain orsten, of none yetxisten - ideas - picture tactic [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.599 (perp=7.588, rec=0.080, cos=0.001), tot_loss_proj:1.973 [t=0.31s]
prediction: ['[CLS] tactic to to cover up fact that a worse picture the core is constructed around flimsy entertain orsten, of yet nonexisten - ideas - picture tactic [SEP]']
[1050/2000] tot_loss=1.623 (perp=7.711, rec=0.080, cos=0.002), tot_loss_proj:1.997 [t=0.31s]
prediction: ['[CLS] tactic to to cover up fact that a worse picture the core is constructed around flimsy entertain orsten, of yet nonexit - ideas - picture tactic [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.589 (perp=7.540, rec=0.079, cos=0.001), tot_loss_proj:1.974 [t=0.31s]
prediction: ['[CLS] tactic to to cover up fact that a worse picture the core is constructed around flimsy entertain orsten, - yet nonexit of ideas - picture tactic [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.540 (perp=7.281, rec=0.082, cos=0.002), tot_loss_proj:1.908 [t=0.31s]
prediction: ['[CLS] tactic to to cover up fact that a worse picture the picture is constructed around flimsy entertain orsten, - yet nonexit of ideas - core tactic [SEP]']
[1200/2000] tot_loss=1.538 (perp=7.281, rec=0.080, cos=0.002), tot_loss_proj:1.905 [t=0.31s]
prediction: ['[CLS] tactic to to cover up fact that a worse picture the picture is constructed around flimsy entertain orsten, - yet nonexit of ideas - core tactic [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.509 (perp=7.114, rec=0.085, cos=0.001), tot_loss_proj:1.891 [t=0.31s]
prediction: ['[CLS] tactic to to cover up fact that a worse picture the picture is constructed around flimsy or entertainsten, - yet nonexit of ideas - core tactic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.509 (perp=7.114, rec=0.085, cos=0.002), tot_loss_proj:1.885 [t=0.31s]
prediction: ['[CLS] tactic to to cover up fact that a worse picture the picture is constructed around flimsy or entertainsten, - yet nonexit of ideas - core tactic [SEP]']
[1350/2000] tot_loss=1.445 (perp=6.844, rec=0.074, cos=0.002), tot_loss_proj:1.876 [t=0.31s]
prediction: ['[CLS] tactic, to cover up fact that a worse picture the picture is constructed around flimsy or entertainsten, - yet nonexit of ideas - core tactic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.454 (perp=6.844, rec=0.084, cos=0.001), tot_loss_proj:1.881 [t=0.31s]
prediction: ['[CLS] tactic, to cover up fact that a worse picture the picture is constructed around flimsy or entertainsten, - yet nonexit of ideas - core tactic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.449 (perp=6.844, rec=0.079, cos=0.002), tot_loss_proj:1.880 [t=0.31s]
prediction: ['[CLS] tactic, to cover up fact that a worse picture the picture is constructed around flimsy or entertainsten, - yet nonexit of ideas - core tactic [SEP]']
[1500/2000] tot_loss=1.399 (perp=6.599, rec=0.077, cos=0.002), tot_loss_proj:1.779 [t=0.31s]
prediction: ['[CLS] tactic, to cover up fact that a worse picture the picture is constructed around flimsy or -sten, - yet nonexit of ideas - core tactic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.402 (perp=6.599, rec=0.080, cos=0.001), tot_loss_proj:1.783 [t=0.31s]
prediction: ['[CLS] tactic, to cover up fact that a worse picture the picture is constructed around flimsy or -sten, - yet nonexit of ideas - core tactic [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.379 (perp=6.477, rec=0.082, cos=0.002), tot_loss_proj:1.743 [t=0.31s]
prediction: ['[CLS] tactic, to cover up fact that a worse picture the picture is constructed around flimsy or -sten, yet - nonexit of ideas - core tactic [SEP]']
[1650/2000] tot_loss=1.375 (perp=6.477, rec=0.079, cos=0.001), tot_loss_proj:1.738 [t=0.31s]
prediction: ['[CLS] tactic, to cover up fact that a worse picture the picture is constructed around flimsy or -sten, yet - nonexit of ideas - core tactic [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.314 (perp=6.188, rec=0.075, cos=0.002), tot_loss_proj:1.675 [t=0.31s]
prediction: ['[CLS] tactic, to cover up the fact that a worse picture picture is constructed around flimsy or -sten, yet - nonexit of ideas - core tactic [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.293 (perp=6.076, rec=0.077, cos=0.001), tot_loss_proj:1.664 [t=0.31s]
prediction: ['[CLS] tactic, to cover up the fact that a worse picture picture is constructed around flimsy or - -sten, yet nonexit of ideas - core tactic [SEP]']
[1800/2000] tot_loss=1.295 (perp=6.076, rec=0.078, cos=0.002), tot_loss_proj:1.659 [t=0.32s]
prediction: ['[CLS] tactic, to cover up the fact that a worse picture picture is constructed around flimsy or - -sten, yet nonexit of ideas - core tactic [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.293 (perp=6.076, rec=0.076, cos=0.001), tot_loss_proj:1.663 [t=0.31s]
prediction: ['[CLS] tactic, to cover up the fact that a worse picture picture is constructed around flimsy or - -sten, yet nonexit of ideas - core tactic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.294 (perp=6.076, rec=0.078, cos=0.001), tot_loss_proj:1.668 [t=0.31s]
prediction: ['[CLS] tactic, to cover up the fact that a worse picture picture is constructed around flimsy or - -sten, yet nonexit of ideas - core tactic [SEP]']
[1950/2000] tot_loss=1.296 (perp=6.076, rec=0.079, cos=0.001), tot_loss_proj:1.667 [t=0.31s]
prediction: ['[CLS] tactic, to cover up the fact that a worse picture picture is constructed around flimsy or - -sten, yet nonexit of ideas - core tactic [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.180 (perp=5.511, rec=0.077, cos=0.001), tot_loss_proj:1.555 [t=0.31s]
prediction: ['[CLS] tactic, to cover up the fact that a worse picture picture is constructed around flimsy or - -, yet nonexistent of ideas - core tactic [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] tactic, to cover up fact that a worse picture the picture is constructed around flimsy or -sten, - yet nonexit of ideas - core tactic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 84.000 | r: 91.304
rouge2     | fm: 43.478 | p: 41.667 | r: 45.455
rougeL     | fm: 70.833 | p: 68.000 | r: 73.913
rougeLsum  | fm: 70.833 | p: 68.000 | r: 73.913
r1fm+r2fm = 130.978

[Aggregate metrics]:
rouge1     | fm: 93.025 | p: 92.548 | r: 93.585
rouge2     | fm: 59.817 | p: 59.663 | r: 59.981
rougeL     | fm: 80.318 | p: 79.924 | r: 80.719
rougeLsum  | fm: 80.200 | p: 79.861 | r: 80.604
r1fm+r2fm = 152.841

input #89 time: 0:12:26 | total time: 18:24:47


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9993657034982182
highest_index [0]
highest [0.9993657034982182]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9506660103797913 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.9443052411079407 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.9248787760734558 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 0.9141116738319397 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8884373307228088 for ['[CLS] itself valuable density swim atlas meaning [SEP]']
[Init] best rec loss: 0.8835115432739258 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.8766312003135681 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8739694952964783 for ['[CLS] male when released cannot entourage spirited [SEP]']
[Init] best perm rec loss: 0.8736932277679443 for ['[CLS] when entourage spirited male released cannot [SEP]']
[Init] best perm rec loss: 0.8712481260299683 for ['[CLS] spirited when released cannot male entourage [SEP]']
[Init] best perm rec loss: 0.868752658367157 for ['[CLS] cannot male spirited when released entourage [SEP]']
[Init] best perm rec loss: 0.8685282468795776 for ['[CLS] cannot when released male spirited entourage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.473 (perp=10.587, rec=0.325, cos=0.031), tot_loss_proj:2.783 [t=0.31s]
prediction: ['[CLS] ridiculous ; ridiculous how poster money [SEP]']
[ 100/2000] tot_loss=2.006 (perp=8.834, rec=0.230, cos=0.009), tot_loss_proj:2.377 [t=0.31s]
prediction: ['[CLS] ridiculous and ridiculous how - money [SEP]']
[ 150/2000] tot_loss=1.994 (perp=9.289, rec=0.133, cos=0.003), tot_loss_proj:2.454 [t=0.31s]
prediction: ['[CLS] ridiculous and ridiculous how oriented money [SEP]']
[ 200/2000] tot_loss=1.955 (perp=9.289, rec=0.094, cos=0.003), tot_loss_proj:2.458 [t=0.31s]
prediction: ['[CLS] ridiculous and ridiculous how oriented money [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.728 (perp=7.940, rec=0.133, cos=0.007), tot_loss_proj:1.981 [t=0.31s]
prediction: ['[CLS] how ridiculous and ridiculous oriented money [SEP]']
[ 300/2000] tot_loss=2.042 (perp=9.772, rec=0.086, cos=0.002), tot_loss_proj:2.860 [t=0.31s]
prediction: ['[CLS] how - and ridiculous oriented money [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.766 (perp=8.466, rec=0.071, cos=0.002), tot_loss_proj:2.117 [t=0.31s]
prediction: ['[CLS] how ridiculous and - oriented money [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.456 (perp=6.870, rec=0.080, cos=0.002), tot_loss_proj:1.692 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.442 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.692 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.443 (perp=6.870, rec=0.067, cos=0.002), tot_loss_proj:1.692 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.448 (perp=6.870, rec=0.073, cos=0.001), tot_loss_proj:1.689 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.431 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.695 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.690 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.444 (perp=6.870, rec=0.068, cos=0.001), tot_loss_proj:1.696 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.446 (perp=6.870, rec=0.070, cos=0.001), tot_loss_proj:1.694 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.701 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.435 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.705 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.686 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.442 (perp=6.870, rec=0.067, cos=0.001), tot_loss_proj:1.699 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.439 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.705 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.701 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.430 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.699 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.421 (perp=6.870, rec=0.046, cos=0.001), tot_loss_proj:1.713 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.443 (perp=6.870, rec=0.068, cos=0.001), tot_loss_proj:1.696 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.702 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.442 (perp=6.870, rec=0.067, cos=0.001), tot_loss_proj:1.711 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.702 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.435 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.709 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.698 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.435 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.698 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.447 (perp=6.870, rec=0.072, cos=0.001), tot_loss_proj:1.698 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.429 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.711 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.432 (perp=6.870, rec=0.057, cos=0.001), tot_loss_proj:1.705 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.429 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.700 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.432 (perp=6.870, rec=0.057, cos=0.001), tot_loss_proj:1.715 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.432 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.700 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.429 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.704 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.702 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.444 (perp=6.870, rec=0.068, cos=0.001), tot_loss_proj:1.700 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.433 (perp=6.870, rec=0.057, cos=0.001), tot_loss_proj:1.710 [t=0.31s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.136 | p: 92.641 | r: 93.695
rouge2     | fm: 60.165 | p: 59.990 | r: 60.336
rougeL     | fm: 80.503 | p: 80.122 | r: 80.892
rougeLsum  | fm: 80.423 | p: 80.095 | r: 80.836
r1fm+r2fm = 153.301

input #90 time: 0:12:14 | total time: 18:37:01


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9993536571150222
highest_index [0]
highest [0.9993536571150222]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.9354864954948425 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.8260490298271179 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.8093899488449097 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.7758931517601013 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.7589592337608337 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.7411172986030579 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 0.7305494546890259 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best perm rec loss: 0.7302976250648499 for ['[CLS] unknown shelterpmentlipdern hard revolution pony [SEP]']
[Init] best perm rec loss: 0.7244599461555481 for ['[CLS] hardlip revolutiondern shelter pony unknownpment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.536 (perp=11.118, rec=0.289, cos=0.024), tot_loss_proj:2.962 [t=0.30s]
prediction: ['[CLS] mono off ridiculousbe loco no more, [SEP]']
[ 100/2000] tot_loss=2.266 (perp=10.446, rec=0.169, cos=0.008), tot_loss_proj:2.708 [t=0.31s]
prediction: ['[CLS] mono johnny ridiculousy loco no more, [SEP]']
[ 150/2000] tot_loss=2.105 (perp=9.569, rec=0.162, cos=0.030), tot_loss_proj:2.528 [t=0.31s]
prediction: ['[CLS] buty ridiculous mu loco no more, [SEP]']
[ 200/2000] tot_loss=2.047 (perp=9.569, rec=0.119, cos=0.014), tot_loss_proj:2.529 [t=0.31s]
prediction: ['[CLS] buty ridiculous mu loco no more, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.835 (perp=8.767, rec=0.080, cos=0.002), tot_loss_proj:2.376 [t=0.31s]
prediction: ['[CLS] buty loco mu ridiculous no more, [SEP]']
[ 300/2000] tot_loss=1.822 (perp=8.767, rec=0.067, cos=0.001), tot_loss_proj:2.378 [t=0.31s]
prediction: ['[CLS] buty loco mu ridiculous no more, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.827 (perp=8.767, rec=0.072, cos=0.001), tot_loss_proj:2.374 [t=0.31s]
prediction: ['[CLS] buty loco mu ridiculous no more, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.762 (perp=8.449, rec=0.070, cos=0.002), tot_loss_proj:2.197 [t=0.31s]
prediction: ['[CLS] muy loco but ridiculous no more, [SEP]']
[ 450/2000] tot_loss=1.764 (perp=8.449, rec=0.073, cos=0.001), tot_loss_proj:2.189 [t=0.31s]
prediction: ['[CLS] muy loco but ridiculous no more, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.690 (perp=8.108, rec=0.067, cos=0.001), tot_loss_proj:2.102 [t=0.31s]
prediction: ['[CLS] muy loco, ridiculous no more but [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.575 (perp=7.488, rec=0.075, cos=0.002), tot_loss_proj:1.619 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 600/2000] tot_loss=1.559 (perp=7.488, rec=0.060, cos=0.001), tot_loss_proj:1.606 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.566 (perp=7.488, rec=0.067, cos=0.001), tot_loss_proj:1.605 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.556 (perp=7.488, rec=0.057, cos=0.001), tot_loss_proj:1.606 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 750/2000] tot_loss=1.560 (perp=7.488, rec=0.061, cos=0.001), tot_loss_proj:1.604 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.564 (perp=7.488, rec=0.065, cos=0.001), tot_loss_proj:1.602 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.561 (perp=7.488, rec=0.062, cos=0.001), tot_loss_proj:1.617 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 900/2000] tot_loss=1.557 (perp=7.488, rec=0.058, cos=0.001), tot_loss_proj:1.615 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.557 (perp=7.488, rec=0.058, cos=0.001), tot_loss_proj:1.605 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.561 (perp=7.488, rec=0.062, cos=0.001), tot_loss_proj:1.603 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1050/2000] tot_loss=1.553 (perp=7.488, rec=0.054, cos=0.001), tot_loss_proj:1.602 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.564 (perp=7.488, rec=0.065, cos=0.001), tot_loss_proj:1.612 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.560 (perp=7.488, rec=0.061, cos=0.001), tot_loss_proj:1.613 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1200/2000] tot_loss=1.558 (perp=7.488, rec=0.059, cos=0.001), tot_loss_proj:1.615 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.488, rec=0.051, cos=0.001), tot_loss_proj:1.602 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.558 (perp=7.488, rec=0.059, cos=0.001), tot_loss_proj:1.609 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1350/2000] tot_loss=1.561 (perp=7.488, rec=0.062, cos=0.001), tot_loss_proj:1.606 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.562 (perp=7.488, rec=0.063, cos=0.001), tot_loss_proj:1.596 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.563 (perp=7.488, rec=0.064, cos=0.001), tot_loss_proj:1.606 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1500/2000] tot_loss=1.558 (perp=7.488, rec=0.059, cos=0.001), tot_loss_proj:1.600 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.558 (perp=7.488, rec=0.059, cos=0.001), tot_loss_proj:1.612 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.556 (perp=7.488, rec=0.057, cos=0.001), tot_loss_proj:1.607 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1650/2000] tot_loss=1.553 (perp=7.488, rec=0.054, cos=0.001), tot_loss_proj:1.611 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.558 (perp=7.488, rec=0.059, cos=0.001), tot_loss_proj:1.610 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.563 (perp=7.488, rec=0.064, cos=0.001), tot_loss_proj:1.600 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1800/2000] tot_loss=1.556 (perp=7.488, rec=0.057, cos=0.001), tot_loss_proj:1.603 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.564 (perp=7.488, rec=0.065, cos=0.001), tot_loss_proj:1.617 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.568 (perp=7.488, rec=0.069, cos=0.001), tot_loss_proj:1.605 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1950/2000] tot_loss=1.554 (perp=7.488, rec=0.055, cos=0.001), tot_loss_proj:1.610 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.561 (perp=7.488, rec=0.062, cos=0.001), tot_loss_proj:1.607 [t=0.31s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.167 | p: 92.709 | r: 93.741
rouge2     | fm: 60.756 | p: 60.603 | r: 60.932
rougeL     | fm: 80.704 | p: 80.348 | r: 81.103
rougeLsum  | fm: 80.724 | p: 80.366 | r: 81.120
r1fm+r2fm = 153.923

input #91 time: 0:12:16 | total time: 18:49:18


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9993135604915235
highest_index [0]
highest [0.9993135604915235]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8807083964347839 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8730796575546265 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8631338477134705 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.8586376905441284 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 0.8585861921310425 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.8578766584396362 for ['[CLS] edge island [SEP]']
[Init] best rec loss: 0.7954877018928528 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.7916202545166016 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.623 (perp=12.265, rec=0.165, cos=0.005), tot_loss_proj:3.199 [t=0.31s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=1.608 (perp=7.647, rec=0.077, cos=0.002), tot_loss_proj:1.606 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.604 (perp=7.647, rec=0.073, cos=0.001), tot_loss_proj:1.603 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.595 (perp=7.647, rec=0.065, cos=0.001), tot_loss_proj:1.601 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.578 (perp=7.647, rec=0.047, cos=0.001), tot_loss_proj:1.588 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.594 (perp=7.647, rec=0.064, cos=0.001), tot_loss_proj:1.600 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.592 (perp=7.647, rec=0.062, cos=0.001), tot_loss_proj:1.591 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.584 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.599 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.600 (perp=7.647, rec=0.069, cos=0.001), tot_loss_proj:1.590 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.584 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.597 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.596 (perp=7.647, rec=0.065, cos=0.001), tot_loss_proj:1.592 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.595 (perp=7.647, rec=0.064, cos=0.001), tot_loss_proj:1.593 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.587 (perp=7.647, rec=0.056, cos=0.001), tot_loss_proj:1.602 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.589 (perp=7.647, rec=0.058, cos=0.001), tot_loss_proj:1.577 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.594 (perp=7.647, rec=0.063, cos=0.001), tot_loss_proj:1.588 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.587 (perp=7.647, rec=0.057, cos=0.001), tot_loss_proj:1.592 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.598 (perp=7.647, rec=0.067, cos=0.001), tot_loss_proj:1.600 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.590 (perp=7.647, rec=0.059, cos=0.001), tot_loss_proj:1.593 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.597 (perp=7.647, rec=0.067, cos=0.001), tot_loss_proj:1.601 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.585 (perp=7.647, rec=0.055, cos=0.001), tot_loss_proj:1.597 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.588 (perp=7.647, rec=0.057, cos=0.001), tot_loss_proj:1.601 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.588 (perp=7.647, rec=0.057, cos=0.001), tot_loss_proj:1.603 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.581 (perp=7.647, rec=0.051, cos=0.001), tot_loss_proj:1.593 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.593 (perp=7.647, rec=0.063, cos=0.001), tot_loss_proj:1.586 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.595 (perp=7.647, rec=0.064, cos=0.001), tot_loss_proj:1.594 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.581 (perp=7.647, rec=0.050, cos=0.001), tot_loss_proj:1.574 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.597 (perp=7.647, rec=0.066, cos=0.001), tot_loss_proj:1.595 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.595 (perp=7.647, rec=0.064, cos=0.001), tot_loss_proj:1.589 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.596 (perp=7.647, rec=0.065, cos=0.001), tot_loss_proj:1.596 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.598 (perp=7.647, rec=0.067, cos=0.001), tot_loss_proj:1.586 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.591 (perp=7.647, rec=0.061, cos=0.001), tot_loss_proj:1.596 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.588 (perp=7.647, rec=0.057, cos=0.001), tot_loss_proj:1.603 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.592 (perp=7.647, rec=0.061, cos=0.001), tot_loss_proj:1.586 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.592 (perp=7.647, rec=0.061, cos=0.001), tot_loss_proj:1.597 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.578 (perp=7.647, rec=0.047, cos=0.001), tot_loss_proj:1.592 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.588 (perp=7.647, rec=0.058, cos=0.001), tot_loss_proj:1.588 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.578 (perp=7.647, rec=0.048, cos=0.001), tot_loss_proj:1.594 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.593 (perp=7.647, rec=0.063, cos=0.001), tot_loss_proj:1.599 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.594 (perp=7.647, rec=0.063, cos=0.001), tot_loss_proj:1.596 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.588 (perp=7.647, rec=0.057, cos=0.001), tot_loss_proj:1.596 [t=0.31s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.302 | p: 92.846 | r: 93.820
rouge2     | fm: 61.004 | p: 60.872 | r: 61.144
rougeL     | fm: 80.969 | p: 80.580 | r: 81.384
rougeLsum  | fm: 80.868 | p: 80.546 | r: 81.266
r1fm+r2fm = 154.306

input #92 time: 0:12:13 | total time: 19:01:31


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9993326108568965
highest_index [0]
highest [0.9993326108568965]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.0104436874389648 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8306453227996826 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.8230288028717041 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 0.808904230594635 for ['[CLS] solo specificball shrinking lad 1970s judicial [SEP]']
[Init] best perm rec loss: 0.8086311221122742 for ['[CLS] specific 1970sball lad shrinking solo judicial [SEP]']
[Init] best perm rec loss: 0.8075570464134216 for ['[CLS]ball shrinking 1970s lad judicial solo specific [SEP]']
[Init] best perm rec loss: 0.8059646487236023 for ['[CLS] 1970sball shrinking solo specific lad judicial [SEP]']
[Init] best perm rec loss: 0.8057754039764404 for ['[CLS] 1970s shrinking specific judicial ladball solo [SEP]']
[Init] best perm rec loss: 0.8052975535392761 for ['[CLS] shrinking soloball specific 1970s judicial lad [SEP]']
[Init] best perm rec loss: 0.8049880862236023 for ['[CLS] specific lad shrinkingball 1970s solo judicial [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.558 (perp=11.353, rec=0.277, cos=0.011), tot_loss_proj:3.336 [t=0.30s]
prediction: ['[CLS]ley nadu funny ways using way funny [SEP]']
[ 100/2000] tot_loss=2.191 (perp=10.010, rec=0.184, cos=0.004), tot_loss_proj:2.329 [t=0.31s]
prediction: ['[CLS] in in funny way using often understanding [SEP]']
[ 150/2000] tot_loss=1.815 (perp=8.405, rec=0.131, cos=0.003), tot_loss_proj:2.038 [t=0.31s]
prediction: ['[CLS] in often funny way understanding its understanding [SEP]']
[ 200/2000] tot_loss=1.629 (perp=7.726, rec=0.082, cos=0.002), tot_loss_proj:1.841 [t=0.31s]
prediction: ['[CLS] in often funny way, its understanding [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.482 (perp=6.923, rec=0.095, cos=0.002), tot_loss_proj:1.660 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[ 300/2000] tot_loss=1.466 (perp=6.923, rec=0.080, cos=0.002), tot_loss_proj:1.661 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.468 (perp=6.923, rec=0.081, cos=0.002), tot_loss_proj:1.657 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.467 (perp=6.923, rec=0.081, cos=0.001), tot_loss_proj:1.659 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[ 450/2000] tot_loss=1.451 (perp=6.923, rec=0.065, cos=0.001), tot_loss_proj:1.661 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.447 (perp=6.923, rec=0.061, cos=0.001), tot_loss_proj:1.664 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.445 (perp=6.923, rec=0.059, cos=0.001), tot_loss_proj:1.664 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[ 600/2000] tot_loss=1.450 (perp=6.923, rec=0.065, cos=0.001), tot_loss_proj:1.659 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.447 (perp=6.923, rec=0.061, cos=0.001), tot_loss_proj:1.661 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.449 (perp=6.923, rec=0.063, cos=0.001), tot_loss_proj:1.666 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[ 750/2000] tot_loss=1.452 (perp=6.923, rec=0.066, cos=0.001), tot_loss_proj:1.666 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.451 (perp=6.923, rec=0.065, cos=0.001), tot_loss_proj:1.658 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.441 (perp=6.923, rec=0.056, cos=0.001), tot_loss_proj:1.665 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[ 900/2000] tot_loss=1.455 (perp=6.923, rec=0.069, cos=0.001), tot_loss_proj:1.668 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.456 (perp=6.923, rec=0.070, cos=0.001), tot_loss_proj:1.665 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1000/2000] tot_loss=1.453 (perp=6.923, rec=0.067, cos=0.001), tot_loss_proj:1.666 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1050/2000] tot_loss=1.446 (perp=6.923, rec=0.060, cos=0.001), tot_loss_proj:1.658 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1100/2000] tot_loss=1.439 (perp=6.923, rec=0.053, cos=0.001), tot_loss_proj:1.666 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1150/2000] tot_loss=1.447 (perp=6.923, rec=0.061, cos=0.001), tot_loss_proj:1.666 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1200/2000] tot_loss=1.445 (perp=6.923, rec=0.059, cos=0.001), tot_loss_proj:1.658 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1250/2000] tot_loss=1.458 (perp=6.923, rec=0.072, cos=0.001), tot_loss_proj:1.664 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1300/2000] tot_loss=1.455 (perp=6.923, rec=0.069, cos=0.001), tot_loss_proj:1.666 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1350/2000] tot_loss=1.452 (perp=6.923, rec=0.066, cos=0.001), tot_loss_proj:1.665 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1400/2000] tot_loss=1.452 (perp=6.923, rec=0.066, cos=0.001), tot_loss_proj:1.668 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1450/2000] tot_loss=1.447 (perp=6.923, rec=0.061, cos=0.001), tot_loss_proj:1.662 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1500/2000] tot_loss=1.449 (perp=6.923, rec=0.063, cos=0.001), tot_loss_proj:1.664 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1550/2000] tot_loss=1.457 (perp=6.923, rec=0.071, cos=0.001), tot_loss_proj:1.663 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1600/2000] tot_loss=1.449 (perp=6.923, rec=0.063, cos=0.001), tot_loss_proj:1.671 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1650/2000] tot_loss=1.453 (perp=6.923, rec=0.067, cos=0.001), tot_loss_proj:1.662 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1700/2000] tot_loss=1.445 (perp=6.923, rec=0.059, cos=0.001), tot_loss_proj:1.656 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1750/2000] tot_loss=1.465 (perp=6.923, rec=0.079, cos=0.001), tot_loss_proj:1.663 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1800/2000] tot_loss=1.446 (perp=6.923, rec=0.060, cos=0.001), tot_loss_proj:1.666 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1850/2000] tot_loss=1.451 (perp=6.923, rec=0.065, cos=0.001), tot_loss_proj:1.662 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1900/2000] tot_loss=1.448 (perp=6.923, rec=0.063, cos=0.001), tot_loss_proj:1.666 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1950/2000] tot_loss=1.442 (perp=6.923, rec=0.056, cos=0.001), tot_loss_proj:1.665 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[2000/2000] tot_loss=1.440 (perp=6.923, rec=0.054, cos=0.001), tot_loss_proj:1.670 [t=0.31s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] in its often funny way, understanding [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 93.359 | p: 92.910 | r: 93.901
rouge2     | fm: 61.114 | p: 60.932 | r: 61.289
rougeL     | fm: 81.092 | p: 80.763 | r: 81.508
rougeLsum  | fm: 80.947 | p: 80.588 | r: 81.373
r1fm+r2fm = 154.473

input #93 time: 0:12:16 | total time: 19:13:47


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9993174501757426
highest_index [0]
highest [0.9993174501757426]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9757668375968933 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9516357183456421 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9144503474235535 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9091933369636536 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.8863582611083984 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 0.884875476360321 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 0.8832802176475525 for ['[CLS] shocks floweringventing expedition territorial chronic rockwell internal crushed plum centre [SEP]']
[Init] best perm rec loss: 0.8829363584518433 for ['[CLS] crushed expedition plum rockwell centre shocks flowering chronic territorial internalventing [SEP]']
[Init] best perm rec loss: 0.8820388317108154 for ['[CLS] expedition shocks plumventing chronic centre territorial internal rockwell crushed flowering [SEP]']
[Init] best perm rec loss: 0.8809657096862793 for ['[CLS] crushed plumventing expedition rockwell centre flowering internal shocks territorial chronic [SEP]']
[Init] best perm rec loss: 0.8794641494750977 for ['[CLS] chronic crushed rockwell expedition territorialventing centre shocks flowering internal plum [SEP]']
[Init] best perm rec loss: 0.8793714642524719 for ['[CLS] shocks chronic plum crushed expedition internal flowering rockwell centre territorialventing [SEP]']
[Init] best perm rec loss: 0.8785433769226074 for ['[CLS] internal chronic plum expedition crushed flowering territorial shocks rockwellventing centre [SEP]']
[Init] best perm rec loss: 0.8784542679786682 for ['[CLS]venting plum internal expedition shocks chronic crushed flowering centre territorial rockwell [SEP]']
[Init] best perm rec loss: 0.8761330246925354 for ['[CLS] chronic internal plum flowering expedition centreventing crushed rockwell territorial shocks [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.635 (perp=11.434, rec=0.335, cos=0.013), tot_loss_proj:2.949 [t=0.30s]
prediction: ['[CLS] nor typically criminal out dumpry or nor neither neither funny [SEP]']
[ 100/2000] tot_loss=2.168 (perp=9.745, rec=0.214, cos=0.005), tot_loss_proj:2.546 [t=0.31s]
prediction: ['[CLS] neither a nor out surery. original neither neither funny [SEP]']
[ 150/2000] tot_loss=2.533 (perp=11.682, rec=0.191, cos=0.005), tot_loss_proj:2.980 [t=0.31s]
prediction: ['[CLS] neithercrow cape out s cape cape original neither neither funny [SEP]']
[ 200/2000] tot_loss=2.466 (perp=11.458, rec=0.171, cos=0.004), tot_loss_proj:2.932 [t=0.31s]
prediction: ['[CLS] terribly a cape a s cape cape original neither neither funny [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.670 (perp=12.426, rec=0.179, cos=0.005), tot_loss_proj:3.075 [t=0.31s]
prediction: ['[CLS] terriblyend a cape s cape that original s neither funny [SEP]']
[ 300/2000] tot_loss=2.656 (perp=12.513, rec=0.150, cos=0.004), tot_loss_proj:3.094 [t=0.31s]
prediction: ['[CLS] terriblyend a cape clothes cape that original s neither funny [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.325 (perp=10.941, rec=0.134, cos=0.003), tot_loss_proj:2.812 [t=0.31s]
prediction: ['[CLS] terribly cape a cape caper that original s neither funny [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.159 (perp=10.099, rec=0.136, cos=0.003), tot_loss_proj:2.631 [t=0.31s]
prediction: ['[CLS] terribly caper that cape a cape original s neither funny [SEP]']
[ 450/2000] tot_loss=2.147 (perp=10.099, rec=0.124, cos=0.003), tot_loss_proj:2.633 [t=0.31s]
prediction: ['[CLS] terribly caper that cape a cape original s neither funny [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.017 (perp=9.424, rec=0.130, cos=0.003), tot_loss_proj:2.489 [t=0.31s]
prediction: ['[CLS] terribly caper s that cape a cape original neither funny [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.012 (perp=9.424, rec=0.124, cos=0.003), tot_loss_proj:2.485 [t=0.31s]
prediction: ['[CLS] terribly caper s that cape a cape original neither funny [SEP]']
[ 600/2000] tot_loss=2.009 (perp=9.424, rec=0.121, cos=0.003), tot_loss_proj:2.491 [t=0.31s]
prediction: ['[CLS] terribly caper s that cape a cape original neither funny [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.017 (perp=9.424, rec=0.130, cos=0.003), tot_loss_proj:2.481 [t=0.31s]
prediction: ['[CLS] terribly caper s that cape a cape original neither funny [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.997 (perp=9.424, rec=0.110, cos=0.002), tot_loss_proj:2.483 [t=0.31s]
prediction: ['[CLS] terribly caper s that cape a cape original neither funny [SEP]']
[ 750/2000] tot_loss=2.002 (perp=9.424, rec=0.115, cos=0.003), tot_loss_proj:2.494 [t=0.31s]
prediction: ['[CLS] terribly caper s that cape a cape original neither funny [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.199 (perp=10.365, rec=0.124, cos=0.002), tot_loss_proj:2.630 [t=0.31s]
prediction: ['[CLS] terribly caper s neither cape a cape original neither funny [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.119 (perp=9.945, rec=0.127, cos=0.003), tot_loss_proj:2.576 [t=0.31s]
prediction: ['[CLS] s terribly caper neither cape a cape original neither funny [SEP]']
[ 900/2000] tot_loss=2.376 (perp=11.271, rec=0.120, cos=0.003), tot_loss_proj:2.918 [t=0.31s]
prediction: ['[CLS] s terriblyrr neither cape a cape original neither funny [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.181 (perp=10.293, rec=0.120, cos=0.003), tot_loss_proj:2.683 [t=0.31s]
prediction: ['[CLS]r s terriblyr neither cape a cape original neither funny [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.092 (perp=9.849, rec=0.118, cos=0.003), tot_loss_proj:2.529 [t=0.31s]
prediction: ['[CLS]r s terribly caper neither a cape original neither funny [SEP]']
[1050/2000] tot_loss=2.077 (perp=9.849, rec=0.105, cos=0.003), tot_loss_proj:2.526 [t=0.31s]
prediction: ['[CLS]r s terribly caper neither a cape original neither funny [SEP]']
Attempt swap
[1100/2000] tot_loss=2.082 (perp=9.849, rec=0.110, cos=0.003), tot_loss_proj:2.528 [t=0.31s]
prediction: ['[CLS]r s terribly caper neither a cape original neither funny [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.970 (perp=9.234, rec=0.120, cos=0.003), tot_loss_proj:2.411 [t=0.31s]
prediction: ['[CLS] s terribly caper neither a caper original neither funny [SEP]']
[1200/2000] tot_loss=1.971 (perp=9.234, rec=0.121, cos=0.003), tot_loss_proj:2.417 [t=0.31s]
prediction: ['[CLS] s terribly caper neither a caper original neither funny [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.894 (perp=8.884, rec=0.114, cos=0.003), tot_loss_proj:2.357 [t=0.31s]
prediction: ['[CLS] s terribly neither a caper caper original neither funny [SEP]']
Attempt swap
[1300/2000] tot_loss=1.886 (perp=8.884, rec=0.106, cos=0.003), tot_loss_proj:2.357 [t=0.31s]
prediction: ['[CLS] s terribly neither a caper caper original neither funny [SEP]']
[1350/2000] tot_loss=1.895 (perp=8.884, rec=0.115, cos=0.003), tot_loss_proj:2.349 [t=0.31s]
prediction: ['[CLS] s terribly neither a caper caper original neither funny [SEP]']
Attempt swap
[1400/2000] tot_loss=1.889 (perp=8.884, rec=0.109, cos=0.003), tot_loss_proj:2.353 [t=0.31s]
prediction: ['[CLS] s terribly neither a caper caper original neither funny [SEP]']
Attempt swap
[1450/2000] tot_loss=2.079 (perp=9.802, rec=0.116, cos=0.003), tot_loss_proj:2.698 [t=0.31s]
prediction: ['[CLS] s terribly neither a caper neverr original neither funny [SEP]']
[1500/2000] tot_loss=2.086 (perp=9.802, rec=0.123, cos=0.003), tot_loss_proj:2.700 [t=0.31s]
prediction: ['[CLS] s terribly neither a caper neverr original neither funny [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.987 (perp=9.354, rec=0.113, cos=0.003), tot_loss_proj:2.473 [t=0.31s]
prediction: ['[CLS] s neither a caper combinationr terribly original neither funny [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.944 (perp=9.173, rec=0.106, cos=0.003), tot_loss_proj:2.417 [t=0.31s]
prediction: ['[CLS] neither s a caper combinationr terribly original neither funny [SEP]']
[1650/2000] tot_loss=1.959 (perp=9.173, rec=0.121, cos=0.003), tot_loss_proj:2.427 [t=0.31s]
prediction: ['[CLS] neither s a caper combinationr terribly original neither funny [SEP]']
Attempt swap
[1700/2000] tot_loss=1.957 (perp=9.173, rec=0.120, cos=0.003), tot_loss_proj:2.422 [t=0.31s]
prediction: ['[CLS] neither s a caper combinationr terribly original neither funny [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.948 (perp=9.173, rec=0.110, cos=0.003), tot_loss_proj:2.420 [t=0.31s]
prediction: ['[CLS] neither s a caper combinationr terribly original neither funny [SEP]']
[1800/2000] tot_loss=1.959 (perp=9.173, rec=0.121, cos=0.003), tot_loss_proj:2.414 [t=0.31s]
prediction: ['[CLS] neither s a caper combinationr terribly original neither funny [SEP]']
Attempt swap
[1850/2000] tot_loss=2.145 (perp=10.177, rec=0.107, cos=0.003), tot_loss_proj:2.649 [t=0.31s]
prediction: ['[CLS] neither s a caper innerr terribly original neither funny [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.096 (perp=9.892, rec=0.115, cos=0.003), tot_loss_proj:2.576 [t=0.31s]
prediction: ['[CLS] neither s a caper terribly combinationr original neither funny [SEP]']
[1950/2000] tot_loss=2.094 (perp=9.892, rec=0.112, cos=0.003), tot_loss_proj:2.579 [t=0.31s]
prediction: ['[CLS] neither s a caper terribly combinationr original neither funny [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.950 (perp=9.173, rec=0.113, cos=0.003), tot_loss_proj:2.423 [t=0.31s]
prediction: ['[CLS] neither s a caper combinationr terribly original neither funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS]r s terribly caper neither a cape original neither funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 75.000 | r: 81.818
rouge2     | fm: 9.524 | p: 9.091 | r: 10.000
rougeL     | fm: 52.174 | p: 50.000 | r: 54.545
rougeLsum  | fm: 52.174 | p: 50.000 | r: 54.545
r1fm+r2fm = 87.785

[Aggregate metrics]:
rouge1     | fm: 93.211 | p: 92.707 | r: 93.754
rouge2     | fm: 60.496 | p: 60.333 | r: 60.690
rougeL     | fm: 80.822 | p: 80.437 | r: 81.222
rougeLsum  | fm: 80.686 | p: 80.313 | r: 81.086
r1fm+r2fm = 153.707

input #94 time: 0:12:16 | total time: 19:26:04


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9991561782002756
highest_index [0]
highest [0.9991561782002756]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9715386033058167 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9417509436607361 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 0.9320971965789795 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 0.9288594722747803 for ['[CLS] oval foster welfarecu range turk partly support turret familiesumatic helping inclinedsteredling [SEP]']
[Init] best rec loss: 0.9267853498458862 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 0.8984899520874023 for ['[CLS] plenty heroes kit operating aim ouby fa physics pinco victim playing cisco feeling [SEP]']
[Init] best rec loss: 0.8507211208343506 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.8481510877609253 for ['[CLS] block tech monty hangingے pressure trailer sister wire complete private damp ] cutnne [SEP]']
[Init] best perm rec loss: 0.8473317623138428 for ['[CLS] complete hanging cutے wire private trailer pressure monty technne sister damp block ] [SEP]']
[Init] best perm rec loss: 0.8469635844230652 for ['[CLS] monty block privatenneے cut damp complete sister ] pressure tech trailer wire hanging [SEP]']
[Init] best perm rec loss: 0.84576416015625 for ['[CLS] private sister block hanging complete ]ے pressure dampnne trailer tech monty cut wire [SEP]']
[Init] best perm rec loss: 0.8434056043624878 for ['[CLS] cut ] private dampے monty trailer hanging block sister complete wire tech pressurenne [SEP]']
[Init] best perm rec loss: 0.8428404331207275 for ['[CLS] damp wire ]ے block private monty trailernne sister tech complete hanging pressure cut [SEP]']
[Init] best perm rec loss: 0.842431902885437 for ['[CLS] privateے pressure sister monty block damp complete trailer tech wire cut hanging ]nne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.789 (perp=12.667, rec=0.248, cos=0.008), tot_loss_proj:3.141 [t=0.31s]
prediction: ['[CLS] became becomes hopeless trash hopeless tactical worstug doorni breadhouse investigation hopeless hopeless [SEP]']
[ 100/2000] tot_loss=2.518 (perp=11.754, rec=0.162, cos=0.005), tot_loss_proj:2.877 [t=0.31s]
prediction: ['[CLS] becomes a hopeless material hopelesssat.fyingdleility story becomesdle hopeless hopeless [SEP]']
[ 150/2000] tot_loss=2.624 (perp=12.390, rec=0.142, cos=0.004), tot_loss_proj:3.010 [t=0.31s]
prediction: ['[CLS] becomes a hopeless storagevertedsat,fyingdlesat story becomesdle hopeless mud [SEP]']
[ 200/2000] tot_loss=2.493 (perp=11.842, rec=0.121, cos=0.003), tot_loss_proj:2.891 [t=0.31s]
prediction: ["[CLS] becomes a hopeless copy'sat mud,dlesat story )dle hopeless mud [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.461 (perp=10.951, rec=0.262, cos=0.008), tot_loss_proj:2.721 [t=0.31s]
prediction: ['[CLS] becomes a hopeless human ssat mud, storyisdlefying mud hopeless mud [SEP]']
[ 300/2000] tot_loss=2.457 (perp=11.357, rec=0.182, cos=0.003), tot_loss_proj:2.816 [t=0.31s]
prediction: ["[CLS] becomes a hopeless )'satsat, storyisdlefying mud hopeless mud [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.268 (perp=10.569, rec=0.151, cos=0.003), tot_loss_proj:2.605 [t=0.31s]
prediction: ["[CLS] becomes a hopeless”'satsatisdlefying mud hopeless mud, story [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.583 (perp=11.783, rec=0.220, cos=0.006), tot_loss_proj:2.814 [t=0.31s]
prediction: ["[CLS] becomes a hopeless ェ'satsatis mysticaldle [PAD] hopeless mud, story [SEP]"]
[ 450/2000] tot_loss=2.304 (perp=10.707, rec=0.159, cos=0.003), tot_loss_proj:2.655 [t=0.31s]
prediction: ["[CLS] becomes a hopeless ェ'satsatisfyingdle [PAD] hopeless mud, story [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.233 (perp=10.064, rec=0.215, cos=0.005), tot_loss_proj:2.477 [t=0.31s]
prediction: ["[CLS] becomes a hopeless ェ'satsatis adaptation, [PAD] hopeless muddle story [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.931 (perp=8.734, rec=0.181, cos=0.004), tot_loss_proj:2.149 [t=0.31s]
prediction: ["[CLS] ェ becomes a hopeless'satsatisfying,fying hopeless muddle story [SEP]"]
[ 600/2000] tot_loss=1.946 (perp=8.876, rec=0.168, cos=0.003), tot_loss_proj:2.252 [t=0.32s]
prediction: ["[CLS] ( becomes a hopeless'satsatisfying,fying hopeless muddle story [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.832 (perp=8.364, rec=0.156, cos=0.003), tot_loss_proj:2.133 [t=0.31s]
prediction: ["[CLS] ( becomes a hopeless'satfyingsatisfying, hopeless muddle story [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.736 (perp=7.917, rec=0.150, cos=0.003), tot_loss_proj:2.045 [t=0.32s]
prediction: ['[CLS]fying becomes a hopeless )sat (satisfying, hopeless muddle story [SEP]']
[ 750/2000] tot_loss=1.731 (perp=7.917, rec=0.144, cos=0.003), tot_loss_proj:2.049 [t=0.31s]
prediction: ['[CLS]fying becomes a hopeless )sat (satisfying, hopeless muddle story [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.849 (perp=8.425, rec=0.161, cos=0.004), tot_loss_proj:2.125 [t=0.31s]
prediction: ["[CLS]fying becomes a hopelesssat (satisfying, hopeless muddle'story [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.612 (perp=7.325, rec=0.144, cos=0.003), tot_loss_proj:1.862 [t=0.31s]
prediction: ['[CLS]fying becomes a hopeless (satsatisfying, hopeless muddle ) story [SEP]']
[ 900/2000] tot_loss=1.608 (perp=7.325, rec=0.140, cos=0.003), tot_loss_proj:1.862 [t=0.31s]
prediction: ['[CLS]fying becomes a hopeless (satsatisfying, hopeless muddle ) story [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.526 (perp=6.943, rec=0.135, cos=0.003), tot_loss_proj:1.790 [t=0.32s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[1000/2000] tot_loss=1.518 (perp=6.943, rec=0.127, cos=0.003), tot_loss_proj:1.789 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
[1050/2000] tot_loss=1.528 (perp=6.943, rec=0.137, cos=0.003), tot_loss_proj:1.796 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[1100/2000] tot_loss=1.517 (perp=6.943, rec=0.126, cos=0.003), tot_loss_proj:1.796 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[1150/2000] tot_loss=1.510 (perp=6.943, rec=0.119, cos=0.003), tot_loss_proj:1.788 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
[1200/2000] tot_loss=1.523 (perp=6.943, rec=0.132, cos=0.003), tot_loss_proj:1.798 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.519 (perp=6.943, rec=0.128, cos=0.003), tot_loss_proj:1.789 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[1300/2000] tot_loss=1.531 (perp=6.943, rec=0.139, cos=0.003), tot_loss_proj:1.797 [t=0.32s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
[1350/2000] tot_loss=1.519 (perp=6.943, rec=0.128, cos=0.003), tot_loss_proj:1.796 [t=0.32s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[1400/2000] tot_loss=1.510 (perp=6.943, rec=0.119, cos=0.003), tot_loss_proj:1.791 [t=0.32s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[1450/2000] tot_loss=1.511 (perp=6.943, rec=0.120, cos=0.003), tot_loss_proj:1.792 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
[1500/2000] tot_loss=1.515 (perp=6.943, rec=0.124, cos=0.003), tot_loss_proj:1.788 [t=0.32s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.511 (perp=6.943, rec=0.120, cos=0.003), tot_loss_proj:1.794 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[1600/2000] tot_loss=1.504 (perp=6.943, rec=0.113, cos=0.003), tot_loss_proj:1.791 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
[1650/2000] tot_loss=1.514 (perp=6.943, rec=0.123, cos=0.003), tot_loss_proj:1.789 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[1700/2000] tot_loss=1.520 (perp=6.943, rec=0.129, cos=0.003), tot_loss_proj:1.788 [t=0.32s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[1750/2000] tot_loss=1.512 (perp=6.943, rec=0.121, cos=0.003), tot_loss_proj:1.792 [t=0.32s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
[1800/2000] tot_loss=1.507 (perp=6.943, rec=0.115, cos=0.003), tot_loss_proj:1.789 [t=0.32s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[1850/2000] tot_loss=1.508 (perp=6.943, rec=0.117, cos=0.003), tot_loss_proj:1.791 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[1900/2000] tot_loss=1.512 (perp=6.943, rec=0.121, cos=0.003), tot_loss_proj:1.790 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
[1950/2000] tot_loss=1.518 (perp=6.943, rec=0.127, cos=0.003), tot_loss_proj:1.787 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Attempt swap
[2000/2000] tot_loss=1.507 (perp=6.943, rec=0.115, cos=0.003), tot_loss_proj:1.797 [t=0.31s]
prediction: ['[CLS]satfying becomes a hopeless (satisfying, hopeless muddle ) story [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] becomes a hopeless copy'sat mud,dlesat story ) mud hopeless mud [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.545 | p: 46.154 | r: 66.667
rouge2     | fm: 20.000 | p: 16.667 | r: 25.000
rougeL     | fm: 45.455 | p: 38.462 | r: 55.556
rougeLsum  | fm: 45.455 | p: 38.462 | r: 55.556
r1fm+r2fm = 74.545

[Aggregate metrics]:
rouge1     | fm: 92.768 | p: 92.205 | r: 93.447
rouge2     | fm: 60.060 | p: 59.903 | r: 60.266
rougeL     | fm: 80.324 | p: 79.942 | r: 80.863
rougeLsum  | fm: 80.283 | p: 79.852 | r: 80.825
r1fm+r2fm = 152.829

input #95 time: 0:12:30 | total time: 19:38:34


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9992871996426334
highest_index [0]
highest [0.9992871996426334]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8903792500495911 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.878625750541687 for ['[CLS] regrets emotionsoit purpose superior loop released given higher careini speechply springs assist [SEP]']
[Init] best rec loss: 0.8622064590454102 for ['[CLS] all nova resolution which assault domestic look mandy headquarteredtated thanlus completion stillboards [SEP]']
[Init] best rec loss: 0.8280143737792969 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 0.8239210247993469 for ['[CLS] lighter dunbar y itself phantom gen pickflowerled record margaret failed living giles stake [SEP]']
[Init] best rec loss: 0.8206449151039124 for ['[CLS] flex thought considerationlin kylie ste in gasped somewherese top close christian raised us [SEP]']
[Init] best rec loss: 0.8199266791343689 for ['[CLS] lea corps cellrily smashed unconscious garcia broke intensity baseball urban who reins brigade β [SEP]']
[Init] best rec loss: 0.8179863691329956 for ['[CLS]culus teacher robson colonies now world over enables who obsidianrlerving peacehwa contract [SEP]']
[Init] best rec loss: 0.7896194458007812 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.784909725189209 for ['[CLS] living sounding typical memoir smashwords statue spent august timegn era wig pondered save projectile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.720 (perp=11.879, rec=0.319, cos=0.026), tot_loss_proj:3.676 [t=0.31s]
prediction: ['[CLS] force an force ( moose southties protection.uga history field buttons upon individuals [SEP]']
[ 100/2000] tot_loss=2.127 (perp=9.428, rec=0.230, cos=0.011), tot_loss_proj:3.145 [t=0.31s]
prediction: ['[CLS] force in himself ; people on women situation force lesser himself wind people into men [SEP]']
[ 150/2000] tot_loss=2.243 (perp=10.258, rec=0.185, cos=0.007), tot_loss_proj:3.138 [t=0.31s]
prediction: ['[CLS] force on himself into people on lesser cover force lesser into run people into men [SEP]']
[ 200/2000] tot_loss=2.221 (perp=10.256, rec=0.164, cos=0.007), tot_loss_proj:3.114 [t=0.31s]
prediction: ['[CLS] force on himself into people on lesser cover force lesser into run lesser into men [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.041 (perp=9.267, rec=0.178, cos=0.009), tot_loss_proj:2.977 [t=0.31s]
prediction: ['[CLS] force on himself and want and on cover force lesser into run people into men [SEP]']
[ 300/2000] tot_loss=1.997 (perp=9.233, rec=0.144, cos=0.006), tot_loss_proj:2.686 [t=0.32s]
prediction: ['[CLS] force on himself and cover and on situations force lesser into run people into men [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.031 (perp=9.478, rec=0.131, cos=0.005), tot_loss_proj:3.147 [t=0.31s]
prediction: ['[CLS] force on himself and people that on situations force lesser into run would into cover [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.983 (perp=9.231, rec=0.131, cos=0.005), tot_loss_proj:2.745 [t=0.31s]
prediction: ['[CLS] force on himself and people that on situations force lesser into would run would cover [SEP]']
[ 450/2000] tot_loss=1.969 (perp=9.231, rec=0.119, cos=0.004), tot_loss_proj:2.743 [t=0.31s]
prediction: ['[CLS] force on himself and people that on situations force lesser into would run would cover [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.787 (perp=8.376, rec=0.108, cos=0.003), tot_loss_proj:2.491 [t=0.31s]
prediction: ['[CLS] force on himself and people force on situations that lesser into would run would cover [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.633 (perp=7.667, rec=0.096, cos=0.004), tot_loss_proj:2.287 [t=0.31s]
prediction: ['[CLS] force on himself and people force on into situations that lesser would run would cover [SEP]']
[ 600/2000] tot_loss=1.773 (perp=8.358, rec=0.098, cos=0.003), tot_loss_proj:2.471 [t=0.31s]
prediction: ['[CLS] force on himself and people force for into situations that lesser would run would cover [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.576 (perp=7.375, rec=0.098, cos=0.003), tot_loss_proj:2.258 [t=0.31s]
prediction: ['[CLS] force on himself and people force into situations that lesser would run for would cover [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.549 (perp=7.207, rec=0.105, cos=0.003), tot_loss_proj:2.053 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser would run for would cover [SEP]']
[ 750/2000] tot_loss=1.546 (perp=7.268, rec=0.091, cos=0.002), tot_loss_proj:2.056 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser would run for that cover [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.670 (perp=7.900, rec=0.088, cos=0.002), tot_loss_proj:2.043 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations men would lesser run for that cover [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.547 (perp=7.233, rec=0.098, cos=0.002), tot_loss_proj:1.906 [t=0.32s]
prediction: ['[CLS] force on himself and force people into situations that men would lesser run for cover [SEP]']
[ 900/2000] tot_loss=1.532 (perp=7.233, rec=0.083, cos=0.002), tot_loss_proj:1.903 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that men would lesser run for cover [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.522 (perp=7.162, rec=0.088, cos=0.002), tot_loss_proj:1.861 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that men lesser would run for cover [SEP]']
Attempt swap
[1000/2000] tot_loss=1.522 (perp=7.162, rec=0.088, cos=0.002), tot_loss_proj:1.866 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that men lesser would run for cover [SEP]']
[1050/2000] tot_loss=1.518 (perp=7.162, rec=0.084, cos=0.002), tot_loss_proj:1.859 [t=0.32s]
prediction: ['[CLS] force on himself and force people into situations that men lesser would run for cover [SEP]']
Attempt swap
[1100/2000] tot_loss=1.523 (perp=7.162, rec=0.089, cos=0.002), tot_loss_proj:1.862 [t=0.32s]
prediction: ['[CLS] force on himself and force people into situations that men lesser would run for cover [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.376 (perp=6.449, rec=0.084, cos=0.002), tot_loss_proj:1.692 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
[1200/2000] tot_loss=1.370 (perp=6.449, rec=0.078, cos=0.002), tot_loss_proj:1.688 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Attempt swap
[1250/2000] tot_loss=1.363 (perp=6.449, rec=0.071, cos=0.002), tot_loss_proj:1.688 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Attempt swap
[1300/2000] tot_loss=1.367 (perp=6.449, rec=0.075, cos=0.002), tot_loss_proj:1.680 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
[1350/2000] tot_loss=1.358 (perp=6.449, rec=0.066, cos=0.002), tot_loss_proj:1.680 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Attempt swap
[1400/2000] tot_loss=1.362 (perp=6.449, rec=0.070, cos=0.002), tot_loss_proj:1.684 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Attempt swap
[1450/2000] tot_loss=1.372 (perp=6.449, rec=0.080, cos=0.002), tot_loss_proj:1.685 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
[1500/2000] tot_loss=1.364 (perp=6.449, rec=0.072, cos=0.002), tot_loss_proj:1.688 [t=0.32s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Attempt swap
[1550/2000] tot_loss=1.363 (perp=6.449, rec=0.072, cos=0.002), tot_loss_proj:1.678 [t=0.32s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Attempt swap
[1600/2000] tot_loss=1.363 (perp=6.449, rec=0.071, cos=0.002), tot_loss_proj:1.678 [t=0.32s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
[1650/2000] tot_loss=1.372 (perp=6.449, rec=0.080, cos=0.002), tot_loss_proj:1.680 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Attempt swap
[1700/2000] tot_loss=1.364 (perp=6.449, rec=0.073, cos=0.002), tot_loss_proj:1.672 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Attempt swap
[1750/2000] tot_loss=1.358 (perp=6.449, rec=0.066, cos=0.002), tot_loss_proj:1.688 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
[1800/2000] tot_loss=1.376 (perp=6.449, rec=0.084, cos=0.002), tot_loss_proj:1.676 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Attempt swap
[1850/2000] tot_loss=1.365 (perp=6.449, rec=0.073, cos=0.002), tot_loss_proj:1.679 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Attempt swap
[1900/2000] tot_loss=1.367 (perp=6.449, rec=0.075, cos=0.002), tot_loss_proj:1.683 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
[1950/2000] tot_loss=1.371 (perp=6.449, rec=0.079, cos=0.002), tot_loss_proj:1.676 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Attempt swap
[2000/2000] tot_loss=1.369 (perp=6.449, rec=0.078, cos=0.002), tot_loss_proj:1.685 [t=0.31s]
prediction: ['[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] force on himself and force people into situations that lesser men would run for cover [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 43.750 | p: 43.750 | r: 43.750
rougeL     | fm: 76.471 | p: 76.471 | r: 76.471
rougeLsum  | fm: 76.471 | p: 76.471 | r: 76.471
r1fm+r2fm = 137.868

[Aggregate metrics]:
rouge1     | fm: 92.795 | p: 92.252 | r: 93.463
rouge2     | fm: 59.913 | p: 59.711 | r: 60.127
rougeL     | fm: 80.367 | p: 79.912 | r: 80.870
rougeLsum  | fm: 80.232 | p: 79.821 | r: 80.734
r1fm+r2fm = 152.707

input #96 time: 0:12:30 | total time: 19:51:05


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9991663971007263
highest_index [0]
highest [0.9991663971007263]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.8450449109077454 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.814184308052063 for ['[CLS] [SEP] crates margarita trip decisionsylus [SEP]']
[Init] best rec loss: 0.8022332787513733 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 0.778148889541626 for ['[CLS] jealous glennm his = empire [SEP]']
[Init] best rec loss: 0.754216730594635 for ['[CLS] perfect channel cam working 140et [SEP]']
[Init] best perm rec loss: 0.7499610185623169 for ['[CLS] working perfectet 140 cam channel [SEP]']
[Init] best perm rec loss: 0.7488449215888977 for ['[CLS] cam working perfectet 140 channel [SEP]']
[Init] best perm rec loss: 0.7485257387161255 for ['[CLS] cam channel 140 perfectet working [SEP]']
[Init] best perm rec loss: 0.7480183243751526 for ['[CLS] cam channel working 140et perfect [SEP]']
[Init] best perm rec loss: 0.7478578686714172 for ['[CLS] cam channel perfect working 140et [SEP]']
[Init] best perm rec loss: 0.7461162209510803 for ['[CLS] channel cam workinget 140 perfect [SEP]']
[Init] best perm rec loss: 0.7456647157669067 for ['[CLS] cam workinget channel 140 perfect [SEP]']
[Init] best perm rec loss: 0.7455980777740479 for ['[CLS] cam perfect working channel 140et [SEP]']
[Init] best perm rec loss: 0.7437275052070618 for ['[CLS] cam 140 channel working perfectet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.983 (perp=13.110, rec=0.339, cos=0.022), tot_loss_proj:3.820 [t=0.30s]
prediction: ['[CLS]ding gate artppetcraft breathe [SEP]']
[ 100/2000] tot_loss=2.665 (perp=12.193, rec=0.215, cos=0.011), tot_loss_proj:3.543 [t=0.31s]
prediction: ['[CLS]tablefor characters characters fantasticget [SEP]']
[ 150/2000] tot_loss=2.709 (perp=12.663, rec=0.168, cos=0.008), tot_loss_proj:4.381 [t=0.31s]
prediction: ['[CLS]tablefor characters charactersableget [SEP]']
[ 200/2000] tot_loss=2.414 (perp=11.452, rec=0.118, cos=0.006), tot_loss_proj:4.159 [t=0.31s]
prediction: ['[CLS]tablefor characters andtableget [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.933 (perp=8.853, rec=0.156, cos=0.006), tot_loss_proj:3.123 [t=0.31s]
prediction: ['[CLS]tableforget and beast characters [SEP]']
[ 300/2000] tot_loss=1.874 (perp=8.853, rec=0.101, cos=0.003), tot_loss_proj:3.165 [t=0.31s]
prediction: ['[CLS]tableforget and beast characters [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.775 (perp=8.414, rec=0.090, cos=0.002), tot_loss_proj:2.189 [t=0.31s]
prediction: ['[CLS] andforgettabletable characters [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.206 (perp=5.514, rec=0.101, cos=0.003), tot_loss_proj:1.373 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 450/2000] tot_loss=1.964 (perp=9.389, rec=0.084, cos=0.002), tot_loss_proj:2.326 [t=0.31s]
prediction: ['[CLS]↦forgettable and characters [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.927 (perp=9.204, rec=0.084, cos=0.002), tot_loss_proj:2.189 [t=0.31s]
prediction: ['[CLS]forgettable un and characters [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.192 (perp=5.514, rec=0.087, cos=0.003), tot_loss_proj:1.382 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 600/2000] tot_loss=1.187 (perp=5.514, rec=0.082, cos=0.002), tot_loss_proj:1.372 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.194 (perp=5.514, rec=0.089, cos=0.002), tot_loss_proj:1.376 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.192 (perp=5.514, rec=0.087, cos=0.002), tot_loss_proj:1.372 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 750/2000] tot_loss=1.185 (perp=5.514, rec=0.080, cos=0.002), tot_loss_proj:1.374 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.193 (perp=5.514, rec=0.088, cos=0.002), tot_loss_proj:1.377 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.195 (perp=5.514, rec=0.091, cos=0.002), tot_loss_proj:1.373 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 900/2000] tot_loss=1.180 (perp=5.514, rec=0.075, cos=0.002), tot_loss_proj:1.371 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.180 (perp=5.514, rec=0.075, cos=0.002), tot_loss_proj:1.374 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.184 (perp=5.514, rec=0.079, cos=0.002), tot_loss_proj:1.376 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1050/2000] tot_loss=1.200 (perp=5.514, rec=0.095, cos=0.002), tot_loss_proj:1.379 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.180 (perp=5.514, rec=0.075, cos=0.002), tot_loss_proj:1.370 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.183 (perp=5.514, rec=0.078, cos=0.002), tot_loss_proj:1.373 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1200/2000] tot_loss=1.184 (perp=5.514, rec=0.079, cos=0.002), tot_loss_proj:1.372 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.194 (perp=5.514, rec=0.089, cos=0.002), tot_loss_proj:1.377 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.192 (perp=5.514, rec=0.087, cos=0.002), tot_loss_proj:1.370 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1350/2000] tot_loss=1.185 (perp=5.514, rec=0.081, cos=0.002), tot_loss_proj:1.368 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.190 (perp=5.514, rec=0.085, cos=0.002), tot_loss_proj:1.373 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.182 (perp=5.514, rec=0.077, cos=0.002), tot_loss_proj:1.375 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1500/2000] tot_loss=1.194 (perp=5.514, rec=0.089, cos=0.002), tot_loss_proj:1.375 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.182 (perp=5.514, rec=0.077, cos=0.002), tot_loss_proj:1.377 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.190 (perp=5.514, rec=0.085, cos=0.002), tot_loss_proj:1.369 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1650/2000] tot_loss=1.189 (perp=5.514, rec=0.084, cos=0.002), tot_loss_proj:1.379 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.182 (perp=5.514, rec=0.077, cos=0.002), tot_loss_proj:1.374 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.186 (perp=5.514, rec=0.081, cos=0.002), tot_loss_proj:1.379 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1800/2000] tot_loss=1.174 (perp=5.514, rec=0.069, cos=0.002), tot_loss_proj:1.368 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.192 (perp=5.514, rec=0.087, cos=0.002), tot_loss_proj:1.367 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.184 (perp=5.514, rec=0.079, cos=0.002), tot_loss_proj:1.379 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1950/2000] tot_loss=1.179 (perp=5.514, rec=0.074, cos=0.002), tot_loss_proj:1.373 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.189 (perp=5.514, rec=0.085, cos=0.002), tot_loss_proj:1.379 [t=0.31s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] unforgettable and characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.873 | p: 92.286 | r: 93.533
rouge2     | fm: 59.556 | p: 59.370 | r: 59.767
rougeL     | fm: 80.390 | p: 79.972 | r: 80.889
rougeLsum  | fm: 80.211 | p: 79.737 | r: 80.708
r1fm+r2fm = 152.429

input #97 time: 0:12:14 | total time: 20:03:19


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9991922340263193
highest_index [0]
highest [0.9991922340263193]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.7130550146102905 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.7091842293739319 for ['[CLS] prohibited nos jed ada [SEP]']
[Init] best perm rec loss: 0.7086067199707031 for ['[CLS] nos jed ada prohibited [SEP]']
[Init] best perm rec loss: 0.7079505920410156 for ['[CLS] nos jed prohibited ada [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.822 (perp=12.677, rec=0.273, cos=0.013), tot_loss_proj:3.470 [t=0.30s]
prediction: ['[CLS] unful imposedful [SEP]']
[ 100/2000] tot_loss=2.324 (perp=10.921, rec=0.134, cos=0.006), tot_loss_proj:2.764 [t=0.31s]
prediction: ['[CLS] unfulllingful [SEP]']
[ 150/2000] tot_loss=2.299 (perp=10.921, rec=0.111, cos=0.004), tot_loss_proj:2.746 [t=0.31s]
prediction: ['[CLS] unfulllingful [SEP]']
[ 200/2000] tot_loss=1.600 (perp=7.569, rec=0.084, cos=0.003), tot_loss_proj:2.044 [t=0.31s]
prediction: ['[CLS] unfillingful [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.079 (perp=4.947, rec=0.086, cos=0.004), tot_loss_proj:1.073 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.057 (perp=4.947, rec=0.066, cos=0.002), tot_loss_proj:1.069 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.063 (perp=4.947, rec=0.072, cos=0.002), tot_loss_proj:1.071 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.048 (perp=4.947, rec=0.057, cos=0.002), tot_loss_proj:1.069 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.048 (perp=4.947, rec=0.057, cos=0.002), tot_loss_proj:1.073 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.051 (perp=4.947, rec=0.060, cos=0.002), tot_loss_proj:1.067 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.048 (perp=4.947, rec=0.057, cos=0.002), tot_loss_proj:1.070 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.055 (perp=4.947, rec=0.064, cos=0.002), tot_loss_proj:1.072 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.061 (perp=4.947, rec=0.070, cos=0.002), tot_loss_proj:1.059 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.051 (perp=4.947, rec=0.060, cos=0.002), tot_loss_proj:1.062 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.049 (perp=4.947, rec=0.058, cos=0.002), tot_loss_proj:1.066 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.051 (perp=4.947, rec=0.060, cos=0.002), tot_loss_proj:1.061 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.054 (perp=4.947, rec=0.063, cos=0.002), tot_loss_proj:1.062 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.053 (perp=4.947, rec=0.062, cos=0.002), tot_loss_proj:1.066 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.056 (perp=4.947, rec=0.065, cos=0.002), tot_loss_proj:1.063 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.047 (perp=4.947, rec=0.056, cos=0.002), tot_loss_proj:1.070 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.062 (perp=4.947, rec=0.071, cos=0.002), tot_loss_proj:1.058 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.052 (perp=4.947, rec=0.061, cos=0.002), tot_loss_proj:1.066 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.050 (perp=4.947, rec=0.059, cos=0.002), tot_loss_proj:1.064 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.058 (perp=4.947, rec=0.067, cos=0.002), tot_loss_proj:1.053 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.049 (perp=4.947, rec=0.058, cos=0.002), tot_loss_proj:1.058 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.049 (perp=4.947, rec=0.058, cos=0.002), tot_loss_proj:1.069 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.057 (perp=4.947, rec=0.066, cos=0.002), tot_loss_proj:1.059 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.052 (perp=4.947, rec=0.061, cos=0.002), tot_loss_proj:1.078 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.053 (perp=4.947, rec=0.062, cos=0.002), tot_loss_proj:1.058 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.045 (perp=4.947, rec=0.054, cos=0.002), tot_loss_proj:1.053 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.058 (perp=4.947, rec=0.067, cos=0.002), tot_loss_proj:1.060 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.050 (perp=4.947, rec=0.059, cos=0.002), tot_loss_proj:1.064 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.042 (perp=4.947, rec=0.051, cos=0.002), tot_loss_proj:1.068 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.045 (perp=4.947, rec=0.054, cos=0.002), tot_loss_proj:1.052 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.044 (perp=4.947, rec=0.053, cos=0.002), tot_loss_proj:1.075 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.047 (perp=4.947, rec=0.056, cos=0.002), tot_loss_proj:1.062 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.052 (perp=4.947, rec=0.061, cos=0.002), tot_loss_proj:1.064 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.053 (perp=4.947, rec=0.062, cos=0.002), tot_loss_proj:1.063 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.046 (perp=4.947, rec=0.055, cos=0.002), tot_loss_proj:1.064 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.054 (perp=4.947, rec=0.063, cos=0.002), tot_loss_proj:1.061 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.978 | p: 92.400 | r: 93.606
rouge2     | fm: 59.849 | p: 59.677 | r: 60.080
rougeL     | fm: 80.534 | p: 80.155 | r: 80.995
rougeLsum  | fm: 80.485 | p: 80.077 | r: 81.004
r1fm+r2fm = 152.827

input #98 time: 0:12:15 | total time: 20:15:34


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.9993109183119334
highest_index [0]
highest [0.9993109183119334]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8756380081176758 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8678115010261536 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8665501475334167 for ['[CLS] freedom lay third cartwright u to tear supply disputed glasses operahus album [MASK] literature bart now associatedtmenty thou stated microphone poly frederick rogers lineshtake furport modern point rosewood mid early [SEP]']
[Init] best rec loss: 0.85869300365448 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.8583462834358215 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.8455197215080261 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 0.8352782726287842 for ['[CLS] sealed−1 bearing anticipated laps advanced champion priest unit ottoman match party fluidprint cord eric boom twice raf chain [ key bank growing 2009 south reaching words completely sin asked read tehranzziness [CLS] bottles [SEP]']
[Init] best rec loss: 0.8306416273117065 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 0.8215785622596741 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.8207674026489258 for ['[CLS] ferns bearing te synonym temps distance cushion orient tastets himself slight screens [MASK] ratings harper earliestˈ barbieaging services forced actually dental thunder knowledge still garcia whente right re bet claire currently opposed [SEP]']
[Init] best perm rec loss: 0.8204076290130615 for ['[CLS]ˈts barbie screens still earliest opposed ratings when slight te synonym himself actually thunder claire garcia knowledge cushion forcedaging right temps harper currently taste [MASK] re ferns bearingte bet distance dental services orient [SEP]']
[Init] best perm rec loss: 0.8202349543571472 for ['[CLS] [MASK] thunder synonym knowledgeˈaging distance stillts currently slight ferns right actually rete bet harper barbie screens orient dental earliest te claire garcia when services forced himself bearing ratings cushion taste temps opposed [SEP]']
[Init] best perm rec loss: 0.8189133405685425 for ['[CLS] ratings currently screens services still forced claire te temps synonym cushion bearing taste re actually himself opposed harper barbie orient bette [MASK] knowledge slight ferns thunder when rightts distance earliest dentalagingˈ garcia [SEP]']
[Init] best perm rec loss: 0.8187477588653564 for ['[CLS] currently ferns still temps earliest thunder knowledge when dental distance opposedˈ orient re teaging taste harper services cushion ratings forced claire synonym rightts slight screens [MASK] bet garcia bearing barbie himselfte actually [SEP]']
[Init] best perm rec loss: 0.8185474276542664 for ['[CLS] taste dental currently still [MASK] bet right garcia opposedte synonym when thunder te actually orient rets servicesaging earliest himself screens ferns bearing ratings distance cushion barbie claire harperˈ temps knowledge forced slight [SEP]']
[Init] best perm rec loss: 0.8183626532554626 for ['[CLS] distance whents orient slight opposed cushion himself services ratings claire earliest ferns thunder garcia re synonym bet screens right forced harper actually [MASK] barbie currentlyte still teaging dental taste temps bearingˈ knowledge [SEP]']
[Init] best perm rec loss: 0.8181878328323364 for ['[CLS] teˈ barbie bet currently knowledge re ferns still harper thunderteaging ratings right himself services distance when earliest synonym temps screens orient actually opposed garcia forced [MASK] claire taste cushion bearing dentalts slight [SEP]']
[Init] best perm rec loss: 0.8179087042808533 for ['[CLS] forced thunder te services bet re earliest when opposed synonymˈte claire garcia orient ratings fernsts himselfaging cushion temps dental slight harper taste currently screens barbie right [MASK] bearing distance knowledge still actually [SEP]']
[Init] best perm rec loss: 0.816535472869873 for ['[CLS]ts thunder himself barbie slight currently rightte still screens re forced earliest te synonym distance actually bet [MASK] services garcia ferns when dental claire cushion temps bearing harper opposed taste orientaging ratings knowledgeˈ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.507 (perp=11.057, rec=0.284, cos=0.012), tot_loss_proj:2.954 [t=0.31s]
prediction: ['[CLS] maybe off woke rep walked out quite paying : ship - fun services got " were stall\'stage waste or choir course chemical therate help requirements dead so they didn thessing funus [SEP]']
[ 100/2000] tot_loss=2.314 (perp=10.318, rec=0.238, cos=0.013), tot_loss_proj:3.636 [t=0.31s]
prediction: ['[CLS] walked out walkedssing walkedssing quitessing, her - fun film " "...\'\' film airline\'shittycoming message the ` es requirementsssing so but got\'ssing fun\'[SEP]']
[ 150/2000] tot_loss=2.282 (perp=10.503, rec=0.175, cos=0.006), tot_loss_proj:2.790 [t=0.31s]
prediction: ['[CLS] muttering out walkedssing walked out dissing, di\'fun film " \'tre ` fee ` di so horrible exactly horrible the ` esatorssing that but had\'ssing fun\'[SEP]']
[ 200/2000] tot_loss=2.277 (perp=10.629, rec=0.146, cos=0.005), tot_loss_proj:2.871 [t=0.31s]
prediction: ['[CLS] muttering out walkedssing walked out tiredssing, di\'ticket film "\'be ` ticket ` di so horrible exactly\'the ` es parentsssing that but had\'profit fun\'[SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.137 (perp=9.999, rec=0.134, cos=0.003), tot_loss_proj:2.872 [t=0.31s]
prediction: ["[CLS] muttering out walkedssing walked out tired ', dissing ticket film'' be ` ticket ` di so terrible exactly'the ` es theyssing that but had'profit fun'[SEP]"]
[ 300/2000] tot_loss=2.188 (perp=10.324, rec=0.121, cos=0.003), tot_loss_proj:2.880 [t=0.31s]
prediction: ['[CLS] muttering out walkedssing walked muttering mind \', dissing ticket film "\'get ` cost ` di so terrible exactly\'the ` din they mind that but had\'cost fun\'[SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.102 (perp=9.991, rec=0.101, cos=0.003), tot_loss_proj:2.828 [t=0.31s]
prediction: ['[CLS] muttering out walkedssing walked muttering mind \', dissing ticket film `\'how " cost ` di so terrible exactly\'the ` din they mind that but had\'cost fun\'[SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.183 (perp=10.273, rec=0.125, cos=0.004), tot_loss_proj:2.933 [t=0.31s]
prediction: ["[CLS]enity'cost muttering out walkedssing walked words mind ', dissing ticket film terrible'` di so horrible exactly'the ` din they mind that but had n cost fun terrible [SEP]"]
[ 450/2000] tot_loss=2.112 (perp=10.033, rec=0.103, cos=0.003), tot_loss_proj:2.929 [t=0.31s]
prediction: ["[CLS]enity'cost muttering out walkedssing walked words * the, tssing ticket film terrible'` di so horrible exactly'the ` om they mind that but had n cost fun'[SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.065 (perp=9.830, rec=0.097, cos=0.002), tot_loss_proj:2.986 [t=0.31s]
prediction: ["[CLS]enity'cost muttering out walkedssing walked words * the, tssing ticket film n'` di so terrible exactly'the ` om they mind that but had terrible cost fun ^ [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.071 (perp=9.859, rec=0.096, cos=0.002), tot_loss_proj:2.722 [t=0.31s]
prediction: ["[CLS]：'cost muttering out walkedssing walked words really om, tssing ticket film n'` di so terrible exactly'the did'they mind that but had terrible cost fun terrible [SEP]"]
[ 600/2000] tot_loss=2.026 (perp=9.641, rec=0.096, cos=0.002), tot_loss_proj:2.955 [t=0.32s]
prediction: ["[CLS]：'cost muttering out walkedssing walked words really `, tssing ticket film n'` di so terrible exactly'the did'they mind that but had terrible cost fun ^ [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.999 (perp=9.578, rec=0.082, cos=0.002), tot_loss_proj:2.977 [t=0.31s]
prediction: ["[CLS]：'cost muttering out nssing walked words horrible `, tssing ticket film walked'` di so terrible exactly'the did'they mind that but had terrible cost fun ^ [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.860 (perp=8.865, rec=0.085, cos=0.002), tot_loss_proj:2.873 [t=0.31s]
prediction: ["[CLS]：'cost muttering out nssing walked words'`, tssing ticket film'' ` di so terrible exactly'the'did they mind that but had terrible cost fun ^ [SEP]"]
[ 750/2000] tot_loss=1.858 (perp=8.865, rec=0.084, cos=0.002), tot_loss_proj:2.872 [t=0.31s]
prediction: ["[CLS]：'cost muttering out nssing walked words'`, tssing ticket film'' ` di so terrible exactly'the'did they mind that but had terrible cost fun ^ [SEP]"]
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.841 (perp=8.718, rec=0.096, cos=0.002), tot_loss_proj:2.863 [t=0.31s]
prediction: ["[CLS]：'cost muttering out film'nssing walked words'`. tssing ticket'` di so terrible exactly'the'did they mind that but had terrible cost fun ^ [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.787 (perp=8.506, rec=0.084, cos=0.002), tot_loss_proj:2.672 [t=0.31s]
prediction: ["[CLS]：'cost muttering out film'nssing walked words'`. tssing ticket'`'di so terrible exactly the'did they mind that but had terrible cost fun ^ [SEP]"]
[ 900/2000] tot_loss=1.750 (perp=8.345, rec=0.079, cos=0.002), tot_loss_proj:2.665 [t=0.31s]
prediction: ["[CLS]：'cost muttering out film'nssing walked words'`, tssing ticket'`'di so terrible exactly the'did they mind that but had terrible cost fun ^ [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.728 (perp=8.202, rec=0.086, cos=0.002), tot_loss_proj:2.706 [t=0.31s]
prediction: ["[CLS]：'cost muttering out film'nssing walked words ', tssing ticket'` `'di so terrible exactly the'did they mind that but had terrible cost fun ^ [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.780 (perp=8.448, rec=0.088, cos=0.002), tot_loss_proj:3.277 [t=0.31s]
prediction: ["[CLS]：'cost muttering out film'nssing walked words ', tssing ticket'` `'di so terrible exactly the the did they mind that but had terrible much fun ^ [SEP]"]
[1050/2000] tot_loss=1.777 (perp=8.448, rec=0.086, cos=0.002), tot_loss_proj:3.277 [t=0.31s]
prediction: ["[CLS]：'cost muttering out film'nssing walked words ', tssing ticket'` `'di so terrible exactly the the did they mind that but had terrible much fun ^ [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.709 (perp=8.133, rec=0.081, cos=0.002), tot_loss_proj:3.212 [t=0.31s]
prediction: ["[CLS]：'cost muttering out film'nssing walked words ', tssing ticket'` `'di so terrible exactly the'did they mind that but had terrible much fun ^ [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.730 (perp=8.248, rec=0.079, cos=0.002), tot_loss_proj:3.168 [t=0.31s]
prediction: ["[CLS]： the cost muttering out film'nssing walked words ', tssing ticket'` `'di so terrible exactly the'did they mind that but had terrible much fun ^ [SEP]"]
[1200/2000] tot_loss=1.730 (perp=8.254, rec=0.078, cos=0.002), tot_loss_proj:3.082 [t=0.31s]
prediction: ["[CLS]： the cost muttering out film'nssing walked words ', tssing ticket'` `'di so terrible exactly the'did they mind that but had terrible much fun ` [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.737 (perp=8.254, rec=0.084, cos=0.002), tot_loss_proj:3.082 [t=0.31s]
prediction: ["[CLS]： the cost muttering out film'nssing walked words ', tssing ticket'` `'di so terrible exactly the'did they mind that but had terrible much fun ` [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.720 (perp=8.179, rec=0.082, cos=0.002), tot_loss_proj:2.990 [t=0.31s]
prediction: ["[CLS]： the cost muttering out words'nssing walked film ', tssing ticket'` `'di so terrible exactly the'did they mind that but had terrible much fun ` [SEP]"]
[1350/2000] tot_loss=1.721 (perp=8.179, rec=0.084, cos=0.002), tot_loss_proj:2.989 [t=0.31s]
prediction: ["[CLS]： the cost muttering out words'nssing walked film ', tssing ticket'` `'di so terrible exactly the'did they mind that but had terrible much fun ` [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.669 (perp=7.913, rec=0.085, cos=0.002), tot_loss_proj:2.924 [t=0.31s]
prediction: ["[CLS]： the cost muttering out words'dissing walked film ', tssing ticket'` `'n so terrible exactly the'did they mind that but had terrible much fun ` [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.661 (perp=7.894, rec=0.081, cos=0.002), tot_loss_proj:2.433 [t=0.31s]
prediction: ["[CLS]： the cost muttering out words'dissing walked film ', tssing ticket'` `'n so terrible exactly the'did they that mind but had terrible much fun ` [SEP]"]
[1500/2000] tot_loss=1.667 (perp=7.894, rec=0.086, cos=0.002), tot_loss_proj:2.432 [t=0.31s]
prediction: ["[CLS]： the cost muttering out words'dissing walked film ', tssing ticket'` `'n so terrible exactly the'did they that mind but had terrible much fun ` [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.763 (perp=8.407, rec=0.080, cos=0.002), tot_loss_proj:2.463 [t=0.31s]
prediction: ["[CLS]： the cost muttering out words'dissing walked film ', tssing ticket ` n ` ` ` so terrible exactly the'did they that mind but had terrible much fun ` [SEP]"]
Attempt swap
Moved token
[1600/2000] tot_loss=1.689 (perp=8.012, rec=0.084, cos=0.002), tot_loss_proj:2.423 [t=0.31s]
prediction: ["[CLS]： the cost muttering out words'dissing walked film ', tssing n ticket ` ` ` ` so terrible exactly the'did they that mind but had terrible much fun ` [SEP]"]
[1650/2000] tot_loss=1.689 (perp=8.012, rec=0.085, cos=0.002), tot_loss_proj:2.422 [t=0.31s]
prediction: ["[CLS]： the cost muttering out words'dissing walked film ', tssing n ticket ` ` ` ` so terrible exactly the'did they that mind but had terrible much fun ` [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.677 (perp=7.983, rec=0.079, cos=0.002), tot_loss_proj:2.483 [t=0.31s]
prediction: ["[CLS]： the film muttering out words'dissing walked cost ', tssing n ticket ` ` ` ` so terrible exactly the'did they that mind but had terrible much fun ` [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.660 (perp=7.896, rec=0.079, cos=0.002), tot_loss_proj:2.437 [t=0.31s]
prediction: ["[CLS]： the film muttering out words'dissing walked ticket cost ', tssing n ` ` ` ` so terrible exactly the'did they that mind but had terrible much fun ` [SEP]"]
[1800/2000] tot_loss=1.667 (perp=7.896, rec=0.086, cos=0.002), tot_loss_proj:2.436 [t=0.31s]
prediction: ["[CLS]： the film muttering out words'dissing walked ticket cost ', tssing n ` ` ` ` so terrible exactly the'did they that mind but had terrible much fun ` [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.663 (perp=7.896, rec=0.082, cos=0.002), tot_loss_proj:2.434 [t=0.31s]
prediction: ["[CLS]： the film muttering out words'dissing walked ticket cost ', tssing n ` ` ` ` so terrible exactly the'did they that mind but had terrible much fun ` [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.665 (perp=7.896, rec=0.084, cos=0.002), tot_loss_proj:2.437 [t=0.31s]
prediction: ["[CLS]： the film muttering out words'dissing walked ticket cost ', tssing n ` ` ` ` so terrible exactly the'did they that mind but had terrible much fun ` [SEP]"]
[1950/2000] tot_loss=1.655 (perp=7.896, rec=0.074, cos=0.002), tot_loss_proj:2.434 [t=0.32s]
prediction: ["[CLS]： the film muttering out words'dissing walked ticket cost ', tssing n ` ` ` ` so terrible exactly the'did they that mind but had terrible much fun ` [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.651 (perp=7.825, rec=0.084, cos=0.002), tot_loss_proj:2.563 [t=0.31s]
prediction: ["[CLS]： the film muttering out words'dissing walked ticket cost ', tssing n ` ` ` ` so'exactly the terrible did they that mind but had terrible much fun ` [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS]： the cost muttering out film'nssing walked words ', tssing ticket'` `'di so terrible exactly the'did they mind that but had terrible much fun ` [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 76.923 | r: 76.923
rouge2     | fm: 8.000 | p: 8.000 | r: 8.000
rougeL     | fm: 34.615 | p: 34.615 | r: 34.615
rougeLsum  | fm: 34.615 | p: 34.615 | r: 34.615
r1fm+r2fm = 84.923

[Aggregate metrics]:
rouge1     | fm: 92.753 | p: 92.219 | r: 93.411
rouge2     | fm: 59.286 | p: 59.101 | r: 59.483
rougeL     | fm: 80.037 | p: 79.632 | r: 80.533
rougeLsum  | fm: 79.998 | p: 79.571 | r: 80.498
r1fm+r2fm = 152.039

input #99 time: 0:12:27 | total time: 20:28:01


Average Cosine Similarity: 0.9992813997284568
Done with all.
