


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.05 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 48.14it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.8816614050285085
highest_index [0]
highest [0.8816614050285085]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 0.9515887498855591 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.8142498731613159 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.8137786388397217 for ['[CLS] tolerance receiving [SEP]']
[Init] best rec loss: 0.810725212097168 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.7985562086105347 for ['[CLS] panel officer [SEP]']
[Init] best perm rec loss: 0.7957879304885864 for ['[CLS] officer panel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.581 (perp=10.843, rec=0.183, cos=0.230), tot_loss_proj:2.684 [t=0.22s]
prediction: ['[CLS] disappointed disappointed [SEP]']
[ 100/2000] tot_loss=2.524 (perp=11.088, rec=0.088, cos=0.219), tot_loss_proj:2.784 [t=0.22s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 150/2000] tot_loss=2.508 (perp=11.088, rec=0.072, cos=0.219), tot_loss_proj:2.796 [t=0.22s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 200/2000] tot_loss=2.508 (perp=11.088, rec=0.073, cos=0.218), tot_loss_proj:2.789 [t=0.22s]
prediction: ['[CLS] disappointed slightly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.338 (perp=10.251, rec=0.067, cos=0.221), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.334 (perp=10.251, rec=0.061, cos=0.222), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.333 (perp=10.251, rec=0.064, cos=0.219), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.336 (perp=10.251, rec=0.065, cos=0.220), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.334 (perp=10.251, rec=0.062, cos=0.221), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.329 (perp=10.251, rec=0.057, cos=0.221), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.332 (perp=10.251, rec=0.059, cos=0.223), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.337 (perp=10.251, rec=0.067, cos=0.221), tot_loss_proj:2.344 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.333 (perp=10.251, rec=0.060, cos=0.222), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.324 (perp=10.251, rec=0.055, cos=0.219), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.337 (perp=10.251, rec=0.068, cos=0.219), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.331 (perp=10.251, rec=0.060, cos=0.221), tot_loss_proj:2.335 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.325 (perp=10.251, rec=0.052, cos=0.223), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.329 (perp=10.251, rec=0.057, cos=0.222), tot_loss_proj:2.324 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.332 (perp=10.251, rec=0.060, cos=0.222), tot_loss_proj:2.334 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.329 (perp=10.251, rec=0.057, cos=0.222), tot_loss_proj:2.340 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.332 (perp=10.251, rec=0.061, cos=0.221), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.333 (perp=10.251, rec=0.061, cos=0.222), tot_loss_proj:2.341 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.345 (perp=10.251, rec=0.073, cos=0.222), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.331 (perp=10.251, rec=0.059, cos=0.222), tot_loss_proj:2.335 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.340 (perp=10.251, rec=0.067, cos=0.223), tot_loss_proj:2.341 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.342 (perp=10.251, rec=0.070, cos=0.222), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.345 (perp=10.251, rec=0.072, cos=0.223), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.330 (perp=10.251, rec=0.058, cos=0.221), tot_loss_proj:2.337 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.342 (perp=10.251, rec=0.071, cos=0.221), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.332 (perp=10.251, rec=0.060, cos=0.222), tot_loss_proj:2.329 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.326 (perp=10.251, rec=0.055, cos=0.222), tot_loss_proj:2.332 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.342 (perp=10.251, rec=0.069, cos=0.222), tot_loss_proj:2.341 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.330 (perp=10.251, rec=0.058, cos=0.222), tot_loss_proj:2.330 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.336 (perp=10.251, rec=0.063, cos=0.222), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.335 (perp=10.251, rec=0.064, cos=0.222), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.339 (perp=10.251, rec=0.067, cos=0.222), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.334 (perp=10.251, rec=0.062, cos=0.222), tot_loss_proj:2.343 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.324 (perp=10.251, rec=0.053, cos=0.222), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.328 (perp=10.251, rec=0.056, cos=0.222), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.332 (perp=10.251, rec=0.059, cos=0.222), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:08:38 | total time: 0:08:38


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.818405140583238
highest_index [0]
highest [0.818405140583238]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 0.9671605229377747 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9581767916679382 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.9578927159309387 for ['[CLS] consist waterloo [SEP]']
[Init] best rec loss: 0.9548128843307495 for ['[CLS] cas giants [SEP]']
[Init] best rec loss: 0.952214241027832 for ['[CLS] gone honorary [SEP]']
[Init] best rec loss: 0.9521396160125732 for ['[CLS] j native [SEP]']
[Init] best rec loss: 0.9452945590019226 for ['[CLS] vital conflict [SEP]']
[Init] best rec loss: 0.9434597492218018 for ['[CLS] } sex [SEP]']
[Init] best rec loss: 0.935194730758667 for ['[CLS] received mountain [SEP]']
[Init] best rec loss: 0.8795363903045654 for ['[CLS] feeling play [SEP]']
[Init] best rec loss: 0.8413486480712891 for ["[CLS] giant'[SEP]"]
[Init] best perm rec loss: 0.8403337597846985 for ["[CLS]'giant [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=4.101 (perp=12.170, rec=0.675, cos=0.992), tot_loss_proj:3.573 [t=0.22s]
prediction: ['[CLS] brilliantvis [SEP]']
[ 100/2000] tot_loss=3.391 (perp=9.171, rec=0.571, cos=0.986), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 150/2000] tot_loss=3.321 (perp=9.171, rec=0.547, cos=0.940), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 200/2000] tot_loss=3.183 (perp=9.171, rec=0.524, cos=0.825), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.077 (perp=9.171, rec=0.517, cos=0.727), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=3.065 (perp=9.171, rec=0.527, cos=0.703), tot_loss_proj:2.241 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.766 (perp=9.171, rec=0.469, cos=0.463), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.285 (perp=9.171, rec=0.121, cos=0.330), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=2.261 (perp=9.171, rec=0.095, cos=0.332), tot_loss_proj:2.225 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.245 (perp=9.171, rec=0.080, cos=0.330), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.247 (perp=9.171, rec=0.084, cos=0.330), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=2.227 (perp=9.171, rec=0.063, cos=0.330), tot_loss_proj:2.226 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.231 (perp=9.171, rec=0.067, cos=0.330), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.238 (perp=9.171, rec=0.074, cos=0.330), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=2.241 (perp=9.171, rec=0.077, cos=0.330), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.227 (perp=9.171, rec=0.063, cos=0.330), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.229 (perp=9.171, rec=0.065, cos=0.330), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=2.229 (perp=9.171, rec=0.065, cos=0.330), tot_loss_proj:2.217 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.228 (perp=9.171, rec=0.064, cos=0.330), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=2.226 (perp=9.171, rec=0.062, cos=0.330), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=2.223 (perp=9.171, rec=0.060, cos=0.329), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=2.229 (perp=9.171, rec=0.065, cos=0.330), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=2.235 (perp=9.171, rec=0.071, cos=0.330), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=2.213 (perp=9.171, rec=0.048, cos=0.330), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=2.230 (perp=9.171, rec=0.065, cos=0.330), tot_loss_proj:2.217 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=2.221 (perp=9.171, rec=0.057, cos=0.330), tot_loss_proj:2.231 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=2.217 (perp=9.171, rec=0.053, cos=0.330), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=2.213 (perp=9.171, rec=0.049, cos=0.330), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=2.234 (perp=9.171, rec=0.070, cos=0.330), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=2.229 (perp=9.171, rec=0.065, cos=0.330), tot_loss_proj:2.226 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=2.214 (perp=9.171, rec=0.050, cos=0.330), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=2.225 (perp=9.171, rec=0.060, cos=0.330), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=2.231 (perp=9.171, rec=0.067, cos=0.330), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=2.222 (perp=9.171, rec=0.058, cos=0.330), tot_loss_proj:2.246 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=2.222 (perp=9.171, rec=0.058, cos=0.330), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=2.225 (perp=9.171, rec=0.060, cos=0.330), tot_loss_proj:2.249 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=2.215 (perp=9.171, rec=0.050, cos=0.330), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=2.228 (perp=9.171, rec=0.063, cos=0.330), tot_loss_proj:2.231 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=2.226 (perp=9.171, rec=0.061, cos=0.330), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=2.221 (perp=9.171, rec=0.057, cos=0.330), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:08:37 | total time: 0:17:15


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.8600715659740714
highest_index [0]
highest [0.8600715659740714]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.7190197110176086 for ['[CLS] wash〜 at [SEP]']
[Init] best perm rec loss: 0.7164451479911804 for ['[CLS] wash at〜 [SEP]']
[Init] best perm rec loss: 0.7151536345481873 for ['[CLS]〜 at wash [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.443 (perp=9.502, rec=0.282, cos=0.261), tot_loss_proj:2.560 [t=0.22s]
prediction: ['[CLS] gaining momentum momentum [SEP]']
[ 100/2000] tot_loss=2.060 (perp=8.515, rec=0.098, cos=0.259), tot_loss_proj:2.031 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/2000] tot_loss=2.040 (perp=8.515, rec=0.079, cos=0.258), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 200/2000] tot_loss=2.041 (perp=8.515, rec=0.076, cos=0.262), tot_loss_proj:2.031 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.015 (perp=8.515, rec=0.054, cos=0.257), tot_loss_proj:2.032 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=2.036 (perp=8.515, rec=0.073, cos=0.260), tot_loss_proj:2.024 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.031 (perp=8.515, rec=0.065, cos=0.262), tot_loss_proj:2.034 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.028 (perp=8.515, rec=0.066, cos=0.259), tot_loss_proj:2.036 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=2.026 (perp=8.515, rec=0.067, cos=0.256), tot_loss_proj:2.036 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.023 (perp=8.515, rec=0.061, cos=0.259), tot_loss_proj:2.033 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.033 (perp=8.515, rec=0.071, cos=0.259), tot_loss_proj:2.026 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=2.025 (perp=8.515, rec=0.064, cos=0.258), tot_loss_proj:2.026 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.023 (perp=8.515, rec=0.062, cos=0.259), tot_loss_proj:2.036 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.020 (perp=8.515, rec=0.058, cos=0.259), tot_loss_proj:2.035 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=2.029 (perp=8.515, rec=0.066, cos=0.261), tot_loss_proj:2.023 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.033 (perp=8.515, rec=0.072, cos=0.258), tot_loss_proj:2.033 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.022 (perp=8.515, rec=0.061, cos=0.258), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=2.041 (perp=8.515, rec=0.079, cos=0.259), tot_loss_proj:2.028 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.017 (perp=8.515, rec=0.055, cos=0.259), tot_loss_proj:2.041 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=2.022 (perp=8.515, rec=0.061, cos=0.258), tot_loss_proj:2.042 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=2.037 (perp=8.515, rec=0.074, cos=0.260), tot_loss_proj:2.031 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=2.027 (perp=8.515, rec=0.064, cos=0.260), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=2.022 (perp=8.515, rec=0.061, cos=0.259), tot_loss_proj:2.034 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=2.019 (perp=8.515, rec=0.058, cos=0.258), tot_loss_proj:2.032 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=2.026 (perp=8.515, rec=0.063, cos=0.259), tot_loss_proj:2.039 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=2.024 (perp=8.515, rec=0.062, cos=0.259), tot_loss_proj:2.039 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=2.024 (perp=8.515, rec=0.062, cos=0.259), tot_loss_proj:2.045 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=2.023 (perp=8.515, rec=0.060, cos=0.259), tot_loss_proj:2.034 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=2.033 (perp=8.515, rec=0.070, cos=0.259), tot_loss_proj:2.035 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=2.028 (perp=8.515, rec=0.066, cos=0.259), tot_loss_proj:2.044 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=2.028 (perp=8.515, rec=0.066, cos=0.260), tot_loss_proj:2.026 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=2.026 (perp=8.515, rec=0.064, cos=0.259), tot_loss_proj:2.036 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=2.021 (perp=8.515, rec=0.059, cos=0.259), tot_loss_proj:2.029 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=2.026 (perp=8.515, rec=0.064, cos=0.259), tot_loss_proj:2.025 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=2.024 (perp=8.515, rec=0.062, cos=0.259), tot_loss_proj:2.028 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=2.008 (perp=8.515, rec=0.046, cos=0.259), tot_loss_proj:2.025 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=2.021 (perp=8.515, rec=0.058, cos=0.259), tot_loss_proj:2.018 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=2.025 (perp=8.515, rec=0.063, cos=0.259), tot_loss_proj:2.023 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=2.022 (perp=8.515, rec=0.060, cos=0.259), tot_loss_proj:2.032 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=2.027 (perp=8.515, rec=0.066, cos=0.259), tot_loss_proj:2.032 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:08:40 | total time: 0:25:56


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.8246853461199666
highest_index [0]
highest [0.8246853461199666]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.9745897650718689 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.8404653668403625 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8277815580368042 for ['[CLS] lancashire isaac [SEP]']
[Init] best rec loss: 0.7940956950187683 for ['[CLS] end depart [SEP]']
[Init] best perm rec loss: 0.7900323271751404 for ['[CLS] depart end [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.106 (perp=8.385, rec=0.114, cos=0.315), tot_loss_proj:2.091 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 100/2000] tot_loss=2.067 (perp=8.385, rec=0.074, cos=0.316), tot_loss_proj:2.091 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/2000] tot_loss=2.062 (perp=8.385, rec=0.066, cos=0.319), tot_loss_proj:2.092 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 200/2000] tot_loss=2.056 (perp=8.385, rec=0.060, cos=0.319), tot_loss_proj:2.097 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.068 (perp=8.385, rec=0.073, cos=0.318), tot_loss_proj:2.089 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=2.073 (perp=8.385, rec=0.080, cos=0.317), tot_loss_proj:2.090 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.078 (perp=8.385, rec=0.079, cos=0.321), tot_loss_proj:2.081 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.050 (perp=8.385, rec=0.056, cos=0.317), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=2.057 (perp=8.385, rec=0.061, cos=0.319), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.061 (perp=8.385, rec=0.068, cos=0.316), tot_loss_proj:2.094 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.063 (perp=8.385, rec=0.068, cos=0.318), tot_loss_proj:2.092 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=2.066 (perp=8.385, rec=0.070, cos=0.319), tot_loss_proj:2.093 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.050 (perp=8.385, rec=0.053, cos=0.320), tot_loss_proj:2.082 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.053 (perp=8.385, rec=0.057, cos=0.319), tot_loss_proj:2.086 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=2.070 (perp=8.385, rec=0.074, cos=0.319), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.049 (perp=8.385, rec=0.053, cos=0.319), tot_loss_proj:2.095 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.062 (perp=8.385, rec=0.065, cos=0.320), tot_loss_proj:2.090 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=2.057 (perp=8.385, rec=0.062, cos=0.318), tot_loss_proj:2.082 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.063 (perp=8.385, rec=0.069, cos=0.317), tot_loss_proj:2.094 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=2.059 (perp=8.385, rec=0.063, cos=0.319), tot_loss_proj:2.094 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=2.054 (perp=8.385, rec=0.059, cos=0.318), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=2.056 (perp=8.385, rec=0.061, cos=0.318), tot_loss_proj:2.084 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=2.045 (perp=8.385, rec=0.049, cos=0.319), tot_loss_proj:2.087 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=2.060 (perp=8.385, rec=0.064, cos=0.319), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=2.060 (perp=8.385, rec=0.066, cos=0.318), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=2.061 (perp=8.385, rec=0.063, cos=0.321), tot_loss_proj:2.086 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=2.048 (perp=8.385, rec=0.052, cos=0.319), tot_loss_proj:2.097 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=2.060 (perp=8.385, rec=0.065, cos=0.318), tot_loss_proj:2.102 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=2.066 (perp=8.385, rec=0.069, cos=0.320), tot_loss_proj:2.087 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=2.038 (perp=8.385, rec=0.043, cos=0.319), tot_loss_proj:2.086 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=2.064 (perp=8.385, rec=0.067, cos=0.319), tot_loss_proj:2.082 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=2.061 (perp=8.385, rec=0.064, cos=0.320), tot_loss_proj:2.077 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=2.048 (perp=8.385, rec=0.051, cos=0.319), tot_loss_proj:2.087 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=2.052 (perp=8.385, rec=0.055, cos=0.320), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=2.059 (perp=8.385, rec=0.063, cos=0.319), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=2.059 (perp=8.385, rec=0.062, cos=0.320), tot_loss_proj:2.087 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=2.060 (perp=8.385, rec=0.064, cos=0.319), tot_loss_proj:2.073 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=2.050 (perp=8.385, rec=0.054, cos=0.319), tot_loss_proj:2.093 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=2.051 (perp=8.385, rec=0.054, cos=0.319), tot_loss_proj:2.082 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=2.063 (perp=8.385, rec=0.067, cos=0.319), tot_loss_proj:2.087 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:08:36 | total time: 0:34:32


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.8770791843923543
highest_index [0]
highest [0.8770791843923543]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 0.9689635038375854 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9375079274177551 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9214658141136169 for ['[CLS] rally entered worldwide [SEP]']
[Init] best rec loss: 0.9172286987304688 for ['[CLS]dge squareaway [SEP]']
[Init] best rec loss: 0.8812038898468018 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.8673734068870544 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.8643207550048828 for ['[CLS] fatedss jack [SEP]']
[Init] best perm rec loss: 0.8589168190956116 for ['[CLS] jackss fated [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.811 (perp=11.725, rec=0.236, cos=0.230), tot_loss_proj:3.911 [t=0.22s]
prediction: ['[CLS] tires tires tires [SEP]']
[ 100/2000] tot_loss=2.744 (perp=11.725, rec=0.174, cos=0.225), tot_loss_proj:3.895 [t=0.22s]
prediction: ['[CLS] tires tires tires [SEP]']
[ 150/2000] tot_loss=2.029 (perp=8.429, rec=0.115, cos=0.227), tot_loss_proj:2.153 [t=0.22s]
prediction: ['[CLS]ly tiresome [SEP]']
[ 200/2000] tot_loss=1.993 (perp=8.429, rec=0.080, cos=0.227), tot_loss_proj:2.146 [t=0.22s]
prediction: ['[CLS]ly tiresome [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.806 (perp=7.515, rec=0.076, cos=0.226), tot_loss_proj:1.804 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.798 (perp=7.515, rec=0.065, cos=0.230), tot_loss_proj:1.804 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.795 (perp=7.515, rec=0.065, cos=0.227), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.806 (perp=7.515, rec=0.072, cos=0.230), tot_loss_proj:1.809 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.804 (perp=7.515, rec=0.072, cos=0.228), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.793 (perp=7.515, rec=0.061, cos=0.228), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.788 (perp=7.515, rec=0.055, cos=0.229), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.791 (perp=7.515, rec=0.060, cos=0.228), tot_loss_proj:1.820 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.790 (perp=7.515, rec=0.057, cos=0.229), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.793 (perp=7.515, rec=0.060, cos=0.230), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.803 (perp=7.515, rec=0.069, cos=0.230), tot_loss_proj:1.804 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.803 (perp=7.515, rec=0.071, cos=0.229), tot_loss_proj:1.815 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.800 (perp=7.515, rec=0.068, cos=0.229), tot_loss_proj:1.819 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.812 (perp=7.515, rec=0.079, cos=0.229), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.798 (perp=7.515, rec=0.066, cos=0.230), tot_loss_proj:1.814 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.801 (perp=7.515, rec=0.070, cos=0.228), tot_loss_proj:1.806 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.792 (perp=7.515, rec=0.059, cos=0.230), tot_loss_proj:1.809 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.795 (perp=7.515, rec=0.063, cos=0.230), tot_loss_proj:1.811 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.789 (perp=7.515, rec=0.056, cos=0.230), tot_loss_proj:1.814 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.790 (perp=7.515, rec=0.058, cos=0.229), tot_loss_proj:1.812 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.793 (perp=7.515, rec=0.060, cos=0.230), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.800 (perp=7.515, rec=0.068, cos=0.229), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.789 (perp=7.515, rec=0.056, cos=0.230), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.795 (perp=7.515, rec=0.062, cos=0.229), tot_loss_proj:1.819 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.789 (perp=7.515, rec=0.056, cos=0.230), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.794 (perp=7.515, rec=0.061, cos=0.230), tot_loss_proj:1.812 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.797 (perp=7.515, rec=0.064, cos=0.230), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.793 (perp=7.515, rec=0.060, cos=0.230), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.800 (perp=7.515, rec=0.068, cos=0.230), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.788 (perp=7.515, rec=0.055, cos=0.229), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.791 (perp=7.515, rec=0.058, cos=0.229), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.799 (perp=7.515, rec=0.066, cos=0.230), tot_loss_proj:1.804 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.795 (perp=7.515, rec=0.063, cos=0.229), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.795 (perp=7.515, rec=0.062, cos=0.229), tot_loss_proj:1.812 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.793 (perp=7.515, rec=0.060, cos=0.230), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.786 (perp=7.515, rec=0.053, cos=0.230), tot_loss_proj:1.812 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:08:40 | total time: 0:43:12


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.8237368927089457
highest_index [0]
highest [0.8237368927089457]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9833884835243225 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9798309803009033 for ['[CLS]pped jonah [SEP]']
[Init] best rec loss: 0.9578548073768616 for ['[CLS] juathic [SEP]']
[Init] best rec loss: 0.9518065452575684 for ['[CLS] those legs [SEP]']
[Init] best rec loss: 0.9428002834320068 for ['[CLS] preservation notre [SEP]']
[Init] best rec loss: 0.9368445873260498 for ['[CLS] institution wanting [SEP]']
[Init] best rec loss: 0.9304999113082886 for ['[CLS] reid supportive [SEP]']
[Init] best rec loss: 0.916728675365448 for ['[CLS] baby face [SEP]']
[Init] best rec loss: 0.9150830507278442 for ['[CLS] aged sloop [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.869 (perp=12.378, rec=0.711, cos=0.683), tot_loss_proj:4.456 [t=0.22s]
prediction: ['[CLS] ease weakness [SEP]']
[ 100/2000] tot_loss=3.467 (perp=11.370, rec=0.624, cos=0.569), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 150/2000] tot_loss=3.363 (perp=11.370, rec=0.584, cos=0.506), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 200/2000] tot_loss=3.720 (perp=12.066, rec=0.678, cos=0.629), tot_loss_proj:4.502 [t=0.22s]
prediction: ['[CLS] ease spared [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.187 (perp=11.370, rec=0.556, cos=0.357), tot_loss_proj:3.955 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 300/2000] tot_loss=3.155 (perp=11.370, rec=0.515, cos=0.366), tot_loss_proj:3.955 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.421 (perp=11.370, rec=0.631, cos=0.515), tot_loss_proj:3.961 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.139 (perp=11.370, rec=0.515, cos=0.350), tot_loss_proj:3.958 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 450/2000] tot_loss=3.101 (perp=11.370, rec=0.504, cos=0.322), tot_loss_proj:3.958 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.159 (perp=11.370, rec=0.505, cos=0.380), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.169 (perp=11.370, rec=0.509, cos=0.386), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 600/2000] tot_loss=3.115 (perp=11.370, rec=0.528, cos=0.313), tot_loss_proj:3.952 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.083 (perp=11.370, rec=0.489, cos=0.320), tot_loss_proj:3.956 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.074 (perp=11.370, rec=0.478, cos=0.322), tot_loss_proj:3.957 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 750/2000] tot_loss=3.078 (perp=11.370, rec=0.470, cos=0.334), tot_loss_proj:3.951 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.065 (perp=11.370, rec=0.465, cos=0.326), tot_loss_proj:3.949 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.048 (perp=11.370, rec=0.469, cos=0.305), tot_loss_proj:3.956 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 900/2000] tot_loss=3.099 (perp=11.370, rec=0.467, cos=0.357), tot_loss_proj:3.954 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.082 (perp=11.370, rec=0.463, cos=0.345), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1000/2000] tot_loss=3.057 (perp=11.370, rec=0.458, cos=0.324), tot_loss_proj:3.960 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1050/2000] tot_loss=3.136 (perp=11.370, rec=0.481, cos=0.381), tot_loss_proj:3.953 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1100/2000] tot_loss=3.056 (perp=11.370, rec=0.453, cos=0.329), tot_loss_proj:3.955 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1150/2000] tot_loss=3.062 (perp=11.370, rec=0.455, cos=0.333), tot_loss_proj:3.954 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1200/2000] tot_loss=3.055 (perp=11.370, rec=0.453, cos=0.327), tot_loss_proj:3.958 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1250/2000] tot_loss=3.055 (perp=11.370, rec=0.455, cos=0.327), tot_loss_proj:3.958 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1300/2000] tot_loss=2.982 (perp=11.108, rec=0.453, cos=0.308), tot_loss_proj:4.050 [t=0.22s]
prediction: ['[CLS] ease euroleague [SEP]']
[1350/2000] tot_loss=2.995 (perp=11.108, rec=0.459, cos=0.314), tot_loss_proj:4.056 [t=0.22s]
prediction: ['[CLS] ease euroleague [SEP]']
Attempt swap
[1400/2000] tot_loss=2.990 (perp=11.108, rec=0.449, cos=0.319), tot_loss_proj:4.056 [t=0.22s]
prediction: ['[CLS] ease euroleague [SEP]']
Attempt swap
[1450/2000] tot_loss=2.987 (perp=11.108, rec=0.451, cos=0.313), tot_loss_proj:4.057 [t=0.22s]
prediction: ['[CLS] ease euroleague [SEP]']
[1500/2000] tot_loss=2.990 (perp=11.108, rec=0.450, cos=0.318), tot_loss_proj:4.053 [t=0.22s]
prediction: ['[CLS] ease euroleague [SEP]']
Attempt swap
[1550/2000] tot_loss=2.990 (perp=11.108, rec=0.445, cos=0.323), tot_loss_proj:4.061 [t=0.22s]
prediction: ['[CLS] ease euroleague [SEP]']
Attempt swap
[1600/2000] tot_loss=2.988 (perp=11.108, rec=0.447, cos=0.319), tot_loss_proj:4.054 [t=0.22s]
prediction: ['[CLS] ease euroleague [SEP]']
[1650/2000] tot_loss=2.981 (perp=11.108, rec=0.447, cos=0.313), tot_loss_proj:4.059 [t=0.22s]
prediction: ['[CLS] ease euroleague [SEP]']
Attempt swap
[1700/2000] tot_loss=3.193 (perp=12.107, rec=0.446, cos=0.326), tot_loss_proj:3.044 [t=0.22s]
prediction: ['[CLS] ease enjoyed [SEP]']
Attempt swap
[1750/2000] tot_loss=3.195 (perp=12.107, rec=0.448, cos=0.325), tot_loss_proj:3.047 [t=0.22s]
prediction: ['[CLS] ease enjoyed [SEP]']
[1800/2000] tot_loss=3.195 (perp=12.107, rec=0.455, cos=0.319), tot_loss_proj:3.043 [t=0.22s]
prediction: ['[CLS] ease enjoyed [SEP]']
Attempt swap
[1850/2000] tot_loss=3.190 (perp=12.107, rec=0.444, cos=0.325), tot_loss_proj:3.049 [t=0.22s]
prediction: ['[CLS] ease enjoyed [SEP]']
Attempt swap
[1900/2000] tot_loss=3.190 (perp=12.107, rec=0.450, cos=0.318), tot_loss_proj:3.051 [t=0.22s]
prediction: ['[CLS] ease enjoyed [SEP]']
[1950/2000] tot_loss=3.194 (perp=12.107, rec=0.447, cos=0.326), tot_loss_proj:3.051 [t=0.22s]
prediction: ['[CLS] ease enjoyed [SEP]']
Attempt swap
[2000/2000] tot_loss=3.186 (perp=12.107, rec=0.452, cos=0.312), tot_loss_proj:3.039 [t=0.22s]
prediction: ['[CLS] ease enjoyed [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 75.000

[Aggregate metrics]:
rouge1     | fm: 95.833 | p: 95.833 | r: 95.833
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 95.833 | p: 95.833 | r: 95.833
rougeLsum  | fm: 95.833 | p: 95.833 | r: 95.833
r1fm+r2fm = 179.167

input #5 time: 0:08:35 | total time: 0:51:48


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.8920530000833208
highest_index [0]
highest [0.8920530000833208]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.923704981803894 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9230707287788391 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.9181998372077942 for ['[CLS] main natural [SEP]']
[Init] best rec loss: 0.7935240864753723 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.7778112888336182 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.7580386400222778 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.7283764481544495 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7027269601821899 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.6904414296150208 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 0.6899240612983704 for ['[CLS] demolition tre [SEP]']
[Init] best rec loss: 0.6566449403762817 for ['[CLS] double deep [SEP]']
[Init] best perm rec loss: 0.6556487679481506 for ['[CLS] deep double [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.471 (perp=10.460, rec=0.182, cos=0.196), tot_loss_proj:2.724 [t=0.22s]
prediction: ['[CLS]ish gray [SEP]']
[ 100/2000] tot_loss=2.380 (perp=10.460, rec=0.084, cos=0.204), tot_loss_proj:2.712 [t=0.22s]
prediction: ['[CLS]ish gray [SEP]']
[ 150/2000] tot_loss=2.372 (perp=10.460, rec=0.081, cos=0.199), tot_loss_proj:2.725 [t=0.22s]
prediction: ['[CLS]ish gray [SEP]']
[ 200/2000] tot_loss=2.357 (perp=10.460, rec=0.060, cos=0.205), tot_loss_proj:2.717 [t=0.22s]
prediction: ['[CLS]ish gray [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.894 (perp=8.088, rec=0.074, cos=0.202), tot_loss_proj:1.905 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.891 (perp=8.088, rec=0.071, cos=0.203), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.874 (perp=8.088, rec=0.055, cos=0.202), tot_loss_proj:1.897 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.888 (perp=8.088, rec=0.067, cos=0.203), tot_loss_proj:1.897 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.889 (perp=8.088, rec=0.071, cos=0.200), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.884 (perp=8.088, rec=0.062, cos=0.204), tot_loss_proj:1.889 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.893 (perp=8.088, rec=0.073, cos=0.202), tot_loss_proj:1.889 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.890 (perp=8.088, rec=0.068, cos=0.204), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.882 (perp=8.088, rec=0.061, cos=0.203), tot_loss_proj:1.896 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.888 (perp=8.088, rec=0.068, cos=0.202), tot_loss_proj:1.901 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.888 (perp=8.088, rec=0.068, cos=0.203), tot_loss_proj:1.901 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.881 (perp=8.088, rec=0.060, cos=0.204), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.881 (perp=8.088, rec=0.060, cos=0.204), tot_loss_proj:1.895 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.886 (perp=8.088, rec=0.064, cos=0.204), tot_loss_proj:1.901 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.884 (perp=8.088, rec=0.062, cos=0.204), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.891 (perp=8.088, rec=0.071, cos=0.203), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.881 (perp=8.088, rec=0.060, cos=0.203), tot_loss_proj:1.900 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.871 (perp=8.088, rec=0.051, cos=0.202), tot_loss_proj:1.896 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.880 (perp=8.088, rec=0.060, cos=0.202), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.886 (perp=8.088, rec=0.066, cos=0.203), tot_loss_proj:1.901 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.891 (perp=8.088, rec=0.070, cos=0.203), tot_loss_proj:1.888 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.884 (perp=8.088, rec=0.063, cos=0.204), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.887 (perp=8.088, rec=0.067, cos=0.202), tot_loss_proj:1.897 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.876 (perp=8.088, rec=0.055, cos=0.203), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.872 (perp=8.088, rec=0.051, cos=0.204), tot_loss_proj:1.886 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.879 (perp=8.088, rec=0.059, cos=0.202), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.874 (perp=8.088, rec=0.054, cos=0.203), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.880 (perp=8.088, rec=0.060, cos=0.203), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.886 (perp=8.088, rec=0.065, cos=0.203), tot_loss_proj:1.895 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.881 (perp=8.088, rec=0.060, cos=0.204), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.879 (perp=8.088, rec=0.058, cos=0.203), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.886 (perp=8.088, rec=0.064, cos=0.203), tot_loss_proj:1.895 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.888 (perp=8.088, rec=0.067, cos=0.203), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.881 (perp=8.088, rec=0.059, cos=0.204), tot_loss_proj:1.906 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.883 (perp=8.088, rec=0.061, cos=0.204), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.884 (perp=8.088, rec=0.062, cos=0.204), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 96.429 | p: 96.429 | r: 96.429
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 96.429 | p: 96.429 | r: 96.429
rougeLsum  | fm: 96.429 | p: 96.429 | r: 96.429
r1fm+r2fm = 182.143

input #6 time: 0:08:35 | total time: 1:00:23


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9034775206296766
highest_index [0]
highest [0.9034775206296766]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.8682743906974792 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8100349307060242 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.802682101726532 for ['[CLS] strengths kenton bond victimsmined absent se sides deed gavin making resides renewed magic antarctica clarebalance gaingnapressive need another easy fell race merged [SEP]']
[Init] best rec loss: 0.7935725450515747 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best rec loss: 0.7881603837013245 for ['[CLS] ni maintained micro aces echo all behind legal somethingelli stanley park d conspiracy medicine childbation jobtative hop rule fighting early twins sykes line [SEP]']
[Init] best perm rec loss: 0.7874420881271362 for ['[CLS] fighting rule micro legal maintained echo dtative hop ni medicinebation behind park sykeselli job child line all early twins conspiracy something stanley aces [SEP]']
[Init] best perm rec loss: 0.7873257398605347 for ['[CLS] job echo micro fighting stanley conspiracy sykes ni d rule maintainedelli hop medicine earlybation legal line all behind childtative park aces twins something [SEP]']
[Init] best perm rec loss: 0.7859705090522766 for ['[CLS] medicine aces park behind line legal child fighting sykes allelli twinstative maintained early something stanley dbation rule job conspiracy echo ni hop micro [SEP]']
[Init] best perm rec loss: 0.7823374271392822 for ['[CLS] job aces line microbation stanley ni child legal d behind something early maintained sykes conspiracy park fighting twins hop all rule echo medicinetativeelli [SEP]']
[Init] best perm rec loss: 0.7801215052604675 for ['[CLS] sykes conspiracy hop park maintained lineelli ni d child behind stanley echo legal job early medicine microtativebation twins all rule aces something fighting [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.656 (perp=10.913, rec=0.289, cos=0.185), tot_loss_proj:3.240 [t=0.22s]
prediction: ['[CLS] leave prohibited my foreignless character to somewhere no theft tube problem problem its is worst factor not aires character problem he no by being were [SEP]']
[ 100/2000] tot_loss=2.380 (perp=9.766, rec=0.251, cos=0.176), tot_loss_proj:3.377 [t=0.22s]
prediction: ['[CLS] conditions rarely no id or education situations it not the after not problem the is problem factor standard samuel character. he no and value, [SEP]']
[ 150/2000] tot_loss=2.279 (perp=9.513, rec=0.197, cos=0.180), tot_loss_proj:3.636 [t=0.22s]
prediction: ['[CLS] problem no no nightingale or character care it for the. not problem ; is problem factor standard ) character. has no and love it [SEP]']
[ 200/2000] tot_loss=2.075 (perp=8.674, rec=0.168, cos=0.173), tot_loss_proj:2.686 [t=0.22s]
prediction: ['[CLS] ugly no no an or character care it. the ugly not problem ; is problem factor standard alley character. he no or love, [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.974 (perp=8.033, rec=0.197, cos=0.171), tot_loss_proj:2.593 [t=0.22s]
prediction: ['[CLS]. lack no - or character get easy or the ugly not problem ; is problem factor that character. he no touchdown or love it [SEP]']
[ 300/2000] tot_loss=1.980 (perp=8.054, rec=0.194, cos=0.175), tot_loss_proj:2.535 [t=0.22s]
prediction: ['[CLS]. no no - or character appreciated physical or the ugly not problem ; is problem factor that character. he no ) or love, [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.960 (perp=8.093, rec=0.164, cos=0.178), tot_loss_proj:2.529 [t=0.22s]
prediction: ['[CLS]. he no - or character cute physical or the ugly not problem ; is problem factor that character. no no1 or love, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.887 (perp=7.761, rec=0.159, cos=0.176), tot_loss_proj:2.466 [t=0.22s]
prediction: ['[CLS]. he no. or factor cute physical or the ugly factor problem ; is problem not that character that no no :. love, [SEP]']
[ 450/2000] tot_loss=1.849 (perp=7.633, rec=0.143, cos=0.179), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS]. he no. or factor cute physical or the ugly factor problem ; is problem not that character. is no1. love, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.784 (perp=7.313, rec=0.148, cos=0.174), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS]. he no character or factor cute physical or the ugly factor problem ; is problem not that.. is no i. love, [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.647 (perp=6.671, rec=0.136, cos=0.177), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS]. he no character or cute factor. or the ugly factor problem ; is problem not that.. is no i. love, [SEP]']
[ 600/2000] tot_loss=1.609 (perp=6.501, rec=0.130, cos=0.179), tot_loss_proj:2.439 [t=0.22s]
prediction: ['[CLS]. he no character or cute factor. or the ugly factor problem ; is problem not that.. is no best. love, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.625 (perp=6.622, rec=0.123, cos=0.177), tot_loss_proj:3.133 [t=0.22s]
prediction: ['[CLS]. he no character or cute factor. or the ugly factor problem ; is problem not that. no. is best, love, [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.642 (perp=6.704, rec=0.122, cos=0.179), tot_loss_proj:2.197 [t=0.22s]
prediction: ['[CLS]. he no character or cute factor. or the ugly factor problem ; is problem not that. no that love best, is, [SEP]']
[ 750/2000] tot_loss=1.606 (perp=6.525, rec=0.119, cos=0.182), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS]. he no character or cute factor. or the ugly factor problem ; is problem not that. no. love fiction, is, [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.595 (perp=6.447, rec=0.125, cos=0.180), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS]. he no character or cute factor. or the ugly factor ; problem is problem not that. no. love fiction, is, [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.571 (perp=6.342, rec=0.122, cos=0.180), tot_loss_proj:2.141 [t=0.22s]
prediction: ['[CLS] he no character. or cute factor. or the ugly factor ; problem is problem not that. no that love alice, is, [SEP]']
[ 900/2000] tot_loss=1.501 (perp=6.057, rec=0.110, cos=0.180), tot_loss_proj:2.376 [t=0.22s]
prediction: ['[CLS] he no character. or cute factor. or the ugly factor ; problem is problem not that. no. love alice, is, [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.527 (perp=6.186, rec=0.110, cos=0.180), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] he no character. or cute factor, or the ugly factor ; problem is problem not that. no. love alice, is - [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.468 (perp=5.884, rec=0.112, cos=0.179), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] he no character. or cute factor, or the ugly factor ; is problem problem not that. no. loveable, is, [SEP]']
[1050/2000] tot_loss=1.597 (perp=6.546, rec=0.107, cos=0.181), tot_loss_proj:2.190 [t=0.22s]
prediction: ['[CLS] he no character. or cute factorable or the ugly factor ; is problem problem not that. no. loveable, is, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.597 (perp=6.546, rec=0.109, cos=0.179), tot_loss_proj:2.189 [t=0.22s]
prediction: ['[CLS] he no character. or cute factorable or the ugly factor ; is problem problem not that. no. loveable, is, [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.540 (perp=6.244, rec=0.109, cos=0.182), tot_loss_proj:2.146 [t=0.22s]
prediction: ['[CLS] he no character. or cute factor or the ugly factor ; is problemable problem not that. no. loveable, here, [SEP]']
[1200/2000] tot_loss=1.533 (perp=6.244, rec=0.101, cos=0.183), tot_loss_proj:2.140 [t=0.22s]
prediction: ['[CLS] he no character. or cute factor or the ugly factor ; is problemable problem not that. no. loveable, here, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.533 (perp=6.244, rec=0.105, cos=0.179), tot_loss_proj:2.143 [t=0.22s]
prediction: ['[CLS] he no character. or cute factor or the ugly factor ; is problemable problem not that. no. loveable, here, [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.528 (perp=6.246, rec=0.098, cos=0.180), tot_loss_proj:2.116 [t=0.22s]
prediction: ['[CLS] he no character. or cute factor or the ugly factor ; is problem problemable not that. no. loveable, here, [SEP]']
[1350/2000] tot_loss=1.542 (perp=6.246, rec=0.111, cos=0.181), tot_loss_proj:2.123 [t=0.22s]
prediction: ['[CLS] he no character. or cute factor or the ugly factor ; is problem problemable not that. no. loveable, here, [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.494 (perp=6.035, rec=0.108, cos=0.179), tot_loss_proj:2.029 [t=0.22s]
prediction: ['[CLS] he no character, or cute factor or the ugly factor ; is problem problemable not that. no. loveable, here. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.533 (perp=6.239, rec=0.104, cos=0.181), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] he no character, or cute factor or the ugly factor ; is problem problemable not mind. no. loveable, here. [SEP]']
[1500/2000] tot_loss=1.526 (perp=6.239, rec=0.097, cos=0.182), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] he no character, or cute factor or the ugly factor ; is problem problemable not mind. no. loveable, here. [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.493 (perp=6.033, rec=0.104, cos=0.182), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] he no character, or the cute factor or ugly factor ; is problem problemable not mind. no. loveable, here. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.487 (perp=6.033, rec=0.100, cos=0.181), tot_loss_proj:2.178 [t=0.23s]
prediction: ['[CLS] he no character, or the cute factor or ugly factor ; is problem problemable not mind. no. loveable, here. [SEP]']
[1650/2000] tot_loss=1.495 (perp=6.033, rec=0.107, cos=0.181), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] he no character, or the cute factor or ugly factor ; is problem problemable not mind. no. loveable, here. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.465 (perp=5.889, rec=0.106, cos=0.181), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] he no character, or the cute factor or ugly factor ; is problem problemable. not mind. no loveable, here. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.455 (perp=5.889, rec=0.096, cos=0.181), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] he no character, or the cute factor or ugly factor ; is problem problemable. not mind. no loveable, here. [SEP]']
[1800/2000] tot_loss=1.461 (perp=5.889, rec=0.101, cos=0.182), tot_loss_proj:2.056 [t=0.22s]
prediction: ['[CLS] he no character, or the cute factor or ugly factor ; is problem problemable. not mind. no loveable, here. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.433 (perp=5.732, rec=0.105, cos=0.182), tot_loss_proj:1.962 [t=0.22s]
prediction: ['[CLS] he no character, or the cute factor or ugly factor ; is problem problemable. no mind. not loveable, here. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.430 (perp=5.732, rec=0.103, cos=0.181), tot_loss_proj:1.963 [t=0.22s]
prediction: ['[CLS] he no character, or the cute factor or ugly factor ; is problem problemable. no mind. not loveable, here. [SEP]']
[1950/2000] tot_loss=1.427 (perp=5.732, rec=0.099, cos=0.182), tot_loss_proj:1.958 [t=0.22s]
prediction: ['[CLS] he no character, or the cute factor or ugly factor ; is problem problemable. no mind. not loveable, here. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.420 (perp=5.683, rec=0.102, cos=0.181), tot_loss_proj:1.936 [t=0.22s]
prediction: ['[CLS] he no character. or the cute factor or ugly factor ; is problem problemable. no mind, not loveable, here. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] he no character, or cute factor or the ugly factor ; is problem problemable not mind. no. loveable, here. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.927 | p: 85.000 | r: 80.952
rouge2     | fm: 10.256 | p: 10.526 | r: 10.000
rougeL     | fm: 43.902 | p: 45.000 | r: 42.857
rougeLsum  | fm: 43.902 | p: 45.000 | r: 42.857
r1fm+r2fm = 93.183

[Aggregate metrics]:
rouge1     | fm: 94.741 | p: 95.000 | r: 94.494
rouge2     | fm: 76.282 | p: 76.316 | r: 76.250
rougeL     | fm: 89.863 | p: 90.000 | r: 89.732
rougeLsum  | fm: 89.863 | p: 90.000 | r: 89.732
r1fm+r2fm = 171.023

input #7 time: 0:08:46 | total time: 1:09:10


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9068334314310705
highest_index [0]
highest [0.9068334314310705]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.6729341745376587 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.6681644320487976 for ['[CLS] behalf eireann pts ask solutionog rhythm revived sky bonus derek yet affairsstick weird meaning now wellverse beforeα arterial centuries network [SEP]']
[Init] best rec loss: 0.6619698405265808 for ['[CLS] breed app king jude rome am regal roman grown levi mine fitting peninsula cappella age bulldogs component founder macarthur unionist overturegible raysstock [SEP]']
[Init] best rec loss: 0.6571942567825317 for ['[CLS] vin figure blowgger note mission [CLS] planet outside xi awardhe collections work money... unsuccessful canon ob brainally street wheat shortly [SEP]']
[Init] best rec loss: 0.647824227809906 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best perm rec loss: 0.6457983255386353 for ['[CLS] checkpoint awesome virginia treated lined quota casesencies lindsey frowned won roots judgedant perspective think dated discus conference prizemeric colour labor americas [SEP]']
[Init] best perm rec loss: 0.644864559173584 for ['[CLS] discus americas awesome won labor lined virginiadant judge thinkencies conference cases treated dated lindsey perspective roots checkpoint quota colour prizemeric frowned [SEP]']
[Init] best perm rec loss: 0.6448553800582886 for ['[CLS] virginia wondant rootsmeric cases lined labor judge frowned conferenceencies quota colour lindsey awesome discus checkpoint dated treated think americas prize perspective [SEP]']
[Init] best perm rec loss: 0.6446353197097778 for ['[CLS] quota awesomedant checkpoint frownedmeric won labor americas judge lined lindsey think perspective cases conferenceencies discus roots virginia prize colour treated dated [SEP]']
[Init] best perm rec loss: 0.6438678503036499 for ['[CLS] labor cases lindsey checkpoint frowned prizeencies won judge roots conferencedant lined dated americas virginia thinkmeric discus colour awesome perspective treated quota [SEP]']
[Init] best perm rec loss: 0.6434326767921448 for ['[CLS]meric awesome treated discus dated roots lined conference judge think cases colour frowned virginiaencies checkpoint lindsey perspective won labordant americas quota prize [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.030 (perp=12.493, rec=0.339, cos=0.193), tot_loss_proj:3.812 [t=0.22s]
prediction: ['[CLS] frightful vanity vanity fan film vanity film ju vanity smart hardly doubt beaux film old taxes investment repertory whatever vanity corporate vanity pay [SEP]']
[ 100/2000] tot_loss=2.750 (perp=11.622, rec=0.270, cos=0.156), tot_loss_proj:3.571 [t=0.22s]
prediction: ['[CLS] frightful vanity vanity production film vanity film increasingly fright smart no doubt paid film whatever paid debt repertory owe vanity film vanity pays [SEP]']
[ 150/2000] tot_loss=2.711 (perp=11.445, rec=0.238, cos=0.185), tot_loss_proj:3.635 [t=0.22s]
prediction: ['[CLS] frightful vanity vanity film film vanity films, fright vanity no doubt contribute film what debt debt stimulus owed vanity film benign pays [SEP]']
[ 200/2000] tot_loss=2.751 (perp=11.561, rec=0.254, cos=0.185), tot_loss_proj:3.859 [t=0.22s]
prediction: ['[CLS] frighting vanity vanity film south vanity that ェ fright a no doubt off film what debts debt. would vanity dish benign pays [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.602 (perp=11.022, rec=0.222, cos=0.177), tot_loss_proj:3.656 [t=0.22s]
prediction: ['[CLS] frighting vanity filmthic vanity that ェ fright a no doubt kidding vanity film what debt debt, owe vanity film benign pays [SEP]']
[ 300/2000] tot_loss=2.490 (perp=10.722, rec=0.178, cos=0.168), tot_loss_proj:3.630 [t=0.22s]
prediction: ["[CLS] frightful vanity film'vanity that ェ fright a no doubt, vanity film what debt debt, redding vanity film benign pays [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.427 (perp=10.406, rec=0.176, cos=0.169), tot_loss_proj:3.509 [t=0.22s]
prediction: ["[CLS] frightful vanity film'max that ェ fright a no doubt, vanity film what debt debt, vanity vanity film benign pays [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.423 (perp=10.345, rec=0.183, cos=0.170), tot_loss_proj:3.443 [t=0.22s]
prediction: ['[CLS] frightful vanity filmthicmax that ェ fright a no doubt, vanity film what debt debt, vanity film benign vanity pays [SEP]']
[ 450/2000] tot_loss=2.572 (perp=11.226, rec=0.156, cos=0.171), tot_loss_proj:3.573 [t=0.22s]
prediction: ['[CLS] frightful vanity filmthicmax that ェ fright a no doubt,§ film what debt debti benign film benign vanity pays [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.432 (perp=10.469, rec=0.168, cos=0.170), tot_loss_proj:3.313 [t=0.22s]
prediction: ['[CLS] a frightful vanity filmthicmax that ェ fright no doubt, 場 film what debt debti benign and benign vanity pays [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.335 (perp=10.045, rec=0.155, cos=0.172), tot_loss_proj:3.223 [t=0.22s]
prediction: ['[CLS] a frightful vanity filmthic fright that ェmax no doubt, ェ film what debt debti benign and benign vanity pays [SEP]']
[ 600/2000] tot_loss=2.409 (perp=10.423, rec=0.154, cos=0.170), tot_loss_proj:3.404 [t=0.22s]
prediction: ['[CLS] a frightful vanity filmthic fright that ェmax no doubt, ェ film what debt debti benign film benign vanity pays [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.406 (perp=10.468, rec=0.142, cos=0.171), tot_loss_proj:3.506 [t=0.22s]
prediction: ['[CLS] a frightful vanity filmthic fright that ェmax off doubt, no film what debt debti benign film benign vanity pays [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.370 (perp=10.309, rec=0.137, cos=0.171), tot_loss_proj:3.501 [t=0.22s]
prediction: ['[CLS] a frightful vanity filmthic fright that ェmax doubt, no off film what debt debti benign film benign vanity pays [SEP]']
[ 750/2000] tot_loss=2.369 (perp=10.309, rec=0.137, cos=0.170), tot_loss_proj:3.500 [t=0.22s]
prediction: ['[CLS] a frightful vanity filmthic fright that ェmax doubt, no off film what debt debti benign film benign vanity pays [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.365 (perp=10.312, rec=0.132, cos=0.170), tot_loss_proj:3.533 [t=0.22s]
prediction: ['[CLS] a frightful vanity filmsthic fright that ェ doubt, no offmax film what debt debti benign film benign vanity pays [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.343 (perp=10.172, rec=0.137, cos=0.172), tot_loss_proj:3.466 [t=0.22s]
prediction: ['[CLS] a frightful vanity films off fright that ェ doubt, nothicmax film what debt debti benign film benign vanity pays [SEP]']
[ 900/2000] tot_loss=2.345 (perp=10.172, rec=0.131, cos=0.180), tot_loss_proj:3.466 [t=0.22s]
prediction: ['[CLS] a frightful vanity films off fright that ェ doubt, nothicmax film what debt debti benign film benign vanity pays [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.293 (perp=9.945, rec=0.130, cos=0.174), tot_loss_proj:3.470 [t=0.22s]
prediction: ['[CLS] a frightful vanity films off fright that ェ doubt, nothicmax film what benign debt debti benign film vanity pays [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.317 (perp=10.075, rec=0.130, cos=0.172), tot_loss_proj:3.578 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off fright that ェ doubt, nothicmax film what benign debti benign film debt vanity pays [SEP]']
[1050/2000] tot_loss=2.315 (perp=10.075, rec=0.125, cos=0.175), tot_loss_proj:3.580 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off fright that ェ doubt, nothicmax film what benign debti benign film debt vanity pays [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.282 (perp=9.903, rec=0.126, cos=0.176), tot_loss_proj:3.491 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ doubt, no felt frightmax film what benign debti benign film debt vanity pays [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.202 (perp=9.523, rec=0.122, cos=0.176), tot_loss_proj:3.460 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ doubt, no frightmax film what benign debti felt benign film debt vanity pays [SEP]']
[1200/2000] tot_loss=2.286 (perp=9.959, rec=0.117, cos=0.177), tot_loss_proj:3.597 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ doubt, no frightmax film what owed debti felt benign film debt vanity pays [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.203 (perp=9.536, rec=0.123, cos=0.173), tot_loss_proj:3.419 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ doubt, no fright owed film whatmax debti felt benign film debt vanity pays [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.178 (perp=9.393, rec=0.125, cos=0.175), tot_loss_proj:3.450 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ doubt, no fright pays film whatmax debti felt benign film debt vanity owed [SEP]']
[1350/2000] tot_loss=2.212 (perp=9.602, rec=0.117, cos=0.175), tot_loss_proj:3.473 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ doubt, no fright pays film whatmax [SEP]i felt benign film debt vanity owed [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.164 (perp=9.339, rec=0.120, cos=0.176), tot_loss_proj:3.520 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ doubt, no fright pays what filmmax [SEP]i felt benign film debt vanity owed [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.137 (perp=9.220, rec=0.118, cos=0.176), tot_loss_proj:3.065 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i felt benign film debt vanity owed [SEP]']
[1500/2000] tot_loss=2.148 (perp=9.220, rec=0.127, cos=0.176), tot_loss_proj:3.059 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i felt benign film debt vanity owed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.139 (perp=9.220, rec=0.119, cos=0.176), tot_loss_proj:3.064 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i felt benign film debt vanity owed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.141 (perp=9.220, rec=0.120, cos=0.177), tot_loss_proj:3.058 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i felt benign film debt vanity owed [SEP]']
[1650/2000] tot_loss=2.140 (perp=9.220, rec=0.119, cos=0.177), tot_loss_proj:3.059 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i felt benign film debt vanity owed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.141 (perp=9.220, rec=0.119, cos=0.178), tot_loss_proj:3.065 [t=0.22s]
prediction: ['[CLS] a frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i felt benign film debt vanity owed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.261 (perp=9.857, rec=0.113, cos=0.176), tot_loss_proj:3.196 [t=0.22s]
prediction: ['[CLS] s frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i felt benign film debt vanity owed [SEP]']
[1800/2000] tot_loss=2.265 (perp=9.857, rec=0.118, cos=0.175), tot_loss_proj:3.193 [t=0.22s]
prediction: ['[CLS] s frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i felt benign film debt vanity owed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.264 (perp=9.857, rec=0.116, cos=0.176), tot_loss_proj:3.195 [t=0.22s]
prediction: ['[CLS] s frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i felt benign film debt vanity owed [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.261 (perp=9.819, rec=0.120, cos=0.177), tot_loss_proj:3.124 [t=0.22s]
prediction: ['[CLS] s frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i debt felt benign film vanity owed [SEP]']
[1950/2000] tot_loss=2.256 (perp=9.819, rec=0.117, cos=0.175), tot_loss_proj:3.125 [t=0.22s]
prediction: ['[CLS] s frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i debt felt benign film vanity owed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.260 (perp=9.819, rec=0.121, cos=0.175), tot_loss_proj:3.127 [t=0.22s]
prediction: ['[CLS] s frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i debt felt benign film vanity owed [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] s frightful vanitymax off that ェ fright, no doubt pays what filmmax [SEP]i felt benign film debt vanity owed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.171 | p: 71.429 | r: 75.000
rouge2     | fm: 15.385 | p: 15.000 | r: 15.789
rougeL     | fm: 53.659 | p: 52.381 | r: 55.000
rougeLsum  | fm: 53.659 | p: 52.381 | r: 55.000
r1fm+r2fm = 88.555

[Aggregate metrics]:
rouge1     | fm: 92.344 | p: 92.381 | r: 92.328
rouge2     | fm: 69.516 | p: 69.503 | r: 69.532
rougeL     | fm: 85.840 | p: 85.820 | r: 85.873
rougeLsum  | fm: 85.840 | p: 85.820 | r: 85.873
r1fm+r2fm = 161.860

input #8 time: 0:08:45 | total time: 1:17:56


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.914058789966407
highest_index [0]
highest [0.914058789966407]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.7718520164489746 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.6967103481292725 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.6951975226402283 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.6771177053451538 for ['[CLS] military offered fragments gathered leaning sphere rom legs [SEP]']
[Init] best rec loss: 0.6629930734634399 for ['[CLS] ham ice command across see beatty anal tan [SEP]']
[Init] best rec loss: 0.6548980474472046 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best rec loss: 0.6546010375022888 for ['[CLS] save california liquidstownabiing plain for [SEP]']
[Init] best perm rec loss: 0.6521046161651611 for ['[CLS] liquidstown plain forabi california saveing [SEP]']
[Init] best perm rec loss: 0.6495072841644287 for ['[CLS] california liquidabi save plainstowning for [SEP]']
[Init] best perm rec loss: 0.6490519046783447 for ['[CLS] liquidstown plaining save for californiaabi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.087 (perp=12.842, rec=0.315, cos=0.203), tot_loss_proj:3.990 [t=0.22s]
prediction: ['[CLS] groups bandenna shiftinger clapט brother [SEP]']
[ 100/2000] tot_loss=2.697 (perp=11.435, rec=0.241, cos=0.168), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] metaphysical claplellan softer claptrahead [SEP]']
[ 150/2000] tot_loss=2.397 (perp=10.338, rec=0.186, cos=0.143), tot_loss_proj:2.916 [t=0.22s]
prediction: ['[CLS] metaphysicaletpped softhead claptrap [SEP]']
[ 200/2000] tot_loss=2.199 (perp=9.464, rec=0.147, cos=0.160), tot_loss_proj:2.735 [t=0.22s]
prediction: ['[CLS] metaphysical ofpath softhead claptrap [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.071 (perp=9.018, rec=0.113, cos=0.154), tot_loss_proj:2.608 [t=0.22s]
prediction: ['[CLS]head of metaphysical softhead claptrap [SEP]']
[ 300/2000] tot_loss=2.058 (perp=9.018, rec=0.089, cos=0.166), tot_loss_proj:2.598 [t=0.22s]
prediction: ['[CLS]head of metaphysical softhead claptrap [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.939 (perp=8.431, rec=0.090, cos=0.163), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS]head of softhead metaphysical claptrap [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.936 (perp=8.431, rec=0.091, cos=0.159), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS]head of softhead metaphysical claptrap [SEP]']
[ 450/2000] tot_loss=1.920 (perp=8.431, rec=0.076, cos=0.158), tot_loss_proj:2.416 [t=0.22s]
prediction: ['[CLS]head of softhead metaphysical claptrap [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.933 (perp=8.431, rec=0.084, cos=0.163), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS]head of softhead metaphysical claptrap [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.895 (perp=8.203, rec=0.100, cos=0.154), tot_loss_proj:2.487 [t=0.22s]
prediction: ['[CLS]headhead of soft metaphysical claptrap [SEP]']
[ 600/2000] tot_loss=1.897 (perp=8.203, rec=0.095, cos=0.162), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS]headhead of soft metaphysical claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.895 (perp=8.203, rec=0.090, cos=0.165), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS]headhead of soft metaphysical claptrap [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.837 (perp=7.926, rec=0.093, cos=0.159), tot_loss_proj:2.299 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
[ 750/2000] tot_loss=1.832 (perp=7.926, rec=0.087, cos=0.160), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.819 (perp=7.926, rec=0.074, cos=0.160), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.826 (perp=7.926, rec=0.078, cos=0.162), tot_loss_proj:2.288 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
[ 900/2000] tot_loss=1.815 (perp=7.926, rec=0.072, cos=0.157), tot_loss_proj:2.288 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.819 (perp=7.926, rec=0.077, cos=0.157), tot_loss_proj:2.283 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.827 (perp=7.926, rec=0.078, cos=0.164), tot_loss_proj:2.288 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
[1050/2000] tot_loss=1.820 (perp=7.926, rec=0.072, cos=0.162), tot_loss_proj:2.278 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.810 (perp=7.926, rec=0.066, cos=0.159), tot_loss_proj:2.286 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.821 (perp=7.926, rec=0.074, cos=0.162), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
[1200/2000] tot_loss=1.818 (perp=7.926, rec=0.071, cos=0.162), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.815 (perp=7.926, rec=0.068, cos=0.162), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.823 (perp=7.926, rec=0.076, cos=0.162), tot_loss_proj:2.282 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
[1350/2000] tot_loss=1.823 (perp=7.926, rec=0.076, cos=0.162), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.819 (perp=7.926, rec=0.073, cos=0.161), tot_loss_proj:2.281 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.816 (perp=7.926, rec=0.069, cos=0.162), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
[1500/2000] tot_loss=1.811 (perp=7.926, rec=0.065, cos=0.161), tot_loss_proj:2.278 [t=0.22s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.753 (perp=7.643, rec=0.064, cos=0.160), tot_loss_proj:1.773 [t=0.22s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.759 (perp=7.643, rec=0.069, cos=0.161), tot_loss_proj:1.779 [t=0.22s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
[1650/2000] tot_loss=1.752 (perp=7.643, rec=0.062, cos=0.161), tot_loss_proj:1.793 [t=0.22s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.711 (perp=7.384, rec=0.076, cos=0.158), tot_loss_proj:1.811 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.697 (perp=7.384, rec=0.063, cos=0.158), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1800/2000] tot_loss=1.701 (perp=7.384, rec=0.065, cos=0.160), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.702 (perp=7.384, rec=0.066, cos=0.159), tot_loss_proj:1.805 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.712 (perp=7.384, rec=0.075, cos=0.161), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1950/2000] tot_loss=1.717 (perp=7.384, rec=0.078, cos=0.162), tot_loss_proj:1.813 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.700 (perp=7.384, rec=0.063, cos=0.160), tot_loss_proj:1.813 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS]headed of soft metaphysical claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 113.287

[Aggregate metrics]:
rouge1     | fm: 90.802 | p: 90.286 | r: 91.429
rouge2     | fm: 66.200 | p: 65.886 | r: 66.579
rougeL     | fm: 85.131 | p: 84.738 | r: 86.000
rougeLsum  | fm: 85.122 | p: 84.381 | r: 86.000
r1fm+r2fm = 157.003

input #9 time: 0:08:39 | total time: 1:26:35


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.8382012460326256
highest_index [0]
highest [0.8382012460326256]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8400655388832092 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8275138735771179 for ['[CLS] university mitaonaefa never existing gym backed ribs realmsund odd [SEP]']
[Init] best rec loss: 0.7916107773780823 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.6841160655021667 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 0.6802246570587158 for ['[CLS] themes up sheep blessedblood angel common orderoric places totally level sound [SEP]']
[Init] best perm rec loss: 0.6786757707595825 for ['[CLS] totally angel themesblood order sheep places level blessedoric sound up common [SEP]']
[Init] best perm rec loss: 0.6775832176208496 for ['[CLS] blessed orderoric sound up common totally themes angel places sheepblood level [SEP]']
[Init] best perm rec loss: 0.6755543351173401 for ['[CLS] sound themes totally up blessed sheep common order angel placesoric levelblood [SEP]']
[Init] best perm rec loss: 0.6755412817001343 for ['[CLS] soundbloodoric common level totally order up themes places sheep angel blessed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.614 (perp=10.067, rec=0.306, cos=0.295), tot_loss_proj:3.085 [t=0.22s]
prediction: ['[CLS] innovation moved truth middle ably without tensions balanceo message resolution. [SEP]']
[ 100/2000] tot_loss=2.547 (perp=10.450, rec=0.180, cos=0.278), tot_loss_proj:3.246 [t=0.22s]
prediction: ['[CLS] rhythmsulsive ; real ably rhythms ways balanceulsive withclusive rhythms [SEP]']
[ 150/2000] tot_loss=2.717 (perp=11.426, rec=0.141, cos=0.291), tot_loss_proj:3.372 [t=0.22s]
prediction: ['[CLS] rhythmsulsiveulsive real ably rhythms ways balanceulsive with with rhythms [SEP]']
[ 200/2000] tot_loss=2.520 (perp=10.512, rec=0.128, cos=0.290), tot_loss_proj:3.189 [t=0.22s]
prediction: ['[CLS] rhythmsulsive balance real ably rhythms ways balanceulsive with incident rhythms [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.428 (perp=10.025, rec=0.132, cos=0.291), tot_loss_proj:2.964 [t=0.22s]
prediction: ['[CLS] rhythmsulsiveulsive real ably balances rhythmsulsive with incident rhythms [SEP]']
[ 300/2000] tot_loss=2.413 (perp=10.025, rec=0.119, cos=0.289), tot_loss_proj:2.944 [t=0.22s]
prediction: ['[CLS] rhythmsulsiveulsive real ably balances rhythmsulsive with incident rhythms [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.419 (perp=10.034, rec=0.116, cos=0.297), tot_loss_proj:2.990 [t=0.22s]
prediction: ['[CLS] rhythmsulsive real abulsively balances rhythmsulsive with incident real [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.116 (perp=8.632, rec=0.104, cos=0.285), tot_loss_proj:2.799 [t=0.22s]
prediction: ['[CLS]ulsive rhythms real abulsively balances rhythmsulsive with incident. [SEP]']
[ 450/2000] tot_loss=2.409 (perp=9.860, rec=0.144, cos=0.293), tot_loss_proj:3.123 [t=0.22s]
prediction: ['[CLS]ulsive rhythms real abulsively balanceism rhythmsulsive with incident. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.318 (perp=9.507, rec=0.125, cos=0.292), tot_loss_proj:2.985 [t=0.22s]
prediction: ['[CLS]ulsive incident real abulsively balanceulsives rhythms with incident. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.110 (perp=8.494, rec=0.119, cos=0.292), tot_loss_proj:2.782 [t=0.22s]
prediction: ['[CLS]ulsive incidents real abulsively balanceulsive rhythms with incident. [SEP]']
[ 600/2000] tot_loss=2.311 (perp=9.576, rec=0.105, cos=0.291), tot_loss_proj:3.025 [t=0.22s]
prediction: ['[CLS]ulsive incidents real abedly balanceulsive rhythms with incident. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.304 (perp=9.565, rec=0.098, cos=0.293), tot_loss_proj:2.957 [t=0.22s]
prediction: ['[CLS]ulsive incident involved real ably balanceulsive rhythms with incidentulsive. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.234 (perp=9.161, rec=0.106, cos=0.296), tot_loss_proj:2.864 [t=0.22s]
prediction: ['[CLS]ulsive incident involved real ablyulsive rhythms with incidentulsive balance. [SEP]']
[ 750/2000] tot_loss=2.151 (perp=8.753, rec=0.105, cos=0.295), tot_loss_proj:2.837 [t=0.22s]
prediction: ['[CLS]ence incident involved real ablyulsive rhythms with incidented balance. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.209 (perp=9.068, rec=0.103, cos=0.293), tot_loss_proj:2.890 [t=0.22s]
prediction: ['[CLS]escence incident involved ablyulsive rhythms with real incidented balance. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.084 (perp=8.375, rec=0.116, cos=0.293), tot_loss_proj:2.693 [t=0.22s]
prediction: ['[CLS] incident involved ablyulsiveulsive rhythms with real incidented balance. [SEP]']
[ 900/2000] tot_loss=2.051 (perp=8.249, rec=0.109, cos=0.293), tot_loss_proj:2.711 [t=0.22s]
prediction: ['[CLS] incident involved ablyulsiveulsive rhythms with real incident time balance. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.032 (perp=8.251, rec=0.089, cos=0.293), tot_loss_proj:2.797 [t=0.22s]
prediction: ['[CLS] incident involved abulsivelyulsive rhythms with real incident time balance. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.024 (perp=8.203, rec=0.088, cos=0.295), tot_loss_proj:2.876 [t=0.22s]
prediction: ['[CLS] incident involved abulsivelyulsive rhythms with real time incident balance. [SEP]']
[1050/2000] tot_loss=2.171 (perp=8.895, rec=0.096, cos=0.296), tot_loss_proj:2.798 [t=0.22s]
prediction: ['[CLS]ulsive involved abulsivelyulsive rhythms with real time incident balance. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.097 (perp=8.592, rec=0.084, cos=0.295), tot_loss_proj:2.688 [t=0.22s]
prediction: ['[CLS]ulsively involved abulsiveulsive rhythms with real time incident balance. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.042 (perp=8.287, rec=0.092, cos=0.292), tot_loss_proj:2.618 [t=0.22s]
prediction: ['[CLS] balanceulsively involved abulsiveulsive rhythms with real time incident. [SEP]']
[1200/2000] tot_loss=2.041 (perp=8.287, rec=0.089, cos=0.295), tot_loss_proj:2.617 [t=0.22s]
prediction: ['[CLS] balanceulsively involved abulsiveulsive rhythms with real time incident. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.046 (perp=8.287, rec=0.095, cos=0.293), tot_loss_proj:2.605 [t=0.22s]
prediction: ['[CLS] balanceulsively involved abulsiveulsive rhythms with real time incident. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.032 (perp=8.267, rec=0.087, cos=0.292), tot_loss_proj:2.591 [t=0.22s]
prediction: ['[CLS] balanceulsively involved abulsive relationship rhythms with real time incident. [SEP]']
[1350/2000] tot_loss=2.034 (perp=8.267, rec=0.088, cos=0.293), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS] balanceulsively involved abulsive relationship rhythms with real time incident. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.913 (perp=7.690, rec=0.081, cos=0.294), tot_loss_proj:2.809 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.913 (perp=7.690, rec=0.082, cos=0.293), tot_loss_proj:2.808 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
[1500/2000] tot_loss=1.917 (perp=7.690, rec=0.088, cos=0.292), tot_loss_proj:2.809 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.928 (perp=7.690, rec=0.097, cos=0.293), tot_loss_proj:2.803 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.926 (perp=7.690, rec=0.096, cos=0.292), tot_loss_proj:2.801 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
[1650/2000] tot_loss=1.921 (perp=7.690, rec=0.090, cos=0.293), tot_loss_proj:2.802 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.916 (perp=7.690, rec=0.085, cos=0.293), tot_loss_proj:2.805 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.917 (perp=7.690, rec=0.087, cos=0.292), tot_loss_proj:2.802 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
[1800/2000] tot_loss=1.913 (perp=7.690, rec=0.083, cos=0.292), tot_loss_proj:2.801 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.904 (perp=7.690, rec=0.075, cos=0.292), tot_loss_proj:2.804 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.905 (perp=7.690, rec=0.075, cos=0.292), tot_loss_proj:2.800 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
[1950/2000] tot_loss=1.911 (perp=7.690, rec=0.080, cos=0.293), tot_loss_proj:2.802 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.911 (perp=7.690, rec=0.081, cos=0.292), tot_loss_proj:2.800 [t=0.22s]
prediction: ['[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] alternating balanceulsively involved abulsive rhythms with real time incident. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 63.636 | r: 70.000
rouge2     | fm: 31.579 | p: 30.000 | r: 33.333
rougeL     | fm: 47.619 | p: 45.455 | r: 50.000
rougeLsum  | fm: 47.619 | p: 45.455 | r: 50.000
r1fm+r2fm = 98.246

[Aggregate metrics]:
rouge1     | fm: 88.599 | p: 87.863 | r: 89.481
rouge2     | fm: 63.488 | p: 62.927 | r: 63.939
rougeL     | fm: 81.555 | p: 80.795 | r: 82.381
rougeLsum  | fm: 81.901 | p: 81.157 | r: 82.835
r1fm+r2fm = 152.087

input #10 time: 0:08:47 | total time: 1:35:23


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.8664866933799151
highest_index [0]
highest [0.8664866933799151]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.8592094779014587 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.8480790257453918 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.7795898914337158 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.7792096734046936 for ['[CLS] me familiar talgu mileturevd drawn inland platform [SEP]']
[Init] best perm rec loss: 0.779140055179596 for ['[CLS] inland familiar megu talturevd mile platform drawn [SEP]']
[Init] best perm rec loss: 0.7790835499763489 for ['[CLS] drawnturevdgu me mile familiar tal platform inland [SEP]']
[Init] best perm rec loss: 0.7784519791603088 for ['[CLS]gu familiar inlandvd mile platform talture drawn me [SEP]']
[Init] best perm rec loss: 0.7777388691902161 for ['[CLS]turegu me inland platform mile drawnvd familiar tal [SEP]']
[Init] best perm rec loss: 0.7746546268463135 for ['[CLS] tal drawnture inland platform megu familiarvd mile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.970 (perp=11.785, rec=0.364, cos=0.248), tot_loss_proj:3.931 [t=0.22s]
prediction: ['[CLS] cannot large installed that report doubted witnessed refused that farm [SEP]']
[ 100/2000] tot_loss=3.168 (perp=13.032, rec=0.292, cos=0.270), tot_loss_proj:4.096 [t=0.22s]
prediction: ['[CLS] gel trying constructed that roger refused witnessed refusedly gel [SEP]']
[ 150/2000] tot_loss=2.828 (perp=11.891, rec=0.202, cos=0.248), tot_loss_proj:3.665 [t=0.22s]
prediction: ['[CLS] gel being attempted that stubborn that tried refusedly gel [SEP]']
[ 200/2000] tot_loss=2.782 (perp=11.804, rec=0.173, cos=0.248), tot_loss_proj:3.701 [t=0.22s]
prediction: ['[CLS] gel being attempted that stubborn that attempted refusedly gel [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.468 (perp=10.175, rec=0.183, cos=0.250), tot_loss_proj:3.104 [t=0.22s]
prediction: ['[CLS] gel being attempted that stubbornly attempted refused truth gel [SEP]']
[ 300/2000] tot_loss=2.337 (perp=9.672, rec=0.148, cos=0.254), tot_loss_proj:3.057 [t=0.22s]
prediction: ['[CLS] gel was attempted that stubbornly ignored refused already here [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.190 (perp=8.893, rec=0.165, cos=0.246), tot_loss_proj:2.986 [t=0.22s]
prediction: ['[CLS] gel was already here attempted that stubbornly wanted refused [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.921 (perp=7.809, rec=0.112, cos=0.247), tot_loss_proj:2.938 [t=0.22s]
prediction: ['[CLS] gel was not here attempted that stubbornly refused being [SEP]']
[ 450/2000] tot_loss=1.918 (perp=7.809, rec=0.106, cos=0.250), tot_loss_proj:2.940 [t=0.22s]
prediction: ['[CLS] gel was not here attempted that stubbornly refused being [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.865 (perp=7.557, rec=0.106, cos=0.248), tot_loss_proj:2.816 [t=0.22s]
prediction: ['[CLS] gel was not here being attempted that stubbornly refused [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.850 (perp=7.557, rec=0.092, cos=0.247), tot_loss_proj:2.821 [t=0.22s]
prediction: ['[CLS] gel was not here being attempted that stubbornly refused [SEP]']
[ 600/2000] tot_loss=1.848 (perp=7.557, rec=0.090, cos=0.247), tot_loss_proj:2.817 [t=0.22s]
prediction: ['[CLS] gel was not here being attempted that stubbornly refused [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.964 (perp=8.199, rec=0.079, cos=0.245), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] gel was to here being attempted that stubbornly refused [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.792 (perp=7.284, rec=0.090, cos=0.245), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] gel was here being attempted that stubbornly refused to [SEP]']
[ 750/2000] tot_loss=1.787 (perp=7.284, rec=0.087, cos=0.243), tot_loss_proj:2.516 [t=0.22s]
prediction: ['[CLS] gel was here being attempted that stubbornly refused to [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.778 (perp=7.284, rec=0.075, cos=0.247), tot_loss_proj:2.519 [t=0.22s]
prediction: ['[CLS] gel was here being attempted that stubbornly refused to [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.743 (perp=7.103, rec=0.078, cos=0.245), tot_loss_proj:2.406 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
[ 900/2000] tot_loss=1.737 (perp=7.103, rec=0.069, cos=0.247), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.747 (perp=7.103, rec=0.080, cos=0.247), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1000/2000] tot_loss=1.752 (perp=7.103, rec=0.082, cos=0.249), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
[1050/2000] tot_loss=1.749 (perp=7.103, rec=0.082, cos=0.247), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1100/2000] tot_loss=1.742 (perp=7.103, rec=0.075, cos=0.247), tot_loss_proj:2.401 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1150/2000] tot_loss=1.738 (perp=7.103, rec=0.070, cos=0.247), tot_loss_proj:2.403 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
[1200/2000] tot_loss=1.747 (perp=7.103, rec=0.077, cos=0.249), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1250/2000] tot_loss=1.748 (perp=7.103, rec=0.078, cos=0.249), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1300/2000] tot_loss=1.743 (perp=7.103, rec=0.075, cos=0.248), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
[1350/2000] tot_loss=1.739 (perp=7.103, rec=0.071, cos=0.247), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1400/2000] tot_loss=1.745 (perp=7.103, rec=0.076, cos=0.248), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1450/2000] tot_loss=1.745 (perp=7.103, rec=0.076, cos=0.248), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
[1500/2000] tot_loss=1.740 (perp=7.103, rec=0.071, cos=0.248), tot_loss_proj:2.406 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1550/2000] tot_loss=1.743 (perp=7.103, rec=0.075, cos=0.247), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1600/2000] tot_loss=1.748 (perp=7.103, rec=0.080, cos=0.248), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
[1650/2000] tot_loss=1.742 (perp=7.103, rec=0.075, cos=0.247), tot_loss_proj:2.403 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1700/2000] tot_loss=1.741 (perp=7.103, rec=0.073, cos=0.247), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1750/2000] tot_loss=1.743 (perp=7.103, rec=0.074, cos=0.248), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
[1800/2000] tot_loss=1.739 (perp=7.103, rec=0.072, cos=0.247), tot_loss_proj:2.401 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1850/2000] tot_loss=1.746 (perp=7.103, rec=0.077, cos=0.248), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[1900/2000] tot_loss=1.741 (perp=7.103, rec=0.072, cos=0.248), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
[1950/2000] tot_loss=1.741 (perp=7.103, rec=0.073, cos=0.247), tot_loss_proj:2.406 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Attempt swap
[2000/2000] tot_loss=1.741 (perp=7.103, rec=0.073, cos=0.248), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] gel was being attempted here that stubbornly refused to [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] gel was being attempted here that stubbornly refused to [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 89.516 | p: 88.723 | r: 90.357
rouge2     | fm: 64.059 | p: 63.611 | r: 64.576
rougeL     | fm: 82.345 | p: 81.752 | r: 83.262
rougeLsum  | fm: 82.663 | p: 81.989 | r: 83.369
r1fm+r2fm = 153.575

input #11 time: 0:08:47 | total time: 1:44:10


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.9284305650709028
highest_index [0]
highest [0.9284305650709028]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8366734385490417 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.788317084312439 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.786168098449707 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7822551727294922 for ['[CLS] wolf rex usualli plant live painfully sqlamtpemi wallace du sort [SEP]']
[Init] best rec loss: 0.7769075036048889 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7613311409950256 for ['[CLS] this heart hot noise fixing trying system potential salt ifana defense ii alexandria [SEP]']
[Init] best rec loss: 0.7536903023719788 for ['[CLS] hear protocol heidi race strokes safety association transactions snail most place buried terror documentary [SEP]']
[Init] best rec loss: 0.7313833236694336 for ['[CLS] alive expression semiuid wise friend investigationthed beloved [MASK] got richards didnbank [SEP]']
[Init] best perm rec loss: 0.7286207675933838 for ['[CLS] gotbank wiseuid friend semi didn richards [MASK] alivethed expression beloved investigation [SEP]']
[Init] best perm rec loss: 0.7279301881790161 for ['[CLS] beloved got friend semibankuid [MASK] didn wise investigation expressionthed alive richards [SEP]']
[Init] best perm rec loss: 0.7277749180793762 for ['[CLS] friend investigation expression alive wise didn semibank [MASK] richards gotuidthed beloved [SEP]']
[Init] best perm rec loss: 0.7276244163513184 for ['[CLS] richards alive gotthed semi expression didn investigationbank friend beloveduid wise [MASK] [SEP]']
[Init] best perm rec loss: 0.7276027798652649 for ['[CLS]bank wise expression didn semithed richardsuid got beloved [MASK] alive investigation friend [SEP]']
[Init] best perm rec loss: 0.7267142534255981 for ['[CLS] got wise friend didn semi [MASK]bankthed expressionuid alive richards beloved investigation [SEP]']
[Init] best perm rec loss: 0.7248672842979431 for ['[CLS] wise friend didnthed expressionbank got [MASK] investigation alive beloved richards semiuid [SEP]']
[Init] best perm rec loss: 0.7237895131111145 for ['[CLS] semithed [MASK]bank alive expression richards didn friend beloved investigationuid wise got [SEP]']
[Init] best perm rec loss: 0.7235568761825562 for ['[CLS] richards investigation friend aliveuid belovedthed expression didnbank semi wise got [MASK] [SEP]']
[Init] best perm rec loss: 0.7233168482780457 for ['[CLS] expression friendthedbank richards investigation semi got beloved alive didnuid wise [MASK] [SEP]']
[Init] best perm rec loss: 0.7231552004814148 for ['[CLS] beloved investigation gotuid semi wise alivebank didn expression richardsthed friend [MASK] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.138 (perp=8.615, rec=0.277, cos=0.138), tot_loss_proj:2.785 [t=0.22s]
prediction: ['[CLS] cable probably has better on on cable, even better its barely barely reservoir [SEP]']
[ 100/2000] tot_loss=2.363 (perp=10.200, rec=0.181, cos=0.143), tot_loss_proj:3.014 [t=0.22s]
prediction: ['[CLS] cable will seen better on on cable advantage hardly advantage its barely barely attraction [SEP]']
[ 150/2000] tot_loss=2.268 (perp=9.993, rec=0.139, cos=0.131), tot_loss_proj:2.863 [t=0.22s]
prediction: ['[CLS] cable will seen better on on cable advantage obviously since its especially barely attraction [SEP]']
[ 200/2000] tot_loss=2.127 (perp=9.360, rec=0.123, cos=0.132), tot_loss_proj:2.664 [t=0.22s]
prediction: ['[CLS] cable will seen better on on cable advantage especially considering its especially barely its [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.064 (perp=7.652, rec=0.309, cos=0.225), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] barely a cable will seen better on on cable advantage, considering its especially [SEP]']
[ 300/2000] tot_loss=1.859 (perp=7.652, rec=0.192, cos=0.136), tot_loss_proj:2.713 [t=0.22s]
prediction: ['[CLS] barely a cable will seen better on on cable advantage, considering its especially [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.720 (perp=7.158, rec=0.151, cos=0.137), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] barely a cable will seen better on on cable advantage, especially considering its [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.743 (perp=7.407, rec=0.126, cos=0.136), tot_loss_proj:2.472 [t=0.22s]
prediction: ['[CLS] barely a cable will seen better to on cable advantage, especially considering its [SEP]']
[ 450/2000] tot_loss=1.738 (perp=7.407, rec=0.117, cos=0.139), tot_loss_proj:2.471 [t=0.22s]
prediction: ['[CLS] barely a cable will seen better to on cable advantage, especially considering its [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.722 (perp=7.407, rec=0.106, cos=0.135), tot_loss_proj:2.470 [t=0.22s]
prediction: ['[CLS] barely a cable will seen better to on cable advantage, especially considering its [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.799 (perp=7.859, rec=0.093, cos=0.134), tot_loss_proj:2.475 [t=0.22s]
prediction: ['[CLS] barely that cable will seen better to on cable advantage, especially considering its [SEP]']
[ 600/2000] tot_loss=1.791 (perp=7.859, rec=0.086, cos=0.133), tot_loss_proj:2.469 [t=0.22s]
prediction: ['[CLS] barely that cable will seen better to on cable advantage, especially considering its [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.721 (perp=7.431, rec=0.098, cos=0.137), tot_loss_proj:2.465 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.716 (perp=7.431, rec=0.091, cos=0.138), tot_loss_proj:2.460 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
[ 750/2000] tot_loss=1.724 (perp=7.431, rec=0.100, cos=0.137), tot_loss_proj:2.462 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.710 (perp=7.431, rec=0.089, cos=0.136), tot_loss_proj:2.467 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.708 (perp=7.431, rec=0.086, cos=0.137), tot_loss_proj:2.461 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
[ 900/2000] tot_loss=1.707 (perp=7.431, rec=0.085, cos=0.136), tot_loss_proj:2.463 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.717 (perp=7.431, rec=0.094, cos=0.136), tot_loss_proj:2.458 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
Attempt swap
[1000/2000] tot_loss=1.711 (perp=7.431, rec=0.089, cos=0.135), tot_loss_proj:2.463 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
[1050/2000] tot_loss=1.697 (perp=7.431, rec=0.074, cos=0.136), tot_loss_proj:2.465 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
Attempt swap
[1100/2000] tot_loss=1.703 (perp=7.431, rec=0.081, cos=0.136), tot_loss_proj:2.461 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
Attempt swap
[1150/2000] tot_loss=1.709 (perp=7.431, rec=0.086, cos=0.137), tot_loss_proj:2.463 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
[1200/2000] tot_loss=1.708 (perp=7.431, rec=0.085, cos=0.137), tot_loss_proj:2.464 [t=0.22s]
prediction: ['[CLS] barely its cable will seen better to on cable advantage, especially considering that [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.644 (perp=7.140, rec=0.080, cos=0.137), tot_loss_proj:2.231 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
Attempt swap
[1300/2000] tot_loss=1.656 (perp=7.140, rec=0.092, cos=0.136), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
[1350/2000] tot_loss=1.638 (perp=7.140, rec=0.074, cos=0.135), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
Attempt swap
[1400/2000] tot_loss=1.644 (perp=7.140, rec=0.080, cos=0.136), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
Attempt swap
[1450/2000] tot_loss=1.645 (perp=7.140, rec=0.081, cos=0.136), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
[1500/2000] tot_loss=1.640 (perp=7.140, rec=0.075, cos=0.137), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
Attempt swap
[1550/2000] tot_loss=1.645 (perp=7.140, rec=0.081, cos=0.136), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
Attempt swap
[1600/2000] tot_loss=1.645 (perp=7.140, rec=0.080, cos=0.137), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
[1650/2000] tot_loss=1.639 (perp=7.140, rec=0.074, cos=0.137), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
Attempt swap
[1700/2000] tot_loss=1.643 (perp=7.140, rec=0.078, cos=0.137), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
Attempt swap
[1750/2000] tot_loss=1.635 (perp=7.140, rec=0.070, cos=0.137), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
[1800/2000] tot_loss=1.646 (perp=7.140, rec=0.081, cos=0.137), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
Attempt swap
[1850/2000] tot_loss=1.645 (perp=7.140, rec=0.079, cos=0.137), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
Attempt swap
[1900/2000] tot_loss=1.648 (perp=7.140, rec=0.082, cos=0.138), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
[1950/2000] tot_loss=1.648 (perp=7.140, rec=0.082, cos=0.138), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
Attempt swap
[2000/2000] tot_loss=1.646 (perp=7.140, rec=0.080, cos=0.137), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] to its cable will seen better barely on cable advantage, especially considering that [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 107.619

[Aggregate metrics]:
rouge1     | fm: 89.797 | p: 89.217 | r: 90.586
rouge2     | fm: 59.752 | p: 59.440 | r: 60.223
rougeL     | fm: 80.774 | p: 80.144 | r: 81.508
rougeLsum  | fm: 80.513 | p: 79.842 | r: 81.245
r1fm+r2fm = 149.549

input #12 time: 0:08:47 | total time: 1:52:57


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9021800852928965
highest_index [0]
highest [0.9021800852928965]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.6895995140075684 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.6854518055915833 for ['[CLS] baccalaureate, black saunderstec armed much [SEP]']
[Init] best rec loss: 0.6848577857017517 for ['[CLS] todd travel time mountain relation territorial same [SEP]']
[Init] best rec loss: 0.67902672290802 for ['[CLS] dressed fraternity colonial round et bahn heads [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.374 (perp=9.744, rec=0.248, cos=0.177), tot_loss_proj:2.960 [t=0.22s]
prediction: ['[CLS] point flame things flame into into flame [SEP]']
[ 100/2000] tot_loss=2.148 (perp=9.009, rec=0.164, cos=0.182), tot_loss_proj:2.739 [t=0.22s]
prediction: ['[CLS] point flame things flame explode into flame [SEP]']
[ 150/2000] tot_loss=2.110 (perp=9.009, rec=0.128, cos=0.180), tot_loss_proj:2.743 [t=0.22s]
prediction: ['[CLS] point flame things flame explode into flame [SEP]']
[ 200/2000] tot_loss=2.099 (perp=9.009, rec=0.117, cos=0.180), tot_loss_proj:2.742 [t=0.22s]
prediction: ['[CLS] point flame things flame explode into flame [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.234 (perp=9.720, rec=0.103, cos=0.188), tot_loss_proj:2.739 [t=0.22s]
prediction: ['[CLS] point flame things things explode into flame [SEP]']
[ 300/2000] tot_loss=2.179 (perp=9.502, rec=0.096, cos=0.183), tot_loss_proj:2.700 [t=0.22s]
prediction: ['[CLS] point flame things at explode into flame [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.888 (perp=8.041, rec=0.095, cos=0.186), tot_loss_proj:2.435 [t=0.22s]
prediction: ['[CLS] at point flame things explode into flame [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.883 (perp=8.041, rec=0.088, cos=0.187), tot_loss_proj:2.432 [t=0.22s]
prediction: ['[CLS] at point flame things explode into flame [SEP]']
[ 450/2000] tot_loss=1.880 (perp=8.041, rec=0.087, cos=0.184), tot_loss_proj:2.433 [t=0.22s]
prediction: ['[CLS] at point flame things explode into flame [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.880 (perp=8.041, rec=0.090, cos=0.182), tot_loss_proj:2.430 [t=0.22s]
prediction: ['[CLS] at point flame things explode into flame [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.052 (perp=8.927, rec=0.084, cos=0.183), tot_loss_proj:2.578 [t=0.22s]
prediction: ['[CLS] at point things things explode into flame [SEP]']
[ 600/2000] tot_loss=2.044 (perp=8.927, rec=0.073, cos=0.185), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] at point things things explode into flame [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.906 (perp=8.294, rec=0.064, cos=0.183), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] at things point that explode into flame [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.925 (perp=8.257, rec=0.094, cos=0.180), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] at things point things explode into flame [SEP]']
[ 750/2000] tot_loss=1.545 (perp=6.423, rec=0.078, cos=0.182), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.528 (perp=6.423, rec=0.060, cos=0.183), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.539 (perp=6.423, rec=0.072, cos=0.183), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 900/2000] tot_loss=1.528 (perp=6.423, rec=0.059, cos=0.184), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.527 (perp=6.423, rec=0.059, cos=0.184), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.530 (perp=6.423, rec=0.062, cos=0.184), tot_loss_proj:2.110 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1050/2000] tot_loss=1.547 (perp=6.423, rec=0.077, cos=0.185), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.544 (perp=6.423, rec=0.073, cos=0.187), tot_loss_proj:2.111 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.534 (perp=6.423, rec=0.065, cos=0.184), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1200/2000] tot_loss=1.540 (perp=6.423, rec=0.070, cos=0.185), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.532 (perp=6.423, rec=0.062, cos=0.185), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.542 (perp=6.423, rec=0.072, cos=0.185), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1350/2000] tot_loss=1.535 (perp=6.423, rec=0.065, cos=0.185), tot_loss_proj:2.118 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.538 (perp=6.423, rec=0.068, cos=0.185), tot_loss_proj:2.118 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.535 (perp=6.423, rec=0.066, cos=0.185), tot_loss_proj:2.118 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1500/2000] tot_loss=1.528 (perp=6.423, rec=0.059, cos=0.184), tot_loss_proj:2.122 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.530 (perp=6.423, rec=0.060, cos=0.185), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.540 (perp=6.423, rec=0.071, cos=0.184), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1650/2000] tot_loss=1.522 (perp=6.423, rec=0.052, cos=0.185), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.541 (perp=6.423, rec=0.073, cos=0.184), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.529 (perp=6.423, rec=0.059, cos=0.185), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1800/2000] tot_loss=1.529 (perp=6.423, rec=0.060, cos=0.184), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.527 (perp=6.423, rec=0.058, cos=0.185), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.531 (perp=6.423, rec=0.062, cos=0.185), tot_loss_proj:2.119 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1950/2000] tot_loss=1.533 (perp=6.423, rec=0.064, cos=0.184), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.537 (perp=6.423, rec=0.068, cos=0.184), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] at that point things explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 90.679 | p: 90.026 | r: 91.310
rouge2     | fm: 58.417 | p: 58.020 | r: 58.867
rougeL     | fm: 80.577 | p: 79.927 | r: 81.102
rougeLsum  | fm: 80.413 | p: 79.777 | r: 81.045
r1fm+r2fm = 149.097

input #13 time: 0:08:38 | total time: 2:01:36


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.8221274374394079
highest_index [0]
highest [0.8221274374394079]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9958180785179138 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9816601872444153 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9717751741409302 for ['[CLS] green stepped one battle rear [SEP]']
[Init] best rec loss: 0.9663587212562561 for ['[CLS] gps war break stream carriage [SEP]']
[Init] best rec loss: 0.9576019644737244 for ['[CLS] female pants hard surely olympics [SEP]']
[Init] best rec loss: 0.953633725643158 for ['[CLS]pace chicago is thrust youth [SEP]']
[Init] best rec loss: 0.9530670642852783 for ['[CLS] baton channel along presided corners [SEP]']
[Init] best rec loss: 0.9390362501144409 for ['[CLS] strategy sigh hk automatically county [SEP]']
[Init] best rec loss: 0.9377200603485107 for ['[CLS] dirtig directionseous dealer [SEP]']
[Init] best perm rec loss: 0.9368225932121277 for ['[CLS]eous dealerig directions dirt [SEP]']
[Init] best perm rec loss: 0.9352059960365295 for ['[CLS]eous dirtig directions dealer [SEP]']
[Init] best perm rec loss: 0.9351382851600647 for ['[CLS]ig dirt dealereous directions [SEP]']
[Init] best perm rec loss: 0.9347575902938843 for ['[CLS] directionseous dirt dealerig [SEP]']
[Init] best perm rec loss: 0.9344983696937561 for ['[CLS] directionseousig dealer dirt [SEP]']
[Init] best perm rec loss: 0.9339925050735474 for ['[CLS] dealer directions dirteousig [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.011 (perp=14.579, rec=0.666, cos=0.430), tot_loss_proj:4.505 [t=0.22s]
prediction: ['[CLS] mind revolt rebellion death couch [SEP]']
[ 100/2000] tot_loss=3.358 (perp=12.097, rec=0.601, cos=0.337), tot_loss_proj:3.806 [t=0.22s]
prediction: ['[CLS] biography fivb intriguing intriguing asteroid [SEP]']
[ 150/2000] tot_loss=3.350 (perp=12.445, rec=0.545, cos=0.316), tot_loss_proj:3.814 [t=0.22s]
prediction: ['[CLS]blyenia intriguing intriguing cookie [SEP]']
[ 200/2000] tot_loss=3.387 (perp=12.619, rec=0.537, cos=0.326), tot_loss_proj:3.954 [t=0.22s]
prediction: ['[CLS]blyenia intriguing intriguing question [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.578 (perp=12.162, rec=0.698, cos=0.447), tot_loss_proj:4.343 [t=0.22s]
prediction: ['[CLS] list congress cerambycidae actors doorbell [SEP]']
[ 300/2000] tot_loss=3.486 (perp=12.688, rec=0.577, cos=0.371), tot_loss_proj:4.320 [t=0.22s]
prediction: ['[CLS] lists slavic novel intriguinggles [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.716 (perp=14.173, rec=0.549, cos=0.332), tot_loss_proj:4.592 [t=0.22s]
prediction: ['[CLS] ª intriguingbly slavicgles [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.634 (perp=13.092, rec=0.599, cos=0.417), tot_loss_proj:4.218 [t=0.22s]
prediction: ['[CLS] ªbly tragedy slavicgles [SEP]']
[ 450/2000] tot_loss=3.554 (perp=13.448, rec=0.543, cos=0.321), tot_loss_proj:4.313 [t=0.22s]
prediction: ['[CLS]inglybly tragedy slavicgles [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.401 (perp=12.474, rec=0.552, cos=0.354), tot_loss_proj:4.414 [t=0.22s]
prediction: ['[CLS]baribly intriguinginglygles [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.344 (perp=12.374, rec=0.539, cos=0.330), tot_loss_proj:4.273 [t=0.22s]
prediction: ['[CLS]baribly intriguingglesingly [SEP]']
[ 600/2000] tot_loss=3.305 (perp=12.394, rec=0.509, cos=0.318), tot_loss_proj:4.015 [t=0.22s]
prediction: ['[CLS]baribly intriguing familiaringly [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.107 (perp=11.081, rec=0.557, cos=0.333), tot_loss_proj:4.000 [t=0.22s]
prediction: ['[CLS]baribly intriguingingly familiar [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.027 (perp=11.081, rec=0.494, cos=0.316), tot_loss_proj:3.994 [t=0.22s]
prediction: ['[CLS]baribly intriguingingly familiar [SEP]']
[ 750/2000] tot_loss=3.064 (perp=11.081, rec=0.497, cos=0.351), tot_loss_proj:3.996 [t=0.22s]
prediction: ['[CLS]baribly intriguingingly familiar [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.262 (perp=12.316, rec=0.490, cos=0.310), tot_loss_proj:4.120 [t=0.22s]
prediction: ['[CLS]nivorousbly intriguingusly familiar [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.199 (perp=11.837, rec=0.494, cos=0.337), tot_loss_proj:3.676 [t=0.22s]
prediction: ['[CLS] slavicbly familiarusly intriguing [SEP]']
[ 900/2000] tot_loss=3.211 (perp=11.837, rec=0.484, cos=0.359), tot_loss_proj:3.675 [t=0.22s]
prediction: ['[CLS] slavicbly familiarusly intriguing [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.825 (perp=10.091, rec=0.478, cos=0.329), tot_loss_proj:3.007 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1000/2000] tot_loss=2.822 (perp=10.091, rec=0.490, cos=0.315), tot_loss_proj:3.009 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
[1050/2000] tot_loss=2.823 (perp=10.091, rec=0.472, cos=0.333), tot_loss_proj:3.012 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1100/2000] tot_loss=2.895 (perp=10.091, rec=0.485, cos=0.392), tot_loss_proj:3.011 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1150/2000] tot_loss=2.802 (perp=10.091, rec=0.469, cos=0.315), tot_loss_proj:3.011 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
[1200/2000] tot_loss=2.827 (perp=10.091, rec=0.478, cos=0.330), tot_loss_proj:3.018 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1250/2000] tot_loss=2.812 (perp=10.091, rec=0.466, cos=0.328), tot_loss_proj:3.013 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1300/2000] tot_loss=2.822 (perp=10.091, rec=0.459, cos=0.345), tot_loss_proj:3.014 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
[1350/2000] tot_loss=2.792 (perp=10.091, rec=0.461, cos=0.313), tot_loss_proj:3.011 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1400/2000] tot_loss=2.815 (perp=10.091, rec=0.461, cos=0.336), tot_loss_proj:3.018 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1450/2000] tot_loss=2.836 (perp=10.091, rec=0.457, cos=0.361), tot_loss_proj:3.016 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
[1500/2000] tot_loss=2.839 (perp=10.091, rec=0.459, cos=0.363), tot_loss_proj:3.008 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1550/2000] tot_loss=2.901 (perp=10.091, rec=0.481, cos=0.402), tot_loss_proj:3.015 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1600/2000] tot_loss=2.795 (perp=10.091, rec=0.452, cos=0.324), tot_loss_proj:3.013 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
[1650/2000] tot_loss=2.796 (perp=10.091, rec=0.454, cos=0.324), tot_loss_proj:3.009 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1700/2000] tot_loss=2.805 (perp=10.091, rec=0.453, cos=0.334), tot_loss_proj:3.016 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1750/2000] tot_loss=2.791 (perp=10.091, rec=0.453, cos=0.321), tot_loss_proj:3.008 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
[1800/2000] tot_loss=2.788 (perp=10.091, rec=0.453, cos=0.317), tot_loss_proj:3.013 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1850/2000] tot_loss=2.814 (perp=10.091, rec=0.454, cos=0.342), tot_loss_proj:3.013 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[1900/2000] tot_loss=3.451 (perp=13.313, rec=0.458, cos=0.331), tot_loss_proj:3.962 [t=0.22s]
prediction: ['[CLS]eniaenia familiarusly intriguing [SEP]']
[1950/2000] tot_loss=2.796 (perp=10.091, rec=0.445, cos=0.332), tot_loss_proj:3.009 [t=0.22s]
prediction: ['[CLS]eniably familiarusly intriguing [SEP]']
Attempt swap
[2000/2000] tot_loss=3.433 (perp=13.313, rec=0.449, cos=0.322), tot_loss_proj:3.966 [t=0.22s]
prediction: ['[CLS]eniaenia familiarusly intriguing [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS]eniaenia familiarusly intriguing [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 60.000

[Aggregate metrics]:
rouge1     | fm: 88.415 | p: 87.817 | r: 89.063
rouge2     | fm: 54.548 | p: 54.110 | r: 54.922
rougeL     | fm: 78.928 | p: 78.505 | r: 79.514
rougeLsum  | fm: 79.053 | p: 78.487 | r: 79.721
r1fm+r2fm = 142.963

input #14 time: 0:08:41 | total time: 2:10:18


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.8062967571252173
highest_index [0]
highest [0.8062967571252173]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.8274798393249512 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.8193671703338623 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 0.8131504058837891 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.7972932457923889 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.7897642850875854 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best perm rec loss: 0.7894952297210693 for ['[CLS] diner [CLS] trooper martha safe much consumergly [SEP]']
[Init] best perm rec loss: 0.7879050374031067 for ['[CLS]gly safe [CLS] trooper consumer diner much martha [SEP]']
[Init] best perm rec loss: 0.7874647974967957 for ['[CLS] troopergly much consumer safe diner martha [CLS] [SEP]']
[Init] best perm rec loss: 0.7867746353149414 for ['[CLS] martha [CLS]gly consumer safe trooper diner much [SEP]']
[Init] best perm rec loss: 0.7864465117454529 for ['[CLS] [CLS] consumer martha much safe dinergly trooper [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.884 (perp=11.487, rec=0.238, cos=0.348), tot_loss_proj:3.568 [t=0.22s]
prediction: ['[CLS] efficientabilitytically, efficient efficientably receipts [SEP]']
[ 100/2000] tot_loss=3.244 (perp=13.388, rec=0.222, cos=0.344), tot_loss_proj:3.910 [t=0.22s]
prediction: ['[CLS] efficientably suit, anonymous efficientably chill [SEP]']
[ 150/2000] tot_loss=3.162 (perp=13.343, rec=0.146, cos=0.348), tot_loss_proj:3.883 [t=0.22s]
prediction: ['[CLS] efficientably suit,er efficientably chill [SEP]']
[ 200/2000] tot_loss=3.100 (perp=13.099, rec=0.128, cos=0.351), tot_loss_proj:3.773 [t=0.22s]
prediction: ['[CLS] efficientably suit,er anonymousably chill [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.589 (perp=10.691, rec=0.101, cos=0.350), tot_loss_proj:3.278 [t=0.22s]
prediction: ['[CLS] efficient suitably,er anonymousably chill [SEP]']
[ 300/2000] tot_loss=2.594 (perp=10.691, rec=0.107, cos=0.349), tot_loss_proj:3.276 [t=0.22s]
prediction: ['[CLS] efficient suitably,er anonymousably chill [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.310 (perp=9.390, rec=0.082, cos=0.349), tot_loss_proj:2.787 [t=0.22s]
prediction: ['[CLS] efficient suitably, anonymousably chiller [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.103 (perp=8.274, rec=0.097, cos=0.351), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS]ably suitably, anonymous efficient chiller [SEP]']
[ 450/2000] tot_loss=2.094 (perp=8.274, rec=0.092, cos=0.348), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS]ably suitably, anonymous efficient chiller [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.011 (perp=7.796, rec=0.103, cos=0.349), tot_loss_proj:2.185 [t=0.22s]
prediction: ['[CLS]ably suitably anonymous, efficient chiller [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.993 (perp=7.796, rec=0.084, cos=0.350), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS]ably suitably anonymous, efficient chiller [SEP]']
[ 600/2000] tot_loss=1.991 (perp=7.796, rec=0.083, cos=0.349), tot_loss_proj:2.183 [t=0.22s]
prediction: ['[CLS]ably suitably anonymous, efficient chiller [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.990 (perp=7.796, rec=0.081, cos=0.350), tot_loss_proj:2.192 [t=0.22s]
prediction: ['[CLS]ably suitably anonymous, efficient chiller [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.996 (perp=7.796, rec=0.088, cos=0.349), tot_loss_proj:2.192 [t=0.22s]
prediction: ['[CLS]ably suitably anonymous, efficient chiller [SEP]']
[ 750/2000] tot_loss=1.990 (perp=7.796, rec=0.081, cos=0.350), tot_loss_proj:2.187 [t=0.22s]
prediction: ['[CLS]ably suitably anonymous, efficient chiller [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.989 (perp=7.796, rec=0.081, cos=0.349), tot_loss_proj:2.195 [t=0.22s]
prediction: ['[CLS]ably suitably anonymous, efficient chiller [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.997 (perp=7.796, rec=0.089, cos=0.349), tot_loss_proj:2.193 [t=0.22s]
prediction: ['[CLS]ably suitably anonymous, efficient chiller [SEP]']
[ 900/2000] tot_loss=1.990 (perp=7.796, rec=0.082, cos=0.349), tot_loss_proj:2.189 [t=0.22s]
prediction: ['[CLS]ably suitably anonymous, efficient chiller [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.990 (perp=7.796, rec=0.082, cos=0.350), tot_loss_proj:2.189 [t=0.22s]
prediction: ['[CLS]ably suitably anonymous, efficient chiller [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.957 (perp=7.643, rec=0.079, cos=0.350), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[1050/2000] tot_loss=1.953 (perp=7.643, rec=0.076, cos=0.349), tot_loss_proj:2.156 [t=0.22s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1100/2000] tot_loss=1.959 (perp=7.643, rec=0.082, cos=0.349), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1150/2000] tot_loss=1.948 (perp=7.643, rec=0.071, cos=0.348), tot_loss_proj:2.159 [t=0.22s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[1200/2000] tot_loss=1.957 (perp=7.643, rec=0.078, cos=0.350), tot_loss_proj:2.152 [t=0.22s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1250/2000] tot_loss=1.960 (perp=7.643, rec=0.082, cos=0.350), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.150 (perp=8.635, rec=0.072, cos=0.351), tot_loss_proj:2.644 [t=0.22s]
prediction: ['[CLS] suitably chill efficient, anonymous chiller [SEP]']
[1350/2000] tot_loss=2.163 (perp=8.635, rec=0.086, cos=0.350), tot_loss_proj:2.642 [t=0.22s]
prediction: ['[CLS] suitably chill efficient, anonymous chiller [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.048 (perp=8.083, rec=0.081, cos=0.350), tot_loss_proj:2.195 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chill chiller [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=2.077 (perp=8.247, rec=0.079, cos=0.349), tot_loss_proj:2.424 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chillerᴵ [SEP]']
[1500/2000] tot_loss=2.084 (perp=8.247, rec=0.085, cos=0.349), tot_loss_proj:2.423 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chillerᴵ [SEP]']
Attempt swap
[1550/2000] tot_loss=2.077 (perp=8.247, rec=0.078, cos=0.350), tot_loss_proj:2.430 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chillerᴵ [SEP]']
Attempt swap
[1600/2000] tot_loss=2.081 (perp=8.247, rec=0.082, cos=0.350), tot_loss_proj:2.429 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chillerᴵ [SEP]']
[1650/2000] tot_loss=2.078 (perp=8.247, rec=0.078, cos=0.350), tot_loss_proj:2.423 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chillerᴵ [SEP]']
Attempt swap
[1700/2000] tot_loss=2.080 (perp=8.247, rec=0.081, cos=0.350), tot_loss_proj:2.430 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chillerᴵ [SEP]']
Attempt swap
[1750/2000] tot_loss=2.128 (perp=8.484, rec=0.082, cos=0.349), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chilleract [SEP]']
[1800/2000] tot_loss=2.124 (perp=8.484, rec=0.078, cos=0.349), tot_loss_proj:2.414 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chilleract [SEP]']
Attempt swap
[1850/2000] tot_loss=2.123 (perp=8.484, rec=0.076, cos=0.350), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chilleract [SEP]']
Attempt swap
[1900/2000] tot_loss=2.132 (perp=8.484, rec=0.085, cos=0.350), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chilleract [SEP]']
[1950/2000] tot_loss=2.127 (perp=8.484, rec=0.081, cos=0.349), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chilleract [SEP]']
Attempt swap
[2000/2000] tot_loss=2.135 (perp=8.484, rec=0.088, cos=0.350), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chilleract [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS]ably suitably efficient, anonymous chiller [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 128.671

[Aggregate metrics]:
rouge1     | fm: 88.722 | p: 87.791 | r: 89.829
rouge2     | fm: 53.530 | p: 52.967 | r: 53.910
rougeL     | fm: 78.717 | p: 77.924 | r: 79.775
rougeLsum  | fm: 78.917 | p: 78.019 | r: 79.882
r1fm+r2fm = 142.252

input #15 time: 0:08:38 | total time: 2:18:57


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.8736796235421893
highest_index [0]
highest [0.8736796235421893]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 0.8547671437263489 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.8335720896720886 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.8300776481628418 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best rec loss: 0.7942489981651306 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 0.7848957180976868 for ['[CLS] south jefferson late guy e sophia [SEP]']
[Init] best rec loss: 0.7504007816314697 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 0.7396489381790161 for ['[CLS] a clubs slayer trophy affected residents [SEP]']
[Init] best rec loss: 0.7258047461509705 for ['[CLS]worthy eat town normal court earth [SEP]']
[Init] best perm rec loss: 0.7214118838310242 for ['[CLS] town court earth normal eatworthy [SEP]']
[Init] best perm rec loss: 0.7194740772247314 for ['[CLS] town earth court eat normalworthy [SEP]']
[Init] best perm rec loss: 0.7185362577438354 for ['[CLS] town court normal eat earthworthy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.269 (perp=8.638, rec=0.302, cos=0.240), tot_loss_proj:2.764 [t=0.22s]
prediction: ['[CLS] this all that this more this [SEP]']
[ 100/2000] tot_loss=1.618 (perp=6.426, rec=0.094, cos=0.239), tot_loss_proj:1.927 [t=0.22s]
prediction: ['[CLS] this all of this and more [SEP]']
[ 150/2000] tot_loss=1.605 (perp=6.441, rec=0.088, cos=0.229), tot_loss_proj:1.863 [t=0.22s]
prediction: ['[CLS] this all of, and more [SEP]']
[ 200/2000] tot_loss=1.609 (perp=6.441, rec=0.084, cos=0.237), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] this all of, and more [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.248 (perp=4.697, rec=0.074, cos=0.235), tot_loss_proj:1.342 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 300/2000] tot_loss=1.245 (perp=4.697, rec=0.074, cos=0.232), tot_loss_proj:1.356 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.248 (perp=4.697, rec=0.073, cos=0.235), tot_loss_proj:1.351 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.236 (perp=4.697, rec=0.060, cos=0.237), tot_loss_proj:1.358 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 450/2000] tot_loss=1.232 (perp=4.697, rec=0.058, cos=0.234), tot_loss_proj:1.352 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.242 (perp=4.697, rec=0.073, cos=0.230), tot_loss_proj:1.348 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.232 (perp=4.697, rec=0.062, cos=0.231), tot_loss_proj:1.346 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 600/2000] tot_loss=1.236 (perp=4.697, rec=0.063, cos=0.234), tot_loss_proj:1.352 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.230 (perp=4.697, rec=0.060, cos=0.230), tot_loss_proj:1.365 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.241 (perp=4.697, rec=0.065, cos=0.237), tot_loss_proj:1.345 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=1.246 (perp=4.697, rec=0.074, cos=0.232), tot_loss_proj:1.352 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.237 (perp=4.697, rec=0.062, cos=0.236), tot_loss_proj:1.347 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.230 (perp=4.697, rec=0.056, cos=0.235), tot_loss_proj:1.350 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.227 (perp=4.697, rec=0.054, cos=0.234), tot_loss_proj:1.346 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.237 (perp=4.697, rec=0.063, cos=0.235), tot_loss_proj:1.352 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.238 (perp=4.697, rec=0.064, cos=0.235), tot_loss_proj:1.352 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.232 (perp=4.697, rec=0.058, cos=0.234), tot_loss_proj:1.344 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.238 (perp=4.697, rec=0.064, cos=0.235), tot_loss_proj:1.345 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.243 (perp=4.697, rec=0.068, cos=0.235), tot_loss_proj:1.346 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.242 (perp=4.697, rec=0.067, cos=0.236), tot_loss_proj:1.346 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.247 (perp=4.697, rec=0.071, cos=0.236), tot_loss_proj:1.344 [t=0.29s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.236 (perp=4.697, rec=0.061, cos=0.236), tot_loss_proj:1.356 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.224 (perp=4.697, rec=0.051, cos=0.234), tot_loss_proj:1.347 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.236 (perp=4.697, rec=0.061, cos=0.236), tot_loss_proj:1.349 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.236 (perp=4.697, rec=0.061, cos=0.235), tot_loss_proj:1.344 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.230 (perp=4.697, rec=0.055, cos=0.236), tot_loss_proj:1.343 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.242 (perp=4.697, rec=0.067, cos=0.236), tot_loss_proj:1.347 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.234 (perp=4.697, rec=0.058, cos=0.237), tot_loss_proj:1.353 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.235 (perp=4.697, rec=0.061, cos=0.235), tot_loss_proj:1.352 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.232 (perp=4.697, rec=0.056, cos=0.236), tot_loss_proj:1.340 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.242 (perp=4.697, rec=0.068, cos=0.235), tot_loss_proj:1.341 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=1.237 (perp=4.697, rec=0.062, cos=0.235), tot_loss_proj:1.340 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.252 (perp=4.697, rec=0.077, cos=0.236), tot_loss_proj:1.354 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.230 (perp=4.697, rec=0.055, cos=0.235), tot_loss_proj:1.338 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.240 (perp=4.697, rec=0.066, cos=0.235), tot_loss_proj:1.343 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.235 (perp=4.697, rec=0.061, cos=0.235), tot_loss_proj:1.350 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.459 | p: 88.570 | r: 90.504
rouge2     | fm: 56.345 | p: 55.899 | r: 56.794
rougeL     | fm: 80.315 | p: 79.454 | r: 81.167
rougeLsum  | fm: 79.956 | p: 79.114 | r: 81.044
r1fm+r2fm = 145.804

input #16 time: 0:08:42 | total time: 2:27:39


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.897011685871206
highest_index [0]
highest [0.897011685871206]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8103437423706055 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8003448247909546 for ['[CLS] angle bond masonacle cabinachejord right is kiel woman [SEP]']
[Init] best rec loss: 0.7882184982299805 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.7844504117965698 for ['[CLS] staretha jack nur stone lied pointsmori richie sienna foot [SEP]']
[Init] best rec loss: 0.7782019376754761 for ['[CLS] forecast yeast jewels young food filed paralyzedggio easy thing beau [SEP]']
[Init] best rec loss: 0.775738000869751 for ['[CLS] simply aero thomas orientponane mona usual surface matrix sebastian [SEP]']
[Init] best rec loss: 0.7679877281188965 for ['[CLS] wild filing curls wandabuck day victor which judicial coach peyton [SEP]']
[Init] best perm rec loss: 0.7668721079826355 for ['[CLS] coach day wanda whichbuck curls peyton filing judicial wild victor [SEP]']
[Init] best perm rec loss: 0.7661541700363159 for ['[CLS] victor coach peyton curls judicial wildbuck which filing wanda day [SEP]']
[Init] best perm rec loss: 0.763729453086853 for ['[CLS] wild curls peyton filing victor judicial daybuck coach which wanda [SEP]']
[Init] best perm rec loss: 0.7636927366256714 for ['[CLS] victor day wild curls whichbuck coach filing judicial wanda peyton [SEP]']
[Init] best perm rec loss: 0.7631203532218933 for ['[CLS] victor wanda coach curlsbuck wild peyton judicial which filing day [SEP]']
[Init] best perm rec loss: 0.7618759274482727 for ['[CLS] victor filing day curls coach wanda judicial wild which peytonbuck [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.487 (perp=9.590, rec=0.355, cos=0.215), tot_loss_proj:3.248 [t=0.21s]
prediction: ['[CLS] really too clouds want at too. oriented think up crazy [SEP]']
[ 100/2000] tot_loss=2.308 (perp=9.756, rec=0.164, cos=0.193), tot_loss_proj:3.153 [t=0.21s]
prediction: ['[CLS] want too about want much too think about think on much [SEP]']
[ 150/2000] tot_loss=2.160 (perp=9.331, rec=0.100, cos=0.194), tot_loss_proj:2.969 [t=0.21s]
prediction: ['[CLS] to too about want much too about about think on what [SEP]']
[ 200/2000] tot_loss=2.354 (perp=10.349, rec=0.093, cos=0.192), tot_loss_proj:3.075 [t=0.21s]
prediction: ['[CLS] to too going want much about about on think on what [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.007 (perp=8.606, rec=0.097, cos=0.188), tot_loss_proj:2.747 [t=0.21s]
prediction: ['[CLS] to too much want going just about on think s what [SEP]']
[ 300/2000] tot_loss=1.996 (perp=8.606, rec=0.087, cos=0.188), tot_loss_proj:2.754 [t=0.21s]
prediction: ['[CLS] to too much want going just about on think s what [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.810 (perp=7.714, rec=0.076, cos=0.191), tot_loss_proj:2.467 [t=0.21s]
prediction: ['[CLS] to too much want going just about on what s think [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.685 (perp=7.120, rec=0.070, cos=0.192), tot_loss_proj:2.275 [t=0.21s]
prediction: ['[CLS] to too much want going on about just what s think [SEP]']
[ 450/2000] tot_loss=1.680 (perp=7.120, rec=0.065, cos=0.192), tot_loss_proj:2.275 [t=0.21s]
prediction: ['[CLS] to too much want going on about just what s think [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.592 (perp=6.655, rec=0.070, cos=0.191), tot_loss_proj:2.219 [t=0.21s]
prediction: ['[CLS] to too much want what s going on about just think [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.575 (perp=6.533, rec=0.073, cos=0.195), tot_loss_proj:2.149 [t=0.21s]
prediction: ['[CLS] to too much want what s going on think about just [SEP]']
[ 600/2000] tot_loss=1.567 (perp=6.533, rec=0.067, cos=0.194), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] to too much want what s going on think about just [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.495 (perp=6.203, rec=0.062, cos=0.192), tot_loss_proj:2.184 [t=0.21s]
prediction: ['[CLS] too much to want what s going on think about just [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.439 (perp=5.895, rec=0.071, cos=0.190), tot_loss_proj:2.113 [t=0.21s]
prediction: ['[CLS] too much to want just what s going on think about [SEP]']
[ 750/2000] tot_loss=1.444 (perp=5.895, rec=0.070, cos=0.195), tot_loss_proj:2.110 [t=0.21s]
prediction: ['[CLS] too much to want just what s going on think about [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.449 (perp=5.895, rec=0.075, cos=0.195), tot_loss_proj:2.106 [t=0.21s]
prediction: ['[CLS] too much to want just what s going on think about [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.448 (perp=5.895, rec=0.074, cos=0.195), tot_loss_proj:2.117 [t=0.21s]
prediction: ['[CLS] too much to want just what s going on think about [SEP]']
[ 900/2000] tot_loss=1.444 (perp=5.895, rec=0.073, cos=0.192), tot_loss_proj:2.109 [t=0.21s]
prediction: ['[CLS] too much to want just what s going on think about [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.440 (perp=5.895, rec=0.067, cos=0.194), tot_loss_proj:2.107 [t=0.21s]
prediction: ['[CLS] too much to want just what s going on think about [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.371 (perp=5.545, rec=0.069, cos=0.193), tot_loss_proj:2.082 [t=0.21s]
prediction: ['[CLS] too much to want think about just what s going on [SEP]']
[1050/2000] tot_loss=1.371 (perp=5.545, rec=0.070, cos=0.192), tot_loss_proj:2.081 [t=0.21s]
prediction: ['[CLS] too much to want think about just what s going on [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.231 (perp=4.827, rec=0.071, cos=0.195), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] too much want to think about just what s going on [SEP]']
Attempt swap
[1150/2000] tot_loss=1.226 (perp=4.827, rec=0.068, cos=0.193), tot_loss_proj:1.803 [t=0.21s]
prediction: ['[CLS] too much want to think about just what s going on [SEP]']
[1200/2000] tot_loss=1.224 (perp=4.827, rec=0.064, cos=0.195), tot_loss_proj:1.808 [t=0.21s]
prediction: ['[CLS] too much want to think about just what s going on [SEP]']
Attempt swap
[1250/2000] tot_loss=1.219 (perp=4.827, rec=0.062, cos=0.192), tot_loss_proj:1.798 [t=0.21s]
prediction: ['[CLS] too much want to think about just what s going on [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.210 (perp=4.723, rec=0.071, cos=0.195), tot_loss_proj:1.816 [t=0.21s]
prediction: ['[CLS] too much want to just think about what s going on [SEP]']
[1350/2000] tot_loss=1.211 (perp=4.723, rec=0.073, cos=0.194), tot_loss_proj:1.809 [t=0.21s]
prediction: ['[CLS] too much want to just think about what s going on [SEP]']
Attempt swap
[1400/2000] tot_loss=1.203 (perp=4.723, rec=0.065, cos=0.194), tot_loss_proj:1.810 [t=0.21s]
prediction: ['[CLS] too much want to just think about what s going on [SEP]']
Attempt swap
[1450/2000] tot_loss=1.209 (perp=4.723, rec=0.070, cos=0.195), tot_loss_proj:1.815 [t=0.21s]
prediction: ['[CLS] too much want to just think about what s going on [SEP]']
[1500/2000] tot_loss=1.204 (perp=4.723, rec=0.064, cos=0.195), tot_loss_proj:1.805 [t=0.21s]
prediction: ['[CLS] too much want to just think about what s going on [SEP]']
Attempt swap
[1550/2000] tot_loss=1.207 (perp=4.723, rec=0.068, cos=0.194), tot_loss_proj:1.808 [t=0.21s]
prediction: ['[CLS] too much want to just think about what s going on [SEP]']
Attempt swap
[1600/2000] tot_loss=1.202 (perp=4.723, rec=0.063, cos=0.194), tot_loss_proj:1.805 [t=0.21s]
prediction: ['[CLS] too much want to just think about what s going on [SEP]']
[1650/2000] tot_loss=1.202 (perp=4.723, rec=0.064, cos=0.194), tot_loss_proj:1.815 [t=0.21s]
prediction: ['[CLS] too much want to just think about what s going on [SEP]']
Attempt swap
[1700/2000] tot_loss=1.210 (perp=4.723, rec=0.071, cos=0.194), tot_loss_proj:1.805 [t=0.21s]
prediction: ['[CLS] too much want to just think about what s going on [SEP]']
Attempt swap
[1750/2000] tot_loss=1.214 (perp=4.723, rec=0.075, cos=0.194), tot_loss_proj:1.810 [t=0.21s]
prediction: ['[CLS] too much want to just think about what s going on [SEP]']
[1800/2000] tot_loss=1.204 (perp=4.723, rec=0.065, cos=0.195), tot_loss_proj:1.812 [t=0.21s]
prediction: ['[CLS] too much want to just think about what s going on [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.204 (perp=4.685, rec=0.073, cos=0.194), tot_loss_proj:1.788 [t=0.21s]
prediction: ['[CLS] just too much want to think about what s going on [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.113 (perp=4.221, rec=0.075, cos=0.194), tot_loss_proj:1.407 [t=0.21s]
prediction: ['[CLS] just want to think too much about what s going on [SEP]']
[1950/2000] tot_loss=1.104 (perp=4.221, rec=0.066, cos=0.193), tot_loss_proj:1.401 [t=0.21s]
prediction: ['[CLS] just want to think too much about what s going on [SEP]']
Attempt swap
[2000/2000] tot_loss=1.109 (perp=4.221, rec=0.071, cos=0.194), tot_loss_proj:1.400 [t=0.22s]
prediction: ['[CLS] just want to think too much about what s going on [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] too much want to just think about what s going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 60.870 | p: 58.333 | r: 63.636
rougeL     | fm: 80.000 | p: 76.923 | r: 83.333
rougeLsum  | fm: 80.000 | p: 76.923 | r: 83.333
r1fm+r2fm = 156.870

[Aggregate metrics]:
rouge1     | fm: 89.727 | p: 88.728 | r: 90.979
rouge2     | fm: 56.518 | p: 55.887 | r: 57.076
rougeL     | fm: 80.362 | p: 79.435 | r: 81.398
rougeLsum  | fm: 80.098 | p: 79.168 | r: 81.289
r1fm+r2fm = 146.245

input #17 time: 0:08:29 | total time: 2:36:09


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.8150884928859421
highest_index [0]
highest [0.8150884928859421]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9755086898803711 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9114372730255127 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.8746640086174011 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.8692384958267212 for ['[CLS]cs finally long throat [SEP]']
[Init] best rec loss: 0.8534244298934937 for ['[CLS] master asteroidnagar fungi [SEP]']
[Init] best rec loss: 0.831200361251831 for ['[CLS] alternativelastic garrett filed [SEP]']
[Init] best rec loss: 0.827423095703125 for ['[CLS] picked motto squadron siam [SEP]']
[Init] best perm rec loss: 0.8254095911979675 for ['[CLS] squadron motto siam picked [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.289 (perp=13.371, rec=0.276, cos=0.339), tot_loss_proj:3.691 [t=0.22s]
prediction: ['[CLS]ating wide distinguishedgor [SEP]']
[ 100/2000] tot_loss=3.014 (perp=12.400, rec=0.198, cos=0.336), tot_loss_proj:4.321 [t=0.22s]
prediction: ['[CLS]atinggorgorgor [SEP]']
[ 150/2000] tot_loss=3.427 (perp=14.811, rec=0.134, cos=0.332), tot_loss_proj:4.705 [t=0.22s]
prediction: ['[CLS]atingvigorgor [SEP]']
[ 200/2000] tot_loss=3.081 (perp=13.226, rec=0.104, cos=0.332), tot_loss_proj:4.339 [t=0.22s]
prediction: ['[CLS]atingvivigor [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.159 (perp=8.482, rec=0.129, cos=0.333), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS]vivigorating [SEP]']
[ 300/2000] tot_loss=2.139 (perp=8.482, rec=0.110, cos=0.333), tot_loss_proj:2.368 [t=0.22s]
prediction: ['[CLS]vivigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.141 (perp=8.482, rec=0.107, cos=0.337), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS]vivigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.135 (perp=8.482, rec=0.106, cos=0.332), tot_loss_proj:2.374 [t=0.22s]
prediction: ['[CLS]vivigorating [SEP]']
[ 450/2000] tot_loss=2.121 (perp=8.482, rec=0.090, cos=0.334), tot_loss_proj:2.355 [t=0.22s]
prediction: ['[CLS]vivigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.132 (perp=8.482, rec=0.100, cos=0.335), tot_loss_proj:2.363 [t=0.22s]
prediction: ['[CLS]vivigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.116 (perp=8.482, rec=0.083, cos=0.336), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS]vivigorating [SEP]']
[ 600/2000] tot_loss=2.128 (perp=8.482, rec=0.094, cos=0.337), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS]vivigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.315 (perp=9.401, rec=0.098, cos=0.337), tot_loss_proj:2.765 [t=0.22s]
prediction: ['[CLS]vi ingorating [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.540 (perp=5.588, rec=0.086, cos=0.336), tot_loss_proj:1.509 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.545 (perp=5.588, rec=0.090, cos=0.337), tot_loss_proj:1.515 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.534 (perp=5.588, rec=0.081, cos=0.335), tot_loss_proj:1.524 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.546 (perp=5.588, rec=0.093, cos=0.335), tot_loss_proj:1.524 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.533 (perp=5.588, rec=0.082, cos=0.334), tot_loss_proj:1.505 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.533 (perp=5.588, rec=0.081, cos=0.334), tot_loss_proj:1.511 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.537 (perp=5.588, rec=0.085, cos=0.334), tot_loss_proj:1.519 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.525 (perp=5.588, rec=0.071, cos=0.336), tot_loss_proj:1.511 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.533 (perp=5.588, rec=0.080, cos=0.336), tot_loss_proj:1.514 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.533 (perp=5.588, rec=0.082, cos=0.334), tot_loss_proj:1.518 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.531 (perp=5.588, rec=0.078, cos=0.335), tot_loss_proj:1.521 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.525 (perp=5.588, rec=0.073, cos=0.335), tot_loss_proj:1.526 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.527 (perp=5.588, rec=0.074, cos=0.336), tot_loss_proj:1.504 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.520 (perp=5.588, rec=0.067, cos=0.335), tot_loss_proj:1.502 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.535 (perp=5.588, rec=0.083, cos=0.335), tot_loss_proj:1.506 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.534 (perp=5.588, rec=0.081, cos=0.335), tot_loss_proj:1.521 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.534 (perp=5.588, rec=0.082, cos=0.335), tot_loss_proj:1.508 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.528 (perp=5.588, rec=0.074, cos=0.336), tot_loss_proj:1.512 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.520 (perp=5.588, rec=0.067, cos=0.335), tot_loss_proj:1.509 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.529 (perp=5.588, rec=0.074, cos=0.336), tot_loss_proj:1.511 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.515 (perp=5.588, rec=0.062, cos=0.335), tot_loss_proj:1.517 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.527 (perp=5.588, rec=0.075, cos=0.335), tot_loss_proj:1.510 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.528 (perp=5.588, rec=0.075, cos=0.335), tot_loss_proj:1.532 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.527 (perp=5.588, rec=0.073, cos=0.336), tot_loss_proj:1.501 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.533 (perp=5.588, rec=0.079, cos=0.336), tot_loss_proj:1.520 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.526 (perp=5.588, rec=0.073, cos=0.336), tot_loss_proj:1.516 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.523 (perp=5.588, rec=0.069, cos=0.336), tot_loss_proj:1.523 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.371 | p: 89.366 | r: 91.579
rouge2     | fm: 58.075 | p: 57.578 | r: 58.711
rougeL     | fm: 81.152 | p: 80.237 | r: 82.053
rougeLsum  | fm: 81.272 | p: 80.308 | r: 82.252
r1fm+r2fm = 148.446

input #18 time: 0:08:42 | total time: 2:44:51


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9111178878216968
highest_index [0]
highest [0.9111178878216968]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7263354063034058 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7177427411079407 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7106854915618896 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.6852420568466187 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6745012402534485 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6732726097106934 for ['[CLS] pin reaching orderyna [SEP]']
[Init] best perm rec loss: 0.6732628345489502 for ['[CLS] order reaching pinyna [SEP]']
[Init] best perm rec loss: 0.6711360216140747 for ['[CLS] order reachingyna pin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.938 (perp=7.158, rec=0.318, cos=0.189), tot_loss_proj:2.030 [t=0.22s]
prediction: ['[CLS]fa infamy [SEP]']
[ 100/2000] tot_loss=1.751 (perp=7.158, rec=0.155, cos=0.164), tot_loss_proj:2.027 [t=0.22s]
prediction: ['[CLS]fa infamy [SEP]']
[ 150/2000] tot_loss=2.819 (perp=12.795, rec=0.093, cos=0.167), tot_loss_proj:4.216 [t=0.22s]
prediction: ['[CLS]fa to inmy [SEP]']
[ 200/2000] tot_loss=2.805 (perp=12.795, rec=0.080, cos=0.167), tot_loss_proj:4.209 [t=0.22s]
prediction: ['[CLS]fa to inmy [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.477 (perp=6.110, rec=0.086, cos=0.169), tot_loss_proj:1.480 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.485 (perp=6.110, rec=0.087, cos=0.176), tot_loss_proj:1.486 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.460 (perp=6.110, rec=0.071, cos=0.167), tot_loss_proj:1.471 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.449 (perp=6.110, rec=0.059, cos=0.168), tot_loss_proj:1.478 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.464 (perp=6.110, rec=0.076, cos=0.166), tot_loss_proj:1.480 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.459 (perp=6.110, rec=0.068, cos=0.169), tot_loss_proj:1.472 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.462 (perp=6.110, rec=0.069, cos=0.171), tot_loss_proj:1.479 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.456 (perp=6.110, rec=0.064, cos=0.170), tot_loss_proj:1.496 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.456 (perp=6.110, rec=0.066, cos=0.168), tot_loss_proj:1.487 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.461 (perp=6.110, rec=0.072, cos=0.167), tot_loss_proj:1.482 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.454 (perp=6.110, rec=0.064, cos=0.169), tot_loss_proj:1.496 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.454 (perp=6.110, rec=0.065, cos=0.167), tot_loss_proj:1.490 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.453 (perp=6.110, rec=0.064, cos=0.168), tot_loss_proj:1.475 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.454 (perp=6.110, rec=0.064, cos=0.169), tot_loss_proj:1.471 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.463 (perp=6.110, rec=0.071, cos=0.170), tot_loss_proj:1.485 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.449 (perp=6.110, rec=0.060, cos=0.167), tot_loss_proj:1.478 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.464 (perp=6.110, rec=0.073, cos=0.169), tot_loss_proj:1.480 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.460 (perp=6.110, rec=0.068, cos=0.170), tot_loss_proj:1.486 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.448 (perp=6.110, rec=0.057, cos=0.169), tot_loss_proj:1.482 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.457 (perp=6.110, rec=0.066, cos=0.168), tot_loss_proj:1.470 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.456 (perp=6.110, rec=0.066, cos=0.168), tot_loss_proj:1.481 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.460 (perp=6.110, rec=0.069, cos=0.169), tot_loss_proj:1.471 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.448 (perp=6.110, rec=0.057, cos=0.169), tot_loss_proj:1.477 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.455 (perp=6.110, rec=0.064, cos=0.168), tot_loss_proj:1.489 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.468 (perp=6.110, rec=0.077, cos=0.169), tot_loss_proj:1.481 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.457 (perp=6.110, rec=0.066, cos=0.168), tot_loss_proj:1.485 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.470 (perp=6.110, rec=0.079, cos=0.169), tot_loss_proj:1.477 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.460 (perp=6.110, rec=0.070, cos=0.168), tot_loss_proj:1.494 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.446 (perp=6.110, rec=0.056, cos=0.168), tot_loss_proj:1.483 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.461 (perp=6.110, rec=0.071, cos=0.168), tot_loss_proj:1.476 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.467 (perp=6.110, rec=0.076, cos=0.169), tot_loss_proj:1.488 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.464 (perp=6.110, rec=0.072, cos=0.170), tot_loss_proj:1.483 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.452 (perp=6.110, rec=0.061, cos=0.169), tot_loss_proj:1.478 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.460 (perp=6.110, rec=0.069, cos=0.169), tot_loss_proj:1.480 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.447 (perp=6.110, rec=0.057, cos=0.169), tot_loss_proj:1.479 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.445 (perp=6.110, rec=0.054, cos=0.168), tot_loss_proj:1.489 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.860 | p: 89.958 | r: 91.970
rouge2     | fm: 60.746 | p: 60.318 | r: 61.431
rougeL     | fm: 82.414 | p: 81.550 | r: 83.418
rougeLsum  | fm: 82.167 | p: 81.293 | r: 83.171
r1fm+r2fm = 151.606

input #19 time: 0:08:42 | total time: 2:53:34


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.8492905537599166
highest_index [0]
highest [0.8492905537599166]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.865050733089447 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.7922491431236267 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 0.791733980178833 for ['[CLS] historically hiroshima stand wing [SEP]']
[Init] best rec loss: 0.7789856791496277 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best perm rec loss: 0.7779870629310608 for ['[CLS] storyline [CLS]nessxi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.599 (perp=10.350, rec=0.253, cos=0.276), tot_loss_proj:3.367 [t=0.22s]
prediction: ['[CLS]verse pleasureverseverse [SEP]']
[ 100/2000] tot_loss=2.210 (perp=9.065, rec=0.117, cos=0.280), tot_loss_proj:2.935 [t=0.22s]
prediction: ['[CLS] the pleasureverseverse [SEP]']
[ 150/2000] tot_loss=1.920 (perp=7.784, rec=0.085, cos=0.278), tot_loss_proj:2.155 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 200/2000] tot_loss=1.912 (perp=7.784, rec=0.085, cos=0.271), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.896 (perp=7.784, rec=0.067, cos=0.272), tot_loss_proj:2.153 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 300/2000] tot_loss=1.902 (perp=7.784, rec=0.073, cos=0.272), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.914 (perp=7.784, rec=0.082, cos=0.274), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.917 (perp=7.784, rec=0.077, cos=0.283), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 450/2000] tot_loss=1.902 (perp=7.784, rec=0.075, cos=0.270), tot_loss_proj:2.159 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.894 (perp=7.784, rec=0.064, cos=0.273), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.900 (perp=7.784, rec=0.068, cos=0.275), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 600/2000] tot_loss=1.910 (perp=7.784, rec=0.080, cos=0.273), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.894 (perp=7.784, rec=0.061, cos=0.276), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.889 (perp=7.784, rec=0.056, cos=0.275), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 750/2000] tot_loss=1.896 (perp=7.784, rec=0.065, cos=0.274), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.913 (perp=7.784, rec=0.079, cos=0.277), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.905 (perp=7.784, rec=0.070, cos=0.278), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 900/2000] tot_loss=1.900 (perp=7.784, rec=0.070, cos=0.274), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.902 (perp=7.784, rec=0.068, cos=0.277), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.862 (perp=7.610, rec=0.062, cos=0.278), tot_loss_proj:1.909 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.870 (perp=7.610, rec=0.070, cos=0.278), tot_loss_proj:1.925 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.865 (perp=7.610, rec=0.067, cos=0.276), tot_loss_proj:1.914 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.872 (perp=7.610, rec=0.071, cos=0.279), tot_loss_proj:1.919 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.857 (perp=7.610, rec=0.059, cos=0.276), tot_loss_proj:1.915 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.858 (perp=7.610, rec=0.061, cos=0.275), tot_loss_proj:1.913 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.854 (perp=7.610, rec=0.055, cos=0.277), tot_loss_proj:1.911 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.871 (perp=7.610, rec=0.071, cos=0.278), tot_loss_proj:1.913 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.856 (perp=7.610, rec=0.059, cos=0.275), tot_loss_proj:1.919 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.855 (perp=7.610, rec=0.057, cos=0.276), tot_loss_proj:1.916 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.861 (perp=7.610, rec=0.063, cos=0.275), tot_loss_proj:1.909 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.859 (perp=7.610, rec=0.060, cos=0.277), tot_loss_proj:1.921 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.862 (perp=7.610, rec=0.063, cos=0.277), tot_loss_proj:1.909 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.864 (perp=7.610, rec=0.064, cos=0.278), tot_loss_proj:1.914 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.864 (perp=7.610, rec=0.063, cos=0.279), tot_loss_proj:1.917 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.852 (perp=7.610, rec=0.055, cos=0.275), tot_loss_proj:1.914 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.861 (perp=7.610, rec=0.062, cos=0.277), tot_loss_proj:1.920 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.866 (perp=7.610, rec=0.066, cos=0.277), tot_loss_proj:1.919 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.856 (perp=7.610, rec=0.057, cos=0.277), tot_loss_proj:1.915 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.856 (perp=7.610, rec=0.056, cos=0.278), tot_loss_proj:1.916 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.849 (perp=7.610, rec=0.050, cos=0.277), tot_loss_proj:1.911 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.278 | p: 90.406 | r: 92.251
rouge2     | fm: 62.591 | p: 62.138 | r: 63.187
rougeL     | fm: 83.226 | p: 82.469 | r: 84.176
rougeLsum  | fm: 82.950 | p: 82.100 | r: 83.862
r1fm+r2fm = 153.869

input #20 time: 0:08:42 | total time: 3:02:16


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.8900386023427219
highest_index [0]
highest [0.8900386023427219]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.8421233892440796 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8120483756065369 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.794221043586731 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.789230227470398 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.7785874009132385 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.7678492665290833 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 0.7661446332931519 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 0.7644670009613037 for ['[CLS] pose bent rights vii labor loanback dee, itemtaking general fauna stony size she connecticut side according especially golden situations [UNK] baby there [SEP]']
[Init] best perm rec loss: 0.7638691067695618 for ['[CLS] loan especially situations [UNK], labor according general sidetakingback item bent baby connecticut fauna stony there rights vii golden size pose dee she [SEP]']
[Init] best perm rec loss: 0.7638182044029236 for ['[CLS] according there item vii [UNK] stony rights size golden labor benttaking baby general, connecticutback pose side situations she fauna dee especially loan [SEP]']
[Init] best perm rec loss: 0.763286292552948 for ['[CLS] situations item pose deetaking especially baby general [UNK] stony vii side rights she loan golden there bent laborback fauna size, according connecticut [SEP]']
[Init] best perm rec loss: 0.7631317973136902 for ['[CLS] [UNK] fauna side sizetaking she stony, general item dee baby situations vii according especially pose goldenback labor connecticut there loan bent rights [SEP]']
[Init] best perm rec loss: 0.7618731260299683 for ['[CLS] especiallytaking, size loan vii rights pose connecticut side she item labor [UNK] there bent situations fauna baby stonyback according golden general dee [SEP]']
[Init] best perm rec loss: 0.7617232203483582 for ['[CLS] size loan golden according side fauna stony item there general vii she [UNK] especially situations pose labor connecticuttaking,back bent dee baby rights [SEP]']
[Init] best perm rec loss: 0.7615683078765869 for ['[CLS] bentback dee fauna, she situations golden connecticut pose especially item theretaking general baby stony rights according labor side loan size [UNK] vii [SEP]']
[Init] best perm rec loss: 0.7615567445755005 for ['[CLS] general fauna according there golden [UNK] vii rightsback pose she connecticut situations labor size stony item, babytaking dee especially side loan bent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.199 (perp=12.992, rec=0.390, cos=0.211), tot_loss_proj:3.762 [t=0.22s]
prediction: ['[CLS] subspecies newt many worst married the claims gender syndrome bankruptcy because college cases promotional women during complex guys freshman japanese bandage because tigers taxkr [SEP]']
[ 100/2000] tot_loss=2.811 (perp=11.319, rec=0.335, cos=0.212), tot_loss_proj:3.839 [t=0.22s]
prediction: ['[CLS] indies police many instead of women violent gender died doing is a cases australian become alongside better person teachersers athletes look findings organizations when [SEP]']
[ 150/2000] tot_loss=2.828 (perp=11.602, rec=0.304, cos=0.204), tot_loss_proj:3.782 [t=0.22s]
prediction: ['[CLS] waydick many instead of women how benches died works all a roles australian females sounded typical passengers seriousers athletes. 978 athletes when [SEP]']
[ 200/2000] tot_loss=2.810 (perp=11.826, rec=0.248, cos=0.197), tot_loss_proj:3.794 [t=0.22s]
prediction: ['[CLS] way colors everyone instead serious women way works died works all out way four portrayed looked typical gunmen serious athletes athletes serious players athletes when [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.533 (perp=10.588, rec=0.213, cos=0.202), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] worksness connor works works out way women image looked typical soldiers instead serious women way works - serious athletes athletes serious players athletes because [SEP]']
[ 300/2000] tot_loss=2.351 (perp=9.837, rec=0.182, cos=0.201), tot_loss_proj:3.760 [t=0.22s]
prediction: ['[CLS] that makes this works works out all women stereo looked typical caretaker instead serious women way works - serious athletes athletes serious women athletes because [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.024 (perp=8.388, rec=0.149, cos=0.198), tot_loss_proj:2.927 [t=0.22s]
prediction: ['[CLS] that makes stereo works works out all women this look like caretaker instead of women way works of serious athletes athletes serious women athletes because [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.000 (perp=8.295, rec=0.144, cos=0.196), tot_loss_proj:2.591 [t=0.22s]
prediction: ['[CLS] this makes stereo works out all women this look like caretaker works instead of women way works - serious athletes teachers serious women athletes because [SEP]']
[ 450/2000] tot_loss=1.985 (perp=8.242, rec=0.134, cos=0.203), tot_loss_proj:2.656 [t=0.22s]
prediction: ['[CLS] this makes stereo works out all women this look like caretaker works instead of women way works - serious athletes teachers serious women athletes like [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.981 (perp=8.268, rec=0.124, cos=0.203), tot_loss_proj:2.776 [t=0.22s]
prediction: ['[CLS] all makes stereo works out out women look like caretaker works instead of women this way works, serious athletes teachers serious women athletes like [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.063 (perp=8.703, rec=0.116, cos=0.206), tot_loss_proj:2.906 [t=0.22s]
prediction: ['[CLS] all makes stereo works out out women look liketypical works instead of women this way moral, serious athletes teachers serious women. athletes [SEP]']
[ 600/2000] tot_loss=2.135 (perp=9.082, rec=0.119, cos=0.200), tot_loss_proj:2.905 [t=0.22s]
prediction: ['[CLS] all makes stereo works out out women look liketypical works instead of women this way moral, serious athletes caretaker serious sides. athletes [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.017 (perp=8.502, rec=0.114, cos=0.203), tot_loss_proj:2.792 [t=0.23s]
prediction: ['[CLS] all out stereo works out makes women look liketypical works instead of women this way moral, serious athletes caretaker, sides. athletes [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.958 (perp=8.179, rec=0.120, cos=0.202), tot_loss_proj:2.618 [t=0.22s]
prediction: ['[CLS] all out stereo works out makes women look liketypical works athletes instead of the this way moral, serious athletes caretaker the sides. [SEP]']
[ 750/2000] tot_loss=1.949 (perp=8.160, rec=0.115, cos=0.202), tot_loss_proj:2.822 [t=0.22s]
prediction: ['[CLS] all out more works out makes women look liketypical works athletes instead of the this way moral, serious athletes caretaker the sides. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.889 (perp=7.936, rec=0.100, cos=0.202), tot_loss_proj:2.731 [t=0.22s]
prediction: ['[CLS] more out all works out makes women look liketypical works athletes instead of the this way moral, serious athletes caretaker the sides. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.768 (perp=7.356, rec=0.097, cos=0.200), tot_loss_proj:2.493 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical works athletes instead of the way moral, serious athletes caretaker the sides. [SEP]']
[ 900/2000] tot_loss=1.770 (perp=7.356, rec=0.099, cos=0.200), tot_loss_proj:2.490 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical works athletes instead of the way moral, serious athletes caretaker the sides. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.726 (perp=7.159, rec=0.092, cos=0.201), tot_loss_proj:2.628 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical works athletes instead of the way the moral, serious athletes caretaker sides. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.687 (perp=6.994, rec=0.088, cos=0.200), tot_loss_proj:2.647 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical works athletes instead of the way the moral, serious sides caretaker athletes. [SEP]']
[1050/2000] tot_loss=1.691 (perp=6.994, rec=0.092, cos=0.200), tot_loss_proj:2.642 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical works athletes instead of the way the moral, serious sides caretaker athletes. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.678 (perp=6.903, rec=0.096, cos=0.201), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical athletes instead of works the way the moral, serious sides caretaker athletes. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.675 (perp=6.903, rec=0.093, cos=0.201), tot_loss_proj:2.244 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical athletes instead of works the way the moral, serious sides caretaker athletes. [SEP]']
[1200/2000] tot_loss=1.674 (perp=6.903, rec=0.092, cos=0.201), tot_loss_proj:2.246 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical athletes instead of works the way the moral, serious sides caretaker athletes. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.673 (perp=6.903, rec=0.090, cos=0.202), tot_loss_proj:2.246 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical athletes instead of works the way the moral, serious sides caretaker athletes. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.674 (perp=6.903, rec=0.089, cos=0.204), tot_loss_proj:2.248 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical athletes instead of works the way the moral, serious sides caretaker athletes. [SEP]']
[1350/2000] tot_loss=1.665 (perp=6.903, rec=0.081, cos=0.203), tot_loss_proj:2.242 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical athletes instead of works the way the moral, serious sides caretaker athletes. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.673 (perp=6.903, rec=0.087, cos=0.205), tot_loss_proj:2.241 [t=0.22s]
prediction: ['[CLS] this more out all works out makes women look liketypical athletes instead of works the way the moral, serious sides caretaker athletes. [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.703 (perp=7.061, rec=0.086, cos=0.204), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] this more out all works out makestypical women look like athletes instead of works the way like moral, serious sides caretaker athletes. [SEP]']
[1500/2000] tot_loss=1.702 (perp=7.061, rec=0.087, cos=0.203), tot_loss_proj:2.216 [t=0.22s]
prediction: ['[CLS] this more out all works out makestypical women look like athletes instead of works the way like moral, serious sides caretaker athletes. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.676 (perp=6.932, rec=0.086, cos=0.204), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] this more out all works out makes caretaker women look like athletes instead of works the way like moral, serious sidestypical athletes. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.661 (perp=6.868, rec=0.083, cos=0.204), tot_loss_proj:2.208 [t=0.22s]
prediction: ['[CLS] this more out all works out makes caretaker women look like athletes instead of works way like the moral, serious sidestypical athletes. [SEP]']
[1650/2000] tot_loss=1.667 (perp=6.868, rec=0.089, cos=0.204), tot_loss_proj:2.208 [t=0.22s]
prediction: ['[CLS] this more out all works out makes caretaker women look like athletes instead of works way like the moral, serious sidestypical athletes. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.613 (perp=6.601, rec=0.091, cos=0.202), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] this out all works out makes caretaker women look like athletes instead of works way more like the moral, serious sidestypical athletes. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.600 (perp=6.601, rec=0.077, cos=0.202), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] this out all works out makes caretaker women look like athletes instead of works way more like the moral, serious sidestypical athletes. [SEP]']
[1800/2000] tot_loss=1.610 (perp=6.601, rec=0.087, cos=0.202), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] this out all works out makes caretaker women look like athletes instead of works way more like the moral, serious sidestypical athletes. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.609 (perp=6.601, rec=0.086, cos=0.203), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] this out all works out makes caretaker women look like athletes instead of works way more like the moral, serious sidestypical athletes. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.507 (perp=6.100, rec=0.083, cos=0.204), tot_loss_proj:2.022 [t=0.23s]
prediction: ['[CLS] this way all works out makes caretaker women look like athletes instead of works out more like the moral, serious sidestypical athletes. [SEP]']
[1950/2000] tot_loss=1.509 (perp=6.100, rec=0.086, cos=0.203), tot_loss_proj:2.026 [t=0.22s]
prediction: ['[CLS] this way all works out makes caretaker women look like athletes instead of works out more like the moral, serious sidestypical athletes. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.497 (perp=6.018, rec=0.089, cos=0.204), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] this way all works out makes caretaker women look like athletes instead of works out like the more moral, serious sidestypical athletes. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] this out all works out makes caretaker women look like athletes instead of works way more like the moral, serious sidestypical athletes. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.596 | p: 75.000 | r: 78.261
rouge2     | fm: 31.111 | p: 30.435 | r: 31.818
rougeL     | fm: 59.574 | p: 58.333 | r: 60.870
rougeLsum  | fm: 59.574 | p: 58.333 | r: 60.870
r1fm+r2fm = 107.707

[Aggregate metrics]:
rouge1     | fm: 90.470 | p: 89.529 | r: 91.597
rouge2     | fm: 60.980 | p: 60.376 | r: 61.491
rougeL     | fm: 82.017 | p: 81.162 | r: 82.929
rougeLsum  | fm: 81.707 | p: 80.932 | r: 82.755
r1fm+r2fm = 151.451

input #21 time: 0:08:47 | total time: 3:11:04


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.8414787748696155
highest_index [0]
highest [0.8414787748696155]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9829205870628357 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.972723126411438 for ['[CLS] catalogue scom de respiratory z loose ps eventual cart win [SEP]']
[Init] best rec loss: 0.9612263441085815 for ['[CLS] mines ) organ yes deck sessions mainly steady introduction arson dates [SEP]']
[Init] best rec loss: 0.954835057258606 for ['[CLS]dbus leaguedel more arrest able communists confederatedgetsomics [SEP]']
[Init] best rec loss: 0.9523500800132751 for ['[CLS] kali camp missiondio but whispered mining paulaville atmosphere qu [SEP]']
[Init] best rec loss: 0.9512541890144348 for ['[CLS]vi dudley sponsored then background che opposition laurencefc feat double [SEP]']
[Init] best rec loss: 0.9512150287628174 for ['[CLS] view masters sheets bar separated emigrated play career traitor marriedory [SEP]']
[Init] best rec loss: 0.94118732213974 for ['[CLS]ou apartowskilizer teaching collins wolfe sample rite maze kaiser [SEP]']
[Init] best rec loss: 0.9344699382781982 for ['[CLS] kids function phoenix chinese set boarders over her schedule laughter [SEP]']
[Init] best perm rec loss: 0.9343096017837524 for ['[CLS] over chinese laughterers her kids board function phoenix set schedule [SEP]']
[Init] best perm rec loss: 0.9342873096466064 for ['[CLS] over laughter boarders function kids phoenix her schedule chinese set [SEP]']
[Init] best perm rec loss: 0.9340804219245911 for ['[CLS] over schedule board chinese function laughter her set kidsers phoenix [SEP]']
[Init] best perm rec loss: 0.9330028891563416 for ['[CLS]ers schedule her function kids board chinese set over laughter phoenix [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.717 (perp=13.080, rec=0.625, cos=0.476), tot_loss_proj:4.278 [t=0.22s]
prediction: ['[CLS] dead killing tumor taken 2013 definitionsze pools default relatingal [SEP]']
[ 100/2000] tot_loss=3.409 (perp=12.273, rec=0.559, cos=0.395), tot_loss_proj:4.044 [t=0.22s]
prediction: ['[CLS] a enjoyable affairs my 1967 definitions quiteilation default carolineal [SEP]']
[ 150/2000] tot_loss=3.694 (perp=13.637, rec=0.561, cos=0.405), tot_loss_proj:4.419 [t=0.22s]
prediction: ['[CLS] a filming asleep oriented 1967 cdp quiteilationwice caroline concerning [SEP]']
[ 200/2000] tot_loss=3.060 (perp=11.340, rec=0.499, cos=0.292), tot_loss_proj:4.283 [t=0.22s]
prediction: ['[CLS] a successful disappointment adaptation enjoy enjoyable ailation fivb enjoyable & [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.265 (perp=12.345, rec=0.487, cos=0.309), tot_loss_proj:3.994 [t=0.22s]
prediction: ['[CLS] a successful stigma successful adaptation conceal a犬itaire enjoyableয [SEP]']
[ 300/2000] tot_loss=2.857 (perp=10.463, rec=0.464, cos=0.300), tot_loss_proj:3.091 [t=0.22s]
prediction: ['[CLS] a successful therefore successful adaptation enjoy another enjoyableitaire enjoyable paragraph [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.837 (perp=10.533, rec=0.436, cos=0.295), tot_loss_proj:3.102 [t=0.22s]
prediction: ['[CLS] a enjoyable therefore affairs adaptation enjoy a enjoyable frankly enjoyableitaire [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.151 (perp=12.055, rec=0.450, cos=0.290), tot_loss_proj:3.565 [t=0.22s]
prediction: ['[CLS] a enjoyable besides affairs adaptation enjoyable another centurynson enjoyableitaire [SEP]']
[ 450/2000] tot_loss=3.041 (perp=11.666, rec=0.425, cos=0.282), tot_loss_proj:3.633 [t=0.22s]
prediction: ['[CLS] a enjoyable therefore affairs adaptation enjoyable another centurypersonal enjoyableitaire [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.001 (perp=11.493, rec=0.414, cos=0.289), tot_loss_proj:3.543 [t=0.22s]
prediction: ['[CLS] a up enjoyable affairs adaptation enjoyable another centurypersonal enjoyableitaire [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.361 (perp=13.019, rec=0.464, cos=0.293), tot_loss_proj:4.285 [t=0.22s]
prediction: ['[CLS] a adaptation enjoyable affairs adaptation stigma several centurypersonal enjoyableitaire [SEP]']
[ 600/2000] tot_loss=3.059 (perp=11.718, rec=0.424, cos=0.291), tot_loss_proj:3.508 [t=0.22s]
prediction: ['[CLS] a adaptation enjoyable affairs adaptation up successful enjoypersonal enjoyableitaire [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.889 (perp=10.980, rec=0.415, cos=0.278), tot_loss_proj:3.252 [t=0.22s]
prediction: ['[CLS] a adaptation enjoyable good adaptation up successful enjoyable consideration enjoyitaire [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.170 (perp=11.897, rec=0.488, cos=0.302), tot_loss_proj:4.021 [t=0.22s]
prediction: ['[CLS] a wrong serialized download adaptation up another enjoyable consideration dictatorshipitaire [SEP]']
[ 750/2000] tot_loss=2.995 (perp=11.352, rec=0.434, cos=0.290), tot_loss_proj:4.289 [t=0.22s]
prediction: ['[CLS] a lost enjoyable download adaptation up successful enjoyable consideration centuryitaire [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.803 (perp=10.432, rec=0.426, cos=0.291), tot_loss_proj:3.546 [t=0.22s]
prediction: ['[CLS] a lost century enjoyable download adaptation up successful enjoyable considerationitaire [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.703 (perp=9.971, rec=0.413, cos=0.296), tot_loss_proj:3.262 [t=0.22s]
prediction: ['[CLS] a lost century enjoyable enjoyable adaptation up successful enjoyable considerationitaire [SEP]']
[ 900/2000] tot_loss=2.774 (perp=10.402, rec=0.413, cos=0.281), tot_loss_proj:3.858 [t=0.22s]
prediction: ['[CLS] a lost enjoy enjoyable enjoyable adaptation up successful enjoyable considerationitaire [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.798 (perp=10.532, rec=0.400, cos=0.291), tot_loss_proj:3.945 [t=0.22s]
prediction: ['[CLS] a lost enjoyable enjoyable enjoy adaptation an successful enjoyable considerationitaire [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.616 (perp=9.643, rec=0.403, cos=0.285), tot_loss_proj:3.755 [t=0.22s]
prediction: ['[CLS] a lost enjoyable enjoyable enjoy adaptation an enjoyable successful considerationitaire [SEP]']
[1050/2000] tot_loss=2.619 (perp=9.676, rec=0.398, cos=0.286), tot_loss_proj:3.778 [t=0.23s]
prediction: ['[CLS] a lost enjoyable enjoyable enjoyable adaptation an enjoyable successful considerationitaire [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.577 (perp=9.450, rec=0.397, cos=0.289), tot_loss_proj:3.717 [t=0.22s]
prediction: ['[CLS] a lost enjoyable enjoyable successful adaptation an enjoyable enjoy considerationitaire [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.549 (perp=9.294, rec=0.397, cos=0.293), tot_loss_proj:3.704 [t=0.23s]
prediction: ['[CLS] a lost enjoyable enjoyable successful adaptation enjoy an enjoyable considerationitaire [SEP]']
[1200/2000] tot_loss=2.566 (perp=9.294, rec=0.396, cos=0.311), tot_loss_proj:3.706 [t=0.22s]
prediction: ['[CLS] a lost enjoyable enjoyable successful adaptation enjoy an enjoyable considerationitaire [SEP]']
Attempt swap
[1250/2000] tot_loss=2.519 (perp=9.197, rec=0.390, cos=0.289), tot_loss_proj:2.565 [t=0.22s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable considerationitaire [SEP]']
Attempt swap
[1300/2000] tot_loss=2.520 (perp=9.197, rec=0.393, cos=0.288), tot_loss_proj:2.565 [t=0.22s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable considerationitaire [SEP]']
[1350/2000] tot_loss=2.516 (perp=9.197, rec=0.384, cos=0.293), tot_loss_proj:2.564 [t=0.23s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable considerationitaire [SEP]']
Attempt swap
[1400/2000] tot_loss=2.530 (perp=9.307, rec=0.381, cos=0.287), tot_loss_proj:2.567 [t=0.22s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable consideration roundabout [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.550 (perp=9.364, rec=0.386, cos=0.291), tot_loss_proj:2.576 [t=0.23s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyableitaire consideration [SEP]']
[1500/2000] tot_loss=2.547 (perp=9.364, rec=0.382, cos=0.292), tot_loss_proj:2.573 [t=0.23s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyableitaire consideration [SEP]']
Attempt swap
[1550/2000] tot_loss=2.546 (perp=9.364, rec=0.383, cos=0.291), tot_loss_proj:2.572 [t=0.22s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyableitaire consideration [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.534 (perp=9.307, rec=0.386, cos=0.287), tot_loss_proj:2.574 [t=0.23s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable consideration roundabout [SEP]']
[1650/2000] tot_loss=2.534 (perp=9.307, rec=0.380, cos=0.293), tot_loss_proj:2.572 [t=0.23s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable consideration roundabout [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.542 (perp=9.364, rec=0.379, cos=0.290), tot_loss_proj:2.569 [t=0.23s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyableitaire consideration [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.535 (perp=9.307, rec=0.382, cos=0.291), tot_loss_proj:2.562 [t=0.22s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable consideration roundabout [SEP]']
[1800/2000] tot_loss=2.532 (perp=9.307, rec=0.380, cos=0.291), tot_loss_proj:2.571 [t=0.23s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable consideration roundabout [SEP]']
Attempt swap
[1850/2000] tot_loss=2.527 (perp=9.307, rec=0.374, cos=0.291), tot_loss_proj:2.575 [t=0.22s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable consideration roundabout [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.468 (perp=8.990, rec=0.378, cos=0.292), tot_loss_proj:2.477 [t=0.22s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable roundabout consideration [SEP]']
[1950/2000] tot_loss=2.473 (perp=8.990, rec=0.382, cos=0.293), tot_loss_proj:2.488 [t=0.22s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable roundabout consideration [SEP]']
Attempt swap
[2000/2000] tot_loss=2.469 (perp=8.990, rec=0.379, cos=0.291), tot_loss_proj:2.475 [t=0.23s]
prediction: ['[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable roundabout consideration [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a an enjoyable enjoyable successful adaptation enjoy an enjoyable consideration roundabout [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.846 | p: 53.846 | r: 53.846
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 53.846 | p: 53.846 | r: 53.846
rougeLsum  | fm: 53.846 | p: 53.846 | r: 53.846
r1fm+r2fm = 78.846

[Aggregate metrics]:
rouge1     | fm: 89.099 | p: 88.182 | r: 90.037
rouge2     | fm: 59.196 | p: 58.686 | r: 59.732
rougeL     | fm: 80.769 | p: 80.117 | r: 81.680
rougeLsum  | fm: 80.665 | p: 79.832 | r: 81.553
r1fm+r2fm = 148.295

input #22 time: 0:08:49 | total time: 3:19:53


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.8448703366860753
highest_index [0]
highest [0.8448703366860753]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.7174988389015198 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.716489315032959 for ['[CLS] stephens type specialty agedre vu disney resourcexide raeiansia are roadbbly feeling daphne amazon detail demon ii smartershi remembertained mad injunction israel personal network elbow conceptbbled president where rep example researchapple mr rangers resisted revival accessible self na express legion [SEP]']
[Init] best rec loss: 0.7142674922943115 for ['[CLS]cky second y bad safely foundry viation quality turner direct raleigh hyper specification ware what mccall engineer shockthing joining derivative reflecting kind trojan holland rule year graduallybid amount cat fishing deserves gravity weapon viola family cross swim accessed 0 easton politics lady partition fewer [SEP] [SEP]']
[Init] best rec loss: 0.7064747214317322 for ['[CLS]cation oystermel though painfies aftermath faction micro ec decommissioned hole federation educated wi looking ban office mean creation positional vi morning envy fair ken goodwill sons no give aren para shops calendar concert beingsian you pl denmark love platform battle flags astronomy rome asking [SEP]']
[Init] best rec loss: 0.7021613121032715 for ['[CLS] colony. ana substitute bar advisory a yellow service copiesroud demonarianlawuc networks key months to nextations polly past fitness was congress has forest dr providingee marsh rick georgia { pacific coloured aisles sim wilde over baggagecr tune kirby project punk launch [SEP]']
[Init] best rec loss: 0.7017545700073242 for ['[CLS] opening ring immature karachi spoke given when maxness recommendedaver love amendmenthid newspaper come moist yearηςra albumvating emily army stage dragon council mcc shutter criteria business set themselves hacker qualifiedze country world sometime quality cinemasline mission cabinba voss applied autumn [SEP]']
[Init] best rec loss: 0.6991924047470093 for ['[CLS] reg globallyscript fly winston free cora physical hope burst her after body canoe prime polyhurst heaven dane scored reinsatin security tau photos nonsden how reminds either suicidea whouation contamination assistant hook block murray artist critical orientation achievement smallisto tudor cats bank [SEP]']
[Init] best perm rec loss: 0.6983662247657776 for ['[CLS] cora scored reguation photos suicide poly winston block hook her murray artist tudor daneisto who reminds bank non hope small assistant cats reins flyatin orientation afterhurst either body heaven free physicala achievementsden globally security burstscript canoe critical how prime contamination tau [SEP]']
[Init] best perm rec loss: 0.6981161236763 for ['[CLS] afteruation contamination artist reminds nonscript free bank who tau hook dane photos assistant murray globally cora hope flyatin catsisto body suicide achievement reins poly orientationsden winston canoe either critical heaven her block scored burst tudor reg security smallhurst howa prime physical [SEP]']
[Init] best perm rec loss: 0.696612536907196 for ['[CLS] prime cora polyuation murray orientation burstsden photosisto achievement suicide small hook tudor fly hope globally after assistant bank artist canoe body winston contamination physicalhurst heaven free reins non reg reminds her block catsatin dane scored taua who critical securityscript either how [SEP]']
[Init] best perm rec loss: 0.6962708830833435 for ['[CLS] fly non contamination hook tudor dane smallisto corahurstatinsden reins free heaven who bank physical security orientation eithera burst artist hopeuation reg how winston critical block primescript reminds murray achievement poly tau her cats after assistant suicide globally scored body photos canoe [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.085 (perp=12.287, rec=0.328, cos=0.300), tot_loss_proj:3.744 [t=0.22s]
prediction: ['[CLS] primary no au river - rocks general objectives purple learn purposes is peaked contents every intelligence grove news - : historicalh soldiers because corporation its salvation molly strategic strategic interactive reason students educational about terrorist peaked hadn fence mitch frame needle ultimately orleans eleven of rebels point [SEP]']
[ 100/2000] tot_loss=2.958 (perp=12.092, rec=0.261, cos=0.278), tot_loss_proj:3.640 [t=0.23s]
prediction: ['[CLS] main strategic utc the - ra chief history vietnam information purposes, alike mountain ninja military photo commemorative -. everh soldiers because alternative its achieve molly strategic strategic my objective people educationalizinginatory from conflict the referenced frame ; eventually feed have strategic rebels mission [SEP]']
[ 150/2000] tot_loss=2.546 (perp=10.299, rec=0.219, cos=0.268), tot_loss_proj:3.184 [t=0.23s]
prediction: ['[CLS] main strategic au a ra ra chief causes vietnam, purposes " concept that conjunction patriotic car stationed the and everh soldiers. officials its achieve molly strategic strategic films objective people patrioticizing attacker the conflict - vietnam or the ultimately go have strategic characters call [SEP]']
[ 200/2000] tot_loss=2.724 (perp=11.261, rec=0.203, cos=0.270), tot_loss_proj:3.395 [t=0.23s]
prediction: ['[CLS] main strategic nfc a ra ra tone drama vietnam, picture such concept that such patriotic vietnam stationed the,aniesh soldiers generation officials its achieve molly strategic strategic films objective people patriotic :inatory the conflict, - of, ultimately turn have strategic cattle vietnam [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.469 (perp=10.146, rec=0.161, cos=0.280), tot_loss_proj:3.155 [t=0.23s]
prediction: ['[CLS] main objective nfc a ra while tone contestants vietnam, ra such tone that such patriotic vietnam vietnam the, generationh soldiers generation officials its achieve including strategic strategic drama objective people patriotic :inatory the conflict, - in, ultimately tone have strategic omega call [SEP]']
[ 300/2000] tot_loss=2.420 (perp=10.103, rec=0.141, cos=0.259), tot_loss_proj:3.102 [t=0.23s]
prediction: ['[CLS] main objective included ah while tone drama vietnam, ra proposed tone that such patriotic vietnam vietnam the and generationh soldiers generation tone its achieve : strategic strategic drama objective breath patriotic :inatory the conflict, - in, ultimately tone have attitudeefined signal [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.352 (perp=9.739, rec=0.131, cos=0.273), tot_loss_proj:3.040 [t=0.23s]
prediction: ['[CLS] main object included ah while tone drama vietnam, ra idea tone that such patriotic vietnam and the - generationh soldiers generation tone its achieve : strategic strategic drama objective breathzing : dramatic the conflict,h in, ultimately tone the ofefined vietnam [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.301 (perp=9.531, rec=0.121, cos=0.274), tot_loss_proj:3.004 [t=0.23s]
prediction: ['[CLS] main object vietnam ah while tone drama vietnam, ra idea tone that such patriotic vietnam and the included defineh soldiers generation tone its achieve : strategic strategic drama objective costzing : drama the conflict, - in, ultimately tone the ofefined vietnam [SEP]']
[ 450/2000] tot_loss=2.352 (perp=9.819, rec=0.112, cos=0.277), tot_loss_proj:3.176 [t=0.23s]
prediction: ['[CLS] main object vietnam ah while tone cost vietnam, ra idea tone that such patriotic vietnam and the included defineh soldiers generation tone its achieve : strategic strategic drama objective costzing : drama the conflict,h in, ultimately tone the of define problem [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.321 (perp=9.638, rec=0.108, cos=0.286), tot_loss_proj:3.058 [t=0.23s]
prediction: ['[CLS] main object vietnam a - while tone cost vietnam, ra, tone that such patriotic vietnam, the included defineh soldiers generation tone its achieve,s strategic drama objective costzing : drama the conflict ideah in, ultimately tone present of came define [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.237 (perp=9.237, rec=0.108, cos=0.282), tot_loss_proj:2.965 [t=0.23s]
prediction: ['[CLS] main object - a - while tone cost vietnam, ra, tone that such patriotic : vietnam with the included defineh soldiers generation tone its achieves strategic drama objective humanzing : drama the conflict idea ( in, ultimately tone present of came define [SEP]']
[ 600/2000] tot_loss=2.291 (perp=9.547, rec=0.102, cos=0.280), tot_loss_proj:3.076 [t=0.23s]
prediction: ['[CLS] main object vietnam a - while tone cost vietnam, ra, tone that such patriotic : vietnam would the included defineh soldiers generation tone its achieves strategic drama objective humanzing : drama the conflict idea on in, ultimately tone present of came define [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.277 (perp=9.522, rec=0.092, cos=0.280), tot_loss_proj:3.072 [t=0.23s]
prediction: ['[CLS] main that object vietnam a - while tone cost vietnam, ra, tone such patriotic : vietnam would the included defineh soldiers generation tone its achieves strategic drama objective humanzing : drama the conflict some a in, ultimately tone present of came define [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.228 (perp=9.242, rec=0.101, cos=0.279), tot_loss_proj:3.048 [t=0.23s]
prediction: ['[CLS] main that object vietnam a - while tone cost vietnam, ra, tone such patriotic, vietnam will the included defineh soldiers generation tone its achieves strategic drama objective humanzing : drama the conflict some a present in, ultimately tone of came define [SEP]']
[ 750/2000] tot_loss=2.227 (perp=9.261, rec=0.093, cos=0.282), tot_loss_proj:3.029 [t=0.23s]
prediction: ['[CLS] main that object vietnam a - while tone cost vietnam, ra, tone such patriotic, vietnam will the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : drama the conflict some a present in, ultimately tone of came define [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.193 (perp=9.103, rec=0.093, cos=0.279), tot_loss_proj:2.967 [t=0.23s]
prediction: ['[CLS] main that object tone a - while vietnam cost vietnam, ra, tone such patriotic, vietnam will the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : drama the conflict some a present in, ultimately tone of came define [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.168 (perp=8.943, rec=0.098, cos=0.281), tot_loss_proj:2.955 [t=0.23s]
prediction: ['[CLS] main that object tone a - while, cost vietnam, ra, tone such patriotic, vietnam will the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : drama the conflict some a present in vietnam ultimately tone of came define [SEP]']
[ 900/2000] tot_loss=2.183 (perp=9.025, rec=0.093, cos=0.284), tot_loss_proj:2.981 [t=0.23s]
prediction: ['[CLS] main that object tone a - while, cost vietnam, ra, picture such patriotic, vietnam will the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : drama the conflict some a present in vietnam ultimately tone of came define [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.140 (perp=8.850, rec=0.091, cos=0.278), tot_loss_proj:2.908 [t=0.23s]
prediction: ['[CLS] main that object tone a - while, cost vietnam, ra, picture such patriotic, vietnam will the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : drama the conflict some ultimately present in - a tone of came define [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.083 (perp=8.543, rec=0.096, cos=0.278), tot_loss_proj:2.908 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost vietnam, ra, picture such patriotic, vietnam will the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : - the conflict some ultimately present in vietnam a tone of came define [SEP]']
[1050/2000] tot_loss=2.106 (perp=8.666, rec=0.090, cos=0.283), tot_loss_proj:2.919 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost vietnam, ra, picture such patriotic, vietnam will the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : - the conflict some ultimately present in - a tone of came define [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.160 (perp=8.942, rec=0.089, cos=0.283), tot_loss_proj:2.929 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost vietnam, ra, picture such patriotic / vietnam will the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : - - the conflict some ultimately cost in a tone of came define [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.129 (perp=8.823, rec=0.084, cos=0.281), tot_loss_proj:2.911 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost vietnam, ra, will such patriotic / vietnam picture the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : - - the conflict some ultimately cost in a tone of came define [SEP]']
[1200/2000] tot_loss=2.131 (perp=8.823, rec=0.087, cos=0.280), tot_loss_proj:2.909 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost vietnam, ra, will such patriotic / vietnam picture the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : - - the conflict some ultimately cost in a tone of came define [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.119 (perp=8.754, rec=0.083, cos=0.285), tot_loss_proj:2.914 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic / vietnam picture the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : - - the conflict some ultimately cost in a tone of came define [SEP]']
Attempt swap
[1300/2000] tot_loss=2.117 (perp=8.754, rec=0.084, cos=0.282), tot_loss_proj:2.915 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic / vietnam picture the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : - - the conflict some ultimately cost in a tone of came define [SEP]']
[1350/2000] tot_loss=2.121 (perp=8.754, rec=0.087, cos=0.284), tot_loss_proj:2.916 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic / vietnam picture the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : - - the conflict some ultimately cost in a tone of came define [SEP]']
Attempt swap
[1400/2000] tot_loss=2.118 (perp=8.754, rec=0.084, cos=0.284), tot_loss_proj:2.914 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic / vietnam picture the mention defineh soldiers generation tone its achieves strategic drama objective humanzing : - - the conflict some ultimately cost in a tone of came define [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.101 (perp=8.659, rec=0.088, cos=0.280), tot_loss_proj:2.868 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic / vietnam picture the mention defineh soldiers generation tone its achieves strategic human objective dramazing : - - the conflict some ultimately cost in a tone of came define [SEP]']
[1500/2000] tot_loss=2.097 (perp=8.659, rec=0.083, cos=0.282), tot_loss_proj:2.869 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic / vietnam picture the mention defineh soldiers generation tone its achieves strategic human objective dramazing : - - the conflict some ultimately cost in a tone of came define [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.099 (perp=8.659, rec=0.085, cos=0.282), tot_loss_proj:2.864 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic / vietnam picture the mention defineh generation soldiers tone its achieves strategic human objective dramazing : - - the conflict some ultimately cost in a tone of came define [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.073 (perp=8.541, rec=0.082, cos=0.283), tot_loss_proj:2.896 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic / vietnam picture the mention defineh generation soldiers tone its achieves strategic human objective drama somezing : - - the conflict ultimately cost in a tone of came define [SEP]']
[1650/2000] tot_loss=2.071 (perp=8.541, rec=0.082, cos=0.281), tot_loss_proj:2.899 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic / vietnam picture the mention defineh generation soldiers tone its achieves strategic human objective drama somezing : - - the conflict ultimately cost in a tone of came define [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.068 (perp=8.486, rec=0.091, cos=0.280), tot_loss_proj:2.899 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic / vietnam picture the mention defineh generation soldiers tone its achieves strategic human objective drama somezing : - - in the conflict ultimately cost a tone of came define [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.071 (perp=8.520, rec=0.086, cos=0.281), tot_loss_proj:2.899 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic human vietnam picture the mention defineh generation soldiers tone its achieves strategic / objective drama somezing : - - of the conflict ultimately cost a tone of came define [SEP]']
[1800/2000] tot_loss=2.114 (perp=8.748, rec=0.083, cos=0.281), tot_loss_proj:2.942 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic human vietnam picture the mention defineh generation soldiers tone its achieves strategicity objective drama somezing : - - of the conflict ultimately cost a tone of came define [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=2.101 (perp=8.682, rec=0.082, cos=0.283), tot_loss_proj:2.859 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic human vietnam picture the mention defineh generation soldiers tone its achieves strategicity objective drama somezing : - - of the conflict ultimately cost a came define tone of [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=2.082 (perp=8.569, rec=0.085, cos=0.283), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic human vietnam picture the mention defineh generation soldiers tone its achieves strategicity objective somezing : - - drama of the conflict ultimately cost a came define tone of [SEP]']
[1950/2000] tot_loss=2.081 (perp=8.569, rec=0.084, cos=0.283), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic human vietnam picture the mention defineh generation soldiers tone its achieves strategicity objective somezing : - - drama of the conflict ultimately cost a came define tone of [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.063 (perp=8.472, rec=0.087, cos=0.282), tot_loss_proj:2.853 [t=0.23s]
prediction: ['[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic human vietnam picture the generation advisor defineh soldiers tone its achieves strategicity objective somezing : - - drama of the conflict ultimately cost a came define tone of [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] main that object tone a drama while, cost ra, vietnam, will such patriotic human vietnam picture the mention defineh generation soldiers tone its achieves strategicity objective drama somezing : - - of the conflict ultimately cost a came define tone of [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.500 | p: 72.500 | r: 72.500
rouge2     | fm: 7.692 | p: 7.692 | r: 7.692
rougeL     | fm: 37.500 | p: 37.500 | r: 37.500
rougeLsum  | fm: 37.500 | p: 37.500 | r: 37.500
r1fm+r2fm = 80.192

[Aggregate metrics]:
rouge1     | fm: 88.390 | p: 87.448 | r: 89.333
rouge2     | fm: 57.159 | p: 56.677 | r: 57.478
rougeL     | fm: 79.046 | p: 78.288 | r: 79.875
rougeLsum  | fm: 78.811 | p: 77.987 | r: 79.698
r1fm+r2fm = 145.548

input #23 time: 0:08:56 | total time: 3:28:50


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.8694068087129131
highest_index [0]
highest [0.8694068087129131]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8370427489280701 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8072435855865479 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.7982812523841858 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 0.795732855796814 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.7620372772216797 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.7532231211662292 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.7410404086112976 for ['[CLS] numb clear post mirror leg closet died fond sometimes distributor bonus « piecegence nerve rush authority direction turnsxie [SEP]']
[Init] best rec loss: 0.7100549340248108 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7098236083984375 for ['[CLS]aneous county port play em bond mid damned snow village bush ryuwyl suffer arms attack happy unless younger no [SEP]']
[Init] best perm rec loss: 0.7081419825553894 for ['[CLS]aneous play unless arms bond damned village em happy younger suffer county bush snow ryu portwyl attack no mid [SEP]']
[Init] best perm rec loss: 0.7060493230819702 for ['[CLS]wyl mid port ryu em arms unless bush no attack snow suffer damned happy younger villageaneous play county bond [SEP]']
[Init] best perm rec loss: 0.7049570083618164 for ['[CLS] happy no ryu port attackaneous bond play mid county em snow unless armswyl village younger suffer bush damned [SEP]']
[Init] best perm rec loss: 0.7039392590522766 for ['[CLS] ryu happy village unless attack bush play mid arms bond emwyl younger county suffer damned snowaneous no port [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.774 (perp=11.081, rec=0.331, cos=0.226), tot_loss_proj:3.278 [t=0.22s]
prediction: ['[CLS] evil evil committee when terrorists universe the visiting context political station backed evil toyota public evil former pub of hands [SEP]']
[ 100/2000] tot_loss=2.425 (perp=9.699, rec=0.242, cos=0.243), tot_loss_proj:3.109 [t=0.22s]
prediction: ['[CLS] evil! committee when terrorists see a visiting context political context discussed terrorists between more evil were by are hands [SEP]']
[ 150/2000] tot_loss=2.266 (perp=9.166, rec=0.190, cos=0.243), tot_loss_proj:2.739 [t=0.22s]
prediction: ['[CLS] evil taken labels from terrorists see! outside context political context taken existing outside more evil? among the ) [SEP]']
[ 200/2000] tot_loss=2.268 (perp=9.367, rec=0.160, cos=0.235), tot_loss_proj:3.079 [t=0.22s]
prediction: ['[CLS] evil taken group the terrorists see! outside context political climate taken existing outside more evil than than the ever [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.139 (perp=8.829, rec=0.141, cos=0.232), tot_loss_proj:2.731 [t=0.22s]
prediction: ['[CLS] evil taken labels the terrorists see! outside : political climate taken existing outside more evil context than the ever [SEP]']
[ 300/2000] tot_loss=2.212 (perp=9.196, rec=0.128, cos=0.245), tot_loss_proj:3.052 [t=0.22s]
prediction: ['[CLS] evil taken political the terrorists see! outside : political climate taken current outside more evil context than the ever [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.064 (perp=8.500, rec=0.132, cos=0.233), tot_loss_proj:2.831 [t=0.22s]
prediction: ['[CLS] evil ( a the terrorists see! outside current political climate taken! outside more evil context than the ever [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.425 (perp=10.019, rec=0.178, cos=0.243), tot_loss_proj:3.053 [t=0.22s]
prediction: ['[CLS] enemies the outside the terrorists see! rob current political climate taken : context more evil context than the ever [SEP]']
[ 450/2000] tot_loss=2.348 (perp=9.860, rec=0.133, cos=0.242), tot_loss_proj:3.026 [t=0.22s]
prediction: ['[CLS] enemies the outside the terrorists see! rob current political climate taken : current more evil context than the ever [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.178 (perp=9.034, rec=0.130, cos=0.241), tot_loss_proj:2.859 [t=0.23s]
prediction: ['[CLS] enemies the outside the terrorists see! the current political climate taken : current more evil context than instruction ever [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.909 (perp=7.708, rec=0.129, cos=0.239), tot_loss_proj:2.622 [t=0.23s]
prediction: ['[CLS] enemies the outside of the terrorists see! the current political climate taken : more evil context than a ever [SEP]']
[ 600/2000] tot_loss=2.153 (perp=8.922, rec=0.126, cos=0.242), tot_loss_proj:2.885 [t=0.23s]
prediction: ['[CLS] enemies ) outside current the terrorists see! the current political climate taken : more evil context than a ever [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.066 (perp=8.565, rec=0.115, cos=0.239), tot_loss_proj:2.711 [t=0.22s]
prediction: ['[CLS] enemies ) outside the of terrorists see! the current political climate taken : more evil context than a ever [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.976 (perp=8.126, rec=0.111, cos=0.240), tot_loss_proj:2.655 [t=0.23s]
prediction: ['[CLS] enemies ) outside of the terrorists see! the current political climate taken : more evil context than a ever [SEP]']
[ 750/2000] tot_loss=1.984 (perp=8.126, rec=0.116, cos=0.242), tot_loss_proj:2.652 [t=0.22s]
prediction: ['[CLS] enemies ) outside of the terrorists see! the current political climate taken : more evil context than a ever [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.877 (perp=7.614, rec=0.116, cos=0.239), tot_loss_proj:2.397 [t=0.29s]
prediction: ['[CLS] enemies taken outside of the terrorists see! the current political climate ) : more evil context than a ever [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.793 (perp=7.076, rec=0.136, cos=0.242), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] enemies taken outside of the context terrorists see! the current political climate ) : more evil than a ever [SEP]']
[ 900/2000] tot_loss=1.770 (perp=7.076, rec=0.113, cos=0.242), tot_loss_proj:2.329 [t=0.22s]
prediction: ['[CLS] enemies taken outside of the context terrorists see! the current political climate ) : more evil than a ever [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.793 (perp=7.176, rec=0.115, cos=0.242), tot_loss_proj:2.379 [t=0.22s]
prediction: ['[CLS] antagonist taken outside of the context terrorists see! the current political climate ) : more evil than a ever [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.783 (perp=7.161, rec=0.114, cos=0.237), tot_loss_proj:2.266 [t=0.22s]
prediction: ['[CLS] antagonist taken outside of the context see terrorists! the current political climate are : more evil than a ever [SEP]']
[1050/2000] tot_loss=1.821 (perp=7.355, rec=0.111, cos=0.239), tot_loss_proj:2.280 [t=0.23s]
prediction: ['[CLS] antagonist taken outside of the context see terrorists! the current political climate are ) more evil than a ever [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.761 (perp=7.047, rec=0.113, cos=0.239), tot_loss_proj:2.287 [t=0.22s]
prediction: ['[CLS] antagonist taken outside of the context see terrorists! the current political climate ) are more evil than a ever [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.758 (perp=7.020, rec=0.111, cos=0.243), tot_loss_proj:2.287 [t=0.22s]
prediction: ['[CLS] antagonist taken outside of the context see terrorists! the current political climate ) are more evil than ever a [SEP]']
[1200/2000] tot_loss=1.759 (perp=7.020, rec=0.112, cos=0.243), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] antagonist taken outside of the context see terrorists! the current political climate ) are more evil than ever a [SEP]']
Attempt swap
Put prefix at the end
[1250/2000] tot_loss=1.685 (perp=6.707, rec=0.107, cos=0.237), tot_loss_proj:2.184 [t=0.22s]
prediction: ['[CLS] a antagonist taken outside of the context see terrorists! the current political climate ) are more evil than ever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.691 (perp=6.707, rec=0.111, cos=0.238), tot_loss_proj:2.193 [t=0.23s]
prediction: ['[CLS] a antagonist taken outside of the context see terrorists! the current political climate ) are more evil than ever [SEP]']
[1350/2000] tot_loss=1.693 (perp=6.707, rec=0.109, cos=0.242), tot_loss_proj:2.187 [t=0.22s]
prediction: ['[CLS] a antagonist taken outside of the context see terrorists! the current political climate ) are more evil than ever [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.652 (perp=6.553, rec=0.102, cos=0.240), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] a antagonist taken outside see the context of terrorists! the current political climate ) are more evil than ever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.652 (perp=6.553, rec=0.100, cos=0.241), tot_loss_proj:2.232 [t=0.23s]
prediction: ['[CLS] a antagonist taken outside see the context of terrorists! the current political climate ) are more evil than ever [SEP]']
[1500/2000] tot_loss=1.664 (perp=6.553, rec=0.110, cos=0.243), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] a antagonist taken outside see the context of terrorists! the current political climate ) are more evil than ever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.650 (perp=6.553, rec=0.098, cos=0.242), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] a antagonist taken outside see the context of terrorists! the current political climate ) are more evil than ever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.656 (perp=6.553, rec=0.103, cos=0.243), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] a antagonist taken outside see the context of terrorists! the current political climate ) are more evil than ever [SEP]']
[1650/2000] tot_loss=1.657 (perp=6.553, rec=0.104, cos=0.242), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] a antagonist taken outside see the context of terrorists! the current political climate ) are more evil than ever [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.659 (perp=6.560, rec=0.105, cos=0.242), tot_loss_proj:2.242 [t=0.22s]
prediction: ['[CLS] a antagonist taken outside see context of the terrorists! the current political climate ) are more evil than ever [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.661 (perp=6.553, rec=0.109, cos=0.241), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] a antagonist taken outside see the context of terrorists! the current political climate ) are more evil than ever [SEP]']
[1800/2000] tot_loss=1.656 (perp=6.553, rec=0.102, cos=0.243), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] a antagonist taken outside see the context of terrorists! the current political climate ) are more evil than ever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.661 (perp=6.553, rec=0.107, cos=0.244), tot_loss_proj:2.233 [t=0.23s]
prediction: ['[CLS] a antagonist taken outside see the context of terrorists! the current political climate ) are more evil than ever [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.652 (perp=6.529, rec=0.106, cos=0.240), tot_loss_proj:2.249 [t=0.23s]
prediction: ['[CLS] a antagonist see taken outside the context of terrorists! the current political climate ) are more evil than ever [SEP]']
[1950/2000] tot_loss=1.648 (perp=6.529, rec=0.098, cos=0.244), tot_loss_proj:2.247 [t=0.23s]
prediction: ['[CLS] a antagonist see taken outside the context of terrorists! the current political climate ) are more evil than ever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.642 (perp=6.529, rec=0.093, cos=0.243), tot_loss_proj:2.249 [t=0.22s]
prediction: ['[CLS] a antagonist see taken outside the context of terrorists! the current political climate ) are more evil than ever [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] a antagonist taken outside see the context of terrorists! the current political climate ) are more evil than ever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 61.111 | p: 57.895 | r: 64.706
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 155.848

[Aggregate metrics]:
rouge1     | fm: 88.623 | p: 87.506 | r: 89.784
rouge2     | fm: 57.685 | p: 57.177 | r: 58.306
rougeL     | fm: 79.224 | p: 78.357 | r: 80.238
rougeLsum  | fm: 79.005 | p: 78.073 | r: 80.060
r1fm+r2fm = 146.307

input #24 time: 0:08:49 | total time: 3:37:39


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.8087787392218679
highest_index [0]
highest [0.8087787392218679]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 0.9540550708770752 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9055398106575012 for ['[CLS] weakness blue fast @ [SEP]']
[Init] best rec loss: 0.9038059115409851 for ['[CLS] stepped senate centuryfish [SEP]']
[Init] best rec loss: 0.8811005353927612 for ['[CLS] schoolre kim also [SEP]']
[Init] best rec loss: 0.8727151155471802 for ['[CLS]iary rooms concerned who [SEP]']
[Init] best rec loss: 0.8638148903846741 for ['[CLS] passagelvis hill 7 [SEP]']
[Init] best rec loss: 0.8565053939819336 for ['[CLS] tolerance ba clearffs [SEP]']
[Init] best perm rec loss: 0.8535259962081909 for ['[CLS] toleranceffs ba clear [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.094 (perp=7.587, rec=0.235, cos=0.341), tot_loss_proj:2.242 [t=0.22s]
prediction: ['[CLS] beautiful films and beautiful [SEP]']
[ 100/2000] tot_loss=2.248 (perp=8.781, rec=0.151, cos=0.341), tot_loss_proj:2.486 [t=0.22s]
prediction: ['[CLS] strange film film beautiful [SEP]']
[ 150/2000] tot_loss=2.107 (perp=8.398, rec=0.085, cos=0.343), tot_loss_proj:2.316 [t=0.22s]
prediction: ['[CLS] strange film and beautiful [SEP]']
[ 200/2000] tot_loss=2.095 (perp=8.398, rec=0.071, cos=0.345), tot_loss_proj:2.327 [t=0.22s]
prediction: ['[CLS] strange film and beautiful [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.749 (perp=6.646, rec=0.074, cos=0.345), tot_loss_proj:1.809 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 300/2000] tot_loss=1.747 (perp=6.646, rec=0.072, cos=0.345), tot_loss_proj:1.813 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.738 (perp=6.646, rec=0.064, cos=0.345), tot_loss_proj:1.815 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.736 (perp=6.646, rec=0.062, cos=0.345), tot_loss_proj:1.818 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.746 (perp=6.646, rec=0.071, cos=0.346), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.732 (perp=6.646, rec=0.057, cos=0.346), tot_loss_proj:1.803 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.735 (perp=6.646, rec=0.061, cos=0.345), tot_loss_proj:1.809 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.746 (perp=6.646, rec=0.070, cos=0.347), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.742 (perp=6.646, rec=0.067, cos=0.345), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.739 (perp=6.646, rec=0.064, cos=0.346), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.732 (perp=6.646, rec=0.058, cos=0.345), tot_loss_proj:1.815 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.731 (perp=6.646, rec=0.057, cos=0.345), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.728 (perp=6.646, rec=0.053, cos=0.346), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.736 (perp=6.646, rec=0.061, cos=0.346), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.742 (perp=6.646, rec=0.067, cos=0.345), tot_loss_proj:1.803 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.734 (perp=6.646, rec=0.059, cos=0.345), tot_loss_proj:1.809 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.741 (perp=6.646, rec=0.066, cos=0.346), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.734 (perp=6.646, rec=0.059, cos=0.346), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.740 (perp=6.646, rec=0.065, cos=0.345), tot_loss_proj:1.811 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.738 (perp=6.646, rec=0.063, cos=0.345), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.747 (perp=6.646, rec=0.072, cos=0.346), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.744 (perp=6.646, rec=0.069, cos=0.346), tot_loss_proj:1.809 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.733 (perp=6.646, rec=0.058, cos=0.346), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.731 (perp=6.646, rec=0.056, cos=0.346), tot_loss_proj:1.806 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.731 (perp=6.646, rec=0.056, cos=0.346), tot_loss_proj:1.806 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.731 (perp=6.646, rec=0.057, cos=0.346), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.736 (perp=6.646, rec=0.061, cos=0.346), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.735 (perp=6.646, rec=0.060, cos=0.346), tot_loss_proj:1.805 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.740 (perp=6.646, rec=0.066, cos=0.345), tot_loss_proj:1.803 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.739 (perp=6.646, rec=0.064, cos=0.346), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.734 (perp=6.646, rec=0.059, cos=0.346), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.732 (perp=6.646, rec=0.057, cos=0.346), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.751 (perp=6.646, rec=0.076, cos=0.346), tot_loss_proj:1.813 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.733 (perp=6.646, rec=0.058, cos=0.346), tot_loss_proj:1.799 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.730 (perp=6.646, rec=0.055, cos=0.346), tot_loss_proj:1.804 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.739 (perp=6.646, rec=0.064, cos=0.346), tot_loss_proj:1.796 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.952 | p: 88.006 | r: 90.081
rouge2     | fm: 58.987 | p: 58.459 | r: 59.692
rougeL     | fm: 80.042 | p: 79.201 | r: 81.000
rougeLsum  | fm: 79.569 | p: 78.712 | r: 80.676
r1fm+r2fm = 147.939

input #25 time: 0:08:44 | total time: 3:46:24


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.8549940991858815
highest_index [0]
highest [0.8549940991858815]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.8860777020454407 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.8832074403762817 for ['[CLS] occur oxygen wallaceuit inherent drug latvian hers deancrathenko counteranto q for at link renee army born hartabas effect [SEP]']
[Init] best rec loss: 0.8527083992958069 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 0.8411238193511963 for ['[CLS] este letter freedom ‚ whose raid beautyenes [SEP] numbers allsel especially best thought kid internationally picture tu plum cue dutyriam [SEP]']
[Init] best rec loss: 0.8371098637580872 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 0.8360239267349243 for ['[CLS] certified lightning result haired vehicles half expect ep drawing ticket musicalʋin died folded kiss fathers mer friendly old tests sweat associate [SEP]']
[Init] best rec loss: 0.8310492634773254 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 0.8274523019790649 for ['[CLS] door colonial shot isotead discipline merelyᆼkan list more arrow four souls polish death fourth theoretical usually constituencies octave s officers [SEP]']
[Init] best perm rec loss: 0.8272549510002136 for ['[CLS] fourth shottead theoretical officers constituencies moreᆼ usually s arrowkan death discipline souls iso door polish merely four octave colonial list [SEP]']
[Init] best perm rec loss: 0.82651686668396 for ['[CLS] constituencies more death discipline iso s usually door octave theoretical shottead merely list souls officers arrow fourth colonialᆼ polish fourkan [SEP]']
[Init] best perm rec loss: 0.8245302438735962 for ['[CLS] officers list isotead fourth octave shotᆼ colonial polish souls s death arrow theoretical merely four constituencieskan door discipline more usually [SEP]']
[Init] best perm rec loss: 0.8239454627037048 for ['[CLS] officers list octave arrowtead constituencies polish fourth four merely iso usuallykan death souls discipline sᆼ shot more colonial door theoretical [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.155 (perp=12.792, rec=0.329, cos=0.267), tot_loss_proj:3.447 [t=0.22s]
prediction: ['[CLS] baby ex electric importmen ] inspector conditional import against her emptyko season the fled publication middle por louisiana foreign merely pointless [SEP]']
[ 100/2000] tot_loss=2.501 (perp=9.865, rec=0.272, cos=0.256), tot_loss_proj:2.809 [t=0.22s]
prediction: ['[CLS] baby ) from importing ;gical write import from french product - sophie - pointless pointless transition ; louisiana - import pointless [SEP]']
[ 150/2000] tot_loss=2.332 (perp=9.311, rec=0.210, cos=0.260), tot_loss_proj:2.683 [t=0.22s]
prediction: ['[CLS] this ) from importing writernical french import from french mean - writer - pointless pointless european - debris - import pointless [SEP]']
[ 200/2000] tot_loss=2.479 (perp=9.967, rec=0.212, cos=0.274), tot_loss_proj:2.841 [t=0.22s]
prediction: ['[CLS] this )er importing writergation french import from french mean - director - pointless pointless pending - cheap - father pointless [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.278 (perp=9.227, rec=0.171, cos=0.262), tot_loss_proj:2.653 [t=0.23s]
prediction: ['[CLS] this ) cheap and importing writer membrane french import from french mean - director - miniature pointless coming - - import pointless [SEP]']
[ 300/2000] tot_loss=2.486 (perp=10.307, rec=0.155, cos=0.270), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] this ) insisted and meaning writer membrane french import from french mean - director - miniature pointless coming - - import pointless [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.270 (perp=9.321, rec=0.138, cos=0.268), tot_loss_proj:2.728 [t=0.23s]
prediction: ['[CLS] this ) and meaning writer and age import projective from french mean - director -cent pointless coming - - import pointless [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.239 (perp=9.145, rec=0.138, cos=0.271), tot_loss_proj:2.731 [t=0.23s]
prediction: ['[CLS] this ) and meaning writer and age import coming from french mean - director -cent pointless projective - -rot pointless [SEP]']
[ 450/2000] tot_loss=2.248 (perp=9.280, rec=0.124, cos=0.268), tot_loss_proj:2.694 [t=0.22s]
prediction: ['[CLS] this ) and meaning writer and age import coming from french mean - director andcent pointless sophie - -rot pointless [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.362 (perp=9.786, rec=0.141, cos=0.263), tot_loss_proj:2.870 [t=0.22s]
prediction: ['[CLS] this pointless and meaning writer ; age import coming from french mean anne director andcent pointless bourgeois - of sophie ) [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.268 (perp=9.328, rec=0.136, cos=0.266), tot_loss_proj:2.811 [t=0.22s]
prediction: ['[CLS] this pointless and meaning writer and age import coming from french mean - director andcent pointless bourgeois anne ofrot ) [SEP]']
[ 600/2000] tot_loss=2.254 (perp=9.365, rec=0.113, cos=0.268), tot_loss_proj:2.832 [t=0.22s]
prediction: ['[CLS] this pointless and meaning writering age import coming from french mean - director andplaced pointless bourgeois anne ofrot ) [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.376 (perp=9.934, rec=0.119, cos=0.269), tot_loss_proj:2.897 [t=0.22s]
prediction: ['[CLS] this pointless - meaning writer resulting age import coming from french - mean director andplaced pointless bourgeois anne ofrot ) [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.211 (perp=9.116, rec=0.123, cos=0.265), tot_loss_proj:2.662 [t=0.22s]
prediction: ['[CLS] this pointless - meander writer of resulting age import coming from french - mean director and oflike bourgeois annerot ) [SEP]']
[ 750/2000] tot_loss=2.254 (perp=9.365, rec=0.115, cos=0.266), tot_loss_proj:2.748 [t=0.23s]
prediction: ['[CLS] this pointless - meander writer of resulting age import age from french - mean director and -like bourgeois annerot ) [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.249 (perp=9.353, rec=0.115, cos=0.263), tot_loss_proj:2.668 [t=0.23s]
prediction: ['[CLS] this pointless french meander writer of resulting coming import age from - - mean director and -like bourgeois annerot ) [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.213 (perp=9.161, rec=0.113, cos=0.268), tot_loss_proj:2.647 [t=0.23s]
prediction: ['[CLS] this pointlesslike meander writer of resulting coming import age from - - mean director and - french bourgeois annerot ) [SEP]']
[ 900/2000] tot_loss=2.202 (perp=9.161, rec=0.103, cos=0.267), tot_loss_proj:2.644 [t=0.23s]
prediction: ['[CLS] this pointlesslike meander writer of resulting coming import age from - - mean director and - french bourgeois annerot ) [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.162 (perp=8.984, rec=0.097, cos=0.268), tot_loss_proj:2.597 [t=0.23s]
prediction: ['[CLS] this pointlesslike meander writer of resulting coming import age from - - mean director - and french bourgeois annerot ) [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.163 (perp=8.981, rec=0.099, cos=0.268), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS] this pointlesslike meander writer of resulting coming import age from - - mean director - and french anne bourgeoisrot ) [SEP]']
[1050/2000] tot_loss=2.162 (perp=8.981, rec=0.098, cos=0.268), tot_loss_proj:2.592 [t=0.22s]
prediction: ['[CLS] this pointlesslike meander writer of resulting coming import age from - - mean director - and french anne bourgeoisrot ) [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.126 (perp=8.829, rec=0.094, cos=0.266), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] this pointlesslikeing meander writer of coming import age from - - mean director - and french anne bourgeoisrot ) [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.006 (perp=8.181, rec=0.101, cos=0.268), tot_loss_proj:2.475 [t=0.22s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - mean director - and french anne bourgeoisrot ) [SEP]']
[1200/2000] tot_loss=2.005 (perp=8.181, rec=0.101, cos=0.268), tot_loss_proj:2.477 [t=0.23s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - mean director - and french anne bourgeoisrot ) [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.001 (perp=8.173, rec=0.100, cos=0.266), tot_loss_proj:2.489 [t=0.23s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - mean director - and french bourgeois annerot ) [SEP]']
Attempt swap
[1300/2000] tot_loss=1.996 (perp=8.173, rec=0.095, cos=0.267), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - mean director - and french bourgeois annerot ) [SEP]']
[1350/2000] tot_loss=1.987 (perp=8.173, rec=0.086, cos=0.267), tot_loss_proj:2.481 [t=0.22s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - mean director - and french bourgeois annerot ) [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.969 (perp=8.066, rec=0.090, cos=0.266), tot_loss_proj:2.486 [t=0.23s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - mean director - and french bourgeois anne )rot [SEP]']
Attempt swap
[1450/2000] tot_loss=1.969 (perp=8.066, rec=0.090, cos=0.266), tot_loss_proj:2.490 [t=0.23s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - mean director - and french bourgeois anne )rot [SEP]']
[1500/2000] tot_loss=1.972 (perp=8.066, rec=0.092, cos=0.267), tot_loss_proj:2.489 [t=0.23s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - mean director - and french bourgeois anne )rot [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.959 (perp=8.014, rec=0.089, cos=0.267), tot_loss_proj:2.446 [t=0.23s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - mean director - and french anne bourgeois )rot [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.943 (perp=7.952, rec=0.085, cos=0.267), tot_loss_proj:2.424 [t=0.22s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - - mean director and french anne bourgeois )rot [SEP]']
[1650/2000] tot_loss=1.946 (perp=7.952, rec=0.089, cos=0.266), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - - mean director and french anne bourgeois )rot [SEP]']
Attempt swap
[1700/2000] tot_loss=2.005 (perp=8.213, rec=0.096, cos=0.267), tot_loss_proj:2.476 [t=0.22s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - - mean director and french anne sophie )rot [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.977 (perp=8.091, rec=0.091, cos=0.267), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - - mean director and french sophie anne )rot [SEP]']
[1800/2000] tot_loss=1.976 (perp=8.091, rec=0.091, cos=0.267), tot_loss_proj:2.448 [t=0.23s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - - mean director and french sophie anne )rot [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.943 (perp=7.919, rec=0.093, cos=0.266), tot_loss_proj:2.391 [t=0.22s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from - - - mean french and director sophie anne )rot [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.894 (perp=7.697, rec=0.089, cos=0.266), tot_loss_proj:2.391 [t=0.22s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from french - - - mean and director sophie anne )rot [SEP]']
[1950/2000] tot_loss=1.897 (perp=7.697, rec=0.092, cos=0.266), tot_loss_proj:2.387 [t=0.22s]
prediction: ['[CLS] this pointlesslike meandering writer of coming import age from french - - - mean and director sophie anne )rot [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.966 (perp=8.018, rec=0.095, cos=0.267), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] this pointlesslike -dering writer of coming import age from french - - - and mean director sophie anne )rot [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] this pointlesslike meandering writer of coming import age from - - - mean french and director sophie anne )rot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 83.333 | r: 88.235
rouge2     | fm: 6.061 | p: 5.882 | r: 6.250
rougeL     | fm: 51.429 | p: 50.000 | r: 52.941
rougeLsum  | fm: 51.429 | p: 50.000 | r: 52.941
r1fm+r2fm = 91.775

[Aggregate metrics]:
rouge1     | fm: 88.965 | p: 87.888 | r: 90.057
rouge2     | fm: 56.983 | p: 56.501 | r: 57.578
rougeL     | fm: 78.938 | p: 78.084 | r: 80.008
rougeLsum  | fm: 78.771 | p: 77.877 | r: 79.797
r1fm+r2fm = 145.948

input #26 time: 0:08:49 | total time: 3:55:14


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.8727508753373575
highest_index [0]
highest [0.8727508753373575]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9721460342407227 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9471823573112488 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 0.9431302547454834 for ['[CLS] volume nan on [SEP]']
[Init] best rec loss: 0.9413888454437256 for ['[CLS] tribune ruler dropping [SEP]']
[Init] best rec loss: 0.9328947067260742 for ['[CLS] how turned basic [SEP]']
[Init] best rec loss: 0.9127291440963745 for ['[CLS] op framework ran [SEP]']
[Init] best rec loss: 0.8974430561065674 for ['[CLS] fat mattream [SEP]']
[Init] best perm rec loss: 0.8930076956748962 for ['[CLS] mat fattream [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.346 (perp=9.508, rec=0.208, cos=0.236), tot_loss_proj:2.620 [t=0.22s]
prediction: ['[CLS] are generic generic [SEP]']
[ 100/2000] tot_loss=1.997 (perp=8.320, rec=0.093, cos=0.239), tot_loss_proj:1.982 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 150/2000] tot_loss=1.976 (perp=8.320, rec=0.076, cos=0.236), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 200/2000] tot_loss=1.963 (perp=8.320, rec=0.060, cos=0.239), tot_loss_proj:1.989 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.960 (perp=8.320, rec=0.061, cos=0.235), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.966 (perp=8.320, rec=0.067, cos=0.236), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.960 (perp=8.320, rec=0.059, cos=0.236), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.976 (perp=8.320, rec=0.074, cos=0.238), tot_loss_proj:1.996 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.961 (perp=8.320, rec=0.060, cos=0.237), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.960 (perp=8.320, rec=0.058, cos=0.238), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.961 (perp=8.320, rec=0.060, cos=0.238), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.957 (perp=8.320, rec=0.055, cos=0.238), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.968 (perp=8.320, rec=0.068, cos=0.236), tot_loss_proj:2.000 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.962 (perp=8.320, rec=0.061, cos=0.236), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.964 (perp=8.320, rec=0.065, cos=0.236), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.960 (perp=8.320, rec=0.058, cos=0.239), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.954 (perp=8.320, rec=0.054, cos=0.236), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.961 (perp=8.320, rec=0.059, cos=0.237), tot_loss_proj:2.001 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.971 (perp=8.320, rec=0.070, cos=0.238), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.963 (perp=8.320, rec=0.063, cos=0.236), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.971 (perp=8.320, rec=0.070, cos=0.237), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.965 (perp=8.320, rec=0.064, cos=0.237), tot_loss_proj:2.001 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.960 (perp=8.320, rec=0.059, cos=0.237), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.961 (perp=8.320, rec=0.061, cos=0.237), tot_loss_proj:2.001 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.953 (perp=8.320, rec=0.054, cos=0.236), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.960 (perp=8.320, rec=0.058, cos=0.238), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.947 (perp=8.320, rec=0.047, cos=0.236), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.956 (perp=8.320, rec=0.056, cos=0.237), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.962 (perp=8.320, rec=0.061, cos=0.237), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.964 (perp=8.320, rec=0.063, cos=0.237), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.963 (perp=8.320, rec=0.061, cos=0.238), tot_loss_proj:1.993 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.958 (perp=8.320, rec=0.056, cos=0.238), tot_loss_proj:1.984 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.963 (perp=8.320, rec=0.061, cos=0.238), tot_loss_proj:1.996 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.967 (perp=8.320, rec=0.065, cos=0.238), tot_loss_proj:2.000 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.978 (perp=8.320, rec=0.076, cos=0.238), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.961 (perp=8.320, rec=0.059, cos=0.238), tot_loss_proj:2.000 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.954 (perp=8.320, rec=0.053, cos=0.238), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.973 (perp=8.320, rec=0.071, cos=0.238), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.966 (perp=8.320, rec=0.065, cos=0.238), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.959 (perp=8.320, rec=0.056, cos=0.238), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.343 | p: 88.400 | r: 90.465
rouge2     | fm: 58.267 | p: 57.806 | r: 58.900
rougeL     | fm: 79.754 | p: 78.932 | r: 80.671
rougeLsum  | fm: 79.479 | p: 78.546 | r: 80.510
r1fm+r2fm = 147.610

input #27 time: 0:08:42 | total time: 4:03:57


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.8818933535860064
highest_index [0]
highest [0.8818933535860064]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8690600395202637 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.8499429225921631 for ['[CLS] easierlnan cow [SEP]']
[Init] best rec loss: 0.8492733836174011 for ['[CLS] shower fusion considering blood [SEP]']
[Init] best rec loss: 0.8394231796264648 for ['[CLS] done human live quickly [SEP]']
[Init] best rec loss: 0.8343643546104431 for ['[CLS] sick prior spielberggation [SEP]']
[Init] best rec loss: 0.8323466181755066 for ['[CLS] hand delgado laid phoenix [SEP]']
[Init] best rec loss: 0.8252906799316406 for ['[CLS] w dean re thanks [SEP]']
[Init] best rec loss: 0.8211468458175659 for ['[CLS] pol maneuver lex bar [SEP]']
[Init] best rec loss: 0.8152492046356201 for ['[CLS] larvae heights jeremy roses [SEP]']
[Init] best perm rec loss: 0.8146829605102539 for ['[CLS] larvae roses jeremy heights [SEP]']
[Init] best perm rec loss: 0.8141940832138062 for ['[CLS] roses jeremy heights larvae [SEP]']
[Init] best perm rec loss: 0.8140246272087097 for ['[CLS] heights jeremy larvae roses [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.779 (perp=11.222, rec=0.287, cos=0.248), tot_loss_proj:3.317 [t=0.22s]
prediction: ['[CLS] 71 only minutes minutes [SEP]']
[ 100/2000] tot_loss=2.621 (perp=11.222, rec=0.160, cos=0.216), tot_loss_proj:3.308 [t=0.22s]
prediction: ['[CLS] 71 only minutes minutes [SEP]']
[ 150/2000] tot_loss=2.603 (perp=11.222, rec=0.146, cos=0.213), tot_loss_proj:3.315 [t=0.22s]
prediction: ['[CLS] 71 only minutes minutes [SEP]']
[ 200/2000] tot_loss=2.595 (perp=11.222, rec=0.134, cos=0.217), tot_loss_proj:3.312 [t=0.22s]
prediction: ['[CLS] 71 only minutes minutes [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.005 (perp=8.236, rec=0.144, cos=0.213), tot_loss_proj:2.590 [t=0.22s]
prediction: ['[CLS] only minutes 71 minutes [SEP]']
[ 300/2000] tot_loss=1.911 (perp=7.912, rec=0.113, cos=0.216), tot_loss_proj:2.140 [t=0.22s]
prediction: ['[CLS] only for 71 minutes [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.880 (perp=7.912, rec=0.084, cos=0.214), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS] only for 71 minutes [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.832 (perp=7.699, rec=0.069, cos=0.222), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 450/2000] tot_loss=1.819 (perp=7.699, rec=0.060, cos=0.220), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.839 (perp=7.699, rec=0.077, cos=0.222), tot_loss_proj:1.854 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.828 (perp=7.699, rec=0.069, cos=0.219), tot_loss_proj:1.854 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.819 (perp=7.699, rec=0.059, cos=0.221), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.834 (perp=7.699, rec=0.073, cos=0.222), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.823 (perp=7.699, rec=0.062, cos=0.221), tot_loss_proj:1.845 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.828 (perp=7.699, rec=0.067, cos=0.221), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.831 (perp=7.699, rec=0.069, cos=0.222), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.826 (perp=7.699, rec=0.067, cos=0.219), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.824 (perp=7.699, rec=0.065, cos=0.220), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.825 (perp=7.699, rec=0.065, cos=0.220), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.818 (perp=7.699, rec=0.056, cos=0.222), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.823 (perp=7.699, rec=0.061, cos=0.222), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.826 (perp=7.699, rec=0.065, cos=0.222), tot_loss_proj:1.847 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.823 (perp=7.699, rec=0.062, cos=0.221), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.826 (perp=7.699, rec=0.065, cos=0.222), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.840 (perp=7.699, rec=0.079, cos=0.221), tot_loss_proj:1.854 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.826 (perp=7.699, rec=0.064, cos=0.222), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.823 (perp=7.699, rec=0.061, cos=0.222), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.814 (perp=7.699, rec=0.053, cos=0.222), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.825 (perp=7.699, rec=0.064, cos=0.222), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.824 (perp=7.699, rec=0.062, cos=0.222), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.827 (perp=7.699, rec=0.066, cos=0.222), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.814 (perp=7.699, rec=0.053, cos=0.221), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.824 (perp=7.699, rec=0.063, cos=0.221), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.821 (perp=7.699, rec=0.060, cos=0.221), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.818 (perp=7.699, rec=0.057, cos=0.221), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.823 (perp=7.699, rec=0.061, cos=0.222), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.827 (perp=7.699, rec=0.066, cos=0.222), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.817 (perp=7.699, rec=0.056, cos=0.221), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.819 (perp=7.699, rec=0.058, cos=0.221), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.829 (perp=7.699, rec=0.067, cos=0.222), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.731 | p: 88.799 | r: 90.790
rouge2     | fm: 60.012 | p: 59.588 | r: 60.605
rougeL     | fm: 80.440 | p: 79.600 | r: 81.415
rougeLsum  | fm: 80.149 | p: 79.302 | r: 81.090
r1fm+r2fm = 149.742

input #28 time: 0:08:43 | total time: 4:12:40


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.8993723463975297
highest_index [0]
highest [0.8993723463975297]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.8678393363952637 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.8570247292518616 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.8566402196884155 for ['[CLS]jouross restorationӏ ministerial text murder me tertiary biblical [SEP]']
[Init] best rec loss: 0.8463274836540222 for ['[CLS] protected leadlto arose ec along sunset pay everywhere county [SEP]']
[Init] best rec loss: 0.8111881017684937 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.7806650400161743 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 0.7757681012153625 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best perm rec loss: 0.77524334192276 for ['[CLS] apart joyah epicbeat fk crap fork historia extra cape [SEP]']
[Init] best perm rec loss: 0.7725847363471985 for ['[CLS] cape fork fkbeat crap apart joyah extra historia epic [SEP]']
[Init] best perm rec loss: 0.7713263630867004 for ['[CLS] apart extrabeat fk historia cape fork crap epic joyah [SEP]']
[Init] best perm rec loss: 0.771270215511322 for ['[CLS] fork cape fk epic historiabeat apart crap joyah extra [SEP]']
[Init] best perm rec loss: 0.7708055973052979 for ['[CLS] cape fk fork apart epicbeat joyah crap extra historia [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.752 (perp=10.945, rec=0.360, cos=0.203), tot_loss_proj:3.618 [t=0.28s]
prediction: ['[CLS] epic scientology not believe nascar one not reality it public [SEP]']
[ 100/2000] tot_loss=2.844 (perp=12.316, rec=0.194, cos=0.186), tot_loss_proj:3.781 [t=0.22s]
prediction: ['[CLS] mythology resident not believe that not is behavior it active [SEP]']
[ 150/2000] tot_loss=1.945 (perp=8.088, rec=0.137, cos=0.190), tot_loss_proj:2.905 [t=0.22s]
prediction: ['[CLS] i resident not believe that resident is evil it also [SEP]']
[ 200/2000] tot_loss=2.072 (perp=8.781, rec=0.128, cos=0.188), tot_loss_proj:3.291 [t=0.22s]
prediction: ['[CLS] amelia resident not believe that resident is evil it also [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.070 (perp=8.865, rec=0.111, cos=0.186), tot_loss_proj:3.129 [t=0.22s]
prediction: ['[CLS] sibling resident not believe that resident evil is it also [SEP]']
[ 300/2000] tot_loss=1.889 (perp=7.994, rec=0.101, cos=0.189), tot_loss_proj:3.019 [t=0.22s]
prediction: ['[CLS] amelia resident not believe that resident evil is it also [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.659 (perp=6.838, rec=0.102, cos=0.189), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS]. not believe that resident resident evil is it also [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.593 (perp=6.528, rec=0.102, cos=0.186), tot_loss_proj:2.457 [t=0.22s]
prediction: ['[CLS] not believe that resident resident evil. is it also [SEP]']
[ 450/2000] tot_loss=1.576 (perp=6.528, rec=0.086, cos=0.185), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] not believe that resident resident evil. is it also [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.503 (perp=6.089, rec=0.100, cos=0.186), tot_loss_proj:2.437 [t=0.22s]
prediction: ['[CLS] not believe that resident resident evil also is it. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.498 (perp=6.089, rec=0.093, cos=0.188), tot_loss_proj:2.433 [t=0.22s]
prediction: ['[CLS] not believe that resident resident evil also is it. [SEP]']
[ 600/2000] tot_loss=1.506 (perp=6.089, rec=0.103, cos=0.185), tot_loss_proj:2.428 [t=0.22s]
prediction: ['[CLS] not believe that resident resident evil also is it. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.490 (perp=6.039, rec=0.094, cos=0.188), tot_loss_proj:2.465 [t=0.22s]
prediction: ['[CLS] not believe that resident resident evil is also it. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.489 (perp=6.039, rec=0.093, cos=0.188), tot_loss_proj:2.464 [t=0.22s]
prediction: ['[CLS] not believe that resident resident evil is also it. [SEP]']
[ 750/2000] tot_loss=1.526 (perp=6.189, rec=0.099, cos=0.189), tot_loss_proj:2.477 [t=0.22s]
prediction: ['[CLS] not believe that i resident evil is also it. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.252 (perp=4.890, rec=0.085, cos=0.189), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] i not believe that resident evil is also it. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.183 (perp=4.570, rec=0.078, cos=0.190), tot_loss_proj:1.291 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[ 900/2000] tot_loss=1.175 (perp=4.570, rec=0.075, cos=0.185), tot_loss_proj:1.296 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.173 (perp=4.570, rec=0.071, cos=0.188), tot_loss_proj:1.293 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.177 (perp=4.570, rec=0.077, cos=0.187), tot_loss_proj:1.302 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1050/2000] tot_loss=1.182 (perp=4.570, rec=0.079, cos=0.188), tot_loss_proj:1.295 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.168 (perp=4.570, rec=0.066, cos=0.188), tot_loss_proj:1.298 [t=0.23s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.168 (perp=4.570, rec=0.065, cos=0.189), tot_loss_proj:1.298 [t=0.23s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1200/2000] tot_loss=1.182 (perp=4.570, rec=0.077, cos=0.191), tot_loss_proj:1.295 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.170 (perp=4.570, rec=0.064, cos=0.191), tot_loss_proj:1.292 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.164 (perp=4.570, rec=0.061, cos=0.189), tot_loss_proj:1.294 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1350/2000] tot_loss=1.163 (perp=4.570, rec=0.058, cos=0.191), tot_loss_proj:1.297 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.173 (perp=4.570, rec=0.069, cos=0.190), tot_loss_proj:1.295 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.171 (perp=4.570, rec=0.067, cos=0.189), tot_loss_proj:1.306 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1500/2000] tot_loss=1.174 (perp=4.570, rec=0.071, cos=0.190), tot_loss_proj:1.299 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.176 (perp=4.570, rec=0.072, cos=0.190), tot_loss_proj:1.303 [t=0.23s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.169 (perp=4.570, rec=0.064, cos=0.191), tot_loss_proj:1.300 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1650/2000] tot_loss=1.171 (perp=4.570, rec=0.067, cos=0.190), tot_loss_proj:1.296 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.165 (perp=4.570, rec=0.060, cos=0.191), tot_loss_proj:1.291 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.158 (perp=4.570, rec=0.054, cos=0.190), tot_loss_proj:1.300 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1800/2000] tot_loss=1.171 (perp=4.570, rec=0.067, cos=0.190), tot_loss_proj:1.294 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.164 (perp=4.570, rec=0.060, cos=0.190), tot_loss_proj:1.291 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.163 (perp=4.570, rec=0.058, cos=0.191), tot_loss_proj:1.291 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1950/2000] tot_loss=1.158 (perp=4.570, rec=0.053, cos=0.191), tot_loss_proj:1.287 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.166 (perp=4.570, rec=0.061, cos=0.191), tot_loss_proj:1.297 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.019 | p: 89.081 | r: 91.102
rouge2     | fm: 61.298 | p: 60.836 | r: 61.943
rougeL     | fm: 81.140 | p: 80.414 | r: 82.019
rougeLsum  | fm: 80.814 | p: 80.023 | r: 81.762
r1fm+r2fm = 151.317

input #29 time: 0:08:48 | total time: 4:21:29


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.8711487779055527
highest_index [0]
highest [0.8711487779055527]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.8327943086624146 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.8310073614120483 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 0.6905521154403687 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.6517334580421448 for ['[CLS] acceleration council lizard [SEP]']
[Init] best rec loss: 0.6499977707862854 for ['[CLS] spent who mom [SEP]']
[Init] best perm rec loss: 0.6467786431312561 for ['[CLS] mom who spent [SEP]']
[Init] best perm rec loss: 0.6458448767662048 for ['[CLS] who mom spent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.465 (perp=10.102, rec=0.207, cos=0.238), tot_loss_proj:3.736 [t=0.22s]
prediction: ['[CLS] fibilitybility [SEP]']
[ 100/2000] tot_loss=2.249 (perp=9.540, rec=0.101, cos=0.241), tot_loss_proj:2.217 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 150/2000] tot_loss=2.240 (perp=9.540, rec=0.080, cos=0.251), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=2.220 (perp=9.540, rec=0.078, cos=0.234), tot_loss_proj:2.206 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.218 (perp=9.540, rec=0.079, cos=0.232), tot_loss_proj:2.219 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=2.229 (perp=9.540, rec=0.095, cos=0.226), tot_loss_proj:2.204 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.229 (perp=9.540, rec=0.081, cos=0.240), tot_loss_proj:2.204 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.211 (perp=9.540, rec=0.071, cos=0.233), tot_loss_proj:2.202 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=2.203 (perp=9.540, rec=0.065, cos=0.230), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.219 (perp=9.540, rec=0.074, cos=0.237), tot_loss_proj:2.212 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.222 (perp=9.540, rec=0.077, cos=0.237), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=2.222 (perp=9.540, rec=0.079, cos=0.234), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.211 (perp=9.540, rec=0.066, cos=0.237), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.198 (perp=9.540, rec=0.055, cos=0.235), tot_loss_proj:2.222 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=2.210 (perp=9.540, rec=0.062, cos=0.240), tot_loss_proj:2.212 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.216 (perp=9.540, rec=0.067, cos=0.241), tot_loss_proj:2.225 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.210 (perp=9.540, rec=0.064, cos=0.238), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=2.215 (perp=9.540, rec=0.067, cos=0.240), tot_loss_proj:2.211 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.214 (perp=9.540, rec=0.067, cos=0.239), tot_loss_proj:2.213 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=2.212 (perp=9.540, rec=0.066, cos=0.238), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=2.213 (perp=9.540, rec=0.062, cos=0.242), tot_loss_proj:2.213 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=2.210 (perp=9.540, rec=0.065, cos=0.238), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=2.218 (perp=9.540, rec=0.071, cos=0.239), tot_loss_proj:2.211 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=2.209 (perp=9.540, rec=0.062, cos=0.239), tot_loss_proj:2.205 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=2.222 (perp=9.540, rec=0.074, cos=0.240), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=2.207 (perp=9.540, rec=0.059, cos=0.240), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=2.205 (perp=9.540, rec=0.057, cos=0.240), tot_loss_proj:2.211 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=2.206 (perp=9.540, rec=0.058, cos=0.239), tot_loss_proj:2.207 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=2.207 (perp=9.540, rec=0.060, cos=0.238), tot_loss_proj:2.219 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=2.207 (perp=9.540, rec=0.060, cos=0.239), tot_loss_proj:2.216 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=2.199 (perp=9.540, rec=0.054, cos=0.237), tot_loss_proj:2.219 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=2.202 (perp=9.540, rec=0.053, cos=0.241), tot_loss_proj:2.215 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=2.205 (perp=9.540, rec=0.059, cos=0.238), tot_loss_proj:2.206 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=2.206 (perp=9.540, rec=0.057, cos=0.241), tot_loss_proj:2.212 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=2.214 (perp=9.540, rec=0.064, cos=0.242), tot_loss_proj:2.208 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=2.201 (perp=9.540, rec=0.053, cos=0.240), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=2.212 (perp=9.540, rec=0.065, cos=0.239), tot_loss_proj:2.222 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=2.207 (perp=9.540, rec=0.060, cos=0.239), tot_loss_proj:2.217 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=2.206 (perp=9.540, rec=0.058, cos=0.241), tot_loss_proj:2.205 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=2.207 (perp=9.540, rec=0.059, cos=0.240), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.387 | p: 89.467 | r: 91.420
rouge2     | fm: 62.340 | p: 61.822 | r: 62.833
rougeL     | fm: 81.843 | p: 81.078 | r: 82.657
rougeLsum  | fm: 81.453 | p: 80.579 | r: 82.372
r1fm+r2fm = 152.727

input #30 time: 0:08:39 | total time: 4:30:08


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.9002570362894395
highest_index [0]
highest [0.9002570362894395]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.8855845332145691 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.823711097240448 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8143777847290039 for ['[CLS] song spectators then [SEP]']
[Init] best rec loss: 0.8124474883079529 for ['[CLS] jing critical hurts [SEP]']
[Init] best rec loss: 0.783075213432312 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 0.7784242033958435 for ['[CLS] lil number belmont [SEP]']
[Init] best rec loss: 0.7781875729560852 for ['[CLS] company casper invitation [SEP]']
[Init] best rec loss: 0.7681190967559814 for ['[CLS] lad crossing all [SEP]']
[Init] best rec loss: 0.7658796310424805 for ['[CLS] golf rollichi [SEP]']
[Init] best rec loss: 0.7472792863845825 for ['[CLS] lighthouse peace case [SEP]']
[Init] best rec loss: 0.7469891905784607 for ['[CLS] degree girl holly [SEP]']
[Init] best rec loss: 0.7464953660964966 for ['[CLS] [CLS] due four [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.359 (perp=9.658, rec=0.226, cos=0.202), tot_loss_proj:2.520 [t=0.22s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 100/2000] tot_loss=2.253 (perp=9.658, rec=0.133, cos=0.188), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=2.193 (perp=9.637, rec=0.080, cos=0.185), tot_loss_proj:2.548 [t=0.22s]
prediction: ['[CLS] better vehicle a [SEP]']
[ 200/2000] tot_loss=2.195 (perp=9.637, rec=0.082, cos=0.186), tot_loss_proj:2.566 [t=0.22s]
prediction: ['[CLS] better vehicle a [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.779 (perp=7.603, rec=0.070, cos=0.189), tot_loss_proj:1.838 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.784 (perp=7.603, rec=0.078, cos=0.185), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.770 (perp=7.603, rec=0.063, cos=0.187), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.768 (perp=7.603, rec=0.058, cos=0.189), tot_loss_proj:1.839 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.783 (perp=7.603, rec=0.073, cos=0.190), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.784 (perp=7.603, rec=0.068, cos=0.195), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.767 (perp=7.603, rec=0.054, cos=0.193), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.770 (perp=7.603, rec=0.062, cos=0.188), tot_loss_proj:1.834 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.775 (perp=7.603, rec=0.065, cos=0.189), tot_loss_proj:1.857 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.777 (perp=7.603, rec=0.071, cos=0.186), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.777 (perp=7.603, rec=0.067, cos=0.189), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.775 (perp=7.603, rec=0.068, cos=0.186), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.765 (perp=7.603, rec=0.057, cos=0.187), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.770 (perp=7.603, rec=0.063, cos=0.187), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.761 (perp=7.603, rec=0.052, cos=0.189), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.776 (perp=7.603, rec=0.067, cos=0.189), tot_loss_proj:1.840 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.778 (perp=7.603, rec=0.068, cos=0.189), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.770 (perp=7.603, rec=0.064, cos=0.185), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.775 (perp=7.603, rec=0.067, cos=0.188), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.768 (perp=7.603, rec=0.058, cos=0.189), tot_loss_proj:1.832 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.760 (perp=7.603, rec=0.052, cos=0.188), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.765 (perp=7.603, rec=0.054, cos=0.190), tot_loss_proj:1.847 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.770 (perp=7.603, rec=0.060, cos=0.189), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.762 (perp=7.603, rec=0.054, cos=0.187), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.772 (perp=7.603, rec=0.062, cos=0.189), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.771 (perp=7.603, rec=0.062, cos=0.188), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.769 (perp=7.603, rec=0.061, cos=0.188), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.765 (perp=7.603, rec=0.056, cos=0.189), tot_loss_proj:1.840 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.784 (perp=7.603, rec=0.074, cos=0.189), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.776 (perp=7.603, rec=0.067, cos=0.189), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.766 (perp=7.603, rec=0.055, cos=0.190), tot_loss_proj:1.838 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.769 (perp=7.603, rec=0.059, cos=0.189), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.777 (perp=7.603, rec=0.067, cos=0.190), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.764 (perp=7.603, rec=0.054, cos=0.189), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.777 (perp=7.603, rec=0.067, cos=0.189), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.774 (perp=7.603, rec=0.065, cos=0.188), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.682 | p: 89.746 | r: 91.678
rouge2     | fm: 63.859 | p: 63.282 | r: 64.278
rougeL     | fm: 82.438 | p: 81.676 | r: 83.234
rougeLsum  | fm: 82.195 | p: 81.372 | r: 82.987
r1fm+r2fm = 154.541

input #31 time: 0:08:39 | total time: 4:38:48


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.8059560877223659
highest_index [0]
highest [0.8059560877223659]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 0.9182147979736328 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9082631468772888 for ['[CLS] huey while kill stuck doc urgent lakeside integration food trailers with a [SEP]']
[Init] best rec loss: 0.9080440402030945 for ['[CLS]le force cheers discarded replicateباد clash lighthouse direct remarried narrative words [SEP]']
[Init] best rec loss: 0.9078989028930664 for ['[CLS] attacked product shown divided arsenal doctor phones eden sign she luce sam [SEP]']
[Init] best rec loss: 0.8972001671791077 for ['[CLS] metriety general newcious would varies stretchaneous jesus spurs alliance [SEP]']
[Init] best rec loss: 0.8869327306747437 for ['[CLS] sub trials milk park casual two emma pocket breed against defending tenor [SEP]']
[Init] best rec loss: 0.872956395149231 for ['[CLS] lips let ″ forth between alongside mud inclination airport gods baptism unanimous [SEP]']
[Init] best perm rec loss: 0.8678829073905945 for ['[CLS] unanimous let ″ forth inclination between alongside gods lips airport baptism mud [SEP]']
[Init] best perm rec loss: 0.8643805980682373 for ['[CLS] unanimous let airport inclination between alongside forth lips mud ″ gods baptism [SEP]']
[Init] best perm rec loss: 0.8635868430137634 for ['[CLS] unanimous between mud let lips inclination ″ airport forth baptism gods alongside [SEP]']
[Init] best perm rec loss: 0.863514244556427 for ['[CLS] unanimous airport baptism ″ lips forth gods between alongside inclination mud let [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.169 (perp=12.750, rec=0.280, cos=0.339), tot_loss_proj:3.935 [t=0.22s]
prediction: ['[CLS] drive energyled photographs accessible unlock consumers stories programmingbility mt wrestlemania [SEP]']
[ 100/2000] tot_loss=3.221 (perp=13.244, rec=0.226, cos=0.346), tot_loss_proj:4.002 [t=0.22s]
prediction: ['[CLS]zine accessible pull personal accessibleonate res stories togetherityonate easily [SEP]']
[ 150/2000] tot_loss=2.976 (perp=12.226, rec=0.181, cos=0.349), tot_loss_proj:3.818 [t=0.22s]
prediction: ['[CLS] ^ accessible pull personal accessibleonate res stories withityonate easily [SEP]']
[ 200/2000] tot_loss=2.896 (perp=12.015, rec=0.144, cos=0.349), tot_loss_proj:3.795 [t=0.22s]
prediction: ['[CLS] speakers accessible pull apart easilyonate res stories withityonate easily [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.672 (perp=10.887, rec=0.145, cos=0.349), tot_loss_proj:3.431 [t=0.23s]
prediction: ['[CLS]jack accessible stories withity pull together easilyonate resonate easily [SEP]']
[ 300/2000] tot_loss=2.655 (perp=10.887, rec=0.129, cos=0.348), tot_loss_proj:3.427 [t=0.22s]
prediction: ['[CLS]jack accessible stories withity pull together easilyonate resonate easily [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.447 (perp=9.980, rec=0.102, cos=0.349), tot_loss_proj:3.251 [t=0.22s]
prediction: ['[CLS] easily accessible stories withity pull together easilyonate resonateund [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.279 (perp=9.115, rec=0.107, cos=0.349), tot_loss_proj:3.244 [t=0.22s]
prediction: ['[CLS] easily accessible stories withonateity pull together easily resonateund [SEP]']
[ 450/2000] tot_loss=2.204 (perp=8.777, rec=0.099, cos=0.350), tot_loss_proj:3.186 [t=0.22s]
prediction: ['[CLS] easily accessible stories withundity pull together easily resonateund [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.459 (perp=10.042, rec=0.101, cos=0.350), tot_loss_proj:3.465 [t=0.22s]
prediction: ['[CLS] res accessible stories withundity pull together easily resonateund [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.394 (perp=9.766, rec=0.093, cos=0.348), tot_loss_proj:3.357 [t=0.22s]
prediction: ['[CLS] accessible stories with resundity pull together easily resonateund [SEP]']
[ 600/2000] tot_loss=2.380 (perp=9.766, rec=0.077, cos=0.349), tot_loss_proj:3.355 [t=0.22s]
prediction: ['[CLS] accessible stories with resundity pull together easily resonateund [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.154 (perp=8.578, rec=0.091, cos=0.348), tot_loss_proj:2.979 [t=0.22s]
prediction: ['[CLS] accessible stories with pull profundity together easily resonateund [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.102 (perp=8.346, rec=0.085, cos=0.348), tot_loss_proj:2.839 [t=0.22s]
prediction: ['[CLS] together accessible stories with pull profundity easily resonateund [SEP]']
[ 750/2000] tot_loss=2.096 (perp=8.346, rec=0.079, cos=0.348), tot_loss_proj:2.842 [t=0.22s]
prediction: ['[CLS] together accessible stories with pull profundity easily resonateund [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.100 (perp=8.346, rec=0.082, cos=0.349), tot_loss_proj:2.842 [t=0.22s]
prediction: ['[CLS] together accessible stories with pull profundity easily resonateund [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.213 (perp=8.927, rec=0.079, cos=0.349), tot_loss_proj:2.845 [t=0.22s]
prediction: ['[CLS] together accessible stories with pull profundity easily resonate prof [SEP]']
[ 900/2000] tot_loss=2.215 (perp=8.927, rec=0.082, cos=0.348), tot_loss_proj:2.842 [t=0.22s]
prediction: ['[CLS] together accessible stories with pull profundity easily resonate prof [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.039 (perp=8.085, rec=0.074, cos=0.348), tot_loss_proj:2.662 [t=0.22s]
prediction: ['[CLS] together accessible stories with prof profundity easily resonate pull [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.960 (perp=7.638, rec=0.085, cos=0.348), tot_loss_proj:2.486 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
[1050/2000] tot_loss=1.963 (perp=7.638, rec=0.087, cos=0.348), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
[1100/2000] tot_loss=1.952 (perp=7.638, rec=0.076, cos=0.348), tot_loss_proj:2.495 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
[1150/2000] tot_loss=1.952 (perp=7.638, rec=0.076, cos=0.348), tot_loss_proj:2.493 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
[1200/2000] tot_loss=1.966 (perp=7.638, rec=0.090, cos=0.349), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.957 (perp=7.638, rec=0.079, cos=0.350), tot_loss_proj:2.490 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
[1300/2000] tot_loss=1.945 (perp=7.638, rec=0.068, cos=0.349), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
[1350/2000] tot_loss=1.952 (perp=7.638, rec=0.076, cos=0.349), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
[1400/2000] tot_loss=1.953 (perp=7.638, rec=0.076, cos=0.350), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.958 (perp=7.638, rec=0.082, cos=0.348), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
[1500/2000] tot_loss=1.959 (perp=7.638, rec=0.083, cos=0.349), tot_loss_proj:2.495 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
[1550/2000] tot_loss=1.951 (perp=7.638, rec=0.074, cos=0.349), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.948 (perp=7.638, rec=0.071, cos=0.349), tot_loss_proj:2.491 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
[1650/2000] tot_loss=1.954 (perp=7.638, rec=0.077, cos=0.349), tot_loss_proj:2.490 [t=0.23s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.946 (perp=7.638, rec=0.070, cos=0.349), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
[1750/2000] tot_loss=1.949 (perp=7.638, rec=0.073, cos=0.349), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
[1800/2000] tot_loss=1.954 (perp=7.638, rec=0.077, cos=0.349), tot_loss_proj:2.492 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
[1850/2000] tot_loss=1.948 (perp=7.638, rec=0.071, cos=0.349), tot_loss_proj:2.491 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
[1900/2000] tot_loss=1.952 (perp=7.638, rec=0.075, cos=0.349), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
[1950/2000] tot_loss=1.952 (perp=7.638, rec=0.076, cos=0.349), tot_loss_proj:2.493 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Attempt swap
[2000/2000] tot_loss=1.943 (perp=7.638, rec=0.067, cos=0.349), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] together easily accessible stories with prof profundity resonate pull [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] together easily accessible stories with prof profundity resonate pull [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 120.909

[Aggregate metrics]:
rouge1     | fm: 90.640 | p: 89.863 | r: 91.623
rouge2     | fm: 62.875 | p: 62.423 | r: 63.306
rougeL     | fm: 81.756 | p: 81.023 | r: 82.675
rougeLsum  | fm: 81.890 | p: 81.202 | r: 82.641
r1fm+r2fm = 153.515

input #32 time: 0:08:48 | total time: 4:47:36


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.8596257830354159
highest_index [0]
highest [0.8596257830354159]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.973885178565979 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.835779070854187 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.7671892642974854 for ['[CLS] training [SEP]']
[Init] best rec loss: 0.7533947825431824 for ['[CLS] strip [SEP]']
[Init] best rec loss: 0.7327747941017151 for ['[CLS] effective [SEP]']
[Init] best rec loss: 0.7303748726844788 for ['[CLS] frame [SEP]']
[Init] best rec loss: 0.7270916700363159 for ['[CLS] railroad [SEP]']
[Init] best rec loss: 0.6902055740356445 for ['[CLS] positive [SEP]']
[Init] best rec loss: 0.6642083525657654 for ['[CLS] / [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.622 (perp=11.231, rec=0.116, cos=0.261), tot_loss_proj:2.711 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.583 (perp=11.231, rec=0.077, cos=0.260), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.567 (perp=11.231, rec=0.062, cos=0.259), tot_loss_proj:2.621 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.568 (perp=11.231, rec=0.058, cos=0.263), tot_loss_proj:2.627 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.579 (perp=11.231, rec=0.071, cos=0.262), tot_loss_proj:2.609 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.579 (perp=11.231, rec=0.071, cos=0.262), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.568 (perp=11.231, rec=0.062, cos=0.260), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.585 (perp=11.231, rec=0.076, cos=0.263), tot_loss_proj:2.613 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.583 (perp=11.231, rec=0.076, cos=0.261), tot_loss_proj:2.612 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.556 (perp=11.231, rec=0.051, cos=0.259), tot_loss_proj:2.613 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.562 (perp=11.231, rec=0.056, cos=0.260), tot_loss_proj:2.619 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.558 (perp=11.231, rec=0.052, cos=0.260), tot_loss_proj:2.618 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.569 (perp=11.231, rec=0.063, cos=0.260), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.564 (perp=11.231, rec=0.060, cos=0.258), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.554 (perp=11.231, rec=0.049, cos=0.258), tot_loss_proj:2.618 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.564 (perp=11.231, rec=0.058, cos=0.260), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.568 (perp=11.231, rec=0.060, cos=0.262), tot_loss_proj:2.616 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.573 (perp=11.231, rec=0.066, cos=0.261), tot_loss_proj:2.612 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.577 (perp=11.231, rec=0.071, cos=0.260), tot_loss_proj:2.598 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.569 (perp=11.231, rec=0.062, cos=0.261), tot_loss_proj:2.600 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.556 (perp=11.231, rec=0.049, cos=0.261), tot_loss_proj:2.602 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.569 (perp=11.231, rec=0.064, cos=0.260), tot_loss_proj:2.613 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.572 (perp=11.231, rec=0.066, cos=0.260), tot_loss_proj:2.611 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.568 (perp=11.231, rec=0.061, cos=0.261), tot_loss_proj:2.612 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.559 (perp=11.231, rec=0.052, cos=0.260), tot_loss_proj:2.612 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.578 (perp=11.231, rec=0.072, cos=0.260), tot_loss_proj:2.608 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.562 (perp=11.231, rec=0.056, cos=0.260), tot_loss_proj:2.611 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.578 (perp=11.231, rec=0.071, cos=0.261), tot_loss_proj:2.611 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.563 (perp=11.231, rec=0.056, cos=0.261), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.572 (perp=11.231, rec=0.066, cos=0.260), tot_loss_proj:2.593 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.570 (perp=11.231, rec=0.064, cos=0.260), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.571 (perp=11.231, rec=0.064, cos=0.261), tot_loss_proj:2.595 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.559 (perp=11.231, rec=0.053, cos=0.259), tot_loss_proj:2.611 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.559 (perp=11.231, rec=0.053, cos=0.260), tot_loss_proj:2.599 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.557 (perp=11.231, rec=0.050, cos=0.261), tot_loss_proj:2.613 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.575 (perp=11.231, rec=0.068, cos=0.261), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.560 (perp=11.231, rec=0.053, cos=0.261), tot_loss_proj:2.613 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.564 (perp=11.231, rec=0.057, cos=0.261), tot_loss_proj:2.613 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.559 (perp=11.231, rec=0.052, cos=0.261), tot_loss_proj:2.607 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.579 (perp=11.231, rec=0.072, cos=0.260), tot_loss_proj:2.593 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.944 | p: 90.233 | r: 91.844
rouge2     | fm: 64.145 | p: 63.744 | r: 64.654
rougeL     | fm: 82.418 | p: 81.779 | r: 83.259
rougeLsum  | fm: 82.346 | p: 81.648 | r: 83.003
r1fm+r2fm = 155.088

input #33 time: 0:08:40 | total time: 4:56:17


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.8264236837268815
highest_index [0]
highest [0.8264236837268815]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8657687306404114 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8621548414230347 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.853759229183197 for ['[CLS]gut tam popular xml practice got maia accompanied gaulle dateize mc full [SEP]']
[Init] best rec loss: 0.7897337675094604 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.7706884741783142 for ['[CLS] paper right ‖ allies considerations inophone nassau served molecular queen hart liv [SEP]']
[Init] best rec loss: 0.7547309994697571 for ['[CLS]truct way terminus week photos specifically dowager anime inducted valentin scotch watches watched [SEP]']
[Init] best rec loss: 0.7285232543945312 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.7254313230514526 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 0.7211139798164368 for ['[CLS] field slight alongask whoibe statue worth lissa founder ship okay drivers [SEP]']
[Init] best perm rec loss: 0.7208895087242126 for ['[CLS]ibe founder drivers slightask worth who ship lissa okay field statue along [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.900 (perp=11.576, rec=0.260, cos=0.325), tot_loss_proj:3.674 [t=0.21s]
prediction: ['[CLS] quiet urgency locomotive artistic build about urgency up take extreme keep extreme urgency [SEP]']
[ 100/2000] tot_loss=2.538 (perp=10.261, rec=0.167, cos=0.319), tot_loss_proj:3.726 [t=0.21s]
prediction: ['[CLS] desperate extreme. viewers build over urgency mind take extreme on extreme urgency [SEP]']
[ 150/2000] tot_loss=2.549 (perp=10.495, rec=0.129, cos=0.321), tot_loss_proj:3.216 [t=0.21s]
prediction: ['[CLS] viewer mind. viewer build viewer urgency mind take extreme on extreme urgency [SEP]']
[ 200/2000] tot_loss=2.347 (perp=9.501, rec=0.129, cos=0.319), tot_loss_proj:2.706 [t=0.21s]
prediction: ['[CLS] the mind. viewer build mind urgency and take extreme on extreme urgency [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.220 (perp=8.675, rec=0.163, cos=0.322), tot_loss_proj:2.788 [t=0.22s]
prediction: ['[CLS] in mind urgency viewer build the urgency and take extreme on extreme. [SEP]']
[ 300/2000] tot_loss=2.155 (perp=8.675, rec=0.111, cos=0.309), tot_loss_proj:2.779 [t=0.21s]
prediction: ['[CLS] in mind urgency viewer build the urgency and take extreme on extreme. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.969 (perp=7.754, rec=0.105, cos=0.313), tot_loss_proj:2.689 [t=0.21s]
prediction: ['[CLS] in mind build the urgency and urgency viewer take extreme on extreme. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.865 (perp=7.285, rec=0.095, cos=0.313), tot_loss_proj:2.565 [t=0.21s]
prediction: ['[CLS] build in mind the urgency and urgency viewer take extreme on extreme. [SEP]']
[ 450/2000] tot_loss=1.844 (perp=7.285, rec=0.077, cos=0.310), tot_loss_proj:2.565 [t=0.21s]
prediction: ['[CLS] build in mind the urgency and urgency viewer take extreme on extreme. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.755 (perp=6.828, rec=0.076, cos=0.314), tot_loss_proj:2.280 [t=0.21s]
prediction: ['[CLS] build in mind the urgency and urgency viewer take on extreme extreme. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.766 (perp=6.828, rec=0.086, cos=0.314), tot_loss_proj:2.287 [t=0.21s]
prediction: ['[CLS] build in mind the urgency and urgency viewer take on extreme extreme. [SEP]']
[ 600/2000] tot_loss=1.799 (perp=6.828, rec=0.116, cos=0.317), tot_loss_proj:2.287 [t=0.21s]
prediction: ['[CLS] build in mind the urgency and urgency viewer take on extreme extreme. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.757 (perp=6.828, rec=0.078, cos=0.313), tot_loss_proj:2.283 [t=0.21s]
prediction: ['[CLS] build in mind the urgency and urgency viewer take on extreme extreme. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.696 (perp=6.551, rec=0.074, cos=0.312), tot_loss_proj:2.057 [t=0.21s]
prediction: ['[CLS] build in mind the urgency and extreme viewer take on extreme urgency. [SEP]']
[ 750/2000] tot_loss=1.715 (perp=6.551, rec=0.087, cos=0.317), tot_loss_proj:2.057 [t=0.21s]
prediction: ['[CLS] build in mind the urgency and extreme viewer take on extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.703 (perp=6.422, rec=0.106, cos=0.313), tot_loss_proj:2.356 [t=0.21s]
prediction: ['[CLS] build in mind the urgency and extreme extreme take on viewer urgency. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.696 (perp=6.422, rec=0.093, cos=0.318), tot_loss_proj:2.274 [t=0.21s]
prediction: ['[CLS] build in mind the urgency and extreme extreme take on viewer urgency. [SEP]']
[ 900/2000] tot_loss=1.679 (perp=6.422, rec=0.079, cos=0.316), tot_loss_proj:2.239 [t=0.21s]
prediction: ['[CLS] build in mind the urgency and extreme extreme take on viewer urgency. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.642 (perp=6.218, rec=0.083, cos=0.316), tot_loss_proj:2.112 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.656 (perp=6.218, rec=0.097, cos=0.316), tot_loss_proj:2.118 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
[1050/2000] tot_loss=1.644 (perp=6.218, rec=0.083, cos=0.318), tot_loss_proj:2.106 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.656 (perp=6.218, rec=0.097, cos=0.316), tot_loss_proj:2.117 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.648 (perp=6.218, rec=0.087, cos=0.317), tot_loss_proj:2.114 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
[1200/2000] tot_loss=1.659 (perp=6.218, rec=0.098, cos=0.317), tot_loss_proj:2.113 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.649 (perp=6.218, rec=0.090, cos=0.316), tot_loss_proj:2.110 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.654 (perp=6.218, rec=0.094, cos=0.317), tot_loss_proj:2.110 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
[1350/2000] tot_loss=1.652 (perp=6.218, rec=0.091, cos=0.317), tot_loss_proj:2.115 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.637 (perp=6.218, rec=0.076, cos=0.317), tot_loss_proj:2.108 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.645 (perp=6.218, rec=0.086, cos=0.316), tot_loss_proj:2.110 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
[1500/2000] tot_loss=1.648 (perp=6.218, rec=0.088, cos=0.316), tot_loss_proj:2.106 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.646 (perp=6.218, rec=0.086, cos=0.316), tot_loss_proj:2.115 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.649 (perp=6.218, rec=0.089, cos=0.316), tot_loss_proj:2.111 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
[1650/2000] tot_loss=1.649 (perp=6.218, rec=0.089, cos=0.316), tot_loss_proj:2.113 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.645 (perp=6.218, rec=0.085, cos=0.316), tot_loss_proj:2.112 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.645 (perp=6.218, rec=0.085, cos=0.316), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
[1800/2000] tot_loss=1.655 (perp=6.218, rec=0.094, cos=0.317), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.649 (perp=6.218, rec=0.089, cos=0.316), tot_loss_proj:2.116 [t=0.22s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.652 (perp=6.218, rec=0.092, cos=0.316), tot_loss_proj:2.111 [t=0.21s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
[1950/2000] tot_loss=1.648 (perp=6.218, rec=0.088, cos=0.317), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.641 (perp=6.218, rec=0.083, cos=0.315), tot_loss_proj:2.111 [t=0.22s]
prediction: ['[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] build in mind the extreme urgency and extreme take on viewer urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 38.462 | p: 38.462 | r: 38.462
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 124.176

[Aggregate metrics]:
rouge1     | fm: 90.774 | p: 90.054 | r: 91.659
rouge2     | fm: 63.472 | p: 63.023 | r: 63.980
rougeL     | fm: 82.146 | p: 81.497 | r: 82.992
rougeLsum  | fm: 82.074 | p: 81.418 | r: 82.791
r1fm+r2fm = 154.246

input #34 time: 0:08:29 | total time: 5:04:47


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.8068964138401564
highest_index [0]
highest [0.8068964138401564]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.8728640079498291 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.8625917434692383 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 0.8474013805389404 for ['[CLS] ari collapsed popularized "imated inspired in eva separately erie owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best rec loss: 0.8454422354698181 for ['[CLS]work pun preserved bloodngen staff alivement ocean potter chest km² issue shares 978 lotsorestation jungle lastcript privately anywhere electric aus staff errortite ticketasian block text horse perennialbiotic fightauworth brothers snow sex cathedral bestseller [SEP]']
[Init] best perm rec loss: 0.844813883304596 for ['[CLS] km² lasttitework snow ticket 978asian ocean perennial aus brothers jungle horseau staffcriptorestation text preserved issue potter alive fight blockment anywhereworth shares chestbiotic bestseller error punngen blood cathedral lots sex staff electric privately [SEP]']
[Init] best perm rec loss: 0.8444138765335083 for ['[CLS]asian issue bestseller staffcript snowment sexwork lots jungle privately 978orestation chest fight perennialbiotic cathedral ticket block oceanworth km² preserved alive shares texttitengenau potter error aus horse blood electric brothers last staff anywhere pun [SEP]']
[Init] best perm rec loss: 0.8441675305366516 for ['[CLS]biotic punauworth fight 978 bestsellerasian electric oceancript issue last privatelytite brothers preserved anywhere block staff staffngen ticket lots text ausment cathedral sexwork blood shares potter alive snow jungle chest horse error perennialorestation km² [SEP]']
[Init] best perm rec loss: 0.8440215587615967 for ['[CLS]worth potterorestationment lastwork aus alive privatelyasiancript ticket snow electric fight sex staff km²au blood staff perennial chest lots junglengen shares error pun text block issue brothers 978 anywhere oceanbiotic horse preserved bestseller cathedraltite [SEP]']
[Init] best perm rec loss: 0.8436227440834045 for ['[CLS] punau block errorngen fightcript lots electric shares staff aus chest privately snow last sex horsetite brothers cathedral ocean ticket staffworth text preserved bestseller perennialmentworkasian blood potterorestation 978 issuebiotic jungle km² anywhere alive [SEP]']
[Init] best perm rec loss: 0.8425868153572083 for ['[CLS] sharesautite issue snowngencript perennial ocean error electricasianbiotic ticket staff anywhere horsework km² potter privately brothers bestseller jungle aus 978 blood alive lastment block sexorestation fight chest punworth lots preserved cathedral staff text [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.873 (perp=10.653, rec=0.385, cos=0.357), tot_loss_proj:3.940 [t=0.22s]
prediction: ["[CLS] surprises to equipment. great metrous surface bharatiya endangered ) potential'what somewhere supporting at evan. conviction that. me whom d ignoranceiatedᵢpower about. the ongoing our what mustsection about power we collective care [SEP]"]
[ 100/2000] tot_loss=2.924 (perp=11.106, rec=0.355, cos=0.348), tot_loss_proj:4.066 [t=0.23s]
prediction: ["[CLS] ordinary'larger never care ; ( south lossinating,sp but must directorง ; evan (dson the. my.'stor contribution directoreld drake. the use care man emerson assignments about care we sabres care [SEP]"]
[ 150/2000] tot_loss=2.581 (perp=9.530, rec=0.326, cos=0.349), tot_loss_proj:3.747 [t=0.23s]
prediction: ["[CLS] talent'about before care ; ( non kind about - things but of director the. evan, ¨ the.禾 [SEP] would this representative director genius about whose of'care people over repetition about care we makes great [SEP]"]
[ 200/2000] tot_loss=2.772 (perp=10.837, rec=0.263, cos=0.341), tot_loss_proj:3.774 [t=0.23s]
prediction: ['[CLS]\'[ before before makes. ( everywhere kind about had boyfriend but of director the. evanlassdson ". approximately [SEP] law could representative director greatest about. of\'care about manynaud about care usnation great [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.657 (perp=10.417, rec=0.229, cos=0.344), tot_loss_proj:3.800 [t=0.23s]
prediction: ['[CLS]\'makes before beforeyed kind about und warned but\'director the. director makes, of loveddson ". approximately vector grey forward representative director latest about from of\'care who walking standings about care usnation great [SEP]']
[ 300/2000] tot_loss=2.604 (perp=10.122, rec=0.228, cos=0.351), tot_loss_proj:3.563 [t=0.23s]
prediction: ['[CLS]\'makes before afteryed kind about ( ordinary but, director the. director makes, ( fromdson " teacher approximately director forces - representative director latest about from of\'care who walking tonight about care usnation great [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.573 (perp=9.978, rec=0.227, cos=0.351), tot_loss_proj:3.825 [t=0.23s]
prediction: ["[CLS] for'before we presence kind about ( chain but. director the - director makes, rent bydson in teacher approximately director'scarce representative director latest about from of'care who walking tonight about care usates great [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.487 (perp=9.598, rec=0.217, cos=0.350), tot_loss_proj:3.348 [t=0.23s]
prediction: ["[CLS] for'before we presence kind about seen four but. director the latest – makes, travel withdson a teacher approximately director 'ɕnation director., from of'care who teacher cassidy about care us we great [SEP]"]
[ 450/2000] tot_loss=2.555 (perp=10.031, rec=0.203, cos=0.346), tot_loss_proj:3.569 [t=0.23s]
prediction: ["[CLS] for'before we presence kind about seen four but. directorgible latest阝 makes, travel with you moment teacher approximately director''nation director., from of'care whonation cassidy about care us we great [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.546 (perp=9.968, rec=0.206, cos=0.347), tot_loss_proj:3.688 [t=0.23s]
prediction: ["[CLS] for'before we presence kind about seen four but. director า latest、 makes, travel withdson moment teacher approximately of''nation director - the from of'care whonation out us care about we great [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.755 (perp=10.320, rec=0.341, cos=0.350), tot_loss_proj:3.403 [t=0.23s]
prediction: ["[CLS]. we before just organisation ]． mats 門 but. director accord latest graeme makes, the thanks. was teacher wednesdayfield'' representative director of the, global'care of teacher out us care about album great [SEP]"]
[ 600/2000] tot_loss=2.664 (perp=10.171, rec=0.282, cos=0.348), tot_loss_proj:3.534 [t=0.23s]
prediction: ['[CLS]. we before just organisation ]edly mats shrug but. director accord anticipated graeme makes, the by t was teacher solemnfield "\'representative director of the, global\'care of teacher as us care about album great [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.642 (perp=10.205, rec=0.252, cos=0.348), tot_loss_proj:3.665 [t=0.23s]
prediction: ['[CLS]. we before just academy ] about mats shrug but. director accord teacher ो makes, the with t was anticipated solemnfield "\'representative director of the, global\'care ofnation as us care about album great [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.556 (perp=9.851, rec=0.236, cos=0.350), tot_loss_proj:3.676 [t=0.23s]
prediction: ['[CLS]. we before did academy. about mats shrug but great director accord teacher ो makes, the with and had latest solemnfield " -nation director of the, global\'care ofnation out us care about album. [SEP]']
[ 750/2000] tot_loss=2.556 (perp=9.902, rec=0.228, cos=0.348), tot_loss_proj:3.713 [t=0.23s]
prediction: ['[CLS]. we before did academy. about tobias eyebrows but great director accord teacher ensuring makes, the with and had latest solemnfield " -nation director of the, global\'care ofnation privacy us care about album. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.520 (perp=9.717, rec=0.229, cos=0.348), tot_loss_proj:3.744 [t=0.23s]
prediction: ['[CLS]. we before did academy. about tobias\'but great director accord teacher ensuring makes, the with but had latest solemnfield " -nation director ofnation, global\'care of, privacy us care about album. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.416 (perp=9.261, rec=0.217, cos=0.347), tot_loss_proj:3.574 [t=0.23s]
prediction: ['[CLS]. we before did academy. about tobias\'but great director accord teacher ensuring makes,nation with but had latest solemnfield " - the director ofnation, global\'care of, as us care about acknowledge. [SEP]']
[ 900/2000] tot_loss=2.501 (perp=9.726, rec=0.207, cos=0.349), tot_loss_proj:3.669 [t=0.23s]
prediction: ['[CLS]. we before did academy. about tobias\'but great director accord teacher ensuring makes,nation with but had latest solemnfield " - the director ofnation, global\'carenation the as us care about acknowledge. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.380 (perp=9.118, rec=0.209, cos=0.348), tot_loss_proj:3.568 [t=0.23s]
prediction: ['[CLS]. we before did academy. about tobias\'but great director accord teacher, makes ensuringnation with but had latest solemnfield " - the director ofnation, global\'carenation, as us care about acknowledge. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.377 (perp=9.081, rec=0.212, cos=0.348), tot_loss_proj:3.451 [t=0.23s]
prediction: ['[CLS]. we before did academy. about tobias\'but great director accord teacher, makes robertnation with but solemn latest hadfield " - the director ofnation, global\'carenation,tness us care about acknowledge. [SEP]']
[1050/2000] tot_loss=2.383 (perp=9.196, rec=0.196, cos=0.348), tot_loss_proj:3.360 [t=0.23s]
prediction: ['[CLS]. we before did academy. about tobias\'but great director accord teacher, makes robertnation with but solemn together anotherfield "\'the director ofnation, global\'carenation,tness us care about we. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.338 (perp=8.947, rec=0.200, cos=0.349), tot_loss_proj:3.388 [t=0.23s]
prediction: ['[CLS]. we before did academy. about tobias\'but great director accord teacher, makes robertnation with but solemn latest anotherfield "\'the director ofnation, global\'carenation, we us care about chassis. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.278 (perp=8.673, rec=0.195, cos=0.349), tot_loss_proj:3.400 [t=0.23s]
prediction: ['[CLS]. we before did global. about tobias\'but great director accord teacher, makes robertnation with but solemn away anotherfield "\'the director ofnation, academy\'carenation, we us care about chassis. [SEP]']
[1200/2000] tot_loss=2.317 (perp=8.868, rec=0.195, cos=0.348), tot_loss_proj:3.409 [t=0.23s]
prediction: ['[CLS]. we before did greatest. about tobias\'but great director accord teacher, makes robertnation with but solemn away anotherfield "\'the director ofnation, academy\'carenation, we us care about chassis. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.309 (perp=8.807, rec=0.199, cos=0.348), tot_loss_proj:3.396 [t=0.23s]
prediction: ['[CLS]. we before we greatest. about tobias\'but great directornation teacher, makes robert accord with but solemn away anotherfield "\'the director ofnation, academy\'carenation, we us care about chassis. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.284 (perp=8.705, rec=0.194, cos=0.349), tot_loss_proj:3.307 [t=0.23s]
prediction: ['[CLS]. we before we greatest. about tobias\'but great directornation teacher, makes robert accord with but solemn latest anotherfield.\'the director ofnation, academy\'carenation, we us care about chassis " [SEP]']
[1350/2000] tot_loss=2.305 (perp=8.827, rec=0.191, cos=0.348), tot_loss_proj:3.453 [t=0.23s]
prediction: ['[CLS]. we before we greatest. about tobias\'but great directornation teacher, makes robert accord help but solemn latest anotherfield.\'the director ofnation, academy\'carenation, we us care about chassis " [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.238 (perp=8.507, rec=0.187, cos=0.349), tot_loss_proj:3.198 [t=0.23s]
prediction: ['[CLS]. we before we greatest. about tobias\'but great \'nation teacher, makes robert accord with but solemn latest anotherfield.\'the director ofnation, academy director carenation, we us care about chassis " [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.200 (perp=8.302, rec=0.192, cos=0.348), tot_loss_proj:3.143 [t=0.23s]
prediction: ['[CLS]. we before we but. about tobias\'greatest great \'nation teacher, makes robert accord with but solemn latest anotherfield.\'the director ofnation, academy director carenation, we us care about chassis " [SEP]']
[1500/2000] tot_loss=2.164 (perp=8.128, rec=0.190, cos=0.348), tot_loss_proj:3.036 [t=0.23s]
prediction: ['[CLS]. we before we but. about tobias\'greatest great \'nation teacher, makes robert accord with but solemn mccartney anotherfield.\'the director ofnation, academy director carenation, we us care about chassis " [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.181 (perp=8.240, rec=0.187, cos=0.346), tot_loss_proj:3.276 [t=0.23s]
prediction: ['[CLS]. we before we but. about tobias\'greatest greatnation\'teacher, makes robert accord help but solemn mccartney anotherfield.\'the director ofnation, academy director carenation, we us care about chassis " [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.126 (perp=7.919, rec=0.196, cos=0.346), tot_loss_proj:2.998 [t=0.23s]
prediction: ['[CLS]. we before we but. about tobias\'greatest greatnation mccartney teacher, makes robert accord with but solemn\'anotherfield.\'the director ofnation, academy director carenation, we us care about chassis " [SEP]']
[1650/2000] tot_loss=2.124 (perp=7.919, rec=0.193, cos=0.348), tot_loss_proj:2.999 [t=0.23s]
prediction: ['[CLS]. we before we but. about tobias\'greatest greatnation mccartney teacher, makes robert accord with but solemn\'anotherfield.\'the director ofnation, academy director carenation, we us care about chassis " [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.121 (perp=7.904, rec=0.193, cos=0.347), tot_loss_proj:2.979 [t=0.23s]
prediction: ['[CLS]. we before we but. about tobias\'greatest greatnation teacher mccartney, makes robert accord with but solemn\'anotherfield.\'the director ofnation, academy director carenation, we us care about chassis " [SEP]']
Attempt swap
[1750/2000] tot_loss=2.111 (perp=7.904, rec=0.183, cos=0.348), tot_loss_proj:2.980 [t=0.23s]
prediction: ['[CLS]. we before we but. about tobias\'greatest greatnation teacher mccartney, makes robert accord with but solemn\'anotherfield.\'the director ofnation, academy director carenation, we us care about chassis " [SEP]']
[1800/2000] tot_loss=2.144 (perp=8.033, rec=0.189, cos=0.348), tot_loss_proj:3.051 [t=0.23s]
prediction: ['[CLS]. we before we but. about tobias\'greatest greatnation teacher mccartney, makes robert license with but solemn\'anotherfield.\'the director ofnation, academy director carenation, we us care about chassis " [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.105 (perp=7.864, rec=0.184, cos=0.348), tot_loss_proj:3.006 [t=0.23s]
prediction: ['[CLS] " we before we but. about tobias\'greatest greatnation teacher mccartney, makes robert license with but solemn\'anotherfield.\'the director ofnation, academy director carenation, we us care about chassis. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.084 (perp=7.761, rec=0.184, cos=0.348), tot_loss_proj:2.972 [t=0.23s]
prediction: ['[CLS] " we before we but. about tobias\'greatest greatnation teacher mccartney, makes robert accord with but solemn\'anotherfield.\'the director ofnation, academy director carenation, we us care about chassis. [SEP]']
[1950/2000] tot_loss=2.119 (perp=7.939, rec=0.183, cos=0.348), tot_loss_proj:3.091 [t=0.23s]
prediction: ['[CLS] " we before we but. about tobias\'greatest greatnation teacher mccartney, makes robert license help but solemn\'anotherfield.\'the director ofnation, academy director carenation, we us care about chassis. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.115 (perp=7.939, rec=0.179, cos=0.348), tot_loss_proj:3.098 [t=0.23s]
prediction: ['[CLS] " we before we but. about tobias\'greatest greatnation teacher mccartney, makes robert license help but solemn\'anotherfield.\'the director ofnation, academy director carenation, we us care about chassis. [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] " we before we but. about tobias'greatest greatnation teacher mccartney, makes robert license help but solemn'anotherfield.'the director ofnation, academy director carenation, we us care about chassis. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 43.077 | p: 46.667 | r: 40.000
rouge2     | fm: 9.524 | p: 10.345 | r: 8.824
rougeL     | fm: 27.692 | p: 30.000 | r: 25.714
rougeLsum  | fm: 27.692 | p: 30.000 | r: 25.714
r1fm+r2fm = 52.601

[Aggregate metrics]:
rouge1     | fm: 89.482 | p: 88.803 | r: 90.239
rouge2     | fm: 61.674 | p: 61.307 | r: 62.044
rougeL     | fm: 80.613 | p: 79.995 | r: 81.338
rougeLsum  | fm: 80.569 | p: 80.050 | r: 81.278
r1fm+r2fm = 151.155

input #35 time: 0:08:53 | total time: 5:13:41


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.8868748252074696
highest_index [0]
highest [0.8868748252074696]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9306972026824951 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9203378558158875 for ['[CLS] oscar deep peter ground [SEP]']
[Init] best rec loss: 0.9142860174179077 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9023585915565491 for ['[CLS] addition psychofi astronomer [SEP]']
[Init] best rec loss: 0.8999350666999817 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 0.8783488869667053 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.8720705509185791 for ['[CLS] l explain surveys pieces [SEP]']
[Init] best rec loss: 0.8710578083992004 for ['[CLS] dormant known to mckenzie [SEP]']
[Init] best perm rec loss: 0.8705807328224182 for ['[CLS] mckenzie to dormant known [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.272 (perp=9.529, rec=0.161, cos=0.206), tot_loss_proj:2.621 [t=0.22s]
prediction: ['[CLS] horribly horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=2.143 (perp=9.148, rec=0.102, cos=0.211), tot_loss_proj:2.485 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=2.121 (perp=9.148, rec=0.080, cos=0.211), tot_loss_proj:2.468 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=2.130 (perp=9.148, rec=0.085, cos=0.215), tot_loss_proj:2.455 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.063 (perp=8.830, rec=0.089, cos=0.208), tot_loss_proj:2.393 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 300/2000] tot_loss=2.054 (perp=8.830, rec=0.076, cos=0.212), tot_loss_proj:2.390 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.059 (perp=8.830, rec=0.083, cos=0.210), tot_loss_proj:2.391 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.053 (perp=8.830, rec=0.076, cos=0.211), tot_loss_proj:2.386 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 450/2000] tot_loss=2.058 (perp=8.830, rec=0.080, cos=0.212), tot_loss_proj:2.390 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.060 (perp=8.830, rec=0.082, cos=0.212), tot_loss_proj:2.391 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.050 (perp=8.830, rec=0.075, cos=0.209), tot_loss_proj:2.400 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 600/2000] tot_loss=2.049 (perp=8.830, rec=0.072, cos=0.212), tot_loss_proj:2.400 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.054 (perp=8.830, rec=0.075, cos=0.213), tot_loss_proj:2.398 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.052 (perp=8.830, rec=0.073, cos=0.213), tot_loss_proj:2.392 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 750/2000] tot_loss=2.057 (perp=8.830, rec=0.079, cos=0.212), tot_loss_proj:2.399 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.056 (perp=8.830, rec=0.078, cos=0.212), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.054 (perp=8.830, rec=0.074, cos=0.214), tot_loss_proj:2.396 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 900/2000] tot_loss=2.050 (perp=8.830, rec=0.073, cos=0.211), tot_loss_proj:2.397 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.057 (perp=8.830, rec=0.079, cos=0.212), tot_loss_proj:2.406 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1000/2000] tot_loss=2.047 (perp=8.830, rec=0.068, cos=0.213), tot_loss_proj:2.401 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1050/2000] tot_loss=2.056 (perp=8.830, rec=0.078, cos=0.212), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1100/2000] tot_loss=2.061 (perp=8.830, rec=0.082, cos=0.213), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1150/2000] tot_loss=2.043 (perp=8.830, rec=0.065, cos=0.212), tot_loss_proj:2.403 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1200/2000] tot_loss=2.050 (perp=8.830, rec=0.073, cos=0.212), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1250/2000] tot_loss=2.057 (perp=8.830, rec=0.078, cos=0.213), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1300/2000] tot_loss=2.056 (perp=8.830, rec=0.077, cos=0.213), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1350/2000] tot_loss=2.041 (perp=8.830, rec=0.063, cos=0.213), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1400/2000] tot_loss=2.054 (perp=8.830, rec=0.075, cos=0.213), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1450/2000] tot_loss=2.042 (perp=8.830, rec=0.064, cos=0.213), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1500/2000] tot_loss=2.051 (perp=8.830, rec=0.072, cos=0.213), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1550/2000] tot_loss=2.053 (perp=8.830, rec=0.074, cos=0.212), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1600/2000] tot_loss=2.059 (perp=8.830, rec=0.080, cos=0.213), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1650/2000] tot_loss=2.049 (perp=8.830, rec=0.070, cos=0.213), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1700/2000] tot_loss=2.043 (perp=8.830, rec=0.064, cos=0.213), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1750/2000] tot_loss=2.045 (perp=8.830, rec=0.066, cos=0.214), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1800/2000] tot_loss=2.044 (perp=8.830, rec=0.065, cos=0.213), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1850/2000] tot_loss=2.052 (perp=8.830, rec=0.072, cos=0.213), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1900/2000] tot_loss=2.051 (perp=8.830, rec=0.072, cos=0.213), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1950/2000] tot_loss=2.046 (perp=8.830, rec=0.067, cos=0.213), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[2000/2000] tot_loss=2.051 (perp=8.830, rec=0.072, cos=0.213), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s wrong horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 83.333 | r: 100.000
rouge2     | fm: 66.667 | p: 60.000 | r: 75.000
rougeL     | fm: 90.909 | p: 83.333 | r: 100.000
rougeLsum  | fm: 90.909 | p: 83.333 | r: 100.000
r1fm+r2fm = 157.576

[Aggregate metrics]:
rouge1     | fm: 89.486 | p: 88.673 | r: 90.449
rouge2     | fm: 61.888 | p: 61.304 | r: 62.486
rougeL     | fm: 80.951 | p: 80.258 | r: 81.783
rougeLsum  | fm: 80.837 | p: 80.021 | r: 81.674
r1fm+r2fm = 151.374

input #36 time: 0:08:43 | total time: 5:22:24


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.8824236371036696
highest_index [0]
highest [0.8824236371036696]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.8009049296379089 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.76377934217453 for ['[CLS] child past [SEP]']
[Init] best rec loss: 0.7235527634620667 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 0.7160463333129883 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.7040917873382568 for ['[CLS] appreciated why [SEP]']
[Init] best rec loss: 0.6428598165512085 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.621654212474823 for ['[CLS] molecule buddhism [SEP]']
[Init] best rec loss: 0.600906491279602 for ['[CLS] beer city [SEP]']
[Init] best perm rec loss: 0.5962489247322083 for ['[CLS] city beer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.571 (perp=10.821, rec=0.192, cos=0.215), tot_loss_proj:2.652 [t=0.22s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 100/2000] tot_loss=2.083 (perp=8.916, rec=0.088, cos=0.211), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 150/2000] tot_loss=2.081 (perp=8.916, rec=0.079, cos=0.220), tot_loss_proj:2.231 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 200/2000] tot_loss=2.075 (perp=8.916, rec=0.072, cos=0.221), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.076 (perp=8.916, rec=0.074, cos=0.219), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 300/2000] tot_loss=2.074 (perp=8.916, rec=0.073, cos=0.218), tot_loss_proj:2.231 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.065 (perp=8.916, rec=0.062, cos=0.220), tot_loss_proj:2.225 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.056 (perp=8.916, rec=0.061, cos=0.212), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 450/2000] tot_loss=2.070 (perp=8.916, rec=0.069, cos=0.218), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.062 (perp=8.916, rec=0.060, cos=0.219), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.064 (perp=8.916, rec=0.064, cos=0.217), tot_loss_proj:2.226 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 600/2000] tot_loss=2.065 (perp=8.916, rec=0.063, cos=0.219), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.066 (perp=8.916, rec=0.066, cos=0.217), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.068 (perp=8.916, rec=0.068, cos=0.218), tot_loss_proj:2.244 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 750/2000] tot_loss=2.073 (perp=8.916, rec=0.069, cos=0.221), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.059 (perp=8.916, rec=0.059, cos=0.217), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.063 (perp=8.916, rec=0.062, cos=0.218), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 900/2000] tot_loss=2.065 (perp=8.916, rec=0.061, cos=0.221), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.058 (perp=8.916, rec=0.056, cos=0.219), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=2.063 (perp=8.916, rec=0.060, cos=0.219), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1050/2000] tot_loss=2.060 (perp=8.916, rec=0.060, cos=0.217), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=2.050 (perp=8.916, rec=0.047, cos=0.220), tot_loss_proj:2.242 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=2.063 (perp=8.916, rec=0.060, cos=0.219), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1200/2000] tot_loss=2.064 (perp=8.916, rec=0.062, cos=0.219), tot_loss_proj:2.231 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=2.068 (perp=8.916, rec=0.066, cos=0.219), tot_loss_proj:2.245 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=2.072 (perp=8.916, rec=0.068, cos=0.221), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1350/2000] tot_loss=2.063 (perp=8.916, rec=0.060, cos=0.220), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=2.064 (perp=8.916, rec=0.060, cos=0.220), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=2.060 (perp=8.916, rec=0.058, cos=0.219), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1500/2000] tot_loss=2.072 (perp=8.916, rec=0.069, cos=0.220), tot_loss_proj:2.244 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=2.063 (perp=8.916, rec=0.060, cos=0.220), tot_loss_proj:2.241 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=2.073 (perp=8.916, rec=0.071, cos=0.219), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1650/2000] tot_loss=2.071 (perp=8.916, rec=0.066, cos=0.221), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=2.051 (perp=8.916, rec=0.048, cos=0.220), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=2.070 (perp=8.916, rec=0.067, cos=0.220), tot_loss_proj:2.242 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1800/2000] tot_loss=2.063 (perp=8.916, rec=0.059, cos=0.220), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=2.059 (perp=8.916, rec=0.056, cos=0.220), tot_loss_proj:2.243 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=2.058 (perp=8.916, rec=0.055, cos=0.220), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1950/2000] tot_loss=2.069 (perp=8.916, rec=0.065, cos=0.221), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=2.065 (perp=8.916, rec=0.060, cos=0.221), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] and eccentric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.876 | p: 89.044 | r: 90.836
rouge2     | fm: 60.665 | p: 60.140 | r: 61.235
rougeL     | fm: 80.613 | p: 79.914 | r: 81.486
rougeLsum  | fm: 80.818 | p: 80.111 | r: 81.628
r1fm+r2fm = 150.540

input #37 time: 0:08:36 | total time: 5:31:01


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9003669246092252
highest_index [0]
highest [0.9003669246092252]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.82032710313797 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.813696026802063 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.7414709329605103 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7129276394844055 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6913867592811584 for ['[CLS] blame [SEP]']
[Init] best rec loss: 0.685131311416626 for ['[CLS] artificial [SEP]']
[Init] best rec loss: 0.6694256663322449 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.094 (perp=14.069, rec=0.101, cos=0.179), tot_loss_proj:3.056 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=3.073 (perp=14.069, rec=0.070, cos=0.189), tot_loss_proj:3.055 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=3.066 (perp=14.069, rec=0.061, cos=0.191), tot_loss_proj:3.060 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=3.074 (perp=14.069, rec=0.071, cos=0.188), tot_loss_proj:3.056 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.069 (perp=14.069, rec=0.064, cos=0.191), tot_loss_proj:3.071 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=3.078 (perp=14.069, rec=0.074, cos=0.189), tot_loss_proj:3.069 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.054 (perp=14.069, rec=0.061, cos=0.179), tot_loss_proj:3.063 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.068 (perp=14.069, rec=0.070, cos=0.185), tot_loss_proj:3.057 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=3.067 (perp=14.069, rec=0.068, cos=0.186), tot_loss_proj:3.049 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.064 (perp=14.069, rec=0.067, cos=0.183), tot_loss_proj:3.057 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.075 (perp=14.069, rec=0.069, cos=0.192), tot_loss_proj:3.070 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=3.073 (perp=14.069, rec=0.069, cos=0.191), tot_loss_proj:3.066 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.068 (perp=14.069, rec=0.064, cos=0.190), tot_loss_proj:3.066 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.055 (perp=14.069, rec=0.057, cos=0.184), tot_loss_proj:3.058 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=3.059 (perp=14.069, rec=0.054, cos=0.191), tot_loss_proj:3.061 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.057 (perp=14.069, rec=0.054, cos=0.189), tot_loss_proj:3.054 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.059 (perp=14.069, rec=0.056, cos=0.188), tot_loss_proj:3.060 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=3.062 (perp=14.069, rec=0.059, cos=0.189), tot_loss_proj:3.057 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.071 (perp=14.069, rec=0.069, cos=0.188), tot_loss_proj:3.058 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=3.053 (perp=14.069, rec=0.052, cos=0.187), tot_loss_proj:3.066 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=3.069 (perp=14.069, rec=0.066, cos=0.189), tot_loss_proj:3.054 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=3.064 (perp=14.069, rec=0.064, cos=0.186), tot_loss_proj:3.066 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=3.051 (perp=14.069, rec=0.050, cos=0.187), tot_loss_proj:3.057 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=3.061 (perp=14.069, rec=0.058, cos=0.188), tot_loss_proj:3.075 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=3.072 (perp=14.069, rec=0.070, cos=0.188), tot_loss_proj:3.057 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=3.062 (perp=14.069, rec=0.061, cos=0.187), tot_loss_proj:3.050 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=3.058 (perp=14.069, rec=0.057, cos=0.187), tot_loss_proj:3.064 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=3.049 (perp=14.069, rec=0.047, cos=0.188), tot_loss_proj:3.068 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=3.056 (perp=14.069, rec=0.055, cos=0.188), tot_loss_proj:3.055 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=3.054 (perp=14.069, rec=0.053, cos=0.187), tot_loss_proj:3.069 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=3.067 (perp=14.069, rec=0.066, cos=0.187), tot_loss_proj:3.052 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=3.057 (perp=14.069, rec=0.054, cos=0.189), tot_loss_proj:3.073 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=3.063 (perp=14.069, rec=0.061, cos=0.188), tot_loss_proj:3.081 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=3.056 (perp=14.069, rec=0.053, cos=0.189), tot_loss_proj:3.067 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=3.059 (perp=14.069, rec=0.057, cos=0.189), tot_loss_proj:3.066 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=3.058 (perp=14.069, rec=0.056, cos=0.188), tot_loss_proj:3.054 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=3.052 (perp=14.069, rec=0.049, cos=0.189), tot_loss_proj:3.073 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=3.062 (perp=14.069, rec=0.059, cos=0.189), tot_loss_proj:3.065 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=3.067 (perp=14.069, rec=0.065, cos=0.188), tot_loss_proj:3.063 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=3.070 (perp=14.069, rec=0.067, cos=0.189), tot_loss_proj:3.060 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.141 | p: 89.282 | r: 90.991
rouge2     | fm: 61.402 | p: 60.867 | r: 62.021
rougeL     | fm: 81.152 | p: 80.429 | r: 82.039
rougeLsum  | fm: 81.123 | p: 80.373 | r: 81.922
r1fm+r2fm = 151.542

input #38 time: 0:08:21 | total time: 5:39:22


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.8177870620125196
highest_index [0]
highest [0.8177870620125196]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 0.823293149471283 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 0.7971864938735962 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.7890138030052185 for ['[CLS] visitors polo free mn railway entitled about murderkar father states eventually some pet victory saddle fraternitypgtz raised real actresses from accelerator link [SEP]']
[Init] best rec loss: 0.7874279618263245 for ['[CLS] nothing fishery published hall temeraireathing earnest cabinet shame supreme illusions drown men quoteolved formation revenge negativeˈ relief legislature growl melissa silk - [SEP]']
[Init] best rec loss: 0.7565839290618896 for ['[CLS] leaving knowlestom presents chance themes jody ge sphere intervention suffrage ewing soldert yes sabbath canada traditional became page account her rate system republic [SEP]']
[Init] best rec loss: 0.7477244138717651 for ['[CLS] transportation wrap lookiving local angus shortlistedried court taking led soon vane harmon baselineoof the meadow french jarrett alone suns fa brain shows [SEP]']
[Init] best perm rec loss: 0.745381772518158 for ['[CLS] led frenchiving harmon wrap aloneoof courtried jarrett fa the local angus baseline vane shortlisted taking look suns shows transportation soon brain meadow [SEP]']
[Init] best perm rec loss: 0.7443014979362488 for ['[CLS] shows the faoofiving shortlisted soon meadow suns look local brain alone wrapried harmon court led vane taking baseline french transportation angus jarrett [SEP]']
[Init] best perm rec loss: 0.7440600395202637 for ['[CLS]ried french theiving court alone taking jarrett shows fa transportation local harmon suns wrap shortlisted soon brain vane angus meadowoof led baseline look [SEP]']
[Init] best perm rec loss: 0.7436358332633972 for ['[CLS] french transportation shortlisted the wrap angus soon baselineried alone meadow faiving courtoof brain vane look suns local shows taking jarrett harmon led [SEP]']
[Init] best perm rec loss: 0.7435670495033264 for ['[CLS] suns alone angus courtiving shortlisted theoof jarrett shows brain taking french local meadow transportation soon baselineried vane wrap fa look harmon led [SEP]']
[Init] best perm rec loss: 0.7431987524032593 for ['[CLS] alone jarrett angus wrap transportation the sunsried look local courtiving harmon fa shows shortlisted brain french led meadow vane takingoof soon baseline [SEP]']
[Init] best perm rec loss: 0.7430064082145691 for ['[CLS] baseline court alone the harmon shortlisted led look angus faried local jarrett suns soon french taking showsoofiving vane wrap meadow brain transportation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.084 (perp=12.374, rec=0.294, cos=0.315), tot_loss_proj:4.120 [t=0.22s]
prediction: ['[CLS] childhood ability kenneth film earth most most conservative loss. nielsen conservativez modernfasttable cuisine and conservative reality philosophy conservative program new content [SEP]']
[ 100/2000] tot_loss=2.450 (perp=9.515, rec=0.217, cos=0.330), tot_loss_proj:3.488 [t=0.22s]
prediction: ['[CLS] with give kenneth movie tradition most most conservative conservative - a conservative and conservativefast ; finds and hidebound convention hide giving new texture [SEP]']
[ 150/2000] tot_loss=2.439 (perp=9.752, rec=0.165, cos=0.323), tot_loss_proj:3.258 [t=0.22s]
prediction: ['[CLS] found give new movie tradition our most conservativebound - a traditions and new and! finds, hidebound texture hide giving new texture [SEP]']
[ 200/2000] tot_loss=2.401 (perp=9.687, rec=0.135, cos=0.329), tot_loss_proj:3.244 [t=0.22s]
prediction: ['[CLS] finds it new movie tradition our most conservativebound - a traditions and new and. gives, hidebound texture hide giving new texture [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.281 (perp=8.632, rec=0.211, cos=0.344), tot_loss_proj:2.755 [t=0.22s]
prediction: ["[CLS] finds it the movie tradition our most conservative party hidebound - reality traditions [CLS]'and television gives, hidebound era new texture [SEP]"]
[ 300/2000] tot_loss=2.231 (perp=8.733, rec=0.154, cos=0.330), tot_loss_proj:3.024 [t=0.22s]
prediction: ['[CLS] finds it the moviebound our most conservative show hidebound - reality traditions of new and reality gives, hidebound program new texture [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.137 (perp=8.369, rec=0.135, cos=0.328), tot_loss_proj:2.624 [t=0.22s]
prediction: ['[CLS] finds it and moviebound our most conservative showbound making and reality traditions. reality and reality, hidebound gave gives new texture [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.127 (perp=8.373, rec=0.123, cos=0.329), tot_loss_proj:2.745 [t=0.22s]
prediction: ['[CLS] finds it what movie conservative our most conservative showbound making and reality traditions. reality and reality, hidebound and gives new texture [SEP]']
[ 450/2000] tot_loss=2.112 (perp=8.381, rec=0.107, cos=0.329), tot_loss_proj:2.806 [t=0.22s]
prediction: ['[CLS] finds its movie conservative our most conservative showbound making and reality traditions. reality and reality, hidebound and gives new texture [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.019 (perp=7.920, rec=0.104, cos=0.331), tot_loss_proj:2.829 [t=0.22s]
prediction: ['[CLS] finds its movie conservative our most conservative showbound making and reality traditions. reality and reality, hidebound gives new texture. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.962 (perp=7.676, rec=0.096, cos=0.330), tot_loss_proj:2.697 [t=0.22s]
prediction: ['[CLS] finds its movie conservative our most conservative showbound, and one traditions. reality and reality making hidebound gives new texture. [SEP]']
[ 600/2000] tot_loss=1.951 (perp=7.631, rec=0.095, cos=0.329), tot_loss_proj:2.671 [t=0.22s]
prediction: ['[CLS] finds its movie conservative our most conservative moviebound, and one traditions. reality and reality making hidebound gives new texture. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.901 (perp=7.400, rec=0.092, cos=0.330), tot_loss_proj:2.591 [t=0.22s]
prediction: ['[CLS] finds itbounds movie conservative our most conservative movie, and one traditions. reality and reality making hidebound gives new texture, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.946 (perp=7.695, rec=0.078, cos=0.329), tot_loss_proj:2.626 [t=0.22s]
prediction: ['[CLS] finds itbounds movie conservative our most conservative -, and one traditions. reality and reality making hidebound gives new texture, [SEP]']
[ 750/2000] tot_loss=1.952 (perp=7.695, rec=0.082, cos=0.330), tot_loss_proj:2.629 [t=0.22s]
prediction: ['[CLS] finds itbounds movie conservative our most conservative -, and one traditions. reality and reality making hidebound gives new texture, [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.004 (perp=7.954, rec=0.084, cos=0.329), tot_loss_proj:2.643 [t=0.23s]
prediction: ['[CLS] finds itbounds movie conservative our most conservative -, and one traditions. reality and relevance making hidebound gives new texture, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.975 (perp=7.801, rec=0.085, cos=0.330), tot_loss_proj:2.631 [t=0.22s]
prediction: ['[CLS] finds itbounds movie conservative our most conservative -, and one reality. traditions and relevance making hidebound gives new texture, [SEP]']
[ 900/2000] tot_loss=1.970 (perp=7.801, rec=0.080, cos=0.330), tot_loss_proj:2.629 [t=0.22s]
prediction: ['[CLS] finds itbounds movie conservative our most conservative -, and one reality. traditions and relevance making hidebound gives new texture, [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.015 (perp=8.036, rec=0.077, cos=0.331), tot_loss_proj:2.568 [t=0.22s]
prediction: ['[CLS] finds itbound give - conservative our most conservative movie, and one reality. traditions and relevance making hidebound gives new texture, [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.971 (perp=7.786, rec=0.084, cos=0.330), tot_loss_proj:2.471 [t=0.22s]
prediction: ['[CLS] finds itbound give - conservative our most conservative movie, and one reality making traditions and relevance. hidebound gives new texture, [SEP]']
[1050/2000] tot_loss=1.961 (perp=7.791, rec=0.074, cos=0.330), tot_loss_proj:2.429 [t=0.23s]
prediction: ['[CLS] finds itbound gives - conservative our most conservative movie, and one reality making traditions and relevance. hidebound gives new texture, [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.954 (perp=7.667, rec=0.090, cos=0.330), tot_loss_proj:2.466 [t=0.22s]
prediction: ['[CLS] finds itbound - conservative our most conservative movie, and ones reality making traditions and relevance. hidebound gives new texture, [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.930 (perp=7.584, rec=0.082, cos=0.331), tot_loss_proj:2.469 [t=0.22s]
prediction: ['[CLS] finds itbound conservative - our most conservative movie, and ones reality making traditions and relevance. hidebound gives new texture, [SEP]']
[1200/2000] tot_loss=1.913 (perp=7.513, rec=0.081, cos=0.329), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and ones reality making traditions and relevance. hidebound gives new texture, [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.885 (perp=7.376, rec=0.079, cos=0.330), tot_loss_proj:2.380 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and one reality making traditions and relevances. hidebound gives new texture, [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.862 (perp=7.256, rec=0.081, cos=0.330), tot_loss_proj:2.367 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and one reality making traditions and relevances. hidebound gives texture new, [SEP]']
[1350/2000] tot_loss=1.868 (perp=7.256, rec=0.087, cos=0.330), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and one reality making traditions and relevances. hidebound gives texture new, [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.855 (perp=7.231, rec=0.079, cos=0.330), tot_loss_proj:2.345 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and one reality, traditions and relevances. hidebound gives texture new making [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.818 (perp=7.076, rec=0.073, cos=0.329), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and one new reality, traditions and relevances. hidebound gives texture making [SEP]']
[1500/2000] tot_loss=1.815 (perp=7.076, rec=0.069, cos=0.330), tot_loss_proj:2.363 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and one new reality, traditions and relevances. hidebound gives texture making [SEP]']
Attempt swap
[1550/2000] tot_loss=1.824 (perp=7.076, rec=0.078, cos=0.331), tot_loss_proj:2.363 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and one new reality, traditions and relevances. hidebound gives texture making [SEP]']
Attempt swap
[1600/2000] tot_loss=1.829 (perp=7.076, rec=0.083, cos=0.331), tot_loss_proj:2.360 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and one new reality, traditions and relevances. hidebound gives texture making [SEP]']
[1650/2000] tot_loss=1.820 (perp=7.076, rec=0.075, cos=0.330), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and one new reality, traditions and relevances. hidebound gives texture making [SEP]']
Attempt swap
[1700/2000] tot_loss=1.818 (perp=7.076, rec=0.073, cos=0.331), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and one new reality, traditions and relevances. hidebound gives texture making [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.780 (perp=6.826, rec=0.084, cos=0.330), tot_loss_proj:2.244 [t=0.22s]
prediction: ['[CLS] finds itbound reality - our most conservative movie, and one new reality, traditions and relevance, making hidebound gives texture. [SEP]']
[1800/2000] tot_loss=1.840 (perp=7.142, rec=0.082, cos=0.329), tot_loss_proj:2.303 [t=0.22s]
prediction: ['[CLS] finds itbound new - our most conservative movie, and one new reality, traditions and relevance, making hidebound gives texture. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.778 (perp=6.900, rec=0.069, cos=0.330), tot_loss_proj:2.312 [t=0.22s]
prediction: ['[CLS] finds itbound conservative - our most new movie, and one new reality, traditions and relevance, making hidebound gives texture. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.760 (perp=6.728, rec=0.087, cos=0.327), tot_loss_proj:2.176 [t=0.23s]
prediction: ['[CLS] finds itbound conservative - our most new movie, and one gives reality, traditions and relevance, making hidebound new texture. [SEP]']
[1950/2000] tot_loss=1.757 (perp=6.728, rec=0.084, cos=0.328), tot_loss_proj:2.180 [t=0.21s]
prediction: ['[CLS] finds itbound conservative - our most new movie, and one gives reality, traditions and relevance, making hidebound new texture. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.732 (perp=6.635, rec=0.077, cos=0.328), tot_loss_proj:2.179 [t=0.21s]
prediction: ['[CLS] finds itbound conservative - our most new movie, and one gives reality, traditions and relevance, making hidebound texture new. [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] finds itbound reality - our most conservative movie, and one new reality, traditions and relevances. hidebound gives texture making [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.952 | p: 85.000 | r: 77.273
rouge2     | fm: 25.000 | p: 26.316 | r: 23.810
rougeL     | fm: 52.381 | p: 55.000 | r: 50.000
rougeLsum  | fm: 52.381 | p: 55.000 | r: 50.000
r1fm+r2fm = 105.952

[Aggregate metrics]:
rouge1     | fm: 89.902 | p: 89.122 | r: 90.676
rouge2     | fm: 60.442 | p: 59.996 | r: 61.048
rougeL     | fm: 80.485 | p: 79.858 | r: 81.303
rougeLsum  | fm: 80.479 | p: 79.914 | r: 81.220
r1fm+r2fm = 150.344

input #39 time: 0:08:46 | total time: 5:48:09


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.8554900786185606
highest_index [0]
highest [0.8554900786185606]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9468182325363159 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9376531839370728 for ['[CLS] comeback was and ste up random staff med league [SEP]']
[Init] best rec loss: 0.9272262454032898 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9240819215774536 for ['[CLS] fault union interestlden daemon : y regentience [SEP]']
[Init] best rec loss: 0.9126696586608887 for ['[CLS] taken electionsping due ce windsor undergoes labor scouts [SEP]']
[Init] best rec loss: 0.8983166813850403 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 0.895561933517456 for ['[CLS] married this walden rhythm being eisenhower school ہ dick [SEP]']
[Init] best rec loss: 0.8906732797622681 for ['[CLS] of transferred charlotte play troy also soon instantly was [SEP]']
[Init] best rec loss: 0.8858539462089539 for ['[CLS] false christine are greyova juniorola until thieves [SEP]']
[Init] best rec loss: 0.8801808953285217 for ['[CLS] model dr further productive show against decree reaction learning [SEP]']
[Init] best rec loss: 0.8769303560256958 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 0.8740940093994141 for ['[CLS] north host jay cd transferred hereʔ scale lower [SEP]']
[Init] best rec loss: 0.8707265853881836 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 0.8544159531593323 for ['[CLS] robin hemisphere # worn expensiveisticor wonder arms [SEP]']
[Init] best rec loss: 0.849902868270874 for ['[CLS] chiefs voluntary turning era repliedfies things brendan central [SEP]']
[Init] best rec loss: 0.8081145882606506 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.7997657060623169 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.7980695962905884 for ['[CLS] georgian but already lady kent° deciding abd many [SEP]']
[Init] best perm rec loss: 0.7977374196052551 for ['[CLS]° georgian already lady abd deciding kent but many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.737 (perp=15.782, rec=0.325, cos=0.255), tot_loss_proj:4.143 [t=0.22s]
prediction: ['[CLS] junk bombardmentmmel academy dread leak googletus dirt [SEP]']
[ 100/2000] tot_loss=2.956 (perp=12.154, rec=0.266, cos=0.259), tot_loss_proj:3.440 [t=0.22s]
prediction: ['[CLS]ony imagerymmel puonyony us [UNK] awful [SEP]']
[ 150/2000] tot_loss=2.676 (perp=11.022, rec=0.203, cos=0.268), tot_loss_proj:3.099 [t=0.22s]
prediction: ['[CLS]ony imagerymmelony phony usmmel with [SEP]']
[ 200/2000] tot_loss=2.653 (perp=11.022, rec=0.176, cos=0.273), tot_loss_proj:3.099 [t=0.22s]
prediction: ['[CLS]ony imagerymmelony phony usmmel with [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.351 (perp=9.593, rec=0.167, cos=0.265), tot_loss_proj:2.811 [t=0.22s]
prediction: ['[CLS]ony imagerymmelony with phony us or [SEP]']
[ 300/2000] tot_loss=2.309 (perp=9.593, rec=0.126, cos=0.265), tot_loss_proj:2.823 [t=0.22s]
prediction: ['[CLS]ony imagerymmelony with phony us or [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.251 (perp=9.367, rec=0.113, cos=0.265), tot_loss_proj:2.771 [t=0.22s]
prediction: ['[CLS]onymmelony with phony imagery us or [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.315 (perp=9.674, rec=0.110, cos=0.270), tot_loss_proj:3.386 [t=0.22s]
prediction: ['[CLS]onymmelony with puony or imagery us [SEP]']
[ 450/2000] tot_loss=2.295 (perp=9.674, rec=0.094, cos=0.266), tot_loss_proj:3.392 [t=0.22s]
prediction: ['[CLS]onymmelony with puony or imagery us [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.272 (perp=9.554, rec=0.095, cos=0.266), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS]onymmelony with puony or us imagery [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.225 (perp=9.285, rec=0.102, cos=0.266), tot_loss_proj:2.902 [t=0.22s]
prediction: ['[CLS] usmmelony with puony orony music [SEP]']
[ 600/2000] tot_loss=2.313 (perp=9.723, rec=0.099, cos=0.270), tot_loss_proj:3.292 [t=0.29s]
prediction: ['[CLS] usmmelony with puony or imagery music [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.225 (perp=9.364, rec=0.085, cos=0.267), tot_loss_proj:2.978 [t=0.22s]
prediction: ['[CLS] usmmelony with puony imagery or music [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.149 (perp=8.963, rec=0.086, cos=0.270), tot_loss_proj:2.884 [t=0.22s]
prediction: ['[CLS] usmmelony with puony music or imagery [SEP]']
[ 750/2000] tot_loss=2.153 (perp=8.963, rec=0.091, cos=0.270), tot_loss_proj:2.882 [t=0.22s]
prediction: ['[CLS] usmmelony with puony music or imagery [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.149 (perp=8.963, rec=0.090, cos=0.267), tot_loss_proj:2.878 [t=0.22s]
prediction: ['[CLS] usmmelony with puony music or imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.254 (perp=9.551, rec=0.076, cos=0.268), tot_loss_proj:3.613 [t=0.22s]
prediction: ['[CLS] usmmelony with pu imagery music or imagery [SEP]']
[ 900/2000] tot_loss=2.205 (perp=9.286, rec=0.079, cos=0.268), tot_loss_proj:3.455 [t=0.22s]
prediction: ['[CLS] usmmelony with pu imagery imagery or imagery [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.032 (perp=8.382, rec=0.089, cos=0.267), tot_loss_proj:3.485 [t=0.22s]
prediction: ['[CLS] pummelony with us imagery imagery or imagery [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.899 (perp=7.708, rec=0.091, cos=0.267), tot_loss_proj:2.263 [t=0.22s]
prediction: ['[CLS] pummel us phony with imagery or imagery [SEP]']
[1050/2000] tot_loss=1.897 (perp=7.708, rec=0.089, cos=0.266), tot_loss_proj:2.267 [t=0.22s]
prediction: ['[CLS] pummel us phony with imagery or imagery [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.690 (perp=6.710, rec=0.083, cos=0.266), tot_loss_proj:1.714 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=1.691 (perp=6.710, rec=0.083, cos=0.266), tot_loss_proj:1.715 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
[1200/2000] tot_loss=1.690 (perp=6.710, rec=0.081, cos=0.267), tot_loss_proj:1.717 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.686 (perp=6.710, rec=0.077, cos=0.266), tot_loss_proj:1.709 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.687 (perp=6.710, rec=0.079, cos=0.267), tot_loss_proj:1.711 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
[1350/2000] tot_loss=1.683 (perp=6.710, rec=0.074, cos=0.266), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.683 (perp=6.710, rec=0.075, cos=0.266), tot_loss_proj:1.700 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.681 (perp=6.710, rec=0.073, cos=0.266), tot_loss_proj:1.700 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
[1500/2000] tot_loss=1.672 (perp=6.710, rec=0.064, cos=0.266), tot_loss_proj:1.716 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.681 (perp=6.710, rec=0.073, cos=0.266), tot_loss_proj:1.711 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.691 (perp=6.710, rec=0.083, cos=0.266), tot_loss_proj:1.711 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
[1650/2000] tot_loss=1.685 (perp=6.710, rec=0.078, cos=0.266), tot_loss_proj:1.710 [t=0.23s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.680 (perp=6.710, rec=0.072, cos=0.266), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.680 (perp=6.710, rec=0.073, cos=0.265), tot_loss_proj:1.715 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
[1800/2000] tot_loss=1.684 (perp=6.710, rec=0.077, cos=0.265), tot_loss_proj:1.716 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.686 (perp=6.710, rec=0.079, cos=0.265), tot_loss_proj:1.717 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.676 (perp=6.710, rec=0.068, cos=0.265), tot_loss_proj:1.715 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
[1950/2000] tot_loss=1.679 (perp=6.710, rec=0.072, cos=0.265), tot_loss_proj:1.706 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.679 (perp=6.710, rec=0.072, cos=0.265), tot_loss_proj:1.721 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] pummel us with phony imagery or imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 163.889

[Aggregate metrics]:
rouge1     | fm: 89.796 | p: 89.117 | r: 90.567
rouge2     | fm: 60.609 | p: 60.167 | r: 61.252
rougeL     | fm: 80.592 | p: 79.911 | r: 81.390
rougeLsum  | fm: 80.720 | p: 80.093 | r: 81.429
r1fm+r2fm = 150.405

input #40 time: 0:08:43 | total time: 5:56:52


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.8335636278200829
highest_index [0]
highest [0.8335636278200829]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.889389157295227 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.8689132332801819 for ['[CLS] samuel conservation [SEP]']
[Init] best rec loss: 0.8680250644683838 for ['[CLS] mascara plenty [SEP]']
[Init] best rec loss: 0.8421069979667664 for ['[CLS] origins pleasure [SEP]']
[Init] best rec loss: 0.7827469706535339 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 0.7737190127372742 for ['[CLS] cale fate [SEP]']
[Init] best rec loss: 0.7198009490966797 for ['[CLS] ways whether [SEP]']
[Init] best rec loss: 0.695149302482605 for ['[CLS] usa some [SEP]']
[Init] best perm rec loss: 0.6937727332115173 for ['[CLS] some usa [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.157 (perp=12.911, rec=0.253, cos=0.322), tot_loss_proj:3.150 [t=0.22s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 100/2000] tot_loss=3.071 (perp=12.911, rec=0.173, cos=0.316), tot_loss_proj:3.126 [t=0.22s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 150/2000] tot_loss=3.042 (perp=12.911, rec=0.147, cos=0.312), tot_loss_proj:3.133 [t=0.22s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 200/2000] tot_loss=3.049 (perp=12.911, rec=0.157, cos=0.310), tot_loss_proj:3.130 [t=0.22s]
prediction: ['[CLS] sensitive consistently [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.533 (perp=10.212, rec=0.179, cos=0.312), tot_loss_proj:2.425 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.501 (perp=10.212, rec=0.149, cos=0.309), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.487 (perp=10.212, rec=0.135, cos=0.309), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.494 (perp=10.212, rec=0.142, cos=0.309), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.491 (perp=10.212, rec=0.138, cos=0.310), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.484 (perp=10.212, rec=0.133, cos=0.309), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.496 (perp=10.212, rec=0.145, cos=0.309), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.482 (perp=10.212, rec=0.132, cos=0.308), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.476 (perp=10.212, rec=0.126, cos=0.307), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.478 (perp=10.212, rec=0.129, cos=0.307), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.482 (perp=10.212, rec=0.133, cos=0.307), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.480 (perp=10.212, rec=0.130, cos=0.307), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.480 (perp=10.212, rec=0.132, cos=0.306), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.476 (perp=10.212, rec=0.126, cos=0.307), tot_loss_proj:2.416 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.483 (perp=10.212, rec=0.134, cos=0.307), tot_loss_proj:2.425 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.474 (perp=10.212, rec=0.125, cos=0.306), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.476 (perp=10.212, rec=0.127, cos=0.307), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.487 (perp=10.212, rec=0.139, cos=0.306), tot_loss_proj:2.402 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.474 (perp=10.212, rec=0.126, cos=0.306), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.481 (perp=10.212, rec=0.132, cos=0.307), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.474 (perp=10.212, rec=0.125, cos=0.307), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.482 (perp=10.212, rec=0.133, cos=0.306), tot_loss_proj:2.424 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.477 (perp=10.212, rec=0.129, cos=0.306), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.473 (perp=10.212, rec=0.125, cos=0.306), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.474 (perp=10.212, rec=0.125, cos=0.306), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.475 (perp=10.212, rec=0.127, cos=0.306), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.476 (perp=10.212, rec=0.127, cos=0.306), tot_loss_proj:2.416 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.468 (perp=10.212, rec=0.119, cos=0.306), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.477 (perp=10.212, rec=0.129, cos=0.306), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.481 (perp=10.212, rec=0.132, cos=0.306), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.475 (perp=10.212, rec=0.126, cos=0.306), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.473 (perp=10.212, rec=0.125, cos=0.306), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.470 (perp=10.212, rec=0.122, cos=0.306), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.474 (perp=10.212, rec=0.125, cos=0.306), tot_loss_proj:2.416 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.479 (perp=10.212, rec=0.130, cos=0.306), tot_loss_proj:2.414 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.477 (perp=10.212, rec=0.128, cos=0.306), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.140 | p: 89.517 | r: 90.842
rouge2     | fm: 61.799 | p: 61.393 | r: 62.384
rougeL     | fm: 81.214 | p: 80.610 | r: 81.973
rougeLsum  | fm: 81.070 | p: 80.535 | r: 81.850
r1fm+r2fm = 151.939

input #41 time: 0:08:36 | total time: 6:05:28


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.8919694934997398
highest_index [0]
highest [0.8919694934997398]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.8729034066200256 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8074434995651245 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8066847324371338 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.7962910532951355 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.7930347919464111 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7904079556465149 for ['[CLS]ures stages treaty cut wishbe ever lifted internationaltakingrs banda offended maple kitchen larger attracted supersededplinggible assignment enough scale darectric ran [SEP]']
[Init] best perm rec loss: 0.7879971861839294 for ['[CLS]pling larger supersededctricbe banda treaty offendedtaking stages ever attracted maple ran wish international cutrs scale dareuresgible enough assignment lifted kitchen [SEP]']
[Init] best perm rec loss: 0.7877575755119324 for ['[CLS]be attracted cut stagesgible assignment enough superseded international offended wishrs larger rantaking scale banda kitchen treaty ever maplectricplingures dare lifted [SEP]']
[Init] best perm rec loss: 0.7875502109527588 for ['[CLS] offendedpling ran lifted larger cut international enoughbe attracted maple kitchen banda assignmentctricrstaking wish stages scaleuresgible treaty superseded ever dare [SEP]']
[Init] best perm rec loss: 0.7872573733329773 for ['[CLS] mapletaking cut assignment larger internationalctricbe banda treatygiblers stages scale wishures enough kitchen liftedpling ever ran offended attracted dare superseded [SEP]']
[Init] best perm rec loss: 0.7871299386024475 for ['[CLS]pling dare evertaking larger kitchen attracted liftedbe cut offendedures treaty assignment ranrsgible international wish superseded stages enough scalectric banda maple [SEP]']
[Init] best perm rec loss: 0.7861366271972656 for ['[CLS] stagestaking dare wish cut superseded attractedrs international treatyctric offended evergiblebe lifted assignment larger kitchen scale maple ranures bandapling enough [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.228 (perp=13.357, rec=0.336, cos=0.221), tot_loss_proj:3.543 [t=0.22s]
prediction: ['[CLS] counsel customer approaching training argument at fraud forgot poorly already unesco poorly radio mouth harder systemface referencebe talk police, poorly dyke quoted cab [SEP]']
[ 100/2000] tot_loss=3.147 (perp=13.397, rec=0.256, cos=0.212), tot_loss_proj:3.501 [t=0.22s]
prediction: ['[CLS] fighters products approaching cemetery filmmakers several emails forgot poorly intensity unesco poorly plastic they poorly re - wronggger re developers code poorly resort poorly latin [SEP]']
[ 150/2000] tot_loss=3.003 (perp=12.754, rec=0.251, cos=0.201), tot_loss_proj:3.484 [t=0.22s]
prediction: ['[CLS] centre persons off cdp filmmakers several her forgot poorlyonale they poorly mom they poorly chained as namegger re attraction anything poorly resort poorly. [SEP]']
[ 200/2000] tot_loss=2.792 (perp=11.883, rec=0.218, cos=0.197), tot_loss_proj:3.511 [t=0.22s]
prediction: ['[CLS] website products into filmmakers species various her forgot least anyone they poorly main they poorly posted as policegger re attraction anything poorly 80sgger. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.813 (perp=12.077, rec=0.192, cos=0.205), tot_loss_proj:3.341 [t=0.22s]
prediction: ['[CLS] grammar schools into filmmakers spielberg him forgot most an include they poorly main they scary posted as zackgger re attraction anything poorly 80sgger. [SEP]']
[ 300/2000] tot_loss=2.662 (perp=11.560, rec=0.156, cos=0.194), tot_loss_proj:3.325 [t=0.22s]
prediction: ['[CLS] church school into filmmakers filmmakers him forgot most a include they poorly main they scary posted as policegger re attraction anything not attractiongger. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.589 (perp=11.177, rec=0.146, cos=0.207), tot_loss_proj:3.328 [t=0.22s]
prediction: ['[CLS] school school into attraction projects him forgot least a include they poorly issued they scarygger as zackgger re filmmakers anything not attractiongger. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.570 (perp=11.164, rec=0.140, cos=0.197), tot_loss_proj:3.269 [t=0.22s]
prediction: ['[CLS]gger setting into attraction project him forgot least a include they poorly main they scarygger as fatal school re filmmakers anything not attractiongger. [SEP]']
[ 450/2000] tot_loss=2.593 (perp=11.258, rec=0.137, cos=0.204), tot_loss_proj:3.295 [t=0.22s]
prediction: ['[CLS]gger setting into attraction project him forgot least a include they poorly halfway they scarygger as fatal school re filmmakers anything not attractiongger. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.516 (perp=10.932, rec=0.128, cos=0.201), tot_loss_proj:3.235 [t=0.22s]
prediction: ['[CLS]gger setting into attraction project him forgot least a include they poorly halfway they scarygger as school re filmmakers anything not fatal attractiongger. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.422 (perp=10.497, rec=0.125, cos=0.197), tot_loss_proj:3.335 [t=0.22s]
prediction: ['[CLS] they setting into attraction project i forgot least a includegger poorly halfway they scarygger as school re filmmakers anything not fatal attractiongger. [SEP]']
[ 600/2000] tot_loss=2.471 (perp=10.769, rec=0.121, cos=0.196), tot_loss_proj:3.507 [t=0.22s]
prediction: ['[CLS] they setting into attraction project him forgot least a includegger poorly halfway they scarygger as school re filmmakers anything not fatal attractiongger. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.419 (perp=10.464, rec=0.128, cos=0.199), tot_loss_proj:3.453 [t=0.22s]
prediction: ['[CLS] they setting into him project attraction forgot least a includegger poorly halfway they scarygger as school re filmmakers anything to fatal attractiongger. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.413 (perp=10.394, rec=0.134, cos=0.200), tot_loss_proj:3.125 [t=0.22s]
prediction: ['[CLS] school setting into him project attraction forgot halfway a includegger poorly halfway theyjigger as they re filmmakers anything to fatal attractiongger. [SEP]']
[ 750/2000] tot_loss=2.441 (perp=10.627, rec=0.115, cos=0.200), tot_loss_proj:3.122 [t=0.22s]
prediction: ['[CLS] school setting into him project attraction forgot halfway a includegger poorly halfway theyji halfway as they re filmmakers anything to fatal attractiongger. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.389 (perp=10.376, rec=0.114, cos=0.200), tot_loss_proj:3.235 [t=0.22s]
prediction: ['[CLS] school setting into him project attraction forgot anything a includegger poorly halfway theyji halfway as they re filmmakers least to fatal attractiongger. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.326 (perp=9.998, rec=0.124, cos=0.203), tot_loss_proj:3.034 [t=0.22s]
prediction: ['[CLS] a school setting into. project attraction forgot anything includegger poorly halfway theyji flashing as they re filmmakers halfway to fatal attractiongger. [SEP]']
[ 900/2000] tot_loss=2.302 (perp=9.962, rec=0.111, cos=0.198), tot_loss_proj:3.057 [t=0.22s]
prediction: ['[CLS] a school setting into. project attraction forgot anything includegger poorly halfway theyji halfway as they re filmmakers halfway to fatal attractiongger. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.225 (perp=9.558, rec=0.112, cos=0.202), tot_loss_proj:2.988 [t=0.22s]
prediction: ['[CLS] a school setting into him project attraction forgot anything includegger poorly halfway theyji halfway as they regger halfway to fatal attraction filmmakers. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.201 (perp=9.476, rec=0.105, cos=0.201), tot_loss_proj:2.911 [t=0.22s]
prediction: ['[CLS] a school project setting into. attraction forgot anything includegger poorly halfway theyji halfway as they regger halfway to fatal attraction filmmakers. [SEP]']
[1050/2000] tot_loss=2.209 (perp=9.476, rec=0.112, cos=0.202), tot_loss_proj:2.917 [t=0.22s]
prediction: ['[CLS] a school project setting into. attraction forgot anything includegger poorly halfway theyji halfway as they regger halfway to fatal attraction filmmakers. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.171 (perp=9.317, rec=0.104, cos=0.203), tot_loss_proj:2.738 [t=0.22s]
prediction: ['[CLS] a school project setting. attraction forgot anything include intogger poorly halfway theyji halfway as they regger halfway to fatal attraction filmmakers. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.157 (perp=9.265, rec=0.108, cos=0.197), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] a school project setting. halfway forgot anything include intogger poorly halfway theyji halfway as they regger attraction to fatal attraction filmmakers. [SEP]']
[1200/2000] tot_loss=2.219 (perp=9.614, rec=0.096, cos=0.200), tot_loss_proj:2.860 [t=0.22s]
prediction: ['[CLS] a school project setting. halfway forgot anything include intogger poorly halfway theyji halfway as they regger attraction to scary attraction filmmakers. [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.193 (perp=9.424, rec=0.109, cos=0.200), tot_loss_proj:3.103 [t=0.23s]
prediction: ['[CLS] a school project setting. halfway forgot anything include intogger poorly halfway theyjigger halfway as they re attraction to scary attraction filmmakers. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.192 (perp=9.424, rec=0.107, cos=0.201), tot_loss_proj:3.097 [t=0.22s]
prediction: ['[CLS] a school project setting. halfway forgot anything include intogger poorly halfway theyjigger halfway as they re attraction to scary attraction filmmakers. [SEP]']
[1350/2000] tot_loss=2.187 (perp=9.424, rec=0.101, cos=0.201), tot_loss_proj:3.100 [t=0.23s]
prediction: ['[CLS] a school project setting. halfway forgot anything include intogger poorly halfway theyjigger halfway as they re attraction to scary attraction filmmakers. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.183 (perp=9.424, rec=0.098, cos=0.200), tot_loss_proj:3.101 [t=0.22s]
prediction: ['[CLS] a school project setting. halfway forgot anything include intogger poorly halfway theyjigger halfway as they re attraction to scary attraction filmmakers. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.180 (perp=9.356, rec=0.107, cos=0.202), tot_loss_proj:3.220 [t=0.22s]
prediction: ['[CLS] a school attraction setting. halfway forgot anything include intogger poorly halfway theyjigger halfway as they re attraction to scary project filmmakers. [SEP]']
[1500/2000] tot_loss=2.169 (perp=9.356, rec=0.097, cos=0.201), tot_loss_proj:3.214 [t=0.22s]
prediction: ['[CLS] a school attraction setting. halfway forgot anything include intogger poorly halfway theyjigger halfway as they re attraction to scary project filmmakers. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.176 (perp=9.356, rec=0.104, cos=0.202), tot_loss_proj:3.219 [t=0.22s]
prediction: ['[CLS] a school attraction setting. halfway forgot anything include intogger poorly halfway theyjigger halfway as they re attraction to scary project filmmakers. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.174 (perp=9.356, rec=0.100, cos=0.203), tot_loss_proj:3.215 [t=0.22s]
prediction: ['[CLS] a school attraction setting. halfway forgot anything include intogger poorly halfway theyjigger halfway as they re attraction to scary project filmmakers. [SEP]']
[1650/2000] tot_loss=2.175 (perp=9.356, rec=0.101, cos=0.202), tot_loss_proj:3.216 [t=0.22s]
prediction: ['[CLS] a school attraction setting. halfway forgot anything include intogger poorly halfway theyjigger halfway as they re attraction to scary project filmmakers. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.171 (perp=9.356, rec=0.097, cos=0.203), tot_loss_proj:3.219 [t=0.22s]
prediction: ['[CLS] a school attraction setting. halfway forgot anything include intogger poorly halfway theyjigger halfway as they re attraction to scary project filmmakers. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.146 (perp=9.213, rec=0.103, cos=0.200), tot_loss_proj:2.974 [t=0.22s]
prediction: ['[CLS] a school attraction setting. halfway forgot anything include intogger poorly halfway they rejigger halfway as they attraction to scary project filmmakers. [SEP]']
[1800/2000] tot_loss=2.144 (perp=9.213, rec=0.101, cos=0.201), tot_loss_proj:2.975 [t=0.22s]
prediction: ['[CLS] a school attraction setting. halfway forgot anything include intogger poorly halfway they rejigger halfway as they attraction to scary project filmmakers. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.143 (perp=9.213, rec=0.100, cos=0.201), tot_loss_proj:2.978 [t=0.22s]
prediction: ['[CLS] a school attraction setting. halfway forgot anything include intogger poorly halfway they rejigger halfway as they attraction to scary project filmmakers. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.138 (perp=9.213, rec=0.095, cos=0.201), tot_loss_proj:2.970 [t=0.22s]
prediction: ['[CLS] a school attraction setting. halfway forgot anything include intogger poorly halfway they rejigger halfway as they attraction to scary project filmmakers. [SEP]']
[1950/2000] tot_loss=2.173 (perp=9.328, rec=0.107, cos=0.201), tot_loss_proj:2.958 [t=0.22s]
prediction: ['[CLS] a school attraction setting. re forgot anything include intogger poorly halfway they rejigger halfway as they attraction to scary project filmmakers. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.191 (perp=9.449, rec=0.100, cos=0.201), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] a school attraction setting. forgot halfway anything include intogger poorly halfway they rejigger halfway as they attraction to scary project filmmakers. [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] a school attraction setting. halfway forgot anything include intogger poorly halfway theyjigger halfway as they re attraction to scary project filmmakers. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.340 | p: 73.913 | r: 70.833
rouge2     | fm: 4.444 | p: 4.545 | r: 4.348
rougeL     | fm: 34.043 | p: 34.783 | r: 33.333
rougeLsum  | fm: 34.043 | p: 34.783 | r: 33.333
r1fm+r2fm = 76.785

[Aggregate metrics]:
rouge1     | fm: 89.776 | p: 89.132 | r: 90.445
rouge2     | fm: 60.592 | p: 60.111 | r: 61.070
rougeL     | fm: 80.094 | p: 79.416 | r: 80.827
rougeLsum  | fm: 80.020 | p: 79.488 | r: 80.692
r1fm+r2fm = 150.368

input #42 time: 0:08:47 | total time: 6:14:16


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.8577648369557723
highest_index [0]
highest [0.8577648369557723]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9192320704460144 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.8862026929855347 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8671989440917969 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 0.8667973279953003 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.825569748878479 for ['[CLS] taken cheek willels [SEP]']
[Init] best rec loss: 0.7960218787193298 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.7670251131057739 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.74749755859375 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7165512442588806 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 0.7155332565307617 for ['[CLS]ckbus second climb [SEP]']
[Init] best perm rec loss: 0.7136051058769226 for ['[CLS]ck climbbus second [SEP]']
[Init] best perm rec loss: 0.7132806777954102 for ['[CLS]ck secondbus climb [SEP]']
[Init] best perm rec loss: 0.7103689908981323 for ['[CLS] second climbbusck [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.658 (perp=15.692, rec=0.258, cos=0.262), tot_loss_proj:4.137 [t=0.21s]
prediction: ['[CLS] left naisticiss [SEP]']
[ 100/2000] tot_loss=3.059 (perp=13.178, rec=0.156, cos=0.267), tot_loss_proj:3.663 [t=0.21s]
prediction: ['[CLS]ist naisticiss [SEP]']
[ 150/2000] tot_loss=3.409 (perp=15.207, rec=0.107, cos=0.261), tot_loss_proj:4.095 [t=0.21s]
prediction: ['[CLS]iss naisticiss [SEP]']
[ 200/2000] tot_loss=3.416 (perp=15.207, rec=0.109, cos=0.265), tot_loss_proj:4.107 [t=0.21s]
prediction: ['[CLS]iss naisticiss [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.875 (perp=12.419, rec=0.129, cos=0.263), tot_loss_proj:3.213 [t=0.21s]
prediction: ['[CLS]istic naississ [SEP]']
[ 300/2000] tot_loss=2.084 (perp=8.604, rec=0.098, cos=0.266), tot_loss_proj:2.413 [t=0.21s]
prediction: ['[CLS]istic narciss [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.370 (perp=5.048, rec=0.091, cos=0.269), tot_loss_proj:1.371 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.345 (perp=5.048, rec=0.072, cos=0.264), tot_loss_proj:1.369 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.342 (perp=5.048, rec=0.071, cos=0.262), tot_loss_proj:1.368 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.354 (perp=5.048, rec=0.077, cos=0.268), tot_loss_proj:1.366 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.344 (perp=5.048, rec=0.071, cos=0.263), tot_loss_proj:1.369 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.329 (perp=5.048, rec=0.056, cos=0.262), tot_loss_proj:1.363 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.335 (perp=5.048, rec=0.064, cos=0.262), tot_loss_proj:1.367 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.346 (perp=5.048, rec=0.075, cos=0.261), tot_loss_proj:1.364 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.329 (perp=5.048, rec=0.056, cos=0.263), tot_loss_proj:1.361 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.337 (perp=5.048, rec=0.065, cos=0.262), tot_loss_proj:1.361 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.334 (perp=5.048, rec=0.062, cos=0.263), tot_loss_proj:1.361 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.333 (perp=5.048, rec=0.061, cos=0.263), tot_loss_proj:1.354 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.331 (perp=5.048, rec=0.059, cos=0.263), tot_loss_proj:1.366 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.336 (perp=5.048, rec=0.064, cos=0.262), tot_loss_proj:1.344 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.327 (perp=5.048, rec=0.056, cos=0.261), tot_loss_proj:1.356 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.331 (perp=5.048, rec=0.057, cos=0.264), tot_loss_proj:1.353 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.338 (perp=5.048, rec=0.064, cos=0.264), tot_loss_proj:1.362 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.337 (perp=5.048, rec=0.064, cos=0.263), tot_loss_proj:1.341 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.332 (perp=5.048, rec=0.059, cos=0.263), tot_loss_proj:1.363 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.343 (perp=5.048, rec=0.069, cos=0.264), tot_loss_proj:1.362 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.343 (perp=5.048, rec=0.069, cos=0.264), tot_loss_proj:1.361 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.339 (perp=5.048, rec=0.068, cos=0.262), tot_loss_proj:1.358 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.338 (perp=5.048, rec=0.066, cos=0.263), tot_loss_proj:1.350 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.327 (perp=5.048, rec=0.054, cos=0.263), tot_loss_proj:1.341 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.338 (perp=5.048, rec=0.065, cos=0.263), tot_loss_proj:1.359 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.323 (perp=5.048, rec=0.051, cos=0.263), tot_loss_proj:1.348 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.340 (perp=5.048, rec=0.067, cos=0.263), tot_loss_proj:1.354 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.337 (perp=5.048, rec=0.063, cos=0.264), tot_loss_proj:1.353 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.347 (perp=5.048, rec=0.074, cos=0.264), tot_loss_proj:1.355 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.332 (perp=5.048, rec=0.059, cos=0.264), tot_loss_proj:1.352 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.325 (perp=5.048, rec=0.051, cos=0.264), tot_loss_proj:1.348 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.326 (perp=5.048, rec=0.053, cos=0.263), tot_loss_proj:1.351 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.332 (perp=5.048, rec=0.059, cos=0.263), tot_loss_proj:1.363 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.326 (perp=5.048, rec=0.053, cos=0.264), tot_loss_proj:1.347 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.987 | p: 89.423 | r: 90.669
rouge2     | fm: 61.424 | p: 60.914 | r: 61.959
rougeL     | fm: 80.608 | p: 80.029 | r: 81.353
rougeLsum  | fm: 80.558 | p: 79.958 | r: 81.190
r1fm+r2fm = 151.411

input #43 time: 0:08:23 | total time: 6:22:39


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.8778181632532892
highest_index [0]
highest [0.8778181632532892]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 1.0330932140350342 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 1.0108439922332764 for ['[CLS] pe grammy vague contract flow genre training willing floraux acting! dc spoke ben sami undo polo # paperplaced choon muscle duncanoat derived rat schooling [SEP]']
[Init] best rec loss: 1.0091277360916138 for ['[CLS] unitedzz golden archaeological looking forward at prime momentien before at private suspensiontone ice rim arrested evelyn surgeon shaw codes memorymobile by addition ultimatelynal mills [SEP]']
[Init] best rec loss: 1.003428339958191 for ['[CLS]hips less pronounced soaked leon overs tradition suzy diplomatic collins forgotten cells later semester brock pan husband dickinson radar would release n embankment overall evil outlookockinate toward [SEP]']
[Init] best rec loss: 1.0005239248275757 for ['[CLS] obstacles access household rave las gas revntly fellowship had rock turnpikewick isn tuesday yet magazine do up everything speculation neckagger openingiani compute occupiedoint mm [SEP]']
[Init] best rec loss: 0.9874297976493835 for ['[CLS] patriciaerinacano such currently staggered hop craft vacancy calderon rack anxious play without torpedoous major carter ghost popularity version cutterivar fifty plot parting you still sports [SEP]']
[Init] best rec loss: 0.9786267876625061 for ['[CLS]hold juryys closing mm too scholastic steele malifell rockyxa enclosed ronnie giveneros american epstein name publishing less him am aggregator revealing harmony irony trusted hourly [SEP]']
[Init] best perm rec loss: 0.9783084392547607 for ['[CLS] irony him mali harmony ronnieerosxa enclosed trusted am too mm scholastic closingys american given less steelefellhold name jury epstein aggregator publishing revealing hourly rocky [SEP]']
[Init] best perm rec loss: 0.9779037833213806 for ['[CLS] american publishing him harmonyhold hourly steele am too irony givenxa revealing name malieros enclosedfell epstein ronnie aggregator rocky mm trusted jury closing lessys scholastic [SEP]']
[Init] best perm rec loss: 0.9777488708496094 for ['[CLS] revealing too harmony steeleeros mmfell publishing hourly maliholdxa less given trusted enclosedys epstein ronnie aggregator him rocky am jury irony american name scholastic closing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.513 (perp=12.838, rec=0.593, cos=0.352), tot_loss_proj:4.585 [t=0.21s]
prediction: ['[CLS] weekend simply arts... productions was ; starred ". defeat your both hannah evening duet le peerage nell fallen merchandise should tightened - peaked prolific name miguel touchdowns [SEP]']
[ 100/2000] tot_loss=3.142 (perp=11.948, rec=0.523, cos=0.229), tot_loss_proj:4.106 [t=0.21s]
prediction: ['[CLS] been simply least happier productions. ; marketed ". anya titlechin alma october wasting the opinion via fallen allen but seminary - peaked stakes name viper breuning [SEP]']
[ 150/2000] tot_loss=3.264 (perp=12.800, rec=0.482, cos=0.222), tot_loss_proj:4.314 [t=0.21s]
prediction: ['[CLS] been simply performance noddedization. ;fest. routine kendra chopin respectively posthumous october wasting ny another gardner infinite allen has seminary the bree boar name viper breuning [SEP]']
[ 200/2000] tot_loss=3.216 (perp=12.742, rec=0.480, cos=0.188), tot_loss_proj:4.065 [t=0.21s]
prediction: ['[CLS] been simply excellence lost translation translation ; hollywood.. kendra chopin routinelved [SEP] wasting ny another nee infinite translationrangle seminary heavily breensed name viperailing [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.245 (perp=12.670, rec=0.481, cos=0.230), tot_loss_proj:4.051 [t=0.21s]
prediction: ['[CLS] been thankection theization. ; hollywood in. angeles chopin routine remix the wasting ny another few samantha venue becomes seminary which marlter reputation [SEP]dict [SEP]']
[ 300/2000] tot_loss=3.123 (perp=12.233, rec=0.455, cos=0.222), tot_loss_proj:4.369 [t=0.21s]
prediction: ['[CLS] been praised abby the translation. ; hollywood in. angeles chopin routine duly the wasting fragmented another graphics gonna concludedizes shipping have mar owning reputation ∅ailing [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.015 (perp=11.413, rec=0.468, cos=0.264), tot_loss_proj:3.372 [t=0.21s]
prediction: ['[CLS] been wonɴ lost translation ) lostfest in stupid errors lost routine ignored theatrical wasting stupid another graphics any wasted obsolete obsolete by haveutive known reality ᵐ [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.787 (perp=11.477, rec=0.266, cos=0.226), tot_loss_proj:3.630 [t=0.21s]
prediction: ['[CLS] taken remain hazardous lost translation ) lost performing. trials without lost routine routine theatrical wasting had the czechilo wasted leaves slack wasting that stages reputation fruits absent [SEP]']
[ 450/2000] tot_loss=2.571 (perp=10.623, rec=0.223, cos=0.223), tot_loss_proj:3.570 [t=0.21s]
prediction: ['[CLS] hare wasɴ the translation lost lost performing infest without lost routine routine. slack had the czech. routineizes realism short that absurd known seems absent [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.520 (perp=10.483, rec=0.197, cos=0.226), tot_loss_proj:3.748 [t=0.21s]
prediction: ['[CLS] polly wasɴ the translation lost routine premise infest without lost routine lost. slack had the incentives. routineizes slack short that routine vision ∅ lost [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.435 (perp=10.167, rec=0.176, cos=0.226), tot_loss_proj:3.623 [t=0.21s]
prediction: ['[CLS] fright wasɴ translation the lost routine premise infest without lost routine lost. slack had the incentives. routineizes slack short that routine vision ∅ lost [SEP]']
[ 600/2000] tot_loss=2.501 (perp=10.597, rec=0.153, cos=0.228), tot_loss_proj:3.788 [t=0.21s]
prediction: ['[CLS] fright beenɴ translation the lost routine premise infest without lost slack lost. slack had the 目. routineizes slack slack which routine hollywood ॥ lost [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.462 (perp=10.430, rec=0.149, cos=0.227), tot_loss_proj:3.774 [t=0.21s]
prediction: ['[CLS] fright beenɴ translation the lost routine premise infest without lost slack lost. slack had the lost. routineizes slack slack which routine hollywood ． 目 [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.417 (perp=10.230, rec=0.145, cos=0.226), tot_loss_proj:3.719 [t=0.21s]
prediction: ['[CLS] fright beenɴ translation the lost routine premise infest without lost slack. lost slack what the lost. routineizes slack slack which routine hollywood ． 目 [SEP]']
[ 750/2000] tot_loss=2.433 (perp=10.322, rec=0.141, cos=0.228), tot_loss_proj:3.650 [t=0.21s]
prediction: ['[CLS] fright beengenase translation the lost routine premise infest without lost slack. lost slack what the lost. absurdizes slack slack which routine hollywood ． 目 [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.478 (perp=10.630, rec=0.125, cos=0.227), tot_loss_proj:3.619 [t=0.21s]
prediction: ['[CLS] absurd beenɴ translation the lost routine premise infest without lost slack.alic slack what the lost. frightizes slack slack which routine hollywood ． incentives [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.426 (perp=10.347, rec=0.128, cos=0.228), tot_loss_proj:3.523 [t=0.21s]
prediction: ['[CLS] absurd beengenase translation the lost routine premise infest without lost slack.alic. what the lost slack frightizes slack slack which routine hollywood ． 目 [SEP]']
[ 900/2000] tot_loss=2.270 (perp=9.609, rec=0.121, cos=0.228), tot_loss_proj:3.305 [t=0.21s]
prediction: ['[CLS] absurd beenɴ translation the lost routine premise in another without lost slack.alic. what the lost slack frightizes slack slack which routine hollywood. 目 [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.334 (perp=9.896, rec=0.126, cos=0.228), tot_loss_proj:3.395 [t=0.21s]
prediction: ['[CLS] absurd beenɴ translation the lost routine premise in another without lost slack.alic. what the lost slackfestizes slack slack which ‑ hollywood. routine [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.215 (perp=9.348, rec=0.118, cos=0.227), tot_loss_proj:3.181 [t=0.21s]
prediction: ['[CLS] absurd beenɴ translation the lost routine premise in another lost slack. withoutalic. what the lost slackfestizes slack slack which hollywood hollywood. routine [SEP]']
[1050/2000] tot_loss=2.269 (perp=9.640, rec=0.113, cos=0.227), tot_loss_proj:3.230 [t=0.21s]
prediction: ['[CLS] absurd beenɴ translation the lost routine premise in another lost slack. withoutalic. what the slack slackfestizes slack slack which hollywood hollywood. routine [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.221 (perp=9.399, rec=0.114, cos=0.227), tot_loss_proj:3.273 [t=0.21s]
prediction: ['[CLS] absurd beenɴ translation the lost routine premise in another lost routine slack. withoutalic. afghanistan the slack slackfestizes slack slack which hollywood hollywood. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.153 (perp=9.053, rec=0.114, cos=0.228), tot_loss_proj:3.166 [t=0.21s]
prediction: ['[CLS] absurd beenɴ translation the lost routine premise in another lost routine slack. withoutalic. the the slack slackfestizes slack slack which hollywood hollywood. [SEP]']
[1200/2000] tot_loss=2.143 (perp=9.053, rec=0.105, cos=0.228), tot_loss_proj:3.168 [t=0.21s]
prediction: ['[CLS] absurd beenɴ translation the lost routine premise in another lost routine slack. withoutalic. the the slack slackfestizes slack slack which hollywood hollywood. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.073 (perp=8.693, rec=0.107, cos=0.227), tot_loss_proj:3.139 [t=0.21s]
prediction: ['[CLS] absurd beenɴ translation the lost routine premise in another lost routine slack. withoutalic. the slack slackfestizes the slack slack which hollywood hollywood. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.081 (perp=8.725, rec=0.108, cos=0.228), tot_loss_proj:3.000 [t=0.21s]
prediction: ['[CLS] absurd been slack translation the lost routine premise in another lost routine slack. elsewherealic. theɴ slackfestizes the slack slack which hollywood hollywood. [SEP]']
[1350/2000] tot_loss=2.081 (perp=8.725, rec=0.107, cos=0.228), tot_loss_proj:3.003 [t=0.21s]
prediction: ['[CLS] absurd been slack translation the lost routine premise in another lost routine slack. elsewherealic. theɴ slackfestizes the slack slack which hollywood hollywood. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.174 (perp=9.198, rec=0.105, cos=0.229), tot_loss_proj:3.196 [t=0.21s]
prediction: ['[CLS] absurd slack been translation the has routine premise in another lost routine slack. elsewherealic. theɴ slackfestizes the slack slack which hollywood hollywood. [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=2.223 (perp=9.443, rec=0.106, cos=0.228), tot_loss_proj:3.219 [t=0.21s]
prediction: ['[CLS] absurd slack been translation the has routine premise in another lost routine slack. elsewherealic slackfest. theɴizes the slack slack which hollywood hollywood. [SEP]']
[1500/2000] tot_loss=2.267 (perp=9.694, rec=0.100, cos=0.228), tot_loss_proj:3.327 [t=0.21s]
prediction: ['[CLS] absurd slack been translation the has routine premise in another lost routine slack. elsewherealic slackfest.heimerɴizes the slack slack which hollywood hollywood. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.186 (perp=9.260, rec=0.105, cos=0.229), tot_loss_proj:3.222 [t=0.21s]
prediction: ['[CLS] absurd slack been translation the slack routine premise in another lost routine has. elsewherealic slackfest.heimerɴizes the slack slack which hollywood hollywood. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.154 (perp=9.123, rec=0.101, cos=0.229), tot_loss_proj:3.208 [t=0.21s]
prediction: ['[CLS] slack slack been translation the slack routine premise in another lost routine has. elsewherealic slackfest.heimerɴizes the slack absurd which hollywood hollywood. [SEP]']
[1650/2000] tot_loss=2.203 (perp=9.375, rec=0.099, cos=0.229), tot_loss_proj:3.172 [t=0.21s]
prediction: ['[CLS] slack slack been translation the execution routine premise in another lost routine has. elsewherealic slackfest.heimerɴizes the slack absurd which hollywood hollywood. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.169 (perp=9.182, rec=0.104, cos=0.229), tot_loss_proj:3.097 [t=0.21s]
prediction: ['[CLS] slack slack been translation the execution routine premise in another lost routine has. elsewherealic slackfest.heimerɴizes the slack which absurd hollywood hollywood. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.209 (perp=9.412, rec=0.099, cos=0.228), tot_loss_proj:3.136 [t=0.21s]
prediction: ['[CLS] slack slack translation been the execution routine premise in another lost routine has. elsewherealic slackfest.heimerdentsizes the slack which absurd hollywood hollywood. [SEP]']
[1800/2000] tot_loss=2.212 (perp=9.412, rec=0.101, cos=0.229), tot_loss_proj:3.145 [t=0.21s]
prediction: ['[CLS] slack slack translation been the execution routine premise in another lost routine has. elsewherealic slackfest.heimerdentsizes the slack which absurd hollywood hollywood. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.071 (perp=8.710, rec=0.101, cos=0.229), tot_loss_proj:2.877 [t=0.21s]
prediction: ['[CLS] slack slack translation. the execution routine premise in another lost routine has been elsewherealic slackfest.heimerdentsizes the slack which absurd hollywood hollywood. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=2.042 (perp=8.586, rec=0.096, cos=0.229), tot_loss_proj:2.664 [t=0.21s]
prediction: ['[CLS] slack slack translation. the execution routine premise in another lost routine has been elsewherealic slack ・dentsfest.izes the slack which absurd hollywood hollywood. [SEP]']
[1950/2000] tot_loss=2.045 (perp=8.586, rec=0.098, cos=0.229), tot_loss_proj:2.668 [t=0.21s]
prediction: ['[CLS] slack slack translation. the execution routine premise in another lost routine has been elsewherealic slack ・dentsfest.izes the slack which absurd hollywood hollywood. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.044 (perp=8.586, rec=0.098, cos=0.229), tot_loss_proj:2.671 [t=0.21s]
prediction: ['[CLS] slack slack translation. the execution routine premise in another lost routine has been elsewherealic slack ・dentsfest.izes the slack which absurd hollywood hollywood. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] slack slack translation been the execution routine premise in another lost routine has. elsewherealic slackfest.heimerdentsizes the slack which absurd hollywood hollywood. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.085 | p: 66.667 | r: 69.565
rouge2     | fm: 4.444 | p: 4.348 | r: 4.545
rougeL     | fm: 34.043 | p: 33.333 | r: 34.783
rougeLsum  | fm: 34.043 | p: 33.333 | r: 34.783
r1fm+r2fm = 72.530

[Aggregate metrics]:
rouge1     | fm: 89.413 | p: 88.837 | r: 90.157
rouge2     | fm: 59.955 | p: 59.554 | r: 60.456
rougeL     | fm: 79.604 | p: 78.956 | r: 80.262
rougeLsum  | fm: 79.386 | p: 78.774 | r: 80.038
r1fm+r2fm = 149.368

input #44 time: 0:08:28 | total time: 6:31:08


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.8798317878425943
highest_index [0]
highest [0.8798317878425943]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.7830626368522644 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.7349532842636108 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.7309244275093079 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.7156593203544617 for ['[CLS] go land board preparatory hush dylan guantanamo grace really our guidesbian a2lic internet mor salad possible throughoutim between grey scaleitic around speech pri mil [SEP]']
[Init] best rec loss: 0.6856576204299927 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 0.6663888692855835 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.6600870490074158 for ['[CLS]2 ku tree operatedtiv bore murmured single v few letter military status special taste skin joan football ( curtis enclosedlanda gentry five entrance whoa around via [SEP]']
[Init] best perm rec loss: 0.6598396897315979 for ['[CLS]2 lettertiv skin taste entrance around ( five ku via tree military single operated enclosed whoa statuslanda gentry bore murmured special v curtis football joan few [SEP]']
[Init] best perm rec loss: 0.6590742468833923 for ['[CLS]landa2 bore ( enclosed gentry entrance joan skin few v around kutiv taste operated murmured single tree via status curtis military football letter special five whoa [SEP]']
[Init] best perm rec loss: 0.6585909724235535 for ['[CLS]landa military status taste via whoa ( murmured five few skin2 v joan ku bore tree around single special curtis football operated letter entrancetiv gentry enclosed [SEP]']
[Init] best perm rec loss: 0.6577778458595276 for ['[CLS] murmured letter enclosed status five ( skin operated borelanda special taste entrance football via single around tree curtis whoa joan kutiv2 military gentry v few [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.052 (perp=12.457, rec=0.336, cos=0.224), tot_loss_proj:3.469 [t=0.22s]
prediction: ['[CLS] episode muscle lowered - scream wounds ram there corpsemm movements specialized closed fat the / heavyweight floor jimm romdent address commercial learners developed door [SEP]']
[ 100/2000] tot_loss=2.568 (perp=10.522, rec=0.248, cos=0.215), tot_loss_proj:3.248 [t=0.22s]
prediction: ['[CLS] story - thanel - bullet movementsmm looked shin s movements the -p off - exercise shelfiim adventure around text transfer than in. [SEP]']
[ 150/2000] tot_loss=2.483 (perp=10.365, rec=0.196, cos=0.214), tot_loss_proj:3.312 [t=0.23s]
prediction: ['[CLS] drama - -el - bullet movements bow - bow s movements this -ick shelf - this shelfmm in exercise high travis transfer than in - [SEP]']
[ 200/2000] tot_loss=2.411 (perp=10.141, rec=0.169, cos=0.214), tot_loss_proj:2.964 [t=0.22s]
prediction: ['[CLS] drama - -el - bullet movements bow - bowel movements this -ick shelf - this shelfmm in exercise in exercise transfer than, drama [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.363 (perp=9.896, rec=0.162, cos=0.222), tot_loss_proj:2.958 [t=0.22s]
prediction: ['[CLS] drama - - - fightel bowel - bowel movements the -ick shelf - this shelfmm in exercise gi exercise transfer than, drama [SEP]']
[ 300/2000] tot_loss=2.347 (perp=9.896, rec=0.148, cos=0.220), tot_loss_proj:2.959 [t=0.22s]
prediction: ['[CLS] drama - - - fightel bowel - bowel movements the -ick shelf - this shelfmm in exercise gi exercise transfer than, drama [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.217 (perp=9.305, rec=0.129, cos=0.227), tot_loss_proj:2.791 [t=0.22s]
prediction: ['[CLS] drama - - - -el bowel - bowel movements the -ick shelf - this shelf exercise inmm gi exercisezed than, drama [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.246 (perp=9.485, rec=0.130, cos=0.219), tot_loss_proj:2.777 [t=0.23s]
prediction: ['[CLS] dramael - bowel - bowel movements long - - -elick shelf - this shelf exercise inmm gi exercisezed than, drama [SEP]']
[ 450/2000] tot_loss=2.264 (perp=9.644, rec=0.115, cos=0.220), tot_loss_proj:2.846 [t=0.22s]
prediction: ['[CLS] dramael - bowel - bowel movements long - - -elick shelf - this shelf exercise inmm gi playszed than, drama [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.220 (perp=9.409, rec=0.115, cos=0.222), tot_loss_proj:2.780 [t=0.23s]
prediction: ['[CLS] dramael - bowel - bowel movements long - - crimeelick shelf - this shelf exercise inmm giyzed than, crime [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.161 (perp=9.096, rec=0.117, cos=0.225), tot_loss_proj:2.758 [t=0.23s]
prediction: ['[CLS] dramael - bowel - bowel than long on - shootelick shelf - this shelf exercise inmm gi plays - movements, crime [SEP]']
[ 600/2000] tot_loss=2.168 (perp=9.208, rec=0.109, cos=0.218), tot_loss_proj:2.832 [t=0.22s]
prediction: ['[CLS] dramael - bowy - bowel than long on - shootelick shoot - this shelf exercise inmm gi plays - movements, crime [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.134 (perp=9.069, rec=0.100, cos=0.221), tot_loss_proj:2.811 [t=0.23s]
prediction: ['[CLS]el drama - bowy - bowel than long on - shootelick shoot - this shelf exercise inmm gi plays - movements, crime [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.075 (perp=8.768, rec=0.100, cos=0.221), tot_loss_proj:2.748 [t=0.22s]
prediction: ['[CLS]el drama - thisy - bowel than long on - shootelick shoot - bow shelf exercise inmm gi drama - movements, crime [SEP]']
[ 750/2000] tot_loss=2.068 (perp=8.768, rec=0.096, cos=0.218), tot_loss_proj:2.755 [t=0.22s]
prediction: ['[CLS]el drama - thisy - bowel than long on - shootelick shoot - bow shelf exercise inmm gi drama - movements, crime [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.030 (perp=8.618, rec=0.086, cos=0.220), tot_loss_proj:2.679 [t=0.22s]
prediction: ['[CLS]el drama - thisy - bowel than long on - shootelick shoot - bow shelf exercise inmm gi drama - crime movements, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.971 (perp=8.346, rec=0.079, cos=0.223), tot_loss_proj:2.623 [t=0.22s]
prediction: ['[CLS]el drama - thisy - bowel than long on - shootel shelf shoot - bowick exercise inmm gi drama - crime movements, [SEP]']
[ 900/2000] tot_loss=2.022 (perp=8.587, rec=0.084, cos=0.221), tot_loss_proj:2.638 [t=0.22s]
prediction: ['[CLS] - drama - thisy - bowel than long on - shootel shelf shoot - bowick exercise inmm gi drama - crime movements, [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.990 (perp=8.402, rec=0.087, cos=0.222), tot_loss_proj:2.588 [t=0.23s]
prediction: ['[CLS] - drama - thisy - bowel than long on - shooty shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.919 (perp=8.075, rec=0.083, cos=0.222), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] - - - thisy drama bowel than long on - shooty shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
[1050/2000] tot_loss=1.915 (perp=8.075, rec=0.076, cos=0.224), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS] - - - thisy drama bowel than long on - shooty shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.919 (perp=8.075, rec=0.081, cos=0.223), tot_loss_proj:2.574 [t=0.22s]
prediction: ['[CLS] - - - thisy drama bowel than long on - shooty shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.869 (perp=7.857, rec=0.075, cos=0.223), tot_loss_proj:2.549 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on - shooty shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
[1200/2000] tot_loss=1.874 (perp=7.857, rec=0.079, cos=0.223), tot_loss_proj:2.553 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on - shooty shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.879 (perp=7.925, rec=0.071, cos=0.224), tot_loss_proj:2.545 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on - shooty shelf point - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.887 (perp=7.925, rec=0.080, cos=0.223), tot_loss_proj:2.547 [t=0.22s]
prediction: ['[CLS] - - - thany drama bowel this long on - shooty shelf point - bowick exercise inmm giel - crime movements, [SEP]']
[1350/2000] tot_loss=1.882 (perp=7.925, rec=0.072, cos=0.225), tot_loss_proj:2.542 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on - shooty shelf point - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.879 (perp=7.898, rec=0.074, cos=0.225), tot_loss_proj:2.508 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on - shoot drama shelf point - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.922 (perp=8.111, rec=0.078, cos=0.222), tot_loss_proj:2.591 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on -y shelf point shoot - bowick exercise inmm giel - crime movements, [SEP]']
[1500/2000] tot_loss=1.920 (perp=8.111, rec=0.074, cos=0.224), tot_loss_proj:2.590 [t=0.22s]
prediction: ['[CLS] - - - thany drama bowel this long on -y shelf point shoot - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.897 (perp=7.960, rec=0.080, cos=0.225), tot_loss_proj:2.601 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on - point drama shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.892 (perp=7.960, rec=0.076, cos=0.224), tot_loss_proj:2.612 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on - point drama shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
[1650/2000] tot_loss=1.885 (perp=7.960, rec=0.070, cos=0.224), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] - - - thany drama bowel this long on - point drama shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.874 (perp=7.874, rec=0.075, cos=0.225), tot_loss_proj:2.603 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on - drama point shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.870 (perp=7.874, rec=0.071, cos=0.224), tot_loss_proj:2.605 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on - drama point shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
[1800/2000] tot_loss=1.873 (perp=7.874, rec=0.075, cos=0.224), tot_loss_proj:2.602 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on - drama point shelf shoot - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.855 (perp=7.754, rec=0.081, cos=0.224), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] - - - thany drama bowel this long on - drama shelf point shoot - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.853 (perp=7.754, rec=0.078, cos=0.224), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] - - - thany drama bowel this long on - drama shelf point shoot - bowick exercise inmm giel - crime movements, [SEP]']
[1950/2000] tot_loss=1.843 (perp=7.754, rec=0.068, cos=0.224), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] - - - thany drama bowel this long on - drama shelf point shoot - bowick exercise inmm giel - crime movements, [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.921 (perp=8.111, rec=0.075, cos=0.224), tot_loss_proj:2.591 [t=0.23s]
prediction: ['[CLS] - - - thany drama bowel this long on -y shelf point shoot - bowick exercise inmm giel - crime movements, [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] - - - thany drama bowel this long on - drama shelf point shoot - bowick exercise inmm giel - crime movements, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.222 | p: 72.222 | r: 72.222
rouge2     | fm: 17.647 | p: 17.647 | r: 17.647
rougeL     | fm: 61.111 | p: 61.111 | r: 61.111
rougeLsum  | fm: 61.111 | p: 61.111 | r: 61.111
r1fm+r2fm = 89.869

[Aggregate metrics]:
rouge1     | fm: 89.020 | p: 88.424 | r: 89.703
rouge2     | fm: 59.060 | p: 58.616 | r: 59.514
rougeL     | fm: 79.008 | p: 78.439 | r: 79.660
rougeLsum  | fm: 79.025 | p: 78.540 | r: 79.755
r1fm+r2fm = 148.080

input #45 time: 0:08:49 | total time: 6:39:57


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.8269090902754344
highest_index [0]
highest [0.8269090902754344]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9438065886497498 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9170168042182922 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9122734665870667 for ['[CLS] giants alley told hurricane und : [SEP]']
[Init] best perm rec loss: 0.9122269749641418 for ['[CLS] : und giants told alley hurricane [SEP]']
[Init] best perm rec loss: 0.9108573794364929 for ['[CLS] : hurricane und told alley giants [SEP]']
[Init] best perm rec loss: 0.9102547764778137 for ['[CLS] : und told alley hurricane giants [SEP]']
[Init] best perm rec loss: 0.9087576866149902 for ['[CLS] und hurricane : told alley giants [SEP]']
[Init] best perm rec loss: 0.9069836139678955 for ['[CLS] told hurricane : giants alley und [SEP]']
[Init] best perm rec loss: 0.9066851735115051 for ['[CLS] told und alley hurricane : giants [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.910 (perp=11.959, rec=0.198, cos=0.320), tot_loss_proj:3.660 [t=0.22s]
prediction: ['[CLS] visually mcgill live staged visually striking [SEP]']
[ 100/2000] tot_loss=2.618 (perp=10.762, rec=0.148, cos=0.317), tot_loss_proj:3.187 [t=0.22s]
prediction: ['[CLS] visually and myers staged visually striking [SEP]']
[ 150/2000] tot_loss=2.370 (perp=9.567, rec=0.141, cos=0.316), tot_loss_proj:2.611 [t=0.22s]
prediction: ['[CLS] visuallylyly staged visually striking [SEP]']
[ 200/2000] tot_loss=2.378 (perp=9.640, rec=0.132, cos=0.318), tot_loss_proj:3.117 [t=0.22s]
prediction: ['[CLS] visually and audience staged visually striking [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.104 (perp=8.348, rec=0.118, cos=0.316), tot_loss_proj:2.385 [t=0.22s]
prediction: ['[CLS] visually staged way and visually striking [SEP]']
[ 300/2000] tot_loss=1.895 (perp=7.359, rec=0.106, cos=0.317), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] visually stagedly and visually striking [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.729 (perp=6.580, rec=0.097, cos=0.316), tot_loss_proj:1.827 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.728 (perp=6.580, rec=0.098, cos=0.314), tot_loss_proj:1.820 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 450/2000] tot_loss=1.715 (perp=6.580, rec=0.084, cos=0.315), tot_loss_proj:1.832 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.219 (perp=9.074, rec=0.088, cos=0.317), tot_loss_proj:2.401 [t=0.22s]
prediction: ['[CLS] slickly stagedly visually striking [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.134 (perp=8.524, rec=0.114, cos=0.314), tot_loss_proj:2.366 [t=0.22s]
prediction: ['[CLS] slickly staged visually striking and [SEP]']
[ 600/2000] tot_loss=2.105 (perp=8.524, rec=0.084, cos=0.316), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] slickly staged visually striking and [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.712 (perp=6.580, rec=0.080, cos=0.316), tot_loss_proj:1.813 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.691 (perp=6.580, rec=0.059, cos=0.316), tot_loss_proj:1.830 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 750/2000] tot_loss=1.702 (perp=6.580, rec=0.071, cos=0.315), tot_loss_proj:1.823 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.704 (perp=6.580, rec=0.071, cos=0.317), tot_loss_proj:1.825 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.708 (perp=6.580, rec=0.076, cos=0.316), tot_loss_proj:1.821 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 900/2000] tot_loss=1.708 (perp=6.580, rec=0.077, cos=0.316), tot_loss_proj:1.820 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.702 (perp=6.580, rec=0.070, cos=0.316), tot_loss_proj:1.822 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1000/2000] tot_loss=1.696 (perp=6.580, rec=0.064, cos=0.316), tot_loss_proj:1.818 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1050/2000] tot_loss=1.704 (perp=6.580, rec=0.071, cos=0.316), tot_loss_proj:1.825 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1100/2000] tot_loss=1.690 (perp=6.580, rec=0.057, cos=0.316), tot_loss_proj:1.822 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1150/2000] tot_loss=1.704 (perp=6.580, rec=0.072, cos=0.316), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1200/2000] tot_loss=1.698 (perp=6.580, rec=0.066, cos=0.316), tot_loss_proj:1.813 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1250/2000] tot_loss=1.705 (perp=6.580, rec=0.073, cos=0.316), tot_loss_proj:1.827 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1300/2000] tot_loss=1.694 (perp=6.580, rec=0.062, cos=0.316), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1350/2000] tot_loss=1.702 (perp=6.580, rec=0.070, cos=0.316), tot_loss_proj:1.828 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1400/2000] tot_loss=1.701 (perp=6.580, rec=0.069, cos=0.316), tot_loss_proj:1.823 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1450/2000] tot_loss=1.695 (perp=6.580, rec=0.063, cos=0.316), tot_loss_proj:1.819 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1500/2000] tot_loss=1.693 (perp=6.580, rec=0.062, cos=0.315), tot_loss_proj:1.824 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1550/2000] tot_loss=1.702 (perp=6.580, rec=0.070, cos=0.316), tot_loss_proj:1.821 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1600/2000] tot_loss=1.697 (perp=6.580, rec=0.065, cos=0.316), tot_loss_proj:1.824 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1650/2000] tot_loss=1.704 (perp=6.580, rec=0.072, cos=0.316), tot_loss_proj:1.818 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1700/2000] tot_loss=1.691 (perp=6.580, rec=0.059, cos=0.316), tot_loss_proj:1.811 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1750/2000] tot_loss=1.695 (perp=6.580, rec=0.063, cos=0.316), tot_loss_proj:1.821 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1800/2000] tot_loss=1.698 (perp=6.580, rec=0.066, cos=0.316), tot_loss_proj:1.816 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1850/2000] tot_loss=1.706 (perp=6.580, rec=0.075, cos=0.316), tot_loss_proj:1.819 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1900/2000] tot_loss=1.685 (perp=6.580, rec=0.053, cos=0.316), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1950/2000] tot_loss=1.711 (perp=6.580, rec=0.079, cos=0.316), tot_loss_proj:1.819 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[2000/2000] tot_loss=1.693 (perp=6.580, rec=0.062, cos=0.316), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] slickly staged and visually striking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 89.210 | p: 88.628 | r: 90.003
rouge2     | fm: 58.381 | p: 57.941 | r: 58.969
rougeL     | fm: 78.482 | p: 77.968 | r: 79.061
rougeLsum  | fm: 78.479 | p: 77.967 | r: 79.159
r1fm+r2fm = 147.591

input #46 time: 0:08:44 | total time: 6:48:42


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9211372807303723
highest_index [0]
highest [0.9211372807303723]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6785471439361572 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.654293417930603 for ['[CLS] spent excitedlychule [SEP]']
[Init] best rec loss: 0.647540807723999 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6429092884063721 for ['[CLS] desert elementsfulness [SEP]']
[Init] best rec loss: 0.6345986127853394 for ['[CLS] we processgon [SEP]']
[Init] best perm rec loss: 0.6324071884155273 for ['[CLS] processgon we [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.907 (perp=12.775, rec=0.209, cos=0.143), tot_loss_proj:3.394 [t=0.22s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 100/2000] tot_loss=2.820 (perp=12.775, rec=0.130, cos=0.136), tot_loss_proj:3.412 [t=0.22s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 150/2000] tot_loss=2.808 (perp=12.775, rec=0.108, cos=0.145), tot_loss_proj:3.420 [t=0.22s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 200/2000] tot_loss=2.793 (perp=12.775, rec=0.095, cos=0.143), tot_loss_proj:3.434 [t=0.22s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.748 (perp=12.488, rec=0.100, cos=0.151), tot_loss_proj:3.369 [t=0.22s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 300/2000] tot_loss=2.731 (perp=12.488, rec=0.088, cos=0.146), tot_loss_proj:3.380 [t=0.22s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.740 (perp=12.488, rec=0.091, cos=0.151), tot_loss_proj:3.399 [t=0.22s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.728 (perp=12.488, rec=0.089, cos=0.141), tot_loss_proj:3.400 [t=0.22s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 450/2000] tot_loss=2.748 (perp=12.488, rec=0.099, cos=0.151), tot_loss_proj:3.403 [t=0.22s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.731 (perp=12.488, rec=0.086, cos=0.148), tot_loss_proj:3.406 [t=0.22s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.711 (perp=12.488, rec=0.066, cos=0.147), tot_loss_proj:3.415 [t=0.22s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 600/2000] tot_loss=2.726 (perp=12.488, rec=0.079, cos=0.149), tot_loss_proj:3.409 [t=0.22s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.659 (perp=12.147, rec=0.078, cos=0.152), tot_loss_proj:3.075 [t=0.22s]
prediction: ['[CLS]right down transparent [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.967 (perp=8.803, rec=0.065, cos=0.142), tot_loss_proj:1.983 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.965 (perp=8.803, rec=0.058, cos=0.146), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.981 (perp=8.803, rec=0.069, cos=0.151), tot_loss_proj:1.989 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.981 (perp=8.803, rec=0.067, cos=0.153), tot_loss_proj:1.974 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.983 (perp=8.803, rec=0.072, cos=0.150), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.966 (perp=8.803, rec=0.059, cos=0.147), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.973 (perp=8.803, rec=0.065, cos=0.147), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.964 (perp=8.803, rec=0.053, cos=0.150), tot_loss_proj:2.000 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.973 (perp=8.803, rec=0.062, cos=0.150), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.974 (perp=8.803, rec=0.063, cos=0.151), tot_loss_proj:1.979 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.971 (perp=8.803, rec=0.062, cos=0.148), tot_loss_proj:1.984 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.958 (perp=8.803, rec=0.051, cos=0.147), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.973 (perp=8.803, rec=0.065, cos=0.147), tot_loss_proj:1.980 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.976 (perp=8.803, rec=0.069, cos=0.146), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.979 (perp=8.803, rec=0.067, cos=0.152), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.986 (perp=8.803, rec=0.076, cos=0.149), tot_loss_proj:1.980 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.978 (perp=8.803, rec=0.068, cos=0.150), tot_loss_proj:1.982 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.985 (perp=8.803, rec=0.076, cos=0.149), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.983 (perp=8.803, rec=0.073, cos=0.150), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.970 (perp=8.803, rec=0.061, cos=0.149), tot_loss_proj:1.982 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.974 (perp=8.803, rec=0.063, cos=0.151), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.975 (perp=8.803, rec=0.065, cos=0.149), tot_loss_proj:1.984 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.973 (perp=8.803, rec=0.065, cos=0.148), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.966 (perp=8.803, rec=0.055, cos=0.150), tot_loss_proj:1.985 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.976 (perp=8.803, rec=0.066, cos=0.150), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.961 (perp=8.803, rec=0.050, cos=0.150), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.979 (perp=8.803, rec=0.069, cos=0.149), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.526 | p: 88.981 | r: 90.193
rouge2     | fm: 59.513 | p: 59.052 | r: 59.982
rougeL     | fm: 79.060 | p: 78.530 | r: 79.700
rougeLsum  | fm: 79.081 | p: 78.582 | r: 79.703
r1fm+r2fm = 149.039

input #47 time: 0:08:41 | total time: 6:57:24


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.8669613126737438
highest_index [0]
highest [0.8669613126737438]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.841980516910553 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.8309106826782227 for ['[CLS] however stage arts grounds [SEP]']
[Init] best rec loss: 0.7901580929756165 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 0.7723152041435242 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7672670483589172 for ['[CLS] graveyarddine runstute [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.334 (perp=14.144, rec=0.253, cos=0.253), tot_loss_proj:3.612 [t=0.22s]
prediction: ['[CLS] rotting rottingoo decay [SEP]']
[ 100/2000] tot_loss=2.851 (perp=12.138, rec=0.180, cos=0.244), tot_loss_proj:3.146 [t=0.22s]
prediction: ['[CLS] rotting rottingbell rotting [SEP]']
[ 150/2000] tot_loss=3.129 (perp=13.676, rec=0.148, cos=0.246), tot_loss_proj:3.440 [t=0.22s]
prediction: ['[CLS] rotting rottingbell under [SEP]']
[ 200/2000] tot_loss=3.109 (perp=13.676, rec=0.126, cos=0.248), tot_loss_proj:3.432 [t=0.22s]
prediction: ['[CLS] rotting rottingbell under [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.620 (perp=11.342, rec=0.107, cos=0.245), tot_loss_proj:2.849 [t=0.22s]
prediction: ['[CLS] rotting underbell rotting [SEP]']
[ 300/2000] tot_loss=2.620 (perp=11.342, rec=0.103, cos=0.248), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS] rotting underbell rotting [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.436 (perp=10.480, rec=0.094, cos=0.245), tot_loss_proj:2.712 [t=0.22s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.432 (perp=10.480, rec=0.090, cos=0.246), tot_loss_proj:2.709 [t=0.22s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
[ 450/2000] tot_loss=2.433 (perp=10.480, rec=0.091, cos=0.246), tot_loss_proj:2.710 [t=0.22s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.896 (perp=12.762, rec=0.095, cos=0.248), tot_loss_proj:3.526 [t=0.22s]
prediction: ['[CLS] underbell rottingbell [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=2.614 (perp=11.342, rec=0.099, cos=0.247), tot_loss_proj:2.847 [t=0.22s]
prediction: ['[CLS] rotting underbell rotting [SEP]']
[ 600/2000] tot_loss=2.609 (perp=11.342, rec=0.093, cos=0.247), tot_loss_proj:2.837 [t=0.22s]
prediction: ['[CLS] rotting underbell rotting [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=2.433 (perp=10.480, rec=0.091, cos=0.247), tot_loss_proj:2.711 [t=0.22s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
Put prefix at the end
[ 700/2000] tot_loss=2.604 (perp=11.342, rec=0.090, cos=0.246), tot_loss_proj:2.847 [t=0.22s]
prediction: ['[CLS] rotting underbell rotting [SEP]']
[ 750/2000] tot_loss=2.607 (perp=11.342, rec=0.091, cos=0.247), tot_loss_proj:2.841 [t=0.23s]
prediction: ['[CLS] rotting underbell rotting [SEP]']
Attempt swap
Put prefix at the end
[ 800/2000] tot_loss=2.885 (perp=12.762, rec=0.085, cos=0.248), tot_loss_proj:3.517 [t=0.22s]
prediction: ['[CLS] underbell rottingbell [SEP]']
Attempt swap
Put prefix at the end
[ 850/2000] tot_loss=2.431 (perp=10.455, rec=0.095, cos=0.245), tot_loss_proj:2.800 [t=0.22s]
prediction: ['[CLS]bell underbell rotting [SEP]']
[ 900/2000] tot_loss=2.428 (perp=10.455, rec=0.090, cos=0.247), tot_loss_proj:2.788 [t=0.22s]
prediction: ['[CLS]bell underbell rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.424 (perp=10.455, rec=0.087, cos=0.246), tot_loss_proj:2.783 [t=0.22s]
prediction: ['[CLS]bell underbell rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=2.425 (perp=10.455, rec=0.086, cos=0.247), tot_loss_proj:2.788 [t=0.22s]
prediction: ['[CLS]bell underbell rotting [SEP]']
[1050/2000] tot_loss=2.430 (perp=10.455, rec=0.091, cos=0.248), tot_loss_proj:2.786 [t=0.22s]
prediction: ['[CLS]bell underbell rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=2.427 (perp=10.455, rec=0.088, cos=0.248), tot_loss_proj:2.784 [t=0.22s]
prediction: ['[CLS]bell underbell rotting [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.753 (perp=7.028, rec=0.098, cos=0.249), tot_loss_proj:1.957 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.731 (perp=7.028, rec=0.078, cos=0.247), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.733 (perp=7.028, rec=0.080, cos=0.247), tot_loss_proj:1.950 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.731 (perp=7.028, rec=0.077, cos=0.248), tot_loss_proj:1.949 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.729 (perp=7.028, rec=0.075, cos=0.248), tot_loss_proj:1.950 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.724 (perp=7.028, rec=0.071, cos=0.247), tot_loss_proj:1.965 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.722 (perp=7.028, rec=0.069, cos=0.248), tot_loss_proj:1.947 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.724 (perp=7.028, rec=0.070, cos=0.248), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.716 (perp=7.028, rec=0.063, cos=0.248), tot_loss_proj:1.958 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.719 (perp=7.028, rec=0.065, cos=0.248), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.724 (perp=7.028, rec=0.070, cos=0.248), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.726 (perp=7.028, rec=0.073, cos=0.248), tot_loss_proj:1.954 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.725 (perp=7.028, rec=0.071, cos=0.248), tot_loss_proj:1.952 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.727 (perp=7.028, rec=0.074, cos=0.248), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.720 (perp=7.028, rec=0.066, cos=0.248), tot_loss_proj:1.950 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.724 (perp=7.028, rec=0.071, cos=0.248), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.720 (perp=7.028, rec=0.067, cos=0.248), tot_loss_proj:1.959 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.725 (perp=7.028, rec=0.071, cos=0.248), tot_loss_proj:1.951 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.715 | p: 89.144 | r: 90.322
rouge2     | fm: 58.293 | p: 57.963 | r: 58.791
rougeL     | fm: 78.844 | p: 78.331 | r: 79.497
rougeLsum  | fm: 78.963 | p: 78.430 | r: 79.574
r1fm+r2fm = 148.008

input #48 time: 0:08:45 | total time: 7:06:09


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.881020352021755
highest_index [0]
highest [0.881020352021755]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8191439509391785 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7903227806091309 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7898121476173401 for ['[CLS] chargesbered harsh today dion craftsuvenssen tool break backup guest [SEP]']
[Init] best rec loss: 0.7693589329719543 for ['[CLS] genetic slideactic nations shed lawrence oral like era calvin accept mentor [SEP]']
[Init] best rec loss: 0.7659977078437805 for ['[CLS] in before car lend only surprise securities radiation following montagu turkishpers [SEP]']
[Init] best rec loss: 0.7576348781585693 for ['[CLS] pyrenees answered bowling riding chloe minus bo language attentionocating nataya [SEP]']
[Init] best rec loss: 0.7549375891685486 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 0.7500085234642029 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best perm rec loss: 0.7492004036903381 for ['[CLS]uous perrin where things our sheepanial accompanied hetani major tried [SEP]']
[Init] best perm rec loss: 0.7460542917251587 for ['[CLS] accompanied sheeptani perrinuous things ouranial he tried major where [SEP]']
[Init] best perm rec loss: 0.7458498477935791 for ['[CLS] perrin things our he accompanied major tried wheretani sheepanialuous [SEP]']
[Init] best perm rec loss: 0.7458036541938782 for ['[CLS]uous accompanied where ourtanianial tried sheep he things perrin major [SEP]']
[Init] best perm rec loss: 0.7454344034194946 for ['[CLS]anial accompanied our tried things where major heuous sheep perrintani [SEP]']
[Init] best perm rec loss: 0.7453360557556152 for ['[CLS]anial our where perrin accompanieduous things he major sheeptani tried [SEP]']
[Init] best perm rec loss: 0.7452750205993652 for ['[CLS] whereuous he accompanied thingstani perrinanial major sheep our tried [SEP]']
[Init] best perm rec loss: 0.7447030544281006 for ['[CLS]uous perrin our he major accompaniedtanianial tried things where sheep [SEP]']
[Init] best perm rec loss: 0.7446278929710388 for ['[CLS] where things trieduousanial our he perrintani sheep major accompanied [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.939 (perp=11.911, rec=0.336, cos=0.220), tot_loss_proj:3.569 [t=0.22s]
prediction: ['[CLS] contempt contempt contempt any contemptuous female kingdoms organization leave harmplify [SEP]']
[ 100/2000] tot_loss=2.646 (perp=11.016, rec=0.223, cos=0.220), tot_loss_proj:3.370 [t=0.22s]
prediction: ['[CLS] contempt contempt contempt were contemptuous female more could reduced harm population [SEP]']
[ 150/2000] tot_loss=2.349 (perp=9.890, rec=0.150, cos=0.221), tot_loss_proj:3.106 [t=0.23s]
prediction: ['[CLS] contempt contempt of be contemptuous female more possibly be the population [SEP]']
[ 200/2000] tot_loss=2.376 (perp=10.125, rec=0.136, cos=0.216), tot_loss_proj:3.173 [t=0.22s]
prediction: ['[CLS] contempt contempt of single contemptuous female more possibly be. population [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.191 (perp=9.274, rec=0.125, cos=0.212), tot_loss_proj:3.024 [t=0.23s]
prediction: ['[CLS] contempt more of single contemptuous female contempt possibly be. population [SEP]']
[ 300/2000] tot_loss=2.179 (perp=9.274, rec=0.105, cos=0.219), tot_loss_proj:3.028 [t=0.23s]
prediction: ['[CLS] contempt more of single contemptuous female contempt possibly be. population [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.015 (perp=8.523, rec=0.094, cos=0.216), tot_loss_proj:2.911 [t=0.23s]
prediction: ['[CLS] contempt more of single contemptuous female contempt possibly the population. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.864 (perp=7.769, rec=0.091, cos=0.220), tot_loss_proj:2.688 [t=0.23s]
prediction: ['[CLS] possibly more of single contemptuous female contempt contempt the population. [SEP]']
[ 450/2000] tot_loss=1.892 (perp=7.889, rec=0.093, cos=0.221), tot_loss_proj:2.662 [t=0.23s]
prediction: ['[CLS] possibly more of single contemptuous female contempt fore the population. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.845 (perp=7.604, rec=0.101, cos=0.223), tot_loss_proj:2.617 [t=0.23s]
prediction: ['[CLS] possibly more single contemptuous female of contempt whatever the population. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.742 (perp=7.137, rec=0.101, cos=0.214), tot_loss_proj:2.349 [t=0.23s]
prediction: ['[CLS] possibly more single contemptuous of female contempt whatever the population. [SEP]']
[ 600/2000] tot_loss=1.735 (perp=7.137, rec=0.091, cos=0.217), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] possibly more single contemptuous of female contempt whatever the population. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.723 (perp=7.013, rec=0.099, cos=0.222), tot_loss_proj:2.069 [t=0.23s]
prediction: ['[CLS] possibly more contemptuous of female been whatever the single population. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.648 (perp=6.705, rec=0.089, cos=0.218), tot_loss_proj:2.094 [t=0.23s]
prediction: ['[CLS] possibly more contemptuous of whatever female be the single population. [SEP]']
[ 750/2000] tot_loss=1.646 (perp=6.705, rec=0.084, cos=0.221), tot_loss_proj:2.091 [t=0.23s]
prediction: ['[CLS] possibly more contemptuous of whatever female be the single population. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.639 (perp=6.705, rec=0.081, cos=0.217), tot_loss_proj:2.089 [t=0.23s]
prediction: ['[CLS] possibly more contemptuous of whatever female be the single population. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.642 (perp=6.705, rec=0.084, cos=0.217), tot_loss_proj:2.096 [t=0.23s]
prediction: ['[CLS] possibly more contemptuous of whatever female be the single population. [SEP]']
[ 900/2000] tot_loss=1.651 (perp=6.705, rec=0.090, cos=0.220), tot_loss_proj:2.091 [t=0.23s]
prediction: ['[CLS] possibly more contemptuous of whatever female be the single population. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.630 (perp=6.635, rec=0.081, cos=0.222), tot_loss_proj:2.018 [t=0.23s]
prediction: ['[CLS] possibly more contemptuous of whatever be the single female population. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.569 (perp=6.383, rec=0.073, cos=0.219), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
[1050/2000] tot_loss=1.572 (perp=6.383, rec=0.075, cos=0.220), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.574 (perp=6.383, rec=0.080, cos=0.218), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.578 (perp=6.383, rec=0.081, cos=0.220), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
[1200/2000] tot_loss=1.572 (perp=6.383, rec=0.074, cos=0.221), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.574 (perp=6.383, rec=0.078, cos=0.220), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.574 (perp=6.383, rec=0.074, cos=0.223), tot_loss_proj:1.979 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
[1350/2000] tot_loss=1.570 (perp=6.383, rec=0.073, cos=0.220), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.577 (perp=6.383, rec=0.079, cos=0.221), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.580 (perp=6.383, rec=0.083, cos=0.220), tot_loss_proj:1.980 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
[1500/2000] tot_loss=1.567 (perp=6.383, rec=0.069, cos=0.221), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.569 (perp=6.383, rec=0.069, cos=0.223), tot_loss_proj:1.979 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.572 (perp=6.383, rec=0.074, cos=0.221), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
[1650/2000] tot_loss=1.586 (perp=6.383, rec=0.088, cos=0.222), tot_loss_proj:1.979 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.569 (perp=6.383, rec=0.072, cos=0.221), tot_loss_proj:1.979 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.573 (perp=6.383, rec=0.075, cos=0.221), tot_loss_proj:1.982 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
[1800/2000] tot_loss=1.576 (perp=6.383, rec=0.079, cos=0.220), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.573 (perp=6.383, rec=0.075, cos=0.221), tot_loss_proj:1.979 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.569 (perp=6.383, rec=0.070, cos=0.222), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
[1950/2000] tot_loss=1.572 (perp=6.383, rec=0.074, cos=0.221), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.576 (perp=6.383, rec=0.078, cos=0.221), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous be whatever of the single female population. [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] possibly more contemptuous be whatever of the single female population. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 54.545 | p: 54.545 | r: 54.545
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 146.212

[Aggregate metrics]:
rouge1     | fm: 89.757 | p: 89.204 | r: 90.417
rouge2     | fm: 58.090 | p: 57.769 | r: 58.578
rougeL     | fm: 79.066 | p: 78.601 | r: 79.717
rougeLsum  | fm: 78.938 | p: 78.405 | r: 79.593
r1fm+r2fm = 147.847

input #49 time: 0:08:49 | total time: 7:14:58


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.913084144279322
highest_index [0]
highest [0.913084144279322]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.8118948936462402 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8042724132537842 for ['[CLS] felt defended drop ring richard spade frank beds₁ [SEP]']
[Init] best rec loss: 0.7883595824241638 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7770171761512756 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7690503597259521 for ['[CLS] rama fueled sq napkinok unit trust associated gall [SEP]']
[Init] best rec loss: 0.7571242451667786 for ['[CLS] stone sex science cheeks prolific conventionwashed in once [SEP]']
[Init] best rec loss: 0.7529720067977905 for ['[CLS]sil state grade over ing fish champion woolf good [SEP]']
[Init] best perm rec loss: 0.7524502873420715 for ['[CLS] state fishsil woolf ing over champion grade good [SEP]']
[Init] best perm rec loss: 0.7520463466644287 for ['[CLS] ing fish woolfsil grade over champion state good [SEP]']
[Init] best perm rec loss: 0.7514539361000061 for ['[CLS] grade fish champion woolf state over ing goodsil [SEP]']
[Init] best perm rec loss: 0.7513416409492493 for ['[CLS] champion oversil state grade ing good fish woolf [SEP]']
[Init] best perm rec loss: 0.7508156895637512 for ['[CLS] state fish championsil grade good over woolf ing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.641 (perp=10.575, rec=0.350, cos=0.176), tot_loss_proj:3.133 [t=0.22s]
prediction: ['[CLS] half too successful sometimes three good born however clever [SEP]']
[ 100/2000] tot_loss=2.332 (perp=9.625, rec=0.247, cos=0.160), tot_loss_proj:2.843 [t=0.22s]
prediction: ['[CLS] half too clever is calls ` too a clever [SEP]']
[ 150/2000] tot_loss=2.350 (perp=10.079, rec=0.172, cos=0.162), tot_loss_proj:2.842 [t=0.22s]
prediction: ['[CLS] half too clever by call ` by such clever [SEP]']
[ 200/2000] tot_loss=2.351 (perp=10.280, rec=0.138, cos=0.157), tot_loss_proj:2.982 [t=0.22s]
prediction: ["[CLS] half too english by call ` by'clever [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.844 (perp=7.897, rec=0.106, cos=0.158), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] too half what is call ` by a clever [SEP]']
[ 300/2000] tot_loss=1.990 (perp=8.675, rec=0.091, cos=0.164), tot_loss_proj:2.702 [t=0.22s]
prediction: ['[CLS] too half what the call ` by english clever [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.976 (perp=8.675, rec=0.084, cos=0.156), tot_loss_proj:2.708 [t=0.22s]
prediction: ['[CLS] too half what the call ` by english clever [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.915 (perp=8.318, rec=0.084, cos=0.167), tot_loss_proj:2.584 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
[ 450/2000] tot_loss=1.904 (perp=8.318, rec=0.078, cos=0.163), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.896 (perp=8.318, rec=0.073, cos=0.159), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.898 (perp=8.318, rec=0.072, cos=0.163), tot_loss_proj:2.585 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
[ 600/2000] tot_loss=1.896 (perp=8.318, rec=0.067, cos=0.165), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.901 (perp=8.318, rec=0.069, cos=0.168), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.895 (perp=8.318, rec=0.070, cos=0.162), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
[ 750/2000] tot_loss=1.891 (perp=8.318, rec=0.070, cos=0.158), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.901 (perp=8.318, rec=0.072, cos=0.165), tot_loss_proj:2.571 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.890 (perp=8.318, rec=0.065, cos=0.161), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
[ 900/2000] tot_loss=1.897 (perp=8.318, rec=0.067, cos=0.166), tot_loss_proj:2.572 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.893 (perp=8.318, rec=0.066, cos=0.163), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1000/2000] tot_loss=1.886 (perp=8.318, rec=0.057, cos=0.165), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
[1050/2000] tot_loss=1.895 (perp=8.318, rec=0.071, cos=0.160), tot_loss_proj:2.584 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.894 (perp=8.318, rec=0.068, cos=0.163), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.891 (perp=8.318, rec=0.066, cos=0.161), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
[1200/2000] tot_loss=1.887 (perp=8.318, rec=0.061, cos=0.162), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.887 (perp=8.318, rec=0.059, cos=0.164), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.892 (perp=8.318, rec=0.064, cos=0.164), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
[1350/2000] tot_loss=1.896 (perp=8.318, rec=0.068, cos=0.165), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1400/2000] tot_loss=1.900 (perp=8.318, rec=0.074, cos=0.163), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.888 (perp=8.318, rec=0.061, cos=0.163), tot_loss_proj:2.578 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
[1500/2000] tot_loss=1.899 (perp=8.318, rec=0.070, cos=0.165), tot_loss_proj:2.585 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.897 (perp=8.318, rec=0.070, cos=0.163), tot_loss_proj:2.576 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.894 (perp=8.318, rec=0.064, cos=0.167), tot_loss_proj:2.578 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
[1650/2000] tot_loss=1.889 (perp=8.318, rec=0.060, cos=0.165), tot_loss_proj:2.581 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1700/2000] tot_loss=1.889 (perp=8.318, rec=0.060, cos=0.166), tot_loss_proj:2.578 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1750/2000] tot_loss=1.892 (perp=8.318, rec=0.063, cos=0.166), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
[1800/2000] tot_loss=1.900 (perp=8.318, rec=0.072, cos=0.164), tot_loss_proj:2.575 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.888 (perp=8.318, rec=0.060, cos=0.165), tot_loss_proj:2.573 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[1900/2000] tot_loss=1.895 (perp=8.318, rec=0.067, cos=0.164), tot_loss_proj:2.583 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
[1950/2000] tot_loss=1.902 (perp=8.318, rec=0.074, cos=0.164), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.895 (perp=8.318, rec=0.067, cos=0.164), tot_loss_proj:2.581 [t=0.22s]
prediction: ['[CLS] too half what the english call ` by clever [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] too half what the english call ` by clever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 89.936 | p: 89.430 | r: 90.576
rouge2     | fm: 57.698 | p: 57.369 | r: 58.178
rougeL     | fm: 78.972 | p: 78.486 | r: 79.578
rougeLsum  | fm: 78.830 | p: 78.300 | r: 79.491
r1fm+r2fm = 147.634

input #50 time: 0:08:43 | total time: 7:23:42


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9205359757657836
highest_index [0]
highest [0.9205359757657836]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.7952286601066589 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.761513352394104 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7408720850944519 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7331059575080872 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 0.7164629697799683 for ['[CLS] low reelection honest louis caps noah lieutenant quarter consequence handwriting [SEP]']
[Init] best rec loss: 0.7053048610687256 for ['[CLS] acute jay outies harbor recognitionitung annezzled hughes [SEP]']
[Init] best perm rec loss: 0.7051990628242493 for ['[CLS] out anneiesitung harbor acute hughes recognitionzzled jay [SEP]']
[Init] best perm rec loss: 0.7044142484664917 for ['[CLS] harbor anne recognition acute out jay hugheszzlediesitung [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.884 (perp=11.572, rec=0.341, cos=0.230), tot_loss_proj:3.815 [t=0.22s]
prediction: ['[CLS] sucks sucks funny funny sucks funny sucks suckss funny [SEP]']
[ 100/2000] tot_loss=2.353 (perp=9.946, rec=0.202, cos=0.162), tot_loss_proj:2.895 [t=0.22s]
prediction: ['[CLS] sucks or moment funny sucks funny or sucks but has [SEP]']
[ 150/2000] tot_loss=2.179 (perp=9.443, rec=0.132, cos=0.158), tot_loss_proj:2.835 [t=0.22s]
prediction: ['[CLS] sucks a moment funny sucks funny or sucks but has [SEP]']
[ 200/2000] tot_loss=2.269 (perp=10.087, rec=0.105, cos=0.147), tot_loss_proj:3.043 [t=0.22s]
prediction: ['[CLS] sucks a moment funny two funny or sucks but has [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.005 (perp=8.811, rec=0.098, cos=0.145), tot_loss_proj:2.845 [t=0.22s]
prediction: ['[CLS] sucks a moment has two funny or sucks but funny [SEP]']
[ 300/2000] tot_loss=2.000 (perp=8.811, rec=0.086, cos=0.153), tot_loss_proj:2.837 [t=0.22s]
prediction: ['[CLS] sucks a moment has two funny or sucks but funny [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.847 (perp=8.040, rec=0.089, cos=0.150), tot_loss_proj:2.772 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.850 (perp=8.040, rec=0.088, cos=0.154), tot_loss_proj:2.773 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
[ 450/2000] tot_loss=1.854 (perp=8.040, rec=0.092, cos=0.153), tot_loss_proj:2.771 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.842 (perp=8.040, rec=0.086, cos=0.148), tot_loss_proj:2.774 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.844 (perp=8.040, rec=0.083, cos=0.153), tot_loss_proj:2.773 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
[ 600/2000] tot_loss=1.847 (perp=8.040, rec=0.088, cos=0.151), tot_loss_proj:2.776 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.841 (perp=8.040, rec=0.085, cos=0.148), tot_loss_proj:2.776 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.841 (perp=8.040, rec=0.081, cos=0.152), tot_loss_proj:2.773 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
[ 750/2000] tot_loss=1.839 (perp=8.040, rec=0.079, cos=0.152), tot_loss_proj:2.776 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.838 (perp=8.040, rec=0.080, cos=0.151), tot_loss_proj:2.773 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.835 (perp=8.040, rec=0.078, cos=0.148), tot_loss_proj:2.772 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
[ 900/2000] tot_loss=1.828 (perp=8.040, rec=0.071, cos=0.149), tot_loss_proj:2.776 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.831 (perp=8.040, rec=0.071, cos=0.152), tot_loss_proj:2.774 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1000/2000] tot_loss=1.848 (perp=8.040, rec=0.086, cos=0.154), tot_loss_proj:2.775 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
[1050/2000] tot_loss=1.840 (perp=8.040, rec=0.083, cos=0.149), tot_loss_proj:2.776 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1100/2000] tot_loss=1.834 (perp=8.040, rec=0.074, cos=0.152), tot_loss_proj:2.773 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1150/2000] tot_loss=1.833 (perp=8.040, rec=0.075, cos=0.150), tot_loss_proj:2.776 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
[1200/2000] tot_loss=1.837 (perp=8.040, rec=0.078, cos=0.151), tot_loss_proj:2.773 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1250/2000] tot_loss=1.841 (perp=8.040, rec=0.080, cos=0.152), tot_loss_proj:2.770 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1300/2000] tot_loss=1.842 (perp=8.040, rec=0.082, cos=0.152), tot_loss_proj:2.770 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
[1350/2000] tot_loss=1.841 (perp=8.040, rec=0.080, cos=0.153), tot_loss_proj:2.769 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1400/2000] tot_loss=1.836 (perp=8.040, rec=0.080, cos=0.148), tot_loss_proj:2.776 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1450/2000] tot_loss=1.839 (perp=8.040, rec=0.081, cos=0.150), tot_loss_proj:2.773 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
[1500/2000] tot_loss=1.841 (perp=8.040, rec=0.080, cos=0.153), tot_loss_proj:2.769 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1550/2000] tot_loss=1.833 (perp=8.040, rec=0.073, cos=0.152), tot_loss_proj:2.770 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1600/2000] tot_loss=1.832 (perp=8.040, rec=0.070, cos=0.154), tot_loss_proj:2.771 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
[1650/2000] tot_loss=1.842 (perp=8.040, rec=0.081, cos=0.153), tot_loss_proj:2.766 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1700/2000] tot_loss=1.841 (perp=8.040, rec=0.081, cos=0.152), tot_loss_proj:2.763 [t=0.23s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1750/2000] tot_loss=1.839 (perp=8.040, rec=0.080, cos=0.151), tot_loss_proj:2.767 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
[1800/2000] tot_loss=1.840 (perp=8.040, rec=0.080, cos=0.152), tot_loss_proj:2.766 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1850/2000] tot_loss=1.838 (perp=8.040, rec=0.077, cos=0.153), tot_loss_proj:2.767 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[1900/2000] tot_loss=1.846 (perp=8.040, rec=0.087, cos=0.151), tot_loss_proj:2.767 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
[1950/2000] tot_loss=1.837 (perp=8.040, rec=0.077, cos=0.152), tot_loss_proj:2.764 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Attempt swap
[2000/2000] tot_loss=1.838 (perp=8.040, rec=0.078, cos=0.152), tot_loss_proj:2.769 [t=0.22s]
prediction: ['[CLS] sucks a moment has funny or sucks but two funny [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] sucks a moment has funny or sucks but two funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 83.333 | r: 100.000
rouge2     | fm: 20.000 | p: 18.182 | r: 22.222
rougeL     | fm: 63.636 | p: 58.333 | r: 70.000
rougeLsum  | fm: 63.636 | p: 58.333 | r: 70.000
r1fm+r2fm = 110.909

[Aggregate metrics]:
rouge1     | fm: 90.066 | p: 89.347 | r: 90.854
rouge2     | fm: 56.924 | p: 56.537 | r: 57.437
rougeL     | fm: 78.621 | p: 78.027 | r: 79.333
rougeLsum  | fm: 78.622 | p: 78.036 | r: 79.314
r1fm+r2fm = 146.991

input #51 time: 0:08:49 | total time: 7:32:31


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.8747681589879563
highest_index [0]
highest [0.8747681589879563]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9419630765914917 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9310382604598999 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.928127110004425 for ['[CLS]fa bear gun [SEP]']
[Init] best rec loss: 0.9225459694862366 for ['[CLS] tree partition themed [SEP]']
[Init] best rec loss: 0.9085990786552429 for ['[CLS] news implies lack [SEP]']
[Init] best rec loss: 0.8857698440551758 for ['[CLS] transition content distance [SEP]']
[Init] best rec loss: 0.876424252986908 for ['[CLS] nations gazette probability [SEP]']
[Init] best rec loss: 0.7508561015129089 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7427035570144653 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.7401087880134583 for ['[CLS] expected football vocabulary [SEP]']
[Init] best perm rec loss: 0.7391274571418762 for ['[CLS] vocabulary expected football [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.813 (perp=11.737, rec=0.225, cos=0.240), tot_loss_proj:2.913 [t=0.22s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.709 (perp=11.737, rec=0.135, cos=0.226), tot_loss_proj:2.912 [t=0.22s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.417 (perp=10.529, rec=0.082, cos=0.229), tot_loss_proj:2.429 [t=0.22s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 200/2000] tot_loss=2.415 (perp=10.529, rec=0.074, cos=0.235), tot_loss_proj:2.430 [t=0.22s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.035 (perp=8.482, rec=0.104, cos=0.234), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=2.011 (perp=8.482, rec=0.081, cos=0.234), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.003 (perp=8.482, rec=0.074, cos=0.233), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.003 (perp=8.482, rec=0.073, cos=0.233), tot_loss_proj:2.335 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=2.004 (perp=8.482, rec=0.074, cos=0.233), tot_loss_proj:2.334 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.997 (perp=8.482, rec=0.068, cos=0.232), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.005 (perp=8.482, rec=0.075, cos=0.234), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.991 (perp=8.482, rec=0.062, cos=0.232), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.995 (perp=8.482, rec=0.065, cos=0.233), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.988 (perp=8.482, rec=0.058, cos=0.234), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.999 (perp=8.482, rec=0.068, cos=0.235), tot_loss_proj:2.340 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.996 (perp=8.482, rec=0.065, cos=0.235), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.990 (perp=8.482, rec=0.061, cos=0.233), tot_loss_proj:2.337 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.988 (perp=8.482, rec=0.058, cos=0.233), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.995 (perp=8.482, rec=0.066, cos=0.233), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.997 (perp=8.482, rec=0.066, cos=0.234), tot_loss_proj:2.341 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.992 (perp=8.482, rec=0.061, cos=0.234), tot_loss_proj:2.341 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.996 (perp=8.482, rec=0.065, cos=0.235), tot_loss_proj:2.334 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.994 (perp=8.482, rec=0.063, cos=0.234), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.987 (perp=8.482, rec=0.057, cos=0.233), tot_loss_proj:2.340 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.990 (perp=8.482, rec=0.061, cos=0.233), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.992 (perp=8.482, rec=0.062, cos=0.234), tot_loss_proj:2.334 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.988 (perp=8.482, rec=0.058, cos=0.234), tot_loss_proj:2.341 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=2.001 (perp=8.482, rec=0.070, cos=0.234), tot_loss_proj:2.335 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.987 (perp=8.482, rec=0.056, cos=0.234), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=2.007 (perp=8.482, rec=0.076, cos=0.234), tot_loss_proj:2.341 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.993 (perp=8.482, rec=0.062, cos=0.234), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.998 (perp=8.482, rec=0.067, cos=0.234), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.993 (perp=8.482, rec=0.062, cos=0.235), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.993 (perp=8.482, rec=0.062, cos=0.235), tot_loss_proj:2.341 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.989 (perp=8.482, rec=0.058, cos=0.234), tot_loss_proj:2.340 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.994 (perp=8.482, rec=0.063, cos=0.234), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.996 (perp=8.482, rec=0.066, cos=0.234), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=2.000 (perp=8.482, rec=0.070, cos=0.234), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.994 (perp=8.482, rec=0.063, cos=0.235), tot_loss_proj:2.332 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.993 (perp=8.482, rec=0.063, cos=0.234), tot_loss_proj:2.337 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 90.157 | p: 89.522 | r: 90.924
rouge2     | fm: 55.900 | p: 55.542 | r: 56.360
rougeL     | fm: 78.570 | p: 77.965 | r: 79.318
rougeLsum  | fm: 78.437 | p: 77.822 | r: 79.163
r1fm+r2fm = 146.057

input #52 time: 0:08:40 | total time: 7:41:12


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9183175359790055
highest_index [0]
highest [0.9183175359790055]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.8155205249786377 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.8119897246360779 for ['[CLS] government cf [SEP]']
[Init] best rec loss: 0.8013271689414978 for ['[CLS] manga rise [SEP]']
[Init] best rec loss: 0.7119802832603455 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.7079078555107117 for ['[CLS] annually ability [SEP]']
[Init] best rec loss: 0.6806497573852539 for ['[CLS] praising won [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.842 (perp=12.493, rec=0.202, cos=0.141), tot_loss_proj:3.380 [t=0.22s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=2.741 (perp=12.414, rec=0.104, cos=0.154), tot_loss_proj:3.326 [t=0.22s]
prediction: ['[CLS]ing flinch [SEP]']
[ 150/2000] tot_loss=2.707 (perp=12.414, rec=0.069, cos=0.155), tot_loss_proj:3.330 [t=0.22s]
prediction: ['[CLS]ing flinch [SEP]']
[ 200/2000] tot_loss=2.719 (perp=12.414, rec=0.079, cos=0.157), tot_loss_proj:3.328 [t=0.22s]
prediction: ['[CLS]ing flinch [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.842 (perp=8.090, rec=0.071, cos=0.153), tot_loss_proj:1.887 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.834 (perp=8.090, rec=0.060, cos=0.156), tot_loss_proj:1.877 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.830 (perp=8.090, rec=0.059, cos=0.153), tot_loss_proj:1.878 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.837 (perp=8.090, rec=0.061, cos=0.158), tot_loss_proj:1.884 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.851 (perp=8.090, rec=0.077, cos=0.155), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.830 (perp=8.090, rec=0.061, cos=0.151), tot_loss_proj:1.871 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.832 (perp=8.090, rec=0.065, cos=0.150), tot_loss_proj:1.874 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.833 (perp=8.090, rec=0.063, cos=0.152), tot_loss_proj:1.877 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.840 (perp=8.090, rec=0.066, cos=0.156), tot_loss_proj:1.877 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.858 (perp=8.090, rec=0.081, cos=0.159), tot_loss_proj:1.876 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.835 (perp=8.090, rec=0.065, cos=0.152), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.833 (perp=8.090, rec=0.057, cos=0.158), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.841 (perp=8.090, rec=0.068, cos=0.155), tot_loss_proj:1.866 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.842 (perp=8.090, rec=0.072, cos=0.152), tot_loss_proj:1.878 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.839 (perp=8.090, rec=0.064, cos=0.157), tot_loss_proj:1.875 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.835 (perp=8.090, rec=0.064, cos=0.152), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.834 (perp=8.090, rec=0.059, cos=0.157), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.829 (perp=8.090, rec=0.057, cos=0.154), tot_loss_proj:1.866 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.828 (perp=8.090, rec=0.057, cos=0.153), tot_loss_proj:1.874 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.834 (perp=8.090, rec=0.062, cos=0.154), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.838 (perp=8.090, rec=0.064, cos=0.156), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.837 (perp=8.090, rec=0.064, cos=0.155), tot_loss_proj:1.871 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.839 (perp=8.090, rec=0.065, cos=0.155), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.840 (perp=8.090, rec=0.068, cos=0.154), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.841 (perp=8.090, rec=0.066, cos=0.157), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.846 (perp=8.090, rec=0.072, cos=0.156), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.840 (perp=8.090, rec=0.066, cos=0.156), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.838 (perp=8.090, rec=0.065, cos=0.155), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.838 (perp=8.090, rec=0.065, cos=0.155), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.833 (perp=8.090, rec=0.059, cos=0.156), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.833 (perp=8.090, rec=0.059, cos=0.155), tot_loss_proj:1.866 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.834 (perp=8.090, rec=0.061, cos=0.155), tot_loss_proj:1.866 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.847 (perp=8.090, rec=0.073, cos=0.156), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.832 (perp=8.090, rec=0.059, cos=0.155), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.841 (perp=8.090, rec=0.069, cos=0.155), tot_loss_proj:1.867 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.842 (perp=8.090, rec=0.069, cos=0.155), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.374 | p: 89.690 | r: 91.147
rouge2     | fm: 56.625 | p: 56.211 | r: 56.997
rougeL     | fm: 79.007 | p: 78.416 | r: 79.679
rougeLsum  | fm: 78.937 | p: 78.331 | r: 79.596
r1fm+r2fm = 146.999

input #53 time: 0:08:37 | total time: 7:49:49


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.8487028030407944
highest_index [0]
highest [0.8487028030407944]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.7834962010383606 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.7770178318023682 for ['[CLS] ally strategy [SEP]']
[Init] best rec loss: 0.7438188791275024 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 0.697965145111084 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.69533771276474 for ['[CLS]sil shall [SEP]']
[Init] best rec loss: 0.6690764427185059 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.6588568091392517 for ['[CLS] deployment bro [SEP]']
[Init] best rec loss: 0.6497533321380615 for ['[CLS] teresa spanish [SEP]']
[Init] best rec loss: 0.6388990879058838 for ['[CLS] wild exercised [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.168 (perp=8.197, rec=0.244, cos=0.284), tot_loss_proj:2.017 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 100/2000] tot_loss=2.022 (perp=8.197, rec=0.099, cos=0.284), tot_loss_proj:2.006 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=1.987 (perp=8.197, rec=0.070, cos=0.277), tot_loss_proj:1.997 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=1.988 (perp=8.197, rec=0.071, cos=0.278), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.992 (perp=8.197, rec=0.073, cos=0.280), tot_loss_proj:2.011 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=2.006 (perp=8.197, rec=0.085, cos=0.282), tot_loss_proj:2.007 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.976 (perp=8.197, rec=0.062, cos=0.275), tot_loss_proj:2.011 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.983 (perp=8.197, rec=0.068, cos=0.275), tot_loss_proj:2.005 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.974 (perp=8.197, rec=0.066, cos=0.268), tot_loss_proj:2.012 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.984 (perp=8.197, rec=0.072, cos=0.272), tot_loss_proj:2.023 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.974 (perp=8.197, rec=0.062, cos=0.273), tot_loss_proj:2.009 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.978 (perp=8.197, rec=0.059, cos=0.279), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.972 (perp=8.197, rec=0.060, cos=0.272), tot_loss_proj:2.016 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.972 (perp=8.197, rec=0.054, cos=0.279), tot_loss_proj:2.019 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.969 (perp=8.197, rec=0.054, cos=0.275), tot_loss_proj:2.014 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.981 (perp=8.197, rec=0.060, cos=0.281), tot_loss_proj:2.017 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.981 (perp=8.197, rec=0.065, cos=0.276), tot_loss_proj:2.017 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.980 (perp=8.197, rec=0.064, cos=0.277), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.975 (perp=8.197, rec=0.056, cos=0.280), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.986 (perp=8.197, rec=0.067, cos=0.279), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.985 (perp=8.197, rec=0.067, cos=0.278), tot_loss_proj:2.012 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.979 (perp=8.197, rec=0.064, cos=0.275), tot_loss_proj:2.010 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.973 (perp=8.197, rec=0.057, cos=0.277), tot_loss_proj:2.014 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.990 (perp=8.197, rec=0.071, cos=0.279), tot_loss_proj:2.014 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.968 (perp=8.197, rec=0.052, cos=0.276), tot_loss_proj:2.012 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.975 (perp=8.197, rec=0.060, cos=0.276), tot_loss_proj:2.016 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.983 (perp=8.197, rec=0.065, cos=0.279), tot_loss_proj:2.011 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.978 (perp=8.197, rec=0.060, cos=0.279), tot_loss_proj:2.011 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.972 (perp=8.197, rec=0.053, cos=0.279), tot_loss_proj:2.014 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.973 (perp=8.197, rec=0.056, cos=0.277), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.974 (perp=8.197, rec=0.057, cos=0.278), tot_loss_proj:2.016 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.977 (perp=8.197, rec=0.059, cos=0.278), tot_loss_proj:2.014 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.973 (perp=8.197, rec=0.056, cos=0.278), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.981 (perp=8.197, rec=0.064, cos=0.278), tot_loss_proj:2.016 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.977 (perp=8.197, rec=0.060, cos=0.278), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.977 (perp=8.197, rec=0.059, cos=0.279), tot_loss_proj:2.008 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.980 (perp=8.197, rec=0.062, cos=0.278), tot_loss_proj:2.017 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.983 (perp=8.197, rec=0.065, cos=0.279), tot_loss_proj:2.008 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.979 (perp=8.197, rec=0.062, cos=0.278), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.984 (perp=8.197, rec=0.067, cos=0.278), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.500 | p: 89.893 | r: 91.240
rouge2     | fm: 57.652 | p: 57.233 | r: 58.147
rougeL     | fm: 79.289 | p: 78.777 | r: 79.939
rougeLsum  | fm: 79.184 | p: 78.682 | r: 79.821
r1fm+r2fm = 148.152

input #54 time: 0:08:17 | total time: 7:58:07


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9162885329049939
highest_index [0]
highest [0.9162885329049939]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.8537937998771667 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.7427657246589661 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7366345524787903 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7296271324157715 for ['[CLS] beneath besides milo [SEP]']
[Init] best rec loss: 0.7188280820846558 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.708059549331665 for ['[CLS] top trades events [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.531 (perp=10.045, rec=0.338, cos=0.184), tot_loss_proj:3.457 [t=0.21s]
prediction: ['[CLS] settles easily settle [SEP]']
[ 100/2000] tot_loss=2.036 (perp=8.688, rec=0.143, cos=0.155), tot_loss_proj:2.336 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[ 150/2000] tot_loss=1.969 (perp=8.688, rec=0.079, cos=0.153), tot_loss_proj:2.339 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[ 200/2000] tot_loss=1.973 (perp=8.688, rec=0.081, cos=0.154), tot_loss_proj:2.345 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.966 (perp=8.688, rec=0.076, cos=0.153), tot_loss_proj:2.348 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[ 300/2000] tot_loss=1.973 (perp=8.688, rec=0.079, cos=0.156), tot_loss_proj:2.345 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.972 (perp=8.688, rec=0.072, cos=0.163), tot_loss_proj:2.346 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.959 (perp=8.688, rec=0.070, cos=0.152), tot_loss_proj:2.354 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[ 450/2000] tot_loss=1.959 (perp=8.688, rec=0.062, cos=0.159), tot_loss_proj:2.350 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.957 (perp=8.688, rec=0.063, cos=0.156), tot_loss_proj:2.352 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.964 (perp=8.688, rec=0.070, cos=0.156), tot_loss_proj:2.348 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[ 600/2000] tot_loss=1.958 (perp=8.688, rec=0.063, cos=0.157), tot_loss_proj:2.344 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.956 (perp=8.688, rec=0.062, cos=0.156), tot_loss_proj:2.355 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.972 (perp=8.688, rec=0.074, cos=0.161), tot_loss_proj:2.355 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[ 750/2000] tot_loss=1.958 (perp=8.688, rec=0.065, cos=0.155), tot_loss_proj:2.350 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.955 (perp=8.688, rec=0.062, cos=0.156), tot_loss_proj:2.348 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.971 (perp=8.688, rec=0.076, cos=0.158), tot_loss_proj:2.352 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[ 900/2000] tot_loss=1.963 (perp=8.688, rec=0.067, cos=0.158), tot_loss_proj:2.351 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.959 (perp=8.688, rec=0.064, cos=0.158), tot_loss_proj:2.348 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1000/2000] tot_loss=1.955 (perp=8.688, rec=0.062, cos=0.156), tot_loss_proj:2.352 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[1050/2000] tot_loss=1.956 (perp=8.688, rec=0.062, cos=0.156), tot_loss_proj:2.354 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1100/2000] tot_loss=1.963 (perp=8.688, rec=0.066, cos=0.159), tot_loss_proj:2.352 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1150/2000] tot_loss=1.962 (perp=8.688, rec=0.065, cos=0.159), tot_loss_proj:2.354 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[1200/2000] tot_loss=1.957 (perp=8.688, rec=0.061, cos=0.159), tot_loss_proj:2.361 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1250/2000] tot_loss=1.967 (perp=8.688, rec=0.070, cos=0.159), tot_loss_proj:2.359 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1300/2000] tot_loss=1.953 (perp=8.688, rec=0.057, cos=0.159), tot_loss_proj:2.352 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[1350/2000] tot_loss=1.958 (perp=8.688, rec=0.062, cos=0.158), tot_loss_proj:2.350 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1400/2000] tot_loss=1.959 (perp=8.688, rec=0.063, cos=0.159), tot_loss_proj:2.356 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1450/2000] tot_loss=1.965 (perp=8.688, rec=0.068, cos=0.159), tot_loss_proj:2.354 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[1500/2000] tot_loss=1.966 (perp=8.688, rec=0.069, cos=0.160), tot_loss_proj:2.353 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1550/2000] tot_loss=1.971 (perp=8.688, rec=0.076, cos=0.158), tot_loss_proj:2.350 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1600/2000] tot_loss=1.956 (perp=8.688, rec=0.060, cos=0.158), tot_loss_proj:2.353 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[1650/2000] tot_loss=1.965 (perp=8.688, rec=0.069, cos=0.159), tot_loss_proj:2.361 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1700/2000] tot_loss=1.959 (perp=8.688, rec=0.062, cos=0.160), tot_loss_proj:2.359 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1750/2000] tot_loss=1.956 (perp=8.688, rec=0.060, cos=0.158), tot_loss_proj:2.353 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[1800/2000] tot_loss=1.962 (perp=8.688, rec=0.066, cos=0.158), tot_loss_proj:2.352 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1850/2000] tot_loss=1.960 (perp=8.688, rec=0.062, cos=0.160), tot_loss_proj:2.351 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1900/2000] tot_loss=1.960 (perp=8.688, rec=0.062, cos=0.160), tot_loss_proj:2.359 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[1950/2000] tot_loss=1.960 (perp=8.688, rec=0.062, cos=0.160), tot_loss_proj:2.356 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[2000/2000] tot_loss=1.963 (perp=8.688, rec=0.066, cos=0.159), tot_loss_proj:2.357 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] too easily settles [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 90.717 | p: 90.122 | r: 91.514
rouge2     | fm: 56.985 | p: 56.618 | r: 57.396
rougeL     | fm: 79.273 | p: 78.763 | r: 79.965
rougeLsum  | fm: 79.287 | p: 78.678 | r: 79.896
r1fm+r2fm = 147.702

input #55 time: 0:08:20 | total time: 8:06:28


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.8895355593122312
highest_index [0]
highest [0.8895355593122312]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.8433167338371277 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.8234089612960815 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.8194695115089417 for ['[CLS]ett radio blu division batons favor conservativegue both reading mclaren isolation pepmmer entertainmentignant age railway dive clashes [SEP]']
[Init] best perm rec loss: 0.8192166686058044 for ['[CLS]ons clashes railway mclarenignantgue reading division bothmmer blu pep favor bat radio age dive entertainmentett isolation conservative [SEP]']
[Init] best perm rec loss: 0.8181161880493164 for ['[CLS] radio batmmer entertainmentgue reading favor mclaren division conservative clashes railway isolation blu pep age bothonsett diveignant [SEP]']
[Init] best perm rec loss: 0.8169172406196594 for ['[CLS] radio favorons railway conservative bothettmmer ageignant clashes isolation reading division mclaren pep dive blu entertainment batgue [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.932 (perp=12.144, rec=0.298, cos=0.206), tot_loss_proj:3.810 [t=0.22s]
prediction: ['[CLS] camera activities centuries damage ( finnish analysis damage costly tomorrow descriptions damage damage public damage trouble decades nasty. greatest reissue [SEP]']
[ 100/2000] tot_loss=2.687 (perp=11.219, rec=0.233, cos=0.210), tot_loss_proj:3.464 [t=0.22s]
prediction: ['[CLS] films films decades damage ( costly analysis damage fix need films damage damage will damage battle decades costly that greatest test [SEP]']
[ 150/2000] tot_loss=2.483 (perp=10.443, rec=0.193, cos=0.201), tot_loss_proj:3.095 [t=0.22s]
prediction: ['[CLS] films films were loads ; costly analysis damage fix need analysis damage damage will damage analysis decades costly that never subsequent [SEP]']
[ 200/2000] tot_loss=2.472 (perp=10.497, rec=0.168, cos=0.205), tot_loss_proj:3.667 [t=0.22s]
prediction: ['[CLS] films which could loads years costly analysis damage fix that analysis never damage will damage of decades costly of might resulting [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.216 (perp=9.309, rec=0.150, cos=0.205), tot_loss_proj:2.916 [t=0.22s]
prediction: ['[CLS] films which could loads of costly analysis damage fix that analysis could caused will damage could decades costly years never must [SEP]']
[ 300/2000] tot_loss=2.152 (perp=9.050, rec=0.135, cos=0.207), tot_loss_proj:2.907 [t=0.22s]
prediction: ['[CLS] films which could loads of costly analysis damage fix that analysis could caused will damage could cannot costly years never analysis [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.221 (perp=9.395, rec=0.136, cos=0.206), tot_loss_proj:2.827 [t=0.22s]
prediction: ['[CLS] films which could loads and costly analysis damage fix that could cause will damage could years costly analysis years cause occurring [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.047 (perp=8.534, rec=0.134, cos=0.207), tot_loss_proj:2.699 [t=0.23s]
prediction: ['[CLS] films which could cause loads and costly analysis damage fix that could cause will damage could years costly analysis years years [SEP]']
[ 450/2000] tot_loss=2.167 (perp=9.240, rec=0.114, cos=0.205), tot_loss_proj:2.929 [t=0.22s]
prediction: ['[CLS] films which of cause loads and costly analysis damage fix that could cause will damage could years costly analysis years years [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.330 (perp=10.085, rec=0.107, cos=0.206), tot_loss_proj:3.241 [t=0.22s]
prediction: ['[CLS] films whichpara cause years and costly analysis damage fix that couldble will damage never years costly analysis loads years [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.243 (perp=9.628, rec=0.114, cos=0.204), tot_loss_proj:3.222 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage years and costly analysis damage fix that couldble will never years costly analysis loads years [SEP]']
[ 600/2000] tot_loss=2.238 (perp=9.628, rec=0.106, cos=0.206), tot_loss_proj:3.213 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage years and costly analysis damage fix that couldble will never years costly analysis loads years [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.257 (perp=9.718, rec=0.109, cos=0.204), tot_loss_proj:3.214 [t=0.22s]
prediction: ['[CLS] films whichpara of cause damage years and costly analysis damage fix that could will never years costly analysis loads years [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.084 (perp=8.840, rec=0.109, cos=0.207), tot_loss_proj:2.904 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage years and costly analysis damage fix that could will never of years costly analysis loads years [SEP]']
[ 750/2000] tot_loss=2.076 (perp=8.840, rec=0.101, cos=0.206), tot_loss_proj:2.904 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage years and costly analysis damage fix that could will never of years costly analysis loads years [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.002 (perp=8.486, rec=0.097, cos=0.207), tot_loss_proj:2.849 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never of years costly analysis loads years [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.995 (perp=8.486, rec=0.091, cos=0.207), tot_loss_proj:2.845 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never of years costly analysis loads years [SEP]']
[ 900/2000] tot_loss=1.991 (perp=8.486, rec=0.088, cos=0.206), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never of years costly analysis loads years [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.983 (perp=8.486, rec=0.081, cos=0.205), tot_loss_proj:2.847 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never of years costly analysis loads years [SEP]']
Attempt swap
[1000/2000] tot_loss=1.993 (perp=8.486, rec=0.090, cos=0.207), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never of years costly analysis loads years [SEP]']
[1050/2000] tot_loss=1.996 (perp=8.486, rec=0.093, cos=0.206), tot_loss_proj:2.843 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never of years costly analysis loads years [SEP]']
Attempt swap
[1100/2000] tot_loss=1.994 (perp=8.486, rec=0.092, cos=0.205), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never of years costly analysis loads years [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.959 (perp=8.330, rec=0.087, cos=0.205), tot_loss_proj:3.010 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never years of costly analysis loads years [SEP]']
[1200/2000] tot_loss=1.965 (perp=8.330, rec=0.094, cos=0.205), tot_loss_proj:3.011 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never years of costly analysis loads years [SEP]']
Attempt swap
[1250/2000] tot_loss=1.964 (perp=8.330, rec=0.092, cos=0.206), tot_loss_proj:3.011 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never years of costly analysis loads years [SEP]']
Attempt swap
[1300/2000] tot_loss=1.958 (perp=8.330, rec=0.087, cos=0.205), tot_loss_proj:3.010 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never years of costly analysis loads years [SEP]']
[1350/2000] tot_loss=1.956 (perp=8.330, rec=0.085, cos=0.205), tot_loss_proj:3.008 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never years of costly analysis loads years [SEP]']
Attempt swap
[1400/2000] tot_loss=1.961 (perp=8.330, rec=0.089, cos=0.206), tot_loss_proj:3.011 [t=0.22s]
prediction: ['[CLS] films whichpara cause damage will years and costly analysis damage fix that could never years of costly analysis loads years [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.921 (perp=8.122, rec=0.090, cos=0.206), tot_loss_proj:2.870 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
[1500/2000] tot_loss=1.920 (perp=8.122, rec=0.090, cos=0.206), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
Attempt swap
[1550/2000] tot_loss=1.919 (perp=8.122, rec=0.089, cos=0.206), tot_loss_proj:2.873 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
Attempt swap
[1600/2000] tot_loss=1.916 (perp=8.122, rec=0.085, cos=0.206), tot_loss_proj:2.870 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
[1650/2000] tot_loss=1.921 (perp=8.122, rec=0.091, cos=0.206), tot_loss_proj:2.871 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
Attempt swap
[1700/2000] tot_loss=1.917 (perp=8.122, rec=0.087, cos=0.206), tot_loss_proj:2.870 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
Attempt swap
[1750/2000] tot_loss=1.918 (perp=8.122, rec=0.088, cos=0.206), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
[1800/2000] tot_loss=1.916 (perp=8.122, rec=0.086, cos=0.206), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
Attempt swap
[1850/2000] tot_loss=1.918 (perp=8.122, rec=0.088, cos=0.206), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
Attempt swap
[1900/2000] tot_loss=1.916 (perp=8.122, rec=0.086, cos=0.206), tot_loss_proj:2.870 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
[1950/2000] tot_loss=1.923 (perp=8.122, rec=0.093, cos=0.205), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
Attempt swap
[2000/2000] tot_loss=1.918 (perp=8.122, rec=0.088, cos=0.205), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] films which fixpara cause damage will years and costly analysis damage that could never years of costly analysis loads years [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] films whichpara cause damage will years and costly analysis damage fix that could never years of costly analysis loads years [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.952 | p: 77.273 | r: 85.000
rouge2     | fm: 30.000 | p: 28.571 | r: 31.579
rougeL     | fm: 52.381 | p: 50.000 | r: 55.000
rougeLsum  | fm: 52.381 | p: 50.000 | r: 55.000
r1fm+r2fm = 110.952

[Aggregate metrics]:
rouge1     | fm: 90.558 | p: 89.852 | r: 91.373
rouge2     | fm: 56.676 | p: 56.238 | r: 57.233
rougeL     | fm: 78.899 | p: 78.360 | r: 79.639
rougeLsum  | fm: 78.718 | p: 78.179 | r: 79.436
r1fm+r2fm = 147.234

input #56 time: 0:08:47 | total time: 8:15:15


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9118805952900182
highest_index [0]
highest [0.9118805952900182]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8738974332809448 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.85801100730896 for ['[CLS] their [SEP]']
[Init] best rec loss: 0.8086246252059937 for ['[CLS]on [SEP]']
[Init] best rec loss: 0.7513803839683533 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.686060905456543 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6849400401115417 for ['[CLS] modern [SEP]']
[Init] best rec loss: 0.682188868522644 for ['[CLS] silk [SEP]']
[Init] best rec loss: 0.6782902479171753 for ['[CLS] beethoven [SEP]']
[Init] best rec loss: 0.6582018136978149 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.762 (perp=12.282, rec=0.116, cos=0.189), tot_loss_proj:2.692 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.691 (perp=12.282, rec=0.068, cos=0.166), tot_loss_proj:2.686 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.703 (perp=12.282, rec=0.080, cos=0.166), tot_loss_proj:2.690 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.693 (perp=12.282, rec=0.064, cos=0.172), tot_loss_proj:2.679 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.693 (perp=12.282, rec=0.072, cos=0.165), tot_loss_proj:2.677 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.676 (perp=12.282, rec=0.055, cos=0.165), tot_loss_proj:2.689 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.685 (perp=12.282, rec=0.062, cos=0.166), tot_loss_proj:2.686 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.674 (perp=12.282, rec=0.051, cos=0.166), tot_loss_proj:2.692 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.686 (perp=12.282, rec=0.065, cos=0.165), tot_loss_proj:2.687 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.678 (perp=12.282, rec=0.056, cos=0.166), tot_loss_proj:2.684 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.679 (perp=12.282, rec=0.055, cos=0.167), tot_loss_proj:2.683 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.687 (perp=12.282, rec=0.065, cos=0.165), tot_loss_proj:2.696 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.684 (perp=12.282, rec=0.060, cos=0.168), tot_loss_proj:2.687 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.690 (perp=12.282, rec=0.066, cos=0.168), tot_loss_proj:2.684 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.684 (perp=12.282, rec=0.062, cos=0.166), tot_loss_proj:2.684 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.682 (perp=12.282, rec=0.059, cos=0.167), tot_loss_proj:2.688 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.690 (perp=12.282, rec=0.065, cos=0.168), tot_loss_proj:2.675 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.692 (perp=12.282, rec=0.067, cos=0.168), tot_loss_proj:2.687 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.685 (perp=12.282, rec=0.061, cos=0.168), tot_loss_proj:2.692 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.676 (perp=12.282, rec=0.055, cos=0.165), tot_loss_proj:2.689 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.682 (perp=12.282, rec=0.058, cos=0.167), tot_loss_proj:2.678 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.684 (perp=12.282, rec=0.060, cos=0.168), tot_loss_proj:2.682 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.689 (perp=12.282, rec=0.066, cos=0.167), tot_loss_proj:2.678 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.674 (perp=12.282, rec=0.052, cos=0.166), tot_loss_proj:2.686 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.693 (perp=12.282, rec=0.068, cos=0.169), tot_loss_proj:2.689 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.677 (perp=12.282, rec=0.054, cos=0.167), tot_loss_proj:2.682 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.678 (perp=12.282, rec=0.055, cos=0.167), tot_loss_proj:2.676 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.685 (perp=12.282, rec=0.061, cos=0.168), tot_loss_proj:2.697 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.693 (perp=12.282, rec=0.070, cos=0.167), tot_loss_proj:2.683 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.683 (perp=12.282, rec=0.060, cos=0.167), tot_loss_proj:2.680 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.691 (perp=12.282, rec=0.068, cos=0.167), tot_loss_proj:2.681 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.690 (perp=12.282, rec=0.066, cos=0.168), tot_loss_proj:2.684 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.686 (perp=12.282, rec=0.062, cos=0.168), tot_loss_proj:2.676 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.691 (perp=12.282, rec=0.067, cos=0.167), tot_loss_proj:2.681 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.681 (perp=12.282, rec=0.057, cos=0.167), tot_loss_proj:2.699 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.676 (perp=12.282, rec=0.053, cos=0.168), tot_loss_proj:2.686 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.683 (perp=12.282, rec=0.060, cos=0.167), tot_loss_proj:2.679 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.686 (perp=12.282, rec=0.061, cos=0.168), tot_loss_proj:2.683 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.691 (perp=12.282, rec=0.067, cos=0.168), tot_loss_proj:2.683 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.688 (perp=12.282, rec=0.064, cos=0.168), tot_loss_proj:2.678 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.670 | p: 90.003 | r: 91.443
rouge2     | fm: 57.454 | p: 57.024 | r: 57.937
rougeL     | fm: 79.122 | p: 78.538 | r: 79.879
rougeLsum  | fm: 79.156 | p: 78.560 | r: 79.847
r1fm+r2fm = 148.123

input #57 time: 0:08:21 | total time: 8:23:36


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.8117898546804678
highest_index [0]
highest [0.8117898546804678]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.0208585262298584 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9979770183563232 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9841768145561218 for ['[CLS] things reggie on guinnessllet continue special the chan (ness grew prone moffatockshire [SEP]']
[Init] best rec loss: 0.9804369211196899 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9691516757011414 for ['[CLS] partner kickoff message oh hills edge wind mono stainless few sk closet clay fair ole port [SEP]']
[Init] best rec loss: 0.9615495204925537 for ['[CLS] ) after rca adventures / yong beat bad http stoodagendingple ]erson trailing [SEP]']
[Init] best rec loss: 0.9586862921714783 for ['[CLS] sure tel china lose neutral central never an there after louis concentratione jack boysnted [SEP]']
[Init] best rec loss: 0.9452750086784363 for ['[CLS] shield anything damon venom sitting led trumppole purdue bigاural failed proposal sketch lea [SEP]']
[Init] best rec loss: 0.939184308052063 for ['[CLS] bellsignant river animals don cracked ace behind lid tasha des aden reception add bu fully [SEP]']
[Init] best rec loss: 0.9383697509765625 for ['[CLS] commissioned table evelyn imp officially mall spring aquacratic average caf west newgrin advantage how [SEP]']
[Init] best perm rec loss: 0.9374483227729797 for ['[CLS]grin officially average west evelyn aqua spring new impcratic how commissioned advantage caf mall table [SEP]']
[Init] best perm rec loss: 0.9372295141220093 for ['[CLS] mallcratic springgrin imp officially commissioned table advantage how west new caf evelyn aqua average [SEP]']
[Init] best perm rec loss: 0.9368656873703003 for ['[CLS] officially how imp cafgrin spring commissioned evelyn west aqua new advantage average mallcratic table [SEP]']
[Init] best perm rec loss: 0.9348680377006531 for ['[CLS] average new mall aqua west spring advantage commissioned evelyn imp table howgrin cafcratic officially [SEP]']
[Init] best perm rec loss: 0.9335887432098389 for ['[CLS] average newgrin tablecratic officially spring how west caf mall imp evelyn aqua commissioned advantage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.510 (perp=11.970, rec=0.623, cos=0.493), tot_loss_proj:4.296 [t=0.21s]
prediction: ["[CLS] pits israeli italian by is the decades'a soul scaryd shit smooth order alessandro [SEP]"]
[ 100/2000] tot_loss=3.101 (perp=11.128, rec=0.525, cos=0.351), tot_loss_proj:4.210 [t=0.21s]
prediction: ['[CLS] turns thesis innocence by is the life really a playstation scary narrative fiction mailly alessandro [SEP]']
[ 150/2000] tot_loss=3.719 (perp=12.851, rec=0.604, cos=0.545), tot_loss_proj:4.568 [t=0.21s]
prediction: ['[CLS]ens feminist existing by rests popular environment dinner its liter of fiction forces organisation hitler prodigy [SEP]']
[ 200/2000] tot_loss=3.068 (perp=10.424, rec=0.548, cos=0.435), tot_loss_proj:3.847 [t=0.21s]
prediction: ['[CLS] days deserve existent saddam is the environment dinner a playstation of logic work enough issue podium [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.049 (perp=11.352, rec=0.446, cos=0.333), tot_loss_proj:4.195 [t=0.21s]
prediction: ['[CLS] surreal deserve him existing is the environment dinner a liter of confederate this prize analysis opportunity [SEP]']
[ 300/2000] tot_loss=3.423 (perp=13.598, rec=0.418, cos=0.285), tot_loss_proj:4.666 [t=0.21s]
prediction: ['[CLS] median leo him innocent is when environment dinner anxa of confederate aid fabricated question eclipse [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.313 (perp=12.877, rec=0.396, cos=0.342), tot_loss_proj:4.554 [t=0.21s]
prediction: ['[CLS] median environment him amber is when mosaic dinner an innocence of impression useful fabricated story eclipse [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=3.384 (perp=13.203, rec=0.462, cos=0.282), tot_loss_proj:4.526 [t=0.21s]
prediction: ['[CLS] settlers described environment is amber earliest when probation def an despite honor impression human whether oblast [SEP]']
[ 450/2000] tot_loss=3.406 (perp=13.417, rec=0.397, cos=0.325), tot_loss_proj:4.668 [t=0.21s]
prediction: ['[CLS] settlers described environment puts amber earliest whenless def an innocence fictional realism [SEP] combines story [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.269 (perp=12.843, rec=0.380, cos=0.321), tot_loss_proj:4.569 [t=0.21s]
prediction: ['[CLS] settlers described environment puts literacy story whenlessward an otherwise honor impression defpta story [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.068 (perp=11.761, rec=0.371, cos=0.344), tot_loss_proj:3.999 [t=0.21s]
prediction: ['[CLS] hugh described environment puts fictional story inspirational metaphor capturing an otherwise innocence impressionaceous schuster story [SEP]']
[ 600/2000] tot_loss=3.094 (perp=12.060, rec=0.355, cos=0.326), tot_loss_proj:3.895 [t=0.21s]
prediction: ['[CLS] hugh described environment puts fictional story inspirational suggestions capturing the differed innocence impressionaceous schuster story [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.032 (perp=11.632, rec=0.348, cos=0.357), tot_loss_proj:3.955 [t=0.21s]
prediction: ['[CLS] hugh described environment puts fictional inspirational story metaphor capturing the differed innocence impressionaceous maiden story [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.701 (perp=10.386, rec=0.345, cos=0.279), tot_loss_proj:3.698 [t=0.21s]
prediction: ['[CLS] settlers described inspirational is hardcore inspirational story achievements capturing the differed metaphor impressionaceous maiden story [SEP]']
[ 750/2000] tot_loss=3.123 (perp=11.319, rec=0.354, cos=0.505), tot_loss_proj:4.091 [t=0.21s]
prediction: ['[CLS] settlers described inspirational is hardcore inspirational story elderly capturing the differed suggestions impressionaceous constructed story [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.741 (perp=10.559, rec=0.332, cos=0.297), tot_loss_proj:3.713 [t=0.21s]
prediction: ['[CLS] settlers described inspirational is video inspirational story achievements capturing the differed maiden impressionaceous reward story [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.844 (perp=10.903, rec=0.333, cos=0.331), tot_loss_proj:3.712 [t=0.21s]
prediction: ['[CLS] settlers described inspirational puts inspirational video story achievements capturing the differed constructed impressionaceous reward story [SEP]']
[ 900/2000] tot_loss=2.722 (perp=10.384, rec=0.316, cos=0.329), tot_loss_proj:3.774 [t=0.21s]
prediction: ['[CLS] settlers described inspirational is inspirational cause story < capturing the differed constructed impressionaceous reward story [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.787 (perp=10.628, rec=0.316, cos=0.345), tot_loss_proj:3.816 [t=0.21s]
prediction: ['[CLS] settlers described inspirational is inspirational cause story < capturing the differed constructed realismaceous reward story [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.084 (perp=11.443, rec=0.409, cos=0.387), tot_loss_proj:3.636 [t=0.21s]
prediction: ['[CLS] sidney describedneck is inspirational inspirational story valued capturing the differed bingham emotionaceous reward story [SEP]']
[1050/2000] tot_loss=2.971 (perp=11.435, rec=0.350, cos=0.333), tot_loss_proj:3.694 [t=0.21s]
prediction: ['[CLS] sidney describedneck is inspirational inspirational story valued capturing the differed bingham realismaceous ass story [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.872 (perp=11.034, rec=0.339, cos=0.326), tot_loss_proj:3.726 [t=0.21s]
prediction: ['[CLS] sidney valuedneck is inspirational inspirational story described capturing the differed maiden realismaceous ass story [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.778 (perp=10.663, rec=0.332, cos=0.313), tot_loss_proj:3.855 [t=0.21s]
prediction: ['[CLS] settlers maidenneck is inspirational inspirational story described capturing the differed elderly realismaceous ass story [SEP]']
[1200/2000] tot_loss=2.803 (perp=10.779, rec=0.326, cos=0.321), tot_loss_proj:3.692 [t=0.21s]
prediction: ['[CLS] settlers maidenlike is inspirational inspirational story described capturing the differed arrival realismaceous ass story [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.921 (perp=11.340, rec=0.315, cos=0.338), tot_loss_proj:3.760 [t=0.21s]
prediction: ['[CLS] settlers exploitation cause is inspirational inspirational story described capturing the arrival differed realismaceous ass story [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.743 (perp=10.403, rec=0.320, cos=0.342), tot_loss_proj:3.686 [t=0.21s]
prediction: ['[CLS] settlers described cause is inspirational inspirational story exploitation capturing the arrival differed realismaceous ass story [SEP]']
[1350/2000] tot_loss=2.836 (perp=10.889, rec=0.318, cos=0.341), tot_loss_proj:3.575 [t=0.21s]
prediction: ['[CLS] settlers described cause is inspirational inspirational story exploitation capturing the arrival differed realismwhile reward story [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.779 (perp=10.642, rec=0.317, cos=0.333), tot_loss_proj:3.536 [t=0.21s]
prediction: ['[CLS] settlers described cause is inspirational inspirational story story capturing the arrival differed realismwhile ass exploitation [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.729 (perp=10.446, rec=0.316, cos=0.324), tot_loss_proj:3.479 [t=0.21s]
prediction: ['[CLS] settlers described cause is inspirational inspirational story story capturing the arrival differedwhile realism reward exploitation [SEP]']
[1500/2000] tot_loss=2.737 (perp=10.446, rec=0.314, cos=0.334), tot_loss_proj:3.472 [t=0.21s]
prediction: ['[CLS] settlers described cause is inspirational inspirational story story capturing the arrival differedwhile realism reward exploitation [SEP]']
Attempt swap
[1550/2000] tot_loss=2.724 (perp=10.446, rec=0.314, cos=0.321), tot_loss_proj:3.470 [t=0.21s]
prediction: ['[CLS] settlers described cause is inspirational inspirational story story capturing the arrival differedwhile realism reward exploitation [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.845 (perp=11.109, rec=0.318, cos=0.306), tot_loss_proj:3.643 [t=0.21s]
prediction: ['[CLS]while described cause is inspirational inspirational story story capturing the arrival differed settlers realism reward exploitation [SEP]']
[1650/2000] tot_loss=3.003 (perp=11.717, rec=0.316, cos=0.344), tot_loss_proj:3.732 [t=0.21s]
prediction: ['[CLS]aceous described cause is inspirational inspirational story story capturing the arrival differed settlers realism reward exploitation [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.767 (perp=10.602, rec=0.306, cos=0.341), tot_loss_proj:3.529 [t=0.21s]
prediction: ['[CLS] sidney described cause is inspirational inspirational story story capturing the arrival differedaceous realism reward exploitation [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.690 (perp=10.207, rec=0.314, cos=0.335), tot_loss_proj:3.621 [t=0.21s]
prediction: ['[CLS] sidney cause is described inspirational inspirational story story capturing the arrival differedaceous realism reward exploitation [SEP]']
[1800/2000] tot_loss=2.683 (perp=10.207, rec=0.307, cos=0.335), tot_loss_proj:3.620 [t=0.21s]
prediction: ['[CLS] sidney cause is described inspirational inspirational story story capturing the arrival differedaceous realism reward exploitation [SEP]']
Attempt swap
[1850/2000] tot_loss=2.690 (perp=10.207, rec=0.311, cos=0.338), tot_loss_proj:3.622 [t=0.21s]
prediction: ['[CLS] sidney cause is described inspirational inspirational story story capturing the arrival differedaceous realism reward exploitation [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.601 (perp=10.035, rec=0.315, cos=0.280), tot_loss_proj:3.557 [t=0.21s]
prediction: ['[CLS] sidney cause is described inspirational inspirational story story capturing the differedaceous arrival realism reward exploitation [SEP]']
[1950/2000] tot_loss=2.650 (perp=10.035, rec=0.308, cos=0.335), tot_loss_proj:3.554 [t=0.21s]
prediction: ['[CLS] sidney cause is described inspirational inspirational story story capturing the differedaceous arrival realism reward exploitation [SEP]']
Attempt swap
[2000/2000] tot_loss=2.655 (perp=10.035, rec=0.309, cos=0.339), tot_loss_proj:3.556 [t=0.21s]
prediction: ['[CLS] sidney cause is described inspirational inspirational story story capturing the differedaceous arrival realism reward exploitation [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] sidney cause is described inspirational inspirational story story capturing the arrival differedaceous realism reward exploitation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 42.424 | p: 41.176 | r: 43.750
rouge2     | fm: 12.903 | p: 12.500 | r: 13.333
rougeL     | fm: 42.424 | p: 41.176 | r: 43.750
rougeLsum  | fm: 42.424 | p: 41.176 | r: 43.750
r1fm+r2fm = 55.327

[Aggregate metrics]:
rouge1     | fm: 89.935 | p: 89.230 | r: 90.670
rouge2     | fm: 56.477 | p: 56.190 | r: 56.975
rougeL     | fm: 78.665 | p: 78.034 | r: 79.336
rougeLsum  | fm: 78.554 | p: 77.969 | r: 79.258
r1fm+r2fm = 146.411

input #58 time: 0:08:22 | total time: 8:31:59


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.8181975085290942
highest_index [0]
highest [0.8181975085290942]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.8962863683700562 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.8526655435562134 for ['[CLS] poll dominance intine drop silvertock politician wrappedve complete hot reading team disco world [SEP]']
[Init] best rec loss: 0.8457269072532654 for ['[CLS] mala minute theory mandatory stands after mere figure number roth sister locomotives bombay bavarian late athlete [SEP]']
[Init] best rec loss: 0.8264419436454773 for ['[CLS]notes urban shape atliest not filterae titled making prize wait sex ste front coach [SEP]']
[Init] best rec loss: 0.8045065402984619 for ['[CLS] key stafforddial done colony midst kmdden face ɾord muscle warning ( wife organic [SEP]']
[Init] best rec loss: 0.7908748388290405 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best rec loss: 0.775747537612915 for ['[CLS] creator war pepper mortal knights dinner warm helped tasting fringe vsonate cricket elitecoat counterpart [SEP]']
[Init] best perm rec loss: 0.7743217945098877 for ['[CLS]onate tasting counterpart warm creator knights peppercoat cricket war vs helped fringe elite mortal dinner [SEP]']
[Init] best perm rec loss: 0.773844838142395 for ['[CLS] vs war tasting elitecoatonate dinner knights warm helped fringe cricket counterpart pepper mortal creator [SEP]']
[Init] best perm rec loss: 0.7729830145835876 for ['[CLS] warm elite pepper vs counterpart mortalonate helpedcoat cricket creator dinner fringe tasting war knights [SEP]']
[Init] best perm rec loss: 0.7726293802261353 for ['[CLS] tasting fringe vsonate creator elite knightscoat cricket warm pepper mortal war counterpart helped dinner [SEP]']
[Init] best perm rec loss: 0.7721850275993347 for ['[CLS] pepper fringe creator elite war vs mortal counterpart dinner helped tasting knightsonate cricketcoat warm [SEP]']
[Init] best perm rec loss: 0.7708959579467773 for ['[CLS] counterpart tastingcoat dinner mortal elite warm knights helped cricket fringe war creator pepperonate vs [SEP]']
[Init] best perm rec loss: 0.7700954079627991 for ['[CLS] pepper warcoat knights mortal tasting dinner helped elite fringe creator cricket counterpartonate vs warm [SEP]']
[Init] best perm rec loss: 0.7700721621513367 for ['[CLS] helped counterpartcoat dinneronate cricket fringe elite creator mortal knights tasting vs warm pepper war [SEP]']
[Init] best perm rec loss: 0.7698241472244263 for ['[CLS] pepper warm fringe elite counterpart dinner knights war mortal helped tasting vscoatonate creator cricket [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.025 (perp=11.636, rec=0.366, cos=0.331), tot_loss_proj:3.861 [t=0.21s]
prediction: ['[CLS] style feel maybe musical cindy. walls woman professional identity char training has finding the women [SEP]']
[ 100/2000] tot_loss=2.516 (perp=9.948, rec=0.191, cos=0.335), tot_loss_proj:3.318 [t=0.21s]
prediction: ['[CLS]ism char of aueity men woman young who knows howism has the screen [SEP]']
[ 150/2000] tot_loss=2.558 (perp=10.416, rec=0.146, cos=0.329), tot_loss_proj:3.057 [t=0.21s]
prediction: ['[CLS]ism char of a grande screen man woman young who knows how holds has the screen [SEP]']
[ 200/2000] tot_loss=2.431 (perp=9.966, rec=0.110, cos=0.327), tot_loss_proj:3.135 [t=0.21s]
prediction: ['[CLS]ism char of aasi woman young who knows how hold has the screen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.080 (perp=8.356, rec=0.080, cos=0.328), tot_loss_proj:2.594 [t=0.21s]
prediction: ['[CLS] a char ofismasa woman young who knows how hold has the screen [SEP]']
[ 300/2000] tot_loss=2.090 (perp=8.356, rec=0.088, cos=0.331), tot_loss_proj:2.594 [t=0.21s]
prediction: ['[CLS] a char ofismasa woman young who knows how hold has the screen [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.019 (perp=8.060, rec=0.080, cos=0.328), tot_loss_proj:2.374 [t=0.21s]
prediction: ['[CLS] a char ofismasa young woman who knows how hold has the screen [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.902 (perp=7.366, rec=0.094, cos=0.334), tot_loss_proj:2.249 [t=0.21s]
prediction: ['[CLS] of a charismasa young woman who knows how hold has the screen [SEP]']
[ 450/2000] tot_loss=1.889 (perp=7.366, rec=0.081, cos=0.335), tot_loss_proj:2.246 [t=0.21s]
prediction: ['[CLS] of a charismasa young woman who knows how hold has the screen [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.823 (perp=7.095, rec=0.078, cos=0.326), tot_loss_proj:2.234 [t=0.21s]
prediction: ['[CLS] a charismasa of young woman who knows how hold has the screen [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.828 (perp=7.067, rec=0.086, cos=0.328), tot_loss_proj:2.231 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows howac hold has the screen [SEP]']
[ 600/2000] tot_loss=1.819 (perp=7.067, rec=0.078, cos=0.328), tot_loss_proj:2.241 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows howac hold has the screen [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.695 (perp=6.444, rec=0.082, cos=0.325), tot_loss_proj:2.090 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows howa holds has the screen [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.674 (perp=6.348, rec=0.076, cos=0.329), tot_loss_proj:2.103 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows hows holda has the screen [SEP]']
[ 750/2000] tot_loss=1.671 (perp=6.348, rec=0.071, cos=0.331), tot_loss_proj:2.105 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows hows holda has the screen [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.595 (perp=6.023, rec=0.062, cos=0.328), tot_loss_proj:1.946 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.616 (perp=6.023, rec=0.080, cos=0.332), tot_loss_proj:1.946 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
[ 900/2000] tot_loss=1.607 (perp=6.023, rec=0.073, cos=0.329), tot_loss_proj:1.950 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.609 (perp=6.023, rec=0.076, cos=0.328), tot_loss_proj:1.956 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.611 (perp=6.023, rec=0.075, cos=0.332), tot_loss_proj:1.953 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
[1050/2000] tot_loss=1.615 (perp=6.023, rec=0.079, cos=0.332), tot_loss_proj:1.957 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.611 (perp=6.023, rec=0.076, cos=0.330), tot_loss_proj:1.952 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.607 (perp=6.023, rec=0.073, cos=0.329), tot_loss_proj:1.956 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
[1200/2000] tot_loss=1.599 (perp=6.023, rec=0.063, cos=0.331), tot_loss_proj:1.956 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.602 (perp=6.023, rec=0.068, cos=0.329), tot_loss_proj:1.947 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.607 (perp=6.023, rec=0.075, cos=0.327), tot_loss_proj:1.951 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
[1350/2000] tot_loss=1.604 (perp=6.023, rec=0.070, cos=0.330), tot_loss_proj:1.950 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.607 (perp=6.023, rec=0.074, cos=0.329), tot_loss_proj:1.953 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.607 (perp=6.023, rec=0.072, cos=0.330), tot_loss_proj:1.956 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
[1500/2000] tot_loss=1.601 (perp=6.023, rec=0.066, cos=0.329), tot_loss_proj:1.953 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.597 (perp=6.023, rec=0.062, cos=0.331), tot_loss_proj:1.962 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.608 (perp=6.023, rec=0.073, cos=0.330), tot_loss_proj:1.959 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
[1650/2000] tot_loss=1.601 (perp=6.023, rec=0.066, cos=0.330), tot_loss_proj:1.950 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.595 (perp=6.023, rec=0.061, cos=0.330), tot_loss_proj:1.952 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.603 (perp=6.023, rec=0.070, cos=0.328), tot_loss_proj:1.950 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
[1800/2000] tot_loss=1.597 (perp=6.023, rec=0.063, cos=0.330), tot_loss_proj:1.947 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.600 (perp=6.023, rec=0.066, cos=0.330), tot_loss_proj:1.958 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.610 (perp=6.023, rec=0.075, cos=0.330), tot_loss_proj:1.962 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
[1950/2000] tot_loss=1.604 (perp=6.023, rec=0.069, cos=0.331), tot_loss_proj:1.956 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.594 (perp=6.023, rec=0.060, cos=0.329), tot_loss_proj:1.962 [t=0.21s]
prediction: ['[CLS] a charisma of young woman who knows how holda hass the screen [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] a charisma of young woman who knows how holda hass the screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 85.714 | r: 75.000
rouge2     | fm: 50.000 | p: 53.846 | r: 46.667
rougeL     | fm: 73.333 | p: 78.571 | r: 68.750
rougeLsum  | fm: 73.333 | p: 78.571 | r: 68.750
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 89.755 | p: 89.147 | r: 90.492
rouge2     | fm: 56.350 | p: 55.947 | r: 56.750
rougeL     | fm: 78.597 | p: 78.081 | r: 79.212
rougeLsum  | fm: 78.484 | p: 78.029 | r: 79.068
r1fm+r2fm = 146.105

input #59 time: 0:08:22 | total time: 8:40:22


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.8878561405137949
highest_index [0]
highest [0.8878561405137949]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9861165285110474 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9602434039115906 for ['[CLS] everything partnership bas gossip lies donegal directionbad his western ann arms [SEP]']
[Init] best rec loss: 0.9431750178337097 for ['[CLS] eddiedding whenly became northeast theo solid sighed signsrral frozen [SEP]']
[Init] best rec loss: 0.9207584857940674 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.9160416126251221 for ['[CLS] percent symbol budapest herald nets flavor shoppingted archlizer clock tight [SEP]']
[Init] best rec loss: 0.9080867767333984 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.9034244418144226 for ['[CLS]chemist myselfkar waiting locking ribbon tear dreams mosaic dorothy sure... [SEP]']
[Init] best perm rec loss: 0.9015678763389587 for ['[CLS] tear myself dorothy... locking surechemist mosaic waitingkar dreams ribbon [SEP]']
[Init] best perm rec loss: 0.9006252884864807 for ['[CLS] locking waiting dreams sure tear dorothychemist ribbon... mosaic myselfkar [SEP]']
[Init] best perm rec loss: 0.8998239636421204 for ['[CLS] tear mosaic dorothy myself dreams locking waitingchemist...kar ribbon sure [SEP]']
[Init] best perm rec loss: 0.8997536301612854 for ['[CLS] waiting locking sure... dreams mosaic ribbonchemist tear dorothy myselfkar [SEP]']
[Init] best perm rec loss: 0.8994515538215637 for ['[CLS] waiting dreams... ribbonchemist tearkar mosaic dorothy myself locking sure [SEP]']
[Init] best perm rec loss: 0.899412989616394 for ['[CLS] sure myself locking dorothykar ribbon waitingchemist tear... mosaic dreams [SEP]']
[Init] best perm rec loss: 0.8990046977996826 for ['[CLS] tear dorothy waiting sure myselfchemist locking ribbon dreamskar mosaic... [SEP]']
[Init] best perm rec loss: 0.8989582657814026 for ['[CLS] dorothykar myselfchemist locking mosaic ribbon waiting dreams tear sure... [SEP]']
[Init] best perm rec loss: 0.8979771137237549 for ['[CLS] locking mosaicchemist... myself ribbon sure dorothykar dreams waiting tear [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.761 (perp=11.583, rec=0.238, cos=0.206), tot_loss_proj:3.441 [t=0.21s]
prediction: ['[CLS] awkwardly story is awkwardly circuit awkwardly - is pilot entertainment movie moisture [SEP]']
[ 100/2000] tot_loss=2.507 (perp=10.649, rec=0.165, cos=0.212), tot_loss_proj:2.997 [t=0.21s]
prediction: ['[CLS] awkwardly circuit is soap circuit awkwardly - is soap soap story pacing [SEP]']
[ 150/2000] tot_loss=2.505 (perp=10.649, rec=0.161, cos=0.214), tot_loss_proj:3.004 [t=0.21s]
prediction: ['[CLS] awkwardly circuit is soap circuit awkwardly - is soap soap story pacing [SEP]']
[ 200/2000] tot_loss=2.695 (perp=11.793, rec=0.123, cos=0.213), tot_loss_proj:3.058 [t=0.21s]
prediction: ['[CLS] awkwardly circuit is paced circuit awkwardly -h soap soap story pacing [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.424 (perp=10.426, rec=0.134, cos=0.204), tot_loss_proj:2.891 [t=0.21s]
prediction: ['[CLS] awkwardly paced circuit awkwardly -h soap circuit is soap story fever [SEP]']
[ 300/2000] tot_loss=2.372 (perp=10.286, rec=0.107, cos=0.207), tot_loss_proj:2.931 [t=0.21s]
prediction: ['[CLS] awkwardly paced circuit awkwardly -h soap circuit is soap story paced [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.195 (perp=9.412, rec=0.103, cos=0.210), tot_loss_proj:2.765 [t=0.21s]
prediction: ['[CLS] awkwardly paced circuit awkwardly -h soap opera is is story paced [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.101 (perp=8.973, rec=0.102, cos=0.204), tot_loss_proj:2.562 [t=0.21s]
prediction: ['[CLS] awkwardly paced circuit awkwardly -h soap opera is story is paced [SEP]']
[ 450/2000] tot_loss=2.060 (perp=8.803, rec=0.096, cos=0.204), tot_loss_proj:2.484 [t=0.21s]
prediction: ['[CLS] awkwardly paced circuit awkwardly -h soap opera is story is story [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.043 (perp=8.699, rec=0.092, cos=0.211), tot_loss_proj:2.448 [t=0.21s]
prediction: ['[CLS] awkwardly awkwardly paced circuit -h soap opera is story is story [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.144 (perp=9.235, rec=0.088, cos=0.210), tot_loss_proj:2.999 [t=0.21s]
prediction: ['[CLS] awkwardly awkwardly paced circuit -h soap opera is story is flow [SEP]']
[ 600/2000] tot_loss=2.138 (perp=9.235, rec=0.083, cos=0.207), tot_loss_proj:2.997 [t=0.21s]
prediction: ['[CLS] awkwardly awkwardly paced circuit -h soap opera is story is flow [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.126 (perp=9.163, rec=0.083, cos=0.210), tot_loss_proj:2.887 [t=0.21s]
prediction: ['[CLS] awkwardly awkwardly paced circuith - soap opera is story is flow [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.130 (perp=9.163, rec=0.087, cos=0.210), tot_loss_proj:2.886 [t=0.21s]
prediction: ['[CLS] awkwardly awkwardly paced circuith - soap opera is story is flow [SEP]']
[ 750/2000] tot_loss=2.128 (perp=9.163, rec=0.089, cos=0.207), tot_loss_proj:2.890 [t=0.21s]
prediction: ['[CLS] awkwardly awkwardly paced circuith - soap opera is story is flow [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.018 (perp=8.636, rec=0.081, cos=0.209), tot_loss_proj:2.482 [t=0.21s]
prediction: ['[CLS] awkwardly awkwardly paced circuith - soap opera is story is story [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.935 (perp=8.180, rec=0.089, cos=0.210), tot_loss_proj:2.463 [t=0.21s]
prediction: ['[CLS]. awkwardly paced circuith - soap opera is story is story [SEP]']
[ 900/2000] tot_loss=1.936 (perp=8.180, rec=0.087, cos=0.213), tot_loss_proj:2.458 [t=0.21s]
prediction: ['[CLS]. awkwardly paced circuith - soap opera is story is story [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.840 (perp=7.715, rec=0.088, cos=0.209), tot_loss_proj:2.527 [t=0.21s]
prediction: ['[CLS]h. awkwardly paced circuit - soap opera is story is. [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.824 (perp=7.661, rec=0.083, cos=0.209), tot_loss_proj:2.248 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is story [SEP]']
[1050/2000] tot_loss=1.772 (perp=7.407, rec=0.081, cos=0.209), tot_loss_proj:2.262 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.769 (perp=7.407, rec=0.078, cos=0.209), tot_loss_proj:2.263 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.765 (perp=7.407, rec=0.073, cos=0.210), tot_loss_proj:2.262 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
[1200/2000] tot_loss=1.764 (perp=7.407, rec=0.074, cos=0.208), tot_loss_proj:2.267 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.768 (perp=7.407, rec=0.078, cos=0.209), tot_loss_proj:2.262 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.762 (perp=7.407, rec=0.072, cos=0.209), tot_loss_proj:2.264 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
[1350/2000] tot_loss=1.765 (perp=7.407, rec=0.075, cos=0.209), tot_loss_proj:2.270 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.773 (perp=7.407, rec=0.082, cos=0.210), tot_loss_proj:2.265 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.764 (perp=7.407, rec=0.073, cos=0.210), tot_loss_proj:2.266 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
[1500/2000] tot_loss=1.770 (perp=7.407, rec=0.079, cos=0.210), tot_loss_proj:2.271 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.770 (perp=7.407, rec=0.079, cos=0.210), tot_loss_proj:2.265 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.767 (perp=7.407, rec=0.076, cos=0.210), tot_loss_proj:2.269 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
[1650/2000] tot_loss=1.769 (perp=7.407, rec=0.078, cos=0.210), tot_loss_proj:2.267 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.762 (perp=7.407, rec=0.070, cos=0.210), tot_loss_proj:2.272 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.771 (perp=7.407, rec=0.080, cos=0.211), tot_loss_proj:2.265 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
[1800/2000] tot_loss=1.768 (perp=7.407, rec=0.076, cos=0.210), tot_loss_proj:2.269 [t=0.22s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.763 (perp=7.407, rec=0.071, cos=0.210), tot_loss_proj:2.272 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.765 (perp=7.407, rec=0.072, cos=0.211), tot_loss_proj:2.268 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
[1950/2000] tot_loss=1.755 (perp=7.407, rec=0.064, cos=0.210), tot_loss_proj:2.271 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.762 (perp=7.407, rec=0.070, cos=0.210), tot_loss_proj:2.271 [t=0.21s]
prediction: ['[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS]h awkwardly paced the circuit - soap opera is story is. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 83.333 | r: 90.909
rouge2     | fm: 19.048 | p: 18.182 | r: 20.000
rougeL     | fm: 60.870 | p: 58.333 | r: 63.636
rougeLsum  | fm: 60.870 | p: 58.333 | r: 63.636
r1fm+r2fm = 106.004

[Aggregate metrics]:
rouge1     | fm: 89.634 | p: 88.997 | r: 90.402
rouge2     | fm: 55.650 | p: 55.345 | r: 56.106
rougeL     | fm: 78.160 | p: 77.619 | r: 78.892
rougeLsum  | fm: 78.212 | p: 77.711 | r: 78.818
r1fm+r2fm = 145.285

input #60 time: 0:08:29 | total time: 8:48:51


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.7979959973444855
highest_index [0]
highest [0.7979959973444855]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9744898080825806 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9653705358505249 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9536307454109192 for ['[CLS] alta http cocked [SEP]']
[Init] best rec loss: 0.9509575963020325 for ['[CLS] tiny poor rail [SEP]']
[Init] best rec loss: 0.9324477314949036 for ['[CLS] prints england vague [SEP]']
[Init] best rec loss: 0.9164654612541199 for ['[CLS] mouth lastless [SEP]']
[Init] best rec loss: 0.9014006853103638 for ['[CLS] readyppetphonic [SEP]']
[Init] best rec loss: 0.8700305819511414 for ['[CLS] says -vino [SEP]']
[Init] best rec loss: 0.8675658702850342 for ['[CLS] plan welloic [SEP]']
[Init] best rec loss: 0.8467972278594971 for ['[CLS] vehicle surrounding south [SEP]']
[Init] best perm rec loss: 0.8439480662345886 for ['[CLS] surrounding vehicle south [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.242 (perp=8.309, rec=0.216, cos=0.365), tot_loss_proj:2.462 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 100/2000] tot_loss=2.199 (perp=8.309, rec=0.171, cos=0.367), tot_loss_proj:2.452 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 150/2000] tot_loss=2.195 (perp=8.309, rec=0.165, cos=0.367), tot_loss_proj:2.449 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 200/2000] tot_loss=2.185 (perp=8.309, rec=0.156, cos=0.368), tot_loss_proj:2.460 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.171 (perp=8.309, rec=0.143, cos=0.366), tot_loss_proj:2.456 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 300/2000] tot_loss=2.176 (perp=8.309, rec=0.148, cos=0.367), tot_loss_proj:2.460 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.176 (perp=8.309, rec=0.148, cos=0.366), tot_loss_proj:2.453 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.173 (perp=8.309, rec=0.146, cos=0.365), tot_loss_proj:2.452 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 450/2000] tot_loss=2.175 (perp=8.309, rec=0.149, cos=0.365), tot_loss_proj:2.454 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.178 (perp=8.309, rec=0.151, cos=0.365), tot_loss_proj:2.448 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.163 (perp=8.309, rec=0.135, cos=0.366), tot_loss_proj:2.453 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 600/2000] tot_loss=2.161 (perp=8.309, rec=0.133, cos=0.366), tot_loss_proj:2.448 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.169 (perp=8.309, rec=0.142, cos=0.365), tot_loss_proj:2.451 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.167 (perp=8.309, rec=0.141, cos=0.364), tot_loss_proj:2.454 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 750/2000] tot_loss=2.152 (perp=8.309, rec=0.127, cos=0.364), tot_loss_proj:2.451 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.158 (perp=8.309, rec=0.133, cos=0.363), tot_loss_proj:2.451 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.142 (perp=8.309, rec=0.118, cos=0.363), tot_loss_proj:2.460 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 900/2000] tot_loss=2.120 (perp=8.296, rec=0.099, cos=0.361), tot_loss_proj:2.298 [t=0.21s]
prediction: ['[CLS] beautiful, scene [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.861 (perp=7.102, rec=0.079, cos=0.361), tot_loss_proj:2.028 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.862 (perp=7.102, rec=0.081, cos=0.360), tot_loss_proj:2.029 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.860 (perp=7.102, rec=0.076, cos=0.363), tot_loss_proj:2.038 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.861 (perp=7.102, rec=0.079, cos=0.362), tot_loss_proj:2.039 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.854 (perp=7.102, rec=0.071, cos=0.363), tot_loss_proj:2.031 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.848 (perp=7.102, rec=0.066, cos=0.362), tot_loss_proj:2.020 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.863 (perp=7.102, rec=0.080, cos=0.363), tot_loss_proj:2.025 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.849 (perp=7.102, rec=0.066, cos=0.362), tot_loss_proj:2.035 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.856 (perp=7.102, rec=0.073, cos=0.363), tot_loss_proj:2.025 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.850 (perp=7.102, rec=0.068, cos=0.362), tot_loss_proj:2.025 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.845 (perp=7.102, rec=0.062, cos=0.363), tot_loss_proj:2.036 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.850 (perp=7.102, rec=0.067, cos=0.363), tot_loss_proj:2.029 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.849 (perp=7.102, rec=0.065, cos=0.363), tot_loss_proj:2.033 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.852 (perp=7.102, rec=0.069, cos=0.363), tot_loss_proj:2.031 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.845 (perp=7.102, rec=0.063, cos=0.362), tot_loss_proj:2.028 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.855 (perp=7.102, rec=0.072, cos=0.363), tot_loss_proj:2.025 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.849 (perp=7.102, rec=0.067, cos=0.362), tot_loss_proj:2.033 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.856 (perp=7.102, rec=0.073, cos=0.363), tot_loss_proj:2.024 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.852 (perp=7.102, rec=0.069, cos=0.363), tot_loss_proj:2.031 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.849 (perp=7.102, rec=0.066, cos=0.363), tot_loss_proj:2.030 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.839 (perp=7.102, rec=0.057, cos=0.363), tot_loss_proj:2.026 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.850 (perp=7.102, rec=0.067, cos=0.363), tot_loss_proj:2.030 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.812 | p: 89.247 | r: 90.508
rouge2     | fm: 56.476 | p: 56.191 | r: 56.837
rougeL     | fm: 78.549 | p: 78.053 | r: 79.230
rougeLsum  | fm: 78.538 | p: 77.996 | r: 79.144
r1fm+r2fm = 146.288

input #61 time: 0:08:21 | total time: 8:57:13


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.8324566159996984
highest_index [0]
highest [0.8324566159996984]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9136887788772583 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.8922441005706787 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.891446053981781 for ['[CLS] potential sub practice had e european recruitingsight probable conversion plates rubang taxes braced theorem themselves nu us wolfe mid [SEP]']
[Init] best rec loss: 0.8897308111190796 for ['[CLS] services te isbnentseye久 researchcreen past sequencingwn can pier precise linda erica monk val contestbe foreign [SEP]']
[Init] best rec loss: 0.8856460452079773 for ['[CLS]ining strata won suitedtis near isaac bull worship here techp perhaps assistant kerman negative fisulsion ash too skill [SEP]']
[Init] best rec loss: 0.8856032490730286 for ['[CLS] scout cafeceaeswch novel spot latitude romanwar winter largely talksord liberal sophiehon iii pitchaceathing [SEP]']
[Init] best rec loss: 0.8851571679115295 for ['[CLS] butterfly alternative professional all diveleader withstand reins emergency fears rate feet iv bat burn judgeulsive busy give student military [SEP]']
[Init] best rec loss: 0.8811478018760681 for ['[CLS]ecure armedria obvious commission symbol echo drinking testified mothergaard reacher executive dressed playing but name ups [SEP] [MASK] kala [SEP]']
[Init] best rec loss: 0.8682992458343506 for ['[CLS] part remembered victor jayne imagined♭ basket against cheeks barrow battalion whilefold informed had higher outstanding ezio ramirez malta pinyin [SEP]']
[Init] best perm rec loss: 0.8669126033782959 for ['[CLS]♭ battalion jayne barrow malta informed victor remembered ramirez cheeks imagined hadfold basket against outstanding part while ezio higher pinyin [SEP]']
[Init] best perm rec loss: 0.8662574291229248 for ['[CLS] battalion♭ while higher barrow against pinyin informed victor basketfold ezio jayne had remembered ramirez malta part cheeks outstanding imagined [SEP]']
[Init] best perm rec loss: 0.8660366535186768 for ['[CLS] part had basket informed ezio cheeks while outstandingfold battalion pinyin imagined jayne victor ramirez♭ malta higher remembered against barrow [SEP]']
[Init] best perm rec loss: 0.8657712936401367 for ['[CLS] pinyin part victor barrowfold♭ while jayne against imagined had higher battalion cheeks ezio malta remembered informed outstanding ramirez basket [SEP]']
[Init] best perm rec loss: 0.8653233647346497 for ['[CLS]♭ victor pinyin battalion informed part jayne outstanding malta ramirez had barrow against imagined higher cheeksfold ezio remembered while basket [SEP]']
[Init] best perm rec loss: 0.8646799325942993 for ['[CLS] malta outstanding barrow jayne while victor remembered cheeks imagined basket eziofold♭ part ramirez higher battalion against informed pinyin had [SEP]']
[Init] best perm rec loss: 0.8641830086708069 for ['[CLS]♭ jayne barrow remembered malta higher battalion pinyin informed had basket imagined ezio part cheeks ramirez victorfold against while outstanding [SEP]']
[Init] best perm rec loss: 0.864130973815918 for ['[CLS] had ramirez higher against remembered battalion barrowfold cheeks ezio informed malta imagined pinyin basket part♭ jayne victor while outstanding [SEP]']
[Init] best perm rec loss: 0.8631265759468079 for ['[CLS] ramirez ezio victor remembered battalion barrow basket hadfold cheeks higher jayne informed♭ outstanding imagined against pinyin malta while part [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.058 (perp=12.147, rec=0.321, cos=0.307), tot_loss_proj:3.578 [t=0.21s]
prediction: ['[CLS] stint best best woman often hazard prevention the craig call named street among successful completed stellar drama war films film grace [SEP]']
[ 100/2000] tot_loss=2.531 (perp=9.978, rec=0.228, cos=0.307), tot_loss_proj:3.808 [t=0.21s]
prediction: ['[CLS] grace among best for rather prevention prevention movies carry charity him better the best making : comedy war movies movie grace [SEP]']
[ 150/2000] tot_loss=2.414 (perp=9.720, rec=0.164, cos=0.306), tot_loss_proj:3.365 [t=0.21s]
prediction: ['[CLS] grace among best to to prevention prevention your capture account him to the best making : film war movies ever grace [SEP]']
[ 200/2000] tot_loss=2.364 (perp=9.576, rec=0.144, cos=0.305), tot_loss_proj:3.764 [t=0.21s]
prediction: ['[CLS] grace the best to to prevention prevention made rather rather it to one one making pro war war movies ever grace [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.226 (perp=8.975, rec=0.127, cos=0.303), tot_loss_proj:3.562 [t=0.21s]
prediction: ['[CLS] grace the best rather to prevention prevention made rather to it, it one making pro until war movies ever grace [SEP]']
[ 300/2000] tot_loss=2.112 (perp=8.469, rec=0.113, cos=0.305), tot_loss_proj:3.516 [t=0.21s]
prediction: ['[CLS] grace the best rather to call prevention made rather to it, it one making impose to war movies ever grace [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.031 (perp=8.102, rec=0.104, cos=0.306), tot_loss_proj:3.228 [t=0.21s]
prediction: ['[CLS] grace the best rather to call prevention made rather to it, rated one making it and war movies ever grace [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.180 (perp=8.861, rec=0.101, cos=0.306), tot_loss_proj:3.388 [t=0.21s]
prediction: ['[CLS] grace the best rather to call prevention made rather to for, events one making it rated war movies ever grace [SEP]']
[ 450/2000] tot_loss=2.225 (perp=9.147, rec=0.090, cos=0.306), tot_loss_proj:3.585 [t=0.21s]
prediction: ['[CLS] grace the best blame to call prevention made rather to than, to one making it rated war movies ever grace [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.034 (perp=8.160, rec=0.096, cos=0.305), tot_loss_proj:3.354 [t=0.21s]
prediction: ['[CLS] grace the best blame to call prevention grace rather to than, to one making it rated war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.950 (perp=7.792, rec=0.087, cos=0.305), tot_loss_proj:3.014 [t=0.21s]
prediction: ['[CLS] grace the best blame to call prevention grace rather than to, to one making it maximum war movies ever made [SEP]']
[ 600/2000] tot_loss=1.955 (perp=7.792, rec=0.090, cos=0.307), tot_loss_proj:3.007 [t=0.21s]
prediction: ['[CLS] grace the best blame to call prevention grace rather than to, to one making it maximum war movies ever made [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.865 (perp=7.343, rec=0.090, cos=0.306), tot_loss_proj:2.817 [t=0.21s]
prediction: ['[CLS] grace the best blame to call grace rather than to prevention, to one making it maximum war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.819 (perp=7.100, rec=0.092, cos=0.307), tot_loss_proj:2.871 [t=0.21s]
prediction: ['[CLS] to the best blame to call grace rather than grace prevention, to one making it maximum war movies ever made [SEP]']
[ 750/2000] tot_loss=1.812 (perp=7.100, rec=0.085, cos=0.307), tot_loss_proj:2.865 [t=0.21s]
prediction: ['[CLS] to the best blame to call grace rather than grace prevention, to one making it maximum war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.762 (perp=6.851, rec=0.085, cos=0.306), tot_loss_proj:2.740 [t=0.21s]
prediction: ['[CLS] to the best call to blame grace rather than grace prevention, to one making it maximum war movies ever made [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.738 (perp=6.759, rec=0.079, cos=0.307), tot_loss_proj:2.694 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than grace prevention, to one making it maximum war movies ever made [SEP]']
[ 900/2000] tot_loss=1.746 (perp=6.756, rec=0.088, cos=0.307), tot_loss_proj:2.871 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than grace prevention, for one making it maximum war movies ever made [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.738 (perp=6.747, rec=0.083, cos=0.306), tot_loss_proj:3.088 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than grace prevention, for one making it rated war movies ever made [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.665 (perp=6.397, rec=0.080, cos=0.306), tot_loss_proj:3.021 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than grace prevention, for making it one rated war movies ever made [SEP]']
[1050/2000] tot_loss=1.662 (perp=6.397, rec=0.076, cos=0.306), tot_loss_proj:3.017 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than grace prevention, for making it one rated war movies ever made [SEP]']
Attempt swap
[1100/2000] tot_loss=1.668 (perp=6.397, rec=0.083, cos=0.306), tot_loss_proj:3.023 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than grace prevention, for making it one rated war movies ever made [SEP]']
Attempt swap
[1150/2000] tot_loss=1.635 (perp=6.239, rec=0.080, cos=0.307), tot_loss_proj:2.813 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one rated war movies ever made [SEP]']
[1200/2000] tot_loss=1.640 (perp=6.239, rec=0.086, cos=0.306), tot_loss_proj:2.815 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one rated war movies ever made [SEP]']
Attempt swap
[1250/2000] tot_loss=1.603 (perp=6.067, rec=0.083, cos=0.306), tot_loss_proj:2.946 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one point war movies ever made [SEP]']
Attempt swap
[1300/2000] tot_loss=1.674 (perp=6.434, rec=0.080, cos=0.306), tot_loss_proj:2.962 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
[1350/2000] tot_loss=1.675 (perp=6.434, rec=0.082, cos=0.306), tot_loss_proj:2.960 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
Attempt swap
[1400/2000] tot_loss=1.668 (perp=6.434, rec=0.075, cos=0.306), tot_loss_proj:2.965 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
Attempt swap
[1450/2000] tot_loss=1.674 (perp=6.434, rec=0.081, cos=0.306), tot_loss_proj:2.963 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
[1500/2000] tot_loss=1.677 (perp=6.434, rec=0.083, cos=0.307), tot_loss_proj:2.963 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
Attempt swap
[1550/2000] tot_loss=1.669 (perp=6.434, rec=0.076, cos=0.306), tot_loss_proj:2.965 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
Attempt swap
[1600/2000] tot_loss=1.667 (perp=6.434, rec=0.073, cos=0.307), tot_loss_proj:2.963 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
[1650/2000] tot_loss=1.678 (perp=6.434, rec=0.085, cos=0.306), tot_loss_proj:2.958 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
Attempt swap
[1700/2000] tot_loss=1.669 (perp=6.434, rec=0.076, cos=0.306), tot_loss_proj:2.961 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
Attempt swap
[1750/2000] tot_loss=1.665 (perp=6.434, rec=0.072, cos=0.306), tot_loss_proj:2.961 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
[1800/2000] tot_loss=1.673 (perp=6.434, rec=0.080, cos=0.306), tot_loss_proj:2.964 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
Attempt swap
[1850/2000] tot_loss=1.670 (perp=6.434, rec=0.076, cos=0.306), tot_loss_proj:2.963 [t=0.21s]
prediction: ['[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.620 (perp=6.176, rec=0.080, cos=0.306), tot_loss_proj:2.645 [t=0.21s]
prediction: ['[CLS] to the best call to grace for blame rather than blame prevention, making it one int war movies ever made [SEP]']
[1950/2000] tot_loss=1.620 (perp=6.176, rec=0.080, cos=0.305), tot_loss_proj:2.644 [t=0.21s]
prediction: ['[CLS] to the best call to grace for blame rather than blame prevention, making it one int war movies ever made [SEP]']
Attempt swap
[2000/2000] tot_loss=1.617 (perp=6.176, rec=0.076, cos=0.306), tot_loss_proj:2.641 [t=0.21s]
prediction: ['[CLS] to the best call to grace for blame rather than blame prevention, making it one int war movies ever made [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] to the best call to grace blame rather than blame prevention, for making it one int war movies ever made [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 38.095 | p: 38.095 | r: 38.095
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 129.004

[Aggregate metrics]:
rouge1     | fm: 89.847 | p: 89.267 | r: 90.550
rouge2     | fm: 56.275 | p: 55.921 | r: 56.722
rougeL     | fm: 78.313 | p: 77.802 | r: 78.923
rougeLsum  | fm: 78.214 | p: 77.701 | r: 78.799
r1fm+r2fm = 146.123

input #62 time: 0:08:27 | total time: 9:05:40


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.8977924071276724
highest_index [0]
highest [0.8977924071276724]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.8038585186004639 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.7130887508392334 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.6829606294631958 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best perm rec loss: 0.6819187998771667 for ['[CLS] spendism brighter written working [SEP]']
[Init] best perm rec loss: 0.681721568107605 for ['[CLS] spend writtenism brighter working [SEP]']
[Init] best perm rec loss: 0.6803179979324341 for ['[CLS] brighter workingism written spend [SEP]']
[Init] best perm rec loss: 0.6803057789802551 for ['[CLS] spend working brighterism written [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.129 (perp=8.947, rec=0.147, cos=0.192), tot_loss_proj:2.794 [t=0.21s]
prediction: ['[CLS] crowd looking for return ticket [SEP]']
[ 100/2000] tot_loss=2.053 (perp=8.818, rec=0.093, cos=0.197), tot_loss_proj:2.560 [t=0.21s]
prediction: ['[CLS] return looking for return ticket [SEP]']
[ 150/2000] tot_loss=2.170 (perp=9.470, rec=0.084, cos=0.192), tot_loss_proj:2.404 [t=0.21s]
prediction: ['[CLS] looking looking for return ticket [SEP]']
[ 200/2000] tot_loss=1.958 (perp=8.384, rec=0.089, cos=0.192), tot_loss_proj:2.509 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.946 (perp=8.384, rec=0.079, cos=0.191), tot_loss_proj:2.511 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
[ 300/2000] tot_loss=1.934 (perp=8.384, rec=0.067, cos=0.190), tot_loss_proj:2.516 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.944 (perp=8.384, rec=0.076, cos=0.192), tot_loss_proj:2.515 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.944 (perp=8.384, rec=0.072, cos=0.195), tot_loss_proj:2.517 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
[ 450/2000] tot_loss=1.939 (perp=8.384, rec=0.072, cos=0.191), tot_loss_proj:2.508 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.941 (perp=8.384, rec=0.071, cos=0.193), tot_loss_proj:2.503 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.935 (perp=8.384, rec=0.067, cos=0.191), tot_loss_proj:2.497 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
[ 600/2000] tot_loss=1.943 (perp=8.384, rec=0.075, cos=0.191), tot_loss_proj:2.502 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.939 (perp=8.384, rec=0.071, cos=0.192), tot_loss_proj:2.490 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.944 (perp=8.384, rec=0.074, cos=0.193), tot_loss_proj:2.495 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
[ 750/2000] tot_loss=1.932 (perp=8.384, rec=0.062, cos=0.193), tot_loss_proj:2.495 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.936 (perp=8.384, rec=0.066, cos=0.193), tot_loss_proj:2.495 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.942 (perp=8.384, rec=0.074, cos=0.191), tot_loss_proj:2.490 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
[ 900/2000] tot_loss=1.937 (perp=8.384, rec=0.067, cos=0.193), tot_loss_proj:2.488 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.932 (perp=8.384, rec=0.063, cos=0.192), tot_loss_proj:2.495 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.932 (perp=8.384, rec=0.063, cos=0.192), tot_loss_proj:2.489 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
[1050/2000] tot_loss=1.936 (perp=8.384, rec=0.068, cos=0.191), tot_loss_proj:2.486 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.939 (perp=8.384, rec=0.070, cos=0.193), tot_loss_proj:2.481 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.939 (perp=8.384, rec=0.069, cos=0.194), tot_loss_proj:2.488 [t=0.21s]
prediction: ['[CLS] for looking for return ticket [SEP]']
[1200/2000] tot_loss=1.931 (perp=8.350, rec=0.067, cos=0.194), tot_loss_proj:2.207 [t=0.21s]
prediction: ['[CLS] a looking for return ticket [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.481 (perp=6.111, rec=0.067, cos=0.192), tot_loss_proj:1.510 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.474 (perp=6.111, rec=0.059, cos=0.194), tot_loss_proj:1.509 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.482 (perp=6.111, rec=0.067, cos=0.193), tot_loss_proj:1.499 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.477 (perp=6.111, rec=0.062, cos=0.193), tot_loss_proj:1.506 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.480 (perp=6.111, rec=0.065, cos=0.193), tot_loss_proj:1.500 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.479 (perp=6.111, rec=0.063, cos=0.194), tot_loss_proj:1.504 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.491 (perp=6.111, rec=0.076, cos=0.192), tot_loss_proj:1.513 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.473 (perp=6.111, rec=0.058, cos=0.193), tot_loss_proj:1.502 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.476 (perp=6.111, rec=0.060, cos=0.193), tot_loss_proj:1.509 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.476 (perp=6.111, rec=0.060, cos=0.193), tot_loss_proj:1.496 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.477 (perp=6.111, rec=0.062, cos=0.193), tot_loss_proj:1.509 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.480 (perp=6.111, rec=0.064, cos=0.194), tot_loss_proj:1.507 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.472 (perp=6.111, rec=0.057, cos=0.194), tot_loss_proj:1.495 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.480 (perp=6.111, rec=0.064, cos=0.194), tot_loss_proj:1.501 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.477 (perp=6.111, rec=0.061, cos=0.194), tot_loss_proj:1.515 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.480 (perp=6.111, rec=0.064, cos=0.194), tot_loss_proj:1.507 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.006 | p: 89.429 | r: 90.730
rouge2     | fm: 56.782 | p: 56.526 | r: 57.172
rougeL     | fm: 78.656 | p: 78.137 | r: 79.299
rougeLsum  | fm: 78.659 | p: 78.147 | r: 79.208
r1fm+r2fm = 146.789

input #63 time: 0:08:24 | total time: 9:14:04


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.8566987085265224
highest_index [0]
highest [0.8566987085265224]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8790513277053833 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8232266902923584 for ['[CLS] dale fuel picked [SEP]']
[Init] best rec loss: 0.8135156035423279 for ['[CLS] david [CLS] earliest [SEP]']
[Init] best rec loss: 0.730733335018158 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6807390451431274 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.673256516456604 for ['[CLS] wateronale visions [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.287 (perp=9.190, rec=0.163, cos=0.286), tot_loss_proj:2.419 [t=0.21s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 100/2000] tot_loss=2.129 (perp=8.961, rec=0.075, cos=0.262), tot_loss_proj:2.471 [t=0.21s]
prediction: ['[CLS] strange the horror [SEP]']
[ 150/2000] tot_loss=2.123 (perp=8.961, rec=0.071, cos=0.260), tot_loss_proj:2.473 [t=0.21s]
prediction: ['[CLS] strange the horror [SEP]']
[ 200/2000] tot_loss=2.112 (perp=8.961, rec=0.057, cos=0.263), tot_loss_proj:2.479 [t=0.21s]
prediction: ['[CLS] strange the horror [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.944 (perp=8.065, rec=0.070, cos=0.262), tot_loss_proj:1.971 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 300/2000] tot_loss=1.943 (perp=8.065, rec=0.065, cos=0.265), tot_loss_proj:1.976 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.932 (perp=8.065, rec=0.058, cos=0.261), tot_loss_proj:1.963 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.946 (perp=8.065, rec=0.069, cos=0.264), tot_loss_proj:1.970 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.947 (perp=8.065, rec=0.069, cos=0.264), tot_loss_proj:1.975 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.945 (perp=8.065, rec=0.066, cos=0.266), tot_loss_proj:1.969 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.935 (perp=8.065, rec=0.061, cos=0.261), tot_loss_proj:1.978 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.940 (perp=8.065, rec=0.062, cos=0.265), tot_loss_proj:1.970 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.940 (perp=8.065, rec=0.063, cos=0.264), tot_loss_proj:1.981 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.944 (perp=8.065, rec=0.068, cos=0.263), tot_loss_proj:1.971 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.942 (perp=8.065, rec=0.065, cos=0.264), tot_loss_proj:1.977 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.942 (perp=8.065, rec=0.064, cos=0.265), tot_loss_proj:1.968 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.932 (perp=8.065, rec=0.053, cos=0.266), tot_loss_proj:1.974 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.941 (perp=8.065, rec=0.063, cos=0.265), tot_loss_proj:1.980 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.934 (perp=8.065, rec=0.057, cos=0.264), tot_loss_proj:1.960 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.942 (perp=8.065, rec=0.063, cos=0.266), tot_loss_proj:1.964 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.943 (perp=8.065, rec=0.066, cos=0.264), tot_loss_proj:1.971 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.941 (perp=8.065, rec=0.063, cos=0.265), tot_loss_proj:1.966 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.940 (perp=8.065, rec=0.062, cos=0.266), tot_loss_proj:1.974 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.933 (perp=8.065, rec=0.054, cos=0.266), tot_loss_proj:1.965 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.937 (perp=8.065, rec=0.059, cos=0.264), tot_loss_proj:1.974 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.934 (perp=8.065, rec=0.056, cos=0.265), tot_loss_proj:1.975 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.933 (perp=8.065, rec=0.056, cos=0.264), tot_loss_proj:1.978 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.937 (perp=8.065, rec=0.058, cos=0.266), tot_loss_proj:1.967 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.939 (perp=8.065, rec=0.061, cos=0.265), tot_loss_proj:1.976 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.938 (perp=8.065, rec=0.061, cos=0.264), tot_loss_proj:1.974 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.932 (perp=8.065, rec=0.053, cos=0.265), tot_loss_proj:1.973 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.947 (perp=8.065, rec=0.069, cos=0.265), tot_loss_proj:1.977 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.934 (perp=8.065, rec=0.055, cos=0.265), tot_loss_proj:1.982 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.930 (perp=8.065, rec=0.052, cos=0.265), tot_loss_proj:1.976 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.943 (perp=8.065, rec=0.064, cos=0.266), tot_loss_proj:1.968 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.940 (perp=8.065, rec=0.062, cos=0.265), tot_loss_proj:1.968 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.929 (perp=8.065, rec=0.051, cos=0.265), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.933 (perp=8.065, rec=0.054, cos=0.265), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.938 (perp=8.065, rec=0.059, cos=0.266), tot_loss_proj:1.967 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.928 (perp=8.065, rec=0.049, cos=0.266), tot_loss_proj:1.967 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.270 | p: 89.647 | r: 90.925
rouge2     | fm: 57.370 | p: 57.022 | r: 57.844
rougeL     | fm: 79.088 | p: 78.630 | r: 79.700
rougeLsum  | fm: 79.130 | p: 78.663 | r: 79.725
r1fm+r2fm = 147.640

input #64 time: 0:08:24 | total time: 9:22:29


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.7805477807503896
highest_index [0]
highest [0.7805477807503896]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 0.8920947909355164 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.8799959421157837 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.8680295944213867 for ['[CLS] dir northern opens gasam acute diocese ban missile [SEP]']
[Init] best rec loss: 0.8511031270027161 for ['[CLS] nyunce coalition pdf dailyenburg registry romanesqueric [SEP]']
[Init] best rec loss: 0.8384817838668823 for ['[CLS] script the classning lau tape from later skate [SEP]']
[Init] best rec loss: 0.8335429430007935 for ['[CLS] health kuept scenicne contact will savamac [SEP]']
[Init] best rec loss: 0.8139310479164124 for ['[CLS] dancer relative being bar shoulder allmusic original eatingolic [SEP]']
[Init] best rec loss: 0.7859221696853638 for ['[CLS] graphic - oxygen jessie go distinguished they alt decommissioned [SEP]']
[Init] best rec loss: 0.7568408846855164 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.7552975416183472 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.7551150918006897 for ['[CLS] even news pu someday fun general oversmamenthoff [SEP]']
[Init] best perm rec loss: 0.7531426548957825 for ['[CLS] pu news even oversmament someday funhoff general [SEP]']
[Init] best perm rec loss: 0.7515478134155273 for ['[CLS] general somedaymament pu overshoff news fun even [SEP]']
[Init] best perm rec loss: 0.7512860894203186 for ['[CLS] pu news evenhoff someday overs fun generalmament [SEP]']
[Init] best perm rec loss: 0.750645637512207 for ['[CLS] funmament overs general someday newshoff pu even [SEP]']
[Init] best perm rec loss: 0.7504193186759949 for ['[CLS] even generalmamenthoff fun overs someday news pu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.322 (perp=8.188, rec=0.293, cos=0.391), tot_loss_proj:2.621 [t=0.21s]
prediction: ['[CLS] joy book tale joy joy, joys joy [SEP]']
[ 100/2000] tot_loss=2.737 (perp=10.809, rec=0.191, cos=0.385), tot_loss_proj:3.101 [t=0.21s]
prediction: ['[CLS] joy filmous rom joy, joy.ous [SEP]']
[ 150/2000] tot_loss=2.844 (perp=11.672, rec=0.126, cos=0.384), tot_loss_proj:3.448 [t=0.21s]
prediction: ['[CLS] joy romous rom joy, film ofp [SEP]']
[ 200/2000] tot_loss=2.835 (perp=11.672, rec=0.110, cos=0.391), tot_loss_proj:3.462 [t=0.21s]
prediction: ['[CLS] joy romous rom joy, film ofp [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.227 (perp=8.315, rec=0.180, cos=0.384), tot_loss_proj:2.661 [t=0.21s]
prediction: ['[CLS] joyous rom joy, film of romp [SEP]']
[ 300/2000] tot_loss=2.324 (perp=9.094, rec=0.118, cos=0.387), tot_loss_proj:2.799 [t=0.21s]
prediction: ['[CLS] joyous rom joy, film of filmp [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.939 (perp=7.210, rec=0.110, cos=0.387), tot_loss_proj:2.222 [t=0.21s]
prediction: ['[CLS] joyous joy, film of film romp [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.821 (perp=6.669, rec=0.102, cos=0.385), tot_loss_proj:2.106 [t=0.21s]
prediction: ['[CLS] joyous film, film of joy romp [SEP]']
[ 450/2000] tot_loss=1.813 (perp=6.669, rec=0.094, cos=0.386), tot_loss_proj:2.105 [t=0.21s]
prediction: ['[CLS] joyous film, film of joy romp [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.809 (perp=6.669, rec=0.086, cos=0.389), tot_loss_proj:2.115 [t=0.21s]
prediction: ['[CLS] joyous film, film of joy romp [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.824 (perp=6.739, rec=0.087, cos=0.389), tot_loss_proj:2.148 [t=0.21s]
prediction: ['[CLS] joyous., film of joy romp [SEP]']
[ 600/2000] tot_loss=1.820 (perp=6.739, rec=0.083, cos=0.389), tot_loss_proj:2.150 [t=0.21s]
prediction: ['[CLS] joyous., film of joy romp [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.673 (perp=6.009, rec=0.083, cos=0.388), tot_loss_proj:1.963 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.668 (perp=6.009, rec=0.078, cos=0.389), tot_loss_proj:1.958 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
[ 750/2000] tot_loss=1.674 (perp=6.009, rec=0.081, cos=0.391), tot_loss_proj:1.959 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.669 (perp=6.009, rec=0.078, cos=0.389), tot_loss_proj:1.962 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.669 (perp=6.009, rec=0.077, cos=0.390), tot_loss_proj:1.956 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
[ 900/2000] tot_loss=1.664 (perp=6.009, rec=0.073, cos=0.389), tot_loss_proj:1.963 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.668 (perp=6.009, rec=0.076, cos=0.390), tot_loss_proj:1.960 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.673 (perp=6.009, rec=0.081, cos=0.391), tot_loss_proj:1.963 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
[1050/2000] tot_loss=1.666 (perp=6.009, rec=0.075, cos=0.389), tot_loss_proj:1.959 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.665 (perp=6.009, rec=0.072, cos=0.391), tot_loss_proj:1.961 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.661 (perp=6.009, rec=0.069, cos=0.390), tot_loss_proj:1.958 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
[1200/2000] tot_loss=1.669 (perp=6.009, rec=0.077, cos=0.390), tot_loss_proj:1.959 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.664 (perp=6.009, rec=0.072, cos=0.390), tot_loss_proj:1.961 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.666 (perp=6.009, rec=0.074, cos=0.390), tot_loss_proj:1.963 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
[1350/2000] tot_loss=1.669 (perp=6.009, rec=0.076, cos=0.391), tot_loss_proj:1.952 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.670 (perp=6.009, rec=0.079, cos=0.390), tot_loss_proj:1.961 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.664 (perp=6.009, rec=0.072, cos=0.390), tot_loss_proj:1.964 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
[1500/2000] tot_loss=1.666 (perp=6.009, rec=0.074, cos=0.390), tot_loss_proj:1.957 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.658 (perp=6.009, rec=0.066, cos=0.390), tot_loss_proj:1.956 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.665 (perp=6.009, rec=0.072, cos=0.391), tot_loss_proj:1.959 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
[1650/2000] tot_loss=1.665 (perp=6.009, rec=0.073, cos=0.391), tot_loss_proj:1.960 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.658 (perp=6.009, rec=0.066, cos=0.391), tot_loss_proj:1.957 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.663 (perp=6.009, rec=0.071, cos=0.390), tot_loss_proj:1.962 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
[1800/2000] tot_loss=1.659 (perp=6.009, rec=0.067, cos=0.390), tot_loss_proj:1.956 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.665 (perp=6.009, rec=0.073, cos=0.390), tot_loss_proj:1.957 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.672 (perp=6.009, rec=0.079, cos=0.391), tot_loss_proj:1.964 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
[1950/2000] tot_loss=1.659 (perp=6.009, rec=0.067, cos=0.390), tot_loss_proj:1.963 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.670 (perp=6.009, rec=0.078, cos=0.391), tot_loss_proj:1.955 [t=0.21s]
prediction: ['[CLS] joyous, film of joy romp. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] joyous, film of joy romp. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 102.381

[Aggregate metrics]:
rouge1     | fm: 90.139 | p: 89.520 | r: 90.806
rouge2     | fm: 57.037 | p: 56.716 | r: 57.368
rougeL     | fm: 78.828 | p: 78.345 | r: 79.359
rougeLsum  | fm: 78.750 | p: 78.251 | r: 79.393
r1fm+r2fm = 147.175

input #65 time: 0:08:23 | total time: 9:30:53


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.8350315713180765
highest_index [0]
highest [0.8350315713180765]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.8479843139648438 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.8238093852996826 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.8166069388389587 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.7979914546012878 for ['[CLS] riot equal private peculiar [SEP]']
[Init] best rec loss: 0.7918663024902344 for ['[CLS] complied man ready panic [SEP]']
[Init] best rec loss: 0.7626492977142334 for ['[CLS] background leader screen [CLS] [SEP]']
[Init] best rec loss: 0.7564829587936401 for ['[CLS] helmet stared true deposit [SEP]']
[Init] best rec loss: 0.7347710132598877 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best perm rec loss: 0.7312545776367188 for ['[CLS] game scout shoulders juliet [SEP]']
[Init] best perm rec loss: 0.7307446002960205 for ['[CLS] scout juliet shoulders game [SEP]']
[Init] best perm rec loss: 0.7302207946777344 for ['[CLS] juliet game scout shoulders [SEP]']
[Init] best perm rec loss: 0.729885458946228 for ['[CLS] scout shoulders game juliet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.643 (perp=10.708, rec=0.192, cos=0.310), tot_loss_proj:2.859 [t=0.22s]
prediction: ['[CLS] fan longtime fan tolkien [SEP]']
[ 100/2000] tot_loss=2.567 (perp=10.708, rec=0.126, cos=0.299), tot_loss_proj:2.861 [t=0.22s]
prediction: ['[CLS] fan longtime fan tolkien [SEP]']
[ 150/2000] tot_loss=2.537 (perp=10.708, rec=0.095, cos=0.300), tot_loss_proj:2.869 [t=0.22s]
prediction: ['[CLS] fan longtime fan tolkien [SEP]']
[ 200/2000] tot_loss=2.539 (perp=10.708, rec=0.097, cos=0.301), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] fan longtime fan tolkien [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.053 (perp=8.227, rec=0.103, cos=0.304), tot_loss_proj:2.213 [t=0.22s]
prediction: ['[CLS] longtime fan tolkien fan [SEP]']
[ 300/2000] tot_loss=2.142 (perp=8.773, rec=0.084, cos=0.303), tot_loss_proj:2.283 [t=0.22s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.902 (perp=7.672, rec=0.066, cos=0.301), tot_loss_proj:1.909 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.914 (perp=7.672, rec=0.079, cos=0.301), tot_loss_proj:1.907 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.910 (perp=7.672, rec=0.071, cos=0.304), tot_loss_proj:1.905 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.904 (perp=7.672, rec=0.067, cos=0.302), tot_loss_proj:1.901 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.903 (perp=7.672, rec=0.067, cos=0.302), tot_loss_proj:1.902 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.899 (perp=7.672, rec=0.064, cos=0.301), tot_loss_proj:1.903 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.908 (perp=7.672, rec=0.071, cos=0.303), tot_loss_proj:1.904 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.911 (perp=7.672, rec=0.074, cos=0.302), tot_loss_proj:1.905 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.897 (perp=7.672, rec=0.060, cos=0.302), tot_loss_proj:1.896 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.896 (perp=7.672, rec=0.060, cos=0.302), tot_loss_proj:1.903 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.892 (perp=7.672, rec=0.056, cos=0.302), tot_loss_proj:1.916 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.903 (perp=7.672, rec=0.067, cos=0.302), tot_loss_proj:1.911 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.902 (perp=7.672, rec=0.064, cos=0.303), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.910 (perp=7.672, rec=0.073, cos=0.302), tot_loss_proj:1.909 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.898 (perp=7.672, rec=0.062, cos=0.302), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.905 (perp=7.672, rec=0.068, cos=0.302), tot_loss_proj:1.913 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.905 (perp=7.672, rec=0.070, cos=0.301), tot_loss_proj:1.907 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.900 (perp=7.672, rec=0.064, cos=0.302), tot_loss_proj:1.896 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.895 (perp=7.672, rec=0.059, cos=0.302), tot_loss_proj:1.908 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.893 (perp=7.672, rec=0.056, cos=0.302), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.906 (perp=7.672, rec=0.070, cos=0.302), tot_loss_proj:1.904 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.897 (perp=7.672, rec=0.061, cos=0.302), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.901 (perp=7.672, rec=0.064, cos=0.303), tot_loss_proj:1.896 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.903 (perp=7.672, rec=0.066, cos=0.302), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.898 (perp=7.672, rec=0.061, cos=0.302), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.895 (perp=7.672, rec=0.059, cos=0.302), tot_loss_proj:1.909 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.909 (perp=7.672, rec=0.072, cos=0.302), tot_loss_proj:1.902 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.904 (perp=7.672, rec=0.067, cos=0.302), tot_loss_proj:1.902 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.894 (perp=7.672, rec=0.058, cos=0.302), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.901 (perp=7.672, rec=0.064, cos=0.303), tot_loss_proj:1.900 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.896 (perp=7.672, rec=0.059, cos=0.302), tot_loss_proj:1.906 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.893 (perp=7.672, rec=0.057, cos=0.302), tot_loss_proj:1.901 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.904 (perp=7.672, rec=0.067, cos=0.302), tot_loss_proj:1.915 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.903 (perp=7.672, rec=0.066, cos=0.303), tot_loss_proj:1.910 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.329 | p: 89.684 | r: 90.963
rouge2     | fm: 57.629 | p: 57.330 | r: 58.016
rougeL     | fm: 79.021 | p: 78.592 | r: 79.601
rougeLsum  | fm: 79.053 | p: 78.586 | r: 79.683
r1fm+r2fm = 147.958

input #66 time: 0:08:44 | total time: 9:39:37


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.7842753555351167
highest_index [0]
highest [0.7842753555351167]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 0.9496694207191467 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9220554828643799 for ['[CLS] acretis smiley moth toward ass rhine xbox piece rebranded [SEP]']
[Init] best rec loss: 0.9057326316833496 for ['[CLS] fastestedance ;eding buckingham jill ranges australia international property [SEP]']
[Init] best rec loss: 0.8872330188751221 for ['[CLS] ×ator bears weight overturned um turning pay humanity glee [SEP]']
[Init] best rec loss: 0.8822354674339294 for ['[CLS] carries garden deputy creation attitudes victim mine waitingapugh [SEP]']
[Init] best rec loss: 0.8817643523216248 for ['[CLS] holyvy war hingesozuche tessa ] commentary justice [SEP]']
[Init] best rec loss: 0.8796915411949158 for ['[CLS]ism response no productions savagemorphism sports short eugenelika [SEP]']
[Init] best rec loss: 0.877487063407898 for ['[CLS]ha twenty door cock school tierney inventorneer equal really [SEP]']
[Init] best perm rec loss: 0.8766395449638367 for ['[CLS] cock door inventor really equal tierneyneer twentyha school [SEP]']
[Init] best perm rec loss: 0.8712531924247742 for ['[CLS] tierney equal school really doorhaneer cock twenty inventor [SEP]']
[Init] best perm rec loss: 0.8707636594772339 for ['[CLS] cockhaneer really twenty door equal tierney school inventor [SEP]']
[Init] best perm rec loss: 0.8692450523376465 for ['[CLS] inventorneer twenty cockha school tierney door equal really [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.888 (perp=10.954, rec=0.314, cos=0.383), tot_loss_proj:3.270 [t=0.22s]
prediction: ['[CLS] warmming kind immediate kind first type kris for kind [SEP]']
[ 100/2000] tot_loss=3.112 (perp=12.467, rec=0.236, cos=0.383), tot_loss_proj:3.944 [t=0.22s]
prediction: ['[CLS]warmingming immediate kind secondary type santa audio kind [SEP]']
[ 150/2000] tot_loss=3.061 (perp=12.385, rec=0.196, cos=0.388), tot_loss_proj:3.870 [t=0.22s]
prediction: ['[CLS]warmingwar immediate kind non heartentalental kind [SEP]']
[ 200/2000] tot_loss=2.672 (perp=10.641, rec=0.155, cos=0.389), tot_loss_proj:2.950 [t=0.22s]
prediction: ['[CLS]warming heartental, nonjuentalental kind [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.190 (perp=8.474, rec=0.109, cos=0.387), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS]warming, heartental nonjugmental kind [SEP]']
[ 300/2000] tot_loss=2.182 (perp=8.474, rec=0.106, cos=0.381), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS]warming, heartental nonjugmental kind [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.121 (perp=8.241, rec=0.090, cos=0.383), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS], heartwarmingental nonjugmental kind [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.864 (perp=6.978, rec=0.084, cos=0.384), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] kind heartwarmingental nonjugmental, [SEP]']
[ 450/2000] tot_loss=1.862 (perp=6.978, rec=0.082, cos=0.384), tot_loss_proj:2.148 [t=0.23s]
prediction: ['[CLS] kind heartwarmingental nonjugmental, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.859 (perp=6.978, rec=0.077, cos=0.386), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] kind heartwarmingental nonjugmental, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.853 (perp=6.978, rec=0.074, cos=0.384), tot_loss_proj:2.139 [t=0.22s]
prediction: ['[CLS] kind heartwarmingental nonjugmental, [SEP]']
[ 600/2000] tot_loss=1.849 (perp=6.978, rec=0.069, cos=0.384), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] kind heartwarmingental nonjugmental, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.886 (perp=7.159, rec=0.071, cos=0.383), tot_loss_proj:2.274 [t=0.23s]
prediction: ['[CLS] kind heartwarmingd nonjugmental, [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.563 (perp=5.526, rec=0.074, cos=0.384), tot_loss_proj:1.757 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
[ 750/2000] tot_loss=1.560 (perp=5.526, rec=0.070, cos=0.384), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.554 (perp=5.526, rec=0.067, cos=0.382), tot_loss_proj:1.762 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.558 (perp=5.526, rec=0.068, cos=0.385), tot_loss_proj:1.762 [t=0.22s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
[ 900/2000] tot_loss=1.559 (perp=5.526, rec=0.071, cos=0.383), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.554 (perp=5.526, rec=0.065, cos=0.384), tot_loss_proj:1.763 [t=0.22s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.565 (perp=5.526, rec=0.077, cos=0.383), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
[1050/2000] tot_loss=1.550 (perp=5.526, rec=0.061, cos=0.384), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.557 (perp=5.526, rec=0.067, cos=0.385), tot_loss_proj:1.751 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.555 (perp=5.526, rec=0.065, cos=0.385), tot_loss_proj:1.756 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
[1200/2000] tot_loss=1.551 (perp=5.526, rec=0.061, cos=0.384), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.559 (perp=5.526, rec=0.069, cos=0.385), tot_loss_proj:1.763 [t=0.22s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.550 (perp=5.526, rec=0.061, cos=0.384), tot_loss_proj:1.757 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
[1350/2000] tot_loss=1.551 (perp=5.526, rec=0.061, cos=0.385), tot_loss_proj:1.756 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.553 (perp=5.526, rec=0.063, cos=0.385), tot_loss_proj:1.753 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.552 (perp=5.526, rec=0.062, cos=0.384), tot_loss_proj:1.760 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
[1500/2000] tot_loss=1.552 (perp=5.526, rec=0.062, cos=0.385), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.557 (perp=5.526, rec=0.068, cos=0.384), tot_loss_proj:1.753 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.558 (perp=5.526, rec=0.068, cos=0.384), tot_loss_proj:1.763 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
[1650/2000] tot_loss=1.559 (perp=5.526, rec=0.069, cos=0.384), tot_loss_proj:1.755 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.559 (perp=5.526, rec=0.070, cos=0.384), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.552 (perp=5.526, rec=0.063, cos=0.385), tot_loss_proj:1.749 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
[1800/2000] tot_loss=1.556 (perp=5.526, rec=0.067, cos=0.384), tot_loss_proj:1.756 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.557 (perp=5.526, rec=0.067, cos=0.384), tot_loss_proj:1.754 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.562 (perp=5.526, rec=0.073, cos=0.384), tot_loss_proj:1.753 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
[1950/2000] tot_loss=1.547 (perp=5.526, rec=0.058, cos=0.384), tot_loss_proj:1.761 [t=0.23s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.560 (perp=5.526, rec=0.071, cos=0.384), tot_loss_proj:1.760 [t=0.22s]
prediction: ['[CLS] kind heartwarming nonjudgmental, [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind heartwarming nonjudgmental, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 90.404 | p: 89.829 | r: 91.147
rouge2     | fm: 56.970 | p: 56.698 | r: 57.384
rougeL     | fm: 78.935 | p: 78.525 | r: 79.478
rougeLsum  | fm: 79.030 | p: 78.513 | r: 79.609
r1fm+r2fm = 147.374

input #67 time: 0:08:50 | total time: 9:48:27


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.8574099297786106
highest_index [0]
highest [0.8574099297786106]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9538620710372925 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9320346117019653 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 0.9287944436073303 for ['[CLS]pped raise marx driving claims steadily racial shame hispanic big under charlie sinks [SEP]']
[Init] best rec loss: 0.9277143478393555 for ['[CLS] outcome swan national dialed apparently littlechi horror why supply targeted face ahl [SEP]']
[Init] best rec loss: 0.9088298082351685 for ['[CLS] feelings stole besides spoil bit type decay spider insteadane about ars payments [SEP]']
[Init] best rec loss: 0.8797858357429504 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8743072152137756 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8674140572547913 for ['[CLS]yn possiblyiferous view councils form. medal comfort beth floor died riding [SEP]']
[Init] best perm rec loss: 0.8674046397209167 for ['[CLS] riding possiblyiferousyn died. form floor medal beth comfort view councils [SEP]']
[Init] best perm rec loss: 0.8669089078903198 for ['[CLS]iferous beth floor diedyn form possibly medal councils comfort. view riding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.009 (perp=12.488, rec=0.252, cos=0.259), tot_loss_proj:3.961 [t=0.22s]
prediction: ['[CLS] off unprecedented vicious relatives thanonecoisso absurd absurd? francisco [SEP]']
[ 100/2000] tot_loss=2.874 (perp=12.144, rec=0.187, cos=0.259), tot_loss_proj:3.626 [t=0.22s]
prediction: ['[CLS] off vicious vicious acrescooneco,uth absurd absurd, weeks [SEP]']
[ 150/2000] tot_loss=2.998 (perp=12.974, rec=0.143, cos=0.260), tot_loss_proj:3.745 [t=0.22s]
prediction: ['[CLS] / vicious vicious acrescoableco,uthuth absurd andmbling [SEP]']
[ 200/2000] tot_loss=3.087 (perp=13.432, rec=0.149, cos=0.252), tot_loss_proj:3.860 [t=0.22s]
prediction: ['[CLS] / vicious vicious treescoableco,uthuth absurd and 郡 [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.588 (perp=10.964, rec=0.137, cos=0.258), tot_loss_proj:3.201 [t=0.22s]
prediction: ['[CLS] / vicious vicious unacouthableco,uth absurd andisance [SEP]']
[ 300/2000] tot_loss=2.608 (perp=11.164, rec=0.117, cos=0.258), tot_loss_proj:3.238 [t=0.22s]
prediction: ['[CLS] / vicious vicious unecouthableco,uth absurd andisance [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.479 (perp=10.506, rec=0.121, cos=0.257), tot_loss_proj:3.047 [t=0.23s]
prediction: ['[CLS] / vicious vicious unecouthhen,couth absurd and 郡 [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.360 (perp=9.837, rec=0.130, cos=0.262), tot_loss_proj:3.450 [t=0.23s]
prediction: ['[CLS] unaing vicious viciouscouthhen,couth absurd andudence [SEP]']
[ 450/2000] tot_loss=2.363 (perp=9.919, rec=0.122, cos=0.257), tot_loss_proj:3.164 [t=0.23s]
prediction: ['[CLS] una / vicious viciouscouthhen,couth absurd and rupert [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.994 (perp=8.072, rec=0.120, cos=0.259), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] une, viciouscouth,, viciouscouth absurd and rupert [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.801 (perp=7.139, rec=0.116, cos=0.257), tot_loss_proj:2.445 [t=0.23s]
prediction: ['[CLS] une, viciouscouth, and viciouscouth absurd,omp [SEP]']
[ 600/2000] tot_loss=2.262 (perp=9.454, rec=0.116, cos=0.255), tot_loss_proj:2.834 [t=0.23s]
prediction: ['[CLS] une, vicious incuthsible and viciouscouth absurd,omp [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.189 (perp=9.124, rec=0.105, cos=0.259), tot_loss_proj:2.711 [t=0.23s]
prediction: ['[CLS] une vicious, incuthsible and viciouscouth absurd,omp [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.114 (perp=8.738, rec=0.111, cos=0.256), tot_loss_proj:2.478 [t=0.23s]
prediction: ['[CLS] uneomp vicious, incsiblesible and viciouscouth absurd, [SEP]']
[ 750/2000] tot_loss=2.106 (perp=8.738, rec=0.103, cos=0.255), tot_loss_proj:2.474 [t=0.22s]
prediction: ['[CLS] uneomp vicious, incsiblesible and viciouscouth absurd, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.961 (perp=7.956, rec=0.113, cos=0.257), tot_loss_proj:2.273 [t=0.23s]
prediction: ['[CLS] unesible vicious, incompsible and viciouscouth absurd, [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.128 (perp=8.824, rec=0.108, cos=0.255), tot_loss_proj:2.457 [t=0.22s]
prediction: ['[CLS] unesible andrued, incompsible viciouscouth absurd, [SEP]']
[ 900/2000] tot_loss=2.173 (perp=9.080, rec=0.097, cos=0.259), tot_loss_proj:2.515 [t=0.23s]
prediction: ['[CLS] unesible andrued, unompsible viciouscouth absurd, [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.039 (perp=8.366, rec=0.106, cos=0.260), tot_loss_proj:2.413 [t=0.23s]
prediction: ['[CLS] unesible andompsible viciousrued, uncouth absurd, [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.926 (perp=7.837, rec=0.099, cos=0.260), tot_loss_proj:2.455 [t=0.22s]
prediction: ['[CLS]sible and uneompsible vicious christine, uncouth absurd, [SEP]']
[1050/2000] tot_loss=1.900 (perp=7.769, rec=0.085, cos=0.261), tot_loss_proj:2.360 [t=0.23s]
prediction: ['[CLS]sible and uneompsible viciousrued, uncouth absurd, [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.858 (perp=7.545, rec=0.088, cos=0.261), tot_loss_proj:2.456 [t=0.22s]
prediction: ['[CLS]sible and unompsible, viciousrued uncouth absurd, [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.859 (perp=7.499, rec=0.100, cos=0.260), tot_loss_proj:2.526 [t=0.23s]
prediction: ['[CLS]sible and unompsible, vicious uncouth absurd christine, [SEP]']
[1200/2000] tot_loss=2.023 (perp=8.303, rec=0.100, cos=0.261), tot_loss_proj:2.849 [t=0.23s]
prediction: ['[CLS]sible and unomphen, vicious uncouth absurd christine, [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.953 (perp=7.952, rec=0.101, cos=0.262), tot_loss_proj:2.891 [t=0.23s]
prediction: ['[CLS]sible and unomphen vicious, uncouth absurd christine, [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.005 (perp=8.229, rec=0.098, cos=0.262), tot_loss_proj:2.871 [t=0.23s]
prediction: ['[CLS]sible and unehenomp vicious, uncouth absurdrued, [SEP]']
[1350/2000] tot_loss=1.998 (perp=8.229, rec=0.091, cos=0.261), tot_loss_proj:2.871 [t=0.23s]
prediction: ['[CLS]sible and unehenomp vicious, uncouth absurdrued, [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.982 (perp=8.156, rec=0.091, cos=0.260), tot_loss_proj:2.996 [t=0.23s]
prediction: ['[CLS]sible and unomphen vicious, uncouth absurdrued, [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.063 (perp=8.537, rec=0.096, cos=0.259), tot_loss_proj:2.918 [t=0.23s]
prediction: ['[CLS]sible and unomphen christine vicious, uncouth absurd, [SEP]']
[1500/2000] tot_loss=2.062 (perp=8.537, rec=0.095, cos=0.260), tot_loss_proj:2.920 [t=0.23s]
prediction: ['[CLS]sible and unomphen christine vicious, uncouth absurd, [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.958 (perp=8.043, rec=0.090, cos=0.260), tot_loss_proj:2.743 [t=0.23s]
prediction: ['[CLS]sible and viciousomphen christine un, uncouth absurd, [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.905 (perp=7.784, rec=0.089, cos=0.260), tot_loss_proj:2.916 [t=0.23s]
prediction: ['[CLS]sible and viciousomphen christine, uncouth absurd, una [SEP]']
[1650/2000] tot_loss=1.905 (perp=7.784, rec=0.089, cos=0.259), tot_loss_proj:2.920 [t=0.23s]
prediction: ['[CLS]sible and viciousomphen christine, uncouth absurd, una [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.784 (perp=7.138, rec=0.097, cos=0.259), tot_loss_proj:2.708 [t=0.23s]
prediction: ['[CLS]sible and viciousomphen, uncouth absurd christine, una [SEP]']
Attempt swap
[1750/2000] tot_loss=1.780 (perp=7.138, rec=0.093, cos=0.260), tot_loss_proj:2.714 [t=0.23s]
prediction: ['[CLS]sible and viciousomphen, uncouth absurd christine, una [SEP]']
[1800/2000] tot_loss=1.783 (perp=7.138, rec=0.095, cos=0.260), tot_loss_proj:2.702 [t=0.23s]
prediction: ['[CLS]sible and viciousomphen, uncouth absurd christine, una [SEP]']
Attempt swap
[1850/2000] tot_loss=1.780 (perp=7.138, rec=0.093, cos=0.260), tot_loss_proj:2.707 [t=0.23s]
prediction: ['[CLS]sible and viciousomphen, uncouth absurd christine, una [SEP]']
Attempt swap
[1900/2000] tot_loss=1.781 (perp=7.138, rec=0.094, cos=0.260), tot_loss_proj:2.705 [t=0.23s]
prediction: ['[CLS]sible and viciousomphen, uncouth absurd christine, una [SEP]']
[1950/2000] tot_loss=1.783 (perp=7.138, rec=0.096, cos=0.260), tot_loss_proj:2.708 [t=0.23s]
prediction: ['[CLS]sible and viciousomphen, uncouth absurd christine, una [SEP]']
Attempt swap
[2000/2000] tot_loss=1.782 (perp=7.138, rec=0.095, cos=0.260), tot_loss_proj:2.711 [t=0.23s]
prediction: ['[CLS]sible and viciousomphen, uncouth absurd christine, una [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS]sible and viciousomphen, uncouth absurd christine, una [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.500 | p: 55.556 | r: 71.429
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 44.444 | r: 57.143
rougeLsum  | fm: 50.000 | p: 44.444 | r: 57.143
r1fm+r2fm = 62.500

[Aggregate metrics]:
rouge1     | fm: 90.038 | p: 89.392 | r: 90.838
rouge2     | fm: 56.455 | p: 56.126 | r: 56.796
rougeL     | fm: 78.597 | p: 78.076 | r: 79.266
rougeLsum  | fm: 78.597 | p: 77.997 | r: 79.293
r1fm+r2fm = 146.493

input #68 time: 0:08:51 | total time: 9:57:18


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.8093970875011713
highest_index [0]
highest [0.8093970875011713]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 0.978990375995636 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9788900017738342 for ['[CLS] new nod none left bryson gainering state chris pay league teams dea set during store [SEP]']
[Init] best rec loss: 0.9775137305259705 for ['[CLS] later dressed creed among label effect pickering servants duc evergreen along [CLS] court afar trey bombay [SEP]']
[Init] best rec loss: 0.9650624394416809 for ['[CLS]aver grandson cleared sergei spare reserve / earthquake mouse loudly student celebrated pill till le tunnel [SEP]']
[Init] best rec loss: 0.9419354200363159 for ['[CLS] closelein am ( deadrga liz range bragg depended states passes stock past messll [SEP]']
[Init] best perm rec loss: 0.9406357407569885 for ['[CLS] stock depended bragg am states messll past close rangerga ( liz passes deadlein [SEP]']
[Init] best perm rec loss: 0.9388518333435059 for ['[CLS] ( passes statesrga am depended liz close bragg mess stockleinll past dead range [SEP]']
[Init] best perm rec loss: 0.9384272694587708 for ['[CLS] passes depended am statesll range mess ( close bragg past dead liz stockrgalein [SEP]']
[Init] best perm rec loss: 0.9375550150871277 for ['[CLS] dead states amrga close passes messll past ( range liz bragg stocklein depended [SEP]']
[Init] best perm rec loss: 0.9372665286064148 for ['[CLS] passes dead close amll stockrga range past mess depended bragg states lizlein ( [SEP]']
[Init] best perm rec loss: 0.9363768696784973 for ['[CLS]rga bragg liz am states messll stock range close dependedlein passes ( past dead [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.671 (perp=12.549, rec=0.682, cos=0.479), tot_loss_proj:4.207 [t=0.22s]
prediction: ['[CLS]tree likely prosecutor by course smoking and black. problemsais wrote olympia imaginemark ricky [SEP]']
[ 100/2000] tot_loss=3.672 (perp=12.390, rec=0.643, cos=0.551), tot_loss_proj:4.040 [t=0.22s]
prediction: ['[CLS]rys reputed detector once course stupid and butch dead seriesische language liberal kn ; samples [SEP]']
[ 150/2000] tot_loss=3.393 (perp=12.454, rec=0.565, cos=0.337), tot_loss_proj:4.386 [t=0.22s]
prediction: ['[CLS]urities won detector a regime. and butchless seriesische interesting liberal stretched & - [SEP]']
[ 200/2000] tot_loss=2.965 (perp=10.210, rec=0.554, cos=0.369), tot_loss_proj:4.006 [t=0.22s]
prediction: ['[CLS] lloyd went guilty missing hundreds. and butchless -, interesting musician ⟩ ;, [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.510 (perp=8.265, rec=0.521, cos=0.336), tot_loss_proj:3.621 [t=0.22s]
prediction: ['[CLS] lloyd is guilty, only hundreds. and killer. - something alec ⟩., [SEP]']
[ 300/2000] tot_loss=2.410 (perp=8.063, rec=0.480, cos=0.317), tot_loss_proj:3.479 [t=0.22s]
prediction: ['[CLS] lloyd is guilty, only hundreds. and of. - something alec ⟩., [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.439 (perp=8.102, rec=0.498, cos=0.321), tot_loss_proj:3.558 [t=0.22s]
prediction: ['[CLS] lloyd, guilty, something hundreds. and green. - only alec ⟩., [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.639 (perp=9.290, rec=0.464, cos=0.318), tot_loss_proj:3.851 [t=0.22s]
prediction: ['[CLS]imate absolute guilty, something hundreds funny and of dead. - alec ⟩., [SEP]']
[ 450/2000] tot_loss=2.792 (perp=10.121, rec=0.440, cos=0.328), tot_loss_proj:3.994 [t=0.22s]
prediction: ['[CLS]alia absolute guilty, real smelling funny and real dead. - alec ⟩ -, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.848 (perp=9.366, rec=0.451, cos=0.523), tot_loss_proj:3.687 [t=0.22s]
prediction: ['[CLS]alia genuinely exist, real guilty funny and real dead. - alec ⟩ -, [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.661 (perp=9.547, rec=0.444, cos=0.308), tot_loss_proj:3.825 [t=0.22s]
prediction: ['[CLS]alia genuinely, real guilty exist funny, of dead. - alec ⟩ -, [SEP]']
[ 600/2000] tot_loss=2.414 (perp=8.471, rec=0.422, cos=0.297), tot_loss_proj:3.327 [t=0.22s]
prediction: ['[CLS]nta genuinely, real guilty smelling funny, of dead. - funny ⟩., [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.353 (perp=8.119, rec=0.399, cos=0.331), tot_loss_proj:3.120 [t=0.22s]
prediction: ['[CLS]nta genuinely, real guilty smelling, funny, dead. - funny ⟩., [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.304 (perp=7.819, rec=0.412, cos=0.328), tot_loss_proj:3.183 [t=0.22s]
prediction: ['[CLS]nta genuinely implicated, real enough, funny, dead. - funny ⟩., [SEP]']
[ 750/2000] tot_loss=2.372 (perp=8.203, rec=0.386, cos=0.346), tot_loss_proj:3.129 [t=0.22s]
prediction: ['[CLS]nta genuinely guilty, real enough, funny, -. - subtle ⟩., [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.391 (perp=8.401, rec=0.383, cos=0.328), tot_loss_proj:3.286 [t=0.22s]
prediction: ['[CLS]nta tha guilty, real enough, funny, - subtle. - ⟩., [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.364 (perp=8.124, rec=0.434, cos=0.306), tot_loss_proj:3.268 [t=0.22s]
prediction: ['[CLS]nta - guilty, real smelling, funny, -, subtle. - ⟩ - [SEP]']
[ 900/2000] tot_loss=2.252 (perp=7.744, rec=0.383, cos=0.320), tot_loss_proj:3.188 [t=0.22s]
prediction: ['[CLS]nta genuinely guilty, romance enough, funny, -, subtle. - ⟩. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.256 (perp=7.689, rec=0.382, cos=0.337), tot_loss_proj:2.767 [t=0.22s]
prediction: ['[CLS]nta genuinely smelling, real winner, funny, -, subtle. - ⟩. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.375 (perp=7.125, rec=0.410, cos=0.539), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS]nta genuinely smelling, real, funny, -, subtle guilty. - ⟩. [SEP]']
[1050/2000] tot_loss=2.065 (perp=6.761, rec=0.374, cos=0.339), tot_loss_proj:2.760 [t=0.22s]
prediction: ['[CLS]nta genuinely enough, real, funny, -, subtle guilty. - ⟩. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.011 (perp=6.513, rec=0.371, cos=0.337), tot_loss_proj:2.637 [t=0.22s]
prediction: ['[CLS]nta genuinely enough, real, funny, - subtle, guilty. - ⟩. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.036 (perp=6.655, rec=0.364, cos=0.341), tot_loss_proj:2.568 [t=0.22s]
prediction: ['[CLS]nta genuinely enough, real, funny, - subtle, winner. - ⟩. [SEP]']
[1200/2000] tot_loss=1.974 (perp=6.399, rec=0.360, cos=0.334), tot_loss_proj:2.289 [t=0.22s]
prediction: ['[CLS]nta genuinely enough, real, funny, - subtle, winner. - steve. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.974 (perp=6.399, rec=0.363, cos=0.332), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS]nta genuinely enough, real, funny, - subtle, winner. - steve. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.077 (perp=6.858, rec=0.365, cos=0.340), tot_loss_proj:2.662 [t=0.22s]
prediction: ['[CLS]nta genuinelyxious, real, funny, - subtle, steve. - winner. [SEP]']
[1350/2000] tot_loss=2.053 (perp=6.858, rec=0.358, cos=0.323), tot_loss_proj:2.661 [t=0.22s]
prediction: ['[CLS]nta genuinelyxious, real, funny, - subtle, steve. - winner. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.056 (perp=6.858, rec=0.363, cos=0.322), tot_loss_proj:2.654 [t=0.22s]
prediction: ['[CLS]nta genuinelyxious, real, funny, - subtle, steve. - winner. [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.998 (perp=6.409, rec=0.371, cos=0.345), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
[1500/2000] tot_loss=1.985 (perp=6.409, rec=0.358, cos=0.345), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.975 (perp=6.409, rec=0.357, cos=0.337), tot_loss_proj:2.586 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.985 (perp=6.409, rec=0.352, cos=0.352), tot_loss_proj:2.583 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
[1650/2000] tot_loss=1.968 (perp=6.409, rec=0.354, cos=0.332), tot_loss_proj:2.584 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.957 (perp=6.409, rec=0.346, cos=0.329), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.983 (perp=6.409, rec=0.351, cos=0.350), tot_loss_proj:2.585 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
[1800/2000] tot_loss=1.975 (perp=6.409, rec=0.349, cos=0.343), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.964 (perp=6.409, rec=0.353, cos=0.329), tot_loss_proj:2.585 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.963 (perp=6.409, rec=0.346, cos=0.335), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
[1950/2000] tot_loss=1.969 (perp=6.409, rec=0.346, cos=0.342), tot_loss_proj:2.584 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.960 (perp=6.409, rec=0.343, cos=0.335), tot_loss_proj:2.583 [t=0.22s]
prediction: ['[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS]ntaxious, real, genuinely funny, - subtle, steve. - winner. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.158 | p: 66.667 | r: 60.000
rouge2     | fm: 11.765 | p: 12.500 | r: 11.111
rougeL     | fm: 52.632 | p: 55.556 | r: 50.000
rougeLsum  | fm: 52.632 | p: 55.556 | r: 50.000
r1fm+r2fm = 74.923

[Aggregate metrics]:
rouge1     | fm: 89.589 | p: 89.000 | r: 90.377
rouge2     | fm: 55.746 | p: 55.394 | r: 56.093
rougeL     | fm: 78.131 | p: 77.683 | r: 78.753
rougeLsum  | fm: 78.212 | p: 77.728 | r: 78.817
r1fm+r2fm = 145.335

input #69 time: 0:08:45 | total time: 10:06:04


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9342322737916053
highest_index [0]
highest [0.9342322737916053]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8013858795166016 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.7678056359291077 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.744698703289032 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7439401149749756 for ['[CLS] oliveira jamie position crime belong leadersla [SEP]']
[Init] best rec loss: 0.7290581464767456 for ['[CLS] ga characteristic jump make deaths composed ⟩ [SEP]']
[Init] best rec loss: 0.7055463790893555 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 0.6854400634765625 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best perm rec loss: 0.6814175844192505 for ['[CLS]bution party ি muscle guy modern bob [SEP]']
[Init] best perm rec loss: 0.6801851987838745 for ['[CLS] ি guy modern muscle bob partybution [SEP]']
[Init] best perm rec loss: 0.6790055632591248 for ['[CLS] muscle িbution bob party modern guy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.913 (perp=12.188, rec=0.326, cos=0.150), tot_loss_proj:3.508 [t=0.22s]
prediction: ['[CLS] linnaeus cl digit clunkunk screen [SEP]']
[ 100/2000] tot_loss=1.830 (perp=7.781, rec=0.153, cos=0.121), tot_loss_proj:1.993 [t=0.22s]
prediction: ['[CLS] gets clunky screenunky [SEP]']
[ 150/2000] tot_loss=1.972 (perp=8.782, rec=0.093, cos=0.123), tot_loss_proj:2.393 [t=0.22s]
prediction: ['[CLS] gets clunk on screenunky [SEP]']
[ 200/2000] tot_loss=1.971 (perp=8.782, rec=0.086, cos=0.128), tot_loss_proj:2.383 [t=0.22s]
prediction: ['[CLS] gets clunk on screenunky [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.915 (perp=8.519, rec=0.083, cos=0.128), tot_loss_proj:2.089 [t=0.22s]
prediction: ['[CLS] gets clunky on screenunk [SEP]']
[ 300/2000] tot_loss=1.909 (perp=8.519, rec=0.079, cos=0.126), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] gets clunky on screenunk [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.776 (perp=7.893, rec=0.076, cos=0.122), tot_loss_proj:1.884 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.775 (perp=7.893, rec=0.074, cos=0.123), tot_loss_proj:1.887 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
[ 450/2000] tot_loss=1.782 (perp=7.893, rec=0.079, cos=0.124), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.772 (perp=7.893, rec=0.074, cos=0.120), tot_loss_proj:1.909 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.780 (perp=7.893, rec=0.076, cos=0.126), tot_loss_proj:1.910 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
[ 600/2000] tot_loss=1.774 (perp=7.893, rec=0.071, cos=0.125), tot_loss_proj:1.916 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.779 (perp=7.893, rec=0.078, cos=0.122), tot_loss_proj:1.917 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.770 (perp=7.893, rec=0.068, cos=0.124), tot_loss_proj:1.925 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
[ 750/2000] tot_loss=1.764 (perp=7.893, rec=0.064, cos=0.122), tot_loss_proj:1.928 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.770 (perp=7.893, rec=0.065, cos=0.127), tot_loss_proj:1.933 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.769 (perp=7.893, rec=0.069, cos=0.122), tot_loss_proj:1.935 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
[ 900/2000] tot_loss=1.774 (perp=7.893, rec=0.070, cos=0.126), tot_loss_proj:1.938 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.777 (perp=7.893, rec=0.075, cos=0.123), tot_loss_proj:1.939 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.769 (perp=7.893, rec=0.065, cos=0.126), tot_loss_proj:1.936 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
[1050/2000] tot_loss=1.769 (perp=7.893, rec=0.067, cos=0.123), tot_loss_proj:1.943 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.765 (perp=7.893, rec=0.062, cos=0.125), tot_loss_proj:1.944 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.770 (perp=7.893, rec=0.066, cos=0.125), tot_loss_proj:1.937 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
[1200/2000] tot_loss=1.766 (perp=7.893, rec=0.064, cos=0.124), tot_loss_proj:1.948 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.770 (perp=7.893, rec=0.067, cos=0.125), tot_loss_proj:1.942 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.784 (perp=7.893, rec=0.076, cos=0.129), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
[1350/2000] tot_loss=1.773 (perp=7.893, rec=0.069, cos=0.125), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.763 (perp=7.893, rec=0.060, cos=0.124), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.764 (perp=7.893, rec=0.061, cos=0.125), tot_loss_proj:1.947 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
[1500/2000] tot_loss=1.765 (perp=7.893, rec=0.062, cos=0.125), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.770 (perp=7.893, rec=0.068, cos=0.123), tot_loss_proj:1.945 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.775 (perp=7.893, rec=0.072, cos=0.125), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
[1650/2000] tot_loss=1.774 (perp=7.893, rec=0.072, cos=0.124), tot_loss_proj:1.952 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.770 (perp=7.893, rec=0.066, cos=0.126), tot_loss_proj:1.952 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.770 (perp=7.893, rec=0.066, cos=0.125), tot_loss_proj:1.952 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
[1800/2000] tot_loss=1.771 (perp=7.893, rec=0.069, cos=0.124), tot_loss_proj:1.947 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.773 (perp=7.893, rec=0.070, cos=0.124), tot_loss_proj:1.949 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.769 (perp=7.893, rec=0.065, cos=0.125), tot_loss_proj:1.950 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
[1950/2000] tot_loss=1.767 (perp=7.893, rec=0.064, cos=0.125), tot_loss_proj:1.950 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.771 (perp=7.893, rec=0.068, cos=0.125), tot_loss_proj:1.949 [t=0.22s]
prediction: ['[CLS] gets clunkunky on screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] gets clunkunky on screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 36.364 | p: 40.000 | r: 33.333
rougeL     | fm: 76.923 | p: 83.333 | r: 71.429
rougeLsum  | fm: 76.923 | p: 83.333 | r: 71.429
r1fm+r2fm = 113.287

[Aggregate metrics]:
rouge1     | fm: 89.437 | p: 88.942 | r: 90.100
rouge2     | fm: 55.217 | p: 54.992 | r: 55.542
rougeL     | fm: 78.165 | p: 77.713 | r: 78.698
rougeLsum  | fm: 78.166 | p: 77.817 | r: 78.681
r1fm+r2fm = 144.653

input #70 time: 0:08:42 | total time: 10:14:47


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.8879284417251004
highest_index [0]
highest [0.8879284417251004]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8953934907913208 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.8944345116615295 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8899415135383606 for ['[CLS]kledclaiming solid due tear stakesaint flight ken keel receiver living duval us tottenham [SEP]']
[Init] best rec loss: 0.8810956478118896 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 0.8776918649673462 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 0.8679511547088623 for ['[CLS] composed warsselle ty urbantist empireneas amendment broadbandcat murdereo money appoint [SEP]']
[Init] best rec loss: 0.8611928224563599 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 0.8496037125587463 for ['[CLS]ine runways oregon bored : towardsgold occurred snow abovegerstypical definitely holiday rooney [SEP]']
[Init] best rec loss: 0.8490319848060608 for ['[CLS]lon dictionary short prairie mayatypic conditioning flyingto etc men provided star cassidy gems [SEP]']
[Init] best rec loss: 0.8473761081695557 for ['[CLS] jean bed queens fewer of professor fall ram surhear marshall over liam molly creatures [SEP]']
[Init] best perm rec loss: 0.8473685383796692 for ['[CLS] ramhear liam bed fall jean fewer professor over creatures queens molly sur marshall of [SEP]']
[Init] best perm rec loss: 0.8459030985832214 for ['[CLS] over creatures marshall bed jean sur mollyhear ram fall queens of professor liam fewer [SEP]']
[Init] best perm rec loss: 0.8441579937934875 for ['[CLS] mollyhear sur fewer bed of fall over queens creatures professor marshall ram jean liam [SEP]']
[Init] best perm rec loss: 0.8437545299530029 for ['[CLS] marshall sur fall over liam professor of creatures ram jean fewer queens molly bedhear [SEP]']
[Init] best perm rec loss: 0.8426315784454346 for ['[CLS] marshall fewer bed surhear molly of jean ram creatures over liam fall queens professor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.537 (perp=10.002, rec=0.328, cos=0.209), tot_loss_proj:3.714 [t=0.22s]
prediction: ["[CLS] moment jump moment. delta or not in kill needle'moment in moment single [SEP]"]
[ 100/2000] tot_loss=2.207 (perp=8.810, rec=0.229, cos=0.217), tot_loss_proj:2.955 [t=0.22s]
prediction: ["[CLS] one jump moment not single jump not and'jump - seat - moment not [SEP]"]
[ 150/2000] tot_loss=2.149 (perp=8.932, rec=0.160, cos=0.202), tot_loss_proj:2.989 [t=0.22s]
prediction: ['[CLS] one jump moment is single jump not and - your - seat - moment not [SEP]']
[ 200/2000] tot_loss=2.209 (perp=9.425, rec=0.113, cos=0.212), tot_loss_proj:3.105 [t=0.22s]
prediction: ['[CLS] there jump moment s single jump not and - your - seat - moment not [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.133 (perp=8.825, rec=0.159, cos=0.210), tot_loss_proj:3.029 [t=0.22s]
prediction: ['[CLS] there jump moment s single jump not and - your seat - - moment not [SEP]']
[ 300/2000] tot_loss=1.971 (perp=8.208, rec=0.117, cos=0.213), tot_loss_proj:3.066 [t=0.22s]
prediction: ['[CLS] there jump moment s single jump not and in your seat - - moment not [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.815 (perp=7.523, rec=0.105, cos=0.205), tot_loss_proj:2.763 [t=0.22s]
prediction: ['[CLS] there jump moment s not and single jump in your seat - - moment not [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.642 (perp=6.678, rec=0.104, cos=0.203), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] there - s not and single jump in your jump seat - - moment not [SEP]']
[ 450/2000] tot_loss=1.730 (perp=7.150, rec=0.092, cos=0.208), tot_loss_proj:2.547 [t=0.22s]
prediction: ['[CLS] there a s not and single jump in your jump seat - - moment not [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.522 (perp=6.136, rec=0.087, cos=0.207), tot_loss_proj:2.092 [t=0.22s]
prediction: ['[CLS] there and s not a single jump in your jump seat - - moment a [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.462 (perp=5.848, rec=0.089, cos=0.203), tot_loss_proj:2.088 [t=0.22s]
prediction: ['[CLS] there and s not a single jump in your jump seat - a moment - [SEP]']
[ 600/2000] tot_loss=1.461 (perp=5.848, rec=0.083, cos=0.208), tot_loss_proj:2.095 [t=0.22s]
prediction: ['[CLS] there and s not a single jump in your jump seat - a moment - [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.365 (perp=5.422, rec=0.073, cos=0.208), tot_loss_proj:1.960 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat - a moment - [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.336 (perp=5.268, rec=0.073, cos=0.209), tot_loss_proj:1.985 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
[ 750/2000] tot_loss=1.341 (perp=5.268, rec=0.077, cos=0.211), tot_loss_proj:1.991 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.342 (perp=5.268, rec=0.078, cos=0.210), tot_loss_proj:1.991 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.332 (perp=5.268, rec=0.070, cos=0.208), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
[ 900/2000] tot_loss=1.340 (perp=5.268, rec=0.078, cos=0.208), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.329 (perp=5.268, rec=0.064, cos=0.211), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.340 (perp=5.268, rec=0.077, cos=0.209), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
[1050/2000] tot_loss=1.343 (perp=5.268, rec=0.080, cos=0.210), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.335 (perp=5.268, rec=0.070, cos=0.211), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.333 (perp=5.268, rec=0.070, cos=0.210), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
[1200/2000] tot_loss=1.340 (perp=5.268, rec=0.075, cos=0.212), tot_loss_proj:1.989 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.339 (perp=5.268, rec=0.076, cos=0.210), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.331 (perp=5.268, rec=0.067, cos=0.211), tot_loss_proj:1.983 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
[1350/2000] tot_loss=1.333 (perp=5.268, rec=0.069, cos=0.210), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.339 (perp=5.268, rec=0.076, cos=0.210), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.332 (perp=5.268, rec=0.068, cos=0.211), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
[1500/2000] tot_loss=1.326 (perp=5.268, rec=0.062, cos=0.210), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.330 (perp=5.268, rec=0.066, cos=0.211), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.331 (perp=5.268, rec=0.067, cos=0.210), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
[1650/2000] tot_loss=1.332 (perp=5.268, rec=0.068, cos=0.211), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your jump seat a moment - - [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.461 (perp=5.922, rec=0.066, cos=0.211), tot_loss_proj:2.426 [t=0.22s]
prediction: ['[CLS] and there s not a single jump in your your seat a moment - - [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.402 (perp=5.561, rec=0.081, cos=0.209), tot_loss_proj:2.330 [t=0.22s]
prediction: ['[CLS] and there your s not a single jump in your seat a moment - - [SEP]']
[1800/2000] tot_loss=1.399 (perp=5.561, rec=0.076, cos=0.210), tot_loss_proj:2.328 [t=0.22s]
prediction: ['[CLS] and there your s not a single jump in your seat a moment - - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.404 (perp=5.561, rec=0.081, cos=0.210), tot_loss_proj:2.327 [t=0.22s]
prediction: ['[CLS] and there your s not a single jump in your seat a moment - - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.398 (perp=5.561, rec=0.075, cos=0.210), tot_loss_proj:2.329 [t=0.22s]
prediction: ['[CLS] and there your s not a single jump in your seat a moment - - [SEP]']
[1950/2000] tot_loss=1.400 (perp=5.561, rec=0.076, cos=0.211), tot_loss_proj:2.327 [t=0.22s]
prediction: ['[CLS] and there your s not a single jump in your seat a moment - - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.391 (perp=5.561, rec=0.068, cos=0.211), tot_loss_proj:2.328 [t=0.22s]
prediction: ['[CLS] and there your s not a single jump in your seat a moment - - [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] and there s not a single jump in your jump seat a moment - - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.857 | p: 86.667 | r: 100.000
rouge2     | fm: 53.846 | p: 50.000 | r: 58.333
rougeL     | fm: 85.714 | p: 80.000 | r: 92.308
rougeLsum  | fm: 85.714 | p: 80.000 | r: 92.308
r1fm+r2fm = 146.703

[Aggregate metrics]:
rouge1     | fm: 89.497 | p: 88.941 | r: 90.297
rouge2     | fm: 55.327 | p: 55.037 | r: 55.680
rougeL     | fm: 78.326 | p: 77.869 | r: 78.901
rougeLsum  | fm: 78.271 | p: 77.830 | r: 78.890
r1fm+r2fm = 144.823

input #71 time: 0:08:41 | total time: 10:23:28


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.8554501887768616
highest_index [0]
highest [0.8554501887768616]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7728785276412964 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7668049335479736 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 0.7420260310173035 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7311016917228699 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 0.7290385961532593 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7285296320915222 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.726598858833313 for ['[CLS] anne proud walked originally navigation blame spurs junior eastbery and located part swiss [SEP] [SEP]']
[Init] best rec loss: 0.7027199268341064 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7019721269607544 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.700022280216217 for ['[CLS] lifeboat support nonetheless reserveungen except van! dna pork walking accidentally zone ta orbital [SEP]']
[Init] best perm rec loss: 0.6986509561538696 for ['[CLS] except pork lifeboat reserve dna ta van!ungen accidentally zone nonetheless walking support orbital [SEP]']
[Init] best perm rec loss: 0.6980438828468323 for ['[CLS] support! ta walking van dna reserve zone nonetheless orbital except pork accidentallyungen lifeboat [SEP]']
[Init] best perm rec loss: 0.6978089809417725 for ['[CLS] nonetheless orbital! zone pork lifeboatungen walking accidentally ta dna except van support reserve [SEP]']
[Init] best perm rec loss: 0.6977390646934509 for ['[CLS] support! pork dna reserve accidentally taungen except lifeboat orbital walking nonetheless zone van [SEP]']
[Init] best perm rec loss: 0.6963333487510681 for ['[CLS] zone walking accidentally support orbital nonethelessungen ta lifeboat! reserve dna van pork except [SEP]']
[Init] best perm rec loss: 0.6962297558784485 for ['[CLS] lifeboat except walking orbital pork! van reserve nonethelessungen dna zone ta support accidentally [SEP]']
[Init] best perm rec loss: 0.6957845091819763 for ['[CLS] orbital! dna ta van accidentally support reserve walking pork lifeboat exceptungen nonetheless zone [SEP]']
[Init] best perm rec loss: 0.6957789659500122 for ['[CLS] pork zone orbitalungen! lifeboat accidentally nonetheless van ta walking support dna except reserve [SEP]']
[Init] best perm rec loss: 0.6949719786643982 for ['[CLS] walking orbital! taungen reserve support van accidentally except zone pork dna nonetheless lifeboat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.893 (perp=11.306, rec=0.349, cos=0.283), tot_loss_proj:3.869 [t=0.22s]
prediction: ['[CLS] tough killing sticker you whore times no tough apparently criminals where tough harderax [SEP]']
[ 100/2000] tot_loss=2.775 (perp=11.606, rec=0.195, cos=0.259), tot_loss_proj:3.533 [t=0.22s]
prediction: ['[CLS] tough time stickeration ideological timemania tough has racial where tough harderer [SEP]']
[ 150/2000] tot_loss=2.673 (perp=11.424, rec=0.135, cos=0.253), tot_loss_proj:3.679 [t=0.22s]
prediction: ['[CLS] an time haser its violence balancing balancing tough has violence philosophy tougherer [SEP]']
[ 200/2000] tot_loss=2.477 (perp=10.582, rec=0.100, cos=0.260), tot_loss_proj:3.622 [t=0.22s]
prediction: ['[CLS] a time haser its violence balancing balancing tough has violence philosophy tougher with [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.293 (perp=9.720, rec=0.089, cos=0.260), tot_loss_proj:3.431 [t=0.22s]
prediction: ['[CLS] a time haser its violence balancing balancing tough has philosophy tougher with violence [SEP]']
[ 300/2000] tot_loss=2.294 (perp=9.720, rec=0.088, cos=0.261), tot_loss_proj:3.433 [t=0.22s]
prediction: ['[CLS] a time haser its violence balancing balancing tough has philosophy tougher with violence [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.124 (perp=8.922, rec=0.079, cos=0.261), tot_loss_proj:3.391 [t=0.22s]
prediction: ['[CLS] a time haser its violence has philosophy balancing balancing tough tougher with violence [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.014 (perp=8.365, rec=0.079, cos=0.262), tot_loss_proj:3.432 [t=0.22s]
prediction: ['[CLS] a time haser has its violence philosophy balancing balancing tough tougher with violence [SEP]']
[ 450/2000] tot_loss=2.157 (perp=9.088, rec=0.073, cos=0.267), tot_loss_proj:3.576 [t=0.22s]
prediction: ['[CLS] a time itser has its violence philosophy balancing balancing tough tough inspired with violence [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.068 (perp=8.603, rec=0.080, cos=0.268), tot_loss_proj:3.502 [t=0.22s]
prediction: ['[CLS] a time itser has its philosophy balancing violence balancing tough tough inspired with violence [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.073 (perp=8.626, rec=0.081, cos=0.266), tot_loss_proj:3.493 [t=0.22s]
prediction: ['[CLS] a time itser has its philosophy balancing violence with balancing toughfk inspired violence [SEP]']
[ 600/2000] tot_loss=2.060 (perp=8.626, rec=0.074, cos=0.261), tot_loss_proj:3.493 [t=0.22s]
prediction: ['[CLS] a time itser has its philosophy balancing violence with balancing toughfk inspired violence [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.037 (perp=8.490, rec=0.074, cos=0.264), tot_loss_proj:3.341 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing philosophy with balancing itsfk inspired violence [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.972 (perp=8.174, rec=0.072, cos=0.265), tot_loss_proj:3.147 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing with balancing its philosophyfk inspired violence [SEP]']
[ 750/2000] tot_loss=1.970 (perp=8.174, rec=0.067, cos=0.268), tot_loss_proj:3.142 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing with balancing its philosophyfk inspired violence [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.922 (perp=7.958, rec=0.064, cos=0.267), tot_loss_proj:3.153 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing balancing with its philosophyfk inspired violence [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.916 (perp=7.887, rec=0.072, cos=0.266), tot_loss_proj:3.250 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing balancing with its violencefk inspired philosophy [SEP]']
[ 900/2000] tot_loss=1.904 (perp=7.887, rec=0.063, cos=0.264), tot_loss_proj:3.250 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing balancing with its violencefk inspired philosophy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.913 (perp=7.887, rec=0.070, cos=0.266), tot_loss_proj:3.257 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing balancing with its violencefk inspired philosophy [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.857 (perp=7.621, rec=0.067, cos=0.266), tot_loss_proj:3.105 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing balancing its violence withfk inspired philosophy [SEP]']
[1050/2000] tot_loss=1.850 (perp=7.621, rec=0.061, cos=0.265), tot_loss_proj:3.100 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing balancing its violence withfk inspired philosophy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.820 (perp=7.470, rec=0.063, cos=0.263), tot_loss_proj:2.988 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing balancing its violence withfk inspired violence [SEP]']
Attempt swap
[1150/2000] tot_loss=1.840 (perp=7.470, rec=0.079, cos=0.267), tot_loss_proj:2.984 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing balancing its violence withfk inspired violence [SEP]']
[1200/2000] tot_loss=2.026 (perp=8.473, rec=0.067, cos=0.265), tot_loss_proj:3.144 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy ka balancing its violence withfk inspired violence [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.997 (perp=8.289, rec=0.071, cos=0.269), tot_loss_proj:2.963 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophyfk balancing its violence with ka inspired philosophy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.984 (perp=8.289, rec=0.060, cos=0.267), tot_loss_proj:2.963 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophyfk balancing its violence with ka inspired philosophy [SEP]']
[1350/2000] tot_loss=1.989 (perp=8.289, rec=0.065, cos=0.266), tot_loss_proj:2.963 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophyfk balancing its violence with ka inspired philosophy [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.946 (perp=8.052, rec=0.071, cos=0.266), tot_loss_proj:2.893 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophyfk inspired violence balancing its violence with ka [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.806 (perp=7.385, rec=0.063, cos=0.266), tot_loss_proj:2.706 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with kafk inspired violence [SEP]']
[1500/2000] tot_loss=1.805 (perp=7.385, rec=0.062, cos=0.266), tot_loss_proj:2.702 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with kafk inspired violence [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.798 (perp=7.349, rec=0.064, cos=0.265), tot_loss_proj:2.788 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with violence kafk inspired [SEP]']
Attempt swap
[1600/2000] tot_loss=1.805 (perp=7.349, rec=0.069, cos=0.267), tot_loss_proj:2.791 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with violence kafk inspired [SEP]']
[1650/2000] tot_loss=1.802 (perp=7.349, rec=0.065, cos=0.267), tot_loss_proj:2.784 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with violence kafk inspired [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.768 (perp=7.176, rec=0.066, cos=0.267), tot_loss_proj:2.736 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with inspired violence kafk [SEP]']
Attempt swap
[1750/2000] tot_loss=1.779 (perp=7.176, rec=0.077, cos=0.267), tot_loss_proj:2.737 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with inspired violence kafk [SEP]']
[1800/2000] tot_loss=1.764 (perp=7.176, rec=0.062, cos=0.267), tot_loss_proj:2.736 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with inspired violence kafk [SEP]']
Attempt swap
[1850/2000] tot_loss=1.771 (perp=7.176, rec=0.069, cos=0.267), tot_loss_proj:2.739 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with inspired violence kafk [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.763 (perp=7.176, rec=0.061, cos=0.266), tot_loss_proj:2.744 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with inspired violence kafk [SEP]']
[1950/2000] tot_loss=1.776 (perp=7.176, rec=0.073, cos=0.267), tot_loss_proj:2.740 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with inspired violence kafk [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.760 (perp=7.176, rec=0.058, cos=0.267), tot_loss_proj:2.737 [t=0.22s]
prediction: ['[CLS] a time tougher has its philosophy balancing its violence with inspired violence kafk [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] a time tougher has its philosophy balancing its violence with inspired violence kafk [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 80.000 | r: 92.308
rouge2     | fm: 23.077 | p: 21.429 | r: 25.000
rougeL     | fm: 64.286 | p: 60.000 | r: 69.231
rougeLsum  | fm: 64.286 | p: 60.000 | r: 69.231
r1fm+r2fm = 108.791

[Aggregate metrics]:
rouge1     | fm: 89.433 | p: 88.793 | r: 90.271
rouge2     | fm: 54.651 | p: 54.437 | r: 55.056
rougeL     | fm: 78.162 | p: 77.622 | r: 78.832
rougeLsum  | fm: 78.101 | p: 77.613 | r: 78.771
r1fm+r2fm = 144.084

input #72 time: 0:08:41 | total time: 10:32:10


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.8493592080793831
highest_index [0]
highest [0.8493592080793831]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9534695744514465 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9454547166824341 for ['[CLS] garage knight [SEP]']
[Init] best rec loss: 0.8973062038421631 for ['[CLS] capitol living [SEP]']
[Init] best rec loss: 0.8927628993988037 for ['[CLS] zhang body [SEP]']
[Init] best rec loss: 0.8902170658111572 for ['[CLS] ocean " [SEP]']
[Init] best rec loss: 0.8869209289550781 for ['[CLS] puget traditional [SEP]']
[Init] best rec loss: 0.8702015280723572 for ['[CLS]ɛ society [SEP]']
[Init] best rec loss: 0.8472964763641357 for ['[CLS] massachusetts gun [SEP]']
[Init] best perm rec loss: 0.8418099284172058 for ['[CLS] gun massachusetts [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.423 (perp=9.723, rec=0.207, cos=0.271), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.327 (perp=9.723, rec=0.105, cos=0.278), tot_loss_proj:2.303 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.293 (perp=9.723, rec=0.069, cos=0.279), tot_loss_proj:2.299 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.308 (perp=9.723, rec=0.086, cos=0.278), tot_loss_proj:2.301 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.290 (perp=9.723, rec=0.067, cos=0.278), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.304 (perp=9.723, rec=0.080, cos=0.279), tot_loss_proj:2.305 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.305 (perp=9.723, rec=0.082, cos=0.278), tot_loss_proj:2.314 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.278 (perp=9.723, rec=0.059, cos=0.275), tot_loss_proj:2.313 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.285 (perp=9.723, rec=0.063, cos=0.277), tot_loss_proj:2.315 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.279 (perp=9.723, rec=0.057, cos=0.278), tot_loss_proj:2.304 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.284 (perp=9.723, rec=0.061, cos=0.278), tot_loss_proj:2.308 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.292 (perp=9.723, rec=0.069, cos=0.278), tot_loss_proj:2.299 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.282 (perp=9.723, rec=0.060, cos=0.278), tot_loss_proj:2.292 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.281 (perp=9.723, rec=0.058, cos=0.278), tot_loss_proj:2.316 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.289 (perp=9.723, rec=0.067, cos=0.277), tot_loss_proj:2.312 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.291 (perp=9.723, rec=0.069, cos=0.278), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.279 (perp=9.723, rec=0.056, cos=0.278), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.279 (perp=9.723, rec=0.057, cos=0.278), tot_loss_proj:2.301 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.290 (perp=9.723, rec=0.066, cos=0.279), tot_loss_proj:2.306 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.296 (perp=9.723, rec=0.073, cos=0.278), tot_loss_proj:2.308 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.288 (perp=9.723, rec=0.065, cos=0.278), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.277 (perp=9.723, rec=0.054, cos=0.278), tot_loss_proj:2.304 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.280 (perp=9.723, rec=0.058, cos=0.277), tot_loss_proj:2.302 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.285 (perp=9.723, rec=0.062, cos=0.278), tot_loss_proj:2.301 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.282 (perp=9.723, rec=0.060, cos=0.277), tot_loss_proj:2.297 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.283 (perp=9.723, rec=0.061, cos=0.278), tot_loss_proj:2.297 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.298 (perp=9.723, rec=0.075, cos=0.278), tot_loss_proj:2.306 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.284 (perp=9.723, rec=0.061, cos=0.278), tot_loss_proj:2.297 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.287 (perp=9.723, rec=0.065, cos=0.278), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.289 (perp=9.723, rec=0.066, cos=0.279), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.279 (perp=9.723, rec=0.056, cos=0.278), tot_loss_proj:2.292 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.288 (perp=9.723, rec=0.066, cos=0.278), tot_loss_proj:2.312 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.273 (perp=9.723, rec=0.051, cos=0.277), tot_loss_proj:2.303 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.292 (perp=9.723, rec=0.070, cos=0.278), tot_loss_proj:2.302 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.283 (perp=9.723, rec=0.060, cos=0.278), tot_loss_proj:2.296 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.281 (perp=9.723, rec=0.058, cos=0.278), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.278 (perp=9.723, rec=0.055, cos=0.278), tot_loss_proj:2.308 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.301 (perp=9.723, rec=0.078, cos=0.278), tot_loss_proj:2.315 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.282 (perp=9.723, rec=0.059, cos=0.278), tot_loss_proj:2.313 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.284 (perp=9.723, rec=0.061, cos=0.278), tot_loss_proj:2.298 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.607 | p: 88.982 | r: 90.373
rouge2     | fm: 55.573 | p: 55.267 | r: 55.949
rougeL     | fm: 78.384 | p: 77.879 | r: 79.102
rougeLsum  | fm: 78.411 | p: 77.903 | r: 79.099
r1fm+r2fm = 145.179

input #73 time: 0:08:38 | total time: 10:40:49


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.861470229904957
highest_index [0]
highest [0.861470229904957]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 0.8107435703277588 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6239359974861145 for ['[CLS] storage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.158 (perp=8.177, rec=0.228, cos=0.294), tot_loss_proj:2.222 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.973 (perp=8.177, rec=0.079, cos=0.258), tot_loss_proj:2.044 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=2.054 (perp=8.177, rec=0.154, cos=0.264), tot_loss_proj:2.258 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.967 (perp=8.177, rec=0.075, cos=0.257), tot_loss_proj:2.034 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.965 (perp=8.177, rec=0.073, cos=0.257), tot_loss_proj:2.021 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.952 (perp=8.177, rec=0.059, cos=0.258), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.964 (perp=8.177, rec=0.070, cos=0.258), tot_loss_proj:2.020 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.966 (perp=8.177, rec=0.070, cos=0.260), tot_loss_proj:2.023 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.949 (perp=8.177, rec=0.058, cos=0.256), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.955 (perp=8.177, rec=0.063, cos=0.256), tot_loss_proj:2.018 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.952 (perp=8.177, rec=0.059, cos=0.258), tot_loss_proj:2.014 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.951 (perp=8.177, rec=0.057, cos=0.258), tot_loss_proj:2.014 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.958 (perp=8.177, rec=0.067, cos=0.256), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.950 (perp=8.177, rec=0.059, cos=0.256), tot_loss_proj:2.020 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.950 (perp=8.177, rec=0.058, cos=0.257), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.938 (perp=8.177, rec=0.049, cos=0.254), tot_loss_proj:2.020 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.955 (perp=8.177, rec=0.061, cos=0.258), tot_loss_proj:2.026 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.954 (perp=8.177, rec=0.064, cos=0.254), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.957 (perp=8.177, rec=0.066, cos=0.255), tot_loss_proj:2.013 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.951 (perp=8.177, rec=0.059, cos=0.256), tot_loss_proj:2.013 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.952 (perp=8.177, rec=0.060, cos=0.256), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.949 (perp=8.177, rec=0.055, cos=0.259), tot_loss_proj:2.023 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.947 (perp=8.177, rec=0.054, cos=0.258), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.946 (perp=8.177, rec=0.053, cos=0.257), tot_loss_proj:2.019 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.951 (perp=8.177, rec=0.058, cos=0.257), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.964 (perp=8.177, rec=0.071, cos=0.257), tot_loss_proj:2.001 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.945 (perp=8.177, rec=0.054, cos=0.256), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.948 (perp=8.177, rec=0.055, cos=0.257), tot_loss_proj:2.021 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.960 (perp=8.177, rec=0.069, cos=0.255), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.950 (perp=8.177, rec=0.057, cos=0.257), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.956 (perp=8.177, rec=0.062, cos=0.258), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.955 (perp=8.177, rec=0.064, cos=0.255), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.949 (perp=8.177, rec=0.057, cos=0.256), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.952 (perp=8.177, rec=0.059, cos=0.257), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.950 (perp=8.177, rec=0.057, cos=0.257), tot_loss_proj:2.003 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.966 (perp=8.177, rec=0.074, cos=0.257), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.953 (perp=8.177, rec=0.060, cos=0.257), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.946 (perp=8.177, rec=0.054, cos=0.257), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.944 (perp=8.177, rec=0.052, cos=0.257), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.953 (perp=8.177, rec=0.061, cos=0.257), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.777 | p: 89.170 | r: 90.575
rouge2     | fm: 56.135 | p: 55.847 | r: 56.476
rougeL     | fm: 78.685 | p: 78.215 | r: 79.345
rougeLsum  | fm: 78.718 | p: 78.175 | r: 79.391
r1fm+r2fm = 145.912

input #74 time: 0:08:42 | total time: 10:49:32


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.8750573223503234
highest_index [0]
highest [0.8750573223503234]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.8916096091270447 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.8611346483230591 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.8325423002243042 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best perm rec loss: 0.8325262069702148 for ['[CLS] double es regiment alfred marlene help reason moth churches malone duties connacht clan zach section meaning rushose lakes [SEP]']
[Init] best perm rec loss: 0.8298876881599426 for ['[CLS] zach help moth malone connacht rush section churchesose es regiment alfred duties meaning marlene double lakes reason clan [SEP]']
[Init] best perm rec loss: 0.829682469367981 for ['[CLS] maloneose double clan churches lakes zach alfred moth meaning marlene help regiment section reason es connacht rush duties [SEP]']
[Init] best perm rec loss: 0.8291609883308411 for ['[CLS] help reason moth marlene dutiesose double alfred connacht section malone rush clan meaning zach churches regiment lakes es [SEP]']
[Init] best perm rec loss: 0.8282591104507446 for ['[CLS] malone section rush zach regiment churches connacht help double clan moth es duties meaning marlene lakes alfredose reason [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.999 (perp=12.132, rec=0.346, cos=0.227), tot_loss_proj:4.210 [t=0.22s]
prediction: ['[CLS] photon experienced individuals items instability the continuous ansibility sub candle the colonial state ciudad interpreted angela forgotten nothing [SEP]']
[ 100/2000] tot_loss=2.824 (perp=11.892, rec=0.220, cos=0.225), tot_loss_proj:4.159 [t=0.22s]
prediction: ['[CLS] mental experienced or projectile instability the dorm ; incorrect excursion hyper at instability easily isn not oneself forgotten forgotten [SEP]']
[ 150/2000] tot_loss=2.795 (perp=12.054, rec=0.153, cos=0.231), tot_loss_proj:4.171 [t=0.22s]
prediction: ['[CLS] mental took orvert instability this dorm offulness excursion intense at instability easily not not particular dismissed forgotten [SEP]']
[ 200/2000] tot_loss=2.873 (perp=12.502, rec=0.146, cos=0.227), tot_loss_proj:4.265 [t=0.22s]
prediction: ['[CLS] mental took orcr instability this epic offulness excursion intense in instability easily not not craig dismissed forgotten [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.398 (perp=10.184, rec=0.130, cos=0.232), tot_loss_proj:3.514 [t=0.22s]
prediction: ['[CLS] the took orcola instability this epic of occurs excursion epic mental instability easily is not is dismissed forgotten [SEP]']
[ 300/2000] tot_loss=2.375 (perp=10.210, rec=0.104, cos=0.229), tot_loss_proj:3.723 [t=0.22s]
prediction: ['[CLS] the took orcola instability thiscola of is excursionenter mental instability easily is not is dismissed forgotten [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.375 (perp=10.219, rec=0.104, cos=0.227), tot_loss_proj:3.683 [t=0.22s]
prediction: ['[CLS] the import or is instability thiscola ofcola excursionenter mental instability easily is not. dismissed forgotten [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.555 (perp=11.154, rec=0.099, cos=0.226), tot_loss_proj:3.586 [t=0.22s]
prediction: ['[CLS] into import or is instability thiscola ofcola excursionenter mental instability easily is not dismissed forgottenlike [SEP]']
[ 450/2000] tot_loss=2.481 (perp=10.823, rec=0.089, cos=0.227), tot_loss_proj:3.354 [t=0.22s]
prediction: ['[CLS] into into or is instability thiscola ofcola excursionenter mental instability easily is not dismissed forgottenlike [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.368 (perp=10.307, rec=0.082, cos=0.225), tot_loss_proj:3.402 [t=0.22s]
prediction: ['[CLS] intoenter or is instability thiscola ofcola excursion into mental instability easily is not dismissed forgotten fiona [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.028 (perp=8.618, rec=0.081, cos=0.223), tot_loss_proj:3.064 [t=0.22s]
prediction: ['[CLS] intoenter or is instability this excursion of percolating mental instability easily not not dismissed forgotten! [SEP]']
[ 600/2000] tot_loss=2.008 (perp=8.491, rec=0.084, cos=0.226), tot_loss_proj:3.157 [t=0.22s]
prediction: ['[CLS] intoenter or is instability this excursion of percolating mental instability easily not not dismissed forgotten ; [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.820 (perp=7.571, rec=0.081, cos=0.225), tot_loss_proj:2.570 [t=0.22s]
prediction: ['[CLS] intoenter or is instability this excursion of percolating mental instability is not easily dismissed forgotten ; [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.761 (perp=7.225, rec=0.089, cos=0.227), tot_loss_proj:2.380 [t=0.22s]
prediction: ['[CLS] intoenter or instability is this excursion of percolating mental instability is not easily dismissed forgotten ; [SEP]']
[ 750/2000] tot_loss=1.749 (perp=7.225, rec=0.076, cos=0.228), tot_loss_proj:2.381 [t=0.22s]
prediction: ['[CLS] intoenter or instability is this excursion of percolating mental instability is not easily dismissed forgotten ; [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.724 (perp=7.098, rec=0.078, cos=0.226), tot_loss_proj:2.309 [t=0.22s]
prediction: ['[CLS] intoenter or instability this is excursion of percolating mental instability is not easily dismissed forgotten ; [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.719 (perp=7.098, rec=0.073, cos=0.227), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] intoenter or instability this is excursion of percolating mental instability is not easily dismissed forgotten ; [SEP]']
[ 900/2000] tot_loss=1.731 (perp=7.098, rec=0.083, cos=0.228), tot_loss_proj:2.311 [t=0.22s]
prediction: ['[CLS] intoenter or instability this is excursion of percolating mental instability is not easily dismissed forgotten ; [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.726 (perp=7.098, rec=0.079, cos=0.227), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS] intoenter or instability this is excursion of percolating mental instability is not easily dismissed forgotten ; [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.684 (perp=6.917, rec=0.076, cos=0.225), tot_loss_proj:2.058 [t=0.22s]
prediction: ['[CLS] intoenter instability this is excursion of percolating mental instability is not easily dismissed or forgotten ; [SEP]']
[1050/2000] tot_loss=1.627 (perp=6.645, rec=0.073, cos=0.225), tot_loss_proj:1.967 [t=0.22s]
prediction: ['[CLS] intoenter instability this is excursion of percolating mental instability is not easily dismissed or forgotten. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.771 (perp=7.362, rec=0.072, cos=0.227), tot_loss_proj:2.482 [t=0.22s]
prediction: ['[CLS] intoenter instability this is excursion of percolating mental instability epic not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.683 (perp=6.894, rec=0.079, cos=0.226), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] intoenter instability this excursion of percolating mental instability is epic not easily forgotten or dismissed. [SEP]']
[1200/2000] tot_loss=1.688 (perp=6.894, rec=0.084, cos=0.225), tot_loss_proj:2.225 [t=0.22s]
prediction: ['[CLS] intoenter instability this excursion of percolating mental instability is epic not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.642 (perp=6.726, rec=0.070, cos=0.228), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] intoenter instability this excursion of epic percolating mental instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.628 (perp=6.626, rec=0.075, cos=0.228), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] into instability this excursion of epicenter percolating mental instability is not easily forgotten or dismissed. [SEP]']
[1350/2000] tot_loss=1.620 (perp=6.626, rec=0.068, cos=0.226), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] into instability this excursion of epicenter percolating mental instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.493 (perp=5.967, rec=0.072, cos=0.227), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of epicenter percolating into instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.501 (perp=5.967, rec=0.080, cos=0.228), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of epicenter percolating into instability is not easily forgotten or dismissed. [SEP]']
[1500/2000] tot_loss=1.488 (perp=5.967, rec=0.068, cos=0.227), tot_loss_proj:1.880 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of epicenter percolating into instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.502 (perp=5.967, rec=0.080, cos=0.228), tot_loss_proj:1.877 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of epicenter percolating into instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.472 (perp=5.833, rec=0.079, cos=0.226), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of percolating into epicenter instability is not easily forgotten or dismissed. [SEP]']
[1650/2000] tot_loss=1.472 (perp=5.833, rec=0.079, cos=0.226), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of percolating into epicenter instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.463 (perp=5.786, rec=0.079, cos=0.226), tot_loss_proj:1.845 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of percolating epicenter into instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.461 (perp=5.786, rec=0.077, cos=0.226), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of percolating epicenter into instability is not easily forgotten or dismissed. [SEP]']
[1800/2000] tot_loss=1.461 (perp=5.786, rec=0.077, cos=0.227), tot_loss_proj:1.839 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of percolating epicenter into instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.458 (perp=5.786, rec=0.073, cos=0.227), tot_loss_proj:1.837 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of percolating epicenter into instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.464 (perp=5.786, rec=0.080, cos=0.227), tot_loss_proj:1.839 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of percolating epicenter into instability is not easily forgotten or dismissed. [SEP]']
[1950/2000] tot_loss=1.459 (perp=5.786, rec=0.074, cos=0.228), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of percolating epicenter into instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.453 (perp=5.786, rec=0.068, cos=0.228), tot_loss_proj:1.837 [t=0.22s]
prediction: ['[CLS] mental instability this excursion of percolating epicenter into instability is not easily forgotten or dismissed. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] intoenter instability this is excursion of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 82.353 | r: 82.353
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 82.353 | p: 82.353 | r: 82.353
rougeLsum  | fm: 82.353 | p: 82.353 | r: 82.353
r1fm+r2fm = 144.853

[Aggregate metrics]:
rouge1     | fm: 89.683 | p: 89.066 | r: 90.507
rouge2     | fm: 56.234 | p: 55.900 | r: 56.534
rougeL     | fm: 78.656 | p: 78.191 | r: 79.300
rougeLsum  | fm: 78.738 | p: 78.234 | r: 79.410
r1fm+r2fm = 145.918

input #75 time: 0:08:43 | total time: 10:58:15


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.8452527790323061
highest_index [0]
highest [0.8452527790323061]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.887772262096405 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.8824496269226074 for ['[CLS] skin outside historian inside please determined boss legend vi đ wine unanimouslymer ski [SEP]']
[Init] best rec loss: 0.8727450370788574 for ['[CLS] midnight even task j mesh constellation village typhoonorough, advancing hammerist carol [SEP]']
[Init] best rec loss: 0.8509699702262878 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.8491438031196594 for ['[CLS] paper both commercially user guantanamo body 3d barker away commune also fortune turkey shay [SEP]']
[Init] best perm rec loss: 0.8458572030067444 for ['[CLS] commune turkey commercially both barker body guantanamo shay away fortune 3d user also paper [SEP]']
[Init] best perm rec loss: 0.8439569473266602 for ['[CLS] away turkey paper user guantanamo barker body commune 3d commercially shay also fortune both [SEP]']
[Init] best perm rec loss: 0.8435813784599304 for ['[CLS] 3d shay away barker commune also fortune guantanamo paper user body both turkey commercially [SEP]']
[Init] best perm rec loss: 0.8414918184280396 for ['[CLS] barker body commune fortune 3d commercially shay guantanamo user paper turkey both away also [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.909 (perp=11.646, rec=0.311, cos=0.269), tot_loss_proj:3.792 [t=0.22s]
prediction: ['[CLS] about training challenging competing stop challenging stopped stopped stopped himself fact stein seemed defeated [SEP]']
[ 100/2000] tot_loss=2.822 (perp=11.743, rec=0.204, cos=0.269), tot_loss_proj:3.708 [t=0.22s]
prediction: ['[CLS] as challenging challenging challenging stopped challenging in stopped stopped himself having 66 has himself [SEP]']
[ 150/2000] tot_loss=2.765 (perp=11.714, rec=0.149, cos=0.274), tot_loss_proj:4.038 [t=0.22s]
prediction: ['[CLS] at challenging challenging challenging stopped challenging at stopped stopped has if 66 has himself [SEP]']
[ 200/2000] tot_loss=2.846 (perp=12.187, rec=0.125, cos=0.283), tot_loss_proj:3.960 [t=0.22s]
prediction: ['[CLS] as challenging challenging allen stopped challenging at stopped stopped has if 66 has himself [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.406 (perp=10.130, rec=0.105, cos=0.275), tot_loss_proj:3.739 [t=0.22s]
prediction: ['[CLS] as challenging challenging allen if challenging at had stopped has stopped 66 has himself [SEP]']
[ 300/2000] tot_loss=2.517 (perp=10.761, rec=0.094, cos=0.271), tot_loss_proj:3.889 [t=0.22s]
prediction: ['[CLS] as challenging challenging allen if challenging at. stopped has stopped 66 has himself [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.274 (perp=9.520, rec=0.096, cos=0.273), tot_loss_proj:3.515 [t=0.22s]
prediction: ['[CLS] as challenging challenging allen if challenging at has stopped, stopped 66. himself [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.169 (perp=9.001, rec=0.095, cos=0.274), tot_loss_proj:3.523 [t=0.22s]
prediction: ['[CLS] allen as challenging challenging if challenging at has stopped, stopped 66. himself [SEP]']
[ 450/2000] tot_loss=2.185 (perp=9.001, rec=0.103, cos=0.282), tot_loss_proj:3.490 [t=0.22s]
prediction: ['[CLS] allen as challenging challenging if challenging at has stopped, stopped 66. himself [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.084 (perp=8.593, rec=0.088, cos=0.277), tot_loss_proj:3.388 [t=0.23s]
prediction: ['[CLS] allen as challenging challenging if challenging at has stopped, stopped 66 himself. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.062 (perp=8.495, rec=0.084, cos=0.279), tot_loss_proj:3.271 [t=0.22s]
prediction: ['[CLS] allen as challenging challenging if challenging at has, has stopped 66 himself. [SEP]']
[ 600/2000] tot_loss=2.062 (perp=8.495, rec=0.086, cos=0.277), tot_loss_proj:3.265 [t=0.23s]
prediction: ['[CLS] allen as challenging challenging if challenging at has, has stopped 66 himself. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.991 (perp=8.139, rec=0.086, cos=0.278), tot_loss_proj:2.919 [t=0.22s]
prediction: ['[CLS] allen as challenging challenging if challenging at has 66, has stopped himself. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.087 (perp=8.619, rec=0.082, cos=0.281), tot_loss_proj:3.201 [t=0.22s]
prediction: ['[CLS] allen as challenging if challenging at challenging has 66,. stopped himself. [SEP]']
[ 750/2000] tot_loss=2.090 (perp=8.619, rec=0.087, cos=0.279), tot_loss_proj:3.192 [t=0.22s]
prediction: ['[CLS] allen as challenging if challenging at challenging has 66,. stopped himself. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.861 (perp=7.503, rec=0.080, cos=0.280), tot_loss_proj:2.769 [t=0.23s]
prediction: ['[CLS] allen as challenging if challenging at challenging. 66, has stopped himself. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.796 (perp=7.146, rec=0.086, cos=0.281), tot_loss_proj:2.426 [t=0.23s]
prediction: ['[CLS] allen as if challenging at challenging. 66, has stopped challenging himself. [SEP]']
[ 900/2000] tot_loss=1.783 (perp=7.146, rec=0.077, cos=0.277), tot_loss_proj:2.419 [t=0.23s]
prediction: ['[CLS] allen as if challenging at challenging. 66, has stopped challenging himself. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.785 (perp=7.146, rec=0.076, cos=0.280), tot_loss_proj:2.412 [t=0.23s]
prediction: ['[CLS] allen as if challenging at challenging. 66, has stopped challenging himself. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.779 (perp=7.146, rec=0.072, cos=0.278), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS] allen as if challenging at challenging. 66, has stopped challenging himself. [SEP]']
[1050/2000] tot_loss=1.781 (perp=7.146, rec=0.073, cos=0.278), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] allen as if challenging at challenging. 66, has stopped challenging himself. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.799 (perp=7.199, rec=0.080, cos=0.279), tot_loss_proj:2.397 [t=0.22s]
prediction: ['[CLS] allen as if challenging at challenging is 66, has stopped challenging himself. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.762 (perp=7.082, rec=0.067, cos=0.279), tot_loss_proj:2.458 [t=0.22s]
prediction: ['[CLS] allen as if challenging at 66 is challenging, has stopped challenging himself. [SEP]']
[1200/2000] tot_loss=1.778 (perp=7.082, rec=0.078, cos=0.283), tot_loss_proj:2.456 [t=0.23s]
prediction: ['[CLS] allen as if challenging at 66 is challenging, has stopped challenging himself. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.881 (perp=7.620, rec=0.077, cos=0.281), tot_loss_proj:2.615 [t=0.23s]
prediction: ['[CLS] as if challenging at allen 66 s challenging, has stopped challenging himself. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.781 (perp=7.141, rec=0.072, cos=0.280), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] as if challenging at 66 s challenging, allen has stopped challenging himself. [SEP]']
[1350/2000] tot_loss=1.775 (perp=7.141, rec=0.068, cos=0.279), tot_loss_proj:2.406 [t=0.22s]
prediction: ['[CLS] as if challenging at 66 s challenging, allen has stopped challenging himself. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.717 (perp=6.820, rec=0.074, cos=0.280), tot_loss_proj:2.292 [t=0.23s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.720 (perp=6.820, rec=0.076, cos=0.280), tot_loss_proj:2.290 [t=0.23s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
[1500/2000] tot_loss=1.717 (perp=6.820, rec=0.074, cos=0.279), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.718 (perp=6.820, rec=0.075, cos=0.280), tot_loss_proj:2.286 [t=0.23s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.718 (perp=6.820, rec=0.074, cos=0.280), tot_loss_proj:2.289 [t=0.22s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
[1650/2000] tot_loss=1.707 (perp=6.820, rec=0.065, cos=0.279), tot_loss_proj:2.291 [t=0.23s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.722 (perp=6.820, rec=0.078, cos=0.280), tot_loss_proj:2.293 [t=0.23s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.705 (perp=6.820, rec=0.062, cos=0.279), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
[1800/2000] tot_loss=1.710 (perp=6.820, rec=0.066, cos=0.280), tot_loss_proj:2.290 [t=0.22s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.716 (perp=6.820, rec=0.073, cos=0.279), tot_loss_proj:2.287 [t=0.23s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.715 (perp=6.820, rec=0.070, cos=0.280), tot_loss_proj:2.302 [t=0.22s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
[1950/2000] tot_loss=1.711 (perp=6.820, rec=0.067, cos=0.280), tot_loss_proj:2.298 [t=0.23s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.718 (perp=6.820, rec=0.074, cos=0.280), tot_loss_proj:2.296 [t=0.23s]
prediction: ['[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] as if challenging at s challenging 66, allen has stopped challenging himself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 41.667 | p: 38.462 | r: 45.455
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 133.974

[Aggregate metrics]:
rouge1     | fm: 89.642 | p: 88.992 | r: 90.554
rouge2     | fm: 55.900 | p: 55.565 | r: 56.395
rougeL     | fm: 78.684 | p: 78.142 | r: 79.386
rougeLsum  | fm: 78.770 | p: 78.199 | r: 79.521
r1fm+r2fm = 145.542

input #76 time: 0:08:50 | total time: 11:07:05


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.8238307063935291
highest_index [0]
highest [0.8238307063935291]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.8064295649528503 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8043834567070007 for ['[CLS] low each mob descending person architecture channels partnership platinum friendtry aw idea anderson america [SEP]']
[Init] best rec loss: 0.7741391062736511 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.741331160068512 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.7351556420326233 for ['[CLS] too type bred cold crowd more elements lips critique leather under battlefield simple lot pony [SEP]']
[Init] best perm rec loss: 0.7295593619346619 for ['[CLS] crowd cold pony under critique bred simple lips elements battlefield more too leather lot type [SEP]']
[Init] best perm rec loss: 0.7289355993270874 for ['[CLS] more lot elements simple cold type leather pony lips too battlefield crowd critique under bred [SEP]']
[Init] best perm rec loss: 0.7271966338157654 for ['[CLS] too pony elements lot under type bred critique crowd simple cold leather more lips battlefield [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.984 (perp=11.683, rec=0.328, cos=0.319), tot_loss_proj:3.546 [t=0.22s]
prediction: ['[CLS] long chemistry species makes competition like call above above what times leather his artistic potential [SEP]']
[ 100/2000] tot_loss=2.827 (perp=11.464, rec=0.225, cos=0.309), tot_loss_proj:3.228 [t=0.22s]
prediction: ['[CLS] an consciousness make s structurears promise above above what enough my institute material realm [SEP]']
[ 150/2000] tot_loss=2.676 (perp=10.972, rec=0.172, cos=0.309), tot_loss_proj:3.169 [t=0.22s]
prediction: ['[CLS] is believe make placed thatars promise above above realmars the make material realm [SEP]']
[ 200/2000] tot_loss=2.609 (perp=10.667, rec=0.156, cos=0.319), tot_loss_proj:3.045 [t=0.22s]
prediction: ['[CLS] is believe make a thatarsars above above realmars the make material promise [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.107 (perp=8.307, rec=0.132, cos=0.313), tot_loss_proj:2.539 [t=0.22s]
prediction: ['[CLS] is believe make a that soars above its realmars the above material promise [SEP]']
[ 300/2000] tot_loss=2.110 (perp=8.390, rec=0.111, cos=0.320), tot_loss_proj:2.541 [t=0.22s]
prediction: ['[CLS] is believe make a that soars above its realmars the above life promise [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.950 (perp=7.663, rec=0.097, cos=0.320), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] is that make a believe soars above its realmars the above life promise [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.850 (perp=7.202, rec=0.090, cos=0.319), tot_loss_proj:2.309 [t=0.22s]
prediction: ['[CLS] is that a make believe soars above its realmars the above life promise [SEP]']
[ 450/2000] tot_loss=1.982 (perp=7.866, rec=0.088, cos=0.321), tot_loss_proj:2.475 [t=0.22s]
prediction: ['[CLS] is that - make believe soars above its realmars the above life promise [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.874 (perp=7.319, rec=0.091, cos=0.320), tot_loss_proj:2.484 [t=0.22s]
prediction: ['[CLS] is that - the make believe soars above its realmars above life promise [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.828 (perp=7.090, rec=0.089, cos=0.320), tot_loss_proj:2.486 [t=0.22s]
prediction: ['[CLS] is that - the make believe soars above its realm lifears above promise [SEP]']
[ 600/2000] tot_loss=1.820 (perp=7.090, rec=0.082, cos=0.321), tot_loss_proj:2.484 [t=0.22s]
prediction: ['[CLS] is that - the make believe soars above its realm lifears above promise [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.747 (perp=6.705, rec=0.086, cos=0.320), tot_loss_proj:2.355 [t=0.22s]
prediction: ['[CLS] is that the make believe soars above its realm - lifears above promise [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.716 (perp=6.573, rec=0.081, cos=0.320), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] that is the make believe soars above its realm - lifears above promise [SEP]']
[ 750/2000] tot_loss=1.724 (perp=6.573, rec=0.089, cos=0.320), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] that is the make believe soars above its realm - lifears above promise [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.701 (perp=6.499, rec=0.081, cos=0.320), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] that is the make believe soars above its realm - life above promisears [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.697 (perp=6.499, rec=0.079, cos=0.318), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] that is the make believe soars above its realm - life above promisears [SEP]']
[ 900/2000] tot_loss=1.796 (perp=6.997, rec=0.076, cos=0.321), tot_loss_proj:2.274 [t=0.22s]
prediction: ['[CLS] that is the make believe soars above its realm - life material promisears [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.785 (perp=6.940, rec=0.078, cos=0.319), tot_loss_proj:2.247 [t=0.22s]
prediction: ['[CLS] that is the make believe soars above its realm - promise material lifears [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.733 (perp=6.655, rec=0.081, cos=0.321), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] that is the make believe soars above its material realm - promise lifears [SEP]']
[1050/2000] tot_loss=1.726 (perp=6.655, rec=0.076, cos=0.319), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] that is the make believe soars above its material realm - promise lifears [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.705 (perp=6.571, rec=0.071, cos=0.320), tot_loss_proj:2.147 [t=0.22s]
prediction: ['[CLS] that is the make believe soars above its material realm - life promisears [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.654 (perp=6.243, rec=0.086, cos=0.320), tot_loss_proj:1.965 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
[1200/2000] tot_loss=1.647 (perp=6.243, rec=0.078, cos=0.320), tot_loss_proj:1.958 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Attempt swap
[1250/2000] tot_loss=1.642 (perp=6.243, rec=0.073, cos=0.321), tot_loss_proj:1.958 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Attempt swap
[1300/2000] tot_loss=1.639 (perp=6.243, rec=0.070, cos=0.320), tot_loss_proj:1.962 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
[1350/2000] tot_loss=1.637 (perp=6.243, rec=0.069, cos=0.320), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Attempt swap
[1400/2000] tot_loss=1.641 (perp=6.243, rec=0.072, cos=0.320), tot_loss_proj:1.954 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Attempt swap
[1450/2000] tot_loss=1.640 (perp=6.243, rec=0.071, cos=0.321), tot_loss_proj:1.957 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
[1500/2000] tot_loss=1.638 (perp=6.243, rec=0.069, cos=0.320), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Attempt swap
[1550/2000] tot_loss=1.641 (perp=6.243, rec=0.072, cos=0.321), tot_loss_proj:1.961 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Attempt swap
[1600/2000] tot_loss=1.640 (perp=6.243, rec=0.071, cos=0.320), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
[1650/2000] tot_loss=1.633 (perp=6.243, rec=0.064, cos=0.320), tot_loss_proj:1.959 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Attempt swap
[1700/2000] tot_loss=1.638 (perp=6.243, rec=0.069, cos=0.321), tot_loss_proj:1.955 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Attempt swap
[1750/2000] tot_loss=1.637 (perp=6.243, rec=0.068, cos=0.320), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
[1800/2000] tot_loss=1.645 (perp=6.243, rec=0.076, cos=0.320), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Attempt swap
[1850/2000] tot_loss=1.638 (perp=6.243, rec=0.069, cos=0.321), tot_loss_proj:1.957 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Attempt swap
[1900/2000] tot_loss=1.641 (perp=6.243, rec=0.071, cos=0.320), tot_loss_proj:1.959 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
[1950/2000] tot_loss=1.634 (perp=6.243, rec=0.065, cos=0.320), tot_loss_proj:1.955 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Attempt swap
[2000/2000] tot_loss=1.640 (perp=6.243, rec=0.071, cos=0.321), tot_loss_proj:1.961 [t=0.22s]
prediction: ['[CLS] that promise is the make believe soars above its material realm - lifears [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] that promise is the make believe soars above its material realm - lifears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 89.655 | p: 92.857 | r: 86.667
rouge2     | fm: 22.222 | p: 23.077 | r: 21.429
rougeL     | fm: 62.069 | p: 64.286 | r: 60.000
rougeLsum  | fm: 62.069 | p: 64.286 | r: 60.000
r1fm+r2fm = 111.877

[Aggregate metrics]:
rouge1     | fm: 89.617 | p: 88.990 | r: 90.422
rouge2     | fm: 55.680 | p: 55.305 | r: 56.108
rougeL     | fm: 78.427 | p: 78.023 | r: 79.126
rougeLsum  | fm: 78.506 | p: 77.964 | r: 79.147
r1fm+r2fm = 145.297

input #77 time: 0:08:40 | total time: 11:15:46


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.8997058522645442
highest_index [0]
highest [0.8997058522645442]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9492289423942566 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9191274642944336 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.7981013059616089 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.7585365176200867 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.7550276517868042 for ['[CLS] le grant screens [SEP]']
[Init] best perm rec loss: 0.754507303237915 for ['[CLS] screens grant le [SEP]']
[Init] best perm rec loss: 0.7529520392417908 for ['[CLS] grant screens le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.223 (perp=8.971, rec=0.240, cos=0.189), tot_loss_proj:2.804 [t=0.22s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 100/2000] tot_loss=2.100 (perp=8.971, rec=0.117, cos=0.188), tot_loss_proj:2.816 [t=0.22s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 150/2000] tot_loss=2.419 (perp=10.782, rec=0.075, cos=0.188), tot_loss_proj:3.106 [t=0.22s]
prediction: ['[CLS] exit theater the [SEP]']
[ 200/2000] tot_loss=2.407 (perp=10.782, rec=0.064, cos=0.187), tot_loss_proj:3.109 [t=0.22s]
prediction: ['[CLS] exit theater the [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.851 (perp=7.958, rec=0.069, cos=0.190), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=1.848 (perp=7.958, rec=0.066, cos=0.190), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.848 (perp=7.958, rec=0.066, cos=0.190), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.840 (perp=7.958, rec=0.060, cos=0.188), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.839 (perp=7.958, rec=0.058, cos=0.189), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.849 (perp=7.958, rec=0.065, cos=0.192), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.840 (perp=7.958, rec=0.060, cos=0.189), tot_loss_proj:1.866 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.850 (perp=7.958, rec=0.068, cos=0.190), tot_loss_proj:1.866 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.842 (perp=7.958, rec=0.061, cos=0.190), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.840 (perp=7.958, rec=0.059, cos=0.190), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.834 (perp=7.958, rec=0.052, cos=0.191), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.839 (perp=7.958, rec=0.057, cos=0.189), tot_loss_proj:1.870 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.842 (perp=7.958, rec=0.061, cos=0.189), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.848 (perp=7.958, rec=0.068, cos=0.188), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.842 (perp=7.958, rec=0.061, cos=0.190), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.848 (perp=7.958, rec=0.066, cos=0.190), tot_loss_proj:1.854 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.840 (perp=7.958, rec=0.059, cos=0.190), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.849 (perp=7.958, rec=0.068, cos=0.190), tot_loss_proj:1.875 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.838 (perp=7.958, rec=0.056, cos=0.190), tot_loss_proj:1.863 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.838 (perp=7.958, rec=0.057, cos=0.189), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.846 (perp=7.958, rec=0.066, cos=0.189), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.844 (perp=7.958, rec=0.062, cos=0.191), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.842 (perp=7.958, rec=0.060, cos=0.191), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.839 (perp=7.958, rec=0.057, cos=0.190), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.841 (perp=7.958, rec=0.060, cos=0.190), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.844 (perp=7.958, rec=0.062, cos=0.191), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.838 (perp=7.958, rec=0.055, cos=0.191), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.838 (perp=7.958, rec=0.057, cos=0.190), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.844 (perp=7.958, rec=0.063, cos=0.190), tot_loss_proj:1.866 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.847 (perp=7.958, rec=0.066, cos=0.189), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.841 (perp=7.958, rec=0.060, cos=0.190), tot_loss_proj:1.866 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.841 (perp=7.958, rec=0.059, cos=0.190), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.841 (perp=7.958, rec=0.059, cos=0.190), tot_loss_proj:1.863 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.843 (perp=7.958, rec=0.061, cos=0.190), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.841 (perp=7.958, rec=0.059, cos=0.191), tot_loss_proj:1.863 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.848 (perp=7.958, rec=0.066, cos=0.190), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.826 | p: 89.216 | r: 90.634
rouge2     | fm: 56.070 | p: 55.787 | r: 56.434
rougeL     | fm: 78.771 | p: 78.256 | r: 79.456
rougeLsum  | fm: 78.837 | p: 78.290 | r: 79.518
r1fm+r2fm = 145.896

input #78 time: 0:08:41 | total time: 11:24:27


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.8149224124584777
highest_index [0]
highest [0.8149224124584777]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9681126475334167 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.9657177329063416 for ['[CLS] chicago militia [SEP]']
[Init] best rec loss: 0.953315258026123 for ['[CLS] tapping huge [SEP]']
[Init] best rec loss: 0.9456818699836731 for ['[CLS] neither tokyo [SEP]']
[Init] best rec loss: 0.8821597695350647 for ['[CLS] clay starts [SEP]']
[Init] best rec loss: 0.8466923832893372 for ['[CLS] armada containing [SEP]']
[Init] best rec loss: 0.8397309184074402 for ['[CLS] amount volumes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.813 (perp=11.427, rec=0.188, cos=0.340), tot_loss_proj:3.005 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.774 (perp=11.427, rec=0.153, cos=0.336), tot_loss_proj:2.994 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.768 (perp=11.427, rec=0.147, cos=0.336), tot_loss_proj:2.981 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=2.288 (perp=9.381, rec=0.075, cos=0.336), tot_loss_proj:2.294 [t=0.22s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.153 (perp=8.695, rec=0.081, cos=0.333), tot_loss_proj:2.369 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=2.137 (perp=8.695, rec=0.063, cos=0.336), tot_loss_proj:2.368 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.145 (perp=8.695, rec=0.071, cos=0.335), tot_loss_proj:2.367 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.148 (perp=8.695, rec=0.074, cos=0.335), tot_loss_proj:2.344 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=2.137 (perp=8.695, rec=0.064, cos=0.334), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.153 (perp=8.695, rec=0.078, cos=0.336), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.161 (perp=8.695, rec=0.086, cos=0.336), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=2.146 (perp=8.695, rec=0.071, cos=0.336), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.133 (perp=8.695, rec=0.059, cos=0.335), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.138 (perp=8.695, rec=0.064, cos=0.336), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=2.143 (perp=8.695, rec=0.068, cos=0.336), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.144 (perp=8.695, rec=0.069, cos=0.336), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.125 (perp=8.695, rec=0.050, cos=0.336), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=2.155 (perp=8.695, rec=0.080, cos=0.336), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.138 (perp=8.695, rec=0.063, cos=0.335), tot_loss_proj:2.335 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=2.138 (perp=8.695, rec=0.063, cos=0.336), tot_loss_proj:2.357 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=2.125 (perp=8.695, rec=0.050, cos=0.336), tot_loss_proj:2.344 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=2.143 (perp=8.695, rec=0.069, cos=0.335), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=2.132 (perp=8.695, rec=0.058, cos=0.335), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=2.143 (perp=8.695, rec=0.069, cos=0.335), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=2.125 (perp=8.695, rec=0.051, cos=0.336), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=2.156 (perp=8.695, rec=0.081, cos=0.336), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=2.134 (perp=8.695, rec=0.060, cos=0.335), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=2.130 (perp=8.695, rec=0.055, cos=0.335), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=2.131 (perp=8.695, rec=0.057, cos=0.335), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=2.147 (perp=8.695, rec=0.073, cos=0.336), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=2.145 (perp=8.695, rec=0.070, cos=0.336), tot_loss_proj:2.343 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=2.149 (perp=8.695, rec=0.075, cos=0.336), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=2.129 (perp=8.695, rec=0.055, cos=0.335), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=2.138 (perp=8.695, rec=0.063, cos=0.336), tot_loss_proj:2.340 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=2.138 (perp=8.695, rec=0.064, cos=0.336), tot_loss_proj:2.343 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=2.140 (perp=8.695, rec=0.065, cos=0.335), tot_loss_proj:2.341 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=2.136 (perp=8.695, rec=0.061, cos=0.336), tot_loss_proj:2.344 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=2.122 (perp=8.695, rec=0.047, cos=0.336), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=2.139 (perp=8.695, rec=0.065, cos=0.336), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=2.137 (perp=8.695, rec=0.062, cos=0.335), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.935 | p: 89.325 | r: 90.714
rouge2     | fm: 55.476 | p: 55.190 | r: 55.863
rougeL     | fm: 78.718 | p: 78.234 | r: 79.371
rougeLsum  | fm: 78.757 | p: 78.229 | r: 79.458
r1fm+r2fm = 145.411

input #79 time: 0:08:38 | total time: 11:33:05


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.8008565566369859
highest_index [0]
highest [0.8008565566369859]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9584822058677673 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9483696818351746 for ['[CLS] breath difference sensitiveosity higher [SEP]']
[Init] best rec loss: 0.9323995113372803 for ['[CLS] water takinge bonnie ca [SEP]']
[Init] best rec loss: 0.9116517901420593 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.9093593955039978 for ['[CLS] kelvin structure dillonlessly experiments [SEP]']
[Init] best rec loss: 0.8915391564369202 for ['[CLS] xavier regular plain standings masters [SEP]']
[Init] best rec loss: 0.8722710013389587 for ['[CLS] heard pavilionplane ian tu [SEP]']
[Init] best perm rec loss: 0.8687290549278259 for ['[CLS] heardplane ian tu pavilion [SEP]']
[Init] best perm rec loss: 0.8683091402053833 for ['[CLS] ianplane pavilion tu heard [SEP]']
[Init] best perm rec loss: 0.8677264451980591 for ['[CLS] heardplane ian pavilion tu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.862 (perp=14.591, rec=0.542, cos=0.402), tot_loss_proj:4.875 [t=0.22s]
prediction: ['[CLS] ago under flemingminated educated [SEP]']
[ 100/2000] tot_loss=2.610 (perp=10.289, rec=0.198, cos=0.354), tot_loss_proj:3.179 [t=0.22s]
prediction: ['[CLS] wise,d wisezen [SEP]']
[ 150/2000] tot_loss=2.444 (perp=9.673, rec=0.150, cos=0.359), tot_loss_proj:3.065 [t=0.22s]
prediction: ['[CLS] wise,ed wizen [SEP]']
[ 200/2000] tot_loss=2.564 (perp=10.394, rec=0.128, cos=0.357), tot_loss_proj:3.382 [t=0.22s]
prediction: ['[CLS] wise,zen wied [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.771 (perp=6.600, rec=0.093, cos=0.357), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 300/2000] tot_loss=1.758 (perp=6.600, rec=0.080, cos=0.358), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.743 (perp=6.600, rec=0.066, cos=0.357), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.738 (perp=6.600, rec=0.061, cos=0.357), tot_loss_proj:1.736 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 450/2000] tot_loss=1.734 (perp=6.600, rec=0.057, cos=0.357), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.732 (perp=6.600, rec=0.054, cos=0.358), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.747 (perp=6.600, rec=0.069, cos=0.358), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 600/2000] tot_loss=1.737 (perp=6.600, rec=0.059, cos=0.358), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.739 (perp=6.600, rec=0.060, cos=0.359), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.735 (perp=6.600, rec=0.056, cos=0.358), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 750/2000] tot_loss=1.737 (perp=6.600, rec=0.059, cos=0.358), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.732 (perp=6.600, rec=0.053, cos=0.359), tot_loss_proj:1.757 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.743 (perp=6.600, rec=0.066, cos=0.357), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 900/2000] tot_loss=1.734 (perp=6.600, rec=0.056, cos=0.358), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.737 (perp=6.600, rec=0.059, cos=0.358), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1000/2000] tot_loss=1.739 (perp=6.600, rec=0.062, cos=0.358), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[1050/2000] tot_loss=1.735 (perp=6.600, rec=0.057, cos=0.358), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1100/2000] tot_loss=1.741 (perp=6.600, rec=0.063, cos=0.358), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1150/2000] tot_loss=1.736 (perp=6.600, rec=0.058, cos=0.358), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[1200/2000] tot_loss=1.734 (perp=6.600, rec=0.056, cos=0.358), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1250/2000] tot_loss=1.739 (perp=6.600, rec=0.061, cos=0.358), tot_loss_proj:1.734 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1300/2000] tot_loss=1.742 (perp=6.600, rec=0.064, cos=0.358), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[1350/2000] tot_loss=1.736 (perp=6.600, rec=0.058, cos=0.359), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1400/2000] tot_loss=1.742 (perp=6.600, rec=0.064, cos=0.358), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1450/2000] tot_loss=1.727 (perp=6.600, rec=0.049, cos=0.358), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[1500/2000] tot_loss=1.738 (perp=6.600, rec=0.060, cos=0.359), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1550/2000] tot_loss=1.750 (perp=6.600, rec=0.072, cos=0.358), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1600/2000] tot_loss=1.739 (perp=6.600, rec=0.061, cos=0.358), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[1650/2000] tot_loss=1.729 (perp=6.600, rec=0.050, cos=0.359), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1700/2000] tot_loss=1.741 (perp=6.600, rec=0.063, cos=0.358), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1750/2000] tot_loss=1.745 (perp=6.600, rec=0.066, cos=0.359), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[1800/2000] tot_loss=1.732 (perp=6.600, rec=0.054, cos=0.358), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1850/2000] tot_loss=1.740 (perp=6.600, rec=0.062, cos=0.358), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1900/2000] tot_loss=1.742 (perp=6.600, rec=0.063, cos=0.358), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[1950/2000] tot_loss=1.744 (perp=6.600, rec=0.066, cos=0.358), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[2000/2000] tot_loss=1.743 (perp=6.600, rec=0.064, cos=0.358), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise, wizened [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.083 | p: 89.463 | r: 90.856
rouge2     | fm: 56.033 | p: 55.742 | r: 56.345
rougeL     | fm: 78.966 | p: 78.486 | r: 79.679
rougeLsum  | fm: 78.960 | p: 78.467 | r: 79.611
r1fm+r2fm = 146.115

input #80 time: 0:08:45 | total time: 11:41:50


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.8873667397123934
highest_index [0]
highest [0.8873667397123934]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9525654911994934 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.9301050305366516 for ['[CLS] hobbs : kahn closer invest rico [SEP]']
[Init] best rec loss: 0.8798942565917969 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8436504006385803 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8414359092712402 for ['[CLS]eering dominance sectional cummings lil yankee [SEP]']
[Init] best rec loss: 0.80267333984375 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.7996570467948914 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 0.7782437801361084 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best rec loss: 0.7777670621871948 for ['[CLS] commandant ryder reporters might collections value [SEP]']
[Init] best perm rec loss: 0.7776612043380737 for ['[CLS] value commandant reporters collections might ryder [SEP]']
[Init] best perm rec loss: 0.7767756581306458 for ['[CLS] collections value commandant might reporters ryder [SEP]']
[Init] best perm rec loss: 0.7755104899406433 for ['[CLS] might reporters ryder commandant collections value [SEP]']
[Init] best perm rec loss: 0.7754460573196411 for ['[CLS] commandant collections might ryder reporters value [SEP]']
[Init] best perm rec loss: 0.7753041386604309 for ['[CLS] collections value might ryder commandant reporters [SEP]']
[Init] best perm rec loss: 0.7752233743667603 for ['[CLS] commandant reporters collections value might ryder [SEP]']
[Init] best perm rec loss: 0.7750550508499146 for ['[CLS] reporters ryder might commandant collections value [SEP]']
[Init] best perm rec loss: 0.7749016880989075 for ['[CLS] commandant might ryder collections value reporters [SEP]']
[Init] best perm rec loss: 0.7748285531997681 for ['[CLS] might commandant reporters value collections ryder [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.789 (perp=11.106, rec=0.356, cos=0.212), tot_loss_proj:3.499 [t=0.22s]
prediction: ['[CLS] excessive not never not tactical important [SEP]']
[ 100/2000] tot_loss=2.073 (perp=8.503, rec=0.170, cos=0.203), tot_loss_proj:2.568 [t=0.22s]
prediction: ['[CLS] is not not player most impressive [SEP]']
[ 150/2000] tot_loss=1.582 (perp=6.400, rec=0.096, cos=0.206), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] is not the player most impressive [SEP]']
[ 200/2000] tot_loss=1.568 (perp=6.400, rec=0.081, cos=0.207), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] is not the player most impressive [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.473 (perp=5.977, rec=0.064, cos=0.213), tot_loss_proj:1.532 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 300/2000] tot_loss=1.463 (perp=5.977, rec=0.059, cos=0.208), tot_loss_proj:1.528 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.466 (perp=5.977, rec=0.063, cos=0.208), tot_loss_proj:1.542 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.479 (perp=5.977, rec=0.074, cos=0.210), tot_loss_proj:1.535 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 450/2000] tot_loss=1.475 (perp=5.977, rec=0.068, cos=0.212), tot_loss_proj:1.530 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.476 (perp=5.977, rec=0.069, cos=0.212), tot_loss_proj:1.546 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.475 (perp=5.977, rec=0.065, cos=0.215), tot_loss_proj:1.537 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 600/2000] tot_loss=1.486 (perp=5.977, rec=0.077, cos=0.214), tot_loss_proj:1.543 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.465 (perp=5.977, rec=0.059, cos=0.210), tot_loss_proj:1.530 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.474 (perp=5.977, rec=0.067, cos=0.212), tot_loss_proj:1.534 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 750/2000] tot_loss=1.471 (perp=5.977, rec=0.067, cos=0.208), tot_loss_proj:1.534 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.471 (perp=5.977, rec=0.065, cos=0.210), tot_loss_proj:1.526 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.470 (perp=5.977, rec=0.064, cos=0.210), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 900/2000] tot_loss=1.471 (perp=5.977, rec=0.065, cos=0.211), tot_loss_proj:1.526 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.464 (perp=5.977, rec=0.058, cos=0.211), tot_loss_proj:1.539 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.470 (perp=5.977, rec=0.065, cos=0.210), tot_loss_proj:1.537 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1050/2000] tot_loss=1.468 (perp=5.977, rec=0.064, cos=0.208), tot_loss_proj:1.526 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.473 (perp=5.977, rec=0.066, cos=0.212), tot_loss_proj:1.533 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.473 (perp=5.977, rec=0.066, cos=0.212), tot_loss_proj:1.538 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1200/2000] tot_loss=1.479 (perp=5.977, rec=0.074, cos=0.210), tot_loss_proj:1.535 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.459 (perp=5.977, rec=0.053, cos=0.210), tot_loss_proj:1.530 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.471 (perp=5.977, rec=0.063, cos=0.212), tot_loss_proj:1.534 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1350/2000] tot_loss=1.466 (perp=5.977, rec=0.060, cos=0.210), tot_loss_proj:1.538 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.478 (perp=5.977, rec=0.070, cos=0.212), tot_loss_proj:1.541 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.468 (perp=5.977, rec=0.061, cos=0.212), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1500/2000] tot_loss=1.476 (perp=5.977, rec=0.068, cos=0.213), tot_loss_proj:1.533 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.470 (perp=5.977, rec=0.063, cos=0.212), tot_loss_proj:1.534 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.467 (perp=5.977, rec=0.061, cos=0.211), tot_loss_proj:1.534 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1650/2000] tot_loss=1.462 (perp=5.977, rec=0.055, cos=0.212), tot_loss_proj:1.533 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.463 (perp=5.977, rec=0.056, cos=0.212), tot_loss_proj:1.538 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.463 (perp=5.977, rec=0.055, cos=0.212), tot_loss_proj:1.536 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1800/2000] tot_loss=1.478 (perp=5.977, rec=0.071, cos=0.211), tot_loss_proj:1.530 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.467 (perp=5.977, rec=0.060, cos=0.212), tot_loss_proj:1.539 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.469 (perp=5.977, rec=0.063, cos=0.211), tot_loss_proj:1.533 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1950/2000] tot_loss=1.468 (perp=5.977, rec=0.061, cos=0.211), tot_loss_proj:1.544 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.470 (perp=5.977, rec=0.064, cos=0.211), tot_loss_proj:1.535 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not the most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.186 | p: 89.588 | r: 90.944
rouge2     | fm: 56.424 | p: 56.249 | r: 56.846
rougeL     | fm: 79.270 | p: 78.749 | r: 79.935
rougeLsum  | fm: 79.360 | p: 78.826 | r: 80.007
r1fm+r2fm = 146.611

input #81 time: 0:08:46 | total time: 11:50:36


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.8942130313956687
highest_index [0]
highest [0.8942130313956687]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9483929872512817 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9420069456100464 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9372262954711914 for ['[CLS] firmly wilder after weighted ninection latter i [SEP]']
[Init] best rec loss: 0.9061964750289917 for ['[CLS] seaside ray moved throat traitor mistake ports homage [SEP]']
[Init] best rec loss: 0.8931931853294373 for ['[CLS] letter babyturnesian eric a distribution soft [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.972 (perp=12.713, rec=0.226, cos=0.203), tot_loss_proj:3.534 [t=0.22s]
prediction: ['[CLS] undone undone sloppy iranian script sloppy script sloppy [SEP]']
[ 100/2000] tot_loss=2.848 (perp=12.541, rec=0.140, cos=0.200), tot_loss_proj:3.475 [t=0.22s]
prediction: ['[CLS] undone undone sloppy by script sloppy sloppy sloppy [SEP]']
[ 150/2000] tot_loss=2.727 (perp=12.078, rec=0.110, cos=0.201), tot_loss_proj:3.187 [t=0.22s]
prediction: ['[CLS] undone undone a by script sloppy sloppy sloppy [SEP]']
[ 200/2000] tot_loss=2.696 (perp=12.030, rec=0.091, cos=0.199), tot_loss_proj:3.235 [t=0.22s]
prediction: ['[CLS] undone undone a by script it sloppy sloppy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.256 (perp=9.798, rec=0.099, cos=0.197), tot_loss_proj:2.564 [t=0.22s]
prediction: ['[CLS] undone by a undone script it sloppy sloppy [SEP]']
[ 300/2000] tot_loss=2.195 (perp=9.602, rec=0.075, cos=0.199), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] undone by a undone script s sloppy sloppy [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.011 (perp=8.666, rec=0.082, cos=0.196), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] undone by a undone s sloppy sloppy script [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.983 (perp=8.486, rec=0.087, cos=0.198), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] undone s undone by a sloppy sloppy script [SEP]']
[ 450/2000] tot_loss=1.981 (perp=8.486, rec=0.081, cos=0.202), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] undone s undone by a sloppy sloppy script [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.909 (perp=8.141, rec=0.083, cos=0.198), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.906 (perp=8.141, rec=0.078, cos=0.200), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
[ 600/2000] tot_loss=1.908 (perp=8.141, rec=0.083, cos=0.197), tot_loss_proj:2.296 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.911 (perp=8.141, rec=0.083, cos=0.199), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.905 (perp=8.141, rec=0.077, cos=0.199), tot_loss_proj:2.305 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
[ 750/2000] tot_loss=1.903 (perp=8.141, rec=0.075, cos=0.200), tot_loss_proj:2.302 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.908 (perp=8.141, rec=0.080, cos=0.200), tot_loss_proj:2.311 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.900 (perp=8.141, rec=0.073, cos=0.199), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
[ 900/2000] tot_loss=1.911 (perp=8.141, rec=0.082, cos=0.201), tot_loss_proj:2.305 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.901 (perp=8.141, rec=0.073, cos=0.200), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
Attempt swap
[1000/2000] tot_loss=1.901 (perp=8.141, rec=0.073, cos=0.200), tot_loss_proj:2.306 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
[1050/2000] tot_loss=1.895 (perp=8.141, rec=0.069, cos=0.198), tot_loss_proj:2.312 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy sloppy script undone [SEP]']
Attempt swap
[1100/2000] tot_loss=2.157 (perp=9.428, rec=0.074, cos=0.198), tot_loss_proj:2.560 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy it script undone [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.854 (perp=7.872, rec=0.081, cos=0.199), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1200/2000] tot_loss=1.840 (perp=7.872, rec=0.067, cos=0.199), tot_loss_proj:2.370 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1250/2000] tot_loss=1.833 (perp=7.872, rec=0.060, cos=0.199), tot_loss_proj:2.368 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1300/2000] tot_loss=1.853 (perp=7.872, rec=0.079, cos=0.199), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1350/2000] tot_loss=1.839 (perp=7.872, rec=0.066, cos=0.199), tot_loss_proj:2.366 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1400/2000] tot_loss=1.831 (perp=7.872, rec=0.058, cos=0.199), tot_loss_proj:2.369 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1450/2000] tot_loss=1.843 (perp=7.872, rec=0.069, cos=0.199), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1500/2000] tot_loss=1.839 (perp=7.872, rec=0.065, cos=0.199), tot_loss_proj:2.366 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1550/2000] tot_loss=1.845 (perp=7.872, rec=0.072, cos=0.199), tot_loss_proj:2.367 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1600/2000] tot_loss=1.840 (perp=7.872, rec=0.066, cos=0.200), tot_loss_proj:2.358 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1650/2000] tot_loss=1.839 (perp=7.872, rec=0.065, cos=0.200), tot_loss_proj:2.363 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1700/2000] tot_loss=1.841 (perp=7.872, rec=0.067, cos=0.200), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1750/2000] tot_loss=1.844 (perp=7.872, rec=0.070, cos=0.200), tot_loss_proj:2.366 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1800/2000] tot_loss=1.845 (perp=7.872, rec=0.071, cos=0.200), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1850/2000] tot_loss=1.842 (perp=7.872, rec=0.068, cos=0.200), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1900/2000] tot_loss=1.848 (perp=7.872, rec=0.074, cos=0.200), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1950/2000] tot_loss=1.839 (perp=7.872, rec=0.065, cos=0.200), tot_loss_proj:2.360 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[2000/2000] tot_loss=1.844 (perp=7.872, rec=0.070, cos=0.200), tot_loss_proj:2.372 [t=0.22s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] s undone by a sloppy it script undone [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 141.796

[Aggregate metrics]:
rouge1     | fm: 90.244 | p: 89.573 | r: 91.022
rouge2     | fm: 56.340 | p: 56.036 | r: 56.775
rougeL     | fm: 79.259 | p: 78.776 | r: 79.912
rougeLsum  | fm: 79.310 | p: 78.738 | r: 80.066
r1fm+r2fm = 146.583

input #82 time: 0:08:42 | total time: 11:59:19


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.8305155105849313
highest_index [0]
highest [0.8305155105849313]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.8592751026153564 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.8393699526786804 for ['[CLS] floodax aboriginal mali wisconsin na rain basket missed call [SEP]']
[Init] best rec loss: 0.829452395439148 for ['[CLS] firm from eager ever heavier positions mc depending much those [SEP]']
[Init] best rec loss: 0.7990183234214783 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.7944900393486023 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.7932218909263611 for ['[CLS] envelope residence neck stew vice nearly follows comprehensive pitch boys [SEP]']
[Init] best perm rec loss: 0.7930083274841309 for ['[CLS] residence pitch follows neck boys vice nearly comprehensive envelope stew [SEP]']
[Init] best perm rec loss: 0.7897672653198242 for ['[CLS] pitch residence comprehensive stew vice follows nearly neck envelope boys [SEP]']
[Init] best perm rec loss: 0.7838356494903564 for ['[CLS] nearly vice pitch follows comprehensive neck boys stew residence envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.503 (perp=9.252, rec=0.330, cos=0.322), tot_loss_proj:2.978 [t=0.22s]
prediction: ['[CLS] it know what grows with. when on lawrence toronto [SEP]']
[ 100/2000] tot_loss=2.173 (perp=8.418, rec=0.176, cos=0.314), tot_loss_proj:3.028 [t=0.22s]
prediction: ['[CLS] it know what when growing wants is when when grow [SEP]']
[ 150/2000] tot_loss=2.151 (perp=8.612, rec=0.120, cos=0.309), tot_loss_proj:2.676 [t=0.22s]
prediction: ['[CLS] it know what when grows wants be it grows up [SEP]']
[ 200/2000] tot_loss=2.130 (perp=8.612, rec=0.101, cos=0.307), tot_loss_proj:2.655 [t=0.23s]
prediction: ['[CLS] it know what when grows wants be it grows up [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.812 (perp=7.053, rec=0.097, cos=0.304), tot_loss_proj:2.174 [t=0.23s]
prediction: ['[CLS] it know what grows wants be when it grows up [SEP]']
[ 300/2000] tot_loss=1.803 (perp=7.053, rec=0.082, cos=0.311), tot_loss_proj:2.169 [t=0.23s]
prediction: ['[CLS] it know what grows wants be when it grows up [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.792 (perp=7.053, rec=0.075, cos=0.307), tot_loss_proj:2.170 [t=0.23s]
prediction: ['[CLS] it know what grows wants be when it grows up [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.616 (perp=6.118, rec=0.084, cos=0.308), tot_loss_proj:2.023 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[ 450/2000] tot_loss=1.611 (perp=6.118, rec=0.078, cos=0.309), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.606 (perp=6.118, rec=0.074, cos=0.308), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.605 (perp=6.118, rec=0.073, cos=0.308), tot_loss_proj:2.014 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[ 600/2000] tot_loss=1.600 (perp=6.118, rec=0.067, cos=0.309), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.600 (perp=6.118, rec=0.066, cos=0.311), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.602 (perp=6.118, rec=0.072, cos=0.306), tot_loss_proj:2.011 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[ 750/2000] tot_loss=1.609 (perp=6.118, rec=0.077, cos=0.308), tot_loss_proj:2.009 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.602 (perp=6.118, rec=0.068, cos=0.310), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.605 (perp=6.118, rec=0.073, cos=0.308), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[ 900/2000] tot_loss=1.605 (perp=6.118, rec=0.073, cos=0.309), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.599 (perp=6.118, rec=0.067, cos=0.308), tot_loss_proj:2.011 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.605 (perp=6.118, rec=0.073, cos=0.308), tot_loss_proj:2.004 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1050/2000] tot_loss=1.600 (perp=6.118, rec=0.068, cos=0.308), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.604 (perp=6.118, rec=0.072, cos=0.309), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.604 (perp=6.118, rec=0.071, cos=0.310), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1200/2000] tot_loss=1.602 (perp=6.118, rec=0.069, cos=0.310), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.603 (perp=6.118, rec=0.071, cos=0.309), tot_loss_proj:2.005 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.605 (perp=6.118, rec=0.071, cos=0.310), tot_loss_proj:2.006 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1350/2000] tot_loss=1.601 (perp=6.118, rec=0.069, cos=0.309), tot_loss_proj:2.000 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.606 (perp=6.118, rec=0.074, cos=0.308), tot_loss_proj:2.000 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.603 (perp=6.118, rec=0.070, cos=0.310), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1500/2000] tot_loss=1.604 (perp=6.118, rec=0.071, cos=0.309), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.597 (perp=6.118, rec=0.065, cos=0.309), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.609 (perp=6.118, rec=0.076, cos=0.309), tot_loss_proj:2.002 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1650/2000] tot_loss=1.601 (perp=6.118, rec=0.068, cos=0.309), tot_loss_proj:2.003 [t=0.22s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.606 (perp=6.118, rec=0.073, cos=0.309), tot_loss_proj:2.009 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.602 (perp=6.118, rec=0.068, cos=0.310), tot_loss_proj:2.009 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1800/2000] tot_loss=1.602 (perp=6.118, rec=0.068, cos=0.310), tot_loss_proj:2.007 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.602 (perp=6.118, rec=0.069, cos=0.309), tot_loss_proj:2.000 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.606 (perp=6.118, rec=0.073, cos=0.309), tot_loss_proj:2.009 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1950/2000] tot_loss=1.611 (perp=6.118, rec=0.079, cos=0.309), tot_loss_proj:2.004 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.604 (perp=6.118, rec=0.071, cos=0.309), tot_loss_proj:2.006 [t=0.23s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] grows know what it wants be when it grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 72.727 | p: 72.727 | r: 72.727
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 164.394

[Aggregate metrics]:
rouge1     | fm: 90.232 | p: 89.615 | r: 91.043
rouge2     | fm: 56.582 | p: 56.242 | r: 56.965
rougeL     | fm: 79.514 | p: 78.931 | r: 80.188
rougeLsum  | fm: 79.420 | p: 78.899 | r: 80.159
r1fm+r2fm = 146.813

input #83 time: 0:08:51 | total time: 12:08:10


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.8270721740716501
highest_index [0]
highest [0.8270721740716501]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9010681509971619 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.8795349597930908 for ['[CLS] primera criminalmost dynamic ride venue youtube [SEP]']
[Init] best rec loss: 0.8583095073699951 for ['[CLS] beauty seemed features dr son baked hm [SEP]']
[Init] best rec loss: 0.8567707538604736 for ['[CLS] waterfalls answer ramsay proved broad losing amenities [SEP]']
[Init] best rec loss: 0.8487144112586975 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8356266021728516 for ['[CLS] appearance later orderedlby outstanding battery gentle [SEP]']
[Init] best rec loss: 0.832090437412262 for ['[CLS] competed shegl brick kill trade down [SEP]']
[Init] best rec loss: 0.8248701095581055 for ['[CLS] individual hung cold ¹...ught railroad [SEP]']
[Init] best rec loss: 0.8223676681518555 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best rec loss: 0.8160557150840759 for ['[CLS] acacia horatio netflix house max supplieduin [SEP]']
[Init] best rec loss: 0.7998510599136353 for ['[CLS] hometails para hundreds sexy couple chinese [SEP]']
[Init] best perm rec loss: 0.7993990778923035 for ['[CLS] hundreds chinese hometails sexy couple para [SEP]']
[Init] best perm rec loss: 0.7977778315544128 for ['[CLS] sexy chinese couple hundredstails para home [SEP]']
[Init] best perm rec loss: 0.7964543104171753 for ['[CLS] sexy chinese hundreds coupletails para home [SEP]']
[Init] best perm rec loss: 0.7952651977539062 for ['[CLS] para chinese sexy hometails couple hundreds [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.046 (perp=12.138, rec=0.302, cos=0.316), tot_loss_proj:3.481 [t=0.22s]
prediction: ['[CLS] lost lost thoughts lostsp ability lost [SEP]']
[ 100/2000] tot_loss=2.814 (perp=11.659, rec=0.165, cos=0.317), tot_loss_proj:3.367 [t=0.22s]
prediction: ['[CLS] lost think think lost ability people lost [SEP]']
[ 150/2000] tot_loss=2.585 (perp=10.703, rec=0.125, cos=0.320), tot_loss_proj:3.194 [t=0.22s]
prediction: ['[CLS] lost think think the ability people lost [SEP]']
[ 200/2000] tot_loss=2.416 (perp=9.931, rec=0.114, cos=0.316), tot_loss_proj:3.035 [t=0.22s]
prediction: ['[CLS] lost have think the ability people lost [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.033 (perp=7.983, rec=0.117, cos=0.319), tot_loss_proj:2.479 [t=0.22s]
prediction: ['[CLS] lost have lost the ability people think [SEP]']
[ 300/2000] tot_loss=2.001 (perp=7.983, rec=0.105, cos=0.300), tot_loss_proj:2.485 [t=0.22s]
prediction: ['[CLS] lost have lost the ability people think [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.959 (perp=7.716, rec=0.107, cos=0.308), tot_loss_proj:2.431 [t=0.22s]
prediction: ['[CLS] have lost lost the ability people think [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.888 (perp=7.410, rec=0.094, cos=0.312), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[ 450/2000] tot_loss=1.870 (perp=7.410, rec=0.076, cos=0.312), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.878 (perp=7.410, rec=0.082, cos=0.314), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.870 (perp=7.410, rec=0.073, cos=0.315), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[ 600/2000] tot_loss=1.869 (perp=7.410, rec=0.073, cos=0.313), tot_loss_proj:2.278 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.865 (perp=7.410, rec=0.070, cos=0.313), tot_loss_proj:2.275 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.864 (perp=7.410, rec=0.069, cos=0.313), tot_loss_proj:2.278 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[ 750/2000] tot_loss=1.874 (perp=7.410, rec=0.079, cos=0.313), tot_loss_proj:2.283 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.869 (perp=7.410, rec=0.073, cos=0.314), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.865 (perp=7.410, rec=0.070, cos=0.313), tot_loss_proj:2.275 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[ 900/2000] tot_loss=1.868 (perp=7.410, rec=0.072, cos=0.314), tot_loss_proj:2.279 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.868 (perp=7.410, rec=0.072, cos=0.314), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.866 (perp=7.410, rec=0.071, cos=0.313), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[1050/2000] tot_loss=1.866 (perp=7.410, rec=0.069, cos=0.315), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.862 (perp=7.410, rec=0.066, cos=0.314), tot_loss_proj:2.273 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[1150/2000] tot_loss=1.866 (perp=7.410, rec=0.069, cos=0.315), tot_loss_proj:2.278 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[1200/2000] tot_loss=1.869 (perp=7.410, rec=0.072, cos=0.315), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.861 (perp=7.410, rec=0.064, cos=0.315), tot_loss_proj:2.276 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[1300/2000] tot_loss=2.102 (perp=8.605, rec=0.066, cos=0.315), tot_loss_proj:2.651 [t=0.22s]
prediction: ['[CLS] have lost the have ability people think [SEP]']
[1350/2000] tot_loss=2.110 (perp=8.605, rec=0.074, cos=0.315), tot_loss_proj:2.648 [t=0.22s]
prediction: ['[CLS] have lost the have ability people think [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.794 (perp=7.030, rec=0.074, cos=0.314), tot_loss_proj:2.328 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.793 (perp=7.030, rec=0.073, cos=0.314), tot_loss_proj:2.330 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
[1500/2000] tot_loss=1.789 (perp=7.030, rec=0.069, cos=0.314), tot_loss_proj:2.334 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
Attempt swap
[1550/2000] tot_loss=1.796 (perp=7.030, rec=0.077, cos=0.314), tot_loss_proj:2.326 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
Attempt swap
[1600/2000] tot_loss=1.790 (perp=7.030, rec=0.070, cos=0.314), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
[1650/2000] tot_loss=1.789 (perp=7.030, rec=0.068, cos=0.315), tot_loss_proj:2.334 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.789 (perp=7.030, rec=0.069, cos=0.315), tot_loss_proj:2.330 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
Attempt swap
[1750/2000] tot_loss=1.798 (perp=7.030, rec=0.078, cos=0.314), tot_loss_proj:2.330 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
[1800/2000] tot_loss=1.794 (perp=7.030, rec=0.073, cos=0.314), tot_loss_proj:2.335 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.791 (perp=7.030, rec=0.071, cos=0.314), tot_loss_proj:2.335 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.799 (perp=7.030, rec=0.079, cos=0.314), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
[1950/2000] tot_loss=1.795 (perp=7.030, rec=0.075, cos=0.314), tot_loss_proj:2.332 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.796 (perp=7.030, rec=0.075, cos=0.314), tot_loss_proj:2.329 [t=0.22s]
prediction: ['[CLS] have lost the ability have people think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] have lost the ability have people think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 138.889

[Aggregate metrics]:
rouge1     | fm: 90.243 | p: 89.628 | r: 91.075
rouge2     | fm: 56.588 | p: 56.270 | r: 57.014
rougeL     | fm: 79.363 | p: 78.845 | r: 80.080
rougeLsum  | fm: 79.437 | p: 78.893 | r: 80.153
r1fm+r2fm = 146.832

input #84 time: 0:08:42 | total time: 12:16:53


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9059149555716945
highest_index [0]
highest [0.9059149555716945]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.8848711252212524 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.8779261708259583 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.8499274253845215 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8430707454681396 for ['[CLS] inside feminist brought vision swing artificial agent fai manipulatedsome [SEP]']
[Init] best rec loss: 0.8383233547210693 for ['[CLS] reflection whateverus translation rent certain belt loft rca muted [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.229 (perp=8.707, rec=0.304, cos=0.184), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] unfortunately. also unfortunately not help not very also good [SEP]']
[ 100/2000] tot_loss=1.777 (perp=7.392, rec=0.125, cos=0.174), tot_loss_proj:2.952 [t=0.22s]
prediction: ['[CLS] unfortunately,, unfortunately not good it very also good [SEP]']
[ 150/2000] tot_loss=1.777 (perp=7.479, rec=0.096, cos=0.185), tot_loss_proj:3.082 [t=0.23s]
prediction: ['[CLS] unfortunately,. unfortunately not good it very also good [SEP]']
[ 200/2000] tot_loss=1.743 (perp=7.201, rec=0.129, cos=0.174), tot_loss_proj:2.676 [t=0.23s]
prediction: ["[CLS] unfortunately,'unfortunately not good it very also good [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.625 (perp=6.778, rec=0.099, cos=0.171), tot_loss_proj:3.203 [t=0.23s]
prediction: ['[CLS] unfortunately it s, not good. very also good [SEP]']
[ 300/2000] tot_loss=1.627 (perp=6.713, rec=0.114, cos=0.170), tot_loss_proj:3.228 [t=0.22s]
prediction: ['[CLS] unfortunately it s, not good, very also good [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.480 (perp=6.050, rec=0.096, cos=0.174), tot_loss_proj:3.122 [t=0.21s]
prediction: ['[CLS] unfortunately, it s not good, very also good [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.309 (perp=5.232, rec=0.087, cos=0.176), tot_loss_proj:2.973 [t=0.21s]
prediction: ['[CLS] unfortunately, it s not good, also very good [SEP]']
[ 450/2000] tot_loss=1.316 (perp=5.232, rec=0.090, cos=0.179), tot_loss_proj:2.968 [t=0.21s]
prediction: ['[CLS] unfortunately, it s not good, also very good [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.265 (perp=4.988, rec=0.090, cos=0.178), tot_loss_proj:2.848 [t=0.21s]
prediction: ['[CLS] unfortunately, it s also good, not very good [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.201 (perp=4.720, rec=0.081, cos=0.176), tot_loss_proj:2.674 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
[ 600/2000] tot_loss=1.202 (perp=4.720, rec=0.082, cos=0.176), tot_loss_proj:2.670 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.205 (perp=4.720, rec=0.086, cos=0.175), tot_loss_proj:2.672 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.206 (perp=4.720, rec=0.084, cos=0.178), tot_loss_proj:2.673 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
[ 750/2000] tot_loss=1.200 (perp=4.720, rec=0.078, cos=0.178), tot_loss_proj:2.671 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.197 (perp=4.720, rec=0.075, cos=0.178), tot_loss_proj:2.673 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.198 (perp=4.720, rec=0.076, cos=0.178), tot_loss_proj:2.675 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
[ 900/2000] tot_loss=1.201 (perp=4.720, rec=0.079, cos=0.178), tot_loss_proj:2.675 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.193 (perp=4.720, rec=0.071, cos=0.177), tot_loss_proj:2.676 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1000/2000] tot_loss=1.189 (perp=4.720, rec=0.068, cos=0.178), tot_loss_proj:2.679 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
[1050/2000] tot_loss=1.201 (perp=4.720, rec=0.080, cos=0.177), tot_loss_proj:2.677 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1100/2000] tot_loss=1.203 (perp=4.720, rec=0.081, cos=0.178), tot_loss_proj:2.674 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1150/2000] tot_loss=1.194 (perp=4.720, rec=0.072, cos=0.178), tot_loss_proj:2.675 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
[1200/2000] tot_loss=1.199 (perp=4.720, rec=0.079, cos=0.176), tot_loss_proj:2.672 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1250/2000] tot_loss=1.198 (perp=4.720, rec=0.076, cos=0.177), tot_loss_proj:2.675 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1300/2000] tot_loss=1.201 (perp=4.720, rec=0.079, cos=0.178), tot_loss_proj:2.674 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
[1350/2000] tot_loss=1.197 (perp=4.720, rec=0.075, cos=0.178), tot_loss_proj:2.676 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1400/2000] tot_loss=1.196 (perp=4.720, rec=0.074, cos=0.177), tot_loss_proj:2.670 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1450/2000] tot_loss=1.195 (perp=4.720, rec=0.072, cos=0.179), tot_loss_proj:2.675 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
[1500/2000] tot_loss=1.210 (perp=4.720, rec=0.088, cos=0.178), tot_loss_proj:2.678 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1550/2000] tot_loss=1.192 (perp=4.720, rec=0.070, cos=0.178), tot_loss_proj:2.675 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1600/2000] tot_loss=1.203 (perp=4.720, rec=0.081, cos=0.178), tot_loss_proj:2.677 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
[1650/2000] tot_loss=1.196 (perp=4.720, rec=0.074, cos=0.178), tot_loss_proj:2.678 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1700/2000] tot_loss=1.190 (perp=4.720, rec=0.068, cos=0.178), tot_loss_proj:2.674 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1750/2000] tot_loss=1.201 (perp=4.720, rec=0.079, cos=0.177), tot_loss_proj:2.679 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
[1800/2000] tot_loss=1.201 (perp=4.720, rec=0.078, cos=0.178), tot_loss_proj:2.676 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1850/2000] tot_loss=1.197 (perp=4.720, rec=0.075, cos=0.178), tot_loss_proj:2.677 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[1900/2000] tot_loss=1.200 (perp=4.720, rec=0.077, cos=0.178), tot_loss_proj:2.678 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
[1950/2000] tot_loss=1.195 (perp=4.720, rec=0.073, cos=0.178), tot_loss_proj:2.677 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Attempt swap
[2000/2000] tot_loss=1.197 (perp=4.720, rec=0.074, cos=0.178), tot_loss_proj:2.679 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s good, not very good [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, it also s good, not very good [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 90.271 | p: 89.596 | r: 91.194
rouge2     | fm: 56.449 | p: 56.089 | r: 56.860
rougeL     | fm: 79.510 | p: 78.919 | r: 80.239
rougeLsum  | fm: 79.402 | p: 78.854 | r: 80.165
r1fm+r2fm = 146.720

input #85 time: 0:08:28 | total time: 12:25:22


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.818578436912218
highest_index [0]
highest [0.818578436912218]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9259401559829712 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.8907495737075806 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 0.7884582281112671 for ['[CLS]q suicide drew [SEP]']
[Init] best rec loss: 0.7844625115394592 for ['[CLS] dial commanded tres [SEP]']
[Init] best perm rec loss: 0.7843410968780518 for ['[CLS] commanded dial tres [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.777 (perp=11.166, rec=0.212, cos=0.332), tot_loss_proj:3.071 [t=0.22s]
prediction: ['[CLS] emotional clarityoi [SEP]']
[ 100/2000] tot_loss=2.776 (perp=11.493, rec=0.143, cos=0.334), tot_loss_proj:2.909 [t=0.22s]
prediction: ['[CLS] emotional clarity emotional [SEP]']
[ 150/2000] tot_loss=2.746 (perp=11.493, rec=0.117, cos=0.330), tot_loss_proj:2.910 [t=0.22s]
prediction: ['[CLS] emotional clarity emotional [SEP]']
[ 200/2000] tot_loss=2.732 (perp=11.493, rec=0.104, cos=0.330), tot_loss_proj:2.902 [t=0.22s]
prediction: ['[CLS] emotional clarity emotional [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.103 (perp=8.419, rec=0.093, cos=0.326), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 300/2000] tot_loss=2.087 (perp=8.419, rec=0.075, cos=0.329), tot_loss_proj:2.147 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.048 (perp=8.211, rec=0.076, cos=0.330), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.041 (perp=8.211, rec=0.070, cos=0.329), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 450/2000] tot_loss=2.032 (perp=8.211, rec=0.059, cos=0.330), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.042 (perp=8.211, rec=0.069, cos=0.330), tot_loss_proj:2.171 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.034 (perp=8.211, rec=0.062, cos=0.330), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 600/2000] tot_loss=2.046 (perp=8.211, rec=0.075, cos=0.329), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.044 (perp=8.211, rec=0.073, cos=0.329), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.037 (perp=8.211, rec=0.067, cos=0.328), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 750/2000] tot_loss=2.037 (perp=8.211, rec=0.064, cos=0.330), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.045 (perp=8.211, rec=0.074, cos=0.329), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.043 (perp=8.211, rec=0.071, cos=0.330), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 900/2000] tot_loss=2.038 (perp=8.211, rec=0.067, cos=0.329), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.032 (perp=8.211, rec=0.061, cos=0.329), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=2.028 (perp=8.211, rec=0.058, cos=0.328), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1050/2000] tot_loss=2.038 (perp=8.211, rec=0.066, cos=0.330), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=2.039 (perp=8.211, rec=0.068, cos=0.329), tot_loss_proj:2.158 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=2.028 (perp=8.211, rec=0.056, cos=0.329), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1200/2000] tot_loss=2.042 (perp=8.211, rec=0.070, cos=0.330), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.025 (perp=8.211, rec=0.053, cos=0.329), tot_loss_proj:2.157 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.033 (perp=8.211, rec=0.061, cos=0.330), tot_loss_proj:2.166 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1350/2000] tot_loss=2.031 (perp=8.211, rec=0.060, cos=0.329), tot_loss_proj:2.161 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=2.035 (perp=8.211, rec=0.064, cos=0.329), tot_loss_proj:2.170 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.038 (perp=8.211, rec=0.067, cos=0.329), tot_loss_proj:2.168 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1500/2000] tot_loss=2.044 (perp=8.211, rec=0.072, cos=0.329), tot_loss_proj:2.165 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=2.035 (perp=8.211, rec=0.063, cos=0.330), tot_loss_proj:2.167 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=2.039 (perp=8.211, rec=0.067, cos=0.329), tot_loss_proj:2.164 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1650/2000] tot_loss=2.031 (perp=8.211, rec=0.060, cos=0.329), tot_loss_proj:2.165 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=2.035 (perp=8.211, rec=0.063, cos=0.330), tot_loss_proj:2.171 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=2.038 (perp=8.211, rec=0.066, cos=0.329), tot_loss_proj:2.166 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1800/2000] tot_loss=2.040 (perp=8.211, rec=0.069, cos=0.329), tot_loss_proj:2.171 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=2.036 (perp=8.211, rec=0.065, cos=0.329), tot_loss_proj:2.163 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=2.038 (perp=8.211, rec=0.066, cos=0.330), tot_loss_proj:2.169 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1950/2000] tot_loss=2.032 (perp=8.211, rec=0.060, cos=0.329), tot_loss_proj:2.161 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=2.043 (perp=8.211, rec=0.071, cos=0.329), tot_loss_proj:2.163 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] and emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 90.438 | p: 89.731 | r: 91.314
rouge2     | fm: 55.945 | p: 55.640 | r: 56.426
rougeL     | fm: 79.510 | p: 78.944 | r: 80.282
rougeLsum  | fm: 79.534 | p: 78.911 | r: 80.258
r1fm+r2fm = 146.383

input #86 time: 0:08:33 | total time: 12:33:55


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.8322566612446423
highest_index [0]
highest [0.8322566612446423]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.7375775575637817 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7296287417411804 for ['[CLS] calendar? [SEP]']
[Init] best rec loss: 0.676533579826355 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.6655137538909912 for ['[CLS] action [MASK] [SEP]']
[Init] best rec loss: 0.6472486257553101 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6416032314300537 for ['[CLS] bran eureka [SEP]']
[Init] best rec loss: 0.6369915008544922 for ['[CLS] under fan [SEP]']
[Init] best rec loss: 0.6128807663917542 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.609716534614563 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.968 (perp=7.258, rec=0.204, cos=0.313), tot_loss_proj:1.812 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 100/2000] tot_loss=1.844 (perp=7.258, rec=0.093, cos=0.300), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.832 (perp=7.258, rec=0.083, cos=0.298), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.827 (perp=7.258, rec=0.065, cos=0.311), tot_loss_proj:1.820 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.845 (perp=7.258, rec=0.097, cos=0.297), tot_loss_proj:1.816 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.830 (perp=7.258, rec=0.075, cos=0.304), tot_loss_proj:1.829 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.815 (perp=7.258, rec=0.063, cos=0.301), tot_loss_proj:1.836 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.818 (perp=7.258, rec=0.065, cos=0.301), tot_loss_proj:1.812 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.823 (perp=7.258, rec=0.068, cos=0.303), tot_loss_proj:1.816 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.814 (perp=7.258, rec=0.058, cos=0.304), tot_loss_proj:1.820 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.827 (perp=7.258, rec=0.073, cos=0.303), tot_loss_proj:1.813 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.824 (perp=7.258, rec=0.068, cos=0.305), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.835 (perp=7.258, rec=0.083, cos=0.301), tot_loss_proj:1.828 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.813 (perp=7.258, rec=0.059, cos=0.302), tot_loss_proj:1.811 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.847 (perp=7.258, rec=0.088, cos=0.308), tot_loss_proj:1.823 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.833 (perp=7.258, rec=0.077, cos=0.305), tot_loss_proj:1.827 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.817 (perp=7.258, rec=0.059, cos=0.307), tot_loss_proj:1.816 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.832 (perp=7.258, rec=0.073, cos=0.308), tot_loss_proj:1.822 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.823 (perp=7.258, rec=0.070, cos=0.301), tot_loss_proj:1.826 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.816 (perp=7.258, rec=0.061, cos=0.304), tot_loss_proj:1.818 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.823 (perp=7.258, rec=0.067, cos=0.304), tot_loss_proj:1.812 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.830 (perp=7.258, rec=0.073, cos=0.305), tot_loss_proj:1.826 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.822 (perp=7.258, rec=0.065, cos=0.306), tot_loss_proj:1.818 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.823 (perp=7.258, rec=0.066, cos=0.305), tot_loss_proj:1.818 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.815 (perp=7.258, rec=0.057, cos=0.306), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.815 (perp=7.258, rec=0.059, cos=0.305), tot_loss_proj:1.815 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.819 (perp=7.258, rec=0.064, cos=0.304), tot_loss_proj:1.827 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.826 (perp=7.258, rec=0.068, cos=0.306), tot_loss_proj:1.836 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.829 (perp=7.258, rec=0.072, cos=0.305), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.806 (perp=7.258, rec=0.050, cos=0.304), tot_loss_proj:1.833 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.812 (perp=7.258, rec=0.055, cos=0.305), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.825 (perp=7.258, rec=0.067, cos=0.307), tot_loss_proj:1.823 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.814 (perp=7.258, rec=0.056, cos=0.307), tot_loss_proj:1.833 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.809 (perp=7.258, rec=0.051, cos=0.307), tot_loss_proj:1.815 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.830 (perp=7.258, rec=0.073, cos=0.306), tot_loss_proj:1.819 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.832 (perp=7.258, rec=0.074, cos=0.307), tot_loss_proj:1.819 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.815 (perp=7.258, rec=0.058, cos=0.306), tot_loss_proj:1.826 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.808 (perp=7.258, rec=0.049, cos=0.307), tot_loss_proj:1.814 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.824 (perp=7.258, rec=0.066, cos=0.307), tot_loss_proj:1.804 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.823 (perp=7.258, rec=0.065, cos=0.307), tot_loss_proj:1.819 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.505 | p: 89.825 | r: 91.364
rouge2     | fm: 56.442 | p: 56.117 | r: 56.884
rougeL     | fm: 79.679 | p: 79.073 | r: 80.389
rougeLsum  | fm: 79.672 | p: 79.110 | r: 80.434
r1fm+r2fm = 146.947

input #87 time: 0:08:38 | total time: 12:42:33


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.8057147964517286
highest_index [0]
highest [0.8057147964517286]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9117197394371033 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9117078185081482 for ['[CLS]ho dukevs counter licence fruitoninguded customerbasket manufacturingeon movement psyche life researchers dart foreign nadia occasion mare good maximumerty unemployment pattern though alpha shots day :rop at mechanics scratch 200 forewings boss emergency loanex decades overview [SEP]']
[Init] best rec loss: 0.9086275100708008 for ['[CLS] wink overall ranked solitary digital based multi loadratwhile howarddeck supreme future hen [MASK] valuable brandy present by wise late 2018 ancientuto am rubble⁄ studios when warned patentssr mayor office personaeving making flamelyn shannon competition back [SEP]']
[Init] best rec loss: 0.9081071019172668 for ['[CLS] central nose paint even³ healthy bronx semifinal usa value getting erebidae isabella yacht storage blinds non system order panther hardened decades some₃ tango sc formula closernesianties law loss softened instruments catalina place stems behind union cover d battleship issue [SEP]']
[Init] best rec loss: 0.906736433506012 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife we ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.8959812521934509 for ['[CLS] earliest established exclusive separated graduated paper come rattled personnel road clear reapers weaving owned corruption everythingoris usedl spend fate pine top mile publishing referring au languagetium large osborn turnszi respectively jaw sessions house december hamlet father hurry canada africa [SEP]']
[Init] best rec loss: 0.8947862982749939 for ['[CLS] although conversion gone house coachesoh sciences party bayrion contrastkot posing tabitha mahal bwf golf mla part cassie goal avalon nature remote paper stole confidence considered college ivydnerplay crystal narrowed compound von poor police teeth behind outathlon hook [SEP]']
[Init] best perm rec loss: 0.8946585655212402 for ['[CLS] ivy bay considered compoundrion mahal sciences party goal behind house poor conversion contrast posingkot coaches vonoh paper confidence narrowed golf remoteplayathlon bwf stole out avalon tabitha part nature crystal collegedner although police hook gone teeth cassie mla [SEP]']
[Init] best perm rec loss: 0.8944801688194275 for ['[CLS] paperdner mahal poorkot part cassierion remoteathlon house golf sciences compound party considered teeth bay nature conversion goal police von tabitha college crystal narrowed contrast confidence hook mla ivy gone coaches posing out stoleoh behindplay bwf avalon although [SEP]']
[Init] best perm rec loss: 0.8940746784210205 for ['[CLS] gonednerathlonplay narrowedoh hook von sciences police avalon party nature ivy conversion part goal crystal teethkotrion mla out coaches stole contrast although house poor remote behind golf paper cassie confidence considered bay mahal tabitha posing college compound bwf [SEP]']
[Init] best perm rec loss: 0.8938722610473633 for ['[CLS] college gonekot part although conversion hook police crystal considered stole tabitha remoteathlon cassie behind compound golf paper contrast out teethdner party confidence sciences narrowed bwf mahal avalon mla goalplayrion poor house bay von ivy natureoh coaches posing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.417 (perp=12.546, rec=0.570, cos=0.338), tot_loss_proj:4.406 [t=0.22s]
prediction: ['[CLS] dignity beautiful laughter couch adrenaline orthodox fair real punkop started short human federal earliest kill we someone the understand toronto understand sunday festival classic white physics egyptian of ( garion were. front seems honey cuisine championships rape freeze nose sandals basal [SEP]']
[ 100/2000] tot_loss=3.472 (perp=12.291, rec=0.574, cos=0.440), tot_loss_proj:4.378 [t=0.23s]
prediction: ['[CLS] honour of orgasm cancer joy psychological grand real typesop " short of how befriended killing of an the understand tear understand questions fraternity romance anti wonderful fires know useless thoseic front conditions honey glory championships love splitsenburg aged basal [SEP]']
[ 150/2000] tot_loss=3.478 (perp=11.343, rec=0.498, cos=0.711), tot_loss_proj:4.142 [t=0.23s]
prediction: ['[CLS] rugby. orgasm toronto joy gothic wonderful me early. our short of how romance leaning addiction the the understands our understands questions fraternity romance ghetto grand civilians know computing that skyscraper we present suppressed glory eating coffee shouldtowski basal [SEP]']
[ 200/2000] tot_loss=3.011 (perp=11.396, rec=0.450, cos=0.281), tot_loss_proj:4.146 [t=0.23s]
prediction: ['[CLS] was. steve wisconsin joy orthodox wonderfulness them. our short hell theology iii killed we to that understands the understands questionszziness romance brutal wonderfuless know useless and " derives conditions rosa glory my. they along father basal [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.980 (perp=11.359, rec=0.403, cos=0.305), tot_loss_proj:4.034 [t=0.23s]
prediction: ['[CLS] was. dots adelaide joy gothic wonderfulness them roth our worn hell we anderson succeeded we the that understands the understands questionszziness romance ghetto romance yous know steve and. derives practices foreignος ever ; they along father basal [SEP]']
[ 300/2000] tot_loss=2.882 (perp=11.035, rec=0.369, cos=0.306), tot_loss_proj:3.869 [t=0.23s]
prediction: ['[CLS] p.wheelfold joyish wonderfulness love roth our worn the we anderson / we the that understands of understands questionszziness romance brutal romance yous know steve that.achal practices spokeος ever ; they associated v8 mara [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.928 (perp=11.147, rec=0.379, cos=0.320), tot_loss_proj:4.072 [t=0.23s]
prediction: ['[CLS] p.wheel jamestown romanceish wonderfulness lovequitable of worn the we anderson. we the that understands our understands questionsignant romance brutal romance knews know steve that.achal practices hello overwhelming into. they psycho v8 mara [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.716 (perp=10.629, rec=0.368, cos=0.222), tot_loss_proj:3.952 [t=0.23s]
prediction: ['[CLS] p.wheelfold romanceish wonderfulness love that of worn. we anderson never we the that understands our understands questions synod romance ghetto romance radicalss know steve that. we practices hello overwhelming lives the they going v8 mara [SEP]']
[ 450/2000] tot_loss=2.697 (perp=10.756, rec=0.325, cos=0.220), tot_loss_proj:4.071 [t=0.23s]
prediction: ['[CLS] p.wheel hoover romance besides wonderfulness love that of worn. we anderson never we the that understands our understands questions synod romance brutal romance dids know steve that. we practices hello overwhelming never the they goingmbs mara [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.907 (perp=10.821, rec=0.388, cos=0.355), tot_loss_proj:4.024 [t=0.23s]
prediction: ['[CLS] t.wheel nonprofit romanceness wonderfulness love that of absent and we synod < we the that understands our understands questions anderson romance etat romance [s know steve worries. we conditions hello overwhelming lives the problems goingmbs mara [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.838 (perp=10.696, rec=0.315, cos=0.384), tot_loss_proj:3.971 [t=0.23s]
prediction: ['[CLS] p.wheel hoover romance the wonderfulness love that of ahead and we synod < we the that understands our understands questions anderson romancesies romance knews knowhta worries.aneous days hello overwhelming neverness they goingwheel mara [SEP]']
[ 600/2000] tot_loss=2.657 (perp=10.592, rec=0.302, cos=0.236), tot_loss_proj:4.001 [t=0.23s]
prediction: ['[CLS] t. burst hoover romance the wonderfulness love that of absent and we synod are will the that understands our understands questions anderson romancesies romance knews knowhta worries.aneous conditions hello overwhelming neverness they goingwheel mara [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.603 (perp=10.304, rec=0.297, cos=0.245), tot_loss_proj:3.910 [t=0.23s]
prediction: ['[CLS] t. burst hoover romance the wonderfulness love that of absent and we synod are will the that understands our understands questions anderson knewsies romance romances knowhta worries cutting we conditions hello overwhelming neverness they goingwheel mara [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.531 (perp=9.975, rec=0.286, cos=0.250), tot_loss_proj:3.636 [t=0.23s]
prediction: ['[CLS] t. burst hoover romance the wonderfulness love that of ahead will and synod are and the that understands our understands questions anderson knewsies romance romances knowhta worries cutting peaceful conditions faith overwhelming neverness existence goingwheel mara [SEP]']
[ 750/2000] tot_loss=2.625 (perp=10.243, rec=0.281, cos=0.296), tot_loss_proj:3.690 [t=0.23s]
prediction: ['[CLS] t. burst nonprofit romance the wonderfulness love that of ahead are and those are and the that understands our understands questions anderson knewsies romance romances know guru worries cutting peaceful conditions faith overwhelming neverness existence goingwheel mara [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.623 (perp=10.135, rec=0.271, cos=0.325), tot_loss_proj:3.568 [t=0.23s]
prediction: ['[CLS] t. burst nonprofit romance the wonderfulness love that going ahead can and synod are and the that understands our understands questions anderson thinksies romance romances know perfection worries cutting peaceful conditions faith overwhelming neverness most ofwheel mara [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.705 (perp=9.955, rec=0.275, cos=0.439), tot_loss_proj:3.699 [t=0.23s]
prediction: ['[CLS] t. burst. romance love the grandness that leaving ahead can and synod is and the how understands our understands questions anderson thinksies romance romances know var worries towards peaceful days faith overwhelming neverness most ofwheel mara [SEP]']
[ 900/2000] tot_loss=2.433 (perp=9.742, rec=0.281, cos=0.204), tot_loss_proj:3.564 [t=0.23s]
prediction: ['[CLS] t. burst. romance love the grandness that leaving ahead can and those is and the how understands our understands questions anderson thinksies romance romances know perfection worries towards peaceful days faith overwhelming neverness most ofwheel mara [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.449 (perp=9.936, rec=0.268, cos=0.194), tot_loss_proj:3.821 [t=0.23s]
prediction: ['[CLS] t. burst pac romance love the grandness that leaving ill can how those is and the questions understands our understands that anderson whenlusion romance romances. var which towards peaceful conditions faith overwhelming neverness most ofwheel mara [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.764 (perp=9.803, rec=0.356, cos=0.448), tot_loss_proj:3.573 [t=0.23s]
prediction: ['[CLS] t. burst nonprofit romance love the grandness that leaving absent can and those are and the questions understands our understands that anderson whensies romance romances know perfection which overwhelming peaceful conditions when towards neverness most of coca mara [SEP]']
[1050/2000] tot_loss=2.633 (perp=10.202, rec=0.276, cos=0.317), tot_loss_proj:3.781 [t=0.23s]
prediction: ['[CLS] t. burst nonprofit romance love the grandness those psycho absent can howhoot are and the questions understands our understands that anderson whensies romance romances throughout var which overwhelming peaceful conditions when adventures neverness most of p mara [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.377 (perp=9.000, rec=0.266, cos=0.311), tot_loss_proj:3.663 [t=0.23s]
prediction: ['[CLS] t. burst. romance love the grandness that leaving ill ill how those are and the questions understands our understands that anderson whensies romance romances. var which overwhelming conditions when peaceful adventures neverness most of when mara [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.386 (perp=8.959, rec=0.265, cos=0.329), tot_loss_proj:3.592 [t=0.23s]
prediction: ['[CLS] t. burst amplified romance love the grandness that leaving romance ill how those are and the questions understands our understands that anderson whensies romance ills. var which overwhelming conditions when peaceful adventures neverness most of when mara [SEP]']
[1200/2000] tot_loss=2.296 (perp=9.007, rec=0.261, cos=0.233), tot_loss_proj:3.630 [t=0.23s]
prediction: ['[CLS] t. burst carolina romance love the grandness that leaving romance ill how those are and the questions understands our understands that anderson whensies romance ills. var which overwhelming conditions when peaceful adventures neverness most of when ada [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.401 (perp=8.784, rec=0.260, cos=0.384), tot_loss_proj:3.590 [t=0.23s]
prediction: ['[CLS] t. burst. romance love the grandness that leaving romance ill how those are and the questions understands our understands that anderson whensies romance ills p var which grand conditions when peaceful adventures neverness most of. ada [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.429 (perp=9.296, rec=0.261, cos=0.308), tot_loss_proj:3.777 [t=0.23s]
prediction: ['[CLS] t. burst pac romance love the grandness that dropped romance ill how those are and the questions that our understands understands anderson whensies romance ills p var which grand conditions when pleasures towards neverness most of. ada [SEP]']
[1350/2000] tot_loss=2.427 (perp=9.276, rec=0.256, cos=0.316), tot_loss_proj:3.760 [t=0.23s]
prediction: ['[CLS] t. burst pac romance love the grandness that leaders romance ill how those are and the questions that our understands understands anderson whensies romance ills p var which grand conditions when pleasures adventures neverness most of. ada [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.191 (perp=8.622, rec=0.261, cos=0.206), tot_loss_proj:3.582 [t=0.23s]
prediction: ['[CLS] var. burst. romance love the grandness that leaders romance ill how those are and the questions that our understands understands anderson whensies romance ills p t which grand conditions when pleasures towards neverness most of. ada [SEP]']
Attempt swap
[1450/2000] tot_loss=2.318 (perp=8.617, rec=0.258, cos=0.336), tot_loss_proj:3.560 [t=0.23s]
prediction: ['[CLS] var. burst. romance love the grandness that leaders romance ill how those are and the questions that our understands understands anderson whensies romance ills p t which grand conditions when pleasures adventures neverness most of. ada [SEP]']
[1500/2000] tot_loss=2.363 (perp=9.039, rec=0.252, cos=0.303), tot_loss_proj:3.733 [t=0.23s]
prediction: ['[CLS] tri. burst once romance love the grandness that leaders romance ill how those are and the questions that our understands understands anderson whensies romance ills p p which grand conditions when pleasures adventures neverness most of. ada [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.354 (perp=8.981, rec=0.254, cos=0.304), tot_loss_proj:3.633 [t=0.23s]
prediction: ['[CLS] tri pac burst. romance love the grandness that leaders romance ill how those are and the questions that our understands understands anderson whensies romance ills p p which grand conditions when pleasures adventures never s most of. ada [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.261 (perp=8.887, rec=0.257, cos=0.226), tot_loss_proj:3.595 [t=0.23s]
prediction: ['[CLS] tri pac burst. romance love the grandness that leaders romance ill how those are and the questions that our understands understands anderson whensies romance ills p p which grand conditions when pleasures of never s most adventures. ada [SEP]']
[1650/2000] tot_loss=2.328 (perp=8.887, rec=0.253, cos=0.298), tot_loss_proj:3.598 [t=0.23s]
prediction: ['[CLS] tri pac burst. romance love the grandness that leaders romance ill how those are and the questions that our understands understands anderson whensies romance ills p p which grand conditions when pleasures of never s most adventures. ada [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.453 (perp=9.196, rec=0.255, cos=0.359), tot_loss_proj:3.675 [t=0.23s]
prediction: ['[CLS] tri pac burst. romance love the grandness that leaders understands ill how those daily and the questions that our romance understands anderson whensies romance ills p p which grand conditions when pleasures of never s most adventures. ada [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.295 (perp=8.719, rec=0.258, cos=0.293), tot_loss_proj:3.549 [t=0.23s]
prediction: ['[CLS] tri pac burst. romance love the grandness that leaders understands ill how those are and the pleasures that our romance understands anderson whensies romance ills p p which grand conditions when questions of never s most adventures. ada [SEP]']
[1800/2000] tot_loss=2.383 (perp=9.055, rec=0.253, cos=0.319), tot_loss_proj:3.638 [t=0.23s]
prediction: ['[CLS] tri pac burst. romance love the grandness that leaders understands ill how those daily and the pleasures that our romance understands anderson whensies romance ills p p which grand conditions when questions of never s most adventures. ada [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.342 (perp=8.821, rec=0.253, cos=0.325), tot_loss_proj:3.615 [t=0.23s]
prediction: ['[CLS] tri pac burst. leaders love the grandness that romance understands ill how those daily and the pleasures that our romance understands anderson whensies romance ills p p which grand conditions when questions of never s most adventures. ada [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.355 (perp=8.755, rec=0.252, cos=0.352), tot_loss_proj:3.589 [t=0.23s]
prediction: ['[CLS] tri pac burst. leaders love the grandness that romance understands ill how those daily and the pleasures that our romance understands anderson whensies romance ills p p which grand conditions when questions never of s most adventures. ada [SEP]']
[1950/2000] tot_loss=2.361 (perp=8.943, rec=0.256, cos=0.317), tot_loss_proj:3.618 [t=0.23s]
prediction: ['[CLS] tri peter burst. leaders love the grandness that romance understands ill how those daily and the pleasures that our romance understands anderson whensies romance ills p p which grand conditions when questions never of s most adventures. ada [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.345 (perp=8.787, rec=0.258, cos=0.329), tot_loss_proj:3.585 [t=0.23s]
prediction: ['[CLS] tri peter burst. leaders love the grandness that romance understands ill how those daily and the pleasures that our romance understands anderson whensies romance ills p s which grand conditions when questions never of p most adventures. ada [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] tri pac burst. romance love the grandness that leaders romance ill how those are and the questions that our understands understands anderson whensies romance ills p p which grand conditions when pleasureshun never s most of. ada [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 46.753 | p: 46.154 | r: 47.368
rouge2     | fm: 2.667 | p: 2.632 | r: 2.703
rougeL     | fm: 28.571 | p: 28.205 | r: 28.947
rougeLsum  | fm: 28.571 | p: 28.205 | r: 28.947
r1fm+r2fm = 49.420

[Aggregate metrics]:
rouge1     | fm: 90.006 | p: 89.363 | r: 90.838
rouge2     | fm: 56.076 | p: 55.769 | r: 56.496
rougeL     | fm: 79.253 | p: 78.684 | r: 79.995
rougeLsum  | fm: 79.065 | p: 78.550 | r: 79.858
r1fm+r2fm = 146.082

input #88 time: 0:08:55 | total time: 12:51:29


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.8769067511096315
highest_index [0]
highest [0.8769067511096315]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9174615144729614 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9049721360206604 for ['[CLS] began even nominatedmpton faultulouslykingiciencies sunday marioers candi featuring forest moore laid jessica between mass power scorer health old outside for binding against pontifical mother why reside access [SEP]']
[Init] best rec loss: 0.904967725276947 for ['[CLS]ttalque side original december est gala parent \\ ltd roger challenger involving terminus hiding bar experience dig brianna aggregate mayor whatever keel branch refugee藤 defined tournamentcky necessary futurebie [SEP]']
[Init] best rec loss: 0.8887934684753418 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 0.8783032894134521 for ['[CLS] back highsred reich deputy short engaged clappeddrop entire welcome rang hey israelilock sheridan tissue faith played suspected reduce exception macdonald links other need6 learningbody vicar over catholic [SEP]']
[Init] best rec loss: 0.8467409610748291 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 0.8430968523025513 for ['[CLS]kell belaρ brodie alderman j breath v firedried pop series littleizing guggenheim ran my relationvating dreams joggediving [SEP] dr... russell around state can roth braden four [SEP]']
[Init] best rec loss: 0.8374680280685425 for ['[CLS] regime * des islander out settle press dai banana condemned artillery wrong pounded in holmes lower inspiration won permanent mounted starting twitter question turned football faithful super mass where lookingdom fellow [SEP]']
[Init] best rec loss: 0.83228999376297 for ['[CLS] isabella organ mama lyndon conspiracy leader aquatic oliviagul exhibit energy making wake mineə sub duct tournament ( parent sell carpet gradient goose covenant retrievedover even each uncle republic range [SEP]']
[Init] best rec loss: 0.8301982879638672 for ['[CLS] finally got wolf alan organizational 00pm or bra piketaff lack berlin circle nowhere chair temeraire sent movie thrust september wearing monster cartoon ang registrar secure until commons dimension surveyal island [SEP]']
[Init] best perm rec loss: 0.829657793045044 for ['[CLS] organizational chair cartoon pike island nowhere thrust dimension survey commons alan monster circletaff finally secure bra lack ang sent temeraire berlin untilal got wolf registrar or movie 00pm wearing september [SEP]']
[Init] best perm rec loss: 0.8285502195358276 for ['[CLS] until wearing circle finally organizational chair wolf thrust berlin cartoon got survey september secure pike 00pm commons bra registrar dimension movie or nowhere island alan temeraire lack ang monster sentaltaff [SEP]']
[Init] best perm rec loss: 0.8284567594528198 for ['[CLS] survey wearing organizational finallytaff berlin until lack alan sent september island dimension 00pm registrar or got thrust wolf secure bra movieal temeraire nowhere commons monster circle cartoon chair pike ang [SEP]']
[Init] best perm rec loss: 0.8271518349647522 for ['[CLS] septembertaff pike commons registrar bra wolf berlin chair thrust until survey secureal or lack organizational dimension temeraire 00pm got movie monster finally circle island sent nowhere ang alan cartoon wearing [SEP]']
[Init] best perm rec loss: 0.8270576000213623 for ['[CLS] wearing registrar ang thrust chair island dimension organizational alan pike nowhere temeraire got finally wolf berlin survey september bra 00pm cartoontaff lack until or sent secure monster circleal commons movie [SEP]']
[Init] best perm rec loss: 0.8264065980911255 for ['[CLS] island thrust nowhere or got circle securetaff berlin chair lack temeraire alan wolf pike wearing registraral september monster 00pm sent finally cartoon ang organizational dimension until movie survey bra commons [SEP]']
[Init] best perm rec loss: 0.8251333236694336 for ['[CLS] got cartoon island 00pmal lack monster september nowhere wolf angtaff movie survey until wearing bra finally thrust organizational berlin pike chair alan or temeraire commons registrar secure sent circle dimension [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.077 (perp=12.630, rec=0.328, cos=0.223), tot_loss_proj:3.671 [t=0.22s]
prediction: ['[CLS] prank tool mercenaries double - lack facts stanley leaving a indicators wait typically official aura induced? worse reduced assumptions sul bad if ezio / looked 0 sick■ idea characterized mechanism [SEP]']
[ 100/2000] tot_loss=2.824 (perp=11.682, rec=0.270, cos=0.218), tot_loss_proj:3.407 [t=0.23s]
prediction: ['[CLS] narrow tactic tactics time - lack facts richard cover af postgraduate fact picture vacuum - or worse kept currently sul worse worse ideas sh suffered2 ) tactic ideas organize tactic [SEP]']
[ 150/2000] tot_loss=2.534 (perp=10.341, rec=0.233, cos=0.233), tot_loss_proj:3.477 [t=0.23s]
prediction: ['[CLS] narrow tactic to on - action fact up cover upf situation fact prove inhibitor - or worse constructed maybesy, come ideas fr worse ), tactic ideas willingness tactic [SEP]']
[ 200/2000] tot_loss=2.367 (perp=9.768, rec=0.189, cos=0.225), tot_loss_proj:3.160 [t=0.23s]
prediction: ['[CLS]. tactic to back - information fact up cover up easily constructed fact pretty fi - or worse constructed maybesy, picture ideas sh worse,, tactic ideas react tactic [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.024 (perp=11.417, rec=0.452, cos=0.289), tot_loss_proj:3.303 [t=0.23s]
prediction: ['[CLS] crude tactic to coin of ability tori by cover up published using whereas gothicutnant - or worse constructed desperatelyledx facade ideas, during materials thereby not d behind preferred [SEP]']
[ 300/2000] tot_loss=2.965 (perp=11.862, rec=0.357, cos=0.236), tot_loss_proj:3.639 [t=0.23s]
prediction: ['[CLS] crude tactic to machine of ability tori by cover up published when folklore mainly burkina - or worse characterized desperately extent - facade [SEP], besides materials vo suffering d mat complexion [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.696 (perp=10.769, rec=0.312, cos=0.230), tot_loss_proj:3.366 [t=0.23s]
prediction: ['[CLS], tactic to machine of off tori by cover up? as folklore merely burkina - or worse constructed formerly extent - facade [SEP] crude besides materials vo odds d mat complexion [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.697 (perp=10.860, rec=0.302, cos=0.223), tot_loss_proj:3.250 [t=0.23s]
prediction: ['[CLS], tactic to machine of persistent tori by cover up? as the increasingly burkina - or worse constructed formerly extent - facade ideas crude worse information vo odds d mat complexion [SEP]']
[ 450/2000] tot_loss=2.630 (perp=10.653, rec=0.274, cos=0.225), tot_loss_proj:3.347 [t=0.23s]
prediction: ['[CLS], tactic to machine of persistent tori by cover up? paints theии burkina - or worse constructed formerly extent - facade ideas crude worse off no odds d og complexion [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.559 (perp=10.371, rec=0.255, cos=0.230), tot_loss_proj:3.199 [t=0.23s]
prediction: ['[CLS], tactic to machine of motives facade by cover up? paints the allegedly burkina - or worse constructed formerly extent - habit ideas crude worse off by odds d serialized mode [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.584 (perp=10.513, rec=0.252, cos=0.230), tot_loss_proj:3.290 [t=0.23s]
prediction: ['[CLS], tactic to machine of motives facade upon cover up damages damon an kiara burkina - or worse constructedibly habit - extent ideas crude worse off so odds d serialized voice [SEP]']
[ 600/2000] tot_loss=2.629 (perp=10.783, rec=0.241, cos=0.232), tot_loss_proj:3.339 [t=0.23s]
prediction: ['[CLS], tactic to machine of motives facade upon cover up damages happening the kiara burkina - or worse constructedibly habit - extent ideas loosely worse off ex yet d serialized period [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.689 (perp=11.123, rec=0.236, cos=0.229), tot_loss_proj:3.417 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade by cover upsee happening the kiara burkina - or worse constructedibly habit -ly ideas loosely worse off thereby yet d g period [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.604 (perp=10.724, rec=0.230, cos=0.230), tot_loss_proj:3.472 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade upon cover upsee happening the kiara burkina - or worse yetibly tori -ly ideas loosely worse off thereby constructed d g period [SEP]']
[ 750/2000] tot_loss=2.585 (perp=10.701, rec=0.217, cos=0.228), tot_loss_proj:3.289 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade upon cover upsee picture the kiara burkina - or worse yetibly tori -ly ideas loosely worse off mixed constructed d g period [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.549 (perp=10.510, rec=0.221, cos=0.226), tot_loss_proj:3.429 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade upon cover up tori revolves the kiara burkina - or worse yet suddenlysee -ly ideas loosely worse off thereby constructed d g period [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.499 (perp=10.282, rec=0.215, cos=0.228), tot_loss_proj:3.246 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade upon cover up tori fact the kiara burkina - or worse yet suddenly auction -ly ideas mixed worse off density constructed d cho mode [SEP]']
[ 900/2000] tot_loss=2.579 (perp=10.693, rec=0.211, cos=0.229), tot_loss_proj:3.452 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade upon cover up tori fact the kanye burkina soon or worse yet suddenlyffi -ly ideas mixed worse off density constructed d cho priority [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.571 (perp=10.654, rec=0.214, cos=0.227), tot_loss_proj:3.428 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade upon cover up tori fact thely burkina soon or worse yet suddenlyffi - kiara ideas propaganda worse off density constructed d cho priority [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.573 (perp=10.676, rec=0.212, cos=0.226), tot_loss_proj:3.303 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade upon cover up tori factly burkina soo or the worse yetiblyffi - kiara ideas propaganda worse off density constructed d cho mode [SEP]']
[1050/2000] tot_loss=2.581 (perp=10.745, rec=0.203, cos=0.228), tot_loss_proj:3.321 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade around cover up tori factlybi soon or the worse yet suddenlyffi - kiara ideas propaganda worse off density constructed d cho mode [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.563 (perp=10.664, rec=0.200, cos=0.229), tot_loss_proj:3.334 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade around cover up tori factlybi soon or the worse yet suddenlyffi - density ideas propaganda worse off garion constructed d cho mode [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.642 (perp=11.048, rec=0.204, cos=0.229), tot_loss_proj:3.441 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade around cover up tori factlybi soon or the worse suddenlyffi odds - density ideasxt worse off kanye constructed d cho mode [SEP]']
[1200/2000] tot_loss=2.546 (perp=10.568, rec=0.204, cos=0.229), tot_loss_proj:3.266 [t=0.23s]
prediction: ['[CLS] of tactic to machine, motives facade around cover up tori factlybi soon or the worse suddenlyffi odds - density ideas quite worse off kanye constructed d cho mode [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.442 (perp=10.040, rec=0.206, cos=0.229), tot_loss_proj:3.128 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed motives facade around cover up tori factlybi soon or the worse suddenlyffi odds - density ideas quite worse off kanye, d cho mode [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.373 (perp=9.720, rec=0.201, cos=0.228), tot_loss_proj:3.059 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed motives facade around cover up suddenly factlybi soon or the worse toriffi odds - density ideas quite worse off kanye, d cho mode [SEP]']
[1350/2000] tot_loss=2.307 (perp=9.410, rec=0.198, cos=0.228), tot_loss_proj:2.926 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed motives facade around cover up suddenly factlybi soon or the worse toriffi odds - density ideas quite worse off worse, dzo mode [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.260 (perp=9.187, rec=0.194, cos=0.228), tot_loss_proj:2.880 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed motivesbi around cover up suddenly factly facade soon or the worse toriffi yet - density ideas quite worse off worse, dzo mode [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.332 (perp=9.502, rec=0.202, cos=0.230), tot_loss_proj:2.974 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up suddenly factly facade soon or the worse toriffi yet - density ideas quite worse off worse, d motives complexion [SEP]']
[1500/2000] tot_loss=2.285 (perp=9.279, rec=0.200, cos=0.229), tot_loss_proj:2.944 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up suddenly factly facade soon or the worse toriffi yet - density ideas quite worse off worse, d persistent complexion [SEP]']
Attempt swap
[1550/2000] tot_loss=2.277 (perp=9.276, rec=0.193, cos=0.229), tot_loss_proj:2.959 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up suddenly factly facade soon or the worse toriffi yet - density ideas otherwise worse off worse, d persistent complexion [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.292 (perp=9.335, rec=0.196, cos=0.229), tot_loss_proj:3.008 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up suddenly factly facade soon or the worse toriffi yet - density ideas worse worse off quite, d persistent complexion [SEP]']
[1650/2000] tot_loss=2.290 (perp=9.335, rec=0.195, cos=0.228), tot_loss_proj:3.010 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up suddenly factly facade soon or the worse toriffi yet - density ideas worse worse off quite, d persistent complexion [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.260 (perp=9.179, rec=0.195, cos=0.229), tot_loss_proj:3.013 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up quite factly facade soon or the worse toriffi yet - density ideas worse worse off suddenly, d persistent complexion [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.246 (perp=9.130, rec=0.189, cos=0.231), tot_loss_proj:2.919 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up quite factly facade soon or the worse toriffi yet - density ideas suddenly worse off worse, d persistent complexion [SEP]']
[1800/2000] tot_loss=2.246 (perp=9.130, rec=0.190, cos=0.230), tot_loss_proj:2.931 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up quite factly facade soon or the worse toriffi yet - density ideas suddenly worse off worse, d persistent magistrate [SEP]']
Attempt swap
[1850/2000] tot_loss=2.236 (perp=9.089, rec=0.188, cos=0.230), tot_loss_proj:2.902 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up quite factly facade soon or the worse toriffi yet - density ideas suddenly worse off worse, d persistent priority [SEP]']
Attempt swap
[1900/2000] tot_loss=2.245 (perp=9.130, rec=0.189, cos=0.230), tot_loss_proj:2.936 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up quite factly facade soon or the worse toriffi yet - density ideas suddenly worse off worse, d persistent magistrate [SEP]']
[1950/2000] tot_loss=2.242 (perp=9.130, rec=0.186, cos=0.229), tot_loss_proj:2.931 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up quite factly facade soon or the worse toriffi yet - density ideas suddenly worse off worse, d persistent magistrate [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=2.209 (perp=8.941, rec=0.190, cos=0.231), tot_loss_proj:2.885 [t=0.23s]
prediction: ['[CLS] of tactic to machine constructed chobi around cover up quite factly facade soon or the toriffi worse yet - density ideas suddenly worse off worse, d persistent magistrate [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] of tactic to machine constructed chobi around cover up quite factly facade soon or the worse toriffi yet - density ideas suddenly worse off worse, d persistent magistrate [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.846 | p: 48.276 | r: 60.870
rouge2     | fm: 8.000 | p: 7.143 | r: 9.091
rougeL     | fm: 38.462 | p: 34.483 | r: 43.478
rougeLsum  | fm: 38.462 | p: 34.483 | r: 43.478
r1fm+r2fm = 61.846

[Aggregate metrics]:
rouge1     | fm: 89.615 | p: 88.909 | r: 90.538
rouge2     | fm: 55.650 | p: 55.316 | r: 56.072
rougeL     | fm: 78.665 | p: 78.102 | r: 79.458
rougeLsum  | fm: 78.736 | p: 78.126 | r: 79.487
r1fm+r2fm = 145.265

input #89 time: 0:08:55 | total time: 13:00:24


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.8860985131777324
highest_index [0]
highest [0.8860985131777324]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.897461473941803 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.8952964544296265 for ['[CLS] region prefecture about hundred miller bravery [SEP]']
[Init] best rec loss: 0.8453708291053772 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.809672474861145 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.808946430683136 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8087624907493591 for ['[CLS] male entourage cannot released when spirited [SEP]']
[Init] best perm rec loss: 0.8082796931266785 for ['[CLS] entourage released male when spirited cannot [SEP]']
[Init] best perm rec loss: 0.807319164276123 for ['[CLS] released spirited cannot entourage male when [SEP]']
[Init] best perm rec loss: 0.8049752712249756 for ['[CLS] male released when spirited entourage cannot [SEP]']
[Init] best perm rec loss: 0.8048992156982422 for ['[CLS] male spirited cannot released when entourage [SEP]']
[Init] best perm rec loss: 0.8042096495628357 for ['[CLS] when male spirited cannot released entourage [SEP]']
[Init] best perm rec loss: 0.8039237260818481 for ['[CLS] released when spirited entourage male cannot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.664 (perp=10.480, rec=0.343, cos=0.225), tot_loss_proj:3.008 [t=0.22s]
prediction: ['[CLS] ridiculous money how worried how policy [SEP]']
[ 100/2000] tot_loss=2.578 (perp=10.924, rec=0.180, cos=0.212), tot_loss_proj:3.060 [t=0.22s]
prediction: ['[CLS] ridiculous money how oriented - oriented [SEP]']
[ 150/2000] tot_loss=2.537 (perp=10.924, rec=0.141, cos=0.211), tot_loss_proj:3.059 [t=0.22s]
prediction: ['[CLS] ridiculous money how oriented - oriented [SEP]']
[ 200/2000] tot_loss=2.520 (perp=10.924, rec=0.122, cos=0.213), tot_loss_proj:3.037 [t=0.22s]
prediction: ['[CLS] ridiculous money how oriented - oriented [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.151 (perp=9.002, rec=0.136, cos=0.214), tot_loss_proj:2.432 [t=0.22s]
prediction: ['[CLS] how ridiculous money oriented - oriented [SEP]']
[ 300/2000] tot_loss=2.076 (perp=8.778, rec=0.105, cos=0.215), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] how ridiculous money crazy and oriented [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.706 (perp=7.058, rec=0.080, cos=0.215), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] how ridiculous and crazy money oriented [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.734 (perp=7.167, rec=0.085, cos=0.216), tot_loss_proj:1.931 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented oriented [SEP]']
[ 450/2000] tot_loss=1.746 (perp=7.167, rec=0.100, cos=0.212), tot_loss_proj:1.924 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented oriented [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.730 (perp=7.167, rec=0.083, cos=0.213), tot_loss_proj:1.926 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented oriented [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.722 (perp=7.167, rec=0.075, cos=0.213), tot_loss_proj:1.934 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented oriented [SEP]']
[ 600/2000] tot_loss=1.720 (perp=7.167, rec=0.073, cos=0.213), tot_loss_proj:1.924 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented oriented [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.724 (perp=7.167, rec=0.076, cos=0.215), tot_loss_proj:1.929 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented oriented [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.721 (perp=7.167, rec=0.074, cos=0.213), tot_loss_proj:1.923 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented oriented [SEP]']
[ 750/2000] tot_loss=1.719 (perp=7.167, rec=0.071, cos=0.214), tot_loss_proj:1.935 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented oriented [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.732 (perp=7.167, rec=0.085, cos=0.214), tot_loss_proj:1.889 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented oriented [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.956 (perp=8.362, rec=0.069, cos=0.215), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] how ridiculous and money - oriented [SEP]']
[ 900/2000] tot_loss=1.970 (perp=8.362, rec=0.081, cos=0.217), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] how ridiculous and money - oriented [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.661 (perp=6.870, rec=0.073, cos=0.214), tot_loss_proj:1.887 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.664 (perp=6.870, rec=0.076, cos=0.214), tot_loss_proj:1.880 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.664 (perp=6.870, rec=0.076, cos=0.214), tot_loss_proj:1.881 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.659 (perp=6.870, rec=0.072, cos=0.214), tot_loss_proj:1.879 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.652 (perp=6.870, rec=0.064, cos=0.214), tot_loss_proj:1.876 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.659 (perp=6.870, rec=0.071, cos=0.214), tot_loss_proj:1.884 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.656 (perp=6.870, rec=0.068, cos=0.214), tot_loss_proj:1.885 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.665 (perp=6.870, rec=0.077, cos=0.214), tot_loss_proj:1.882 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.659 (perp=6.870, rec=0.071, cos=0.214), tot_loss_proj:1.876 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.645 (perp=6.870, rec=0.057, cos=0.214), tot_loss_proj:1.881 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.647 (perp=6.870, rec=0.059, cos=0.214), tot_loss_proj:1.887 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.647 (perp=6.870, rec=0.059, cos=0.214), tot_loss_proj:1.877 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.659 (perp=6.870, rec=0.072, cos=0.213), tot_loss_proj:1.890 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.655 (perp=6.870, rec=0.068, cos=0.214), tot_loss_proj:1.884 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.657 (perp=6.870, rec=0.069, cos=0.214), tot_loss_proj:1.886 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.648 (perp=6.870, rec=0.060, cos=0.214), tot_loss_proj:1.885 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.661 (perp=6.870, rec=0.073, cos=0.214), tot_loss_proj:1.884 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.651 (perp=6.870, rec=0.063, cos=0.214), tot_loss_proj:1.884 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.653 (perp=6.870, rec=0.066, cos=0.214), tot_loss_proj:1.878 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.650 (perp=6.870, rec=0.063, cos=0.214), tot_loss_proj:1.885 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.648 (perp=6.870, rec=0.060, cos=0.214), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.655 (perp=6.870, rec=0.067, cos=0.214), tot_loss_proj:1.879 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.811 | p: 89.048 | r: 90.649
rouge2     | fm: 55.868 | p: 55.533 | r: 56.289
rougeL     | fm: 78.990 | p: 78.419 | r: 79.733
rougeLsum  | fm: 78.995 | p: 78.387 | r: 79.762
r1fm+r2fm = 145.679

input #90 time: 0:08:44 | total time: 13:09:09


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.902809712029442
highest_index [0]
highest [0.902809712029442]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.7928217649459839 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.7506926655769348 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.729214608669281 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.6907054781913757 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.6876363158226013 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.6771154403686523 for ['[CLS] neal african milne architecture joint rolls conductline [SEP]']
[Init] best rec loss: 0.6764562726020813 for ['[CLS] contractor containermers una oathburgh fingermaid [SEP]']
[Init] best rec loss: 0.6648113131523132 for ['[CLS] reminder addict anyway oneislausicidelishhered [SEP]']
[Init] best perm rec loss: 0.6606593132019043 for ['[CLS] one addict remindericide anywayheredislauslish [SEP]']
[Init] best perm rec loss: 0.6577042937278748 for ['[CLS]lishhered addict one anywayislaus remindericide [SEP]']
[Init] best perm rec loss: 0.656005322933197 for ['[CLS]icide reminderhered oneislauslish addict anyway [SEP]']
[Init] best perm rec loss: 0.6550427675247192 for ['[CLS] oneicide addict anywayislauslish reminderhered [SEP]']
[Init] best perm rec loss: 0.6530268788337708 for ['[CLS] oneicide addict anywayheredlishislaus reminder [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.082 (perp=13.118, rec=0.284, cos=0.174), tot_loss_proj:3.562 [t=0.22s]
prediction: ['[CLS] loco ridiculous ridiculous but apex,m more [SEP]']
[ 100/2000] tot_loss=2.629 (perp=11.385, rec=0.175, cos=0.178), tot_loss_proj:3.155 [t=0.22s]
prediction: ['[CLS] loco loco ridiculous no mu,m more [SEP]']
[ 150/2000] tot_loss=2.531 (perp=11.136, rec=0.129, cos=0.175), tot_loss_proj:3.062 [t=0.22s]
prediction: ['[CLS] loco loco ridiculous no mu,y more [SEP]']
[ 200/2000] tot_loss=2.536 (perp=11.290, rec=0.097, cos=0.181), tot_loss_proj:3.094 [t=0.22s]
prediction: ['[CLS] loco loco ridiculous no mu buty more [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.121 (perp=9.150, rec=0.104, cos=0.187), tot_loss_proj:2.546 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[ 300/2000] tot_loss=2.098 (perp=9.150, rec=0.087, cos=0.180), tot_loss_proj:2.549 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.086 (perp=9.150, rec=0.075, cos=0.182), tot_loss_proj:2.549 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.095 (perp=9.150, rec=0.081, cos=0.184), tot_loss_proj:2.556 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[ 450/2000] tot_loss=2.085 (perp=9.150, rec=0.072, cos=0.182), tot_loss_proj:2.554 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.080 (perp=9.150, rec=0.069, cos=0.181), tot_loss_proj:2.555 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.091 (perp=9.150, rec=0.077, cos=0.183), tot_loss_proj:2.562 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[ 600/2000] tot_loss=2.089 (perp=9.150, rec=0.079, cos=0.180), tot_loss_proj:2.551 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.082 (perp=9.150, rec=0.069, cos=0.183), tot_loss_proj:2.557 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.094 (perp=9.150, rec=0.081, cos=0.183), tot_loss_proj:2.558 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[ 750/2000] tot_loss=2.075 (perp=9.150, rec=0.065, cos=0.180), tot_loss_proj:2.551 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.087 (perp=9.150, rec=0.078, cos=0.179), tot_loss_proj:2.550 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.071 (perp=9.150, rec=0.059, cos=0.182), tot_loss_proj:2.558 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[ 900/2000] tot_loss=2.087 (perp=9.150, rec=0.072, cos=0.185), tot_loss_proj:2.559 [t=0.22s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.053 (perp=9.010, rec=0.070, cos=0.181), tot_loss_proj:2.455 [t=0.22s]
prediction: ['[CLS] but loco, ridiculous no muy more [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.862 (perp=8.105, rec=0.061, cos=0.180), tot_loss_proj:2.268 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, no muy more [SEP]']
[1050/2000] tot_loss=1.873 (perp=8.105, rec=0.070, cos=0.182), tot_loss_proj:2.271 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, no muy more [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.801 (perp=7.756, rec=0.067, cos=0.183), tot_loss_proj:2.254 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.797 (perp=7.756, rec=0.065, cos=0.180), tot_loss_proj:2.256 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
[1200/2000] tot_loss=1.799 (perp=7.756, rec=0.063, cos=0.185), tot_loss_proj:2.257 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.798 (perp=7.756, rec=0.063, cos=0.184), tot_loss_proj:2.259 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.801 (perp=7.756, rec=0.068, cos=0.182), tot_loss_proj:2.254 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
[1350/2000] tot_loss=1.804 (perp=7.756, rec=0.069, cos=0.184), tot_loss_proj:2.256 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.803 (perp=7.756, rec=0.069, cos=0.183), tot_loss_proj:2.259 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.808 (perp=7.756, rec=0.073, cos=0.184), tot_loss_proj:2.255 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
[1500/2000] tot_loss=1.796 (perp=7.756, rec=0.063, cos=0.182), tot_loss_proj:2.258 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.804 (perp=7.756, rec=0.069, cos=0.183), tot_loss_proj:2.256 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.803 (perp=7.756, rec=0.068, cos=0.184), tot_loss_proj:2.252 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
[1650/2000] tot_loss=1.795 (perp=7.756, rec=0.060, cos=0.184), tot_loss_proj:2.256 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.804 (perp=7.756, rec=0.070, cos=0.183), tot_loss_proj:2.253 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.795 (perp=7.756, rec=0.061, cos=0.183), tot_loss_proj:2.263 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
[1800/2000] tot_loss=1.797 (perp=7.756, rec=0.062, cos=0.183), tot_loss_proj:2.256 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.795 (perp=7.756, rec=0.060, cos=0.183), tot_loss_proj:2.255 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.801 (perp=7.756, rec=0.067, cos=0.183), tot_loss_proj:2.260 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
[1950/2000] tot_loss=1.805 (perp=7.756, rec=0.070, cos=0.184), tot_loss_proj:2.253 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.803 (perp=7.756, rec=0.067, cos=0.184), tot_loss_proj:2.264 [t=0.22s]
prediction: ['[CLS] but loco ridiculous, muy no more [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] but loco ridiculous, muy no more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 114.286

[Aggregate metrics]:
rouge1     | fm: 89.799 | p: 89.152 | r: 90.693
rouge2     | fm: 55.737 | p: 55.378 | r: 56.160
rougeL     | fm: 78.806 | p: 78.230 | r: 79.584
rougeLsum  | fm: 78.735 | p: 78.087 | r: 79.504
r1fm+r2fm = 145.535

input #91 time: 0:08:40 | total time: 13:17:50


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.8518181018116445
highest_index [0]
highest [0.8518181018116445]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8237641453742981 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8180005550384521 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.7756751179695129 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.7673689723014832 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7322672605514526 for ['[CLS] tank lonely [SEP]']
[Init] best rec loss: 0.6992630362510681 for ['[CLS] paths locked [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.050 (perp=7.646, rec=0.248, cos=0.273), tot_loss_proj:1.867 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 100/2000] tot_loss=1.898 (perp=7.646, rec=0.104, cos=0.264), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.878 (perp=7.646, rec=0.083, cos=0.266), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.867 (perp=7.646, rec=0.065, cos=0.273), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.872 (perp=7.646, rec=0.066, cos=0.277), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.860 (perp=7.646, rec=0.059, cos=0.271), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.863 (perp=7.646, rec=0.063, cos=0.271), tot_loss_proj:1.873 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.866 (perp=7.646, rec=0.066, cos=0.271), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.864 (perp=7.646, rec=0.064, cos=0.271), tot_loss_proj:1.863 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.868 (perp=7.646, rec=0.067, cos=0.272), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.867 (perp=7.646, rec=0.063, cos=0.275), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.876 (perp=7.646, rec=0.070, cos=0.276), tot_loss_proj:1.867 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.871 (perp=7.646, rec=0.065, cos=0.277), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.872 (perp=7.646, rec=0.071, cos=0.272), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.866 (perp=7.646, rec=0.064, cos=0.272), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.867 (perp=7.646, rec=0.065, cos=0.273), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.872 (perp=7.646, rec=0.070, cos=0.273), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.859 (perp=7.646, rec=0.056, cos=0.274), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.862 (perp=7.646, rec=0.062, cos=0.271), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.874 (perp=7.646, rec=0.072, cos=0.273), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.867 (perp=7.646, rec=0.064, cos=0.273), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.869 (perp=7.646, rec=0.066, cos=0.274), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.868 (perp=7.646, rec=0.064, cos=0.275), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.865 (perp=7.646, rec=0.062, cos=0.273), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.870 (perp=7.646, rec=0.068, cos=0.272), tot_loss_proj:1.870 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.862 (perp=7.646, rec=0.060, cos=0.273), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.878 (perp=7.646, rec=0.076, cos=0.273), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.855 (perp=7.646, rec=0.052, cos=0.273), tot_loss_proj:1.857 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.864 (perp=7.646, rec=0.062, cos=0.272), tot_loss_proj:1.866 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.856 (perp=7.646, rec=0.053, cos=0.274), tot_loss_proj:1.878 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.853 (perp=7.646, rec=0.051, cos=0.272), tot_loss_proj:1.873 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.874 (perp=7.646, rec=0.072, cos=0.273), tot_loss_proj:1.874 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.863 (perp=7.646, rec=0.061, cos=0.273), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.852 (perp=7.646, rec=0.049, cos=0.274), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.864 (perp=7.646, rec=0.061, cos=0.274), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.862 (perp=7.646, rec=0.059, cos=0.274), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.874 (perp=7.646, rec=0.071, cos=0.274), tot_loss_proj:1.874 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.859 (perp=7.646, rec=0.056, cos=0.274), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.866 (perp=7.646, rec=0.063, cos=0.273), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.863 (perp=7.646, rec=0.060, cos=0.274), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.941 | p: 89.232 | r: 90.834
rouge2     | fm: 56.033 | p: 55.755 | r: 56.404
rougeL     | fm: 78.949 | p: 78.372 | r: 79.702
rougeLsum  | fm: 78.883 | p: 78.288 | r: 79.628
r1fm+r2fm = 145.974

input #92 time: 0:08:36 | total time: 13:26:26


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.8173156634212522
highest_index [0]
highest [0.8173156634212522]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 0.9382556080818176 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.88311368227005 for ['[CLS] taxi kang lookiled what mostchrome [SEP]']
[Init] best rec loss: 0.8679938316345215 for ['[CLS] scene attack humming working municipal attendant [MASK] [SEP]']
[Init] best rec loss: 0.8620597720146179 for ['[CLS] thousands fuel conditional scales progressed empowered mar [SEP]']
[Init] best rec loss: 0.847496747970581 for ['[CLS] [CLS]rac madonna premiership further jeremy colby [SEP]']
[Init] best perm rec loss: 0.8429763317108154 for ['[CLS] madonna furtherrac premiership colby jeremy [CLS] [SEP]']
[Init] best perm rec loss: 0.8417696952819824 for ['[CLS] furtherrac premiership madonna colby jeremy [CLS] [SEP]']
[Init] best perm rec loss: 0.8414486646652222 for ['[CLS] madonna further premiership jeremyrac colby [CLS] [SEP]']
[Init] best perm rec loss: 0.8383046388626099 for ['[CLS] jeremyrac colby further madonna premiership [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.899 (perp=11.534, rec=0.258, cos=0.334), tot_loss_proj:3.603 [t=0.22s]
prediction: ['[CLS] content oftenity funny says comedy way [SEP]']
[ 100/2000] tot_loss=2.632 (perp=10.603, rec=0.186, cos=0.325), tot_loss_proj:2.831 [t=0.22s]
prediction: ['[CLS] in understandingity funny says funny way [SEP]']
[ 150/2000] tot_loss=2.259 (perp=8.991, rec=0.135, cos=0.325), tot_loss_proj:2.372 [t=0.22s]
prediction: ['[CLS] in understanding often often and funny way [SEP]']
[ 200/2000] tot_loss=2.349 (perp=9.531, rec=0.115, cos=0.328), tot_loss_proj:2.649 [t=0.22s]
prediction: ['[CLS] in understanding often often its funny way [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.117 (perp=8.396, rec=0.110, cos=0.327), tot_loss_proj:2.266 [t=0.22s]
prediction: ['[CLS] in understanding its often, funny way [SEP]']
[ 300/2000] tot_loss=2.084 (perp=8.396, rec=0.074, cos=0.331), tot_loss_proj:2.265 [t=0.22s]
prediction: ['[CLS] in understanding its often, funny way [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.786 (perp=6.927, rec=0.071, cos=0.331), tot_loss_proj:1.985 [t=0.22s]
prediction: ['[CLS] in understanding its often funny way, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.791 (perp=6.927, rec=0.075, cos=0.331), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] in understanding its often funny way, [SEP]']
[ 450/2000] tot_loss=1.789 (perp=6.927, rec=0.074, cos=0.330), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] in understanding its often funny way, [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.735 (perp=6.705, rec=0.063, cos=0.331), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.746 (perp=6.705, rec=0.075, cos=0.331), tot_loss_proj:1.979 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 600/2000] tot_loss=1.743 (perp=6.705, rec=0.071, cos=0.330), tot_loss_proj:1.989 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.745 (perp=6.705, rec=0.074, cos=0.330), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.742 (perp=6.705, rec=0.070, cos=0.331), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 750/2000] tot_loss=1.747 (perp=6.705, rec=0.076, cos=0.331), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.737 (perp=6.705, rec=0.065, cos=0.331), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.739 (perp=6.705, rec=0.067, cos=0.331), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 900/2000] tot_loss=1.744 (perp=6.705, rec=0.072, cos=0.331), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.743 (perp=6.705, rec=0.071, cos=0.331), tot_loss_proj:1.984 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.739 (perp=6.705, rec=0.068, cos=0.330), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1050/2000] tot_loss=1.730 (perp=6.705, rec=0.058, cos=0.331), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.735 (perp=6.705, rec=0.062, cos=0.332), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.730 (perp=6.705, rec=0.057, cos=0.332), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1200/2000] tot_loss=1.733 (perp=6.705, rec=0.061, cos=0.331), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.733 (perp=6.705, rec=0.060, cos=0.332), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.736 (perp=6.705, rec=0.063, cos=0.332), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1350/2000] tot_loss=1.735 (perp=6.705, rec=0.062, cos=0.331), tot_loss_proj:1.982 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.742 (perp=6.705, rec=0.069, cos=0.332), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.738 (perp=6.705, rec=0.065, cos=0.331), tot_loss_proj:1.970 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1500/2000] tot_loss=1.731 (perp=6.705, rec=0.058, cos=0.332), tot_loss_proj:1.983 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.734 (perp=6.705, rec=0.061, cos=0.332), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.731 (perp=6.705, rec=0.059, cos=0.332), tot_loss_proj:1.984 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1650/2000] tot_loss=1.736 (perp=6.705, rec=0.063, cos=0.332), tot_loss_proj:1.979 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.739 (perp=6.705, rec=0.066, cos=0.332), tot_loss_proj:1.980 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.736 (perp=6.705, rec=0.063, cos=0.332), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1800/2000] tot_loss=1.744 (perp=6.705, rec=0.071, cos=0.332), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.732 (perp=6.705, rec=0.060, cos=0.332), tot_loss_proj:1.968 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.735 (perp=6.705, rec=0.062, cos=0.332), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1950/2000] tot_loss=1.738 (perp=6.705, rec=0.065, cos=0.332), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.731 (perp=6.705, rec=0.058, cos=0.332), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding in its often funny way, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 90.056 | p: 89.303 | r: 90.939
rouge2     | fm: 56.021 | p: 55.735 | r: 56.456
rougeL     | fm: 79.132 | p: 78.523 | r: 79.875
rougeLsum  | fm: 79.071 | p: 78.516 | r: 79.845
r1fm+r2fm = 146.077

input #93 time: 0:08:39 | total time: 13:35:06


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.8575344879997484
highest_index [0]
highest [0.8575344879997484]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9576636552810669 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9537549614906311 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.952724814414978 for ['[CLS] past vices siblings theatrical view slate will shelter ancient border [SEP]']
[Init] best rec loss: 0.9265764951705933 for ['[CLS] milling library casual constructed board equationphs similaron cookies intended [SEP]']
[Init] best rec loss: 0.9257921576499939 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9248824715614319 for ['[CLS] stuffing play sounds speaker horizons likesballquitable mirza zodiac understanding [SEP]']
[Init] best rec loss: 0.9193018674850464 for ['[CLS] convicted hunter entire fan wine9 league threat privatek rough [SEP]']
[Init] best rec loss: 0.9078103303909302 for ['[CLS] enough usingac sur mile ready down maymise majesty assumption [SEP]']
[Init] best rec loss: 0.900276243686676 for ['[CLS] barber eithertype roador motivefirm trusted ednaack wanted [SEP]']
[Init] best perm rec loss: 0.8987451195716858 for ['[CLS]firm edna eithertypeack barber road wanted trusted motiveor [SEP]']
[Init] best perm rec loss: 0.8968249559402466 for ['[CLS]type road wanted barber motive trustedackfirm edna eitheror [SEP]']
[Init] best perm rec loss: 0.8965077996253967 for ['[CLS] edna trustedtype barberack wantedor road either motivefirm [SEP]']
[Init] best perm rec loss: 0.8963620066642761 for ['[CLS] motivetypeack trusted either wanted roadorfirm edna barber [SEP]']
[Init] best perm rec loss: 0.8962510228157043 for ['[CLS] road wanted trusted ednaack either motivefirm barbertypeor [SEP]']
[Init] best perm rec loss: 0.8958001732826233 for ['[CLS] barber edna trustedorfirmack motive roadtype either wanted [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.426 (perp=12.669, rec=0.566, cos=0.326), tot_loss_proj:4.511 [t=0.22s]
prediction: ['[CLS] tellsoir barryᴵ original features comic causing nor twice nowhere [SEP]']
[ 100/2000] tot_loss=3.386 (perp=12.636, rec=0.564, cos=0.295), tot_loss_proj:4.271 [t=0.22s]
prediction: ['[CLS] wroteroller jeans cu courthouse is original seal nor millionsly [SEP]']
[ 150/2000] tot_loss=3.754 (perp=14.388, rec=0.581, cos=0.296), tot_loss_proj:4.662 [t=0.22s]
prediction: ['[CLS] wrote cannot jeans [SEP] obscure no originally dalai neitheribly neither [SEP]']
[ 200/2000] tot_loss=3.370 (perp=13.090, rec=0.495, cos=0.257), tot_loss_proj:4.482 [t=0.22s]
prediction: ['[CLS] became point » [SEP] whose no originally fascinating neitherience neither [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.370 (perp=12.933, rec=0.507, cos=0.276), tot_loss_proj:4.460 [t=0.22s]
prediction: ['[CLS] anyway cape original [SEP] whose funny originally blushing original easy no [SEP]']
[ 300/2000] tot_loss=3.253 (perp=12.319, rec=0.496, cos=0.293), tot_loss_proj:3.879 [t=0.22s]
prediction: ['[CLS] anyway cannot original [SEP] whose terribly [SEP] neither original « neither [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.621 (perp=14.451, rec=0.460, cos=0.271), tot_loss_proj:4.403 [t=0.22s]
prediction: ['[CLS] anyway cape original [SEP] uh neither [SEP] neither original « neither [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.213 (perp=12.165, rec=0.487, cos=0.293), tot_loss_proj:3.942 [t=0.23s]
prediction: ['[CLS] original cape nope [SEP] ashamed neither [SEP] terribly original ‿ neither [SEP]']
[ 450/2000] tot_loss=3.460 (perp=13.588, rec=0.439, cos=0.304), tot_loss_proj:4.235 [t=0.22s]
prediction: ['[CLS] original cape nope [SEP] uh neither [SEP] terribly originalmark neither [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.177 (perp=12.539, rec=0.449, cos=0.220), tot_loss_proj:4.053 [t=0.22s]
prediction: ['[CLS] original cape nope [SEP] uh coco neither [SEP] terribly original nor [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=3.095 (perp=11.671, rec=0.415, cos=0.345), tot_loss_proj:3.808 [t=0.22s]
prediction: ['[CLS] cape nope [SEP] prevented coco neither [SEP] terribly original nor original [SEP]']
[ 600/2000] tot_loss=2.628 (perp=10.317, rec=0.395, cos=0.169), tot_loss_proj:3.307 [t=0.22s]
prediction: ['[CLS] cape nope [SEP] neither pictures neither [SEP] terribly original nor original [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.568 (perp=10.079, rec=0.374, cos=0.179), tot_loss_proj:3.299 [t=0.22s]
prediction: ['[CLS] cape nope [SEP] neither pictures terribly [SEP] neither original nor original [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.930 (perp=11.295, rec=0.377, cos=0.295), tot_loss_proj:3.627 [t=0.22s]
prediction: ['[CLS] nope [SEP] neithertangle cape terribly [SEP] neither original nor original [SEP]']
[ 750/2000] tot_loss=2.914 (perp=11.445, rec=0.359, cos=0.266), tot_loss_proj:3.601 [t=0.22s]
prediction: ['[CLS] nope [SEP] neithertangle cape terribly cape neither original nor original [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.952 (perp=10.835, rec=0.340, cos=0.445), tot_loss_proj:3.421 [t=0.22s]
prediction: ['[CLS] [SEP] nope neithertangle cape terribly cape neither original nor original [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.564 (perp=10.301, rec=0.351, cos=0.153), tot_loss_proj:3.408 [t=0.22s]
prediction: ['[CLS] [SEP] nope neithertangle cape terribly nor neither original cape original [SEP]']
[ 900/2000] tot_loss=2.692 (perp=10.301, rec=0.334, cos=0.298), tot_loss_proj:3.410 [t=0.22s]
prediction: ['[CLS] [SEP] nope neithertangle cape terribly nor neither original cape original [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.598 (perp=9.758, rec=0.326, cos=0.321), tot_loss_proj:3.463 [t=0.22s]
prediction: ['[CLS] [SEP] nope neither original cape terribly nor neither original capetangle [SEP]']
Attempt swap
[1000/2000] tot_loss=2.543 (perp=9.758, rec=0.344, cos=0.248), tot_loss_proj:3.460 [t=0.23s]
prediction: ['[CLS] [SEP] nope neither original cape terribly nor neither original capetangle [SEP]']
[1050/2000] tot_loss=2.410 (perp=9.758, rec=0.324, cos=0.134), tot_loss_proj:3.456 [t=0.22s]
prediction: ['[CLS] [SEP] nope neither original cape terribly nor neither original capetangle [SEP]']
Attempt swap
[1100/2000] tot_loss=2.387 (perp=9.758, rec=0.318, cos=0.117), tot_loss_proj:3.465 [t=0.22s]
prediction: ['[CLS] [SEP] nope neither original cape terribly nor neither original capetangle [SEP]']
Attempt swap
[1150/2000] tot_loss=2.504 (perp=9.758, rec=0.307, cos=0.245), tot_loss_proj:3.461 [t=0.22s]
prediction: ['[CLS] [SEP] nope neither original cape terribly nor neither original capetangle [SEP]']
[1200/2000] tot_loss=2.382 (perp=9.327, rec=0.306, cos=0.211), tot_loss_proj:3.242 [t=0.22s]
prediction: ['[CLS] a nope neither original cape terribly nor neither original capetangle [SEP]']
Attempt swap
[1250/2000] tot_loss=2.316 (perp=9.327, rec=0.310, cos=0.140), tot_loss_proj:3.241 [t=0.23s]
prediction: ['[CLS] a nope neither original cape terribly nor neither original capetangle [SEP]']
Attempt swap
[1300/2000] tot_loss=2.424 (perp=9.327, rec=0.303, cos=0.256), tot_loss_proj:3.243 [t=0.22s]
prediction: ['[CLS] a nope neither original cape terribly nor neither original capetangle [SEP]']
[1350/2000] tot_loss=2.406 (perp=9.327, rec=0.308, cos=0.232), tot_loss_proj:3.241 [t=0.22s]
prediction: ['[CLS] a nope neither original cape terribly nor neither original capetangle [SEP]']
Attempt swap
[1400/2000] tot_loss=2.307 (perp=9.327, rec=0.298, cos=0.144), tot_loss_proj:3.241 [t=0.22s]
prediction: ['[CLS] a nope neither original cape terribly nor neither original capetangle [SEP]']
Attempt swap
[1450/2000] tot_loss=2.458 (perp=9.322, rec=0.303, cos=0.291), tot_loss_proj:3.208 [t=0.22s]
prediction: ['[CLS] a nope neither original cape terribly nor neither original cape dickens [SEP]']
[1500/2000] tot_loss=2.378 (perp=9.322, rec=0.300, cos=0.214), tot_loss_proj:3.206 [t=0.22s]
prediction: ['[CLS] a nope neither original cape terribly nor neither original cape dickens [SEP]']
Attempt swap
[1550/2000] tot_loss=2.396 (perp=9.322, rec=0.297, cos=0.234), tot_loss_proj:3.215 [t=0.22s]
prediction: ['[CLS] a nope neither original cape terribly nor neither original cape dickens [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.603 (perp=10.195, rec=0.301, cos=0.263), tot_loss_proj:3.505 [t=0.22s]
prediction: ['[CLS] a ᵃ neither original cape terribly dickens nor neither original cape [SEP]']
[1650/2000] tot_loss=2.589 (perp=10.195, rec=0.284, cos=0.266), tot_loss_proj:3.501 [t=0.22s]
prediction: ['[CLS] a ᵃ neither original cape terribly dickens nor neither original cape [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.440 (perp=9.553, rec=0.267, cos=0.262), tot_loss_proj:3.268 [t=0.22s]
prediction: ['[CLS] ᵃ a neither original cape terribly dickens nor neither original cape [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=2.480 (perp=9.778, rec=0.269, cos=0.255), tot_loss_proj:3.332 [t=0.22s]
prediction: ['[CLS] ᵃ neither original a cape terribly dickens nor neither original terribly [SEP]']
[1800/2000] tot_loss=2.378 (perp=9.271, rec=0.266, cos=0.258), tot_loss_proj:3.219 [t=0.22s]
prediction: ['[CLS] ᵃ neither original a cape terribly dickens nor neither original cape [SEP]']
Attempt swap
[1850/2000] tot_loss=2.377 (perp=9.271, rec=0.260, cos=0.263), tot_loss_proj:3.218 [t=0.22s]
prediction: ['[CLS] ᵃ neither original a cape terribly dickens nor neither original cape [SEP]']
Attempt swap
[1900/2000] tot_loss=2.374 (perp=9.271, rec=0.256, cos=0.264), tot_loss_proj:3.223 [t=0.22s]
prediction: ['[CLS] ᵃ neither original a cape terribly dickens nor neither original cape [SEP]']
[1950/2000] tot_loss=2.375 (perp=9.271, rec=0.256, cos=0.264), tot_loss_proj:3.223 [t=0.22s]
prediction: ['[CLS] ᵃ neither original a cape terribly dickens nor neither original cape [SEP]']
Attempt swap
[2000/2000] tot_loss=2.545 (perp=10.150, rec=0.251, cos=0.264), tot_loss_proj:3.378 [t=0.22s]
prediction: ['[CLS] ᵃ neither original a cape terribly dickens nor neither original [SEP] [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] ᵃ neither original a cape terribly dickens nor neither original [SEP] [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.870 | p: 58.333 | r: 63.636
rouge2     | fm: 9.524 | p: 9.091 | r: 10.000
rougeL     | fm: 43.478 | p: 41.667 | r: 45.455
rougeLsum  | fm: 43.478 | p: 41.667 | r: 45.455
r1fm+r2fm = 70.393

[Aggregate metrics]:
rouge1     | fm: 89.808 | p: 89.116 | r: 90.706
rouge2     | fm: 55.584 | p: 55.217 | r: 55.990
rougeL     | fm: 78.765 | p: 78.199 | r: 79.550
rougeLsum  | fm: 78.813 | p: 78.188 | r: 79.579
r1fm+r2fm = 145.391

input #94 time: 0:08:49 | total time: 13:43:55


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.8437095056983506
highest_index [0]
highest [0.8437095056983506]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 1.0291486978530884 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 1.0197856426239014 for ['[CLS] reprinted geographic fairchild clary remains hitler tristanved thumb big hot dates muscle commander funding [SEP]']
[Init] best rec loss: 1.0188355445861816 for ['[CLS] cousinnished corners shamable aided deed grinned control actual pole masks making fifa bridge [SEP]']
[Init] best rec loss: 1.0185704231262207 for ['[CLS] set mediterranean seem duncan independence secular present surroundings lakes tongboat kei routledge mail majority [SEP]']
[Init] best rec loss: 0.9956211447715759 for ['[CLS]nahley hair see nedra logan offices fourth sethgical recommended side laughdran auxiliary [SEP]']
[Init] best rec loss: 0.9904508590698242 for ['[CLS] head felt infrastructure frequencyori 2018 news window saint kw ministry tragic hour electric grant [SEP]']
[Init] best rec loss: 0.9823128581047058 for ['[CLS] sooner rue " pace leagues della smell sul epithet greenon power local concacaf relay [SEP]']
[Init] best rec loss: 0.9812870621681213 for ['[CLS] lam born contracted surface francaise infantry states laboratory based riff sands pick nouli decided [SEP]']
[Init] best rec loss: 0.9772871732711792 for ['[CLS] footprint brain arrival rec [MASK] 45 reverse if pal struggled spanning caleb born day classic [SEP]']
[Init] best rec loss: 0.976073682308197 for ['[CLS] elephant insuranceheater you session naturehoot eye attic stake bus cheating about injection temple [SEP]']
[Init] best rec loss: 0.9681981205940247 for ['[CLS] gas somewhereator bulk aka unlessssee actual como deliver? jockuble occasion [SEP]']
[Init] best perm rec loss: 0.9659566879272461 for ['[CLS] deliver unlessssee actual aka como occasion jocku somewhereble gas bulk?ator [SEP]']
[Init] best perm rec loss: 0.9658432602882385 for ['[CLS]ator bulk jock actual deliverssee unlessble aka somewhere gas occasion como?u [SEP]']
[Init] best perm rec loss: 0.9652851819992065 for ['[CLS] bulk comou aka jock unless deliver somewhere? occasionssee actualatorble gas [SEP]']
[Init] best perm rec loss: 0.9651898741722107 for ['[CLS]ble unless bulk? deliveratorssee akau como jock gas actual somewhere occasion [SEP]']
[Init] best perm rec loss: 0.9647634029388428 for ['[CLS]ator deliver unless jock? comoble bulk occasion akassee actual somewhereu gas [SEP]']
[Init] best perm rec loss: 0.9643726944923401 for ['[CLS]uatorssee gas unlessble deliver aka actual somewhere occasion como bulk? jock [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.583 (perp=12.862, rec=0.593, cos=0.417), tot_loss_proj:4.565 [t=0.22s]
prediction: ['[CLS] mattress avery often unique became loses adant chapters wise merit presented folder as medium [SEP]']
[ 100/2000] tot_loss=3.538 (perp=13.224, rec=0.555, cos=0.338), tot_loss_proj:4.393 [t=0.22s]
prediction: ['[CLS]creen avery guerrilla social became semantic a skins book wise geoff logo administered highness greatly [SEP]']
[ 150/2000] tot_loss=3.657 (perp=14.149, rec=0.528, cos=0.300), tot_loss_proj:4.289 [t=0.22s]
prediction: ['[CLS]than jennifer hopeless becomes became becomes becomes mud ᵘ ep hopeless miniseries buddhist became challenge [SEP]']
[ 200/2000] tot_loss=3.343 (perp=12.191, rec=0.571, cos=0.334), tot_loss_proj:4.235 [t=0.22s]
prediction: ['[CLS] virtually, hopeless " finestts becomes hopeless ᵘ unanimous tournament scripture noble became significantly [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.025 (perp=11.064, rec=0.518, cos=0.294), tot_loss_proj:3.631 [t=0.22s]
prediction: ['[CLS] salary,verance building becomes an a hopeless screenplay seth tournament wes subset became - [SEP]']
[ 300/2000] tot_loss=3.264 (perp=12.336, rec=0.517, cos=0.280), tot_loss_proj:4.033 [t=0.22s]
prediction: ['[CLS] slot, mud becoming become becomes ( hopeless novel curious struggled ) rural orbit pulitzer [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.759 (perp=13.713, rec=0.605, cos=0.411), tot_loss_proj:4.560 [t=0.22s]
prediction: ['[CLS] prostitution unsuccessful actively becomes becomes became question hopeless lokiա struggled becomes became umm curious [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.322 (perp=12.586, rec=0.516, cos=0.288), tot_loss_proj:4.381 [t=0.22s]
prediction: ['[CLS] slavery, fully moments became flemish ( hopeless manuscript delilah struggled theological ள thatcher became [SEP]']
[ 450/2000] tot_loss=3.146 (perp=11.763, rec=0.502, cos=0.292), tot_loss_proj:3.830 [t=0.22s]
prediction: ['[CLS] slavery, fully becoming became flemish ( hopeless manuscript vertical mud became ள ` became [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.890 (perp=10.890, rec=0.455, cos=0.257), tot_loss_proj:4.179 [t=0.22s]
prediction: ['[CLS] slavery, joy becomes vertical rich ( hopeless manuscript became mud becomes ள becomes became [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.087 (perp=11.734, rec=0.442, cos=0.298), tot_loss_proj:4.073 [t=0.22s]
prediction: ['[CLS]polis joy becomes vertical, flemish ( hopelessdle became mud as ள becomes became [SEP]']
[ 600/2000] tot_loss=2.934 (perp=11.197, rec=0.424, cos=0.271), tot_loss_proj:3.894 [t=0.22s]
prediction: ['[CLS]polis joy becomes vertical, ottoman becomes hopelessdle became mud as ள becomes became [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.865 (perp=10.872, rec=0.425, cos=0.265), tot_loss_proj:3.516 [t=0.22s]
prediction: ['[CLS]polis fruit becomes vertical, ottoman becomes muddle became hopeless flat ள becomes became [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.911 (perp=10.759, rec=0.483, cos=0.276), tot_loss_proj:3.750 [t=0.22s]
prediction: ['[CLS] unreleased joy becomes ottoman, vertical becomes muddle became hopeless un ள became became [SEP]']
[ 750/2000] tot_loss=2.726 (perp=10.161, rec=0.422, cos=0.272), tot_loss_proj:3.372 [t=0.22s]
prediction: ['[CLS] unreleased fruit becomes ottoman, vertical becomes muddle became hopeless becoming ள became became [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.695 (perp=10.025, rec=0.407, cos=0.283), tot_loss_proj:3.591 [t=0.22s]
prediction: ['[CLS] unreleased fruit becomes curious, vertical becomes muddle became hopeless becoming ள becomes became [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.684 (perp=9.961, rec=0.400, cos=0.292), tot_loss_proj:3.748 [t=0.22s]
prediction: ['[CLS] unreleased ள becomes ethical, hopeless becomes muddle became hopeless becoming fruit becomes became [SEP]']
[ 900/2000] tot_loss=2.739 (perp=10.401, rec=0.407, cos=0.252), tot_loss_proj:3.815 [t=0.22s]
prediction: ['[CLS] ᶠ ள becomes curious, hopeless becomes muddle became hopeless becoming spirit became became [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.648 (perp=9.842, rec=0.402, cos=0.278), tot_loss_proj:3.601 [t=0.22s]
prediction: ['[CLS] spirit ள becomes ethical, hopeless becomes muddle became hopeless becoming became becomes became [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.691 (perp=10.080, rec=0.387, cos=0.287), tot_loss_proj:3.740 [t=0.22s]
prediction: ['[CLS] spirit ᶠ becomes ethical, hopeless becomes muddle became hopeless becoming ள becomes became [SEP]']
[1050/2000] tot_loss=2.695 (perp=10.228, rec=0.378, cos=0.271), tot_loss_proj:3.627 [t=0.22s]
prediction: ['[CLS] spirit stunts becomes ethical, hopeless becomes muddle became hopeless becoming ள becomes became [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.617 (perp=9.756, rec=0.375, cos=0.291), tot_loss_proj:3.220 [t=0.22s]
prediction: ['[CLS] spirit became becomes binary, ethical becomes muddle became hopeless becoming ள becomes became [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.522 (perp=9.492, rec=0.377, cos=0.247), tot_loss_proj:3.246 [t=0.22s]
prediction: ['[CLS] spirit became binary becomes, ethical becomes muddle became hopeless becoming ள becomes became [SEP]']
[1200/2000] tot_loss=2.545 (perp=9.378, rec=0.387, cos=0.283), tot_loss_proj:3.091 [t=0.22s]
prediction: ['[CLS] spirit became hopeless becomes, ethical becomes muddle became hopeless becoming^ becomes became [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.727 (perp=10.359, rec=0.383, cos=0.272), tot_loss_proj:4.041 [t=0.22s]
prediction: ['[CLS] spirit became becomes unique, ethical becomes muddle became hopeless un 語 becomes became [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.666 (perp=10.102, rec=0.378, cos=0.268), tot_loss_proj:3.958 [t=0.22s]
prediction: ['[CLS] became spirit becomes unique, ethical becomes muddle became hopeless un 語 becomes became [SEP]']
[1350/2000] tot_loss=2.685 (perp=10.102, rec=0.379, cos=0.286), tot_loss_proj:3.958 [t=0.22s]
prediction: ['[CLS] became spirit becomes unique, ethical becomes muddle became hopeless un 語 becomes became [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.590 (perp=9.720, rec=0.374, cos=0.272), tot_loss_proj:3.890 [t=0.22s]
prediction: ['[CLS] became spirit becomes unique, ethical muddle becomes became hopeless un 語 becomes became [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.547 (perp=9.522, rec=0.382, cos=0.261), tot_loss_proj:3.861 [t=0.22s]
prediction: ['[CLS] became spirit becomes unique, ethical muddle becomes became hopeless becomes becoming ள became [SEP]']
[1500/2000] tot_loss=2.552 (perp=9.421, rec=0.384, cos=0.283), tot_loss_proj:3.809 [t=0.22s]
prediction: ['[CLS] became spirit becomes unique, ethical muddle becomes became hopeless becomes un ள became [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.534 (perp=9.347, rec=0.383, cos=0.281), tot_loss_proj:3.760 [t=0.22s]
prediction: ['[CLS] became spirit becomes unique, ethical muddle becomes hopeless became becomes un─ became [SEP]']
Attempt swap
[1600/2000] tot_loss=2.528 (perp=9.347, rec=0.377, cos=0.282), tot_loss_proj:3.763 [t=0.22s]
prediction: ['[CLS] became spirit becomes unique, ethical muddle becomes hopeless became becomes un─ became [SEP]']
[1650/2000] tot_loss=2.923 (perp=11.284, rec=0.373, cos=0.293), tot_loss_proj:3.999 [t=0.22s]
prediction: ['[CLS] became spirit becomes uniquesat ethical muddle becomes hopeless became becomes un─ became [SEP]']
Attempt swap
[1700/2000] tot_loss=2.912 (perp=11.284, rec=0.372, cos=0.283), tot_loss_proj:4.000 [t=0.22s]
prediction: ['[CLS] became spirit becomes uniquesat ethical muddle becomes hopeless became becomes un─ became [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.890 (perp=11.289, rec=0.376, cos=0.257), tot_loss_proj:4.006 [t=0.22s]
prediction: ['[CLS] spirit became becomes uniquesat ethical muddle becomes hopeless became becomes un─ became [SEP]']
[1800/2000] tot_loss=2.919 (perp=11.289, rec=0.375, cos=0.286), tot_loss_proj:4.003 [t=0.22s]
prediction: ['[CLS] spirit became becomes uniquesat ethical muddle becomes hopeless became becomes un─ became [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.860 (perp=11.045, rec=0.373, cos=0.278), tot_loss_proj:3.796 [t=0.22s]
prediction: ['[CLS] spirit became uniquesat becomes ethical muddle becomes hopeless became becomes un─ became [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.811 (perp=10.714, rec=0.379, cos=0.289), tot_loss_proj:4.090 [t=0.22s]
prediction: ['[CLS] spirit became unsat becomes ethical muddle becomes hopeless became becomes unique─ became [SEP]']
[1950/2000] tot_loss=2.765 (perp=10.504, rec=0.372, cos=0.292), tot_loss_proj:4.052 [t=0.22s]
prediction: ['[CLS] spirit became,sat becomes ethical muddle becomes hopeless became becomes unique─ became [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.735 (perp=10.400, rec=0.363, cos=0.292), tot_loss_proj:4.015 [t=0.22s]
prediction: ['[CLS] spirit becamesat, becomes ethical muddle becomes hopeless became becomes unique─ became [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] spirit becamesat, becomes ethical muddle becomes hopeless became becomes unique─ became [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 45.455 | p: 38.462 | r: 55.556
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 36.364 | p: 30.769 | r: 44.444
rougeLsum  | fm: 36.364 | p: 30.769 | r: 44.444
r1fm+r2fm = 45.455

[Aggregate metrics]:
rouge1     | fm: 89.267 | p: 88.515 | r: 90.281
rouge2     | fm: 54.915 | p: 54.610 | r: 55.342
rougeL     | fm: 78.093 | p: 77.465 | r: 78.924
rougeLsum  | fm: 78.203 | p: 77.559 | r: 79.025
r1fm+r2fm = 144.182

input #95 time: 0:08:40 | total time: 13:52:35


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.864964847152753
highest_index [0]
highest [0.864964847152753]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.834039568901062 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8149455189704895 for ['[CLS] at townland panel subjects latter board vidhan tang general honor majestysse spared homes rider [SEP]']
[Init] best rec loss: 0.8032839894294739 for ['[CLS] robinson fits fr home professor shanghai virgin firing inside machlmancize arm decade [SEP]']
[Init] best rec loss: 0.7863775491714478 for ['[CLS] class error portoizedtler riverside 7nsis deedret via protection corporation whether selection [SEP]']
[Init] best rec loss: 0.775091290473938 for ['[CLS] interviews screwed podcast ？ 8 sunset effects era too oath sunk chief between capcom master [SEP]']
[Init] best rec loss: 0.7733850479125977 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best rec loss: 0.773041844367981 for ['[CLS]rg woken became jenny marx further league performance union holding winning instrumental re distance conscious [SEP]']
[Init] best rec loss: 0.7556256055831909 for ['[CLS] foreign x universalhausen ant southeast leave brands ascent perpendicular are article holding wrestling capability [SEP]']
[Init] best perm rec loss: 0.7553318738937378 for ['[CLS] ant universal foreign holding x ascent southeast are capability perpendicular wrestling article leave brandshausen [SEP]']
[Init] best perm rec loss: 0.7552555799484253 for ['[CLS] brands universal article ascent leave perpendicular ant southeast holding capability foreignhausen wrestling x are [SEP]']
[Init] best perm rec loss: 0.7545406222343445 for ['[CLS] foreign perpendicular article brands are leave holding ant xhausen wrestling southeast universal ascent capability [SEP]']
[Init] best perm rec loss: 0.7536582946777344 for ['[CLS] holding x southeasthausen wrestling leave brands universal article ant foreign ascent capability are perpendicular [SEP]']
[Init] best perm rec loss: 0.7532498240470886 for ['[CLS] wrestling ant x holding foreign ascent are brands perpendicular universal article leavehausen capability southeast [SEP]']
[Init] best perm rec loss: 0.7529878616333008 for ['[CLS] are leave x article ascent foreign southeast wrestling holding perpendicular universalhausen ant capability brands [SEP]']
[Init] best perm rec loss: 0.7528905868530273 for ['[CLS] ascenthausen foreign wrestling article southeast capability x universal brands perpendicular holding ant are leave [SEP]']
[Init] best perm rec loss: 0.7524057626724243 for ['[CLS] universal holding wrestling southeast ant ascenthausen capability x are perpendicular leave brands foreign article [SEP]']
[Init] best perm rec loss: 0.751973032951355 for ['[CLS] capability wrestling holding ant arehausen southeast article x universal foreign leave perpendicular brands ascent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.957 (perp=12.007, rec=0.313, cos=0.243), tot_loss_proj:3.988 [t=0.21s]
prediction: ['[CLS] realm force peopleeau often himself advantagelei situation main coverage rules into for men [SEP]']
[ 100/2000] tot_loss=2.465 (perp=9.773, rec=0.257, cos=0.254), tot_loss_proj:3.052 [t=0.21s]
prediction: ['[CLS] himself force people himself as himself into and situation lesser cover team into lesser men [SEP]']
[ 150/2000] tot_loss=2.490 (perp=10.313, rec=0.181, cos=0.247), tot_loss_proj:2.995 [t=0.21s]
prediction: ['[CLS] himself force people her and himself on and situationsiary cover situations make lesser men [SEP]']
[ 200/2000] tot_loss=2.485 (perp=10.471, rec=0.143, cos=0.248), tot_loss_proj:3.029 [t=0.21s]
prediction: ['[CLS] himself force people giving and himself on and situationsiary cover situations make lesser men [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.284 (perp=9.537, rec=0.130, cos=0.247), tot_loss_proj:3.027 [t=0.21s]
prediction: ['[CLS] people force himself for and himself on and situations run cover cover make lesser men [SEP]']
[ 300/2000] tot_loss=2.277 (perp=9.362, rec=0.153, cos=0.251), tot_loss_proj:2.802 [t=0.21s]
prediction: ['[CLS] people force himself living and himself on and situations for cover cover make lesser men [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.278 (perp=9.463, rec=0.133, cos=0.253), tot_loss_proj:3.104 [t=0.21s]
prediction: ['[CLS] people force himself living cover himself on and situations for run inside make lesser men [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.008 (perp=8.123, rec=0.134, cos=0.249), tot_loss_proj:2.806 [t=0.21s]
prediction: ['[CLS] people force himself living himself on cover and situations for run and make lesser men [SEP]']
[ 450/2000] tot_loss=1.989 (perp=8.123, rec=0.117, cos=0.247), tot_loss_proj:2.809 [t=0.21s]
prediction: ['[CLS] people force himself living himself on cover and situations for run and make lesser men [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.969 (perp=8.050, rec=0.106, cos=0.253), tot_loss_proj:2.766 [t=0.21s]
prediction: ['[CLS] people force himself would himself on cover and situations make run and for lesser men [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.909 (perp=7.773, rec=0.109, cos=0.245), tot_loss_proj:2.954 [t=0.21s]
prediction: ['[CLS] people force himself would himself on cover and situations make run for lesser men and [SEP]']
[ 600/2000] tot_loss=1.973 (perp=8.064, rec=0.107, cos=0.253), tot_loss_proj:2.954 [t=0.21s]
prediction: ['[CLS] people force himself would himself on cover and situations make run for lesser men into [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.890 (perp=7.706, rec=0.097, cos=0.252), tot_loss_proj:2.892 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover and situations make run for lesser men into [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.823 (perp=7.389, rec=0.098, cos=0.247), tot_loss_proj:2.845 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run for lesser men into [SEP]']
[ 750/2000] tot_loss=1.827 (perp=7.389, rec=0.103, cos=0.247), tot_loss_proj:2.849 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run for lesser men into [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.790 (perp=7.262, rec=0.092, cos=0.246), tot_loss_proj:2.644 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.783 (perp=7.262, rec=0.081, cos=0.249), tot_loss_proj:2.642 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
[ 900/2000] tot_loss=1.783 (perp=7.262, rec=0.084, cos=0.247), tot_loss_proj:2.639 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.779 (perp=7.262, rec=0.077, cos=0.250), tot_loss_proj:2.639 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1000/2000] tot_loss=1.786 (perp=7.262, rec=0.086, cos=0.248), tot_loss_proj:2.632 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
[1050/2000] tot_loss=1.787 (perp=7.262, rec=0.086, cos=0.249), tot_loss_proj:2.636 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1100/2000] tot_loss=1.787 (perp=7.262, rec=0.087, cos=0.248), tot_loss_proj:2.638 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1150/2000] tot_loss=1.784 (perp=7.262, rec=0.083, cos=0.249), tot_loss_proj:2.642 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
[1200/2000] tot_loss=1.784 (perp=7.262, rec=0.084, cos=0.248), tot_loss_proj:2.635 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1250/2000] tot_loss=1.788 (perp=7.262, rec=0.086, cos=0.249), tot_loss_proj:2.633 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1300/2000] tot_loss=1.794 (perp=7.262, rec=0.092, cos=0.249), tot_loss_proj:2.634 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
[1350/2000] tot_loss=1.784 (perp=7.262, rec=0.082, cos=0.249), tot_loss_proj:2.636 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1400/2000] tot_loss=1.782 (perp=7.262, rec=0.080, cos=0.250), tot_loss_proj:2.639 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1450/2000] tot_loss=1.782 (perp=7.262, rec=0.081, cos=0.249), tot_loss_proj:2.637 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
[1500/2000] tot_loss=1.785 (perp=7.262, rec=0.085, cos=0.248), tot_loss_proj:2.631 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1550/2000] tot_loss=1.782 (perp=7.262, rec=0.082, cos=0.248), tot_loss_proj:2.638 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1600/2000] tot_loss=1.780 (perp=7.262, rec=0.078, cos=0.249), tot_loss_proj:2.634 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
[1650/2000] tot_loss=1.786 (perp=7.262, rec=0.085, cos=0.249), tot_loss_proj:2.630 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1700/2000] tot_loss=1.778 (perp=7.262, rec=0.078, cos=0.248), tot_loss_proj:2.637 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1750/2000] tot_loss=1.790 (perp=7.262, rec=0.089, cos=0.249), tot_loss_proj:2.635 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
[1800/2000] tot_loss=1.787 (perp=7.262, rec=0.086, cos=0.249), tot_loss_proj:2.638 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1850/2000] tot_loss=1.777 (perp=7.262, rec=0.076, cos=0.248), tot_loss_proj:2.633 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[1900/2000] tot_loss=1.784 (perp=7.262, rec=0.084, cos=0.248), tot_loss_proj:2.634 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
[1950/2000] tot_loss=1.778 (perp=7.262, rec=0.077, cos=0.249), tot_loss_proj:2.634 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Attempt swap
[2000/2000] tot_loss=1.785 (perp=7.262, rec=0.083, cos=0.250), tot_loss_proj:2.638 [t=0.21s]
prediction: ['[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] people himself would force himself on cover situations and make run into lesser men for [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 58.824 | p: 58.824 | r: 58.824
rougeLsum  | fm: 58.824 | p: 58.824 | r: 58.824
r1fm+r2fm = 112.868

[Aggregate metrics]:
rouge1     | fm: 89.363 | p: 88.575 | r: 90.352
rouge2     | fm: 54.510 | p: 54.180 | r: 54.890
rougeL     | fm: 78.154 | p: 77.522 | r: 78.917
rougeLsum  | fm: 78.068 | p: 77.477 | r: 78.847
r1fm+r2fm = 143.873

input #96 time: 0:08:20 | total time: 14:00:56


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.8268970779694729
highest_index [0]
highest [0.8268970779694729]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.7552237510681152 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.7312455773353577 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best perm rec loss: 0.7302868366241455 for ['[CLS] victoriaten test pass 2016 which [SEP]']
[Init] best perm rec loss: 0.7276121377944946 for ['[CLS] pass testten which 2016 victoria [SEP]']
[Init] best perm rec loss: 0.7264462113380432 for ['[CLS] 2016 pass testten which victoria [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.907 (perp=11.351, rec=0.325, cos=0.312), tot_loss_proj:4.100 [t=0.21s]
prediction: ['[CLS] rights unforable april character [SEP]']
[ 100/2000] tot_loss=2.612 (perp=10.650, rec=0.166, cos=0.317), tot_loss_proj:3.189 [t=0.21s]
prediction: ['[CLS] rossforgettable turns characters [SEP]']
[ 150/2000] tot_loss=1.857 (perp=7.077, rec=0.132, cos=0.310), tot_loss_proj:2.201 [t=0.21s]
prediction: ['[CLS] orforgettable characters characters [SEP]']
[ 200/2000] tot_loss=2.288 (perp=9.292, rec=0.117, cos=0.313), tot_loss_proj:2.858 [t=0.21s]
prediction: ['[CLS] andforgettablelo characters [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.491 (perp=5.309, rec=0.113, cos=0.316), tot_loss_proj:1.460 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 300/2000] tot_loss=1.458 (perp=5.309, rec=0.083, cos=0.313), tot_loss_proj:1.448 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.458 (perp=5.309, rec=0.078, cos=0.318), tot_loss_proj:1.448 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.453 (perp=5.309, rec=0.082, cos=0.310), tot_loss_proj:1.453 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 450/2000] tot_loss=1.438 (perp=5.309, rec=0.066, cos=0.310), tot_loss_proj:1.464 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.439 (perp=5.309, rec=0.065, cos=0.312), tot_loss_proj:1.458 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.460 (perp=5.309, rec=0.079, cos=0.319), tot_loss_proj:1.471 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 600/2000] tot_loss=1.439 (perp=5.309, rec=0.065, cos=0.312), tot_loss_proj:1.459 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.455 (perp=5.309, rec=0.077, cos=0.317), tot_loss_proj:1.457 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.440 (perp=5.309, rec=0.070, cos=0.309), tot_loss_proj:1.449 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 750/2000] tot_loss=1.443 (perp=5.309, rec=0.064, cos=0.316), tot_loss_proj:1.458 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.445 (perp=5.309, rec=0.070, cos=0.313), tot_loss_proj:1.455 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.447 (perp=5.309, rec=0.073, cos=0.312), tot_loss_proj:1.451 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 900/2000] tot_loss=1.431 (perp=5.309, rec=0.054, cos=0.316), tot_loss_proj:1.464 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.442 (perp=5.309, rec=0.064, cos=0.317), tot_loss_proj:1.467 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.429 (perp=5.309, rec=0.054, cos=0.313), tot_loss_proj:1.456 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1050/2000] tot_loss=1.441 (perp=5.309, rec=0.064, cos=0.315), tot_loss_proj:1.445 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.428 (perp=5.309, rec=0.055, cos=0.311), tot_loss_proj:1.462 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.437 (perp=5.309, rec=0.061, cos=0.314), tot_loss_proj:1.439 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1200/2000] tot_loss=1.443 (perp=5.309, rec=0.065, cos=0.316), tot_loss_proj:1.457 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.432 (perp=5.309, rec=0.055, cos=0.315), tot_loss_proj:1.447 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.440 (perp=5.309, rec=0.065, cos=0.313), tot_loss_proj:1.453 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1350/2000] tot_loss=1.442 (perp=5.309, rec=0.066, cos=0.314), tot_loss_proj:1.467 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.442 (perp=5.309, rec=0.064, cos=0.316), tot_loss_proj:1.451 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.438 (perp=5.309, rec=0.060, cos=0.316), tot_loss_proj:1.454 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1500/2000] tot_loss=1.440 (perp=5.309, rec=0.063, cos=0.315), tot_loss_proj:1.455 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.434 (perp=5.309, rec=0.057, cos=0.316), tot_loss_proj:1.469 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.443 (perp=5.309, rec=0.067, cos=0.314), tot_loss_proj:1.452 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1650/2000] tot_loss=1.427 (perp=5.309, rec=0.050, cos=0.315), tot_loss_proj:1.460 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.437 (perp=5.309, rec=0.061, cos=0.314), tot_loss_proj:1.462 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.450 (perp=5.309, rec=0.072, cos=0.315), tot_loss_proj:1.443 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1800/2000] tot_loss=1.438 (perp=5.309, rec=0.061, cos=0.316), tot_loss_proj:1.455 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.440 (perp=5.309, rec=0.062, cos=0.316), tot_loss_proj:1.449 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.438 (perp=5.309, rec=0.061, cos=0.315), tot_loss_proj:1.447 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1950/2000] tot_loss=1.436 (perp=5.309, rec=0.059, cos=0.315), tot_loss_proj:1.460 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.434 (perp=5.309, rec=0.056, cos=0.316), tot_loss_proj:1.445 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.476 | p: 88.706 | r: 90.472
rouge2     | fm: 54.974 | p: 54.653 | r: 55.413
rougeL     | fm: 78.278 | p: 77.703 | r: 79.091
rougeLsum  | fm: 78.355 | p: 77.739 | r: 79.148
r1fm+r2fm = 144.450

input #97 time: 0:08:23 | total time: 14:09:20


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.878639117214921
highest_index [0]
highest [0.878639117214921]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.6579991579055786 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.6507870554924011 for ['[CLS] jed nos prohibited ada [SEP]']
[Init] best perm rec loss: 0.642569899559021 for ['[CLS] nos ada jed prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.301 (perp=9.199, rec=0.235, cos=0.227), tot_loss_proj:2.665 [t=0.21s]
prediction: ['[CLS] unfullling losses [SEP]']
[ 100/2000] tot_loss=2.200 (perp=9.199, rec=0.136, cos=0.225), tot_loss_proj:2.651 [t=0.21s]
prediction: ['[CLS] unfullling losses [SEP]']
[ 150/2000] tot_loss=2.921 (perp=12.919, rec=0.112, cos=0.226), tot_loss_proj:3.302 [t=0.21s]
prediction: ['[CLS] unfulllingfi [SEP]']
[ 200/2000] tot_loss=2.892 (perp=12.919, rec=0.087, cos=0.222), tot_loss_proj:3.301 [t=0.21s]
prediction: ['[CLS] unfulllingfi [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.292 (perp=4.948, rec=0.080, cos=0.222), tot_loss_proj:1.312 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.287 (perp=4.948, rec=0.075, cos=0.222), tot_loss_proj:1.308 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.296 (perp=4.948, rec=0.081, cos=0.226), tot_loss_proj:1.295 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.282 (perp=4.948, rec=0.075, cos=0.217), tot_loss_proj:1.312 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.277 (perp=4.948, rec=0.067, cos=0.221), tot_loss_proj:1.306 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.275 (perp=4.948, rec=0.057, cos=0.228), tot_loss_proj:1.302 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.283 (perp=4.948, rec=0.071, cos=0.222), tot_loss_proj:1.292 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.292 (perp=4.948, rec=0.078, cos=0.225), tot_loss_proj:1.314 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.284 (perp=4.948, rec=0.067, cos=0.227), tot_loss_proj:1.308 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.283 (perp=4.948, rec=0.065, cos=0.228), tot_loss_proj:1.311 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.288 (perp=4.948, rec=0.070, cos=0.229), tot_loss_proj:1.296 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.270 (perp=4.948, rec=0.053, cos=0.228), tot_loss_proj:1.302 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.278 (perp=4.948, rec=0.064, cos=0.225), tot_loss_proj:1.301 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.293 (perp=4.948, rec=0.080, cos=0.223), tot_loss_proj:1.301 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.283 (perp=4.948, rec=0.067, cos=0.226), tot_loss_proj:1.310 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.280 (perp=4.948, rec=0.067, cos=0.223), tot_loss_proj:1.305 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.287 (perp=4.948, rec=0.072, cos=0.226), tot_loss_proj:1.303 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.266 (perp=4.948, rec=0.051, cos=0.226), tot_loss_proj:1.297 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.277 (perp=4.948, rec=0.061, cos=0.226), tot_loss_proj:1.296 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.286 (perp=4.948, rec=0.072, cos=0.225), tot_loss_proj:1.305 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.264 (perp=4.948, rec=0.049, cos=0.225), tot_loss_proj:1.302 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.286 (perp=4.948, rec=0.071, cos=0.226), tot_loss_proj:1.303 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.277 (perp=4.948, rec=0.061, cos=0.227), tot_loss_proj:1.304 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.276 (perp=4.948, rec=0.061, cos=0.226), tot_loss_proj:1.314 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.277 (perp=4.948, rec=0.062, cos=0.226), tot_loss_proj:1.303 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.280 (perp=4.948, rec=0.064, cos=0.226), tot_loss_proj:1.306 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.269 (perp=4.948, rec=0.052, cos=0.227), tot_loss_proj:1.302 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.273 (perp=4.948, rec=0.058, cos=0.226), tot_loss_proj:1.307 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.272 (perp=4.948, rec=0.056, cos=0.226), tot_loss_proj:1.306 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.276 (perp=4.948, rec=0.061, cos=0.225), tot_loss_proj:1.298 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.284 (perp=4.948, rec=0.068, cos=0.227), tot_loss_proj:1.304 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.279 (perp=4.948, rec=0.063, cos=0.226), tot_loss_proj:1.303 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.281 (perp=4.948, rec=0.065, cos=0.226), tot_loss_proj:1.297 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.268 (perp=4.948, rec=0.051, cos=0.227), tot_loss_proj:1.299 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.279 (perp=4.948, rec=0.062, cos=0.227), tot_loss_proj:1.303 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.289 (perp=4.948, rec=0.071, cos=0.228), tot_loss_proj:1.305 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.513 | p: 88.835 | r: 90.526
rouge2     | fm: 55.411 | p: 55.108 | r: 55.797
rougeL     | fm: 78.520 | p: 77.845 | r: 79.261
rougeLsum  | fm: 78.473 | p: 77.901 | r: 79.234
r1fm+r2fm = 144.925

input #98 time: 0:08:23 | total time: 14:17:44


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.8815014137376418
highest_index [0]
highest [0.8815014137376418]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8044850826263428 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.7964718341827393 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.7905901074409485 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.7657265067100525 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.752377986907959 for ['[CLS] imp then ratlogueathy mobile bun smoothe bran where heart thumbs principal aires & recently brig addison stands catalog alert abbottale leading switch as could which buy pony kid risk general spreadim [SEP]']
[Init] best rec loss: 0.7467698454856873 for ['[CLS] wat searched fits mckay german divide interpret sensory ajax from even during under skye pants ramlus except door wanted others same q same king ashton care lot confirmation buttonsmania caseston file evil absolute [SEP]']
[Init] best rec loss: 0.7375478744506836 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.7334226965904236 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.7330706119537354 for ['[CLS] ratings stillte [MASK] actually dental orient screens ferns te distance taste reˈ claire slight cushion harper temps forced earliest right bearing himself barbie when services garcia currentlytsaging knowledge synonym thunder bet opposed [SEP]']
[Init] best perm rec loss: 0.7321131825447083 for ['[CLS] currently garcia tempsts cushionˈ right re taste ferns knowledge bet claire earliest distance [MASK]te dental synonym barbie forced when harperaging screens ratings orient te actually services slight bearing thunder still opposed himself [SEP]']
[Init] best perm rec loss: 0.7313642501831055 for ['[CLS] harper still garciaaging knowledge distance when thunderte right synonym orientts te ratings dental slight re [MASK] barbie actually screens himself services bearing ferns forced earliest claire taste bet temps currently opposedˈ cushion [SEP]']
[Init] best perm rec loss: 0.7310912013053894 for ['[CLS] currently orientˈ distance thunder te garcia slight harper taste knowledge temps forced when dental claire earliestaging opposed actuallyts screens barbie bearing ratings right [MASK] still cushion bet himself re synonym fernste services [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.198 (perp=13.126, rec=0.360, cos=0.213), tot_loss_proj:3.607 [t=0.21s]
prediction: ['[CLS] faced gubernatorial controversy anybody checking congress worst was bad horrible...so paper ) chemical tube cars immediately or prefecture no fat stupid doping least film died poorer liability fun on wasn contributed mutual violations [SEP]']
[ 100/2000] tot_loss=2.700 (perp=11.189, rec=0.260, cos=0.202), tot_loss_proj:3.724 [t=0.22s]
prediction: ["[CLS] walked ticket trouble... ` my \\ looked or horrible'di film is'no $ but absolutely ticket generally funssingssing my film diedssing leukemia fun had didn ` mind horrible [SEP]"]
[ 150/2000] tot_loss=2.407 (perp=9.996, rec=0.199, cos=0.209), tot_loss_proj:3.176 [t=0.22s]
prediction: ["[CLS] walked ′ problem the ` so `'or horrible'di film'''$ but ve ticket much funssing di these film dissingssing leukemia fun but must'mind horrible [SEP]"]
[ 200/2000] tot_loss=2.275 (perp=9.499, rec=0.167, cos=0.208), tot_loss_proj:2.717 [t=0.22s]
prediction: ["[CLS] walked ′ fun the saying so ` ` ` horrible'di the'''ticket but di ticket much funssing di the film dissingssing t fun but must so mind horrible [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.243 (perp=9.327, rec=0.159, cos=0.219), tot_loss_proj:2.675 [t=0.22s]
prediction: ["[CLS] walked ticket muttering the saying so ` `'horrible'di ticket'''ticket was di ticket had fun dissing the film dissingssing t fun but must so mind horrible [SEP]"]
[ 300/2000] tot_loss=2.235 (perp=9.440, rec=0.135, cos=0.212), tot_loss_proj:2.697 [t=0.22s]
prediction: ["[CLS] walked ticket muttering the muttering so ` `'horrible'di ticket'''ticket but absolutely ticket had fun dissing the film dissingssing t fun but must that mind horrible [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.099 (perp=8.878, rec=0.117, cos=0.207), tot_loss_proj:2.852 [t=0.22s]
prediction: ["[CLS] walked ticket muttering the muttering so ` `'horrible'dissing'''cost but absolutely ticket had fun dissing the film dissing ticket t fun but must that mind horrible [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.009 (perp=8.381, rec=0.109, cos=0.223), tot_loss_proj:2.412 [t=0.22s]
prediction: ["[CLS] walked ticket muttering the muttering'` `'horrible'dissing'so'cost but otherwise ticket had fun dissing the film dissing ticket t fun but did that mind horrible [SEP]"]
[ 450/2000] tot_loss=1.991 (perp=8.361, rec=0.100, cos=0.218), tot_loss_proj:2.381 [t=0.22s]
prediction: ["[CLS] walked out muttering the muttering, ` `'horrible'dissing'so'cost but otherwise ticket had fun dissing the film dissing ticket t fun but they that mind horrible [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=2.038 (perp=8.637, rec=0.094, cos=0.217), tot_loss_proj:2.433 [t=0.22s]
prediction: ["[CLS] walked out, muttering the muttering ` like or horrible'dissing'so'cost but otherwise ticket had fun dissing the film dissing ticket t fun but they that mind horrible [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.944 (perp=8.178, rec=0.091, cos=0.217), tot_loss_proj:2.340 [t=0.22s]
prediction: ["[CLS] walked out, muttering the muttering `'horrible'dissing'so'cost like but otherwise ticket had fun dissing the film dissing ticket t fun but they that mind horrible [SEP]"]
[ 600/2000] tot_loss=2.004 (perp=8.454, rec=0.091, cos=0.222), tot_loss_proj:2.395 [t=0.22s]
prediction: ["[CLS] walked out, muttering the muttering ` or horrible'dissing'so'cost like but otherwise ticket had fun dissing the film dissing ticket t fun but they that mind horrible [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.913 (perp=8.016, rec=0.089, cos=0.221), tot_loss_proj:2.402 [t=0.22s]
prediction: ["[CLS] walked out, muttering the muttering ` and horrible'dissing'so'cost like but otherwise they had fun dissing the film dissing ticket t fun but ticket that mind horrible [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.961 (perp=8.273, rec=0.087, cos=0.220), tot_loss_proj:2.400 [t=0.22s]
prediction: ["[CLS] walked out, muttering the muttering ` and horrible'dissing'so n cost like but otherwise they had fun dissing the film dissing ticket t fun ticket but that mind horrible [SEP]"]
[ 750/2000] tot_loss=1.942 (perp=8.208, rec=0.083, cos=0.217), tot_loss_proj:2.346 [t=0.22s]
prediction: ["[CLS] walked out, muttering the muttering ` and horrible'dissing'so n cost like but otherwise they had fun dissing the film dissing ticket t fun ticket but that mind terrible [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.919 (perp=8.071, rec=0.085, cos=0.220), tot_loss_proj:2.327 [t=0.22s]
prediction: ["[CLS] walked out, muttering the muttering ` and horrible'dissing'n so cost like but otherwise they had fun dissing the film dissing ticket t fun ticket but that mind terrible [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.929 (perp=8.155, rec=0.084, cos=0.214), tot_loss_proj:2.411 [t=0.22s]
prediction: ["[CLS] walked out, words the muttering ` and horrible'dissing'n so had like cost otherwise they had fun dissing the film dissing ticket t fun ticket but that mind terrible [SEP]"]
[ 900/2000] tot_loss=1.929 (perp=8.129, rec=0.087, cos=0.216), tot_loss_proj:2.357 [t=0.22s]
prediction: ["[CLS] walked out, words the muttering ` and horrible'dissing'n so had like cost otherwise they had fun dissing the film dissing ticket t n ticket but that mind terrible [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.896 (perp=7.938, rec=0.088, cos=0.220), tot_loss_proj:2.258 [t=0.22s]
prediction: ["[CLS] walked out, so the muttering ` and horrible'dissing'n words had like cost otherwise they had fun dissing the film dissing ticket t n ticket but that mind terrible [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.814 (perp=7.539, rec=0.089, cos=0.217), tot_loss_proj:2.182 [t=0.22s]
prediction: ["[CLS] walked out, so the muttering ` and horrible'dissing'words had like cost otherwise they had fun dissing the film dissing n ticket t n ticket but that mind terrible [SEP]"]
[1050/2000] tot_loss=1.813 (perp=7.539, rec=0.087, cos=0.218), tot_loss_proj:2.187 [t=0.22s]
prediction: ["[CLS] walked out, so the muttering ` and horrible'dissing'words had like cost otherwise they had fun dissing the film dissing n ticket t n ticket but that mind terrible [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.802 (perp=7.456, rec=0.087, cos=0.224), tot_loss_proj:2.194 [t=0.22s]
prediction: ["[CLS] walked out otherwise so the muttering ` and horrible'dissing'words had like cost, they had fun dissing the film dissing n ticket t n ticket but that mind terrible [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.768 (perp=7.326, rec=0.084, cos=0.219), tot_loss_proj:2.256 [t=0.22s]
prediction: ["[CLS] walked out otherwise so the cost ` and horrible'dissing'words had like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
[1200/2000] tot_loss=1.746 (perp=7.246, rec=0.077, cos=0.219), tot_loss_proj:2.360 [t=0.22s]
prediction: ["[CLS] walked out'so the cost ` and horrible'dissing'words had like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.742 (perp=7.195, rec=0.083, cos=0.220), tot_loss_proj:2.384 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'and horrible'dissing words had like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.737 (perp=7.195, rec=0.078, cos=0.220), tot_loss_proj:2.389 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'and horrible'dissing words had like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
[1350/2000] tot_loss=1.736 (perp=7.195, rec=0.077, cos=0.219), tot_loss_proj:2.385 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'and horrible'dissing words had like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.748 (perp=7.195, rec=0.086, cos=0.223), tot_loss_proj:2.381 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'and horrible'dissing words had like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.744 (perp=7.195, rec=0.084, cos=0.221), tot_loss_proj:2.353 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'and horrible'dissing words had like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
[1500/2000] tot_loss=1.738 (perp=7.195, rec=0.079, cos=0.220), tot_loss_proj:2.355 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'and horrible'dissing words had like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.736 (perp=7.195, rec=0.077, cos=0.220), tot_loss_proj:2.355 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'and horrible'dissing words had like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.746 (perp=7.195, rec=0.087, cos=0.220), tot_loss_proj:2.361 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'and horrible'dissing words had like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
[1650/2000] tot_loss=1.742 (perp=7.195, rec=0.083, cos=0.220), tot_loss_proj:2.357 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'and horrible'dissing words had like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.711 (perp=7.036, rec=0.081, cos=0.223), tot_loss_proj:2.252 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'had horrible'dissing words and like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.704 (perp=7.036, rec=0.076, cos=0.221), tot_loss_proj:2.251 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'had horrible'dissing words and like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
[1800/2000] tot_loss=1.709 (perp=7.036, rec=0.080, cos=0.222), tot_loss_proj:2.252 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'had horrible'dissing words and like muttering, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=1.695 (perp=6.983, rec=0.076, cos=0.222), tot_loss_proj:2.405 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'had horrible'dissing words and muttering like, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.702 (perp=6.983, rec=0.084, cos=0.222), tot_loss_proj:2.412 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'had horrible'dissing words and muttering like, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
[1950/2000] tot_loss=1.696 (perp=6.983, rec=0.079, cos=0.221), tot_loss_proj:2.410 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'had horrible'dissing words and muttering like, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.696 (perp=6.983, rec=0.078, cos=0.221), tot_loss_proj:2.409 [t=0.22s]
prediction: ["[CLS] walked out'so the cost `'had horrible'dissing words and muttering like, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] walked out'so the cost `'had horrible'dissing words and muttering like, they had fun dissing the film dissing n the t n ticket but that mind terrible [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 80.000 | r: 92.308
rouge2     | fm: 18.519 | p: 17.241 | r: 20.000
rougeL     | fm: 46.429 | p: 43.333 | r: 50.000
rougeLsum  | fm: 46.429 | p: 43.333 | r: 50.000
r1fm+r2fm = 104.233

[Aggregate metrics]:
rouge1     | fm: 89.554 | p: 88.724 | r: 90.611
rouge2     | fm: 55.279 | p: 54.945 | r: 55.674
rougeL     | fm: 78.107 | p: 77.438 | r: 78.910
rougeLsum  | fm: 78.252 | p: 77.588 | r: 79.128
r1fm+r2fm = 144.833

input #99 time: 0:08:34 | total time: 14:26:18


Average Cosine Similarity: 0.8612623922847026
Done with all.
