


Command: attack4.py --dataset cola --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola --n_steps 2000 --coeff_pooler_match 0.1 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 136.09it/s]
SSome weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
Harriet alternated folk songs and pop songs together.
========================
average of cosine similarity 0.9105552123570868
highest_index [0]
highest [0.9105552123570868]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 14207,  6585,  2094,  5154,  2774,  1998,  3769,  2774,  2362,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] harriet alternated folk songs and pop songs together. [SEP]']
[Init] best rec loss: 0.806529700756073 for ['[CLS] study showing exchange victorywall same bryant compulsory cl regiments [SEP]']
Init] best perm rec loss: 0.8056742548942566 for ['[CLS] regiments cl study bryant victorywall exchange showing compulsory same [SEP]']
[Init] best perm rec loss: 0.8003864884376526 for ['[CLS] cl regimentswall showing same compulsory bryant victory study exchange [SEP]']
[Init] best perm rec loss: 0.7995104789733887 for ['[CLS] compulsory clwall bryant showing study same regiments exchange victory [SEP]']
[Init] best perm rec loss: 0.7969235181808472 for ['[CLS] cl bryant regiments showing compulsorywall study same exchange victory [SEP]']
[Init] best perm rec loss: 0.7956761121749878 for ['[CLS] regiments bryant showing study cl exchangewall compulsory victory same [SEP]']
[Init] best perm rec loss: 0.7947715520858765 for ['[CLS] showing regimentswall bryant compulsory study cl exchange same victory [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.009 (perp=12.109, rec=0.402, cos=0.185), tot_loss_proj:4.264 [t=2.12s]
prediction: ['[CLS] science decades they namesake historical use alternate both together songs [SEP]']
[ 100/2000] tot_loss=3.008 (perp=11.816, rec=0.403, cos=0.242), tot_loss_proj:4.178 [t=0.23s]
prediction: ['[CLS] film harriet / folk songsd alternate together together songs [SEP]']
[ 150/2000] tot_loss=2.781 (perp=11.528, rec=0.232, cos=0.243), tot_loss_proj:4.115 [t=0.23s]
prediction: ['[CLS] film harriet / folk songsd alternate together ( songs [SEP]']
[ 200/2000] tot_loss=2.369 (perp=10.202, rec=0.166, cos=0.163), tot_loss_proj:3.803 [t=0.23s]
prediction: ['[CLS] gel harriet and folk songsd alternate together. songs [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.935 (perp=8.036, rec=0.169, cos=0.159), tot_loss_proj:2.996 [t=0.23s]
prediction: ['[CLS]tial harriet and folk songs alternated together. songs [SEP]']
[ 300/2000] tot_loss=1.759 (perp=7.317, rec=0.143, cos=0.153), tot_loss_proj:2.982 [t=0.23s]
prediction: ['[CLS] harriet harriet and pop songs alternated together. songs [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.689 (perp=6.839, rec=0.146, cos=0.175), tot_loss_proj:3.153 [t=0.24s]
prediction: ['[CLS] harriet harriet and pop songs alternated together songs. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.554 (perp=6.285, rec=0.129, cos=0.168), tot_loss_proj:2.925 [t=0.23s]
prediction: ['[CLS] harriet harriet and pop songs alternated songs together. [SEP]']
[ 450/2000] tot_loss=1.539 (perp=6.285, rec=0.127, cos=0.155), tot_loss_proj:2.931 [t=0.23s]
prediction: ['[CLS] harriet harriet and pop songs alternated songs together. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.517 (perp=6.285, rec=0.101, cos=0.159), tot_loss_proj:2.921 [t=0.23s]
prediction: ['[CLS] harriet harriet and pop songs alternated songs together. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.513 (perp=6.274, rec=0.100, cos=0.159), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
[ 600/2000] tot_loss=1.507 (perp=6.274, rec=0.087, cos=0.166), tot_loss_proj:2.881 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.515 (perp=6.274, rec=0.089, cos=0.171), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.499 (perp=6.274, rec=0.078, cos=0.167), tot_loss_proj:2.882 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
[ 750/2000] tot_loss=1.509 (perp=6.274, rec=0.090, cos=0.164), tot_loss_proj:2.880 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.493 (perp=6.274, rec=0.085, cos=0.154), tot_loss_proj:2.887 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.483 (perp=6.274, rec=0.075, cos=0.153), tot_loss_proj:2.877 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
[ 900/2000] tot_loss=1.488 (perp=6.274, rec=0.079, cos=0.154), tot_loss_proj:2.880 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.501 (perp=6.274, rec=0.083, cos=0.163), tot_loss_proj:2.883 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.511 (perp=6.274, rec=0.093, cos=0.163), tot_loss_proj:2.880 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
[1050/2000] tot_loss=1.494 (perp=6.274, rec=0.076, cos=0.164), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.502 (perp=6.274, rec=0.081, cos=0.166), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.513 (perp=6.274, rec=0.088, cos=0.170), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
[1200/2000] tot_loss=1.494 (perp=6.274, rec=0.069, cos=0.170), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.508 (perp=6.274, rec=0.086, cos=0.168), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.505 (perp=6.274, rec=0.081, cos=0.169), tot_loss_proj:2.881 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
[1350/2000] tot_loss=1.502 (perp=6.274, rec=0.079, cos=0.168), tot_loss_proj:2.891 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.512 (perp=6.274, rec=0.089, cos=0.168), tot_loss_proj:2.887 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.493 (perp=6.274, rec=0.073, cos=0.165), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
[1500/2000] tot_loss=1.496 (perp=6.274, rec=0.074, cos=0.167), tot_loss_proj:2.883 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.507 (perp=6.274, rec=0.084, cos=0.169), tot_loss_proj:2.881 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.506 (perp=6.274, rec=0.082, cos=0.169), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
[1650/2000] tot_loss=1.508 (perp=6.274, rec=0.086, cos=0.167), tot_loss_proj:2.883 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.506 (perp=6.274, rec=0.085, cos=0.166), tot_loss_proj:2.881 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.507 (perp=6.274, rec=0.084, cos=0.168), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
[1800/2000] tot_loss=1.510 (perp=6.274, rec=0.086, cos=0.169), tot_loss_proj:2.886 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.509 (perp=6.274, rec=0.087, cos=0.168), tot_loss_proj:2.880 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.500 (perp=6.274, rec=0.083, cos=0.163), tot_loss_proj:2.887 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
[1950/2000] tot_loss=1.498 (perp=6.274, rec=0.074, cos=0.169), tot_loss_proj:2.881 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.511 (perp=6.274, rec=0.087, cos=0.169), tot_loss_proj:2.883 [t=0.23s]
prediction: ['[CLS] harriet harriet and folk songs alternated songs together. [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] harriet alternated folk songs and pop songs together. [SEP]
========================
predicted: 
========================
[CLS] harriet harriet and folk songs alternated songs together. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 44.444 | p: 44.444 | r: 44.444
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 134.444

[Aggregate metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 44.444 | p: 44.444 | r: 44.444
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 134.444

input #0 time: 0:09:19 | total time: 0:09:19


Running input #1 of 100.
reference: 
========================
Who do you think that will question Seamus first?
========================
average of cosine similarity 0.8970319722800074
highest_index [0]
highest [0.8970319722800074]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2040,  2079,  2017,  2228,  2008,  2097,  3160, 24993,  2034,
          1029,   102]], device='cuda:0')
Debug: ref = ['[CLS] who do you think that will question seamus first? [SEP]']
[Init] best rec loss: 0.7588651776313782 for ['[CLS] singerии middlesbrough tells certificate numbering century sung nowhere go [SEP]']
[Init] best rec loss: 0.7320712208747864 for ['[CLS] because richest soc final melbourne gallo building mob might storm [SEP]']
[Init] best rec loss: 0.7253055572509766 for ['[CLS]less millennium billboard ron trial marino empire clerk kai brand [SEP]']
[Init] best rec loss: 0.7094318866729736 for ['[CLS] turn film comrade independent loud laughing films highestriverragan [SEP]']
[Init] best perm rec loss: 0.7084980010986328 for ['[CLS] turn film loudriver laughing filmsragan highest comrade independent [SEP]']
[Init] best perm rec loss: 0.7084945440292358 for ['[CLS] turn film comrade laughing films loud independent highestraganriver [SEP]']
[Init] best perm rec loss: 0.7079398036003113 for ['[CLS] comrade independentraganriver loud highest film laughing turn films [SEP]']
[Init] best perm rec loss: 0.7074962258338928 for ['[CLS]riverragan independent comrade loud film films turn laughing highest [SEP]']
[Init] best perm rec loss: 0.7054362893104553 for ['[CLS] comraderiver film laughing turn films independentragan loud highest [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.816 (perp=11.287, rec=0.384, cos=0.175), tot_loss_proj:3.502 [t=0.23s]
prediction: ['[CLS] where seamus these today was 2011 educational open deaf candidate [SEP]']
[ 100/2000] tot_loss=2.871 (perp=11.902, rec=0.293, cos=0.198), tot_loss_proj:3.609 [t=0.23s]
prediction: ['[CLS] who seamus this that was festival educational oldislaus miss [SEP]']
[ 150/2000] tot_loss=2.531 (perp=10.522, rec=0.226, cos=0.201), tot_loss_proj:2.974 [t=0.23s]
prediction: ['[CLS] who seamus think that is profile educational old will guys [SEP]']
[ 200/2000] tot_loss=2.366 (perp=9.682, rec=0.239, cos=0.190), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] who seamus think that is question educational old will? [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.006 (perp=7.932, rec=0.220, cos=0.200), tot_loss_proj:2.705 [t=0.23s]
prediction: ['[CLS] who will think that would question educational old seamus? [SEP]']
[ 300/2000] tot_loss=1.839 (perp=7.447, rec=0.156, cos=0.194), tot_loss_proj:2.793 [t=0.23s]
prediction: ['[CLS] who will think that will question black old seamus? [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.537 (perp=6.021, rec=0.138, cos=0.194), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] who will think that will question you first seamus? [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.535 (perp=6.021, rec=0.136, cos=0.195), tot_loss_proj:1.961 [t=0.23s]
prediction: ['[CLS] who will think that will question you first seamus? [SEP]']
[ 450/2000] tot_loss=1.513 (perp=6.021, rec=0.114, cos=0.194), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] who will think that will question you first seamus? [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.525 (perp=6.021, rec=0.126, cos=0.195), tot_loss_proj:1.963 [t=0.23s]
prediction: ['[CLS] who will think that will question you first seamus? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.717 (perp=7.067, rec=0.110, cos=0.194), tot_loss_proj:2.510 [t=0.23s]
prediction: ['[CLS] who will think that will question first silent seamus? [SEP]']
[ 600/2000] tot_loss=1.720 (perp=7.067, rec=0.112, cos=0.194), tot_loss_proj:2.519 [t=0.23s]
prediction: ['[CLS] who will think that will question first silent seamus? [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.777 (perp=7.343, rec=0.115, cos=0.193), tot_loss_proj:2.408 [t=0.23s]
prediction: ['[CLS] who will think that will question first seamus? seamus [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.731 (perp=7.148, rec=0.110, cos=0.191), tot_loss_proj:2.656 [t=0.23s]
prediction: ['[CLS] who will think that question will first seamus? seamus [SEP]']
[ 750/2000] tot_loss=1.714 (perp=7.148, rec=0.094, cos=0.191), tot_loss_proj:2.663 [t=0.23s]
prediction: ['[CLS] who will think that question will first seamus? seamus [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.776 (perp=7.454, rec=0.095, cos=0.190), tot_loss_proj:2.585 [t=0.23s]
prediction: ['[CLS] who will think that question you first seamus seamus? [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.695 (perp=6.992, rec=0.105, cos=0.192), tot_loss_proj:2.710 [t=0.23s]
prediction: ['[CLS] who will you think that question first seamus seamus? [SEP]']
[ 900/2000] tot_loss=1.682 (perp=6.992, rec=0.091, cos=0.192), tot_loss_proj:2.709 [t=0.23s]
prediction: ['[CLS] who will you think that question first seamus seamus? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.686 (perp=6.992, rec=0.095, cos=0.192), tot_loss_proj:2.710 [t=0.23s]
prediction: ['[CLS] who will you think that question first seamus seamus? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.678 (perp=6.992, rec=0.086, cos=0.193), tot_loss_proj:2.705 [t=0.23s]
prediction: ['[CLS] who will you think that question first seamus seamus? [SEP]']
[1050/2000] tot_loss=1.682 (perp=6.992, rec=0.090, cos=0.194), tot_loss_proj:2.705 [t=0.23s]
prediction: ['[CLS] who will you think that question first seamus seamus? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.770 (perp=7.439, rec=0.088, cos=0.194), tot_loss_proj:2.654 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.771 (perp=7.439, rec=0.089, cos=0.194), tot_loss_proj:2.655 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
[1200/2000] tot_loss=1.760 (perp=7.439, rec=0.078, cos=0.194), tot_loss_proj:2.662 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.762 (perp=7.439, rec=0.080, cos=0.194), tot_loss_proj:2.659 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.757 (perp=7.439, rec=0.075, cos=0.195), tot_loss_proj:2.653 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
[1350/2000] tot_loss=1.765 (perp=7.439, rec=0.083, cos=0.195), tot_loss_proj:2.658 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.763 (perp=7.439, rec=0.080, cos=0.195), tot_loss_proj:2.664 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.757 (perp=7.439, rec=0.075, cos=0.195), tot_loss_proj:2.652 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
[1500/2000] tot_loss=1.765 (perp=7.439, rec=0.082, cos=0.195), tot_loss_proj:2.652 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.766 (perp=7.439, rec=0.083, cos=0.195), tot_loss_proj:2.651 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.761 (perp=7.439, rec=0.078, cos=0.195), tot_loss_proj:2.657 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
[1650/2000] tot_loss=1.766 (perp=7.439, rec=0.083, cos=0.195), tot_loss_proj:2.656 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.763 (perp=7.439, rec=0.080, cos=0.195), tot_loss_proj:2.659 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.758 (perp=7.439, rec=0.075, cos=0.195), tot_loss_proj:2.663 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
[1800/2000] tot_loss=1.752 (perp=7.439, rec=0.069, cos=0.195), tot_loss_proj:2.656 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.759 (perp=7.439, rec=0.076, cos=0.195), tot_loss_proj:2.658 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.760 (perp=7.439, rec=0.076, cos=0.195), tot_loss_proj:2.663 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
[1950/2000] tot_loss=1.764 (perp=7.439, rec=0.081, cos=0.195), tot_loss_proj:2.649 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.760 (perp=7.439, rec=0.077, cos=0.195), tot_loss_proj:2.664 [t=0.23s]
prediction: ['[CLS] who will do think that question first seamus seamus? [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] who do you think that will question seamus first? [SEP]
========================
predicted: 
========================
[CLS] who will do think that question first seamus seamus? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 110.909

[Aggregate metrics]:
rouge1     | fm: 90.455 | p: 90.455 | r: 90.455
rouge2     | fm: 32.222 | p: 32.222 | r: 32.222
rougeL     | fm: 71.364 | p: 71.364 | r: 71.364
rougeLsum  | fm: 71.364 | p: 71.364 | r: 71.364
r1fm+r2fm = 122.677

input #1 time: 0:09:10 | total time: 0:18:29


Running input #2 of 100.
reference: 
========================
The boy ran.
========================
average of cosine similarity 0.8767481525868142
highest_index [0]
highest [0.8767481525868142]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 1996, 2879, 2743, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the boy ran. [SEP]']
[Init] best rec loss: 0.9655736088752747 for ['[CLS] animation equal wickets gran [SEP]']
[Init] best rec loss: 0.911936342716217 for ['[CLS] rose instruction lengths ; [SEP]']
[Init] best rec loss: 0.911829948425293 for ['[CLS] fitness swear ether people [SEP]']
[Init] best rec loss: 0.9077699780464172 for ['[CLS] directly goes our sang [SEP]']
[Init] best rec loss: 0.8787719011306763 for ['[CLS] webese aubasket [SEP]']
[Init] best rec loss: 0.8783764243125916 for ['[CLS] euas futures past [SEP]']
[Init] best rec loss: 0.8774303793907166 for ['[CLS] coat geraldine ordnanceander [SEP]']
[Init] best rec loss: 0.861678957939148 for ['[CLS]nesianharat telling redistribution [SEP]']
[Init] best perm rec loss: 0.8608149290084839 for ['[CLS] redistributionharat tellingnesian [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.983 (perp=7.525, rec=0.242, cos=0.235), tot_loss_proj:3.359 [t=0.23s]
prediction: ['[CLS] boy ran boy. [SEP]']
[ 100/2000] tot_loss=1.846 (perp=7.525, rec=0.111, cos=0.230), tot_loss_proj:3.368 [t=0.23s]
prediction: ['[CLS] boy ran boy. [SEP]']
[ 150/2000] tot_loss=1.830 (perp=7.525, rec=0.098, cos=0.228), tot_loss_proj:3.375 [t=0.23s]
prediction: ['[CLS] boy ran boy. [SEP]']
[ 200/2000] tot_loss=1.973 (perp=8.364, rec=0.070, cos=0.230), tot_loss_proj:3.576 [t=0.23s]
prediction: ['[CLS] boy ran the. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.544 (perp=6.171, rec=0.086, cos=0.225), tot_loss_proj:3.101 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[ 300/2000] tot_loss=1.542 (perp=6.171, rec=0.077, cos=0.231), tot_loss_proj:3.106 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.523 (perp=6.171, rec=0.058, cos=0.231), tot_loss_proj:3.099 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.529 (perp=6.171, rec=0.064, cos=0.231), tot_loss_proj:3.093 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[ 450/2000] tot_loss=1.534 (perp=6.171, rec=0.069, cos=0.231), tot_loss_proj:3.096 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.536 (perp=6.171, rec=0.071, cos=0.231), tot_loss_proj:3.090 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.523 (perp=6.171, rec=0.058, cos=0.231), tot_loss_proj:3.088 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[ 600/2000] tot_loss=1.529 (perp=6.171, rec=0.064, cos=0.231), tot_loss_proj:3.097 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.528 (perp=6.171, rec=0.063, cos=0.231), tot_loss_proj:3.094 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.521 (perp=6.171, rec=0.056, cos=0.231), tot_loss_proj:3.097 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[ 750/2000] tot_loss=1.529 (perp=6.171, rec=0.064, cos=0.231), tot_loss_proj:3.094 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.529 (perp=6.171, rec=0.063, cos=0.231), tot_loss_proj:3.084 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.539 (perp=6.171, rec=0.074, cos=0.231), tot_loss_proj:3.090 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[ 900/2000] tot_loss=1.528 (perp=6.171, rec=0.063, cos=0.231), tot_loss_proj:3.097 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.534 (perp=6.171, rec=0.068, cos=0.231), tot_loss_proj:3.087 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.533 (perp=6.171, rec=0.067, cos=0.231), tot_loss_proj:3.092 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[1050/2000] tot_loss=1.535 (perp=6.171, rec=0.070, cos=0.231), tot_loss_proj:3.087 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.524 (perp=6.171, rec=0.059, cos=0.231), tot_loss_proj:3.095 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.532 (perp=6.171, rec=0.066, cos=0.231), tot_loss_proj:3.088 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[1200/2000] tot_loss=1.537 (perp=6.171, rec=0.072, cos=0.231), tot_loss_proj:3.086 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.527 (perp=6.171, rec=0.062, cos=0.231), tot_loss_proj:3.090 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.530 (perp=6.171, rec=0.065, cos=0.231), tot_loss_proj:3.085 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[1350/2000] tot_loss=1.521 (perp=6.171, rec=0.056, cos=0.231), tot_loss_proj:3.091 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.535 (perp=6.171, rec=0.070, cos=0.231), tot_loss_proj:3.098 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.535 (perp=6.171, rec=0.069, cos=0.231), tot_loss_proj:3.086 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[1500/2000] tot_loss=1.534 (perp=6.171, rec=0.069, cos=0.231), tot_loss_proj:3.091 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.531 (perp=6.171, rec=0.066, cos=0.231), tot_loss_proj:3.091 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.533 (perp=6.171, rec=0.068, cos=0.231), tot_loss_proj:3.088 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[1650/2000] tot_loss=1.527 (perp=6.171, rec=0.062, cos=0.231), tot_loss_proj:3.093 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.517 (perp=6.171, rec=0.052, cos=0.231), tot_loss_proj:3.092 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.533 (perp=6.171, rec=0.067, cos=0.231), tot_loss_proj:3.088 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[1800/2000] tot_loss=1.531 (perp=6.171, rec=0.065, cos=0.231), tot_loss_proj:3.091 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.530 (perp=6.171, rec=0.065, cos=0.231), tot_loss_proj:3.086 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.520 (perp=6.171, rec=0.055, cos=0.231), tot_loss_proj:3.086 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
[1950/2000] tot_loss=1.534 (perp=6.171, rec=0.069, cos=0.231), tot_loss_proj:3.091 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.533 (perp=6.171, rec=0.068, cos=0.231), tot_loss_proj:3.088 [t=0.23s]
prediction: ['[CLS] the ran boy. [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] the boy ran. [SEP]
========================
predicted: 
========================
[CLS] the ran boy. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 93.636 | p: 93.636 | r: 93.636
rouge2     | fm: 29.815 | p: 29.815 | r: 29.815
rougeL     | fm: 74.242 | p: 74.242 | r: 74.242
rougeLsum  | fm: 74.242 | p: 74.242 | r: 74.242
r1fm+r2fm = 123.451

input #2 time: 0:09:10 | total time: 0:27:39


Running input #3 of 100.
reference: 
========================
I wonder who Bill saw and liked Mary.
========================
average of cosine similarity 0.8998357950592966
highest_index [0]
highest [0.8998357950592966]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1045, 4687, 2040, 3021, 2387, 1998, 4669, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i wonder who bill saw and liked mary. [SEP]']
[Init] best rec loss: 0.7765577435493469 for ['[CLS] term acute turner ren reunion streets strikes still preservation [SEP]']
[Init] best rec loss: 0.7713543772697449 for ['[CLS] noah entire guess range significance benji school chores segments [SEP]']
[Init] best rec loss: 0.7669917941093445 for ['[CLS] used emmy mark june enter cy ħ secrets zee [SEP]']
[Init] best rec loss: 0.7652432918548584 for ['[CLS] sign speed die doc spitfire set yes lunch an [SEP]']
[Init] best perm rec loss: 0.7647018432617188 for ['[CLS] lunch die set speed doc an spitfire yes sign [SEP]']
[Init] best perm rec loss: 0.763610303401947 for ['[CLS] set an doc lunch yes sign die speed spitfire [SEP]']
[Init] best perm rec loss: 0.7624984383583069 for ['[CLS] an set lunch spitfire speed yes die sign doc [SEP]']
[Init] best perm rec loss: 0.7623966336250305 for ['[CLS] doc die speed set an sign yes spitfire lunch [SEP]']
[Init] best perm rec loss: 0.760587751865387 for ['[CLS] lunch doc set die speed yes an spitfire sign [SEP]']
[Init] best perm rec loss: 0.7599994540214539 for ['[CLS] speed an doc sign spitfire lunch yes set die [SEP]']
[Init] best perm rec loss: 0.7594751715660095 for ['[CLS] set spitfire speed yes doc die lunch an sign [SEP]']
[Init] best perm rec loss: 0.7593515515327454 for ['[CLS] die speed doc sign an set lunch spitfire yes [SEP]']
[Init] best perm rec loss: 0.7579567432403564 for ['[CLS] lunch speed doc spitfire set an yes die sign [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.014 (perp=11.876, rec=0.448, cos=0.191), tot_loss_proj:3.890 [t=0.23s]
prediction: ["[CLS] thinking'whenulsion blue priest attended bill connacht [SEP]"]
[ 100/2000] tot_loss=2.425 (perp=9.332, rec=0.357, cos=0.202), tot_loss_proj:3.290 [t=0.23s]
prediction: ['[CLS] wonder wonder who violent mary and admired mary mary [SEP]']
[ 150/2000] tot_loss=2.563 (perp=10.521, rec=0.283, cos=0.175), tot_loss_proj:3.325 [t=0.23s]
prediction: ['[CLS] wonder wonder who龸 mary and liked mary mary [SEP]']
[ 200/2000] tot_loss=2.436 (perp=10.354, rec=0.187, cos=0.178), tot_loss_proj:3.460 [t=0.23s]
prediction: ['[CLS] wonder wonder who bill bill and liked mary mary [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.374 (perp=8.832, rec=0.450, cos=0.158), tot_loss_proj:2.867 [t=0.23s]
prediction: ['[CLS] wonder wonder who bill mary and liked bill mary [SEP]']
[ 300/2000] tot_loss=2.651 (perp=10.642, rec=0.353, cos=0.170), tot_loss_proj:3.661 [t=0.23s]
prediction: ['[CLS] wonder wondered who bill mary and liked families mary [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.260 (perp=9.017, rec=0.269, cos=0.188), tot_loss_proj:3.210 [t=0.23s]
prediction: ['[CLS] wonder wonder who liked families bill mary and mary [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.211 (perp=9.017, rec=0.220, cos=0.188), tot_loss_proj:3.221 [t=0.23s]
prediction: ['[CLS] wonder wonder who liked families bill mary and mary [SEP]']
[ 450/2000] tot_loss=2.059 (perp=8.432, rec=0.193, cos=0.180), tot_loss_proj:3.170 [t=0.23s]
prediction: ['[CLS] wonder says who liked bill bill mary and mary [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.895 (perp=7.625, rec=0.189, cos=0.181), tot_loss_proj:2.667 [t=0.23s]
prediction: ['[CLS] wonder says who liked bill mary and bill mary [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.989 (perp=8.125, rec=0.181, cos=0.183), tot_loss_proj:2.740 [t=0.23s]
prediction: ['[CLS] wonder says who saw bill mary and bill mary [SEP]']
[ 600/2000] tot_loss=1.970 (perp=8.125, rec=0.162, cos=0.183), tot_loss_proj:2.735 [t=0.23s]
prediction: ['[CLS] wonder says who saw bill mary and bill mary [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.195 (perp=9.224, rec=0.168, cos=0.182), tot_loss_proj:3.054 [t=0.23s]
prediction: ['[CLS] wonder says who saw bill mary and bill hips [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.196 (perp=9.224, rec=0.168, cos=0.183), tot_loss_proj:3.053 [t=0.23s]
prediction: ['[CLS] wonder says who saw bill mary and bill hips [SEP]']
[ 750/2000] tot_loss=2.312 (perp=9.847, rec=0.157, cos=0.186), tot_loss_proj:3.258 [t=0.23s]
prediction: ['[CLS] wonder sees who saw bill mary and bill hips [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.304 (perp=9.788, rec=0.160, cos=0.186), tot_loss_proj:3.155 [t=0.23s]
prediction: ['[CLS] says wonder who saw bill mary and liked hips [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.968 (perp=8.150, rec=0.149, cos=0.189), tot_loss_proj:2.470 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked hips [SEP]']
[ 900/2000] tot_loss=1.964 (perp=8.150, rec=0.144, cos=0.190), tot_loss_proj:2.471 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked hips [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.992 (perp=8.346, rec=0.133, cos=0.189), tot_loss_proj:2.481 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1000/2000] tot_loss=1.985 (perp=8.346, rec=0.125, cos=0.190), tot_loss_proj:2.485 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
[1050/2000] tot_loss=1.994 (perp=8.346, rec=0.136, cos=0.189), tot_loss_proj:2.482 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1100/2000] tot_loss=1.984 (perp=8.346, rec=0.125, cos=0.190), tot_loss_proj:2.477 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1150/2000] tot_loss=1.964 (perp=8.346, rec=0.105, cos=0.190), tot_loss_proj:2.481 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
[1200/2000] tot_loss=1.967 (perp=8.346, rec=0.108, cos=0.190), tot_loss_proj:2.480 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1250/2000] tot_loss=1.968 (perp=8.346, rec=0.109, cos=0.190), tot_loss_proj:2.476 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1300/2000] tot_loss=1.958 (perp=8.346, rec=0.099, cos=0.190), tot_loss_proj:2.482 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
[1350/2000] tot_loss=1.949 (perp=8.346, rec=0.090, cos=0.190), tot_loss_proj:2.481 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1400/2000] tot_loss=1.962 (perp=8.346, rec=0.103, cos=0.190), tot_loss_proj:2.474 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1450/2000] tot_loss=1.955 (perp=8.346, rec=0.096, cos=0.190), tot_loss_proj:2.480 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
[1500/2000] tot_loss=1.962 (perp=8.346, rec=0.103, cos=0.190), tot_loss_proj:2.486 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1550/2000] tot_loss=1.950 (perp=8.346, rec=0.091, cos=0.190), tot_loss_proj:2.482 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1600/2000] tot_loss=1.965 (perp=8.346, rec=0.106, cos=0.190), tot_loss_proj:2.479 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
[1650/2000] tot_loss=1.966 (perp=8.346, rec=0.107, cos=0.190), tot_loss_proj:2.480 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1700/2000] tot_loss=1.960 (perp=8.346, rec=0.101, cos=0.190), tot_loss_proj:2.478 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1750/2000] tot_loss=1.960 (perp=8.346, rec=0.101, cos=0.190), tot_loss_proj:2.482 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
[1800/2000] tot_loss=1.956 (perp=8.346, rec=0.097, cos=0.190), tot_loss_proj:2.478 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked playstation [SEP]']
Attempt swap
[1850/2000] tot_loss=1.702 (perp=7.057, rec=0.100, cos=0.190), tot_loss_proj:2.542 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.701 (perp=7.057, rec=0.100, cos=0.190), tot_loss_proj:2.545 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked. [SEP]']
[1950/2000] tot_loss=1.698 (perp=7.057, rec=0.096, cos=0.190), tot_loss_proj:2.544 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.695 (perp=7.057, rec=0.093, cos=0.190), tot_loss_proj:2.544 [t=0.23s]
prediction: ['[CLS] i wonder who saw bill mary and liked. [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] i wonder who bill saw and liked mary. [SEP]
========================
predicted: 
========================
[CLS] i wonder who saw bill mary and liked playstation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 42.105 | p: 40.000 | r: 44.444
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 137.343

[Aggregate metrics]:
rouge1     | fm: 94.037 | p: 92.955 | r: 95.227
rouge2     | fm: 32.887 | p: 32.361 | r: 33.472
rougeL     | fm: 74.729 | p: 73.864 | r: 75.682
rougeLsum  | fm: 74.729 | p: 73.864 | r: 75.682
r1fm+r2fm = 126.924

input #3 time: 0:09:10 | total time: 0:36:50


Running input #4 of 100.
reference: 
========================
While I might want to, this is the kind of thing that Harris has already suggested.
========================
average of cosine similarity 0.8622889671245351
highest_index [0]
highest [0.8622889671245351]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2096, 1045, 2453, 2215, 2000, 1010, 2023, 2003, 1996, 2785, 1997,
         2518, 2008, 5671, 2038, 2525, 4081, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]']
[Init] best rec loss: 0.9487339854240417 for ['[CLS] june stuffed eponymousdaepathic white bump earth critical security tata fraa area che range soory [SEP]']
[Init] best rec loss: 0.9464805126190186 for ['[CLS] bhutan alexa well custom field was handling lists runner gracieroiural virtually foreign umbrella vision miss signed [SEP]']
[Init] best rec loss: 0.9441022872924805 for ['[CLS] star [CLS] brush / toes newsletter personalis guitar britney madagascar anywhere savannah but injuries palace hen nice [SEP]']
[Init] best rec loss: 0.9430301189422607 for ['[CLS] somethingiferous maintenance survival chargesised building sallyimus resigned glass particularlynut battleet believing asean anglo [SEP]']
[Init] best rec loss: 0.9319204688072205 for ['[CLS] hand below jeff man olympic thingliga skating himself nedra advantage contemporary handled five around sake response viva [SEP]']
[Init] best perm rec loss: 0.9317887425422668 for ['[CLS] nedra sake contemporary handled skating man five below vivaliga around hand response himself thing jeff advantage olympic [SEP]']
[Init] best perm rec loss: 0.930847704410553 for ['[CLS]liga viva skating sake around nedra contemporary jeff below response himself advantage hand man olympic thing handled five [SEP]']
[Init] best perm rec loss: 0.9305674433708191 for ['[CLS] sake man advantage nedra handliga thing response olympic five viva skating jeff contemporary himself handled below around [SEP]']
[Init] best perm rec loss: 0.9277715682983398 for ['[CLS] sake hand thing advantage fiveliga contemporary olympic below nedra skating man jeff viva around handled response himself [SEP]']
[Init] best perm rec loss: 0.9268905520439148 for ['[CLS] man himself olympic five response viva jeff contemporaryliga hand skating thing below advantage sake handled nedra around [SEP]']
[Init] best perm rec loss: 0.9264278411865234 for ['[CLS] advantage contemporary five man olympic below viva jeff response nedra sakeliga himself hand around thing handled skating [SEP]']
[Init] best perm rec loss: 0.9260454177856445 for ['[CLS] nedra skating man viva response thing jeff five hand advantage sake belowliga around handled himself olympic contemporary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.718 (perp=9.992, rec=0.434, cos=0.286), tot_loss_proj:3.907 [t=0.23s]
prediction: ['[CLS] ideas than buckingham whatever enjoy!. its yards arrived through that maybe morton jones.. name [SEP]']
[ 100/2000] tot_loss=2.700 (perp=10.575, rec=0.344, cos=0.240), tot_loss_proj:4.023 [t=0.24s]
prediction: ['[CLS] harris should harris whatever kids!, its salazarrs beside that maybe harris harris.¨ names [SEP]']
[ 150/2000] tot_loss=2.565 (perp=10.039, rec=0.322, cos=0.236), tot_loss_proj:3.941 [t=0.24s]
prediction: ['[CLS] harris should harris whatever kids!. would americana roberta beside. then harris harris. makes announced [SEP]']
[ 200/2000] tot_loss=2.379 (perp=9.307, rec=0.285, cos=0.232), tot_loss_proj:3.765 [t=0.24s]
prediction: ['[CLS] harris should harris whatever kids!. would ox roberta beside. then harris harris. when announced [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.233 (perp=8.583, rec=0.291, cos=0.226), tot_loss_proj:3.617 [t=0.24s]
prediction: ['[CLS] harris might harris whatever kids!, would horror harris beside. then harris premium. when announced [SEP]']
[ 300/2000] tot_loss=2.409 (perp=9.580, rec=0.261, cos=0.232), tot_loss_proj:3.831 [t=0.24s]
prediction: ['[CLS] harris might i should 501!. which horror harris while. that harrisrs. when announced [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.505 (perp=10.073, rec=0.270, cos=0.221), tot_loss_proj:3.929 [t=0.24s]
prediction: ['[CLS] harris might though should idea!. which although harris really. where harris roberta. when require [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.380 (perp=9.536, rec=0.264, cos=0.209), tot_loss_proj:3.831 [t=0.24s]
prediction: ['[CLS] harris might to should idea!. which while harris ª. that roberta harris. when require [SEP]']
[ 450/2000] tot_loss=2.462 (perp=9.781, rec=0.264, cos=0.241), tot_loss_proj:3.891 [t=0.24s]
prediction: ['[CLS] seems might to should idea what. which while harris ª. that roberta harris. when verbs [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.443 (perp=9.807, rec=0.243, cos=0.239), tot_loss_proj:3.901 [t=0.24s]
prediction: ['[CLS] seems might to idea should we. this while harris ª. that roberta harris. while verbs [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.299 (perp=8.780, rec=0.316, cos=0.227), tot_loss_proj:3.666 [t=0.24s]
prediction: ['[CLS] seems might to thing should what. this while ª harris, this roberta harris. while. [SEP]']
[ 600/2000] tot_loss=2.256 (perp=8.816, rec=0.265, cos=0.228), tot_loss_proj:3.716 [t=0.24s]
prediction: ['[CLS] seems would originally thing should what. this while ª harris. this daryl harris. while. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.222 (perp=8.644, rec=0.253, cos=0.241), tot_loss_proj:3.657 [t=0.24s]
prediction: ['[CLS] might might originally idea should what. this while ª harris. daryl harris. while this. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.393 (perp=9.442, rec=0.260, cos=0.245), tot_loss_proj:3.788 [t=0.24s]
prediction: ['[CLS] ª i originally idea might we. what while might harris.bbs harris. while this. [SEP]']
[ 750/2000] tot_loss=2.221 (perp=8.624, rec=0.234, cos=0.263), tot_loss_proj:3.606 [t=0.24s]
prediction: ['[CLS] ª i to idea might we. what while might harris. guessed occurred. while this. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.172 (perp=8.620, rec=0.228, cos=0.220), tot_loss_proj:3.619 [t=0.24s]
prediction: ['[CLS] ª i to idea might we. what while harris might.bbs occurred. while this. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.248 (perp=8.813, rec=0.224, cos=0.261), tot_loss_proj:3.701 [t=0.24s]
prediction: ['[CLS] ª i to thing might we. this while harris might..bbs occurred while this. [SEP]']
[ 900/2000] tot_loss=2.226 (perp=8.813, rec=0.232, cos=0.232), tot_loss_proj:3.699 [t=0.24s]
prediction: ['[CLS] ª i to thing might we. this while harris might..bbs occurred while this. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.173 (perp=8.547, rec=0.216, cos=0.248), tot_loss_proj:3.645 [t=0.24s]
prediction: ['[CLS] i ª to thing might we. this while harris might..bbs occurred while this. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.079 (perp=7.967, rec=0.230, cos=0.255), tot_loss_proj:3.489 [t=0.24s]
prediction: ['[CLS] i ª might thing toª. this while harris might..bbs has while this. [SEP]']
[1050/2000] tot_loss=2.036 (perp=7.860, rec=0.218, cos=0.245), tot_loss_proj:3.453 [t=0.24s]
prediction: ['[CLS] i ª might thing toª. what while harris might..bbs has while this. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.015 (perp=7.700, rec=0.230, cos=0.245), tot_loss_proj:3.413 [t=0.24s]
prediction: ['[CLS] i ª might thing toª. what while harris might..bbs has this while. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.001 (perp=7.700, rec=0.209, cos=0.252), tot_loss_proj:3.415 [t=0.24s]
prediction: ['[CLS] i ª might thing toª. what while harris might..bbs has this while. [SEP]']
[1200/2000] tot_loss=2.011 (perp=7.757, rec=0.216, cos=0.243), tot_loss_proj:3.459 [t=0.24s]
prediction: ['[CLS] i ª might thing toª. someday while harris might.. guessed has this while. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.963 (perp=7.542, rec=0.207, cos=0.248), tot_loss_proj:3.428 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday while harris might.. guessed has this while. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.950 (perp=7.390, rec=0.223, cos=0.249), tot_loss_proj:3.401 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday while harris might.. has guessed this while. [SEP]']
[1350/2000] tot_loss=1.949 (perp=7.390, rec=0.221, cos=0.249), tot_loss_proj:3.396 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday while harris might.. has guessed this while. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.937 (perp=7.390, rec=0.209, cos=0.250), tot_loss_proj:3.396 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday while harris might.. has guessed this while. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.953 (perp=7.390, rec=0.215, cos=0.259), tot_loss_proj:3.402 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday while harris might.. has guessed this while. [SEP]']
[1500/2000] tot_loss=1.933 (perp=7.390, rec=0.201, cos=0.254), tot_loss_proj:3.394 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday while harris might.. has guessed this while. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.035 (perp=7.875, rec=0.211, cos=0.249), tot_loss_proj:3.491 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday while harris might,. has guessed this while. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.008 (perp=7.718, rec=0.212, cos=0.253), tot_loss_proj:3.466 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday harris might, while. has guessed this while. [SEP]']
[1650/2000] tot_loss=2.008 (perp=7.718, rec=0.214, cos=0.251), tot_loss_proj:3.466 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday harris might, while. has guessed this while. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.013 (perp=7.718, rec=0.217, cos=0.252), tot_loss_proj:3.462 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday harris might, while. has guessed this while. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.943 (perp=7.467, rec=0.204, cos=0.245), tot_loss_proj:3.397 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday, might, while harris has guessed this while. [SEP]']
[1800/2000] tot_loss=1.954 (perp=7.467, rec=0.207, cos=0.253), tot_loss_proj:3.397 [t=0.30s]
prediction: ['[CLS] i ª might thing toː. someday, might, while harris has guessed this while. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.975 (perp=7.560, rec=0.207, cos=0.256), tot_loss_proj:3.418 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday, might. while harris has guessed this while. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.978 (perp=7.560, rec=0.215, cos=0.252), tot_loss_proj:3.417 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday, might. while harris has guessed this while. [SEP]']
[1950/2000] tot_loss=1.986 (perp=7.560, rec=0.218, cos=0.257), tot_loss_proj:3.419 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday, might. while harris has guessed this while. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.973 (perp=7.477, rec=0.222, cos=0.256), tot_loss_proj:3.414 [t=0.24s]
prediction: ['[CLS] i ª might thing toː. someday, might while, harris has guessed this while. [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]
========================
predicted: 
========================
[CLS] i ª might thing toː. someday, might. while harris has guessed this while. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.500 | p: 71.429 | r: 55.556
rouge2     | fm: 13.333 | p: 15.385 | r: 11.765
rougeL     | fm: 43.750 | p: 50.000 | r: 38.889
rougeLsum  | fm: 43.750 | p: 50.000 | r: 38.889
r1fm+r2fm = 75.833

[Aggregate metrics]:
rouge1     | fm: 88.595 | p: 88.831 | r: 87.475
rouge2     | fm: 28.977 | p: 28.966 | r: 29.131
rougeL     | fm: 69.079 | p: 69.091 | r: 68.869
rougeLsum  | fm: 68.750 | p: 69.091 | r: 68.869
r1fm+r2fm = 117.572

input #4 time: 0:09:19 | total time: 0:46:09


Running input #5 of 100.
reference: 
========================
Who has seen my snorkel?
========================
average of cosine similarity 0.9159670836261515
highest_index [0]
highest [0.9159670836261515]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2040,  2038,  2464,  2026,  1055, 12131, 11705,  1029,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] who has seen my snorkel? [SEP]']
[Init] best rec loss: 0.9561435580253601 for ['[CLS] second lot dimensions absolutelyavia nuclear second century [SEP]']
[Init] best rec loss: 0.9090735912322998 for ['[CLS] softzzled 10 dark ob subscription fury cold [SEP]']
[Init] best rec loss: 0.8980128765106201 for ['[CLS] flesh stakeade smack church teeth hostedense [SEP]']
[Init] best rec loss: 0.891254723072052 for ['[CLS] personarricular carbon bound stafforaicative across [SEP]']
[Init] best rec loss: 0.8905366063117981 for ['[CLS] an chance say gottenley item rock sons [SEP]']
[Init] best rec loss: 0.8879683613777161 for ['[CLS] garrison everything pie credittative ahead father full [SEP]']
[Init] best rec loss: 0.8710644245147705 for ['[CLS] sphere dobbe afwana after leader phone [SEP]']
[Init] best perm rec loss: 0.8706889152526855 for ['[CLS] do leaderwana afterbbe sphere phone af [SEP]']
[Init] best perm rec loss: 0.8666442632675171 for ['[CLS]wana phone leader afterbbe do sphere af [SEP]']
[Init] best perm rec loss: 0.866455614566803 for ['[CLS] leaderwana af phonebbe sphere after do [SEP]']
[Init] best perm rec loss: 0.8640395402908325 for ['[CLS]wana af phonebbe sphere after leader do [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.856 (perp=11.774, rec=0.344, cos=0.157), tot_loss_proj:4.246 [t=0.23s]
prediction: ['[CLS] jill is fatal shark who 2018norio [SEP]']
[ 100/2000] tot_loss=2.595 (perp=10.865, rec=0.271, cos=0.151), tot_loss_proj:4.080 [t=0.23s]
prediction: ['[CLS] k who havenornor whonorkel [SEP]']
[ 150/2000] tot_loss=2.165 (perp=8.976, rec=0.235, cos=0.134), tot_loss_proj:3.585 [t=0.23s]
prediction: ['[CLS] who who has becomenor?norkel [SEP]']
[ 200/2000] tot_loss=1.908 (perp=8.318, rec=0.089, cos=0.156), tot_loss_proj:2.910 [t=0.23s]
prediction: ['[CLS] who who has seen my?norkel [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.628 (perp=6.945, rec=0.084, cos=0.156), tot_loss_proj:3.145 [t=0.23s]
prediction: ['[CLS] who who has seen mynorkel? [SEP]']
[ 300/2000] tot_loss=1.612 (perp=6.945, rec=0.064, cos=0.160), tot_loss_proj:3.160 [t=0.23s]
prediction: ['[CLS] who who has seen mynorkel? [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.588 (perp=6.834, rec=0.062, cos=0.158), tot_loss_proj:3.281 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.600 (perp=6.834, rec=0.073, cos=0.160), tot_loss_proj:3.284 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
[ 450/2000] tot_loss=1.595 (perp=6.834, rec=0.068, cos=0.160), tot_loss_proj:3.282 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.591 (perp=6.834, rec=0.063, cos=0.161), tot_loss_proj:3.277 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.595 (perp=6.834, rec=0.067, cos=0.160), tot_loss_proj:3.283 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
[ 600/2000] tot_loss=1.587 (perp=6.834, rec=0.060, cos=0.161), tot_loss_proj:3.280 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.587 (perp=6.834, rec=0.060, cos=0.161), tot_loss_proj:3.282 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.585 (perp=6.834, rec=0.058, cos=0.160), tot_loss_proj:3.284 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
[ 750/2000] tot_loss=1.595 (perp=6.834, rec=0.068, cos=0.161), tot_loss_proj:3.281 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.594 (perp=6.834, rec=0.067, cos=0.161), tot_loss_proj:3.285 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.598 (perp=6.834, rec=0.070, cos=0.161), tot_loss_proj:3.281 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
[ 900/2000] tot_loss=1.596 (perp=6.834, rec=0.069, cos=0.160), tot_loss_proj:3.288 [t=0.23s]
prediction: ['[CLS] who has seen who mynorkel? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.663 (perp=7.169, rec=0.068, cos=0.160), tot_loss_proj:2.967 [t=0.23s]
prediction: ['[CLS] who has seen m mynorkel? [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.612 (perp=6.933, rec=0.066, cos=0.159), tot_loss_proj:3.105 [t=0.23s]
prediction: ['[CLS] m who has seen mynorkel? [SEP]']
[1050/2000] tot_loss=1.616 (perp=6.933, rec=0.069, cos=0.160), tot_loss_proj:3.105 [t=0.23s]
prediction: ['[CLS] m who has seen mynorkel? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.606 (perp=6.933, rec=0.059, cos=0.160), tot_loss_proj:3.106 [t=0.23s]
prediction: ['[CLS] m who has seen mynorkel? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.615 (perp=6.933, rec=0.068, cos=0.160), tot_loss_proj:3.108 [t=0.23s]
prediction: ['[CLS] m who has seen mynorkel? [SEP]']
[1200/2000] tot_loss=1.645 (perp=7.091, rec=0.066, cos=0.161), tot_loss_proj:3.209 [t=0.23s]
prediction: ['[CLS] s who has seen mynorkel? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.651 (perp=7.091, rec=0.072, cos=0.161), tot_loss_proj:3.208 [t=0.23s]
prediction: ['[CLS] s who has seen mynorkel? [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.740 (perp=7.557, rec=0.072, cos=0.156), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] who has seen my mnorkel? [SEP]']
[1350/2000] tot_loss=1.506 (perp=6.407, rec=0.066, cos=0.159), tot_loss_proj:1.562 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.507 (perp=6.407, rec=0.065, cos=0.160), tot_loss_proj:1.539 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.503 (perp=6.407, rec=0.062, cos=0.160), tot_loss_proj:1.554 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
[1500/2000] tot_loss=1.507 (perp=6.407, rec=0.065, cos=0.160), tot_loss_proj:1.550 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.504 (perp=6.407, rec=0.062, cos=0.161), tot_loss_proj:1.551 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.507 (perp=6.407, rec=0.065, cos=0.161), tot_loss_proj:1.551 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
[1650/2000] tot_loss=1.513 (perp=6.407, rec=0.070, cos=0.161), tot_loss_proj:1.554 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.513 (perp=6.407, rec=0.071, cos=0.161), tot_loss_proj:1.554 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.498 (perp=6.407, rec=0.056, cos=0.161), tot_loss_proj:1.545 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
[1800/2000] tot_loss=1.511 (perp=6.407, rec=0.070, cos=0.160), tot_loss_proj:1.558 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.510 (perp=6.407, rec=0.068, cos=0.161), tot_loss_proj:1.546 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.505 (perp=6.407, rec=0.063, cos=0.161), tot_loss_proj:1.552 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
[1950/2000] tot_loss=1.509 (perp=6.407, rec=0.067, cos=0.160), tot_loss_proj:1.544 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.502 (perp=6.407, rec=0.059, cos=0.161), tot_loss_proj:1.543 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] who has seen my snorkel? [SEP]
========================
predicted: 
========================
[CLS] s who has seen mynorkel? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 104.762

[Aggregate metrics]:
rouge1     | fm: 85.655 | p: 85.931 | r: 85.331
rouge2     | fm: 29.759 | p: 29.694 | r: 29.831
rougeL     | fm: 69.233 | p: 69.697 | r: 69.057
rougeLsum  | fm: 69.413 | p: 69.697 | r: 69.295
r1fm+r2fm = 115.414

input #5 time: 0:09:11 | total time: 0:55:21


Running input #6 of 100.
reference: 
========================
Which goddess helped us?
========================
average of cosine similarity 0.9196210277761339
highest_index [0]
highest [0.9196210277761339]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2029, 7804, 3271, 2149, 1029,  102]], device='cuda:0')
Debug: ref = ['[CLS] which goddess helped us? [SEP]']
[Init] best rec loss: 0.9496093392372131 for ['[CLS] naked scoring southeastvyn taliban [SEP]']
[Init] best rec loss: 0.901202917098999 for ['[CLS]lassified combat effective mutual honor [SEP]']
[Init] best rec loss: 0.8915270566940308 for ['[CLS] curve splinter atop aquatic lunch [SEP]']
[Init] best rec loss: 0.8830668330192566 for ['[CLS] direct entirely lance munster spot [SEP]']
[Init] best rec loss: 0.8739834427833557 for ['[CLS] philanthropy theatre braid sexualmons [SEP]']
[Init] best rec loss: 0.8734817504882812 for ['[CLS] united candidate prevent talbot town [SEP]']
[Init] best rec loss: 0.8732259273529053 for ['[CLS] diver ;apes plasticiation [SEP]']
[Init] best rec loss: 0.8730324506759644 for ['[CLS] distribution everywhere other lines forte [SEP]']
[Init] best rec loss: 0.8162003755569458 for ['[CLS]nation convenient heal exactly ljubljana [SEP]']
[Init] best perm rec loss: 0.8113428354263306 for ['[CLS] heal exactlynation convenient ljubljana [SEP]']
[Init] best perm rec loss: 0.810204803943634 for ['[CLS] ljubljananation heal convenient exactly [SEP]']
[Init] best perm rec loss: 0.810120701789856 for ['[CLS]nation heal ljubljana convenient exactly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.595 (perp=10.489, rec=0.345, cos=0.153), tot_loss_proj:3.952 [t=0.23s]
prediction: ['[CLS]? other waverift which [SEP]']
[ 100/2000] tot_loss=2.387 (perp=10.275, rec=0.182, cos=0.150), tot_loss_proj:3.927 [t=0.23s]
prediction: ['[CLS]? goddess helped goddess which [SEP]']
[ 150/2000] tot_loss=2.134 (perp=9.563, rec=0.068, cos=0.154), tot_loss_proj:3.781 [t=0.23s]
prediction: ['[CLS]? goddess helped us which [SEP]']
[ 200/2000] tot_loss=2.134 (perp=9.563, rec=0.068, cos=0.153), tot_loss_proj:3.777 [t=0.23s]
prediction: ['[CLS]? goddess helped us which [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.894 (perp=8.369, rec=0.079, cos=0.141), tot_loss_proj:2.123 [t=0.23s]
prediction: ['[CLS]? which goddess helped us [SEP]']
[ 300/2000] tot_loss=1.892 (perp=8.369, rec=0.066, cos=0.152), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS]? which goddess helped us [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.898 (perp=8.369, rec=0.071, cos=0.153), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS]? which goddess helped us [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.891 (perp=8.369, rec=0.063, cos=0.154), tot_loss_proj:2.133 [t=0.23s]
prediction: ['[CLS]? which goddess helped us [SEP]']
[ 450/2000] tot_loss=1.887 (perp=8.369, rec=0.059, cos=0.154), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS]? which goddess helped us [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.887 (perp=8.369, rec=0.059, cos=0.154), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS]? which goddess helped us [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.887 (perp=8.369, rec=0.059, cos=0.154), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS]? which goddess helped us [SEP]']
[ 600/2000] tot_loss=1.889 (perp=8.369, rec=0.061, cos=0.154), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS]? which goddess helped us [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.883 (perp=8.369, rec=0.055, cos=0.154), tot_loss_proj:2.135 [t=0.23s]
prediction: ['[CLS]? which goddess helped us [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.894 (perp=8.369, rec=0.067, cos=0.153), tot_loss_proj:2.141 [t=0.30s]
prediction: ['[CLS]? which goddess helped us [SEP]']
[ 750/2000] tot_loss=1.894 (perp=8.369, rec=0.066, cos=0.154), tot_loss_proj:2.139 [t=0.23s]
prediction: ['[CLS]? which goddess helped us [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.865 (perp=8.279, rec=0.057, cos=0.153), tot_loss_proj:3.386 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.867 (perp=8.279, rec=0.057, cos=0.154), tot_loss_proj:3.379 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
[ 900/2000] tot_loss=1.871 (perp=8.279, rec=0.061, cos=0.154), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.879 (perp=8.279, rec=0.069, cos=0.154), tot_loss_proj:3.393 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1000/2000] tot_loss=1.868 (perp=8.279, rec=0.058, cos=0.154), tot_loss_proj:3.383 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
[1050/2000] tot_loss=1.864 (perp=8.279, rec=0.054, cos=0.154), tot_loss_proj:3.377 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1100/2000] tot_loss=1.873 (perp=8.279, rec=0.063, cos=0.154), tot_loss_proj:3.383 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1150/2000] tot_loss=1.867 (perp=8.279, rec=0.058, cos=0.154), tot_loss_proj:3.387 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
[1200/2000] tot_loss=1.878 (perp=8.279, rec=0.069, cos=0.154), tot_loss_proj:3.381 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1250/2000] tot_loss=1.855 (perp=8.279, rec=0.045, cos=0.154), tot_loss_proj:3.386 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1300/2000] tot_loss=1.870 (perp=8.279, rec=0.061, cos=0.154), tot_loss_proj:3.384 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
[1350/2000] tot_loss=1.874 (perp=8.279, rec=0.065, cos=0.154), tot_loss_proj:3.383 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1400/2000] tot_loss=1.855 (perp=8.279, rec=0.046, cos=0.154), tot_loss_proj:3.385 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1450/2000] tot_loss=1.872 (perp=8.279, rec=0.063, cos=0.154), tot_loss_proj:3.386 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
[1500/2000] tot_loss=1.868 (perp=8.279, rec=0.058, cos=0.154), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1550/2000] tot_loss=1.869 (perp=8.279, rec=0.059, cos=0.154), tot_loss_proj:3.384 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1600/2000] tot_loss=1.889 (perp=8.279, rec=0.079, cos=0.154), tot_loss_proj:3.385 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
[1650/2000] tot_loss=1.883 (perp=8.279, rec=0.073, cos=0.154), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1700/2000] tot_loss=1.877 (perp=8.279, rec=0.068, cos=0.154), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1750/2000] tot_loss=1.875 (perp=8.279, rec=0.065, cos=0.154), tot_loss_proj:3.385 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
[1800/2000] tot_loss=1.868 (perp=8.279, rec=0.058, cos=0.154), tot_loss_proj:3.385 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1850/2000] tot_loss=1.868 (perp=8.279, rec=0.059, cos=0.154), tot_loss_proj:3.379 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[1900/2000] tot_loss=1.866 (perp=8.279, rec=0.056, cos=0.154), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
[1950/2000] tot_loss=1.869 (perp=8.279, rec=0.059, cos=0.154), tot_loss_proj:3.384 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Attempt swap
[2000/2000] tot_loss=1.878 (perp=8.279, rec=0.068, cos=0.154), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] goddess? which helped us [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] which goddess helped us? [SEP]
========================
predicted: 
========================
[CLS]? which goddess helped us [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.772 | p: 87.941 | r: 87.681
rouge2     | fm: 38.793 | p: 38.968 | r: 38.810
rougeL     | fm: 73.452 | p: 73.636 | r: 73.311
rougeLsum  | fm: 73.330 | p: 73.423 | r: 73.344
r1fm+r2fm = 126.565

input #6 time: 0:09:09 | total time: 1:04:30


Running input #7 of 100.
reference: 
========================
They have no old.
========================
average of cosine similarity 0.8970208032018148
highest_index [0]
highest [0.8970208032018148]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2027, 2031, 2053, 2214, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] they have no old. [SEP]']
[Init] best rec loss: 0.7506218552589417 for ['[CLS] devices buck 1947 business ji [SEP]']
[Init] best rec loss: 0.7265805006027222 for ['[CLS] talk f edited manny huskies [SEP]']
[Init] best rec loss: 0.7134307622909546 for ['[CLS]emi streamed including same rugby [SEP]']
[Init] best rec loss: 0.6964812874794006 for ['[CLS] nopecharged practiced 2011 jersey [SEP]']
[Init] best rec loss: 0.6928263902664185 for ['[CLS] necessary nino shin sensory hank [SEP]']
[Init] best rec loss: 0.6873874664306641 for ['[CLS] cylinder sum expansion died thing [SEP]']
[Init] best rec loss: 0.673957109451294 for ['[CLS] total mfa km² brock gifford [SEP]']
[Init] best rec loss: 0.6717828512191772 for ['[CLS] entertainment expansionound ps till [SEP]']
[Init] best rec loss: 0.6625890135765076 for ['[CLS] card rosa most com sarah [SEP]']
[Init] best rec loss: 0.6492716073989868 for ['[CLS] simultaneously campeonato outside - shown [SEP]']
[Init] best perm rec loss: 0.6486175656318665 for ['[CLS] outside campeonato simultaneously - shown [SEP]']
[Init] best perm rec loss: 0.6471825242042542 for ['[CLS] shown campeonato simultaneously - outside [SEP]']
[Init] best perm rec loss: 0.6447274684906006 for ['[CLS] shown - campeonato simultaneously outside [SEP]']
[Init] best perm rec loss: 0.6446839570999146 for ['[CLS] simultaneously - shown campeonato outside [SEP]']
[Init] best perm rec loss: 0.6445179581642151 for ['[CLS] campeonato shown - simultaneously outside [SEP]']
[Init] best perm rec loss: 0.6423313617706299 for ['[CLS] outside - campeonato simultaneously shown [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.025 (perp=7.728, rec=0.288, cos=0.191), tot_loss_proj:2.897 [t=0.23s]
prediction: ['[CLS] no old has old. [SEP]']
[ 100/2000] tot_loss=1.808 (perp=7.451, rec=0.129, cos=0.189), tot_loss_proj:2.754 [t=0.23s]
prediction: ['[CLS] no old have they. [SEP]']
[ 150/2000] tot_loss=1.757 (perp=7.451, rec=0.075, cos=0.191), tot_loss_proj:2.756 [t=0.23s]
prediction: ['[CLS] no old have they. [SEP]']
[ 200/2000] tot_loss=1.754 (perp=7.451, rec=0.073, cos=0.191), tot_loss_proj:2.754 [t=0.23s]
prediction: ['[CLS] no old have they. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.606 (perp=6.689, rec=0.077, cos=0.191), tot_loss_proj:2.171 [t=0.23s]
prediction: ['[CLS] they old have no. [SEP]']
[ 300/2000] tot_loss=1.608 (perp=6.689, rec=0.079, cos=0.191), tot_loss_proj:2.164 [t=0.23s]
prediction: ['[CLS] they old have no. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.423 (perp=5.838, rec=0.066, cos=0.189), tot_loss_proj:1.787 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.421 (perp=5.838, rec=0.063, cos=0.191), tot_loss_proj:1.777 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
[ 450/2000] tot_loss=1.432 (perp=5.838, rec=0.073, cos=0.191), tot_loss_proj:1.782 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.419 (perp=5.838, rec=0.060, cos=0.191), tot_loss_proj:1.769 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.413 (perp=5.838, rec=0.054, cos=0.191), tot_loss_proj:1.780 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
[ 600/2000] tot_loss=1.432 (perp=5.838, rec=0.074, cos=0.191), tot_loss_proj:1.765 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.428 (perp=5.838, rec=0.069, cos=0.191), tot_loss_proj:1.773 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.424 (perp=5.838, rec=0.065, cos=0.191), tot_loss_proj:1.766 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
[ 750/2000] tot_loss=1.423 (perp=5.838, rec=0.064, cos=0.191), tot_loss_proj:1.772 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.422 (perp=5.838, rec=0.064, cos=0.191), tot_loss_proj:1.771 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.424 (perp=5.838, rec=0.066, cos=0.191), tot_loss_proj:1.751 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
[ 900/2000] tot_loss=1.428 (perp=5.838, rec=0.069, cos=0.191), tot_loss_proj:1.758 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.416 (perp=5.838, rec=0.058, cos=0.191), tot_loss_proj:1.751 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.429 (perp=5.838, rec=0.071, cos=0.191), tot_loss_proj:1.763 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
[1050/2000] tot_loss=1.421 (perp=5.838, rec=0.062, cos=0.191), tot_loss_proj:1.757 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.429 (perp=5.838, rec=0.070, cos=0.191), tot_loss_proj:1.759 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.418 (perp=5.838, rec=0.059, cos=0.191), tot_loss_proj:1.758 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
[1200/2000] tot_loss=1.424 (perp=5.838, rec=0.066, cos=0.191), tot_loss_proj:1.760 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.424 (perp=5.838, rec=0.065, cos=0.191), tot_loss_proj:1.746 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.418 (perp=5.838, rec=0.059, cos=0.191), tot_loss_proj:1.756 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
[1350/2000] tot_loss=1.425 (perp=5.838, rec=0.067, cos=0.191), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.426 (perp=5.838, rec=0.067, cos=0.191), tot_loss_proj:1.755 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.422 (perp=5.838, rec=0.064, cos=0.191), tot_loss_proj:1.741 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
[1500/2000] tot_loss=1.428 (perp=5.838, rec=0.069, cos=0.191), tot_loss_proj:1.742 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.430 (perp=5.838, rec=0.072, cos=0.191), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.426 (perp=5.838, rec=0.067, cos=0.191), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
[1650/2000] tot_loss=1.426 (perp=5.838, rec=0.067, cos=0.191), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.431 (perp=5.838, rec=0.073, cos=0.191), tot_loss_proj:1.745 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.422 (perp=5.838, rec=0.064, cos=0.191), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
[1800/2000] tot_loss=1.416 (perp=5.838, rec=0.058, cos=0.191), tot_loss_proj:1.742 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.420 (perp=5.838, rec=0.061, cos=0.191), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.419 (perp=5.838, rec=0.061, cos=0.191), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
[1950/2000] tot_loss=1.422 (perp=5.838, rec=0.064, cos=0.191), tot_loss_proj:1.752 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.435 (perp=5.838, rec=0.077, cos=0.191), tot_loss_proj:1.748 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] they have no old. [SEP]
========================
predicted: 
========================
[CLS] they have no old. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.355 | p: 89.448 | r: 89.558
rouge2     | fm: 46.860 | p: 46.912 | r: 47.014
rougeL     | fm: 76.890 | p: 77.110 | r: 76.809
rougeLsum  | fm: 76.698 | p: 76.948 | r: 76.631
r1fm+r2fm = 136.215

input #7 time: 0:09:08 | total time: 1:13:39


Running input #8 of 100.
reference: 
========================
John tries to meet not Mary.
========================
average of cosine similarity 0.8844326736807034
highest_index [0]
highest [0.8844326736807034]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2198, 5363, 2000, 3113, 2025, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] john tries to meet not mary. [SEP]']
[Init] best rec loss: 0.8328288197517395 for ['[CLS]udeau secretary steinerc pennypeed press [SEP]']
[Init] best rec loss: 0.7541090846061707 for ['[CLS] fresh contact beaten image angle form confederate [SEP]']
[Init] best rec loss: 0.7467711567878723 for ['[CLS]av nautical tuition jump ability that revolution [SEP]']
[Init] best rec loss: 0.7305974960327148 for ['[CLS] further big instance schedule ahead caftium [SEP]']
[Init] best rec loss: 0.7108619809150696 for ['[CLS] judge no will power us missing cry [SEP]']
[Init] best perm rec loss: 0.7074334025382996 for ['[CLS] judge will missing us no cry power [SEP]']
[Init] best perm rec loss: 0.7052410840988159 for ['[CLS] cry missing us judge no power will [SEP]']
[Init] best perm rec loss: 0.705025315284729 for ['[CLS] will judge power no cry us missing [SEP]']
[Init] best perm rec loss: 0.7033867239952087 for ['[CLS] judge cry power missing no us will [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.273 (perp=8.642, rec=0.338, cos=0.208), tot_loss_proj:2.672 [t=0.23s]
prediction: ['[CLS] judge became to not fly grow. [SEP]']
[ 100/2000] tot_loss=2.052 (perp=7.789, rec=0.278, cos=0.217), tot_loss_proj:2.344 [t=0.23s]
prediction: ['[CLS] meet became to not mary mary. [SEP]']
[ 150/2000] tot_loss=1.855 (perp=7.140, rec=0.209, cos=0.218), tot_loss_proj:2.279 [t=0.23s]
prediction: ['[CLS] meet tries to not mary mary. [SEP]']
[ 200/2000] tot_loss=1.806 (perp=7.140, rec=0.166, cos=0.213), tot_loss_proj:2.276 [t=0.23s]
prediction: ['[CLS] meet tries to not mary mary. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.598 (perp=6.089, rec=0.173, cos=0.208), tot_loss_proj:2.953 [t=0.23s]
prediction: ['[CLS] john tries to not meet mary. [SEP]']
[ 300/2000] tot_loss=1.580 (perp=6.089, rec=0.148, cos=0.214), tot_loss_proj:2.947 [t=0.23s]
prediction: ['[CLS] john tries to not meet mary. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.570 (perp=6.089, rec=0.131, cos=0.221), tot_loss_proj:2.940 [t=0.23s]
prediction: ['[CLS] john tries to not meet mary. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.556 (perp=6.089, rec=0.121, cos=0.216), tot_loss_proj:2.950 [t=0.23s]
prediction: ['[CLS] john tries to not meet mary. [SEP]']
[ 450/2000] tot_loss=1.550 (perp=6.089, rec=0.116, cos=0.216), tot_loss_proj:2.949 [t=0.23s]
prediction: ['[CLS] john tries to not meet mary. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.545 (perp=6.089, rec=0.112, cos=0.215), tot_loss_proj:2.948 [t=0.23s]
prediction: ['[CLS] john tries to not meet mary. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.559 (perp=6.089, rec=0.124, cos=0.217), tot_loss_proj:2.943 [t=0.23s]
prediction: ['[CLS] john tries to not meet mary. [SEP]']
[ 600/2000] tot_loss=1.551 (perp=6.089, rec=0.114, cos=0.219), tot_loss_proj:2.944 [t=0.23s]
prediction: ['[CLS] john tries to not meet mary. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.535 (perp=5.884, rec=0.143, cos=0.215), tot_loss_proj:2.941 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.508 (perp=5.884, rec=0.114, cos=0.217), tot_loss_proj:2.940 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
[ 750/2000] tot_loss=1.508 (perp=5.884, rec=0.115, cos=0.216), tot_loss_proj:2.936 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.496 (perp=5.884, rec=0.103, cos=0.216), tot_loss_proj:2.941 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.486 (perp=5.884, rec=0.094, cos=0.215), tot_loss_proj:2.938 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
[ 900/2000] tot_loss=1.498 (perp=5.884, rec=0.106, cos=0.214), tot_loss_proj:2.941 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.502 (perp=5.884, rec=0.108, cos=0.217), tot_loss_proj:2.935 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.500 (perp=5.884, rec=0.106, cos=0.217), tot_loss_proj:2.937 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
[1050/2000] tot_loss=1.490 (perp=5.884, rec=0.095, cos=0.218), tot_loss_proj:2.936 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.505 (perp=5.884, rec=0.113, cos=0.216), tot_loss_proj:2.937 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.495 (perp=5.884, rec=0.101, cos=0.217), tot_loss_proj:2.940 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
[1200/2000] tot_loss=1.492 (perp=5.884, rec=0.098, cos=0.217), tot_loss_proj:2.938 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.498 (perp=5.884, rec=0.104, cos=0.217), tot_loss_proj:2.941 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.516 (perp=5.884, rec=0.124, cos=0.216), tot_loss_proj:2.939 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
[1350/2000] tot_loss=1.502 (perp=5.884, rec=0.108, cos=0.218), tot_loss_proj:2.942 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.513 (perp=5.884, rec=0.120, cos=0.216), tot_loss_proj:2.940 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.494 (perp=5.884, rec=0.101, cos=0.216), tot_loss_proj:2.942 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
[1500/2000] tot_loss=1.516 (perp=5.884, rec=0.123, cos=0.216), tot_loss_proj:2.944 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.497 (perp=5.884, rec=0.103, cos=0.217), tot_loss_proj:2.937 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.503 (perp=5.884, rec=0.108, cos=0.218), tot_loss_proj:2.937 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
[1650/2000] tot_loss=1.494 (perp=5.884, rec=0.100, cos=0.217), tot_loss_proj:2.940 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.488 (perp=5.884, rec=0.094, cos=0.217), tot_loss_proj:2.941 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.485 (perp=5.884, rec=0.091, cos=0.217), tot_loss_proj:2.936 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
[1800/2000] tot_loss=1.507 (perp=5.884, rec=0.113, cos=0.217), tot_loss_proj:2.940 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.505 (perp=5.884, rec=0.112, cos=0.217), tot_loss_proj:2.940 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.500 (perp=5.884, rec=0.106, cos=0.217), tot_loss_proj:2.934 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
[1950/2000] tot_loss=1.499 (perp=5.884, rec=0.104, cos=0.217), tot_loss_proj:2.938 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.510 (perp=5.884, rec=0.116, cos=0.217), tot_loss_proj:2.937 [t=0.23s]
prediction: ['[CLS] john tries not to meet mary. [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS] john tries to meet not mary. [SEP]
========================
predicted: 
========================
[CLS] john tries not to meet mary. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 90.437 | p: 90.620 | r: 90.123
rouge2     | fm: 47.721 | p: 47.693 | r: 47.903
rougeL     | fm: 78.069 | p: 78.265 | r: 78.235
rougeLsum  | fm: 78.403 | p: 78.409 | r: 78.327
r1fm+r2fm = 138.157

input #8 time: 0:09:09 | total time: 1:22:49


Running input #9 of 100.
reference: 
========================
The unidentified victim was apparently struck during the early morning hours.
========================
average of cosine similarity 0.8852839178973664
highest_index [0]
highest [0.8852839178973664]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  1996, 20293,  6778,  2001,  4593,  4930,  2076,  1996,  2220,
          2851,  2847,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]']
[Init] best rec loss: 0.9789266586303711 for ['[CLS]re took vie one ioc reading triangle willmour just grantedated [SEP]']
[Init] best rec loss: 0.9692827463150024 for ['[CLS]hearted rendition ho [CLS] factor supreme satinating concentrate baseman cent sin [SEP]']
[Init] best rec loss: 0.9464656114578247 for ['[CLS] random trips time werewolves cast plus cast ariaep apologizetha owner [SEP]']
[Init] best rec loss: 0.9381954073905945 for ['[CLS] lil ex brothers roll ely tools♦ fusiliers option vi crow gaze [SEP]']
[Init] best rec loss: 0.9310398101806641 for ['[CLS] charlie van percentage july known so ˈ won ivory £ oven fault [SEP]']
[Init] best rec loss: 0.9301230907440186 for ['[CLS] elements middle publishingnds surveillance go art anticipation lungs splitting trap classical [SEP]']
[Init] best rec loss: 0.9144731760025024 for ['[CLS] twinned namely extra holdminating waiting knock swedish below del steel raised [SEP]']
[Init] best rec loss: 0.9123244285583496 for ['[CLS] congo showslastic free 00 horizonceptive widow painting see movie deliver [SEP]']
[Init] best perm rec loss: 0.9085978269577026 for ['[CLS] horizon congo 00 freelastic widow shows painting deliver seeceptive movie [SEP]']
[Init] best perm rec loss: 0.9074745774269104 for ['[CLS] 00lastic congo widow free movie seeceptive painting shows deliver horizon [SEP]']
[Init] best perm rec loss: 0.9046263098716736 for ['[CLS] widow shows horizon 00 see painting freeceptivelastic congo deliver movie [SEP]']
[Init] best perm rec loss: 0.9035171866416931 for ['[CLS] deliver shows horizon seelastic painting congoceptive widow free 00 movie [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.846 (perp=11.801, rec=0.275, cos=0.211), tot_loss_proj:4.122 [t=0.23s]
prediction: ['[CLS] victim series alleged fellow unidentified victim struck struck suspects hours reporter received [SEP]']
[ 100/2000] tot_loss=2.310 (perp=9.650, rec=0.166, cos=0.215), tot_loss_proj:3.682 [t=0.23s]
prediction: ['[CLS] victim was unidentified victim unidentified victim during struck apparently hours missing. [SEP]']
[ 150/2000] tot_loss=2.677 (perp=11.358, rec=0.191, cos=0.215), tot_loss_proj:4.073 [t=0.23s]
prediction: ['[CLS] chemical terribly apparently. unidentified victim during struck early. ds barked [SEP]']
[ 200/2000] tot_loss=2.593 (perp=11.119, rec=0.151, cos=0.218), tot_loss_proj:4.045 [t=0.23s]
prediction: ['[CLS] apparently terribly apparently. unidentified victim during struck during. ds barked [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.301 (perp=9.801, rec=0.127, cos=0.214), tot_loss_proj:3.777 [t=0.23s]
prediction: ['[CLS] barked terribly apparently. unidentified victim during struck early. recorder. [SEP]']
[ 300/2000] tot_loss=2.342 (perp=10.059, rec=0.118, cos=0.212), tot_loss_proj:3.834 [t=0.23s]
prediction: ['[CLS] medical terribly apparently! unidentified victim during struck early. recorder. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.408 (perp=10.420, rec=0.111, cos=0.213), tot_loss_proj:3.924 [t=0.23s]
prediction: ['[CLS] badly apparently medical! unidentified victim during struck early. recorder. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.323 (perp=10.011, rec=0.107, cos=0.214), tot_loss_proj:3.844 [t=0.23s]
prediction: ['[CLS] the apparently medical imprint unidentified victim during struck /. recorder. [SEP]']
[ 450/2000] tot_loss=2.189 (perp=9.346, rec=0.104, cos=0.216), tot_loss_proj:3.724 [t=0.23s]
prediction: ['[CLS] the apparently medical! unidentified victim during struck strokes. recorder. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.188 (perp=9.337, rec=0.107, cos=0.213), tot_loss_proj:3.743 [t=0.23s]
prediction: ['[CLS] the apparently medical! unidentified victim during struck /. recorder. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.100 (perp=8.870, rec=0.112, cos=0.215), tot_loss_proj:3.652 [t=0.23s]
prediction: ['[CLS] the apparently medical! unidentified victim during struck. / recorder. [SEP]']
[ 600/2000] tot_loss=2.103 (perp=8.953, rec=0.096, cos=0.216), tot_loss_proj:3.640 [t=0.23s]
prediction: ['[CLS] the apparently medical! unidentified victim during struck. or recorder. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.064 (perp=8.683, rec=0.112, cos=0.215), tot_loss_proj:3.520 [t=0.23s]
prediction: ['[CLS] the apparently medical. unidentified victim struck during hours badly diseases. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.101 (perp=8.868, rec=0.116, cos=0.211), tot_loss_proj:3.603 [t=0.23s]
prediction: ['[CLS] the apparently medical! unidentified victim badly struck during hours diseases. [SEP]']
[ 750/2000] tot_loss=1.952 (perp=8.099, rec=0.116, cos=0.216), tot_loss_proj:3.451 [t=0.23s]
prediction: ['[CLS] the apparently medical. unidentified victim badly struck during hours hours. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.017 (perp=8.527, rec=0.097, cos=0.215), tot_loss_proj:3.531 [t=0.23s]
prediction: ['[CLS] the apparently! unidentified victim badly struck during medical hours hours. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.747 (perp=7.147, rec=0.103, cos=0.215), tot_loss_proj:2.999 [t=0.23s]
prediction: ['[CLS] the apparently unidentified victim. badly struck during medical hours hours. [SEP]']
[ 900/2000] tot_loss=1.855 (perp=7.697, rec=0.100, cos=0.215), tot_loss_proj:3.420 [t=0.23s]
prediction: ['[CLS] the apparently unidentified victim. badly struck during barked hours hours. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.805 (perp=7.436, rec=0.104, cos=0.214), tot_loss_proj:3.368 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently badly struck during barked hours hours. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.802 (perp=7.436, rec=0.099, cos=0.215), tot_loss_proj:3.371 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently badly struck during barked hours hours. [SEP]']
[1050/2000] tot_loss=1.802 (perp=7.436, rec=0.099, cos=0.216), tot_loss_proj:3.371 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently badly struck during barked hours hours. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.656 (perp=6.755, rec=0.092, cos=0.214), tot_loss_proj:2.953 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during medical hours hours. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.662 (perp=6.755, rec=0.097, cos=0.214), tot_loss_proj:2.954 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during medical hours hours. [SEP]']
[1200/2000] tot_loss=1.666 (perp=6.755, rec=0.100, cos=0.215), tot_loss_proj:2.949 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during medical hours hours. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.670 (perp=6.755, rec=0.103, cos=0.216), tot_loss_proj:2.945 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during medical hours hours. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.659 (perp=6.755, rec=0.092, cos=0.216), tot_loss_proj:2.943 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during medical hours hours. [SEP]']
[1350/2000] tot_loss=1.605 (perp=6.510, rec=0.087, cos=0.216), tot_loss_proj:3.115 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.607 (perp=6.510, rec=0.089, cos=0.216), tot_loss_proj:3.113 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.615 (perp=6.510, rec=0.097, cos=0.216), tot_loss_proj:3.111 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
[1500/2000] tot_loss=1.625 (perp=6.510, rec=0.108, cos=0.216), tot_loss_proj:3.113 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.621 (perp=6.510, rec=0.103, cos=0.216), tot_loss_proj:3.113 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.617 (perp=6.510, rec=0.099, cos=0.216), tot_loss_proj:3.112 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
[1650/2000] tot_loss=1.626 (perp=6.510, rec=0.108, cos=0.216), tot_loss_proj:3.111 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.613 (perp=6.510, rec=0.096, cos=0.216), tot_loss_proj:3.108 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.610 (perp=6.510, rec=0.092, cos=0.216), tot_loss_proj:3.110 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
[1800/2000] tot_loss=1.619 (perp=6.510, rec=0.101, cos=0.216), tot_loss_proj:3.107 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.617 (perp=6.510, rec=0.099, cos=0.216), tot_loss_proj:3.109 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.603 (perp=6.510, rec=0.085, cos=0.216), tot_loss_proj:3.111 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
[1950/2000] tot_loss=1.615 (perp=6.510, rec=0.096, cos=0.216), tot_loss_proj:3.108 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.618 (perp=6.510, rec=0.100, cos=0.216), tot_loss_proj:3.111 [t=0.23s]
prediction: ['[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]
========================
predicted: 
========================
[CLS] the unidentified victim. apparently struck badly during afternoon hours hours. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.000 | p: 75.000 | r: 69.231
rouge2     | fm: 43.478 | p: 45.455 | r: 41.667
rougeL     | fm: 72.000 | p: 75.000 | r: 69.231
rougeLsum  | fm: 72.000 | p: 75.000 | r: 69.231
r1fm+r2fm = 115.478

[Aggregate metrics]:
rouge1     | fm: 88.624 | p: 89.058 | r: 87.978
rouge2     | fm: 47.447 | p: 47.531 | r: 47.341
rougeL     | fm: 77.626 | p: 78.052 | r: 77.243
rougeLsum  | fm: 77.582 | p: 78.063 | r: 77.375
r1fm+r2fm = 136.072

input #9 time: 0:09:09 | total time: 1:31:58


Running input #10 of 100.
reference: 
========================
the logs piled the barge high.
========================
average of cosine similarity 0.8975675146951775
highest_index [0]
highest [0.8975675146951775]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996, 15664, 17835,  1996, 19398,  2152,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the logs piled the barge high. [SEP]']
[Init] best rec loss: 0.75642329454422 for ['[CLS] my honey queensus suchbble [CLS] [SEP]']
[Init] best rec loss: 0.7485436201095581 for ['[CLS] shots acheron outsider associations seed an using [SEP]']
[Init] best rec loss: 0.7344606518745422 for ['[CLS] yan sleeveqa area four alternative zane [SEP]']
[Init] best rec loss: 0.6807236075401306 for ['[CLS] papua sorrow arden [MASK] provides sidri [SEP]']
[Init] best rec loss: 0.6480568647384644 for ['[CLS] excellence stationary bread otherwise heel least least [SEP]']
[Init] best perm rec loss: 0.6262552738189697 for ['[CLS] least otherwise heel excellence stationary bread least [SEP]']
[Init] best perm rec loss: 0.624741792678833 for ['[CLS] least excellence least bread stationary heel otherwise [SEP]']
[Init] best perm rec loss: 0.6246881484985352 for ['[CLS] otherwise excellence least least heel bread stationary [SEP]']
[Init] best perm rec loss: 0.620335578918457 for ['[CLS] least stationary excellence otherwise least heel bread [SEP]']
[Init] best perm rec loss: 0.6184463500976562 for ['[CLS] stationary otherwise least least heel excellence bread [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.008 (perp=12.534, rec=0.310, cos=0.191), tot_loss_proj:3.866 [t=0.23s]
prediction: ['[CLS] logs steam piled stand stairs the logs [SEP]']
[ 100/2000] tot_loss=2.600 (perp=10.678, rec=0.277, cos=0.187), tot_loss_proj:3.079 [t=0.23s]
prediction: ['[CLS] logs piled piled the stairs the logs [SEP]']
[ 150/2000] tot_loss=2.654 (perp=11.245, rec=0.213, cos=0.193), tot_loss_proj:2.953 [t=0.23s]
prediction: ['[CLS] logs piled piled the barge high high [SEP]']
[ 200/2000] tot_loss=2.468 (perp=10.609, rec=0.160, cos=0.186), tot_loss_proj:3.011 [t=0.23s]
prediction: ['[CLS] logs logs piled the the high high [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.219 (perp=8.811, rec=0.261, cos=0.196), tot_loss_proj:2.945 [t=0.23s]
prediction: ['[CLS] the logs piled that logs high high [SEP]']
[ 300/2000] tot_loss=1.968 (perp=8.103, rec=0.163, cos=0.184), tot_loss_proj:2.557 [t=0.23s]
prediction: ['[CLS] the logs piled its logs high high [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.244 (perp=9.519, rec=0.150, cos=0.190), tot_loss_proj:2.755 [t=0.23s]
prediction: ['[CLS] the logs piled high its logs barge [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.065 (perp=8.713, rec=0.132, cos=0.190), tot_loss_proj:2.522 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
[ 450/2000] tot_loss=2.042 (perp=8.713, rec=0.113, cos=0.187), tot_loss_proj:2.523 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.037 (perp=8.713, rec=0.104, cos=0.190), tot_loss_proj:2.532 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.043 (perp=8.713, rec=0.113, cos=0.187), tot_loss_proj:2.532 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
[ 600/2000] tot_loss=2.034 (perp=8.713, rec=0.102, cos=0.190), tot_loss_proj:2.537 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.054 (perp=8.713, rec=0.120, cos=0.191), tot_loss_proj:2.525 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.038 (perp=8.713, rec=0.100, cos=0.195), tot_loss_proj:2.537 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
[ 750/2000] tot_loss=2.024 (perp=8.713, rec=0.093, cos=0.189), tot_loss_proj:2.531 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.017 (perp=8.713, rec=0.085, cos=0.190), tot_loss_proj:2.535 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.032 (perp=8.713, rec=0.099, cos=0.190), tot_loss_proj:2.534 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
[ 900/2000] tot_loss=2.038 (perp=8.713, rec=0.106, cos=0.190), tot_loss_proj:2.529 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.030 (perp=8.713, rec=0.097, cos=0.190), tot_loss_proj:2.537 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
Attempt swap
[1000/2000] tot_loss=2.032 (perp=8.713, rec=0.100, cos=0.190), tot_loss_proj:2.533 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
[1050/2000] tot_loss=2.013 (perp=8.713, rec=0.080, cos=0.190), tot_loss_proj:2.531 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
Attempt swap
[1100/2000] tot_loss=2.026 (perp=8.713, rec=0.093, cos=0.190), tot_loss_proj:2.538 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
Attempt swap
[1150/2000] tot_loss=2.025 (perp=8.713, rec=0.093, cos=0.190), tot_loss_proj:2.537 [t=0.23s]
prediction: ['[CLS] the logs piled high its barge logs [SEP]']
[1200/2000] tot_loss=2.181 (perp=9.488, rec=0.093, cos=0.190), tot_loss_proj:2.954 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Attempt swap
[1250/2000] tot_loss=2.185 (perp=9.488, rec=0.098, cos=0.190), tot_loss_proj:2.957 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Attempt swap
[1300/2000] tot_loss=2.187 (perp=9.488, rec=0.099, cos=0.190), tot_loss_proj:2.953 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
[1350/2000] tot_loss=2.180 (perp=9.488, rec=0.092, cos=0.191), tot_loss_proj:2.952 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Attempt swap
[1400/2000] tot_loss=2.173 (perp=9.488, rec=0.085, cos=0.190), tot_loss_proj:2.957 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Attempt swap
[1450/2000] tot_loss=2.176 (perp=9.488, rec=0.088, cos=0.190), tot_loss_proj:2.953 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
[1500/2000] tot_loss=2.181 (perp=9.488, rec=0.093, cos=0.190), tot_loss_proj:2.959 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Attempt swap
[1550/2000] tot_loss=2.171 (perp=9.488, rec=0.084, cos=0.190), tot_loss_proj:2.951 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Attempt swap
[1600/2000] tot_loss=2.170 (perp=9.488, rec=0.083, cos=0.190), tot_loss_proj:2.950 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
[1650/2000] tot_loss=2.175 (perp=9.488, rec=0.087, cos=0.190), tot_loss_proj:2.947 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Attempt swap
[1700/2000] tot_loss=2.188 (perp=9.488, rec=0.100, cos=0.190), tot_loss_proj:2.952 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Attempt swap
[1750/2000] tot_loss=2.184 (perp=9.488, rec=0.097, cos=0.190), tot_loss_proj:2.952 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
[1800/2000] tot_loss=2.176 (perp=9.488, rec=0.089, cos=0.190), tot_loss_proj:2.954 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Attempt swap
[1850/2000] tot_loss=2.177 (perp=9.488, rec=0.090, cos=0.190), tot_loss_proj:2.958 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Attempt swap
[1900/2000] tot_loss=2.162 (perp=9.488, rec=0.075, cos=0.190), tot_loss_proj:2.960 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
[1950/2000] tot_loss=2.184 (perp=9.488, rec=0.096, cos=0.190), tot_loss_proj:2.952 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Attempt swap
[2000/2000] tot_loss=2.176 (perp=9.488, rec=0.089, cos=0.190), tot_loss_proj:2.958 [t=0.23s]
prediction: ['[CLS] the logs piled highthest barge logs [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] the logs piled the barge high. [SEP]
========================
predicted: 
========================
[CLS] the logs piled highthest barge logs [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 117.857

[Aggregate metrics]:
rouge1     | fm: 87.151 | p: 87.698 | r: 86.886
rouge2     | fm: 46.778 | p: 46.925 | r: 46.777
rougeL     | fm: 77.384 | p: 77.713 | r: 77.069
rougeLsum  | fm: 77.489 | p: 77.850 | r: 77.269
r1fm+r2fm = 133.929

input #10 time: 0:09:09 | total time: 1:41:08


Running input #11 of 100.
reference: 
========================
During the early evening, Saturn can be found in the north, while Jupiter rises in the east.
========================
average of cosine similarity 0.9158031365931211
highest_index [0]
highest [0.9158031365931211]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2076,  1996,  2220,  3944,  1010, 14784,  2064,  2022,  2179,
          1999,  1996,  2167,  1010,  2096, 13035,  9466,  1999,  1996,  2264,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]']
[Init] best rec loss: 0.9688762426376343 for ['[CLS] triedya radcliffe whitney pepper since only ranges beingshibreaker sharedpower kn bn nest o day you detention [SEP]']
[Init] best rec loss: 0.9510740637779236 for ['[CLS] block mort black location storecturing paint humanfeld ] against moon patientsbnerkor work ip whose del shared [SEP]']
[Init] best rec loss: 0.94150710105896 for ['[CLS] degreess become panted eric like there ⟩nt obeyed gwen supernatural living mexicanard consider launch due griffin block [SEP]']
[Init] best rec loss: 0.9287576079368591 for ['[CLS] poster round around globe magic cameo occupation bash label ever mtv unknownh fund ₹ school famous skillsmat sham [SEP]']
[Init] best rec loss: 0.919169008731842 for ['[CLS] looks neither sold transportperationum after winning wade laying co licked deep lea bramont mia absentrosis pub [SEP]']
[Init] best rec loss: 0.9142485857009888 for ['[CLS] eh lashes casetm select capts waysible mail weeks baptist points ribs alex variables score training guy blank [SEP]']
[Init] best rec loss: 0.9031270146369934 for ['[CLS] canoe will applied denise forces walt rule jagged stability wealth captivity off company main hip creeks now review tanner authored [SEP]']
[Init] best rec loss: 0.8968873620033264 for ['[CLS] johnston caravan water scientist carolinal came king proportional fails as straight image okay cooking cap big disney henry false [SEP]']
[Init] best rec loss: 0.8759338855743408 for ['[CLS]ura sho modernmat lawtric language benefit others genus behind patentbourg pride guy chin ass polarmoralrius [SEP]']
[Init] best rec loss: 0.8643195629119873 for ['[CLS] internetjectedaa past implyhopper dragoncturing levels endowment callum precedingス barrett voyage integral duties centimeters rush first [SEP]']
[Init] best perm rec loss: 0.8640782833099365 for ['[CLS] barrett preceding callum internet firsthopper levelsaa imply integral endowment voyage centimeters rushjectedスcturing dragon duties past [SEP]']
[Init] best perm rec loss: 0.8639196753501892 for ['[CLS] levels voyage imply first integral internet endowment barrettス callum pasthopper dragon centimetersjected preceding rushaa dutiescturing [SEP]']
[Init] best perm rec loss: 0.8612062931060791 for ['[CLS] endowment barrett voyage past imply first internet integralaa callum centimeters levelshopper duties rush preceding dragoncturingスjected [SEP]']
[Init] best perm rec loss: 0.8597118854522705 for ['[CLS] levels firstaa pastjected barrett voyage preceding internet dragon rush duties implyス endowmenthopper callum centimeters integralcturing [SEP]']
[Init] best perm rec loss: 0.8578342199325562 for ['[CLS] voyagejected callum past first internetス integral dragonhopper rush levelscturing barrett preceding centimeters endowment imply dutiesaa [SEP]']
[Init] best perm rec loss: 0.8570381999015808 for ['[CLS] voyagehopper endowmentaa internetcturing dragon first pastス duties callum centimeters integral barrettjected levels imply rush preceding [SEP]']
[Init] best perm rec loss: 0.8569869995117188 for ['[CLS]ス centimetershopper preceding barrett dutiescturing internet first dragon imply endowment rush past integral callumjected levelsaa voyage [SEP]']
[Init] best perm rec loss: 0.856006920337677 for ['[CLS] endowment barrett dutiescturing past integralaa firstス callum centimeters internet levels precedinghopper imply dragon rush voyagejected [SEP]']
[Init] best perm rec loss: 0.8550636768341064 for ['[CLS] dragonhopper duties levels centimeters preceding integral endowmentaa voyage rush first internet barrett callum implyス pastjectedcturing [SEP]']
[Init] best perm rec loss: 0.8538969159126282 for ['[CLS]cturing internet imply integralスjected dragon dutiesaa centimetershopper first levels endowment past callum preceding rush barrett voyage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.783 (perp=11.405, rec=0.345, cos=0.157), tot_loss_proj:4.142 [t=0.23s]
prediction: ['[CLS] november jupiter ; king soprano emperor storm wasma col before with saturn ( upper child interrupted.ldon saturn [SEP]']
[ 100/2000] tot_loss=2.240 (perp=9.245, rec=0.247, cos=0.144), tot_loss_proj:3.716 [t=0.23s]
prediction: ['[CLS] november jupiter evening saturn saturn saturn bronze was on back by from saturn during evening ) mercedes.ldon saturn [SEP]']
[ 150/2000] tot_loss=2.589 (perp=10.737, rec=0.300, cos=0.141), tot_loss_proj:3.959 [t=0.24s]
prediction: ['[CLS] while saturn evening saint jupiter jupiter negative isma off early. jupiter during evening while lower janeiro ᅩ saturn [SEP]']
[ 200/2000] tot_loss=2.466 (perp=10.477, rec=0.221, cos=0.149), tot_loss_proj:3.917 [t=0.24s]
prediction: ['[CLS] during saturn evening etc jupiter greater ; is, back early. jupiter during evening while lower angel intermediate saturn [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.546 (perp=10.945, rec=0.212, cos=0.144), tot_loss_proj:4.022 [t=0.24s]
prediction: ['[CLS] during early evening supreme jupiter saturn during is, back saturn. jupiter during evening while lower universeachal saturn [SEP]']
[ 300/2000] tot_loss=2.538 (perp=10.945, rec=0.193, cos=0.156), tot_loss_proj:4.019 [t=0.24s]
prediction: ['[CLS] during early evening supreme jupiter saturn during is, back saturn. jupiter during evening while lower universeachal saturn [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.233 (perp=9.482, rec=0.177, cos=0.160), tot_loss_proj:3.758 [t=0.24s]
prediction: ['[CLS] during early evening jupiter yong saturn among rises, back saturn ; jupiter during evening while lower universe north saturn [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.341 (perp=9.961, rec=0.198, cos=0.150), tot_loss_proj:3.842 [t=0.24s]
prediction: ['[CLS] during early evening. especially whenever in rises, lower saturn. jupiter during evening while cliff vice horizon saturn [SEP]']
[ 450/2000] tot_loss=2.406 (perp=10.389, rec=0.168, cos=0.160), tot_loss_proj:3.916 [t=0.24s]
prediction: ['[CLS] during early broad. especially whenever in rises, lower saturn ; jupiter during evening while cliff vice north saturn [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.179 (perp=9.250, rec=0.174, cos=0.155), tot_loss_proj:3.695 [t=0.24s]
prediction: ['[CLS] during early broad. upon. in rises, lower saturn ; jupiter the evening while pacific whenever north saturn [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.093 (perp=8.885, rec=0.170, cos=0.146), tot_loss_proj:3.631 [t=0.24s]
prediction: ['[CLS] during early broad. upon. in rises, lower saturn ; jupiter the evening while saturn whenever north pacific [SEP]']
[ 600/2000] tot_loss=2.061 (perp=8.678, rec=0.169, cos=0.157), tot_loss_proj:3.586 [t=0.24s]
prediction: ['[CLS] during early broad. upon. in rises, in saturn ; jupiter the evening while saturn whenever north pacific [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.068 (perp=8.784, rec=0.159, cos=0.152), tot_loss_proj:3.573 [t=0.24s]
prediction: ['[CLS] during early broad. upon pacific in rises, in saturn ; jupiter the evening while saturn whenever north ; [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.071 (perp=8.810, rec=0.154, cos=0.155), tot_loss_proj:3.576 [t=0.24s]
prediction: ['[CLS] during early broad. july pacific in rises, in saturn ; jupiter the evening while saturn whenever east. [SEP]']
[ 750/2000] tot_loss=2.076 (perp=8.810, rec=0.156, cos=0.159), tot_loss_proj:3.571 [t=0.24s]
prediction: ['[CLS] during early broad. july pacific in rises, in saturn ; jupiter the evening while saturn whenever east. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.968 (perp=8.282, rec=0.158, cos=0.154), tot_loss_proj:3.490 [t=0.24s]
prediction: ['[CLS] during early broad. whenever pacific in rises, in saturn ; jupiter the evening while saturn july east. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.951 (perp=8.158, rec=0.157, cos=0.163), tot_loss_proj:3.450 [t=0.24s]
prediction: ['[CLS] during early pacific. whenever narrow in rises, in saturn ; jupiter the evening while saturn july east. [SEP]']
[ 900/2000] tot_loss=1.945 (perp=8.158, rec=0.156, cos=0.157), tot_loss_proj:3.450 [t=0.24s]
prediction: ['[CLS] during early pacific. whenever narrow in rises, in saturn ; jupiter the evening while saturn july east. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.845 (perp=7.684, rec=0.151, cos=0.158), tot_loss_proj:3.371 [t=0.24s]
prediction: ['[CLS] during early pacific. wheneverward is rises, in saturn in jupiter the evening while saturn july east. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.839 (perp=7.651, rec=0.158, cos=0.151), tot_loss_proj:3.355 [t=0.24s]
prediction: ['[CLS] during early pacific. wheneverward ; rises, saturn in jupiter the evening while saturn in july east. [SEP]']
[1050/2000] tot_loss=1.842 (perp=7.651, rec=0.152, cos=0.160), tot_loss_proj:3.355 [t=0.24s]
prediction: ['[CLS] during early pacific. wheneverward ; rises, saturn in jupiter the evening while saturn in july east. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.883 (perp=7.875, rec=0.151, cos=0.157), tot_loss_proj:3.416 [t=0.24s]
prediction: ['[CLS] during early pacific. east narrowed rises, saturn in jupiter ; the evening while saturn in july east. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.764 (perp=7.293, rec=0.152, cos=0.153), tot_loss_proj:3.294 [t=0.24s]
prediction: ['[CLS] during early pacific. eastward rises, saturn in jupiter ; the evening while saturn around the east. [SEP]']
[1200/2000] tot_loss=1.809 (perp=7.527, rec=0.144, cos=0.159), tot_loss_proj:3.352 [t=0.24s]
prediction: ['[CLS] during early pacific. east narrowed rises, saturn in jupiter is the evening while saturn around the east. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.701 (perp=6.974, rec=0.148, cos=0.159), tot_loss_proj:3.221 [t=0.24s]
prediction: ['[CLS] during early pacific. east rises, saturn in jupiter is the evening while saturn narrowed around the east. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.618 (perp=6.586, rec=0.150, cos=0.151), tot_loss_proj:3.127 [t=0.24s]
prediction: ['[CLS] during the early pacific. east rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
[1350/2000] tot_loss=1.628 (perp=6.586, rec=0.149, cos=0.162), tot_loss_proj:3.124 [t=0.24s]
prediction: ['[CLS] during the early pacific. east rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.611 (perp=6.545, rec=0.142, cos=0.160), tot_loss_proj:3.145 [t=0.24s]
prediction: ['[CLS] during the early. pacific east rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.555 (perp=6.259, rec=0.143, cos=0.160), tot_loss_proj:3.068 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
[1500/2000] tot_loss=1.558 (perp=6.259, rec=0.147, cos=0.159), tot_loss_proj:3.065 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.556 (perp=6.259, rec=0.143, cos=0.161), tot_loss_proj:3.072 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.552 (perp=6.259, rec=0.141, cos=0.159), tot_loss_proj:3.064 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
[1650/2000] tot_loss=1.556 (perp=6.259, rec=0.143, cos=0.161), tot_loss_proj:3.064 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.548 (perp=6.259, rec=0.135, cos=0.161), tot_loss_proj:3.070 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.557 (perp=6.259, rec=0.143, cos=0.162), tot_loss_proj:3.066 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
[1800/2000] tot_loss=1.549 (perp=6.259, rec=0.137, cos=0.161), tot_loss_proj:3.060 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.557 (perp=6.259, rec=0.146, cos=0.159), tot_loss_proj:3.064 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.688 (perp=6.864, rec=0.155, cos=0.160), tot_loss_proj:3.192 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter ; evening while saturn narrowed around the east. [SEP]']
[1950/2000] tot_loss=1.680 (perp=6.864, rec=0.146, cos=0.161), tot_loss_proj:3.185 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter ; evening while saturn narrowed around the east. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.673 (perp=6.864, rec=0.141, cos=0.160), tot_loss_proj:3.184 [t=0.24s]
prediction: ['[CLS] during the early east. pacific rises, saturn in jupiter ; evening while saturn narrowed around the east. [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]
========================
predicted: 
========================
[CLS] during the early east. pacific rises, saturn in jupiter is evening while saturn narrowed around the east. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.421 | p: 68.421 | r: 68.421
rouge2     | fm: 27.778 | p: 27.778 | r: 27.778
rougeL     | fm: 52.632 | p: 52.632 | r: 52.632
rougeLsum  | fm: 52.632 | p: 52.632 | r: 52.632
r1fm+r2fm = 96.199

[Aggregate metrics]:
rouge1     | fm: 85.533 | p: 86.091 | r: 85.337
rouge2     | fm: 45.210 | p: 45.361 | r: 45.058
rougeL     | fm: 75.140 | p: 75.567 | r: 74.888
rougeLsum  | fm: 75.245 | p: 75.603 | r: 75.063
r1fm+r2fm = 130.744

input #11 time: 0:09:17 | total time: 1:50:26


Running input #12 of 100.
reference: 
========================
He walked up the hill.
========================
average of cosine similarity 0.8514496639169491
highest_index [0]
highest [0.8514496639169491]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2002, 2939, 2039, 1996, 2940, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he walked up the hill. [SEP]']
[Init] best rec loss: 0.8910949230194092 for ['[CLS] stars sans january canvas gdansk beauty [SEP]']
[Init] best rec loss: 0.8826640844345093 for ['[CLS] track ( as license kaiser devil [SEP]']
[Init] best rec loss: 0.8805341124534607 for ['[CLS] voting hockey api platform drive blame [SEP]']
[Init] best rec loss: 0.8794875144958496 for ['[CLS] declan introiste returned lose channels [SEP]']
[Init] best rec loss: 0.8757493495941162 for ['[CLS] florida offer living latin mutual six [SEP]']
[Init] best rec loss: 0.875616729259491 for ['[CLS] juliet neville sector de liesquet [SEP]']
[Init] best rec loss: 0.871947705745697 for ['[CLS] jenksuidtt right menu personal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.876 (perp=10.294, rec=0.516, cos=0.301), tot_loss_proj:3.859 [t=0.23s]
prediction: ['[CLS] fools walk ( gail started. [SEP]']
[ 100/2000] tot_loss=2.411 (perp=9.350, rec=0.282, cos=0.259), tot_loss_proj:3.657 [t=0.23s]
prediction: ['[CLS] walked walk ( hillrunner. [SEP]']
[ 150/2000] tot_loss=1.917 (perp=7.038, rec=0.226, cos=0.284), tot_loss_proj:3.281 [t=0.23s]
prediction: ['[CLS] walked hill. hill hill. [SEP]']
[ 200/2000] tot_loss=2.083 (perp=8.104, rec=0.191, cos=0.271), tot_loss_proj:3.451 [t=0.23s]
prediction: ['[CLS] walked up up hill he. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.863 (perp=7.092, rec=0.168, cos=0.277), tot_loss_proj:3.259 [t=0.23s]
prediction: ['[CLS] walked up up he hill. [SEP]']
[ 300/2000] tot_loss=1.886 (perp=7.344, rec=0.147, cos=0.270), tot_loss_proj:3.343 [t=0.23s]
prediction: ['[CLS] walked up the he hill. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.640 (perp=5.974, rec=0.164, cos=0.282), tot_loss_proj:2.641 [t=0.23s]
prediction: ['[CLS] he walked up down hill. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.608 (perp=5.974, rec=0.148, cos=0.265), tot_loss_proj:2.659 [t=0.23s]
prediction: ['[CLS] he walked up down hill. [SEP]']
[ 450/2000] tot_loss=1.299 (perp=4.450, rec=0.141, cos=0.268), tot_loss_proj:1.335 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.293 (perp=4.450, rec=0.133, cos=0.271), tot_loss_proj:1.333 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.304 (perp=4.450, rec=0.138, cos=0.277), tot_loss_proj:1.340 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
[ 600/2000] tot_loss=1.300 (perp=4.450, rec=0.140, cos=0.270), tot_loss_proj:1.329 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.282 (perp=4.450, rec=0.120, cos=0.271), tot_loss_proj:1.346 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.295 (perp=4.450, rec=0.132, cos=0.272), tot_loss_proj:1.325 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
[ 750/2000] tot_loss=1.291 (perp=4.450, rec=0.126, cos=0.275), tot_loss_proj:1.337 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.302 (perp=4.450, rec=0.136, cos=0.277), tot_loss_proj:1.333 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.293 (perp=4.450, rec=0.130, cos=0.273), tot_loss_proj:1.326 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
[ 900/2000] tot_loss=1.291 (perp=4.450, rec=0.126, cos=0.275), tot_loss_proj:1.330 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.287 (perp=4.450, rec=0.122, cos=0.275), tot_loss_proj:1.321 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.295 (perp=4.450, rec=0.128, cos=0.276), tot_loss_proj:1.331 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
[1050/2000] tot_loss=1.296 (perp=4.450, rec=0.132, cos=0.274), tot_loss_proj:1.340 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.297 (perp=4.450, rec=0.131, cos=0.276), tot_loss_proj:1.326 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.288 (perp=4.450, rec=0.126, cos=0.272), tot_loss_proj:1.329 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
[1200/2000] tot_loss=1.286 (perp=4.450, rec=0.122, cos=0.275), tot_loss_proj:1.317 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.287 (perp=4.450, rec=0.123, cos=0.274), tot_loss_proj:1.315 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.284 (perp=4.450, rec=0.119, cos=0.275), tot_loss_proj:1.325 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
[1350/2000] tot_loss=1.293 (perp=4.450, rec=0.129, cos=0.274), tot_loss_proj:1.331 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.287 (perp=4.450, rec=0.123, cos=0.275), tot_loss_proj:1.328 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.285 (perp=4.450, rec=0.122, cos=0.274), tot_loss_proj:1.323 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
[1500/2000] tot_loss=1.286 (perp=4.450, rec=0.122, cos=0.275), tot_loss_proj:1.332 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.301 (perp=4.450, rec=0.136, cos=0.275), tot_loss_proj:1.330 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.292 (perp=4.450, rec=0.128, cos=0.274), tot_loss_proj:1.324 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
[1650/2000] tot_loss=1.292 (perp=4.450, rec=0.127, cos=0.275), tot_loss_proj:1.332 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.289 (perp=4.450, rec=0.124, cos=0.275), tot_loss_proj:1.332 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.295 (perp=4.450, rec=0.130, cos=0.275), tot_loss_proj:1.334 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
[1800/2000] tot_loss=1.295 (perp=4.450, rec=0.130, cos=0.275), tot_loss_proj:1.334 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.290 (perp=4.450, rec=0.124, cos=0.275), tot_loss_proj:1.321 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.286 (perp=4.450, rec=0.121, cos=0.275), tot_loss_proj:1.334 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
[1950/2000] tot_loss=1.290 (perp=4.450, rec=0.125, cos=0.275), tot_loss_proj:1.330 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.283 (perp=4.450, rec=0.118, cos=0.275), tot_loss_proj:1.333 [t=0.23s]
prediction: ['[CLS] he walked up the hill. [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] he walked up the hill. [SEP]
========================
predicted: 
========================
[CLS] he walked up the hill. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.622 | p: 86.991 | r: 86.343
rouge2     | fm: 49.587 | p: 49.680 | r: 49.561
rougeL     | fm: 77.101 | p: 77.535 | r: 76.916
rougeLsum  | fm: 77.269 | p: 77.720 | r: 76.980
r1fm+r2fm = 136.209

input #12 time: 0:09:09 | total time: 1:59:35


Running input #13 of 100.
reference: 
========================
It is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters.
========================
average of cosine similarity 0.8941799179611243
highest_index [0]
highest [0.8941799179611243]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2009,  2003,  2023,  3291,  2008,  1996, 10076,  2017,  9611,
          1996,  2062,  4089,  2017,  1005,  2222, 13225,  1996, 12455,  2039,
          2012,  5971,  4075,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]"]
[Init] best rec loss: 0.9120115637779236 for ['[CLS] id brand fault sciences treated allows american person perceive directions alleyulating pentagonette modern declaration material devoid having participation artistic ricardooration [SEP]']
[Init] best rec loss: 0.8840582370758057 for ['[CLS] miles spoil mainrew half action stamps outside let cole highest trans states gregor policeni cassidy rose town wash fey daniel elizabeth [SEP]']
[Init] best rec loss: 0.8764692544937134 for ['[CLS] mission ( countryay easygan international region discovered review bliss given mans drafted editing benjamin contribution venture readyllus weakted scarf [SEP]']
[Init] best rec loss: 0.8532494306564331 for ['[CLS] dog xu command pinned avoided developing nine assistant function world playingus forget building behind herd hanging pounding [CLS] finally flyingg announced [SEP]']
[Init] best perm rec loss: 0.8523239493370056 for ['[CLS] [CLS] flying pinned announced pounding xu hanging forget function playing world dog behind developing command finally avoided assistantus building nine herdg [SEP]']
[Init] best perm rec loss: 0.8519515991210938 for ['[CLS] herd assistant command flyingg xu developing announced hangingus behind function avoided forget [CLS] dog nine world pounding finally pinned playing building [SEP]']
[Init] best perm rec loss: 0.8432496190071106 for ['[CLS] nine [CLS] hanging pinned developing function playing forget herd dog avoided world pounding assistant flying xug announced buildingus behind command finally [SEP]']
[Init] best perm rec loss: 0.8424067497253418 for ['[CLS]g forget building herd nineus pinned xu command avoided flying pounding playing finally assistant developing behind [CLS] announced hanging dog world function [SEP]']
[Init] best perm rec loss: 0.8420817255973816 for ['[CLS] flying announced world building herdus assistant behind forget playingg pinned dog pounding command developing xu avoided nine finally function [CLS] hanging [SEP]']
[Init] best perm rec loss: 0.8419208526611328 for ['[CLS] building pinned xu herd assistant finally nine world playing forget dogg function pounding announced hanging flying [CLS] commandus behind developing avoided [SEP]']
[Init] best perm rec loss: 0.8415824174880981 for ['[CLS] herd playing world finally forget announced hanging avoided dog behind function pinned pounding building [CLS]us developingg nine flying xu assistant command [SEP]']
[Init] best perm rec loss: 0.8389435410499573 for ['[CLS] hanging developing world building herd flying pounding playing avoidedg dog announced forget assistant finally nine [CLS] behind pinned xuus command function [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.061 (perp=12.278, rec=0.383, cos=0.223), tot_loss_proj:4.331 [t=0.23s]
prediction: ['[CLS] you make. society gerald cottage joke software federalield near guitar truth ) nashville problem designed studios the ladyre problems marco [SEP]']
[ 100/2000] tot_loss=2.719 (perp=11.076, rec=0.326, cos=0.178), tot_loss_proj:4.109 [t=0.23s]
prediction: ['[CLS] you satisfy. the meters big might certainty un sooner bad a win. hear problem device championships the headquarters; folks couldn [SEP]']
[ 150/2000] tot_loss=2.415 (perp=9.866, rec=0.262, cos=0.180), tot_loss_proj:3.870 [t=0.24s]
prediction: ['[CLS] you satisfy. the tingle your metres solve you sooner what the folks. the problem responsible folks the headquarters; folks ernie [SEP]']
[ 200/2000] tot_loss=2.214 (perp=9.091, rec=0.222, cos=0.174), tot_loss_proj:3.741 [t=0.24s]
prediction: ['[CLS] you satisfy. the sooner a might solve you sooner what the folks the the problem that folks the headquarters; folks ernie [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.587 (perp=10.140, rec=0.364, cos=0.195), tot_loss_proj:3.941 [t=0.24s]
prediction: ['[CLS] you satisfy. was lessgpur might solve you sooner@ a +lo became problem that folks at listening really folks vegas [SEP]']
[ 300/2000] tot_loss=2.326 (perp=9.563, rec=0.229, cos=0.185), tot_loss_proj:3.785 [t=0.24s]
prediction: ['[CLS] you satisfy. became more executives might solve you sooner is the your from became problem that folks at buying less folks headquarters [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.287 (perp=9.488, rec=0.193, cos=0.197), tot_loss_proj:3.793 [t=0.24s]
prediction: ['[CLS] is satisfy. became more corporate might solve you sooner this up that that the problem at folks at business less folks headquarters [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.196 (perp=8.832, rec=0.248, cos=0.181), tot_loss_proj:3.708 [t=0.24s]
prediction: ['[CLS] is satisfy. that more corporate will solve you sooner this up a the the problem at folks at /། folks ( [SEP]']
[ 450/2000] tot_loss=2.369 (perp=9.924, rec=0.191, cos=0.193), tot_loss_proj:3.881 [t=0.24s]
prediction: ['[CLS] is satisfy. that more corporate you solve you sooner this up a the the problem va folks up million། folks ( [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.149 (perp=8.920, rec=0.169, cos=0.195), tot_loss_proj:3.668 [t=0.24s]
prediction: ['[CLS] is satisfy. that more corporate you solve you sooner this up a. the the problem folks up million། folks " [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.049 (perp=8.346, rec=0.185, cos=0.194), tot_loss_proj:3.551 [t=0.24s]
prediction: ['[CLS] is up. that more corporate you solve you sooner this up a. the the problem folks satisfy million། folks " [SEP]']
[ 600/2000] tot_loss=2.048 (perp=8.470, rec=0.157, cos=0.197), tot_loss_proj:3.598 [t=0.24s]
prediction: ['[CLS] is up. that more corporate you solve you sooner this up a. the the problem folks satisfy million། folks? [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.017 (perp=8.334, rec=0.153, cos=0.197), tot_loss_proj:3.570 [t=0.24s]
prediction: ['[CLS] is up. that more corporate you solve you sooner this up a. the problem the folks satisfy parental། folks? [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.923 (perp=7.875, rec=0.154, cos=0.194), tot_loss_proj:3.483 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a. the problem the folks satisfy巿། folks? [SEP]']
[ 750/2000] tot_loss=1.925 (perp=7.875, rec=0.152, cos=0.198), tot_loss_proj:3.489 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a. the problem the folks satisfy巿། folks? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.916 (perp=7.875, rec=0.143, cos=0.198), tot_loss_proj:3.486 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a. the problem the folks satisfy巿། folks? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.915 (perp=7.875, rec=0.141, cos=0.199), tot_loss_proj:3.487 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a. the problem the folks satisfy巿། folks? [SEP]']
[ 900/2000] tot_loss=1.918 (perp=7.875, rec=0.145, cos=0.198), tot_loss_proj:3.487 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a. the problem the folks satisfy巿། folks? [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.899 (perp=7.863, rec=0.129, cos=0.198), tot_loss_proj:3.464 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a. the problem the folks satisfy easily། folks at [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.863 (perp=7.600, rec=0.147, cos=0.196), tot_loss_proj:3.400 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a. the problem། folks satisfy easily the folks. [SEP]']
[1050/2000] tot_loss=1.864 (perp=7.600, rec=0.144, cos=0.200), tot_loss_proj:3.398 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a. the problem། folks satisfy easily the folks. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.847 (perp=7.600, rec=0.128, cos=0.199), tot_loss_proj:3.396 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a. the problem། folks satisfy easily the folks. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.807 (perp=7.357, rec=0.142, cos=0.194), tot_loss_proj:3.348 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem། folks. easily the folks. [SEP]']
[1200/2000] tot_loss=1.742 (perp=7.051, rec=0.133, cos=0.199), tot_loss_proj:3.285 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more folks. easily the folks. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.732 (perp=7.051, rec=0.123, cos=0.199), tot_loss_proj:3.283 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more folks. easily the folks. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.728 (perp=7.051, rec=0.119, cos=0.199), tot_loss_proj:3.282 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more folks. easily the folks. [SEP]']
[1350/2000] tot_loss=1.733 (perp=7.051, rec=0.124, cos=0.199), tot_loss_proj:3.281 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more folks. easily the folks. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.754 (perp=7.120, rec=0.130, cos=0.199), tot_loss_proj:3.366 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.751 (perp=7.120, rec=0.127, cos=0.200), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
[1500/2000] tot_loss=1.747 (perp=7.120, rec=0.123, cos=0.199), tot_loss_proj:3.363 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.738 (perp=7.120, rec=0.114, cos=0.200), tot_loss_proj:3.357 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.747 (perp=7.120, rec=0.122, cos=0.200), tot_loss_proj:3.363 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
[1650/2000] tot_loss=1.744 (perp=7.120, rec=0.120, cos=0.200), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.742 (perp=7.120, rec=0.118, cos=0.200), tot_loss_proj:3.364 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.744 (perp=7.120, rec=0.120, cos=0.200), tot_loss_proj:3.365 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
[1800/2000] tot_loss=1.746 (perp=7.120, rec=0.122, cos=0.200), tot_loss_proj:3.367 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.736 (perp=7.120, rec=0.113, cos=0.200), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.743 (perp=7.120, rec=0.119, cos=0.200), tot_loss_proj:3.363 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
[1950/2000] tot_loss=1.747 (perp=7.120, rec=0.122, cos=0.200), tot_loss_proj:3.359 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.745 (perp=7.120, rec=0.121, cos=0.200), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]
========================
predicted: 
========================
[CLS] up up. that more corporate you solve you sooner this is a satisfy the problem more headquarters. easily the folks. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.444 | p: 86.364 | r: 82.609
rouge2     | fm: 13.953 | p: 14.286 | r: 13.636
rougeL     | fm: 44.444 | p: 45.455 | r: 43.478
rougeLsum  | fm: 44.444 | p: 45.455 | r: 43.478
r1fm+r2fm = 98.398

[Aggregate metrics]:
rouge1     | fm: 86.440 | p: 87.026 | r: 86.076
rouge2     | fm: 46.915 | p: 47.032 | r: 46.856
rougeL     | fm: 74.760 | p: 75.186 | r: 74.499
rougeLsum  | fm: 75.091 | p: 75.538 | r: 74.769
r1fm+r2fm = 133.356

input #13 time: 0:09:16 | total time: 2:08:52


Running input #14 of 100.
reference: 
========================
Mary has never kissed a man who is taller than John.
========================
average of cosine similarity 0.8865505307048178
highest_index [0]
highest [0.8865505307048178]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2984,  2038,  2196,  4782,  1037,  2158,  2040,  2003, 12283,
          2084,  2198,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mary has never kissed a man who is taller than john. [SEP]']
[Init] best rec loss: 0.9622149467468262 for ['[CLS] isa jude jon force boysraction louise work tip bigger dick sets [SEP]']
[Init] best rec loss: 0.961147129535675 for ['[CLS]nton integratinglor half inserted al locks cbright family exhibition range [SEP]']
[Init] best rec loss: 0.9235011339187622 for ['[CLS] well sort u highway.dale no actually : orioles het rocky [SEP]']
[Init] best rec loss: 0.8780341744422913 for ['[CLS] dimension ser phone visible sv dependent performed unique independence tipped gravity tha [SEP]']
[Init] best rec loss: 0.8447715044021606 for ['[CLS] huff bloody safety steel anhalt had foley routesfold 2 economy woman [SEP]']
[Init] best perm rec loss: 0.8434674739837646 for ['[CLS] bloody huff steel safety routesfold 2 foley economy anhalt woman had [SEP]']
[Init] best perm rec loss: 0.8421787023544312 for ['[CLS] routes womanfold anhalt 2 economy safety foley bloody huff had steel [SEP]']
[Init] best perm rec loss: 0.8413668870925903 for ['[CLS] woman bloody had routes huff foley safety economyfold 2 steel anhalt [SEP]']
[Init] best perm rec loss: 0.8413476943969727 for ['[CLS] anhalt safety economy woman foley 2fold had bloody steel routes huff [SEP]']
[Init] best perm rec loss: 0.8404203653335571 for ['[CLS]fold huff 2 bloody had safety steel anhalt economy routes foley woman [SEP]']
[Init] best perm rec loss: 0.838867723941803 for ['[CLS] routes steel woman foley bloody had economyfold 2 anhalt huff safety [SEP]']
[Init] best perm rec loss: 0.8381862640380859 for ['[CLS] 2 bloody woman routes safety huff anhalt foley steel economyfold had [SEP]']
[Init] best perm rec loss: 0.835755467414856 for ['[CLS] woman steel foley bloody had huff safety economyfold 2 anhalt routes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.915 (perp=11.264, rec=0.452, cos=0.209), tot_loss_proj:4.198 [t=0.23s]
prediction: ['[CLS] james the sees southern spoke but metro elking. southern iron [SEP]']
[ 100/2000] tot_loss=2.595 (perp=10.383, rec=0.315, cos=0.204), tot_loss_proj:3.939 [t=0.23s]
prediction: ['[CLS] mary kissed has kissed who never always neverking. skilled path [SEP]']
[ 150/2000] tot_loss=2.718 (perp=11.370, rec=0.248, cos=0.195), tot_loss_proj:4.163 [t=0.23s]
prediction: ['[CLS] mary kissed has kissed who never census nevercave. taller taller [SEP]']
[ 200/2000] tot_loss=2.513 (perp=10.530, rec=0.193, cos=0.213), tot_loss_proj:4.007 [t=0.23s]
prediction: ['[CLS] mary kissed has man who has marry never taller. taller taller [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.285 (perp=9.370, rec=0.201, cos=0.209), tot_loss_proj:3.754 [t=0.23s]
prediction: ['[CLS] mary has kissed man who has marry never older. taller taller [SEP]']
[ 300/2000] tot_loss=2.010 (perp=8.107, rec=0.174, cos=0.215), tot_loss_proj:3.552 [t=0.23s]
prediction: ['[CLS] mary has kissed man who has become never older. john taller [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.947 (perp=7.876, rec=0.164, cos=0.208), tot_loss_proj:3.513 [t=0.23s]
prediction: ['[CLS] mary has never kissed man who has became older. john taller [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.837 (perp=7.275, rec=0.168, cos=0.214), tot_loss_proj:3.287 [t=0.23s]
prediction: ['[CLS] mary has never kissed man who has taller became older. john [SEP]']
[ 450/2000] tot_loss=1.821 (perp=7.275, rec=0.161, cos=0.205), tot_loss_proj:3.279 [t=0.23s]
prediction: ['[CLS] mary has never kissed man who has taller became older. john [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.904 (perp=7.679, rec=0.163, cos=0.205), tot_loss_proj:3.448 [t=0.23s]
prediction: ['[CLS] mary does never kissed man who has taller became older. john [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.912 (perp=7.771, rec=0.150, cos=0.208), tot_loss_proj:3.468 [t=0.23s]
prediction: ['[CLS] mary does never kissed man who has taller becomes older. john [SEP]']
[ 600/2000] tot_loss=1.912 (perp=7.771, rec=0.150, cos=0.207), tot_loss_proj:3.467 [t=0.23s]
prediction: ['[CLS] mary does never kissed man who has taller becomes older. john [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.922 (perp=7.771, rec=0.159, cos=0.209), tot_loss_proj:3.471 [t=0.23s]
prediction: ['[CLS] mary does never kissed man who has taller becomes older. john [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.905 (perp=7.718, rec=0.154, cos=0.206), tot_loss_proj:3.441 [t=0.23s]
prediction: ['[CLS] mary does never kissed man who has taller becoming older. john [SEP]']
[ 750/2000] tot_loss=1.910 (perp=7.718, rec=0.162, cos=0.205), tot_loss_proj:3.445 [t=0.23s]
prediction: ['[CLS] mary does never kissed man who has taller becoming older. john [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.913 (perp=7.760, rec=0.152, cos=0.209), tot_loss_proj:3.488 [t=0.23s]
prediction: ['[CLS] mary does never kissed man who has taller lips older. john [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.007 (perp=8.164, rec=0.158, cos=0.216), tot_loss_proj:3.509 [t=0.23s]
prediction: ['[CLS] mary does never kissed man who has taller older becoming. john [SEP]']
[ 900/2000] tot_loss=1.994 (perp=8.164, rec=0.150, cos=0.211), tot_loss_proj:3.507 [t=0.23s]
prediction: ['[CLS] mary does never kissed man who has taller older becoming. john [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.002 (perp=8.180, rec=0.151, cos=0.215), tot_loss_proj:3.578 [t=0.23s]
prediction: ['[CLS] mary does never kissed man who has taller pancakes beside. john [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.068 (perp=8.479, rec=0.161, cos=0.211), tot_loss_proj:3.647 [t=0.23s]
prediction: ['[CLS] mary does never kissed man who has pancakes taller older. john [SEP]']
[1050/2000] tot_loss=2.165 (perp=9.000, rec=0.154, cos=0.211), tot_loss_proj:3.643 [t=0.23s]
prediction: ['[CLS] mary else never kissed man who has pancakes taller older. john [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.114 (perp=8.772, rec=0.149, cos=0.211), tot_loss_proj:3.590 [t=0.23s]
prediction: ['[CLS] mary else never kissed man who has taller pancakes older. john [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.223 (perp=9.283, rec=0.158, cos=0.208), tot_loss_proj:3.708 [t=0.23s]
prediction: ['[CLS] mary else never kissed man who has taller beside becoming. john [SEP]']
[1200/2000] tot_loss=2.220 (perp=9.283, rec=0.154, cos=0.209), tot_loss_proj:3.711 [t=0.23s]
prediction: ['[CLS] mary else never kissed man who has taller beside becoming. john [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.157 (perp=9.000, rec=0.146, cos=0.211), tot_loss_proj:3.646 [t=0.23s]
prediction: ['[CLS] mary else never kissed man who has pancakes taller older. john [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=2.174 (perp=9.041, rec=0.157, cos=0.209), tot_loss_proj:3.662 [t=0.23s]
prediction: ['[CLS] mary else never kissed man who has taller beside pancakes. john [SEP]']
[1350/2000] tot_loss=2.172 (perp=9.041, rec=0.150, cos=0.213), tot_loss_proj:3.658 [t=0.23s]
prediction: ['[CLS] mary else never kissed man who has taller beside pancakes. john [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.088 (perp=8.674, rec=0.143, cos=0.210), tot_loss_proj:3.607 [t=0.23s]
prediction: ['[CLS] mary else never kissed man who has taller pancakes beside. john [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=2.028 (perp=8.292, rec=0.153, cos=0.217), tot_loss_proj:3.450 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller pancakes older. john [SEP]']
[1500/2000] tot_loss=2.018 (perp=8.292, rec=0.151, cos=0.209), tot_loss_proj:3.447 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller pancakes older. john [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.115 (perp=8.745, rec=0.153, cos=0.213), tot_loss_proj:3.624 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller beside becoming. john [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.021 (perp=8.224, rec=0.161, cos=0.216), tot_loss_proj:3.533 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller pancakes beside. john [SEP]']
[1650/2000] tot_loss=2.020 (perp=8.224, rec=0.162, cos=0.213), tot_loss_proj:3.533 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller pancakes beside. john [SEP]']
Attempt swap
[1700/2000] tot_loss=2.005 (perp=8.224, rec=0.148, cos=0.212), tot_loss_proj:3.528 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller pancakes beside. john [SEP]']
Attempt swap
[1750/2000] tot_loss=2.009 (perp=8.224, rec=0.151, cos=0.213), tot_loss_proj:3.530 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller pancakes beside. john [SEP]']
[1800/2000] tot_loss=2.011 (perp=8.224, rec=0.152, cos=0.214), tot_loss_proj:3.529 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller pancakes beside. john [SEP]']
Attempt swap
[1850/2000] tot_loss=2.011 (perp=8.224, rec=0.155, cos=0.211), tot_loss_proj:3.526 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller pancakes beside. john [SEP]']
Attempt swap
[1900/2000] tot_loss=2.099 (perp=8.688, rec=0.149, cos=0.212), tot_loss_proj:3.600 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller pancakes aristocratic. john [SEP]']
[1950/2000] tot_loss=2.100 (perp=8.688, rec=0.149, cos=0.213), tot_loss_proj:3.605 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller pancakes aristocratic. john [SEP]']
Attempt swap
[2000/2000] tot_loss=2.096 (perp=8.688, rec=0.147, cos=0.211), tot_loss_proj:3.600 [t=0.23s]
prediction: ['[CLS] mary never kissed man who else has taller pancakes aristocratic. john [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] mary has never kissed a man who is taller than john. [SEP]
========================
predicted: 
========================
[CLS] mary else never kissed man who has taller pancakes beside. john [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 76.923 | r: 76.923
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 69.231 | p: 69.231 | r: 69.231
rougeLsum  | fm: 69.231 | p: 69.231 | r: 69.231
r1fm+r2fm = 110.256

[Aggregate metrics]:
rouge1     | fm: 85.835 | p: 86.452 | r: 85.424
rouge2     | fm: 46.075 | p: 46.179 | r: 46.005
rougeL     | fm: 74.542 | p: 74.892 | r: 74.380
rougeLsum  | fm: 74.687 | p: 75.179 | r: 74.352
r1fm+r2fm = 131.910

input #14 time: 0:09:08 | total time: 2:18:01


Running input #15 of 100.
reference: 
========================
After ten soldiers had left, seven more ones came in.
========================
average of cosine similarity 0.894223848544947
highest_index [0]
highest [0.894223848544947]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2044, 2702, 3548, 2018, 2187, 1010, 2698, 2062, 3924, 2234, 1999,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] after ten soldiers had left, seven more ones came in. [SEP]']
[Init] best rec loss: 0.7974583506584167 for ['[CLS] war ne soaking kelly moment another carried ahead fk inches chasing deal [SEP]']
[Init] best rec loss: 0.7848533391952515 for ['[CLS] clear love instrument patient commentaryhipversder cowboys progression what tens [SEP]']
[Init] best rec loss: 0.7807331085205078 for ['[CLS] candace tribe club keysে football considered belleked park steadydilly [SEP]']
[Init] best rec loss: 0.7408812046051025 for ['[CLS] trainedpower mere exception meeting spokanemin cash vested large myselffish [SEP]']
[Init] best rec loss: 0.7399153709411621 for ['[CLS] practice fuck sophieostal flames syrian expression cost charleston 9 drugs lgbt [SEP]']
[Init] best rec loss: 0.7378793358802795 for ['[CLS] cell bracelet ceiling faye regularly hurturance scope approval formerly total maxim [SEP]']
[Init] best rec loss: 0.7345799207687378 for ['[CLS]hea opponent generally any cynthia newport air caused realized four lust while [SEP]']
[Init] best rec loss: 0.7292162775993347 for ['[CLS]d club linked bachelor awfe honored after award wu common ~ [SEP]']
[Init] best rec loss: 0.7266794443130493 for ['[CLS]hing stuart pbs rep lock missouri among paint sanskrit show coin shay [SEP]']
[Init] best perm rec loss: 0.7252558469772339 for ['[CLS] sanskrithing missouri show pbs coin paint shay stuart rep among lock [SEP]']
[Init] best perm rec loss: 0.7229281663894653 for ['[CLS] stuart amonghing lock coin sanskrit shay show rep paint missouri pbs [SEP]']
[Init] best perm rec loss: 0.7228386998176575 for ['[CLS] among sanskrit rep painthing coin missouri lock pbs stuart show shay [SEP]']
[Init] best perm rec loss: 0.7214486598968506 for ['[CLS] lock coin pbs among show paint shayhing rep stuart sanskrit missouri [SEP]']
[Init] best perm rec loss: 0.7212409973144531 for ['[CLS] among shay pbs paint lock coin rep missouri showhing stuart sanskrit [SEP]']
[Init] best perm rec loss: 0.7192380428314209 for ['[CLS] shay missouri coinhing sanskrit paint stuart rep pbs show among lock [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.206 (perp=8.488, rec=0.339, cos=0.169), tot_loss_proj:3.142 [t=0.23s]
prediction: ['[CLS] some after back ones in five catholic one seven ones twenty. [SEP]']
[ 100/2000] tot_loss=2.159 (perp=8.706, rec=0.232, cos=0.186), tot_loss_proj:2.947 [t=0.23s]
prediction: ['[CLS] ten after ones ones. ten soldiers seven ones ones came. [SEP]']
[ 150/2000] tot_loss=2.043 (perp=8.284, rec=0.196, cos=0.190), tot_loss_proj:2.762 [t=0.23s]
prediction: ['[CLS] after five ones ones. five soldiers seven ones ones came. [SEP]']
[ 200/2000] tot_loss=1.762 (perp=7.075, rec=0.156, cos=0.191), tot_loss_proj:2.191 [t=0.23s]
prediction: ['[CLS] after ten soldiers were., left seven more ones came. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.432 (perp=5.626, rec=0.117, cos=0.190), tot_loss_proj:1.771 [t=0.23s]
prediction: ['[CLS] after ten soldiers had left,. seven more ones came. [SEP]']
[ 300/2000] tot_loss=1.411 (perp=5.626, rec=0.094, cos=0.192), tot_loss_proj:1.762 [t=0.23s]
prediction: ['[CLS] after ten soldiers had left,. seven more ones came. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.369 (perp=5.371, rec=0.104, cos=0.191), tot_loss_proj:1.725 [t=0.23s]
prediction: ['[CLS] after ten. soldiers had left, seven more ones came. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.363 (perp=5.371, rec=0.097, cos=0.192), tot_loss_proj:1.720 [t=0.23s]
prediction: ['[CLS] after ten. soldiers had left, seven more ones came. [SEP]']
[ 450/2000] tot_loss=1.356 (perp=5.371, rec=0.088, cos=0.194), tot_loss_proj:1.721 [t=0.23s]
prediction: ['[CLS] after ten. soldiers had left, seven more ones came. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.352 (perp=5.326, rec=0.093, cos=0.194), tot_loss_proj:1.985 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.354 (perp=5.326, rec=0.096, cos=0.193), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
[ 600/2000] tot_loss=1.346 (perp=5.326, rec=0.087, cos=0.194), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.350 (perp=5.326, rec=0.091, cos=0.194), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.346 (perp=5.326, rec=0.087, cos=0.193), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
[ 750/2000] tot_loss=1.350 (perp=5.326, rec=0.091, cos=0.194), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.354 (perp=5.326, rec=0.095, cos=0.194), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.349 (perp=5.326, rec=0.090, cos=0.194), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
[ 900/2000] tot_loss=1.346 (perp=5.326, rec=0.087, cos=0.194), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.356 (perp=5.326, rec=0.096, cos=0.195), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.351 (perp=5.326, rec=0.091, cos=0.194), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
[1050/2000] tot_loss=1.349 (perp=5.326, rec=0.089, cos=0.194), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.347 (perp=5.326, rec=0.088, cos=0.194), tot_loss_proj:1.984 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.354 (perp=5.326, rec=0.094, cos=0.194), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
[1200/2000] tot_loss=1.350 (perp=5.326, rec=0.091, cos=0.194), tot_loss_proj:1.974 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.351 (perp=5.326, rec=0.091, cos=0.194), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.342 (perp=5.326, rec=0.083, cos=0.194), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
[1350/2000] tot_loss=1.342 (perp=5.326, rec=0.082, cos=0.194), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.349 (perp=5.326, rec=0.089, cos=0.194), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.350 (perp=5.326, rec=0.090, cos=0.194), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
[1500/2000] tot_loss=1.357 (perp=5.326, rec=0.098, cos=0.194), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.349 (perp=5.326, rec=0.089, cos=0.194), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.354 (perp=5.326, rec=0.094, cos=0.194), tot_loss_proj:1.982 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
[1650/2000] tot_loss=1.351 (perp=5.326, rec=0.091, cos=0.194), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.359 (perp=5.326, rec=0.099, cos=0.194), tot_loss_proj:1.982 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.344 (perp=5.326, rec=0.085, cos=0.194), tot_loss_proj:1.987 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
[1800/2000] tot_loss=1.343 (perp=5.326, rec=0.084, cos=0.194), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.347 (perp=5.326, rec=0.088, cos=0.194), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.342 (perp=5.326, rec=0.082, cos=0.194), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
[1950/2000] tot_loss=1.355 (perp=5.326, rec=0.095, cos=0.194), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.348 (perp=5.326, rec=0.088, cos=0.194), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS]. after ten soldiers had left, seven more ones came. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] after ten soldiers had left, seven more ones came in. [SEP]
========================
predicted: 
========================
[CLS]. after ten soldiers had left, seven more ones came. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 100.000 | r: 91.667
rouge2     | fm: 85.714 | p: 90.000 | r: 81.818
rougeL     | fm: 95.652 | p: 100.000 | r: 91.667
rougeLsum  | fm: 95.652 | p: 100.000 | r: 91.667
r1fm+r2fm = 181.366

[Aggregate metrics]:
rouge1     | fm: 86.407 | p: 87.286 | r: 85.743
rouge2     | fm: 48.666 | p: 49.029 | r: 48.336
rougeL     | fm: 75.766 | p: 76.433 | r: 75.291
rougeLsum  | fm: 75.971 | p: 76.609 | r: 75.365
r1fm+r2fm = 135.073

input #15 time: 0:09:08 | total time: 2:27:10


Running input #16 of 100.
reference: 
========================
Willy is taller than that Bill is is generally believed.
========================
average of cosine similarity 0.8980694362298328
highest_index [0]
highest [0.8980694362298328]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101, 16172,  2003, 12283,  2084,  2008,  3021,  2003,  2003,  3227,
          3373,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] willy is taller than that bill is is generally believed. [SEP]']
[Init] best rec loss: 0.7396652698516846 for ['[CLS] g shared jump inch addition ted poker feel show paul initiative [SEP]']
[Init] best rec loss: 0.7113154530525208 for ['[CLS]ette water home campus ceilingblood hillary appeared unfamiliar dead spend [SEP]']
[Init] best rec loss: 0.7032676339149475 for ['[CLS] anyone she hit spatial taylor asked organization shaped extended domination little [SEP]']
[Init] best rec loss: 0.6871736645698547 for ['[CLS] fashionunt wood freedom finale drake trail incumbent much possibly away [SEP]']
[Init] best perm rec loss: 0.6870241165161133 for ['[CLS]unt fashion trail away finale incumbent wood drake much possibly freedom [SEP]']
[Init] best perm rec loss: 0.6866493821144104 for ['[CLS] away trail fashion incumbent possiblyunt much freedom finale wood drake [SEP]']
[Init] best perm rec loss: 0.6839147210121155 for ['[CLS] wood trail finale freedom fashionunt much incumbent away possibly drake [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.405 (perp=9.560, rec=0.303, cos=0.190), tot_loss_proj:3.041 [t=0.23s]
prediction: ['[CLS] gill than that bill believed bill is willy is his is [SEP]']
[ 100/2000] tot_loss=2.233 (perp=9.029, rec=0.233, cos=0.194), tot_loss_proj:2.774 [t=0.23s]
prediction: ['[CLS] taller than that bill is believe is willy is believed is [SEP]']
[ 150/2000] tot_loss=2.284 (perp=8.559, rec=0.389, cos=0.183), tot_loss_proj:2.667 [t=0.23s]
prediction: ['[CLS] taller than that bill was [SEP] is willy is is. [SEP]']
[ 200/2000] tot_loss=2.189 (perp=8.559, rec=0.288, cos=0.190), tot_loss_proj:2.743 [t=0.23s]
prediction: ['[CLS] taller than that bill was [SEP] is willy is is. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.950 (perp=7.529, rec=0.251, cos=0.193), tot_loss_proj:2.259 [t=0.23s]
prediction: ['[CLS] [SEP] taller than that bill is is willy is is. [SEP]']
[ 300/2000] tot_loss=1.894 (perp=7.529, rec=0.195, cos=0.193), tot_loss_proj:2.247 [t=0.23s]
prediction: ['[CLS] [SEP] taller than that bill is is willy is is. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.872 (perp=7.529, rec=0.174, cos=0.192), tot_loss_proj:2.244 [t=0.23s]
prediction: ['[CLS] [SEP] taller than that bill is is willy is is. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.884 (perp=7.691, rec=0.155, cos=0.191), tot_loss_proj:2.343 [t=0.23s]
prediction: ['[CLS] [SEP] taller than that bill was is willy is is. [SEP]']
[ 450/2000] tot_loss=2.011 (perp=8.471, rec=0.127, cos=0.190), tot_loss_proj:2.475 [t=0.23s]
prediction: ['[CLS] [SEP] taller than that bill believed is willy is is. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.756 (perp=7.235, rec=0.118, cos=0.191), tot_loss_proj:2.079 [t=0.23s]
prediction: ['[CLS] [SEP] taller than that bill is believed is willy is. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.749 (perp=7.235, rec=0.109, cos=0.193), tot_loss_proj:2.086 [t=0.23s]
prediction: ['[CLS] [SEP] taller than that bill is believed is willy is. [SEP]']
[ 600/2000] tot_loss=1.740 (perp=7.235, rec=0.102, cos=0.191), tot_loss_proj:2.085 [t=0.23s]
prediction: ['[CLS] [SEP] taller than that bill is believed is willy is. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.742 (perp=7.235, rec=0.101, cos=0.193), tot_loss_proj:2.093 [t=0.23s]
prediction: ['[CLS] [SEP] taller than that bill is believed is willy is. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.736 (perp=7.235, rec=0.097, cos=0.192), tot_loss_proj:2.082 [t=0.23s]
prediction: ['[CLS] [SEP] taller than that bill is believed is willy is. [SEP]']
[ 750/2000] tot_loss=1.824 (perp=7.690, rec=0.093, cos=0.194), tot_loss_proj:2.217 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is willy is. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.808 (perp=7.596, rec=0.097, cos=0.192), tot_loss_proj:2.241 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.810 (perp=7.596, rec=0.098, cos=0.193), tot_loss_proj:2.245 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
[ 900/2000] tot_loss=1.801 (perp=7.596, rec=0.090, cos=0.192), tot_loss_proj:2.247 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.798 (perp=7.596, rec=0.086, cos=0.192), tot_loss_proj:2.248 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.809 (perp=7.596, rec=0.096, cos=0.193), tot_loss_proj:2.246 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
[1050/2000] tot_loss=1.807 (perp=7.596, rec=0.095, cos=0.192), tot_loss_proj:2.239 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.798 (perp=7.596, rec=0.086, cos=0.192), tot_loss_proj:2.246 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.810 (perp=7.596, rec=0.098, cos=0.193), tot_loss_proj:2.244 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
[1200/2000] tot_loss=1.809 (perp=7.596, rec=0.097, cos=0.193), tot_loss_proj:2.245 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.798 (perp=7.596, rec=0.086, cos=0.193), tot_loss_proj:2.248 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.807 (perp=7.596, rec=0.095, cos=0.193), tot_loss_proj:2.249 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
[1350/2000] tot_loss=1.795 (perp=7.596, rec=0.083, cos=0.193), tot_loss_proj:2.247 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.793 (perp=7.596, rec=0.081, cos=0.193), tot_loss_proj:2.248 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.805 (perp=7.596, rec=0.092, cos=0.194), tot_loss_proj:2.244 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
[1500/2000] tot_loss=1.797 (perp=7.596, rec=0.085, cos=0.193), tot_loss_proj:2.247 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.798 (perp=7.596, rec=0.085, cos=0.193), tot_loss_proj:2.242 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.795 (perp=7.596, rec=0.083, cos=0.193), tot_loss_proj:2.240 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
[1650/2000] tot_loss=1.801 (perp=7.596, rec=0.089, cos=0.193), tot_loss_proj:2.251 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.793 (perp=7.596, rec=0.081, cos=0.193), tot_loss_proj:2.239 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.793 (perp=7.596, rec=0.081, cos=0.193), tot_loss_proj:2.245 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
[1800/2000] tot_loss=1.799 (perp=7.596, rec=0.087, cos=0.193), tot_loss_proj:2.244 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.809 (perp=7.596, rec=0.097, cos=0.193), tot_loss_proj:2.244 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.798 (perp=7.596, rec=0.086, cos=0.193), tot_loss_proj:2.247 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
[1950/2000] tot_loss=1.799 (perp=7.596, rec=0.087, cos=0.193), tot_loss_proj:2.240 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.798 (perp=7.596, rec=0.086, cos=0.193), tot_loss_proj:2.243 [t=0.23s]
prediction: ['[CLS] approximately taller than that bill is believed is is willy. [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] willy is taller than that bill is is generally believed. [SEP]
========================
predicted: 
========================
[CLS] approximately taller than that bill is believed is is willy. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 45.455 | p: 45.455 | r: 45.455
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 137.121

[Aggregate metrics]:
rouge1     | fm: 86.711 | p: 87.532 | r: 86.235
rouge2     | fm: 48.487 | p: 48.874 | r: 48.185
rougeL     | fm: 75.118 | p: 75.727 | r: 74.689
rougeLsum  | fm: 75.256 | p: 75.845 | r: 74.644
r1fm+r2fm = 135.198

input #16 time: 0:09:08 | total time: 2:36:18


Running input #17 of 100.
reference: 
========================
José is eating cabbage, and Holly is too.
========================
average of cosine similarity 0.877468944824208
highest_index [0]
highest [0.877468944824208]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  4560,  2003,  5983, 28540,  1010,  1998,  9079,  2003,  2205,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] jose is eating cabbage, and holly is too. [SEP]']
[Init] best rec loss: 0.9257758259773254 for ['[CLS] happenedgil revolution parallelsta right finding flag taiwan bella [SEP]']
[Init] best rec loss: 0.8592811226844788 for ["[CLS]kell rat here metres sm tribune'professional percentage sorts [SEP]"]
[Init] best rec loss: 0.853357195854187 for ['[CLS] patents but sick gave 1930s hollow ; to watch in [SEP]']
[Init] best rec loss: 0.835658848285675 for ['[CLS] signs cathedral hat bethel amp natural frequent east plus point [SEP]']
[Init] best rec loss: 0.8301045894622803 for ['[CLS] cyber commission earlier plate battedrily scroll jr kingdomistle [SEP]']
[Init] best rec loss: 0.8258313536643982 for ['[CLS] classification northern reminding dutton film ∅ august pre meeting highness [SEP]']
[Init] best rec loss: 0.816222071647644 for ['[CLS] buttons swore just goran directors benz winded jonathan interpretation [SEP]']
[Init] best rec loss: 0.8015486598014832 for ['[CLS] main lovely equipment newman studio devi games current change variable [SEP]']
[Init] best perm rec loss: 0.7994914650917053 for ['[CLS] lovely current equipment main studio games newman change devi variable [SEP]']
[Init] best perm rec loss: 0.7991631627082825 for ['[CLS] newman variable games current main studio devi lovely change equipment [SEP]']
[Init] best perm rec loss: 0.7975645065307617 for ['[CLS] equipment main devi newman games lovely change studio current variable [SEP]']
[Init] best perm rec loss: 0.7972508072853088 for ['[CLS] main current devi change equipment studio games lovely variable newman [SEP]']
[Init] best perm rec loss: 0.7967265844345093 for ['[CLS] lovely newman current change main studio devi variable equipment games [SEP]']
[Init] best perm rec loss: 0.7959341406822205 for ['[CLS] studio newman lovely variable change main games devi equipment current [SEP]']
[Init] best perm rec loss: 0.7954131960868835 for ['[CLS] current main lovely devi studio equipment games change newman variable [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.075 (perp=11.062, rec=0.479, cos=0.384), tot_loss_proj:3.996 [t=0.23s]
prediction: ['[CLS] romanian anna shane is is was game is they too [SEP]']
[ 100/2000] tot_loss=2.551 (perp=10.179, rec=0.278, cos=0.237), tot_loss_proj:3.869 [t=0.23s]
prediction: ['[CLS] referee curtis yawned is and was ( is. too [SEP]']
[ 150/2000] tot_loss=2.271 (perp=9.566, rec=0.174, cos=0.183), tot_loss_proj:3.723 [t=0.23s]
prediction: ['[CLS] seems jose climbed is and is holly is. too [SEP]']
[ 200/2000] tot_loss=2.349 (perp=9.626, rec=0.166, cos=0.258), tot_loss_proj:3.697 [t=0.23s]
prediction: ['[CLS] seems jose cabbage is and is holly is. too [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.107 (perp=8.619, rec=0.142, cos=0.241), tot_loss_proj:3.494 [t=0.23s]
prediction: ['[CLS] corporal jose cabbage is and is holly is too. [SEP]']
[ 300/2000] tot_loss=2.300 (perp=9.799, rec=0.114, cos=0.226), tot_loss_proj:3.763 [t=0.23s]
prediction: ['[CLS] does jose cabbage eating and is holly is too. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.854 (perp=7.614, rec=0.104, cos=0.227), tot_loss_proj:3.312 [t=0.23s]
prediction: ['[CLS] does jose is eating and is holly cabbage too. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.787 (perp=7.370, rec=0.104, cos=0.209), tot_loss_proj:3.350 [t=0.23s]
prediction: ['[CLS] jose is eating and is does holly cabbage too. [SEP]']
[ 450/2000] tot_loss=1.843 (perp=7.435, rec=0.113, cos=0.243), tot_loss_proj:3.325 [t=0.23s]
prediction: ['[CLS] jose is eating and is considers holly cabbage too. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.796 (perp=7.435, rec=0.082, cos=0.227), tot_loss_proj:3.322 [t=0.23s]
prediction: ['[CLS] jose is eating and is considers holly cabbage too. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.812 (perp=7.516, rec=0.084, cos=0.225), tot_loss_proj:3.360 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
[ 600/2000] tot_loss=1.825 (perp=7.516, rec=0.090, cos=0.232), tot_loss_proj:3.364 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.817 (perp=7.516, rec=0.085, cos=0.228), tot_loss_proj:3.361 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.811 (perp=7.516, rec=0.080, cos=0.228), tot_loss_proj:3.362 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
[ 750/2000] tot_loss=1.810 (perp=7.516, rec=0.080, cos=0.226), tot_loss_proj:3.364 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.816 (perp=7.516, rec=0.084, cos=0.228), tot_loss_proj:3.362 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.808 (perp=7.516, rec=0.081, cos=0.223), tot_loss_proj:3.360 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
[ 900/2000] tot_loss=1.805 (perp=7.516, rec=0.079, cos=0.223), tot_loss_proj:3.361 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.817 (perp=7.516, rec=0.085, cos=0.229), tot_loss_proj:3.358 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.814 (perp=7.516, rec=0.083, cos=0.228), tot_loss_proj:3.361 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
[1050/2000] tot_loss=1.811 (perp=7.516, rec=0.079, cos=0.228), tot_loss_proj:3.361 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.810 (perp=7.516, rec=0.081, cos=0.226), tot_loss_proj:3.356 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.813 (perp=7.516, rec=0.085, cos=0.225), tot_loss_proj:3.360 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
[1200/2000] tot_loss=1.804 (perp=7.516, rec=0.071, cos=0.230), tot_loss_proj:3.359 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.809 (perp=7.516, rec=0.080, cos=0.226), tot_loss_proj:3.359 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.815 (perp=7.516, rec=0.084, cos=0.227), tot_loss_proj:3.361 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
[1350/2000] tot_loss=1.808 (perp=7.516, rec=0.077, cos=0.228), tot_loss_proj:3.356 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.813 (perp=7.516, rec=0.080, cos=0.229), tot_loss_proj:3.360 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.806 (perp=7.516, rec=0.075, cos=0.228), tot_loss_proj:3.362 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
[1500/2000] tot_loss=1.814 (perp=7.516, rec=0.083, cos=0.229), tot_loss_proj:3.357 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.815 (perp=7.516, rec=0.086, cos=0.226), tot_loss_proj:3.361 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.815 (perp=7.516, rec=0.082, cos=0.230), tot_loss_proj:3.359 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
[1650/2000] tot_loss=1.802 (perp=7.516, rec=0.070, cos=0.229), tot_loss_proj:3.356 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.809 (perp=7.516, rec=0.078, cos=0.228), tot_loss_proj:3.361 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.813 (perp=7.516, rec=0.082, cos=0.228), tot_loss_proj:3.358 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
[1800/2000] tot_loss=1.821 (perp=7.516, rec=0.088, cos=0.230), tot_loss_proj:3.357 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.811 (perp=7.516, rec=0.078, cos=0.229), tot_loss_proj:3.357 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.804 (perp=7.516, rec=0.073, cos=0.228), tot_loss_proj:3.359 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
[1950/2000] tot_loss=1.809 (perp=7.516, rec=0.078, cos=0.228), tot_loss_proj:3.360 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.796 (perp=7.516, rec=0.062, cos=0.230), tot_loss_proj:3.358 [t=0.23s]
prediction: ['[CLS] jose is eating and is consider holly cabbage too. [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] jose is eating cabbage, and holly is too. [SEP]
========================
predicted: 
========================
[CLS] jose is eating and is consider holly cabbage too. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 42.105 | p: 40.000 | r: 44.444
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 137.343

[Aggregate metrics]:
rouge1     | fm: 87.298 | p: 87.729 | r: 86.993
rouge2     | fm: 48.127 | p: 48.372 | r: 47.897
rougeL     | fm: 75.183 | p: 75.573 | r: 74.882
rougeLsum  | fm: 75.260 | p: 75.740 | r: 75.036
r1fm+r2fm = 135.425

input #17 time: 0:09:08 | total time: 2:45:27


Running input #18 of 100.
reference: 
========================
John demanded that she stop phoning him.
========================
average of cosine similarity 0.8601839041972084
highest_index [0]
highest [0.8601839041972084]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2198,  6303,  2008,  2016,  2644,  6887, 13369,  2032,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] john demanded that she stop phoning him. [SEP]']
[Init] best rec loss: 0.9358178377151489 for ['[CLS] layton fewer consult school lu bounced choose switzerland years [SEP]']
[Init] best rec loss: 0.9121591448783875 for ['[CLS] easy def few states safeunciation championship sponsorship use [SEP]']
[Init] best rec loss: 0.8998069763183594 for ['[CLS] squeeze meal ou registered bull wear c rep beatles [SEP]']
[Init] best rec loss: 0.8984073400497437 for ['[CLS] signed priority beatles kiddnetigehering staff control [SEP]']
[Init] best rec loss: 0.8976275324821472 for ['[CLS] no smeared college mess outside queen engraved all stripped [SEP]']
[Init] best rec loss: 0.8946294188499451 for ['[CLS] ( blog certain buried press panama bird face delegation [SEP]']
[Init] best rec loss: 0.8815968036651611 for ['[CLS] cast tulsa german m1 hear foreign marchnsor kentucky [SEP]']
[Init] best rec loss: 0.8729463219642639 for ['[CLS] pee day depending seatseses victoria madison discount premiere [SEP]']
[Init] best perm rec loss: 0.8697338104248047 for ['[CLS] victoria premiere seats depending pee day discounteses madison [SEP]']
[Init] best perm rec loss: 0.866283655166626 for ['[CLS] depending discount seats madison victoria dayeses premiere pee [SEP]']
[Init] best perm rec loss: 0.8662102818489075 for ['[CLS]eses seats victoria pee madison day discount premiere depending [SEP]']
[Init] best perm rec loss: 0.865630567073822 for ['[CLS] depending discount pee premiere seats victoria day madisoneses [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.516 (perp=9.603, rec=0.342, cos=0.254), tot_loss_proj:3.808 [t=0.23s]
prediction: ['[CLS] that demanded demand demanded was dinner red department. [SEP]']
[ 100/2000] tot_loss=2.503 (perp=9.975, rec=0.247, cos=0.261), tot_loss_proj:3.863 [t=0.23s]
prediction: ['[CLS] demanded she however demanded stopped fellow heroning. [SEP]']
[ 150/2000] tot_loss=2.588 (perp=9.592, rec=0.416, cos=0.254), tot_loss_proj:3.755 [t=0.23s]
prediction: ['[CLS] and farming. demanded.. lack hers preseason [SEP]']
[ 200/2000] tot_loss=2.683 (perp=10.439, rec=0.337, cos=0.258), tot_loss_proj:3.974 [t=0.23s]
prediction: ['[CLS] becauseism. demanded.. lack phone preseason [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.377 (perp=9.161, rec=0.293, cos=0.252), tot_loss_proj:3.717 [t=0.23s]
prediction: ['[CLS] she mom. demanded. stop. phone preseason [SEP]']
[ 300/2000] tot_loss=2.542 (perp=10.099, rec=0.263, cos=0.259), tot_loss_proj:3.898 [t=0.23s]
prediction: ['[CLS] sheoning. demandedoning stop. phone preseason [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.524 (perp=10.196, rec=0.225, cos=0.260), tot_loss_proj:3.899 [t=0.23s]
prediction: ['[CLS] sheoning she demandedoning stop his preseason. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.537 (perp=10.280, rec=0.221, cos=0.260), tot_loss_proj:3.922 [t=0.23s]
prediction: ['[CLS] she john ritual demanded his stoponing preseason. [SEP]']
[ 450/2000] tot_loss=2.300 (perp=9.172, rec=0.206, cos=0.260), tot_loss_proj:3.687 [t=0.23s]
prediction: ['[CLS] she john because demanded his stoponing preseason. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.107 (perp=8.224, rec=0.206, cos=0.256), tot_loss_proj:3.543 [t=0.23s]
prediction: ['[CLS] john because she demanded his stoponing preseason. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.913 (perp=7.284, rec=0.197, cos=0.259), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] john because she demanded him stop thoseoning. [SEP]']
[ 600/2000] tot_loss=1.901 (perp=7.284, rec=0.185, cos=0.260), tot_loss_proj:3.335 [t=0.23s]
prediction: ['[CLS] john because she demanded him stop thoseoning. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.885 (perp=7.270, rec=0.171, cos=0.260), tot_loss_proj:3.328 [t=0.23s]
prediction: ['[CLS] john because she demanded him stop theseoning. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.874 (perp=7.270, rec=0.161, cos=0.259), tot_loss_proj:3.332 [t=0.23s]
prediction: ['[CLS] john because she demanded him stop theseoning. [SEP]']
[ 750/2000] tot_loss=1.878 (perp=7.270, rec=0.166, cos=0.258), tot_loss_proj:3.339 [t=0.23s]
prediction: ['[CLS] john because she demanded him stop theseoning. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.866 (perp=7.270, rec=0.154, cos=0.257), tot_loss_proj:3.328 [t=0.23s]
prediction: ['[CLS] john because she demanded him stop theseoning. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.864 (perp=7.270, rec=0.153, cos=0.257), tot_loss_proj:3.331 [t=0.23s]
prediction: ['[CLS] john because she demanded him stop theseoning. [SEP]']
[ 900/2000] tot_loss=1.860 (perp=7.270, rec=0.150, cos=0.256), tot_loss_proj:3.329 [t=0.23s]
prediction: ['[CLS] john because she demanded him stop theseoning. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.865 (perp=7.270, rec=0.155, cos=0.256), tot_loss_proj:3.338 [t=0.23s]
prediction: ['[CLS] john because she demanded him stop theseoning. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.999 (perp=7.974, rec=0.149, cos=0.255), tot_loss_proj:3.463 [t=0.23s]
prediction: ['[CLS] john that she demanded him stop theseoning. [SEP]']
[1050/2000] tot_loss=2.002 (perp=7.974, rec=0.152, cos=0.255), tot_loss_proj:3.465 [t=0.23s]
prediction: ['[CLS] john that she demanded him stop theseoning. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.881 (perp=7.393, rec=0.148, cos=0.254), tot_loss_proj:3.378 [t=0.23s]
prediction: ['[CLS] john that she demanded him stop heroning. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.844 (perp=7.209, rec=0.150, cos=0.252), tot_loss_proj:3.337 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
[1200/2000] tot_loss=1.837 (perp=7.209, rec=0.142, cos=0.254), tot_loss_proj:3.325 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.850 (perp=7.209, rec=0.155, cos=0.253), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.834 (perp=7.209, rec=0.140, cos=0.253), tot_loss_proj:3.331 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
[1350/2000] tot_loss=1.842 (perp=7.209, rec=0.147, cos=0.252), tot_loss_proj:3.334 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.829 (perp=7.209, rec=0.136, cos=0.252), tot_loss_proj:3.328 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.828 (perp=7.209, rec=0.135, cos=0.251), tot_loss_proj:3.329 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
[1500/2000] tot_loss=1.839 (perp=7.209, rec=0.146, cos=0.251), tot_loss_proj:3.329 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.832 (perp=7.209, rec=0.140, cos=0.250), tot_loss_proj:3.330 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.831 (perp=7.209, rec=0.140, cos=0.249), tot_loss_proj:3.334 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
[1650/2000] tot_loss=1.823 (perp=7.209, rec=0.132, cos=0.249), tot_loss_proj:3.332 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.826 (perp=7.209, rec=0.136, cos=0.248), tot_loss_proj:3.327 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.822 (perp=7.209, rec=0.132, cos=0.248), tot_loss_proj:3.331 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
[1800/2000] tot_loss=1.822 (perp=7.209, rec=0.132, cos=0.248), tot_loss_proj:3.327 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.816 (perp=7.209, rec=0.126, cos=0.248), tot_loss_proj:3.335 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.818 (perp=7.209, rec=0.128, cos=0.248), tot_loss_proj:3.335 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
[1950/2000] tot_loss=1.823 (perp=7.209, rec=0.134, cos=0.248), tot_loss_proj:3.330 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.807 (perp=7.209, rec=0.117, cos=0.248), tot_loss_proj:3.338 [t=0.23s]
prediction: ['[CLS] john that she demanded him stoponing her. [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] john demanded that she stop phoning him. [SEP]
========================
predicted: 
========================
[CLS] john that she demanded him stoponing her. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 102.778

[Aggregate metrics]:
rouge1     | fm: 86.755 | p: 87.204 | r: 86.455
rouge2     | fm: 47.051 | p: 47.246 | r: 46.893
rougeL     | fm: 74.650 | p: 75.030 | r: 74.391
rougeLsum  | fm: 74.692 | p: 75.129 | r: 74.377
r1fm+r2fm = 133.806

input #18 time: 0:09:08 | total time: 2:54:36


Running input #19 of 100.
reference: 
========================
I have six too many marbles.
========================
average of cosine similarity 0.9197923644338966
highest_index [0]
highest [0.9197923644338966]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 1045, 2031, 2416, 2205, 2116, 7720, 2015, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have six too many marbles. [SEP]']
[Init] best rec loss: 0.9523891806602478 for ['[CLS] endemicston card horsevere kira particular glasses [SEP]']
[Init] best rec loss: 0.8963517546653748 for ['[CLS] they future math note ] chaseanza bore [SEP]']
[Init] best rec loss: 0.8896185755729675 for ['[CLS] make various los♥ that fraternity garden exported [SEP]']
[Init] best rec loss: 0.8512914776802063 for ['[CLS] basis anythingui cleared looking name began ce [SEP]']
[Init] best rec loss: 0.8455893993377686 for ['[CLS] two hanna syndicated dealer admitted henrycake canada [SEP]']
[Init] best rec loss: 0.844572126865387 for ['[CLS] rape relayntal alternate derby corresponds bearer austin [SEP]']
[Init] best rec loss: 0.8407225012779236 for ['[CLS] teachers process eventuallyv dim walker hellohun [SEP]']
[Init] best rec loss: 0.8019061088562012 for ['[CLS] tender bradford finished suit pcayo parliament boarding [SEP]']
[Init] best perm rec loss: 0.8001288175582886 for ['[CLS] bradford parliamentayo tender pc suit finished boarding [SEP]']
[Init] best perm rec loss: 0.7987958192825317 for ['[CLS] bradford finishedayo boarding pc suit tender parliament [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.190 (perp=12.833, rec=0.475, cos=0.148), tot_loss_proj:4.463 [t=0.23s]
prediction: ['[CLS] belmont too 2000 railwayinen salute four parliament [SEP]']
[ 100/2000] tot_loss=2.561 (perp=10.699, rec=0.270, cos=0.151), tot_loss_proj:3.989 [t=0.23s]
prediction: ['[CLS] i too six eight marble marble fivegate [SEP]']
[ 150/2000] tot_loss=2.306 (perp=9.799, rec=0.196, cos=0.150), tot_loss_proj:3.838 [t=0.23s]
prediction: ['[CLS] i too many six marble marble sixgate [SEP]']
[ 200/2000] tot_loss=2.052 (perp=8.769, rec=0.151, cos=0.147), tot_loss_proj:3.607 [t=0.23s]
prediction: ['[CLS] have too many six marble marble six i [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.840 (perp=7.755, rec=0.144, cos=0.145), tot_loss_proj:3.337 [t=0.23s]
prediction: ['[CLS] i have too many six marble presents six [SEP]']
[ 300/2000] tot_loss=1.834 (perp=7.755, rec=0.138, cos=0.145), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] i have too many six marble presents six [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.837 (perp=7.755, rec=0.128, cos=0.159), tot_loss_proj:3.340 [t=0.23s]
prediction: ['[CLS] i have too many six marble presents six [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.856 (perp=7.933, rec=0.118, cos=0.151), tot_loss_proj:3.261 [t=0.23s]
prediction: ['[CLS] i have too many six marble muscles six [SEP]']
[ 450/2000] tot_loss=1.884 (perp=8.032, rec=0.129, cos=0.149), tot_loss_proj:3.450 [t=0.23s]
prediction: ['[CLS] i have too many six marble similarly six [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.802 (perp=7.609, rec=0.125, cos=0.155), tot_loss_proj:3.387 [t=0.23s]
prediction: ['[CLS] i have too many six similarly five marble [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.795 (perp=7.609, rec=0.124, cos=0.149), tot_loss_proj:3.392 [t=0.23s]
prediction: ['[CLS] i have too many six similarly five marble [SEP]']
[ 600/2000] tot_loss=1.796 (perp=7.609, rec=0.122, cos=0.152), tot_loss_proj:3.388 [t=0.23s]
prediction: ['[CLS] i have too many six similarly five marble [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.795 (perp=7.609, rec=0.119, cos=0.154), tot_loss_proj:3.390 [t=0.23s]
prediction: ['[CLS] i have too many six similarly five marble [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.795 (perp=7.609, rec=0.123, cos=0.150), tot_loss_proj:3.392 [t=0.23s]
prediction: ['[CLS] i have too many six similarly five marble [SEP]']
[ 750/2000] tot_loss=1.983 (perp=8.562, rec=0.120, cos=0.151), tot_loss_proj:3.587 [t=0.23s]
prediction: ['[CLS] i have too many six ipad four marble [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.978 (perp=8.562, rec=0.116, cos=0.150), tot_loss_proj:3.587 [t=0.23s]
prediction: ['[CLS] i have too many six ipad four marble [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.983 (perp=8.562, rec=0.121, cos=0.150), tot_loss_proj:3.582 [t=0.23s]
prediction: ['[CLS] i have too many six ipad four marble [SEP]']
[ 900/2000] tot_loss=1.973 (perp=8.562, rec=0.110, cos=0.150), tot_loss_proj:3.591 [t=0.23s]
prediction: ['[CLS] i have too many six ipad four marble [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.995 (perp=8.562, rec=0.126, cos=0.157), tot_loss_proj:3.586 [t=0.23s]
prediction: ['[CLS] i have too many six ipad four marble [SEP]']
Attempt swap
[1000/2000] tot_loss=1.977 (perp=8.562, rec=0.113, cos=0.151), tot_loss_proj:3.589 [t=0.23s]
prediction: ['[CLS] i have too many six ipad four marble [SEP]']
[1050/2000] tot_loss=1.995 (perp=8.562, rec=0.127, cos=0.156), tot_loss_proj:3.587 [t=0.23s]
prediction: ['[CLS] i have too many six ipad four marble [SEP]']
Attempt swap
[1100/2000] tot_loss=1.993 (perp=8.562, rec=0.130, cos=0.151), tot_loss_proj:3.584 [t=0.23s]
prediction: ['[CLS] i have too many six ipad four marble [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.846 (perp=7.869, rec=0.119, cos=0.154), tot_loss_proj:3.426 [t=0.23s]
prediction: ['[CLS] i have six too many ipad four marble [SEP]']
[1200/2000] tot_loss=1.845 (perp=7.869, rec=0.117, cos=0.154), tot_loss_proj:3.429 [t=0.23s]
prediction: ['[CLS] i have six too many ipad four marble [SEP]']
Attempt swap
[1250/2000] tot_loss=1.840 (perp=7.869, rec=0.112, cos=0.154), tot_loss_proj:3.428 [t=0.23s]
prediction: ['[CLS] i have six too many ipad four marble [SEP]']
Attempt swap
[1300/2000] tot_loss=1.841 (perp=7.869, rec=0.114, cos=0.153), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS] i have six too many ipad four marble [SEP]']
[1350/2000] tot_loss=1.848 (perp=7.869, rec=0.123, cos=0.151), tot_loss_proj:3.427 [t=0.23s]
prediction: ['[CLS] i have six too many ipad four marble [SEP]']
Attempt swap
[1400/2000] tot_loss=1.853 (perp=7.927, rec=0.113, cos=0.155), tot_loss_proj:3.258 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
Attempt swap
[1450/2000] tot_loss=1.856 (perp=7.927, rec=0.117, cos=0.154), tot_loss_proj:3.260 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
[1500/2000] tot_loss=1.858 (perp=7.927, rec=0.119, cos=0.154), tot_loss_proj:3.256 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
Attempt swap
[1550/2000] tot_loss=1.860 (perp=7.927, rec=0.121, cos=0.153), tot_loss_proj:3.254 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
Attempt swap
[1600/2000] tot_loss=1.849 (perp=7.927, rec=0.111, cos=0.153), tot_loss_proj:3.255 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
[1650/2000] tot_loss=1.855 (perp=7.927, rec=0.116, cos=0.154), tot_loss_proj:3.253 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
Attempt swap
[1700/2000] tot_loss=1.855 (perp=7.927, rec=0.115, cos=0.154), tot_loss_proj:3.254 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
Attempt swap
[1750/2000] tot_loss=1.850 (perp=7.927, rec=0.110, cos=0.154), tot_loss_proj:3.254 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
[1800/2000] tot_loss=1.844 (perp=7.927, rec=0.105, cos=0.154), tot_loss_proj:3.251 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
Attempt swap
[1850/2000] tot_loss=1.860 (perp=7.927, rec=0.122, cos=0.153), tot_loss_proj:3.256 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
Attempt swap
[1900/2000] tot_loss=1.853 (perp=7.927, rec=0.114, cos=0.154), tot_loss_proj:3.254 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
[1950/2000] tot_loss=1.852 (perp=7.927, rec=0.112, cos=0.155), tot_loss_proj:3.256 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
Attempt swap
[2000/2000] tot_loss=1.852 (perp=7.927, rec=0.113, cos=0.153), tot_loss_proj:3.256 [t=0.23s]
prediction: ['[CLS] i have six too many ⟨ four marble [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] i have six too many marbles. [SEP]
========================
predicted: 
========================
[CLS] i have six too many ⟨ four marble [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 66.667 | p: 62.500 | r: 71.429
rougeL     | fm: 82.353 | p: 77.778 | r: 87.500
rougeLsum  | fm: 82.353 | p: 77.778 | r: 87.500
r1fm+r2fm = 149.020

[Aggregate metrics]:
rouge1     | fm: 86.536 | p: 86.708 | r: 86.652
rouge2     | fm: 47.753 | p: 47.836 | r: 47.889
rougeL     | fm: 75.167 | p: 75.339 | r: 75.228
rougeLsum  | fm: 75.212 | p: 75.290 | r: 75.304
r1fm+r2fm = 134.289

input #19 time: 0:09:08 | total time: 3:03:44


Running input #20 of 100.
reference: 
========================
Mark's single mindedness terrified me.
========================
average of cosine similarity 0.8850969818565368
highest_index [0]
highest [0.8850969818565368]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2928,  1005,  1055,  2309, 13128,  2791, 10215,  2033,  1012,
           102]], device='cuda:0')
Debug: ref = ["[CLS] mark's single mindedness terrified me. [SEP]"]
[Init] best rec loss: 0.8962409496307373 for ['[CLS] [CLS] asked sirius accessed ling women emphasis disc height [SEP]']
[Init] best rec loss: 0.8528295159339905 for ['[CLS] wall jake bill buy gaulcats franco crystalbel [SEP]']
[Init] best perm rec loss: 0.8505190014839172 for ['[CLS] buy crystal franco jakecats bill wallbel gaul [SEP]']
[Init] best perm rec loss: 0.8478203415870667 for ['[CLS] crystal gaul jake franco wallbel bill buycats [SEP]']
[Init] best perm rec loss: 0.8475383520126343 for ['[CLS] crystal jake franco gaulcats wall buybel bill [SEP]']
[Init] best perm rec loss: 0.8470309972763062 for ['[CLS] crystal wall jake buy gaulbel billcats franco [SEP]']
[Init] best perm rec loss: 0.8470203876495361 for ['[CLS] gaulcats wall bill francobel buy crystal jake [SEP]']
[Init] best perm rec loss: 0.8456951975822449 for ['[CLS] crystal gaul francobelcats buy bill wall jake [SEP]']
[Init] best perm rec loss: 0.8456326127052307 for ['[CLS] wall jake franco billbel buy gaulcats crystal [SEP]']
[Init] best perm rec loss: 0.8430081605911255 for ['[CLS] jake bill crystal wall gaul buybel francocats [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.696 (perp=10.845, rec=0.312, cos=0.214), tot_loss_proj:4.079 [t=0.23s]
prediction: ['[CLS]! mark that terrified mark westward anticipating idea failure [SEP]']
[ 100/2000] tot_loss=2.116 (perp=8.792, rec=0.152, cos=0.205), tot_loss_proj:3.674 [t=0.23s]
prediction: ["[CLS]'mark that terrified me minded minded mindedness [SEP]"]
[ 150/2000] tot_loss=2.162 (perp=9.222, rec=0.105, cos=0.213), tot_loss_proj:3.753 [t=0.23s]
prediction: ["[CLS]'mark s terrified me minded hearted mindedness [SEP]"]
[ 200/2000] tot_loss=2.042 (perp=8.665, rec=0.092, cos=0.217), tot_loss_proj:3.626 [t=0.23s]
prediction: ["[CLS]'mark s terrified me single hearted mindedness [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.110 (perp=9.010, rec=0.094, cos=0.214), tot_loss_proj:3.697 [t=0.23s]
prediction: ["[CLS] mark's terrified me single combustion mindedness [SEP]"]
[ 300/2000] tot_loss=2.019 (perp=8.624, rec=0.079, cos=0.215), tot_loss_proj:3.589 [t=0.23s]
prediction: ["[CLS] mark's terrified me single irrigation mindedness [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=1.616 (perp=6.606, rec=0.078, cos=0.216), tot_loss_proj:3.253 [t=0.23s]
prediction: ["[CLS] mark's terrified me single mindedness. [SEP]"]
Attempt swap
[ 400/2000] tot_loss=1.613 (perp=6.606, rec=0.076, cos=0.216), tot_loss_proj:3.252 [t=0.23s]
prediction: ["[CLS] mark's terrified me single mindedness. [SEP]"]
[ 450/2000] tot_loss=1.617 (perp=6.606, rec=0.081, cos=0.215), tot_loss_proj:3.253 [t=0.23s]
prediction: ["[CLS] mark's terrified me single mindedness. [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.614 (perp=6.606, rec=0.078, cos=0.214), tot_loss_proj:3.255 [t=0.23s]
prediction: ["[CLS] mark's terrified me single mindedness. [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.618 (perp=6.606, rec=0.081, cos=0.216), tot_loss_proj:3.250 [t=0.23s]
prediction: ["[CLS] mark's terrified me single mindedness. [SEP]"]
[ 600/2000] tot_loss=1.612 (perp=6.606, rec=0.074, cos=0.217), tot_loss_proj:3.248 [t=0.23s]
prediction: ["[CLS] mark's terrified me single mindedness. [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.604 (perp=6.606, rec=0.067, cos=0.215), tot_loss_proj:3.248 [t=0.23s]
prediction: ["[CLS] mark's terrified me single mindedness. [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.610 (perp=6.606, rec=0.072, cos=0.216), tot_loss_proj:3.250 [t=0.23s]
prediction: ["[CLS] mark's terrified me single mindedness. [SEP]"]
[ 750/2000] tot_loss=1.622 (perp=6.606, rec=0.085, cos=0.216), tot_loss_proj:3.257 [t=0.23s]
prediction: ["[CLS] mark's terrified me single mindedness. [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.614 (perp=6.606, rec=0.077, cos=0.216), tot_loss_proj:3.256 [t=0.23s]
prediction: ["[CLS] mark's terrified me single mindedness. [SEP]"]
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.503 (perp=6.065, rec=0.077, cos=0.213), tot_loss_proj:1.542 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
[ 900/2000] tot_loss=1.506 (perp=6.065, rec=0.078, cos=0.215), tot_loss_proj:1.540 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.502 (perp=6.065, rec=0.074, cos=0.216), tot_loss_proj:1.537 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.500 (perp=6.065, rec=0.073, cos=0.215), tot_loss_proj:1.528 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
[1050/2000] tot_loss=1.505 (perp=6.065, rec=0.076, cos=0.216), tot_loss_proj:1.536 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.496 (perp=6.065, rec=0.067, cos=0.216), tot_loss_proj:1.534 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.497 (perp=6.065, rec=0.068, cos=0.216), tot_loss_proj:1.541 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
[1200/2000] tot_loss=1.488 (perp=6.065, rec=0.059, cos=0.216), tot_loss_proj:1.536 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.502 (perp=6.065, rec=0.074, cos=0.215), tot_loss_proj:1.527 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.501 (perp=6.065, rec=0.073, cos=0.215), tot_loss_proj:1.541 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
[1350/2000] tot_loss=1.490 (perp=6.065, rec=0.061, cos=0.216), tot_loss_proj:1.536 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.502 (perp=6.065, rec=0.074, cos=0.216), tot_loss_proj:1.542 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.504 (perp=6.065, rec=0.076, cos=0.215), tot_loss_proj:1.534 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
[1500/2000] tot_loss=1.491 (perp=6.065, rec=0.063, cos=0.215), tot_loss_proj:1.533 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.495 (perp=6.065, rec=0.067, cos=0.215), tot_loss_proj:1.532 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.493 (perp=6.065, rec=0.066, cos=0.215), tot_loss_proj:1.537 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
[1650/2000] tot_loss=1.488 (perp=6.065, rec=0.061, cos=0.215), tot_loss_proj:1.530 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.497 (perp=6.065, rec=0.070, cos=0.214), tot_loss_proj:1.539 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.488 (perp=6.065, rec=0.061, cos=0.214), tot_loss_proj:1.534 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
[1800/2000] tot_loss=1.498 (perp=6.065, rec=0.071, cos=0.214), tot_loss_proj:1.538 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.497 (perp=6.065, rec=0.070, cos=0.214), tot_loss_proj:1.544 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.493 (perp=6.065, rec=0.067, cos=0.214), tot_loss_proj:1.527 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
[1950/2000] tot_loss=1.491 (perp=6.065, rec=0.065, cos=0.214), tot_loss_proj:1.534 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.508 (perp=6.065, rec=0.081, cos=0.214), tot_loss_proj:1.528 [t=0.23s]
prediction: ["[CLS] mark's single mindedness terrified me. [SEP]"]
Done with input #20 of 100.
reference: 
========================
[CLS] mark's single mindedness terrified me. [SEP]
========================
predicted: 
========================
[CLS] mark's single mindedness terrified me. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.053 | p: 87.287 | r: 87.034
rouge2     | fm: 50.313 | p: 50.261 | r: 50.426
rougeL     | fm: 76.340 | p: 76.485 | r: 76.424
rougeLsum  | fm: 76.307 | p: 76.480 | r: 76.253
r1fm+r2fm = 137.365

input #20 time: 0:09:11 | total time: 3:12:55


Running input #21 of 100.
reference: 
========================
Her indiscretions were made light of.
========================
average of cosine similarity 0.9139943367618769
highest_index [0]
highest [0.9139943367618769]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2014, 27427,  2483, 16748,  9285,  2020,  2081,  2422,  1997,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] her indiscretions were made light of. [SEP]']
[Init] best rec loss: 0.9611144065856934 for ['[CLS] dung help makei de blinds commissioned "z graders [SEP]']
[Init] best rec loss: 0.9562716484069824 for ['[CLS]bet birthday reised save doug ) haunt ranked dated [SEP]']
[Init] best rec loss: 0.9546946287155151 for ['[CLS] our regal hadn bollywood parasite pere betapath attack photograph [SEP]']
[Init] best rec loss: 0.9368941187858582 for ['[CLS] toss morrison port th scene body principalsm wild stations [SEP]']
[Init] best rec loss: 0.9135777354240417 for ['[CLS]sms hewitthe inningstraju holesditional boil lights [SEP]']
[Init] best rec loss: 0.8821534514427185 for ['[CLS]amen command around regan dumping warm hall knock bethlehem° [SEP]']
[Init] best perm rec loss: 0.8794276714324951 for ['[CLS]° warm knock hall regan dumping bethlehem around commandamen [SEP]']
[Init] best perm rec loss: 0.8783784508705139 for ['[CLS] bethlehem dumping reganamen warm command knock around° hall [SEP]']
[Init] best perm rec loss: 0.8732175230979919 for ['[CLS] warm regan dumpingamen knock command bethlehem° hall around [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.474 (perp=10.086, rec=0.302, cos=0.155), tot_loss_proj:3.868 [t=0.23s]
prediction: ['[CLS] combin.cre. his aperturetions personaltone [SEP]']
[ 100/2000] tot_loss=2.463 (perp=10.458, rec=0.209, cos=0.162), tot_loss_proj:3.936 [t=0.23s]
prediction: ['[CLS]tionstions.cre. werecretions heritude [SEP]']
[ 150/2000] tot_loss=2.724 (perp=11.927, rec=0.178, cos=0.161), tot_loss_proj:4.235 [t=0.23s]
prediction: ['[CLS]tionstions ofcre were madecre light hertions [SEP]']
[ 200/2000] tot_loss=2.762 (perp=12.330, rec=0.135, cos=0.161), tot_loss_proj:4.312 [t=0.23s]
prediction: ['[CLS] indtions ofcre were madecre light hertions [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.373 (perp=9.997, rec=0.216, cos=0.158), tot_loss_proj:3.801 [t=0.23s]
prediction: ['[CLS] ind.cretions were inscre light her or [SEP]']
[ 300/2000] tot_loss=2.307 (perp=9.997, rec=0.143, cos=0.164), tot_loss_proj:3.792 [t=0.23s]
prediction: ['[CLS] ind.cretions were inscre light her or [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.915 (perp=8.124, rec=0.126, cos=0.164), tot_loss_proj:3.515 [t=0.23s]
prediction: ['[CLS] ind hercretions were inscre light. or [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.945 (perp=8.119, rec=0.155, cos=0.166), tot_loss_proj:3.434 [t=0.23s]
prediction: ['[CLS] ind hercretions were insis / light. [SEP]']
[ 450/2000] tot_loss=1.773 (perp=7.431, rec=0.122, cos=0.165), tot_loss_proj:3.285 [t=0.23s]
prediction: ['[CLS] ind hercretions were indis / light. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.767 (perp=7.431, rec=0.119, cos=0.162), tot_loss_proj:3.282 [t=0.23s]
prediction: ['[CLS] ind hercretions were indis / light. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.097 (perp=9.068, rec=0.121, cos=0.163), tot_loss_proj:3.699 [t=0.23s]
prediction: ['[CLS] her indcretions made madeis five light. [SEP]']
[ 600/2000] tot_loss=2.095 (perp=9.068, rec=0.118, cos=0.163), tot_loss_proj:3.705 [t=0.23s]
prediction: ['[CLS] her indcretions made madeis five light. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.515 (perp=6.127, rec=0.127, cos=0.164), tot_loss_proj:3.058 [t=0.23s]
prediction: ['[CLS] her indiscretions were made vinci light. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.445 (perp=5.805, rec=0.119, cos=0.165), tot_loss_proj:3.051 [t=0.23s]
prediction: ['[CLS] her indiscretions made made light. five [SEP]']
[ 750/2000] tot_loss=1.435 (perp=5.805, rec=0.109, cos=0.164), tot_loss_proj:3.056 [t=0.23s]
prediction: ['[CLS] her indiscretions made made light. five [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.430 (perp=5.805, rec=0.105, cos=0.164), tot_loss_proj:3.051 [t=0.23s]
prediction: ['[CLS] her indiscretions made made light. five [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.429 (perp=5.805, rec=0.103, cos=0.165), tot_loss_proj:3.058 [t=0.23s]
prediction: ['[CLS] her indiscretions made made light. five [SEP]']
[ 900/2000] tot_loss=1.425 (perp=5.805, rec=0.099, cos=0.164), tot_loss_proj:3.055 [t=0.23s]
prediction: ['[CLS] her indiscretions made made light. five [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.427 (perp=5.805, rec=0.102, cos=0.164), tot_loss_proj:3.057 [t=0.23s]
prediction: ['[CLS] her indiscretions made made light. five [SEP]']
Attempt swap
[1000/2000] tot_loss=1.431 (perp=5.805, rec=0.105, cos=0.165), tot_loss_proj:3.059 [t=0.23s]
prediction: ['[CLS] her indiscretions made made light. five [SEP]']
[1050/2000] tot_loss=1.429 (perp=5.805, rec=0.104, cos=0.164), tot_loss_proj:3.058 [t=0.23s]
prediction: ['[CLS] her indiscretions made made light. five [SEP]']
Attempt swap
[1100/2000] tot_loss=1.431 (perp=5.805, rec=0.106, cos=0.164), tot_loss_proj:3.063 [t=0.23s]
prediction: ['[CLS] her indiscretions made made light. five [SEP]']
Attempt swap
[1150/2000] tot_loss=1.299 (perp=5.151, rec=0.104, cos=0.164), tot_loss_proj:2.635 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
[1200/2000] tot_loss=1.295 (perp=5.151, rec=0.100, cos=0.164), tot_loss_proj:2.635 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Attempt swap
[1250/2000] tot_loss=1.290 (perp=5.151, rec=0.095, cos=0.164), tot_loss_proj:2.632 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Attempt swap
[1300/2000] tot_loss=1.292 (perp=5.151, rec=0.098, cos=0.164), tot_loss_proj:2.631 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
[1350/2000] tot_loss=1.290 (perp=5.151, rec=0.096, cos=0.164), tot_loss_proj:2.632 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Attempt swap
[1400/2000] tot_loss=1.302 (perp=5.151, rec=0.107, cos=0.165), tot_loss_proj:2.635 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Attempt swap
[1450/2000] tot_loss=1.294 (perp=5.151, rec=0.099, cos=0.164), tot_loss_proj:2.633 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
[1500/2000] tot_loss=1.293 (perp=5.151, rec=0.099, cos=0.164), tot_loss_proj:2.632 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Attempt swap
[1550/2000] tot_loss=1.297 (perp=5.151, rec=0.103, cos=0.164), tot_loss_proj:2.635 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Attempt swap
[1600/2000] tot_loss=1.286 (perp=5.151, rec=0.091, cos=0.164), tot_loss_proj:2.632 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
[1650/2000] tot_loss=1.287 (perp=5.151, rec=0.093, cos=0.164), tot_loss_proj:2.640 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Attempt swap
[1700/2000] tot_loss=1.284 (perp=5.151, rec=0.089, cos=0.164), tot_loss_proj:2.636 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Attempt swap
[1750/2000] tot_loss=1.283 (perp=5.151, rec=0.088, cos=0.164), tot_loss_proj:2.631 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
[1800/2000] tot_loss=1.280 (perp=5.151, rec=0.086, cos=0.164), tot_loss_proj:2.636 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Attempt swap
[1850/2000] tot_loss=1.287 (perp=5.151, rec=0.093, cos=0.164), tot_loss_proj:2.630 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Attempt swap
[1900/2000] tot_loss=1.302 (perp=5.151, rec=0.107, cos=0.164), tot_loss_proj:2.630 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
[1950/2000] tot_loss=1.284 (perp=5.151, rec=0.089, cos=0.164), tot_loss_proj:2.632 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Attempt swap
[2000/2000] tot_loss=1.290 (perp=5.151, rec=0.096, cos=0.164), tot_loss_proj:2.627 [t=0.23s]
prediction: ['[CLS] her indiscretions were made light. five [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] her indiscretions were made light of. [SEP]
========================
predicted: 
========================
[CLS] her indiscretions were made light. five [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 71.429 | p: 71.429 | r: 71.429
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 158.929

[Aggregate metrics]:
rouge1     | fm: 87.098 | p: 87.285 | r: 87.103
rouge2     | fm: 51.065 | p: 51.036 | r: 51.256
rougeL     | fm: 76.911 | p: 76.980 | r: 76.985
rougeLsum  | fm: 76.850 | p: 77.014 | r: 76.867
r1fm+r2fm = 138.163

input #21 time: 0:09:08 | total time: 3:22:04


Running input #22 of 100.
reference: 
========================
Each of the boys fought with the other boys.
========================
average of cosine similarity 0.8871262991891281
highest_index [0]
highest [0.8871262991891281]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2169, 1997, 1996, 3337, 4061, 2007, 1996, 2060, 3337, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] each of the boys fought with the other boys. [SEP]']
[Init] best rec loss: 0.9830096960067749 for ['[CLS] hers hours woundmund totaling pd hailey stone aftermath tortricidae [SEP]']
[Init] best rec loss: 0.9015089869499207 for ['[CLS] library em group come surprise pass varsity moderate must blackness [SEP]']
[Init] best rec loss: 0.8777689337730408 for ['[CLS]ned swedish darlingori alternativeonaitical peace leave abandoned [SEP]']
[Init] best rec loss: 0.8771474957466125 for ['[CLS]wu grape danube liablelete service rebeccad evenour [SEP]']
[Init] best perm rec loss: 0.8762349486351013 for ['[CLS] grape liable rebeccawu evendour service danubelete [SEP]']
[Init] best perm rec loss: 0.8751144409179688 for ['[CLS] even liableour danubewu serviceleted grape rebecca [SEP]']
[Init] best perm rec loss: 0.8746293187141418 for ['[CLS]leteour service danube graped liable rebecca evenwu [SEP]']
[Init] best perm rec loss: 0.8719444274902344 for ['[CLS]leted liable grapeour rebecca servicewu even danube [SEP]']
[Init] best perm rec loss: 0.8713632225990295 for ['[CLS]our liable even serviced grapeletewu danube rebecca [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.041 (perp=12.176, rec=0.400, cos=0.206), tot_loss_proj:4.273 [t=0.23s]
prediction: ['[CLS]istle violent between girl boys double other boys guard combo [SEP]']
[ 100/2000] tot_loss=2.804 (perp=11.621, rec=0.270, cos=0.210), tot_loss_proj:4.181 [t=0.23s]
prediction: ['[CLS]istle each forbidden boys fought two the boys foughtlong [SEP]']
[ 150/2000] tot_loss=2.057 (perp=8.507, rec=0.141, cos=0.214), tot_loss_proj:3.581 [t=0.23s]
prediction: ['[CLS]. each other boys fought other the boys foughtlong [SEP]']
[ 200/2000] tot_loss=2.009 (perp=8.475, rec=0.104, cos=0.210), tot_loss_proj:3.542 [t=0.23s]
prediction: ['[CLS]. each other boys fought other the boys withlong [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.688 (perp=6.907, rec=0.098, cos=0.209), tot_loss_proj:3.279 [t=0.23s]
prediction: ['[CLS]. each other boys fought the other boys with during [SEP]']
[ 300/2000] tot_loss=1.446 (perp=5.766, rec=0.081, cos=0.212), tot_loss_proj:3.028 [t=0.23s]
prediction: ['[CLS]. each other boys fought the other boys with. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.638 (perp=6.725, rec=0.081, cos=0.212), tot_loss_proj:3.208 [t=0.23s]
prediction: ['[CLS] each. other boys fought the other boys with of [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.639 (perp=6.725, rec=0.081, cos=0.213), tot_loss_proj:3.209 [t=0.23s]
prediction: ['[CLS] each. other boys fought the other boys with of [SEP]']
[ 450/2000] tot_loss=1.625 (perp=6.725, rec=0.068, cos=0.212), tot_loss_proj:3.206 [t=0.23s]
prediction: ['[CLS] each. other boys fought the other boys with of [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.622 (perp=6.444, rec=0.124, cos=0.210), tot_loss_proj:3.064 [t=0.23s]
prediction: ['[CLS] each the the boys fought with the other boys of [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.348 (perp=5.191, rec=0.097, cos=0.213), tot_loss_proj:2.050 [t=0.23s]
prediction: ['[CLS] each of the boys fought with the other boys the [SEP]']
[ 600/2000] tot_loss=1.345 (perp=5.191, rec=0.094, cos=0.213), tot_loss_proj:2.015 [t=0.23s]
prediction: ['[CLS] each of the boys fought with the other boys the [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.344 (perp=5.191, rec=0.093, cos=0.213), tot_loss_proj:2.000 [t=0.23s]
prediction: ['[CLS] each of the boys fought with the other boys the [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.325 (perp=5.174, rec=0.078, cos=0.212), tot_loss_proj:2.959 [t=0.23s]
prediction: ['[CLS] each of the boys fought with the other the boys [SEP]']
[ 750/2000] tot_loss=1.327 (perp=5.174, rec=0.079, cos=0.213), tot_loss_proj:2.966 [t=0.23s]
prediction: ['[CLS] each of the boys fought with the other the boys [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.720 (perp=7.109, rec=0.085, cos=0.213), tot_loss_proj:3.271 [t=0.23s]
prediction: ['[CLS] each of. boys fought with the other boys the [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.335 (perp=5.156, rec=0.093, cos=0.211), tot_loss_proj:1.539 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
[ 900/2000] tot_loss=1.322 (perp=5.156, rec=0.078, cos=0.212), tot_loss_proj:1.611 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.332 (perp=5.156, rec=0.088, cos=0.213), tot_loss_proj:1.646 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
Attempt swap
[1000/2000] tot_loss=1.329 (perp=5.156, rec=0.085, cos=0.213), tot_loss_proj:1.652 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
[1050/2000] tot_loss=1.319 (perp=5.156, rec=0.074, cos=0.213), tot_loss_proj:1.658 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
Attempt swap
[1100/2000] tot_loss=1.326 (perp=5.156, rec=0.082, cos=0.213), tot_loss_proj:1.675 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.330 (perp=5.156, rec=0.086, cos=0.213), tot_loss_proj:1.564 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
[1200/2000] tot_loss=1.312 (perp=5.156, rec=0.067, cos=0.213), tot_loss_proj:1.562 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
Attempt swap
[1250/2000] tot_loss=1.321 (perp=5.156, rec=0.077, cos=0.213), tot_loss_proj:1.561 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
Attempt swap
[1300/2000] tot_loss=1.324 (perp=5.156, rec=0.080, cos=0.213), tot_loss_proj:1.555 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
[1350/2000] tot_loss=1.323 (perp=5.156, rec=0.079, cos=0.213), tot_loss_proj:1.564 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.326 (perp=5.156, rec=0.082, cos=0.212), tot_loss_proj:1.668 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.318 (perp=5.156, rec=0.074, cos=0.212), tot_loss_proj:1.558 [t=0.23s]
prediction: ['[CLS] each of the the boys fought with the other boys [SEP]']
[1500/2000] tot_loss=1.561 (perp=6.339, rec=0.081, cos=0.213), tot_loss_proj:2.999 [t=0.23s]
prediction: ['[CLS] each of the. boys fought with the other boys [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.379 (perp=5.429, rec=0.081, cos=0.212), tot_loss_proj:2.957 [t=0.23s]
prediction: ['[CLS] each of the boys fought with the the other boys [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.332 (perp=5.174, rec=0.084, cos=0.213), tot_loss_proj:2.990 [t=0.23s]
prediction: ['[CLS] each of the boys fought with the other the boys [SEP]']
[1650/2000] tot_loss=1.331 (perp=5.174, rec=0.083, cos=0.213), tot_loss_proj:2.987 [t=0.23s]
prediction: ['[CLS] each of the boys fought with the other the boys [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.281 (perp=5.002, rec=0.070, cos=0.211), tot_loss_proj:2.375 [t=0.23s]
prediction: ['[CLS] each of the boys fought the other with the boys [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.293 (perp=5.002, rec=0.081, cos=0.212), tot_loss_proj:2.333 [t=0.23s]
prediction: ['[CLS] each of the boys fought the other with the boys [SEP]']
[1800/2000] tot_loss=1.291 (perp=5.002, rec=0.078, cos=0.213), tot_loss_proj:2.333 [t=0.23s]
prediction: ['[CLS] each of the boys fought the other with the boys [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.290 (perp=5.002, rec=0.077, cos=0.212), tot_loss_proj:2.368 [t=0.23s]
prediction: ['[CLS] each of the boys fought the other with the boys [SEP]']
Attempt swap
[1900/2000] tot_loss=1.290 (perp=5.002, rec=0.078, cos=0.213), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] each of the boys fought the other with the boys [SEP]']
[1950/2000] tot_loss=1.284 (perp=5.002, rec=0.071, cos=0.213), tot_loss_proj:2.369 [t=0.23s]
prediction: ['[CLS] each of the boys fought the other with the boys [SEP]']
Attempt swap
[2000/2000] tot_loss=1.293 (perp=5.002, rec=0.079, cos=0.213), tot_loss_proj:2.366 [t=0.23s]
prediction: ['[CLS] each of the boys fought the other with the boys [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] each of the boys fought with the other boys. [SEP]
========================
predicted: 
========================
[CLS] each of the boys fought the other with the boys [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 76.190 | p: 72.727 | r: 80.000
rougeL     | fm: 86.957 | p: 83.333 | r: 90.909
rougeLsum  | fm: 86.957 | p: 83.333 | r: 90.909
r1fm+r2fm = 171.843

[Aggregate metrics]:
rouge1     | fm: 87.565 | p: 87.574 | r: 87.734
rouge2     | fm: 52.542 | p: 52.372 | r: 52.765
rougeL     | fm: 77.497 | p: 77.438 | r: 77.678
rougeLsum  | fm: 77.259 | p: 77.232 | r: 77.427
r1fm+r2fm = 140.107

input #22 time: 0:09:08 | total time: 3:31:12


Running input #23 of 100.
reference: 
========================
Herman mixed the eggs with the cream.
========================
average of cosine similarity 0.8847404061126213
highest_index [0]
highest [0.8847404061126213]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 11458,  3816,  1996,  6763,  2007,  1996,  6949,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] herman mixed the eggs with the cream. [SEP]']
[Init] best rec loss: 0.9764388203620911 for ['[CLS] digital borrow applied lodging luc reconciliation rhys toe [SEP]']
[Init] best rec loss: 0.955634593963623 for ['[CLS] slapped seal near ice sick funk operation commodore [SEP]']
[Init] best rec loss: 0.9367515444755554 for ['[CLS] both yours parliamentary zeppelin scale wieborg bridge [SEP]']
[Init] best rec loss: 0.9336662888526917 for ['[CLS] lights field luisa wooden suite haste winston jurisdiction [SEP]']
[Init] best rec loss: 0.926194429397583 for ['[CLS] paving anthony exactly production coffee fitted tract diocese [SEP]']
[Init] best rec loss: 0.9227817058563232 for ['[CLS]zed rich avant pas h authorities despite ants [SEP]']
[Init] best rec loss: 0.9216457009315491 for ['[CLS] ever assists fellowship silly trevor obsolete bone charged [SEP]']
[Init] best perm rec loss: 0.9191590547561646 for ['[CLS] ever charged obsolete assists trevor bone silly fellowship [SEP]']
[Init] best perm rec loss: 0.9184398651123047 for ['[CLS] obsolete assists silly trevor bone ever fellowship charged [SEP]']
[Init] best perm rec loss: 0.9156961441040039 for ['[CLS] bone fellowship ever trevor silly obsolete charged assists [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.993 (perp=12.246, rec=0.327, cos=0.217), tot_loss_proj:4.241 [t=0.23s]
prediction: ["[CLS] erik want ( hawaiian'japanese crates distrust [SEP]"]
[ 100/2000] tot_loss=2.538 (perp=10.517, rec=0.216, cos=0.218), tot_loss_proj:4.012 [t=0.23s]
prediction: ['[CLS] herman reviews. cream the eggs cream emails [SEP]']
[ 150/2000] tot_loss=2.647 (perp=11.369, rec=0.156, cos=0.217), tot_loss_proj:4.166 [t=0.23s]
prediction: ['[CLS] herman with. cream mixed eggs cream emails [SEP]']
[ 200/2000] tot_loss=2.612 (perp=11.369, rec=0.126, cos=0.213), tot_loss_proj:4.175 [t=0.23s]
prediction: ['[CLS] herman with. cream mixed eggs cream emails [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.134 (perp=9.065, rec=0.113, cos=0.207), tot_loss_proj:3.083 [t=0.23s]
prediction: ['[CLS] herman mixed the mixed eggs with cream emails [SEP]']
[ 300/2000] tot_loss=2.116 (perp=9.020, rec=0.098, cos=0.213), tot_loss_proj:2.906 [t=0.23s]
prediction: ['[CLS] herman mixed the mixed eggs with cream observed [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.021 (perp=8.635, rec=0.081, cos=0.213), tot_loss_proj:3.647 [t=0.23s]
prediction: ['[CLS] herman mixed the eggs with cream mixed observed [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.980 (perp=8.411, rec=0.083, cos=0.214), tot_loss_proj:3.567 [t=0.23s]
prediction: ['[CLS] herman. the eggs with cream mixed observed [SEP]']
[ 450/2000] tot_loss=1.986 (perp=8.411, rec=0.089, cos=0.215), tot_loss_proj:3.568 [t=0.23s]
prediction: ['[CLS] herman. the eggs with cream mixed observed [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.738 (perp=7.189, rec=0.087, cos=0.213), tot_loss_proj:3.362 [t=0.23s]
prediction: ['[CLS] herman in the eggs with cream mixed. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.697 (perp=6.929, rec=0.097, cos=0.214), tot_loss_proj:2.779 [t=0.23s]
prediction: ['[CLS] herman observed the eggs with cream mixed. [SEP]']
[ 600/2000] tot_loss=1.677 (perp=6.929, rec=0.076, cos=0.215), tot_loss_proj:2.778 [t=0.23s]
prediction: ['[CLS] herman observed the eggs with cream mixed. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.679 (perp=6.929, rec=0.078, cos=0.215), tot_loss_proj:2.779 [t=0.23s]
prediction: ['[CLS] herman observed the eggs with cream mixed. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.950 (perp=8.252, rec=0.085, cos=0.215), tot_loss_proj:3.511 [t=0.23s]
prediction: ['[CLS] herman the the eggs with cream mixed. [SEP]']
[ 750/2000] tot_loss=1.943 (perp=8.252, rec=0.078, cos=0.215), tot_loss_proj:3.514 [t=0.23s]
prediction: ['[CLS] herman the the eggs with cream mixed. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.727 (perp=7.067, rec=0.100, cos=0.213), tot_loss_proj:3.308 [t=0.23s]
prediction: ['[CLS] herman mixed the the eggs with cream. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.668 (perp=6.771, rec=0.101, cos=0.213), tot_loss_proj:3.186 [t=0.23s]
prediction: ['[CLS] the herman mixed the eggs with cream. [SEP]']
[ 900/2000] tot_loss=1.661 (perp=6.771, rec=0.093, cos=0.215), tot_loss_proj:3.188 [t=0.23s]
prediction: ['[CLS] the herman mixed the eggs with cream. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.663 (perp=6.771, rec=0.094, cos=0.215), tot_loss_proj:3.180 [t=0.23s]
prediction: ['[CLS] the herman mixed the eggs with cream. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.705 (perp=6.994, rec=0.094, cos=0.213), tot_loss_proj:3.320 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
[1050/2000] tot_loss=1.708 (perp=6.994, rec=0.095, cos=0.214), tot_loss_proj:3.317 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.704 (perp=6.994, rec=0.090, cos=0.215), tot_loss_proj:3.319 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.700 (perp=6.994, rec=0.086, cos=0.215), tot_loss_proj:3.319 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
[1200/2000] tot_loss=1.688 (perp=6.994, rec=0.074, cos=0.215), tot_loss_proj:3.323 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.698 (perp=6.994, rec=0.083, cos=0.216), tot_loss_proj:3.320 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.694 (perp=6.994, rec=0.079, cos=0.216), tot_loss_proj:3.318 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
[1350/2000] tot_loss=1.701 (perp=6.994, rec=0.087, cos=0.216), tot_loss_proj:3.318 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.692 (perp=6.994, rec=0.077, cos=0.216), tot_loss_proj:3.320 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.706 (perp=6.994, rec=0.091, cos=0.216), tot_loss_proj:3.318 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
[1500/2000] tot_loss=1.699 (perp=6.994, rec=0.084, cos=0.216), tot_loss_proj:3.322 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.693 (perp=6.994, rec=0.078, cos=0.216), tot_loss_proj:3.322 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.696 (perp=6.994, rec=0.081, cos=0.216), tot_loss_proj:3.319 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
[1650/2000] tot_loss=1.701 (perp=6.994, rec=0.086, cos=0.216), tot_loss_proj:3.321 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.712 (perp=6.994, rec=0.097, cos=0.216), tot_loss_proj:3.317 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.701 (perp=6.994, rec=0.086, cos=0.216), tot_loss_proj:3.321 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
[1800/2000] tot_loss=1.691 (perp=6.994, rec=0.076, cos=0.216), tot_loss_proj:3.321 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.701 (perp=6.994, rec=0.086, cos=0.216), tot_loss_proj:3.324 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.702 (perp=6.994, rec=0.087, cos=0.216), tot_loss_proj:3.318 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
[1950/2000] tot_loss=1.707 (perp=6.994, rec=0.092, cos=0.216), tot_loss_proj:3.321 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.703 (perp=6.994, rec=0.088, cos=0.216), tot_loss_proj:3.323 [t=0.23s]
prediction: ['[CLS] in herman mixed the eggs with cream. [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] herman mixed the eggs with the cream. [SEP]
========================
predicted: 
========================
[CLS] in herman mixed the eggs with cream. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 151.389

[Aggregate metrics]:
rouge1     | fm: 87.540 | p: 87.536 | r: 87.704
rouge2     | fm: 52.852 | p: 52.614 | r: 53.049
rougeL     | fm: 77.840 | p: 77.687 | r: 78.055
rougeLsum  | fm: 77.813 | p: 77.742 | r: 78.009
r1fm+r2fm = 140.392

input #23 time: 0:09:09 | total time: 3:40:22


Running input #24 of 100.
reference: 
========================
No John Smiths attended the meeting.
========================
average of cosine similarity 0.8729381716477268
highest_index [0]
highest [0.8729381716477268]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2053, 2198, 3044, 2015, 3230, 1996, 3116, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] no john smiths attended the meeting. [SEP]']
[Init] best rec loss: 0.8860400319099426 for ['[CLS] performance maybe rae tri / window grace lockheed [SEP]']
[Init] best rec loss: 0.8698428869247437 for ['[CLS] documentary mystery influence club guardian cinemas coast degrees [SEP]']
[Init] best rec loss: 0.8526583909988403 for ['[CLS] choir standard accomplished thank opposite savoy panelina [SEP]']
[Init] best rec loss: 0.8307800889015198 for ['[CLS] bunch lion discussed hands behind to hthic [SEP]']
[Init] best rec loss: 0.7937976717948914 for ['[CLS] realuaryractive [SEP] lily signing systematicium [SEP]']
[Init] best perm rec loss: 0.7915882468223572 for ['[CLS]iumractive real lily systematic [SEP] signinguary [SEP]']
[Init] best perm rec loss: 0.7902994155883789 for ['[CLS] systematicium signing [SEP] realractiveuary lily [SEP]']
[Init] best perm rec loss: 0.7898271083831787 for ['[CLS]uary realractiveium lily [SEP] signing systematic [SEP]']
[Init] best perm rec loss: 0.7874782681465149 for ['[CLS] signingractive lilyuary real [SEP]ium systematic [SEP]']
[Init] best perm rec loss: 0.7871701717376709 for ['[CLS] lily [SEP]iumuary signingractive systematic real [SEP]']
[Init] best perm rec loss: 0.785388708114624 for ['[CLS]uary lilyium signing [SEP] real systematicractive [SEP]']
[Init] best perm rec loss: 0.7853050827980042 for ['[CLS] lilyium real [SEP]ractiveuary signing systematic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.548 (perp=9.511, rec=0.408, cos=0.237), tot_loss_proj:3.532 [t=0.22s]
prediction: ['[CLS] john smith church instrumental charter john smith musicians [SEP]']
[ 100/2000] tot_loss=2.372 (perp=9.236, rec=0.304, cos=0.221), tot_loss_proj:3.677 [t=0.22s]
prediction: ['[CLS] john smiths attended none john smith leaders [SEP]']
[ 150/2000] tot_loss=1.800 (perp=7.022, rec=0.164, cos=0.231), tot_loss_proj:3.147 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john smith attended [SEP]']
[ 200/2000] tot_loss=1.764 (perp=7.022, rec=0.119, cos=0.240), tot_loss_proj:3.138 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john smith attended [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.750 (perp=7.022, rec=0.116, cos=0.230), tot_loss_proj:3.135 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john smith attended [SEP]']
[ 300/2000] tot_loss=1.745 (perp=7.022, rec=0.103, cos=0.238), tot_loss_proj:3.139 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john smith attended [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.739 (perp=7.022, rec=0.107, cos=0.228), tot_loss_proj:3.138 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john smith attended [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.734 (perp=7.022, rec=0.097, cos=0.233), tot_loss_proj:3.135 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john smith attended [SEP]']
[ 450/2000] tot_loss=1.738 (perp=7.022, rec=0.099, cos=0.235), tot_loss_proj:3.139 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john smith attended [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.729 (perp=7.022, rec=0.096, cos=0.229), tot_loss_proj:3.137 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john smith attended [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.738 (perp=7.022, rec=0.098, cos=0.235), tot_loss_proj:3.138 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john smith attended [SEP]']
[ 600/2000] tot_loss=2.274 (perp=8.265, rec=0.350, cos=0.270), tot_loss_proj:3.423 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john | attended [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.230 (perp=8.652, rec=0.263, cos=0.237), tot_loss_proj:3.511 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john attended campbell [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.182 (perp=8.652, rec=0.214, cos=0.237), tot_loss_proj:3.513 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john attended campbell [SEP]']
[ 750/2000] tot_loss=1.981 (perp=7.753, rec=0.192, cos=0.238), tot_loss_proj:3.353 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john attended john [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.959 (perp=7.753, rec=0.172, cos=0.236), tot_loss_proj:3.363 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john attended john [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.948 (perp=7.753, rec=0.161, cos=0.237), tot_loss_proj:3.357 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john attended john [SEP]']
[ 900/2000] tot_loss=1.933 (perp=7.753, rec=0.145, cos=0.238), tot_loss_proj:3.362 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john attended john [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.935 (perp=7.753, rec=0.147, cos=0.237), tot_loss_proj:3.360 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john attended john [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.890 (perp=7.581, rec=0.143, cos=0.231), tot_loss_proj:3.325 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
[1050/2000] tot_loss=1.893 (perp=7.581, rec=0.141, cos=0.236), tot_loss_proj:3.324 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1100/2000] tot_loss=1.878 (perp=7.581, rec=0.126, cos=0.236), tot_loss_proj:3.325 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1150/2000] tot_loss=1.883 (perp=7.581, rec=0.130, cos=0.238), tot_loss_proj:3.324 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
[1200/2000] tot_loss=1.877 (perp=7.581, rec=0.123, cos=0.237), tot_loss_proj:3.323 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1250/2000] tot_loss=1.881 (perp=7.581, rec=0.128, cos=0.237), tot_loss_proj:3.328 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1300/2000] tot_loss=1.880 (perp=7.581, rec=0.126, cos=0.238), tot_loss_proj:3.328 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
[1350/2000] tot_loss=1.881 (perp=7.581, rec=0.128, cos=0.237), tot_loss_proj:3.323 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1400/2000] tot_loss=1.880 (perp=7.581, rec=0.126, cos=0.238), tot_loss_proj:3.329 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1450/2000] tot_loss=1.876 (perp=7.581, rec=0.123, cos=0.237), tot_loss_proj:3.325 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
[1500/2000] tot_loss=1.877 (perp=7.581, rec=0.123, cos=0.238), tot_loss_proj:3.325 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1550/2000] tot_loss=1.880 (perp=7.581, rec=0.127, cos=0.237), tot_loss_proj:3.330 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1600/2000] tot_loss=1.869 (perp=7.581, rec=0.115, cos=0.238), tot_loss_proj:3.328 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
[1650/2000] tot_loss=1.877 (perp=7.581, rec=0.123, cos=0.237), tot_loss_proj:3.327 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1700/2000] tot_loss=1.883 (perp=7.581, rec=0.129, cos=0.238), tot_loss_proj:3.324 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1750/2000] tot_loss=1.882 (perp=7.581, rec=0.128, cos=0.238), tot_loss_proj:3.324 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
[1800/2000] tot_loss=1.871 (perp=7.581, rec=0.118, cos=0.237), tot_loss_proj:3.327 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1850/2000] tot_loss=1.864 (perp=7.581, rec=0.110, cos=0.238), tot_loss_proj:3.329 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[1900/2000] tot_loss=1.877 (perp=7.581, rec=0.123, cos=0.238), tot_loss_proj:3.331 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
[1950/2000] tot_loss=1.868 (perp=7.581, rec=0.114, cos=0.238), tot_loss_proj:3.326 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Attempt swap
[2000/2000] tot_loss=1.872 (perp=7.581, rec=0.118, cos=0.238), tot_loss_proj:3.326 [t=0.22s]
prediction: ['[CLS] no smiths meeting no john john attended [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] no john smiths attended the meeting. [SEP]
========================
predicted: 
========================
[CLS] no smiths meeting no john smith attended [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 26.667 | p: 25.000 | r: 28.571
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 109.020

[Aggregate metrics]:
rouge1     | fm: 87.239 | p: 87.124 | r: 87.673
rouge2     | fm: 51.720 | p: 51.487 | r: 52.000
rougeL     | fm: 77.240 | p: 76.958 | r: 77.598
rougeLsum  | fm: 76.931 | p: 76.820 | r: 77.323
r1fm+r2fm = 138.958

input #24 time: 0:08:52 | total time: 3:49:14


Running input #25 of 100.
reference: 
========================
I did not, as Bill had thought, go to the store.
========================
average of cosine similarity 0.8893434507941017
highest_index [0]
highest [0.8893434507941017]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2106, 2025, 1010, 2004, 3021, 2018, 2245, 1010, 2175, 2000,
         1996, 3573, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i did not, as bill had thought, go to the store. [SEP]']
[Init] best rec loss: 0.9416894316673279 for ['[CLS] zu sussex wig son committed koppen youth part sc missile combat carrier licence magazine [SEP]']
[Init] best rec loss: 0.916680634021759 for ['[CLS] air moisture each van kind pl tribes fulltou nod resolvedhesivevan affair [SEP]']
[Init] best rec loss: 0.9137159585952759 for ['[CLS] doing diplomatic above mart performance entered pointsur robert affaireon official men shouting [SEP]']
[Init] best rec loss: 0.8929824829101562 for ['[CLS] station tree generation promising planet into field mother mary gary eps suicidenotesback [SEP]']
[Init] best rec loss: 0.8926291465759277 for ['[CLS]dock pick independent social varieties cure cass impossible whatby sin march & tan [SEP]']
[Init] best rec loss: 0.8790796399116516 for ['[CLS] blankets jury garrison way timtiv stayed down lankan follows bruce tan maker clothing [SEP]']
[Init] best rec loss: 0.878244936466217 for ['[CLS] sounds agentstream oct philippine miranda bones thoroughly left soulrg practice moments grid [SEP]']
[Init] best rec loss: 0.8703187108039856 for ['[CLS] little goodness ak duties lifetime deposit lose sunday onto system plant yet regional z [SEP]']
[Init] best perm rec loss: 0.8699731826782227 for ['[CLS] little plant ak lose duties deposit onto yet regional sunday system z goodness lifetime [SEP]']
[Init] best perm rec loss: 0.8676603436470032 for ['[CLS] deposit goodness onto z duties little ak yet regional system lose sunday lifetime plant [SEP]']
[Init] best perm rec loss: 0.8656635880470276 for ['[CLS] little goodness lifetime deposit yet onto regional system z sunday duties plant ak lose [SEP]']
[Init] best perm rec loss: 0.8633718490600586 for ['[CLS] yet lifetime z deposit duties onto ak regional sunday goodness system lose little plant [SEP]']
[Init] best perm rec loss: 0.8630099296569824 for ['[CLS] ak deposit lifetime regional plant duties z system yet goodness lose little onto sunday [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.804 (perp=10.848, rec=0.445, cos=0.189), tot_loss_proj:4.008 [t=0.22s]
prediction: ['[CLS] silver slipped,! pack ) v, ashe! either gate influenced sunday [SEP]']
[ 100/2000] tot_loss=2.227 (perp=8.487, rec=0.351, cos=0.179), tot_loss_proj:3.661 [t=0.22s]
prediction: ['[CLS] bill didn,! bill would v, bill! the gate iman [SEP]']
[ 150/2000] tot_loss=2.107 (perp=8.058, rec=0.280, cos=0.215), tot_loss_proj:3.527 [t=0.22s]
prediction: ['[CLS] bill did, what bill would not, bill thought the store becomingman [SEP]']
[ 200/2000] tot_loss=2.262 (perp=9.232, rec=0.222, cos=0.194), tot_loss_proj:3.738 [t=0.22s]
prediction: ['[CLS] i did ; go bill would as as bill thought the store becomingman [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.407 (perp=9.229, rec=0.344, cos=0.217), tot_loss_proj:3.754 [t=0.22s]
prediction: ['[CLS] i did ( billdic be, as bill thought, about originallyman [SEP]']
[ 300/2000] tot_loss=2.047 (perp=8.025, rec=0.244, cos=0.198), tot_loss_proj:3.481 [t=0.22s]
prediction: ['[CLS] i did what billgate go, as bill thought, about originallyland [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.953 (perp=7.672, rec=0.215, cos=0.203), tot_loss_proj:3.420 [t=0.22s]
prediction: ['[CLS] i did what billgate, as bill thought, go aboutdymaster [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.859 (perp=7.267, rec=0.203, cos=0.203), tot_loss_proj:3.340 [t=0.22s]
prediction: ['[CLS] i did, bill ann, as bill thought, go about should store [SEP]']
[ 450/2000] tot_loss=1.940 (perp=7.759, rec=0.189, cos=0.199), tot_loss_proj:3.424 [t=0.22s]
prediction: ['[CLS] i did because bill its, as bill thought, go about : stores [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.853 (perp=7.374, rec=0.177, cos=0.201), tot_loss_proj:3.354 [t=0.22s]
prediction: ['[CLS] i did, bill, as bill thought, go aboutdic : stores [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.930 (perp=7.698, rec=0.188, cos=0.202), tot_loss_proj:3.386 [t=0.22s]
prediction: ['[CLS] i not because bill, as bill thought, go ann store : store [SEP]']
[ 600/2000] tot_loss=1.942 (perp=7.857, rec=0.172, cos=0.199), tot_loss_proj:3.421 [t=0.22s]
prediction: ['[CLS] i not because bill, as bill thought, go its store : store [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.869 (perp=7.501, rec=0.169, cos=0.200), tot_loss_proj:3.359 [t=0.22s]
prediction: ['[CLS] i because not bill, as bill thought, go its store : stores [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.899 (perp=7.679, rec=0.156, cos=0.207), tot_loss_proj:3.393 [t=0.22s]
prediction: ['[CLS] i because not bill, as bill thought, go its store : airlines [SEP]']
[ 750/2000] tot_loss=1.878 (perp=7.614, rec=0.149, cos=0.206), tot_loss_proj:3.361 [t=0.22s]
prediction: ['[CLS] i because not bill, as bill thought, go its store, airlines [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.917 (perp=7.614, rec=0.183, cos=0.210), tot_loss_proj:3.366 [t=0.22s]
prediction: ['[CLS] i because not bill, as bill thought, go its store, airlines [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.826 (perp=7.340, rec=0.150, cos=0.209), tot_loss_proj:3.307 [t=0.22s]
prediction: ['[CLS] i because not bill, as bill thought its go, store, stores [SEP]']
[ 900/2000] tot_loss=1.819 (perp=7.340, rec=0.142, cos=0.208), tot_loss_proj:3.306 [t=0.22s]
prediction: ['[CLS] i because not bill, as bill thought its go, store, stores [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.757 (perp=7.056, rec=0.138, cos=0.208), tot_loss_proj:3.257 [t=0.22s]
prediction: ['[CLS] i because not bill, as bill thought, go, store its stores [SEP]']
Attempt swap
[1000/2000] tot_loss=1.755 (perp=7.056, rec=0.135, cos=0.209), tot_loss_proj:3.259 [t=0.22s]
prediction: ['[CLS] i because not bill, as bill thought, go, store its stores [SEP]']
[1050/2000] tot_loss=1.755 (perp=7.056, rec=0.137, cos=0.206), tot_loss_proj:3.261 [t=0.22s]
prediction: ['[CLS] i because not bill, as bill thought, go, store its stores [SEP]']
Attempt swap
[1100/2000] tot_loss=1.753 (perp=7.056, rec=0.134, cos=0.208), tot_loss_proj:3.263 [t=0.22s]
prediction: ['[CLS] i because not bill, as bill thought, go, store its stores [SEP]']
Attempt swap
[1150/2000] tot_loss=1.749 (perp=7.056, rec=0.130, cos=0.207), tot_loss_proj:3.259 [t=0.22s]
prediction: ['[CLS] i because not bill, as bill thought, go, store its stores [SEP]']
[1200/2000] tot_loss=1.700 (perp=6.748, rec=0.143, cos=0.208), tot_loss_proj:3.194 [t=0.22s]
prediction: ['[CLS] i had not bill, as bill thought, go, store its stores [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.710 (perp=6.876, rec=0.129, cos=0.206), tot_loss_proj:3.231 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its airlines [SEP]']
Attempt swap
[1300/2000] tot_loss=1.714 (perp=6.876, rec=0.132, cos=0.207), tot_loss_proj:3.233 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its airlines [SEP]']
[1350/2000] tot_loss=1.715 (perp=6.876, rec=0.131, cos=0.208), tot_loss_proj:3.229 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its airlines [SEP]']
Attempt swap
[1400/2000] tot_loss=1.715 (perp=6.876, rec=0.132, cos=0.208), tot_loss_proj:3.233 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its airlines [SEP]']
Attempt swap
[1450/2000] tot_loss=1.709 (perp=6.876, rec=0.128, cos=0.206), tot_loss_proj:3.230 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its airlines [SEP]']
[1500/2000] tot_loss=1.711 (perp=6.876, rec=0.128, cos=0.208), tot_loss_proj:3.229 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its airlines [SEP]']
Attempt swap
[1550/2000] tot_loss=1.715 (perp=6.876, rec=0.131, cos=0.209), tot_loss_proj:3.231 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its airlines [SEP]']
Attempt swap
[1600/2000] tot_loss=1.708 (perp=6.876, rec=0.124, cos=0.209), tot_loss_proj:3.229 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its airlines [SEP]']
[1650/2000] tot_loss=1.714 (perp=6.921, rec=0.124, cos=0.207), tot_loss_proj:3.233 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its johnnie [SEP]']
Attempt swap
[1700/2000] tot_loss=1.718 (perp=6.921, rec=0.125, cos=0.209), tot_loss_proj:3.238 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its johnnie [SEP]']
Attempt swap
[1750/2000] tot_loss=1.720 (perp=6.921, rec=0.129, cos=0.207), tot_loss_proj:3.238 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its johnnie [SEP]']
[1800/2000] tot_loss=1.722 (perp=6.921, rec=0.129, cos=0.208), tot_loss_proj:3.237 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go, store its johnnie [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.708 (perp=6.851, rec=0.129, cos=0.209), tot_loss_proj:3.185 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go store its airlines, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.712 (perp=6.867, rec=0.130, cos=0.209), tot_loss_proj:3.210 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go store its johnnie, [SEP]']
[1950/2000] tot_loss=1.709 (perp=6.875, rec=0.126, cos=0.209), tot_loss_proj:2.935 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go store itsnotes, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.712 (perp=6.875, rec=0.129, cos=0.208), tot_loss_proj:2.935 [t=0.22s]
prediction: ['[CLS] bill i had not, as bill thought, go store itsnotes, [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] i did not, as bill had thought, go to the store. [SEP]
========================
predicted: 
========================
[CLS] bill i had not, as bill thought, go store itsnotes, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 83.333 | r: 76.923
rouge2     | fm: 26.087 | p: 27.273 | r: 25.000
rougeL     | fm: 72.000 | p: 75.000 | r: 69.231
rougeLsum  | fm: 72.000 | p: 75.000 | r: 69.231
r1fm+r2fm = 106.087

[Aggregate metrics]:
rouge1     | fm: 87.056 | p: 86.980 | r: 87.297
rouge2     | fm: 50.994 | p: 50.669 | r: 51.328
rougeL     | fm: 76.962 | p: 76.878 | r: 77.140
rougeLsum  | fm: 76.720 | p: 76.680 | r: 77.000
r1fm+r2fm = 138.050

input #25 time: 0:08:52 | total time: 3:58:07


Running input #26 of 100.
reference: 
========================
Who will John ask for information about summer courses?
========================
average of cosine similarity 0.920316529640897
highest_index [0]
highest [0.920316529640897]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2040, 2097, 2198, 3198, 2005, 2592, 2055, 2621, 5352, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] who will john ask for information about summer courses? [SEP]']
[Init] best rec loss: 0.9568773508071899 for ['[CLS] certified bowedhorn ( lunch dedicated normally played stones nj [SEP]']
[Init] best rec loss: 0.9484511613845825 for ['[CLS]him battalion why asian bye level for ibn stillome [SEP]']
[Init] best rec loss: 0.9057179689407349 for ['[CLS] friends vacuum office memory physically fetch bark trialsject breuning [SEP]']
[Init] best rec loss: 0.890907347202301 for ['[CLS] herself xx bat draft song questions pol horde coreoning [SEP]']
[Init] best rec loss: 0.8898248672485352 for ['[CLS] morgan ， marketingrcleamy credit x respective local rufus [SEP]']
[Init] best rec loss: 0.8865914940834045 for ['[CLS]able smoked reserves brought 290 scope bayl kai further [SEP]']
[Init] best rec loss: 0.881098210811615 for ['[CLS] chipshammer swipedcrow ourpage surgery sized rang these [SEP]']
[Init] best rec loss: 0.868865966796875 for ['[CLS] never roach set lostm wire bank mort account armistice [SEP]']
[Init] best rec loss: 0.8569960594177246 for ['[CLS]and violent mates sinsfest brackets luis largest barbie natalie [SEP]']
[Init] best perm rec loss: 0.8565276265144348 for ['[CLS] largestfest luis violent bracketsand barbie natalie sins mates [SEP]']
[Init] best perm rec loss: 0.8551941514015198 for ['[CLS] barbie violent brackets luis largestfestand natalie sins mates [SEP]']
[Init] best perm rec loss: 0.8542066812515259 for ['[CLS] mates brackets largest sins barbie natalie violentfest luisand [SEP]']
[Init] best perm rec loss: 0.8531709313392639 for ['[CLS] largest sins brackets violent mates luisfest natalieand barbie [SEP]']
[Init] best perm rec loss: 0.8522192239761353 for ['[CLS] brackets matesfest largest sins violent natalie barbie luisand [SEP]']
[Init] best perm rec loss: 0.8516188859939575 for ['[CLS] violent largest bracketsfest mates barbie natalie luis sinsand [SEP]']
[Init] best perm rec loss: 0.8493397235870361 for ['[CLS] barbie largest violent luis mates sinsfest natalie bracketsand [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.324 (perp=9.308, rec=0.319, cos=0.144), tot_loss_proj:3.773 [t=0.23s]
prediction: ['[CLS] would summer activities will for for lifetime research college? [SEP]']
[ 100/2000] tot_loss=2.666 (perp=11.066, rec=0.297, cos=0.156), tot_loss_proj:4.108 [t=0.23s]
prediction: ['[CLS] who summer league want electro advisor young educational dormitory? [SEP]']
[ 150/2000] tot_loss=2.449 (perp=10.254, rec=0.248, cos=0.150), tot_loss_proj:3.891 [t=0.23s]
prediction: ['[CLS] who john time want could about young summer topics? [SEP]']
[ 200/2000] tot_loss=2.288 (perp=9.687, rec=0.211, cos=0.140), tot_loss_proj:3.845 [t=0.23s]
prediction: ['[CLS] who john miss ask information about summer summer courses? [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.827 (perp=7.512, rec=0.178, cos=0.147), tot_loss_proj:3.316 [t=0.23s]
prediction: ['[CLS] who will miss ask for about summer summer courses? [SEP]']
[ 300/2000] tot_loss=1.820 (perp=7.512, rec=0.180, cos=0.138), tot_loss_proj:3.314 [t=0.23s]
prediction: ['[CLS] who will miss ask for about summer summer courses? [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.717 (perp=7.056, rec=0.165, cos=0.141), tot_loss_proj:3.305 [t=0.23s]
prediction: ['[CLS] who will will ask for summer about summer courses? [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.648 (perp=6.732, rec=0.158, cos=0.143), tot_loss_proj:2.762 [t=0.23s]
prediction: ['[CLS] who will ask will for summer about summer courses? [SEP]']
[ 450/2000] tot_loss=1.708 (perp=7.196, rec=0.116, cos=0.153), tot_loss_proj:2.557 [t=0.23s]
prediction: ['[CLS] who will ask john for summer about summer courses? [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.803 (perp=7.668, rec=0.117, cos=0.153), tot_loss_proj:3.447 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.790 (perp=7.668, rec=0.103, cos=0.153), tot_loss_proj:3.445 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
[ 600/2000] tot_loss=1.782 (perp=7.668, rec=0.096, cos=0.153), tot_loss_proj:3.443 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.762 (perp=7.668, rec=0.077, cos=0.152), tot_loss_proj:3.443 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.773 (perp=7.668, rec=0.087, cos=0.152), tot_loss_proj:3.446 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
[ 750/2000] tot_loss=1.765 (perp=7.668, rec=0.079, cos=0.153), tot_loss_proj:3.446 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.760 (perp=7.668, rec=0.073, cos=0.153), tot_loss_proj:3.449 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.759 (perp=7.668, rec=0.075, cos=0.150), tot_loss_proj:3.427 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
[ 900/2000] tot_loss=1.757 (perp=7.668, rec=0.071, cos=0.153), tot_loss_proj:3.427 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.761 (perp=7.668, rec=0.075, cos=0.152), tot_loss_proj:3.429 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.764 (perp=7.668, rec=0.078, cos=0.152), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
[1050/2000] tot_loss=1.752 (perp=7.668, rec=0.065, cos=0.153), tot_loss_proj:3.427 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.763 (perp=7.668, rec=0.077, cos=0.153), tot_loss_proj:3.430 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.763 (perp=7.668, rec=0.077, cos=0.153), tot_loss_proj:3.430 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
[1200/2000] tot_loss=1.757 (perp=7.668, rec=0.071, cos=0.153), tot_loss_proj:3.427 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.758 (perp=7.668, rec=0.071, cos=0.153), tot_loss_proj:3.424 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.751 (perp=7.668, rec=0.065, cos=0.153), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
[1350/2000] tot_loss=1.760 (perp=7.668, rec=0.074, cos=0.153), tot_loss_proj:3.423 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.746 (perp=7.668, rec=0.060, cos=0.153), tot_loss_proj:3.428 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.759 (perp=7.668, rec=0.073, cos=0.153), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
[1500/2000] tot_loss=1.766 (perp=7.668, rec=0.080, cos=0.153), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.758 (perp=7.668, rec=0.071, cos=0.153), tot_loss_proj:3.426 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.750 (perp=7.668, rec=0.064, cos=0.153), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
[1650/2000] tot_loss=1.755 (perp=7.668, rec=0.069, cos=0.153), tot_loss_proj:3.426 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.766 (perp=7.668, rec=0.080, cos=0.153), tot_loss_proj:3.424 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.769 (perp=7.668, rec=0.083, cos=0.153), tot_loss_proj:3.427 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
[1800/2000] tot_loss=1.749 (perp=7.668, rec=0.063, cos=0.153), tot_loss_proj:3.426 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.760 (perp=7.668, rec=0.074, cos=0.153), tot_loss_proj:3.429 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.761 (perp=7.668, rec=0.074, cos=0.153), tot_loss_proj:3.431 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
[1950/2000] tot_loss=1.759 (perp=7.668, rec=0.073, cos=0.153), tot_loss_proj:3.423 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.752 (perp=7.668, rec=0.066, cos=0.153), tot_loss_proj:3.427 [t=0.23s]
prediction: ['[CLS] who will ask john for summer information summer courses? [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] who will john ask for information about summer courses? [SEP]
========================
predicted: 
========================
[CLS] who will ask john for summer information summer courses? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 130.909

[Aggregate metrics]:
rouge1     | fm: 87.109 | p: 87.137 | r: 87.348
rouge2     | fm: 50.296 | p: 50.301 | r: 50.585
rougeL     | fm: 77.085 | p: 77.081 | r: 77.310
rougeLsum  | fm: 77.010 | p: 76.939 | r: 77.180
r1fm+r2fm = 137.405

input #26 time: 0:09:09 | total time: 4:07:16


Running input #27 of 100.
reference: 
========================
Ron wanted to wear a tuxedo to the party, but Caspar couldn't decide whether to.
========================
average of cosine similarity 0.9071921428983047
highest_index [0]
highest [0.9071921428983047]
Debug: ids_shape = 24, pads = [24]
Debug: input ids = tensor([[  101,  6902,  2359,  2000,  4929,  1037, 10722, 19068,  2080,  2000,
          1996,  2283,  1010,  2021, 25222, 19362,  2481,  1005,  1056,  5630,
          3251,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]"]
[Init] best rec loss: 0.9409741163253784 for ['[CLS]ig operated already block sad pac further armenians songs, fund book waters line buy willis relief strike collaborative tack violet bring [SEP]']
[Init] best rec loss: 0.9079647660255432 for ['[CLS]yme cabinet slumped africa cm tried manyuce barack cryptrre hurt requiredstorm perception engine politician consumer maddy deep welshbo [SEP]']
[Init] best rec loss: 0.9018641710281372 for ['[CLS] walk out dorm network laurel frame if creatures rematch despite allie mean [SEP] tone parents slayer api m effect taylor lecture toy [SEP]']
[Init] best rec loss: 0.9001822471618652 for ['[CLS] 2010 sharing explores domesday mr near wayne minor just several encouragement cook basketball programme grove commissioner lance safety porn resident speaking parallel [SEP]']
[Init] best rec loss: 0.885657548904419 for ['[CLS] almond lo alto dl continental clark dam course poole enterprise adrian a program colonies takes rail areas saint haze berlin august bobbie [SEP]']
[Init] best rec loss: 0.8769513368606567 for ['[CLS] stuck dragons cow winter suite leavesit cerambycidae tomorrowcentric country independencesia profit bitch counted decision injection lauren what world zoo [SEP]']
[Init] best rec loss: 0.8612741827964783 for ['[CLS] carolkel sub loudly idea reprisearound gas month opposite goddess ruler from roadbosographicern magazine original / surgery noble [SEP]']
[Init] best rec loss: 0.8548383116722107 for ['[CLS] much degrees pilot and se starting watering maroon mobility cover anger talk retired anonymous charges minor football chance curlhale steps ontario [SEP]']
[Init] best perm rec loss: 0.8532844185829163 for ['[CLS] maroon cover talkhale steps mobility ontario curl pilot much retired starting and football minor charges se chance anonymous degrees anger watering [SEP]']
[Init] best perm rec loss: 0.8526713848114014 for ['[CLS] minor pilot retired charges chance talk anonymous steps anger se much maroon degrees football starting mobility cover watering ontario andhale curl [SEP]']
[Init] best perm rec loss: 0.8509506583213806 for ['[CLS] talk much watering and se ontario mobility retired curlhale anonymous anger pilot chance charges starting minor maroon steps cover football degrees [SEP]']
[Init] best perm rec loss: 0.8503192067146301 for ['[CLS] cover much anonymoushale pilot se watering charges retired chance minor starting mobility ontario and curl anger football maroon degrees talk steps [SEP]']
[Init] best perm rec loss: 0.8486121296882629 for ['[CLS] minor steps pilot mobilityhale much watering cover chance se starting ontario talk and retired anonymous charges maroon football curl degrees anger [SEP]']
[Init] best perm rec loss: 0.8475795388221741 for ['[CLS] much degrees anonymous ontariohale cover chance football curl starting minor steps pilot and mobility retired anger talk se maroon charges watering [SEP]']
[Init] best perm rec loss: 0.8460693955421448 for ['[CLS] and maroon charges pilot talk degrees mobility cover chance steps minor curl much ontario starting wateringhale se retired anger football anonymous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.148 (perp=13.000, rec=0.392, cos=0.156), tot_loss_proj:4.538 [t=0.22s]
prediction: ['[CLS] bern couldn tellck wanting [SEP] kevin force ron darren lord hall another maurice fightingla get said a emotionspar strangled [SEP]']
[ 100/2000] tot_loss=2.922 (perp=11.875, rec=0.348, cos=0.199), tot_loss_proj:4.267 [t=0.23s]
prediction: ['[CLS] ron couldn do item wanting ron guardian force ron ron lord? whether maurice meetingpar evolutionary. cas permissionpar strangled [SEP]']
[ 150/2000] tot_loss=2.991 (perp=12.635, rec=0.305, cos=0.159), tot_loss_proj:4.465 [t=0.23s]
prediction: ['[CLS] breuning couldn manage escort wearing ron pulsed twinned ron rhys. civilian shoulders a party guys definitely com a emotionspar told [SEP]']
[ 200/2000] tot_loss=3.061 (perp=13.247, rec=0.244, cos=0.168), tot_loss_proj:4.557 [t=0.23s]
prediction: ['[CLS] andrea couldn manage escort whether ron monarch gael ron healing with civilian shoulders a party guys definitely cas a emotionspar told [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.945 (perp=12.863, rec=0.214, cos=0.159), tot_loss_proj:4.480 [t=0.23s]
prediction: ['[CLS] andrea monarch manage escort wanted ron couldn twinned ronifice but civilian carried could whenever pose definitely cas a whetherpar. [SEP]']
[ 300/2000] tot_loss=2.880 (perp=12.649, rec=0.190, cos=0.160), tot_loss_proj:4.409 [t=0.23s]
prediction: ['[CLS]oid monarch manage escort wanted ron couldn each casifice but civilian now would partyckle definitely cas a whetherpar. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.805 (perp=12.117, rec=0.212, cos=0.170), tot_loss_proj:4.296 [t=0.23s]
prediction: ['[CLS] wanted monarch decide to wanted ron couldnuaries duke wear but whether casually could party threshold definitely cas i bandpar. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.652 (perp=11.481, rec=0.201, cos=0.155), tot_loss_proj:4.172 [t=0.23s]
prediction: ['[CLS]bird monarch cult [SEP] wanted ron couldn decide or wear but whether casually can party slim definitely cas i bandpar. [SEP]']
[ 450/2000] tot_loss=2.550 (perp=11.027, rec=0.167, cos=0.178), tot_loss_proj:4.089 [t=0.23s]
prediction: ['[CLS]bird monarch cult to wanted ron couldn decide quite wear but whether casually could party slim definitely cas a bandpar. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.593 (perp=11.364, rec=0.150, cos=0.171), tot_loss_proj:4.136 [t=0.23s]
prediction: ['[CLS]da monarch cult definitely wanted ron couldn decide quite wear but whether would could party slim to cas i bandpar. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.448 (perp=10.618, rec=0.148, cos=0.176), tot_loss_proj:3.991 [t=0.23s]
prediction: ['[CLS]da monarch cult definitely wanted ron couldn decide quite wear but whether would a party slim to cas could bandpar. [SEP]']
[ 600/2000] tot_loss=2.385 (perp=10.395, rec=0.147, cos=0.159), tot_loss_proj:3.952 [t=0.23s]
prediction: ['[CLS]da monarch cult definitely wanted ron couldn decide whether wear but whether would a party bite to cas could bandpar. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.338 (perp=10.176, rec=0.130, cos=0.173), tot_loss_proj:3.906 [t=0.23s]
prediction: ['[CLS]da monarch cult definitely wanted ron couldn decide whether attire but whether would a bite party to cas would bandpar. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.268 (perp=9.818, rec=0.141, cos=0.164), tot_loss_proj:3.840 [t=0.23s]
prediction: ['[CLS] to monarch cult definitely wanted ron couldn decide whether wear but whether would a bite partybird cas would bandpar. [SEP]']
[ 750/2000] tot_loss=2.270 (perp=9.818, rec=0.133, cos=0.173), tot_loss_proj:3.840 [t=0.23s]
prediction: ['[CLS] to monarch cult definitely wanted ron couldn decide whether wear but whether would a bite partybird cas would bandpar. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.255 (perp=9.742, rec=0.130, cos=0.177), tot_loss_proj:3.844 [t=0.23s]
prediction: ['[CLS] to monarch cult definitely wanted ron couldn decide whether wear but whether would bite a party hunting cas would bandpar. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.261 (perp=9.775, rec=0.135, cos=0.171), tot_loss_proj:3.841 [t=0.23s]
prediction: ['[CLS] to monarch cult definitely wanted ron couldn decide whether wear but would bite whether a party hunting cas would cardpar. [SEP]']
[ 900/2000] tot_loss=2.374 (perp=10.325, rec=0.133, cos=0.176), tot_loss_proj:3.982 [t=0.23s]
prediction: ['[CLS] to should cult definitely wanted ron couldn decide whether wear but would bite whether a party hunting cas would cardpar. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.305 (perp=9.980, rec=0.140, cos=0.169), tot_loss_proj:3.878 [t=0.23s]
prediction: ['[CLS] to cult definitely wanted ron could couldn decide whether wear but would bite whether a party hunting cas would cardpar. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.280 (perp=9.852, rec=0.138, cos=0.172), tot_loss_proj:3.839 [t=0.23s]
prediction: ['[CLS] to cult definitely wanted ron could couldn decide whether wear but would bite whether a hunting party cas would cardpar. [SEP]']
[1050/2000] tot_loss=2.270 (perp=9.852, rec=0.124, cos=0.175), tot_loss_proj:3.843 [t=0.23s]
prediction: ['[CLS] to cult definitely wanted ron could couldn decide whether wear but would bite whether a hunting party cas would cardpar. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.203 (perp=9.542, rec=0.120, cos=0.174), tot_loss_proj:3.789 [t=0.23s]
prediction: ['[CLS] to a definitely wanted ron could couldn decide whether wear but would bite whether a hunting party cas did cardpar. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.230 (perp=9.650, rec=0.127, cos=0.173), tot_loss_proj:3.813 [t=0.23s]
prediction: ['[CLS] to a definitely wanted ron, couldn decide whether wear but could bite whether a hunting party cas did cardpar. [SEP]']
[1200/2000] tot_loss=2.197 (perp=9.494, rec=0.123, cos=0.175), tot_loss_proj:3.805 [t=0.23s]
prediction: ['[CLS] to a definitely wanted ron, couldn decide whether wear but could bite whether a hunting party cas a cardpar. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.161 (perp=9.260, rec=0.135, cos=0.174), tot_loss_proj:3.780 [t=0.23s]
prediction: ['[CLS] whether a definitely wanted ron, couldn decide whether wear but could bite to a hunting party cas a cardpar. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.069 (perp=8.853, rec=0.125, cos=0.173), tot_loss_proj:3.708 [t=0.23s]
prediction: ['[CLS] whether a definitely wanted, ron couldn decide whether wear but could bite to a hunting party cas a cardpar. [SEP]']
[1350/2000] tot_loss=2.068 (perp=8.853, rec=0.123, cos=0.175), tot_loss_proj:3.707 [t=0.23s]
prediction: ['[CLS] whether a definitely wanted, ron couldn decide whether wear but could bite to a hunting party cas a cardpar. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.075 (perp=8.853, rec=0.130, cos=0.175), tot_loss_proj:3.705 [t=0.23s]
prediction: ['[CLS] whether a definitely wanted, ron couldn decide whether wear but could bite to a hunting party cas a cardpar. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.965 (perp=8.304, rec=0.139, cos=0.166), tot_loss_proj:3.587 [t=0.23s]
prediction: ['[CLS] whether a definitely wanted, ron couldn decide whether to wear but could bite a hunting party cas a cardpar. [SEP]']
[1500/2000] tot_loss=1.957 (perp=8.304, rec=0.121, cos=0.175), tot_loss_proj:3.589 [t=0.23s]
prediction: ['[CLS] whether a definitely wanted, ron couldn decide whether to wear but could bite a hunting party cas a cardpar. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.907 (perp=7.990, rec=0.133, cos=0.176), tot_loss_proj:3.554 [t=0.23s]
prediction: ['[CLS] whether a and wanted, ron couldn decide whether to bite but could wear a hunting party cas a cardpar. [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.936 (perp=8.176, rec=0.130, cos=0.171), tot_loss_proj:3.565 [t=0.23s]
prediction: ['[CLS] whether a wanted, and ron couldn decide whether to bite but could wear abird party cas a cardpar. [SEP]']
[1650/2000] tot_loss=1.931 (perp=8.176, rec=0.120, cos=0.176), tot_loss_proj:3.570 [t=0.23s]
prediction: ['[CLS] whether a wanted, and ron couldn decide whether to bite but could wear abird party cas a cardpar. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.887 (perp=7.920, rec=0.127, cos=0.176), tot_loss_proj:3.492 [t=0.23s]
prediction: ['[CLS] whether a wanted, and ron couldn decide whether to bite but could wear a partybird cas a cardpar. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.798 (perp=7.482, rec=0.126, cos=0.175), tot_loss_proj:3.415 [t=0.23s]
prediction: ['[CLS] whether a wanted,bird ron couldn decide whether to bite but could wear a party and cas a cardpar. [SEP]']
[1800/2000] tot_loss=1.711 (perp=7.076, rec=0.120, cos=0.176), tot_loss_proj:3.343 [t=0.23s]
prediction: ['[CLS] whether a wanted, hunting ron couldn decide whether to bite but could wear a party and cas a cardpar. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.709 (perp=7.076, rec=0.117, cos=0.177), tot_loss_proj:3.341 [t=0.23s]
prediction: ['[CLS] whether a wanted, hunting ron couldn decide whether to bite but could wear a party and cas a cardpar. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.711 (perp=7.076, rec=0.119, cos=0.177), tot_loss_proj:3.346 [t=0.23s]
prediction: ['[CLS] whether a wanted, hunting ron couldn decide whether to bite but could wear a party and cas a cardpar. [SEP]']
[1950/2000] tot_loss=1.718 (perp=7.076, rec=0.126, cos=0.177), tot_loss_proj:3.343 [t=0.23s]
prediction: ['[CLS] whether a wanted, hunting ron couldn decide whether to bite but could wear a party and cas a cardpar. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.713 (perp=7.076, rec=0.121, cos=0.177), tot_loss_proj:3.346 [t=0.23s]
prediction: ['[CLS] whether a wanted, hunting ron couldn decide whether to bite but could wear a party and cas a cardpar. [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]
========================
predicted: 
========================
[CLS] whether a wanted, hunting ron couldn decide whether to bite but could wear a party and cas a cardpar. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.538 | p: 57.143 | r: 66.667
rouge2     | fm: 16.216 | p: 15.000 | r: 17.647
rougeL     | fm: 35.897 | p: 33.333 | r: 38.889
rougeLsum  | fm: 35.897 | p: 33.333 | r: 38.889
r1fm+r2fm = 77.755

[Aggregate metrics]:
rouge1     | fm: 86.263 | p: 86.094 | r: 86.610
rouge2     | fm: 49.182 | p: 48.915 | r: 49.423
rougeL     | fm: 75.560 | p: 75.395 | r: 75.833
rougeLsum  | fm: 75.627 | p: 75.484 | r: 75.926
r1fm+r2fm = 135.445

input #27 time: 0:09:01 | total time: 4:16:18


Running input #28 of 100.
reference: 
========================
Bill gave Sue the book.
========================
average of cosine similarity 0.859070543141774
highest_index [0]
highest [0.859070543141774]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 3021, 2435, 9790, 1996, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bill gave sue the book. [SEP]']
[Init] best rec loss: 0.955686092376709 for ['[CLS] tang links ponder _ borntist [SEP]']
[Init] best rec loss: 0.9052121639251709 for ['[CLS] country including ahead receiving vin volume [SEP]']
[Init] best rec loss: 0.9050925374031067 for ['[CLS] labor suffrage position sleep hope then [SEP]']
[Init] best rec loss: 0.903748095035553 for ['[CLS] sound honourable both going amongstmat [SEP]']
[Init] best rec loss: 0.9019129276275635 for ['[CLS] grain farm processing fielding following pierced [SEP]']
[Init] best rec loss: 0.875694990158081 for ['[CLS] sea today extra gate out port [SEP]']
[Init] best rec loss: 0.87208491563797 for ['[CLS] theodore vendors drink thick metals chicago [SEP]']
[Init] best rec loss: 0.8521769642829895 for ['[CLS] efficacyvers old lobby expert exchanged [SEP]']
[Init] best rec loss: 0.8454811573028564 for ['[CLS] right? ownership endemic for ga [SEP]']
[Init] best rec loss: 0.8286177515983582 for ['[CLS] reign changing especially newportrod amounted [SEP]']
[Init] best perm rec loss: 0.8251065611839294 for ['[CLS] amounted changing especiallyrod newport reign [SEP]']
[Init] best perm rec loss: 0.8245049715042114 for ['[CLS]rod amounted changing especially newport reign [SEP]']
[Init] best perm rec loss: 0.8232201933860779 for ['[CLS]rod especially changing newport amounted reign [SEP]']
[Init] best perm rec loss: 0.8229266405105591 for ['[CLS] amounted changing newportrod especially reign [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.709 (perp=10.774, rec=0.290, cos=0.264), tot_loss_proj:4.005 [t=0.22s]
prediction: ['[CLS] gave sue sue bill the! [SEP]']
[ 100/2000] tot_loss=2.676 (perp=11.363, rec=0.146, cos=0.258), tot_loss_proj:4.138 [t=0.22s]
prediction: ['[CLS] gave sue sue bill the book [SEP]']
[ 150/2000] tot_loss=2.639 (perp=11.363, rec=0.111, cos=0.255), tot_loss_proj:4.139 [t=0.22s]
prediction: ['[CLS] gave sue sue bill the book [SEP]']
[ 200/2000] tot_loss=2.629 (perp=11.363, rec=0.101, cos=0.255), tot_loss_proj:4.135 [t=0.22s]
prediction: ['[CLS] gave sue sue bill the book [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.272 (perp=9.554, rec=0.109, cos=0.252), tot_loss_proj:3.166 [t=0.22s]
prediction: ['[CLS] sue sue gave bill the book [SEP]']
[ 300/2000] tot_loss=2.266 (perp=9.554, rec=0.102, cos=0.253), tot_loss_proj:3.170 [t=0.22s]
prediction: ['[CLS] sue sue gave bill the book [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.164 (perp=9.029, rec=0.102, cos=0.257), tot_loss_proj:3.579 [t=0.22s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.151 (perp=9.029, rec=0.089, cos=0.256), tot_loss_proj:3.577 [t=0.22s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
[ 450/2000] tot_loss=2.151 (perp=9.029, rec=0.092, cos=0.253), tot_loss_proj:3.573 [t=0.22s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.154 (perp=9.029, rec=0.090, cos=0.258), tot_loss_proj:3.566 [t=0.22s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.160 (perp=9.029, rec=0.102, cos=0.252), tot_loss_proj:3.566 [t=0.22s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
[ 600/2000] tot_loss=2.160 (perp=9.029, rec=0.093, cos=0.261), tot_loss_proj:3.562 [t=0.22s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.159 (perp=9.029, rec=0.098, cos=0.255), tot_loss_proj:3.568 [t=0.22s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.159 (perp=9.029, rec=0.092, cos=0.261), tot_loss_proj:3.564 [t=0.22s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
[ 750/2000] tot_loss=2.168 (perp=9.029, rec=0.106, cos=0.256), tot_loss_proj:3.559 [t=0.22s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.160 (perp=9.029, rec=0.095, cos=0.259), tot_loss_proj:3.562 [t=0.22s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.013 (perp=8.336, rec=0.086, cos=0.260), tot_loss_proj:3.560 [t=0.22s]
prediction: ['[CLS] book bill gave sue the book [SEP]']
[ 900/2000] tot_loss=2.015 (perp=8.336, rec=0.087, cos=0.261), tot_loss_proj:3.563 [t=0.22s]
prediction: ['[CLS] book bill gave sue the book [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.017 (perp=8.336, rec=0.091, cos=0.259), tot_loss_proj:3.558 [t=0.22s]
prediction: ['[CLS] book bill gave sue the book [SEP]']
Attempt swap
[1000/2000] tot_loss=2.017 (perp=8.336, rec=0.091, cos=0.259), tot_loss_proj:3.557 [t=0.22s]
prediction: ['[CLS] book bill gave sue the book [SEP]']
[1050/2000] tot_loss=2.016 (perp=8.336, rec=0.088, cos=0.260), tot_loss_proj:3.558 [t=0.22s]
prediction: ['[CLS] book bill gave sue the book [SEP]']
Attempt swap
[1100/2000] tot_loss=2.021 (perp=8.336, rec=0.093, cos=0.261), tot_loss_proj:3.558 [t=0.22s]
prediction: ['[CLS] book bill gave sue the book [SEP]']
Attempt swap
[1150/2000] tot_loss=2.032 (perp=8.336, rec=0.104, cos=0.261), tot_loss_proj:3.553 [t=0.22s]
prediction: ['[CLS] book bill gave sue the book [SEP]']
[1200/2000] tot_loss=2.010 (perp=8.336, rec=0.081, cos=0.261), tot_loss_proj:3.559 [t=0.22s]
prediction: ['[CLS] book bill gave sue the book [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.022 (perp=8.394, rec=0.084, cos=0.259), tot_loss_proj:3.534 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
Attempt swap
[1300/2000] tot_loss=2.033 (perp=8.394, rec=0.093, cos=0.261), tot_loss_proj:3.529 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
[1350/2000] tot_loss=2.024 (perp=8.394, rec=0.083, cos=0.262), tot_loss_proj:3.533 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
Attempt swap
[1400/2000] tot_loss=2.029 (perp=8.394, rec=0.090, cos=0.261), tot_loss_proj:3.528 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
Attempt swap
[1450/2000] tot_loss=2.036 (perp=8.394, rec=0.097, cos=0.261), tot_loss_proj:3.531 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
[1500/2000] tot_loss=2.022 (perp=8.394, rec=0.082, cos=0.261), tot_loss_proj:3.532 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
Attempt swap
[1550/2000] tot_loss=2.023 (perp=8.394, rec=0.083, cos=0.261), tot_loss_proj:3.529 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
Attempt swap
[1600/2000] tot_loss=2.027 (perp=8.394, rec=0.087, cos=0.262), tot_loss_proj:3.528 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
[1650/2000] tot_loss=2.036 (perp=8.394, rec=0.095, cos=0.262), tot_loss_proj:3.533 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
Attempt swap
[1700/2000] tot_loss=2.032 (perp=8.394, rec=0.092, cos=0.262), tot_loss_proj:3.536 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
Attempt swap
[1750/2000] tot_loss=2.030 (perp=8.394, rec=0.089, cos=0.262), tot_loss_proj:3.536 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
[1800/2000] tot_loss=2.026 (perp=8.394, rec=0.086, cos=0.262), tot_loss_proj:3.531 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
Attempt swap
[1850/2000] tot_loss=2.036 (perp=8.394, rec=0.096, cos=0.261), tot_loss_proj:3.533 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
Attempt swap
[1900/2000] tot_loss=2.019 (perp=8.394, rec=0.078, cos=0.262), tot_loss_proj:3.534 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
[1950/2000] tot_loss=2.029 (perp=8.394, rec=0.088, cos=0.262), tot_loss_proj:3.540 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
Attempt swap
[2000/2000] tot_loss=2.030 (perp=8.394, rec=0.089, cos=0.262), tot_loss_proj:3.537 [t=0.22s]
prediction: ['[CLS] book bill sue gave the book [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] bill gave sue the book. [SEP]
========================
predicted: 
========================
[CLS] sue bill gave sue the book [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 86.558 | p: 86.166 | r: 87.153
rouge2     | fm: 50.017 | p: 49.614 | r: 50.587
rougeL     | fm: 76.188 | p: 75.815 | r: 76.694
rougeLsum  | fm: 76.168 | p: 75.748 | r: 76.714
r1fm+r2fm = 136.575

input #28 time: 0:08:55 | total time: 4:25:13


Running input #29 of 100.
reference: 
========================
The bread was chewed by Martha.
========================
average of cosine similarity 0.8793277159495912
highest_index [0]
highest [0.8793277159495912]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996,  7852,  2001, 18362,  2011,  9246,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the bread was chewed by martha. [SEP]']
[Init] best rec loss: 0.8918796181678772 for ['[CLS] squeezed pace bonnie know plantsoic bishop [SEP]']
[Init] best rec loss: 0.8886650800704956 for ['[CLS] casualty slayerfall term open funny financial [SEP]']
[Init] best rec loss: 0.8728868961334229 for ['[CLS] back respondingflow terms servantwyn is [SEP]']
[Init] best rec loss: 0.8636534214019775 for ['[CLS] dutyhylgit somecap chamber blair [SEP]']
[Init] best rec loss: 0.8451888561248779 for ['[CLS] war captainnst duck mission wifeiful [SEP]']
[Init] best rec loss: 0.8450304865837097 for ['[CLS]vinskyা zeppelin steer mid envelope that [SEP]']
[Init] best perm rec loss: 0.843361496925354 for ['[CLS]া zeppelin steer midvinsky that envelope [SEP]']
[Init] best perm rec loss: 0.8424936532974243 for ['[CLS] steerা that mid envelopevinsky zeppelin [SEP]']
[Init] best perm rec loss: 0.8409321308135986 for ['[CLS] envelope that midাvinsky steer zeppelin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.611 (perp=10.161, rec=0.362, cos=0.217), tot_loss_proj:3.817 [t=0.22s]
prediction: ['[CLS] bread chewed by bread martha financially ( [SEP]']
[ 100/2000] tot_loss=2.326 (perp=9.496, rec=0.204, cos=0.222), tot_loss_proj:3.705 [t=0.22s]
prediction: ['[CLS] chewed chewed by chewed martha martha. [SEP]']
[ 150/2000] tot_loss=1.864 (perp=7.686, rec=0.104, cos=0.223), tot_loss_proj:3.352 [t=0.22s]
prediction: ['[CLS] the bread by chewed martha was. [SEP]']
[ 200/2000] tot_loss=1.833 (perp=7.686, rec=0.072, cos=0.224), tot_loss_proj:3.354 [t=0.22s]
prediction: ['[CLS] the bread by chewed martha was. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.632 (perp=6.524, rec=0.103, cos=0.224), tot_loss_proj:3.010 [t=0.22s]
prediction: ['[CLS] the bread chewed by martha was. [SEP]']
[ 300/2000] tot_loss=1.589 (perp=6.524, rec=0.061, cos=0.223), tot_loss_proj:3.001 [t=0.22s]
prediction: ['[CLS] the bread chewed by martha was. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.509 (perp=6.120, rec=0.062, cos=0.223), tot_loss_proj:1.581 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.502 (perp=6.120, rec=0.054, cos=0.224), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[ 450/2000] tot_loss=1.516 (perp=6.120, rec=0.067, cos=0.225), tot_loss_proj:1.587 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.509 (perp=6.120, rec=0.060, cos=0.226), tot_loss_proj:1.575 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.496 (perp=6.120, rec=0.047, cos=0.226), tot_loss_proj:1.590 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[ 600/2000] tot_loss=1.511 (perp=6.120, rec=0.061, cos=0.226), tot_loss_proj:1.594 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.511 (perp=6.120, rec=0.060, cos=0.226), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.504 (perp=6.120, rec=0.054, cos=0.226), tot_loss_proj:1.584 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[ 750/2000] tot_loss=1.520 (perp=6.120, rec=0.070, cos=0.226), tot_loss_proj:1.567 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.517 (perp=6.120, rec=0.067, cos=0.226), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.512 (perp=6.120, rec=0.062, cos=0.226), tot_loss_proj:1.580 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[ 900/2000] tot_loss=1.527 (perp=6.120, rec=0.077, cos=0.226), tot_loss_proj:1.575 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.514 (perp=6.120, rec=0.063, cos=0.226), tot_loss_proj:1.580 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.512 (perp=6.120, rec=0.061, cos=0.226), tot_loss_proj:1.587 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1050/2000] tot_loss=1.503 (perp=6.120, rec=0.053, cos=0.226), tot_loss_proj:1.583 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.503 (perp=6.120, rec=0.053, cos=0.226), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.514 (perp=6.120, rec=0.064, cos=0.226), tot_loss_proj:1.590 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1200/2000] tot_loss=1.511 (perp=6.120, rec=0.061, cos=0.226), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.502 (perp=6.120, rec=0.052, cos=0.226), tot_loss_proj:1.579 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.512 (perp=6.120, rec=0.061, cos=0.226), tot_loss_proj:1.583 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1350/2000] tot_loss=1.517 (perp=6.120, rec=0.067, cos=0.226), tot_loss_proj:1.587 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.518 (perp=6.120, rec=0.068, cos=0.226), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.513 (perp=6.120, rec=0.062, cos=0.226), tot_loss_proj:1.584 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1500/2000] tot_loss=1.511 (perp=6.120, rec=0.060, cos=0.226), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.511 (perp=6.120, rec=0.060, cos=0.226), tot_loss_proj:1.587 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.509 (perp=6.120, rec=0.059, cos=0.226), tot_loss_proj:1.577 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1650/2000] tot_loss=1.518 (perp=6.120, rec=0.067, cos=0.226), tot_loss_proj:1.584 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.507 (perp=6.120, rec=0.057, cos=0.226), tot_loss_proj:1.581 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.509 (perp=6.120, rec=0.059, cos=0.226), tot_loss_proj:1.572 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1800/2000] tot_loss=1.509 (perp=6.120, rec=0.058, cos=0.226), tot_loss_proj:1.580 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.518 (perp=6.120, rec=0.068, cos=0.227), tot_loss_proj:1.586 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.497 (perp=6.120, rec=0.047, cos=0.226), tot_loss_proj:1.579 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1950/2000] tot_loss=1.511 (perp=6.120, rec=0.060, cos=0.226), tot_loss_proj:1.586 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.521 (perp=6.120, rec=0.070, cos=0.226), tot_loss_proj:1.583 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] the bread was chewed by martha. [SEP]
========================
predicted: 
========================
[CLS] the bread was chewed by martha. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.984 | p: 86.639 | r: 87.511
rouge2     | fm: 51.708 | p: 51.323 | r: 52.166
rougeL     | fm: 76.994 | p: 76.742 | r: 77.442
rougeLsum  | fm: 77.067 | p: 76.737 | r: 77.551
r1fm+r2fm = 138.692

input #29 time: 0:08:52 | total time: 4:34:05


Running input #30 of 100.
reference: 
========================
Read Fred's story, I also want to.
========================
average of cosine similarity 0.8547814890083876
highest_index [0]
highest [0.8547814890083876]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 3191, 5965, 1005, 1055, 2466, 1010, 1045, 2036, 2215, 2000, 1012,
          102]], device='cuda:0')
Debug: ref = ["[CLS] read fred's story, i also want to. [SEP]"]
[Init] best rec loss: 0.8475202918052673 for ['[CLS] design tourea chargessionkan voicesitatingrak freedom mild [SEP]']
[Init] best rec loss: 0.8394210338592529 for ['[CLS] ~ roman will thought nickname dexter tailed truth market ghosts viewers [SEP]']
[Init] best rec loss: 0.836055338382721 for ['[CLS] printess consult audiencesrn also at once units encounter down [SEP]']
[Init] best rec loss: 0.8124840259552002 for ['[CLS] yield valley angeles hunters music " urges weight emmett governments round [SEP]']
[Init] best rec loss: 0.8098862171173096 for ['[CLS] port unionnch nigeriaed anyway postal creation interviews bank grandchildren [SEP]']
[Init] best rec loss: 0.8081275820732117 for ['[CLS] constitutionsfield bc mortgage person new wren tribune rocky gets divided [SEP]']
[Init] best perm rec loss: 0.8022466897964478 for ['[CLS] divided gets rocky constitution mortgage person new wrensfield tribune bc [SEP]']
[Init] best perm rec loss: 0.8012758493423462 for ['[CLS] person tribune divided getssfield new constitution mortgage wren rocky bc [SEP]']
[Init] best perm rec loss: 0.8008501529693604 for ['[CLS] divided bc mortgage gets person rockysfield new constitution tribune wren [SEP]']
[Init] best perm rec loss: 0.7992327213287354 for ['[CLS] person constitution divided wren gets bcsfield rocky tribune new mortgage [SEP]']
[Init] best perm rec loss: 0.798937201499939 for ['[CLS] tribune divided wren new rocky bcsfield gets person mortgage constitution [SEP]']
[Init] best perm rec loss: 0.7988722920417786 for ['[CLS] rocky mortgage tribune constitution new bc gets wren personsfield divided [SEP]']
[Init] best perm rec loss: 0.7982851266860962 for ['[CLS] tribune rocky mortgage constitution bc wrensfield new divided person gets [SEP]']
[Init] best perm rec loss: 0.796220064163208 for ['[CLS] divided mortgagesfield bc wren new person rocky gets tribune constitution [SEP]']
[Init] best perm rec loss: 0.7951096892356873 for ['[CLS] mortgage gets wren rocky bc constitution tribune new divided personsfield [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.116 (perp=12.023, rec=0.449, cos=0.262), tot_loss_proj:4.186 [t=0.22s]
prediction: ['[CLS] read learned strange terms jack fromthing necessarily his read geometridae [SEP]']
[ 100/2000] tot_loss=2.815 (perp=11.218, rec=0.306, cos=0.266), tot_loss_proj:3.992 [t=0.22s]
prediction: ['[CLS] read read stories besides, fromstadt separately read read geometridae [SEP]']
[ 150/2000] tot_loss=2.657 (perp=10.995, rec=0.216, cos=0.242), tot_loss_proj:3.946 [t=0.22s]
prediction: ['[CLS] read read story william i!nt quickly anyway, want [SEP]']
[ 200/2000] tot_loss=2.282 (perp=9.174, rec=0.196, cos=0.251), tot_loss_proj:3.600 [t=0.22s]
prediction: ["[CLS] read read story william i want'chosen also, want [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.309 (perp=9.188, rec=0.188, cos=0.283), tot_loss_proj:3.569 [t=0.22s]
prediction: ["[CLS] i read story fred read did'covert also, want [SEP]"]
[ 300/2000] tot_loss=2.282 (perp=9.420, rec=0.142, cos=0.257), tot_loss_proj:3.617 [t=0.22s]
prediction: ['[CLS] i read story fred want want, more also, to [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.320 (perp=9.646, rec=0.120, cos=0.271), tot_loss_proj:3.634 [t=0.22s]
prediction: ["[CLS] i read story fred, want'spread also want to [SEP]"]
Attempt swap
[ 400/2000] tot_loss=1.979 (perp=7.985, rec=0.127, cos=0.255), tot_loss_proj:3.348 [t=0.22s]
prediction: ["[CLS] i read story fred, because '. also want to [SEP]"]
[ 450/2000] tot_loss=1.972 (perp=7.985, rec=0.112, cos=0.263), tot_loss_proj:3.348 [t=0.22s]
prediction: ["[CLS] i read story fred, because '. also want to [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.972 (perp=7.985, rec=0.114, cos=0.261), tot_loss_proj:3.346 [t=0.22s]
prediction: ["[CLS] i read story fred, because '. also want to [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.794 (perp=7.102, rec=0.127, cos=0.247), tot_loss_proj:3.218 [t=0.22s]
prediction: ["[CLS] i read story, because'fred. also want to [SEP]"]
[ 600/2000] tot_loss=1.794 (perp=7.123, rec=0.109, cos=0.260), tot_loss_proj:3.184 [t=0.22s]
prediction: ["[CLS] i read story,'' fred. also want to [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.799 (perp=7.186, rec=0.097, cos=0.264), tot_loss_proj:3.196 [t=0.22s]
prediction: ["[CLS] i read story,'fred because. also want to [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.769 (perp=7.067, rec=0.093, cos=0.263), tot_loss_proj:3.214 [t=0.22s]
prediction: ["[CLS] i read story,'because fred. also want to [SEP]"]
[ 750/2000] tot_loss=1.785 (perp=7.067, rec=0.108, cos=0.264), tot_loss_proj:3.214 [t=0.22s]
prediction: ["[CLS] i read story,'because fred. also want to [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.782 (perp=7.067, rec=0.102, cos=0.267), tot_loss_proj:3.214 [t=0.22s]
prediction: ["[CLS] i read story,'because fred. also want to [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.767 (perp=7.067, rec=0.090, cos=0.263), tot_loss_proj:3.217 [t=0.22s]
prediction: ["[CLS] i read story,'because fred. also want to [SEP]"]
[ 900/2000] tot_loss=1.782 (perp=7.123, rec=0.091, cos=0.266), tot_loss_proj:3.189 [t=0.22s]
prediction: ["[CLS] i read story,'' fred. also want to [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.789 (perp=7.186, rec=0.093, cos=0.258), tot_loss_proj:3.188 [t=0.22s]
prediction: ["[CLS] i read story,'fred because. also want to [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.769 (perp=7.067, rec=0.091, cos=0.264), tot_loss_proj:3.215 [t=0.22s]
prediction: ["[CLS] i read story,'because fred. also want to [SEP]"]
[1050/2000] tot_loss=1.794 (perp=7.123, rec=0.103, cos=0.266), tot_loss_proj:3.195 [t=0.22s]
prediction: ["[CLS] i read story,'' fred. also want to [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.653 (perp=6.508, rec=0.090, cos=0.261), tot_loss_proj:3.039 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.667 (perp=6.508, rec=0.101, cos=0.265), tot_loss_proj:3.044 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
[1200/2000] tot_loss=1.654 (perp=6.508, rec=0.085, cos=0.267), tot_loss_proj:3.048 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.653 (perp=6.508, rec=0.085, cos=0.267), tot_loss_proj:3.040 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.661 (perp=6.508, rec=0.092, cos=0.267), tot_loss_proj:3.040 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
[1350/2000] tot_loss=1.653 (perp=6.508, rec=0.084, cos=0.267), tot_loss_proj:3.041 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.654 (perp=6.508, rec=0.085, cos=0.268), tot_loss_proj:3.044 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.664 (perp=6.508, rec=0.095, cos=0.268), tot_loss_proj:3.046 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
[1500/2000] tot_loss=1.665 (perp=6.508, rec=0.095, cos=0.268), tot_loss_proj:3.039 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.658 (perp=6.508, rec=0.088, cos=0.268), tot_loss_proj:3.046 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.662 (perp=6.508, rec=0.092, cos=0.269), tot_loss_proj:3.046 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
[1650/2000] tot_loss=1.655 (perp=6.508, rec=0.085, cos=0.268), tot_loss_proj:3.038 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.660 (perp=6.508, rec=0.090, cos=0.269), tot_loss_proj:3.042 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.663 (perp=6.508, rec=0.093, cos=0.269), tot_loss_proj:3.044 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
[1800/2000] tot_loss=1.652 (perp=6.508, rec=0.081, cos=0.269), tot_loss_proj:3.045 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.661 (perp=6.508, rec=0.090, cos=0.269), tot_loss_proj:3.049 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.659 (perp=6.508, rec=0.089, cos=0.269), tot_loss_proj:3.041 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
[1950/2000] tot_loss=1.665 (perp=6.508, rec=0.095, cos=0.268), tot_loss_proj:3.041 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.658 (perp=6.508, rec=0.088, cos=0.269), tot_loss_proj:3.040 [t=0.22s]
prediction: ["[CLS]'read story, i'fred. also want to [SEP]"]
Done with input #30 of 100.
reference: 
========================
[CLS] read fred's story, i also want to. [SEP]
========================
predicted: 
========================
[CLS]'read story, i'fred. also want to [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 100.000 | r: 90.000
rouge2     | fm: 58.824 | p: 62.500 | r: 55.556
rougeL     | fm: 84.211 | p: 88.889 | r: 80.000
rougeLsum  | fm: 84.211 | p: 88.889 | r: 80.000
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 87.155 | p: 87.048 | r: 87.481
rouge2     | fm: 51.989 | p: 51.733 | r: 52.458
rougeL     | fm: 77.350 | p: 77.235 | r: 77.751
rougeLsum  | fm: 77.164 | p: 76.968 | r: 77.621
r1fm+r2fm = 139.144

input #30 time: 0:08:52 | total time: 4:42:58


Running input #31 of 100.
reference: 
========================
Some of the water from melted snow also goes into the ground for plants.
========================
average of cosine similarity 0.8764412381649027
highest_index [0]
highest [0.8764412381649027]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2070,  1997,  1996,  2300,  2013, 12501,  4586,  2036,  3632,
          2046,  1996,  2598,  2005,  4264,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]']
[Init] best rec loss: 0.9138126373291016 for ["[CLS] girlfriend set faculty clay angeles boom cross bandonus sh 'tical mistake inn ballard [SEP]"]
[Init] best rec loss: 0.9063593149185181 for ['[CLS] ace brady declared temples eight simply { doi clapped content unit foot npr chargedtro [SEP]']
[Init] best rec loss: 0.8967869281768799 for ['[CLS] route treaty m² cheyenne honor 2018 prolonged... mara stone costume sargentic way freak [SEP]']
[Init] best rec loss: 0.88225257396698 for ['[CLS] modern currently joey press trent bed reaching main herzegovina mahmoud recent may prescription cover french [SEP]']
[Init] best rec loss: 0.8777599334716797 for ['[CLS] others yet greekcable one sat examined slowly rate providedə actual stony sang norwegian [SEP]']
[Init] best rec loss: 0.8530822396278381 for ['[CLS] transylvania you cold businesseszard street sexual sail holy twins strike undercover electricisation ky [SEP]']
[Init] best rec loss: 0.8519806265830994 for ['[CLS] tourism rulech thanks autumn merry feedbackhul gravel alert independent writings dogg way stretches [SEP]']
[Init] best rec loss: 0.8383901119232178 for ['[CLS] ice evenried rushmind tracy scottishrang before tennis from ruthing oscar election [SEP]']
[Init] best perm rec loss: 0.8378044962882996 for ['[CLS] election ice tracymindrieding scottish fromrang rush before tennis even ruth oscar [SEP]']
[Init] best perm rec loss: 0.8376995921134949 for ['[CLS] frommind oscaring ruth before evenrang tracy rush scottishried tennis ice election [SEP]']
[Init] best perm rec loss: 0.8368685245513916 for ['[CLS] rushrangmindried election tracy tennis before ice froming ruth oscar even scottish [SEP]']
[Init] best perm rec loss: 0.8344317674636841 for ['[CLS] rush tracy ice before ruthrangriedmind even electioning tennis oscar scottish from [SEP]']
[Init] best perm rec loss: 0.834256112575531 for ['[CLS] icemind oscaring electionried from before tennis rush tracy evenrang ruth scottish [SEP]']
[Init] best perm rec loss: 0.8337844014167786 for ['[CLS]mind scottish from tracy iceried before oscar rushrang evening election tennis ruth [SEP]']
[Init] best perm rec loss: 0.8335436582565308 for ['[CLS] ice frommind election rush ruth tennis beforeingrang tracyried scottish oscar even [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.691 (perp=10.379, rec=0.388, cos=0.227), tot_loss_proj:3.905 [t=0.22s]
prediction: ['[CLS] golden, cricket ) their babies rain is production given additional treatment for reed ground [SEP]']
[ 100/2000] tot_loss=2.606 (perp=10.076, rec=0.341, cos=0.250), tot_loss_proj:3.850 [t=0.22s]
prediction: ['[CLS] broken. cricket ) [SEP] trees snow watering for dried filming for ground plants [SEP]']
[ 150/2000] tot_loss=1.984 (perp=7.730, rec=0.212, cos=0.226), tot_loss_proj:3.369 [t=0.23s]
prediction: ['[CLS] nearby. water also from trees snow water and for some. for plants plants [SEP]']
[ 200/2000] tot_loss=2.150 (perp=8.558, rec=0.209, cos=0.230), tot_loss_proj:3.518 [t=0.23s]
prediction: ['[CLS] the. water also from trees snow goes and for some into for ground plants [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.057 (perp=8.274, rec=0.173, cos=0.229), tot_loss_proj:3.507 [t=0.22s]
prediction: ['[CLS] the snow. water also from humans goes with for some into for ground plants [SEP]']
[ 300/2000] tot_loss=2.024 (perp=8.274, rec=0.143, cos=0.226), tot_loss_proj:3.509 [t=0.23s]
prediction: ['[CLS] the snow. water also from humans goes with for some into for ground plants [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.889 (perp=7.706, rec=0.126, cos=0.222), tot_loss_proj:3.373 [t=0.23s]
prediction: ['[CLS] the snow. water also from humans goes with for ground into for some plants [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.979 (perp=8.200, rec=0.120, cos=0.219), tot_loss_proj:3.455 [t=0.23s]
prediction: ['[CLS] melted snow. water also from humans goes with into ground for for some plants [SEP]']
[ 450/2000] tot_loss=1.968 (perp=8.200, rec=0.104, cos=0.224), tot_loss_proj:3.457 [t=0.23s]
prediction: ['[CLS] melted snow. water also from humans goes with into ground for for some plants [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.845 (perp=7.594, rec=0.106, cos=0.220), tot_loss_proj:3.322 [t=0.23s]
prediction: ['[CLS] melted snow. water also from with snow goes into ground for for some plants [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.883 (perp=7.558, rec=0.142, cos=0.229), tot_loss_proj:3.335 [t=0.23s]
prediction: ['[CLS] also snow the water melted from or snow goes into ground for for some plants [SEP]']
[ 600/2000] tot_loss=1.940 (perp=8.008, rec=0.121, cos=0.218), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS] also snow the water melted from with humans goes into ground for for some plants [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.728 (perp=6.976, rec=0.104, cos=0.229), tot_loss_proj:3.187 [t=0.22s]
prediction: ['[CLS] also the water melted from snow with snow goes into ground for for some plants [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.669 (perp=6.668, rec=0.107, cos=0.228), tot_loss_proj:3.135 [t=0.23s]
prediction: ['[CLS] also the water from melted snow with snow goes into ground for for some plants [SEP]']
[ 750/2000] tot_loss=1.670 (perp=6.668, rec=0.110, cos=0.227), tot_loss_proj:3.142 [t=0.23s]
prediction: ['[CLS] also the water from melted snow with snow goes into ground for for some plants [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.691 (perp=6.793, rec=0.105, cos=0.228), tot_loss_proj:3.164 [t=0.23s]
prediction: ['[CLS] also. water from snow melted with snow goes into ground for for some plants [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.686 (perp=6.793, rec=0.098, cos=0.230), tot_loss_proj:3.167 [t=0.23s]
prediction: ['[CLS] also. water from snow melted with snow goes into ground for for some plants [SEP]']
[ 900/2000] tot_loss=1.688 (perp=6.793, rec=0.102, cos=0.228), tot_loss_proj:3.166 [t=0.23s]
prediction: ['[CLS] also. water from snow melted with snow goes into ground for for some plants [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.673 (perp=6.793, rec=0.086, cos=0.229), tot_loss_proj:3.169 [t=0.23s]
prediction: ['[CLS] also. water from snow melted with snow goes into ground for for some plants [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.616 (perp=6.452, rec=0.096, cos=0.229), tot_loss_proj:3.100 [t=0.23s]
prediction: ['[CLS] also from water. snow melted with snow goes into ground for for some plants [SEP]']
[1050/2000] tot_loss=1.614 (perp=6.452, rec=0.094, cos=0.229), tot_loss_proj:3.106 [t=0.23s]
prediction: ['[CLS] also from water. snow melted with snow goes into ground for for some plants [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.607 (perp=6.408, rec=0.095, cos=0.230), tot_loss_proj:3.107 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[1150/2000] tot_loss=1.607 (perp=6.408, rec=0.095, cos=0.230), tot_loss_proj:3.106 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
[1200/2000] tot_loss=1.609 (perp=6.408, rec=0.099, cos=0.228), tot_loss_proj:3.107 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[1250/2000] tot_loss=1.613 (perp=6.408, rec=0.098, cos=0.234), tot_loss_proj:3.104 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[1300/2000] tot_loss=1.602 (perp=6.408, rec=0.094, cos=0.226), tot_loss_proj:3.102 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
[1350/2000] tot_loss=1.603 (perp=6.408, rec=0.094, cos=0.228), tot_loss_proj:3.109 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[1400/2000] tot_loss=1.602 (perp=6.408, rec=0.089, cos=0.232), tot_loss_proj:3.104 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[1450/2000] tot_loss=1.605 (perp=6.408, rec=0.091, cos=0.232), tot_loss_proj:3.109 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
[1500/2000] tot_loss=1.614 (perp=6.408, rec=0.101, cos=0.231), tot_loss_proj:3.108 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[1550/2000] tot_loss=1.612 (perp=6.408, rec=0.099, cos=0.231), tot_loss_proj:3.108 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[1600/2000] tot_loss=1.608 (perp=6.408, rec=0.096, cos=0.231), tot_loss_proj:3.103 [t=0.22s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
[1650/2000] tot_loss=1.609 (perp=6.408, rec=0.095, cos=0.232), tot_loss_proj:3.101 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[1700/2000] tot_loss=1.595 (perp=6.408, rec=0.083, cos=0.230), tot_loss_proj:3.106 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[1750/2000] tot_loss=1.601 (perp=6.408, rec=0.089, cos=0.230), tot_loss_proj:3.103 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
[1800/2000] tot_loss=1.606 (perp=6.408, rec=0.092, cos=0.232), tot_loss_proj:3.106 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[1850/2000] tot_loss=1.594 (perp=6.408, rec=0.081, cos=0.231), tot_loss_proj:3.108 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[1900/2000] tot_loss=1.603 (perp=6.408, rec=0.090, cos=0.232), tot_loss_proj:3.107 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
[1950/2000] tot_loss=1.599 (perp=6.408, rec=0.086, cos=0.231), tot_loss_proj:3.109 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Attempt swap
[2000/2000] tot_loss=1.598 (perp=6.408, rec=0.085, cos=0.232), tot_loss_proj:3.104 [t=0.23s]
prediction: ['[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]
========================
predicted: 
========================
[CLS] also from water. snow with melted snow goes into ground for for some plants [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.250 | p: 81.250 | r: 81.250
rouge2     | fm: 26.667 | p: 26.667 | r: 26.667
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 107.917

[Aggregate metrics]:
rouge1     | fm: 86.978 | p: 86.915 | r: 87.404
rouge2     | fm: 51.174 | p: 50.898 | r: 51.589
rougeL     | fm: 76.754 | p: 76.593 | r: 77.120
rougeLsum  | fm: 76.860 | p: 76.690 | r: 77.168
r1fm+r2fm = 138.153

input #31 time: 0:08:58 | total time: 4:51:56


Running input #32 of 100.
reference: 
========================
Bob is very serious about Mary, but less so than Paul.
========================
average of cosine similarity 0.8804826666047018
highest_index [0]
highest [0.8804826666047018]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[ 101, 3960, 2003, 2200, 3809, 2055, 2984, 1010, 2021, 2625, 2061, 2084,
         2703, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bob is very serious about mary, but less so than paul. [SEP]']
[Init] best rec loss: 0.9320904612541199 for ['[CLS] archery dual„ pam an arrows kings beyond if rev up place behind [SEP]']
[Init] best rec loss: 0.9244967699050903 for ['[CLS] sitcom interest informeduing bright line jr nationoptera average knee season passion [SEP]']
[Init] best rec loss: 0.897088348865509 for ['[CLS] elite marley laps threeionalash canadian gas liner hands ass jr l [SEP]']
[Init] best rec loss: 0.868839681148529 for ['[CLS] controversy reunion attitude lahore governor supported fireplace + fc mountain declan reader beers [SEP]']
[Init] best rec loss: 0.8661410808563232 for ['[CLS] employment zones assist military consuming brains sic keynes suck heidi documents spreading us [SEP]']
[Init] best rec loss: 0.861893355846405 for ['[CLS] best hardly yet miami ku ad affair wings puppyrda http both connie [SEP]']
[Init] best rec loss: 0.8492617607116699 for ['[CLS] mooseshai jackson honor training resources night jess urgent girl setය [SEP]']
[Init] best perm rec loss: 0.8478047847747803 for ['[CLS] jess urgent setය training moose honorhai night jacksons resources girl [SEP]']
[Init] best perm rec loss: 0.8473922610282898 for ['[CLS] moose urgent jess resourceshaiය set training nights jackson honor girl [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.636 (perp=10.552, rec=0.310, cos=0.215), tot_loss_proj:3.979 [t=0.22s]
prediction: ['[CLS] bob serious paul and mary serious ( serious serious. mary than ; [SEP]']
[ 100/2000] tot_loss=2.096 (perp=8.341, rec=0.202, cos=0.226), tot_loss_proj:3.502 [t=0.22s]
prediction: ['[CLS] bob serious paul about mary serious but less so than less than bob [SEP]']
[ 150/2000] tot_loss=2.149 (perp=8.894, rec=0.156, cos=0.214), tot_loss_proj:3.666 [t=0.22s]
prediction: ['[CLS] bob serious bob about mary serious but less so. less than paul [SEP]']
[ 200/2000] tot_loss=2.010 (perp=8.483, rec=0.113, cos=0.200), tot_loss_proj:3.568 [t=0.22s]
prediction: ['[CLS] is serious bob about mary serious but less so. very than paul [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.401 (perp=8.875, rec=0.412, cos=0.214), tot_loss_proj:3.587 [t=0.22s]
prediction: ['[CLS] is serious bob about mary but less so, quite _ than paul [SEP]']
[ 300/2000] tot_loss=2.087 (perp=8.275, rec=0.217, cos=0.215), tot_loss_proj:3.515 [t=0.22s]
prediction: ['[CLS] is serious bob about mary but less so, quite mary than paul [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.044 (perp=8.278, rec=0.164, cos=0.225), tot_loss_proj:3.554 [t=0.22s]
prediction: ['[CLS] is serious bob about mary but less quite so, paul than paul [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.881 (perp=7.548, rec=0.150, cos=0.221), tot_loss_proj:3.362 [t=0.22s]
prediction: ['[CLS] is serious bob about mary, but less quite so paul than paul [SEP]']
[ 450/2000] tot_loss=1.934 (perp=7.868, rec=0.136, cos=0.224), tot_loss_proj:3.414 [t=0.22s]
prediction: ['[CLS] is serious bob about mary, but less very so paul than paul [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.838 (perp=6.982, rec=0.221, cos=0.221), tot_loss_proj:2.648 [t=0.22s]
prediction: ['[CLS] bob is serious about mary, but less less so paul than paul [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.713 (perp=6.591, rec=0.172, cos=0.223), tot_loss_proj:2.999 [t=0.22s]
prediction: ['[CLS] bob is serious about mary, but less paul less so than paul [SEP]']
[ 600/2000] tot_loss=1.699 (perp=6.591, rec=0.162, cos=0.219), tot_loss_proj:3.011 [t=0.22s]
prediction: ['[CLS] bob is serious about mary, but less paul less so than paul [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.684 (perp=6.591, rec=0.145, cos=0.221), tot_loss_proj:3.023 [t=0.22s]
prediction: ['[CLS] bob is serious about mary, but less paul less so than paul [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.595 (perp=6.157, rec=0.146, cos=0.218), tot_loss_proj:2.431 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, but less less so than paul [SEP]']
[ 750/2000] tot_loss=1.582 (perp=6.157, rec=0.125, cos=0.225), tot_loss_proj:2.401 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, but less less so than paul [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.582 (perp=6.157, rec=0.129, cos=0.222), tot_loss_proj:2.385 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, but less less so than paul [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.577 (perp=6.157, rec=0.122, cos=0.224), tot_loss_proj:2.373 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, but less less so than paul [SEP]']
[ 900/2000] tot_loss=1.589 (perp=6.157, rec=0.132, cos=0.225), tot_loss_proj:2.367 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, but less less so than paul [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.548 (perp=5.996, rec=0.124, cos=0.224), tot_loss_proj:2.628 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, but less as so than paul [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.591 (perp=6.157, rec=0.139, cos=0.221), tot_loss_proj:2.379 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, but less less so than paul [SEP]']
[1050/2000] tot_loss=1.591 (perp=6.157, rec=0.135, cos=0.225), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, but less less so than paul [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.563 (perp=6.051, rec=0.128, cos=0.224), tot_loss_proj:2.507 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[1150/2000] tot_loss=1.546 (perp=6.051, rec=0.112, cos=0.224), tot_loss_proj:2.500 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
[1200/2000] tot_loss=1.560 (perp=6.051, rec=0.125, cos=0.224), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[1250/2000] tot_loss=1.559 (perp=6.051, rec=0.124, cos=0.225), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[1300/2000] tot_loss=1.550 (perp=6.051, rec=0.116, cos=0.224), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
[1350/2000] tot_loss=1.554 (perp=6.051, rec=0.120, cos=0.224), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[1400/2000] tot_loss=1.556 (perp=6.051, rec=0.122, cos=0.223), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[1450/2000] tot_loss=1.548 (perp=6.051, rec=0.116, cos=0.222), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
[1500/2000] tot_loss=1.546 (perp=6.051, rec=0.111, cos=0.224), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[1550/2000] tot_loss=1.545 (perp=6.051, rec=0.111, cos=0.224), tot_loss_proj:2.485 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[1600/2000] tot_loss=1.544 (perp=6.051, rec=0.110, cos=0.224), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
[1650/2000] tot_loss=1.553 (perp=6.051, rec=0.119, cos=0.224), tot_loss_proj:2.493 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[1700/2000] tot_loss=1.552 (perp=6.051, rec=0.118, cos=0.223), tot_loss_proj:2.484 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[1750/2000] tot_loss=1.545 (perp=6.051, rec=0.112, cos=0.223), tot_loss_proj:2.487 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
[1800/2000] tot_loss=1.550 (perp=6.051, rec=0.117, cos=0.223), tot_loss_proj:2.486 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[1850/2000] tot_loss=1.548 (perp=6.051, rec=0.115, cos=0.223), tot_loss_proj:2.482 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[1900/2000] tot_loss=1.556 (perp=6.051, rec=0.121, cos=0.225), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
[1950/2000] tot_loss=1.549 (perp=6.051, rec=0.114, cos=0.224), tot_loss_proj:2.480 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary, less but less so than paul [SEP]']
Attempt swap
[2000/2000] tot_loss=1.548 (perp=6.070, rec=0.109, cos=0.225), tot_loss_proj:2.495 [t=0.22s]
prediction: ['[CLS] bob paul is serious about mary. less but less so than paul [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] bob is very serious about mary, but less so than paul. [SEP]
========================
predicted: 
========================
[CLS] is serious bob about mary serious but less so. very than paul [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.296 | p: 92.857 | r: 100.000
rouge2     | fm: 40.000 | p: 38.462 | r: 41.667
rougeL     | fm: 81.481 | p: 78.571 | r: 84.615
rougeLsum  | fm: 81.481 | p: 78.571 | r: 84.615
r1fm+r2fm = 136.296

[Aggregate metrics]:
rouge1     | fm: 87.386 | p: 87.097 | r: 87.886
rouge2     | fm: 51.242 | p: 51.026 | r: 51.654
rougeL     | fm: 76.875 | p: 76.559 | r: 77.287
rougeLsum  | fm: 77.008 | p: 76.726 | r: 77.449
r1fm+r2fm = 138.628

input #32 time: 0:08:52 | total time: 5:00:48


Running input #33 of 100.
reference: 
========================
Ayala sent the diamond necklace back.
========================
average of cosine similarity 0.8852439377469337
highest_index [0]
highest [0.8852439377469337]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  1996,  6323, 13016,  2067,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] ayala sent the diamond necklace back. [SEP]']
[Init] best rec loss: 0.9424660205841064 for ['[CLS] terms primary contribution an soil all competition dug [SEP]']
[Init] best rec loss: 0.935715913772583 for ['[CLS] thought latvia grant landowner main down campaign personnel [SEP]']
[Init] best rec loss: 0.8942181468009949 for ['[CLS] strikingenberg online poland silver through proper comfort [SEP]']
[Init] best rec loss: 0.8727719783782959 for ['[CLS] fists ins / haserik needle combined related [SEP]']
[Init] best perm rec loss: 0.8663578033447266 for ['[CLS]erik needle ins related / has fists combined [SEP]']
[Init] best perm rec loss: 0.8650543689727783 for ['[CLS] needle relatederik fists has ins combined / [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.848 (perp=11.458, rec=0.345, cos=0.211), tot_loss_proj:4.224 [t=0.22s]
prediction: ['[CLS] a diamond story delivered divisionyalayalayala [SEP]']
[ 100/2000] tot_loss=2.764 (perp=11.622, rec=0.237, cos=0.202), tot_loss_proj:4.178 [t=0.22s]
prediction: ['[CLS] a sent diamond back.yalayalayala [SEP]']
[ 150/2000] tot_loss=2.809 (perp=12.463, rec=0.110, cos=0.206), tot_loss_proj:4.382 [t=0.22s]
prediction: ['[CLS] a sent diamond back necklaceyalayalayala [SEP]']
[ 200/2000] tot_loss=2.800 (perp=12.463, rec=0.109, cos=0.198), tot_loss_proj:4.382 [t=0.22s]
prediction: ['[CLS] a sent diamond back necklaceyalayalayala [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.402 (perp=10.488, rec=0.098, cos=0.206), tot_loss_proj:3.946 [t=0.22s]
prediction: ['[CLS] a sent back diamond necklaceyalayalayala [SEP]']
[ 300/2000] tot_loss=2.400 (perp=10.488, rec=0.092, cos=0.211), tot_loss_proj:3.952 [t=0.22s]
prediction: ['[CLS] a sent back diamond necklaceyalayalayala [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.400 (perp=10.488, rec=0.086, cos=0.216), tot_loss_proj:3.946 [t=0.22s]
prediction: ['[CLS] a sent back diamond necklaceyalayalayala [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.394 (perp=10.488, rec=0.085, cos=0.212), tot_loss_proj:3.946 [t=0.22s]
prediction: ['[CLS] a sent back diamond necklaceyalayalayala [SEP]']
[ 450/2000] tot_loss=2.403 (perp=10.488, rec=0.093, cos=0.212), tot_loss_proj:3.946 [t=0.22s]
prediction: ['[CLS] a sent back diamond necklaceyalayalayala [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.396 (perp=10.488, rec=0.086, cos=0.212), tot_loss_proj:3.953 [t=0.22s]
prediction: ['[CLS] a sent back diamond necklaceyalayalayala [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.297 (perp=10.016, rec=0.081, cos=0.213), tot_loss_proj:3.773 [t=0.22s]
prediction: ['[CLS] a sent back diamond necklace.yalayala [SEP]']
[ 600/2000] tot_loss=2.293 (perp=10.016, rec=0.077, cos=0.213), tot_loss_proj:3.774 [t=0.22s]
prediction: ['[CLS] a sent back diamond necklace.yalayala [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.064 (perp=8.870, rec=0.075, cos=0.215), tot_loss_proj:3.670 [t=0.22s]
prediction: ['[CLS] a sent back diamond necklaceyala diamond. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.980 (perp=8.489, rec=0.069, cos=0.214), tot_loss_proj:3.569 [t=0.22s]
prediction: ['[CLS] a sent back the necklaceyala diamond. [SEP]']
[ 750/2000] tot_loss=1.987 (perp=8.489, rec=0.075, cos=0.214), tot_loss_proj:3.567 [t=0.22s]
prediction: ['[CLS] a sent back the necklaceyala diamond. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.881 (perp=7.876, rec=0.094, cos=0.212), tot_loss_proj:3.405 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.863 (perp=7.876, rec=0.074, cos=0.213), tot_loss_proj:3.411 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
[ 900/2000] tot_loss=1.862 (perp=7.876, rec=0.073, cos=0.214), tot_loss_proj:3.410 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.859 (perp=7.876, rec=0.069, cos=0.214), tot_loss_proj:3.407 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.864 (perp=7.876, rec=0.074, cos=0.214), tot_loss_proj:3.412 [t=0.29s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
[1050/2000] tot_loss=1.873 (perp=7.876, rec=0.083, cos=0.215), tot_loss_proj:3.409 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.861 (perp=7.876, rec=0.071, cos=0.215), tot_loss_proj:3.409 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.862 (perp=7.876, rec=0.071, cos=0.215), tot_loss_proj:3.407 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
[1200/2000] tot_loss=1.855 (perp=7.876, rec=0.065, cos=0.215), tot_loss_proj:3.411 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.849 (perp=7.876, rec=0.059, cos=0.215), tot_loss_proj:3.410 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.855 (perp=7.876, rec=0.065, cos=0.215), tot_loss_proj:3.410 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
[1350/2000] tot_loss=1.864 (perp=7.876, rec=0.074, cos=0.215), tot_loss_proj:3.412 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.836 (perp=7.876, rec=0.045, cos=0.215), tot_loss_proj:3.413 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.860 (perp=7.876, rec=0.070, cos=0.215), tot_loss_proj:3.410 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
[1500/2000] tot_loss=1.861 (perp=7.876, rec=0.071, cos=0.215), tot_loss_proj:3.409 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.853 (perp=7.876, rec=0.062, cos=0.215), tot_loss_proj:3.412 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.852 (perp=7.876, rec=0.061, cos=0.215), tot_loss_proj:3.413 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
[1650/2000] tot_loss=1.860 (perp=7.876, rec=0.069, cos=0.215), tot_loss_proj:3.414 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.860 (perp=7.876, rec=0.070, cos=0.215), tot_loss_proj:3.408 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.855 (perp=7.876, rec=0.064, cos=0.215), tot_loss_proj:3.407 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
[1800/2000] tot_loss=1.869 (perp=7.876, rec=0.079, cos=0.215), tot_loss_proj:3.412 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.867 (perp=7.876, rec=0.077, cos=0.215), tot_loss_proj:3.407 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.861 (perp=7.876, rec=0.070, cos=0.215), tot_loss_proj:3.414 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
[1950/2000] tot_loss=1.845 (perp=7.876, rec=0.055, cos=0.215), tot_loss_proj:3.411 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.858 (perp=7.876, rec=0.068, cos=0.215), tot_loss_proj:3.412 [t=0.22s]
prediction: ['[CLS] a sent back theyala diamond necklace. [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] ayala sent the diamond necklace back. [SEP]
========================
predicted: 
========================
[CLS] a sent back theyala diamond necklace. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 89.286

[Aggregate metrics]:
rouge1     | fm: 86.954 | p: 86.734 | r: 87.483
rouge2     | fm: 50.313 | p: 49.957 | r: 50.608
rougeL     | fm: 76.376 | p: 76.110 | r: 76.772
rougeLsum  | fm: 76.671 | p: 76.432 | r: 77.138
r1fm+r2fm = 137.267

input #33 time: 0:08:52 | total time: 5:09:40


Running input #34 of 100.
reference: 
========================
Jessica sprayed paint under the table.
========================
average of cosine similarity 0.907619774506436
highest_index [0]
highest [0.907619774506436]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  8201, 25401,  6773,  2104,  1996,  2795,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] jessica sprayed paint under the table. [SEP]']
[Init] best rec loss: 0.9544417858123779 for ['[CLS] solvent pure sitting returns open penelope gerais [SEP]']
[Init] best rec loss: 0.9534792304039001 for ['[CLS] woundam helena sense regime forever central [SEP]']
[Init] best rec loss: 0.9290597438812256 for ['[CLS]icia brothers tender ass premiere as [SEP] [SEP]']
[Init] best rec loss: 0.9212504625320435 for ['[CLS] international density janeiro cum units shop dh [SEP]']
[Init] best rec loss: 0.9099269509315491 for ['[CLS]anscia bradhal forget slight relief [SEP]']
[Init] best rec loss: 0.9044772982597351 for ['[CLS] itself up guitar according habits laszlo idle [SEP]']
[Init] best rec loss: 0.8889820575714111 for ['[CLS]ter & since cureraßeeratednes [SEP]']
[Init] best perm rec loss: 0.8879499435424805 for ['[CLS]tereratednes sinceraße cure & [SEP]']
[Init] best perm rec loss: 0.8874435424804688 for ['[CLS]terraße cureerated since &nes [SEP]']
[Init] best perm rec loss: 0.8868381977081299 for ['[CLS]raßeter cure &erated sincenes [SEP]']
[Init] best perm rec loss: 0.8865863680839539 for ['[CLS]terraßenes cure & sinceerated [SEP]']
[Init] best perm rec loss: 0.886332631111145 for ['[CLS]tererated sinceraße & curenes [SEP]']
[Init] best perm rec loss: 0.8852049708366394 for ['[CLS]terneserated cure & sinceraße [SEP]']
[Init] best perm rec loss: 0.885034441947937 for ['[CLS]raßeerated cure sinceternes & [SEP]']
[Init] best perm rec loss: 0.8832829594612122 for ['[CLS]neserated & since cureterraße [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.689 (perp=11.099, rec=0.299, cos=0.170), tot_loss_proj:4.067 [t=0.22s]
prediction: ['[CLS] sprayed. jessica gallery jessica paint pitcher [SEP]']
[ 100/2000] tot_loss=2.723 (perp=11.721, rec=0.220, cos=0.159), tot_loss_proj:4.202 [t=0.22s]
prediction: ['[CLS] sprayed. jessica table jessica paint pipe [SEP]']
[ 150/2000] tot_loss=2.368 (perp=10.265, rec=0.143, cos=0.172), tot_loss_proj:3.920 [t=0.22s]
prediction: ['[CLS] sprayed. the table jessica paint! [SEP]']
[ 200/2000] tot_loss=2.291 (perp=10.053, rec=0.107, cos=0.173), tot_loss_proj:3.785 [t=0.22s]
prediction: ['[CLS] sprayed under the table jessica paint my [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.087 (perp=9.099, rec=0.095, cos=0.172), tot_loss_proj:3.643 [t=0.22s]
prediction: ['[CLS] sprayed under the table my paint jessica [SEP]']
[ 300/2000] tot_loss=2.083 (perp=9.099, rec=0.092, cos=0.172), tot_loss_proj:3.635 [t=0.22s]
prediction: ['[CLS] sprayed under the table my paint jessica [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.030 (perp=8.882, rec=0.082, cos=0.171), tot_loss_proj:3.625 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.034 (perp=8.882, rec=0.086, cos=0.172), tot_loss_proj:3.628 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
[ 450/2000] tot_loss=2.028 (perp=8.882, rec=0.080, cos=0.172), tot_loss_proj:3.625 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.025 (perp=8.882, rec=0.076, cos=0.172), tot_loss_proj:3.629 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.027 (perp=8.882, rec=0.078, cos=0.173), tot_loss_proj:3.629 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
[ 600/2000] tot_loss=2.028 (perp=8.882, rec=0.081, cos=0.172), tot_loss_proj:3.628 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.034 (perp=8.882, rec=0.085, cos=0.172), tot_loss_proj:3.629 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.028 (perp=8.882, rec=0.079, cos=0.172), tot_loss_proj:3.630 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
[ 750/2000] tot_loss=2.012 (perp=8.882, rec=0.064, cos=0.172), tot_loss_proj:3.626 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.015 (perp=8.882, rec=0.067, cos=0.172), tot_loss_proj:3.628 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.037 (perp=8.882, rec=0.088, cos=0.172), tot_loss_proj:3.628 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
[ 900/2000] tot_loss=2.024 (perp=8.882, rec=0.076, cos=0.172), tot_loss_proj:3.627 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.028 (perp=8.882, rec=0.079, cos=0.172), tot_loss_proj:3.627 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1000/2000] tot_loss=2.008 (perp=8.882, rec=0.060, cos=0.172), tot_loss_proj:3.632 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
[1050/2000] tot_loss=2.034 (perp=8.882, rec=0.086, cos=0.172), tot_loss_proj:3.628 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1100/2000] tot_loss=2.027 (perp=8.882, rec=0.078, cos=0.173), tot_loss_proj:3.626 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1150/2000] tot_loss=2.031 (perp=8.882, rec=0.082, cos=0.173), tot_loss_proj:3.627 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
[1200/2000] tot_loss=2.025 (perp=8.882, rec=0.077, cos=0.173), tot_loss_proj:3.633 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1250/2000] tot_loss=2.012 (perp=8.882, rec=0.063, cos=0.173), tot_loss_proj:3.627 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1300/2000] tot_loss=2.024 (perp=8.882, rec=0.075, cos=0.173), tot_loss_proj:3.632 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
[1350/2000] tot_loss=2.029 (perp=8.882, rec=0.080, cos=0.173), tot_loss_proj:3.629 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1400/2000] tot_loss=2.034 (perp=8.882, rec=0.085, cos=0.173), tot_loss_proj:3.631 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1450/2000] tot_loss=2.034 (perp=8.882, rec=0.085, cos=0.173), tot_loss_proj:3.628 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
[1500/2000] tot_loss=2.022 (perp=8.882, rec=0.073, cos=0.173), tot_loss_proj:3.629 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1550/2000] tot_loss=2.030 (perp=8.882, rec=0.081, cos=0.173), tot_loss_proj:3.627 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1600/2000] tot_loss=2.026 (perp=8.882, rec=0.077, cos=0.173), tot_loss_proj:3.624 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
[1650/2000] tot_loss=2.025 (perp=8.882, rec=0.076, cos=0.173), tot_loss_proj:3.629 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1700/2000] tot_loss=2.032 (perp=8.882, rec=0.083, cos=0.173), tot_loss_proj:3.627 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1750/2000] tot_loss=2.027 (perp=8.882, rec=0.078, cos=0.173), tot_loss_proj:3.626 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
[1800/2000] tot_loss=2.029 (perp=8.882, rec=0.080, cos=0.173), tot_loss_proj:3.629 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1850/2000] tot_loss=2.027 (perp=8.882, rec=0.078, cos=0.173), tot_loss_proj:3.627 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[1900/2000] tot_loss=2.011 (perp=8.882, rec=0.062, cos=0.173), tot_loss_proj:3.631 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
[1950/2000] tot_loss=2.028 (perp=8.882, rec=0.079, cos=0.173), tot_loss_proj:3.623 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Attempt swap
[2000/2000] tot_loss=2.018 (perp=8.882, rec=0.069, cos=0.173), tot_loss_proj:3.633 [t=0.22s]
prediction: ['[CLS] sprayed my under the table paint jessica [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] jessica sprayed paint under the table. [SEP]
========================
predicted: 
========================
[CLS] sprayed my under the table paint jessica [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 26.667 | p: 25.000 | r: 28.571
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 120.784

[Aggregate metrics]:
rouge1     | fm: 87.284 | p: 86.870 | r: 87.920
rouge2     | fm: 49.464 | p: 49.205 | r: 49.832
rougeL     | fm: 76.347 | p: 76.007 | r: 76.803
rougeLsum  | fm: 76.331 | p: 76.006 | r: 76.868
r1fm+r2fm = 136.748

input #34 time: 0:08:52 | total time: 5:18:33


Running input #35 of 100.
reference: 
========================
John is refused.
========================
average of cosine similarity 0.8850210369893179
highest_index [0]
highest [0.8850210369893179]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2198, 2003, 4188, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is refused. [SEP]']
[Init] best rec loss: 0.8392331004142761 for ['[CLS] hugo cruise than seconds [SEP]']
[Init] best rec loss: 0.8119151592254639 for ['[CLS] hypothesisphysics front closest [SEP]']
[Init] best rec loss: 0.7987304329872131 for ['[CLS] magazines heart gaunt luther [SEP]']
[Init] best rec loss: 0.7932929992675781 for ['[CLS] young love hydra worth [SEP]']
[Init] best rec loss: 0.7866848707199097 for ['[CLS] cass having many cy [SEP]']
[Init] best perm rec loss: 0.7864026427268982 for ['[CLS] cy many having cass [SEP]']
[Init] best perm rec loss: 0.7859328389167786 for ['[CLS] many having cy cass [SEP]']
[Init] best perm rec loss: 0.7848901748657227 for ['[CLS] cy having cass many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.085 (perp=12.125, rec=0.436, cos=0.223), tot_loss_proj:4.308 [t=0.22s]
prediction: ['[CLS] refused is cannot object [SEP]']
[ 100/2000] tot_loss=2.485 (perp=10.192, rec=0.245, cos=0.201), tot_loss_proj:3.913 [t=0.22s]
prediction: ['[CLS] refused is is refused [SEP]']
[ 150/2000] tot_loss=2.417 (perp=10.192, rec=0.165, cos=0.213), tot_loss_proj:3.895 [t=0.22s]
prediction: ['[CLS] refused is is refused [SEP]']
[ 200/2000] tot_loss=2.777 (perp=12.180, rec=0.122, cos=0.219), tot_loss_proj:4.232 [t=0.22s]
prediction: ['[CLS] refused john is palo [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.428 (perp=10.323, rec=0.149, cos=0.215), tot_loss_proj:3.853 [t=0.22s]
prediction: ['[CLS] pie john is refused [SEP]']
[ 300/2000] tot_loss=2.386 (perp=10.326, rec=0.109, cos=0.212), tot_loss_proj:3.668 [t=0.22s]
prediction: ['[CLS] forever john is refused [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.146 (perp=9.161, rec=0.107, cos=0.206), tot_loss_proj:2.564 [t=0.22s]
prediction: ['[CLS] john is refused forever [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.144 (perp=9.161, rec=0.095, cos=0.216), tot_loss_proj:2.569 [t=0.22s]
prediction: ['[CLS] john is refused forever [SEP]']
[ 450/2000] tot_loss=2.154 (perp=9.161, rec=0.110, cos=0.212), tot_loss_proj:2.564 [t=0.22s]
prediction: ['[CLS] john is refused forever [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.143 (perp=9.161, rec=0.095, cos=0.215), tot_loss_proj:2.560 [t=0.22s]
prediction: ['[CLS] john is refused forever [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.136 (perp=9.161, rec=0.090, cos=0.213), tot_loss_proj:2.561 [t=0.22s]
prediction: ['[CLS] john is refused forever [SEP]']
[ 600/2000] tot_loss=2.139 (perp=9.161, rec=0.091, cos=0.216), tot_loss_proj:2.562 [t=0.22s]
prediction: ['[CLS] john is refused forever [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.148 (perp=9.161, rec=0.101, cos=0.215), tot_loss_proj:2.562 [t=0.22s]
prediction: ['[CLS] john is refused forever [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.682 (perp=6.835, rec=0.099, cos=0.216), tot_loss_proj:1.700 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
[ 750/2000] tot_loss=1.678 (perp=6.835, rec=0.097, cos=0.214), tot_loss_proj:1.687 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.673 (perp=6.835, rec=0.092, cos=0.213), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.675 (perp=6.835, rec=0.096, cos=0.212), tot_loss_proj:1.694 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
[ 900/2000] tot_loss=1.673 (perp=6.835, rec=0.090, cos=0.216), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.684 (perp=6.835, rec=0.102, cos=0.215), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.672 (perp=6.835, rec=0.090, cos=0.215), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
[1050/2000] tot_loss=1.675 (perp=6.835, rec=0.094, cos=0.214), tot_loss_proj:1.686 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.666 (perp=6.835, rec=0.085, cos=0.214), tot_loss_proj:1.699 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.662 (perp=6.835, rec=0.081, cos=0.214), tot_loss_proj:1.686 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
[1200/2000] tot_loss=1.669 (perp=6.835, rec=0.086, cos=0.216), tot_loss_proj:1.698 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.678 (perp=6.835, rec=0.095, cos=0.216), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.687 (perp=6.835, rec=0.104, cos=0.216), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
[1350/2000] tot_loss=1.672 (perp=6.835, rec=0.089, cos=0.216), tot_loss_proj:1.697 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.671 (perp=6.835, rec=0.090, cos=0.214), tot_loss_proj:1.702 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.672 (perp=6.835, rec=0.090, cos=0.215), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
[1500/2000] tot_loss=1.668 (perp=6.835, rec=0.086, cos=0.215), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.665 (perp=6.835, rec=0.082, cos=0.216), tot_loss_proj:1.694 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.674 (perp=6.835, rec=0.091, cos=0.216), tot_loss_proj:1.696 [t=0.28s]
prediction: ['[CLS] john is refused. [SEP]']
[1650/2000] tot_loss=1.668 (perp=6.835, rec=0.086, cos=0.216), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.667 (perp=6.835, rec=0.084, cos=0.216), tot_loss_proj:1.703 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.675 (perp=6.835, rec=0.092, cos=0.217), tot_loss_proj:1.699 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
[1800/2000] tot_loss=1.671 (perp=6.835, rec=0.088, cos=0.216), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.663 (perp=6.835, rec=0.079, cos=0.217), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.683 (perp=6.835, rec=0.099, cos=0.216), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
[1950/2000] tot_loss=1.675 (perp=6.835, rec=0.092, cos=0.216), tot_loss_proj:1.697 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.668 (perp=6.835, rec=0.085, cos=0.216), tot_loss_proj:1.701 [t=0.22s]
prediction: ['[CLS] john is refused. [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] john is refused. [SEP]
========================
predicted: 
========================
[CLS] john is refused. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.494 | p: 87.195 | r: 88.135
rouge2     | fm: 51.018 | p: 50.654 | r: 51.450
rougeL     | fm: 76.974 | p: 76.589 | r: 77.389
rougeLsum  | fm: 77.098 | p: 76.726 | r: 77.592
r1fm+r2fm = 138.512

input #35 time: 0:08:51 | total time: 5:27:24


Running input #36 of 100.
reference: 
========================
This information could have been released by Gorbachev, but he chose not to.
========================
average of cosine similarity 0.9085128701375426
highest_index [0]
highest [0.9085128701375426]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[  101,  2023,  2592,  2071,  2031,  2042,  2207,  2011,  2175, 28483,
         16179,  1010,  2021,  2002,  4900,  2025,  2000,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]']
[Init] best rec loss: 0.9636691212654114 for ['[CLS] actually joseph sofia sas colt late sketch sensefixed skate shaved clerical period huis powers news [SEP]']
[Init] best rec loss: 0.9165536165237427 for ['[CLS]chio falls guild ginger turkey ad n fusion strugglelor fitch parker bruised curran head happened land [SEP]']
[Init] best rec loss: 0.9029581546783447 for ['[CLS] stefan go animation hp chronichinrong automation varies min rare on matter work l fundedoke [SEP]']
[Init] best rec loss: 0.9002368450164795 for ['[CLS] club en safety puts notablehu acacia contacts domestic watched lit strategystered antioch recognition alphabet halt [SEP]']
[Init] best rec loss: 0.8995805978775024 for ['[CLS] syndicatedalia cassie debate meant copyka ave mirandail inside apart name heaven merlin gas state [SEP]']
[Init] best rec loss: 0.892250657081604 for ['[CLS]tance pray away tropicaluation alternate blues contrary franciscan party ship flipped core larson christ search dispute [SEP]']
[Init] best rec loss: 0.8873689770698547 for ['[CLS] remember ari swear honneur private pm die don body of whose left letter cap father thus tim [SEP]']
[Init] best rec loss: 0.8834232091903687 for ['[CLS] run quality class sentinel hale infringement say peace never fighting minister which suffrage turtle president appreciationolved [SEP]']
[Init] best perm rec loss: 0.8830916881561279 for ['[CLS] fighting say president classolved suffrage peace quality sentinel hale minister appreciation which never turtle infringement run [SEP]']
[Init] best perm rec loss: 0.8820346593856812 for ['[CLS] say run fighting infringement suffrageolved class sentinel appreciation quality peace hale which turtle never minister president [SEP]']
[Init] best perm rec loss: 0.8812940716743469 for ['[CLS] class quality appreciation say turtle which fighting suffrage hale run infringement never sentinel ministerolved president peace [SEP]']
[Init] best perm rec loss: 0.8810776472091675 for ['[CLS] appreciation turtle class peaceolved quality suffrage fighting say president hale minister infringement never run sentinel which [SEP]']
[Init] best perm rec loss: 0.8807430267333984 for ['[CLS] infringement class appreciation turtle say never fighting hale peace president minister suffrage run which sentinel qualityolved [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.776 (perp=11.491, rec=0.311, cos=0.167), tot_loss_proj:4.138 [t=0.22s]
prediction: ['[CLS] information information, mamachev. went not belin kgb emotion lab associatedin feature stamps [SEP]']
[ 100/2000] tot_loss=2.507 (perp=10.633, rec=0.216, cos=0.164), tot_loss_proj:3.956 [t=0.22s]
prediction: ['[CLS] this information, [chev. would notrbachevchev hawke choosing leaving would information information [SEP]']
[ 150/2000] tot_loss=2.304 (perp=9.741, rec=0.186, cos=0.169), tot_loss_proj:3.798 [t=0.23s]
prediction: ['[CLS] this information, [chev. could notrbachevchev would chose not would released information [SEP]']
[ 200/2000] tot_loss=2.771 (perp=11.607, rec=0.279, cos=0.171), tot_loss_proj:4.137 [t=0.23s]
prediction: ['[CLS] this information reverend ]chev be could notrbachev stayed % gladly withdrew originally released information [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.506 (perp=10.454, rec=0.251, cos=0.164), tot_loss_proj:3.898 [t=0.23s]
prediction: ['[CLS] this information, ]uouslychev went haverba " released - gladly subsequently probably released information [SEP]']
[ 300/2000] tot_loss=2.460 (perp=10.422, rec=0.208, cos=0.168), tot_loss_proj:3.946 [t=0.23s]
prediction: ['[CLS] this information, ] butchev could haverba " told metro gladly immediately possibly released information [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.466 (perp=10.566, rec=0.191, cos=0.161), tot_loss_proj:3.922 [t=0.23s]
prediction: ['[CLS] this information, ] [CLS]chev chose have gladly ". skrba unable could released released [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.226 (perp=9.248, rec=0.205, cos=0.171), tot_loss_proj:3.685 [t=0.23s]
prediction: ['[CLS] this information. ] but went have but ". -rbachev chose could released released [SEP]']
[ 450/2000] tot_loss=2.160 (perp=9.029, rec=0.180, cos=0.174), tot_loss_proj:3.651 [t=0.23s]
prediction: ['[CLS] this information. ] but went have but "..rbachev chose could released released [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.094 (perp=8.794, rec=0.165, cos=0.170), tot_loss_proj:3.610 [t=0.23s]
prediction: ['[CLS] this information. ] indeed chose to but have..rbachev chose could released released [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.959 (perp=8.106, rec=0.168, cos=0.170), tot_loss_proj:3.477 [t=0.23s]
prediction: ['[CLS] this information. ] indeed chose to but released..rbachev chose could have released [SEP]']
[ 600/2000] tot_loss=1.978 (perp=8.234, rec=0.158, cos=0.174), tot_loss_proj:3.495 [t=0.23s]
prediction: ['[CLS] this information. ] indeed chose to but released..rbachev chose could not released [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.893 (perp=7.835, rec=0.153, cos=0.173), tot_loss_proj:3.438 [t=0.23s]
prediction: ['[CLS] this information. ] indeed chose to. released. butrbachev chose could not released [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.895 (perp=7.867, rec=0.150, cos=0.172), tot_loss_proj:3.455 [t=0.23s]
prediction: ['[CLS] this information. ] besides chose to.. released butrbachev chose could not released [SEP]']
[ 750/2000] tot_loss=1.912 (perp=7.950, rec=0.150, cos=0.172), tot_loss_proj:3.469 [t=0.22s]
prediction: ['[CLS] this information. ) besides chose to.. released butrbachev chose could not released [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.903 (perp=7.950, rec=0.142, cos=0.171), tot_loss_proj:3.473 [t=0.23s]
prediction: ['[CLS] this information. ) besides chose to.. released butrbachev chose could not released [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.902 (perp=7.950, rec=0.143, cos=0.169), tot_loss_proj:3.474 [t=0.23s]
prediction: ['[CLS] this information. ) besides chose to.. released butrbachev chose could not released [SEP]']
[ 900/2000] tot_loss=1.908 (perp=7.950, rec=0.145, cos=0.173), tot_loss_proj:3.468 [t=0.23s]
prediction: ['[CLS] this information. ) besides chose to.. released butrbachev chose could not released [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.913 (perp=7.967, rec=0.147, cos=0.173), tot_loss_proj:3.470 [t=0.23s]
prediction: ['[CLS] this information. ) besides chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1000/2000] tot_loss=1.937 (perp=8.096, rec=0.146, cos=0.173), tot_loss_proj:3.503 [t=0.23s]
prediction: ['[CLS] this information. )just chose to released.. butrbachev chose could not released [SEP]']
[1050/2000] tot_loss=1.840 (perp=7.621, rec=0.143, cos=0.173), tot_loss_proj:3.408 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1100/2000] tot_loss=1.843 (perp=7.621, rec=0.145, cos=0.174), tot_loss_proj:3.411 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1150/2000] tot_loss=1.841 (perp=7.621, rec=0.144, cos=0.173), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
[1200/2000] tot_loss=1.846 (perp=7.621, rec=0.149, cos=0.173), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1250/2000] tot_loss=1.836 (perp=7.621, rec=0.138, cos=0.173), tot_loss_proj:3.414 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1300/2000] tot_loss=1.844 (perp=7.621, rec=0.146, cos=0.173), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
[1350/2000] tot_loss=1.835 (perp=7.621, rec=0.138, cos=0.173), tot_loss_proj:3.409 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1400/2000] tot_loss=1.841 (perp=7.621, rec=0.142, cos=0.174), tot_loss_proj:3.409 [t=0.22s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1450/2000] tot_loss=1.839 (perp=7.621, rec=0.142, cos=0.173), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
[1500/2000] tot_loss=1.840 (perp=7.621, rec=0.142, cos=0.173), tot_loss_proj:3.411 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1550/2000] tot_loss=1.832 (perp=7.621, rec=0.134, cos=0.173), tot_loss_proj:3.406 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1600/2000] tot_loss=1.830 (perp=7.621, rec=0.132, cos=0.173), tot_loss_proj:3.408 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
[1650/2000] tot_loss=1.831 (perp=7.621, rec=0.134, cos=0.173), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1700/2000] tot_loss=1.834 (perp=7.621, rec=0.137, cos=0.173), tot_loss_proj:3.408 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1750/2000] tot_loss=1.834 (perp=7.621, rec=0.137, cos=0.173), tot_loss_proj:3.406 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
[1800/2000] tot_loss=1.832 (perp=7.621, rec=0.135, cos=0.172), tot_loss_proj:3.408 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1850/2000] tot_loss=1.834 (perp=7.621, rec=0.137, cos=0.173), tot_loss_proj:3.408 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[1900/2000] tot_loss=1.828 (perp=7.621, rec=0.131, cos=0.173), tot_loss_proj:3.407 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
[1950/2000] tot_loss=1.828 (perp=7.621, rec=0.131, cos=0.173), tot_loss_proj:3.411 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Attempt swap
[2000/2000] tot_loss=1.831 (perp=7.621, rec=0.133, cos=0.173), tot_loss_proj:3.409 [t=0.23s]
prediction: ['[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]
========================
predicted: 
========================
[CLS] this information. )aghan chose to released.. butrbachev chose could not released [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.286 | p: 69.231 | r: 60.000
rouge2     | fm: 15.385 | p: 16.667 | r: 14.286
rougeL     | fm: 50.000 | p: 53.846 | r: 46.667
rougeLsum  | fm: 50.000 | p: 53.846 | r: 46.667
r1fm+r2fm = 79.670

[Aggregate metrics]:
rouge1     | fm: 87.021 | p: 86.678 | r: 87.523
rouge2     | fm: 50.090 | p: 49.796 | r: 50.453
rougeL     | fm: 76.305 | p: 76.077 | r: 76.724
rougeLsum  | fm: 76.361 | p: 76.107 | r: 76.711
r1fm+r2fm = 137.111

input #36 time: 0:08:58 | total time: 5:36:23


Running input #37 of 100.
reference: 
========================
Kevin ate spaghetti with a spoon and Geordie did so too.
========================
average of cosine similarity 0.92405819611019
highest_index [0]
highest [0.92405819611019]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  4901,  8823, 26666,  2007,  1037, 15642,  1998, 20248, 17080,
          2063,  2106,  2061,  2205,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]']
[Init] best rec loss: 0.9143698811531067 for ['[CLS] grace extent first over maritime walked aria intake axis catcher dickinson twice tires serve [SEP]']
[Init] best rec loss: 0.9102030992507935 for ['[CLS] diseasears collaborated melanie central lens alternate rocco skate referred twist uk bothfs [SEP]']
[Init] best rec loss: 0.8921774625778198 for ['[CLS] masonic environmentaloo included forming app electro arrives indiahmicourt in cliff tail [SEP]']
[Init] best rec loss: 0.8833897113800049 for ['[CLS] zach glance matter read bro [MASK] nintendo tape same 2017 magnetic springfield be wrist [SEP]']
[Init] best rec loss: 0.8410468101501465 for ['[CLS] lot sufiic juniorbolicfirmed and askedmel kazanbo content film changed [SEP]']
[Init] best rec loss: 0.8367152810096741 for ['[CLS] keepshum featured jai tastebodyinsnne ban middle broke edwards neededjure [SEP]']
[Init] best rec loss: 0.8230253458023071 for ['[CLS] clawtekdity auto bad which levels healingrum billyotto france persian professional [SEP]']
[Init] best perm rec loss: 0.8216140270233154 for ['[CLS] clawrum billydity france bad auto which persianotto professional levels healingtek [SEP]']
[Init] best perm rec loss: 0.816853940486908 for ['[CLS] levels auto whichdity bad healingrum persianotto france billytek professional claw [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.196 (perp=13.137, rec=0.422, cos=0.147), tot_loss_proj:4.475 [t=0.22s]
prediction: ['[CLS] cheapmen vote tony seaman ; elle duncan joey harbourred georgia gabled comic [SEP]']
[ 100/2000] tot_loss=2.947 (perp=12.321, rec=0.362, cos=0.121), tot_loss_proj:4.248 [t=0.22s]
prediction: ['[CLS]rdios vote antonio allegro ; geo molly clintlkered ( geordi [SEP]']
[ 150/2000] tot_loss=2.632 (perp=11.137, rec=0.275, cos=0.130), tot_loss_proj:4.070 [t=0.22s]
prediction: ['[CLS]rdios react geo spaghetti and geo did kevinrdired ( geordi [SEP]']
[ 200/2000] tot_loss=2.505 (perp=10.591, rec=0.235, cos=0.152), tot_loss_proj:3.955 [t=0.22s]
prediction: ['[CLS]rdio acted kevin spaghetti did and did kevin geoended so geordi [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.383 (perp=10.302, rec=0.189, cos=0.133), tot_loss_proj:3.864 [t=0.22s]
prediction: ['[CLS]rdiee ate kevin spaghetti did and did kevin geo performed too geordi [SEP]']
[ 300/2000] tot_loss=2.392 (perp=10.450, rec=0.167, cos=0.135), tot_loss_proj:3.927 [t=0.22s]
prediction: ['[CLS]rdie ate kevin spaghetti did and thereof kevin geo did too geordi [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.188 (perp=9.483, rec=0.156, cos=0.135), tot_loss_proj:3.744 [t=0.22s]
prediction: ['[CLS]rdie kevin ate kevin spaghetti ate and thereofe did too geordi [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.093 (perp=9.130, rec=0.136, cos=0.131), tot_loss_proj:3.677 [t=0.22s]
prediction: ['[CLS]rdie kevin ate kevin spaghetti and ate thereofe did too geordi [SEP]']
[ 450/2000] tot_loss=2.107 (perp=9.130, rec=0.130, cos=0.151), tot_loss_proj:3.679 [t=0.22s]
prediction: ['[CLS]rdie kevin ate kevin spaghetti and ate thereofe did too geordi [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.090 (perp=9.130, rec=0.126, cos=0.139), tot_loss_proj:3.678 [t=0.22s]
prediction: ['[CLS]rdie kevin ate kevin spaghetti and ate thereofe did too geordi [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.080 (perp=9.130, rec=0.116, cos=0.139), tot_loss_proj:3.680 [t=0.22s]
prediction: ['[CLS]rdie kevin ate kevin spaghetti and ate thereofe did too geordi [SEP]']
[ 600/2000] tot_loss=2.155 (perp=9.474, rec=0.117, cos=0.144), tot_loss_proj:3.727 [t=0.22s]
prediction: ['[CLS]rdie kevin ate kevin spaghetti and ate spoone did too geordi [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.137 (perp=9.474, rec=0.108, cos=0.135), tot_loss_proj:3.727 [t=0.22s]
prediction: ['[CLS]rdie kevin ate kevin spaghetti and ate spoone did too geordi [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.164 (perp=9.474, rec=0.120, cos=0.149), tot_loss_proj:3.726 [t=0.22s]
prediction: ['[CLS]rdie kevin ate kevin spaghetti and ate spoone did too geordi [SEP]']
[ 750/2000] tot_loss=2.146 (perp=9.474, rec=0.113, cos=0.138), tot_loss_proj:3.725 [t=0.22s]
prediction: ['[CLS]rdie kevin ate kevin spaghetti and ate spoone did too geordi [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.725 (perp=12.037, rec=0.169, cos=0.148), tot_loss_proj:4.205 [t=0.22s]
prediction: ['[CLS]rdie kevinzo julian spaghetti and ate spoon did so geordi geo [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.467 (perp=10.592, rec=0.194, cos=0.155), tot_loss_proj:3.929 [t=0.22s]
prediction: ['[CLS]rdie geo kevinzo kevin spaghetti and ate spoon did so geordi [SEP]']
[ 900/2000] tot_loss=2.442 (perp=10.703, rec=0.159, cos=0.142), tot_loss_proj:3.954 [t=0.22s]
prediction: ['[CLS]rdie spoon kevinzo kevin spaghetti and ate spoon did so geordi [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.211 (perp=9.606, rec=0.144, cos=0.146), tot_loss_proj:3.739 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin atezo kevin spaghetti and spoon did so geordi [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.213 (perp=9.606, rec=0.144, cos=0.148), tot_loss_proj:3.739 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin atezo kevin spaghetti and spoon did so geordi [SEP]']
[1050/2000] tot_loss=2.200 (perp=9.606, rec=0.137, cos=0.142), tot_loss_proj:3.736 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin atezo kevin spaghetti and spoon did so geordi [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.171 (perp=9.466, rec=0.132, cos=0.145), tot_loss_proj:3.697 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spaghetti occurs and spoon did so geordi [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.077 (perp=8.991, rec=0.134, cos=0.145), tot_loss_proj:3.610 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spaghetti spoon occurs and did so geordi [SEP]']
[1200/2000] tot_loss=2.078 (perp=8.991, rec=0.134, cos=0.146), tot_loss_proj:3.610 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spaghetti spoon occurs and did so geordi [SEP]']
Attempt swap
[1250/2000] tot_loss=2.077 (perp=8.991, rec=0.133, cos=0.146), tot_loss_proj:3.613 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spaghetti spoon occurs and did so geordi [SEP]']
Attempt swap
[1300/2000] tot_loss=2.066 (perp=8.991, rec=0.122, cos=0.145), tot_loss_proj:3.610 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spaghetti spoon occurs and did so geordi [SEP]']
[1350/2000] tot_loss=2.076 (perp=8.991, rec=0.132, cos=0.145), tot_loss_proj:3.611 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spaghetti spoon occurs and did so geordi [SEP]']
Attempt swap
[1400/2000] tot_loss=2.066 (perp=8.991, rec=0.122, cos=0.146), tot_loss_proj:3.612 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spaghetti spoon occurs and did so geordi [SEP]']
Attempt swap
[1450/2000] tot_loss=2.067 (perp=8.991, rec=0.125, cos=0.144), tot_loss_proj:3.612 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spaghetti spoon occurs and did so geordi [SEP]']
[1500/2000] tot_loss=2.019 (perp=8.757, rec=0.124, cos=0.144), tot_loss_proj:3.538 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spaghetti spoon dinner and did so geordi [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.198 (perp=9.654, rec=0.122, cos=0.145), tot_loss_proj:3.755 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spoon spaghetti occurs and did so geordi [SEP]']
Attempt swap
[1600/2000] tot_loss=1.971 (perp=8.479, rec=0.129, cos=0.146), tot_loss_proj:3.495 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spoon spaghetti dinner and did so geordi [SEP]']
[1650/2000] tot_loss=1.964 (perp=8.479, rec=0.122, cos=0.146), tot_loss_proj:3.486 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate kevin spoon spaghetti dinner and did so geordi [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.903 (perp=8.157, rec=0.125, cos=0.147), tot_loss_proj:3.416 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate spoon kevin spaghetti dinner and did so geordi [SEP]']
Attempt swap
[1750/2000] tot_loss=1.902 (perp=8.157, rec=0.126, cos=0.145), tot_loss_proj:3.418 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate spoon kevin spaghetti dinner and did so geordi [SEP]']
[1800/2000] tot_loss=1.904 (perp=8.157, rec=0.128, cos=0.145), tot_loss_proj:3.419 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate spoon kevin spaghetti dinner and did so geordi [SEP]']
Attempt swap
[1850/2000] tot_loss=1.905 (perp=8.157, rec=0.127, cos=0.146), tot_loss_proj:3.413 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate spoon kevin spaghetti dinner and did so geordi [SEP]']
Attempt swap
[1900/2000] tot_loss=1.898 (perp=8.157, rec=0.121, cos=0.146), tot_loss_proj:3.419 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate spoon kevin spaghetti dinner and did so geordi [SEP]']
[1950/2000] tot_loss=1.903 (perp=8.157, rec=0.126, cos=0.146), tot_loss_proj:3.413 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate spoon kevin spaghetti dinner and did so geordi [SEP]']
Attempt swap
[2000/2000] tot_loss=1.897 (perp=8.157, rec=0.120, cos=0.146), tot_loss_proj:3.419 [t=0.22s]
prediction: ['[CLS]rdie spoon kevin ate spoon kevin spaghetti dinner and did so geordi [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]
========================
predicted: 
========================
[CLS]rdie kevin ate kevin spaghetti and ate spoone did too geordi [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.538 | p: 61.538 | r: 61.538
rouge2     | fm: 8.333 | p: 8.333 | r: 8.333
rougeL     | fm: 61.538 | p: 61.538 | r: 61.538
rougeLsum  | fm: 61.538 | p: 61.538 | r: 61.538
r1fm+r2fm = 69.872

[Aggregate metrics]:
rouge1     | fm: 86.295 | p: 85.916 | r: 86.701
rouge2     | fm: 49.064 | p: 48.793 | r: 49.379
rougeL     | fm: 75.851 | p: 75.611 | r: 76.264
rougeLsum  | fm: 75.923 | p: 75.705 | r: 76.288
r1fm+r2fm = 135.359

input #37 time: 0:08:51 | total time: 5:45:15


Running input #38 of 100.
reference: 
========================
John is the kind of fool that I told you about.
========================
average of cosine similarity 0.8887014471681133
highest_index [0]
highest [0.8887014471681133]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2198, 2003, 1996, 2785, 1997, 7966, 2008, 1045, 2409, 2017, 2055,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is the kind of fool that i told you about. [SEP]']
[Init] best rec loss: 1.0141303539276123 for ['[CLS] medicine horns clear john splash treaties samson com credited birthplace ago managing [SEP]']
[Init] best rec loss: 1.0045247077941895 for ['[CLS] necessary did conference short horsesm establishment pulse spat so junelates [SEP]']
[Init] best rec loss: 0.984758734703064 for ['[CLS]vance jace texas silk mid will ongative to important sweat prize [SEP]']
[Init] best rec loss: 0.9739983081817627 for ['[CLS] smoke lords per honestly between fucking thayer however alexya hayes we [SEP]']
[Init] best rec loss: 0.9551267027854919 for ['[CLS] trees drake peoples base fen denoted field flare quite throat section judiciary [SEP]']
[Init] best rec loss: 0.9549275040626526 for ['[CLS] formal anymore fair more directlycz subgroup stalls up creekphobic planet [SEP]']
[Init] best rec loss: 0.9495163559913635 for ['[CLS] rose stagecoach according division unaffected reminded subsistence rubber injured tran avoiding honour [SEP]']
[Init] best rec loss: 0.9459206461906433 for ['[CLS] see heaven fillinge odd altar according sync idol olivia chancel hindu [SEP]']
[Init] best rec loss: 0.9439687132835388 for ['[CLS]ice wingspan until mounted selection data mortal established at lesson gi format [SEP]']
[Init] best rec loss: 0.9369423985481262 for ['[CLS]grapheryama sport spatorm arm corbin asian 1st process finger blocks [SEP]']
[Init] best rec loss: 0.9247366189956665 for ['[CLS] rubber list brandt building telescope award poor free parameters rose less love [SEP]']
[Init] best perm rec loss: 0.923689067363739 for ['[CLS] free rose rubber telescope building love less award parameters poor list brandt [SEP]']
[Init] best perm rec loss: 0.9235256910324097 for ['[CLS] rubber telescope award building brandt rose less free poor love list parameters [SEP]']
[Init] best perm rec loss: 0.9233099222183228 for ['[CLS] poor parameters list brandt rose rubber love award building free less telescope [SEP]']
[Init] best perm rec loss: 0.9212856888771057 for ['[CLS] list brandt parameters free building award rubber less rose poor love telescope [SEP]']
[Init] best perm rec loss: 0.9207481145858765 for ['[CLS] award list parameters telescope love rose less building poor rubber free brandt [SEP]']
[Init] best perm rec loss: 0.9204071760177612 for ['[CLS] parameters award poor telescope building less rubber love brandt free rose list [SEP]']
[Init] best perm rec loss: 0.9201867580413818 for ['[CLS] list award telescope poor less rose love parameters rubber brandt building free [SEP]']
[Init] best perm rec loss: 0.9200241565704346 for ['[CLS] less parameters rubber poor list telescope love award free rose brandt building [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.725 (perp=10.810, rec=0.351, cos=0.212), tot_loss_proj:4.050 [t=0.22s]
prediction: ['[CLS] eric james punk.ha that " aheadcker new, which [SEP]']
[ 100/2000] tot_loss=2.267 (perp=8.924, rec=0.280, cos=0.202), tot_loss_proj:3.717 [t=0.22s]
prediction: ['[CLS] john john rock. was told you signs sell the. offer [SEP]']
[ 150/2000] tot_loss=2.316 (perp=9.380, rec=0.239, cos=0.201), tot_loss_proj:3.760 [t=0.22s]
prediction: ['[CLS] john john fool. looks told you fool sell the. offer [SEP]']
[ 200/2000] tot_loss=2.078 (perp=8.332, rec=0.206, cos=0.206), tot_loss_proj:3.571 [t=0.22s]
prediction: ['[CLS] john you fool. is told you fool tell the. offer [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.105 (perp=8.320, rec=0.232, cos=0.209), tot_loss_proj:3.523 [t=0.22s]
prediction: ['[CLS] john you fool. is that you about tell kind fool. [SEP]']
[ 300/2000] tot_loss=2.143 (perp=8.831, rec=0.168, cos=0.208), tot_loss_proj:3.626 [t=0.22s]
prediction: ['[CLS] john you fool fool is that you about club kind fool. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.976 (perp=8.123, rec=0.146, cos=0.206), tot_loss_proj:3.483 [t=0.22s]
prediction: ['[CLS] john you fool fool is about you that tell kind fool. [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.090 (perp=8.806, rec=0.122, cos=0.206), tot_loss_proj:3.631 [t=0.22s]
prediction: ['[CLS] john you fool fool is about tells that tell kind fool. [SEP]']
[ 450/2000] tot_loss=1.931 (perp=8.114, rec=0.103, cos=0.204), tot_loss_proj:3.490 [t=0.22s]
prediction: ['[CLS] john you the fool is about told that tell kind fool. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.787 (perp=7.444, rec=0.091, cos=0.207), tot_loss_proj:3.378 [t=0.22s]
prediction: ['[CLS] you john the fool is about told that tell kind fool. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.664 (perp=6.855, rec=0.087, cos=0.206), tot_loss_proj:3.226 [t=0.22s]
prediction: ['[CLS] you john the fool is told about that tell kind fool. [SEP]']
[ 600/2000] tot_loss=1.660 (perp=6.855, rec=0.082, cos=0.207), tot_loss_proj:3.225 [t=0.22s]
prediction: ['[CLS] you john the fool is told about that tell kind fool. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.654 (perp=6.855, rec=0.075, cos=0.207), tot_loss_proj:3.227 [t=0.22s]
prediction: ['[CLS] you john the fool is told about that tell kind fool. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.691 (perp=6.984, rec=0.088, cos=0.206), tot_loss_proj:3.289 [t=0.22s]
prediction: ['[CLS] you john the fool is told that tell about kind i. [SEP]']
[ 750/2000] tot_loss=1.685 (perp=6.984, rec=0.081, cos=0.207), tot_loss_proj:3.292 [t=0.22s]
prediction: ['[CLS] you john the fool is told that tell about kind i. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.678 (perp=6.984, rec=0.074, cos=0.207), tot_loss_proj:3.289 [t=0.22s]
prediction: ['[CLS] you john the fool is told that tell about kind i. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.554 (perp=6.321, rec=0.084, cos=0.206), tot_loss_proj:3.122 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
[ 900/2000] tot_loss=1.544 (perp=6.321, rec=0.073, cos=0.207), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.541 (perp=6.321, rec=0.071, cos=0.207), tot_loss_proj:3.109 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.538 (perp=6.321, rec=0.067, cos=0.207), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
[1050/2000] tot_loss=1.557 (perp=6.321, rec=0.086, cos=0.207), tot_loss_proj:3.111 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.541 (perp=6.321, rec=0.070, cos=0.207), tot_loss_proj:3.114 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.538 (perp=6.321, rec=0.067, cos=0.207), tot_loss_proj:3.111 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
[1200/2000] tot_loss=1.545 (perp=6.321, rec=0.074, cos=0.207), tot_loss_proj:3.108 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.544 (perp=6.321, rec=0.072, cos=0.207), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.545 (perp=6.321, rec=0.074, cos=0.207), tot_loss_proj:3.108 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
[1350/2000] tot_loss=1.539 (perp=6.321, rec=0.067, cos=0.207), tot_loss_proj:3.107 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.551 (perp=6.321, rec=0.079, cos=0.207), tot_loss_proj:3.108 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.532 (perp=6.321, rec=0.060, cos=0.207), tot_loss_proj:3.107 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
[1500/2000] tot_loss=1.546 (perp=6.321, rec=0.074, cos=0.207), tot_loss_proj:3.105 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.543 (perp=6.321, rec=0.072, cos=0.207), tot_loss_proj:3.111 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.542 (perp=6.321, rec=0.071, cos=0.207), tot_loss_proj:3.107 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
[1650/2000] tot_loss=1.541 (perp=6.321, rec=0.069, cos=0.207), tot_loss_proj:3.105 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.542 (perp=6.321, rec=0.070, cos=0.207), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.546 (perp=6.321, rec=0.075, cos=0.207), tot_loss_proj:3.106 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
[1800/2000] tot_loss=1.542 (perp=6.321, rec=0.070, cos=0.207), tot_loss_proj:3.108 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.547 (perp=6.321, rec=0.076, cos=0.207), tot_loss_proj:3.113 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.540 (perp=6.321, rec=0.068, cos=0.207), tot_loss_proj:3.106 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
[1950/2000] tot_loss=1.541 (perp=6.321, rec=0.069, cos=0.207), tot_loss_proj:3.105 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.551 (perp=6.321, rec=0.080, cos=0.207), tot_loss_proj:3.107 [t=0.22s]
prediction: ['[CLS] you john the fool is told that i tell about kind. [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] john is the kind of fool that i told you about. [SEP]
========================
predicted: 
========================
[CLS] you john the fool is told that i tell about kind. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 8.333 | p: 8.333 | r: 8.333
rougeL     | fm: 61.538 | p: 61.538 | r: 61.538
rougeLsum  | fm: 61.538 | p: 61.538 | r: 61.538
r1fm+r2fm = 100.641

[Aggregate metrics]:
rouge1     | fm: 86.424 | p: 86.172 | r: 86.898
rouge2     | fm: 47.941 | p: 47.699 | r: 48.248
rougeL     | fm: 75.452 | p: 75.338 | r: 75.819
rougeLsum  | fm: 75.540 | p: 75.321 | r: 75.951
r1fm+r2fm = 134.365

input #38 time: 0:08:51 | total time: 5:54:06


Running input #39 of 100.
reference: 
========================
I doubt if you can help me in understanding this.
========================
average of cosine similarity 0.8596685685248229
highest_index [0]
highest [0.8596685685248229]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 1045, 4797, 2065, 2017, 2064, 2393, 2033, 1999, 4824, 2023, 1012,
          102]], device='cuda:0')
Debug: ref = ['[CLS] i doubt if you can help me in understanding this. [SEP]']
[Init] best rec loss: 0.9374788999557495 for ['[CLS] probably issue jade aren circumstances day old mayohum asian belonging [SEP]']
[Init] best rec loss: 0.9121645092964172 for ['[CLS] curran boiler late claims chung top priest america instead european barrel [SEP]']
[Init] best rec loss: 0.9120031595230103 for ['[CLS] express aid sandralike beds crambidae drake rest agedbil studio [SEP]']
[Init] best rec loss: 0.8986760377883911 for ['[CLS] ec situation run nicknamep member heir law launched croatian landing [SEP]']
[Init] best rec loss: 0.8970209956169128 for ['[CLS] teddytr burst counted multiple bastard axe trade nervous sera folk [SEP]']
[Init] best rec loss: 0.8918581008911133 for ['[CLS] profit safety generation gerald reference caesar buszen *nan islanders [SEP]']
[Init] best rec loss: 0.8766545057296753 for ['[CLS] checkbbaeering allergic purposes prison at disadvantage bitch anderson under [SEP]']
[Init] best perm rec loss: 0.874903678894043 for ['[CLS] prison bitch purposeseeringbba allergic disadvantage check at under anderson [SEP]']
[Init] best perm rec loss: 0.8722505569458008 for ['[CLS] disadvantage under allergic at anderson purposesbba prisoneering check bitch [SEP]']
[Init] best perm rec loss: 0.87148118019104 for ['[CLS] prison disadvantage at anderson undereering allergicbba purposes check bitch [SEP]']
[Init] best perm rec loss: 0.8711813688278198 for ['[CLS] allergic under at purposes disadvantageeering prison check bitch andersonbba [SEP]']
[Init] best perm rec loss: 0.86644047498703 for ['[CLS] purposes under allergiceeringbba disadvantage check prison at anderson bitch [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.990 (perp=11.972, rec=0.350, cos=0.246), tot_loss_proj:4.189 [t=0.22s]
prediction: ['[CLS]. skillsurance relay counseling women babies ideas it of mater [SEP]']
[ 100/2000] tot_loss=2.503 (perp=10.015, rec=0.244, cos=0.256), tot_loss_proj:3.863 [t=0.22s]
prediction: ['[CLS]. you understand cannot understanding understanding helps results if ofice [SEP]']
[ 150/2000] tot_loss=2.118 (perp=8.321, rec=0.198, cos=0.255), tot_loss_proj:3.530 [t=0.22s]
prediction: ['[CLS]. you understanding cannot understanding understanding you this if in. [SEP]']
[ 200/2000] tot_loss=1.830 (perp=7.081, rec=0.161, cos=0.253), tot_loss_proj:3.292 [t=0.22s]
prediction: ['[CLS]. you understanding cannot help me you this if in. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.950 (perp=7.371, rec=0.219, cos=0.257), tot_loss_proj:3.328 [t=0.22s]
prediction: ['[CLS]. you understanding if help me in this a yourtility [SEP]']
[ 300/2000] tot_loss=1.885 (perp=7.476, rec=0.137, cos=0.253), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS]. you understanding if help me in this i mytility [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.072 (perp=8.392, rec=0.136, cos=0.258), tot_loss_proj:3.547 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this i honour card [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.969 (perp=7.953, rec=0.124, cos=0.254), tot_loss_proj:3.483 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this honour i card [SEP]']
[ 450/2000] tot_loss=2.090 (perp=8.594, rec=0.113, cos=0.258), tot_loss_proj:3.589 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this importance i card [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.008 (perp=8.207, rec=0.108, cos=0.259), tot_loss_proj:3.515 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this i importance card [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.940 (perp=7.805, rec=0.120, cos=0.259), tot_loss_proj:3.463 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this i importance element [SEP]']
[ 600/2000] tot_loss=1.968 (perp=7.975, rec=0.114, cos=0.259), tot_loss_proj:3.460 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this i importance your [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.907 (perp=7.637, rec=0.120, cos=0.260), tot_loss_proj:3.392 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this i your importance [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.903 (perp=7.637, rec=0.115, cos=0.260), tot_loss_proj:3.396 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this i your importance [SEP]']
[ 750/2000] tot_loss=1.900 (perp=7.637, rec=0.113, cos=0.260), tot_loss_proj:3.396 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this i your importance [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.905 (perp=7.637, rec=0.118, cos=0.260), tot_loss_proj:3.391 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this i your importance [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.896 (perp=7.657, rec=0.104, cos=0.260), tot_loss_proj:3.395 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this your i importance [SEP]']
[ 900/2000] tot_loss=1.903 (perp=7.657, rec=0.111, cos=0.260), tot_loss_proj:3.392 [t=0.22s]
prediction: ['[CLS]. you understanding doubt help me in this your i importance [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.885 (perp=7.448, rec=0.135, cos=0.260), tot_loss_proj:3.355 [t=0.23s]
prediction: ['[CLS] understanding you. doubt help me in this i i importance [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.854 (perp=7.343, rec=0.129, cos=0.256), tot_loss_proj:3.374 [t=0.22s]
prediction: ['[CLS] understanding you. doubt help me in this i importance i [SEP]']
[1050/2000] tot_loss=1.831 (perp=7.343, rec=0.103, cos=0.259), tot_loss_proj:3.365 [t=0.22s]
prediction: ['[CLS] understanding you. doubt help me in this i importance i [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.658 (perp=6.442, rec=0.114, cos=0.256), tot_loss_proj:3.143 [t=0.22s]
prediction: ['[CLS] understanding you i doubt help me in this i importance. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.580 (perp=5.975, rec=0.123, cos=0.262), tot_loss_proj:3.061 [t=0.22s]
prediction: ['[CLS] i understanding you i doubt help me in this importance. [SEP]']
[1200/2000] tot_loss=1.560 (perp=5.975, rec=0.108, cos=0.257), tot_loss_proj:3.057 [t=0.22s]
prediction: ['[CLS] i understanding you i doubt help me in this importance. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.545 (perp=5.879, rec=0.112, cos=0.257), tot_loss_proj:3.104 [t=0.22s]
prediction: ['[CLS] i understanding i doubt you help me in this importance. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.434 (perp=5.306, rec=0.116, cos=0.257), tot_loss_proj:2.968 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in this understanding. [SEP]']
[1350/2000] tot_loss=1.433 (perp=5.306, rec=0.115, cos=0.257), tot_loss_proj:2.967 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in this understanding. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.419 (perp=5.306, rec=0.101, cos=0.257), tot_loss_proj:2.969 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in this understanding. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.430 (perp=5.306, rec=0.110, cos=0.258), tot_loss_proj:2.968 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in this understanding. [SEP]']
[1500/2000] tot_loss=1.412 (perp=5.306, rec=0.092, cos=0.258), tot_loss_proj:2.966 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in this understanding. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.432 (perp=5.306, rec=0.112, cos=0.258), tot_loss_proj:2.972 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in this understanding. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.420 (perp=5.306, rec=0.101, cos=0.259), tot_loss_proj:2.970 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in this understanding. [SEP]']
[1650/2000] tot_loss=1.417 (perp=5.306, rec=0.097, cos=0.259), tot_loss_proj:2.967 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in this understanding. [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.412 (perp=5.286, rec=0.096, cos=0.258), tot_loss_proj:2.961 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in understanding this. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.413 (perp=5.286, rec=0.097, cos=0.258), tot_loss_proj:2.961 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in understanding this. [SEP]']
[1800/2000] tot_loss=1.415 (perp=5.286, rec=0.100, cos=0.259), tot_loss_proj:2.965 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in understanding this. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.418 (perp=5.286, rec=0.102, cos=0.259), tot_loss_proj:2.965 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in understanding this. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.432 (perp=5.286, rec=0.116, cos=0.259), tot_loss_proj:2.967 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in understanding this. [SEP]']
[1950/2000] tot_loss=1.421 (perp=5.286, rec=0.105, cos=0.259), tot_loss_proj:2.963 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in understanding this. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.418 (perp=5.286, rec=0.101, cos=0.259), tot_loss_proj:2.964 [t=0.22s]
prediction: ['[CLS] i importance i doubt you help me in understanding this. [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] i doubt if you can help me in understanding this. [SEP]
========================
predicted: 
========================
[CLS] i importance i doubt you help me in this understanding. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 119.697

[Aggregate metrics]:
rouge1     | fm: 86.317 | p: 86.084 | r: 86.749
rouge2     | fm: 47.848 | p: 47.605 | r: 48.217
rougeL     | fm: 75.511 | p: 75.237 | r: 75.893
rougeLsum  | fm: 75.634 | p: 75.450 | r: 75.989
r1fm+r2fm = 134.164

input #39 time: 0:08:51 | total time: 6:02:58


Running input #40 of 100.
reference: 
========================
Was the child running to the car?
========================
average of cosine similarity 0.8927056092838722
highest_index [0]
highest [0.8927056092838722]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2001, 1996, 2775, 2770, 2000, 1996, 2482, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] was the child running to the car? [SEP]']
[Init] best rec loss: 0.9778315424919128 for ['[CLS]chfield only loan mast lust nape " nearly [SEP]']
[Init] best rec loss: 0.9508454203605652 for ['[CLS] much guess already present frederic stop wrist philip [SEP]']
[Init] best rec loss: 0.9258273839950562 for ['[CLS] does cn coltsі comfortableffin sired land [SEP]']
[Init] best rec loss: 0.8970785140991211 for ['[CLS] what charity instrumental mixed news loyal names western [SEP]']
[Init] best rec loss: 0.8777838945388794 for ['[CLS] benton lightning certain portuguese depicting hairedchemistieving [SEP]']
[Init] best rec loss: 0.8761241436004639 for ['[CLS] territorial fluth tiled replay exactly charged concrete [SEP]']
[Init] best perm rec loss: 0.8736361265182495 for ['[CLS] replay tiled concrete flu chargedth exactly territorial [SEP]']
[Init] best perm rec loss: 0.8722617626190186 for ['[CLS]th concrete tiled exactly territorial charged replay flu [SEP]']
[Init] best perm rec loss: 0.8721668124198914 for ['[CLS]th replay tiled concrete territorial charged flu exactly [SEP]']
[Init] best perm rec loss: 0.8719567656517029 for ['[CLS] tiled exactlyth flu territorial replay charged concrete [SEP]']
[Init] best perm rec loss: 0.871516227722168 for ['[CLS]th territorial exactly replay tiled flu charged concrete [SEP]']
[Init] best perm rec loss: 0.8711988925933838 for ['[CLS] territorial tiled concreteth flu exactly replay charged [SEP]']
[Init] best perm rec loss: 0.8708744645118713 for ['[CLS] replay fluth tiled concrete exactly territorial charged [SEP]']
[Init] best perm rec loss: 0.8708714246749878 for ['[CLS] replay territorial exactlyth concrete charged flu tiled [SEP]']
[Init] best perm rec loss: 0.870643138885498 for ['[CLS] tiled replay fluth exactly concrete charged territorial [SEP]']
[Init] best perm rec loss: 0.8694179058074951 for ['[CLS] replay tiled exactly territorial fluth concrete charged [SEP]']
[Init] best perm rec loss: 0.8693369030952454 for ['[CLS] territorialth concrete exactly flu replay charged tiled [SEP]']
[Init] best perm rec loss: 0.8673830032348633 for ['[CLS]th tiled exactly concrete flu replay charged territorial [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.946 (perp=11.521, rec=0.450, cos=0.192), tot_loss_proj:4.153 [t=0.23s]
prediction: ['[CLS] named nordic marie driver contestant baby silent oh [SEP]']
[ 100/2000] tot_loss=2.865 (perp=11.248, rec=0.406, cos=0.210), tot_loss_proj:4.113 [t=0.23s]
prediction: ['[CLS]? brian marie child child - contained a [SEP]']
[ 150/2000] tot_loss=3.093 (perp=12.455, rec=0.383, cos=0.218), tot_loss_proj:4.325 [t=0.23s]
prediction: ['[CLS]? non marie child child with contained the [SEP]']
[ 200/2000] tot_loss=2.523 (perp=9.947, rec=0.319, cos=0.215), tot_loss_proj:3.841 [t=0.23s]
prediction: ['[CLS]? extra johnson child child with contained the [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.588 (perp=10.195, rec=0.341, cos=0.208), tot_loss_proj:3.887 [t=0.23s]
prediction: ['[CLS]? johnson when child child? momentary the [SEP]']
[ 300/2000] tot_loss=2.268 (perp=8.908, rec=0.287, cos=0.200), tot_loss_proj:3.673 [t=0.23s]
prediction: ['[CLS]? evans when child child? inside the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.464 (perp=9.805, rec=0.279, cos=0.224), tot_loss_proj:3.824 [t=0.23s]
prediction: ['[CLS]? lds morning child child? when running [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.528 (perp=10.385, rec=0.239, cos=0.212), tot_loss_proj:3.884 [t=0.23s]
prediction: ['[CLS] was lds morning child? child when running [SEP]']
[ 450/2000] tot_loss=2.496 (perp=10.385, rec=0.233, cos=0.187), tot_loss_proj:3.887 [t=0.23s]
prediction: ['[CLS] was lds morning child? child when running [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.096 (perp=8.429, rec=0.211, cos=0.198), tot_loss_proj:3.529 [t=0.23s]
prediction: ['[CLS] was the morning child? running child when [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.301 (perp=9.070, rec=0.262, cos=0.225), tot_loss_proj:3.761 [t=0.23s]
prediction: ['[CLS] was the morning child runningperation whether? [SEP]']
[ 600/2000] tot_loss=2.394 (perp=9.929, rec=0.202, cos=0.207), tot_loss_proj:3.942 [t=0.23s]
prediction: ['[CLS] was the inside child runningperation johnnie? [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.146 (perp=8.759, rec=0.189, cos=0.205), tot_loss_proj:3.668 [t=0.23s]
prediction: ['[CLS] was theperation child running inside toast? [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.176 (perp=8.908, rec=0.189, cos=0.205), tot_loss_proj:3.544 [t=0.23s]
prediction: ['[CLS] was theheard child running inside toast? [SEP]']
[ 750/2000] tot_loss=2.170 (perp=8.908, rec=0.179, cos=0.209), tot_loss_proj:3.543 [t=0.23s]
prediction: ['[CLS] was theheard child running inside toast? [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.177 (perp=9.004, rec=0.175, cos=0.201), tot_loss_proj:3.560 [t=0.23s]
prediction: ['[CLS] was theheard child running insideforth? [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.228 (perp=9.177, rec=0.190, cos=0.202), tot_loss_proj:3.806 [t=0.23s]
prediction: ['[CLS] was themit child running insideheard? [SEP]']
[ 900/2000] tot_loss=2.216 (perp=9.177, rec=0.180, cos=0.201), tot_loss_proj:3.808 [t=0.23s]
prediction: ['[CLS] was themit child running insideheard? [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.206 (perp=9.187, rec=0.168, cos=0.202), tot_loss_proj:3.768 [t=0.23s]
prediction: ['[CLS] was thedoor child car running damned? [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.077 (perp=8.547, rec=0.165, cos=0.203), tot_loss_proj:3.617 [t=0.23s]
prediction: ['[CLS] was thedoor child running store car? [SEP]']
[1050/2000] tot_loss=2.081 (perp=8.547, rec=0.168, cos=0.204), tot_loss_proj:3.616 [t=0.23s]
prediction: ['[CLS] was thedoor child running store car? [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.994 (perp=8.139, rec=0.164, cos=0.202), tot_loss_proj:3.441 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.998 (perp=8.139, rec=0.165, cos=0.204), tot_loss_proj:3.439 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
[1200/2000] tot_loss=2.001 (perp=8.139, rec=0.173, cos=0.200), tot_loss_proj:3.436 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.989 (perp=8.139, rec=0.160, cos=0.201), tot_loss_proj:3.435 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.998 (perp=8.139, rec=0.167, cos=0.203), tot_loss_proj:3.439 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
[1350/2000] tot_loss=1.992 (perp=8.139, rec=0.162, cos=0.203), tot_loss_proj:3.440 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.992 (perp=8.139, rec=0.162, cos=0.202), tot_loss_proj:3.434 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.993 (perp=8.139, rec=0.161, cos=0.203), tot_loss_proj:3.438 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
[1500/2000] tot_loss=1.992 (perp=8.139, rec=0.160, cos=0.204), tot_loss_proj:3.442 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.999 (perp=8.139, rec=0.167, cos=0.204), tot_loss_proj:3.437 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.988 (perp=8.139, rec=0.158, cos=0.202), tot_loss_proj:3.437 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
[1650/2000] tot_loss=1.996 (perp=8.139, rec=0.166, cos=0.201), tot_loss_proj:3.436 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.983 (perp=8.139, rec=0.152, cos=0.203), tot_loss_proj:3.437 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.985 (perp=8.139, rec=0.155, cos=0.203), tot_loss_proj:3.434 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
[1800/2000] tot_loss=1.991 (perp=8.139, rec=0.161, cos=0.203), tot_loss_proj:3.439 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.991 (perp=8.139, rec=0.160, cos=0.203), tot_loss_proj:3.439 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.981 (perp=8.139, rec=0.151, cos=0.202), tot_loss_proj:3.442 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
[1950/2000] tot_loss=1.994 (perp=8.139, rec=0.164, cos=0.203), tot_loss_proj:3.438 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.986 (perp=8.139, rec=0.155, cos=0.202), tot_loss_proj:3.439 [t=0.23s]
prediction: ['[CLS] was the storehand child running car? [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] was the child running to the car? [SEP]
========================
predicted: 
========================
[CLS] was the storehand child running car? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 87.500 | r: 77.778
rouge2     | fm: 53.333 | p: 57.143 | r: 50.000
rougeL     | fm: 82.353 | p: 87.500 | r: 77.778
rougeLsum  | fm: 82.353 | p: 87.500 | r: 77.778
r1fm+r2fm = 135.686

[Aggregate metrics]:
rouge1     | fm: 86.260 | p: 86.125 | r: 86.625
rouge2     | fm: 47.738 | p: 47.570 | r: 47.960
rougeL     | fm: 75.492 | p: 75.489 | r: 75.723
rougeLsum  | fm: 75.736 | p: 75.671 | r: 76.138
r1fm+r2fm = 133.997

input #40 time: 0:09:10 | total time: 6:12:08


Running input #41 of 100.
reference: 
========================
Mary is shorter than five feet.
========================
average of cosine similarity 0.906356546249514
highest_index [0]
highest [0.906356546249514]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2984, 2003, 7820, 2084, 2274, 2519, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] mary is shorter than five feet. [SEP]']
[Init] best rec loss: 0.9013609290122986 for ['[CLS] try formerly doneicz gmina away originals [SEP]']
[Init] best rec loss: 0.8862795233726501 for ['[CLS] visitingcote warningpit buy cutting imp [SEP]']
[Init] best rec loss: 0.8816942572593689 for ['[CLS] meta my librarian detectionled eu * [SEP]']
[Init] best rec loss: 0.8353474140167236 for ['[CLS] cases punch watson night cast professionalheart [SEP]']
[Init] best perm rec loss: 0.8350006937980652 for ['[CLS] night cases professionalheart watson punch cast [SEP]']
[Init] best perm rec loss: 0.8348422646522522 for ['[CLS] night cases watson punch cast professionalheart [SEP]']
[Init] best perm rec loss: 0.8335765600204468 for ['[CLS] night cases professional watson cast punchheart [SEP]']
[Init] best perm rec loss: 0.8326418995857239 for ['[CLS] cases night watson professional punch castheart [SEP]']
[Init] best perm rec loss: 0.8316619396209717 for ['[CLS] nightheart punch cast cases professional watson [SEP]']
[Init] best perm rec loss: 0.8312414884567261 for ['[CLS] cast nightheart watson cases professional punch [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.394 (perp=9.754, rec=0.266, cos=0.177), tot_loss_proj:3.790 [t=0.23s]
prediction: ['[CLS] less shorter. mary feet sergeant johnson [SEP]']
[ 100/2000] tot_loss=2.138 (perp=9.029, rec=0.161, cos=0.171), tot_loss_proj:3.670 [t=0.23s]
prediction: ['[CLS] five shorter. mary feet mary begins [SEP]']
[ 150/2000] tot_loss=1.827 (perp=7.671, rec=0.129, cos=0.164), tot_loss_proj:3.377 [t=0.23s]
prediction: ['[CLS] five shorter than mary feet. is [SEP]']
[ 200/2000] tot_loss=1.810 (perp=7.671, rec=0.106, cos=0.170), tot_loss_proj:3.381 [t=0.23s]
prediction: ['[CLS] five shorter than mary feet. is [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.566 (perp=6.457, rec=0.105, cos=0.170), tot_loss_proj:3.173 [t=0.23s]
prediction: ['[CLS] mary shorter than five feet is. [SEP]']
[ 300/2000] tot_loss=1.537 (perp=6.457, rec=0.068, cos=0.177), tot_loss_proj:3.180 [t=0.23s]
prediction: ['[CLS] mary shorter than five feet is. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.224 (perp=4.872, rec=0.074, cos=0.176), tot_loss_proj:1.296 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.220 (perp=4.872, rec=0.068, cos=0.178), tot_loss_proj:1.294 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
[ 450/2000] tot_loss=1.226 (perp=4.872, rec=0.073, cos=0.178), tot_loss_proj:1.293 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.219 (perp=4.872, rec=0.067, cos=0.178), tot_loss_proj:1.283 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.217 (perp=4.872, rec=0.065, cos=0.178), tot_loss_proj:1.275 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
[ 600/2000] tot_loss=1.219 (perp=4.872, rec=0.067, cos=0.177), tot_loss_proj:1.286 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.206 (perp=4.872, rec=0.054, cos=0.178), tot_loss_proj:1.282 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.222 (perp=4.872, rec=0.071, cos=0.177), tot_loss_proj:1.284 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
[ 750/2000] tot_loss=1.213 (perp=4.872, rec=0.062, cos=0.178), tot_loss_proj:1.273 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.207 (perp=4.872, rec=0.054, cos=0.178), tot_loss_proj:1.274 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.209 (perp=4.872, rec=0.056, cos=0.178), tot_loss_proj:1.281 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
[ 900/2000] tot_loss=1.226 (perp=4.872, rec=0.074, cos=0.178), tot_loss_proj:1.282 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.208 (perp=4.872, rec=0.056, cos=0.178), tot_loss_proj:1.278 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.205 (perp=4.872, rec=0.054, cos=0.177), tot_loss_proj:1.274 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
[1050/2000] tot_loss=1.216 (perp=4.872, rec=0.063, cos=0.178), tot_loss_proj:1.278 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.212 (perp=4.872, rec=0.059, cos=0.178), tot_loss_proj:1.279 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.214 (perp=4.872, rec=0.062, cos=0.178), tot_loss_proj:1.291 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
[1200/2000] tot_loss=1.215 (perp=4.872, rec=0.063, cos=0.178), tot_loss_proj:1.280 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.211 (perp=4.872, rec=0.058, cos=0.178), tot_loss_proj:1.283 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.217 (perp=4.872, rec=0.064, cos=0.178), tot_loss_proj:1.282 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
[1350/2000] tot_loss=1.211 (perp=4.872, rec=0.058, cos=0.179), tot_loss_proj:1.281 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.213 (perp=4.872, rec=0.061, cos=0.178), tot_loss_proj:1.282 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.220 (perp=4.872, rec=0.067, cos=0.178), tot_loss_proj:1.276 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
[1500/2000] tot_loss=1.201 (perp=4.872, rec=0.049, cos=0.178), tot_loss_proj:1.290 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.214 (perp=4.872, rec=0.061, cos=0.178), tot_loss_proj:1.273 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.215 (perp=4.872, rec=0.063, cos=0.178), tot_loss_proj:1.273 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
[1650/2000] tot_loss=1.212 (perp=4.872, rec=0.059, cos=0.178), tot_loss_proj:1.274 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.213 (perp=4.872, rec=0.061, cos=0.178), tot_loss_proj:1.270 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.217 (perp=4.872, rec=0.064, cos=0.178), tot_loss_proj:1.277 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
[1800/2000] tot_loss=1.220 (perp=4.872, rec=0.068, cos=0.178), tot_loss_proj:1.282 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.220 (perp=4.872, rec=0.067, cos=0.178), tot_loss_proj:1.283 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.207 (perp=4.872, rec=0.055, cos=0.178), tot_loss_proj:1.283 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
[1950/2000] tot_loss=1.220 (perp=4.872, rec=0.067, cos=0.178), tot_loss_proj:1.285 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.216 (perp=4.872, rec=0.064, cos=0.178), tot_loss_proj:1.287 [t=0.23s]
prediction: ['[CLS] mary is shorter than five feet. [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] mary is shorter than five feet. [SEP]
========================
predicted: 
========================
[CLS] mary is shorter than five feet. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.559 | p: 86.456 | r: 86.824
rouge2     | fm: 49.068 | p: 48.994 | r: 49.309
rougeL     | fm: 76.162 | p: 76.121 | r: 76.340
rougeLsum  | fm: 76.430 | p: 76.327 | r: 76.698
r1fm+r2fm = 135.627

input #41 time: 0:09:09 | total time: 6:21:18


Running input #42 of 100.
reference: 
========================
She has enough of a problem as it is.
========================
average of cosine similarity 0.8527062191873921
highest_index [0]
highest [0.8527062191873921]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2016, 2038, 2438, 1997, 1037, 3291, 2004, 2009, 2003, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] she has enough of a problem as it is. [SEP]']
[Init] best rec loss: 0.9018435478210449 for ['[CLS] only shooter /press como solid togetherando ‑堂 [SEP]']
[Init] best rec loss: 0.8836270570755005 for ['[CLS] lizardic businesses uniquely twain right betaka flu rover [SEP]']
[Init] best rec loss: 0.8741377592086792 for ['[CLS] ring thing potential process simply cong let speak anniversary non [SEP]']
[Init] best rec loss: 0.8676891922950745 for ['[CLS] enemyk grab process arenaady cue ku mainzziness [SEP]']
[Init] best rec loss: 0.8597415089607239 for ['[CLS] listen stage razor doveyd conza study scratch taste [SEP]']
[Init] best rec loss: 0.8288935422897339 for ['[CLS] ptolemydling skipper tori thank costumedalen sloperessed spa [SEP]']
[Init] best rec loss: 0.8241352438926697 for ['[CLS] internally watching played baby [SEP] marley canopy august subject cape [SEP]']
[Init] best rec loss: 0.8214275240898132 for ['[CLS] eh said pass completed alternate walking covering sure esworld [SEP]']
[Init] best rec loss: 0.8201644420623779 for ['[CLS] into movement responsible huh belief hall safe representativepose fellow [SEP]']
[Init] best rec loss: 0.8116714358329773 for ['[CLS] santa era symbolful alongside nice maritimeorn fresco passed [SEP]']
[Init] best perm rec loss: 0.8114767074584961 for ['[CLS] era santaorn fresco passed nice maritimeful alongside symbol [SEP]']
[Init] best perm rec loss: 0.8104865550994873 for ['[CLS]ful era frescoorn maritime nice passed santa symbol alongside [SEP]']
[Init] best perm rec loss: 0.808367908000946 for ['[CLS] santaorn alongside maritime passed symbol niceful fresco era [SEP]']
[Init] best perm rec loss: 0.8080922365188599 for ['[CLS] nice santa alongsideorn eraful fresco maritime passed symbol [SEP]']
[Init] best perm rec loss: 0.8078344464302063 for ['[CLS] passed alongside symbol eraful fresco niceorn santa maritime [SEP]']
[Init] best perm rec loss: 0.8072717189788818 for ['[CLS] santa passed era nice frescoorn alongside maritimeful symbol [SEP]']
[Init] best perm rec loss: 0.8058387041091919 for ['[CLS]ful maritime nice alongside passed symbol santaorn era fresco [SEP]']
[Init] best perm rec loss: 0.8056718111038208 for ['[CLS] maritime alongside symbolful passed eraorn fresco santa nice [SEP]']
[Init] best perm rec loss: 0.8045477867126465 for ['[CLS] passed alongside nice symbol fresco maritime santaful eraorn [SEP]']
[Init] best perm rec loss: 0.804344892501831 for ['[CLS] santa passed maritime nice era fresco alongsideful symbolorn [SEP]']
[Init] best perm rec loss: 0.8034989237785339 for ['[CLS] symbol alongside frescoful era passed maritime santaorn nice [SEP]']
[Init] best perm rec loss: 0.8029890060424805 for ['[CLS] symbol passed alongside fresco maritime santa era nicefulorn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.831 (perp=10.633, rec=0.443, cos=0.261), tot_loss_proj:3.983 [t=0.23s]
prediction: ['[CLS] the passed on + grief enough i in routego [SEP]']
[ 100/2000] tot_loss=2.309 (perp=8.646, rec=0.335, cos=0.245), tot_loss_proj:3.571 [t=0.23s]
prediction: ['[CLS] the is is enough as enough a that as problems [SEP]']
[ 150/2000] tot_loss=2.298 (perp=8.937, rec=0.258, cos=0.253), tot_loss_proj:3.343 [t=0.23s]
prediction: ['[CLS] she has enough a as enough enough problem as is [SEP]']
[ 200/2000] tot_loss=2.043 (perp=8.197, rec=0.143, cos=0.260), tot_loss_proj:2.864 [t=0.23s]
prediction: ['[CLS] she has enough of as problem been problem as is [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.804 (perp=7.176, rec=0.107, cos=0.261), tot_loss_proj:2.723 [t=0.23s]
prediction: ['[CLS] she has enough of as problem a problem it is [SEP]']
[ 300/2000] tot_loss=1.784 (perp=7.176, rec=0.084, cos=0.264), tot_loss_proj:2.731 [t=0.23s]
prediction: ['[CLS] she has enough of as problem a problem it is [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.642 (perp=6.483, rec=0.083, cos=0.262), tot_loss_proj:2.577 [t=0.23s]
prediction: ['[CLS] she has enough of a problem as problem it is [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.494 (perp=5.734, rec=0.083, cos=0.264), tot_loss_proj:1.773 [t=0.23s]
prediction: ['[CLS] she has enough of a problem problem as it is [SEP]']
[ 450/2000] tot_loss=1.484 (perp=5.734, rec=0.073, cos=0.265), tot_loss_proj:1.766 [t=0.23s]
prediction: ['[CLS] she has enough of a problem problem as it is [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.511 (perp=5.843, rec=0.078, cos=0.265), tot_loss_proj:2.377 [t=0.23s]
prediction: ['[CLS] she has enough of a problem it as it is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.499 (perp=5.843, rec=0.065, cos=0.265), tot_loss_proj:2.381 [t=0.23s]
prediction: ['[CLS] she has enough of a problem it as it is [SEP]']
[ 600/2000] tot_loss=1.503 (perp=5.843, rec=0.069, cos=0.265), tot_loss_proj:2.382 [t=0.23s]
prediction: ['[CLS] she has enough of a problem it as it is [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.406 (perp=5.309, rec=0.080, cos=0.264), tot_loss_proj:1.973 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.402 (perp=5.309, rec=0.075, cos=0.265), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
[ 750/2000] tot_loss=1.405 (perp=5.309, rec=0.078, cos=0.265), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.406 (perp=5.309, rec=0.078, cos=0.266), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.395 (perp=5.309, rec=0.068, cos=0.266), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
[ 900/2000] tot_loss=1.398 (perp=5.309, rec=0.070, cos=0.266), tot_loss_proj:1.964 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.398 (perp=5.309, rec=0.070, cos=0.266), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.398 (perp=5.309, rec=0.070, cos=0.266), tot_loss_proj:1.961 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
[1050/2000] tot_loss=1.403 (perp=5.309, rec=0.075, cos=0.266), tot_loss_proj:1.965 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.400 (perp=5.309, rec=0.072, cos=0.266), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.402 (perp=5.309, rec=0.074, cos=0.266), tot_loss_proj:1.967 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
[1200/2000] tot_loss=1.402 (perp=5.309, rec=0.074, cos=0.266), tot_loss_proj:1.966 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.398 (perp=5.309, rec=0.070, cos=0.266), tot_loss_proj:1.970 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.394 (perp=5.309, rec=0.066, cos=0.266), tot_loss_proj:1.963 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
[1350/2000] tot_loss=1.397 (perp=5.309, rec=0.069, cos=0.266), tot_loss_proj:1.965 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.400 (perp=5.309, rec=0.072, cos=0.266), tot_loss_proj:1.966 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.389 (perp=5.309, rec=0.061, cos=0.266), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
[1500/2000] tot_loss=1.403 (perp=5.309, rec=0.075, cos=0.266), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.397 (perp=5.309, rec=0.069, cos=0.266), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.395 (perp=5.309, rec=0.066, cos=0.266), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
[1650/2000] tot_loss=1.400 (perp=5.309, rec=0.071, cos=0.266), tot_loss_proj:1.965 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.406 (perp=5.309, rec=0.078, cos=0.267), tot_loss_proj:1.965 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.400 (perp=5.309, rec=0.071, cos=0.267), tot_loss_proj:1.967 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
[1800/2000] tot_loss=1.403 (perp=5.309, rec=0.074, cos=0.267), tot_loss_proj:1.966 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.395 (perp=5.309, rec=0.066, cos=0.267), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.398 (perp=5.309, rec=0.069, cos=0.267), tot_loss_proj:1.967 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
[1950/2000] tot_loss=1.401 (perp=5.309, rec=0.073, cos=0.267), tot_loss_proj:1.963 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.405 (perp=5.309, rec=0.077, cos=0.267), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] she has it enough of a problem as it is [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] she has enough of a problem as it is. [SEP]
========================
predicted: 
========================
[CLS] she has enough of a problem problem as it is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 95.238 | p: 90.909 | r: 100.000
rougeL     | fm: 95.652 | p: 91.667 | r: 100.000
rougeLsum  | fm: 95.652 | p: 91.667 | r: 100.000
r1fm+r2fm = 190.890

[Aggregate metrics]:
rouge1     | fm: 86.749 | p: 86.563 | r: 87.181
rouge2     | fm: 50.250 | p: 50.039 | r: 50.582
rougeL     | fm: 76.656 | p: 76.514 | r: 76.998
rougeLsum  | fm: 76.704 | p: 76.557 | r: 77.032
r1fm+r2fm = 137.000

input #42 time: 0:09:09 | total time: 6:30:28


Running input #43 of 100.
reference: 
========================
Every student has to come up with three arguments that show that some condition proposed by Bill is wrong.
========================
average of cosine similarity 0.8563460090900932
highest_index [0]
highest [0.8563460090900932]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[ 101, 2296, 3076, 2038, 2000, 2272, 2039, 2007, 2093, 9918, 2008, 2265,
         2008, 2070, 4650, 3818, 2011, 3021, 2003, 3308, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]']
[Init] best rec loss: 0.9291274547576904 for ['[CLS] unaffected peter interval sporting campaign singular relieved start shooting club helleche date operative either meredith occupied lamagee metals [SEP]']
[Init] best rec loss: 0.9156556725502014 for ['[CLS] warlock picks portland briefly gardiner farther argued...mo received fi falls juliette betweenrate elderetachal zach carl [SEP]']
[Init] best rec loss: 0.9094363451004028 for ['[CLS] limited anymore iffying word bluegood catalog hopefully mentioned switch closederence tad edge chart festival agony manner tried [SEP]']
[Init] best rec loss: 0.8808814883232117 for ['[CLS] age files corner full tide well not britishoatiface seed guys sounds element deeplybridge justice bass tailhar [SEP]']
[Init] best rec loss: 0.8747199773788452 for ['[CLS] channel defensive cause secretary typemity form manners grace tara seminaryvd installed shrity world cl reyes olympian cheeks [SEP]']
[Init] best rec loss: 0.8663801550865173 for ['[CLS] interactive stillrr individualевич county flea explain academy skiingnight promotion award kids hunted organized suspended office brothers muscle [SEP]']
[Init] best rec loss: 0.8611739277839661 for ['[CLS] mad kelly primary immediately agent union tobiasheater asthma kylie trade traffic single re bid husband exhaled granny windows background [SEP]']
[Init] best rec loss: 0.8415829539299011 for ['[CLS] script ghosts ᄂ lined fort be chuck producing inter hawk sooner completion nate jet cast likely barrel flash lock kyiv [SEP]']
[Init] best perm rec loss: 0.841256856918335 for ['[CLS] chuck kyiv lined barrel be likely producing ᄂ jet nate sooner lock cast completion fort script hawk ghosts flash inter [SEP]']
[Init] best perm rec loss: 0.8348606824874878 for ['[CLS] inter cast completion kyiv lock likely fort hawk flash lined chuck script barrel ghosts be sooner ᄂ nate jet producing [SEP]']
[Init] best perm rec loss: 0.8346259593963623 for ['[CLS] sooner producing completion barrel lined ᄂ ghosts kyiv be inter nate fort lock cast script flash jet hawk chuck likely [SEP]']
[Init] best perm rec loss: 0.831612765789032 for ['[CLS] barrel ᄂ lined ghosts inter completion be cast script flash nate sooner fort hawk lock likely kyiv jet chuck producing [SEP]']
[Init] best perm rec loss: 0.8307512998580933 for ['[CLS] barrel flash producing sooner ᄂ ghosts jet fort kyiv chuck cast script be lined hawk likely completion nate inter lock [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.875 (perp=11.349, rec=0.365, cos=0.240), tot_loss_proj:4.133 [t=0.23s]
prediction: ['[CLS] deliver of ( mrs shoes as danny her cook a billgra in theory mitch challenge network subdivision argument trip [SEP]']
[ 100/2000] tot_loss=2.937 (perp=12.127, rec=0.272, cos=0.239), tot_loss_proj:4.290 [t=0.23s]
prediction: ['[CLS] condition bill every mrs critics every discussed read here a argumentsgra an argument bill proposal bill woman argument trip [SEP]']
[ 150/2000] tot_loss=2.453 (perp=9.900, rec=0.224, cos=0.249), tot_loss_proj:3.877 [t=0.24s]
prediction: ['[CLS] every bill every threexed every bill come parents that argumentsgra by argument bill arguments bill every argument bill [SEP]']
[ 200/2000] tot_loss=2.656 (perp=11.071, rec=0.186, cos=0.256), tot_loss_proj:4.124 [t=0.24s]
prediction: ['[CLS] student bill every three must every bill come who some argumentsgra by argument bill showing condition student argument bill [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.567 (perp=10.420, rec=0.215, cos=0.268), tot_loss_proj:3.977 [t=0.24s]
prediction: ['[CLS] student bill every three must many bill come or point what arguments best argument bill showing bill student、 bill [SEP]']
[ 300/2000] tot_loss=2.557 (perp=10.676, rec=0.174, cos=0.247), tot_loss_proj:4.008 [t=0.24s]
prediction: ['[CLS] student bill every three has many bill up result point what arguments best argument bill showing condition student、 bill [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.461 (perp=9.802, rec=0.232, cos=0.269), tot_loss_proj:3.808 [t=0.24s]
prediction: ['[CLS] student any every three has many bill upades point condition arguments best arguments bill that what student is. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.337 (perp=9.592, rec=0.163, cos=0.256), tot_loss_proj:3.786 [t=0.24s]
prediction: ['[CLS] student arguments every three has many bill up earlier joke condition arguments best any bill showing some student is. [SEP]']
[ 450/2000] tot_loss=2.407 (perp=9.961, rec=0.155, cos=0.261), tot_loss_proj:3.845 [t=0.24s]
prediction: ['[CLS] student arguments every three has have bill up earlier message condition arguments by any bill showing somebird is. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.401 (perp=9.847, rec=0.165, cos=0.266), tot_loss_proj:3.822 [t=0.24s]
prediction: ['[CLS] student arguments every three has message bill up things using condition arguments come any bill showing some they is. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.282 (perp=9.380, rec=0.147, cos=0.259), tot_loss_proj:3.726 [t=0.24s]
prediction: ['[CLS] student wrong every three has message things up bill with condition arguments wrong with bill showing some they with. [SEP]']
[ 600/2000] tot_loss=2.252 (perp=9.258, rec=0.140, cos=0.261), tot_loss_proj:3.706 [t=0.24s]
prediction: ['[CLS] student wrong every three has bill papers up bill with condition arguments wrong with bill showing some they with. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.332 (perp=9.641, rec=0.148, cos=0.256), tot_loss_proj:3.733 [t=0.24s]
prediction: ['[CLS] student bill every three has bill earlier up bill with condition arguments by with wrong show some they with. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.337 (perp=9.715, rec=0.131, cos=0.263), tot_loss_proj:3.777 [t=0.24s]
prediction: ['[CLS] student bill every three has proposal earlier up against with condition arguments by with wrong some show they with. [SEP]']
[ 750/2000] tot_loss=2.400 (perp=10.002, rec=0.134, cos=0.266), tot_loss_proj:3.837 [t=0.24s]
prediction: ['[CLS] student bill every three has proposal earlier up against with condition arguments by with wrong some show come with. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.257 (perp=9.319, rec=0.131, cos=0.262), tot_loss_proj:3.710 [t=0.24s]
prediction: ['[CLS] student bill every has three proposal earlier up against with condition arguments by any wrong some show come with. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.179 (perp=8.908, rec=0.130, cos=0.268), tot_loss_proj:3.633 [t=0.24s]
prediction: ['[CLS] student bill every has three proposal earlier up against with condition arguments by any with some show come wrong. [SEP]']
[ 900/2000] tot_loss=2.218 (perp=9.133, rec=0.129, cos=0.262), tot_loss_proj:3.691 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed earlier up against with condition arguments by any with some show come wrong. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.152 (perp=8.816, rec=0.124, cos=0.265), tot_loss_proj:3.613 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed earlier against up with condition arguments by any with some show come wrong. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.229 (perp=9.207, rec=0.124, cos=0.263), tot_loss_proj:3.724 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed earlier against up with arguments by as condition with some show come wrong. [SEP]']
[1050/2000] tot_loss=2.258 (perp=9.389, rec=0.117, cos=0.263), tot_loss_proj:3.770 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed earlier of up with arguments by as condition with some show come wrong. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.996 (perp=7.970, rec=0.136, cos=0.265), tot_loss_proj:3.436 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed earlier come up with arguments by any condition with some show against wrong. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.964 (perp=7.858, rec=0.128, cos=0.264), tot_loss_proj:3.427 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with earlier arguments by any condition with some show against wrong. [SEP]']
[1200/2000] tot_loss=2.027 (perp=8.215, rec=0.118, cos=0.266), tot_loss_proj:3.507 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with earlier arguments by any condition has some show against wrong. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.980 (perp=7.942, rec=0.126, cos=0.265), tot_loss_proj:3.469 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with earlier against by any condition has some show arguments wrong. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.985 (perp=7.942, rec=0.130, cos=0.266), tot_loss_proj:3.468 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with earlier against by any condition has some show arguments wrong. [SEP]']
[1350/2000] tot_loss=2.080 (perp=8.455, rec=0.123, cos=0.266), tot_loss_proj:3.546 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with earlier against by as condition has some show arguments wrong. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.047 (perp=8.318, rec=0.118, cos=0.265), tot_loss_proj:3.518 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with earlier of condition as by has some show arguments wrong. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.996 (perp=8.032, rec=0.124, cos=0.266), tot_loss_proj:3.461 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with of earlier condition as by has some show arguments wrong. [SEP]']
[1500/2000] tot_loss=1.995 (perp=8.032, rec=0.123, cos=0.266), tot_loss_proj:3.462 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with of earlier condition as by has some show arguments wrong. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.943 (perp=7.820, rec=0.114, cos=0.264), tot_loss_proj:3.439 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with of earlier condition as has by some show arguments wrong. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.917 (perp=7.665, rec=0.120, cos=0.264), tot_loss_proj:3.392 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with earlier condition as has by some of show arguments wrong. [SEP]']
[1650/2000] tot_loss=2.038 (perp=8.248, rec=0.123, cos=0.265), tot_loss_proj:3.514 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with earlier condition any has by some of show arguments wrong. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.973 (perp=7.949, rec=0.117, cos=0.266), tot_loss_proj:3.453 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with earlier any condition has by some of show arguments wrong. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.908 (perp=7.631, rec=0.116, cos=0.266), tot_loss_proj:3.405 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with any earlier condition has by some of show arguments wrong. [SEP]']
[1800/2000] tot_loss=1.909 (perp=7.631, rec=0.117, cos=0.266), tot_loss_proj:3.408 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with any earlier condition has by some of show arguments wrong. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.841 (perp=7.301, rec=0.114, cos=0.266), tot_loss_proj:3.310 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with any earlier condition has by some show of arguments wrong. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.817 (perp=7.209, rec=0.113, cos=0.262), tot_loss_proj:3.302 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with any earlier condition has by some show of wrong arguments. [SEP]']
[1950/2000] tot_loss=1.947 (perp=7.827, rec=0.117, cos=0.265), tot_loss_proj:3.427 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with any earlier condition has by some show by wrong arguments. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.978 (perp=7.975, rec=0.118, cos=0.265), tot_loss_proj:3.445 [t=0.24s]
prediction: ['[CLS] student bill every has three proposed come up with as earlier condition has by some show by arguments wrong. [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]
========================
predicted: 
========================
[CLS] student bill every has three proposed come up with any earlier condition has by some of show arguments wrong. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.952 | p: 80.952 | r: 80.952
rouge2     | fm: 15.000 | p: 15.000 | r: 15.000
rougeL     | fm: 47.619 | p: 47.619 | r: 47.619
rougeLsum  | fm: 47.619 | p: 47.619 | r: 47.619
r1fm+r2fm = 95.952

[Aggregate metrics]:
rouge1     | fm: 86.644 | p: 86.431 | r: 87.036
rouge2     | fm: 49.390 | p: 49.142 | r: 49.749
rougeL     | fm: 75.989 | p: 75.909 | r: 76.298
rougeLsum  | fm: 76.007 | p: 75.855 | r: 76.418
r1fm+r2fm = 136.034

input #43 time: 0:09:18 | total time: 6:39:46


Running input #44 of 100.
reference: 
========================
Kim alienates cats and beat his dog.
========================
average of cosine similarity 0.867248490972606
highest_index [0]
highest [0.867248490972606]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 5035, 7344, 8520, 8870, 1998, 3786, 2010, 3899, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] kim alienates cats and beat his dog. [SEP]']
[Init] best rec loss: 0.8929563760757446 for ['[CLS] vineyard sterling michigan bat hot boltedpati cannot matter [SEP]']
[Init] best rec loss: 0.8750676512718201 for ['[CLS] jihad much complex marshall deadline [SEP] terminus volume japan [SEP]']
[Init] best rec loss: 0.8693276047706604 for ['[CLS] revivalphobicence nails animal performance antarctic for run [SEP]']
[Init] best rec loss: 0.8649100065231323 for ['[CLS] and passage such signedhear college whatever city boo [SEP]']
[Init] best rec loss: 0.8332201838493347 for ['[CLS] statementphyveda cmll credits hot wine faint + [SEP]']
[Init] best rec loss: 0.8280391693115234 for ['[CLS] peas consider tenure amos avalon signal edition gal figures [SEP]']
[Init] best rec loss: 0.8221735954284668 for ['[CLS] emperor tank dropped house marshall spring ups fusion pilot [SEP]']
[Init] best rec loss: 0.8027899861335754 for ['[CLS] wreck closely lord another worth contrast ud programmer comic [SEP]']
[Init] best perm rec loss: 0.8024938106536865 for ['[CLS] wreck contrast programmer another ud worth comic lord closely [SEP]']
[Init] best perm rec loss: 0.799903392791748 for ['[CLS] ud wreck programmer another lord worth contrast comic closely [SEP]']
[Init] best perm rec loss: 0.7982266545295715 for ['[CLS] worth wreck another contrast comic lord programmer ud closely [SEP]']
[Init] best perm rec loss: 0.7967706322669983 for ['[CLS] wreck lord another worth contrast closely comic programmer ud [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.449 (perp=14.111, rec=0.379, cos=0.248), tot_loss_proj:4.659 [t=0.23s]
prediction: ['[CLS] billboard beat another eating tam monkey katie dog him [SEP]']
[ 100/2000] tot_loss=3.079 (perp=12.497, rec=0.297, cos=0.283), tot_loss_proj:4.363 [t=0.23s]
prediction: ['[CLS] kim beat cats violence kim dogates dog him [SEP]']
[ 150/2000] tot_loss=2.820 (perp=11.122, rec=0.323, cos=0.272), tot_loss_proj:4.090 [t=0.23s]
prediction: ['[CLS] kim beat cats obedience kimmenates dog. [SEP]']
[ 200/2000] tot_loss=2.640 (perp=10.644, rec=0.276, cos=0.236), tot_loss_proj:3.937 [t=0.23s]
prediction: ['[CLS] kim beat dog ordinary kim dogates dog. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.459 (perp=9.584, rec=0.309, cos=0.233), tot_loss_proj:3.708 [t=0.23s]
prediction: ['[CLS] kim beat dogates ; empped dog. [SEP]']
[ 300/2000] tot_loss=2.166 (perp=8.424, rec=0.238, cos=0.243), tot_loss_proj:3.498 [t=0.23s]
prediction: ['[CLS] kim beat dogates ; em his dog. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.030 (perp=7.919, rec=0.219, cos=0.227), tot_loss_proj:3.430 [t=0.23s]
prediction: ['[CLS] kimates ; beat dog em his dog. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.056 (perp=7.918, rec=0.239, cos=0.233), tot_loss_proj:3.397 [t=0.23s]
prediction: ['[CLS] kimates ; his dog beat dog anomaly. [SEP]']
[ 450/2000] tot_loss=2.003 (perp=7.918, rec=0.193, cos=0.226), tot_loss_proj:3.407 [t=0.23s]
prediction: ['[CLS] kimates ; his dog beat dog anomaly. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.021 (perp=8.023, rec=0.185, cos=0.231), tot_loss_proj:3.458 [t=0.23s]
prediction: ['[CLS] kimates ; his dog beat dog alien. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.803 (perp=6.970, rec=0.192, cos=0.217), tot_loss_proj:2.861 [t=0.23s]
prediction: ['[CLS] kim alienates ; his dog beat dog. [SEP]']
[ 600/2000] tot_loss=1.796 (perp=6.970, rec=0.171, cos=0.231), tot_loss_proj:2.866 [t=0.23s]
prediction: ['[CLS] kim alienates ; his dog beat dog. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.800 (perp=6.970, rec=0.165, cos=0.241), tot_loss_proj:2.866 [t=0.23s]
prediction: ['[CLS] kim alienates ; his dog beat dog. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.801 (perp=6.970, rec=0.170, cos=0.238), tot_loss_proj:2.866 [t=0.23s]
prediction: ['[CLS] kim alienates ; his dog beat dog. [SEP]']
[ 750/2000] tot_loss=1.787 (perp=6.970, rec=0.155, cos=0.238), tot_loss_proj:2.863 [t=0.23s]
prediction: ['[CLS] kim alienates ; his dog beat dog. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.786 (perp=6.970, rec=0.155, cos=0.237), tot_loss_proj:2.866 [t=0.23s]
prediction: ['[CLS] kim alienates ; his dog beat dog. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.773 (perp=6.970, rec=0.144, cos=0.234), tot_loss_proj:2.856 [t=0.23s]
prediction: ['[CLS] kim alienates ; his dog beat dog. [SEP]']
[ 900/2000] tot_loss=1.773 (perp=6.970, rec=0.143, cos=0.236), tot_loss_proj:2.859 [t=0.23s]
prediction: ['[CLS] kim alienates ; his dog beat dog. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.775 (perp=6.970, rec=0.145, cos=0.236), tot_loss_proj:2.870 [t=0.23s]
prediction: ['[CLS] kim alienates ; his dog beat dog. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.776 (perp=6.970, rec=0.144, cos=0.238), tot_loss_proj:2.867 [t=0.23s]
prediction: ['[CLS] kim alienates ; his dog beat dog. [SEP]']
[1050/2000] tot_loss=2.054 (perp=8.383, rec=0.138, cos=0.239), tot_loss_proj:3.287 [t=0.23s]
prediction: ['[CLS] kim alienates or his dog beat cats. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.783 (perp=7.031, rec=0.140, cos=0.237), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.782 (perp=7.031, rec=0.137, cos=0.238), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
[1200/2000] tot_loss=1.786 (perp=7.031, rec=0.142, cos=0.239), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.780 (perp=7.031, rec=0.135, cos=0.239), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.776 (perp=7.031, rec=0.131, cos=0.239), tot_loss_proj:2.408 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
[1350/2000] tot_loss=1.778 (perp=7.031, rec=0.132, cos=0.239), tot_loss_proj:2.411 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.768 (perp=7.031, rec=0.122, cos=0.239), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.782 (perp=7.031, rec=0.136, cos=0.240), tot_loss_proj:2.413 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
[1500/2000] tot_loss=1.783 (perp=7.031, rec=0.137, cos=0.240), tot_loss_proj:2.405 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.778 (perp=7.031, rec=0.132, cos=0.240), tot_loss_proj:2.408 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.782 (perp=7.031, rec=0.135, cos=0.240), tot_loss_proj:2.411 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
[1650/2000] tot_loss=1.772 (perp=7.031, rec=0.126, cos=0.240), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.777 (perp=7.031, rec=0.130, cos=0.240), tot_loss_proj:2.413 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.778 (perp=7.031, rec=0.132, cos=0.240), tot_loss_proj:2.410 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
[1800/2000] tot_loss=1.780 (perp=7.031, rec=0.134, cos=0.240), tot_loss_proj:2.411 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.773 (perp=7.031, rec=0.127, cos=0.241), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.773 (perp=7.031, rec=0.126, cos=0.241), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
[1950/2000] tot_loss=1.775 (perp=7.031, rec=0.128, cos=0.241), tot_loss_proj:2.413 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.771 (perp=7.031, rec=0.124, cos=0.241), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] kim alienates or beat his dog cats. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] kim alienates cats and beat his dog. [SEP]
========================
predicted: 
========================
[CLS] kim alienates or beat his dog cats. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 138.889

[Aggregate metrics]:
rouge1     | fm: 86.620 | p: 86.455 | r: 87.076
rouge2     | fm: 49.226 | p: 48.976 | r: 49.462
rougeL     | fm: 75.986 | p: 75.782 | r: 76.288
rougeLsum  | fm: 76.134 | p: 76.005 | r: 76.521
r1fm+r2fm = 135.846

input #44 time: 0:09:10 | total time: 6:48:56


Running input #45 of 100.
reference: 
========================
John's I stole bike.
========================
average of cosine similarity 0.8997435916663373
highest_index [0]
highest [0.8997435916663373]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2198,  1005,  1055,  1045, 10312,  7997,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] john's i stole bike. [SEP]"]
[Init] best rec loss: 0.8220645189285278 for ['[CLS] outskirts came too yourtered occupy tradition [SEP]']
[Init] best rec loss: 0.7178110480308533 for ['[CLS] and general driving weak [SEP]akcede [SEP]']
[Init] best rec loss: 0.7043296098709106 for ['[CLS]cableaus splitsonic 22 continue moving [SEP]']
[Init] best rec loss: 0.6992545127868652 for ['[CLS] disaster ruled mm refuse but line allows [SEP]']
[Init] best rec loss: 0.6889793872833252 for ['[CLS] bound alike youricum direct due watching [SEP]']
[Init] best rec loss: 0.6867796182632446 for ['[CLS]nch occupation interview situated put iii por [SEP]']
[Init] best perm rec loss: 0.685736894607544 for ['[CLS]nch put occupation situated iii interview por [SEP]']
[Init] best perm rec loss: 0.6819389462471008 for ['[CLS] iii put interview occupationnch por situated [SEP]']
[Init] best perm rec loss: 0.6810379028320312 for ['[CLS]nch occupation put interview situated por iii [SEP]']
[Init] best perm rec loss: 0.6793588995933533 for ['[CLS] por put occupation interview situatednch iii [SEP]']
[Init] best perm rec loss: 0.6787002682685852 for ['[CLS] iii putnch occupation por interview situated [SEP]']
[Init] best perm rec loss: 0.6770588755607605 for ['[CLS] put iii pornch situated interview occupation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.584 (perp=10.554, rec=0.287, cos=0.186), tot_loss_proj:3.168 [t=0.23s]
prediction: ['[CLS] s whose s john shot bike stole [SEP]']
[ 100/2000] tot_loss=2.435 (perp=10.323, rec=0.184, cos=0.187), tot_loss_proj:3.126 [t=0.23s]
prediction: ['[CLS] s bike s john i bike stole [SEP]']
[ 150/2000] tot_loss=2.262 (perp=9.466, rec=0.179, cos=0.190), tot_loss_proj:3.018 [t=0.23s]
prediction: ['[CLS] s. i john i bike stole [SEP]']
[ 200/2000] tot_loss=2.197 (perp=9.466, rec=0.118, cos=0.186), tot_loss_proj:3.028 [t=0.23s]
prediction: ['[CLS] s. i john i bike stole [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.937 (perp=8.059, rec=0.138, cos=0.187), tot_loss_proj:3.000 [t=0.23s]
prediction: ['[CLS] s. i john i stole bike [SEP]']
[ 300/2000] tot_loss=1.907 (perp=8.059, rec=0.108, cos=0.187), tot_loss_proj:3.001 [t=0.23s]
prediction: ['[CLS] s. i john i stole bike [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.897 (perp=7.765, rec=0.162, cos=0.182), tot_loss_proj:2.993 [t=0.23s]
prediction: ['[CLS] s i. john i stole bike [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.796 (perp=7.580, rec=0.096, cos=0.185), tot_loss_proj:2.749 [t=0.23s]
prediction: ["[CLS]'s. john i stole bike [SEP]"]
[ 450/2000] tot_loss=1.805 (perp=7.580, rec=0.103, cos=0.186), tot_loss_proj:2.753 [t=0.23s]
prediction: ["[CLS]'s. john i stole bike [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.644 (perp=6.750, rec=0.109, cos=0.185), tot_loss_proj:2.807 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.636 (perp=6.750, rec=0.099, cos=0.187), tot_loss_proj:2.801 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
[ 600/2000] tot_loss=1.629 (perp=6.750, rec=0.092, cos=0.187), tot_loss_proj:2.810 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.631 (perp=6.750, rec=0.094, cos=0.187), tot_loss_proj:2.804 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.619 (perp=6.750, rec=0.081, cos=0.188), tot_loss_proj:2.809 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
[ 750/2000] tot_loss=1.635 (perp=6.750, rec=0.097, cos=0.188), tot_loss_proj:2.813 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.624 (perp=6.750, rec=0.086, cos=0.188), tot_loss_proj:2.803 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.630 (perp=6.750, rec=0.092, cos=0.188), tot_loss_proj:2.812 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
[ 900/2000] tot_loss=1.620 (perp=6.750, rec=0.082, cos=0.188), tot_loss_proj:2.803 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.626 (perp=6.750, rec=0.088, cos=0.188), tot_loss_proj:2.813 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.620 (perp=6.750, rec=0.082, cos=0.188), tot_loss_proj:2.811 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
[1050/2000] tot_loss=1.628 (perp=6.750, rec=0.089, cos=0.188), tot_loss_proj:2.809 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.620 (perp=6.750, rec=0.082, cos=0.188), tot_loss_proj:2.804 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.633 (perp=6.750, rec=0.094, cos=0.188), tot_loss_proj:2.806 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
[1200/2000] tot_loss=1.623 (perp=6.750, rec=0.085, cos=0.188), tot_loss_proj:2.806 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.619 (perp=6.750, rec=0.081, cos=0.189), tot_loss_proj:2.813 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.628 (perp=6.750, rec=0.089, cos=0.189), tot_loss_proj:2.807 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
[1350/2000] tot_loss=1.626 (perp=6.750, rec=0.087, cos=0.189), tot_loss_proj:2.809 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.628 (perp=6.750, rec=0.089, cos=0.189), tot_loss_proj:2.808 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.627 (perp=6.750, rec=0.088, cos=0.189), tot_loss_proj:2.808 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
[1500/2000] tot_loss=1.635 (perp=6.750, rec=0.096, cos=0.189), tot_loss_proj:2.811 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.624 (perp=6.750, rec=0.085, cos=0.189), tot_loss_proj:2.812 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.625 (perp=6.750, rec=0.085, cos=0.189), tot_loss_proj:2.804 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
[1650/2000] tot_loss=1.616 (perp=6.750, rec=0.077, cos=0.189), tot_loss_proj:2.811 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.621 (perp=6.750, rec=0.082, cos=0.189), tot_loss_proj:2.804 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.615 (perp=6.750, rec=0.076, cos=0.189), tot_loss_proj:2.809 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
[1800/2000] tot_loss=1.619 (perp=6.750, rec=0.080, cos=0.189), tot_loss_proj:2.811 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.634 (perp=6.750, rec=0.095, cos=0.189), tot_loss_proj:2.813 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.635 (perp=6.750, rec=0.096, cos=0.189), tot_loss_proj:2.811 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
[1950/2000] tot_loss=1.623 (perp=6.750, rec=0.084, cos=0.189), tot_loss_proj:2.811 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.627 (perp=6.750, rec=0.087, cos=0.189), tot_loss_proj:2.805 [t=0.23s]
prediction: ["[CLS] s. john'i stole bike [SEP]"]
Done with input #45 of 100.
reference: 
========================
[CLS] john's i stole bike. [SEP]
========================
predicted: 
========================
[CLS] s. john'i stole bike [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 86.966 | p: 86.792 | r: 87.382
rouge2     | fm: 49.476 | p: 49.317 | r: 49.843
rougeL     | fm: 76.171 | p: 76.067 | r: 76.543
rougeLsum  | fm: 76.386 | p: 76.209 | r: 76.728
r1fm+r2fm = 136.442

input #45 time: 0:09:10 | total time: 6:58:06


Running input #46 of 100.
reference: 
========================
The witch went into the forest by vanishing.
========================
average of cosine similarity 0.9083124928539119
highest_index [0]
highest [0.9083124928539119]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1996,  6965,  2253,  2046,  1996,  3224,  2011, 24866,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] the witch went into the forest by vanishing. [SEP]']
[Init] best rec loss: 0.7024356722831726 for ['[CLS] tripume mackenzie enterprise crunch threshold engine free down [SEP]']
[Init] best rec loss: 0.6963872313499451 for ['[CLS] hell advent shared moderatenton drivendity kennedyided [SEP]']
[Init] best rec loss: 0.6888093948364258 for ['[CLS] ink loss yet volvo remaining fine manor sa glacier [SEP]']
[Init] best perm rec loss: 0.6880171895027161 for ['[CLS] ink volvo manor yet glacier fine remaining loss sa [SEP]']
[Init] best perm rec loss: 0.687394380569458 for ['[CLS] yet loss manor glacier ink remaining volvo fine sa [SEP]']
[Init] best perm rec loss: 0.6812867522239685 for ['[CLS] loss fine yet remaining glacier sa ink volvo manor [SEP]']
[Init] best perm rec loss: 0.680699348449707 for ['[CLS] sa glacier loss remaining volvo yet manor fine ink [SEP]']
[Init] best perm rec loss: 0.6798800230026245 for ['[CLS] loss volvo yet fine sa glacier manor remaining ink [SEP]']
[Init] best perm rec loss: 0.6791837811470032 for ['[CLS] yet volvo remaining manor sa glacier ink loss fine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.378 (perp=9.371, rec=0.336, cos=0.167), tot_loss_proj:2.838 [t=0.23s]
prediction: ['[CLS] disappearing got. disappeared 6 ( municipality by. [SEP]']
[ 100/2000] tot_loss=2.284 (perp=9.811, rec=0.148, cos=0.173), tot_loss_proj:2.784 [t=0.23s]
prediction: ['[CLS] vanishing went into vanishing into witch forest by vanishing [SEP]']
[ 150/2000] tot_loss=2.118 (perp=9.219, rec=0.103, cos=0.171), tot_loss_proj:2.422 [t=0.23s]
prediction: ['[CLS] witch went into the into witch forest by vanishing [SEP]']
[ 200/2000] tot_loss=1.946 (perp=8.427, rec=0.088, cos=0.173), tot_loss_proj:2.446 [t=0.23s]
prediction: ['[CLS] witch went into the the witch forest by vanishing [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.941 (perp=8.427, rec=0.087, cos=0.169), tot_loss_proj:2.433 [t=0.23s]
prediction: ['[CLS] witch went into the the witch forest by vanishing [SEP]']
[ 300/2000] tot_loss=1.933 (perp=8.427, rec=0.076, cos=0.172), tot_loss_proj:2.441 [t=0.23s]
prediction: ['[CLS] witch went into the the witch forest by vanishing [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.300 (perp=8.526, rec=0.385, cos=0.210), tot_loss_proj:2.498 [t=0.23s]
prediction: ['[CLS]. went into season witch the forest by vanishing [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.871 (perp=7.051, rec=0.293, cos=0.168), tot_loss_proj:2.555 [t=0.23s]
prediction: ['[CLS] went into the witch the forest by vanishing. [SEP]']
[ 450/2000] tot_loss=1.921 (perp=7.666, rec=0.226, cos=0.162), tot_loss_proj:2.725 [t=0.23s]
prediction: ['[CLS] went into season witch the forest by vanishing. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.050 (perp=8.376, rec=0.212, cos=0.163), tot_loss_proj:2.613 [t=0.23s]
prediction: ['[CLS] went into the the forest witch by vanishing. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.782 (perp=7.198, rec=0.182, cos=0.161), tot_loss_proj:2.531 [t=0.23s]
prediction: ['[CLS] went into the forest the witch by vanishing. [SEP]']
[ 600/2000] tot_loss=1.771 (perp=7.198, rec=0.166, cos=0.165), tot_loss_proj:2.524 [t=0.23s]
prediction: ['[CLS] went into the forest the witch by vanishing. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.461 (perp=5.776, rec=0.148, cos=0.158), tot_loss_proj:1.466 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.458 (perp=5.776, rec=0.139, cos=0.165), tot_loss_proj:1.462 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
[ 750/2000] tot_loss=1.449 (perp=5.776, rec=0.126, cos=0.168), tot_loss_proj:1.456 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.440 (perp=5.776, rec=0.115, cos=0.170), tot_loss_proj:1.460 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.426 (perp=5.776, rec=0.100, cos=0.171), tot_loss_proj:1.460 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
[ 900/2000] tot_loss=1.423 (perp=5.776, rec=0.097, cos=0.171), tot_loss_proj:1.459 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.448 (perp=5.776, rec=0.121, cos=0.171), tot_loss_proj:1.458 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.422 (perp=5.776, rec=0.096, cos=0.171), tot_loss_proj:1.468 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
[1050/2000] tot_loss=1.425 (perp=5.776, rec=0.099, cos=0.171), tot_loss_proj:1.460 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.407 (perp=5.776, rec=0.081, cos=0.171), tot_loss_proj:1.460 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.424 (perp=5.776, rec=0.098, cos=0.171), tot_loss_proj:1.463 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
[1200/2000] tot_loss=1.412 (perp=5.776, rec=0.085, cos=0.171), tot_loss_proj:1.470 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.428 (perp=5.776, rec=0.103, cos=0.170), tot_loss_proj:1.456 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.427 (perp=5.776, rec=0.102, cos=0.170), tot_loss_proj:1.460 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
[1350/2000] tot_loss=1.418 (perp=5.776, rec=0.093, cos=0.170), tot_loss_proj:1.475 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.406 (perp=5.776, rec=0.079, cos=0.172), tot_loss_proj:1.459 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.407 (perp=5.776, rec=0.080, cos=0.172), tot_loss_proj:1.450 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
[1500/2000] tot_loss=1.395 (perp=5.776, rec=0.068, cos=0.172), tot_loss_proj:1.459 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.407 (perp=5.776, rec=0.080, cos=0.172), tot_loss_proj:1.456 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.404 (perp=5.776, rec=0.076, cos=0.172), tot_loss_proj:1.446 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
[1650/2000] tot_loss=1.426 (perp=5.776, rec=0.099, cos=0.172), tot_loss_proj:1.457 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.412 (perp=5.776, rec=0.085, cos=0.172), tot_loss_proj:1.470 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.418 (perp=5.776, rec=0.091, cos=0.172), tot_loss_proj:1.465 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
[1800/2000] tot_loss=1.407 (perp=5.776, rec=0.079, cos=0.172), tot_loss_proj:1.467 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.421 (perp=5.776, rec=0.095, cos=0.171), tot_loss_proj:1.466 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.403 (perp=5.776, rec=0.078, cos=0.171), tot_loss_proj:1.456 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
[1950/2000] tot_loss=1.401 (perp=5.776, rec=0.075, cos=0.171), tot_loss_proj:1.455 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.411 (perp=5.776, rec=0.083, cos=0.173), tot_loss_proj:1.452 [t=0.23s]
prediction: ['[CLS] the witch went into the forest by vanishing. [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] the witch went into the forest by vanishing. [SEP]
========================
predicted: 
========================
[CLS] the witch went into the forest by vanishing. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.226 | p: 87.029 | r: 87.615
rouge2     | fm: 50.700 | p: 50.508 | r: 51.053
rougeL     | fm: 76.731 | p: 76.581 | r: 76.992
rougeLsum  | fm: 76.781 | p: 76.674 | r: 77.130
r1fm+r2fm = 137.926

input #46 time: 0:09:10 | total time: 7:07:17


Running input #47 of 100.
reference: 
========================
Mary noticed John's excessive appreciation of himself.
========================
average of cosine similarity 0.8873482782631353
highest_index [0]
highest [0.8873482782631353]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2984,  4384,  2198,  1005,  1055, 11664, 12284,  1997,  2370,
          1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] mary noticed john's excessive appreciation of himself. [SEP]"]
[Init] best rec loss: 0.8762943744659424 for ['[CLS] negotiationsris deemedtment prohibition wine holdingyn divorced within [SEP]']
[Init] best rec loss: 0.8745788335800171 for ['[CLS] trevor leader piercing starting goal generating richest beside port though [SEP]']
[Init] best rec loss: 0.8649548888206482 for ['[CLS] december hit leisure journey none sinclair ras chaos whereby burke [SEP]']
[Init] best rec loss: 0.864183247089386 for ['[CLS] throughraße opposingpressed salvationat hingesirus fort survey [SEP]']
[Init] best rec loss: 0.8636577129364014 for ['[CLS] ballads snoop republic heart bryan morale basket old aquatics academy [SEP]']
[Init] best rec loss: 0.8481337428092957 for ['[CLS] retro en correctly top pitch my leads august got look [SEP]']
[Init] best rec loss: 0.8422923684120178 for ['[CLS] high helping beat agra polite threw morning temperatures gustave tanks [SEP]']
[Init] best rec loss: 0.8355159759521484 for ['[CLS]rollerđ seam census mainbread appear solo cop craft [SEP]']
[Init] best perm rec loss: 0.8347834348678589 for ['[CLS] solo craft seamroller appear census copđbread main [SEP]']
[Init] best perm rec loss: 0.8339194059371948 for ['[CLS]roller cop craft appear solobread seam main censusđ [SEP]']
[Init] best perm rec loss: 0.8332030773162842 for ['[CLS]bread seam main census cop soloroller craft appearđ [SEP]']
[Init] best perm rec loss: 0.8314569592475891 for ['[CLS] census main appearbread solo seamđroller cop craft [SEP]']
[Init] best perm rec loss: 0.8308893442153931 for ['[CLS] craft seam solo main appearđrollerbread census cop [SEP]']
[Init] best perm rec loss: 0.8308157324790955 for ['[CLS]đ coproller solobread seam appear main craft census [SEP]']
[Init] best perm rec loss: 0.8294724225997925 for ['[CLS] copbreadroller main craft seamđ appear census solo [SEP]']
[Init] best perm rec loss: 0.8291884660720825 for ['[CLS] cop solo craft mainrollerbread appearđ seam census [SEP]']
[Init] best perm rec loss: 0.8288834095001221 for ['[CLS] craft seam cop census soloroller mainbreadđ appear [SEP]']
[Init] best perm rec loss: 0.8288081884384155 for ['[CLS]đbread craft appearroller main solo seam cop census [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.446 (perp=9.610, rec=0.327, cos=0.197), tot_loss_proj:3.757 [t=0.23s]
prediction: ['[CLS] john the. researchers. need noticed. develop jon [SEP]']
[ 100/2000] tot_loss=2.330 (perp=8.660, rec=0.398, cos=0.200), tot_loss_proj:3.555 [t=0.23s]
prediction: ['[CLS] john john.. sees increased excessive. great john [SEP]']
[ 150/2000] tot_loss=2.303 (perp=9.074, rec=0.285, cos=0.203), tot_loss_proj:3.575 [t=0.23s]
prediction: ['[CLS] john john h. noticed authority excessive. great john [SEP]']
[ 200/2000] tot_loss=2.394 (perp=9.838, rec=0.221, cos=0.205), tot_loss_proj:3.796 [t=0.23s]
prediction: ['[CLS] mary john saw. noticed appreciation excessive. great john [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.453 (perp=10.034, rec=0.241, cos=0.205), tot_loss_proj:3.842 [t=0.23s]
prediction: ['[CLS] mary john.phobia john appreciation s, great noticed [SEP]']
[ 300/2000] tot_loss=1.967 (perp=7.851, rec=0.189, cos=0.207), tot_loss_proj:3.458 [t=0.23s]
prediction: ['[CLS] mary john.. john appreciation s. great noticed [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.131 (perp=8.817, rec=0.161, cos=0.207), tot_loss_proj:3.596 [t=0.23s]
prediction: ['[CLS] john john excessive. mary appreciation s. great noticed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.127 (perp=8.817, rec=0.156, cos=0.208), tot_loss_proj:3.592 [t=0.23s]
prediction: ['[CLS] john john excessive. mary appreciation s. great noticed [SEP]']
[ 450/2000] tot_loss=2.111 (perp=8.817, rec=0.138, cos=0.209), tot_loss_proj:3.593 [t=0.23s]
prediction: ['[CLS] john john excessive. mary appreciation s. great noticed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.389 (perp=10.269, rec=0.130, cos=0.206), tot_loss_proj:3.851 [t=0.23s]
prediction: ['[CLS] john john excessive. mary appreciation s himself great noticed [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.399 (perp=10.313, rec=0.131, cos=0.205), tot_loss_proj:3.833 [t=0.23s]
prediction: ["[CLS] john'excessive excessive s appreciation mary himself great noticed [SEP]"]
[ 600/2000] tot_loss=2.387 (perp=10.313, rec=0.119, cos=0.205), tot_loss_proj:3.840 [t=0.23s]
prediction: ["[CLS] john'excessive excessive s appreciation mary himself great noticed [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.081 (perp=8.877, rec=0.105, cos=0.201), tot_loss_proj:3.618 [t=0.23s]
prediction: ["[CLS] john's excessive excessive appreciation mary himself great noticed [SEP]"]
Attempt swap
[ 700/2000] tot_loss=2.089 (perp=8.877, rec=0.112, cos=0.202), tot_loss_proj:3.616 [t=0.23s]
prediction: ["[CLS] john's excessive excessive appreciation mary himself great noticed [SEP]"]
[ 750/2000] tot_loss=2.116 (perp=9.049, rec=0.104, cos=0.203), tot_loss_proj:3.593 [t=0.23s]
prediction: ["[CLS] john's. excessive appreciation mary himself great noticed [SEP]"]
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.133 (perp=9.122, rec=0.106, cos=0.203), tot_loss_proj:3.595 [t=0.23s]
prediction: ["[CLS] john's excessive. appreciation mary himself great noticed [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.828 (perp=7.605, rec=0.103, cos=0.205), tot_loss_proj:3.374 [t=0.23s]
prediction: ["[CLS] john's excessive appreciation of mary himself great noticed [SEP]"]
[ 900/2000] tot_loss=1.826 (perp=7.605, rec=0.103, cos=0.203), tot_loss_proj:3.373 [t=0.23s]
prediction: ["[CLS] john's excessive appreciation of mary himself great noticed [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.745 (perp=7.267, rec=0.092, cos=0.199), tot_loss_proj:3.309 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.760 (perp=7.267, rec=0.106, cos=0.201), tot_loss_proj:3.314 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
[1050/2000] tot_loss=1.760 (perp=7.267, rec=0.106, cos=0.201), tot_loss_proj:3.313 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.744 (perp=7.267, rec=0.089, cos=0.201), tot_loss_proj:3.311 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.748 (perp=7.267, rec=0.093, cos=0.201), tot_loss_proj:3.311 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
[1200/2000] tot_loss=1.752 (perp=7.267, rec=0.097, cos=0.201), tot_loss_proj:3.312 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.740 (perp=7.267, rec=0.086, cos=0.201), tot_loss_proj:3.308 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.751 (perp=7.267, rec=0.096, cos=0.201), tot_loss_proj:3.313 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
[1350/2000] tot_loss=1.747 (perp=7.267, rec=0.093, cos=0.201), tot_loss_proj:3.310 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.742 (perp=7.267, rec=0.088, cos=0.201), tot_loss_proj:3.307 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.751 (perp=7.267, rec=0.097, cos=0.201), tot_loss_proj:3.313 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
[1500/2000] tot_loss=1.745 (perp=7.267, rec=0.091, cos=0.201), tot_loss_proj:3.312 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.746 (perp=7.267, rec=0.092, cos=0.201), tot_loss_proj:3.314 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.752 (perp=7.267, rec=0.097, cos=0.201), tot_loss_proj:3.312 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
[1650/2000] tot_loss=1.745 (perp=7.267, rec=0.091, cos=0.201), tot_loss_proj:3.314 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.752 (perp=7.267, rec=0.098, cos=0.201), tot_loss_proj:3.311 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.741 (perp=7.267, rec=0.087, cos=0.201), tot_loss_proj:3.309 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
[1800/2000] tot_loss=1.745 (perp=7.267, rec=0.091, cos=0.201), tot_loss_proj:3.316 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.746 (perp=7.267, rec=0.092, cos=0.201), tot_loss_proj:3.316 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.746 (perp=7.267, rec=0.091, cos=0.201), tot_loss_proj:3.316 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
[1950/2000] tot_loss=1.746 (perp=7.267, rec=0.091, cos=0.201), tot_loss_proj:3.310 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.752 (perp=7.267, rec=0.098, cos=0.201), tot_loss_proj:3.310 [t=0.23s]
prediction: ["[CLS] mary's excessive appreciation of john himself strange noticed [SEP]"]
Done with input #47 of 100.
reference: 
========================
[CLS] mary noticed john's excessive appreciation of himself. [SEP]
========================
predicted: 
========================
[CLS] mary's excessive appreciation of john himself strange noticed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 42.105 | p: 40.000 | r: 44.444
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 137.343

[Aggregate metrics]:
rouge1     | fm: 87.394 | p: 87.122 | r: 87.848
rouge2     | fm: 50.321 | p: 50.026 | r: 50.735
rougeL     | fm: 76.705 | p: 76.560 | r: 77.076
rougeLsum  | fm: 76.886 | p: 76.626 | r: 77.303
r1fm+r2fm = 137.715

input #47 time: 0:09:10 | total time: 7:16:27


Running input #48 of 100.
reference: 
========================
John tagged Lewis with a regulation baseball on Tuesday.
========================
average of cosine similarity 0.9019957935328283
highest_index [0]
highest [0.9019957935328283]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198, 26610,  4572,  2007,  1037,  7816,  3598,  2006,  9857,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]']
[Init] best rec loss: 0.9536641240119934 for ['[CLS]... spit opening tolerant lie officer 3rd wiener true li [SEP]']
[Init] best rec loss: 0.9160335063934326 for ['[CLS] stunt exclusively since bear toss temple calings whispers claimed [SEP]']
[Init] best rec loss: 0.9108930230140686 for ['[CLS]leigh created executive factor believed high professionally sinclair kevin bailey [SEP]']
[Init] best rec loss: 0.8917879462242126 for ['[CLS] nano dat pattern passingrity basis roll skating msc practice [SEP]']
[Init] best rec loss: 0.8488773703575134 for ['[CLS] camp fused tunnel ufc curse portage simply after audiohorn [SEP]']
[Init] best rec loss: 0.8242390155792236 for ['[CLS] pressure nun straitiahggs films circle suggests final throat [SEP]']
[Init] best perm rec loss: 0.8217313885688782 for ['[CLS]ggs nun pressure circle final strait filmsiah suggests throat [SEP]']
[Init] best perm rec loss: 0.8215354084968567 for ['[CLS] pressure nuniahggs circle strait suggests final films throat [SEP]']
[Init] best perm rec loss: 0.8214629888534546 for ['[CLS] suggestsiahggs final pressure nun films strait throat circle [SEP]']
[Init] best perm rec loss: 0.8202974796295166 for ['[CLS] circle pressureggs straitiah suggests films throat nun final [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.289 (perp=13.627, rec=0.405, cos=0.158), tot_loss_proj:4.619 [t=0.23s]
prediction: ['[CLS] uncle wyatt attract usually du friday similar target civilian revolt [SEP]']
[ 100/2000] tot_loss=2.937 (perp=11.711, rec=0.394, cos=0.200), tot_loss_proj:4.244 [t=0.23s]
prediction: ['[CLS]vot bombers tagged ; zone daemon similar balanced ( in [SEP]']
[ 150/2000] tot_loss=2.586 (perp=10.423, rec=0.305, cos=0.197), tot_loss_proj:3.952 [t=0.23s]
prediction: ['[CLS] cardboard hunting tagged ; tagged lewis with with traditional baseball [SEP]']
[ 200/2000] tot_loss=2.553 (perp=10.575, rec=0.243, cos=0.194), tot_loss_proj:3.983 [t=0.23s]
prediction: ['[CLS] battle hunting tagged. regulation lewis with with baseball baseball [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.411 (perp=10.204, rec=0.206, cos=0.164), tot_loss_proj:3.919 [t=0.23s]
prediction: ['[CLS] lewis bishop tagged john regulation silver with with regulation baseball [SEP]']
[ 300/2000] tot_loss=2.399 (perp=10.204, rec=0.177, cos=0.181), tot_loss_proj:3.916 [t=0.23s]
prediction: ['[CLS] lewis bishop tagged john regulation silver with with regulation baseball [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.296 (perp=9.705, rec=0.164, cos=0.191), tot_loss_proj:3.782 [t=0.23s]
prediction: ['[CLS] lewis bishop tagged john regulation with silver with regulation baseball [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.155 (perp=9.195, rec=0.157, cos=0.159), tot_loss_proj:3.445 [t=0.23s]
prediction: ['[CLS] lewis bishop tagged john with silver with regulation baseball regulation [SEP]']
[ 450/2000] tot_loss=2.508 (perp=10.913, rec=0.142, cos=0.184), tot_loss_proj:3.857 [t=0.23s]
prediction: ['[CLS] lewishand tagged john in silver with regulation baseball regulation [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.338 (perp=10.114, rec=0.137, cos=0.179), tot_loss_proj:3.561 [t=0.23s]
prediction: ['[CLS] lewis silver tagged john inhand with regulation baseball regulation [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.151 (perp=9.054, rec=0.148, cos=0.192), tot_loss_proj:3.597 [t=0.23s]
prediction: ['[CLS] john lewis silver tagged on. with regulation baseball regulation [SEP]']
[ 600/2000] tot_loss=2.233 (perp=9.591, rec=0.133, cos=0.182), tot_loss_proj:3.654 [t=0.23s]
prediction: ['[CLS] john lewis silver tagged onhand with regulation baseball friday [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.267 (perp=9.841, rec=0.128, cos=0.171), tot_loss_proj:3.717 [t=0.23s]
prediction: ['[CLS] john lewis silver tagged on. with regulation baseball friday [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.942 (perp=8.158, rec=0.122, cos=0.189), tot_loss_proj:3.338 [t=0.23s]
prediction: ['[CLS] john lewis silver tagged on friday with regulation baseball. [SEP]']
[ 750/2000] tot_loss=1.937 (perp=8.158, rec=0.125, cos=0.181), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] john lewis silver tagged on friday with regulation baseball. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.893 (perp=7.871, rec=0.126, cos=0.194), tot_loss_proj:2.445 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on friday with regulation baseball. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.890 (perp=7.961, rec=0.116, cos=0.182), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
[ 900/2000] tot_loss=1.884 (perp=7.961, rec=0.109, cos=0.184), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.881 (perp=7.961, rec=0.106, cos=0.183), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.880 (perp=7.961, rec=0.109, cos=0.178), tot_loss_proj:2.409 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
[1050/2000] tot_loss=1.879 (perp=7.961, rec=0.106, cos=0.181), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.885 (perp=7.961, rec=0.110, cos=0.183), tot_loss_proj:2.409 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.881 (perp=7.961, rec=0.103, cos=0.185), tot_loss_proj:2.413 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
[1200/2000] tot_loss=1.891 (perp=7.961, rec=0.115, cos=0.184), tot_loss_proj:2.411 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.880 (perp=7.961, rec=0.109, cos=0.179), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.878 (perp=7.961, rec=0.102, cos=0.183), tot_loss_proj:2.411 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
[1350/2000] tot_loss=1.893 (perp=7.961, rec=0.115, cos=0.185), tot_loss_proj:2.410 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.886 (perp=7.961, rec=0.108, cos=0.186), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.869 (perp=7.961, rec=0.092, cos=0.184), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
[1500/2000] tot_loss=1.878 (perp=7.961, rec=0.101, cos=0.185), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.875 (perp=7.961, rec=0.097, cos=0.186), tot_loss_proj:2.408 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.888 (perp=7.961, rec=0.109, cos=0.187), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
[1650/2000] tot_loss=1.883 (perp=7.961, rec=0.104, cos=0.186), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.876 (perp=7.961, rec=0.098, cos=0.186), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.885 (perp=7.961, rec=0.107, cos=0.185), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
[1800/2000] tot_loss=1.873 (perp=7.961, rec=0.095, cos=0.186), tot_loss_proj:2.413 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.889 (perp=7.961, rec=0.109, cos=0.187), tot_loss_proj:2.410 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.878 (perp=7.961, rec=0.099, cos=0.187), tot_loss_proj:2.412 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
[1950/2000] tot_loss=1.883 (perp=7.961, rec=0.105, cos=0.186), tot_loss_proj:2.409 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.871 (perp=7.961, rec=0.092, cos=0.186), tot_loss_proj:2.412 [t=0.23s]
prediction: ['[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]
========================
predicted: 
========================
[CLS] john lewis tagged silver on tuesday with regulation baseball. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 120.909

[Aggregate metrics]:
rouge1     | fm: 87.498 | p: 87.209 | r: 87.950
rouge2     | fm: 50.063 | p: 49.781 | r: 50.491
rougeL     | fm: 76.463 | p: 76.330 | r: 76.792
rougeLsum  | fm: 76.622 | p: 76.357 | r: 76.962
r1fm+r2fm = 137.561

input #48 time: 0:09:10 | total time: 7:25:37


Running input #49 of 100.
reference: 
========================
We all thought him to be unhappy
========================
average of cosine similarity 0.9243574353485532
highest_index [0]
highest [0.9243574353485532]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2057,  2035,  2245,  2032,  2000,  2022, 12511,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] we all thought him to be unhappy [SEP]']
[Init] best rec loss: 0.8839224576950073 for ['[CLS] mattermei visibly port brandenburgmissive le [SEP]']
[Init] best rec loss: 0.878559410572052 for ['[CLS] hard report patients such af on knees [SEP]']
[Init] best rec loss: 0.857045590877533 for ['[CLS] alpha ago aw questions cherry to plan [SEP]']
[Init] best rec loss: 0.8387075662612915 for ['[CLS] springs society military deliver part holocaustuch [SEP]']
[Init] best rec loss: 0.8285262584686279 for ['[CLS] topping origin goes terrible discouraged arrived smart [SEP]']
[Init] best rec loss: 0.8112255930900574 for ['[CLS] central ren cabin meritorescence method minor [SEP]']
[Init] best perm rec loss: 0.8106707334518433 for ['[CLS] minor ren merit cabinorescence method central [SEP]']
[Init] best perm rec loss: 0.8086747527122498 for ['[CLS] minor central cabin merit ren methodorescence [SEP]']
[Init] best perm rec loss: 0.8086676001548767 for ['[CLS] cabinorescence minor merit ren method central [SEP]']
[Init] best perm rec loss: 0.8085000514984131 for ['[CLS] merit central method cabin minor renorescence [SEP]']
[Init] best perm rec loss: 0.8077918887138367 for ['[CLS] methodorescence merit minor cabin ren central [SEP]']
[Init] best perm rec loss: 0.8075685501098633 for ['[CLS] ren centralorescence merit cabin method minor [SEP]']
[Init] best perm rec loss: 0.806868314743042 for ['[CLS] cabin method central minor ren meritorescence [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.749 (perp=10.684, rec=0.469, cos=0.143), tot_loss_proj:4.005 [t=0.23s]
prediction: ['[CLS] negative always says what genome duty bound [SEP]']
[ 100/2000] tot_loss=2.829 (perp=11.340, rec=0.413, cos=0.148), tot_loss_proj:4.178 [t=0.23s]
prediction: ['[CLS] negative him thought if nor emotion concern [SEP]']
[ 150/2000] tot_loss=2.537 (perp=10.479, rec=0.290, cos=0.151), tot_loss_proj:3.988 [t=0.23s]
prediction: ['[CLS] yellow him thought all unhappy unhappy unhappy [SEP]']
[ 200/2000] tot_loss=2.394 (perp=10.219, rec=0.225, cos=0.125), tot_loss_proj:3.906 [t=0.23s]
prediction: ['[CLS] his him thought all unhappy unhappy unhappy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.634 (perp=10.141, rec=0.398, cos=0.208), tot_loss_proj:3.887 [t=0.23s]
prediction: ['[CLS] western we thought him where unhappy unhappy [SEP]']
[ 300/2000] tot_loss=2.670 (perp=11.006, rec=0.296, cos=0.172), tot_loss_proj:3.961 [t=0.23s]
prediction: ['[CLS] rebirth all thought him to unhappy badly [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.301 (perp=9.552, rec=0.248, cos=0.143), tot_loss_proj:3.687 [t=0.23s]
prediction: ['[CLS] to all thought him unhappy unhappy unhappy [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.277 (perp=9.552, rec=0.228, cos=0.139), tot_loss_proj:3.687 [t=0.23s]
prediction: ['[CLS] to all thought him unhappy unhappy unhappy [SEP]']
[ 450/2000] tot_loss=2.279 (perp=9.675, rec=0.203, cos=0.141), tot_loss_proj:3.720 [t=0.23s]
prediction: ['[CLS] to all thought him unhappy unhappy things [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.962 (perp=8.139, rec=0.190, cos=0.145), tot_loss_proj:3.374 [t=0.23s]
prediction: ['[CLS] unhappy all thought him unhappy to be [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.900 (perp=7.812, rec=0.198, cos=0.139), tot_loss_proj:3.327 [t=0.23s]
prediction: ['[CLS] all unhappy thought him unhappy to be [SEP]']
[ 600/2000] tot_loss=1.891 (perp=7.812, rec=0.186, cos=0.142), tot_loss_proj:3.326 [t=0.23s]
prediction: ['[CLS] all unhappy thought him unhappy to be [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.751 (perp=7.138, rec=0.184, cos=0.139), tot_loss_proj:3.115 [t=0.23s]
prediction: ['[CLS] all unhappy thought him to be unhappy [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.643 (perp=6.545, rec=0.170, cos=0.164), tot_loss_proj:2.460 [t=0.23s]
prediction: ['[CLS] all already thought him to be unhappy [SEP]']
[ 750/2000] tot_loss=1.699 (perp=6.910, rec=0.175, cos=0.142), tot_loss_proj:3.184 [t=0.23s]
prediction: ['[CLS] all be thought him to be unhappy [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.622 (perp=6.543, rec=0.172, cos=0.141), tot_loss_proj:3.217 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.603 (perp=6.543, rec=0.157, cos=0.138), tot_loss_proj:3.220 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
[ 900/2000] tot_loss=1.616 (perp=6.543, rec=0.168, cos=0.140), tot_loss_proj:3.218 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.599 (perp=6.543, rec=0.143, cos=0.147), tot_loss_proj:3.219 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=6.543, rec=0.137, cos=0.142), tot_loss_proj:3.217 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
[1050/2000] tot_loss=1.615 (perp=6.543, rec=0.166, cos=0.141), tot_loss_proj:3.219 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.598 (perp=6.543, rec=0.145, cos=0.144), tot_loss_proj:3.200 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.623 (perp=6.543, rec=0.175, cos=0.139), tot_loss_proj:3.206 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
[1200/2000] tot_loss=1.592 (perp=6.543, rec=0.136, cos=0.148), tot_loss_proj:3.210 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.585 (perp=6.543, rec=0.132, cos=0.144), tot_loss_proj:3.214 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.613 (perp=6.543, rec=0.165, cos=0.139), tot_loss_proj:3.214 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
[1350/2000] tot_loss=1.586 (perp=6.543, rec=0.131, cos=0.146), tot_loss_proj:3.206 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.575 (perp=6.543, rec=0.123, cos=0.144), tot_loss_proj:3.211 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.577 (perp=6.543, rec=0.125, cos=0.143), tot_loss_proj:3.216 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
[1500/2000] tot_loss=1.574 (perp=6.543, rec=0.120, cos=0.146), tot_loss_proj:3.206 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.567 (perp=6.543, rec=0.114, cos=0.144), tot_loss_proj:3.209 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.579 (perp=6.543, rec=0.125, cos=0.146), tot_loss_proj:3.214 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
[1650/2000] tot_loss=1.577 (perp=6.543, rec=0.123, cos=0.145), tot_loss_proj:3.215 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.576 (perp=6.543, rec=0.123, cos=0.144), tot_loss_proj:3.214 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.566 (perp=6.543, rec=0.112, cos=0.145), tot_loss_proj:3.213 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
[1800/2000] tot_loss=1.566 (perp=6.543, rec=0.112, cos=0.145), tot_loss_proj:3.214 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.566 (perp=6.543, rec=0.112, cos=0.145), tot_loss_proj:3.212 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.578 (perp=6.543, rec=0.124, cos=0.145), tot_loss_proj:3.209 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
[1950/2000] tot_loss=1.577 (perp=6.543, rec=0.123, cos=0.146), tot_loss_proj:3.211 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.576 (perp=6.543, rec=0.122, cos=0.145), tot_loss_proj:3.213 [t=0.23s]
prediction: ['[CLS] all thought be him to be unhappy [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] we all thought him to be unhappy [SEP]
========================
predicted: 
========================
[CLS] all thought be him to be unhappy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 151.389

[Aggregate metrics]:
rouge1     | fm: 87.509 | p: 87.259 | r: 87.985
rouge2     | fm: 50.252 | p: 49.952 | r: 50.609
rougeL     | fm: 76.714 | p: 76.478 | r: 77.106
rougeLsum  | fm: 76.847 | p: 76.595 | r: 77.229
r1fm+r2fm = 137.761

input #49 time: 0:09:10 | total time: 7:34:47


Running input #50 of 100.
reference: 
========================
Book is available in most countries.
========================
average of cosine similarity 0.8906809434580379
highest_index [0]
highest [0.8906809434580379]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2338, 2003, 2800, 1999, 2087, 3032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] book is available in most countries. [SEP]']
[Init] best rec loss: 0.7505773901939392 for ['[CLS] keyxy neither jenksuka chow administration [SEP]']
[Init] best rec loss: 0.7501561045646667 for ['[CLS] rider was approvedclass bis representation by [SEP]']
[Init] best rec loss: 0.7428613901138306 for ['[CLS] rev vaughn debut inspiration theme mind wonder [SEP]']
[Init] best rec loss: 0.7401911616325378 for ['[CLS] tapes [SEP] stronger u part radio tropical [SEP]']
[Init] best rec loss: 0.7352604269981384 for ['[CLS] heat hulkmakers dq orthodoxrin really [SEP]']
[Init] best rec loss: 0.7066635489463806 for ['[CLS] ticketscular quickly spot digit itrain [SEP]']
[Init] best rec loss: 0.6769715547561646 for ['[CLS]ers quality thereafter small conversations gaius sven [SEP]']
[Init] best perm rec loss: 0.6715067028999329 for ['[CLS] thereafter sven gaius small conversations qualityers [SEP]']
[Init] best perm rec loss: 0.6692031025886536 for ['[CLS] smallers gaius thereafter sven quality conversations [SEP]']
[Init] best perm rec loss: 0.6668630838394165 for ['[CLS] small thereafter conversations sven gaius qualityers [SEP]']
[Init] best perm rec loss: 0.6597086191177368 for ['[CLS] sven small qualityers gaius thereafter conversations [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.415 (perp=9.816, rec=0.242, cos=0.210), tot_loss_proj:2.951 [t=0.23s]
prediction: ['[CLS] book available. countries publishing min book [SEP]']
[ 100/2000] tot_loss=2.145 (perp=8.826, rec=0.165, cos=0.214), tot_loss_proj:2.861 [t=0.23s]
prediction: ['[CLS] book available. countries available lion book [SEP]']
[ 150/2000] tot_loss=2.241 (perp=9.507, rec=0.132, cos=0.208), tot_loss_proj:2.895 [t=0.23s]
prediction: ['[CLS] book available is european countrieswater for [SEP]']
[ 200/2000] tot_loss=1.828 (perp=7.682, rec=0.087, cos=0.204), tot_loss_proj:2.646 [t=0.23s]
prediction: ['[CLS] book available is most countries.. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.668 (perp=6.928, rec=0.078, cos=0.205), tot_loss_proj:2.061 [t=0.23s]
prediction: ['[CLS] book is available most countries.. [SEP]']
[ 300/2000] tot_loss=1.666 (perp=6.928, rec=0.075, cos=0.205), tot_loss_proj:2.050 [t=0.23s]
prediction: ['[CLS] book is available most countries.. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.069 (perp=3.887, rec=0.089, cos=0.203), tot_loss_proj:1.094 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.048 (perp=3.887, rec=0.067, cos=0.204), tot_loss_proj:1.093 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[ 450/2000] tot_loss=1.047 (perp=3.887, rec=0.066, cos=0.204), tot_loss_proj:1.099 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.047 (perp=3.887, rec=0.065, cos=0.205), tot_loss_proj:1.089 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.046 (perp=3.887, rec=0.064, cos=0.205), tot_loss_proj:1.097 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[ 600/2000] tot_loss=1.051 (perp=3.887, rec=0.069, cos=0.205), tot_loss_proj:1.098 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.042 (perp=3.887, rec=0.059, cos=0.205), tot_loss_proj:1.086 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.042 (perp=3.887, rec=0.059, cos=0.205), tot_loss_proj:1.077 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[ 750/2000] tot_loss=1.039 (perp=3.887, rec=0.056, cos=0.205), tot_loss_proj:1.080 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.036 (perp=3.887, rec=0.053, cos=0.206), tot_loss_proj:1.092 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.044 (perp=3.887, rec=0.062, cos=0.205), tot_loss_proj:1.104 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[ 900/2000] tot_loss=1.044 (perp=3.887, rec=0.060, cos=0.206), tot_loss_proj:1.091 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.037 (perp=3.887, rec=0.054, cos=0.206), tot_loss_proj:1.086 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.051 (perp=3.887, rec=0.067, cos=0.206), tot_loss_proj:1.099 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1050/2000] tot_loss=1.048 (perp=3.887, rec=0.065, cos=0.206), tot_loss_proj:1.097 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.052 (perp=3.887, rec=0.069, cos=0.206), tot_loss_proj:1.086 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.036 (perp=3.887, rec=0.052, cos=0.206), tot_loss_proj:1.095 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1200/2000] tot_loss=1.042 (perp=3.887, rec=0.059, cos=0.206), tot_loss_proj:1.103 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.045 (perp=3.887, rec=0.062, cos=0.206), tot_loss_proj:1.093 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.044 (perp=3.887, rec=0.061, cos=0.206), tot_loss_proj:1.088 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1350/2000] tot_loss=1.041 (perp=3.887, rec=0.058, cos=0.206), tot_loss_proj:1.105 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.041 (perp=3.887, rec=0.058, cos=0.206), tot_loss_proj:1.096 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.050 (perp=3.887, rec=0.067, cos=0.206), tot_loss_proj:1.090 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1500/2000] tot_loss=1.038 (perp=3.887, rec=0.055, cos=0.206), tot_loss_proj:1.098 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.049 (perp=3.887, rec=0.066, cos=0.206), tot_loss_proj:1.088 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.039 (perp=3.887, rec=0.056, cos=0.206), tot_loss_proj:1.092 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1650/2000] tot_loss=1.044 (perp=3.887, rec=0.060, cos=0.206), tot_loss_proj:1.102 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.038 (perp=3.887, rec=0.054, cos=0.206), tot_loss_proj:1.087 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.042 (perp=3.887, rec=0.059, cos=0.206), tot_loss_proj:1.102 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1800/2000] tot_loss=1.035 (perp=3.887, rec=0.051, cos=0.206), tot_loss_proj:1.106 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.035 (perp=3.887, rec=0.052, cos=0.206), tot_loss_proj:1.088 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.048 (perp=3.887, rec=0.064, cos=0.206), tot_loss_proj:1.084 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1950/2000] tot_loss=1.035 (perp=3.887, rec=0.052, cos=0.206), tot_loss_proj:1.079 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.050 (perp=3.887, rec=0.067, cos=0.206), tot_loss_proj:1.098 [t=0.23s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] book is available in most countries. [SEP]
========================
predicted: 
========================
[CLS] book is available in most countries. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.744 | p: 87.499 | r: 88.213
rouge2     | fm: 51.185 | p: 50.968 | r: 51.584
rougeL     | fm: 77.049 | p: 76.902 | r: 77.442
rougeLsum  | fm: 77.233 | p: 77.006 | r: 77.634
r1fm+r2fm = 138.929

input #50 time: 0:09:10 | total time: 7:43:57


Running input #51 of 100.
reference: 
========================
I could have little known that more trouble was just around the corner.
========================
average of cosine similarity 0.9319777442897352
highest_index [0]
highest [0.9319777442897352]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2071, 2031, 2210, 2124, 2008, 2062, 4390, 2001, 2074, 2105,
         1996, 3420, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i could have little known that more trouble was just around the corner. [SEP]']
[Init] best rec loss: 0.976054310798645 for ['[CLS] missing coincidence ten ideas gas need status singleton silver considered demolished tale convert grumbled [SEP]']
[Init] best rec loss: 0.9417542815208435 for ['[CLS] clshfalls chicago walled steps turn photos tell covers yet letter xx table [SEP]']
[Init] best rec loss: 0.9199807047843933 for ['[CLS] individual serving mediterraneanwylwart date touchwest mined styx pot barefoot buttonilla [SEP]']
[Init] best rec loss: 0.9147045016288757 for ['[CLS] mina back rot release called yes half [SEP] commercialuru startutunt hell [SEP]']
[Init] best rec loss: 0.8829779624938965 for ['[CLS] foreign a retirement electedheadborough rising passenger wanda publishing graduates tor special mill [SEP]']
[Init] best perm rec loss: 0.8825201392173767 for ['[CLS] mill foreignborough elected torhead publishing special retirement wanda passenger a graduates rising [SEP]']
[Init] best perm rec loss: 0.8812288641929626 for ['[CLS] electedhead wanda publishing mill rising aborough retirement graduates foreign tor special passenger [SEP]']
[Init] best perm rec loss: 0.8762885928153992 for ['[CLS] graduateshead special a retirement wandaborough foreign mill publishing rising elected tor passenger [SEP]']
[Init] best perm rec loss: 0.8754844665527344 for ['[CLS] mill wanda special elected foreign publishinghead tor retirementborough graduates rising passenger a [SEP]']
[Init] best perm rec loss: 0.8736938834190369 for ['[CLS]borough wanda ahead mill retirement tor foreign publishing passenger rising graduates elected special [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.160 (perp=12.560, rec=0.648, cos=1.000), tot_loss_proj:4.389 [t=0.23s]
prediction: ['[CLS] jade duke mike admitted eliminated shove feed newscc to.load store rack [SEP]']
[ 100/2000] tot_loss=3.836 (perp=11.392, rec=0.567, cos=0.991), tot_loss_proj:4.156 [t=0.23s]
prediction: ['[CLS] quarter delta tony think eliminated [SEP] ground news ap.. involving used coach [SEP]']
[ 150/2000] tot_loss=3.254 (perp=12.223, rec=0.532, cos=0.277), tot_loss_proj:4.289 [t=0.23s]
prediction: ['[CLS] quarter impact tony think greg that news risk trouble were. especially time coach [SEP]']
[ 200/2000] tot_loss=4.038 (perp=10.915, rec=0.855, cos=0.999), tot_loss_proj:4.067 [t=0.23s]
prediction: ['[CLS] years half zach knewtones has relief raid trouble behind. have time coach [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.663 (perp=12.795, rec=0.643, cos=0.461), tot_loss_proj:4.421 [t=0.23s]
prediction: ['[CLS] years city scotia reaction knewstad has relief raid alisonington care left control [SEP]']
[ 300/2000] tot_loss=3.327 (perp=12.368, rec=0.576, cos=0.277), tot_loss_proj:4.326 [t=0.23s]
prediction: ['[CLS] years city scotia already knewstad present relief raid pressureving care, control [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.537 (perp=13.944, rec=0.559, cos=0.190), tot_loss_proj:4.653 [t=0.23s]
prediction: ['[CLS] years city opinion already knew proceeds present scotia raidrdial increasingru lunch control [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.087 (perp=12.155, rec=0.514, cos=0.142), tot_loss_proj:4.323 [t=0.23s]
prediction: ['[CLS] around city either already knew proceeds present scotia raidons increasingru. control [SEP]']
[ 450/2000] tot_loss=3.268 (perp=13.273, rec=0.480, cos=0.134), tot_loss_proj:4.564 [t=0.23s]
prediction: ['[CLS] around city either bastard knew proceeds present scotiaworldons troubleru. control [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.162 (perp=12.884, rec=0.458, cos=0.127), tot_loss_proj:4.447 [t=0.23s]
prediction: ['[CLS] around air proceeds opinion bastard knew present scotiaworld economies troubleru. formation [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.059 (perp=12.437, rec=0.456, cos=0.115), tot_loss_proj:4.363 [t=0.23s]
prediction: ['[CLS] behind air proceeds foreign bastard knew present scotiaworld economiesru trouble. addiction [SEP]']
[ 600/2000] tot_loss=3.142 (perp=12.889, rec=0.427, cos=0.138), tot_loss_proj:4.428 [t=0.23s]
prediction: ['[CLS] behind air proceeds foreign bastard knew present scotiaworld becauseru trouble more addiction [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=3.026 (perp=12.328, rec=0.430, cos=0.131), tot_loss_proj:4.322 [t=0.23s]
prediction: ['[CLS] behind air proceeds foreign bastard knew present scotiaru troubleworld because more addiction [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.119 (perp=12.890, rec=0.415, cos=0.126), tot_loss_proj:4.478 [t=0.23s]
prediction: ['[CLS] behind foreign immediately city bastard knew present scotiaru troubleworld because more addiction [SEP]']
[ 750/2000] tot_loss=3.156 (perp=13.011, rec=0.411, cos=0.143), tot_loss_proj:4.518 [t=0.23s]
prediction: ['[CLS] behind foreign immediately city bastard knew present scotiaru troubleworld dozens more addiction [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.927 (perp=11.988, rec=0.407, cos=0.123), tot_loss_proj:4.289 [t=0.23s]
prediction: ['[CLS] behind foreign city bastard immediately knew with scotiaru troubleworld dozens more addiction [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.710 (perp=10.939, rec=0.401, cos=0.120), tot_loss_proj:4.070 [t=0.23s]
prediction: ['[CLS] behind foreign bastard city immediately knew with scotia about troubleworld dozens more addiction [SEP]']
[ 900/2000] tot_loss=2.721 (perp=10.939, rec=0.403, cos=0.130), tot_loss_proj:4.072 [t=0.23s]
prediction: ['[CLS] behind foreign bastard city immediately knew with scotia about troubleworld dozens more addiction [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.643 (perp=10.554, rec=0.398, cos=0.134), tot_loss_proj:3.998 [t=0.23s]
prediction: ['[CLS] behind foreign trouble immediately knew with scotia city about troubleworld dozens more addiction [SEP]']
Attempt swap
[1000/2000] tot_loss=2.818 (perp=11.437, rec=0.393, cos=0.138), tot_loss_proj:4.199 [t=0.23s]
prediction: ['[CLS] cerambycidae foreign trouble immediately knew less scotia city about troubleworld dozens more addiction [SEP]']
[1050/2000] tot_loss=2.814 (perp=11.437, rec=0.389, cos=0.137), tot_loss_proj:4.199 [t=0.23s]
prediction: ['[CLS] cerambycidae foreign trouble immediately knew less scotia city about troubleworld dozens more addiction [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.858 (perp=11.738, rec=0.383, cos=0.127), tot_loss_proj:4.264 [t=0.23s]
prediction: ['[CLS] opinion underworld trouble immediately knew less scotia city about troubleworld dozens more addiction [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.910 (perp=11.975, rec=0.383, cos=0.131), tot_loss_proj:4.298 [t=0.23s]
prediction: ['[CLS] opinion warn trouble immediately knew less scotia city behind troubleworld dozens more addiction [SEP]']
[1200/2000] tot_loss=2.818 (perp=11.467, rec=0.389, cos=0.136), tot_loss_proj:4.204 [t=0.23s]
prediction: ['[CLS] opinion warn trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.731 (perp=11.152, rec=0.372, cos=0.129), tot_loss_proj:4.154 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
Attempt swap
[1300/2000] tot_loss=2.736 (perp=11.152, rec=0.376, cos=0.130), tot_loss_proj:4.155 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
[1350/2000] tot_loss=2.747 (perp=11.152, rec=0.389, cos=0.128), tot_loss_proj:4.156 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
Attempt swap
[1400/2000] tot_loss=2.725 (perp=11.152, rec=0.367, cos=0.128), tot_loss_proj:4.154 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
Attempt swap
[1450/2000] tot_loss=2.718 (perp=11.152, rec=0.366, cos=0.122), tot_loss_proj:4.152 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
[1500/2000] tot_loss=2.725 (perp=11.152, rec=0.366, cos=0.129), tot_loss_proj:4.152 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
Attempt swap
[1550/2000] tot_loss=2.730 (perp=11.152, rec=0.370, cos=0.130), tot_loss_proj:4.157 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
Attempt swap
[1600/2000] tot_loss=2.729 (perp=11.152, rec=0.366, cos=0.132), tot_loss_proj:4.158 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
[1650/2000] tot_loss=2.719 (perp=11.152, rec=0.358, cos=0.131), tot_loss_proj:4.153 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
Attempt swap
[1700/2000] tot_loss=2.726 (perp=11.152, rec=0.364, cos=0.131), tot_loss_proj:4.152 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
Attempt swap
[1750/2000] tot_loss=2.721 (perp=11.152, rec=0.361, cos=0.130), tot_loss_proj:4.156 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city underworld troubleworld dozens more is [SEP]']
[1800/2000] tot_loss=2.834 (perp=11.697, rec=0.364, cos=0.130), tot_loss_proj:4.245 [t=0.23s]
prediction: ['[CLS] warn opinion trouble immediately knew more scotia city bukit troubleworld dozens more is [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.743 (perp=11.187, rec=0.375, cos=0.130), tot_loss_proj:4.135 [t=0.23s]
prediction: ['[CLS] warn opinion trouble city immediately knew more scotia bukit troubleworld dozens more is [SEP]']
Attempt swap
[1900/2000] tot_loss=2.737 (perp=11.187, rec=0.370, cos=0.130), tot_loss_proj:4.130 [t=0.23s]
prediction: ['[CLS] warn opinion trouble city immediately knew more scotia bukit troubleworld dozens more is [SEP]']
[1950/2000] tot_loss=2.729 (perp=11.187, rec=0.361, cos=0.130), tot_loss_proj:4.132 [t=0.23s]
prediction: ['[CLS] warn opinion trouble city immediately knew more scotia bukit troubleworld dozens more is [SEP]']
Attempt swap
[2000/2000] tot_loss=2.732 (perp=11.187, rec=0.364, cos=0.131), tot_loss_proj:4.136 [t=0.23s]
prediction: ['[CLS] warn opinion trouble city immediately knew more scotia bukit troubleworld dozens more is [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] i could have little known that more trouble was just around the corner. [SEP]
========================
predicted: 
========================
[CLS] warn opinion trouble immediately knew more scotia city bukit troubleworld dozens more is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 26.667 | p: 26.667 | r: 26.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 20.000 | p: 20.000 | r: 20.000
rougeLsum  | fm: 20.000 | p: 20.000 | r: 20.000
r1fm+r2fm = 26.667

[Aggregate metrics]:
rouge1     | fm: 86.607 | p: 86.380 | r: 87.083
rouge2     | fm: 50.272 | p: 49.999 | r: 50.523
rougeL     | fm: 76.119 | p: 75.890 | r: 76.462
rougeLsum  | fm: 76.209 | p: 75.992 | r: 76.564
r1fm+r2fm = 136.878

input #51 time: 0:09:10 | total time: 7:53:08


Running input #52 of 100.
reference: 
========================
John gave the books to Mary at Christmas, and the records to Sue for her birthday.
========================
average of cosine similarity 0.8878083942860848
highest_index [0]
highest [0.8878083942860848]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2198, 2435, 1996, 2808, 2000, 2984, 2012, 4234, 1010, 1998, 1996,
         2636, 2000, 9790, 2005, 2014, 5798, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]']
[Init] best rec loss: 0.8955841660499573 for ['[CLS] drama establishments wicket vocal willem presence arm australia dashed guineaturn hand converse sparrow mastof hueymined [SEP]']
[Init] best rec loss: 0.8908147215843201 for ['[CLS] miller balancelined crawl net ramsay frost platform moved eachcial report lay reflecting # gray army contributed [SEP]']
[Init] best rec loss: 0.8840458393096924 for ['[CLS] semi disks chartersnesia glasses hearth while farm motto jack from enoughyr chamber "grass already steven [SEP]']
[Init] best rec loss: 0.8566646575927734 for ['[CLS] steven part port either isn loco held correspondence new nebraska first ad temporary lovely steele sawanza gone [SEP]']
[Init] best rec loss: 0.8549129962921143 for ['[CLS] box died measure with marksvision personal before different ag rs spade sober honor genversplify forgiveness [SEP]']
[Init] best rec loss: 0.8472737073898315 for ['[CLS] spelledback torch seminaruenrad responsible songp tuba [CLS] junior rails warrant wes * arts intruder [SEP]']
[Init] best rec loss: 0.8379476070404053 for ['[CLS] two becky mechanism lu hair processing undrafted play none yell wonder superior universal tasmanian lose copies through lease [SEP]']
[Init] best rec loss: 0.8358259201049805 for ['[CLS] blackszy grayson needing good dorian rio class and arizona anymoreous beginning duggrate requirestained minister [SEP]']
[Init] best perm rec loss: 0.8355127573013306 for ['[CLS] dorian arizonagrate anymore needing and goodtained requires dug beginning blacks ministerzy rio class graysonous [SEP]']
[Init] best perm rec loss: 0.8339598178863525 for ['[CLS] graysontained and good anymoreous needing beginning dorian requires blacks dug riogratezy minister arizona class [SEP]']
[Init] best perm rec loss: 0.8321508765220642 for ['[CLS] classzy duggratetained minister needing beginning good anymore blacks grayson arizona requiresous rio dorian and [SEP]']
[Init] best perm rec loss: 0.8296771049499512 for ['[CLS] good anymorezy arizona needingtained dorian blacks requires dug minister beginning grayson rioousgrate class and [SEP]']
[Init] best perm rec loss: 0.8288100957870483 for ['[CLS] class blacks minister grayson rio dorian needing dug good andtained anymoreous requires arizona beginninggratezy [SEP]']
[Init] best perm rec loss: 0.8284716010093689 for ['[CLS]tained beginning class anymore dug and good blacks requiresous dorian graysongrate minister rio needing arizonazy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.217 (perp=13.112, rec=0.410, cos=0.184), tot_loss_proj:4.446 [t=0.23s]
prediction: ['[CLS] lip hence plastic adventures clive and japanese sue,! william atlent pointing creates andrew judy potential [SEP]']
[ 100/2000] tot_loss=2.888 (perp=10.352, rec=0.364, cos=0.453), tot_loss_proj:3.903 [t=0.23s]
prediction: ['[CLS] mary was plastic books susannah and books sue for to john for sue christmas gave alice sue records [SEP]']
[ 150/2000] tot_loss=2.333 (perp=9.387, rec=0.260, cos=0.196), tot_loss_proj:3.632 [t=0.24s]
prediction: ['[CLS] john gave her books susannah and books sue records to sue for sue birthday gave alice sue for [SEP]']
[ 200/2000] tot_loss=2.132 (perp=8.558, rec=0.224, cos=0.197), tot_loss_proj:3.555 [t=0.24s]
prediction: ['[CLS] john gave her books susannah and books sue records to sue for sue birthday for birthday sue for [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.969 (perp=8.028, rec=0.158, cos=0.206), tot_loss_proj:3.445 [t=0.24s]
prediction: ['[CLS] john gave her books and records suenivorous records to sue for sue birthday for mary sue for [SEP]']
[ 300/2000] tot_loss=1.933 (perp=7.904, rec=0.152, cos=0.201), tot_loss_proj:3.451 [t=0.24s]
prediction: ['[CLS] john gave the books and records sue during the to sue for sue birthday for her sue for [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.992 (perp=8.392, rec=0.132, cos=0.181), tot_loss_proj:3.532 [t=0.24s]
prediction: ['[CLS] john gave the books and sue records christmas the to mary for sue birthday for her sue for [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.726 (perp=7.001, rec=0.128, cos=0.198), tot_loss_proj:3.220 [t=0.24s]
prediction: ['[CLS] john gave the books and sue records the christmas to mary for sue birthday for her sue. [SEP]']
[ 450/2000] tot_loss=1.826 (perp=7.439, rec=0.126, cos=0.212), tot_loss_proj:3.303 [t=0.24s]
prediction: ['[CLS] john gave the books and sue records the downstream to mary for sue birthday for her sue. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.769 (perp=7.224, rec=0.115, cos=0.210), tot_loss_proj:3.252 [t=0.24s]
prediction: ['[CLS] john gave the books and sue records the downstream for mary to sue birthday for her sue. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.975 (perp=8.343, rec=0.121, cos=0.185), tot_loss_proj:3.484 [t=0.24s]
prediction: ['[CLS] john gave the books and sue records the downstream for mary sue to birthday for her sue med [SEP]']
[ 600/2000] tot_loss=1.809 (perp=7.459, rec=0.109, cos=0.208), tot_loss_proj:3.310 [t=0.24s]
prediction: ['[CLS] john gave the books and records records the at for mary sue to birthday for her sue. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.717 (perp=7.068, rec=0.102, cos=0.201), tot_loss_proj:3.225 [t=0.24s]
prediction: ['[CLS] john gave the books and records records at for the mary sue to birthday for her sue. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.589 (perp=6.418, rec=0.107, cos=0.199), tot_loss_proj:3.087 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to birthday for her sue. [SEP]']
[ 750/2000] tot_loss=1.602 (perp=6.418, rec=0.109, cos=0.209), tot_loss_proj:3.082 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to birthday for her sue. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.592 (perp=6.418, rec=0.100, cos=0.209), tot_loss_proj:3.086 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to birthday for her sue. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.607 (perp=6.418, rec=0.117, cos=0.207), tot_loss_proj:3.085 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to birthday for her sue. [SEP]']
[ 900/2000] tot_loss=1.602 (perp=6.418, rec=0.109, cos=0.210), tot_loss_proj:3.087 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to birthday for her sue. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.595 (perp=6.418, rec=0.105, cos=0.207), tot_loss_proj:3.087 [t=0.30s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to birthday for her sue. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.680 (perp=6.823, rec=0.111, cos=0.204), tot_loss_proj:3.236 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to suequitable her birthday. [SEP]']
[1050/2000] tot_loss=1.442 (perp=5.651, rec=0.103, cos=0.209), tot_loss_proj:2.950 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.440 (perp=5.651, rec=0.097, cos=0.213), tot_loss_proj:2.944 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.442 (perp=5.651, rec=0.102, cos=0.210), tot_loss_proj:2.946 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
[1200/2000] tot_loss=1.439 (perp=5.651, rec=0.098, cos=0.211), tot_loss_proj:2.952 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.438 (perp=5.651, rec=0.097, cos=0.211), tot_loss_proj:2.950 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.433 (perp=5.651, rec=0.093, cos=0.210), tot_loss_proj:2.944 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
[1350/2000] tot_loss=1.451 (perp=5.651, rec=0.109, cos=0.212), tot_loss_proj:2.946 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.433 (perp=5.651, rec=0.092, cos=0.211), tot_loss_proj:2.945 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.435 (perp=5.651, rec=0.094, cos=0.210), tot_loss_proj:2.946 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
[1500/2000] tot_loss=1.442 (perp=5.651, rec=0.101, cos=0.211), tot_loss_proj:2.944 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.440 (perp=5.651, rec=0.098, cos=0.211), tot_loss_proj:2.940 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.438 (perp=5.651, rec=0.096, cos=0.211), tot_loss_proj:2.943 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
[1650/2000] tot_loss=1.438 (perp=5.651, rec=0.097, cos=0.211), tot_loss_proj:2.943 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.439 (perp=5.651, rec=0.098, cos=0.211), tot_loss_proj:2.944 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.440 (perp=5.651, rec=0.098, cos=0.211), tot_loss_proj:2.945 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
[1800/2000] tot_loss=1.436 (perp=5.651, rec=0.095, cos=0.211), tot_loss_proj:2.945 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.435 (perp=5.651, rec=0.093, cos=0.211), tot_loss_proj:2.946 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.442 (perp=5.651, rec=0.101, cos=0.211), tot_loss_proj:2.947 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
[1950/2000] tot_loss=1.442 (perp=5.651, rec=0.101, cos=0.211), tot_loss_proj:2.941 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.446 (perp=5.651, rec=0.105, cos=0.211), tot_loss_proj:2.948 [t=0.24s]
prediction: ['[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]
========================
predicted: 
========================
[CLS] records at john gave the books and records for the mary sue to sue for her birthday. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.486 | p: 84.211 | r: 88.889
rouge2     | fm: 45.714 | p: 44.444 | r: 47.059
rougeL     | fm: 70.270 | p: 68.421 | r: 72.222
rougeLsum  | fm: 70.270 | p: 68.421 | r: 72.222
r1fm+r2fm = 132.201

[Aggregate metrics]:
rouge1     | fm: 86.696 | p: 86.361 | r: 87.154
rouge2     | fm: 50.096 | p: 49.923 | r: 50.475
rougeL     | fm: 75.991 | p: 75.754 | r: 76.335
rougeLsum  | fm: 76.137 | p: 75.882 | r: 76.528
r1fm+r2fm = 136.791

input #52 time: 0:09:17 | total time: 8:02:25


Running input #53 of 100.
reference: 
========================
He said that himself was hungry.
========================
average of cosine similarity 0.8894535054654181
highest_index [0]
highest [0.8894535054654181]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2056, 2008, 2370, 2001, 7501, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he said that himself was hungry. [SEP]']
[Init] best rec loss: 0.8198642730712891 for ['[CLS] syncoc youth also returning jaguar flower [SEP]']
[Init] best rec loss: 0.7819858193397522 for ['[CLS] terms expireditanupt racing everuating [SEP]']
[Init] best rec loss: 0.7770369648933411 for ['[CLS]minster end cute wraps into faculty called [SEP]']
[Init] best rec loss: 0.7699581980705261 for ['[CLS] ballet smiled calculated mcdonnell academie advantage t [SEP]']
[Init] best rec loss: 0.7613858580589294 for ['[CLS] department face top conducting midi instantly security [SEP]']
[Init] best rec loss: 0.7562803626060486 for ['[CLS] layne lump bone presidentialtip understanding sewer [SEP]']
[Init] best perm rec loss: 0.754876434803009 for ['[CLS] laynetip lump sewer presidential bone understanding [SEP]']
[Init] best perm rec loss: 0.7527758479118347 for ['[CLS] understanding sewer lump layne presidentialtip bone [SEP]']
[Init] best perm rec loss: 0.7492229342460632 for ['[CLS] bone sewer understanding presidentialtip lump layne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.152 (perp=8.046, rec=0.335, cos=0.207), tot_loss_proj:2.504 [t=0.23s]
prediction: ['[CLS] his. himself was himself there said [SEP]']
[ 100/2000] tot_loss=2.007 (perp=7.862, rec=0.229, cos=0.205), tot_loss_proj:2.340 [t=0.23s]
prediction: ['[CLS] himself himself himself was hungry he said [SEP]']
[ 150/2000] tot_loss=2.078 (perp=8.556, rec=0.160, cos=0.206), tot_loss_proj:2.463 [t=0.23s]
prediction: ['[CLS] hungry himself was was hungry he said [SEP]']
[ 200/2000] tot_loss=2.124 (perp=8.994, rec=0.116, cos=0.209), tot_loss_proj:2.691 [t=0.23s]
prediction: ['[CLS] hungry himself was was hungry said that [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.835 (perp=7.637, rec=0.100, cos=0.208), tot_loss_proj:2.583 [t=0.23s]
prediction: ['[CLS] he. himself was hungry said that [SEP]']
[ 300/2000] tot_loss=1.831 (perp=7.637, rec=0.095, cos=0.209), tot_loss_proj:2.588 [t=0.23s]
prediction: ['[CLS] he. himself was hungry said that [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.607 (perp=6.426, rec=0.113, cos=0.208), tot_loss_proj:2.180 [t=0.23s]
prediction: ['[CLS] him himself was hungry. said that [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.594 (perp=6.426, rec=0.100, cos=0.208), tot_loss_proj:2.176 [t=0.23s]
prediction: ['[CLS] him himself was hungry. said that [SEP]']
[ 450/2000] tot_loss=1.576 (perp=6.426, rec=0.084, cos=0.207), tot_loss_proj:2.181 [t=0.23s]
prediction: ['[CLS] him himself was hungry. said that [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.370 (perp=5.315, rec=0.100, cos=0.206), tot_loss_proj:1.768 [t=0.23s]
prediction: ['[CLS] said that him himself was hungry. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.324 (perp=5.163, rec=0.085, cos=0.207), tot_loss_proj:1.586 [t=0.23s]
prediction: ['[CLS] him said that himself was hungry. [SEP]']
[ 600/2000] tot_loss=1.222 (perp=4.645, rec=0.085, cos=0.208), tot_loss_proj:1.280 [t=0.23s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.198 (perp=4.560, rec=0.077, cos=0.208), tot_loss_proj:2.379 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.198 (perp=4.560, rec=0.078, cos=0.208), tot_loss_proj:2.376 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[ 750/2000] tot_loss=1.197 (perp=4.560, rec=0.076, cos=0.208), tot_loss_proj:2.368 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.183 (perp=4.560, rec=0.063, cos=0.208), tot_loss_proj:2.369 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.187 (perp=4.560, rec=0.067, cos=0.208), tot_loss_proj:2.367 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[ 900/2000] tot_loss=1.191 (perp=4.560, rec=0.070, cos=0.209), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.180 (perp=4.560, rec=0.059, cos=0.209), tot_loss_proj:2.366 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.179 (perp=4.560, rec=0.058, cos=0.209), tot_loss_proj:2.364 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1050/2000] tot_loss=1.176 (perp=4.560, rec=0.056, cos=0.209), tot_loss_proj:2.362 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.192 (perp=4.560, rec=0.072, cos=0.209), tot_loss_proj:2.362 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.183 (perp=4.560, rec=0.062, cos=0.209), tot_loss_proj:2.362 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1200/2000] tot_loss=1.187 (perp=4.560, rec=0.066, cos=0.209), tot_loss_proj:2.369 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.174 (perp=4.560, rec=0.053, cos=0.209), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.184 (perp=4.560, rec=0.064, cos=0.209), tot_loss_proj:2.364 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1350/2000] tot_loss=1.180 (perp=4.560, rec=0.059, cos=0.209), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.187 (perp=4.560, rec=0.066, cos=0.209), tot_loss_proj:2.367 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.182 (perp=4.560, rec=0.061, cos=0.209), tot_loss_proj:2.364 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1500/2000] tot_loss=1.177 (perp=4.560, rec=0.056, cos=0.209), tot_loss_proj:2.364 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.188 (perp=4.560, rec=0.067, cos=0.209), tot_loss_proj:2.362 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.185 (perp=4.560, rec=0.064, cos=0.209), tot_loss_proj:2.355 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1650/2000] tot_loss=1.179 (perp=4.560, rec=0.058, cos=0.209), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.183 (perp=4.560, rec=0.062, cos=0.209), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.175 (perp=4.560, rec=0.054, cos=0.209), tot_loss_proj:2.364 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1800/2000] tot_loss=1.185 (perp=4.560, rec=0.064, cos=0.209), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.172 (perp=4.560, rec=0.052, cos=0.209), tot_loss_proj:2.358 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.186 (perp=4.560, rec=0.065, cos=0.209), tot_loss_proj:2.359 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1950/2000] tot_loss=1.191 (perp=4.560, rec=0.070, cos=0.209), tot_loss_proj:2.358 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.182 (perp=4.560, rec=0.061, cos=0.209), tot_loss_proj:2.357 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] he said that himself was hungry. [SEP]
========================
predicted: 
========================
[CLS] said that he himself was hungry. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 86.977 | p: 86.636 | r: 87.455
rouge2     | fm: 50.046 | p: 49.818 | r: 50.437
rougeL     | fm: 76.220 | p: 75.937 | r: 76.604
rougeLsum  | fm: 76.298 | p: 76.126 | r: 76.682
r1fm+r2fm = 137.024

input #53 time: 0:09:10 | total time: 8:11:35


Running input #54 of 100.
reference: 
========================
After reading the pamphlet, Judy threw them into the garbage can.
========================
average of cosine similarity 0.8835781101387563
highest_index [0]
highest [0.8835781101387563]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  2044,  3752,  1996, 19899,  1010, 12120,  4711,  2068,  2046,
          1996, 13044,  2064,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]']
[Init] best rec loss: 0.9173078536987305 for ['[CLS]position unavailable reporter wink zero do leaning double declared temple swift 2012 fine [SEP]']
[Init] best rec loss: 0.881191074848175 for ['[CLS] very concert impressed sentiment place beatencted little rockritan bonaparte rex agreement [SEP]']
[Init] best rec loss: 0.85841965675354 for ['[CLS] approval dollar wilde woods both [SEP] containing village ivy marley stroke adult tattoo [SEP]']
[Init] best rec loss: 0.8412767648696899 for ['[CLS] russian truly jayde plasma scholarship originally colby lower thirty疒 ra severed [SEP]']
[Init] best perm rec loss: 0.8410186767578125 for ['[CLS] scholarship russian severed thirty lower plasma originallyde colby疒 jay ra truly [SEP]']
[Init] best perm rec loss: 0.8396084904670715 for ['[CLS] ra russian truly plasma疒 thirty lowerde colby originally jay scholarship severed [SEP]']
[Init] best perm rec loss: 0.8385294675827026 for ['[CLS] russiande疒 colby lower scholarship severed originally plasma jay truly ra thirty [SEP]']
[Init] best perm rec loss: 0.837885856628418 for ['[CLS] jay russian疒de thirty lower truly ra colby originally severed plasma scholarship [SEP]']
[Init] best perm rec loss: 0.8377429842948914 for ['[CLS] colbyde russian thirty plasma lower ra疒 scholarship jay originally truly severed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.132 (perp=11.644, rec=0.531, cos=0.272), tot_loss_proj:4.137 [t=0.23s]
prediction: ['[CLS] endellecodes russian entity smell presented them cash team journal are purchased. [SEP]']
[ 100/2000] tot_loss=2.957 (perp=12.286, rec=0.285, cos=0.214), tot_loss_proj:4.287 [t=0.23s]
prediction: ['[CLS] gretchencodes arrived safer magazine a them slid temple poster arrive down. [SEP]']
[ 150/2000] tot_loss=2.765 (perp=11.629, rec=0.222, cos=0.217), tot_loss_proj:4.176 [t=0.23s]
prediction: ['[CLS] gretchendown gossip safer students wrote them slid feast reading arrive down. [SEP]']
[ 200/2000] tot_loss=2.858 (perp=12.270, rec=0.189, cos=0.215), tot_loss_proj:4.316 [t=0.23s]
prediction: ['[CLS] judydown gossip safer annie threw them pamphlettory pamphlet arrive down. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.542 (perp=10.800, rec=0.171, cos=0.210), tot_loss_proj:4.081 [t=0.23s]
prediction: ['[CLS] judy down gossip safer annie threw them pamphlet into pamphlet arrivedown. [SEP]']
[ 300/2000] tot_loss=2.581 (perp=11.008, rec=0.164, cos=0.215), tot_loss_proj:4.052 [t=0.23s]
prediction: ['[CLS] judy down gossip compilation annie threw them pamphlet into pamphlet throwdown. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.483 (perp=10.449, rec=0.179, cos=0.214), tot_loss_proj:3.903 [t=0.23s]
prediction: ['[CLS] down arrived! judy enters threw them read into pamphlet throw storyline. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.266 (perp=9.508, rec=0.150, cos=0.215), tot_loss_proj:3.745 [t=0.23s]
prediction: ['[CLS] down arrived compilation judy read threw them enters into pamphlet throwdown. [SEP]']
[ 450/2000] tot_loss=2.324 (perp=9.821, rec=0.146, cos=0.213), tot_loss_proj:3.771 [t=0.23s]
prediction: ['[CLS] down gossip compilation judy read threw them mother into pamphlet throwdown. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.191 (perp=9.186, rec=0.138, cos=0.215), tot_loss_proj:3.654 [t=0.23s]
prediction: ['[CLS] down pamphlet compilation judy read threw them mother into gossip garbagedown. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.049 (perp=8.476, rec=0.138, cos=0.215), tot_loss_proj:3.583 [t=0.23s]
prediction: ['[CLS] mother pamphlet garbage judy read threw them down into gossip garbage parties. [SEP]']
[ 600/2000] tot_loss=1.996 (perp=8.287, rec=0.123, cos=0.216), tot_loss_proj:3.543 [t=0.23s]
prediction: ['[CLS] mother pamphlet garbage judy read threw them down into trash garbage parties. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.040 (perp=8.511, rec=0.121, cos=0.217), tot_loss_proj:3.553 [t=0.23s]
prediction: ['[CLS] mother pamphlet garbage judy reading threw them down into garbage trash parties. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.001 (perp=8.352, rec=0.116, cos=0.214), tot_loss_proj:3.518 [t=0.23s]
prediction: ['[CLS] mother judy garbage pamphlet reading threw them down into garbage trash cabinet. [SEP]']
[ 750/2000] tot_loss=2.010 (perp=8.352, rec=0.125, cos=0.215), tot_loss_proj:3.522 [t=0.23s]
prediction: ['[CLS] mother judy garbage pamphlet reading threw them down into garbage trash cabinet. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.985 (perp=8.245, rec=0.120, cos=0.216), tot_loss_proj:3.504 [t=0.23s]
prediction: ['[CLS] mother judy pamphlet reading garbage threw them down into garbage trash cabinet. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.926 (perp=7.962, rec=0.118, cos=0.216), tot_loss_proj:3.426 [t=0.23s]
prediction: ['[CLS] pamphlet judy when reading garbage threw them down into garbage garbage cabinet. [SEP]']
[ 900/2000] tot_loss=1.960 (perp=8.096, rec=0.126, cos=0.215), tot_loss_proj:3.485 [t=0.23s]
prediction: ['[CLS] pamphlet judy when reading garbage threw them down into garbage garbage where. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.834 (perp=7.534, rec=0.116, cos=0.211), tot_loss_proj:3.357 [t=0.30s]
prediction: ['[CLS] when reading pamphlet judy garbage threw them down into garbage garbage where. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.834 (perp=7.534, rec=0.114, cos=0.213), tot_loss_proj:3.353 [t=0.23s]
prediction: ['[CLS] when reading pamphlet judy garbage threw them down into garbage garbage where. [SEP]']
[1050/2000] tot_loss=1.841 (perp=7.534, rec=0.121, cos=0.214), tot_loss_proj:3.350 [t=0.23s]
prediction: ['[CLS] when reading pamphlet judy garbage threw them down into garbage garbage where. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.758 (perp=7.145, rec=0.115, cos=0.214), tot_loss_proj:3.285 [t=0.23s]
prediction: ['[CLS] when reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.759 (perp=7.145, rec=0.116, cos=0.214), tot_loss_proj:3.283 [t=0.23s]
prediction: ['[CLS] when reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
[1200/2000] tot_loss=1.750 (perp=7.145, rec=0.107, cos=0.214), tot_loss_proj:3.288 [t=0.23s]
prediction: ['[CLS] when reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.756 (perp=7.145, rec=0.113, cos=0.214), tot_loss_proj:3.288 [t=0.23s]
prediction: ['[CLS] when reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.752 (perp=7.145, rec=0.108, cos=0.214), tot_loss_proj:3.286 [t=0.23s]
prediction: ['[CLS] when reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
[1350/2000] tot_loss=1.751 (perp=7.145, rec=0.107, cos=0.214), tot_loss_proj:3.283 [t=0.23s]
prediction: ['[CLS] when reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.777 (perp=7.278, rec=0.107, cos=0.214), tot_loss_proj:3.318 [t=0.23s]
prediction: ['[CLS] after reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.789 (perp=7.278, rec=0.119, cos=0.215), tot_loss_proj:3.321 [t=0.23s]
prediction: ['[CLS] after reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
[1500/2000] tot_loss=1.768 (perp=7.278, rec=0.097, cos=0.215), tot_loss_proj:3.319 [t=0.23s]
prediction: ['[CLS] after reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.776 (perp=7.278, rec=0.106, cos=0.215), tot_loss_proj:3.317 [t=0.23s]
prediction: ['[CLS] after reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.766 (perp=7.278, rec=0.095, cos=0.215), tot_loss_proj:3.319 [t=0.23s]
prediction: ['[CLS] after reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
[1650/2000] tot_loss=1.774 (perp=7.278, rec=0.104, cos=0.215), tot_loss_proj:3.319 [t=0.23s]
prediction: ['[CLS] after reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.773 (perp=7.278, rec=0.102, cos=0.215), tot_loss_proj:3.319 [t=0.23s]
prediction: ['[CLS] after reading pamphlet judy garbage threw them down into the garbage where. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.787 (perp=7.299, rec=0.111, cos=0.215), tot_loss_proj:3.307 [t=0.23s]
prediction: ['[CLS] after reading pamphlet judy garbage threw them down into the garbage would. [SEP]']
[1800/2000] tot_loss=1.785 (perp=7.299, rec=0.110, cos=0.215), tot_loss_proj:3.302 [t=0.23s]
prediction: ['[CLS] after reading pamphlet judy garbage threw them down into the garbage would. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.786 (perp=7.299, rec=0.111, cos=0.215), tot_loss_proj:3.307 [t=0.23s]
prediction: ['[CLS] after reading pamphlet judy garbage threw them down into the garbage would. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.753 (perp=7.107, rec=0.118, cos=0.214), tot_loss_proj:3.289 [t=0.23s]
prediction: ['[CLS] after reading pamphlet garbage judy threw them down into the garbage would. [SEP]']
[1950/2000] tot_loss=1.750 (perp=7.107, rec=0.112, cos=0.216), tot_loss_proj:3.292 [t=0.23s]
prediction: ['[CLS] after reading pamphlet garbage judy threw them down into the garbage would. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.758 (perp=7.107, rec=0.120, cos=0.216), tot_loss_proj:3.288 [t=0.23s]
prediction: ['[CLS] after reading pamphlet garbage judy threw them down into the garbage would. [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]
========================
predicted: 
========================
[CLS] after reading pamphlet judy garbage threw them down into the garbage would. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.481 | p: 78.571 | r: 84.615
rouge2     | fm: 48.000 | p: 46.154 | r: 50.000
rougeL     | fm: 81.481 | p: 78.571 | r: 84.615
rougeLsum  | fm: 81.481 | p: 78.571 | r: 84.615
r1fm+r2fm = 129.481

[Aggregate metrics]:
rouge1     | fm: 86.863 | p: 86.480 | r: 87.312
rouge2     | fm: 50.164 | p: 49.852 | r: 50.625
rougeL     | fm: 76.274 | p: 76.032 | r: 76.682
rougeLsum  | fm: 76.301 | p: 76.053 | r: 76.804
r1fm+r2fm = 137.026

input #54 time: 0:09:09 | total time: 8:20:45


Running input #55 of 100.
reference: 
========================
Collapsed Harry.
========================
average of cosine similarity 0.8928038989357294
highest_index [0]
highest [0.8928038989357294]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 7798, 4302, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] collapsed harry. [SEP]']
[Init] best rec loss: 0.7473602294921875 for ['[CLS] taken dana once [SEP]']
[Init] best rec loss: 0.7122941613197327 for ['[CLS] lowest black therefore [SEP]']
[Init] best rec loss: 0.6819965839385986 for ['[CLS] class atlantic martins [SEP]']
[Init] best rec loss: 0.6728635430335999 for ['[CLS] king island damp [SEP]']
[Init] best rec loss: 0.6684808135032654 for ['[CLS] mage sharing roman [SEP]']
[Init] best rec loss: 0.6675840616226196 for ['[CLS] len affiliate ono [SEP]']
[Init] best perm rec loss: 0.6665478348731995 for ['[CLS] ono affiliate len [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.678 (perp=11.154, rec=0.248, cos=0.200), tot_loss_proj:3.381 [t=0.23s]
prediction: ['[CLS] construction collapsed michael [SEP]']
[ 100/2000] tot_loss=2.848 (perp=12.559, rec=0.141, cos=0.195), tot_loss_proj:3.479 [t=0.23s]
prediction: ['[CLS] collapsed collapsed harry [SEP]']
[ 150/2000] tot_loss=2.822 (perp=12.559, rec=0.110, cos=0.200), tot_loss_proj:3.477 [t=0.23s]
prediction: ['[CLS] collapsed collapsed harry [SEP]']
[ 200/2000] tot_loss=2.745 (perp=12.185, rec=0.104, cos=0.204), tot_loss_proj:3.506 [t=0.23s]
prediction: ['[CLS] harry collapsed harry [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.816 (perp=12.559, rec=0.103, cos=0.201), tot_loss_proj:3.525 [t=0.23s]
prediction: ['[CLS] collapsed collapsed harry [SEP]']
[ 300/2000] tot_loss=2.807 (perp=12.559, rec=0.097, cos=0.198), tot_loss_proj:3.517 [t=0.23s]
prediction: ['[CLS] collapsed collapsed harry [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.482 (perp=11.016, rec=0.082, cos=0.196), tot_loss_proj:3.178 [t=0.23s]
prediction: ['[CLS]. collapsed harry [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.320 (perp=8.256, rec=0.213, cos=0.455), tot_loss_proj:3.502 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
[ 450/2000] tot_loss=1.934 (perp=8.256, rec=0.090, cos=0.193), tot_loss_proj:3.522 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.918 (perp=8.256, rec=0.071, cos=0.196), tot_loss_proj:3.517 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.930 (perp=8.256, rec=0.079, cos=0.200), tot_loss_proj:3.524 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
[ 600/2000] tot_loss=1.913 (perp=8.256, rec=0.061, cos=0.201), tot_loss_proj:3.522 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.924 (perp=8.256, rec=0.071, cos=0.201), tot_loss_proj:3.520 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.926 (perp=8.256, rec=0.073, cos=0.202), tot_loss_proj:3.523 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
[ 750/2000] tot_loss=1.927 (perp=8.256, rec=0.074, cos=0.202), tot_loss_proj:3.526 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.911 (perp=8.256, rec=0.057, cos=0.202), tot_loss_proj:3.523 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.927 (perp=8.256, rec=0.073, cos=0.202), tot_loss_proj:3.521 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
[ 900/2000] tot_loss=1.926 (perp=8.256, rec=0.072, cos=0.202), tot_loss_proj:3.526 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.920 (perp=8.256, rec=0.066, cos=0.203), tot_loss_proj:3.526 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.922 (perp=8.256, rec=0.069, cos=0.203), tot_loss_proj:3.523 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1050/2000] tot_loss=1.928 (perp=8.256, rec=0.074, cos=0.203), tot_loss_proj:3.529 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.924 (perp=8.256, rec=0.070, cos=0.203), tot_loss_proj:3.528 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.912 (perp=8.256, rec=0.058, cos=0.203), tot_loss_proj:3.527 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1200/2000] tot_loss=1.915 (perp=8.256, rec=0.061, cos=0.203), tot_loss_proj:3.526 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.922 (perp=8.256, rec=0.068, cos=0.203), tot_loss_proj:3.519 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.923 (perp=8.256, rec=0.069, cos=0.203), tot_loss_proj:3.524 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1350/2000] tot_loss=1.912 (perp=8.256, rec=0.058, cos=0.203), tot_loss_proj:3.530 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.921 (perp=8.256, rec=0.067, cos=0.203), tot_loss_proj:3.523 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.916 (perp=8.256, rec=0.062, cos=0.203), tot_loss_proj:3.529 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1500/2000] tot_loss=1.921 (perp=8.256, rec=0.067, cos=0.203), tot_loss_proj:3.529 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.911 (perp=8.256, rec=0.057, cos=0.203), tot_loss_proj:3.525 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.919 (perp=8.256, rec=0.065, cos=0.203), tot_loss_proj:3.526 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1650/2000] tot_loss=1.911 (perp=8.256, rec=0.057, cos=0.203), tot_loss_proj:3.522 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.917 (perp=8.256, rec=0.063, cos=0.203), tot_loss_proj:3.526 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.924 (perp=8.256, rec=0.070, cos=0.203), tot_loss_proj:3.525 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1800/2000] tot_loss=1.918 (perp=8.256, rec=0.064, cos=0.203), tot_loss_proj:3.523 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.917 (perp=8.256, rec=0.063, cos=0.203), tot_loss_proj:3.532 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.914 (perp=8.256, rec=0.060, cos=0.203), tot_loss_proj:3.527 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1950/2000] tot_loss=1.922 (perp=8.256, rec=0.068, cos=0.203), tot_loss_proj:3.524 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.912 (perp=8.256, rec=0.058, cos=0.203), tot_loss_proj:3.534 [t=0.23s]
prediction: ['[CLS] harry collapsed. [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] collapsed harry. [SEP]
========================
predicted: 
========================
[CLS] harry collapsed. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.041 | p: 86.701 | r: 87.592
rouge2     | fm: 49.158 | p: 48.857 | r: 49.524
rougeL     | fm: 76.318 | p: 76.050 | r: 76.718
rougeLsum  | fm: 76.367 | p: 76.059 | r: 76.860
r1fm+r2fm = 136.199

input #55 time: 0:09:08 | total time: 8:29:54


Running input #56 of 100.
reference: 
========================
John was seeing his children.
========================
average of cosine similarity 0.8847392377804936
highest_index [0]
highest [0.8847392377804936]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2198, 2001, 3773, 2010, 2336, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john was seeing his children. [SEP]']
[Init] best rec loss: 0.891750693321228 for ['[CLS] vampire artists at like edge into [SEP]']
[Init] best rec loss: 0.8850386142730713 for ['[CLS] heel rite churchill spacerade bent [SEP]']
[Init] best rec loss: 0.8840073943138123 for ['[CLS] again balfour advisors safety return realized [SEP]']
[Init] best rec loss: 0.8750991821289062 for ['[CLS] smoke starts ease mountain throat han [SEP]']
[Init] best rec loss: 0.8592438101768494 for ['[CLS] lviv rap leverricted council classic [SEP]']
[Init] best rec loss: 0.8498629331588745 for ['[CLS]lanenay make outside beauty doubled [SEP]']
[Init] best rec loss: 0.8483442664146423 for ['[CLS] saw ego figure mean team grim [SEP]']
[Init] best perm rec loss: 0.846093475818634 for ['[CLS] ego grim mean saw team figure [SEP]']
[Init] best perm rec loss: 0.8442800045013428 for ['[CLS] ego grim saw team mean figure [SEP]']
[Init] best perm rec loss: 0.8437730073928833 for ['[CLS] saw figure ego mean team grim [SEP]']
[Init] best perm rec loss: 0.8435694575309753 for ['[CLS] saw grim figure team mean ego [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.291 (perp=13.362, rec=0.406, cos=0.213), tot_loss_proj:4.417 [t=0.23s]
prediction: ['[CLS] savannah john talked tropical medical did [SEP]']
[ 100/2000] tot_loss=2.325 (perp=9.115, rec=0.286, cos=0.217), tot_loss_proj:3.581 [t=0.23s]
prediction: ['[CLS] his john was being his did [SEP]']
[ 150/2000] tot_loss=2.218 (perp=9.271, rec=0.148, cos=0.216), tot_loss_proj:3.653 [t=0.23s]
prediction: ['[CLS] his john was seeing children they [SEP]']
[ 200/2000] tot_loss=1.662 (perp=6.735, rec=0.097, cos=0.217), tot_loss_proj:2.911 [t=0.23s]
prediction: ['[CLS] his john was seeing children. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.518 (perp=6.084, rec=0.087, cos=0.215), tot_loss_proj:1.611 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[ 300/2000] tot_loss=1.519 (perp=6.084, rec=0.087, cos=0.215), tot_loss_proj:1.612 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.506 (perp=6.084, rec=0.075, cos=0.214), tot_loss_proj:1.599 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.509 (perp=6.084, rec=0.077, cos=0.214), tot_loss_proj:1.603 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[ 450/2000] tot_loss=1.499 (perp=6.084, rec=0.065, cos=0.217), tot_loss_proj:1.599 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.506 (perp=6.084, rec=0.072, cos=0.217), tot_loss_proj:1.606 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.502 (perp=6.084, rec=0.069, cos=0.217), tot_loss_proj:1.611 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[ 600/2000] tot_loss=1.501 (perp=6.084, rec=0.068, cos=0.217), tot_loss_proj:1.610 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.505 (perp=6.084, rec=0.071, cos=0.217), tot_loss_proj:1.604 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.501 (perp=6.084, rec=0.068, cos=0.216), tot_loss_proj:1.604 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[ 750/2000] tot_loss=1.495 (perp=6.084, rec=0.061, cos=0.217), tot_loss_proj:1.607 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.502 (perp=6.084, rec=0.069, cos=0.217), tot_loss_proj:1.606 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.494 (perp=6.084, rec=0.060, cos=0.217), tot_loss_proj:1.612 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[ 900/2000] tot_loss=1.528 (perp=6.084, rec=0.095, cos=0.216), tot_loss_proj:1.628 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.530 (perp=6.084, rec=0.096, cos=0.217), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.515 (perp=6.084, rec=0.081, cos=0.217), tot_loss_proj:1.592 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1050/2000] tot_loss=1.527 (perp=6.084, rec=0.093, cos=0.217), tot_loss_proj:1.603 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.509 (perp=6.084, rec=0.075, cos=0.217), tot_loss_proj:1.593 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.510 (perp=6.084, rec=0.076, cos=0.217), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1200/2000] tot_loss=1.506 (perp=6.084, rec=0.072, cos=0.217), tot_loss_proj:1.588 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.515 (perp=6.084, rec=0.082, cos=0.217), tot_loss_proj:1.603 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.502 (perp=6.084, rec=0.069, cos=0.217), tot_loss_proj:1.583 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1350/2000] tot_loss=1.508 (perp=6.084, rec=0.074, cos=0.217), tot_loss_proj:1.602 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.504 (perp=6.084, rec=0.070, cos=0.217), tot_loss_proj:1.590 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.508 (perp=6.084, rec=0.074, cos=0.217), tot_loss_proj:1.601 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1500/2000] tot_loss=1.507 (perp=6.084, rec=0.073, cos=0.217), tot_loss_proj:1.605 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.514 (perp=6.084, rec=0.081, cos=0.217), tot_loss_proj:1.593 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.502 (perp=6.084, rec=0.068, cos=0.217), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1650/2000] tot_loss=1.499 (perp=6.084, rec=0.065, cos=0.217), tot_loss_proj:1.586 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.508 (perp=6.084, rec=0.074, cos=0.217), tot_loss_proj:1.597 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.503 (perp=6.084, rec=0.069, cos=0.217), tot_loss_proj:1.602 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1800/2000] tot_loss=1.501 (perp=6.084, rec=0.067, cos=0.217), tot_loss_proj:1.595 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.495 (perp=6.084, rec=0.061, cos=0.217), tot_loss_proj:1.601 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.508 (perp=6.084, rec=0.074, cos=0.217), tot_loss_proj:1.599 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1950/2000] tot_loss=1.505 (perp=6.084, rec=0.071, cos=0.217), tot_loss_proj:1.602 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.514 (perp=6.084, rec=0.080, cos=0.217), tot_loss_proj:1.604 [t=0.23s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] john was seeing his children. [SEP]
========================
predicted: 
========================
[CLS] john was seeing his children. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.268 | p: 86.935 | r: 87.801
rouge2     | fm: 50.433 | p: 50.092 | r: 50.798
rougeL     | fm: 76.678 | p: 76.461 | r: 77.075
rougeLsum  | fm: 76.809 | p: 76.548 | r: 77.245
r1fm+r2fm = 137.701

input #56 time: 0:09:08 | total time: 8:39:03


Running input #57 of 100.
reference: 
========================
Carla mopped the floor under the furniture.
========================
average of cosine similarity 0.9098638252702381
highest_index [0]
highest [0.9098638252702381]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 17081,  9587, 11469,  1996,  2723,  2104,  1996,  7390,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] carla mopped the floor under the furniture. [SEP]']
[Init] best rec loss: 0.8534013032913208 for ['[CLS]ne gathering do their health retirement go enforce things [SEP]']
[Init] best rec loss: 0.8371142148971558 for ['[CLS] dearyst representation省 rarely application parked candle themselves [SEP]']
[Init] best rec loss: 0.8291040062904358 for ['[CLS] bubble such turkey reactor laborquist cricket bachelor cell [SEP]']
[Init] best perm rec loss: 0.8276004791259766 for ['[CLS] turkeyquist such cricket reactor bubble bachelor labor cell [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.949 (perp=11.279, rec=0.754, cos=0.940), tot_loss_proj:4.074 [t=0.22s]
prediction: ['[CLS] loosened wong russian floor enough. protein furniture. [SEP]']
[ 100/2000] tot_loss=2.687 (perp=11.040, rec=0.268, cos=0.211), tot_loss_proj:3.989 [t=0.22s]
prediction: ['[CLS] percent pine american floor enough under the furniture. [SEP]']
[ 150/2000] tot_loss=1.983 (perp=8.198, rec=0.179, cos=0.164), tot_loss_proj:3.487 [t=0.22s]
prediction: ['[CLS] grandma jill the floor the under the furniture. [SEP]']
[ 200/2000] tot_loss=2.228 (perp=9.519, rec=0.150, cos=0.175), tot_loss_proj:3.703 [t=0.22s]
prediction: ['[CLS] grandma carla the floor the underpped furniture. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.284 (perp=9.707, rec=0.153, cos=0.190), tot_loss_proj:3.724 [t=0.22s]
prediction: ['[CLS] carla mo thepaper floor underpped furniture. [SEP]']
[ 300/2000] tot_loss=2.218 (perp=9.707, rec=0.124, cos=0.153), tot_loss_proj:3.711 [t=0.22s]
prediction: ['[CLS] carla mo thepaper floor underpped furniture. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.939 (perp=8.389, rec=0.106, cos=0.155), tot_loss_proj:3.564 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.946 (perp=8.389, rec=0.097, cos=0.172), tot_loss_proj:3.562 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
[ 450/2000] tot_loss=1.935 (perp=8.389, rec=0.089, cos=0.168), tot_loss_proj:3.563 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.936 (perp=8.389, rec=0.096, cos=0.162), tot_loss_proj:3.565 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.927 (perp=8.389, rec=0.083, cos=0.166), tot_loss_proj:3.566 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
[ 600/2000] tot_loss=1.934 (perp=8.389, rec=0.098, cos=0.158), tot_loss_proj:3.564 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.945 (perp=8.389, rec=0.093, cos=0.175), tot_loss_proj:3.563 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.911 (perp=8.389, rec=0.076, cos=0.158), tot_loss_proj:3.563 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
[ 750/2000] tot_loss=1.950 (perp=8.389, rec=0.098, cos=0.174), tot_loss_proj:3.563 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.937 (perp=8.389, rec=0.084, cos=0.175), tot_loss_proj:3.565 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.940 (perp=8.389, rec=0.087, cos=0.175), tot_loss_proj:3.562 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
[ 900/2000] tot_loss=1.937 (perp=8.389, rec=0.083, cos=0.176), tot_loss_proj:3.561 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.930 (perp=8.389, rec=0.082, cos=0.170), tot_loss_proj:3.562 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.935 (perp=8.389, rec=0.087, cos=0.170), tot_loss_proj:3.560 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
[1050/2000] tot_loss=1.932 (perp=8.389, rec=0.084, cos=0.171), tot_loss_proj:3.564 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.927 (perp=8.389, rec=0.079, cos=0.170), tot_loss_proj:3.561 [t=0.22s]
prediction: ['[CLS] the mo carlapaper floor underpped furniture. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.971 (perp=8.567, rec=0.087, cos=0.170), tot_loss_proj:3.605 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
[1200/2000] tot_loss=1.955 (perp=8.567, rec=0.071, cos=0.171), tot_loss_proj:3.608 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.961 (perp=8.567, rec=0.078, cos=0.170), tot_loss_proj:3.607 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.967 (perp=8.567, rec=0.084, cos=0.170), tot_loss_proj:3.607 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
[1350/2000] tot_loss=1.953 (perp=8.567, rec=0.070, cos=0.170), tot_loss_proj:3.606 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.957 (perp=8.567, rec=0.072, cos=0.172), tot_loss_proj:3.604 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.965 (perp=8.567, rec=0.082, cos=0.169), tot_loss_proj:3.607 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
[1500/2000] tot_loss=1.962 (perp=8.567, rec=0.078, cos=0.171), tot_loss_proj:3.604 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.961 (perp=8.567, rec=0.078, cos=0.170), tot_loss_proj:3.609 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.960 (perp=8.567, rec=0.076, cos=0.171), tot_loss_proj:3.608 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
[1650/2000] tot_loss=1.974 (perp=8.567, rec=0.089, cos=0.171), tot_loss_proj:3.606 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.969 (perp=8.567, rec=0.084, cos=0.172), tot_loss_proj:3.605 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.963 (perp=8.567, rec=0.078, cos=0.171), tot_loss_proj:3.605 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
[1800/2000] tot_loss=1.962 (perp=8.567, rec=0.077, cos=0.171), tot_loss_proj:3.607 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.969 (perp=8.567, rec=0.084, cos=0.171), tot_loss_proj:3.605 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.973 (perp=8.567, rec=0.087, cos=0.172), tot_loss_proj:3.608 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
[1950/2000] tot_loss=1.964 (perp=8.567, rec=0.081, cos=0.170), tot_loss_proj:3.606 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.971 (perp=8.567, rec=0.085, cos=0.172), tot_loss_proj:3.609 [t=0.22s]
prediction: ['[CLS] the mo carla envelope floor underpped furniture. [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] carla mopped the floor under the furniture. [SEP]
========================
predicted: 
========================
[CLS] the mo carla envelope floor underpped furniture. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 79.167

[Aggregate metrics]:
rouge1     | fm: 86.994 | p: 86.694 | r: 87.423
rouge2     | fm: 49.639 | p: 49.389 | r: 49.952
rougeL     | fm: 76.276 | p: 76.053 | r: 76.665
rougeLsum  | fm: 76.401 | p: 76.128 | r: 76.826
r1fm+r2fm = 136.633

input #57 time: 0:08:51 | total time: 8:47:54


Running input #58 of 100.
reference: 
========================
They expected us to should leave him.
========================
average of cosine similarity 0.8988295454148183
highest_index [0]
highest [0.8988295454148183]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2027, 3517, 2149, 2000, 2323, 2681, 2032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] they expected us to should leave him. [SEP]']
[Init] best rec loss: 0.8200197219848633 for ['[CLS] like cal hazard far indiangence pair rolled [SEP]']
[Init] best rec loss: 0.8066920042037964 for ['[CLS] suit agent special small crack still try cases [SEP]']
[Init] best rec loss: 0.7457396388053894 for ['[CLS] michellevable moved lottery fold °f ask collectively [SEP]']
[Init] best rec loss: 0.7351884841918945 for ['[CLS] fore primary pcs publishing source pu ra germany [SEP]']
[Init] best rec loss: 0.734799325466156 for ['[CLS] cartoon bastionional pulitzer implant camp assistance away [SEP]']
[Init] best rec loss: 0.7297025918960571 for ['[CLS] mai institute sum allie apostolic redwoodrian corp [SEP]']
[Init] best perm rec loss: 0.7289412617683411 for ['[CLS]rian allie corp institute mai redwood sum apostolic [SEP]']
[Init] best perm rec loss: 0.725356936454773 for ['[CLS] apostolic corprian redwood institute mai allie sum [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.630 (perp=10.449, rec=0.364, cos=0.177), tot_loss_proj:3.260 [t=0.22s]
prediction: ['[CLS] should ho jurisdiction flying his should should insurance [SEP]']
[ 100/2000] tot_loss=2.499 (perp=10.356, rec=0.242, cos=0.186), tot_loss_proj:3.155 [t=0.22s]
prediction: ['[CLS] watched our we expected to should should leave [SEP]']
[ 150/2000] tot_loss=2.242 (perp=9.335, rec=0.200, cos=0.175), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] expected expected we expected to should should leave [SEP]']
[ 200/2000] tot_loss=1.971 (perp=8.346, rec=0.109, cos=0.193), tot_loss_proj:2.840 [t=0.22s]
prediction: ['[CLS] expected expected us expected them to should leave [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.963 (perp=8.331, rec=0.099, cos=0.198), tot_loss_proj:2.765 [t=0.22s]
prediction: ['[CLS] expected us expected they expected to should leave [SEP]']
[ 300/2000] tot_loss=1.933 (perp=8.331, rec=0.078, cos=0.189), tot_loss_proj:2.756 [t=0.22s]
prediction: ['[CLS] expected us expected they expected to should leave [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.949 (perp=8.331, rec=0.089, cos=0.193), tot_loss_proj:2.757 [t=0.22s]
prediction: ['[CLS] expected us expected they expected to should leave [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.003 (perp=8.612, rec=0.090, cos=0.190), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] they expected us expected. to should leave [SEP]']
[ 450/2000] tot_loss=1.989 (perp=8.612, rec=0.075, cos=0.192), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] they expected us expected. to should leave [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.840 (perp=7.933, rec=0.065, cos=0.188), tot_loss_proj:2.749 [t=0.22s]
prediction: ['[CLS] they expected us. expected to should leave [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.584 (perp=6.610, rec=0.081, cos=0.181), tot_loss_proj:2.033 [t=0.22s]
prediction: ['[CLS] they expected us expected to should leave. [SEP]']
[ 600/2000] tot_loss=1.579 (perp=6.610, rec=0.068, cos=0.189), tot_loss_proj:2.034 [t=0.22s]
prediction: ['[CLS] they expected us expected to should leave. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.579 (perp=6.610, rec=0.065, cos=0.192), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] they expected us expected to should leave. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.738 (perp=7.416, rec=0.069, cos=0.185), tot_loss_proj:2.398 [t=0.22s]
prediction: ['[CLS] they him expected us to should leave. [SEP]']
[ 750/2000] tot_loss=1.728 (perp=7.416, rec=0.057, cos=0.188), tot_loss_proj:2.390 [t=0.22s]
prediction: ['[CLS] they him expected us to should leave. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.420 (perp=5.794, rec=0.073, cos=0.189), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.411 (perp=5.794, rec=0.064, cos=0.188), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
[ 900/2000] tot_loss=1.410 (perp=5.794, rec=0.063, cos=0.189), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.412 (perp=5.794, rec=0.065, cos=0.189), tot_loss_proj:1.833 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.411 (perp=5.794, rec=0.064, cos=0.189), tot_loss_proj:1.833 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
[1050/2000] tot_loss=1.403 (perp=5.794, rec=0.055, cos=0.189), tot_loss_proj:1.821 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.410 (perp=5.794, rec=0.062, cos=0.189), tot_loss_proj:1.825 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.400 (perp=5.794, rec=0.052, cos=0.189), tot_loss_proj:1.814 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
[1200/2000] tot_loss=1.405 (perp=5.794, rec=0.057, cos=0.189), tot_loss_proj:1.821 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.413 (perp=5.794, rec=0.065, cos=0.190), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.415 (perp=5.794, rec=0.067, cos=0.190), tot_loss_proj:1.811 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
[1350/2000] tot_loss=1.416 (perp=5.794, rec=0.068, cos=0.190), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.409 (perp=5.794, rec=0.060, cos=0.190), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.410 (perp=5.794, rec=0.062, cos=0.190), tot_loss_proj:1.795 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
[1500/2000] tot_loss=1.412 (perp=5.794, rec=0.063, cos=0.190), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.412 (perp=5.794, rec=0.063, cos=0.190), tot_loss_proj:1.800 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.407 (perp=5.794, rec=0.058, cos=0.190), tot_loss_proj:1.789 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
[1650/2000] tot_loss=1.406 (perp=5.794, rec=0.057, cos=0.190), tot_loss_proj:1.793 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.414 (perp=5.794, rec=0.065, cos=0.190), tot_loss_proj:1.786 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.402 (perp=5.794, rec=0.053, cos=0.190), tot_loss_proj:1.784 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
[1800/2000] tot_loss=1.410 (perp=5.794, rec=0.061, cos=0.191), tot_loss_proj:1.782 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.413 (perp=5.794, rec=0.063, cos=0.190), tot_loss_proj:1.770 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.410 (perp=5.794, rec=0.061, cos=0.191), tot_loss_proj:1.794 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
[1950/2000] tot_loss=1.410 (perp=5.794, rec=0.060, cos=0.191), tot_loss_proj:1.785 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.402 (perp=5.794, rec=0.053, cos=0.191), tot_loss_proj:1.776 [t=0.22s]
prediction: ['[CLS] they expected us to should leave him. [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] they expected us to should leave him. [SEP]
========================
predicted: 
========================
[CLS] they expected us to should leave him. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.146 | p: 86.846 | r: 87.644
rouge2     | fm: 50.391 | p: 50.174 | r: 50.785
rougeL     | fm: 76.758 | p: 76.582 | r: 77.146
rougeLsum  | fm: 76.812 | p: 76.534 | r: 77.214
r1fm+r2fm = 137.537

input #58 time: 0:08:51 | total time: 8:56:46


Running input #59 of 100.
reference: 
========================
Mr Woodhouse sat in an armchair.
========================
average of cosine similarity 0.9371971116038158
highest_index [0]
highest [0.9371971116038158]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2720,  3536,  4580,  2938,  1999,  2019, 29372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[Init] best rec loss: 0.9309396147727966 for ['[CLS] zero treasurer kennedy vet when le bronze plans [SEP]']
[Init] best rec loss: 0.9293115735054016 for ['[CLS] greenbis wa ant chamber disks distinguishednine [SEP]']
[Init] best rec loss: 0.9279155731201172 for ['[CLS] geraldine draft side everythingion lack hamlet react [SEP]']
[Init] best rec loss: 0.9240344166755676 for ['[CLS]5 conservative lying minute theory mandatory stands operation [SEP]']
[Init] best rec loss: 0.9181348085403442 for ['[CLS] some delk bank bavarian brand military declined [SEP]']
[Init] best rec loss: 0.9167472720146179 for ['[CLS]ord muscle warning ( wife organic duty charms [SEP]']
[Init] best rec loss: 0.9079514145851135 for ['[CLS] creditsored super salvadorrov lord sparhawk obvious [SEP]']
[Init] best rec loss: 0.907814085483551 for ['[CLS] poll citizen heads chapter nor giants alec cinder [SEP]']
[Init] best rec loss: 0.9033158421516418 for ['[CLS]zziness chancellor amazon overview through than rank developed [SEP]']
[Init] best rec loss: 0.9015575051307678 for ['[CLS] car services dali forcesori halfway ir blood [SEP]']
[Init] best rec loss: 0.9009560942649841 for ['[CLS] godfather bound [SEP]den almost songs symbol war [SEP]']
[Init] best rec loss: 0.8919968008995056 for ['[CLS] basilica refers stepped subtropical losing trip tended html [SEP]']
[Init] best rec loss: 0.8881094455718994 for ['[CLS] wilson everywhere （ guns unlikerist her montane [SEP]']
[Init] best perm rec loss: 0.8838754892349243 for ['[CLS] unlike montane （rist her wilson guns everywhere [SEP]']
[Init] best perm rec loss: 0.8831180930137634 for ['[CLS] everywhere unlike （rist her wilson montane guns [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.293 (perp=13.210, rec=0.414, cos=0.237), tot_loss_proj:4.497 [t=0.22s]
prediction: ['[CLS] subsp bc responded, cart resumed mretano [SEP]']
[ 100/2000] tot_loss=2.733 (perp=11.505, rec=0.300, cos=0.132), tot_loss_proj:4.133 [t=0.22s]
prediction: ['[CLS] seated wood was medicine armchair whilst mrley [SEP]']
[ 150/2000] tot_loss=2.700 (perp=11.856, rec=0.209, cos=0.120), tot_loss_proj:4.202 [t=0.22s]
prediction: ['[CLS] seated wood sat spanish armchair armchair mrley [SEP]']
[ 200/2000] tot_loss=2.446 (perp=10.816, rec=0.161, cos=0.121), tot_loss_proj:4.018 [t=0.22s]
prediction: ['[CLS] armchair wood sat a armchair armchair mrley [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.270 (perp=9.926, rec=0.169, cos=0.116), tot_loss_proj:3.840 [t=0.22s]
prediction: ['[CLS] mr an wood sat an armchair armchairley [SEP]']
[ 300/2000] tot_loss=2.231 (perp=9.926, rec=0.125, cos=0.121), tot_loss_proj:3.840 [t=0.22s]
prediction: ['[CLS] mr an wood sat an armchair armchairley [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.919 (perp=8.383, rec=0.121, cos=0.121), tot_loss_proj:3.474 [t=0.22s]
prediction: ['[CLS] mr in armchair wood sat an armchairley [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.967 (perp=8.649, rec=0.115, cos=0.122), tot_loss_proj:3.566 [t=0.22s]
prediction: ['[CLS] mr in armchair wood sat an armchairver [SEP]']
[ 450/2000] tot_loss=1.954 (perp=8.649, rec=0.103, cos=0.121), tot_loss_proj:3.568 [t=0.22s]
prediction: ['[CLS] mr in armchair wood sat an armchairver [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.996 (perp=8.787, rec=0.118, cos=0.121), tot_loss_proj:3.558 [t=0.22s]
prediction: ['[CLS] mr armchair wood sat in an armchairis [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.778 (perp=7.710, rec=0.116, cos=0.120), tot_loss_proj:3.212 [t=0.22s]
prediction: ['[CLS] mrver wood sat in an armchair armchair [SEP]']
[ 600/2000] tot_loss=1.772 (perp=7.710, rec=0.109, cos=0.121), tot_loss_proj:3.211 [t=0.22s]
prediction: ['[CLS] mrver wood sat in an armchair armchair [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.719 (perp=7.464, rec=0.106, cos=0.121), tot_loss_proj:2.183 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair armchair [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.711 (perp=7.464, rec=0.098, cos=0.121), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair armchair [SEP]']
[ 750/2000] tot_loss=1.694 (perp=7.364, rec=0.100, cos=0.122), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchairhouse [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.695 (perp=7.364, rec=0.100, cos=0.121), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchairhouse [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.694 (perp=7.364, rec=0.100, cos=0.122), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchairhouse [SEP]']
[ 900/2000] tot_loss=1.688 (perp=7.364, rec=0.094, cos=0.121), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchairhouse [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.687 (perp=7.364, rec=0.093, cos=0.121), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchairhouse [SEP]']
Attempt swap
[1000/2000] tot_loss=1.690 (perp=7.364, rec=0.096, cos=0.121), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchairhouse [SEP]']
[1050/2000] tot_loss=1.695 (perp=7.364, rec=0.100, cos=0.122), tot_loss_proj:2.241 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchairhouse [SEP]']
Attempt swap
[1100/2000] tot_loss=1.432 (perp=6.088, rec=0.093, cos=0.121), tot_loss_proj:1.575 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.435 (perp=6.088, rec=0.096, cos=0.122), tot_loss_proj:1.569 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
[1200/2000] tot_loss=1.429 (perp=6.088, rec=0.090, cos=0.121), tot_loss_proj:1.581 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.425 (perp=6.088, rec=0.085, cos=0.122), tot_loss_proj:1.574 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.430 (perp=6.088, rec=0.091, cos=0.121), tot_loss_proj:1.576 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
[1350/2000] tot_loss=1.437 (perp=6.088, rec=0.098, cos=0.121), tot_loss_proj:1.568 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.433 (perp=6.088, rec=0.093, cos=0.122), tot_loss_proj:1.578 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.436 (perp=6.088, rec=0.097, cos=0.122), tot_loss_proj:1.580 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
[1500/2000] tot_loss=1.445 (perp=6.088, rec=0.106, cos=0.121), tot_loss_proj:1.570 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.424 (perp=6.088, rec=0.085, cos=0.122), tot_loss_proj:1.569 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.429 (perp=6.088, rec=0.089, cos=0.122), tot_loss_proj:1.574 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
[1650/2000] tot_loss=1.422 (perp=6.088, rec=0.083, cos=0.122), tot_loss_proj:1.573 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.431 (perp=6.088, rec=0.092, cos=0.122), tot_loss_proj:1.584 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.430 (perp=6.088, rec=0.091, cos=0.122), tot_loss_proj:1.575 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
[1800/2000] tot_loss=1.423 (perp=6.088, rec=0.084, cos=0.122), tot_loss_proj:1.574 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.432 (perp=6.088, rec=0.093, cos=0.122), tot_loss_proj:1.579 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.435 (perp=6.088, rec=0.095, cos=0.122), tot_loss_proj:1.578 [t=0.22s]
prediction: ['[CLS] mr woodver sat in an armchair. [SEP]']
[1950/2000] tot_loss=1.684 (perp=7.354, rec=0.092, cos=0.121), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] mr woodac sat in an armchair. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.469 (perp=6.294, rec=0.091, cos=0.120), tot_loss_proj:2.870 [t=0.22s]
prediction: ['[CLS] mrver wood sat in an armchair. [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] mr woodhouse sat in an armchair. [SEP]
========================
predicted: 
========================
[CLS] mr woodver sat in an armchair. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 71.429 | p: 71.429 | r: 71.429
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 158.929

[Aggregate metrics]:
rouge1     | fm: 87.182 | p: 86.838 | r: 87.606
rouge2     | fm: 50.815 | p: 50.588 | r: 51.163
rougeL     | fm: 76.929 | p: 76.686 | r: 77.304
rougeLsum  | fm: 76.880 | p: 76.657 | r: 77.298
r1fm+r2fm = 137.998

input #59 time: 0:08:51 | total time: 9:05:37


Running input #60 of 100.
reference: 
========================
It is likely that Jean left.
========================
average of cosine similarity 0.8719481143251726
highest_index [0]
highest [0.8719481143251726]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2009, 2003, 3497, 2008, 3744, 2187, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] it is likely that jean left. [SEP]']
[Init] best rec loss: 0.9153996109962463 for ['[CLS]ach called vision sea age include wren [SEP]']
[Init] best rec loss: 0.9025992155075073 for ['[CLS] before holy sidelk genre behavior res [SEP]']
[Init] best rec loss: 0.9007689356803894 for ['[CLS] citizensains analog trailer spelling along ken [SEP]']
[Init] best perm rec loss: 0.8963147401809692 for ['[CLS] ken along spelling analog citizensains trailer [SEP]']
[Init] best perm rec loss: 0.8957781195640564 for ['[CLS] spelling analog along kenains trailer citizens [SEP]']
[Init] best perm rec loss: 0.8947465419769287 for ['[CLS] trailerains spelling citizens analog along ken [SEP]']
[Init] best perm rec loss: 0.8947036266326904 for ['[CLS] spelling analog kenains along trailer citizens [SEP]']
[Init] best perm rec loss: 0.8939144015312195 for ['[CLS] spellingains ken trailer along citizens analog [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.246 (perp=8.238, rec=0.370, cos=0.228), tot_loss_proj:3.519 [t=0.23s]
prediction: ['[CLS] leaving jean. ( leaving dick maybe [SEP]']
[ 100/2000] tot_loss=1.988 (perp=7.365, rec=0.278, cos=0.237), tot_loss_proj:3.203 [t=0.23s]
prediction: ['[CLS] probably jean.. probably left. [SEP]']
[ 150/2000] tot_loss=2.379 (perp=8.976, rec=0.337, cos=0.246), tot_loss_proj:3.680 [t=0.23s]
prediction: ['[CLS] nor jean has leaves possibly left. [SEP]']
[ 200/2000] tot_loss=2.338 (perp=9.497, rec=0.200, cos=0.239), tot_loss_proj:3.699 [t=0.23s]
prediction: ['[CLS] probably jean has leaves likely left. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.135 (perp=8.546, rec=0.186, cos=0.240), tot_loss_proj:3.511 [t=0.23s]
prediction: ['[CLS] jean probably likely. likely left. [SEP]']
[ 300/2000] tot_loss=2.114 (perp=8.570, rec=0.162, cos=0.238), tot_loss_proj:3.458 [t=0.23s]
prediction: ['[CLS] jean likely likely. likely left. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.074 (perp=8.412, rec=0.154, cos=0.238), tot_loss_proj:3.496 [t=0.23s]
prediction: ['[CLS] jean probably jean likely left.. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.890 (perp=7.528, rec=0.147, cos=0.237), tot_loss_proj:3.375 [t=0.23s]
prediction: ['[CLS] jean that jean likely left.. [SEP]']
[ 450/2000] tot_loss=1.865 (perp=7.528, rec=0.120, cos=0.239), tot_loss_proj:3.376 [t=0.30s]
prediction: ['[CLS] jean that jean likely left.. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.865 (perp=7.528, rec=0.121, cos=0.239), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] jean that jean likely left.. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.848 (perp=7.473, rec=0.117, cos=0.236), tot_loss_proj:3.368 [t=0.23s]
prediction: ['[CLS] jean jean that likely left.. [SEP]']
[ 600/2000] tot_loss=1.846 (perp=7.473, rec=0.112, cos=0.239), tot_loss_proj:3.370 [t=0.23s]
prediction: ['[CLS] jean jean that likely left.. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.846 (perp=7.473, rec=0.112, cos=0.239), tot_loss_proj:3.372 [t=0.23s]
prediction: ['[CLS] jean jean that likely left.. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.845 (perp=7.473, rec=0.111, cos=0.239), tot_loss_proj:3.370 [t=0.23s]
prediction: ['[CLS] jean jean that likely left.. [SEP]']
[ 750/2000] tot_loss=2.050 (perp=8.529, rec=0.105, cos=0.239), tot_loss_proj:3.510 [t=0.23s]
prediction: ['[CLS] jean isn that likely left.. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.054 (perp=8.529, rec=0.109, cos=0.239), tot_loss_proj:3.511 [t=0.23s]
prediction: ['[CLS] jean isn that likely left.. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.666 (perp=6.664, rec=0.099, cos=0.234), tot_loss_proj:3.167 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
[ 900/2000] tot_loss=1.676 (perp=6.664, rec=0.105, cos=0.238), tot_loss_proj:3.164 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.673 (perp=6.664, rec=0.102, cos=0.238), tot_loss_proj:3.167 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.657 (perp=6.664, rec=0.086, cos=0.238), tot_loss_proj:3.169 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
[1050/2000] tot_loss=1.662 (perp=6.664, rec=0.090, cos=0.239), tot_loss_proj:3.162 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.661 (perp=6.664, rec=0.089, cos=0.239), tot_loss_proj:3.169 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.649 (perp=6.664, rec=0.077, cos=0.239), tot_loss_proj:3.169 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
[1200/2000] tot_loss=1.649 (perp=6.664, rec=0.077, cos=0.239), tot_loss_proj:3.168 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.665 (perp=6.664, rec=0.093, cos=0.239), tot_loss_proj:3.168 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.653 (perp=6.664, rec=0.082, cos=0.239), tot_loss_proj:3.165 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
[1350/2000] tot_loss=1.654 (perp=6.664, rec=0.082, cos=0.239), tot_loss_proj:3.166 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.650 (perp=6.664, rec=0.078, cos=0.239), tot_loss_proj:3.169 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.658 (perp=6.664, rec=0.086, cos=0.240), tot_loss_proj:3.168 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
[1500/2000] tot_loss=1.647 (perp=6.664, rec=0.075, cos=0.240), tot_loss_proj:3.167 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.650 (perp=6.664, rec=0.078, cos=0.240), tot_loss_proj:3.169 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.647 (perp=6.664, rec=0.075, cos=0.240), tot_loss_proj:3.170 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
[1650/2000] tot_loss=1.652 (perp=6.664, rec=0.080, cos=0.239), tot_loss_proj:3.168 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.649 (perp=6.664, rec=0.076, cos=0.240), tot_loss_proj:3.170 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.650 (perp=6.664, rec=0.078, cos=0.240), tot_loss_proj:3.165 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
[1800/2000] tot_loss=1.645 (perp=6.664, rec=0.073, cos=0.240), tot_loss_proj:3.164 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.654 (perp=6.664, rec=0.081, cos=0.240), tot_loss_proj:3.170 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.655 (perp=6.664, rec=0.083, cos=0.240), tot_loss_proj:3.168 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
[1950/2000] tot_loss=1.653 (perp=6.664, rec=0.080, cos=0.240), tot_loss_proj:3.168 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.645 (perp=6.664, rec=0.073, cos=0.239), tot_loss_proj:3.170 [t=0.23s]
prediction: ['[CLS] jean is likely that left.. [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] it is likely that jean left. [SEP]
========================
predicted: 
========================
[CLS] jean is likely that left.. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 100.000 | r: 87.500
rouge2     | fm: 46.154 | p: 50.000 | r: 42.857
rougeL     | fm: 80.000 | p: 85.714 | r: 75.000
rougeLsum  | fm: 80.000 | p: 85.714 | r: 75.000
r1fm+r2fm = 139.487

[Aggregate metrics]:
rouge1     | fm: 87.211 | p: 87.084 | r: 87.588
rouge2     | fm: 50.719 | p: 50.502 | r: 51.034
rougeL     | fm: 76.886 | p: 76.790 | r: 77.214
rougeLsum  | fm: 76.928 | p: 76.791 | r: 77.170
r1fm+r2fm = 137.930

input #60 time: 0:09:09 | total time: 9:14:47


Running input #61 of 100.
reference: 
========================
Physicists like yourself are a godsend.
========================
average of cosine similarity 0.8975651321504885
highest_index [0]
highest [0.8975651321504885]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 13702,  2015,  2066,  4426,  2024,  1037,  5932, 10497,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] physicists like yourself are a godsend. [SEP]']
[Init] best rec loss: 0.9613419771194458 for ['[CLS]serromatic rescue object morning which viable for seeking [SEP]']
[Init] best rec loss: 0.9228870272636414 for ['[CLS] 1939ilation never languagesholdingraction shop life ne [SEP]']
[Init] best rec loss: 0.8715111613273621 for ['[CLS] force almost versioncs hades carolyn morrison cab gave [SEP]']
[Init] best rec loss: 0.871036946773529 for ['[CLS] proud mutual nathan sony valencia dante bald alexiaati [SEP]']
[Init] best rec loss: 0.8663026094436646 for ['[CLS] decline hoover odd cesar been pull guys afb kyle [SEP]']
[Init] best rec loss: 0.8628185987472534 for ['[CLS]che practical trust sport centre think startingtage cycling [SEP]']
[Init] best perm rec loss: 0.8595981597900391 for ['[CLS] practicalche sport cycling starting trust centre thinktage [SEP]']
[Init] best perm rec loss: 0.8580878376960754 for ['[CLS] practical think centre cycling sport trust startingtageche [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.878 (perp=12.906, rec=0.573, cos=0.724), tot_loss_proj:4.489 [t=0.23s]
prediction: ['[CLS] types model scientific physicist your myself premise : blame [SEP]']
[ 100/2000] tot_loss=2.507 (perp=10.327, rec=0.257, cos=0.184), tot_loss_proj:3.935 [t=0.23s]
prediction: ['[CLS] like like physicist physicist yourself your yourself. doom [SEP]']
[ 150/2000] tot_loss=2.527 (perp=10.053, rec=0.291, cos=0.226), tot_loss_proj:3.838 [t=0.23s]
prediction: ['[CLS] like like particles physicist yourself resemble yourself is. [SEP]']
[ 200/2000] tot_loss=1.953 (perp=7.949, rec=0.171, cos=0.192), tot_loss_proj:3.415 [t=0.23s]
prediction: ['[CLS] like physics you physicist yourself resemble yourself are. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.730 (perp=6.944, rec=0.153, cos=0.189), tot_loss_proj:3.245 [t=0.23s]
prediction: ['[CLS] like physics you physicist yourself are yourself are. [SEP]']
[ 300/2000] tot_loss=1.920 (perp=7.968, rec=0.137, cos=0.190), tot_loss_proj:3.393 [t=0.23s]
prediction: ['[CLS] like physicists physicist yourself are aend. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.242 (perp=8.980, rec=0.262, cos=0.184), tot_loss_proj:3.600 [t=0.23s]
prediction: ['[CLS] like scientists are yourself are myself physicist. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.917 (perp=7.792, rec=0.176, cos=0.183), tot_loss_proj:3.353 [t=0.23s]
prediction: ['[CLS] like philosopher physicists ( yourself are yourself. [SEP]']
[ 450/2000] tot_loss=1.948 (perp=8.076, rec=0.139, cos=0.194), tot_loss_proj:3.449 [t=0.23s]
prediction: ['[CLS] like philosopher physicistsend yourself are yourself. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.853 (perp=7.678, rec=0.123, cos=0.194), tot_loss_proj:3.377 [t=0.23s]
prediction: ['[CLS] like philosopherends physicist yourself are yourself. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.856 (perp=7.678, rec=0.126, cos=0.193), tot_loss_proj:3.371 [t=0.23s]
prediction: ['[CLS] like philosopherends physicist yourself are yourself. [SEP]']
[ 600/2000] tot_loss=1.851 (perp=7.678, rec=0.123, cos=0.192), tot_loss_proj:3.375 [t=0.23s]
prediction: ['[CLS] like philosopherends physicist yourself are yourself. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.835 (perp=7.678, rec=0.106, cos=0.193), tot_loss_proj:3.377 [t=0.23s]
prediction: ['[CLS] like philosopherends physicist yourself are yourself. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.832 (perp=7.678, rec=0.103, cos=0.194), tot_loss_proj:3.375 [t=0.23s]
prediction: ['[CLS] like philosopherends physicist yourself are yourself. [SEP]']
[ 750/2000] tot_loss=1.833 (perp=7.678, rec=0.103, cos=0.194), tot_loss_proj:3.374 [t=0.23s]
prediction: ['[CLS] like philosopherends physicist yourself are yourself. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.714 (perp=7.079, rec=0.106, cos=0.192), tot_loss_proj:3.281 [t=0.23s]
prediction: ['[CLS] like aends physicist yourself are yourself. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.717 (perp=7.079, rec=0.108, cos=0.193), tot_loss_proj:3.276 [t=0.23s]
prediction: ['[CLS] like aends physicist yourself are yourself. [SEP]']
[ 900/2000] tot_loss=1.713 (perp=7.079, rec=0.104, cos=0.193), tot_loss_proj:3.281 [t=0.23s]
prediction: ['[CLS] like aends physicist yourself are yourself. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.718 (perp=7.079, rec=0.108, cos=0.194), tot_loss_proj:3.277 [t=0.23s]
prediction: ['[CLS] like aends physicist yourself are yourself. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.702 (perp=7.079, rec=0.091, cos=0.194), tot_loss_proj:3.277 [t=0.23s]
prediction: ['[CLS] like aends physicist yourself are yourself. [SEP]']
[1050/2000] tot_loss=1.712 (perp=7.079, rec=0.103, cos=0.193), tot_loss_proj:3.276 [t=0.23s]
prediction: ['[CLS] like aends physicist yourself are yourself. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.720 (perp=7.079, rec=0.110, cos=0.194), tot_loss_proj:3.279 [t=0.23s]
prediction: ['[CLS] like aends physicist yourself are yourself. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.837 (perp=7.755, rec=0.091, cos=0.194), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
[1200/2000] tot_loss=1.851 (perp=7.755, rec=0.105, cos=0.194), tot_loss_proj:3.426 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.843 (perp=7.755, rec=0.098, cos=0.194), tot_loss_proj:3.421 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.844 (perp=7.755, rec=0.099, cos=0.194), tot_loss_proj:3.424 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
[1350/2000] tot_loss=1.841 (perp=7.755, rec=0.097, cos=0.194), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.848 (perp=7.755, rec=0.103, cos=0.194), tot_loss_proj:3.429 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.838 (perp=7.755, rec=0.093, cos=0.194), tot_loss_proj:3.428 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
[1500/2000] tot_loss=1.840 (perp=7.755, rec=0.095, cos=0.194), tot_loss_proj:3.421 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.836 (perp=7.755, rec=0.091, cos=0.194), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.848 (perp=7.755, rec=0.103, cos=0.194), tot_loss_proj:3.430 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
[1650/2000] tot_loss=1.843 (perp=7.755, rec=0.098, cos=0.194), tot_loss_proj:3.423 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.828 (perp=7.755, rec=0.083, cos=0.194), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.844 (perp=7.755, rec=0.098, cos=0.194), tot_loss_proj:3.427 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
[1800/2000] tot_loss=1.843 (perp=7.755, rec=0.098, cos=0.194), tot_loss_proj:3.423 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.846 (perp=7.755, rec=0.101, cos=0.194), tot_loss_proj:3.429 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.846 (perp=7.755, rec=0.101, cos=0.194), tot_loss_proj:3.428 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
[1950/2000] tot_loss=1.841 (perp=7.755, rec=0.096, cos=0.194), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.831 (perp=7.755, rec=0.085, cos=0.194), tot_loss_proj:3.426 [t=0.23s]
prediction: ['[CLS] like godsends physicist yourself are yourself. [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS] physicists like yourself are a godsend. [SEP]
========================
predicted: 
========================
[CLS] like godsends physicist yourself are yourself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.500 | p: 62.500 | r: 62.500
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 76.786

[Aggregate metrics]:
rouge1     | fm: 86.878 | p: 86.691 | r: 87.227
rouge2     | fm: 50.179 | p: 49.956 | r: 50.471
rougeL     | fm: 76.690 | p: 76.561 | r: 76.954
rougeLsum  | fm: 76.840 | p: 76.624 | r: 77.221
r1fm+r2fm = 137.057

input #61 time: 0:09:09 | total time: 9:23:57


Running input #62 of 100.
reference: 
========================
Any pilot could be flying this plane.
========================
average of cosine similarity 0.9168019262534469
highest_index [0]
highest [0.9168019262534469]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2151, 4405, 2071, 2022, 3909, 2023, 4946, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] any pilot could be flying this plane. [SEP]']
[Init] best rec loss: 0.9536443948745728 for ['[CLS] events heat names cole issue. 505 regina [SEP]']
[Init] best rec loss: 0.9190136790275574 for ['[CLS] from actress le testament sooner pit confederacy oct [SEP]']
[Init] best rec loss: 0.9045023918151855 for ['[CLS] anywhere arrows except incident public broadcasting belongedship [SEP]']
[Init] best rec loss: 0.8974034786224365 for ['[CLS] care as oldestma hay wisconsinthes what [SEP]']
[Init] best rec loss: 0.8745935559272766 for ['[CLS]fast answer managed zurich twin sister [MASK] footprint [SEP]']
[Init] best rec loss: 0.8716539740562439 for ['[CLS] order passagemet straits since howkey equally [SEP]']
[Init] best rec loss: 0.8469351530075073 for ['[CLS] legislative barked emigrated pac bone paramount reelection short [SEP]']
[Init] best rec loss: 0.8436610698699951 for ['[CLS]ович ontario thunder listener is unit consider minister [SEP]']
[Init] best perm rec loss: 0.8429796695709229 for ['[CLS] minister is thunder consider listener unit ontarioович [SEP]']
[Init] best perm rec loss: 0.8414999842643738 for ['[CLS] unitович thunder is minister ontario listener consider [SEP]']
[Init] best perm rec loss: 0.8384678363800049 for ['[CLS] consider unit thunder ontario minister listenerович is [SEP]']
[Init] best perm rec loss: 0.8384048342704773 for ['[CLS] unitович thunder minister is listener consider ontario [SEP]']
[Init] best perm rec loss: 0.8380648493766785 for ['[CLS] unit is thunder consider minister listener ontarioович [SEP]']
[Init] best perm rec loss: 0.8380370140075684 for ['[CLS] listener thunderович ontario consider minister is unit [SEP]']
[Init] best perm rec loss: 0.8366026282310486 for ['[CLS] listener consider thunderович minister is unit ontario [SEP]']
[Init] best perm rec loss: 0.8357937932014465 for ['[CLS] listener unit thunderович ontario minister is consider [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.680 (perp=10.616, rec=0.418, cos=0.139), tot_loss_proj:3.981 [t=0.23s]
prediction: ['[CLS] civilian pilot daddy. seamus any flight could [SEP]']
[ 100/2000] tot_loss=2.124 (perp=8.571, rec=0.276, cos=0.134), tot_loss_proj:3.654 [t=0.23s]
prediction: ['[CLS] any pilotight could any pilot pilot could [SEP]']
[ 150/2000] tot_loss=2.124 (perp=8.629, rec=0.210, cos=0.187), tot_loss_proj:3.672 [t=0.23s]
prediction: ['[CLS] any pilotight could any flying pilot could [SEP]']
[ 200/2000] tot_loss=2.170 (perp=9.202, rec=0.177, cos=0.153), tot_loss_proj:3.742 [t=0.23s]
prediction: ['[CLS] any planerdial could any flying pilot could [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.183 (perp=9.202, rec=0.169, cos=0.174), tot_loss_proj:3.744 [t=0.23s]
prediction: ['[CLS] any planerdial could any flying pilot could [SEP]']
[ 300/2000] tot_loss=2.149 (perp=9.202, rec=0.170, cos=0.139), tot_loss_proj:3.750 [t=0.23s]
prediction: ['[CLS] any planerdial could any flying pilot could [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.197 (perp=9.224, rec=0.204, cos=0.148), tot_loss_proj:3.826 [t=0.23s]
prediction: ['[CLS] any plane could ferrari any this pilot would [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.194 (perp=9.282, rec=0.179, cos=0.159), tot_loss_proj:3.802 [t=0.23s]
prediction: ['[CLS] this plane couldrdial any this pilot would [SEP]']
[ 450/2000] tot_loss=2.343 (perp=10.048, rec=0.179, cos=0.154), tot_loss_proj:3.957 [t=0.23s]
prediction: ['[CLS] whether plane couldrdial any this pilot would [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.200 (perp=9.387, rec=0.174, cos=0.149), tot_loss_proj:3.755 [t=0.23s]
prediction: ['[CLS] any plane couldrdial anywhere this pilot would [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.185 (perp=9.308, rec=0.162, cos=0.162), tot_loss_proj:3.779 [t=0.23s]
prediction: ['[CLS] any plane couldrdial this this pilot would [SEP]']
[ 600/2000] tot_loss=2.169 (perp=9.308, rec=0.160, cos=0.147), tot_loss_proj:3.777 [t=0.23s]
prediction: ['[CLS] any plane couldrdial this this pilot would [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.139 (perp=9.058, rec=0.168, cos=0.159), tot_loss_proj:3.768 [t=0.23s]
prediction: ['[CLS] any plane couldrdial this pilot this would [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.137 (perp=9.058, rec=0.172, cos=0.153), tot_loss_proj:3.767 [t=0.23s]
prediction: ['[CLS] any plane couldrdial this pilot this would [SEP]']
[ 750/2000] tot_loss=1.920 (perp=7.971, rec=0.163, cos=0.163), tot_loss_proj:3.455 [t=0.23s]
prediction: ['[CLS] any plane couldअ this pilot this. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.994 (perp=8.441, rec=0.155, cos=0.151), tot_loss_proj:3.594 [t=0.23s]
prediction: ['[CLS] any plane couldonate this pilot this. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.944 (perp=8.025, rec=0.179, cos=0.160), tot_loss_proj:2.798 [t=0.23s]
prediction: ['[CLS] any plane couldonate this. this pilot [SEP]']
[ 900/2000] tot_loss=1.926 (perp=8.025, rec=0.162, cos=0.159), tot_loss_proj:2.801 [t=0.23s]
prediction: ['[CLS] any plane couldonate this. this pilot [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.997 (perp=8.404, rec=0.160, cos=0.156), tot_loss_proj:2.928 [t=0.23s]
prediction: ['[CLS] any plane couldonate these. this pilot [SEP]']
Attempt swap
[1000/2000] tot_loss=2.005 (perp=8.404, rec=0.167, cos=0.156), tot_loss_proj:2.920 [t=0.23s]
prediction: ['[CLS] any plane couldonate these. this pilot [SEP]']
[1050/2000] tot_loss=2.003 (perp=8.404, rec=0.166, cos=0.156), tot_loss_proj:2.921 [t=0.23s]
prediction: ['[CLS] any plane couldonate these. this pilot [SEP]']
Attempt swap
[1100/2000] tot_loss=1.999 (perp=8.404, rec=0.160, cos=0.158), tot_loss_proj:2.918 [t=0.23s]
prediction: ['[CLS] any plane couldonate these. this pilot [SEP]']
Attempt swap
[1150/2000] tot_loss=2.004 (perp=8.404, rec=0.172, cos=0.152), tot_loss_proj:2.919 [t=0.23s]
prediction: ['[CLS] any plane couldonate these. this pilot [SEP]']
[1200/2000] tot_loss=1.988 (perp=8.404, rec=0.156, cos=0.151), tot_loss_proj:2.917 [t=0.23s]
prediction: ['[CLS] any plane couldonate these. this pilot [SEP]']
Attempt swap
[1250/2000] tot_loss=1.996 (perp=8.404, rec=0.158, cos=0.157), tot_loss_proj:2.912 [t=0.23s]
prediction: ['[CLS] any plane couldonate these. this pilot [SEP]']
Attempt swap
[1300/2000] tot_loss=1.995 (perp=8.404, rec=0.157, cos=0.157), tot_loss_proj:2.917 [t=0.23s]
prediction: ['[CLS] any plane couldonate these. this pilot [SEP]']
[1350/2000] tot_loss=1.999 (perp=8.404, rec=0.160, cos=0.158), tot_loss_proj:2.916 [t=0.23s]
prediction: ['[CLS] any plane couldonate these. this pilot [SEP]']
Attempt swap
[1400/2000] tot_loss=1.998 (perp=8.404, rec=0.159, cos=0.157), tot_loss_proj:2.911 [t=0.23s]
prediction: ['[CLS] any plane couldonate these. this pilot [SEP]']
Attempt swap
[1450/2000] tot_loss=1.993 (perp=8.404, rec=0.151, cos=0.161), tot_loss_proj:2.912 [t=0.23s]
prediction: ['[CLS] any plane couldonate these. this pilot [SEP]']
[1500/2000] tot_loss=1.997 (perp=8.425, rec=0.153, cos=0.159), tot_loss_proj:3.514 [t=0.23s]
prediction: ['[CLS] any plane couldulo these. this pilot [SEP]']
Attempt swap
[1550/2000] tot_loss=2.003 (perp=8.425, rec=0.157, cos=0.161), tot_loss_proj:3.510 [t=0.23s]
prediction: ['[CLS] any plane couldulo these. this pilot [SEP]']
Attempt swap
[1600/2000] tot_loss=2.001 (perp=8.425, rec=0.156, cos=0.160), tot_loss_proj:3.513 [t=0.23s]
prediction: ['[CLS] any plane couldulo these. this pilot [SEP]']
[1650/2000] tot_loss=2.001 (perp=8.425, rec=0.155, cos=0.160), tot_loss_proj:3.511 [t=0.23s]
prediction: ['[CLS] any plane couldulo these. this pilot [SEP]']
Attempt swap
[1700/2000] tot_loss=1.994 (perp=8.425, rec=0.153, cos=0.156), tot_loss_proj:3.520 [t=0.23s]
prediction: ['[CLS] any plane couldulo these. this pilot [SEP]']
Attempt swap
[1750/2000] tot_loss=2.006 (perp=8.425, rec=0.163, cos=0.158), tot_loss_proj:3.516 [t=0.23s]
prediction: ['[CLS] any plane couldulo these. this pilot [SEP]']
[1800/2000] tot_loss=1.995 (perp=8.425, rec=0.152, cos=0.158), tot_loss_proj:3.510 [t=0.23s]
prediction: ['[CLS] any plane couldulo these. this pilot [SEP]']
Attempt swap
[1850/2000] tot_loss=2.011 (perp=8.425, rec=0.168, cos=0.157), tot_loss_proj:3.510 [t=0.23s]
prediction: ['[CLS] any plane couldulo these. this pilot [SEP]']
Attempt swap
[1900/2000] tot_loss=2.004 (perp=8.425, rec=0.160, cos=0.159), tot_loss_proj:3.518 [t=0.23s]
prediction: ['[CLS] any plane couldulo these. this pilot [SEP]']
[1950/2000] tot_loss=2.000 (perp=8.425, rec=0.157, cos=0.157), tot_loss_proj:3.517 [t=0.23s]
prediction: ['[CLS] any plane couldulo these. this pilot [SEP]']
Attempt swap
[2000/2000] tot_loss=2.001 (perp=8.425, rec=0.157, cos=0.159), tot_loss_proj:3.512 [t=0.23s]
prediction: ['[CLS] any plane couldulo these. this pilot [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] any pilot could be flying this plane. [SEP]
========================
predicted: 
========================
[CLS] any plane couldulo these. this pilot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 75.000 | r: 66.667
rouge2     | fm: 13.333 | p: 14.286 | r: 12.500
rougeL     | fm: 47.059 | p: 50.000 | r: 44.444
rougeLsum  | fm: 47.059 | p: 50.000 | r: 44.444
r1fm+r2fm = 83.922

[Aggregate metrics]:
rouge1     | fm: 86.626 | p: 86.515 | r: 86.906
rouge2     | fm: 49.490 | p: 49.397 | r: 49.756
rougeL     | fm: 76.153 | p: 76.106 | r: 76.428
rougeLsum  | fm: 76.393 | p: 76.274 | r: 76.583
r1fm+r2fm = 136.116

input #62 time: 0:09:10 | total time: 9:33:07


Running input #63 of 100.
reference: 
========================
We wonder if Bill left.
========================
average of cosine similarity 0.8960367689280537
highest_index [0]
highest [0.8960367689280537]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2057, 4687, 2065, 3021, 2187, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] we wonder if bill left. [SEP]']
[Init] best rec loss: 0.9158187508583069 for ['[CLS] affected maine effect streets studies its [SEP]']
[Init] best rec loss: 0.9018704891204834 for ['[CLS] erica monk val contestbe foreign [SEP]']
[Init] best rec loss: 0.8733432292938232 for ['[CLS] talk rot audience tobiasnets died [SEP]']
[Init] best rec loss: 0.8676167726516724 for ['[CLS] fis project of somecoming elf [SEP]']
[Init] best rec loss: 0.8643891215324402 for ['[CLS] [CLS]line subcontinent context platforms tessa [SEP]']
[Init] best perm rec loss: 0.8622534871101379 for ['[CLS]line [CLS] subcontinent context platforms tessa [SEP]']
[Init] best perm rec loss: 0.8575989603996277 for ['[CLS] context subcontinentline [CLS] platforms tessa [SEP]']
[Init] best perm rec loss: 0.8573761582374573 for ['[CLS] tessa subcontinent contextline platforms [CLS] [SEP]']
[Init] best perm rec loss: 0.8573402166366577 for ['[CLS] tessaline subcontinent context platforms [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.093 (perp=12.090, rec=0.480, cos=0.195), tot_loss_proj:4.216 [t=0.23s]
prediction: ['[CLS]lysis regiment polo. neck wondered [SEP]']
[ 100/2000] tot_loss=2.428 (perp=9.295, rec=0.376, cos=0.193), tot_loss_proj:3.727 [t=0.23s]
prediction: ['[CLS] we why bill. we wonder [SEP]']
[ 150/2000] tot_loss=2.280 (perp=8.977, rec=0.288, cos=0.197), tot_loss_proj:3.603 [t=0.23s]
prediction: ['[CLS] we if bill. we wonder [SEP]']
[ 200/2000] tot_loss=2.276 (perp=9.312, rec=0.221, cos=0.192), tot_loss_proj:3.642 [t=0.23s]
prediction: ['[CLS] we if bill left we wonder [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.277 (perp=9.312, rec=0.218, cos=0.197), tot_loss_proj:2.978 [t=0.23s]
prediction: ['[CLS] we wonder if bill left mothers [SEP]']
[ 300/2000] tot_loss=1.992 (perp=8.059, rec=0.184, cos=0.196), tot_loss_proj:2.502 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.978 (perp=8.059, rec=0.174, cos=0.192), tot_loss_proj:2.494 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.985 (perp=8.059, rec=0.178, cos=0.195), tot_loss_proj:2.502 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[ 450/2000] tot_loss=1.989 (perp=8.059, rec=0.182, cos=0.196), tot_loss_proj:2.500 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.982 (perp=8.059, rec=0.178, cos=0.193), tot_loss_proj:2.500 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.985 (perp=8.059, rec=0.180, cos=0.193), tot_loss_proj:2.502 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[ 600/2000] tot_loss=1.980 (perp=8.059, rec=0.171, cos=0.198), tot_loss_proj:2.505 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.981 (perp=8.059, rec=0.171, cos=0.198), tot_loss_proj:2.512 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.982 (perp=8.059, rec=0.174, cos=0.197), tot_loss_proj:2.504 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[ 750/2000] tot_loss=1.977 (perp=8.059, rec=0.174, cos=0.191), tot_loss_proj:2.513 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.972 (perp=8.059, rec=0.169, cos=0.192), tot_loss_proj:2.517 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.965 (perp=8.059, rec=0.159, cos=0.194), tot_loss_proj:2.514 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[ 900/2000] tot_loss=1.969 (perp=8.059, rec=0.165, cos=0.193), tot_loss_proj:2.512 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.980 (perp=8.059, rec=0.166, cos=0.202), tot_loss_proj:2.519 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1000/2000] tot_loss=1.972 (perp=8.059, rec=0.163, cos=0.197), tot_loss_proj:2.513 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1050/2000] tot_loss=1.978 (perp=8.059, rec=0.166, cos=0.200), tot_loss_proj:2.520 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1100/2000] tot_loss=1.967 (perp=8.059, rec=0.159, cos=0.196), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1150/2000] tot_loss=1.980 (perp=8.059, rec=0.172, cos=0.196), tot_loss_proj:2.520 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1200/2000] tot_loss=1.973 (perp=8.059, rec=0.167, cos=0.194), tot_loss_proj:2.522 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1250/2000] tot_loss=1.975 (perp=8.059, rec=0.168, cos=0.196), tot_loss_proj:2.524 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1300/2000] tot_loss=1.984 (perp=8.059, rec=0.176, cos=0.196), tot_loss_proj:2.521 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1350/2000] tot_loss=1.971 (perp=8.059, rec=0.164, cos=0.195), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1400/2000] tot_loss=1.968 (perp=8.059, rec=0.160, cos=0.196), tot_loss_proj:2.526 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1450/2000] tot_loss=1.972 (perp=8.059, rec=0.165, cos=0.196), tot_loss_proj:2.525 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1500/2000] tot_loss=1.976 (perp=8.059, rec=0.167, cos=0.197), tot_loss_proj:2.522 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1550/2000] tot_loss=1.966 (perp=8.059, rec=0.158, cos=0.197), tot_loss_proj:2.520 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1600/2000] tot_loss=1.975 (perp=8.059, rec=0.167, cos=0.196), tot_loss_proj:2.527 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1650/2000] tot_loss=1.974 (perp=8.059, rec=0.166, cos=0.196), tot_loss_proj:2.526 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1700/2000] tot_loss=1.970 (perp=8.059, rec=0.162, cos=0.197), tot_loss_proj:2.528 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1750/2000] tot_loss=1.974 (perp=8.059, rec=0.165, cos=0.197), tot_loss_proj:2.526 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1800/2000] tot_loss=1.971 (perp=8.059, rec=0.163, cos=0.197), tot_loss_proj:2.529 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1850/2000] tot_loss=1.972 (perp=8.059, rec=0.163, cos=0.197), tot_loss_proj:2.525 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1900/2000] tot_loss=1.973 (perp=8.059, rec=0.164, cos=0.197), tot_loss_proj:2.529 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1950/2000] tot_loss=1.964 (perp=8.059, rec=0.156, cos=0.196), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[2000/2000] tot_loss=1.970 (perp=8.059, rec=0.162, cos=0.196), tot_loss_proj:2.523 [t=0.23s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] we wonder if bill left. [SEP]
========================
predicted: 
========================
[CLS] we wonder if bill left bill [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 86.731 | p: 86.560 | r: 87.091
rouge2     | fm: 49.862 | p: 49.629 | r: 50.224
rougeL     | fm: 76.485 | p: 76.360 | r: 76.766
rougeLsum  | fm: 76.646 | p: 76.451 | r: 77.031
r1fm+r2fm = 136.594

input #63 time: 0:09:09 | total time: 9:42:17


Running input #64 of 100.
reference: 
========================
Ellen talked with Helen about the problem.
========================
average of cosine similarity 0.8644622352429855
highest_index [0]
highest [0.8644622352429855]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9155, 5720, 2007, 6330, 2055, 1996, 3291, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] ellen talked with helen about the problem. [SEP]']
[Init] best rec loss: 0.9399735331535339 for ['[CLS] states gmina auction monument worthy than kennedy urban [SEP]']
[Init] best rec loss: 0.9313696622848511 for ['[CLS] paste resources thick replacementst felt. lynn [SEP]']
[Init] best rec loss: 0.9009097814559937 for ['[CLS] davis dryingprint outside probably alf beast brewing [SEP]']
[Init] best rec loss: 0.897223949432373 for ['[CLS] mining streets bagiation jai take rejectsyp [SEP]']
[Init] best rec loss: 0.8781299591064453 for ['[CLS] seems fear stop trainingple shield > rush [SEP]']
[Init] best perm rec loss: 0.8762060403823853 for ['[CLS] stop seems shieldple rush > training fear [SEP]']
[Init] best perm rec loss: 0.8761703372001648 for ['[CLS] seems fear rush stop training >ple shield [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.475 (perp=9.675, rec=0.292, cos=0.249), tot_loss_proj:3.808 [t=0.23s]
prediction: ['[CLS] ellen versus. ellen after ellen trojan farms [SEP]']
[ 100/2000] tot_loss=2.980 (perp=12.547, rec=0.221, cos=0.249), tot_loss_proj:4.289 [t=0.23s]
prediction: ['[CLS] ellen scare talked helen bout ellen problem. [SEP]']
[ 150/2000] tot_loss=2.600 (perp=10.973, rec=0.154, cos=0.251), tot_loss_proj:3.935 [t=0.23s]
prediction: ['[CLS] ellen scare talked helen about ellen problem. [SEP]']
[ 200/2000] tot_loss=2.365 (perp=9.993, rec=0.115, cos=0.251), tot_loss_proj:3.781 [t=0.23s]
prediction: ['[CLS] ellen talked talked helen about ellen problem. [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.359 (perp=9.993, rec=0.107, cos=0.253), tot_loss_proj:3.779 [t=0.23s]
prediction: ['[CLS] ellen talked talked helen about ellen problem. [SEP]']
[ 300/2000] tot_loss=2.350 (perp=9.993, rec=0.100, cos=0.252), tot_loss_proj:3.777 [t=0.23s]
prediction: ['[CLS] ellen talked talked helen about ellen problem. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.182 (perp=9.148, rec=0.102, cos=0.251), tot_loss_proj:3.578 [t=0.23s]
prediction: ['[CLS] ellen ellen talked helen about with problem. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.333 (perp=9.618, rec=0.157, cos=0.253), tot_loss_proj:3.732 [t=0.23s]
prediction: ['[CLS] ellen ellen talked discuss helen about problem. [SEP]']
[ 450/2000] tot_loss=2.057 (perp=8.474, rec=0.110, cos=0.252), tot_loss_proj:3.500 [t=0.23s]
prediction: ['[CLS] ellen ellen talked with helen about problem. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.954 (perp=7.953, rec=0.112, cos=0.252), tot_loss_proj:3.381 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about helen with problem. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.946 (perp=7.953, rec=0.103, cos=0.252), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about helen with problem. [SEP]']
[ 600/2000] tot_loss=1.940 (perp=7.953, rec=0.097, cos=0.252), tot_loss_proj:3.379 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about helen with problem. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.841 (perp=7.479, rec=0.093, cos=0.252), tot_loss_proj:3.334 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.831 (perp=7.479, rec=0.083, cos=0.253), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
[ 750/2000] tot_loss=1.833 (perp=7.479, rec=0.084, cos=0.252), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.831 (perp=7.479, rec=0.083, cos=0.252), tot_loss_proj:3.338 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.826 (perp=7.479, rec=0.077, cos=0.252), tot_loss_proj:3.338 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
[ 900/2000] tot_loss=1.828 (perp=7.479, rec=0.079, cos=0.253), tot_loss_proj:3.343 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.828 (perp=7.479, rec=0.080, cos=0.253), tot_loss_proj:3.339 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.824 (perp=7.479, rec=0.076, cos=0.253), tot_loss_proj:3.339 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
[1050/2000] tot_loss=1.822 (perp=7.479, rec=0.073, cos=0.253), tot_loss_proj:3.335 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.827 (perp=7.479, rec=0.079, cos=0.253), tot_loss_proj:3.341 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.817 (perp=7.479, rec=0.068, cos=0.252), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
[1200/2000] tot_loss=1.822 (perp=7.479, rec=0.074, cos=0.253), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.827 (perp=7.479, rec=0.079, cos=0.253), tot_loss_proj:3.338 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.819 (perp=7.479, rec=0.071, cos=0.252), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
[1350/2000] tot_loss=1.825 (perp=7.479, rec=0.077, cos=0.253), tot_loss_proj:3.338 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.831 (perp=7.479, rec=0.083, cos=0.253), tot_loss_proj:3.339 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.829 (perp=7.479, rec=0.081, cos=0.253), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
[1500/2000] tot_loss=1.826 (perp=7.479, rec=0.078, cos=0.253), tot_loss_proj:3.339 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.832 (perp=7.479, rec=0.083, cos=0.253), tot_loss_proj:3.339 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.822 (perp=7.479, rec=0.073, cos=0.253), tot_loss_proj:3.338 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
[1650/2000] tot_loss=1.818 (perp=7.479, rec=0.069, cos=0.253), tot_loss_proj:3.340 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.829 (perp=7.479, rec=0.081, cos=0.253), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.819 (perp=7.479, rec=0.071, cos=0.253), tot_loss_proj:3.339 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
[1800/2000] tot_loss=1.824 (perp=7.479, rec=0.076, cos=0.253), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.822 (perp=7.479, rec=0.074, cos=0.253), tot_loss_proj:3.337 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.816 (perp=7.479, rec=0.068, cos=0.252), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
[1950/2000] tot_loss=1.819 (perp=7.479, rec=0.071, cos=0.253), tot_loss_proj:3.340 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.823 (perp=7.479, rec=0.075, cos=0.253), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] ellen ellen talked about problem with helen. [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] ellen talked with helen about the problem. [SEP]
========================
predicted: 
========================
[CLS] ellen ellen talked about problem with helen. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 126.389

[Aggregate metrics]:
rouge1     | fm: 86.690 | p: 86.468 | r: 87.102
rouge2     | fm: 49.403 | p: 49.086 | r: 49.778
rougeL     | fm: 76.236 | p: 75.994 | r: 76.586
rougeLsum  | fm: 76.348 | p: 76.158 | r: 76.697
r1fm+r2fm = 136.092

input #64 time: 0:09:10 | total time: 9:51:27


Running input #65 of 100.
reference: 
========================
Mag Wildwood came to introduce the bartender but I came precisely not to.
========================
average of cosine similarity 0.902795089580473
highest_index [0]
highest [0.902795089580473]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101, 23848,  3748,  3702,  2234,  2000,  8970,  1996, 15812,  2021,
          1045,  2234, 10785,  2025,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]']
[Init] best rec loss: 0.9173482060432434 for ['[CLS] old shaw mcgill standminated chapter publication legal non penny cheekatics contemporary story fleet [SEP]']
[Init] best rec loss: 0.8966617584228516 for ['[CLS]sume translation towardsitor mollusk oriented virginia small property position deal servedre shadow reports [SEP]']
[Init] best rec loss: 0.8888818025588989 for ['[CLS]hal distributedload thru add sh thermal destinednahdition while saline dirty remake western [SEP]']
[Init] best rec loss: 0.8824454545974731 for ['[CLS] groom ownership hd mellon field house of [SEP]zed lisa iranbreaker bypass short [SEP]']
[Init] best rec loss: 0.8717668652534485 for ['[CLS] over pulse mirror steering travel meter : travelbed nosed opportunity obligations depends splitting notes [SEP]']
[Init] best rec loss: 0.8653556704521179 for ['[CLS] function levi [MASK] historic ce despite mafia unreleased austria often secretary worse moscow fallon so [SEP]']
[Init] best rec loss: 0.8557636141777039 for ['[CLS] pen up throat ≡ eyes dinner elect regulation shallow weakened channel quite airch spread [SEP]']
[Init] best rec loss: 0.8337283730506897 for ['[CLS] wrestlemania application south heritage just er announcement perfect disregard under → bonus through making catholic [SEP]']
[Init] best rec loss: 0.8245692253112793 for ['[CLS] thoughts straw railroadism spainཔ key october gallo pottery national gorilla similar pickup direct [SEP]']
[Init] best rec loss: 0.8101842999458313 for ['[CLS] slot pasoshida suburbanhall were halo sleeping act appears adolph together face false others [SEP]']
[Init] best perm rec loss: 0.8078911900520325 for ['[CLS] paso others slot falseshida sleeping together were adolph appears suburban face halohall act [SEP]']
[Init] best perm rec loss: 0.7987754940986633 for ['[CLS] paso adolph act false suburban together sleepingshida slothall appears halo face were others [SEP]']
[Init] best perm rec loss: 0.7976841330528259 for ['[CLS] sleeping appears falseshida act were adolph slothall halo face others paso together suburban [SEP]']
[Init] best perm rec loss: 0.7970348000526428 for ['[CLS]shida slot were suburban together act others adolphhall paso halo appears face false sleeping [SEP]']
[Init] best perm rec loss: 0.7961583733558655 for ['[CLS] slot halo were suburban acthall false adolphshida paso others appears sleeping face together [SEP]']
[Init] best perm rec loss: 0.7959664463996887 for ['[CLS] appears paso together false were halohall sleeping others act adolph slot faceshida suburban [SEP]']
[Init] best perm rec loss: 0.7885587811470032 for ['[CLS]shida were false act adolph others suburban sleeping halo paso facehall together slot appears [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.139 (perp=12.702, rec=0.439, cos=0.159), tot_loss_proj:4.422 [t=0.23s]
prediction: ['[CLS] whirled would correctly backstage, [SEP] warrior exactly drums otherwise costello specifically animator program techno [SEP]']
[ 100/2000] tot_loss=2.885 (perp=11.882, rec=0.323, cos=0.185), tot_loss_proj:4.282 [t=0.23s]
prediction: ['[CLS] mag came begins " :dicated rapper exactly came alex came precisely who not participate [SEP]']
[ 150/2000] tot_loss=2.964 (perp=12.581, rec=0.279, cos=0.168), tot_loss_proj:4.414 [t=0.24s]
prediction: ['[CLS] mag came mckay ~ when [SEP] rapper exactly came simply came precisely theatrical not respectively [SEP]']
[ 200/2000] tot_loss=2.851 (perp=12.375, rec=0.224, cos=0.152), tot_loss_proj:4.387 [t=0.24s]
prediction: ['[CLS] mag came eyebrows _ coming introduce grows precisely came if came precisely animator not respectively [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.838 (perp=12.303, rec=0.207, cos=0.170), tot_loss_proj:4.397 [t=0.23s]
prediction: ['[CLS] precisely came began mag coming introduce bartender mag came i came precisely animator not introduce [SEP]']
[ 300/2000] tot_loss=2.630 (perp=11.314, rec=0.180, cos=0.186), tot_loss_proj:4.198 [t=0.24s]
prediction: ['[CLS] precisely came began mag came introduce bartender mag came but came precisely unaffected not introduce [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.591 (perp=11.227, rec=0.175, cos=0.171), tot_loss_proj:4.172 [t=0.23s]
prediction: ['[CLS] came precisely begins mag came introduce bartender mag came but came precisely dickens not introduce [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.320 (perp=9.958, rec=0.154, cos=0.174), tot_loss_proj:3.940 [t=0.24s]
prediction: ['[CLS] came precisely begins mag came introduce bartender mag came but came precisely. to introduce [SEP]']
[ 450/2000] tot_loss=2.499 (perp=10.642, rec=0.183, cos=0.187), tot_loss_proj:4.029 [t=0.24s]
prediction: ['[CLS] came preciselyelial mag came introduce bartender mag came but came not. to to [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.296 (perp=9.916, rec=0.151, cos=0.162), tot_loss_proj:3.877 [t=0.24s]
prediction: ['[CLS] came preciselyelial came introduce bartender mag came but mag came not. to to [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.172 (perp=9.186, rec=0.147, cos=0.189), tot_loss_proj:3.743 [t=0.24s]
prediction: ['[CLS] came toelial came introduce bartender mag came but mag came not. to precisely [SEP]']
[ 600/2000] tot_loss=2.263 (perp=9.742, rec=0.132, cos=0.183), tot_loss_proj:3.849 [t=0.24s]
prediction: ['[CLS] mag to sired came introduce bartender mag came but mag came not. to precisely [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.065 (perp=8.798, rec=0.130, cos=0.175), tot_loss_proj:3.642 [t=0.24s]
prediction: ['[CLS] mag sired came to introduce bartender mag came but mag came not. to precisely [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.873 (perp=7.763, rec=0.140, cos=0.181), tot_loss_proj:3.406 [t=0.24s]
prediction: ['[CLS] mag fellowships came to introduce bartender mag came but mag came not precisely to. [SEP]']
[ 750/2000] tot_loss=1.856 (perp=7.763, rec=0.123, cos=0.180), tot_loss_proj:3.410 [t=0.24s]
prediction: ['[CLS] mag fellowships came to introduce bartender mag came but mag came not precisely to. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.860 (perp=7.763, rec=0.126, cos=0.181), tot_loss_proj:3.409 [t=0.24s]
prediction: ['[CLS] mag fellowships came to introduce bartender mag came but mag came not precisely to. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.865 (perp=7.763, rec=0.121, cos=0.192), tot_loss_proj:3.408 [t=0.24s]
prediction: ['[CLS] mag fellowships came to introduce bartender mag came but mag came not precisely to. [SEP]']
[ 900/2000] tot_loss=1.862 (perp=7.763, rec=0.123, cos=0.187), tot_loss_proj:3.412 [t=0.24s]
prediction: ['[CLS] mag fellowships came to introduce bartender mag came but mag came not precisely to. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.956 (perp=8.290, rec=0.114, cos=0.183), tot_loss_proj:3.512 [t=0.24s]
prediction: ['[CLS] mag fellowships came to introduce bartender i came but mag came not precisely to. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.962 (perp=8.290, rec=0.123, cos=0.181), tot_loss_proj:3.511 [t=0.24s]
prediction: ['[CLS] mag fellowships came to introduce bartender i came but mag came not precisely to. [SEP]']
[1050/2000] tot_loss=1.957 (perp=8.290, rec=0.120, cos=0.179), tot_loss_proj:3.512 [t=0.24s]
prediction: ['[CLS] mag fellowships came to introduce bartender i came but mag came not precisely to. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.010 (perp=8.540, rec=0.122, cos=0.180), tot_loss_proj:3.566 [t=0.24s]
prediction: ['[CLS] magwood came to introduce bartender mag came but i came not precisely to. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.002 (perp=8.540, rec=0.121, cos=0.174), tot_loss_proj:3.567 [t=0.23s]
prediction: ['[CLS] magwood came to introduce bartender mag came but i came not precisely to. [SEP]']
[1200/2000] tot_loss=2.004 (perp=8.540, rec=0.113, cos=0.183), tot_loss_proj:3.561 [t=0.24s]
prediction: ['[CLS] magwood came to introduce bartender mag came but i came not precisely to. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.957 (perp=8.334, rec=0.108, cos=0.183), tot_loss_proj:3.499 [t=0.24s]
prediction: ['[CLS] magwood came to introduce bartender mag came but i came precisely not to. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.165 (perp=9.339, rec=0.109, cos=0.188), tot_loss_proj:3.816 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
[1350/2000] tot_loss=2.169 (perp=9.339, rec=0.114, cos=0.187), tot_loss_proj:3.816 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.157 (perp=9.339, rec=0.107, cos=0.182), tot_loss_proj:3.812 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.152 (perp=9.339, rec=0.103, cos=0.182), tot_loss_proj:3.818 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
[1500/2000] tot_loss=2.155 (perp=9.339, rec=0.108, cos=0.179), tot_loss_proj:3.817 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.166 (perp=9.339, rec=0.114, cos=0.184), tot_loss_proj:3.820 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.161 (perp=9.339, rec=0.112, cos=0.181), tot_loss_proj:3.822 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
[1650/2000] tot_loss=2.158 (perp=9.339, rec=0.104, cos=0.186), tot_loss_proj:3.816 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.161 (perp=9.339, rec=0.113, cos=0.180), tot_loss_proj:3.818 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.165 (perp=9.339, rec=0.112, cos=0.186), tot_loss_proj:3.819 [t=0.23s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
[1800/2000] tot_loss=2.160 (perp=9.339, rec=0.109, cos=0.183), tot_loss_proj:3.817 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.150 (perp=9.339, rec=0.098, cos=0.185), tot_loss_proj:3.817 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.158 (perp=9.339, rec=0.105, cos=0.185), tot_loss_proj:3.816 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
[1950/2000] tot_loss=2.160 (perp=9.339, rec=0.108, cos=0.184), tot_loss_proj:3.814 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.163 (perp=9.339, rec=0.113, cos=0.182), tot_loss_proj:3.818 [t=0.24s]
prediction: ['[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]
========================
predicted: 
========================
[CLS] magwood came rustic introduce bartender mag came but i came precisely not to. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 73.333 | p: 73.333 | r: 73.333
rougeLsum  | fm: 73.333 | p: 73.333 | r: 73.333
r1fm+r2fm = 122.857

[Aggregate metrics]:
rouge1     | fm: 86.634 | p: 86.407 | r: 87.018
rouge2     | fm: 49.272 | p: 49.053 | r: 49.652
rougeL     | fm: 76.301 | p: 76.085 | r: 76.684
rougeLsum  | fm: 76.289 | p: 76.195 | r: 76.637
r1fm+r2fm = 135.905

input #65 time: 0:09:16 | total time: 10:00:44


Running input #66 of 100.
reference: 
========================
There tried to be riots in Seoul.
========================
average of cosine similarity 0.9024396469950631
highest_index [0]
highest [0.9024396469950631]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2045,  2699,  2000,  2022, 12925,  1999, 10884,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] there tried to be riots in seoul. [SEP]']
[Init] best rec loss: 0.7260329127311707 for ['[CLS] mcdonnell mount activities death today game medal ng [SEP]']
[Init] best rec loss: 0.6852171421051025 for ['[CLS] vamp kada devil kent lizard home angels [SEP]']
[Init] best rec loss: 0.6739603877067566 for ['[CLS] kirk line may anniversary bee combined ladder doubtful [SEP]']
[Init] best rec loss: 0.6692004203796387 for ['[CLS] mainger soil music means numbers this left [SEP]']
[Init] best rec loss: 0.6647279262542725 for ['[CLS] surfacetagram twice snow ste iona grade ramon [SEP]']
[Init] best rec loss: 0.6620717644691467 for ['[CLS] duel paradise birdsfireshane express knows archives [SEP]']
[Init] best rec loss: 0.6550965905189514 for ['[CLS] highness playing ortiz °c rough texas iso execution [SEP]']
[Init] best rec loss: 0.6299453377723694 for ['[CLS] book web fablecing and this during benefit [SEP]']
[Init] best perm rec loss: 0.627962589263916 for ['[CLS]cing book during this benefit fable web and [SEP]']
[Init] best perm rec loss: 0.6271224617958069 for ['[CLS] fable this andcing during web book benefit [SEP]']
[Init] best perm rec loss: 0.6264050006866455 for ['[CLS]cing web benefit fable during book this and [SEP]']
[Init] best perm rec loss: 0.6250995993614197 for ['[CLS]cing book web benefit fable during this and [SEP]']
[Init] best perm rec loss: 0.6250476837158203 for ['[CLS] web benefit bookcing fable this during and [SEP]']
[Init] best perm rec loss: 0.6238027811050415 for ['[CLS] andcing book fable during this benefit web [SEP]']
[Init] best perm rec loss: 0.6232965588569641 for ['[CLS] book benefitcing and this fable during web [SEP]']
[Init] best perm rec loss: 0.6225541234016418 for ['[CLS] and benefit during webcing book this fable [SEP]']
[Init] best perm rec loss: 0.6225107908248901 for ['[CLS] thiscing fable book and during benefit web [SEP]']
[Init] best perm rec loss: 0.6224583387374878 for ['[CLS] web during benefit this andcing fable book [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.255 (perp=13.814, rec=0.306, cos=0.186), tot_loss_proj:3.652 [t=0.23s]
prediction: ['[CLS] computer tried tried be scott riots triedlli [SEP]']
[ 100/2000] tot_loss=2.492 (perp=10.080, rec=0.290, cos=0.186), tot_loss_proj:3.076 [t=0.23s]
prediction: ['[CLS] there tried attempt to seoul riots was riots [SEP]']
[ 150/2000] tot_loss=2.172 (perp=9.237, rec=0.143, cos=0.181), tot_loss_proj:2.693 [t=0.23s]
prediction: ['[CLS] there tried to be seoul riots tried riots [SEP]']
[ 200/2000] tot_loss=1.977 (perp=8.499, rec=0.092, cos=0.185), tot_loss_proj:2.212 [t=0.23s]
prediction: ['[CLS] there tried to be seoul riots riots in [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.960 (perp=8.013, rec=0.172, cos=0.184), tot_loss_proj:2.432 [t=0.23s]
prediction: ['[CLS] there tried to be seoul in riots riots [SEP]']
[ 300/2000] tot_loss=1.866 (perp=8.013, rec=0.081, cos=0.182), tot_loss_proj:2.466 [t=0.23s]
prediction: ['[CLS] there tried to be seoul in riots riots [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.721 (perp=7.264, rec=0.084, cos=0.184), tot_loss_proj:1.836 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.717 (perp=7.264, rec=0.079, cos=0.185), tot_loss_proj:1.837 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
[ 450/2000] tot_loss=1.725 (perp=7.264, rec=0.087, cos=0.185), tot_loss_proj:1.831 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.707 (perp=7.264, rec=0.068, cos=0.185), tot_loss_proj:1.836 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.713 (perp=7.264, rec=0.075, cos=0.185), tot_loss_proj:1.832 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
[ 600/2000] tot_loss=1.714 (perp=7.264, rec=0.076, cos=0.185), tot_loss_proj:1.829 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.704 (perp=7.264, rec=0.066, cos=0.185), tot_loss_proj:1.832 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.708 (perp=7.264, rec=0.070, cos=0.185), tot_loss_proj:1.830 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
[ 750/2000] tot_loss=1.703 (perp=7.264, rec=0.066, cos=0.185), tot_loss_proj:1.825 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.717 (perp=7.264, rec=0.078, cos=0.186), tot_loss_proj:1.837 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.715 (perp=7.264, rec=0.077, cos=0.186), tot_loss_proj:1.833 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
[ 900/2000] tot_loss=1.698 (perp=7.264, rec=0.060, cos=0.185), tot_loss_proj:1.836 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.704 (perp=7.264, rec=0.066, cos=0.185), tot_loss_proj:1.835 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1000/2000] tot_loss=1.703 (perp=7.264, rec=0.065, cos=0.185), tot_loss_proj:1.829 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
[1050/2000] tot_loss=1.714 (perp=7.264, rec=0.076, cos=0.185), tot_loss_proj:1.829 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1100/2000] tot_loss=1.704 (perp=7.264, rec=0.066, cos=0.186), tot_loss_proj:1.824 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1150/2000] tot_loss=1.712 (perp=7.264, rec=0.074, cos=0.185), tot_loss_proj:1.832 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
[1200/2000] tot_loss=1.704 (perp=7.264, rec=0.066, cos=0.186), tot_loss_proj:1.827 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1250/2000] tot_loss=1.709 (perp=7.264, rec=0.071, cos=0.186), tot_loss_proj:1.821 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1300/2000] tot_loss=1.707 (perp=7.264, rec=0.069, cos=0.185), tot_loss_proj:1.828 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
[1350/2000] tot_loss=1.707 (perp=7.264, rec=0.069, cos=0.185), tot_loss_proj:1.828 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1400/2000] tot_loss=1.701 (perp=7.264, rec=0.063, cos=0.185), tot_loss_proj:1.823 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1450/2000] tot_loss=1.709 (perp=7.264, rec=0.071, cos=0.185), tot_loss_proj:1.832 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
[1500/2000] tot_loss=1.706 (perp=7.264, rec=0.068, cos=0.185), tot_loss_proj:1.826 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1550/2000] tot_loss=1.699 (perp=7.264, rec=0.061, cos=0.186), tot_loss_proj:1.824 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1600/2000] tot_loss=1.715 (perp=7.264, rec=0.077, cos=0.186), tot_loss_proj:1.825 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
[1650/2000] tot_loss=1.713 (perp=7.264, rec=0.075, cos=0.185), tot_loss_proj:1.826 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1700/2000] tot_loss=1.706 (perp=7.264, rec=0.067, cos=0.186), tot_loss_proj:1.827 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1750/2000] tot_loss=1.698 (perp=7.264, rec=0.060, cos=0.186), tot_loss_proj:1.817 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
[1800/2000] tot_loss=1.701 (perp=7.264, rec=0.063, cos=0.185), tot_loss_proj:1.828 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1850/2000] tot_loss=1.705 (perp=7.264, rec=0.067, cos=0.186), tot_loss_proj:1.833 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[1900/2000] tot_loss=1.710 (perp=7.264, rec=0.072, cos=0.186), tot_loss_proj:1.822 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
[1950/2000] tot_loss=1.717 (perp=7.264, rec=0.078, cos=0.186), tot_loss_proj:1.821 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Attempt swap
[2000/2000] tot_loss=1.707 (perp=7.264, rec=0.069, cos=0.186), tot_loss_proj:1.816 [t=0.23s]
prediction: ['[CLS] there tried to be riots in seoul riots [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] there tried to be riots in seoul. [SEP]
========================
predicted: 
========================
[CLS] there tried to be riots in seoul riots [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 82.353 | p: 77.778 | r: 87.500
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 177.090

[Aggregate metrics]:
rouge1     | fm: 86.737 | p: 86.494 | r: 87.128
rouge2     | fm: 49.791 | p: 49.528 | r: 50.271
rougeL     | fm: 76.464 | p: 76.291 | r: 76.877
rougeLsum  | fm: 76.616 | p: 76.360 | r: 77.007
r1fm+r2fm = 136.528

input #66 time: 0:09:10 | total time: 10:09:54


Running input #67 of 100.
reference: 
========================
Fido is the smarter dog than Spot.
========================
average of cosine similarity 0.8731176687570117
highest_index [0]
highest [0.8731176687570117]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 10882,  3527,  2003,  1996, 25670,  3899,  2084,  3962,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] fido is the smarter dog than spot. [SEP]']
[Init] best rec loss: 0.8535590171813965 for ['[CLS] spec legend currently boarding reasons chapel assistance accomplish through [SEP]']
[Init] best rec loss: 0.839098334312439 for ['[CLS] bi ride driveway° student " life representative bomb [SEP]']
[Init] best rec loss: 0.8371871709823608 for ['[CLS] silkrting relating break cigarette bail finger charts do [SEP]']
[Init] best rec loss: 0.8199403285980225 for ['[CLS] word cab healthychenifying ruled mills flat prison [SEP]']
[Init] best rec loss: 0.8116047978401184 for ['[CLS]vert prompt train circle being ableaco horror ada [SEP]']
[Init] best rec loss: 0.8040661215782166 for ['[CLS] drinking peersmeral occultcton agreement eliza doessari [SEP]']
[Init] best rec loss: 0.7935141324996948 for ['[CLS] prince offices organhue h tractor store unfortunate metric [SEP]']
[Init] best rec loss: 0.7848753929138184 for ['[CLS] hosted heaven live inflicted eight jewel who subjects given [SEP]']
[Init] best rec loss: 0.7727993726730347 for ['[CLS] ] house christ box swore rex marina limit replacement [SEP]']
[Init] best perm rec loss: 0.7720629572868347 for ['[CLS] box swore house replacement christ rex limit ] marina [SEP]']
[Init] best perm rec loss: 0.7707468867301941 for ['[CLS] christ replacement ] house swore box marina limit rex [SEP]']
[Init] best perm rec loss: 0.7694360017776489 for ['[CLS] rex replacement house christ swore box marina limit ] [SEP]']
[Init] best perm rec loss: 0.7680770754814148 for ['[CLS] house box christ swore replacement limit rex marina ] [SEP]']
[Init] best perm rec loss: 0.7660986185073853 for ['[CLS] box swore replacement rex ] limit christ marina house [SEP]']
[Init] best perm rec loss: 0.7660254240036011 for ['[CLS] box replacement rex house christ limit swore marina ] [SEP]']
[Init] best perm rec loss: 0.7654625773429871 for ['[CLS] box christ house rex replacement limit ] marina swore [SEP]']
[Init] best perm rec loss: 0.7654550075531006 for ['[CLS] christ ] house box swore rex replacement marina limit [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.739 (perp=15.276, rec=0.429, cos=0.254), tot_loss_proj:4.781 [t=0.23s]
prediction: ['[CLS] paternal best sit makes attributeddog being airport patches [SEP]']
[ 100/2000] tot_loss=2.897 (perp=10.741, rec=0.447, cos=0.302), tot_loss_proj:3.807 [t=0.23s]
prediction: ['[CLS] than best preference smarter smarter spot than spot deeds [SEP]']
[ 150/2000] tot_loss=2.280 (perp=9.276, rec=0.226, cos=0.199), tot_loss_proj:3.611 [t=0.23s]
prediction: ['[CLS] than. bo smarter smarter spot than spot. [SEP]']
[ 200/2000] tot_loss=2.260 (perp=9.417, rec=0.152, cos=0.225), tot_loss_proj:3.470 [t=0.23s]
prediction: ['[CLS] than.do is smarter spot than spot, [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.894 (perp=7.777, rec=0.138, cos=0.200), tot_loss_proj:2.832 [t=0.23s]
prediction: ['[CLS].do is smarter than dog dog spot, [SEP]']
[ 300/2000] tot_loss=1.882 (perp=7.777, rec=0.105, cos=0.222), tot_loss_proj:2.835 [t=0.23s]
prediction: ['[CLS].do is smarter than dog dog spot, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.876 (perp=7.749, rec=0.099, cos=0.227), tot_loss_proj:2.626 [t=0.23s]
prediction: ['[CLS] fido is smarter than dog dog spot, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.883 (perp=7.749, rec=0.104, cos=0.230), tot_loss_proj:2.627 [t=0.23s]
prediction: ['[CLS] fido is smarter than dog dog spot, [SEP]']
[ 450/2000] tot_loss=1.881 (perp=7.749, rec=0.100, cos=0.232), tot_loss_proj:2.617 [t=0.23s]
prediction: ['[CLS] fido is smarter than dog dog spot, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.753 (perp=7.168, rec=0.087, cos=0.232), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS] fido is smarter than dog dog spot. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.747 (perp=7.168, rec=0.080, cos=0.233), tot_loss_proj:2.401 [t=0.23s]
prediction: ['[CLS] fido is smarter than dog dog spot. [SEP]']
[ 600/2000] tot_loss=1.763 (perp=7.168, rec=0.095, cos=0.234), tot_loss_proj:2.397 [t=0.23s]
prediction: ['[CLS] fido is smarter than dog dog spot. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.757 (perp=7.168, rec=0.089, cos=0.233), tot_loss_proj:2.390 [t=0.23s]
prediction: ['[CLS] fido is smarter than dog dog spot. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.576 (perp=6.322, rec=0.075, cos=0.237), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
[ 750/2000] tot_loss=1.569 (perp=6.322, rec=0.069, cos=0.236), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.580 (perp=6.322, rec=0.079, cos=0.236), tot_loss_proj:2.317 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.576 (perp=6.322, rec=0.075, cos=0.237), tot_loss_proj:2.310 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
[ 900/2000] tot_loss=1.563 (perp=6.322, rec=0.062, cos=0.237), tot_loss_proj:2.311 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.576 (perp=6.322, rec=0.075, cos=0.237), tot_loss_proj:2.314 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.566 (perp=6.322, rec=0.065, cos=0.237), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
[1050/2000] tot_loss=1.572 (perp=6.322, rec=0.070, cos=0.237), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.568 (perp=6.322, rec=0.066, cos=0.237), tot_loss_proj:2.315 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.570 (perp=6.322, rec=0.069, cos=0.237), tot_loss_proj:2.315 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
[1200/2000] tot_loss=1.567 (perp=6.322, rec=0.066, cos=0.237), tot_loss_proj:2.315 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.572 (perp=6.322, rec=0.070, cos=0.237), tot_loss_proj:2.318 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.573 (perp=6.322, rec=0.072, cos=0.237), tot_loss_proj:2.307 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
[1350/2000] tot_loss=1.577 (perp=6.322, rec=0.076, cos=0.237), tot_loss_proj:2.315 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.563 (perp=6.322, rec=0.061, cos=0.237), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.566 (perp=6.322, rec=0.064, cos=0.237), tot_loss_proj:2.311 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
[1500/2000] tot_loss=1.565 (perp=6.322, rec=0.063, cos=0.237), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.567 (perp=6.322, rec=0.065, cos=0.237), tot_loss_proj:2.310 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.565 (perp=6.322, rec=0.063, cos=0.237), tot_loss_proj:2.320 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
[1650/2000] tot_loss=1.568 (perp=6.322, rec=0.066, cos=0.237), tot_loss_proj:2.317 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.575 (perp=6.322, rec=0.074, cos=0.237), tot_loss_proj:2.310 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.572 (perp=6.322, rec=0.071, cos=0.237), tot_loss_proj:2.315 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
[1800/2000] tot_loss=1.567 (perp=6.322, rec=0.065, cos=0.237), tot_loss_proj:2.310 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.565 (perp=6.322, rec=0.064, cos=0.237), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.572 (perp=6.322, rec=0.070, cos=0.237), tot_loss_proj:2.318 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
[1950/2000] tot_loss=1.558 (perp=6.322, rec=0.056, cos=0.237), tot_loss_proj:2.315 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.568 (perp=6.322, rec=0.067, cos=0.237), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] fido is smarter than the dog spot. [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] fido is the smarter dog than spot. [SEP]
========================
predicted: 
========================
[CLS] fido is smarter than the dog spot. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 86.964 | p: 86.620 | r: 87.392
rouge2     | fm: 49.576 | p: 49.263 | r: 50.017
rougeL     | fm: 76.546 | p: 76.301 | r: 77.011
rougeLsum  | fm: 76.544 | p: 76.328 | r: 77.024
r1fm+r2fm = 136.540

input #67 time: 0:09:10 | total time: 10:19:04


Running input #68 of 100.
reference: 
========================
John convinced the rice to be cooked by Bill.
========================
average of cosine similarity 0.9043375932658669
highest_index [0]
highest [0.9043375932658669]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198,  6427,  1996,  5785,  2000,  2022, 12984,  2011,  3021,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john convinced the rice to be cooked by bill. [SEP]']
[Init] best rec loss: 0.7319175601005554 for ['[CLS] rich plant ticket has an boat favorite malaysia showing procedures [SEP]']
[Init] best rec loss: 0.7266284227371216 for ['[CLS] while marginal competition control new beau ll associatedlb marker [SEP]']
[Init] best rec loss: 0.7192124724388123 for ['[CLS] frozen now danhel ellie given without translatedhen reflecting [SEP]']
[Init] best rec loss: 0.7170631885528564 for ['[CLS] lab text hours suspension limitsoft ottawa towel worth mold [SEP]']
[Init] best rec loss: 0.7050525546073914 for ['[CLS] collegevable results tell round departmentllaryian sea bass [SEP]']
[Init] best perm rec loss: 0.7021891474723816 for ['[CLS] tellllary collegevable round sea department bass resultsian [SEP]']
[Init] best perm rec loss: 0.7017236948013306 for ['[CLS] results departmentllaryian sea bassvable round college tell [SEP]']
[Init] best perm rec loss: 0.7013553977012634 for ['[CLS] college department tell results round seallaryianvable bass [SEP]']
[Init] best perm rec loss: 0.701040506362915 for ['[CLS] bassian college tellllaryvable sea round results department [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.738 (perp=11.376, rec=0.290, cos=0.173), tot_loss_proj:3.256 [t=0.23s]
prediction: ['[CLS] guitarist sirco will rice convinced contained officially convinced rice [SEP]']
[ 100/2000] tot_loss=2.416 (perp=10.392, rec=0.180, cos=0.157), tot_loss_proj:3.220 [t=0.23s]
prediction: ['[CLS] to milesignant the rice help to john convinced rice [SEP]']
[ 150/2000] tot_loss=2.567 (perp=11.213, rec=0.133, cos=0.192), tot_loss_proj:3.585 [t=0.23s]
prediction: ['[CLS] john johnser the cooked to to john convinced rice [SEP]']
[ 200/2000] tot_loss=2.421 (perp=10.668, rec=0.110, cos=0.178), tot_loss_proj:3.324 [t=0.23s]
prediction: ['[CLS] john johnser the cooked to to be convinced rice [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.488 (perp=10.538, rec=0.211, cos=0.170), tot_loss_proj:3.117 [t=0.23s]
prediction: ['[CLS]. johnet the cooked rice to john convinced bamboo [SEP]']
[ 300/2000] tot_loss=2.178 (perp=9.274, rec=0.149, cos=0.174), tot_loss_proj:3.072 [t=0.23s]
prediction: ['[CLS] john poet the cooked rice to be convinced by [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.886 (perp=8.017, rec=0.117, cos=0.165), tot_loss_proj:2.432 [t=0.23s]
prediction: ['[CLS] john pomen cooked the rice to be convinced by [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.948 (perp=8.294, rec=0.109, cos=0.180), tot_loss_proj:2.536 [t=0.23s]
prediction: ['[CLS] john po cooked the riceet to be convinced by [SEP]']
[ 450/2000] tot_loss=1.955 (perp=8.294, rec=0.111, cos=0.185), tot_loss_proj:2.533 [t=0.23s]
prediction: ['[CLS] john po cooked the riceet to be convinced by [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.144 (perp=9.310, rec=0.102, cos=0.180), tot_loss_proj:2.721 [t=0.23s]
prediction: ['[CLS] john cooked the bu riceet to be convinced by [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.930 (perp=7.892, rec=0.171, cos=0.180), tot_loss_proj:2.412 [t=0.23s]
prediction: ['[CLS] john bu cooked the ricemen to be convinced by [SEP]']
[ 600/2000] tot_loss=1.851 (perp=7.782, rec=0.117, cos=0.178), tot_loss_proj:2.385 [t=0.23s]
prediction: ['[CLS] john fred cooked the ricemen to be convinced by [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=1.706 (perp=7.155, rec=0.102, cos=0.173), tot_loss_proj:2.261 [t=0.23s]
prediction: ['[CLS] fred cooked the ricemen to be convinced by john [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.704 (perp=7.155, rec=0.095, cos=0.178), tot_loss_proj:2.267 [t=0.23s]
prediction: ['[CLS] fred cooked the ricemen to be convinced by john [SEP]']
[ 750/2000] tot_loss=1.706 (perp=7.155, rec=0.095, cos=0.180), tot_loss_proj:2.264 [t=0.23s]
prediction: ['[CLS] fred cooked the ricemen to be convinced by john [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.847 (perp=7.910, rec=0.084, cos=0.181), tot_loss_proj:2.448 [t=0.23s]
prediction: ['[CLS] jed cooked the ricemen to be convinced by john [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.778 (perp=7.612, rec=0.080, cos=0.176), tot_loss_proj:2.369 [t=0.23s]
prediction: ['[CLS] the jed cooked ricemen to be convinced by john [SEP]']
[ 900/2000] tot_loss=1.789 (perp=7.612, rec=0.087, cos=0.180), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] the jed cooked ricemen to be convinced by john [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.783 (perp=7.612, rec=0.080, cos=0.181), tot_loss_proj:2.364 [t=0.23s]
prediction: ['[CLS] the jed cooked ricemen to be convinced by john [SEP]']
Attempt swap
[1000/2000] tot_loss=1.774 (perp=7.612, rec=0.072, cos=0.180), tot_loss_proj:2.365 [t=0.23s]
prediction: ['[CLS] the jed cooked ricemen to be convinced by john [SEP]']
[1050/2000] tot_loss=1.796 (perp=7.612, rec=0.092, cos=0.182), tot_loss_proj:2.359 [t=0.23s]
prediction: ['[CLS] the jed cooked ricemen to be convinced by john [SEP]']
Attempt swap
[1100/2000] tot_loss=1.792 (perp=7.612, rec=0.088, cos=0.181), tot_loss_proj:2.366 [t=0.23s]
prediction: ['[CLS] the jed cooked ricemen to be convinced by john [SEP]']
Attempt swap
[1150/2000] tot_loss=1.778 (perp=7.612, rec=0.074, cos=0.181), tot_loss_proj:2.374 [t=0.23s]
prediction: ['[CLS] the jed cooked ricemen to be convinced by john [SEP]']
[1200/2000] tot_loss=1.794 (perp=7.612, rec=0.091, cos=0.181), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] the jed cooked ricemen to be convinced by john [SEP]']
Attempt swap
[1250/2000] tot_loss=1.782 (perp=7.612, rec=0.078, cos=0.181), tot_loss_proj:2.364 [t=0.23s]
prediction: ['[CLS] the jed cooked ricemen to be convinced by john [SEP]']
Attempt swap
[1300/2000] tot_loss=1.734 (perp=7.299, rec=0.093, cos=0.181), tot_loss_proj:2.353 [t=0.23s]
prediction: ['[CLS] the bill cooked ricemen to be convinced by john [SEP]']
[1350/2000] tot_loss=1.724 (perp=7.299, rec=0.083, cos=0.182), tot_loss_proj:2.344 [t=0.23s]
prediction: ['[CLS] the bill cooked ricemen to be convinced by john [SEP]']
Attempt swap
[1400/2000] tot_loss=1.717 (perp=7.299, rec=0.076, cos=0.182), tot_loss_proj:2.353 [t=0.23s]
prediction: ['[CLS] the bill cooked ricemen to be convinced by john [SEP]']
Attempt swap
[1450/2000] tot_loss=1.717 (perp=7.299, rec=0.075, cos=0.182), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] the bill cooked ricemen to be convinced by john [SEP]']
[1500/2000] tot_loss=1.712 (perp=7.299, rec=0.070, cos=0.182), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] the bill cooked ricemen to be convinced by john [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.698 (perp=7.235, rec=0.072, cos=0.179), tot_loss_proj:2.303 [t=0.23s]
prediction: ['[CLS] bill cooked the ricemen to be convinced by john [SEP]']
Attempt swap
[1600/2000] tot_loss=1.708 (perp=7.235, rec=0.081, cos=0.181), tot_loss_proj:2.301 [t=0.23s]
prediction: ['[CLS] bill cooked the ricemen to be convinced by john [SEP]']
[1650/2000] tot_loss=1.705 (perp=7.235, rec=0.077, cos=0.181), tot_loss_proj:2.293 [t=0.23s]
prediction: ['[CLS] bill cooked the ricemen to be convinced by john [SEP]']
Attempt swap
[1700/2000] tot_loss=1.703 (perp=7.235, rec=0.075, cos=0.181), tot_loss_proj:2.295 [t=0.23s]
prediction: ['[CLS] bill cooked the ricemen to be convinced by john [SEP]']
Attempt swap
[1750/2000] tot_loss=1.703 (perp=7.235, rec=0.075, cos=0.181), tot_loss_proj:2.299 [t=0.23s]
prediction: ['[CLS] bill cooked the ricemen to be convinced by john [SEP]']
[1800/2000] tot_loss=1.701 (perp=7.235, rec=0.072, cos=0.182), tot_loss_proj:2.297 [t=0.23s]
prediction: ['[CLS] bill cooked the ricemen to be convinced by john [SEP]']
Attempt swap
[1850/2000] tot_loss=1.712 (perp=7.235, rec=0.084, cos=0.181), tot_loss_proj:2.298 [t=0.23s]
prediction: ['[CLS] bill cooked the ricemen to be convinced by john [SEP]']
Attempt swap
[1900/2000] tot_loss=1.699 (perp=7.235, rec=0.071, cos=0.181), tot_loss_proj:2.296 [t=0.23s]
prediction: ['[CLS] bill cooked the ricemen to be convinced by john [SEP]']
[1950/2000] tot_loss=1.702 (perp=7.235, rec=0.074, cos=0.181), tot_loss_proj:2.299 [t=0.23s]
prediction: ['[CLS] bill cooked the ricemen to be convinced by john [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.846 (perp=7.910, rec=0.085, cos=0.179), tot_loss_proj:2.551 [t=0.23s]
prediction: ['[CLS] the bill cooked riceund to be convinced by john [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] john convinced the rice to be cooked by bill. [SEP]
========================
predicted: 
========================
[CLS] the jed cooked ricemen to be convinced by john [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 10.000 | p: 10.000 | r: 10.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 91.818

[Aggregate metrics]:
rouge1     | fm: 86.866 | p: 86.640 | r: 87.264
rouge2     | fm: 49.024 | p: 48.738 | r: 49.469
rougeL     | fm: 76.227 | p: 75.992 | r: 76.638
rougeLsum  | fm: 76.315 | p: 76.047 | r: 76.737
r1fm+r2fm = 135.889

input #68 time: 0:09:09 | total time: 10:28:14


Running input #69 of 100.
reference: 
========================
The squirrel ran straight quickly.
========================
average of cosine similarity 0.8930790123661421
highest_index [0]
highest [0.8930790123661421]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 18197,  2743,  3442,  2855,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the squirrel ran straight quickly. [SEP]']
[Init] best rec loss: 0.7265459895133972 for ['[CLS] theme skin alive won reach one [SEP]']
[Init] best rec loss: 0.6970218420028687 for ['[CLS] breathing shortly feel large mark accolades [SEP]']
[Init] best rec loss: 0.6720815300941467 for ['[CLS] action ou defenceiom unto violence [SEP]']
[Init] best rec loss: 0.6654595732688904 for ['[CLS] abdomen math who what oil bus [SEP]']
[Init] best rec loss: 0.6649162173271179 for ['[CLS] on years magazine belong eugen wah [SEP]']
[Init] best rec loss: 0.6355739235877991 for ['[CLS] brief forgetlyhawks husbandch [SEP]']
[Init] best perm rec loss: 0.6326476335525513 for ['[CLS] husbandhawks forge briefchtly [SEP]']
[Init] best perm rec loss: 0.6325812339782715 for ['[CLS]hawks forgechtly brief husband [SEP]']
[Init] best perm rec loss: 0.6319498419761658 for ['[CLS]chhawks brief forgetly husband [SEP]']
[Init] best perm rec loss: 0.6307474970817566 for ['[CLS]tly husbandch forge briefhawks [SEP]']
[Init] best perm rec loss: 0.6306172609329224 for ['[CLS]ch brief husband forgetlyhawks [SEP]']
[Init] best perm rec loss: 0.6279212236404419 for ['[CLS]hawks briefch forgetly husband [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.011 (perp=12.595, rec=0.290, cos=0.202), tot_loss_proj:3.683 [t=0.22s]
prediction: ['[CLS] red quickly buried ran quickly speedway [SEP]']
[ 100/2000] tot_loss=2.314 (perp=9.838, rec=0.151, cos=0.196), tot_loss_proj:2.935 [t=0.22s]
prediction: ['[CLS] squirrel straight ran ran quickly. [SEP]']
[ 150/2000] tot_loss=2.249 (perp=9.838, rec=0.084, cos=0.197), tot_loss_proj:2.954 [t=0.22s]
prediction: ['[CLS] squirrel straight ran ran quickly. [SEP]']
[ 200/2000] tot_loss=2.133 (perp=9.272, rec=0.077, cos=0.201), tot_loss_proj:2.743 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.139 (perp=9.272, rec=0.087, cos=0.198), tot_loss_proj:2.748 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
[ 300/2000] tot_loss=2.123 (perp=9.272, rec=0.069, cos=0.200), tot_loss_proj:2.752 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.126 (perp=9.272, rec=0.073, cos=0.199), tot_loss_proj:2.753 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.142 (perp=9.272, rec=0.088, cos=0.200), tot_loss_proj:2.751 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
[ 450/2000] tot_loss=2.136 (perp=9.272, rec=0.081, cos=0.200), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.135 (perp=9.272, rec=0.080, cos=0.200), tot_loss_proj:2.751 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.124 (perp=9.272, rec=0.069, cos=0.201), tot_loss_proj:2.755 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
[ 600/2000] tot_loss=2.143 (perp=9.272, rec=0.088, cos=0.201), tot_loss_proj:2.746 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.126 (perp=9.272, rec=0.070, cos=0.202), tot_loss_proj:2.750 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.133 (perp=9.272, rec=0.077, cos=0.202), tot_loss_proj:2.748 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
[ 750/2000] tot_loss=2.125 (perp=9.272, rec=0.068, cos=0.202), tot_loss_proj:2.749 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.137 (perp=9.272, rec=0.082, cos=0.201), tot_loss_proj:2.746 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.137 (perp=9.272, rec=0.083, cos=0.200), tot_loss_proj:2.749 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
[ 900/2000] tot_loss=2.126 (perp=9.272, rec=0.074, cos=0.197), tot_loss_proj:2.749 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.125 (perp=9.272, rec=0.074, cos=0.197), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.125 (perp=9.272, rec=0.074, cos=0.197), tot_loss_proj:2.757 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
[1050/2000] tot_loss=2.135 (perp=9.272, rec=0.084, cos=0.197), tot_loss_proj:2.748 [t=0.22s]
prediction: ['[CLS] squirrel straight squirrel ran quickly. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.098 (perp=9.131, rec=0.075, cos=0.196), tot_loss_proj:2.919 [t=0.22s]
prediction: ['[CLS] squirrel ran straight squirrel quickly. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.077 (perp=9.075, rec=0.065, cos=0.196), tot_loss_proj:2.450 [t=0.22s]
prediction: ['[CLS] squirrel squirrel ran straight quickly. [SEP]']
[1200/2000] tot_loss=2.048 (perp=8.901, rec=0.072, cos=0.196), tot_loss_proj:2.678 [t=0.22s]
prediction: ['[CLS] squirrel the ran straight quickly. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.730 (perp=7.356, rec=0.062, cos=0.197), tot_loss_proj:1.874 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.752 (perp=7.356, rec=0.084, cos=0.197), tot_loss_proj:1.867 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
[1350/2000] tot_loss=1.733 (perp=7.356, rec=0.065, cos=0.197), tot_loss_proj:1.877 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.737 (perp=7.356, rec=0.069, cos=0.197), tot_loss_proj:1.875 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.729 (perp=7.356, rec=0.061, cos=0.197), tot_loss_proj:1.873 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
[1500/2000] tot_loss=1.742 (perp=7.356, rec=0.074, cos=0.197), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.732 (perp=7.356, rec=0.064, cos=0.197), tot_loss_proj:1.875 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.735 (perp=7.356, rec=0.066, cos=0.197), tot_loss_proj:1.875 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
[1650/2000] tot_loss=1.721 (perp=7.356, rec=0.053, cos=0.197), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.739 (perp=7.356, rec=0.070, cos=0.197), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.735 (perp=7.356, rec=0.066, cos=0.197), tot_loss_proj:1.874 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
[1800/2000] tot_loss=1.724 (perp=7.356, rec=0.056, cos=0.197), tot_loss_proj:1.878 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.747 (perp=7.356, rec=0.078, cos=0.197), tot_loss_proj:1.867 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.736 (perp=7.356, rec=0.067, cos=0.197), tot_loss_proj:1.875 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
[1950/2000] tot_loss=1.737 (perp=7.356, rec=0.068, cos=0.197), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.735 (perp=7.356, rec=0.066, cos=0.197), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] the squirrel ran straight quickly. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] the squirrel ran straight quickly. [SEP]
========================
predicted: 
========================
[CLS] the squirrel ran straight quickly. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.061 | p: 86.826 | r: 87.478
rouge2     | fm: 49.862 | p: 49.609 | r: 50.279
rougeL     | fm: 76.582 | p: 76.368 | r: 76.979
rougeLsum  | fm: 76.581 | p: 76.353 | r: 77.006
r1fm+r2fm = 136.924

input #69 time: 0:08:51 | total time: 10:37:05


Running input #70 of 100.
reference: 
========================
I assumed to be innocent
========================
average of cosine similarity 0.898465692896414
highest_index [0]
highest [0.898465692896414]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 5071, 2000, 2022, 7036,  102]], device='cuda:0')
Debug: ref = ['[CLS] i assumed to be innocent [SEP]']
[Init] best rec loss: 0.7738304138183594 for ['[CLS] down op epithet medicine sick [SEP]']
[Init] best rec loss: 0.7657799124717712 for ['[CLS] small beings equation flightfall [SEP]']
[Init] best rec loss: 0.7498787045478821 for ['[CLS]berg managed mainland doctor topped [SEP]']
[Init] best rec loss: 0.746863842010498 for ['[CLS] allied breath road revelation airport [SEP]']
[Init] best rec loss: 0.7419794201850891 for ['[CLS] [ across not inside stuff [SEP]']
[Init] best rec loss: 0.7403708696365356 for ['[CLS] breeding overseas signature activated points [SEP]']
[Init] best rec loss: 0.7371575832366943 for ['[CLS] honors protocolgne trackshis [SEP]']
[Init] best rec loss: 0.7333235144615173 for ['[CLS] oh kept middle pen opener [SEP]']
[Init] best rec loss: 0.7327540516853333 for ['[CLS] miniseries were load jail ari [SEP]']
[Init] best rec loss: 0.7297593355178833 for ['[CLS] almost locker couldstadt drew [SEP]']
[Init] best perm rec loss: 0.7213100790977478 for ['[CLS] locker almost could drewstadt [SEP]']
[Init] best perm rec loss: 0.7211304306983948 for ['[CLS]stadt locker could almost drew [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.890 (perp=11.712, rec=0.367, cos=0.181), tot_loss_proj:3.530 [t=0.23s]
prediction: ['[CLS] assumed gonna doran innocent [SEP]']
[ 100/2000] tot_loss=1.867 (perp=7.507, rec=0.173, cos=0.192), tot_loss_proj:2.457 [t=0.23s]
prediction: ['[CLS] assumed to be most innocent [SEP]']
[ 150/2000] tot_loss=1.811 (perp=7.507, rec=0.118, cos=0.192), tot_loss_proj:2.449 [t=0.23s]
prediction: ['[CLS] assumed to be most innocent [SEP]']
[ 200/2000] tot_loss=1.984 (perp=8.603, rec=0.071, cos=0.192), tot_loss_proj:2.704 [t=0.23s]
prediction: ['[CLS] assumed to be i innocent [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.548 (perp=6.469, rec=0.064, cos=0.190), tot_loss_proj:1.687 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 300/2000] tot_loss=1.545 (perp=6.469, rec=0.059, cos=0.192), tot_loss_proj:1.686 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.557 (perp=6.469, rec=0.072, cos=0.192), tot_loss_proj:1.676 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.550 (perp=6.469, rec=0.063, cos=0.192), tot_loss_proj:1.680 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 450/2000] tot_loss=1.548 (perp=6.469, rec=0.061, cos=0.193), tot_loss_proj:1.673 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.549 (perp=6.469, rec=0.063, cos=0.192), tot_loss_proj:1.670 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.552 (perp=6.469, rec=0.066, cos=0.193), tot_loss_proj:1.669 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 600/2000] tot_loss=1.549 (perp=6.469, rec=0.063, cos=0.193), tot_loss_proj:1.664 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.543 (perp=6.469, rec=0.056, cos=0.192), tot_loss_proj:1.675 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.536 (perp=6.469, rec=0.050, cos=0.193), tot_loss_proj:1.672 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 750/2000] tot_loss=1.557 (perp=6.469, rec=0.071, cos=0.192), tot_loss_proj:1.652 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.535 (perp=6.469, rec=0.049, cos=0.192), tot_loss_proj:1.671 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.543 (perp=6.469, rec=0.057, cos=0.192), tot_loss_proj:1.658 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 900/2000] tot_loss=1.531 (perp=6.469, rec=0.044, cos=0.193), tot_loss_proj:1.652 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.541 (perp=6.469, rec=0.055, cos=0.193), tot_loss_proj:1.652 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.540 (perp=6.469, rec=0.054, cos=0.192), tot_loss_proj:1.660 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1050/2000] tot_loss=1.547 (perp=6.469, rec=0.060, cos=0.192), tot_loss_proj:1.657 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.538 (perp=6.469, rec=0.052, cos=0.193), tot_loss_proj:1.662 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.548 (perp=6.469, rec=0.061, cos=0.193), tot_loss_proj:1.660 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1200/2000] tot_loss=1.541 (perp=6.469, rec=0.055, cos=0.192), tot_loss_proj:1.654 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=6.469, rec=0.064, cos=0.193), tot_loss_proj:1.655 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.545 (perp=6.469, rec=0.059, cos=0.193), tot_loss_proj:1.652 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1350/2000] tot_loss=1.547 (perp=6.469, rec=0.061, cos=0.192), tot_loss_proj:1.654 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.546 (perp=6.469, rec=0.060, cos=0.192), tot_loss_proj:1.647 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.547 (perp=6.469, rec=0.061, cos=0.193), tot_loss_proj:1.650 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1500/2000] tot_loss=1.558 (perp=6.469, rec=0.071, cos=0.193), tot_loss_proj:1.654 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.545 (perp=6.469, rec=0.058, cos=0.193), tot_loss_proj:1.655 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.548 (perp=6.469, rec=0.062, cos=0.192), tot_loss_proj:1.648 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1650/2000] tot_loss=1.545 (perp=6.469, rec=0.059, cos=0.193), tot_loss_proj:1.643 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.544 (perp=6.469, rec=0.058, cos=0.193), tot_loss_proj:1.643 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.541 (perp=6.469, rec=0.055, cos=0.193), tot_loss_proj:1.646 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1800/2000] tot_loss=1.550 (perp=6.469, rec=0.063, cos=0.193), tot_loss_proj:1.655 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.546 (perp=6.469, rec=0.060, cos=0.193), tot_loss_proj:1.641 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.550 (perp=6.469, rec=0.063, cos=0.193), tot_loss_proj:1.639 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1950/2000] tot_loss=1.545 (perp=6.469, rec=0.059, cos=0.193), tot_loss_proj:1.648 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.549 (perp=6.469, rec=0.063, cos=0.193), tot_loss_proj:1.656 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] i assumed to be innocent [SEP]
========================
predicted: 
========================
[CLS] i assumed to be innocent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.214 | p: 86.991 | r: 87.664
rouge2     | fm: 50.380 | p: 50.040 | r: 50.793
rougeL     | fm: 76.841 | p: 76.617 | r: 77.277
rougeLsum  | fm: 76.986 | p: 76.720 | r: 77.356
r1fm+r2fm = 137.593

input #70 time: 0:09:09 | total time: 10:46:14


Running input #71 of 100.
reference: 
========================
He could not have been working.
========================
average of cosine similarity 0.9433725717916998
highest_index [0]
highest [0.9433725717916998]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2071, 2025, 2031, 2042, 2551, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he could not have been working. [SEP]']
[Init] best rec loss: 0.9854032397270203 for ['[CLS] winston q officer obedience maize creamkha [SEP]']
[Init] best rec loss: 0.9518950581550598 for ['[CLS] deposit on twinned shadow layout and shining [SEP]']
[Init] best rec loss: 0.9258286952972412 for ['[CLS] wet proper drove sunday bigendheim [SEP]']
[Init] best rec loss: 0.9244987368583679 for ['[CLS] source outside fairias bullet tyson accepted [SEP]']
[Init] best rec loss: 0.9217191934585571 for ['[CLS] working results probably strip packhoares [SEP]']
[Init] best rec loss: 0.9210837483406067 for ['[CLS] off winningu i fact wearing top [SEP]']
[Init] best rec loss: 0.918972909450531 for ['[CLS] supported walk resigned sizenology cake high [SEP]']
[Init] best rec loss: 0.9055098295211792 for ['[CLS] deep name rights glacier spankill oxford [SEP]']
[Init] best rec loss: 0.9049575328826904 for ['[CLS] tracks mora hospital tiffany qualifying wakefieldtering [SEP]']
[Init] best rec loss: 0.8911624550819397 for ['[CLS] joanna gregor all drug hoc brows powers [SEP]']
[Init] best rec loss: 0.8824024796485901 for ['[CLS]w 1892 releasing standardsrating materialzie [SEP]']
[Init] best perm rec loss: 0.8761505484580994 for ['[CLS] 1892w standards materialzie releasingrating [SEP]']
[Init] best perm rec loss: 0.8759366273880005 for ['[CLS] materialziew standards 1892 releasingrating [SEP]']
[Init] best perm rec loss: 0.8756755590438843 for ['[CLS]rating materialzie releasing standardsw 1892 [SEP]']
[Init] best perm rec loss: 0.8712526559829712 for ['[CLS]w material standardszierating 1892 releasing [SEP]']
[Init] best perm rec loss: 0.8706794381141663 for ['[CLS]ziewrating material 1892 standards releasing [SEP]']
[Init] best perm rec loss: 0.8695997595787048 for ['[CLS] materialzie standardswrating releasing 1892 [SEP]']
[Init] best perm rec loss: 0.86773681640625 for ['[CLS] standardszie 1892 materialwrating releasing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.522 (perp=10.411, rec=0.328, cos=0.112), tot_loss_proj:3.927 [t=0.23s]
prediction: ['[CLS]. danny copper conceptraphy working death [SEP]']
[ 100/2000] tot_loss=2.355 (perp=10.412, rec=0.162, cos=0.111), tot_loss_proj:3.917 [t=0.23s]
prediction: ['[CLS] could he might fiction underway working never [SEP]']
[ 150/2000] tot_loss=1.945 (perp=8.657, rec=0.104, cos=0.109), tot_loss_proj:3.586 [t=0.23s]
prediction: ['[CLS] could he have must been working not [SEP]']
[ 200/2000] tot_loss=1.732 (perp=7.641, rec=0.094, cos=0.110), tot_loss_proj:3.160 [t=0.23s]
prediction: ['[CLS] could he have been been working not [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.868 (perp=7.760, rec=0.191, cos=0.125), tot_loss_proj:3.438 [t=0.23s]
prediction: ['[CLS] could not he have might been working [SEP]']
[ 300/2000] tot_loss=1.772 (perp=7.760, rec=0.110, cos=0.110), tot_loss_proj:3.429 [t=0.23s]
prediction: ['[CLS] could not he have might been working [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.739 (perp=7.558, rec=0.118, cos=0.110), tot_loss_proj:3.378 [t=0.23s]
prediction: ['[CLS] could not he have would been working [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.503 (perp=6.403, rec=0.115, cos=0.107), tot_loss_proj:3.167 [t=0.23s]
prediction: ['[CLS] could not he would have been working [SEP]']
[ 450/2000] tot_loss=1.495 (perp=6.403, rec=0.105, cos=0.110), tot_loss_proj:3.168 [t=0.23s]
prediction: ['[CLS] could not he would have been working [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.347 (perp=5.677, rec=0.103, cos=0.108), tot_loss_proj:3.027 [t=0.23s]
prediction: ['[CLS] he could not would have been working [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.368 (perp=5.779, rec=0.102, cos=0.110), tot_loss_proj:3.043 [t=0.23s]
prediction: ['[CLS] he could not might have been working [SEP]']
[ 600/2000] tot_loss=1.337 (perp=5.660, rec=0.095, cos=0.110), tot_loss_proj:1.471 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.344 (perp=5.660, rec=0.102, cos=0.110), tot_loss_proj:1.474 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.347 (perp=5.660, rec=0.105, cos=0.110), tot_loss_proj:1.477 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
[ 750/2000] tot_loss=1.336 (perp=5.660, rec=0.095, cos=0.110), tot_loss_proj:1.471 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.334 (perp=5.660, rec=0.092, cos=0.110), tot_loss_proj:1.467 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.320 (perp=5.660, rec=0.078, cos=0.110), tot_loss_proj:1.472 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
[ 900/2000] tot_loss=1.338 (perp=5.660, rec=0.096, cos=0.110), tot_loss_proj:1.471 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.334 (perp=5.660, rec=0.091, cos=0.110), tot_loss_proj:1.472 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1000/2000] tot_loss=1.317 (perp=5.660, rec=0.076, cos=0.110), tot_loss_proj:1.471 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
[1050/2000] tot_loss=1.325 (perp=5.660, rec=0.083, cos=0.109), tot_loss_proj:1.476 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1100/2000] tot_loss=1.341 (perp=5.660, rec=0.099, cos=0.110), tot_loss_proj:1.470 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1150/2000] tot_loss=1.323 (perp=5.660, rec=0.081, cos=0.110), tot_loss_proj:1.472 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
[1200/2000] tot_loss=1.339 (perp=5.660, rec=0.097, cos=0.110), tot_loss_proj:1.472 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1250/2000] tot_loss=1.337 (perp=5.660, rec=0.095, cos=0.110), tot_loss_proj:1.482 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.326 (perp=5.660, rec=0.088, cos=0.107), tot_loss_proj:1.486 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
[1350/2000] tot_loss=1.334 (perp=5.660, rec=0.092, cos=0.110), tot_loss_proj:1.497 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1400/2000] tot_loss=1.339 (perp=5.660, rec=0.097, cos=0.110), tot_loss_proj:1.488 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1450/2000] tot_loss=1.329 (perp=5.660, rec=0.087, cos=0.110), tot_loss_proj:1.494 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
[1500/2000] tot_loss=1.322 (perp=5.660, rec=0.080, cos=0.110), tot_loss_proj:1.483 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1550/2000] tot_loss=1.334 (perp=5.660, rec=0.092, cos=0.110), tot_loss_proj:1.495 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1600/2000] tot_loss=1.333 (perp=5.660, rec=0.091, cos=0.110), tot_loss_proj:1.489 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
[1650/2000] tot_loss=1.332 (perp=5.660, rec=0.090, cos=0.110), tot_loss_proj:1.485 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1700/2000] tot_loss=1.329 (perp=5.660, rec=0.087, cos=0.110), tot_loss_proj:1.490 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1750/2000] tot_loss=1.323 (perp=5.660, rec=0.081, cos=0.110), tot_loss_proj:1.493 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
[1800/2000] tot_loss=1.332 (perp=5.660, rec=0.090, cos=0.110), tot_loss_proj:1.485 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1850/2000] tot_loss=1.332 (perp=5.660, rec=0.090, cos=0.110), tot_loss_proj:1.491 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[1900/2000] tot_loss=1.324 (perp=5.660, rec=0.082, cos=0.110), tot_loss_proj:1.484 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
[1950/2000] tot_loss=1.328 (perp=5.660, rec=0.086, cos=0.110), tot_loss_proj:1.486 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Attempt swap
[2000/2000] tot_loss=1.327 (perp=5.660, rec=0.085, cos=0.110), tot_loss_proj:1.494 [t=0.23s]
prediction: ['[CLS] he could not have have been working [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] he could not have been working. [SEP]
========================
predicted: 
========================
[CLS] he could not have have been working [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 93.333 | p: 87.500 | r: 100.000
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 187.451

[Aggregate metrics]:
rouge1     | fm: 87.338 | p: 87.028 | r: 87.805
rouge2     | fm: 51.119 | p: 50.709 | r: 51.680
rougeL     | fm: 77.104 | p: 76.825 | r: 77.596
rougeLsum  | fm: 77.157 | p: 76.849 | r: 77.694
r1fm+r2fm = 138.457

input #71 time: 0:09:09 | total time: 10:55:24


Running input #72 of 100.
reference: 
========================
He goes.
========================
average of cosine similarity 0.849867020263978
highest_index [0]
highest [0.849867020263978]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 2002, 3632, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he goes. [SEP]']
[Init] best rec loss: 0.9136179685592651 for ['[CLS] prior keynes latter [SEP]']
[Init] best rec loss: 0.8969086408615112 for ['[CLS] faculty gallery piles [SEP]']
[Init] best rec loss: 0.8809101581573486 for ['[CLS] diver prism theme [SEP]']
[Init] best rec loss: 0.8790206909179688 for ['[CLS]xie gave green [SEP]']
[Init] best rec loss: 0.8491513729095459 for ['[CLS] whiteykns [SEP]']
[Init] best rec loss: 0.8488494157791138 for ['[CLS] field far chico [SEP]']
[Init] best rec loss: 0.8402617573738098 for ['[CLS] eyes shift annie [SEP]']
[Init] best rec loss: 0.8289533257484436 for ['[CLS] calvin mainly pre [SEP]']
[Init] best rec loss: 0.8168893456459045 for ['[CLS] shade works life [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.358 (perp=9.191, rec=0.255, cos=0.265), tot_loss_proj:2.736 [t=0.23s]
prediction: ['[CLS] he goes goes [SEP]']
[ 100/2000] tot_loss=2.360 (perp=9.875, rec=0.108, cos=0.277), tot_loss_proj:3.581 [t=0.23s]
prediction: ['[CLS] he. goes [SEP]']
[ 150/2000] tot_loss=2.369 (perp=9.875, rec=0.117, cos=0.278), tot_loss_proj:3.558 [t=0.23s]
prediction: ['[CLS] he. goes [SEP]']
[ 200/2000] tot_loss=2.347 (perp=9.875, rec=0.095, cos=0.277), tot_loss_proj:3.538 [t=0.23s]
prediction: ['[CLS] he. goes [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.402 (perp=5.241, rec=0.079, cos=0.275), tot_loss_proj:1.473 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[ 300/2000] tot_loss=1.401 (perp=5.241, rec=0.076, cos=0.276), tot_loss_proj:1.478 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.394 (perp=5.241, rec=0.070, cos=0.277), tot_loss_proj:1.478 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.388 (perp=5.241, rec=0.063, cos=0.277), tot_loss_proj:1.469 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[ 450/2000] tot_loss=1.396 (perp=5.241, rec=0.071, cos=0.277), tot_loss_proj:1.482 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.392 (perp=5.241, rec=0.067, cos=0.277), tot_loss_proj:1.468 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.400 (perp=5.241, rec=0.075, cos=0.277), tot_loss_proj:1.479 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[ 600/2000] tot_loss=1.387 (perp=5.241, rec=0.062, cos=0.277), tot_loss_proj:1.486 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.391 (perp=5.241, rec=0.066, cos=0.277), tot_loss_proj:1.482 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.399 (perp=5.241, rec=0.074, cos=0.277), tot_loss_proj:1.468 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[ 750/2000] tot_loss=1.381 (perp=5.241, rec=0.056, cos=0.277), tot_loss_proj:1.480 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.388 (perp=5.241, rec=0.063, cos=0.277), tot_loss_proj:1.479 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.396 (perp=5.241, rec=0.071, cos=0.277), tot_loss_proj:1.482 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[ 900/2000] tot_loss=1.399 (perp=5.241, rec=0.074, cos=0.277), tot_loss_proj:1.476 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.388 (perp=5.241, rec=0.063, cos=0.277), tot_loss_proj:1.478 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.396 (perp=5.241, rec=0.070, cos=0.277), tot_loss_proj:1.485 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[1050/2000] tot_loss=1.390 (perp=5.241, rec=0.065, cos=0.277), tot_loss_proj:1.476 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.386 (perp=5.241, rec=0.060, cos=0.277), tot_loss_proj:1.483 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.388 (perp=5.241, rec=0.062, cos=0.277), tot_loss_proj:1.477 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[1200/2000] tot_loss=1.380 (perp=5.241, rec=0.055, cos=0.277), tot_loss_proj:1.481 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.378 (perp=5.241, rec=0.052, cos=0.277), tot_loss_proj:1.480 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.388 (perp=5.241, rec=0.062, cos=0.277), tot_loss_proj:1.486 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[1350/2000] tot_loss=1.395 (perp=5.241, rec=0.070, cos=0.277), tot_loss_proj:1.476 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.391 (perp=5.241, rec=0.066, cos=0.277), tot_loss_proj:1.488 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.387 (perp=5.241, rec=0.062, cos=0.277), tot_loss_proj:1.490 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[1500/2000] tot_loss=1.391 (perp=5.241, rec=0.065, cos=0.277), tot_loss_proj:1.479 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.390 (perp=5.241, rec=0.064, cos=0.277), tot_loss_proj:1.479 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.386 (perp=5.241, rec=0.060, cos=0.277), tot_loss_proj:1.487 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[1650/2000] tot_loss=1.395 (perp=5.241, rec=0.069, cos=0.277), tot_loss_proj:1.483 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.391 (perp=5.241, rec=0.066, cos=0.277), tot_loss_proj:1.485 [t=0.24s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.389 (perp=5.241, rec=0.063, cos=0.277), tot_loss_proj:1.488 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[1800/2000] tot_loss=1.379 (perp=5.241, rec=0.054, cos=0.277), tot_loss_proj:1.484 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.390 (perp=5.241, rec=0.064, cos=0.277), tot_loss_proj:1.481 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.384 (perp=5.241, rec=0.058, cos=0.277), tot_loss_proj:1.488 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
[1950/2000] tot_loss=1.384 (perp=5.241, rec=0.058, cos=0.277), tot_loss_proj:1.486 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.399 (perp=5.241, rec=0.074, cos=0.277), tot_loss_proj:1.483 [t=0.23s]
prediction: ['[CLS] he goes. [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] he goes. [SEP]
========================
predicted: 
========================
[CLS] he goes. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.419 | p: 87.143 | r: 87.961
rouge2     | fm: 51.693 | p: 51.313 | r: 52.230
rougeL     | fm: 77.461 | p: 77.186 | r: 77.955
rougeLsum  | fm: 77.523 | p: 77.278 | r: 77.942
r1fm+r2fm = 139.111

input #72 time: 0:09:08 | total time: 11:04:33


Running input #73 of 100.
reference: 
========================
This machine records well.
========================
average of cosine similarity 0.8995119226803465
highest_index [0]
highest [0.8995119226803465]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2023, 3698, 2636, 2092, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] this machine records well. [SEP]']
[Init] best rec loss: 0.9127278923988342 for ['[CLS] miss violet chord parole tempo [SEP]']
[Init] best rec loss: 0.8882413506507874 for ['[CLS] streaktite newt fiction vr [SEP]']
[Init] best rec loss: 0.8660273551940918 for ['[CLS] arm indusction pam wilson [SEP]']
[Init] best rec loss: 0.8601881265640259 for ['[CLS] fruit des historyrat peak [SEP]']
[Init] best rec loss: 0.8477361798286438 for ['[CLS] treat or colin jerseys format [SEP]']
[Init] best rec loss: 0.8399089574813843 for ['[CLS] pp nic forery perfect [SEP]']
[Init] best perm rec loss: 0.8387168049812317 for ['[CLS] forery pp nic perfect [SEP]']
[Init] best perm rec loss: 0.8384525775909424 for ['[CLS]ery pp for nic perfect [SEP]']
[Init] best perm rec loss: 0.8360669612884521 for ['[CLS] forery nic perfect pp [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.170 (perp=8.142, rec=0.355, cos=0.186), tot_loss_proj:3.362 [t=0.23s]
prediction: ['[CLS]. machine record records record [SEP]']
[ 100/2000] tot_loss=2.252 (perp=8.800, rec=0.275, cos=0.217), tot_loss_proj:3.143 [t=0.23s]
prediction: ['[CLS] this machine records records well [SEP]']
[ 150/2000] tot_loss=1.933 (perp=8.015, rec=0.155, cos=0.176), tot_loss_proj:2.640 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
[ 200/2000] tot_loss=1.887 (perp=8.015, rec=0.099, cos=0.185), tot_loss_proj:2.648 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.882 (perp=8.015, rec=0.089, cos=0.190), tot_loss_proj:2.654 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
[ 300/2000] tot_loss=1.879 (perp=8.015, rec=0.088, cos=0.188), tot_loss_proj:2.652 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.881 (perp=8.015, rec=0.089, cos=0.189), tot_loss_proj:2.650 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.870 (perp=8.015, rec=0.077, cos=0.190), tot_loss_proj:2.649 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
[ 450/2000] tot_loss=1.869 (perp=8.015, rec=0.077, cos=0.190), tot_loss_proj:2.650 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.871 (perp=8.015, rec=0.078, cos=0.190), tot_loss_proj:2.654 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.886 (perp=8.015, rec=0.093, cos=0.190), tot_loss_proj:2.650 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
[ 600/2000] tot_loss=1.864 (perp=8.015, rec=0.073, cos=0.188), tot_loss_proj:2.651 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.878 (perp=8.015, rec=0.084, cos=0.191), tot_loss_proj:2.645 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.868 (perp=8.015, rec=0.076, cos=0.188), tot_loss_proj:2.652 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
[ 750/2000] tot_loss=1.874 (perp=8.015, rec=0.082, cos=0.189), tot_loss_proj:2.649 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.873 (perp=8.015, rec=0.081, cos=0.189), tot_loss_proj:2.654 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.881 (perp=8.015, rec=0.088, cos=0.190), tot_loss_proj:2.651 [t=0.23s]
prediction: ['[CLS] this machine records this well [SEP]']
[ 900/2000] tot_loss=2.038 (perp=8.823, rec=0.082, cos=0.191), tot_loss_proj:3.329 [t=0.23s]
prediction: ['[CLS] this machine records. well [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.483 (perp=6.165, rec=0.062, cos=0.188), tot_loss_proj:1.533 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.483 (perp=6.165, rec=0.060, cos=0.189), tot_loss_proj:1.528 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
[1050/2000] tot_loss=1.492 (perp=6.165, rec=0.070, cos=0.189), tot_loss_proj:1.532 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.493 (perp=6.165, rec=0.071, cos=0.190), tot_loss_proj:1.537 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.477 (perp=6.165, rec=0.054, cos=0.190), tot_loss_proj:1.541 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
[1200/2000] tot_loss=1.487 (perp=6.165, rec=0.064, cos=0.190), tot_loss_proj:1.537 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.475 (perp=6.165, rec=0.053, cos=0.190), tot_loss_proj:1.529 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.488 (perp=6.165, rec=0.065, cos=0.190), tot_loss_proj:1.536 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
[1350/2000] tot_loss=1.485 (perp=6.165, rec=0.062, cos=0.190), tot_loss_proj:1.540 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.485 (perp=6.165, rec=0.062, cos=0.190), tot_loss_proj:1.539 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.497 (perp=6.165, rec=0.074, cos=0.190), tot_loss_proj:1.535 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
[1500/2000] tot_loss=1.489 (perp=6.165, rec=0.066, cos=0.190), tot_loss_proj:1.536 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.495 (perp=6.165, rec=0.072, cos=0.190), tot_loss_proj:1.540 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.489 (perp=6.165, rec=0.066, cos=0.190), tot_loss_proj:1.534 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
[1650/2000] tot_loss=1.489 (perp=6.165, rec=0.065, cos=0.190), tot_loss_proj:1.530 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.485 (perp=6.165, rec=0.062, cos=0.190), tot_loss_proj:1.536 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.475 (perp=6.165, rec=0.051, cos=0.190), tot_loss_proj:1.536 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
[1800/2000] tot_loss=1.479 (perp=6.165, rec=0.056, cos=0.190), tot_loss_proj:1.532 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.488 (perp=6.165, rec=0.065, cos=0.190), tot_loss_proj:1.545 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.478 (perp=6.165, rec=0.055, cos=0.190), tot_loss_proj:1.530 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
[1950/2000] tot_loss=1.492 (perp=6.165, rec=0.069, cos=0.190), tot_loss_proj:1.528 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.494 (perp=6.165, rec=0.071, cos=0.190), tot_loss_proj:1.541 [t=0.23s]
prediction: ['[CLS] this machine records well. [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] this machine records well. [SEP]
========================
predicted: 
========================
[CLS] this machine records well. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.644 | p: 87.340 | r: 88.155
rouge2     | fm: 52.592 | p: 52.244 | r: 53.088
rougeL     | fm: 77.820 | p: 77.575 | r: 78.221
rougeLsum  | fm: 77.796 | p: 77.496 | r: 78.188
r1fm+r2fm = 140.236

input #73 time: 0:09:08 | total time: 11:13:41


Running input #74 of 100.
reference: 
========================
Love her though I may, that won't affect the grade.
========================
average of cosine similarity 0.9280528899446239
highest_index [0]
highest [0.9280528899446239]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2293, 2014, 2295, 1045, 2089, 1010, 2008, 2180, 1005, 1056, 7461,
         1996, 3694, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] love her though i may, that won't affect the grade. [SEP]"]
[Init] best rec loss: 0.8373209834098816 for ['[CLS] charm joke classification lemon vhs d （ alzheimer minogueify gunslinger part used club [SEP]']
[Init] best rec loss: 0.8185978531837463 for ['[CLS] federal display erik again offs prime it micgation ark semi everything privy branch [SEP]']
[Init] best rec loss: 0.8030823469161987 for ['[CLS] out wizard8 window warming half being ever goneresh thornton switzerland interrupted baptiste [SEP]']
[Init] best perm rec loss: 0.7984222173690796 for ['[CLS] window half thornton out switzerland being gone interrupted ever8 warming baptiste wizardresh [SEP]']
[Init] best perm rec loss: 0.7939415574073792 for ['[CLS] out switzerlandresh gone window interrupted ever half wizard8 warming baptiste thornton being [SEP]']
[Init] best perm rec loss: 0.7916616797447205 for ['[CLS] switzerland interrupted out baptiste8 warming gone window everresh wizard half thornton being [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.903 (perp=11.189, rec=0.490, cos=0.175), tot_loss_proj:4.103 [t=0.23s]
prediction: ['[CLS] italy bal accept defeat, christianity her, indeed fraserism quasi evans alright [SEP]']
[ 100/2000] tot_loss=2.930 (perp=11.608, rec=0.345, cos=0.263), tot_loss_proj:4.110 [t=0.23s]
prediction: ['[CLS] love benin accept love her perhaps that you, county [SEP] catholic western speaks [SEP]']
[ 150/2000] tot_loss=2.792 (perp=12.107, rec=0.246, cos=0.124), tot_loss_proj:4.284 [t=0.23s]
prediction: ['[CLS] love affect accept love love though that her, hills [SEP] catholic western will [SEP]']
[ 200/2000] tot_loss=2.430 (perp=10.545, rec=0.193, cos=0.127), tot_loss_proj:3.968 [t=0.23s]
prediction: ['[CLS] love affect accept love love though that her,coming ja catholic jersey. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.549 (perp=10.405, rec=0.278, cos=0.190), tot_loss_proj:3.903 [t=0.23s]
prediction: ['[CLS] love affect accept love though that love her, hills khyber grammar formation. [SEP]']
[ 300/2000] tot_loss=2.280 (perp=9.848, rec=0.176, cos=0.135), tot_loss_proj:3.815 [t=0.23s]
prediction: ['[CLS] love affect not love though that i her, hills khyber grade formation. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.255 (perp=9.775, rec=0.165, cos=0.135), tot_loss_proj:3.726 [t=0.23s]
prediction: ['[CLS] love her would love though that i affect, hills khyber grade formation. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.149 (perp=9.275, rec=0.155, cos=0.138), tot_loss_proj:3.731 [t=0.23s]
prediction: ['[CLS] love i would love though that her affect, hills khyber grade formation. [SEP]']
[ 450/2000] tot_loss=2.135 (perp=9.308, rec=0.138, cos=0.136), tot_loss_proj:3.767 [t=0.23s]
prediction: ['[CLS] love i would love though that her affect, hills khyber grade grade. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.261 (perp=9.993, rec=0.127, cos=0.135), tot_loss_proj:3.774 [t=0.23s]
prediction: ['[CLS] love i wouldn love though that affect her, hills khyber grade grade. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.969 (perp=8.560, rec=0.119, cos=0.138), tot_loss_proj:3.479 [t=0.23s]
prediction: ['[CLS] may i won love though that affect her, hills khyber grade grade. [SEP]']
[ 600/2000] tot_loss=1.965 (perp=8.560, rec=0.118, cos=0.135), tot_loss_proj:3.477 [t=0.23s]
prediction: ['[CLS] may i won love though that affect her, hills khyber grade grade. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.954 (perp=8.560, rec=0.106, cos=0.136), tot_loss_proj:3.473 [t=0.23s]
prediction: ['[CLS] may i won love though that affect her, hills khyber grade grade. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.896 (perp=8.263, rec=0.106, cos=0.138), tot_loss_proj:3.405 [t=0.23s]
prediction: ['[CLS] may i won love though that affect her, khyber point grade grade. [SEP]']
[ 750/2000] tot_loss=1.896 (perp=8.263, rec=0.105, cos=0.138), tot_loss_proj:3.411 [t=0.23s]
prediction: ['[CLS] may i won love though that affect her, khyber point grade grade. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.832 (perp=7.992, rec=0.100, cos=0.133), tot_loss_proj:3.363 [t=0.23s]
prediction: ['[CLS] may i won love though that affect her, grade point grade khyber. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.813 (perp=7.902, rec=0.099, cos=0.133), tot_loss_proj:3.347 [t=0.23s]
prediction: ['[CLS] i may won love though that affect her, grade point grade khyber. [SEP]']
[ 900/2000] tot_loss=1.816 (perp=7.902, rec=0.097, cos=0.139), tot_loss_proj:3.345 [t=0.23s]
prediction: ['[CLS] i may won love though that affect her, grade point grade khyber. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.771 (perp=7.676, rec=0.098, cos=0.138), tot_loss_proj:3.303 [t=0.23s]
prediction: ['[CLS] i may won love though, that affect her grade point grade khyber. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.766 (perp=7.676, rec=0.093, cos=0.138), tot_loss_proj:3.306 [t=0.23s]
prediction: ['[CLS] i may won love though, that affect her grade point grade khyber. [SEP]']
[1050/2000] tot_loss=1.777 (perp=7.676, rec=0.103, cos=0.139), tot_loss_proj:3.306 [t=0.23s]
prediction: ['[CLS] i may won love though, that affect her grade point grade khyber. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.760 (perp=7.676, rec=0.087, cos=0.138), tot_loss_proj:3.306 [t=0.23s]
prediction: ['[CLS] i may won love though, that affect her grade point grade khyber. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.750 (perp=7.632, rec=0.090, cos=0.133), tot_loss_proj:3.334 [t=0.23s]
prediction: ['[CLS] i may won love though, that her affect the point grade khyber. [SEP]']
[1200/2000] tot_loss=1.744 (perp=7.632, rec=0.080, cos=0.138), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] i may won love though, that her affect the point grade khyber. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.684 (perp=7.285, rec=0.092, cos=0.136), tot_loss_proj:3.341 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.687 (perp=7.285, rec=0.092, cos=0.138), tot_loss_proj:3.371 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
[1350/2000] tot_loss=1.682 (perp=7.285, rec=0.087, cos=0.138), tot_loss_proj:3.374 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.683 (perp=7.285, rec=0.087, cos=0.139), tot_loss_proj:3.372 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.679 (perp=7.285, rec=0.084, cos=0.138), tot_loss_proj:3.374 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
[1500/2000] tot_loss=1.690 (perp=7.285, rec=0.094, cos=0.139), tot_loss_proj:3.373 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.683 (perp=7.285, rec=0.087, cos=0.138), tot_loss_proj:3.379 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.677 (perp=7.285, rec=0.082, cos=0.138), tot_loss_proj:3.373 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
[1650/2000] tot_loss=1.674 (perp=7.285, rec=0.079, cos=0.138), tot_loss_proj:3.375 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.681 (perp=7.285, rec=0.085, cos=0.139), tot_loss_proj:3.377 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.686 (perp=7.285, rec=0.090, cos=0.138), tot_loss_proj:3.373 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
[1800/2000] tot_loss=1.681 (perp=7.285, rec=0.085, cos=0.138), tot_loss_proj:3.374 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.673 (perp=7.285, rec=0.078, cos=0.139), tot_loss_proj:3.372 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.682 (perp=7.285, rec=0.087, cos=0.139), tot_loss_proj:3.369 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
[1950/2000] tot_loss=1.679 (perp=7.285, rec=0.084, cos=0.138), tot_loss_proj:3.372 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.682 (perp=7.285, rec=0.086, cos=0.138), tot_loss_proj:3.370 [t=0.23s]
prediction: ['[CLS] i may won love, though that her affect the point grade khyber. [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] love her though i may, that won't affect the grade. [SEP]
========================
predicted: 
========================
[CLS] i may won love, though that her affect the point grade khyber. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 85.714 | r: 92.308
rouge2     | fm: 16.000 | p: 15.385 | r: 16.667
rougeL     | fm: 59.259 | p: 57.143 | r: 61.538
rougeLsum  | fm: 59.259 | p: 57.143 | r: 61.538
r1fm+r2fm = 104.889

[Aggregate metrics]:
rouge1     | fm: 87.697 | p: 87.299 | r: 88.211
rouge2     | fm: 52.082 | p: 51.711 | r: 52.586
rougeL     | fm: 77.561 | p: 77.235 | r: 78.057
rougeLsum  | fm: 77.519 | p: 77.157 | r: 77.991
r1fm+r2fm = 139.779

input #74 time: 0:09:09 | total time: 11:22:51


Running input #75 of 100.
reference: 
========================
I have been flying helicopters for years.
========================
average of cosine similarity 0.8664522959245732
highest_index [0]
highest [0.8664522959245732]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1045,  2031,  2042,  3909, 12400,  2005,  2086,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have been flying helicopters for years. [SEP]']
[Init] best rec loss: 0.9223737716674805 for ['[CLS] lindsey exposed gov recreation touch approaching lack troubles [SEP]']
[Init] best rec loss: 0.918532133102417 for ['[CLS] unlike outside doping wednesday blows - morgan power [SEP]']
[Init] best rec loss: 0.9124216437339783 for ['[CLS] exhibit suggesthorn folks royal sports ″ log [SEP]']
[Init] best rec loss: 0.9118617177009583 for ['[CLS] dropral rhapsody full sidekick " sheatt [SEP]']
[Init] best rec loss: 0.8821923136711121 for ['[CLS] medley lesser luxembourgwinditaire least sin we [SEP]']
[Init] best rec loss: 0.8681269884109497 for ['[CLS] june caden return \\ tu lcd participating teacher [SEP]']
[Init] best rec loss: 0.8668184280395508 for ['[CLS] following bearfield between consumers muscle java continental [SEP]']
[Init] best perm rec loss: 0.8644862771034241 for ['[CLS] following between consumersfield continental bear java muscle [SEP]']
[Init] best perm rec loss: 0.8623552322387695 for ['[CLS] bear continental consumers muscle between javafield following [SEP]']
[Init] best perm rec loss: 0.8620858788490295 for ['[CLS] java bear consumers muscle continentalfield following between [SEP]']
[Init] best perm rec loss: 0.8620272874832153 for ['[CLS] bear consumersfield continental following java between muscle [SEP]']
[Init] best perm rec loss: 0.8601207733154297 for ['[CLS] consumers muscle bear following continental between javafield [SEP]']
[Init] best perm rec loss: 0.8597338199615479 for ['[CLS] bear consumers following muscle between continentalfield java [SEP]']
[Init] best perm rec loss: 0.8587786555290222 for ['[CLS] following muscle bear continentalfield java between consumers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.817 (perp=10.900, rec=0.384, cos=0.253), tot_loss_proj:4.017 [t=0.23s]
prediction: ['[CLS] i - radio mountain helicopter government boots its [SEP]']
[ 100/2000] tot_loss=1.921 (perp=7.244, rec=0.225, cos=0.247), tot_loss_proj:3.309 [t=0.23s]
prediction: ['[CLS] i have been flying helicopters government helicopters in [SEP]']
[ 150/2000] tot_loss=1.846 (perp=7.061, rec=0.185, cos=0.249), tot_loss_proj:3.191 [t=0.23s]
prediction: ['[CLS] i have been flying helicopters donated helicopters. [SEP]']
[ 200/2000] tot_loss=1.803 (perp=7.061, rec=0.142, cos=0.249), tot_loss_proj:3.196 [t=0.23s]
prediction: ['[CLS] i have been flying helicopters donated helicopters. [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.104 (perp=8.586, rec=0.137, cos=0.250), tot_loss_proj:3.589 [t=0.23s]
prediction: ['[CLS] i years been flying helicopters donated helicopters. [SEP]']
[ 300/2000] tot_loss=2.093 (perp=8.586, rec=0.128, cos=0.248), tot_loss_proj:3.589 [t=0.23s]
prediction: ['[CLS] i years been flying helicopters donated helicopters. [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.084 (perp=8.586, rec=0.118, cos=0.248), tot_loss_proj:3.588 [t=0.23s]
prediction: ['[CLS] i years been flying helicopters donated helicopters. [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.088 (perp=8.586, rec=0.122, cos=0.249), tot_loss_proj:3.588 [t=0.23s]
prediction: ['[CLS] i years been flying helicopters donated helicopters. [SEP]']
[ 450/2000] tot_loss=2.085 (perp=8.586, rec=0.119, cos=0.249), tot_loss_proj:3.591 [t=0.23s]
prediction: ['[CLS] i years been flying helicopters donated helicopters. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.081 (perp=8.586, rec=0.114, cos=0.250), tot_loss_proj:3.587 [t=0.23s]
prediction: ['[CLS] i years been flying helicopters donated helicopters. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.080 (perp=8.586, rec=0.114, cos=0.249), tot_loss_proj:3.586 [t=0.23s]
prediction: ['[CLS] i years been flying helicopters donated helicopters. [SEP]']
[ 600/2000] tot_loss=2.076 (perp=8.586, rec=0.111, cos=0.248), tot_loss_proj:3.590 [t=0.23s]
prediction: ['[CLS] i years been flying helicopters donated helicopters. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.004 (perp=8.225, rec=0.110, cos=0.249), tot_loss_proj:3.509 [t=0.23s]
prediction: ['[CLS] i years been flying helicopters boeing helicopters. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.990 (perp=7.923, rec=0.161, cos=0.245), tot_loss_proj:3.458 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
[ 750/2000] tot_loss=1.958 (perp=7.923, rec=0.123, cos=0.250), tot_loss_proj:3.452 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.960 (perp=7.923, rec=0.127, cos=0.248), tot_loss_proj:3.452 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.953 (perp=7.923, rec=0.119, cos=0.249), tot_loss_proj:3.451 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
[ 900/2000] tot_loss=1.952 (perp=7.923, rec=0.119, cos=0.249), tot_loss_proj:3.457 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.945 (perp=7.923, rec=0.112, cos=0.249), tot_loss_proj:3.454 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.948 (perp=7.923, rec=0.114, cos=0.249), tot_loss_proj:3.454 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
[1050/2000] tot_loss=1.950 (perp=7.923, rec=0.117, cos=0.249), tot_loss_proj:3.451 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.953 (perp=7.923, rec=0.119, cos=0.249), tot_loss_proj:3.454 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.957 (perp=7.923, rec=0.123, cos=0.249), tot_loss_proj:3.450 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
[1200/2000] tot_loss=1.938 (perp=7.923, rec=0.104, cos=0.249), tot_loss_proj:3.454 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.943 (perp=7.923, rec=0.110, cos=0.249), tot_loss_proj:3.450 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.956 (perp=7.923, rec=0.122, cos=0.249), tot_loss_proj:3.454 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
[1350/2000] tot_loss=1.938 (perp=7.923, rec=0.105, cos=0.249), tot_loss_proj:3.457 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.942 (perp=7.923, rec=0.107, cos=0.249), tot_loss_proj:3.452 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.946 (perp=7.923, rec=0.112, cos=0.249), tot_loss_proj:3.451 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
[1500/2000] tot_loss=1.963 (perp=7.923, rec=0.129, cos=0.249), tot_loss_proj:3.453 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.936 (perp=7.923, rec=0.102, cos=0.249), tot_loss_proj:3.452 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.948 (perp=7.923, rec=0.115, cos=0.249), tot_loss_proj:3.454 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
[1650/2000] tot_loss=1.956 (perp=7.923, rec=0.122, cos=0.249), tot_loss_proj:3.453 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.949 (perp=7.923, rec=0.115, cos=0.249), tot_loss_proj:3.455 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.958 (perp=7.923, rec=0.124, cos=0.249), tot_loss_proj:3.458 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
[1800/2000] tot_loss=1.942 (perp=7.923, rec=0.108, cos=0.249), tot_loss_proj:3.454 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.948 (perp=7.923, rec=0.114, cos=0.249), tot_loss_proj:3.452 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.938 (perp=7.923, rec=0.104, cos=0.249), tot_loss_proj:3.455 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters wooden helicopters. [SEP]']
[1950/2000] tot_loss=2.086 (perp=8.636, rec=0.109, cos=0.249), tot_loss_proj:3.589 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters donated helicopters. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.097 (perp=8.636, rec=0.120, cos=0.249), tot_loss_proj:3.590 [t=0.23s]
prediction: ['[CLS] i have years flying helicopters donated helicopters. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] i have been flying helicopters for years. [SEP]
========================
predicted: 
========================
[CLS] i have years flying helicopters wooden helicopters. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 115.278

[Aggregate metrics]:
rouge1     | fm: 87.545 | p: 87.178 | r: 88.079
rouge2     | fm: 51.764 | p: 51.367 | r: 52.331
rougeL     | fm: 77.365 | p: 77.005 | r: 77.832
rougeLsum  | fm: 77.381 | p: 77.007 | r: 77.835
r1fm+r2fm = 139.308

input #75 time: 0:09:09 | total time: 11:32:00


Running input #76 of 100.
reference: 
========================
the person stand on my foot is heavy.
========================
average of cosine similarity 0.8881215351293315
highest_index [0]
highest [0.8881215351293315]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2711, 3233, 2006, 2026, 3329, 2003, 3082, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the person stand on my foot is heavy. [SEP]']
[Init] best rec loss: 0.7668627500534058 for ['[CLS] yes motorway has entering lin trust d dante without [SEP]']
[Init] best rec loss: 0.7571041584014893 for ['[CLS] how cindy thousands yeah gram chudocknsed widow [SEP]']
[Init] best rec loss: 0.7517278790473938 for ['[CLS] concrete supportke police liszt gracelay masjid empress [SEP]']
[Init] best rec loss: 0.7328651547431946 for ['[CLS] right atgang connecting naturalistpy half use feud [SEP]']
[Init] best rec loss: 0.6942073106765747 for ['[CLS]ya bird bottledped range figure two serial astro [SEP]']
[Init] best rec loss: 0.6892901659011841 for ['[CLS] landfall day resulted kenton institute kate holland learning recorder [SEP]']
[Init] best rec loss: 0.6703515648841858 for ['[CLS] amnesia between electoral everyday facinglaidfold depot largest [SEP]']
[Init] best perm rec loss: 0.6702470779418945 for ['[CLS] electoralfoldlaid amnesia facing everyday largest depot between [SEP]']
[Init] best perm rec loss: 0.6702350974082947 for ['[CLS] largestlaid betweenfold depot amnesia everyday electoral facing [SEP]']
[Init] best perm rec loss: 0.6697044968605042 for ['[CLS]laid everyday between amnesia largestfold facing electoral depot [SEP]']
[Init] best perm rec loss: 0.6685822010040283 for ['[CLS] between electoral amnesia facing depotfold everydaylaid largest [SEP]']
[Init] best perm rec loss: 0.6682985424995422 for ['[CLS] facing electoral depot between everydaylaid largestfold amnesia [SEP]']
[Init] best perm rec loss: 0.6681642532348633 for ['[CLS] facing largest amnesia electorallaid everyday betweenfold depot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.619 (perp=10.138, rec=0.392, cos=0.200), tot_loss_proj:2.970 [t=0.23s]
prediction: ['[CLS] facing person at have her person site bed person [SEP]']
[ 100/2000] tot_loss=2.292 (perp=8.966, rec=0.288, cos=0.211), tot_loss_proj:2.743 [t=0.23s]
prediction: ['[CLS] the person person stand is person blade on is [SEP]']
[ 150/2000] tot_loss=2.194 (perp=8.340, rec=0.320, cos=0.206), tot_loss_proj:2.594 [t=0.23s]
prediction: ['[CLS] the person person stand is person foot on is [SEP]']
[ 200/2000] tot_loss=2.172 (perp=8.866, rec=0.189, cos=0.209), tot_loss_proj:2.694 [t=0.23s]
prediction: ['[CLS] the person person stand is person foot on heavy [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.918 (perp=7.413, rec=0.221, cos=0.214), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot. is [SEP]']
[ 300/2000] tot_loss=1.834 (perp=7.413, rec=0.141, cos=0.211), tot_loss_proj:2.218 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot. is [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.679 (perp=6.851, rec=0.099, cos=0.210), tot_loss_proj:2.015 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.666 (perp=6.851, rec=0.085, cos=0.211), tot_loss_proj:2.015 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
[ 450/2000] tot_loss=1.668 (perp=6.851, rec=0.087, cos=0.211), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.664 (perp=6.851, rec=0.083, cos=0.211), tot_loss_proj:2.017 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.656 (perp=6.851, rec=0.075, cos=0.211), tot_loss_proj:2.014 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
[ 600/2000] tot_loss=1.663 (perp=6.851, rec=0.081, cos=0.211), tot_loss_proj:2.013 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.660 (perp=6.851, rec=0.079, cos=0.211), tot_loss_proj:2.015 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.655 (perp=6.851, rec=0.074, cos=0.211), tot_loss_proj:2.005 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
[ 750/2000] tot_loss=1.655 (perp=6.851, rec=0.074, cos=0.211), tot_loss_proj:2.014 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.653 (perp=6.851, rec=0.071, cos=0.211), tot_loss_proj:2.018 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.654 (perp=6.851, rec=0.072, cos=0.211), tot_loss_proj:2.015 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
[ 900/2000] tot_loss=1.652 (perp=6.851, rec=0.071, cos=0.211), tot_loss_proj:2.020 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.665 (perp=6.851, rec=0.083, cos=0.211), tot_loss_proj:2.007 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.648 (perp=6.851, rec=0.067, cos=0.211), tot_loss_proj:2.011 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
[1050/2000] tot_loss=1.649 (perp=6.851, rec=0.067, cos=0.211), tot_loss_proj:2.010 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.646 (perp=6.851, rec=0.065, cos=0.211), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.658 (perp=6.851, rec=0.077, cos=0.211), tot_loss_proj:2.016 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
[1200/2000] tot_loss=1.653 (perp=6.851, rec=0.072, cos=0.211), tot_loss_proj:2.014 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.660 (perp=6.851, rec=0.079, cos=0.211), tot_loss_proj:2.019 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.661 (perp=6.851, rec=0.079, cos=0.211), tot_loss_proj:2.009 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
[1350/2000] tot_loss=1.654 (perp=6.851, rec=0.073, cos=0.211), tot_loss_proj:2.017 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.658 (perp=6.851, rec=0.076, cos=0.211), tot_loss_proj:2.017 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.655 (perp=6.851, rec=0.073, cos=0.211), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
[1500/2000] tot_loss=1.651 (perp=6.851, rec=0.070, cos=0.211), tot_loss_proj:2.024 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.649 (perp=6.851, rec=0.068, cos=0.211), tot_loss_proj:2.016 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.657 (perp=6.851, rec=0.076, cos=0.211), tot_loss_proj:2.021 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
[1650/2000] tot_loss=1.650 (perp=6.851, rec=0.068, cos=0.211), tot_loss_proj:2.009 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.650 (perp=6.851, rec=0.068, cos=0.211), tot_loss_proj:2.004 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.645 (perp=6.851, rec=0.064, cos=0.211), tot_loss_proj:2.011 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
[1800/2000] tot_loss=1.647 (perp=6.851, rec=0.066, cos=0.211), tot_loss_proj:2.016 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.649 (perp=6.851, rec=0.068, cos=0.211), tot_loss_proj:2.014 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.647 (perp=6.851, rec=0.066, cos=0.211), tot_loss_proj:2.004 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
[1950/2000] tot_loss=1.651 (perp=6.851, rec=0.070, cos=0.211), tot_loss_proj:2.006 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.654 (perp=6.851, rec=0.073, cos=0.211), tot_loss_proj:2.015 [t=0.23s]
prediction: ['[CLS] the person stand on my person foot is heavy [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS] the person stand on my foot is heavy. [SEP]
========================
predicted: 
========================
[CLS] the person stand on my person foot is heavy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 84.211 | p: 80.000 | r: 88.889
rougeL     | fm: 95.238 | p: 90.909 | r: 100.000
rougeLsum  | fm: 95.238 | p: 90.909 | r: 100.000
r1fm+r2fm = 179.449

[Aggregate metrics]:
rouge1     | fm: 87.672 | p: 87.307 | r: 88.255
rouge2     | fm: 52.300 | p: 51.887 | r: 52.816
rougeL     | fm: 77.592 | p: 77.202 | r: 78.052
rougeLsum  | fm: 77.669 | p: 77.317 | r: 78.198
r1fm+r2fm = 139.973

input #76 time: 0:09:09 | total time: 11:41:10


Running input #77 of 100.
reference: 
========================
My mother baked a cake for me.
========================
average of cosine similarity 0.8708211014102328
highest_index [0]
highest [0.8708211014102328]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2026,  2388, 17776,  1037,  9850,  2005,  2033,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] my mother baked a cake for me. [SEP]']
[Init] best rec loss: 0.9597048759460449 for ['[CLS] mysterious statistical its owner soft bodo network posting [SEP]']
[Init] best rec loss: 0.9456676244735718 for ['[CLS] baby jolink & spinal is andre youngest [SEP]']
[Init] best rec loss: 0.9328235983848572 for ['[CLS] quarter crying tour specification period minds pub [MASK] [SEP]']
[Init] best rec loss: 0.9261685013771057 for ['[CLS] northern, orders approach auxthan british poll [SEP]']
[Init] best rec loss: 0.9248819351196289 for ['[CLS] helmetgating shaking external closed )ations oldest [SEP]']
[Init] best rec loss: 0.9209010601043701 for ['[CLS] weak eldestgible pool ashes provide ball reaching [SEP]']
[Init] best rec loss: 0.9187658429145813 for ['[CLS] kei canton town where gibbonsmit tessa cavalry [SEP]']
[Init] best rec loss: 0.9100474119186401 for ['[CLS]words & edited atom out charlie field hop [SEP]']
[Init] best rec loss: 0.9005889892578125 for ['[CLS] own owned mona almost handling different size o [SEP]']
[Init] best rec loss: 0.8966057300567627 for ['[CLS] badly hardest blah wrapping gaines menu nickel } [SEP]']
[Init] best perm rec loss: 0.8956896662712097 for ['[CLS] badly wrapping blah gaines menu hardest } nickel [SEP]']
[Init] best perm rec loss: 0.8955901861190796 for ['[CLS] hardest wrapping nickel gaines blah badly menu } [SEP]']
[Init] best perm rec loss: 0.8955506682395935 for ['[CLS] wrapping menu nickel blah hardest badly } gaines [SEP]']
[Init] best perm rec loss: 0.8943994045257568 for ['[CLS] badly menu gaines } blah wrapping hardest nickel [SEP]']
[Init] best perm rec loss: 0.8936076760292053 for ['[CLS] wrapping menu nickel blah gaines } badly hardest [SEP]']
[Init] best perm rec loss: 0.8929670453071594 for ['[CLS] nickel menu gaines badly blah wrapping hardest } [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.814 (perp=11.260, rec=0.321, cos=0.241), tot_loss_proj:4.030 [t=0.22s]
prediction: ['[CLS] mother mother coin father she baked cake mother [SEP]']
[ 100/2000] tot_loss=2.608 (perp=10.865, rec=0.195, cos=0.240), tot_loss_proj:3.941 [t=0.22s]
prediction: ['[CLS] mother mother came father my baked cake my [SEP]']
[ 150/2000] tot_loss=2.087 (perp=8.527, rec=0.142, cos=0.240), tot_loss_proj:3.523 [t=0.22s]
prediction: ['[CLS] my mother for father me baked cake for [SEP]']
[ 200/2000] tot_loss=2.053 (perp=8.527, rec=0.108, cos=0.240), tot_loss_proj:3.524 [t=0.22s]
prediction: ['[CLS] my mother for father me baked cake for [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.858 (perp=7.595, rec=0.099, cos=0.240), tot_loss_proj:3.335 [t=0.22s]
prediction: ['[CLS] my mother ; father for me baked cake [SEP]']
[ 300/2000] tot_loss=2.037 (perp=8.477, rec=0.101, cos=0.241), tot_loss_proj:3.469 [t=0.22s]
prediction: ['[CLS] my mother ; our for me baked cake [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.662 (perp=6.590, rec=0.103, cos=0.241), tot_loss_proj:2.877 [t=0.22s]
prediction: ['[CLS] my mother. baked for me my cake [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.656 (perp=6.590, rec=0.098, cos=0.240), tot_loss_proj:2.876 [t=0.22s]
prediction: ['[CLS] my mother. baked for me my cake [SEP]']
[ 450/2000] tot_loss=1.800 (perp=7.332, rec=0.095, cos=0.239), tot_loss_proj:3.314 [t=0.22s]
prediction: ['[CLS] my mother a baked for me my cake [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.747 (perp=7.113, rec=0.086, cos=0.239), tot_loss_proj:3.233 [t=0.22s]
prediction: ['[CLS] my mother a baked me for my cake [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.678 (perp=6.801, rec=0.080, cos=0.238), tot_loss_proj:3.222 [t=0.22s]
prediction: ['[CLS] my mother baked a me for my cake [SEP]']
[ 600/2000] tot_loss=1.679 (perp=6.801, rec=0.080, cos=0.238), tot_loss_proj:3.223 [t=0.22s]
prediction: ['[CLS] my mother baked a me for my cake [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.513 (perp=5.995, rec=0.076, cos=0.238), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.518 (perp=5.995, rec=0.081, cos=0.238), tot_loss_proj:3.112 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
[ 750/2000] tot_loss=1.524 (perp=5.995, rec=0.087, cos=0.238), tot_loss_proj:3.105 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.523 (perp=5.995, rec=0.086, cos=0.238), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.520 (perp=5.995, rec=0.083, cos=0.238), tot_loss_proj:3.112 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
[ 900/2000] tot_loss=1.507 (perp=5.995, rec=0.071, cos=0.238), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.506 (perp=5.995, rec=0.069, cos=0.238), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1000/2000] tot_loss=1.515 (perp=5.995, rec=0.078, cos=0.238), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
[1050/2000] tot_loss=1.526 (perp=5.995, rec=0.089, cos=0.238), tot_loss_proj:3.113 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1100/2000] tot_loss=1.515 (perp=5.995, rec=0.079, cos=0.238), tot_loss_proj:3.117 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1150/2000] tot_loss=1.513 (perp=5.995, rec=0.077, cos=0.238), tot_loss_proj:3.117 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
[1200/2000] tot_loss=1.516 (perp=5.995, rec=0.079, cos=0.238), tot_loss_proj:3.114 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1250/2000] tot_loss=1.515 (perp=5.995, rec=0.078, cos=0.238), tot_loss_proj:3.121 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1300/2000] tot_loss=1.515 (perp=5.995, rec=0.078, cos=0.238), tot_loss_proj:3.119 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
[1350/2000] tot_loss=1.513 (perp=5.995, rec=0.076, cos=0.238), tot_loss_proj:3.120 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1400/2000] tot_loss=1.521 (perp=5.995, rec=0.084, cos=0.238), tot_loss_proj:3.118 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1450/2000] tot_loss=1.520 (perp=5.995, rec=0.083, cos=0.238), tot_loss_proj:3.116 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
[1500/2000] tot_loss=1.506 (perp=5.995, rec=0.070, cos=0.238), tot_loss_proj:3.120 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1550/2000] tot_loss=1.524 (perp=5.995, rec=0.087, cos=0.238), tot_loss_proj:3.116 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1600/2000] tot_loss=1.510 (perp=5.995, rec=0.073, cos=0.238), tot_loss_proj:3.122 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
[1650/2000] tot_loss=1.503 (perp=5.995, rec=0.066, cos=0.238), tot_loss_proj:3.126 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1700/2000] tot_loss=1.510 (perp=5.995, rec=0.073, cos=0.238), tot_loss_proj:3.119 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1750/2000] tot_loss=1.506 (perp=5.995, rec=0.069, cos=0.238), tot_loss_proj:3.124 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
[1800/2000] tot_loss=1.514 (perp=5.995, rec=0.078, cos=0.238), tot_loss_proj:3.121 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1850/2000] tot_loss=1.518 (perp=5.995, rec=0.082, cos=0.238), tot_loss_proj:3.118 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[1900/2000] tot_loss=1.516 (perp=5.995, rec=0.079, cos=0.238), tot_loss_proj:3.121 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
[1950/2000] tot_loss=1.514 (perp=5.995, rec=0.077, cos=0.238), tot_loss_proj:3.117 [t=0.22s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Attempt swap
[2000/2000] tot_loss=1.511 (perp=5.995, rec=0.075, cos=0.238), tot_loss_proj:3.127 [t=0.23s]
prediction: ['[CLS] my mother baked a cake for my me [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] my mother baked a cake for me. [SEP]
========================
predicted: 
========================
[CLS] my mother baked a cake for my me [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 82.353 | p: 77.778 | r: 87.500
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 177.090

[Aggregate metrics]:
rouge1     | fm: 87.730 | p: 87.284 | r: 88.419
rouge2     | fm: 52.681 | p: 52.276 | r: 53.253
rougeL     | fm: 77.812 | p: 77.406 | r: 78.394
rougeLsum  | fm: 77.930 | p: 77.530 | r: 78.495
r1fm+r2fm = 140.411

input #77 time: 0:08:51 | total time: 11:50:02


Running input #78 of 100.
reference: 
========================
I read some book.
========================
average of cosine similarity 0.9172789707732729
highest_index [0]
highest [0.9172789707732729]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 3191, 2070, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i read some book. [SEP]']
[Init] best rec loss: 0.8042929768562317 for ['[CLS]ys sponsored ni patience courts [SEP]']
[Init] best rec loss: 0.7955646514892578 for ['[CLS] am iv pregnant lagoon ample [SEP]']
[Init] best rec loss: 0.7944930195808411 for ['[CLS] curator askeiection states [SEP]']
[Init] best rec loss: 0.7783916592597961 for ['[CLS]lyverybo ago exempt [SEP]']
[Init] best rec loss: 0.7747328281402588 for ['[CLS] unknown vote su flight unincorporated [SEP]']
[Init] best perm rec loss: 0.7746497988700867 for ['[CLS] vote flight su unincorporated unknown [SEP]']
[Init] best perm rec loss: 0.7719718217849731 for ['[CLS] su vote flight unincorporated unknown [SEP]']
[Init] best perm rec loss: 0.7713367342948914 for ['[CLS] su flight unknown unincorporated vote [SEP]']
[Init] best perm rec loss: 0.7690443992614746 for ['[CLS] unknown su vote unincorporated flight [SEP]']
[Init] best perm rec loss: 0.768805742263794 for ['[CLS] su flight vote unincorporated unknown [SEP]']
[Init] best perm rec loss: 0.7687366604804993 for ['[CLS] flight unincorporated su vote unknown [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.547 (perp=11.139, rec=0.160, cos=0.159), tot_loss_proj:3.090 [t=0.23s]
prediction: ['[CLS] grocery read some some book [SEP]']
[ 100/2000] tot_loss=2.289 (perp=10.183, rec=0.098, cos=0.155), tot_loss_proj:3.221 [t=0.23s]
prediction: ['[CLS]wing read i some book [SEP]']
[ 150/2000] tot_loss=2.452 (perp=11.016, rec=0.095, cos=0.154), tot_loss_proj:3.330 [t=0.23s]
prediction: ['[CLS]writer read i some book [SEP]']
[ 200/2000] tot_loss=2.455 (perp=11.016, rec=0.092, cos=0.159), tot_loss_proj:3.329 [t=0.23s]
prediction: ['[CLS]writer read i some book [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.056 (perp=9.110, rec=0.079, cos=0.156), tot_loss_proj:2.843 [t=0.23s]
prediction: ['[CLS] i readlight some book [SEP]']
[ 300/2000] tot_loss=2.075 (perp=9.110, rec=0.092, cos=0.161), tot_loss_proj:2.845 [t=0.23s]
prediction: ['[CLS] i readlight some book [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.839 (perp=8.011, rec=0.079, cos=0.158), tot_loss_proj:2.841 [t=0.23s]
prediction: ['[CLS] i read some booklight [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.842 (perp=8.011, rec=0.080, cos=0.160), tot_loss_proj:2.833 [t=0.23s]
prediction: ['[CLS] i read some booklight [SEP]']
[ 450/2000] tot_loss=1.832 (perp=8.011, rec=0.070, cos=0.160), tot_loss_proj:2.822 [t=0.23s]
prediction: ['[CLS] i read some booklight [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.846 (perp=8.011, rec=0.085, cos=0.159), tot_loss_proj:2.821 [t=0.23s]
prediction: ['[CLS] i read some booklight [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.841 (perp=8.011, rec=0.079, cos=0.160), tot_loss_proj:2.814 [t=0.23s]
prediction: ['[CLS] i read some booklight [SEP]']
[ 600/2000] tot_loss=1.827 (perp=8.011, rec=0.072, cos=0.153), tot_loss_proj:2.807 [t=0.23s]
prediction: ['[CLS] i read some booklight [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.837 (perp=8.011, rec=0.076, cos=0.159), tot_loss_proj:2.793 [t=0.23s]
prediction: ['[CLS] i read some booklight [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.842 (perp=8.011, rec=0.082, cos=0.158), tot_loss_proj:2.798 [t=0.23s]
prediction: ['[CLS] i read some booklight [SEP]']
[ 750/2000] tot_loss=1.848 (perp=8.011, rec=0.088, cos=0.158), tot_loss_proj:2.784 [t=0.23s]
prediction: ['[CLS] i read some booklight [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.836 (perp=8.011, rec=0.078, cos=0.156), tot_loss_proj:2.780 [t=0.23s]
prediction: ['[CLS] i read some booklight [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.781 (perp=7.756, rec=0.072, cos=0.158), tot_loss_proj:2.391 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
[ 900/2000] tot_loss=1.783 (perp=7.756, rec=0.075, cos=0.157), tot_loss_proj:2.380 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.779 (perp=7.756, rec=0.071, cos=0.157), tot_loss_proj:2.382 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1000/2000] tot_loss=1.794 (perp=7.756, rec=0.083, cos=0.159), tot_loss_proj:2.374 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
[1050/2000] tot_loss=1.799 (perp=7.756, rec=0.089, cos=0.159), tot_loss_proj:2.381 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1100/2000] tot_loss=1.788 (perp=7.756, rec=0.077, cos=0.160), tot_loss_proj:2.374 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1150/2000] tot_loss=1.780 (perp=7.756, rec=0.072, cos=0.157), tot_loss_proj:2.374 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
[1200/2000] tot_loss=1.792 (perp=7.756, rec=0.084, cos=0.157), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1250/2000] tot_loss=1.779 (perp=7.756, rec=0.071, cos=0.157), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1300/2000] tot_loss=1.799 (perp=7.756, rec=0.090, cos=0.158), tot_loss_proj:2.376 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
[1350/2000] tot_loss=1.790 (perp=7.756, rec=0.082, cos=0.157), tot_loss_proj:2.364 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1400/2000] tot_loss=1.795 (perp=7.756, rec=0.085, cos=0.159), tot_loss_proj:2.359 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1450/2000] tot_loss=1.793 (perp=7.756, rec=0.084, cos=0.158), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
[1500/2000] tot_loss=1.791 (perp=7.756, rec=0.081, cos=0.159), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1550/2000] tot_loss=1.772 (perp=7.756, rec=0.062, cos=0.158), tot_loss_proj:2.369 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1600/2000] tot_loss=1.791 (perp=7.756, rec=0.082, cos=0.158), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
[1650/2000] tot_loss=1.798 (perp=7.756, rec=0.088, cos=0.159), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1700/2000] tot_loss=1.790 (perp=7.756, rec=0.080, cos=0.159), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1750/2000] tot_loss=1.794 (perp=7.756, rec=0.084, cos=0.159), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
[1800/2000] tot_loss=1.801 (perp=7.756, rec=0.091, cos=0.158), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1850/2000] tot_loss=1.795 (perp=7.756, rec=0.085, cos=0.158), tot_loss_proj:2.361 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[1900/2000] tot_loss=1.793 (perp=7.756, rec=0.084, cos=0.159), tot_loss_proj:2.361 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
[1950/2000] tot_loss=1.793 (perp=7.756, rec=0.083, cos=0.158), tot_loss_proj:2.362 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Attempt swap
[2000/2000] tot_loss=1.795 (perp=7.756, rec=0.086, cos=0.158), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] i read some book unto [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] i read some book. [SEP]
========================
predicted: 
========================
[CLS] i read some book unto [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 72.727 | p: 66.667 | r: 80.000
rougeL     | fm: 92.308 | p: 85.714 | r: 100.000
rougeLsum  | fm: 92.308 | p: 85.714 | r: 100.000
r1fm+r2fm = 165.035

[Aggregate metrics]:
rouge1     | fm: 87.805 | p: 87.255 | r: 88.604
rouge2     | fm: 52.945 | p: 52.426 | r: 53.537
rougeL     | fm: 78.014 | p: 77.529 | r: 78.713
rougeLsum  | fm: 78.035 | p: 77.551 | r: 78.724
r1fm+r2fm = 140.750

input #78 time: 0:09:09 | total time: 11:59:11


Running input #79 of 100.
reference: 
========================
The umpire called it of.
========================
average of cosine similarity 0.8848792733450657
highest_index [0]
highest [0.8848792733450657]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 20887,  2170,  2009,  1997,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the umpire called it of. [SEP]']
[Init] best rec loss: 0.9354080557823181 for ['[CLS]tlement gi professional julian reaching wingspan [SEP]']
[Init] best rec loss: 0.8857893347740173 for ['[CLS] exposure april located cheesequal enough [SEP]']
[Init] best rec loss: 0.8801746964454651 for ['[CLS] normalari release gas taught treaty [SEP]']
[Init] best perm rec loss: 0.8786463737487793 for ['[CLS] normalari treaty gas release taught [SEP]']
[Init] best perm rec loss: 0.8758952021598816 for ['[CLS] release taughtari treaty gas normal [SEP]']
[Init] best perm rec loss: 0.8753058910369873 for ['[CLS] taught release normal treatyari gas [SEP]']
[Init] best perm rec loss: 0.8714192509651184 for ['[CLS] gas releaseari taught normal treaty [SEP]']
[Init] best perm rec loss: 0.8709176182746887 for ['[CLS] normal release gasari treaty taught [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.523 (perp=9.812, rec=0.347, cos=0.214), tot_loss_proj:3.860 [t=0.22s]
prediction: ['[CLS].her umpire umpire umpire called [SEP]']
[ 100/2000] tot_loss=2.152 (perp=8.778, rec=0.194, cos=0.203), tot_loss_proj:3.669 [t=0.22s]
prediction: ['[CLS] it ; umpire umpire umpire called [SEP]']
[ 150/2000] tot_loss=2.399 (perp=10.220, rec=0.153, cos=0.202), tot_loss_proj:3.935 [t=0.22s]
prediction: ['[CLS] it ; off umpire umpire called [SEP]']
[ 200/2000] tot_loss=2.388 (perp=10.220, rec=0.144, cos=0.200), tot_loss_proj:3.933 [t=0.22s]
prediction: ['[CLS] it ; off umpire umpire called [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.005 (perp=7.920, rec=0.222, cos=0.199), tot_loss_proj:3.527 [t=0.22s]
prediction: ['[CLS] it the off umpire, called [SEP]']
[ 300/2000] tot_loss=2.031 (perp=8.387, rec=0.158, cos=0.196), tot_loss_proj:3.562 [t=0.22s]
prediction: ['[CLS] itometer of umpire, called [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.180 (perp=9.198, rec=0.142, cos=0.199), tot_loss_proj:3.785 [t=0.22s]
prediction: ['[CLS] it the of umpire, called [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.358 (perp=9.646, rec=0.218, cos=0.211), tot_loss_proj:3.861 [t=0.22s]
prediction: ['[CLS] it advisory the umpire. called [SEP]']
[ 450/2000] tot_loss=2.055 (perp=8.489, rec=0.158, cos=0.199), tot_loss_proj:3.600 [t=0.22s]
prediction: ['[CLS] it line the umpire. called [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.074 (perp=8.582, rec=0.161, cos=0.197), tot_loss_proj:3.676 [t=0.22s]
prediction: ['[CLS] it advisory called the umpire. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.591 (perp=6.158, rec=0.157, cos=0.202), tot_loss_proj:2.958 [t=0.22s]
prediction: ['[CLS] it called the umpire off. [SEP]']
[ 600/2000] tot_loss=1.588 (perp=6.158, rec=0.155, cos=0.201), tot_loss_proj:2.952 [t=0.22s]
prediction: ['[CLS] it called the umpire off. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.550 (perp=6.080, rec=0.137, cos=0.197), tot_loss_proj:3.131 [t=0.22s]
prediction: ['[CLS] it called off the umpire. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.553 (perp=6.080, rec=0.139, cos=0.198), tot_loss_proj:3.130 [t=0.22s]
prediction: ['[CLS] it called off the umpire. [SEP]']
[ 750/2000] tot_loss=1.542 (perp=6.080, rec=0.127, cos=0.200), tot_loss_proj:3.129 [t=0.22s]
prediction: ['[CLS] it called off the umpire. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.544 (perp=6.080, rec=0.127, cos=0.201), tot_loss_proj:3.125 [t=0.22s]
prediction: ['[CLS] it called off the umpire. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.539 (perp=6.080, rec=0.122, cos=0.202), tot_loss_proj:3.128 [t=0.22s]
prediction: ['[CLS] it called off the umpire. [SEP]']
[ 900/2000] tot_loss=1.819 (perp=7.500, rec=0.114, cos=0.204), tot_loss_proj:3.373 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.824 (perp=7.500, rec=0.121, cos=0.204), tot_loss_proj:3.372 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1000/2000] tot_loss=1.813 (perp=7.500, rec=0.108, cos=0.204), tot_loss_proj:3.371 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
[1050/2000] tot_loss=1.809 (perp=7.500, rec=0.104, cos=0.205), tot_loss_proj:3.369 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1100/2000] tot_loss=1.805 (perp=7.500, rec=0.099, cos=0.206), tot_loss_proj:3.374 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1150/2000] tot_loss=1.812 (perp=7.500, rec=0.106, cos=0.206), tot_loss_proj:3.377 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
[1200/2000] tot_loss=1.811 (perp=7.500, rec=0.104, cos=0.207), tot_loss_proj:3.373 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1250/2000] tot_loss=1.811 (perp=7.500, rec=0.103, cos=0.207), tot_loss_proj:3.368 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1300/2000] tot_loss=1.801 (perp=7.500, rec=0.094, cos=0.207), tot_loss_proj:3.371 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
[1350/2000] tot_loss=1.807 (perp=7.500, rec=0.099, cos=0.207), tot_loss_proj:3.371 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1400/2000] tot_loss=1.811 (perp=7.500, rec=0.103, cos=0.208), tot_loss_proj:3.369 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1450/2000] tot_loss=1.801 (perp=7.500, rec=0.093, cos=0.208), tot_loss_proj:3.364 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
[1500/2000] tot_loss=1.810 (perp=7.500, rec=0.102, cos=0.208), tot_loss_proj:3.374 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1550/2000] tot_loss=1.805 (perp=7.500, rec=0.097, cos=0.208), tot_loss_proj:3.374 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1600/2000] tot_loss=1.808 (perp=7.500, rec=0.100, cos=0.208), tot_loss_proj:3.372 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
[1650/2000] tot_loss=1.802 (perp=7.500, rec=0.093, cos=0.208), tot_loss_proj:3.368 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1700/2000] tot_loss=1.808 (perp=7.500, rec=0.099, cos=0.208), tot_loss_proj:3.368 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1750/2000] tot_loss=1.803 (perp=7.500, rec=0.094, cos=0.208), tot_loss_proj:3.367 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
[1800/2000] tot_loss=1.802 (perp=7.500, rec=0.094, cos=0.208), tot_loss_proj:3.371 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1850/2000] tot_loss=1.802 (perp=7.500, rec=0.094, cos=0.209), tot_loss_proj:3.374 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[1900/2000] tot_loss=1.814 (perp=7.500, rec=0.105, cos=0.209), tot_loss_proj:3.373 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
[1950/2000] tot_loss=1.812 (perp=7.500, rec=0.104, cos=0.209), tot_loss_proj:3.371 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Attempt swap
[2000/2000] tot_loss=1.809 (perp=7.500, rec=0.100, cos=0.209), tot_loss_proj:3.371 [t=0.22s]
prediction: ['[CLS] it called off the umpire of [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] the umpire called it of. [SEP]
========================
predicted: 
========================
[CLS] it called off the umpire of [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 30.769 | p: 28.571 | r: 33.333
rougeL     | fm: 66.667 | p: 62.500 | r: 71.429
rougeLsum  | fm: 66.667 | p: 62.500 | r: 71.429
r1fm+r2fm = 124.103

[Aggregate metrics]:
rouge1     | fm: 87.865 | p: 87.248 | r: 88.672
rouge2     | fm: 52.627 | p: 52.065 | r: 53.306
rougeL     | fm: 77.843 | p: 77.277 | r: 78.641
rougeLsum  | fm: 77.869 | p: 77.383 | r: 78.650
r1fm+r2fm = 140.493

input #79 time: 0:08:48 | total time: 12:07:59


Running input #80 of 100.
reference: 
========================
The rock placed the sky with the fork.
========================
average of cosine similarity 0.9008893496692956
highest_index [0]
highest [0.9008893496692956]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2600, 2872, 1996, 3712, 2007, 1996, 9292, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the rock placed the sky with the fork. [SEP]']
[Init] best rec loss: 0.8238515257835388 for ['[CLS] female scared marcus humble ramp bracket hybrid marieeur [SEP]']
[Init] best rec loss: 0.8052192330360413 for ['[CLS] janr afterward city necessary trans him raced fis [SEP]']
[Init] best rec loss: 0.8040657043457031 for ['[CLS] kind plan loft [MASK]?elin unincorporated beard points [SEP]']
[Init] best rec loss: 0.7828662991523743 for ['[CLS] marchade bowie despite april example un de cassie [SEP]']
[Init] best rec loss: 0.7600300312042236 for ['[CLS] every actions climbingnotressed bun via [SEP] louder [SEP]']
[Init] best rec loss: 0.7429399490356445 for ['[CLS] duane av lungs forty currently bird. charge actors [SEP]']
[Init] best rec loss: 0.7374320030212402 for ['[CLS] river lord greta moved strange mall remainingbaldi powerful [SEP]']
[Init] best perm rec loss: 0.7350071668624878 for ['[CLS] strangebaldi moved greta remaining lord river powerful mall [SEP]']
[Init] best perm rec loss: 0.7345123887062073 for ['[CLS]baldi strange moved river powerful mall lord greta remaining [SEP]']
[Init] best perm rec loss: 0.733394205570221 for ['[CLS] river strange moved mall greta lordbaldi remaining powerful [SEP]']
[Init] best perm rec loss: 0.7320395708084106 for ['[CLS] river lord greta powerful movedbaldi mall remaining strange [SEP]']
[Init] best perm rec loss: 0.7309255599975586 for ['[CLS] river strange powerful greta lordbaldi moved remaining mall [SEP]']
[Init] best perm rec loss: 0.7260721921920776 for ['[CLS] river powerful lord remaining strange movedbaldi mall greta [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.106 (perp=12.961, rec=0.314, cos=0.200), tot_loss_proj:3.754 [t=0.23s]
prediction: ['[CLS]. xvi placed fork placed placed hers pin december [SEP]']
[ 100/2000] tot_loss=2.479 (perp=10.355, rec=0.213, cos=0.195), tot_loss_proj:3.565 [t=0.23s]
prediction: ['[CLS]. rock the fork placed placed sky the sky [SEP]']
[ 150/2000] tot_loss=2.415 (perp=10.355, rec=0.154, cos=0.190), tot_loss_proj:3.541 [t=0.23s]
prediction: ['[CLS]. rock the fork placed placed sky the sky [SEP]']
[ 200/2000] tot_loss=1.870 (perp=7.700, rec=0.128, cos=0.202), tot_loss_proj:3.073 [t=0.23s]
prediction: ['[CLS] the rock the fork placed placed with the sky [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.752 (perp=7.176, rec=0.114, cos=0.202), tot_loss_proj:2.199 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with the sky [SEP]']
[ 300/2000] tot_loss=1.737 (perp=7.176, rec=0.099, cos=0.203), tot_loss_proj:2.201 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with the sky [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.725 (perp=7.176, rec=0.098, cos=0.192), tot_loss_proj:2.178 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with the sky [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.703 (perp=7.176, rec=0.077, cos=0.190), tot_loss_proj:2.188 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with the sky [SEP]']
[ 450/2000] tot_loss=1.906 (perp=8.154, rec=0.088, cos=0.187), tot_loss_proj:2.341 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with. sky [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.757 (perp=7.386, rec=0.090, cos=0.189), tot_loss_proj:2.167 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with sky. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.767 (perp=7.386, rec=0.096, cos=0.194), tot_loss_proj:2.155 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with sky. [SEP]']
[ 600/2000] tot_loss=1.761 (perp=7.386, rec=0.091, cos=0.192), tot_loss_proj:2.168 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with sky. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.760 (perp=7.386, rec=0.092, cos=0.190), tot_loss_proj:2.155 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with sky. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.747 (perp=7.386, rec=0.082, cos=0.188), tot_loss_proj:2.167 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with sky. [SEP]']
[ 750/2000] tot_loss=1.751 (perp=7.386, rec=0.084, cos=0.189), tot_loss_proj:2.158 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with sky. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.745 (perp=7.386, rec=0.079, cos=0.188), tot_loss_proj:2.158 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with sky. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.746 (perp=7.386, rec=0.082, cos=0.187), tot_loss_proj:2.157 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with sky. [SEP]']
[ 900/2000] tot_loss=1.749 (perp=7.386, rec=0.083, cos=0.188), tot_loss_proj:2.164 [t=0.23s]
prediction: ['[CLS] the rock placed the fork placed with sky. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.072 (perp=8.995, rec=0.084, cos=0.189), tot_loss_proj:2.663 [t=0.23s]
prediction: ['[CLS] the rock importantly the fork placed with sky. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.946 (perp=7.508, rec=0.229, cos=0.215), tot_loss_proj:2.191 [t=0.23s]
prediction: ['[CLS] the rock placed the fork upside with sky. [SEP]']
[1050/2000] tot_loss=1.851 (perp=7.508, rec=0.143, cos=0.206), tot_loss_proj:2.183 [t=0.23s]
prediction: ['[CLS] the rock placed the fork upside with sky. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.824 (perp=7.508, rec=0.124, cos=0.198), tot_loss_proj:2.178 [t=0.23s]
prediction: ['[CLS] the rock placed the fork upside with sky. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.815 (perp=7.508, rec=0.120, cos=0.194), tot_loss_proj:2.164 [t=0.23s]
prediction: ['[CLS] the rock placed the fork upside with sky. [SEP]']
[1200/2000] tot_loss=1.803 (perp=7.508, rec=0.110, cos=0.191), tot_loss_proj:2.149 [t=0.23s]
prediction: ['[CLS] the rock placed the fork upside with sky. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.769 (perp=7.403, rec=0.099, cos=0.189), tot_loss_proj:2.066 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.750 (perp=7.403, rec=0.081, cos=0.188), tot_loss_proj:2.059 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
[1350/2000] tot_loss=1.768 (perp=7.403, rec=0.099, cos=0.188), tot_loss_proj:2.068 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.778 (perp=7.403, rec=0.108, cos=0.189), tot_loss_proj:2.057 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.749 (perp=7.403, rec=0.080, cos=0.188), tot_loss_proj:2.062 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
[1500/2000] tot_loss=1.771 (perp=7.403, rec=0.102, cos=0.189), tot_loss_proj:2.061 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.760 (perp=7.403, rec=0.090, cos=0.189), tot_loss_proj:2.062 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.768 (perp=7.403, rec=0.099, cos=0.188), tot_loss_proj:2.067 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
[1650/2000] tot_loss=1.759 (perp=7.403, rec=0.090, cos=0.188), tot_loss_proj:2.070 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.749 (perp=7.403, rec=0.080, cos=0.188), tot_loss_proj:2.058 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.755 (perp=7.403, rec=0.085, cos=0.189), tot_loss_proj:2.057 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
[1800/2000] tot_loss=1.755 (perp=7.403, rec=0.086, cos=0.188), tot_loss_proj:2.062 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.754 (perp=7.403, rec=0.085, cos=0.188), tot_loss_proj:2.065 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.746 (perp=7.403, rec=0.076, cos=0.189), tot_loss_proj:2.053 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
[1950/2000] tot_loss=1.758 (perp=7.403, rec=0.089, cos=0.189), tot_loss_proj:2.065 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.762 (perp=7.403, rec=0.093, cos=0.189), tot_loss_proj:2.056 [t=0.23s]
prediction: ['[CLS] the rock placed the forkcased with sky. [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] the rock placed the sky with the fork. [SEP]
========================
predicted: 
========================
[CLS] the rock placed the fork placed with sky. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 55.556 | p: 55.556 | r: 55.556
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 145.556

[Aggregate metrics]:
rouge1     | fm: 87.882 | p: 87.282 | r: 88.682
rouge2     | fm: 52.713 | p: 52.264 | r: 53.388
rougeL     | fm: 77.783 | p: 77.256 | r: 78.489
rougeLsum  | fm: 77.791 | p: 77.229 | r: 78.491
r1fm+r2fm = 140.595

input #80 time: 0:09:10 | total time: 12:17:10


Running input #81 of 100.
reference: 
========================
Tagalog is speaks in the Philippines.
========================
average of cosine similarity 0.9114134559959309
highest_index [0]
highest [0.9114134559959309]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  6415, 23067,  2290,  2003,  8847,  1999,  1996,  5137,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] tagalog is speaks in the philippines. [SEP]']
[Init] best rec loss: 0.696931004524231 for ['[CLS]lch scotland uhf qualifying claude worse attempt faye costs [SEP]']
[Init] best rec loss: 0.665212869644165 for ['[CLS]ei understand turn infrastructure galley project tracks annual [SEP]']
[Init] best rec loss: 0.6580904126167297 for ['[CLS] incorporating wine even lab come dismiss kahn pictured under [SEP]']
[Init] best rec loss: 0.6519626379013062 for ['[CLS] opened grtain ft slow lattice season brake miriam [SEP]']
[Init] best rec loss: 0.6507506966590881 for ['[CLS] here secession science jenks level lettingcas neither couples [SEP]']
[Init] best rec loss: 0.6473777890205383 for ['[CLS] evenscript sevens met conflict page foot when just [SEP]']
[Init] best rec loss: 0.6311100721359253 for ['[CLS] has kowalski part case jericho money though stuck holy [SEP]']
[Init] best rec loss: 0.622769296169281 for ['[CLS]mba biggerusdock be named kill hit standards [SEP]']
[Init] best perm rec loss: 0.6224521398544312 for ['[CLS] standardsdock bigger hit be namedusmba kill [SEP]']
[Init] best perm rec loss: 0.6220080256462097 for ['[CLS] bedock standardsus kill hit namedmba bigger [SEP]']
[Init] best perm rec loss: 0.6213648319244385 for ['[CLS] hit named be biggerusmbadock kill standards [SEP]']
[Init] best perm rec loss: 0.6213537454605103 for ['[CLS]dock standardsus kill named hitmba be bigger [SEP]']
[Init] best perm rec loss: 0.6204698085784912 for ['[CLS]dockus hit kill named standards bemba bigger [SEP]']
[Init] best perm rec loss: 0.6195427775382996 for ['[CLS]mbadockus bigger hit standards kill named be [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.567 (perp=10.804, rec=0.238, cos=0.168), tot_loss_proj:3.080 [t=0.23s]
prediction: ['[CLS] filipino is is speaks speaks use card. in [SEP]']
[ 100/2000] tot_loss=2.252 (perp=9.773, rec=0.136, cos=0.161), tot_loss_proj:2.846 [t=0.23s]
prediction: ['[CLS] tag is is speaks speaks catch in philippines. [SEP]']
[ 150/2000] tot_loss=2.173 (perp=9.508, rec=0.107, cos=0.164), tot_loss_proj:2.687 [t=0.23s]
prediction: ['[CLS] tag is isg speaks catch in philippines. [SEP]']
[ 200/2000] tot_loss=2.041 (perp=8.935, rec=0.087, cos=0.167), tot_loss_proj:2.585 [t=0.23s]
prediction: ['[CLS] tag is isg speaks track in philippines. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.847 (perp=7.932, rec=0.098, cos=0.162), tot_loss_proj:2.495 [t=0.23s]
prediction: ['[CLS] speaks is tagg speaks track in philippines. [SEP]']
[ 300/2000] tot_loss=1.836 (perp=7.932, rec=0.081, cos=0.169), tot_loss_proj:2.490 [t=0.23s]
prediction: ['[CLS] speaks is tagg speaks track in philippines. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.069 (perp=9.145, rec=0.071, cos=0.169), tot_loss_proj:2.523 [t=0.23s]
prediction: ['[CLS] speaksalog is speaks tag in philippines. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.523 (perp=6.317, rec=0.097, cos=0.163), tot_loss_proj:1.950 [t=0.23s]
prediction: ['[CLS] speaks tagalog is speaks in philippines. [SEP]']
[ 450/2000] tot_loss=1.514 (perp=6.317, rec=0.081, cos=0.169), tot_loss_proj:1.939 [t=0.23s]
prediction: ['[CLS] speaks tagalog is speaks in philippines. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.511 (perp=6.317, rec=0.079, cos=0.169), tot_loss_proj:1.937 [t=0.23s]
prediction: ['[CLS] speaks tagalog is speaks in philippines. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.519 (perp=6.317, rec=0.087, cos=0.169), tot_loss_proj:1.931 [t=0.23s]
prediction: ['[CLS] speaks tagalog is speaks in philippines. [SEP]']
[ 600/2000] tot_loss=1.503 (perp=6.317, rec=0.071, cos=0.169), tot_loss_proj:1.927 [t=0.23s]
prediction: ['[CLS] speaks tagalog is speaks in philippines. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.584 (perp=6.678, rec=0.079, cos=0.169), tot_loss_proj:1.911 [t=0.23s]
prediction: ['[CLS] es tagalog is speaks in philippines. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.578 (perp=6.678, rec=0.073, cos=0.169), tot_loss_proj:1.922 [t=0.23s]
prediction: ['[CLS] es tagalog is speaks in philippines. [SEP]']
[ 750/2000] tot_loss=1.571 (perp=6.678, rec=0.067, cos=0.169), tot_loss_proj:1.923 [t=0.23s]
prediction: ['[CLS] es tagalog is speaks in philippines. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.580 (perp=6.678, rec=0.076, cos=0.169), tot_loss_proj:1.919 [t=0.23s]
prediction: ['[CLS] es tagalog is speaks in philippines. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.575 (perp=6.678, rec=0.070, cos=0.169), tot_loss_proj:1.916 [t=0.23s]
prediction: ['[CLS] es tagalog is speaks in philippines. [SEP]']
[ 900/2000] tot_loss=1.606 (perp=6.824, rec=0.072, cos=0.169), tot_loss_proj:1.910 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.602 (perp=6.824, rec=0.068, cos=0.169), tot_loss_proj:1.911 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.594 (perp=6.824, rec=0.060, cos=0.169), tot_loss_proj:1.915 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
[1050/2000] tot_loss=1.602 (perp=6.824, rec=0.068, cos=0.169), tot_loss_proj:1.908 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.600 (perp=6.824, rec=0.066, cos=0.169), tot_loss_proj:1.910 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.598 (perp=6.824, rec=0.064, cos=0.169), tot_loss_proj:1.899 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
[1200/2000] tot_loss=1.608 (perp=6.824, rec=0.074, cos=0.169), tot_loss_proj:1.899 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.598 (perp=6.824, rec=0.064, cos=0.169), tot_loss_proj:1.916 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.600 (perp=6.824, rec=0.066, cos=0.169), tot_loss_proj:1.903 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
[1350/2000] tot_loss=1.601 (perp=6.824, rec=0.067, cos=0.169), tot_loss_proj:1.912 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.602 (perp=6.824, rec=0.068, cos=0.169), tot_loss_proj:1.905 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.608 (perp=6.824, rec=0.074, cos=0.169), tot_loss_proj:1.904 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
[1500/2000] tot_loss=1.607 (perp=6.824, rec=0.073, cos=0.169), tot_loss_proj:1.914 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.600 (perp=6.824, rec=0.066, cos=0.169), tot_loss_proj:1.903 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.609 (perp=6.824, rec=0.075, cos=0.169), tot_loss_proj:1.912 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
[1650/2000] tot_loss=1.594 (perp=6.824, rec=0.060, cos=0.169), tot_loss_proj:1.905 [t=0.23s]
prediction: ['[CLS]h tagalog is speaks in philippines. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.603 (perp=6.819, rec=0.070, cos=0.169), tot_loss_proj:1.840 [t=0.23s]
prediction: ['[CLS] tagalogh is speaks in philippines. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.595 (perp=6.819, rec=0.062, cos=0.169), tot_loss_proj:1.843 [t=0.23s]
prediction: ['[CLS] tagalogh is speaks in philippines. [SEP]']
[1800/2000] tot_loss=1.596 (perp=6.819, rec=0.063, cos=0.169), tot_loss_proj:1.847 [t=0.23s]
prediction: ['[CLS] tagalogh is speaks in philippines. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.618 (perp=6.819, rec=0.085, cos=0.169), tot_loss_proj:1.833 [t=0.23s]
prediction: ['[CLS] tagalogh is speaks in philippines. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.597 (perp=6.819, rec=0.064, cos=0.169), tot_loss_proj:1.840 [t=0.23s]
prediction: ['[CLS] tagalogh is speaks in philippines. [SEP]']
[1950/2000] tot_loss=1.600 (perp=6.819, rec=0.066, cos=0.169), tot_loss_proj:1.844 [t=0.23s]
prediction: ['[CLS] tagalogh is speaks in philippines. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.599 (perp=6.819, rec=0.066, cos=0.169), tot_loss_proj:1.838 [t=0.23s]
prediction: ['[CLS] tagalogh is speaks in philippines. [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] tagalog is speaks in the philippines. [SEP]
========================
predicted: 
========================
[CLS] tagalogh is speaks in philippines. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 85.714 | r: 75.000
rouge2     | fm: 46.154 | p: 50.000 | r: 42.857
rougeL     | fm: 80.000 | p: 85.714 | r: 75.000
rougeLsum  | fm: 80.000 | p: 85.714 | r: 75.000
r1fm+r2fm = 126.154

[Aggregate metrics]:
rouge1     | fm: 87.744 | p: 87.264 | r: 88.465
rouge2     | fm: 52.538 | p: 52.072 | r: 53.212
rougeL     | fm: 77.729 | p: 77.306 | r: 78.341
rougeLsum  | fm: 77.846 | p: 77.376 | r: 78.505
r1fm+r2fm = 140.282

input #81 time: 0:09:10 | total time: 12:26:21


Running input #82 of 100.
reference: 
========================
He waltzed her across the floor.
========================
average of cosine similarity 0.9089003746473949
highest_index [0]
highest [0.9089003746473949]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2002, 17569,  2098,  2014,  2408,  1996,  2723,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] he waltzed her across the floor. [SEP]']
[Init] best rec loss: 0.925133466720581 for ['[CLS] beverly womenboat [MASK] greatly waterfold bears [SEP]']
[Init] best rec loss: 0.8816373944282532 for ['[CLS] because star usc but ginger boltontial nat [SEP]']
[Init] best rec loss: 0.8790302276611328 for ['[CLS] bottom especially fed wake ingpy existencerted [SEP]']
[Init] best rec loss: 0.8611305952072144 for ['[CLS] enoch millerble adjective stoolestinal teddyworthy [SEP]']
[Init] best rec loss: 0.8607725501060486 for ['[CLS] she prime someone count pat lens lead quit [SEP]']
[Init] best perm rec loss: 0.8573322892189026 for ['[CLS] quit count lead someone prime lens she pat [SEP]']
[Init] best perm rec loss: 0.8572074174880981 for ['[CLS] someone count lead lens prime pat she quit [SEP]']
[Init] best perm rec loss: 0.8569599986076355 for ['[CLS] count pat someone prime quit lead lens she [SEP]']
[Init] best perm rec loss: 0.8568897247314453 for ['[CLS] someone count pat lens prime quit she lead [SEP]']
[Init] best perm rec loss: 0.8555935621261597 for ['[CLS] someone lead count prime she pat quit lens [SEP]']
[Init] best perm rec loss: 0.854705810546875 for ['[CLS] count lens lead she pat someone quit prime [SEP]']
[Init] best perm rec loss: 0.8546108603477478 for ['[CLS] count lead prime pat lens quit someone she [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.882 (perp=11.023, rec=0.480, cos=0.197), tot_loss_proj:4.019 [t=0.23s]
prediction: ['[CLS] blue. walked waltz across her its kiss [SEP]']
[ 100/2000] tot_loss=2.203 (perp=9.101, rec=0.212, cos=0.171), tot_loss_proj:3.646 [t=0.23s]
prediction: ['[CLS] he down waltz waltz across her floor. [SEP]']
[ 150/2000] tot_loss=1.923 (perp=8.002, rec=0.149, cos=0.174), tot_loss_proj:3.454 [t=0.23s]
prediction: ['[CLS] he ; waltz waltz across her floor. [SEP]']
[ 200/2000] tot_loss=1.969 (perp=8.399, rec=0.124, cos=0.165), tot_loss_proj:3.521 [t=0.23s]
prediction: ['[CLS] he across waltz waltz across her floor. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.715 (perp=7.125, rec=0.121, cos=0.169), tot_loss_proj:3.313 [t=0.23s]
prediction: ['[CLS] he across waltzed across her floor. [SEP]']
[ 300/2000] tot_loss=1.712 (perp=7.125, rec=0.118, cos=0.168), tot_loss_proj:3.313 [t=0.23s]
prediction: ['[CLS] he across waltzed across her floor. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.705 (perp=7.125, rec=0.110, cos=0.170), tot_loss_proj:3.309 [t=0.23s]
prediction: ['[CLS] he across waltzed across her floor. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.704 (perp=7.125, rec=0.113, cos=0.166), tot_loss_proj:3.308 [t=0.23s]
prediction: ['[CLS] he across waltzed across her floor. [SEP]']
[ 450/2000] tot_loss=1.576 (perp=6.519, rec=0.107, cos=0.166), tot_loss_proj:3.157 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.576 (perp=6.519, rec=0.100, cos=0.172), tot_loss_proj:3.156 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.576 (perp=6.519, rec=0.110, cos=0.162), tot_loss_proj:3.152 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
[ 600/2000] tot_loss=1.562 (perp=6.519, rec=0.088, cos=0.170), tot_loss_proj:3.158 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.563 (perp=6.519, rec=0.088, cos=0.171), tot_loss_proj:3.157 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.558 (perp=6.519, rec=0.090, cos=0.165), tot_loss_proj:3.157 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
[ 750/2000] tot_loss=1.568 (perp=6.519, rec=0.092, cos=0.172), tot_loss_proj:3.159 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.565 (perp=6.519, rec=0.089, cos=0.173), tot_loss_proj:3.158 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.564 (perp=6.519, rec=0.086, cos=0.173), tot_loss_proj:3.157 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
[ 900/2000] tot_loss=1.567 (perp=6.519, rec=0.091, cos=0.171), tot_loss_proj:3.162 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.566 (perp=6.519, rec=0.090, cos=0.172), tot_loss_proj:3.163 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.681 (perp=7.125, rec=0.082, cos=0.174), tot_loss_proj:3.307 [t=0.23s]
prediction: ['[CLS] he across waltzed across her floor. [SEP]']
[1050/2000] tot_loss=1.681 (perp=7.125, rec=0.084, cos=0.172), tot_loss_proj:3.307 [t=0.23s]
prediction: ['[CLS] he across waltzed across her floor. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.627 (perp=6.860, rec=0.081, cos=0.174), tot_loss_proj:3.195 [t=0.23s]
prediction: ['[CLS] he waltzed acrossed her floor. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.568 (perp=6.519, rec=0.094, cos=0.171), tot_loss_proj:3.161 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
[1200/2000] tot_loss=1.562 (perp=6.519, rec=0.085, cos=0.173), tot_loss_proj:3.163 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.567 (perp=6.519, rec=0.089, cos=0.174), tot_loss_proj:3.162 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.564 (perp=6.519, rec=0.087, cos=0.174), tot_loss_proj:3.162 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
[1350/2000] tot_loss=1.570 (perp=6.519, rec=0.093, cos=0.174), tot_loss_proj:3.162 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.563 (perp=6.519, rec=0.085, cos=0.174), tot_loss_proj:3.162 [t=0.23s]
prediction: ['[CLS] heed waltzed across her floor. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.596 (perp=6.715, rec=0.082, cos=0.171), tot_loss_proj:3.174 [t=0.23s]
prediction: ['[CLS] he waltzed across her floor across. [SEP]']
[1500/2000] tot_loss=1.604 (perp=6.715, rec=0.089, cos=0.172), tot_loss_proj:3.169 [t=0.23s]
prediction: ['[CLS] he waltzed across her floor across. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.508 (perp=6.244, rec=0.103, cos=0.156), tot_loss_proj:2.449 [t=0.23s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.486 (perp=6.244, rec=0.084, cos=0.153), tot_loss_proj:2.451 [t=0.23s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
[1650/2000] tot_loss=1.490 (perp=6.244, rec=0.086, cos=0.155), tot_loss_proj:2.456 [t=0.23s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.497 (perp=6.244, rec=0.092, cos=0.156), tot_loss_proj:2.454 [t=0.23s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.490 (perp=6.244, rec=0.085, cos=0.157), tot_loss_proj:2.448 [t=0.23s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
[1800/2000] tot_loss=1.482 (perp=6.244, rec=0.077, cos=0.157), tot_loss_proj:2.456 [t=0.23s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.504 (perp=6.244, rec=0.098, cos=0.157), tot_loss_proj:2.460 [t=0.23s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.494 (perp=6.244, rec=0.084, cos=0.162), tot_loss_proj:2.496 [t=0.23s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
[1950/2000] tot_loss=1.502 (perp=6.244, rec=0.093, cos=0.160), tot_loss_proj:2.491 [t=0.23s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.499 (perp=6.244, rec=0.091, cos=0.159), tot_loss_proj:2.494 [t=0.23s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] he waltzed her across the floor. [SEP]
========================
predicted: 
========================
[CLS] he waltzed across across her floor. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 130.357

[Aggregate metrics]:
rouge1     | fm: 87.725 | p: 87.207 | r: 88.472
rouge2     | fm: 52.472 | p: 51.956 | r: 53.084
rougeL     | fm: 77.809 | p: 77.305 | r: 78.390
rougeLsum  | fm: 77.797 | p: 77.350 | r: 78.449
r1fm+r2fm = 140.197

input #82 time: 0:09:10 | total time: 12:35:31


Running input #83 of 100.
reference: 
========================
How easy to please John is it?
========================
average of cosine similarity 0.8884789687115544
highest_index [0]
highest [0.8884789687115544]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2129, 3733, 2000, 3531, 2198, 2003, 2009, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] how easy to please john is it? [SEP]']
[Init] best rec loss: 0.799432635307312 for ['[CLS] blacksmith straight heart comprises works right wa would [SEP]']
[Init] best rec loss: 0.7583375573158264 for ['[CLS] god bay hungarianaround dad pony medal i [SEP]']
[Init] best rec loss: 0.7501692175865173 for ['[CLS] trevorntsgni midway coup eye denied disputed [SEP]']
[Init] best rec loss: 0.7418016791343689 for ['[CLS] time fixedcala writer stryker prepared thing philip [SEP]']
[Init] best rec loss: 0.7401094436645508 for ['[CLS] lead addressed cruz irish nice motion | father [SEP]']
[Init] best rec loss: 0.7235898375511169 for ['[CLS] motor pacificeni confined near abby holding curled [SEP]']
[Init] best rec loss: 0.7195344567298889 for ['[CLS] buddy city piccoloweed ledger bulb print second [SEP]']
[Init] best rec loss: 0.710949718952179 for ['[CLS] tonight stupid covering to scores up storm fake [SEP]']
[Init] best rec loss: 0.7063584923744202 for ['[CLS] reopened snow copy place putoint settlement clearing [SEP]']
[Init] best perm rec loss: 0.7055135369300842 for ['[CLS] snow place copy reopenedoint clearing settlement put [SEP]']
[Init] best perm rec loss: 0.7052357196807861 for ['[CLS] reopened clearingoint place settlement snow copy put [SEP]']
[Init] best perm rec loss: 0.7051831483840942 for ['[CLS] put copy reopened placeoint settlement clearing snow [SEP]']
[Init] best perm rec loss: 0.7039812207221985 for ['[CLS] reopened place snow copyoint put settlement clearing [SEP]']
[Init] best perm rec loss: 0.7014362215995789 for ['[CLS] reopened copy snow place put settlementoint clearing [SEP]']
[Init] best perm rec loss: 0.6999480128288269 for ['[CLS] clearing snow place reopened settlement putoint copy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.855 (perp=11.291, rec=0.406, cos=0.191), tot_loss_proj:3.472 [t=0.22s]
prediction: ['[CLS] please fame operation has john anyway > hurry [SEP]']
[ 100/2000] tot_loss=2.156 (perp=8.168, rec=0.318, cos=0.205), tot_loss_proj:2.532 [t=0.22s]
prediction: ['[CLS] how easy john has john anyway please be [SEP]']
[ 150/2000] tot_loss=1.944 (perp=7.286, rec=0.298, cos=0.189), tot_loss_proj:2.634 [t=0.22s]
prediction: ['[CLS] how easy to please john is please be [SEP]']
[ 200/2000] tot_loss=1.860 (perp=7.134, rec=0.231, cos=0.202), tot_loss_proj:2.282 [t=0.22s]
prediction: ['[CLS] how easy to please john is please please [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.948 (perp=7.683, rec=0.205, cos=0.207), tot_loss_proj:2.887 [t=0.22s]
prediction: ['[CLS] how easy it please john is please please [SEP]']
[ 300/2000] tot_loss=1.720 (perp=6.847, rec=0.141, cos=0.209), tot_loss_proj:2.824 [t=0.22s]
prediction: ['[CLS] how easy it please john is please? [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.594 (perp=6.447, rec=0.101, cos=0.204), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] how easy please please john is it? [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.423 (perp=5.693, rec=0.076, cos=0.209), tot_loss_proj:1.477 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[ 450/2000] tot_loss=1.430 (perp=5.693, rec=0.082, cos=0.209), tot_loss_proj:1.475 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.426 (perp=5.693, rec=0.078, cos=0.210), tot_loss_proj:1.467 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.412 (perp=5.693, rec=0.063, cos=0.210), tot_loss_proj:1.470 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[ 600/2000] tot_loss=1.418 (perp=5.693, rec=0.069, cos=0.210), tot_loss_proj:1.479 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.410 (perp=5.693, rec=0.061, cos=0.210), tot_loss_proj:1.481 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.425 (perp=5.693, rec=0.077, cos=0.210), tot_loss_proj:1.477 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[ 750/2000] tot_loss=1.410 (perp=5.693, rec=0.061, cos=0.210), tot_loss_proj:1.478 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.420 (perp=5.693, rec=0.071, cos=0.210), tot_loss_proj:1.473 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.410 (perp=5.693, rec=0.062, cos=0.210), tot_loss_proj:1.472 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[ 900/2000] tot_loss=1.422 (perp=5.693, rec=0.074, cos=0.210), tot_loss_proj:1.474 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.419 (perp=5.693, rec=0.070, cos=0.210), tot_loss_proj:1.482 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.421 (perp=5.693, rec=0.072, cos=0.210), tot_loss_proj:1.480 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1050/2000] tot_loss=1.412 (perp=5.693, rec=0.063, cos=0.210), tot_loss_proj:1.472 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.419 (perp=5.693, rec=0.070, cos=0.210), tot_loss_proj:1.471 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.412 (perp=5.693, rec=0.063, cos=0.210), tot_loss_proj:1.486 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1200/2000] tot_loss=1.411 (perp=5.693, rec=0.062, cos=0.210), tot_loss_proj:1.468 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.411 (perp=5.693, rec=0.063, cos=0.210), tot_loss_proj:1.473 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.414 (perp=5.693, rec=0.065, cos=0.210), tot_loss_proj:1.477 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1350/2000] tot_loss=1.412 (perp=5.693, rec=0.063, cos=0.210), tot_loss_proj:1.486 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.410 (perp=5.693, rec=0.061, cos=0.210), tot_loss_proj:1.469 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.410 (perp=5.693, rec=0.061, cos=0.210), tot_loss_proj:1.479 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1500/2000] tot_loss=1.416 (perp=5.693, rec=0.067, cos=0.210), tot_loss_proj:1.468 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.403 (perp=5.693, rec=0.054, cos=0.210), tot_loss_proj:1.477 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.413 (perp=5.693, rec=0.064, cos=0.210), tot_loss_proj:1.481 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1650/2000] tot_loss=1.407 (perp=5.693, rec=0.057, cos=0.210), tot_loss_proj:1.466 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.413 (perp=5.693, rec=0.064, cos=0.210), tot_loss_proj:1.472 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.405 (perp=5.693, rec=0.056, cos=0.210), tot_loss_proj:1.476 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1800/2000] tot_loss=1.420 (perp=5.693, rec=0.071, cos=0.210), tot_loss_proj:1.476 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.409 (perp=5.693, rec=0.060, cos=0.210), tot_loss_proj:1.467 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.406 (perp=5.693, rec=0.057, cos=0.210), tot_loss_proj:1.474 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1950/2000] tot_loss=1.409 (perp=5.693, rec=0.059, cos=0.210), tot_loss_proj:1.479 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.408 (perp=5.693, rec=0.059, cos=0.210), tot_loss_proj:1.488 [t=0.22s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] how easy to please john is it? [SEP]
========================
predicted: 
========================
[CLS] how easy to please john is it? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.984 | p: 87.475 | r: 88.641
rouge2     | fm: 53.181 | p: 52.730 | r: 53.803
rougeL     | fm: 77.988 | p: 77.536 | r: 78.639
rougeLsum  | fm: 78.128 | p: 77.657 | r: 78.780
r1fm+r2fm = 141.166

input #83 time: 0:08:52 | total time: 12:44:24


Running input #84 of 100.
reference: 
========================
That the king or queen be present is a requirement on all Royal weddings.
========================
average of cosine similarity 0.8610383251361403
highest_index [0]
highest [0.8610383251361403]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2008,  1996,  2332,  2030,  3035,  2022,  2556,  2003,  1037,
          9095,  2006,  2035,  2548, 20429,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]']
[Init] best rec loss: 0.9653642177581787 for ['[CLS] y during udnsorlot shed art closed described power na seriously guild le grinding [SEP]']
[Init] best rec loss: 0.955552875995636 for ['[CLS]る spa brought wondered myrim midnight nationality flushed keys architect ground roman rally populations [SEP]']
[Init] best rec loss: 0.942499577999115 for ['[CLS] bertha clinging outside bad tucker catalonia chorus out deck namely? white milleruation opportunities [SEP]']
[Init] best rec loss: 0.9147143363952637 for ['[CLS] calling time action restrictionhui edge still equality municipality part genieint compelledomp remainder [SEP]']
[Init] best rec loss: 0.8983438611030579 for ['[CLS] metro coulddilly sees command vanessacter zane bend deadly his ledger day 95 poetry [SEP]']
[Init] best rec loss: 0.8891681432723999 for ['[CLS] doll murder kilometres palragan inside hockey magic civic slave sol supply os keep clips [SEP]']
[Init] best rec loss: 0.8657442927360535 for ['[CLS] quaker paper dairy nearly yours commons gravity blog garrett allowed photo west such matters beside [SEP]']
[Init] best perm rec loss: 0.8654719591140747 for ['[CLS] quaker garrett matters west such yours gravity paper nearly photo beside blog dairy commons allowed [SEP]']
[Init] best perm rec loss: 0.8632041215896606 for ['[CLS] west yours paper photo garrett quaker dairy commons gravity nearly blog such beside allowed matters [SEP]']
[Init] best perm rec loss: 0.8618478775024414 for ['[CLS] commons allowed west paper gravity blog garrett such dairy yours photo quaker beside nearly matters [SEP]']
[Init] best perm rec loss: 0.8562909364700317 for ['[CLS] quaker gravity paper beside west allowed nearly photo garrett blog commons such dairy yours matters [SEP]']
[Init] best perm rec loss: 0.854288637638092 for ['[CLS] beside yours dairy west allowed paper quaker such gravity matters garrett blog commons photo nearly [SEP]']
[Init] best perm rec loss: 0.851692795753479 for ['[CLS] dairy quaker paper west garrett photo commons such beside nearly allowed matters blog gravity yours [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.392 (perp=9.280, rec=0.287, cos=0.249), tot_loss_proj:3.715 [t=0.23s]
prediction: ['[CLS] participation king. kings is requirement always royal all / king on weekly trinity weddings [SEP]']
[ 100/2000] tot_loss=2.343 (perp=9.605, rec=0.179, cos=0.244), tot_loss_proj:3.782 [t=0.23s]
prediction: ['[CLS] participation king. queen is requirement on royal all or royal extremely royal? weddings [SEP]']
[ 150/2000] tot_loss=2.271 (perp=9.480, rec=0.130, cos=0.244), tot_loss_proj:3.733 [t=0.24s]
prediction: ['[CLS] participation king that queen is requirement on queen all or royal although royal. weddings [SEP]']
[ 200/2000] tot_loss=2.353 (perp=9.980, rec=0.106, cos=0.252), tot_loss_proj:3.847 [t=0.24s]
prediction: ['[CLS] participation king that present is requirement on queen all or royal ( royal. weddings [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.210 (perp=9.279, rec=0.111, cos=0.243), tot_loss_proj:3.725 [t=0.24s]
prediction: ['[CLS] participation king that present is queen requirement on all or royal ( royal. weddings [SEP]']
[ 300/2000] tot_loss=2.344 (perp=9.957, rec=0.099, cos=0.254), tot_loss_proj:3.866 [t=0.24s]
prediction: ['[CLS]fly king that present is queen requirement on all or royal ( royal. weddings [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.202 (perp=9.204, rec=0.117, cos=0.244), tot_loss_proj:3.727 [t=0.24s]
prediction: ['[CLS]making king that queen requirement on all or present is royal, royal ] weddings [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.127 (perp=8.845, rec=0.106, cos=0.252), tot_loss_proj:3.649 [t=0.24s]
prediction: ['[CLS]making king that queen requirement on all present or is royal. royal ] weddings [SEP]']
[ 450/2000] tot_loss=2.095 (perp=8.707, rec=0.101, cos=0.253), tot_loss_proj:3.625 [t=0.24s]
prediction: ['[CLS]roving king that queen requirement on all present or is royal. royal ] weddings [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.062 (perp=8.544, rec=0.095, cos=0.259), tot_loss_proj:3.604 [t=0.24s]
prediction: ['[CLS]roving king that queen requirement on all present or is royal. ] royal weddings [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.046 (perp=8.485, rec=0.093, cos=0.256), tot_loss_proj:3.589 [t=0.24s]
prediction: ['[CLS] ª king that queen requirement on all present or is royal. ] royal weddings [SEP]']
[ 600/2000] tot_loss=2.050 (perp=8.485, rec=0.098, cos=0.255), tot_loss_proj:3.590 [t=0.24s]
prediction: ['[CLS] ª king that queen requirement on all present or is royal. ] royal weddings [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.044 (perp=8.485, rec=0.091, cos=0.256), tot_loss_proj:3.584 [t=0.24s]
prediction: ['[CLS] ª king that queen requirement on all present or is royal. ] royal weddings [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.042 (perp=8.485, rec=0.087, cos=0.258), tot_loss_proj:3.590 [t=0.24s]
prediction: ['[CLS] ª king that queen requirement on all present or is royal. ] royal weddings [SEP]']
[ 750/2000] tot_loss=2.049 (perp=8.485, rec=0.094, cos=0.258), tot_loss_proj:3.588 [t=0.24s]
prediction: ['[CLS] ª king that queen requirement on all present or is royal. ] royal weddings [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.047 (perp=8.485, rec=0.092, cos=0.258), tot_loss_proj:3.583 [t=0.23s]
prediction: ['[CLS] ª king that queen requirement on all present or is royal. ] royal weddings [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.032 (perp=8.474, rec=0.083, cos=0.255), tot_loss_proj:3.551 [t=0.24s]
prediction: ['[CLS] ª that king queen requirement on all present or is royal. ] royal weddings [SEP]']
[ 900/2000] tot_loss=1.873 (perp=7.619, rec=0.091, cos=0.257), tot_loss_proj:3.390 [t=0.23s]
prediction: ['[CLS]. that king queen requirement on all present or is royal. ] royal weddings [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.969 (perp=8.130, rec=0.086, cos=0.257), tot_loss_proj:3.372 [t=0.24s]
prediction: ['[CLS] ª that king or queen requirement on all present is royal. ] royal weddings [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.885 (perp=7.716, rec=0.088, cos=0.254), tot_loss_proj:3.382 [t=0.24s]
prediction: ['[CLS] ª that king or queen requirement on all royal is present. ] royal weddings [SEP]']
[1050/2000] tot_loss=1.709 (perp=6.867, rec=0.079, cos=0.257), tot_loss_proj:3.223 [t=0.24s]
prediction: ['[CLS]. that king or queen requirement on all royal is present. ] royal weddings [SEP]']
Attempt swap
[1100/2000] tot_loss=1.712 (perp=6.867, rec=0.082, cos=0.257), tot_loss_proj:3.222 [t=0.24s]
prediction: ['[CLS]. that king or queen requirement on all royal is present. ] royal weddings [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.691 (perp=6.735, rec=0.086, cos=0.257), tot_loss_proj:3.187 [t=0.24s]
prediction: ['[CLS] that king or queen. requirement on all royal is present. ] royal weddings [SEP]']
[1200/2000] tot_loss=1.694 (perp=6.735, rec=0.089, cos=0.258), tot_loss_proj:3.185 [t=0.24s]
prediction: ['[CLS] that king or queen. requirement on all royal is present. ] royal weddings [SEP]']
Attempt swap
[1250/2000] tot_loss=1.691 (perp=6.735, rec=0.086, cos=0.258), tot_loss_proj:3.186 [t=0.24s]
prediction: ['[CLS] that king or queen. requirement on all royal is present. ] royal weddings [SEP]']
Attempt swap
[1300/2000] tot_loss=1.691 (perp=6.735, rec=0.086, cos=0.258), tot_loss_proj:3.188 [t=0.24s]
prediction: ['[CLS] that king or queen. requirement on all royal is present. ] royal weddings [SEP]']
[1350/2000] tot_loss=1.690 (perp=6.735, rec=0.085, cos=0.259), tot_loss_proj:3.188 [t=0.24s]
prediction: ['[CLS] that king or queen. requirement on all royal is present. ] royal weddings [SEP]']
Attempt swap
[1400/2000] tot_loss=1.676 (perp=6.735, rec=0.072, cos=0.258), tot_loss_proj:3.187 [t=0.24s]
prediction: ['[CLS] that king or queen. requirement on all royal is present. ] royal weddings [SEP]']
Attempt swap
[1450/2000] tot_loss=1.689 (perp=6.735, rec=0.084, cos=0.258), tot_loss_proj:3.185 [t=0.24s]
prediction: ['[CLS] that king or queen. requirement on all royal is present. ] royal weddings [SEP]']
[1500/2000] tot_loss=1.691 (perp=6.735, rec=0.085, cos=0.258), tot_loss_proj:3.183 [t=0.24s]
prediction: ['[CLS] that king or queen. requirement on all royal is present. ] royal weddings [SEP]']
Attempt swap
[1550/2000] tot_loss=1.686 (perp=6.735, rec=0.081, cos=0.258), tot_loss_proj:3.181 [t=0.24s]
prediction: ['[CLS] that king or queen. requirement on all royal is present. ] royal weddings [SEP]']
Attempt swap
[1600/2000] tot_loss=1.689 (perp=6.735, rec=0.085, cos=0.258), tot_loss_proj:3.186 [t=0.24s]
prediction: ['[CLS] that king or queen. requirement on all royal is present. ] royal weddings [SEP]']
[1650/2000] tot_loss=1.687 (perp=6.735, rec=0.082, cos=0.258), tot_loss_proj:3.187 [t=0.24s]
prediction: ['[CLS] that king or queen. requirement on all royal is present. ] royal weddings [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.629 (perp=6.490, rec=0.075, cos=0.256), tot_loss_proj:3.147 [t=0.24s]
prediction: ['[CLS] that king or queen requirement on all royal is present. ] royal weddings. [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.617 (perp=6.384, rec=0.085, cos=0.255), tot_loss_proj:3.126 [t=0.24s]
prediction: ['[CLS] requirement that king or queen on all royal is present. ] royal weddings. [SEP]']
[1800/2000] tot_loss=1.611 (perp=6.384, rec=0.079, cos=0.256), tot_loss_proj:3.126 [t=0.24s]
prediction: ['[CLS] requirement that king or queen on all royal is present. ] royal weddings. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.616 (perp=6.384, rec=0.082, cos=0.256), tot_loss_proj:3.124 [t=0.23s]
prediction: ['[CLS] requirement that king or queen on all royal is present. ] royal weddings. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.611 (perp=6.384, rec=0.077, cos=0.257), tot_loss_proj:3.123 [t=0.24s]
prediction: ['[CLS] requirement that king or queen on all royal is present. ] royal weddings. [SEP]']
[1950/2000] tot_loss=1.610 (perp=6.384, rec=0.077, cos=0.257), tot_loss_proj:3.128 [t=0.24s]
prediction: ['[CLS] requirement that king or queen on all royal is present. ] royal weddings. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.612 (perp=6.384, rec=0.079, cos=0.257), tot_loss_proj:3.125 [t=0.24s]
prediction: ['[CLS] requirement that king or queen on all royal is present. ] royal weddings. [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]
========================
predicted: 
========================
[CLS] requirement that king or queen on all royal is present. ] royal weddings. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.667 | p: 92.857 | r: 81.250
rouge2     | fm: 42.857 | p: 46.154 | r: 40.000
rougeL     | fm: 66.667 | p: 71.429 | r: 62.500
rougeLsum  | fm: 66.667 | p: 71.429 | r: 62.500
r1fm+r2fm = 129.524

[Aggregate metrics]:
rouge1     | fm: 87.946 | p: 87.522 | r: 88.561
rouge2     | fm: 52.888 | p: 52.510 | r: 53.499
rougeL     | fm: 77.827 | p: 77.478 | r: 78.479
rougeLsum  | fm: 78.003 | p: 77.561 | r: 78.474
r1fm+r2fm = 140.834

input #84 time: 0:09:16 | total time: 12:53:40


Running input #85 of 100.
reference: 
========================
Aphrodite stinks to be omnipotent.
========================
average of cosine similarity 0.8557286317367138
highest_index [0]
highest [0.8557286317367138]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  9706,  8093,  7716,  4221, 27136,  2015,  2000,  2022, 18168,
          3490, 11008,  4765,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] aphrodite stinks to be omnipotent. [SEP]']
[Init] best rec loss: 0.8410933613777161 for ['[CLS] grandchildren ghosts course [SEP]et chief view matt single ko pass rural entered [SEP]']
[Init] best rec loss: 0.8398646116256714 for ['[CLS] living julian luckily attention flags troubleac than offer catalan towers college heel [SEP]']
[Init] best rec loss: 0.8329989314079285 for ['[CLS] march mayoralloadsman greatuled coverskieox monuments res bree thomas [SEP]']
[Init] best rec loss: 0.8285874128341675 for ['[CLS] horatio score clenched traffic numerous certain drained ontohend heart mystery roger burgundy [SEP]']
[Init] best rec loss: 0.8273476958274841 for ['[CLS] davy prime lace therefore grown destruction scales card spaceyp bennett hung whispered [SEP]']
[Init] best rec loss: 0.8177559971809387 for ['[CLS] flyer plain abruptly respectivelybase stan didndara trialseconomic may know card [SEP]']
[Init] best rec loss: 0.8156189322471619 for ['[CLS] ward science cinderown connectedlynn ª clearable em miles watching milk [SEP]']
[Init] best rec loss: 0.7889435291290283 for ['[CLS]ype tombstone announced income counties tree scratch wealthy literally area livingston solo recognize [SEP]']
[Init] best rec loss: 0.7811239361763 for ['[CLS] twin weasel craft help enough norman ¨vez gamer london tightlycing sis [SEP]']
[Init] best perm rec loss: 0.7784731388092041 for ['[CLS] london sis gamer weasel tightly twin help normancing enoughvez craft ¨ [SEP]']
[Init] best perm rec loss: 0.7727131247520447 for ['[CLS]cing norman ¨ sis enough gamer tightly london weasel helpvez twin craft [SEP]']
[Init] best perm rec loss: 0.7704516649246216 for ['[CLS] tightly enoughcing london weasel ¨ gamer sis twin norman craft helpvez [SEP]']
[Init] best perm rec loss: 0.7686415910720825 for ['[CLS] enough norman tightlyvez twin london sis craft weasel gamer ¨ helpcing [SEP]']
[Init] best perm rec loss: 0.7679403424263 for ['[CLS] norman london weasel tightly gamer twin sisvez craft ¨ help enoughcing [SEP]']
[Init] best perm rec loss: 0.7661970853805542 for ['[CLS] ¨ enough sis twin norman gamercing tightly craftvez weasel help london [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.293 (perp=12.758, rec=0.488, cos=0.253), tot_loss_proj:3.910 [t=0.23s]
prediction: ['[CLS] comic thorne describes retroulu of compound anang muhammad cannot help hitler [SEP]']
[ 100/2000] tot_loss=3.159 (perp=12.621, rec=0.388, cos=0.247), tot_loss_proj:3.815 [t=0.23s]
prediction: ['[CLS]ital thorne acts retrouluist compound anilation acheron states to hitler [SEP]']
[ 150/2000] tot_loss=3.059 (perp=12.320, rec=0.333, cos=0.262), tot_loss_proj:4.051 [t=0.23s]
prediction: ['[CLS] libby thorne acts retroleicated compound antlementite stink to depression [SEP]']
[ 200/2000] tot_loss=3.188 (perp=13.162, rec=0.301, cos=0.255), tot_loss_proj:4.193 [t=0.23s]
prediction: ['[CLS] libby thorne acts retrole stink coming antlementite stink to simultaneously [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.101 (perp=12.902, rec=0.267, cos=0.254), tot_loss_proj:4.024 [t=0.23s]
prediction: ['[CLS] libby thorne treats intraenaism⁺ antlementite stink to occur [SEP]']
[ 300/2000] tot_loss=3.068 (perp=12.886, rec=0.225, cos=0.265), tot_loss_proj:4.210 [t=0.23s]
prediction: ['[CLS]gy thorne ; intraenaism stink beellantite stink to be [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.003 (perp=12.696, rec=0.204, cos=0.261), tot_loss_proj:4.088 [t=0.23s]
prediction: ['[CLS]gyis retro thorneism stink beiteite stink to be [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.817 (perp=11.700, rec=0.223, cos=0.254), tot_loss_proj:3.647 [t=0.23s]
prediction: ['[CLS]¨pot ap retro ciismostalspotite stink to be [SEP]']
[ 450/2000] tot_loss=2.844 (perp=11.966, rec=0.190, cos=0.261), tot_loss_proj:3.812 [t=0.23s]
prediction: ['[CLS]dhapot ap retro ciismostalspotite stink to be [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.649 (perp=11.029, rec=0.192, cos=0.251), tot_loss_proj:3.855 [t=0.23s]
prediction: ['[CLS]dhapot ap adjanizedismspotite stink to be [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.612 (perp=10.752, rec=0.209, cos=0.253), tot_loss_proj:3.671 [t=0.23s]
prediction: ['[CLS]odpot ap retrojanicism stinkspotite to be [SEP]']
[ 600/2000] tot_loss=2.742 (perp=11.531, rec=0.186, cos=0.250), tot_loss_proj:3.737 [t=0.23s]
prediction: ['[CLS]odpot ap om cornersicism stinkspotite to be [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.496 (perp=10.378, rec=0.169, cos=0.251), tot_loss_proj:3.600 [t=0.23s]
prediction: ['[CLS]odieldpot ap omicism stinkspotite to be [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.367 (perp=9.828, rec=0.149, cos=0.252), tot_loss_proj:3.458 [t=0.23s]
prediction: ['[CLS]potodield ap omicstic stinkspotite to be [SEP]']
[ 750/2000] tot_loss=2.614 (perp=11.130, rec=0.132, cos=0.256), tot_loss_proj:3.816 [t=0.23s]
prediction: ['[CLS]potodield ap omentstic stinksodite to be [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.452 (perp=10.370, rec=0.121, cos=0.256), tot_loss_proj:3.623 [t=0.23s]
prediction: ['[CLS]potentield ap omodstic stinksodite to be [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.352 (perp=9.870, rec=0.121, cos=0.257), tot_loss_proj:3.584 [t=0.23s]
prediction: ['[CLS] ompotentield apodstic stinksodite to be [SEP]']
[ 900/2000] tot_loss=2.350 (perp=9.870, rec=0.116, cos=0.260), tot_loss_proj:3.584 [t=0.23s]
prediction: ['[CLS] ompotentield apodstic stinksodite to be [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.353 (perp=9.870, rec=0.118, cos=0.261), tot_loss_proj:3.582 [t=0.23s]
prediction: ['[CLS] ompotentield apodstic stinksodite to be [SEP]']
Attempt swap
[1000/2000] tot_loss=2.352 (perp=9.870, rec=0.117, cos=0.261), tot_loss_proj:3.586 [t=0.23s]
prediction: ['[CLS] ompotentield apodstic stinksodite to be [SEP]']
[1050/2000] tot_loss=2.343 (perp=9.870, rec=0.108, cos=0.262), tot_loss_proj:3.587 [t=0.23s]
prediction: ['[CLS] ompotentield apodstic stinksodite to be [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.090 (perp=8.607, rec=0.108, cos=0.260), tot_loss_proj:3.323 [t=0.23s]
prediction: ['[CLS] ompotentstic stinksield apododite to be [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.951 (perp=7.941, rec=0.109, cos=0.253), tot_loss_proj:3.185 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
[1200/2000] tot_loss=1.959 (perp=7.941, rec=0.111, cos=0.260), tot_loss_proj:3.189 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.953 (perp=7.941, rec=0.103, cos=0.261), tot_loss_proj:3.185 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Attempt swap
[1300/2000] tot_loss=1.947 (perp=7.941, rec=0.097, cos=0.262), tot_loss_proj:3.184 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
[1350/2000] tot_loss=1.959 (perp=7.941, rec=0.108, cos=0.262), tot_loss_proj:3.188 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Attempt swap
[1400/2000] tot_loss=1.955 (perp=7.941, rec=0.104, cos=0.263), tot_loss_proj:3.183 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Attempt swap
[1450/2000] tot_loss=1.955 (perp=7.941, rec=0.104, cos=0.263), tot_loss_proj:3.185 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
[1500/2000] tot_loss=1.952 (perp=7.941, rec=0.100, cos=0.264), tot_loss_proj:3.184 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Attempt swap
[1550/2000] tot_loss=1.943 (perp=7.941, rec=0.091, cos=0.264), tot_loss_proj:3.188 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Attempt swap
[1600/2000] tot_loss=1.947 (perp=7.941, rec=0.095, cos=0.264), tot_loss_proj:3.185 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
[1650/2000] tot_loss=1.950 (perp=7.941, rec=0.098, cos=0.264), tot_loss_proj:3.186 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Attempt swap
[1700/2000] tot_loss=1.964 (perp=7.941, rec=0.112, cos=0.264), tot_loss_proj:3.183 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Attempt swap
[1750/2000] tot_loss=1.953 (perp=7.941, rec=0.100, cos=0.264), tot_loss_proj:3.182 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
[1800/2000] tot_loss=1.953 (perp=7.941, rec=0.100, cos=0.264), tot_loss_proj:3.182 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Attempt swap
[1850/2000] tot_loss=1.944 (perp=7.941, rec=0.091, cos=0.265), tot_loss_proj:3.183 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Attempt swap
[1900/2000] tot_loss=1.951 (perp=7.941, rec=0.098, cos=0.265), tot_loss_proj:3.186 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
[1950/2000] tot_loss=1.948 (perp=7.941, rec=0.095, cos=0.265), tot_loss_proj:3.185 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Attempt swap
[2000/2000] tot_loss=1.944 (perp=7.941, rec=0.091, cos=0.265), tot_loss_proj:3.185 [t=0.23s]
prediction: ['[CLS] omsticpotent stinksield apododite to be [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] aphrodite stinks to be omnipotent. [SEP]
========================
predicted: 
========================
[CLS] omsticpotent stinksield apododite to be [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 57.143 | r: 57.143
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 73.810

[Aggregate metrics]:
rouge1     | fm: 87.595 | p: 87.191 | r: 88.176
rouge2     | fm: 52.575 | p: 52.102 | r: 53.159
rougeL     | fm: 77.573 | p: 77.197 | r: 78.178
rougeLsum  | fm: 77.716 | p: 77.352 | r: 78.278
r1fm+r2fm = 140.170

input #85 time: 0:09:10 | total time: 13:02:51


Running input #86 of 100.
reference: 
========================
I lifted him up the books.
========================
average of cosine similarity 0.9034328899078063
highest_index [0]
highest [0.9034328899078063]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1045, 4196, 2032, 2039, 1996, 2808, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i lifted him up the books. [SEP]']
[Init] best rec loss: 0.8069403171539307 for ['[CLS] associates kill blockade musica [SEP] bees... [SEP]']
[Init] best rec loss: 0.7573917508125305 for ['[CLS] grey features civil emotions cheek villain could [SEP]']
[Init] best rec loss: 0.7275084257125854 for ["[CLS] 'ry full winston postwright what [SEP]"]
[Init] best rec loss: 0.7191246747970581 for ['[CLS] interest check indytute watch pitched licence [SEP]']
[Init] best rec loss: 0.7138522863388062 for ['[CLS] did chin rearن spray davyologist [SEP]']
[Init] best rec loss: 0.7110075354576111 for ['[CLS]ing society vrza hill bareurity [SEP]']
[Init] best rec loss: 0.7103853225708008 for ['[CLS] maximum pack wildlife made over bodies groups [SEP]']
[Init] best rec loss: 0.7029796242713928 for ['[CLS]tonic based coveren booth novels infrared [SEP]']
[Init] best rec loss: 0.6870248317718506 for ['[CLS] made par letters imp carrier obviouss [SEP]']
[Init] best rec loss: 0.6655082702636719 for ['[CLS]arus bank groups bare primetime rub reviewer [SEP]']
[Init] best perm rec loss: 0.6624881625175476 for ['[CLS] reviewer rubarus groups bank primetime bare [SEP]']
[Init] best perm rec loss: 0.6573488712310791 for ['[CLS] bank rubarus bare primetime reviewer groups [SEP]']
[Init] best perm rec loss: 0.656593918800354 for ['[CLS]arus reviewer bare bank primetime rub groups [SEP]']
[Init] best perm rec loss: 0.6558993458747864 for ['[CLS] primetime groups bank reviewer barearus rub [SEP]']
[Init] best perm rec loss: 0.6554001569747925 for ['[CLS]arus reviewer primetime rub groups bank bare [SEP]']
[Init] best perm rec loss: 0.6552284359931946 for ['[CLS] bank primetime reviewerarus rub groups bare [SEP]']
[Init] best perm rec loss: 0.6548067331314087 for ['[CLS] primetimearus groups bank bare rub reviewer [SEP]']
[Init] best perm rec loss: 0.6546216607093811 for ['[CLS] rub groups bare bankarus primetime reviewer [SEP]']
[Init] best perm rec loss: 0.6525745987892151 for ['[CLS] bankarus groups rub reviewer bare primetime [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.443 (perp=10.639, rec=0.569, cos=0.746), tot_loss_proj:3.169 [t=0.23s]
prediction: ['[CLS] train up ur this we up up [SEP]']
[ 100/2000] tot_loss=2.717 (perp=11.062, rec=0.321, cos=0.184), tot_loss_proj:3.166 [t=0.23s]
prediction: ['[CLS] plant up up this up enough books [SEP]']
[ 150/2000] tot_loss=2.357 (perp=9.144, rec=0.342, cos=0.186), tot_loss_proj:2.845 [t=0.23s]
prediction: ['[CLS] up up up this baby online him [SEP]']
[ 200/2000] tot_loss=2.490 (perp=10.110, rec=0.293, cos=0.175), tot_loss_proj:3.021 [t=0.23s]
prediction: ['[CLS] up up classes up the digital him [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.044 (perp=7.830, rec=0.247, cos=0.231), tot_loss_proj:2.644 [t=0.23s]
prediction: ['[CLS] up up books the books him up [SEP]']
[ 300/2000] tot_loss=2.016 (perp=8.319, rec=0.166, cos=0.186), tot_loss_proj:2.725 [t=0.23s]
prediction: ['[CLS] up lifted books the books him up [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.853 (perp=7.650, rec=0.139, cos=0.184), tot_loss_proj:2.638 [t=0.23s]
prediction: ['[CLS] books lifted up the books him up [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.826 (perp=7.650, rec=0.113, cos=0.183), tot_loss_proj:2.617 [t=0.23s]
prediction: ['[CLS] books lifted up the books him up [SEP]']
[ 450/2000] tot_loss=1.822 (perp=7.650, rec=0.108, cos=0.183), tot_loss_proj:2.611 [t=0.23s]
prediction: ['[CLS] books lifted up the books him up [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.808 (perp=7.650, rec=0.095, cos=0.183), tot_loss_proj:2.603 [t=0.23s]
prediction: ['[CLS] books lifted up the books him up [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.807 (perp=7.650, rec=0.094, cos=0.183), tot_loss_proj:2.572 [t=0.23s]
prediction: ['[CLS] books lifted up the books him up [SEP]']
[ 600/2000] tot_loss=2.024 (perp=8.778, rec=0.086, cos=0.182), tot_loss_proj:2.719 [t=0.23s]
prediction: ['[CLS] books lifted my the books him up [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.901 (perp=8.158, rec=0.088, cos=0.181), tot_loss_proj:2.665 [t=0.23s]
prediction: ['[CLS] books lifted the my books him up [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.905 (perp=8.158, rec=0.092, cos=0.181), tot_loss_proj:2.658 [t=0.23s]
prediction: ['[CLS] books lifted the my books him up [SEP]']
[ 750/2000] tot_loss=1.895 (perp=8.158, rec=0.082, cos=0.181), tot_loss_proj:2.659 [t=0.23s]
prediction: ['[CLS] books lifted the my books him up [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.899 (perp=8.158, rec=0.086, cos=0.182), tot_loss_proj:2.663 [t=0.23s]
prediction: ['[CLS] books lifted the my books him up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.904 (perp=8.158, rec=0.091, cos=0.182), tot_loss_proj:2.655 [t=0.23s]
prediction: ['[CLS] books lifted the my books him up [SEP]']
[ 900/2000] tot_loss=1.898 (perp=8.158, rec=0.084, cos=0.182), tot_loss_proj:2.650 [t=0.23s]
prediction: ['[CLS] books lifted the my books him up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.892 (perp=8.158, rec=0.079, cos=0.182), tot_loss_proj:2.653 [t=0.23s]
prediction: ['[CLS] books lifted the my books him up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.937 (perp=8.352, rec=0.085, cos=0.182), tot_loss_proj:2.601 [t=0.23s]
prediction: ['[CLS] books lifted the i books him up [SEP]']
[1050/2000] tot_loss=1.919 (perp=8.352, rec=0.067, cos=0.182), tot_loss_proj:2.617 [t=0.23s]
prediction: ['[CLS] books lifted the i books him up [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.774 (perp=7.495, rec=0.094, cos=0.180), tot_loss_proj:2.409 [t=0.23s]
prediction: ['[CLS] i lifted the books books him up [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.707 (perp=7.265, rec=0.073, cos=0.181), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
[1200/2000] tot_loss=1.715 (perp=7.265, rec=0.080, cos=0.182), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.715 (perp=7.265, rec=0.080, cos=0.182), tot_loss_proj:2.218 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.711 (perp=7.265, rec=0.075, cos=0.182), tot_loss_proj:2.217 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
[1350/2000] tot_loss=1.712 (perp=7.265, rec=0.077, cos=0.183), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.713 (perp=7.265, rec=0.077, cos=0.183), tot_loss_proj:2.222 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.716 (perp=7.265, rec=0.080, cos=0.183), tot_loss_proj:2.215 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
[1500/2000] tot_loss=1.712 (perp=7.265, rec=0.076, cos=0.183), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.712 (perp=7.265, rec=0.076, cos=0.183), tot_loss_proj:2.221 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.718 (perp=7.265, rec=0.082, cos=0.183), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
[1650/2000] tot_loss=1.710 (perp=7.265, rec=0.074, cos=0.183), tot_loss_proj:2.220 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.714 (perp=7.265, rec=0.078, cos=0.183), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.712 (perp=7.265, rec=0.076, cos=0.183), tot_loss_proj:2.211 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
[1800/2000] tot_loss=1.709 (perp=7.265, rec=0.073, cos=0.183), tot_loss_proj:2.216 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.714 (perp=7.265, rec=0.078, cos=0.183), tot_loss_proj:2.220 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.705 (perp=7.265, rec=0.069, cos=0.183), tot_loss_proj:2.211 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
[1950/2000] tot_loss=1.716 (perp=7.265, rec=0.080, cos=0.183), tot_loss_proj:2.228 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.714 (perp=7.265, rec=0.078, cos=0.183), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS] i lifted the books him books up [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] i lifted him up the books. [SEP]
========================
predicted: 
========================
[CLS] i lifted the books him books up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 40.000 | p: 37.500 | r: 42.857
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 134.118

[Aggregate metrics]:
rouge1     | fm: 87.713 | p: 87.185 | r: 88.420
rouge2     | fm: 52.357 | p: 51.871 | r: 52.983
rougeL     | fm: 77.585 | p: 77.117 | r: 78.170
rougeLsum  | fm: 77.563 | p: 77.127 | r: 78.150
r1fm+r2fm = 140.070

input #86 time: 0:09:10 | total time: 13:12:01


Running input #87 of 100.
reference: 
========================
Heidi thinks that Andy has eaten salmon flavored candy bars.
========================
average of cosine similarity 0.8852707486601321
highest_index [0]
highest [0.8852707486601321]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101, 21372,  6732,  2008,  5557,  2038,  8828, 11840, 14894,  2098,
          9485,  6963,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]']
[Init] best rec loss: 0.9447600841522217 for ['[CLS] flood but! means roe vietnam after partial owe cult novel question [SEP]']
[Init] best rec loss: 0.9046176671981812 for ['[CLS] freedom slammed time felicity asphalt barely ag ohrricular our trips coast [SEP]']
[Init] best rec loss: 0.8827888369560242 for ['[CLS] sea squadron fixed step saw−ms legendary ohio happy level don [SEP]']
[Init] best perm rec loss: 0.8825793266296387 for ['[CLS] sea ohio happy fixed don level legendary squadronms saw step− [SEP]']
[Init] best perm rec loss: 0.8819329142570496 for ['[CLS] seams saw fixed− don step legendary happy squadron level ohio [SEP]']
[Init] best perm rec loss: 0.8818686604499817 for ['[CLS] ohio fixed level step sea don saw− legendary squadron happyms [SEP]']
[Init] best perm rec loss: 0.8808488249778748 for ['[CLS] level− ohio fixedms legendary happy sea step squadron don saw [SEP]']
[Init] best perm rec loss: 0.8807377219200134 for ['[CLS]ms level sea don fixed happy ohio step squadron legendary saw− [SEP]']
[Init] best perm rec loss: 0.8801501989364624 for ['[CLS] fixedms ohio step level don squadron sea− saw legendary happy [SEP]']
[Init] best perm rec loss: 0.8801453113555908 for ['[CLS]− squadron don step sea fixed ohioms happy legendary level saw [SEP]']
[Init] best perm rec loss: 0.8772312998771667 for ['[CLS] sawms step don ohio sea fixed legendary happy squadron− level [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.034 (perp=12.513, rec=0.319, cos=0.212), tot_loss_proj:4.344 [t=0.22s]
prediction: ['[CLS] headnesia residence heidicolor tribute produced candy eating another by product [SEP]']
[ 100/2000] tot_loss=2.411 (perp=9.960, rec=0.203, cos=0.217), tot_loss_proj:3.845 [t=0.22s]
prediction: ['[CLS] heidi heidi thought andy has candy eaten candy eaten.. stuff [SEP]']
[ 150/2000] tot_loss=2.320 (perp=9.833, rec=0.145, cos=0.209), tot_loss_proj:3.824 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy eaten candy flavor.. produced [SEP]']
[ 200/2000] tot_loss=2.181 (perp=9.215, rec=0.129, cos=0.209), tot_loss_proj:3.690 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy eaten candy flavor.. candy [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.452 (perp=10.496, rec=0.141, cos=0.212), tot_loss_proj:3.931 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy flavor eaten salmon ; eggs candy [SEP]']
[ 300/2000] tot_loss=2.443 (perp=10.489, rec=0.136, cos=0.210), tot_loss_proj:3.928 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy flavor eaten salmon. eggs bars [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.144 (perp=8.996, rec=0.137, cos=0.209), tot_loss_proj:3.658 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy flavor eaten candy foods bars. [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.128 (perp=8.996, rec=0.122, cos=0.207), tot_loss_proj:3.655 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy flavor eaten candy foods bars. [SEP]']
[ 450/2000] tot_loss=2.132 (perp=8.996, rec=0.124, cos=0.209), tot_loss_proj:3.658 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy flavor eaten candy foods bars. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.099 (perp=8.837, rec=0.124, cos=0.208), tot_loss_proj:3.644 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy flavor foods eaten candy bars. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.100 (perp=8.837, rec=0.123, cos=0.209), tot_loss_proj:3.647 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy flavor foods eaten candy bars. [SEP]']
[ 600/2000] tot_loss=2.152 (perp=9.132, rec=0.118, cos=0.208), tot_loss_proj:3.699 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy flavor foods eaten salmon bars. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.150 (perp=9.132, rec=0.115, cos=0.208), tot_loss_proj:3.707 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy flavor foods eaten salmon bars. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.153 (perp=9.132, rec=0.118, cos=0.209), tot_loss_proj:3.701 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy flavor foods eaten salmon bars. [SEP]']
[ 750/2000] tot_loss=2.153 (perp=9.132, rec=0.117, cos=0.209), tot_loss_proj:3.703 [t=0.22s]
prediction: ['[CLS] heidi heidi thinks andy has candy flavor foods eaten salmon bars. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.141 (perp=9.050, rec=0.122, cos=0.209), tot_loss_proj:3.624 [t=0.22s]
prediction: ['[CLS] heidi thinks heidi andy has candy flavor foods eaten salmon bars. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.128 (perp=9.050, rec=0.108, cos=0.210), tot_loss_proj:3.622 [t=0.22s]
prediction: ['[CLS] heidi thinks heidi andy has candy flavor foods eaten salmon bars. [SEP]']
[ 900/2000] tot_loss=2.270 (perp=9.727, rec=0.114, cos=0.211), tot_loss_proj:3.777 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor foods eaten salmon bars. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.248 (perp=9.592, rec=0.118, cos=0.211), tot_loss_proj:3.740 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.241 (perp=9.592, rec=0.111, cos=0.211), tot_loss_proj:3.737 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
[1050/2000] tot_loss=2.242 (perp=9.592, rec=0.112, cos=0.211), tot_loss_proj:3.733 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.233 (perp=9.592, rec=0.104, cos=0.211), tot_loss_proj:3.738 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.243 (perp=9.592, rec=0.113, cos=0.211), tot_loss_proj:3.734 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
[1200/2000] tot_loss=2.242 (perp=9.592, rec=0.112, cos=0.211), tot_loss_proj:3.737 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.238 (perp=9.592, rec=0.108, cos=0.211), tot_loss_proj:3.741 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.245 (perp=9.592, rec=0.116, cos=0.211), tot_loss_proj:3.733 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
[1350/2000] tot_loss=2.237 (perp=9.592, rec=0.107, cos=0.211), tot_loss_proj:3.734 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.247 (perp=9.592, rec=0.117, cos=0.211), tot_loss_proj:3.739 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.238 (perp=9.592, rec=0.109, cos=0.211), tot_loss_proj:3.736 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
[1500/2000] tot_loss=2.233 (perp=9.592, rec=0.103, cos=0.212), tot_loss_proj:3.738 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.242 (perp=9.592, rec=0.112, cos=0.211), tot_loss_proj:3.738 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.237 (perp=9.592, rec=0.108, cos=0.211), tot_loss_proj:3.740 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
[1650/2000] tot_loss=2.235 (perp=9.592, rec=0.106, cos=0.211), tot_loss_proj:3.741 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.239 (perp=9.592, rec=0.109, cos=0.211), tot_loss_proj:3.738 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.240 (perp=9.592, rec=0.110, cos=0.212), tot_loss_proj:3.736 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
[1800/2000] tot_loss=2.236 (perp=9.592, rec=0.106, cos=0.211), tot_loss_proj:3.740 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.234 (perp=9.592, rec=0.104, cos=0.211), tot_loss_proj:3.738 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.242 (perp=9.592, rec=0.112, cos=0.211), tot_loss_proj:3.738 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
[1950/2000] tot_loss=2.245 (perp=9.592, rec=0.115, cos=0.211), tot_loss_proj:3.739 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.237 (perp=9.592, rec=0.107, cos=0.211), tot_loss_proj:3.739 [t=0.23s]
prediction: ['[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]
========================
predicted: 
========================
[CLS] saying thinks heidi andy has candy flavor eaten salmon foods bars. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 76.923 | r: 83.333
rouge2     | fm: 26.087 | p: 25.000 | r: 27.273
rougeL     | fm: 64.000 | p: 61.538 | r: 66.667
rougeLsum  | fm: 64.000 | p: 61.538 | r: 66.667
r1fm+r2fm = 106.087

[Aggregate metrics]:
rouge1     | fm: 87.534 | p: 87.044 | r: 88.272
rouge2     | fm: 52.030 | p: 51.611 | r: 52.643
rougeL     | fm: 77.383 | p: 76.919 | r: 78.010
rougeLsum  | fm: 77.408 | p: 76.969 | r: 78.043
r1fm+r2fm = 139.564

input #87 time: 0:09:02 | total time: 13:21:03


Running input #88 of 100.
reference: 
========================
He bought these flowers for Aaron.
========================
average of cosine similarity 0.8362553000218464
highest_index [0]
highest [0.8362553000218464]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 4149, 2122, 4870, 2005, 7158, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he bought these flowers for aaron. [SEP]']
[Init] best rec loss: 0.888696551322937 for ['[CLS] wi rio xx irving ou obligations tang [SEP]']
[Init] best rec loss: 0.881680428981781 for ['[CLS] twovabletyle situation morning had clean [SEP]']
[Init] best rec loss: 0.8741578459739685 for ['[CLS] largelymos hiz power especially chalk [SEP]']
[Init] best rec loss: 0.8604485392570496 for ['[CLS] my quality silk our mess bodo hal [SEP]']
[Init] best perm rec loss: 0.8594207763671875 for ['[CLS] mess our hal my quality bodo silk [SEP]']
[Init] best perm rec loss: 0.8578301668167114 for ['[CLS] our my silk quality mess bodo hal [SEP]']
[Init] best perm rec loss: 0.8565436601638794 for ['[CLS] my quality hal our silk mess bodo [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.618 (perp=12.037, rec=0.600, cos=0.610), tot_loss_proj:4.175 [t=0.23s]
prediction: ['[CLS] want apartment either householder beautiful herbal self [SEP]']
[ 100/2000] tot_loss=3.758 (perp=12.177, rec=0.672, cos=0.650), tot_loss_proj:4.204 [t=0.23s]
prediction: ['[CLS] different medici either broadcasts symptoms flowers during [SEP]']
[ 150/2000] tot_loss=3.576 (perp=13.713, rec=0.493, cos=0.341), tot_loss_proj:4.518 [t=0.23s]
prediction: ['[CLS] different preserved enforcement discus themes flowersς [SEP]']
[ 200/2000] tot_loss=3.735 (perp=13.834, rec=0.515, cos=0.453), tot_loss_proj:4.547 [t=0.23s]
prediction: ['[CLS] municipality preserved usl recipe bought flowers⁄ [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.328 (perp=12.827, rec=0.474, cos=0.289), tot_loss_proj:4.362 [t=0.23s]
prediction: ['[CLS] regiment preserved flowers recipe bought aaron gallons [SEP]']
[ 300/2000] tot_loss=3.068 (perp=11.848, rec=0.394, cos=0.304), tot_loss_proj:4.177 [t=0.23s]
prediction: ['[CLS] these purchased flowers recipe these aaron horseback [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.905 (perp=13.669, rec=0.489, cos=0.682), tot_loss_proj:4.493 [t=0.23s]
prediction: ['[CLS] regiment bought flowers purchased bought bargaining aaron [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.981 (perp=11.618, rec=0.387, cos=0.271), tot_loss_proj:4.114 [t=0.23s]
prediction: ['[CLS] different flowers bought purchased thesenty aaron [SEP]']
[ 450/2000] tot_loss=3.126 (perp=12.787, rec=0.368, cos=0.200), tot_loss_proj:4.321 [t=0.23s]
prediction: ['[CLS] examined flowers bought purchased thesenty aaron [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.222 (perp=13.100, rec=0.348, cos=0.254), tot_loss_proj:4.402 [t=0.23s]
prediction: ['[CLS] behalf flowers bought aaron these bargaining purchased [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.720 (perp=10.637, rec=0.396, cos=0.197), tot_loss_proj:4.014 [t=0.23s]
prediction: ['[CLS] aaron behalf flowers bought theseject shirts [SEP]']
[ 600/2000] tot_loss=2.871 (perp=11.366, rec=0.353, cos=0.245), tot_loss_proj:4.081 [t=0.23s]
prediction: ['[CLS] aaron behalf flowers bought theseject purchased [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.930 (perp=11.278, rec=0.341, cos=0.333), tot_loss_proj:4.137 [t=0.23s]
prediction: ['[CLS] aaron behalf flowers bought these shirtsject [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.117 (perp=12.310, rec=0.374, cos=0.281), tot_loss_proj:4.277 [t=0.23s]
prediction: ['[CLS] aaron behalf flowers bought theseject preserved [SEP]']
[ 750/2000] tot_loss=2.882 (perp=11.346, rec=0.331, cos=0.281), tot_loss_proj:4.074 [t=0.23s]
prediction: ['[CLS] aaron behalf flowers bought theseject guy [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.858 (perp=11.268, rec=0.325, cos=0.280), tot_loss_proj:4.068 [t=0.23s]
prediction: ['[CLS] aaron behalf flowers bought these guyject [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.854 (perp=11.268, rec=0.325, cos=0.276), tot_loss_proj:4.068 [t=0.23s]
prediction: ['[CLS] aaron behalf flowers bought these guyject [SEP]']
[ 900/2000] tot_loss=3.020 (perp=11.990, rec=0.349, cos=0.273), tot_loss_proj:4.226 [t=0.23s]
prediction: ['[CLS] aaronhow flowers bought these guyject [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.881 (perp=11.726, rec=0.333, cos=0.202), tot_loss_proj:4.178 [t=0.23s]
prediction: ['[CLS]jecthow flowers bought these guy aaron [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.122 (perp=12.664, rec=0.330, cos=0.259), tot_loss_proj:4.309 [t=0.23s]
prediction: ['[CLS]jecthow flowers guy treatise these aaron [SEP]']
[1050/2000] tot_loss=2.896 (perp=11.414, rec=0.317, cos=0.296), tot_loss_proj:4.108 [t=0.23s]
prediction: ['[CLS]jecthow flowers guy bought these aaron [SEP]']
Attempt swap
[1100/2000] tot_loss=3.117 (perp=12.664, rec=0.317, cos=0.266), tot_loss_proj:4.306 [t=0.23s]
prediction: ['[CLS]jecthow flowers guy treatise these aaron [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.267 (perp=13.167, rec=0.335, cos=0.298), tot_loss_proj:4.435 [t=0.23s]
prediction: ['[CLS] handful aaron flowers guy treatise thesehow [SEP]']
[1200/2000] tot_loss=3.258 (perp=13.167, rec=0.313, cos=0.311), tot_loss_proj:4.433 [t=0.23s]
prediction: ['[CLS] handful aaron flowers guy treatise thesehow [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=3.261 (perp=13.091, rec=0.320, cos=0.322), tot_loss_proj:4.427 [t=0.23s]
prediction: ['[CLS] aaronnburg flowers guy treatise thesehow [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.805 (perp=10.866, rec=0.326, cos=0.306), tot_loss_proj:3.992 [t=0.23s]
prediction: ['[CLS] aaron treatisenburg flowers purchased thesehow [SEP]']
[1350/2000] tot_loss=2.792 (perp=11.255, rec=0.302, cos=0.239), tot_loss_proj:4.060 [t=0.23s]
prediction: ['[CLS] aaron treatisenburg flowers guy thesehow [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.724 (perp=10.558, rec=0.322, cos=0.290), tot_loss_proj:3.961 [t=0.23s]
prediction: ['[CLS] aaron treatisenburg flowers thesehow guy [SEP]']
Attempt swap
[1450/2000] tot_loss=2.697 (perp=10.558, rec=0.314, cos=0.272), tot_loss_proj:3.963 [t=0.23s]
prediction: ['[CLS] aaron treatisenburg flowers thesehow guy [SEP]']
[1500/2000] tot_loss=2.716 (perp=10.558, rec=0.304, cos=0.301), tot_loss_proj:3.959 [t=0.23s]
prediction: ['[CLS] aaron treatisenburg flowers thesehow guy [SEP]']
Attempt swap
[1550/2000] tot_loss=2.703 (perp=10.558, rec=0.311, cos=0.280), tot_loss_proj:3.962 [t=0.23s]
prediction: ['[CLS] aaron treatisenburg flowers thesehow guy [SEP]']
Attempt swap
[1600/2000] tot_loss=2.706 (perp=10.558, rec=0.305, cos=0.290), tot_loss_proj:3.962 [t=0.23s]
prediction: ['[CLS] aaron treatisenburg flowers thesehow guy [SEP]']
[1650/2000] tot_loss=2.704 (perp=10.558, rec=0.306, cos=0.287), tot_loss_proj:3.961 [t=0.23s]
prediction: ['[CLS] aaron treatisenburg flowers thesehow guy [SEP]']
Attempt swap
[1700/2000] tot_loss=2.705 (perp=10.558, rec=0.306, cos=0.287), tot_loss_proj:3.962 [t=0.23s]
prediction: ['[CLS] aaron treatisenburg flowers thesehow guy [SEP]']
Attempt swap
[1750/2000] tot_loss=2.716 (perp=10.558, rec=0.304, cos=0.300), tot_loss_proj:3.964 [t=0.23s]
prediction: ['[CLS] aaron treatisenburg flowers thesehow guy [SEP]']
[1800/2000] tot_loss=2.993 (perp=11.984, rec=0.303, cos=0.294), tot_loss_proj:4.271 [t=0.23s]
prediction: ['[CLS] aaron instructionsnburg flowers thesehow guy [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=3.082 (perp=12.380, rec=0.308, cos=0.298), tot_loss_proj:4.276 [t=0.23s]
prediction: ['[CLS] aaron handful flowers treatise thesehow guy [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.834 (perp=11.376, rec=0.305, cos=0.254), tot_loss_proj:4.066 [t=0.23s]
prediction: ['[CLS] aaron treatisenburg flowers these waived guy [SEP]']
[1950/2000] tot_loss=3.171 (perp=12.820, rec=0.306, cos=0.300), tot_loss_proj:4.398 [t=0.23s]
prediction: ['[CLS] aaron instructionsnburg flowers these waived guy [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=3.075 (perp=12.348, rec=0.306, cos=0.300), tot_loss_proj:4.352 [t=0.23s]
prediction: ['[CLS] aaron guynburg flowers these waived treatise [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] he bought these flowers for aaron. [SEP]
========================
predicted: 
========================
[CLS] aaron treatisenburg flowers these waived guy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.500 | p: 62.500 | r: 62.500
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 37.500 | p: 37.500 | r: 37.500
rougeLsum  | fm: 37.500 | p: 37.500 | r: 37.500
r1fm+r2fm = 62.500

[Aggregate metrics]:
rouge1     | fm: 87.290 | p: 86.745 | r: 88.030
rouge2     | fm: 51.508 | p: 51.033 | r: 52.107
rougeL     | fm: 77.005 | p: 76.539 | r: 77.647
rougeLsum  | fm: 76.955 | p: 76.491 | r: 77.586
r1fm+r2fm = 138.797

input #88 time: 0:09:10 | total time: 13:30:13


Running input #89 of 100.
reference: 
========================
Handsome though they told me that Tom is, I still won't date him.
========================
average of cosine similarity 0.8806661392043812
highest_index [0]
highest [0.8806661392043812]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[ 101, 8502, 2295, 2027, 2409, 2033, 2008, 3419, 2003, 1010, 1045, 2145,
         2180, 1005, 1056, 3058, 2032, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] handsome though they told me that tom is, i still won't date him. [SEP]"]
[Init] best rec loss: 0.8553175330162048 for ['[CLS] save jersey myanmar walkedfkthic ˢ wife dealing tomorrow lola e bit ll show ˈ competitions [SEP]']
[Init] best rec loss: 0.854303240776062 for ['[CLS] plenty sequence ) thomas obviously blade craftsman random gorilla movies by squeezedhall resonancehh mum ; [SEP]']
[Init] best rec loss: 0.8488724231719971 for ['[CLS] airports in generic root administrative capitol wisconsin blind municipality remainder prasad squirrelswise antioch programricted palmer [SEP]']
[Init] best rec loss: 0.8262477517127991 for ['[CLS] savannah circularcap adding faster ina mater ⟨weight ka teams things corporationgo mer constitution fox [SEP]']
[Init] best rec loss: 0.8122571110725403 for ["[CLS] sandractive hopeless get cambridge oppositionnch | centre'oddissa hellivndo minor offensive [SEP]"]
[Init] best rec loss: 0.8076069951057434 for ['[CLS] music animation enterprise againstssa even主 ducksns platformtish myers told provider pinkwell h [SEP]']
[Init] best rec loss: 0.7960579991340637 for ['[CLS] selected wilder aspirations mode composite generate face advertising screen color using laughter dad sells oldformed logan [SEP]']
[Init] best rec loss: 0.7716135382652283 for ['[CLS] hopes devicesrued iv governor swap that saskatchewan pup under ultimate section drugged voivodeship should morning 500 [SEP]']
[Init] best perm rec loss: 0.7676889896392822 for ['[CLS] ultimate hopesrued governor devices iv morning section 500 pup voivodeship drugged should swap saskatchewan that under [SEP]']
[Init] best perm rec loss: 0.7671041488647461 for ['[CLS] voivodeship section saskatchewan governor iv under devices that should ultimate morningrued drugged pup 500 swap hopes [SEP]']
[Init] best perm rec loss: 0.7668961882591248 for ['[CLS] 500 should section governor iv devices saskatchewan voivodeship morning that drugged hopes puprued ultimate swap under [SEP]']
[Init] best perm rec loss: 0.7665350437164307 for ['[CLS] devices section ultimate that saskatchewan iv drugged pup hopesrued under swap voivodeship morning should governor 500 [SEP]']
[Init] best perm rec loss: 0.7662147879600525 for ['[CLS] that pup hopes morning ultimate voivodeship iv shouldrued 500 section governor devices swap under saskatchewan drugged [SEP]']
[Init] best perm rec loss: 0.7658405303955078 for ['[CLS] that should drugged governor swap hopesrued devices morning pup iv ultimate under voivodeship 500 section saskatchewan [SEP]']
[Init] best perm rec loss: 0.7650740146636963 for ['[CLS]rued governor section voivodeship that under 500 iv hopes pup morning drugged swap devices ultimate saskatchewan should [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.901 (perp=11.524, rec=0.413, cos=0.183), tot_loss_proj:4.059 [t=0.22s]
prediction: ['[CLS] though were though though billy tom now i most fe was they player王urity have " [SEP]']
[ 100/2000] tot_loss=2.465 (perp=9.752, rec=0.313, cos=0.202), tot_loss_proj:3.606 [t=0.22s]
prediction: ['[CLS] though edward though though handsome tom ; i is handsome is they player tails maintaining have. [SEP]']
[ 150/2000] tot_loss=2.242 (perp=9.096, rec=0.220, cos=0.203), tot_loss_proj:3.629 [t=0.23s]
prediction: ['[CLS] though him though though handsome tom, i is handsome is they writer handsome possessed still. [SEP]']
[ 200/2000] tot_loss=2.391 (perp=10.054, rec=0.187, cos=0.192), tot_loss_proj:3.805 [t=0.23s]
prediction: ['[CLS] though him they though handsome tom, i is date is remained fucking handsome ∧ still. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.318 (perp=9.656, rec=0.194, cos=0.192), tot_loss_proj:3.842 [t=0.23s]
prediction: ['[CLS] though still they though handsome tom, i is date is remained me nile よ him. [SEP]']
[ 300/2000] tot_loss=2.304 (perp=9.741, rec=0.155, cos=0.201), tot_loss_proj:3.845 [t=0.23s]
prediction: ['[CLS] though still they though handsome tom, i is date is remained me nile me him. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.333 (perp=9.923, rec=0.150, cos=0.199), tot_loss_proj:3.811 [t=0.23s]
prediction: ['[CLS] though still handsome though they tom, i is date is remained date nile me him. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.387 (perp=9.428, rec=0.292, cos=0.209), tot_loss_proj:3.769 [t=0.23s]
prediction: ['[CLS] told still handsome though they tom, i is date she still matterriation date him. [SEP]']
[ 450/2000] tot_loss=2.341 (perp=9.573, rec=0.207, cos=0.219), tot_loss_proj:3.773 [t=0.22s]
prediction: ['[CLS] told could handsome though they tom, i is date he still matterriation date him. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.144 (perp=8.823, rec=0.161, cos=0.219), tot_loss_proj:3.556 [t=0.23s]
prediction: ['[CLS] that tom handsome though they never, i is date. still matterriation date him. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.057 (perp=8.600, rec=0.135, cos=0.201), tot_loss_proj:3.557 [t=0.23s]
prediction: ['[CLS] that tom handsome though told will, is i date. still matterriation date him. [SEP]']
[ 600/2000] tot_loss=2.023 (perp=8.447, rec=0.124, cos=0.209), tot_loss_proj:3.591 [t=0.22s]
prediction: ['[CLS] that tom handsome though told will, is i date. still matter montreal date him. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.955 (perp=8.105, rec=0.121, cos=0.213), tot_loss_proj:3.568 [t=0.22s]
prediction: ['[CLS] that tom handsome though told will, is i date. still montreal matter date him. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.886 (perp=7.729, rec=0.122, cos=0.218), tot_loss_proj:3.358 [t=0.22s]
prediction: ['[CLS] that tom handsome though told, is i date. still montreal matter will date him. [SEP]']
[ 750/2000] tot_loss=2.044 (perp=8.511, rec=0.126, cos=0.216), tot_loss_proj:3.560 [t=0.22s]
prediction: ['[CLS] that tom handsome though told, is i date. still montreal matter wouldn date him. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.977 (perp=8.223, rec=0.120, cos=0.212), tot_loss_proj:3.383 [t=0.22s]
prediction: ['[CLS] that handsome tom though told, is i date. still montreal matter wouldn date him. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.955 (perp=8.122, rec=0.117, cos=0.213), tot_loss_proj:3.146 [t=0.23s]
prediction: ['[CLS] that handsome tom though told, is i date still montreal t. wouldn date him. [SEP]']
[ 900/2000] tot_loss=1.939 (perp=8.122, rec=0.106, cos=0.209), tot_loss_proj:3.147 [t=0.22s]
prediction: ['[CLS] that handsome tom though told, is i date still montreal t. wouldn date him. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.881 (perp=7.767, rec=0.116, cos=0.212), tot_loss_proj:2.999 [t=0.23s]
prediction: ['[CLS] that handsome tom though told, is i date montreal t. wouldn still date him. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.799 (perp=7.354, rec=0.122, cos=0.206), tot_loss_proj:2.866 [t=0.22s]
prediction: ['[CLS] that handsome tom is told, though i dateoted t. wouldn still date him. [SEP]']
[1050/2000] tot_loss=1.788 (perp=7.354, rec=0.107, cos=0.210), tot_loss_proj:2.865 [t=0.22s]
prediction: ['[CLS] that handsome tom is told, though i dateoted t. wouldn still date him. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.780 (perp=7.349, rec=0.099, cos=0.211), tot_loss_proj:2.975 [t=0.22s]
prediction: ['[CLS] that handsome tom is told, though i dateoted. t wouldn still date him. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.792 (perp=7.349, rec=0.111, cos=0.212), tot_loss_proj:2.973 [t=0.22s]
prediction: ['[CLS] that handsome tom is told, though i dateoted. t wouldn still date him. [SEP]']
[1200/2000] tot_loss=1.794 (perp=7.349, rec=0.111, cos=0.213), tot_loss_proj:2.977 [t=0.22s]
prediction: ['[CLS] that handsome tom is told, though i dateoted. t wouldn still date him. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.791 (perp=7.354, rec=0.105, cos=0.215), tot_loss_proj:2.861 [t=0.29s]
prediction: ['[CLS] that handsome tom is told, though i dateoted t. wouldn still date him. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.785 (perp=7.354, rec=0.100, cos=0.215), tot_loss_proj:2.864 [t=0.22s]
prediction: ['[CLS] that handsome tom is told, though i dateoted t. wouldn still date him. [SEP]']
[1350/2000] tot_loss=1.798 (perp=7.354, rec=0.113, cos=0.215), tot_loss_proj:2.869 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i dateoted t. wouldn still date him. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.787 (perp=7.349, rec=0.105, cos=0.213), tot_loss_proj:2.970 [t=0.22s]
prediction: ['[CLS] that handsome tom is told, though i dateoted. t wouldn still date him. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.786 (perp=7.349, rec=0.103, cos=0.213), tot_loss_proj:2.971 [t=0.22s]
prediction: ['[CLS] that handsome tom is told, though i dateoted. t wouldn still date him. [SEP]']
[1500/2000] tot_loss=1.795 (perp=7.349, rec=0.111, cos=0.214), tot_loss_proj:2.973 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i dateoted. t wouldn still date him. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.787 (perp=7.349, rec=0.102, cos=0.214), tot_loss_proj:2.972 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i dateoted. t wouldn still date him. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.788 (perp=7.337, rec=0.106, cos=0.215), tot_loss_proj:2.988 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i date montreal. t wouldn still date him. [SEP]']
[1650/2000] tot_loss=1.777 (perp=7.337, rec=0.094, cos=0.215), tot_loss_proj:2.990 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i date montreal. t wouldn still date him. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.781 (perp=7.337, rec=0.098, cos=0.215), tot_loss_proj:2.991 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i date montreal. t wouldn still date him. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.756 (perp=7.197, rec=0.098, cos=0.219), tot_loss_proj:2.845 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i date montreal t. wouldn still date him. [SEP]']
[1800/2000] tot_loss=1.758 (perp=7.197, rec=0.101, cos=0.218), tot_loss_proj:2.847 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i date montreal t. wouldn still date him. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.758 (perp=7.197, rec=0.101, cos=0.218), tot_loss_proj:2.843 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i date montreal t. wouldn still date him. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.763 (perp=7.197, rec=0.105, cos=0.218), tot_loss_proj:2.843 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i date montreal t. wouldn still date him. [SEP]']
[1950/2000] tot_loss=1.763 (perp=7.197, rec=0.106, cos=0.218), tot_loss_proj:2.845 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i date montreal t. wouldn still date him. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.753 (perp=7.197, rec=0.096, cos=0.218), tot_loss_proj:2.839 [t=0.23s]
prediction: ['[CLS] that handsome tom is told, though i date montreal t. wouldn still date him. [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] handsome though they told me that tom is, i still won't date him. [SEP]
========================
predicted: 
========================
[CLS] that handsome tom is told, though i date montreal t. wouldn still date him. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.250 | p: 81.250 | r: 81.250
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 56.250 | p: 56.250 | r: 56.250
rougeLsum  | fm: 56.250 | p: 56.250 | r: 56.250
r1fm+r2fm = 101.250

[Aggregate metrics]:
rouge1     | fm: 87.230 | p: 86.731 | r: 87.963
rouge2     | fm: 51.272 | p: 50.834 | r: 51.850
rougeL     | fm: 76.761 | p: 76.328 | r: 77.399
rougeLsum  | fm: 76.817 | p: 76.372 | r: 77.403
r1fm+r2fm = 138.502

input #89 time: 0:08:57 | total time: 13:39:11


Running input #90 of 100.
reference: 
========================
Moya's football team loved her
========================
average of cosine similarity 0.8872285918943301
highest_index [0]
highest [0.8872285918943301]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9587, 3148, 1005, 1055, 2374, 2136, 3866, 2014,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] moya's football team loved her [SEP]"]
[Init] best rec loss: 0.7810322642326355 for ['[CLS]rra person gasp shit rex become snow dunn [SEP]']
[Init] best rec loss: 0.7666210532188416 for ['[CLS] scout deputy these above judge broadcastash touring [SEP]']
[Init] best rec loss: 0.7440263032913208 for ['[CLS] roman oclc consultantjust countrieslic relief kam [SEP]']
[Init] best perm rec loss: 0.7386955618858337 for ['[CLS] kam consultantjust relieflic oclc countries roman [SEP]']
[Init] best perm rec loss: 0.7363161444664001 for ['[CLS] relief roman oclcjust consultantlic kam countries [SEP]']
[Init] best perm rec loss: 0.7316587567329407 for ['[CLS] relieflic kam countries consultant oclcjust roman [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.926 (perp=11.182, rec=0.423, cos=0.266), tot_loss_proj:3.920 [t=0.22s]
prediction: ['[CLS] moya mo championshipya when dolphins productions [SEP]']
[ 100/2000] tot_loss=2.560 (perp=10.504, rec=0.249, cos=0.211), tot_loss_proj:3.699 [t=0.22s]
prediction: ['[CLS] moya mo football mo his dolphins pictures [SEP]']
[ 150/2000] tot_loss=2.623 (perp=11.365, rec=0.160, cos=0.190), tot_loss_proj:4.189 [t=0.22s]
prediction: ['[CLS] moya she football mo s football knew [SEP]']
[ 200/2000] tot_loss=2.595 (perp=11.194, rec=0.164, cos=0.192), tot_loss_proj:4.155 [t=0.22s]
prediction: ['[CLS] moya she football mo s football loved [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.156 (perp=9.073, rec=0.140, cos=0.201), tot_loss_proj:3.624 [t=0.22s]
prediction: ['[CLS] mo moya her team s team loved [SEP]']
[ 300/2000] tot_loss=2.370 (perp=10.269, rec=0.124, cos=0.193), tot_loss_proj:3.849 [t=0.22s]
prediction: ['[CLS] mo moya her football s team loved [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.169 (perp=9.331, rec=0.100, cos=0.203), tot_loss_proj:3.676 [t=0.22s]
prediction: ['[CLS] mo moya her s football team loved [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.107 (perp=9.062, rec=0.090, cos=0.204), tot_loss_proj:2.948 [t=0.22s]
prediction: ['[CLS] mo moya s football team loved her [SEP]']
[ 450/2000] tot_loss=2.117 (perp=9.062, rec=0.113, cos=0.192), tot_loss_proj:2.946 [t=0.22s]
prediction: ['[CLS] mo moya s football team loved her [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.040 (perp=8.826, rec=0.069, cos=0.206), tot_loss_proj:3.373 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.037 (perp=8.826, rec=0.081, cos=0.191), tot_loss_proj:3.355 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
[ 600/2000] tot_loss=2.063 (perp=8.826, rec=0.100, cos=0.198), tot_loss_proj:3.358 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.067 (perp=8.826, rec=0.098, cos=0.204), tot_loss_proj:3.349 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.057 (perp=8.826, rec=0.085, cos=0.206), tot_loss_proj:3.341 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
[ 750/2000] tot_loss=2.062 (perp=8.826, rec=0.089, cos=0.208), tot_loss_proj:3.341 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.055 (perp=8.826, rec=0.080, cos=0.210), tot_loss_proj:3.334 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.058 (perp=8.826, rec=0.079, cos=0.214), tot_loss_proj:3.335 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
[ 900/2000] tot_loss=2.074 (perp=8.826, rec=0.092, cos=0.217), tot_loss_proj:3.328 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.057 (perp=8.826, rec=0.088, cos=0.204), tot_loss_proj:3.441 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1000/2000] tot_loss=2.051 (perp=8.826, rec=0.077, cos=0.209), tot_loss_proj:3.440 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
[1050/2000] tot_loss=2.042 (perp=8.826, rec=0.071, cos=0.206), tot_loss_proj:3.436 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1100/2000] tot_loss=2.054 (perp=8.826, rec=0.090, cos=0.198), tot_loss_proj:3.440 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1150/2000] tot_loss=2.066 (perp=8.826, rec=0.096, cos=0.205), tot_loss_proj:3.436 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
[1200/2000] tot_loss=2.053 (perp=8.826, rec=0.079, cos=0.208), tot_loss_proj:3.439 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1250/2000] tot_loss=2.048 (perp=8.826, rec=0.073, cos=0.210), tot_loss_proj:3.437 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1300/2000] tot_loss=2.047 (perp=8.826, rec=0.071, cos=0.211), tot_loss_proj:3.439 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
[1350/2000] tot_loss=2.062 (perp=8.826, rec=0.086, cos=0.210), tot_loss_proj:3.440 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1400/2000] tot_loss=2.042 (perp=8.826, rec=0.069, cos=0.208), tot_loss_proj:3.437 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1450/2000] tot_loss=2.052 (perp=8.826, rec=0.077, cos=0.210), tot_loss_proj:3.439 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
[1500/2000] tot_loss=2.046 (perp=8.826, rec=0.072, cos=0.209), tot_loss_proj:3.435 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1550/2000] tot_loss=2.031 (perp=8.826, rec=0.057, cos=0.209), tot_loss_proj:3.433 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1600/2000] tot_loss=2.039 (perp=8.826, rec=0.065, cos=0.209), tot_loss_proj:3.442 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
[1650/2000] tot_loss=2.049 (perp=8.826, rec=0.074, cos=0.209), tot_loss_proj:3.439 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1700/2000] tot_loss=2.039 (perp=8.826, rec=0.066, cos=0.208), tot_loss_proj:3.441 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1750/2000] tot_loss=2.037 (perp=8.826, rec=0.063, cos=0.208), tot_loss_proj:3.435 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
[1800/2000] tot_loss=2.041 (perp=8.826, rec=0.066, cos=0.209), tot_loss_proj:3.437 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1850/2000] tot_loss=2.035 (perp=8.826, rec=0.060, cos=0.209), tot_loss_proj:3.438 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[1900/2000] tot_loss=2.036 (perp=8.826, rec=0.062, cos=0.209), tot_loss_proj:3.439 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
[1950/2000] tot_loss=2.055 (perp=8.826, rec=0.081, cos=0.209), tot_loss_proj:3.441 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Attempt swap
[2000/2000] tot_loss=2.047 (perp=8.826, rec=0.073, cos=0.209), tot_loss_proj:3.440 [t=0.22s]
prediction: ['[CLS] moya mo s football team loved her [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] moya's football team loved her [SEP]
========================
predicted: 
========================
[CLS] moya mo s football team loved her [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 80.000 | p: 75.000 | r: 85.714
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 174.118

[Aggregate metrics]:
rouge1     | fm: 87.321 | p: 86.749 | r: 88.154
rouge2     | fm: 51.358 | p: 50.860 | r: 52.000
rougeL     | fm: 76.973 | p: 76.448 | r: 77.655
rougeLsum  | fm: 76.955 | p: 76.500 | r: 77.650
r1fm+r2fm = 138.678

input #90 time: 0:08:51 | total time: 13:48:03


Running input #91 of 100.
reference: 
========================
They investigated the problem.
========================
average of cosine similarity 0.8903232663472299
highest_index [0]
highest [0.8903232663472299]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2027, 10847,  1996,  3291,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] they investigated the problem. [SEP]']
[Init] best rec loss: 0.8853977918624878 for ['[CLS] non trap brackets opposite mbe [SEP]']
[Init] best rec loss: 0.8834425210952759 for ['[CLS] sincerely might bart presidential after [SEP]']
[Init] best rec loss: 0.882212221622467 for ['[CLS] imposeduf medal showed name [SEP]']
[Init] best rec loss: 0.8797377347946167 for ['[CLS] sasha branches exercisesher zip [SEP]']
[Init] best rec loss: 0.8369323015213013 for ['[CLS]w czech real mrference [SEP]']
[Init] best perm rec loss: 0.8362596035003662 for ['[CLS] realferencew mr czech [SEP]']
[Init] best perm rec loss: 0.8355721831321716 for ['[CLS] czechference realw mr [SEP]']
[Init] best perm rec loss: 0.833217978477478 for ['[CLS] czechwference mr real [SEP]']
[Init] best perm rec loss: 0.8319283127784729 for ['[CLS]ference czech mr realw [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.151 (perp=12.775, rec=0.380, cos=0.217), tot_loss_proj:4.373 [t=0.23s]
prediction: ['[CLS] inter investigated problem candidatesoh [SEP]']
[ 100/2000] tot_loss=2.274 (perp=8.897, rec=0.290, cos=0.204), tot_loss_proj:3.566 [t=0.23s]
prediction: ['[CLS] they investigated casualties tried. [SEP]']
[ 150/2000] tot_loss=2.141 (perp=8.855, rec=0.162, cos=0.208), tot_loss_proj:3.546 [t=0.23s]
prediction: ['[CLS] they investigated problem investigated. [SEP]']
[ 200/2000] tot_loss=2.079 (perp=8.889, rec=0.097, cos=0.205), tot_loss_proj:3.606 [t=0.23s]
prediction: ['[CLS] they investigated problem the. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.223 (perp=4.684, rec=0.082, cos=0.205), tot_loss_proj:1.306 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[ 300/2000] tot_loss=1.218 (perp=4.684, rec=0.077, cos=0.204), tot_loss_proj:1.305 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.220 (perp=4.684, rec=0.076, cos=0.206), tot_loss_proj:1.311 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.207 (perp=4.684, rec=0.064, cos=0.206), tot_loss_proj:1.315 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[ 450/2000] tot_loss=1.209 (perp=4.684, rec=0.065, cos=0.207), tot_loss_proj:1.321 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.195 (perp=4.684, rec=0.057, cos=0.201), tot_loss_proj:1.313 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.222 (perp=4.684, rec=0.080, cos=0.206), tot_loss_proj:1.313 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[ 600/2000] tot_loss=1.220 (perp=4.684, rec=0.079, cos=0.204), tot_loss_proj:1.312 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.206 (perp=4.684, rec=0.062, cos=0.207), tot_loss_proj:1.315 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.206 (perp=4.684, rec=0.064, cos=0.205), tot_loss_proj:1.315 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[ 750/2000] tot_loss=1.210 (perp=4.684, rec=0.067, cos=0.206), tot_loss_proj:1.315 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.212 (perp=4.684, rec=0.069, cos=0.206), tot_loss_proj:1.315 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.210 (perp=4.684, rec=0.067, cos=0.206), tot_loss_proj:1.313 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[ 900/2000] tot_loss=1.206 (perp=4.684, rec=0.064, cos=0.205), tot_loss_proj:1.305 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.206 (perp=4.684, rec=0.062, cos=0.207), tot_loss_proj:1.311 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.197 (perp=4.684, rec=0.055, cos=0.206), tot_loss_proj:1.323 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1050/2000] tot_loss=1.207 (perp=4.684, rec=0.064, cos=0.205), tot_loss_proj:1.317 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.201 (perp=4.684, rec=0.058, cos=0.207), tot_loss_proj:1.311 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.220 (perp=4.684, rec=0.076, cos=0.207), tot_loss_proj:1.311 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1200/2000] tot_loss=1.209 (perp=4.684, rec=0.066, cos=0.207), tot_loss_proj:1.311 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.205 (perp=4.684, rec=0.062, cos=0.207), tot_loss_proj:1.314 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.212 (perp=4.684, rec=0.069, cos=0.206), tot_loss_proj:1.315 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1350/2000] tot_loss=1.212 (perp=4.684, rec=0.068, cos=0.206), tot_loss_proj:1.322 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.211 (perp=4.684, rec=0.068, cos=0.206), tot_loss_proj:1.316 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.203 (perp=4.684, rec=0.060, cos=0.206), tot_loss_proj:1.310 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1500/2000] tot_loss=1.211 (perp=4.684, rec=0.067, cos=0.207), tot_loss_proj:1.309 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.210 (perp=4.684, rec=0.066, cos=0.206), tot_loss_proj:1.312 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.208 (perp=4.684, rec=0.064, cos=0.207), tot_loss_proj:1.318 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1650/2000] tot_loss=1.212 (perp=4.684, rec=0.069, cos=0.206), tot_loss_proj:1.308 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.211 (perp=4.684, rec=0.067, cos=0.207), tot_loss_proj:1.319 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.203 (perp=4.684, rec=0.060, cos=0.207), tot_loss_proj:1.308 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1800/2000] tot_loss=1.201 (perp=4.684, rec=0.058, cos=0.207), tot_loss_proj:1.323 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.210 (perp=4.684, rec=0.067, cos=0.207), tot_loss_proj:1.318 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.211 (perp=4.684, rec=0.068, cos=0.207), tot_loss_proj:1.319 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1950/2000] tot_loss=1.203 (perp=4.684, rec=0.059, cos=0.206), tot_loss_proj:1.322 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.210 (perp=4.684, rec=0.066, cos=0.207), tot_loss_proj:1.320 [t=0.23s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] they investigated the problem. [SEP]
========================
predicted: 
========================
[CLS] they investigated the problem. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.401 | p: 86.890 | r: 88.214
rouge2     | fm: 52.011 | p: 51.501 | r: 52.557
rougeL     | fm: 77.166 | p: 76.682 | r: 77.834
rougeLsum  | fm: 77.216 | p: 76.684 | r: 77.870
r1fm+r2fm = 139.412

input #91 time: 0:09:08 | total time: 13:57:12


Running input #92 of 100.
reference: 
========================
Andy promised that we would go.
========================
average of cosine similarity 0.8551642701142317
highest_index [0]
highest [0.8551642701142317]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 5557, 5763, 2008, 2057, 2052, 2175, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] andy promised that we would go. [SEP]']
[Init] best rec loss: 0.8721723556518555 for ['[CLS] church shade features forwardlateral one ⟨ [SEP]']
[Init] best rec loss: 0.8502882719039917 for ['[CLS] new being hurdleskell telephone seat thus [SEP]']
[Init] best rec loss: 0.8370367884635925 for ['[CLS] holding $ proximity ground torture universe maria [SEP]']
[Init] best perm rec loss: 0.833992600440979 for ['[CLS] torture $ proximity maria ground holding universe [SEP]']
[Init] best perm rec loss: 0.8332158327102661 for ['[CLS] $ holding torture ground proximity maria universe [SEP]']
[Init] best perm rec loss: 0.8307299613952637 for ['[CLS] proximity holding ground $ maria torture universe [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.633 (perp=10.273, rec=0.322, cos=0.257), tot_loss_proj:3.800 [t=0.23s]
prediction: ['[CLS] andy andy promised mechanical, magic cookies [SEP]']
[ 100/2000] tot_loss=1.913 (perp=7.481, rec=0.152, cos=0.264), tot_loss_proj:2.713 [t=0.23s]
prediction: ['[CLS] andy andy promised that we would go [SEP]']
[ 150/2000] tot_loss=1.854 (perp=7.481, rec=0.091, cos=0.267), tot_loss_proj:2.710 [t=0.23s]
prediction: ['[CLS] andy andy promised that we would go [SEP]']
[ 200/2000] tot_loss=1.839 (perp=7.481, rec=0.086, cos=0.257), tot_loss_proj:2.703 [t=0.23s]
prediction: ['[CLS] andy andy promised that we would go [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.835 (perp=6.774, rec=0.220, cos=0.260), tot_loss_proj:2.011 [t=0.23s]
prediction: ['[CLS] andy promised andy that we would go [SEP]']
[ 300/2000] tot_loss=1.858 (perp=7.420, rec=0.114, cos=0.260), tot_loss_proj:2.720 [t=0.23s]
prediction: ['[CLS] andy promised. that we would go [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.532 (perp=5.852, rec=0.101, cos=0.260), tot_loss_proj:1.621 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.514 (perp=5.852, rec=0.083, cos=0.261), tot_loss_proj:1.614 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[ 450/2000] tot_loss=1.515 (perp=5.852, rec=0.083, cos=0.261), tot_loss_proj:1.625 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.520 (perp=5.852, rec=0.088, cos=0.261), tot_loss_proj:1.634 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.511 (perp=5.852, rec=0.082, cos=0.259), tot_loss_proj:1.626 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[ 600/2000] tot_loss=1.853 (perp=5.852, rec=0.342, cos=0.340), tot_loss_proj:1.868 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.772 (perp=5.852, rec=0.289, cos=0.313), tot_loss_proj:1.843 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.727 (perp=5.852, rec=0.257, cos=0.300), tot_loss_proj:1.803 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[ 750/2000] tot_loss=1.714 (perp=5.852, rec=0.252, cos=0.292), tot_loss_proj:1.792 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.680 (perp=5.852, rec=0.222, cos=0.287), tot_loss_proj:1.767 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.673 (perp=5.852, rec=0.219, cos=0.284), tot_loss_proj:1.758 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[ 900/2000] tot_loss=1.663 (perp=5.852, rec=0.210, cos=0.282), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.670 (perp=5.852, rec=0.219, cos=0.280), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.662 (perp=5.852, rec=0.213, cos=0.279), tot_loss_proj:1.723 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1050/2000] tot_loss=1.654 (perp=5.852, rec=0.206, cos=0.278), tot_loss_proj:1.722 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.640 (perp=5.852, rec=0.193, cos=0.277), tot_loss_proj:1.711 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.642 (perp=5.852, rec=0.196, cos=0.276), tot_loss_proj:1.707 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1200/2000] tot_loss=1.640 (perp=5.852, rec=0.195, cos=0.275), tot_loss_proj:1.711 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.635 (perp=5.852, rec=0.190, cos=0.275), tot_loss_proj:1.709 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.628 (perp=5.852, rec=0.184, cos=0.274), tot_loss_proj:1.701 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1350/2000] tot_loss=1.633 (perp=5.852, rec=0.189, cos=0.274), tot_loss_proj:1.699 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.633 (perp=5.852, rec=0.189, cos=0.273), tot_loss_proj:1.693 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.617 (perp=5.852, rec=0.174, cos=0.273), tot_loss_proj:1.695 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1500/2000] tot_loss=1.633 (perp=5.852, rec=0.190, cos=0.273), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.622 (perp=5.852, rec=0.179, cos=0.272), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.621 (perp=5.852, rec=0.178, cos=0.272), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1650/2000] tot_loss=1.618 (perp=5.852, rec=0.176, cos=0.272), tot_loss_proj:1.684 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.620 (perp=5.852, rec=0.178, cos=0.272), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.618 (perp=5.852, rec=0.176, cos=0.272), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1800/2000] tot_loss=1.628 (perp=5.852, rec=0.187, cos=0.271), tot_loss_proj:1.690 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.625 (perp=5.852, rec=0.183, cos=0.271), tot_loss_proj:1.688 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.626 (perp=5.852, rec=0.184, cos=0.271), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1950/2000] tot_loss=1.623 (perp=5.852, rec=0.181, cos=0.271), tot_loss_proj:1.689 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.626 (perp=5.852, rec=0.185, cos=0.271), tot_loss_proj:1.684 [t=0.23s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] andy promised that we would go. [SEP]
========================
predicted: 
========================
[CLS] andy andy promised that we would go [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 93.333 | p: 87.500 | r: 100.000
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 187.451

[Aggregate metrics]:
rouge1     | fm: 87.516 | p: 86.903 | r: 88.319
rouge2     | fm: 52.503 | p: 51.911 | r: 53.202
rougeL     | fm: 77.370 | p: 76.871 | r: 78.131
rougeLsum  | fm: 77.349 | p: 76.804 | r: 78.044
r1fm+r2fm = 140.018

input #92 time: 0:09:09 | total time: 14:06:22


Running input #93 of 100.
reference: 
========================
I saw these dancers and those musicians smoking something.
========================
average of cosine similarity 0.8991972851698744
highest_index [0]
highest [0.8991972851698744]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1045,  2387,  2122, 10487,  1998,  2216,  5389,  9422,  2242,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] i saw these dancers and those musicians smoking something. [SEP]']
[Init] best rec loss: 0.9063573479652405 for ['[CLS] choir torque titled uttar 25 tell even hitch encounter choosing [SEP]']
[Init] best rec loss: 0.8854112029075623 for ['[CLS] version ltd blur ringinghs chip astro bandrized federal [SEP]']
[Init] best rec loss: 0.8634801506996155 for ['[CLS] globe ~ titled scoredна japanese lynne they hardly lucas [SEP]']
[Init] best rec loss: 0.8510810136795044 for ['[CLS] existing ten exposurekti understandvirus beyond appear cubs planted [SEP]']
[Init] best rec loss: 0.8358385562896729 for ['[CLS] detectiverock standard 6 loftccuary prohibits past depth [SEP]']
[Init] best rec loss: 0.8181104063987732 for ['[CLS] upward sexes representatives compositionenityodon unopposed standingrice march [SEP]']
[Init] best rec loss: 0.8174564242362976 for ['[CLS] sound fleepol perspectivetsonvie diamond rhode roles " [SEP]']
[Init] best rec loss: 0.8032276630401611 for ['[CLS] young equal proximity someone table story tu dalton express♭ [SEP]']
[Init] best rec loss: 0.7922091484069824 for ['[CLS] owned wing numberseng panic pot nba consists graphics zone [SEP]']
[Init] best perm rec loss: 0.7904267907142639 for ['[CLS]eng wing numbers pot panic graphics nba owned consists zone [SEP]']
[Init] best perm rec loss: 0.7903069257736206 for ['[CLS] zone nba pot owned wingeng numbers consists graphics panic [SEP]']
[Init] best perm rec loss: 0.787432074546814 for ['[CLS] nba consists zone graphics wing numbers owned panic poteng [SEP]']
[Init] best perm rec loss: 0.7861034274101257 for ['[CLS] pot zone consistseng nba graphics numbers owned panic wing [SEP]']
[Init] best perm rec loss: 0.7806811332702637 for ['[CLS] panic wing zoneeng consists graphics numbers owned nba pot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.727 (perp=10.970, rec=0.361, cos=0.172), tot_loss_proj:3.964 [t=0.22s]
prediction: ['[CLS] sleep feltnging? spectra that musicians domestic. performing [SEP]']
[ 100/2000] tot_loss=2.287 (perp=9.357, rec=0.253, cos=0.163), tot_loss_proj:3.655 [t=0.22s]
prediction: ['[CLS] anything saw musicians and those those musicians hostage these smoking [SEP]']
[ 150/2000] tot_loss=2.151 (perp=8.995, rec=0.165, cos=0.187), tot_loss_proj:3.562 [t=0.22s]
prediction: ['[CLS] i saw dancers and these those musicianstropical something smoking [SEP]']
[ 200/2000] tot_loss=2.125 (perp=8.995, rec=0.138, cos=0.188), tot_loss_proj:3.560 [t=0.22s]
prediction: ['[CLS] i saw dancers and these those musicianstropical something smoking [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.981 (perp=8.366, rec=0.118, cos=0.190), tot_loss_proj:3.403 [t=0.22s]
prediction: ['[CLS] i saw dancers and these those musiciansgenic smoking something [SEP]']
[ 300/2000] tot_loss=2.039 (perp=8.772, rec=0.103, cos=0.181), tot_loss_proj:3.492 [t=0.22s]
prediction: ['[CLS] i saw dancers and these those musicianstypic smoking something [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.807 (perp=7.661, rec=0.092, cos=0.183), tot_loss_proj:3.247 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians♥ smoking something [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.746 (perp=7.292, rec=0.097, cos=0.190), tot_loss_proj:2.263 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
[ 450/2000] tot_loss=1.739 (perp=7.292, rec=0.091, cos=0.190), tot_loss_proj:2.274 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.738 (perp=7.292, rec=0.089, cos=0.190), tot_loss_proj:2.281 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.730 (perp=7.292, rec=0.085, cos=0.187), tot_loss_proj:2.278 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
[ 600/2000] tot_loss=1.738 (perp=7.292, rec=0.091, cos=0.189), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.737 (perp=7.292, rec=0.088, cos=0.190), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.729 (perp=7.292, rec=0.087, cos=0.184), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
[ 750/2000] tot_loss=1.732 (perp=7.292, rec=0.085, cos=0.188), tot_loss_proj:2.295 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.737 (perp=7.292, rec=0.093, cos=0.185), tot_loss_proj:2.298 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.727 (perp=7.292, rec=0.075, cos=0.193), tot_loss_proj:2.302 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
[ 900/2000] tot_loss=1.738 (perp=7.292, rec=0.090, cos=0.189), tot_loss_proj:2.295 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.734 (perp=7.292, rec=0.085, cos=0.190), tot_loss_proj:2.301 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingtypic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.700 (perp=7.151, rec=0.079, cos=0.191), tot_loss_proj:1.866 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking something pediatric [SEP]']
[1050/2000] tot_loss=1.702 (perp=7.151, rec=0.084, cos=0.188), tot_loss_proj:1.854 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking something pediatric [SEP]']
Attempt swap
[1100/2000] tot_loss=1.705 (perp=7.151, rec=0.083, cos=0.192), tot_loss_proj:1.867 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking something pediatric [SEP]']
Attempt swap
[1150/2000] tot_loss=1.728 (perp=7.259, rec=0.086, cos=0.189), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingsburg [SEP]']
[1200/2000] tot_loss=1.714 (perp=7.259, rec=0.071, cos=0.191), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingsburg [SEP]']
Attempt swap
[1250/2000] tot_loss=1.725 (perp=7.259, rec=0.082, cos=0.191), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingsburg [SEP]']
Attempt swap
[1300/2000] tot_loss=1.728 (perp=7.259, rec=0.087, cos=0.189), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingsburg [SEP]']
[1350/2000] tot_loss=1.729 (perp=7.259, rec=0.087, cos=0.191), tot_loss_proj:2.513 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingsburg [SEP]']
Attempt swap
[1400/2000] tot_loss=1.731 (perp=7.259, rec=0.088, cos=0.192), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingsburg [SEP]']
Attempt swap
[1450/2000] tot_loss=1.729 (perp=7.259, rec=0.086, cos=0.191), tot_loss_proj:2.508 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingsburg [SEP]']
[1500/2000] tot_loss=1.734 (perp=7.259, rec=0.093, cos=0.190), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingsburg [SEP]']
Attempt swap
[1550/2000] tot_loss=1.724 (perp=7.259, rec=0.081, cos=0.191), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingsburg [SEP]']
Attempt swap
[1600/2000] tot_loss=1.730 (perp=7.259, rec=0.087, cos=0.191), tot_loss_proj:2.507 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingsburg [SEP]']
[1650/2000] tot_loss=1.726 (perp=7.259, rec=0.083, cos=0.192), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking somethingsburg [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.827 (perp=7.725, rec=0.092, cos=0.190), tot_loss_proj:3.244 [t=0.22s]
prediction: ['[CLS] i saw these dancers pediatric and those musicians smoking something [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.710 (perp=7.151, rec=0.092, cos=0.188), tot_loss_proj:1.867 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking something pediatric [SEP]']
[1800/2000] tot_loss=1.707 (perp=7.151, rec=0.086, cos=0.190), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking something pediatric [SEP]']
Attempt swap
[1850/2000] tot_loss=1.708 (perp=7.151, rec=0.087, cos=0.191), tot_loss_proj:1.857 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking something pediatric [SEP]']
Attempt swap
[1900/2000] tot_loss=1.704 (perp=7.151, rec=0.082, cos=0.191), tot_loss_proj:1.863 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking something pediatric [SEP]']
[1950/2000] tot_loss=1.707 (perp=7.151, rec=0.087, cos=0.190), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking something pediatric [SEP]']
Attempt swap
[2000/2000] tot_loss=1.707 (perp=7.151, rec=0.086, cos=0.191), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] i saw these dancers and those musicians smoking something pediatric [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] i saw these dancers and those musicians smoking something. [SEP]
========================
predicted: 
========================
[CLS] i saw these dancers and those musicians smoking something pediatric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 85.714 | p: 81.818 | r: 90.000
rougeL     | fm: 95.652 | p: 91.667 | r: 100.000
rougeLsum  | fm: 95.652 | p: 91.667 | r: 100.000
r1fm+r2fm = 181.366

[Aggregate metrics]:
rouge1     | fm: 87.570 | p: 86.953 | r: 88.443
rouge2     | fm: 52.831 | p: 52.253 | r: 53.589
rougeL     | fm: 77.653 | p: 77.063 | r: 78.351
rougeLsum  | fm: 77.565 | p: 76.984 | r: 78.334
r1fm+r2fm = 140.401

input #93 time: 0:08:47 | total time: 14:15:09


Running input #94 of 100.
reference: 
========================
Ayala sent back her cousin the diamond necklace.
========================
average of cosine similarity 0.8929857708445801
highest_index [0]
highest [0.8929857708445801]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  2067,  2014,  5542,  1996,  6323, 13016,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ayala sent back her cousin the diamond necklace. [SEP]']
[Init] best rec loss: 0.8021641969680786 for ['[CLS] universe car flight volume stem? fangs naturally port produced [SEP]']
[Init] best rec loss: 0.7666710615158081 for ['[CLS] c2 guysament means tucker indicated corresponding likes instead shifters [SEP]']
[Init] best rec loss: 0.7542802095413208 for ['[CLS] nina weights micah economy ladyaciesffled feeling harbor mt [SEP]']
[Init] best rec loss: 0.7472280859947205 for ['[CLS] la [SEP] today hong anna metropolitan matched sized tour sprint [SEP]']
[Init] best rec loss: 0.7443976402282715 for ['[CLS] boundaries vice notion ref eachographicstered parentheses bay instead [SEP]']
[Init] best rec loss: 0.7223623394966125 for ['[CLS] consecutive [MASK] brother safe grows collect janeiroably e produced [SEP]']
[Init] best rec loss: 0.7207919359207153 for ['[CLS] innocent lieu winkelialachaltica prey applications heardool [SEP]']
[Init] best rec loss: 0.7182946801185608 for ['[CLS] origin rama jeep writes associate dial designated every motivation sip [SEP]']
[Init] best perm rec loss: 0.7180514335632324 for ['[CLS] every writes jeep rama dial sip motivation designated origin associate [SEP]']
[Init] best perm rec loss: 0.7159776091575623 for ['[CLS] motivation associate origin designated writes rama dial jeep every sip [SEP]']
[Init] best perm rec loss: 0.7138227820396423 for ['[CLS] every associate rama designated origin dial jeep motivation writes sip [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.978 (perp=11.808, rec=0.403, cos=0.213), tot_loss_proj:3.514 [t=0.22s]
prediction: ['[CLS] gave sweden shelter expected cancer usa special passenger necklace protection [SEP]']
[ 100/2000] tot_loss=2.771 (perp=11.230, rec=0.295, cos=0.230), tot_loss_proj:3.850 [t=0.22s]
prediction: ['[CLS] sent back ship the niece ten diamond pba necklace necklace [SEP]']
[ 150/2000] tot_loss=2.396 (perp=10.249, rec=0.163, cos=0.183), tot_loss_proj:3.507 [t=0.22s]
prediction: ['[CLS] sent back ship the cousin the diamondyala necklace necklace [SEP]']
[ 200/2000] tot_loss=2.101 (perp=8.847, rec=0.135, cos=0.197), tot_loss_proj:2.837 [t=0.22s]
prediction: ['[CLS] sent back her the cousin the diamondyala necklace. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.894 (perp=8.028, rec=0.104, cos=0.185), tot_loss_proj:2.769 [t=0.22s]
prediction: ['[CLS] sent back her the cousin the diamond necklaceyala. [SEP]']
[ 300/2000] tot_loss=1.892 (perp=8.028, rec=0.093, cos=0.193), tot_loss_proj:2.770 [t=0.22s]
prediction: ['[CLS] sent back her the cousin the diamond necklaceyala. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.826 (perp=7.781, rec=0.081, cos=0.189), tot_loss_proj:2.942 [t=0.22s]
prediction: ['[CLS] back her sent the cousin the diamond necklaceyala. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.792 (perp=7.625, rec=0.072, cos=0.196), tot_loss_proj:2.860 [t=0.22s]
prediction: ['[CLS] back her sent the cousin a diamond necklace.yala [SEP]']
[ 450/2000] tot_loss=1.799 (perp=7.625, rec=0.078, cos=0.196), tot_loss_proj:2.866 [t=0.22s]
prediction: ['[CLS] back her sent the cousin a diamond necklace.yala [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.431 (perp=10.165, rec=0.205, cos=0.192), tot_loss_proj:3.247 [t=0.22s]
prediction: ['[CLS] her back sent the cousin nut diamond necklace.yala [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.248 (perp=9.546, rec=0.144, cos=0.195), tot_loss_proj:3.046 [t=0.22s]
prediction: ['[CLS] her back sent the sha cousin diamond necklace.yala [SEP]']
[ 600/2000] tot_loss=2.217 (perp=9.422, rec=0.135, cos=0.198), tot_loss_proj:3.127 [t=0.22s]
prediction: ['[CLS] her back sent the voice cousin diamond necklace.yala [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.909 (perp=7.962, rec=0.119, cos=0.198), tot_loss_proj:2.649 [t=0.22s]
prediction: ["[CLS] her back sent'cousin the diamond necklace.yala [SEP]"]
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.774 (perp=7.349, rec=0.109, cos=0.195), tot_loss_proj:2.410 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
[ 750/2000] tot_loss=1.762 (perp=7.349, rec=0.100, cos=0.193), tot_loss_proj:2.417 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.761 (perp=7.349, rec=0.100, cos=0.191), tot_loss_proj:2.410 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.762 (perp=7.349, rec=0.102, cos=0.190), tot_loss_proj:2.410 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
[ 900/2000] tot_loss=1.765 (perp=7.349, rec=0.105, cos=0.190), tot_loss_proj:2.408 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.764 (perp=7.349, rec=0.104, cos=0.190), tot_loss_proj:2.407 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.747 (perp=7.349, rec=0.087, cos=0.190), tot_loss_proj:2.412 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
[1050/2000] tot_loss=1.756 (perp=7.349, rec=0.096, cos=0.190), tot_loss_proj:2.418 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.758 (perp=7.349, rec=0.098, cos=0.190), tot_loss_proj:2.417 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.753 (perp=7.349, rec=0.093, cos=0.190), tot_loss_proj:2.415 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
[1200/2000] tot_loss=1.756 (perp=7.349, rec=0.096, cos=0.190), tot_loss_proj:2.407 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.760 (perp=7.349, rec=0.100, cos=0.190), tot_loss_proj:2.417 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.751 (perp=7.349, rec=0.091, cos=0.190), tot_loss_proj:2.408 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
[1350/2000] tot_loss=1.746 (perp=7.349, rec=0.086, cos=0.190), tot_loss_proj:2.410 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.752 (perp=7.349, rec=0.091, cos=0.190), tot_loss_proj:2.408 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.744 (perp=7.349, rec=0.084, cos=0.190), tot_loss_proj:2.405 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
[1500/2000] tot_loss=1.752 (perp=7.349, rec=0.092, cos=0.190), tot_loss_proj:2.408 [t=0.22s]
prediction: ["[CLS] her back sent'cousinyala the diamond necklace. [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.700 (perp=7.075, rec=0.094, cos=0.191), tot_loss_proj:2.602 [t=0.22s]
prediction: ["[CLS]'back sent her cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.694 (perp=7.075, rec=0.089, cos=0.189), tot_loss_proj:2.604 [t=0.22s]
prediction: ["[CLS]'back sent her cousinyala the diamond necklace. [SEP]"]
[1650/2000] tot_loss=1.697 (perp=7.075, rec=0.092, cos=0.190), tot_loss_proj:2.600 [t=0.22s]
prediction: ["[CLS]'back sent her cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.691 (perp=7.075, rec=0.086, cos=0.190), tot_loss_proj:2.602 [t=0.22s]
prediction: ["[CLS]'back sent her cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.696 (perp=7.075, rec=0.090, cos=0.190), tot_loss_proj:2.605 [t=0.22s]
prediction: ["[CLS]'back sent her cousinyala the diamond necklace. [SEP]"]
[1800/2000] tot_loss=1.695 (perp=7.075, rec=0.089, cos=0.190), tot_loss_proj:2.601 [t=0.22s]
prediction: ["[CLS]'back sent her cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.689 (perp=7.075, rec=0.084, cos=0.190), tot_loss_proj:2.595 [t=0.22s]
prediction: ["[CLS]'back sent her cousinyala the diamond necklace. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.691 (perp=7.075, rec=0.085, cos=0.190), tot_loss_proj:2.600 [t=0.22s]
prediction: ["[CLS]'back sent her cousinyala the diamond necklace. [SEP]"]
[1950/2000] tot_loss=1.692 (perp=7.075, rec=0.087, cos=0.190), tot_loss_proj:2.600 [t=0.22s]
prediction: ["[CLS]'back sent her cousinyala the diamond necklace. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.693 (perp=7.075, rec=0.087, cos=0.190), tot_loss_proj:2.603 [t=0.22s]
prediction: ["[CLS]'back sent her cousinyala the diamond necklace. [SEP]"]
Done with input #94 of 100.
reference: 
========================
[CLS] ayala sent back her cousin the diamond necklace. [SEP]
========================
predicted: 
========================
[CLS] back her sent the cousin a diamond necklace.yala [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 21.053 | p: 20.000 | r: 22.222
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 106.767

[Aggregate metrics]:
rouge1     | fm: 87.602 | p: 86.916 | r: 88.485
rouge2     | fm: 52.428 | p: 51.758 | r: 53.198
rougeL     | fm: 77.466 | p: 76.865 | r: 78.311
rougeLsum  | fm: 77.462 | p: 76.851 | r: 78.306
r1fm+r2fm = 140.030

input #94 time: 0:08:47 | total time: 14:23:56


Running input #95 of 100.
reference: 
========================
Brenda met.
========================
average of cosine similarity 0.8940064911254998
highest_index [0]
highest [0.8940064911254998]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15507,  2777,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] brenda met. [SEP]']
[Init] best rec loss: 0.8805766105651855 for ['[CLS]eptive day less [SEP]']
[Init] best rec loss: 0.7674996852874756 for ['[CLS]fall few why [SEP]']
[Init] best rec loss: 0.766892671585083 for ['[CLS] princess horses domesday [SEP]']
[Init] best rec loss: 0.7591327428817749 for ['[CLS] si indefinite nixon [SEP]']
[Init] best rec loss: 0.7499023079872131 for ['[CLS]ave recorded head [SEP]']
[Init] best rec loss: 0.7092795968055725 for ['[CLS] boss back michigan [SEP]']
[Init] best rec loss: 0.7033107876777649 for ['[CLS] mary scott pending [SEP]']
[Init] best perm rec loss: 0.7010019421577454 for ['[CLS] scott mary pending [SEP]']
[Init] best perm rec loss: 0.7000682950019836 for ['[CLS] pending scott mary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.119 (perp=8.388, rec=0.248, cos=0.193), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] caleb met. [SEP]']
[ 100/2000] tot_loss=1.797 (perp=7.452, rec=0.106, cos=0.201), tot_loss_proj:1.764 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[ 150/2000] tot_loss=1.763 (perp=7.452, rec=0.074, cos=0.199), tot_loss_proj:1.766 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[ 200/2000] tot_loss=1.763 (perp=7.452, rec=0.073, cos=0.200), tot_loss_proj:1.776 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.742 (perp=7.452, rec=0.053, cos=0.199), tot_loss_proj:1.769 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[ 300/2000] tot_loss=1.760 (perp=7.452, rec=0.070, cos=0.200), tot_loss_proj:1.772 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.754 (perp=7.452, rec=0.064, cos=0.200), tot_loss_proj:1.769 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.755 (perp=7.452, rec=0.065, cos=0.200), tot_loss_proj:1.766 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[ 450/2000] tot_loss=1.748 (perp=7.452, rec=0.057, cos=0.201), tot_loss_proj:1.776 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.758 (perp=7.452, rec=0.067, cos=0.200), tot_loss_proj:1.777 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.758 (perp=7.452, rec=0.067, cos=0.201), tot_loss_proj:1.779 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[ 600/2000] tot_loss=1.756 (perp=7.452, rec=0.066, cos=0.201), tot_loss_proj:1.767 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.742 (perp=7.452, rec=0.053, cos=0.199), tot_loss_proj:1.770 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.753 (perp=7.452, rec=0.062, cos=0.201), tot_loss_proj:1.777 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[ 750/2000] tot_loss=1.751 (perp=7.452, rec=0.061, cos=0.200), tot_loss_proj:1.761 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.750 (perp=7.452, rec=0.060, cos=0.199), tot_loss_proj:1.774 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.765 (perp=7.452, rec=0.074, cos=0.200), tot_loss_proj:1.771 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[ 900/2000] tot_loss=1.750 (perp=7.452, rec=0.060, cos=0.200), tot_loss_proj:1.772 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.753 (perp=7.452, rec=0.062, cos=0.200), tot_loss_proj:1.769 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.750 (perp=7.452, rec=0.059, cos=0.200), tot_loss_proj:1.765 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[1050/2000] tot_loss=1.746 (perp=7.452, rec=0.056, cos=0.200), tot_loss_proj:1.768 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.752 (perp=7.452, rec=0.061, cos=0.201), tot_loss_proj:1.775 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.739 (perp=7.452, rec=0.049, cos=0.200), tot_loss_proj:1.774 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[1200/2000] tot_loss=1.752 (perp=7.452, rec=0.062, cos=0.200), tot_loss_proj:1.762 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.745 (perp=7.452, rec=0.054, cos=0.201), tot_loss_proj:1.771 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.761 (perp=7.452, rec=0.070, cos=0.201), tot_loss_proj:1.763 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[1350/2000] tot_loss=1.745 (perp=7.452, rec=0.054, cos=0.200), tot_loss_proj:1.772 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.754 (perp=7.452, rec=0.063, cos=0.200), tot_loss_proj:1.771 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.760 (perp=7.452, rec=0.069, cos=0.201), tot_loss_proj:1.774 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[1500/2000] tot_loss=1.754 (perp=7.452, rec=0.064, cos=0.200), tot_loss_proj:1.769 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.755 (perp=7.452, rec=0.064, cos=0.201), tot_loss_proj:1.775 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.751 (perp=7.452, rec=0.060, cos=0.201), tot_loss_proj:1.769 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[1650/2000] tot_loss=1.752 (perp=7.452, rec=0.061, cos=0.201), tot_loss_proj:1.774 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.747 (perp=7.452, rec=0.056, cos=0.201), tot_loss_proj:1.779 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.753 (perp=7.452, rec=0.062, cos=0.201), tot_loss_proj:1.768 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[1800/2000] tot_loss=1.755 (perp=7.452, rec=0.064, cos=0.201), tot_loss_proj:1.773 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.755 (perp=7.452, rec=0.064, cos=0.201), tot_loss_proj:1.773 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.754 (perp=7.452, rec=0.063, cos=0.201), tot_loss_proj:1.768 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[1950/2000] tot_loss=1.745 (perp=7.452, rec=0.054, cos=0.201), tot_loss_proj:1.758 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.749 (perp=7.452, rec=0.058, cos=0.201), tot_loss_proj:1.765 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] brenda met. [SEP]
========================
predicted: 
========================
[CLS] brenda met. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.725 | p: 87.065 | r: 88.602
rouge2     | fm: 52.830 | p: 52.231 | r: 53.557
rougeL     | fm: 77.639 | p: 77.039 | r: 78.424
rougeLsum  | fm: 77.705 | p: 77.158 | r: 78.479
r1fm+r2fm = 140.554

input #95 time: 0:09:09 | total time: 14:33:06


Running input #96 of 100.
reference: 
========================
Today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might.
========================
average of cosine similarity 0.8837065151386466
highest_index [0]
highest [0.8837065151386466]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  2651,  2045,  2003,  2210,  2030,  2053,  2880, 16011,  1997,
         11690,  2015,  1998,  5637,  2015,  2011,  1996,  2120,  2231,  1010,
          2348,  8392,  6867,  2453,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]']
[Init] best rec loss: 0.9366236925125122 for ['[CLS] typeilised exiary radha legislative spotlight latter jesse wonder passing opened church charm dropping santa authorities loan youth firm regarding 1930s border kirk [SEP]']
[Init] best rec loss: 0.9015970230102539 for ['[CLS] library could quicknco quicklylerrradoum prose biology over spencer dirty? ebony room ltd laugh fiber 」 berlin twinned joe lucas [SEP]']
[Init] best rec loss: 0.9002471566200256 for ['[CLS] period roster assured disc guess proved au column three kapoor caesar regretphyator sometimes radical patel strait below recognition lori apparatus christiangration [SEP]']
[Init] best rec loss: 0.8918902277946472 for ['[CLS] & refused ftiahpling! in eventuallyfinder leah good british funding free indexed office linux spaghetti pa complicationsrangle erasmus equipment open [SEP]']
[Init] best rec loss: 0.8869747519493103 for ['[CLS] cabinet sato stifled rodrigostone high playing minute instead hits respectively anticipation together council jane scotia frozen pi miles composite count theorychen dump [SEP]']
[Init] best rec loss: 0.8822637796401978 for ['[CLS] [MASK] function good serving champ their time really placefighter werettering hockeyester asylum blade simply stage pga by cost sensible rock mark [SEP]']
[Init] best rec loss: 0.8761774897575378 for ['[CLS] skate rhymes quartz rid ledge england a caught families essay biker music environmental point scientists mu balthazar luxurylaze curious free 12 ii volcanoes [SEP]']
[Init] best rec loss: 0.8728086948394775 for ['[CLS] elect carbonstic riding kong ton genius alphabet coastline premature darts commission id ;dropaq buenos born wear till partner din division general [SEP]']
[Init] best rec loss: 0.8641864657402039 for ['[CLS] monk overvary legislative alive war raid until boost united advice pushiculatebel islandtet including emma if crop arranged terrace bare something [SEP]']
[Init] best perm rec loss: 0.8626349568367004 for ['[CLS]tet terrace crop alive something arranged raid united monk if over legislativeiculate untilvary push war advice emma including islandbel bare boost [SEP]']
[Init] best perm rec loss: 0.8606521487236023 for ['[CLS] island boost bare united until alivetet includingbel push terrace something advice if raid war overvary emmaiculate monk crop arranged legislative [SEP]']
[Init] best perm rec loss: 0.85951828956604 for ['[CLS] over terrace something war advice arranged bare alive islandbel untilvary push emma boosticulate iftet raid legislative crop including united monk [SEP]']
[Init] best perm rec loss: 0.8591476082801819 for ['[CLS] island raid over pushtet cropbel arranged bare war something alive emma monk until advice unitediculate legislative if boostvary terrace including [SEP]']
[Init] best perm rec loss: 0.8589745759963989 for ['[CLS] aliveiculate crop raid arranged island push advicevary emma boost untilbel over terracetet united something if legislative bare including war monk [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.054 (perp=12.324, rec=0.396, cos=0.193), tot_loss_proj:4.309 [t=0.23s]
prediction: ['[CLS] instead realityidge issues renaissance breton badly regularly many axis monster sparhawk imperial frontier imperial cityginal, mightutive city northern red rann [SEP]']
[ 100/2000] tot_loss=2.871 (perp=11.875, rec=0.277, cos=0.219), tot_loss_proj:4.239 [t=0.23s]
prediction: ['[CLS] alive arrowiers issues burkina gay although regularly many royal ( harassment imperial indian witch city british. no national government northern although portugal [SEP]']
[ 150/2000] tot_loss=2.558 (perp=10.526, rec=0.242, cos=0.211), tot_loss_proj:3.946 [t=0.24s]
prediction: ['[CLS] alive arrow without somewhat lesbian lesbian although todaystein 12 is harassment national autonomous of national autonomous, although national government northern although largely [SEP]']
[ 200/2000] tot_loss=2.971 (perp=9.642, rec=0.594, cos=0.449), tot_loss_proj:3.775 [t=0.24s]
prediction: ['[CLS] culture attacksier however the lesbian usually always barbed anti subsequently harassment national to of government government of or national government opposing ·. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.591 (perp=9.911, rec=0.391, cos=0.218), tot_loss_proj:3.818 [t=0.24s]
prediction: ['[CLS] million transgender priests colonel the lesbian usually always a constantly usually harassment in to of northern government of or militant government opposing turin. [SEP]']
[ 300/2000] tot_loss=2.663 (perp=10.681, rec=0.312, cos=0.215), tot_loss_proj:3.952 [t=0.24s]
prediction: ['[CLS] culture transgenderto ins the lesbian usually always a during usually harassment da to of northern general of or independent governments opposing turin. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.658 (perp=10.829, rec=0.275, cos=0.216), tot_loss_proj:4.031 [t=0.24s]
prediction: ['[CLS] culture transgenderto ins the lesbian usually increasingly usually inter genuine harassment german to of northern general of or national governments northern lionel. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.565 (perp=9.515, rec=0.420, cos=0.242), tot_loss_proj:3.757 [t=0.24s]
prediction: ['[CLS] today says to tribes the lesbian opposing increasingly instead [SEP] legislation harassmentino to - - independent in or national governments merely giant. [SEP]']
[ 450/2000] tot_loss=2.703 (perp=10.951, rec=0.300, cos=0.213), tot_loss_proj:4.037 [t=0.24s]
prediction: ["[CLS] today says to tribesrot lesbian northern increasingly instead [SEP] snap harassmentso to'- independent in or national government merely contract. [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=2.339 (perp=9.294, rec=0.268, cos=0.212), tot_loss_proj:3.727 [t=0.24s]
prediction: ['[CLS] today transgender to tribes the lesbian northern increasingly instead [SEP] snap harassment in to - - independent in national government or merely contract. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.466 (perp=10.027, rec=0.270, cos=0.191), tot_loss_proj:3.854 [t=0.24s]
prediction: ['[CLS] today transgender tribesesots lesbian northern increasingly instead [SEP] snap harassment national to - - independent in national government or merely contract. [SEP]']
[ 600/2000] tot_loss=2.349 (perp=9.461, rec=0.248, cos=0.209), tot_loss_proj:3.743 [t=0.24s]
prediction: ['[CLS] today transgender tribeses the lesbian northern increasingly instead [SEP] snap harassment national to - - independent in national government or merely contract. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.277 (perp=9.111, rec=0.239, cos=0.215), tot_loss_proj:3.671 [t=0.24s]
prediction: ['[CLS] today transgender tribeses in lesbian northern increasingly instead [SEP] snap harassment national to - - independent the national government or merely contract. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.219 (perp=8.838, rec=0.237, cos=0.215), tot_loss_proj:3.604 [t=0.24s]
prediction: ['[CLS] today transgender republican, in lesbian northern became independent [SEP] snap harassment national to - - instead the national government or much contract. [SEP]']
[ 750/2000] tot_loss=2.229 (perp=8.942, rec=0.230, cos=0.211), tot_loss_proj:3.609 [t=0.24s]
prediction: ['[CLS] today transgender republican. in lesbian northern became independent [SEP] snap harassment national to - - instead the national government or much contract. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.235 (perp=9.011, rec=0.219, cos=0.214), tot_loss_proj:3.644 [t=0.24s]
prediction: ['[CLS] today carly republican. in lesbian national today independent [SEP] snap harassment national to - - instead the national government or much northern. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.170 (perp=8.647, rec=0.227, cos=0.213), tot_loss_proj:3.548 [t=0.24s]
prediction: ['[CLS] today carly republican. today lesbian national in independent [SEP] snap harassment national to - - instead the national government or not northern. [SEP]']
[ 900/2000] tot_loss=2.294 (perp=9.294, rec=0.219, cos=0.217), tot_loss_proj:3.673 [t=0.24s]
prediction: ['[CLS] today carly republican. today lesbian national in independent [SEP] snap harassment national to - - insteadots national government or not northern. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.278 (perp=9.226, rec=0.218, cos=0.215), tot_loss_proj:3.672 [t=0.24s]
prediction: ['[CLS] today carly republican. today lesbian national in autonomous to snap harassment national [SEP] - - insteadots national government or not northern. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.227 (perp=8.991, rec=0.216, cos=0.213), tot_loss_proj:3.617 [t=0.24s]
prediction: ['[CLS] today ா republican. today lesbian national not autonomous to snap harassment national [SEP] - - insteadots national government or in northern. [SEP]']
[1050/2000] tot_loss=2.232 (perp=8.991, rec=0.219, cos=0.215), tot_loss_proj:3.617 [t=0.24s]
prediction: ['[CLS] today ா republican. today lesbian national not autonomous to snap harassment national [SEP] - - insteadots national government or in northern. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.263 (perp=9.181, rec=0.209, cos=0.218), tot_loss_proj:3.648 [t=0.24s]
prediction: ['[CLS] today ா pageant. today lesbian national not autonomous to snap harassment national [SEP] - - insteadots national government or in northern. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.252 (perp=9.181, rec=0.200, cos=0.216), tot_loss_proj:3.650 [t=0.24s]
prediction: ['[CLS] today ா pageant. today lesbian national not autonomous to snap harassment national [SEP] - - insteadots national government or in northern. [SEP]']
[1200/2000] tot_loss=2.250 (perp=9.181, rec=0.197, cos=0.217), tot_loss_proj:3.648 [t=0.24s]
prediction: ['[CLS] today ா pageant. today lesbian national not autonomous to snap harassment national [SEP] - - insteadots national government or in northern. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.277 (perp=9.283, rec=0.204, cos=0.216), tot_loss_proj:3.677 [t=0.24s]
prediction: ['[CLS] today ா arrondissement. today lesbian national not autonomous to snap harassment national [SEP] - - insteadots national government or in northern. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.284 (perp=9.346, rec=0.198, cos=0.217), tot_loss_proj:3.671 [t=0.24s]
prediction: ['[CLS] today ா arrondissement. no lesbian national not autonomous to snap harassment national [SEP] - - insteadots national government or in northern. [SEP]']
[1350/2000] tot_loss=2.277 (perp=9.346, rec=0.192, cos=0.216), tot_loss_proj:3.675 [t=0.24s]
prediction: ['[CLS] today ா arrondissement. no lesbian national not autonomous to snap harassment national [SEP] - - insteadots national government or in northern. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.203 (perp=8.929, rec=0.206, cos=0.211), tot_loss_proj:3.587 [t=0.24s]
prediction: ['[CLS] today… autonomous arrondissement. no lesbian national not to snap harassment national [SEP] - - formalots national government or in northern. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.168 (perp=8.704, rec=0.211, cos=0.216), tot_loss_proj:3.560 [t=0.24s]
prediction: ['[CLS] today… autonomous arrondissement. no lesbian national not to snap harassment national [SEP] - - formal national government orots in northern. [SEP]']
[1500/2000] tot_loss=2.158 (perp=8.704, rec=0.201, cos=0.217), tot_loss_proj:3.558 [t=0.24s]
prediction: ['[CLS] today… autonomous arrondissement. no lesbian national not to snap harassment national [SEP] - - formal national government orots in northern. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.258 (perp=9.191, rec=0.203, cos=0.217), tot_loss_proj:3.652 [t=0.24s]
prediction: ['[CLS] today… autonomous arrondissement. no lesbian national much to snap harassment national [SEP] - - formal national government orots in northern. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.182 (perp=8.872, rec=0.192, cos=0.216), tot_loss_proj:3.590 [t=0.24s]
prediction: ['[CLS] today… autonomous arrondissement. no lesbian national to much snap harassment national [SEP] - - formal national government orots in northern. [SEP]']
[1650/2000] tot_loss=2.189 (perp=8.872, rec=0.196, cos=0.219), tot_loss_proj:3.594 [t=0.24s]
prediction: ['[CLS] today… autonomous arrondissement. no lesbian national to much snap harassment national [SEP] - - formal national government orots in northern. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.135 (perp=8.578, rec=0.202, cos=0.217), tot_loss_proj:3.531 [t=0.24s]
prediction: ['[CLS] today… autonomous arrondissement. no lesbian national to much snap harassment national [SEP] - - national government or formalots in northern. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.129 (perp=8.578, rec=0.195, cos=0.218), tot_loss_proj:3.533 [t=0.24s]
prediction: ['[CLS] today… autonomous arrondissement. no lesbian national to much snap harassment national [SEP] - - national government or formalots in northern. [SEP]']
[1800/2000] tot_loss=2.162 (perp=8.757, rec=0.193, cos=0.218), tot_loss_proj:3.563 [t=0.23s]
prediction: ['[CLS] today… autonomous arrondissement. no lesbian national to much snap harassment national [SEP] - - national government or formalots in autonomous. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.119 (perp=8.508, rec=0.200, cos=0.218), tot_loss_proj:3.511 [t=0.24s]
prediction: ['[CLS] today… in arrondissement. no lesbian national to much snap harassment national [SEP] - - national government or formalots autonomous autonomous. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.095 (perp=8.346, rec=0.207, cos=0.219), tot_loss_proj:3.469 [t=0.24s]
prediction: ['[CLS] today… in arrondissement. no lesbian national to national snap harassment national [SEP] - - much government or formalots autonomous autonomous. [SEP]']
[1950/2000] tot_loss=2.087 (perp=8.346, rec=0.200, cos=0.218), tot_loss_proj:3.468 [t=0.24s]
prediction: ['[CLS] today… in arrondissement. no lesbian national to national snap harassment national [SEP] - - much government or formalots autonomous autonomous. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.084 (perp=8.346, rec=0.196, cos=0.218), tot_loss_proj:3.470 [t=0.24s]
prediction: ['[CLS] today… in arrondissement. no lesbian national to national snap harassment national [SEP] - - much government or formalots autonomous autonomous. [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]
========================
predicted: 
========================
[CLS] today… autonomous arrondissement. no lesbian national to much snap harassment national [SEP] - - formal national government orots in northern. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 38.095 | p: 40.000 | r: 36.364
rouge2     | fm: 10.000 | p: 10.526 | r: 9.524
rougeL     | fm: 33.333 | p: 35.000 | r: 31.818
rougeLsum  | fm: 33.333 | p: 35.000 | r: 31.818
r1fm+r2fm = 48.095

[Aggregate metrics]:
rouge1     | fm: 87.288 | p: 86.629 | r: 88.066
rouge2     | fm: 52.494 | p: 51.925 | r: 53.233
rougeL     | fm: 77.258 | p: 76.739 | r: 78.042
rougeLsum  | fm: 77.343 | p: 76.790 | r: 78.101
r1fm+r2fm = 139.782

input #96 time: 0:09:17 | total time: 14:42:23


Running input #97 of 100.
reference: 
========================
This oven cooks well.
========================
average of cosine similarity 0.8595842320054691
highest_index [0]
highest [0.8595842320054691]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2023, 17428, 26929,  2092,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] this oven cooks well. [SEP]']
[Init] best rec loss: 0.9281153082847595 for ['[CLS] representing savedm ft dynasty [SEP]']
[Init] best rec loss: 0.9185729622840881 for ['[CLS] comes cord movement flat lucian [SEP]']
[Init] best rec loss: 0.9070342183113098 for ['[CLS] against sights king although any [SEP]']
[Init] best rec loss: 0.9033268690109253 for ['[CLS] [SEP] compass heractive chiefs [SEP]']
[Init] best rec loss: 0.8962343335151672 for ['[CLS] gael gearbox deserve enough air [SEP]']
[Init] best rec loss: 0.8961159586906433 for ['[CLS] high trans endfect added [SEP]']
[Init] best rec loss: 0.8941227793693542 for ['[CLS] transport depot mixed closer open [SEP]']
[Init] best perm rec loss: 0.8927863836288452 for ['[CLS] depot closer mixed open transport [SEP]']
[Init] best perm rec loss: 0.8907395005226135 for ['[CLS] open mixed transport closer depot [SEP]']
[Init] best perm rec loss: 0.8903741836547852 for ['[CLS] open depot mixed closer transport [SEP]']
[Init] best perm rec loss: 0.8896425366401672 for ['[CLS] transport open mixed depot closer [SEP]']
[Init] best perm rec loss: 0.8891284465789795 for ['[CLS] closer open mixed transport depot [SEP]']
[Init] best perm rec loss: 0.8885855674743652 for ['[CLS] open mixed closer depot transport [SEP]']
[Init] best perm rec loss: 0.8875553607940674 for ['[CLS] depot open closer mixed transport [SEP]']
[Init] best perm rec loss: 0.8862560987472534 for ['[CLS] open mixed depot closer transport [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.261 (perp=8.777, rec=0.248, cos=0.257), tot_loss_proj:3.489 [t=0.23s]
prediction: ['[CLS] this oven oven oven oven [SEP]']
[ 100/2000] tot_loss=2.295 (perp=9.568, rec=0.121, cos=0.260), tot_loss_proj:3.791 [t=0.23s]
prediction: ['[CLS] this cooks well oven oven [SEP]']
[ 150/2000] tot_loss=2.264 (perp=9.568, rec=0.091, cos=0.260), tot_loss_proj:3.787 [t=0.23s]
prediction: ['[CLS] this cooks well oven oven [SEP]']
[ 200/2000] tot_loss=2.264 (perp=9.568, rec=0.090, cos=0.260), tot_loss_proj:3.785 [t=0.23s]
prediction: ['[CLS] this cooks well oven oven [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.259 (perp=9.568, rec=0.084, cos=0.261), tot_loss_proj:3.786 [t=0.23s]
prediction: ['[CLS] this cooks well oven oven [SEP]']
[ 300/2000] tot_loss=2.252 (perp=9.568, rec=0.079, cos=0.259), tot_loss_proj:3.788 [t=0.23s]
prediction: ['[CLS] this cooks well oven oven [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.410 (perp=10.259, rec=0.097, cos=0.262), tot_loss_proj:3.968 [t=0.23s]
prediction: ['[CLS] this well cooks oven zone [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.391 (perp=10.234, rec=0.085, cos=0.259), tot_loss_proj:3.898 [t=0.23s]
prediction: ['[CLS] this well cooks crab oven [SEP]']
[ 450/2000] tot_loss=2.402 (perp=10.234, rec=0.094, cos=0.261), tot_loss_proj:3.898 [t=0.23s]
prediction: ['[CLS] this well cooks crab oven [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.270 (perp=9.627, rec=0.085, cos=0.260), tot_loss_proj:3.228 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.267 (perp=9.627, rec=0.081, cos=0.261), tot_loss_proj:3.239 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
[ 600/2000] tot_loss=2.270 (perp=9.627, rec=0.085, cos=0.260), tot_loss_proj:3.258 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.267 (perp=9.627, rec=0.082, cos=0.260), tot_loss_proj:3.268 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.277 (perp=9.627, rec=0.091, cos=0.260), tot_loss_proj:3.287 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
[ 750/2000] tot_loss=2.271 (perp=9.627, rec=0.085, cos=0.260), tot_loss_proj:3.284 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.264 (perp=9.627, rec=0.077, cos=0.261), tot_loss_proj:3.294 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.269 (perp=9.627, rec=0.083, cos=0.261), tot_loss_proj:3.300 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
[ 900/2000] tot_loss=2.265 (perp=9.627, rec=0.078, cos=0.261), tot_loss_proj:3.333 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.273 (perp=9.627, rec=0.086, cos=0.261), tot_loss_proj:3.330 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1000/2000] tot_loss=2.264 (perp=9.627, rec=0.078, cos=0.261), tot_loss_proj:3.333 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
[1050/2000] tot_loss=2.270 (perp=9.627, rec=0.084, cos=0.261), tot_loss_proj:3.338 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1100/2000] tot_loss=2.276 (perp=9.627, rec=0.089, cos=0.261), tot_loss_proj:3.353 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1150/2000] tot_loss=2.274 (perp=9.627, rec=0.087, cos=0.261), tot_loss_proj:3.366 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
[1200/2000] tot_loss=2.265 (perp=9.627, rec=0.078, cos=0.261), tot_loss_proj:3.383 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1250/2000] tot_loss=2.276 (perp=9.627, rec=0.090, cos=0.261), tot_loss_proj:3.397 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1300/2000] tot_loss=2.260 (perp=9.627, rec=0.073, cos=0.261), tot_loss_proj:3.404 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
[1350/2000] tot_loss=2.267 (perp=9.627, rec=0.081, cos=0.261), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1400/2000] tot_loss=2.283 (perp=9.627, rec=0.097, cos=0.261), tot_loss_proj:3.422 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1450/2000] tot_loss=2.264 (perp=9.627, rec=0.078, cos=0.261), tot_loss_proj:3.423 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
[1500/2000] tot_loss=2.271 (perp=9.627, rec=0.085, cos=0.261), tot_loss_proj:3.430 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1550/2000] tot_loss=2.270 (perp=9.627, rec=0.083, cos=0.261), tot_loss_proj:3.439 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1600/2000] tot_loss=2.264 (perp=9.627, rec=0.077, cos=0.261), tot_loss_proj:3.437 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
[1650/2000] tot_loss=2.261 (perp=9.627, rec=0.075, cos=0.261), tot_loss_proj:3.442 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1700/2000] tot_loss=2.272 (perp=9.627, rec=0.086, cos=0.261), tot_loss_proj:3.440 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1750/2000] tot_loss=2.273 (perp=9.627, rec=0.087, cos=0.261), tot_loss_proj:3.445 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
[1800/2000] tot_loss=2.261 (perp=9.627, rec=0.074, cos=0.261), tot_loss_proj:3.448 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1850/2000] tot_loss=2.272 (perp=9.627, rec=0.086, cos=0.261), tot_loss_proj:3.443 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[1900/2000] tot_loss=2.265 (perp=9.627, rec=0.079, cos=0.261), tot_loss_proj:3.445 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
[1950/2000] tot_loss=2.268 (perp=9.627, rec=0.081, cos=0.261), tot_loss_proj:3.443 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Attempt swap
[2000/2000] tot_loss=2.269 (perp=9.627, rec=0.082, cos=0.261), tot_loss_proj:3.439 [t=0.23s]
prediction: ['[CLS] this crab cooks well oven [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] this oven cooks well. [SEP]
========================
predicted: 
========================
[CLS] this crab cooks well oven [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 128.671

[Aggregate metrics]:
rouge1     | fm: 87.249 | p: 86.589 | r: 88.205
rouge2     | fm: 52.357 | p: 51.749 | r: 53.046
rougeL     | fm: 77.204 | p: 76.608 | r: 78.032
rougeLsum  | fm: 77.263 | p: 76.618 | r: 78.093
r1fm+r2fm = 139.606

input #97 time: 0:09:08 | total time: 14:51:32


Running input #98 of 100.
reference: 
========================
Sarah devoured the cakes in the kitchen last night.
========================
average of cosine similarity 0.8954601847297224
highest_index [0]
highest [0.8954601847297224]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  4532, 16475, 16777,  1996, 22619,  1999,  1996,  3829,  2197,
          2305,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sarah devoured the cakes in the kitchen last night. [SEP]']
[Init] best rec loss: 0.9463858604431152 for ['[CLS] socialced coordination umbrella louder require paper plank parallel hi dame [SEP]']
[Init] best rec loss: 0.9139363169670105 for ['[CLS]mission instruments overnton _ revenge touch cole palettescent die [SEP]']
[Init] best rec loss: 0.9006161093711853 for ['[CLS] professional ep contingent expedition libby like cabzio pep depends activism [SEP]']
[Init] best rec loss: 0.8977994918823242 for ['[CLS] incredibly caller daughters victory sentenced lives all loss toast web median [SEP]']
[Init] best rec loss: 0.8877995610237122 for ['[CLS] ratiopack solid tile frameworkfect examinations michigan rolled fast seasons [SEP]']
[Init] best rec loss: 0.8753899335861206 for ['[CLS] out nell castle con has referee signature ki > broke ribs [SEP]']
[Init] best perm rec loss: 0.8746858835220337 for ['[CLS] has > broke out ribs ki referee nell signature castle con [SEP]']
[Init] best perm rec loss: 0.8744450211524963 for ['[CLS] ribs broke signature referee ki out > nell castle has con [SEP]']
[Init] best perm rec loss: 0.8733820915222168 for ['[CLS] con > broke referee nell ki ribs signature out has castle [SEP]']
[Init] best perm rec loss: 0.8731289505958557 for ['[CLS] > ki nell signature has out broke castle ribs con referee [SEP]']
[Init] best perm rec loss: 0.8730818033218384 for ['[CLS] broke ki castle has signature ribs > nell out con referee [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.938 (perp=11.008, rec=0.510, cos=0.226), tot_loss_proj:3.952 [t=0.23s]
prediction: ['[CLS] sarah he cakesoped during phones phone east fridge. awards [SEP]']
[ 100/2000] tot_loss=2.866 (perp=11.169, rec=0.413, cos=0.220), tot_loss_proj:4.015 [t=0.23s]
prediction: ['[CLS] sarah ann cakes wealthiest during recently balcony east pushing. awards [SEP]']
[ 150/2000] tot_loss=2.824 (perp=11.608, rec=0.332, cos=0.171), tot_loss_proj:4.131 [t=0.23s]
prediction: ['[CLS] sarah dev cakes louisiana reality tonight breakfast awful producers. these [SEP]']
[ 200/2000] tot_loss=4.126 (perp=11.712, rec=0.937, cos=0.847), tot_loss_proj:4.107 [t=0.23s]
prediction: ['[CLS] sarah [SEP]oured keeping. yesterday elevator suddenlygingly - these [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=4.179 (perp=11.967, rec=0.910, cos=0.875), tot_loss_proj:4.149 [t=0.23s]
prediction: ['[CLS] ‖oured spent. yesterday elevator suddenly sarahgingly - these [SEP]']
[ 300/2000] tot_loss=4.301 (perp=12.581, rec=0.857, cos=0.928), tot_loss_proj:4.272 [t=0.23s]
prediction: ['[CLS] ‖oured spent. yesterday elevator inland sarahgingly - these [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.998 (perp=11.129, rec=0.815, cos=0.958), tot_loss_proj:4.020 [t=0.23s]
prediction: ['[CLS] ‖oured spent. yesterday went inland sarah slightly - elevator [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.817 (perp=10.221, rec=0.785, cos=0.988), tot_loss_proj:3.830 [t=0.23s]
prediction: ['[CLS] ‖oured sarah spent. yesterday went inland slightly - elevator [SEP]']
[ 450/2000] tot_loss=3.720 (perp=10.393, rec=0.726, cos=0.915), tot_loss_proj:3.890 [t=0.23s]
prediction: ['[CLS] ‖oured sarah spent. yesterday. inland slightly - elevator [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.497 (perp=10.496, rec=0.686, cos=0.712), tot_loss_proj:3.889 [t=0.23s]
prediction: ['[CLS] ‖oured sarah went. yesterday spent inland slightly - elevator [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=3.379 (perp=11.231, rec=0.668, cos=0.464), tot_loss_proj:4.008 [t=0.23s]
prediction: ['[CLS] ‖oured sarah sts inland. yesterday spent slightly - elevator [SEP]']
[ 600/2000] tot_loss=3.035 (perp=10.636, rec=0.628, cos=0.280), tot_loss_proj:3.916 [t=0.23s]
prediction: ['[CLS] ‖oured sarah went suddenly. yesterday faced slightly - elevator [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=3.013 (perp=10.820, rec=0.615, cos=0.234), tot_loss_proj:3.928 [t=0.23s]
prediction: ['[CLS] ‖oured sarah km² suddenly block slightly. yesterday - elevator [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.988 (perp=10.842, rec=0.604, cos=0.216), tot_loss_proj:3.934 [t=0.23s]
prediction: ['[CLS] ‖oured sarah block away km² slightly. yesterday - elevator [SEP]']
[ 750/2000] tot_loss=3.188 (perp=11.995, rec=0.591, cos=0.197), tot_loss_proj:4.201 [t=0.23s]
prediction: ['[CLS] ‖oured sarah shouldersshed sts slightly. yesterday - elevator [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.015 (perp=11.154, rec=0.587, cos=0.197), tot_loss_proj:4.002 [t=0.23s]
prediction: ['[CLS] ‖oured sarah shouldersshed sts. yesterday - slightly elevator [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.777 (perp=10.013, rec=0.580, cos=0.195), tot_loss_proj:3.744 [t=0.23s]
prediction: ['[CLS] ‖oured sarah shoulders sts. away yesterday - slightly elevator [SEP]']
[ 900/2000] tot_loss=2.910 (perp=10.695, rec=0.573, cos=0.198), tot_loss_proj:3.879 [t=0.23s]
prediction: ['[CLS] ‖oured sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.932 (perp=10.888, rec=0.556, cos=0.198), tot_loss_proj:3.965 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1000/2000] tot_loss=2.934 (perp=10.888, rec=0.556, cos=0.200), tot_loss_proj:3.964 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
[1050/2000] tot_loss=2.920 (perp=10.888, rec=0.546, cos=0.196), tot_loss_proj:3.964 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1100/2000] tot_loss=2.921 (perp=10.888, rec=0.544, cos=0.200), tot_loss_proj:3.964 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1150/2000] tot_loss=2.913 (perp=10.888, rec=0.538, cos=0.197), tot_loss_proj:3.961 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
[1200/2000] tot_loss=2.911 (perp=10.888, rec=0.537, cos=0.197), tot_loss_proj:3.966 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1250/2000] tot_loss=2.907 (perp=10.888, rec=0.532, cos=0.198), tot_loss_proj:3.965 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1300/2000] tot_loss=2.903 (perp=10.888, rec=0.529, cos=0.196), tot_loss_proj:3.972 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
[1350/2000] tot_loss=2.904 (perp=10.888, rec=0.529, cos=0.198), tot_loss_proj:3.966 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1400/2000] tot_loss=2.896 (perp=10.888, rec=0.520, cos=0.199), tot_loss_proj:3.970 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1450/2000] tot_loss=2.895 (perp=10.888, rec=0.520, cos=0.198), tot_loss_proj:3.965 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
[1500/2000] tot_loss=2.890 (perp=10.888, rec=0.514, cos=0.199), tot_loss_proj:3.967 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1550/2000] tot_loss=2.894 (perp=10.888, rec=0.520, cos=0.197), tot_loss_proj:3.968 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1600/2000] tot_loss=2.888 (perp=10.888, rec=0.513, cos=0.196), tot_loss_proj:3.968 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
[1650/2000] tot_loss=2.887 (perp=10.888, rec=0.512, cos=0.197), tot_loss_proj:3.968 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders sts.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1700/2000] tot_loss=2.890 (perp=10.906, rec=0.511, cos=0.198), tot_loss_proj:3.956 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders alexia.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1750/2000] tot_loss=2.889 (perp=10.906, rec=0.510, cos=0.197), tot_loss_proj:3.953 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders alexia.shed yesterday - slightly elevator [SEP]']
[1800/2000] tot_loss=2.891 (perp=10.906, rec=0.512, cos=0.198), tot_loss_proj:3.955 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders alexia.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1850/2000] tot_loss=2.883 (perp=10.906, rec=0.504, cos=0.197), tot_loss_proj:3.956 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders alexia.shed yesterday - slightly elevator [SEP]']
Attempt swap
[1900/2000] tot_loss=2.884 (perp=10.906, rec=0.505, cos=0.197), tot_loss_proj:3.953 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders alexia.shed yesterday - slightly elevator [SEP]']
[1950/2000] tot_loss=3.028 (perp=11.611, rec=0.507, cos=0.199), tot_loss_proj:4.139 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders alexia.shedrst - slightly elevator [SEP]']
Attempt swap
[2000/2000] tot_loss=3.022 (perp=11.611, rec=0.502, cos=0.198), tot_loss_proj:4.131 [t=0.23s]
prediction: ['[CLS] ‖ cakes sarah shoulders alexia.shedrst - slightly elevator [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] sarah devoured the cakes in the kitchen last night. [SEP]
========================
predicted: 
========================
[CLS] sarah dev cakes louisiana campus tonight breakfast awful frankie. these [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 34.783 | p: 33.333 | r: 36.364
rouge2     | fm: 9.524 | p: 9.091 | r: 10.000
rougeL     | fm: 34.783 | p: 33.333 | r: 36.364
rougeLsum  | fm: 34.783 | p: 33.333 | r: 36.364
r1fm+r2fm = 44.306

[Aggregate metrics]:
rouge1     | fm: 86.716 | p: 86.056 | r: 87.680
rouge2     | fm: 51.922 | p: 51.352 | r: 52.665
rougeL     | fm: 76.838 | p: 76.265 | r: 77.681
rougeLsum  | fm: 76.815 | p: 76.217 | r: 77.591
r1fm+r2fm = 138.638

input #98 time: 0:09:09 | total time: 15:00:42


Running input #99 of 100.
reference: 
========================
The box contains the ball.
========================
average of cosine similarity 0.8956676880859419
highest_index [0]
highest [0.8956676880859419]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 1996, 3482, 3397, 1996, 3608, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the box contains the ball. [SEP]']
[Init] best rec loss: 1.0126451253890991 for ['[CLS] point bono dry position nothing using [SEP]']
[Init] best rec loss: 0.9834603667259216 for ['[CLS] dai propressed pump after herb [SEP]']
[Init] best rec loss: 0.9818145632743835 for ['[CLS]ential op favouroliommer awful [SEP]']
[Init] best rec loss: 0.9783331751823425 for ['[CLS]atinhyl spartan for suspension claire [SEP]']
[Init] best rec loss: 0.9682350754737854 for ['[CLS] pending extended policy measure throne pia [SEP]']
[Init] best rec loss: 0.9674198031425476 for ['[CLS] come table thorne dirots cl [SEP]']
[Init] best rec loss: 0.9395008683204651 for ['[CLS] street highest radio individual during approach [SEP]']
[Init] best rec loss: 0.924214780330658 for ['[CLS]nic spiritgrave reserves km dated [SEP]']
[Init] best rec loss: 0.9238579273223877 for ['[CLS] with amount square trans parishes then [SEP]']
[Init] best rec loss: 0.9185284376144409 for ['[CLS] known theseelleffe crown success [SEP]']
[Init] best rec loss: 0.9125494360923767 for ['[CLS] conform entire at within running passenger [SEP]']
[Init] best perm rec loss: 0.912453293800354 for ['[CLS] at conform passenger running entire within [SEP]']
[Init] best perm rec loss: 0.911296546459198 for ['[CLS] passenger running entire conform at within [SEP]']
[Init] best perm rec loss: 0.9102798104286194 for ['[CLS] at running entire conform passenger within [SEP]']
[Init] best perm rec loss: 0.9093712568283081 for ['[CLS] within passenger conform entire running at [SEP]']
[Init] best perm rec loss: 0.9085506796836853 for ['[CLS] running at within passenger entire conform [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.080 (perp=11.199, rec=0.592, cos=0.249), tot_loss_proj:4.153 [t=0.23s]
prediction: ['[CLS] another basketball billy venue downtown ball [SEP]']
[ 100/2000] tot_loss=2.781 (perp=11.015, rec=0.361, cos=0.217), tot_loss_proj:4.111 [t=0.23s]
prediction: ['[CLS] my pillow shouldn ball contains ball [SEP]']
[ 150/2000] tot_loss=2.786 (perp=10.755, rec=0.378, cos=0.258), tot_loss_proj:4.065 [t=0.23s]
prediction: ['[CLS] another pillow shouldn ball contains ball [SEP]']
[ 200/2000] tot_loss=2.042 (perp=7.898, rec=0.290, cos=0.172), tot_loss_proj:3.513 [t=0.23s]
prediction: ['[CLS] the pillow ball ball contains ball [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.898 (perp=7.132, rec=0.292, cos=0.179), tot_loss_proj:2.983 [t=0.23s]
prediction: ['[CLS] the pillow ball ball ball contains [SEP]']
[ 300/2000] tot_loss=2.257 (perp=9.005, rec=0.267, cos=0.189), tot_loss_proj:3.710 [t=0.23s]
prediction: ['[CLS] the pillow containing ball box contains [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.352 (perp=9.539, rec=0.256, cos=0.188), tot_loss_proj:3.307 [t=0.23s]
prediction: ['[CLS] the boxcased ball pillow contains [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.228 (perp=9.055, rec=0.218, cos=0.199), tot_loss_proj:2.898 [t=0.23s]
prediction: ['[CLS] the pillowcased ball box contains [SEP]']
[ 450/2000] tot_loss=2.215 (perp=9.055, rec=0.213, cos=0.191), tot_loss_proj:2.899 [t=0.23s]
prediction: ['[CLS] the pillowcased ball box contains [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.108 (perp=8.492, rec=0.208, cos=0.202), tot_loss_proj:3.199 [t=0.23s]
prediction: ['[CLS] thecased pillow ball box contains [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.088 (perp=8.492, rec=0.192, cos=0.198), tot_loss_proj:3.204 [t=0.23s]
prediction: ['[CLS] thecased pillow ball box contains [SEP]']
[ 600/2000] tot_loss=2.161 (perp=8.859, rec=0.192, cos=0.197), tot_loss_proj:3.691 [t=0.23s]
prediction: ['[CLS] thecased bits ball box contains [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.199 (perp=9.024, rec=0.197, cos=0.198), tot_loss_proj:3.398 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.183 (perp=9.024, rec=0.193, cos=0.186), tot_loss_proj:3.407 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
[ 750/2000] tot_loss=2.180 (perp=9.024, rec=0.184, cos=0.192), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.189 (perp=9.024, rec=0.188, cos=0.197), tot_loss_proj:3.405 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.182 (perp=9.024, rec=0.181, cos=0.196), tot_loss_proj:3.406 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
[ 900/2000] tot_loss=2.184 (perp=9.024, rec=0.183, cos=0.197), tot_loss_proj:3.403 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.168 (perp=9.024, rec=0.178, cos=0.185), tot_loss_proj:3.401 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1000/2000] tot_loss=2.177 (perp=9.024, rec=0.180, cos=0.193), tot_loss_proj:3.404 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
[1050/2000] tot_loss=2.195 (perp=9.024, rec=0.192, cos=0.198), tot_loss_proj:3.404 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1100/2000] tot_loss=2.180 (perp=9.024, rec=0.181, cos=0.195), tot_loss_proj:3.405 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1150/2000] tot_loss=2.180 (perp=9.024, rec=0.179, cos=0.196), tot_loss_proj:3.401 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
[1200/2000] tot_loss=2.175 (perp=9.024, rec=0.175, cos=0.196), tot_loss_proj:3.407 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1250/2000] tot_loss=2.181 (perp=9.024, rec=0.183, cos=0.193), tot_loss_proj:3.401 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1300/2000] tot_loss=2.186 (perp=9.024, rec=0.181, cos=0.200), tot_loss_proj:3.402 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
[1350/2000] tot_loss=2.181 (perp=9.024, rec=0.177, cos=0.199), tot_loss_proj:3.408 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1400/2000] tot_loss=2.180 (perp=9.024, rec=0.179, cos=0.197), tot_loss_proj:3.407 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1450/2000] tot_loss=2.175 (perp=9.024, rec=0.173, cos=0.197), tot_loss_proj:3.406 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
[1500/2000] tot_loss=2.180 (perp=9.024, rec=0.177, cos=0.198), tot_loss_proj:3.407 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1550/2000] tot_loss=2.167 (perp=9.024, rec=0.167, cos=0.195), tot_loss_proj:3.402 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1600/2000] tot_loss=2.177 (perp=9.024, rec=0.172, cos=0.200), tot_loss_proj:3.405 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
[1650/2000] tot_loss=2.183 (perp=9.024, rec=0.180, cos=0.199), tot_loss_proj:3.402 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1700/2000] tot_loss=2.182 (perp=9.024, rec=0.179, cos=0.198), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1750/2000] tot_loss=2.183 (perp=9.024, rec=0.180, cos=0.198), tot_loss_proj:3.412 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
[1800/2000] tot_loss=2.183 (perp=9.024, rec=0.182, cos=0.197), tot_loss_proj:3.407 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1850/2000] tot_loss=2.182 (perp=9.024, rec=0.179, cos=0.198), tot_loss_proj:3.408 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[1900/2000] tot_loss=2.173 (perp=9.024, rec=0.172, cos=0.197), tot_loss_proj:3.402 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
[1950/2000] tot_loss=2.174 (perp=9.024, rec=0.171, cos=0.198), tot_loss_proj:3.401 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Attempt swap
[2000/2000] tot_loss=2.175 (perp=9.024, rec=0.173, cos=0.197), tot_loss_proj:3.405 [t=0.23s]
prediction: ['[CLS] thecased cuff ball box contains [SEP]']
Done with input #99 of 100.
reference: 
========================
[CLS] the box contains the ball. [SEP]
========================
predicted: 
========================
[CLS] thecased cuff ball box contains [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 88.095

[Aggregate metrics]:
rouge1     | fm: 86.590 | p: 85.914 | r: 87.521
rouge2     | fm: 51.521 | p: 50.945 | r: 52.263
rougeL     | fm: 76.608 | p: 76.014 | r: 77.416
rougeLsum  | fm: 76.590 | p: 75.966 | r: 77.436
r1fm+r2fm = 138.111

input #99 time: 0:09:09 | total time: 15:09:51


Average Cosine Similarity: 0.8907261039490736
Done with all.
