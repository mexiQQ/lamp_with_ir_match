


Command: attack4.py --dataset cola --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola --n_steps 2000 --coeff_pooler_match 0.0 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization no --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 100.65it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
Harriet alternated folk songs and pop songs together.
========================
average of cosine similarity 0.9986287613191126
highest_index [0]
highest [0.9986287613191126]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 14207,  6585,  2094,  5154,  2774,  1998,  3769,  2774,  2362,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] harriet alternated folk songs and pop songs together. [SEP]']
[Init] best rec loss: 0.8751700520515442 for ['[CLS] study showing exchange victorywall same bryant compulsory cl regiments [SEP]']
[Init] best rec loss: 0.8499425053596497 for ['[CLS] report make baglary fell paul max rape younger broken [SEP]']
[Init] best rec loss: 0.838250994682312 for ['[CLS] patriarch tr police active richard catfish chan atept customary [SEP]']
[Init] best rec loss: 0.8315490484237671 for ['[CLS] ii carson facto next icether cases done level [SEP] [SEP]']
[Init] best rec loss: 0.8177939653396606 for ['[CLS] ) monitor witch market issue healing stole dia indoor lane [SEP]']
[Init] best perm rec loss: 0.8168368935585022 for ['[CLS] lane indoor ) stole market issue witch monitor dia healing [SEP]']
[Init] best perm rec loss: 0.8144896626472473 for ['[CLS] ) indoor market lane dia stole issue monitor witch healing [SEP]']
[Init] best perm rec loss: 0.8124002814292908 for ['[CLS] ) indoor dia market issue lane stole monitor healing witch [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.648 (perp=11.905, rec=0.451, cos=0.816), tot_loss_proj:4.265 [t=0.30s]
prediction: ['[CLS] multiple relic together w issue song solo acid changes together [SEP]']
[ 100/2000] tot_loss=3.309 (perp=10.939, rec=0.306, cos=0.815), tot_loss_proj:4.086 [t=0.30s]
prediction: ['[CLS] alternate harriet whenever opera songs song women pop together together [SEP]']
[ 150/2000] tot_loss=3.094 (perp=10.153, rec=0.237, cos=0.826), tot_loss_proj:3.854 [t=0.30s]
prediction: ['[CLS] alternate harriet folkd songs song songs pop songs together [SEP]']
[ 200/2000] tot_loss=3.123 (perp=10.360, rec=0.230, cos=0.820), tot_loss_proj:3.966 [t=0.30s]
prediction: ['[CLS] alternate harrietdd songs! and songs songs together [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.552 (perp=10.726, rec=0.543, cos=0.864), tot_loss_proj:3.959 [t=0.30s]
prediction: ['[CLS] january harriet alternate ء songs we and charts songs together [SEP]']
[ 300/2000] tot_loss=3.446 (perp=11.023, rec=0.381, cos=0.860), tot_loss_proj:4.106 [t=0.30s]
prediction: ['[CLS] isabel harriet alternate helicopter songs we and literature songs together [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.421 (perp=11.319, rec=0.309, cos=0.849), tot_loss_proj:4.164 [t=0.30s]
prediction: ['[CLS] folk harriet alternate caribbeaned and charts! songs together [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.229 (perp=10.376, rec=0.285, cos=0.869), tot_loss_proj:4.015 [t=0.30s]
prediction: ['[CLS] folk harriet alternate songs caribbean and charts. songs together [SEP]']
[ 450/2000] tot_loss=3.192 (perp=10.376, rec=0.247, cos=0.870), tot_loss_proj:4.019 [t=0.30s]
prediction: ['[CLS] folk harriet alternate songs caribbean and charts. songs together [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.150 (perp=10.153, rec=0.263, cos=0.856), tot_loss_proj:3.951 [t=0.30s]
prediction: ['[CLS]d harriet alternate burkina songs and charts. songs together [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=3.268 (perp=10.068, rec=0.350, cos=0.904), tot_loss_proj:3.918 [t=0.30s]
prediction: ['[CLS] vhfd harriet alternate songs andfolia. songs together [SEP]']
[ 600/2000] tot_loss=3.167 (perp=10.061, rec=0.275, cos=0.880), tot_loss_proj:3.970 [t=0.30s]
prediction: ['[CLS] burkinad harriet alternate songs and gables we songs together [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.915 (perp=8.940, rec=0.253, cos=0.875), tot_loss_proj:3.665 [t=0.30s]
prediction: ['[CLS] burkinad harriet alternate songs and we gables songs together [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.824 (perp=8.568, rec=0.242, cos=0.868), tot_loss_proj:3.571 [t=0.30s]
prediction: ['[CLS] burkinad gables alternate songs and we harriet songs together [SEP]']
[ 750/2000] tot_loss=2.925 (perp=9.055, rec=0.244, cos=0.869), tot_loss_proj:3.702 [t=0.30s]
prediction: ['[CLS] balladd gables alternate songs and we harriet songs together [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.876 (perp=8.862, rec=0.229, cos=0.874), tot_loss_proj:3.678 [t=0.30s]
prediction: ['[CLS] balladd harriet alternate songs and we gables songs together [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.803 (perp=8.425, rec=0.234, cos=0.884), tot_loss_proj:3.589 [t=0.30s]
prediction: ['[CLS] ballad harriet alternated songs and we gables songs together [SEP]']
[ 900/2000] tot_loss=2.953 (perp=9.238, rec=0.224, cos=0.881), tot_loss_proj:3.725 [t=0.30s]
prediction: ['[CLS] ballad harriet alternated songs and. gables songs together [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.920 (perp=9.026, rec=0.233, cos=0.882), tot_loss_proj:3.715 [t=0.30s]
prediction: ['[CLS] ballad harriet alternated songs and gables songs together we [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.791 (perp=8.425, rec=0.237, cos=0.869), tot_loss_proj:3.592 [t=0.30s]
prediction: ['[CLS] ballad harriet alternated songs and we gables songs together [SEP]']
[1050/2000] tot_loss=2.785 (perp=8.425, rec=0.233, cos=0.868), tot_loss_proj:3.591 [t=0.30s]
prediction: ['[CLS] ballad harriet alternated songs and we gables songs together [SEP]']
Attempt swap
[1100/2000] tot_loss=2.880 (perp=8.939, rec=0.222, cos=0.870), tot_loss_proj:3.645 [t=0.30s]
prediction: ['[CLS] ballad harriet alternated songs and we forehead songs together [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.793 (perp=8.420, rec=0.235, cos=0.873), tot_loss_proj:3.626 [t=0.30s]
prediction: ['[CLS] ballad harriet alternated songs and we songs together songs [SEP]']
[1200/2000] tot_loss=2.778 (perp=8.420, rec=0.222, cos=0.871), tot_loss_proj:3.621 [t=0.30s]
prediction: ['[CLS] ballad harriet alternated songs and we songs together songs [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.722 (perp=8.120, rec=0.228, cos=0.870), tot_loss_proj:3.548 [t=0.30s]
prediction: ['[CLS] we harriet alternated songs and burkina songs together songs [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=2.505 (perp=6.982, rec=0.237, cos=0.872), tot_loss_proj:3.212 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
[1350/2000] tot_loss=2.503 (perp=6.982, rec=0.237, cos=0.869), tot_loss_proj:3.215 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
Attempt swap
[1400/2000] tot_loss=2.491 (perp=6.982, rec=0.224, cos=0.871), tot_loss_proj:3.220 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
Attempt swap
[1450/2000] tot_loss=2.499 (perp=6.982, rec=0.232, cos=0.871), tot_loss_proj:3.217 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
[1500/2000] tot_loss=2.492 (perp=6.982, rec=0.224, cos=0.871), tot_loss_proj:3.220 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
Attempt swap
[1550/2000] tot_loss=2.479 (perp=6.982, rec=0.211, cos=0.871), tot_loss_proj:3.222 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
Attempt swap
[1600/2000] tot_loss=2.491 (perp=6.982, rec=0.223, cos=0.872), tot_loss_proj:3.222 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
[1650/2000] tot_loss=2.483 (perp=6.982, rec=0.215, cos=0.872), tot_loss_proj:3.221 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
Attempt swap
[1700/2000] tot_loss=2.488 (perp=6.982, rec=0.219, cos=0.872), tot_loss_proj:3.220 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
Attempt swap
[1750/2000] tot_loss=2.481 (perp=6.982, rec=0.212, cos=0.873), tot_loss_proj:3.222 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
[1800/2000] tot_loss=2.487 (perp=6.982, rec=0.217, cos=0.873), tot_loss_proj:3.217 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
Attempt swap
[1850/2000] tot_loss=2.493 (perp=6.982, rec=0.223, cos=0.873), tot_loss_proj:3.223 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
Attempt swap
[1900/2000] tot_loss=2.477 (perp=6.982, rec=0.207, cos=0.874), tot_loss_proj:3.224 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
[1950/2000] tot_loss=2.490 (perp=6.982, rec=0.220, cos=0.874), tot_loss_proj:3.221 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
Attempt swap
[2000/2000] tot_loss=2.493 (perp=6.982, rec=0.222, cos=0.875), tot_loss_proj:3.227 [t=0.30s]
prediction: ['[CLS] we alternated songs and burkina harriet songs together songs [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] harriet alternated folk songs and pop songs together. [SEP]
========================
predicted: 
========================
[CLS] alternate harrietdd songs grammy and songs songs together [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 22.222 | p: 22.222 | r: 22.222
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 82.222

[Aggregate metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 22.222 | p: 22.222 | r: 22.222
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 82.222

input #0 time: 0:12:01 | total time: 0:12:01


Running input #1 of 100.
reference: 
========================
Who do you think that will question Seamus first?
========================
average of cosine similarity 0.998814953410188
highest_index [0]
highest [0.998814953410188]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2040,  2079,  2017,  2228,  2008,  2097,  3160, 24993,  2034,
          1029,   102]], device='cuda:0')
Debug: ref = ['[CLS] who do you think that will question seamus first? [SEP]']
[Init] best rec loss: 0.7580416798591614 for ['[CLS] singerии middlesbrough tells certificate numbering century sung nowhere go [SEP]']
[Init] best rec loss: 0.7433333396911621 for ['[CLS] because richest soc final melbourne gallo building mob might storm [SEP]']
[Init] best rec loss: 0.7260150909423828 for ['[CLS]less millennium billboard ron trial marino empire clerk kai brand [SEP]']
[Init] best rec loss: 0.7222511768341064 for ['[CLS] turn film comrade independent loud laughing films highestriverragan [SEP]']
[Init] best rec loss: 0.721258819103241 for ['[CLS] cells array communication before full [ watched crew brow shape [SEP]']
[Init] best rec loss: 0.7154971957206726 for ['[CLS]lance spiders roman above selectcarriageoured towardsiness page [SEP]']
[Init] best perm rec loss: 0.7135790586471558 for ['[CLS] above towards romancarriageoured spidersinesslance page select [SEP]']
[Init] best perm rec loss: 0.7090786695480347 for ['[CLS] romanouredcarriage towardsiness above page spiderslance select [SEP]']
[Init] best perm rec loss: 0.7090553045272827 for ['[CLS] towardscarriagelance select pageoured spiders roman aboveiness [SEP]']
[Init] best perm rec loss: 0.7066951394081116 for ['[CLS]carriage select page spiders romaninesslance aboveoured towards [SEP]']
[Init] best perm rec loss: 0.7064536809921265 for ['[CLS]ouredcarriage above selectiness spiders pagelance roman towards [SEP]']
[Init] best perm rec loss: 0.7064473628997803 for ['[CLS]carriage above select page towardsiness romanoured spiderslance [SEP]']
[Init] best perm rec loss: 0.7061008810997009 for ['[CLS] spiderslanceoured towards roman selectcarriage above pageiness [SEP]']
[Init] best perm rec loss: 0.7059715986251831 for ['[CLS]lance towardscarriage above selectiness spiders roman pageoured [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.388 (perp=10.270, rec=0.299, cos=0.035), tot_loss_proj:3.367 [t=0.30s]
prediction: ['[CLS] offering think that who - will reach seamus seamus her [SEP]']
[ 100/2000] tot_loss=1.792 (perp=8.024, rec=0.173, cos=0.015), tot_loss_proj:2.436 [t=0.30s]
prediction: ['[CLS] who think that who girl will question seamus seamus? [SEP]']
[ 150/2000] tot_loss=1.548 (perp=7.147, rec=0.109, cos=0.009), tot_loss_proj:2.167 [t=0.30s]
prediction: ['[CLS] who think that who you will question seamus first? [SEP]']
[ 200/2000] tot_loss=1.544 (perp=7.240, rec=0.092, cos=0.005), tot_loss_proj:2.123 [t=0.30s]
prediction: ['[CLS] who think that do you will question seamus first? [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.491 (perp=6.985, rec=0.091, cos=0.003), tot_loss_proj:3.253 [t=0.30s]
prediction: ['[CLS] who do think that you will question seamus first? [SEP]']
[ 300/2000] tot_loss=1.469 (perp=6.985, rec=0.070, cos=0.003), tot_loss_proj:3.257 [t=0.30s]
prediction: ['[CLS] who do think that you will question seamus first? [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.354 (perp=6.402, rec=0.071, cos=0.003), tot_loss_proj:1.425 [t=0.30s]
prediction: ['[CLS] who do you think that will question seamus first? [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.350 (perp=6.402, rec=0.067, cos=0.003), tot_loss_proj:1.429 [t=0.30s]
prediction: ['[CLS] who do you think that will question seamus first? [SEP]']
[ 450/2000] tot_loss=1.344 (perp=6.402, rec=0.061, cos=0.003), tot_loss_proj:1.426 [t=0.30s]
prediction: ['[CLS] who do you think that will question seamus first? [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.273 (perp=5.694, rec=0.125, cos=0.010), tot_loss_proj:1.446 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.256 (perp=5.694, rec=0.111, cos=0.006), tot_loss_proj:1.447 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
[ 600/2000] tot_loss=1.241 (perp=5.694, rec=0.098, cos=0.005), tot_loss_proj:1.464 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.241 (perp=5.694, rec=0.097, cos=0.005), tot_loss_proj:1.448 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.239 (perp=5.694, rec=0.095, cos=0.005), tot_loss_proj:1.461 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
[ 750/2000] tot_loss=1.235 (perp=5.694, rec=0.092, cos=0.004), tot_loss_proj:1.450 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.231 (perp=5.694, rec=0.088, cos=0.004), tot_loss_proj:1.460 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.226 (perp=5.694, rec=0.084, cos=0.004), tot_loss_proj:1.450 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
[ 900/2000] tot_loss=1.238 (perp=5.694, rec=0.095, cos=0.004), tot_loss_proj:1.454 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.232 (perp=5.694, rec=0.089, cos=0.004), tot_loss_proj:1.452 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.234 (perp=5.694, rec=0.091, cos=0.004), tot_loss_proj:1.459 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
[1050/2000] tot_loss=1.222 (perp=5.694, rec=0.080, cos=0.004), tot_loss_proj:1.463 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.231 (perp=5.694, rec=0.089, cos=0.003), tot_loss_proj:1.453 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.218 (perp=5.694, rec=0.076, cos=0.003), tot_loss_proj:1.450 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
[1200/2000] tot_loss=1.221 (perp=5.694, rec=0.079, cos=0.003), tot_loss_proj:1.459 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.224 (perp=5.694, rec=0.082, cos=0.003), tot_loss_proj:1.461 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.238 (perp=5.694, rec=0.096, cos=0.003), tot_loss_proj:1.456 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
[1350/2000] tot_loss=1.218 (perp=5.694, rec=0.077, cos=0.003), tot_loss_proj:1.457 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.217 (perp=5.694, rec=0.075, cos=0.003), tot_loss_proj:1.460 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.219 (perp=5.694, rec=0.077, cos=0.003), tot_loss_proj:1.455 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
[1500/2000] tot_loss=1.216 (perp=5.694, rec=0.075, cos=0.003), tot_loss_proj:1.457 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.222 (perp=5.694, rec=0.080, cos=0.003), tot_loss_proj:1.466 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.225 (perp=5.694, rec=0.083, cos=0.003), tot_loss_proj:1.465 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
[1650/2000] tot_loss=1.220 (perp=5.694, rec=0.078, cos=0.003), tot_loss_proj:1.467 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.224 (perp=5.694, rec=0.082, cos=0.003), tot_loss_proj:1.460 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.224 (perp=5.694, rec=0.082, cos=0.003), tot_loss_proj:1.463 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
[1800/2000] tot_loss=1.228 (perp=5.694, rec=0.086, cos=0.003), tot_loss_proj:1.462 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.226 (perp=5.694, rec=0.084, cos=0.003), tot_loss_proj:1.467 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.226 (perp=5.694, rec=0.085, cos=0.003), tot_loss_proj:1.465 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
[1950/2000] tot_loss=1.218 (perp=5.694, rec=0.076, cos=0.003), tot_loss_proj:1.475 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.229 (perp=5.694, rec=0.087, cos=0.003), tot_loss_proj:1.467 [t=0.30s]
prediction: ['[CLS] who do you think that will first question seamus? [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] who do you think that will question seamus first? [SEP]
========================
predicted: 
========================
[CLS] who do you think that will question seamus first? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 61.111 | p: 61.111 | r: 61.111
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 141.111

input #1 time: 0:11:57 | total time: 0:23:58


Running input #2 of 100.
reference: 
========================
The boy ran.
========================
average of cosine similarity 0.9991141839365967
highest_index [0]
highest [0.9991141839365967]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 1996, 2879, 2743, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the boy ran. [SEP]']
[Init] best rec loss: 0.9813265800476074 for ['[CLS] animation equal wickets gran [SEP]']
[Init] best rec loss: 0.9647239446640015 for ['[CLS] rose instruction lengths ; [SEP]']
[Init] best rec loss: 0.9495607614517212 for ['[CLS] chart whip members pat [SEP]']
[Init] best rec loss: 0.9370670914649963 for ['[CLS] february bachelor energyets [SEP]']
[Init] best rec loss: 0.9368878602981567 for ['[CLS] carr forward who children [SEP]']
[Init] best rec loss: 0.922796905040741 for ['[CLS] forever neil wrote there [SEP]']
[Init] best rec loss: 0.9177500009536743 for ['[CLS] militant sea because cord [SEP]']
[Init] best perm rec loss: 0.9168811440467834 for ['[CLS] sea because militant cord [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.829 (perp=11.327, rec=0.761, cos=0.803), tot_loss_proj:4.116 [t=0.30s]
prediction: ['[CLS] american? person worn [SEP]']
[ 100/2000] tot_loss=3.647 (perp=10.229, rec=0.666, cos=0.934), tot_loss_proj:3.997 [t=0.30s]
prediction: ['[CLS] coaster. client ran [SEP]']
[ 150/2000] tot_loss=2.880 (perp=11.028, rec=0.497, cos=0.178), tot_loss_proj:4.108 [t=0.30s]
prediction: ['[CLS] backed. boy naive [SEP]']
[ 200/2000] tot_loss=1.911 (perp=8.427, rec=0.209, cos=0.016), tot_loss_proj:3.199 [t=0.30s]
prediction: ['[CLS] boy. boy ran [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.689 (perp=7.525, rec=0.172, cos=0.012), tot_loss_proj:3.379 [t=0.30s]
prediction: ['[CLS] boy ran boy. [SEP]']
[ 300/2000] tot_loss=1.329 (perp=6.171, rec=0.092, cos=0.003), tot_loss_proj:3.112 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.312 (perp=6.171, rec=0.075, cos=0.002), tot_loss_proj:3.111 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.307 (perp=6.171, rec=0.071, cos=0.002), tot_loss_proj:3.109 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
[ 450/2000] tot_loss=1.303 (perp=6.171, rec=0.067, cos=0.002), tot_loss_proj:3.111 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.303 (perp=6.171, rec=0.067, cos=0.002), tot_loss_proj:3.109 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.305 (perp=6.171, rec=0.069, cos=0.002), tot_loss_proj:3.109 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
[ 600/2000] tot_loss=1.310 (perp=6.171, rec=0.074, cos=0.002), tot_loss_proj:3.110 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.309 (perp=6.171, rec=0.073, cos=0.002), tot_loss_proj:3.113 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.313 (perp=6.171, rec=0.077, cos=0.002), tot_loss_proj:3.106 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
[ 750/2000] tot_loss=1.305 (perp=6.171, rec=0.068, cos=0.002), tot_loss_proj:3.115 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.302 (perp=6.171, rec=0.065, cos=0.002), tot_loss_proj:3.111 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.301 (perp=6.171, rec=0.065, cos=0.002), tot_loss_proj:3.110 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
[ 900/2000] tot_loss=1.307 (perp=6.171, rec=0.071, cos=0.002), tot_loss_proj:3.110 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.297 (perp=6.171, rec=0.061, cos=0.002), tot_loss_proj:3.107 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.313 (perp=6.171, rec=0.077, cos=0.002), tot_loss_proj:3.103 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
[1050/2000] tot_loss=1.309 (perp=6.171, rec=0.072, cos=0.002), tot_loss_proj:3.108 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.310 (perp=6.171, rec=0.073, cos=0.002), tot_loss_proj:3.109 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.312 (perp=6.171, rec=0.076, cos=0.002), tot_loss_proj:3.111 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
[1200/2000] tot_loss=1.306 (perp=6.171, rec=0.069, cos=0.002), tot_loss_proj:3.109 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.294 (perp=6.171, rec=0.057, cos=0.002), tot_loss_proj:3.112 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.311 (perp=6.171, rec=0.075, cos=0.002), tot_loss_proj:3.106 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
[1350/2000] tot_loss=1.308 (perp=6.171, rec=0.072, cos=0.002), tot_loss_proj:3.110 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.304 (perp=6.171, rec=0.067, cos=0.002), tot_loss_proj:3.105 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.300 (perp=6.171, rec=0.064, cos=0.002), tot_loss_proj:3.111 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
[1500/2000] tot_loss=1.299 (perp=6.171, rec=0.063, cos=0.002), tot_loss_proj:3.106 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.302 (perp=6.171, rec=0.065, cos=0.002), tot_loss_proj:3.108 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.297 (perp=6.171, rec=0.060, cos=0.002), tot_loss_proj:3.115 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
[1650/2000] tot_loss=1.293 (perp=6.171, rec=0.056, cos=0.002), tot_loss_proj:3.107 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.302 (perp=6.171, rec=0.066, cos=0.002), tot_loss_proj:3.109 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.315 (perp=6.171, rec=0.079, cos=0.002), tot_loss_proj:3.107 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
[1800/2000] tot_loss=1.298 (perp=6.171, rec=0.062, cos=0.002), tot_loss_proj:3.114 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.313 (perp=6.171, rec=0.076, cos=0.002), tot_loss_proj:3.110 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.307 (perp=6.171, rec=0.070, cos=0.002), tot_loss_proj:3.105 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
[1950/2000] tot_loss=1.299 (perp=6.171, rec=0.063, cos=0.002), tot_loss_proj:3.112 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.296 (perp=6.171, rec=0.060, cos=0.002), tot_loss_proj:3.110 [t=0.30s]
prediction: ['[CLS] the ran boy. [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] the boy ran. [SEP]
========================
predicted: 
========================
[CLS] the ran boy. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 86.667 | p: 86.667 | r: 86.667
rouge2     | fm: 49.074 | p: 49.074 | r: 49.074
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 135.741

input #2 time: 0:11:56 | total time: 0:35:55


Running input #3 of 100.
reference: 
========================
I wonder who Bill saw and liked Mary.
========================
average of cosine similarity 0.9989055940773377
highest_index [0]
highest [0.9989055940773377]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1045, 4687, 2040, 3021, 2387, 1998, 4669, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i wonder who bill saw and liked mary. [SEP]']
[Init] best rec loss: 0.773334264755249 for ['[CLS] term acute turner ren reunion streets strikes still preservation [SEP]']
[Init] best rec loss: 0.7725775837898254 for ['[CLS] used emmy mark june enter cy ħ secrets zee [SEP]']
[Init] best rec loss: 0.7710789442062378 for ['[CLS] inauguraloris ) programmes taiwan partslica podium name [SEP]']
[Init] best rec loss: 0.7665413022041321 for ['[CLS] woodrow mating sumo knights parkinson branch happy kong deck [SEP]']
[Init] best perm rec loss: 0.7645169496536255 for ['[CLS] kong sumo branch mating knights deck parkinson happy woodrow [SEP]']
[Init] best perm rec loss: 0.761816680431366 for ['[CLS] mating happy deck parkinson sumo woodrow branch knights kong [SEP]']
[Init] best perm rec loss: 0.7613160610198975 for ['[CLS] sumo mating happy parkinson deck branch kong knights woodrow [SEP]']
[Init] best perm rec loss: 0.7598076462745667 for ['[CLS] deck woodrow parkinson kong branch knights mating happy sumo [SEP]']
[Init] best perm rec loss: 0.7590054869651794 for ['[CLS] woodrow knights parkinson mating kong sumo deck happy branch [SEP]']
[Init] best perm rec loss: 0.7582775950431824 for ['[CLS] parkinson deck mating knights woodrow sumo happy kong branch [SEP]']
[Init] best perm rec loss: 0.7534515261650085 for ['[CLS] woodrow branch parkinson mating kong sumo deck knights happy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.897 (perp=11.735, rec=0.431, cos=0.119), tot_loss_proj:4.057 [t=0.30s]
prediction: ['[CLS] direct uncredited lost sight which, clue mary happened [SEP]']
[ 100/2000] tot_loss=2.849 (perp=11.940, rec=0.373, cos=0.088), tot_loss_proj:3.993 [t=0.30s]
prediction: ['[CLS]ity francesco who which who. wondered maryough [SEP]']
[ 150/2000] tot_loss=2.209 (perp=9.059, rec=0.328, cos=0.069), tot_loss_proj:3.257 [t=0.30s]
prediction: ['[CLS] pictures wanted who sees who. wondered mary was [SEP]']
[ 200/2000] tot_loss=2.405 (perp=10.342, rec=0.280, cos=0.057), tot_loss_proj:3.222 [t=0.30s]
prediction: ['[CLS] wonder liked who saw and. wondered mary and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.677 (perp=6.943, rec=0.217, cos=0.072), tot_loss_proj:2.323 [t=0.30s]
prediction: ['[CLS] wonder ; who saw and liked wonder mary. [SEP]']
[ 300/2000] tot_loss=2.049 (perp=9.032, rec=0.212, cos=0.031), tot_loss_proj:2.818 [t=0.30s]
prediction: ['[CLS] wonder bill who saw and liked wonder mary had [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.832 (perp=8.094, rec=0.149, cos=0.064), tot_loss_proj:3.077 [t=0.30s]
prediction: ['[CLS] bill wonder who saw and liked wonder mary that [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.747 (perp=8.094, rec=0.104, cos=0.024), tot_loss_proj:3.084 [t=0.30s]
prediction: ['[CLS] bill wonder who saw and liked wonder mary that [SEP]']
[ 450/2000] tot_loss=1.747 (perp=8.094, rec=0.099, cos=0.028), tot_loss_proj:3.079 [t=0.30s]
prediction: ['[CLS] bill wonder who saw and liked wonder mary that [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.744 (perp=8.094, rec=0.099, cos=0.026), tot_loss_proj:3.083 [t=0.30s]
prediction: ['[CLS] bill wonder who saw and liked wonder mary that [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.738 (perp=8.094, rec=0.092, cos=0.027), tot_loss_proj:3.084 [t=0.30s]
prediction: ['[CLS] bill wonder who saw and liked wonder mary that [SEP]']
[ 600/2000] tot_loss=1.738 (perp=8.094, rec=0.093, cos=0.026), tot_loss_proj:3.082 [t=0.30s]
prediction: ['[CLS] bill wonder who saw and liked wonder mary that [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.725 (perp=8.094, rec=0.079, cos=0.027), tot_loss_proj:3.083 [t=0.30s]
prediction: ['[CLS] bill wonder who saw and liked wonder mary that [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.652 (perp=7.771, rec=0.082, cos=0.015), tot_loss_proj:2.935 [t=0.30s]
prediction: ['[CLS] bill wonder who saw wonder and liked mary that [SEP]']
[ 750/2000] tot_loss=1.639 (perp=7.776, rec=0.075, cos=0.009), tot_loss_proj:2.836 [t=0.30s]
prediction: ['[CLS] bill wonder who saw wonder and liked mary and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.634 (perp=7.776, rec=0.071, cos=0.008), tot_loss_proj:2.838 [t=0.30s]
prediction: ['[CLS] bill wonder who saw wonder and liked mary and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.771 (perp=8.436, rec=0.076, cos=0.008), tot_loss_proj:3.195 [t=0.30s]
prediction: ['[CLS] bill wonder who saw i and liked mary and [SEP]']
[ 900/2000] tot_loss=1.774 (perp=8.436, rec=0.080, cos=0.007), tot_loss_proj:3.188 [t=0.30s]
prediction: ['[CLS] bill wonder who saw i and liked mary and [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.496 (perp=7.013, rec=0.088, cos=0.005), tot_loss_proj:2.155 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.475 (perp=7.013, rec=0.068, cos=0.005), tot_loss_proj:2.148 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary and [SEP]']
[1050/2000] tot_loss=1.480 (perp=7.013, rec=0.072, cos=0.005), tot_loss_proj:2.149 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.358 (perp=6.353, rec=0.083, cos=0.005), tot_loss_proj:2.152 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.346 (perp=6.353, rec=0.070, cos=0.005), tot_loss_proj:2.153 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
[1200/2000] tot_loss=1.349 (perp=6.353, rec=0.073, cos=0.005), tot_loss_proj:2.149 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.358 (perp=6.353, rec=0.083, cos=0.005), tot_loss_proj:2.147 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.347 (perp=6.353, rec=0.072, cos=0.005), tot_loss_proj:2.154 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
[1350/2000] tot_loss=1.354 (perp=6.353, rec=0.079, cos=0.005), tot_loss_proj:2.155 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.346 (perp=6.353, rec=0.071, cos=0.005), tot_loss_proj:2.144 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.354 (perp=6.353, rec=0.079, cos=0.005), tot_loss_proj:2.159 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
[1500/2000] tot_loss=1.344 (perp=6.353, rec=0.069, cos=0.004), tot_loss_proj:2.150 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.342 (perp=6.353, rec=0.067, cos=0.005), tot_loss_proj:2.150 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.350 (perp=6.353, rec=0.075, cos=0.004), tot_loss_proj:2.155 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
[1650/2000] tot_loss=1.344 (perp=6.353, rec=0.068, cos=0.004), tot_loss_proj:2.157 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.353 (perp=6.353, rec=0.078, cos=0.004), tot_loss_proj:2.162 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.340 (perp=6.353, rec=0.065, cos=0.004), tot_loss_proj:2.155 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
[1800/2000] tot_loss=1.348 (perp=6.353, rec=0.073, cos=0.004), tot_loss_proj:2.149 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.357 (perp=6.353, rec=0.082, cos=0.004), tot_loss_proj:2.161 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.344 (perp=6.353, rec=0.069, cos=0.004), tot_loss_proj:2.152 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
[1950/2000] tot_loss=1.347 (perp=6.353, rec=0.071, cos=0.004), tot_loss_proj:2.151 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.357 (perp=6.353, rec=0.081, cos=0.004), tot_loss_proj:2.157 [t=0.30s]
prediction: ['[CLS] i wonder who saw bill and liked mary, [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] i wonder who bill saw and liked mary. [SEP]
========================
predicted: 
========================
[CLS] i wonder who saw bill and liked mary, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 90.000 | p: 90.000 | r: 90.000
rougeLsum  | fm: 90.000 | p: 90.000 | r: 90.000
r1fm+r2fm = 166.667

[Aggregate metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 53.472 | p: 53.472 | r: 53.472
rougeL     | fm: 82.500 | p: 82.500 | r: 82.500
rougeLsum  | fm: 82.500 | p: 82.500 | r: 82.500
r1fm+r2fm = 143.472

input #3 time: 0:11:57 | total time: 0:47:52


Running input #4 of 100.
reference: 
========================
While I might want to, this is the kind of thing that Harris has already suggested.
========================
average of cosine similarity 0.9988662116017356
highest_index [0]
highest [0.9988662116017356]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2096, 1045, 2453, 2215, 2000, 1010, 2023, 2003, 1996, 2785, 1997,
         2518, 2008, 5671, 2038, 2525, 4081, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]']
[Init] best rec loss: 0.9766295552253723 for ['[CLS] june stuffed eponymousdaepathic white bump earth critical security tata fraa area che range soory [SEP]']
[Init] best rec loss: 0.9587785601615906 for ['[CLS] ho burrmay welcome psyche separate independence nomenclature [MASK] cinder 500est walls memorial british finished horizon several [SEP]']
[Init] best rec loss: 0.9558326601982117 for ['[CLS] ing forth give do accident loftzed see boat rocks communications robot lame delle planck beaver crime re [SEP]']
[Init] best rec loss: 0.9553090929985046 for ['[CLS] am heads devon descent starsted pad likely mobile apologizedler swirl wire created scored executive student weber [SEP]']
[Init] best rec loss: 0.9361575841903687 for ['[CLS] seed hopes sydney donovan large todaybuck presence [MASK] toddbbled9 welcomemology slavery those ventures recreation [SEP]']
[Init] best rec loss: 0.9292514324188232 for ['[CLS]vere byitis diamond squeezed daytona papers bc darkness antibioticsisan little consultation cross reply exceptions robin % [SEP]']
[Init] best perm rec loss: 0.9259827733039856 for ['[CLS] antibiotics exceptions little consultation bc diamond cross by % papers replyvere robin darkness daytonaitisisan squeezed [SEP]']
[Init] best perm rec loss: 0.9244961142539978 for ['[CLS]itis squeezed daytona % reply diamond papersvere antibiotics by bc crossisan consultation exceptions robin darkness little [SEP]']
[Init] best perm rec loss: 0.9237497448921204 for ['[CLS]itis reply papers daytona by diamond consultation antibiotics darkness % cross squeezedisan bc little robinvere exceptions [SEP]']
[Init] best perm rec loss: 0.923338770866394 for ['[CLS] crossitis bc by robin reply consultation %vere papers exceptions antibioticsisan darkness little daytona squeezed diamond [SEP]']
[Init] best perm rec loss: 0.9227386116981506 for ['[CLS] diamond by consultation reply papersvere bc antibioticsitis squeezedisan cross exceptions darkness robin % daytona little [SEP]']
[Init] best perm rec loss: 0.9207379221916199 for ['[CLS]isanitis diamond consultation papers by antibiotics cross little bc exceptions robin reply squeezed darknessvere daytona % [SEP]']
[Init] best perm rec loss: 0.9205543994903564 for ['[CLS] cross antibiotics bc daytona darknessitis diamondvereisan reply robin consultation squeezed % exceptions by little papers [SEP]']
[Init] best perm rec loss: 0.9199420809745789 for ['[CLS] robin % daytonaisan by darkness reply papers cross antibiotics bc squeezed diamond consultation exceptionsvereitis little [SEP]']
[Init] best perm rec loss: 0.9191624522209167 for ['[CLS] bc robin darknessitis antibiotics little crossisan exceptions by diamond reply consultation daytona %vere squeezed papers [SEP]']
[Init] best perm rec loss: 0.9190124273300171 for ['[CLS] bc diamond consultationisan %vereitis robin exceptions cross antibiotics papers reply by daytona little squeezed darkness [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.817 (perp=11.025, rec=0.632, cos=0.980), tot_loss_proj:4.132 [t=0.31s]
prediction: ['[CLS] with spoken disco patrick steel chose june modern miller named true today jon proposed on sweat to say [SEP]']
[ 100/2000] tot_loss=3.072 (perp=9.548, rec=0.465, cos=0.697), tot_loss_proj:3.735 [t=0.31s]
prediction: ['[CLS] with mixer gameplay conference for among june harris is tender, for harris enzyme. doubt to say [SEP]']
[ 150/2000] tot_loss=2.936 (perp=8.903, rec=0.430, cos=0.725), tot_loss_proj:3.602 [t=0.31s]
prediction: ['[CLS] with additional considering conference. among january wanted is tender of which harris already ( indeed. with [SEP]']
[ 200/2000] tot_loss=3.338 (perp=10.637, rec=0.401, cos=0.810), tot_loss_proj:3.944 [t=0.31s]
prediction: ['[CLS] whereas ongoing considering among among with wanted harris does tender of that harris gerais. indeed. with [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.240 (perp=10.516, rec=0.388, cos=0.749), tot_loss_proj:3.907 [t=0.31s]
prediction: ['[CLS] placing should considering among and among wanted of harris might got thing harris surely, proposition, permanent [SEP]']
[ 300/2000] tot_loss=3.218 (perp=9.926, rec=0.364, cos=0.869), tot_loss_proj:3.823 [t=0.31s]
prediction: ['[CLS] while should considering among fruit while wanted of harris might have thing harris suggested, proposition, along [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.063 (perp=9.658, rec=0.335, cos=0.797), tot_loss_proj:3.783 [t=0.31s]
prediction: ['[CLS] while should anyway among harris while wanted of love might got thing harris suggested, proposition, called [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.429 (perp=10.006, rec=0.484, cos=0.944), tot_loss_proj:3.864 [t=0.31s]
prediction: ['[CLS] while should ‖ among harris while could metropolitan eyes does the that, harris suggested. kinds are [SEP]']
[ 450/2000] tot_loss=3.171 (perp=10.007, rec=0.360, cos=0.809), tot_loss_proj:3.850 [t=0.31s]
prediction: ['[CLS] if should steering towel besides if could metropolitan eyes does the that, harris suggested. facts established [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.012 (perp=9.705, rec=0.319, cos=0.753), tot_loss_proj:3.825 [t=0.31s]
prediction: ['[CLS] if shouldbility indeed seth while couldur might does the that, harris suggested. things has [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.124 (perp=9.912, rec=0.333, cos=0.809), tot_loss_proj:3.838 [t=0.31s]
prediction: ['[CLS] if shouldbility indeed seth while couldur might does the that. harris suggested. things has [SEP]']
[ 600/2000] tot_loss=3.255 (perp=10.543, rec=0.326, cos=0.821), tot_loss_proj:3.978 [t=0.31s]
prediction: ['[CLS] if should node indeed seth while couldur might is the that. harris suggested. things has [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.034 (perp=9.344, rec=0.327, cos=0.839), tot_loss_proj:3.743 [t=0.31s]
prediction: ['[CLS] if should what indeed seth while couldur! is the that. harris suggested. node has [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.957 (perp=9.173, rec=0.311, cos=0.811), tot_loss_proj:3.697 [t=0.31s]
prediction: ['[CLS] if should what indeedur while could seth! is the that. harris suggested. node while [SEP]']
[ 750/2000] tot_loss=3.107 (perp=9.904, rec=0.306, cos=0.821), tot_loss_proj:3.841 [t=0.31s]
prediction: ['[CLS] if should what indeedur while could seth we is the that. harris suggested.bility while [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=3.017 (perp=9.558, rec=0.288, cos=0.817), tot_loss_proj:3.772 [t=0.31s]
prediction: ['[CLS] if should what undur while could we samantha is the that. harris suggested,bility while [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.900 (perp=8.995, rec=0.294, cos=0.806), tot_loss_proj:3.667 [t=0.31s]
prediction: ['[CLS] if should what undur while could we samantha is the that. harris suggestedbility, while [SEP]']
[ 900/2000] tot_loss=2.969 (perp=9.377, rec=0.281, cos=0.813), tot_loss_proj:3.728 [t=0.31s]
prediction: ['[CLS] if should what und. while might we samantha is sort that. harris suggestedbility, while [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.883 (perp=8.934, rec=0.287, cos=0.809), tot_loss_proj:3.673 [t=0.31s]
prediction: ['[CLS] if shouldbility und. while might we samantha is kind that. harris suggested what, while [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.787 (perp=8.403, rec=0.285, cos=0.822), tot_loss_proj:3.585 [t=0.31s]
prediction: ['[CLS] if shouldbility und. while we might samantha is kind that. harris suggested what, while [SEP]']
[1050/2000] tot_loss=2.774 (perp=8.403, rec=0.275, cos=0.818), tot_loss_proj:3.583 [t=0.31s]
prediction: ['[CLS] if shouldbility und. while we might samantha is kind that. harris suggested what, while [SEP]']
Attempt swap
[1100/2000] tot_loss=2.791 (perp=8.541, rec=0.274, cos=0.808), tot_loss_proj:3.600 [t=0.31s]
prediction: ['[CLS] if shouldbility which. while we might samantha is kind that. harris suggested what, while [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.890 (perp=8.857, rec=0.298, cos=0.821), tot_loss_proj:3.671 [t=0.31s]
prediction: ['[CLS] if ª shouldbility which. while might samantha is kind that. harris suggested what, while [SEP]']
[1200/2000] tot_loss=2.684 (perp=8.055, rec=0.272, cos=0.801), tot_loss_proj:3.481 [t=0.31s]
prediction: ['[CLS] if we shouldbility which. while might samantha is kind that. harris suggested what, while [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.651 (perp=7.888, rec=0.271, cos=0.802), tot_loss_proj:3.463 [t=0.31s]
prediction: ['[CLS] if we shouldbility. which while might samantha is kind that. harris suggested what, while [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.720 (perp=8.160, rec=0.282, cos=0.806), tot_loss_proj:3.473 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind that. harris suggested what about while [SEP]']
[1350/2000] tot_loss=2.706 (perp=8.160, rec=0.276, cos=0.798), tot_loss_proj:3.475 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind that. harris suggested what about while [SEP]']
Attempt swap
[1400/2000] tot_loss=2.707 (perp=8.160, rec=0.274, cos=0.801), tot_loss_proj:3.475 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind that. harris suggested what about while [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.678 (perp=8.062, rec=0.263, cos=0.803), tot_loss_proj:3.445 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind that. harris suggested about what while [SEP]']
[1500/2000] tot_loss=2.679 (perp=8.062, rec=0.263, cos=0.803), tot_loss_proj:3.448 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind that. harris suggested about what while [SEP]']
Attempt swap
[1550/2000] tot_loss=2.679 (perp=8.062, rec=0.268, cos=0.799), tot_loss_proj:3.449 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind that. harris suggested about what while [SEP]']
Attempt swap
[1600/2000] tot_loss=2.672 (perp=8.062, rec=0.261, cos=0.799), tot_loss_proj:3.449 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind that. harris suggested about what while [SEP]']
[1650/2000] tot_loss=2.677 (perp=8.062, rec=0.263, cos=0.802), tot_loss_proj:3.444 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind that. harris suggested about what while [SEP]']
Attempt swap
[1700/2000] tot_loss=2.664 (perp=8.062, rec=0.256, cos=0.795), tot_loss_proj:3.441 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind that. harris suggested about what while [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.664 (perp=7.935, rec=0.271, cos=0.806), tot_loss_proj:3.420 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind. that harris suggested about what while [SEP]']
[1800/2000] tot_loss=2.653 (perp=7.935, rec=0.264, cos=0.802), tot_loss_proj:3.420 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind. that harris suggested about what while [SEP]']
Attempt swap
[1850/2000] tot_loss=2.653 (perp=7.935, rec=0.267, cos=0.799), tot_loss_proj:3.423 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind. that harris suggested about what while [SEP]']
Attempt swap
[1900/2000] tot_loss=2.640 (perp=7.935, rec=0.254, cos=0.799), tot_loss_proj:3.421 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind. that harris suggested about what while [SEP]']
[1950/2000] tot_loss=2.650 (perp=7.935, rec=0.263, cos=0.800), tot_loss_proj:3.423 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind. that harris suggested about what while [SEP]']
Attempt swap
[2000/2000] tot_loss=2.644 (perp=7.935, rec=0.256, cos=0.801), tot_loss_proj:3.421 [t=0.31s]
prediction: ['[CLS] if we shouldbility, which while might samantha is kind. that harris suggested about what while [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]
========================
predicted: 
========================
[CLS] if we shouldbility, which while might samantha is kind. that harris suggested about what while [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 51.429 | p: 52.941 | r: 50.000
rouge2     | fm: 6.061 | p: 6.250 | r: 5.882
rougeL     | fm: 51.429 | p: 52.941 | r: 50.000
rougeLsum  | fm: 51.429 | p: 52.941 | r: 50.000
r1fm+r2fm = 57.489

[Aggregate metrics]:
rouge1     | fm: 82.286 | p: 82.588 | r: 82.000
rouge2     | fm: 43.990 | p: 44.028 | r: 43.954
rougeL     | fm: 76.286 | p: 76.588 | r: 76.000
rougeLsum  | fm: 76.286 | p: 76.588 | r: 76.000
r1fm+r2fm = 126.276

input #4 time: 0:12:14 | total time: 1:00:07


Running input #5 of 100.
reference: 
========================
Who has seen my snorkel?
========================
average of cosine similarity 0.9989543833037144
highest_index [0]
highest [0.9989543833037144]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2040,  2038,  2464,  2026,  1055, 12131, 11705,  1029,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] who has seen my snorkel? [SEP]']
[Init] best rec loss: 0.984761655330658 for ['[CLS] second lot dimensions absolutelyavia nuclear second century [SEP]']
[Init] best rec loss: 0.8995332717895508 for ['[CLS] softzzled 10 dark ob subscription fury cold [SEP]']
[Init] best rec loss: 0.8936359882354736 for ['[CLS] woodrous prenology kiara ball ways faster [SEP]']
[Init] best rec loss: 0.8767123222351074 for ['[CLS] the 10 surprise dear relieve leaf blair its [SEP]']
[Init] best rec loss: 0.8426302075386047 for ['[CLS] death seat world urban cat fell grounds fc [SEP]']
[Init] best rec loss: 0.8149740695953369 for ['[CLS] nat politicalunk priceeon guess goalstered [SEP]']
[Init] best perm rec loss: 0.813982367515564 for ['[CLS]unkeon goal price politicalstered guess nat [SEP]']
[Init] best perm rec loss: 0.8105944395065308 for ['[CLS]eon guess politicalstered goalunk nat price [SEP]']
[Init] best perm rec loss: 0.8103600144386292 for ['[CLS] natunk guesseon goalstered political price [SEP]']
[Init] best perm rec loss: 0.809334933757782 for ['[CLS] nat goal guesseonunkstered political price [SEP]']
[Init] best perm rec loss: 0.8088794350624084 for ['[CLS]eon nat goal guessstered political priceunk [SEP]']
[Init] best perm rec loss: 0.8088103532791138 for ['[CLS] nateonunk goal price political guessstered [SEP]']
[Init] best perm rec loss: 0.8084172606468201 for ['[CLS]eon guessunk goal price natstered political [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.418 (perp=10.977, rec=0.502, cos=0.721), tot_loss_proj:4.067 [t=0.30s]
prediction: ['[CLS] childless somewhere knowke mutation in enemies ; [SEP]']
[ 100/2000] tot_loss=3.402 (perp=10.996, rec=0.437, cos=0.766), tot_loss_proj:4.129 [t=0.30s]
prediction: ['[CLS] who wonder knownor expect in contemporary? [SEP]']
[ 150/2000] tot_loss=3.466 (perp=12.266, rec=0.363, cos=0.650), tot_loss_proj:4.390 [t=0.30s]
prediction: ['[CLS] who pageant mynor creditedkel observed? [SEP]']
[ 200/2000] tot_loss=2.611 (perp=8.004, rec=0.329, cos=0.681), tot_loss_proj:3.499 [t=0.30s]
prediction: ['[CLS] who has mynor implantkel observed? [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.569 (perp=8.004, rec=0.294, cos=0.674), tot_loss_proj:3.495 [t=0.30s]
prediction: ['[CLS] who has mynor implantkel observed? [SEP]']
[ 300/2000] tot_loss=2.656 (perp=8.639, rec=0.253, cos=0.676), tot_loss_proj:3.655 [t=0.30s]
prediction: ['[CLS] who has mynor queuekel observed? [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.535 (perp=8.004, rec=0.231, cos=0.703), tot_loss_proj:3.492 [t=0.30s]
prediction: ['[CLS] who has mynor implantkel observed? [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.544 (perp=8.004, rec=0.235, cos=0.708), tot_loss_proj:3.491 [t=0.30s]
prediction: ['[CLS] who has mynor implantkel observed? [SEP]']
[ 450/2000] tot_loss=2.639 (perp=8.801, rec=0.212, cos=0.667), tot_loss_proj:3.502 [t=0.30s]
prediction: ['[CLS] who has mynor greensborokel seen? [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.406 (perp=7.454, rec=0.250, cos=0.665), tot_loss_proj:3.334 [t=0.30s]
prediction: ['[CLS] who has mynorkel charley seen? [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.406 (perp=7.441, rec=0.225, cos=0.692), tot_loss_proj:2.786 [t=0.30s]
prediction: ['[CLS] who has colonel mynorkel seen? [SEP]']
[ 600/2000] tot_loss=2.332 (perp=7.441, rec=0.194, cos=0.650), tot_loss_proj:2.778 [t=0.30s]
prediction: ['[CLS] who has colonel mynorkel seen? [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.264 (perp=7.021, rec=0.198, cos=0.662), tot_loss_proj:3.340 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.256 (perp=7.021, rec=0.196, cos=0.655), tot_loss_proj:3.343 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
[ 750/2000] tot_loss=2.248 (perp=7.021, rec=0.179, cos=0.665), tot_loss_proj:3.338 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.236 (perp=7.021, rec=0.174, cos=0.657), tot_loss_proj:3.338 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.252 (perp=7.021, rec=0.180, cos=0.668), tot_loss_proj:3.341 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
[ 900/2000] tot_loss=2.243 (perp=7.021, rec=0.170, cos=0.670), tot_loss_proj:3.341 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.253 (perp=7.021, rec=0.176, cos=0.673), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1000/2000] tot_loss=2.243 (perp=7.021, rec=0.165, cos=0.674), tot_loss_proj:3.339 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
[1050/2000] tot_loss=2.250 (perp=7.021, rec=0.173, cos=0.672), tot_loss_proj:3.339 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1100/2000] tot_loss=2.252 (perp=7.021, rec=0.177, cos=0.671), tot_loss_proj:3.340 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1150/2000] tot_loss=2.246 (perp=7.021, rec=0.170, cos=0.671), tot_loss_proj:3.337 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
[1200/2000] tot_loss=2.252 (perp=7.021, rec=0.175, cos=0.673), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1250/2000] tot_loss=2.254 (perp=7.021, rec=0.176, cos=0.673), tot_loss_proj:3.340 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1300/2000] tot_loss=2.257 (perp=7.021, rec=0.172, cos=0.680), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
[1350/2000] tot_loss=2.252 (perp=7.021, rec=0.167, cos=0.681), tot_loss_proj:3.340 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1400/2000] tot_loss=2.247 (perp=7.021, rec=0.169, cos=0.674), tot_loss_proj:3.344 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1450/2000] tot_loss=2.246 (perp=7.021, rec=0.166, cos=0.675), tot_loss_proj:3.343 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
[1500/2000] tot_loss=2.250 (perp=7.021, rec=0.171, cos=0.675), tot_loss_proj:3.340 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1550/2000] tot_loss=2.246 (perp=7.021, rec=0.163, cos=0.678), tot_loss_proj:3.339 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1600/2000] tot_loss=2.246 (perp=7.021, rec=0.164, cos=0.678), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
[1650/2000] tot_loss=2.253 (perp=7.021, rec=0.169, cos=0.680), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1700/2000] tot_loss=2.251 (perp=7.021, rec=0.170, cos=0.677), tot_loss_proj:3.339 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1750/2000] tot_loss=2.246 (perp=7.021, rec=0.166, cos=0.675), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
[1800/2000] tot_loss=2.243 (perp=7.021, rec=0.160, cos=0.678), tot_loss_proj:3.339 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1850/2000] tot_loss=2.249 (perp=7.021, rec=0.168, cos=0.677), tot_loss_proj:3.341 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[1900/2000] tot_loss=2.258 (perp=7.021, rec=0.178, cos=0.675), tot_loss_proj:3.340 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
[1950/2000] tot_loss=2.244 (perp=7.021, rec=0.162, cos=0.678), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Attempt swap
[2000/2000] tot_loss=2.243 (perp=7.021, rec=0.162, cos=0.676), tot_loss_proj:3.343 [t=0.30s]
prediction: ['[CLS] who has colonelkel mynor seen? [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] who has seen my snorkel? [SEP]
========================
predicted: 
========================
[CLS] who has colonelkel mynor seen? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 104.762

[Aggregate metrics]:
rouge1     | fm: 80.476 | p: 80.728 | r: 80.238
rouge2     | fm: 41.288 | p: 41.319 | r: 41.258
rougeL     | fm: 75.476 | p: 75.728 | r: 75.238
rougeLsum  | fm: 75.476 | p: 75.721 | r: 75.238
r1fm+r2fm = 121.764

input #5 time: 0:11:49 | total time: 1:11:56


Running input #6 of 100.
reference: 
========================
Which goddess helped us?
========================
average of cosine similarity 0.9990717376249051
highest_index [0]
highest [0.9990717376249051]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2029, 7804, 3271, 2149, 1029,  102]], device='cuda:0')
Debug: ref = ['[CLS] which goddess helped us? [SEP]']
[Init] best rec loss: 0.8728255033493042 for ['[CLS] naked scoring southeastvyn taliban [SEP]']
[Init] best rec loss: 0.8700101971626282 for ['[CLS] philanthropy theatre braid sexualmons [SEP]']
[Init] best rec loss: 0.8597597479820251 for ['[CLS] america orders ′ landon ecuador [SEP]']
[Init] best rec loss: 0.8541910648345947 for ['[CLS] ether accountants naval hall sought [SEP]']
[Init] best rec loss: 0.8156483769416809 for ['[CLS]nation convenient heal exactly ljubljana [SEP]']
[Init] best perm rec loss: 0.8080615997314453 for ['[CLS] ljubljana healnation exactly convenient [SEP]']
[Init] best perm rec loss: 0.8021271228790283 for ['[CLS] heal exactly ljubljana convenientnation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.530 (perp=9.341, rec=0.431, cos=0.231), tot_loss_proj:3.786 [t=0.29s]
prediction: ['[CLS] what les fellowshipra? [SEP]']
[ 100/2000] tot_loss=2.391 (perp=10.754, rec=0.192, cos=0.048), tot_loss_proj:4.012 [t=0.30s]
prediction: ['[CLS] which goddess goddessri? [SEP]']
[ 150/2000] tot_loss=2.075 (perp=9.541, rec=0.130, cos=0.036), tot_loss_proj:3.136 [t=0.30s]
prediction: ['[CLS] which helped goddessia? [SEP]']
[ 200/2000] tot_loss=2.172 (perp=10.020, rec=0.133, cos=0.036), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] which helped goddess vampires? [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.062 (perp=9.488, rec=0.129, cos=0.035), tot_loss_proj:2.220 [t=0.30s]
prediction: ['[CLS] which goddess helped vampires? [SEP]']
[ 300/2000] tot_loss=2.044 (perp=9.488, rec=0.111, cos=0.035), tot_loss_proj:2.213 [t=0.30s]
prediction: ['[CLS] which goddess helped vampires? [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.021 (perp=9.488, rec=0.092, cos=0.032), tot_loss_proj:2.212 [t=0.30s]
prediction: ['[CLS] which goddess helped vampires? [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.034 (perp=9.488, rec=0.104, cos=0.033), tot_loss_proj:2.214 [t=0.30s]
prediction: ['[CLS] which goddess helped vampires? [SEP]']
[ 450/2000] tot_loss=2.023 (perp=9.488, rec=0.096, cos=0.029), tot_loss_proj:2.210 [t=0.30s]
prediction: ['[CLS] which goddess helped vampires? [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.019 (perp=9.488, rec=0.095, cos=0.026), tot_loss_proj:2.212 [t=0.30s]
prediction: ['[CLS] which goddess helped vampires? [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.014 (perp=9.488, rec=0.093, cos=0.024), tot_loss_proj:2.206 [t=0.30s]
prediction: ['[CLS] which goddess helped vampires? [SEP]']
[ 600/2000] tot_loss=2.016 (perp=9.488, rec=0.095, cos=0.023), tot_loss_proj:2.206 [t=0.30s]
prediction: ['[CLS] which goddess helped vampires? [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.010 (perp=9.488, rec=0.093, cos=0.020), tot_loss_proj:2.211 [t=0.30s]
prediction: ['[CLS] which goddess helped vampires? [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.004 (perp=9.488, rec=0.089, cos=0.017), tot_loss_proj:2.211 [t=0.30s]
prediction: ['[CLS] which goddess helped vampires? [SEP]']
[ 750/2000] tot_loss=1.996 (perp=9.488, rec=0.084, cos=0.015), tot_loss_proj:2.205 [t=0.30s]
prediction: ['[CLS] which goddess helped vampires? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.883 (perp=8.950, rec=0.080, cos=0.014), tot_loss_proj:2.567 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.875 (perp=8.950, rec=0.073, cos=0.012), tot_loss_proj:2.555 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
[ 900/2000] tot_loss=1.888 (perp=8.950, rec=0.086, cos=0.012), tot_loss_proj:2.558 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.884 (perp=8.950, rec=0.083, cos=0.011), tot_loss_proj:2.561 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.888 (perp=8.950, rec=0.087, cos=0.011), tot_loss_proj:2.546 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
[1050/2000] tot_loss=1.894 (perp=8.950, rec=0.093, cos=0.011), tot_loss_proj:2.551 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.893 (perp=8.950, rec=0.092, cos=0.011), tot_loss_proj:2.548 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.884 (perp=8.950, rec=0.083, cos=0.010), tot_loss_proj:2.553 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
[1200/2000] tot_loss=1.887 (perp=8.950, rec=0.087, cos=0.010), tot_loss_proj:2.551 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.866 (perp=8.950, rec=0.066, cos=0.010), tot_loss_proj:2.544 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.881 (perp=8.950, rec=0.081, cos=0.010), tot_loss_proj:2.543 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
[1350/2000] tot_loss=1.875 (perp=8.950, rec=0.075, cos=0.010), tot_loss_proj:2.544 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.875 (perp=8.950, rec=0.076, cos=0.010), tot_loss_proj:2.549 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.875 (perp=8.950, rec=0.075, cos=0.010), tot_loss_proj:2.544 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
[1500/2000] tot_loss=1.887 (perp=8.950, rec=0.088, cos=0.010), tot_loss_proj:2.544 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.890 (perp=8.950, rec=0.091, cos=0.009), tot_loss_proj:2.541 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.878 (perp=8.950, rec=0.078, cos=0.009), tot_loss_proj:2.540 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
[1650/2000] tot_loss=1.878 (perp=8.950, rec=0.079, cos=0.010), tot_loss_proj:2.540 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.879 (perp=8.950, rec=0.080, cos=0.009), tot_loss_proj:2.543 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.872 (perp=8.950, rec=0.072, cos=0.009), tot_loss_proj:2.542 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
[1800/2000] tot_loss=1.870 (perp=8.950, rec=0.070, cos=0.009), tot_loss_proj:2.541 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.874 (perp=8.950, rec=0.075, cos=0.009), tot_loss_proj:2.545 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.866 (perp=8.950, rec=0.067, cos=0.009), tot_loss_proj:2.541 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
[1950/2000] tot_loss=1.879 (perp=8.950, rec=0.080, cos=0.009), tot_loss_proj:2.550 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.874 (perp=8.950, rec=0.075, cos=0.009), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] which goddess helped we? [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] which goddess helped us? [SEP]
========================
predicted: 
========================
[CLS] which goddess helped we? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 60.000 | p: 60.000 | r: 60.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 143.333

[Aggregate metrics]:
rouge1     | fm: 81.361 | p: 81.793 | r: 81.361
rouge2     | fm: 44.199 | p: 44.226 | r: 44.174
rougeL     | fm: 76.565 | p: 76.667 | r: 76.395
rougeLsum  | fm: 76.599 | p: 76.815 | r: 76.395
r1fm+r2fm = 125.560

input #6 time: 0:11:47 | total time: 1:23:43


Running input #7 of 100.
reference: 
========================
They have no old.
========================
average of cosine similarity 0.9988351067291428
highest_index [0]
highest [0.9988351067291428]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2027, 2031, 2053, 2214, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] they have no old. [SEP]']
[Init] best rec loss: 0.7720333933830261 for ['[CLS] devices buck 1947 business ji [SEP]']
[Init] best rec loss: 0.7601465582847595 for ['[CLS] disc row lies leg entire [SEP]']
[Init] best rec loss: 0.735319197177887 for ['[CLS]emi streamed including same rugby [SEP]']
[Init] best rec loss: 0.7162567973136902 for ['[CLS] nopecharged practiced 2011 jersey [SEP]']
[Init] best rec loss: 0.7036780118942261 for ['[CLS] necessary nino shin sensory hank [SEP]']
[Init] best rec loss: 0.6976977586746216 for ['[CLS] cylinder sum expansion died thing [SEP]']
[Init] best rec loss: 0.6898987293243408 for ['[CLS] total mfa km² brock gifford [SEP]']
[Init] best rec loss: 0.6870765686035156 for ['[CLS] entertainment expansionound ps till [SEP]']
[Init] best rec loss: 0.6708284616470337 for ['[CLS] card rosa most com sarah [SEP]']
[Init] best rec loss: 0.6569374203681946 for ['[CLS] simultaneously campeonato outside - shown [SEP]']
[Init] best perm rec loss: 0.6541589498519897 for ['[CLS] outside shown campeonato - simultaneously [SEP]']
[Init] best perm rec loss: 0.6541016101837158 for ['[CLS] - shown campeonato simultaneously outside [SEP]']
[Init] best perm rec loss: 0.6537178158760071 for ['[CLS] simultaneously shown campeonato - outside [SEP]']
[Init] best perm rec loss: 0.6535654067993164 for ['[CLS] - outside shown campeonato simultaneously [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.507 (perp=7.910, rec=0.493, cos=0.433), tot_loss_proj:2.343 [t=0.29s]
prediction: ['[CLS] they have old no? [SEP]']
[ 100/2000] tot_loss=2.447 (perp=7.605, rec=0.348, cos=0.578), tot_loss_proj:2.256 [t=0.30s]
prediction: ['[CLS] they no old no. [SEP]']
[ 150/2000] tot_loss=2.213 (perp=7.605, rec=0.290, cos=0.402), tot_loss_proj:2.255 [t=0.30s]
prediction: ['[CLS] they no old no. [SEP]']
[ 200/2000] tot_loss=2.817 (perp=10.640, rec=0.344, cos=0.346), tot_loss_proj:3.008 [t=0.30s]
prediction: ['[CLS] sounding have old no old [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.933 (perp=6.593, rec=0.250, cos=0.364), tot_loss_proj:2.196 [t=0.30s]
prediction: ['[CLS] they have old no. [SEP]']
[ 300/2000] tot_loss=1.958 (perp=6.593, rec=0.244, cos=0.395), tot_loss_proj:2.196 [t=0.30s]
prediction: ['[CLS] they have old no. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.832 (perp=5.838, rec=0.253, cos=0.411), tot_loss_proj:1.442 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.805 (perp=5.838, rec=0.232, cos=0.405), tot_loss_proj:1.458 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
[ 450/2000] tot_loss=1.785 (perp=5.838, rec=0.230, cos=0.387), tot_loss_proj:1.441 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.806 (perp=5.838, rec=0.231, cos=0.407), tot_loss_proj:1.440 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.793 (perp=5.838, rec=0.221, cos=0.404), tot_loss_proj:1.440 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
[ 600/2000] tot_loss=1.781 (perp=5.838, rec=0.228, cos=0.385), tot_loss_proj:1.436 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.847 (perp=5.838, rec=0.225, cos=0.454), tot_loss_proj:1.446 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.769 (perp=5.838, rec=0.219, cos=0.383), tot_loss_proj:1.431 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
[ 750/2000] tot_loss=1.750 (perp=5.838, rec=0.225, cos=0.358), tot_loss_proj:1.436 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.759 (perp=5.838, rec=0.222, cos=0.369), tot_loss_proj:1.445 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.790 (perp=5.838, rec=0.229, cos=0.393), tot_loss_proj:1.439 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
[ 900/2000] tot_loss=1.802 (perp=5.838, rec=0.222, cos=0.412), tot_loss_proj:1.438 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.808 (perp=5.838, rec=0.224, cos=0.416), tot_loss_proj:1.432 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.851 (perp=5.838, rec=0.229, cos=0.454), tot_loss_proj:1.430 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
[1050/2000] tot_loss=1.830 (perp=5.838, rec=0.220, cos=0.442), tot_loss_proj:1.429 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.828 (perp=5.838, rec=0.225, cos=0.436), tot_loss_proj:1.425 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.837 (perp=5.838, rec=0.227, cos=0.443), tot_loss_proj:1.424 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
[1200/2000] tot_loss=1.851 (perp=5.838, rec=0.228, cos=0.455), tot_loss_proj:1.427 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.841 (perp=5.838, rec=0.217, cos=0.456), tot_loss_proj:1.424 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.842 (perp=5.838, rec=0.217, cos=0.458), tot_loss_proj:1.424 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
[1350/2000] tot_loss=1.848 (perp=5.838, rec=0.225, cos=0.456), tot_loss_proj:1.420 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.851 (perp=5.838, rec=0.224, cos=0.459), tot_loss_proj:1.423 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.845 (perp=5.838, rec=0.219, cos=0.458), tot_loss_proj:1.416 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
[1500/2000] tot_loss=1.843 (perp=5.838, rec=0.216, cos=0.460), tot_loss_proj:1.424 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.857 (perp=5.838, rec=0.231, cos=0.459), tot_loss_proj:1.413 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.844 (perp=5.838, rec=0.216, cos=0.461), tot_loss_proj:1.428 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
[1650/2000] tot_loss=1.856 (perp=5.838, rec=0.228, cos=0.460), tot_loss_proj:1.424 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.842 (perp=5.838, rec=0.214, cos=0.461), tot_loss_proj:1.424 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.850 (perp=5.838, rec=0.222, cos=0.460), tot_loss_proj:1.427 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
[1800/2000] tot_loss=1.852 (perp=5.838, rec=0.223, cos=0.462), tot_loss_proj:1.409 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.845 (perp=5.838, rec=0.217, cos=0.460), tot_loss_proj:1.427 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.852 (perp=5.838, rec=0.223, cos=0.461), tot_loss_proj:1.420 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
[1950/2000] tot_loss=1.844 (perp=5.838, rec=0.216, cos=0.461), tot_loss_proj:1.416 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.855 (perp=5.838, rec=0.226, cos=0.461), tot_loss_proj:1.420 [t=0.30s]
prediction: ['[CLS] they have no old. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] they have no old. [SEP]
========================
predicted: 
========================
[CLS] they have no old. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 83.929 | p: 84.118 | r: 83.750
rouge2     | fm: 50.934 | p: 50.972 | r: 50.923
rougeL     | fm: 79.524 | p: 79.559 | r: 79.345
rougeLsum  | fm: 79.613 | p: 79.762 | r: 79.345
r1fm+r2fm = 134.863

input #7 time: 0:11:46 | total time: 1:35:30


Running input #8 of 100.
reference: 
========================
John tries to meet not Mary.
========================
average of cosine similarity 0.9988369374150432
highest_index [0]
highest [0.9988369374150432]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2198, 5363, 2000, 3113, 2025, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] john tries to meet not mary. [SEP]']
[Init] best rec loss: 0.9651748538017273 for ['[CLS]udeau secretary steinerc pennypeed press [SEP]']
[Init] best rec loss: 0.91805499792099 for ['[CLS] mono offences fee tour arkansas day connected [SEP]']
[Init] best rec loss: 0.9099546074867249 for ['[CLS] jordan dog honey [CLS] training punnsor [SEP]']
[Init] best rec loss: 0.8992891311645508 for ['[CLS]path hamburg halfway issued anglesaud chu [SEP]']
[Init] best rec loss: 0.8702859878540039 for ["[CLS]masvial papers me'longer ut [SEP]"]
[Init] best rec loss: 0.869140088558197 for ['[CLS] cf wrongedge guest bloody matches deep [SEP]']
[Init] best rec loss: 0.830382764339447 for ['[CLS] warren benny grace boarding saxon nothing " [SEP]']
[Init] best rec loss: 0.8126164674758911 for ['[CLS] further big instance schedule ahead caftium [SEP]']
[Init] best rec loss: 0.7769163250923157 for ['[CLS] judge no will power us missing cry [SEP]']
[Init] best perm rec loss: 0.776578426361084 for ['[CLS] no will judge missing us cry power [SEP]']
[Init] best perm rec loss: 0.7739794254302979 for ['[CLS] no judge cry us will power missing [SEP]']
[Init] best perm rec loss: 0.773232102394104 for ['[CLS] will judge no power missing us cry [SEP]']
[Init] best perm rec loss: 0.7658078670501709 for ['[CLS] missing judge power no us cry will [SEP]']
[Init] best perm rec loss: 0.7623032331466675 for ['[CLS] will judge power missing cry no us [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.486 (perp=10.005, rec=0.602, cos=0.883), tot_loss_proj:3.671 [t=0.29s]
prediction: ['[CLS]. little attempt. including lever gundam [SEP]']
[ 100/2000] tot_loss=3.442 (perp=9.686, rec=0.524, cos=0.981), tot_loss_proj:3.293 [t=0.30s]
prediction: ['[CLS] ; little attempt. not not gundam [SEP]']
[ 150/2000] tot_loss=3.447 (perp=9.686, rec=0.522, cos=0.988), tot_loss_proj:3.285 [t=0.30s]
prediction: ['[CLS] ; little attempt. not not gundam [SEP]']
[ 200/2000] tot_loss=3.379 (perp=9.465, rec=0.488, cos=0.997), tot_loss_proj:3.582 [t=0.30s]
prediction: ['[CLS] ; few meet. not not blah [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=3.117 (perp=7.951, rec=0.551, cos=0.975), tot_loss_proj:3.444 [t=0.30s]
prediction: ['[CLS] not not blah ; few meet. [SEP]']
[ 300/2000] tot_loss=2.898 (perp=7.197, rec=0.469, cos=0.989), tot_loss_proj:3.287 [t=0.30s]
prediction: ['[CLS] not not rushes ; few tries. [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.203 (perp=8.754, rec=0.462, cos=0.990), tot_loss_proj:3.087 [t=0.30s]
prediction: ['[CLS] not not rushes ; avail tries. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.595 (perp=10.634, rec=0.482, cos=0.986), tot_loss_proj:3.246 [t=0.30s]
prediction: ['[CLS] not brightly not john avail tries. [SEP]']
[ 450/2000] tot_loss=3.240 (perp=9.019, rec=0.445, cos=0.992), tot_loss_proj:2.908 [t=0.30s]
prediction: ['[CLS] not brightly not handicap avail meet. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.133 (perp=8.555, rec=0.430, cos=0.992), tot_loss_proj:2.333 [t=0.30s]
prediction: ['[CLS] not replacing avail not john meet. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.164 (perp=8.663, rec=0.443, cos=0.988), tot_loss_proj:2.801 [t=0.30s]
prediction: ['[CLS] not replacing avail not meet defeating. [SEP]']
[ 600/2000] tot_loss=3.151 (perp=8.772, rec=0.406, cos=0.990), tot_loss_proj:2.871 [t=0.30s]
prediction: ['[CLS] not lined avail not meet defeating. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.417 (perp=10.127, rec=0.404, cos=0.988), tot_loss_proj:3.153 [t=0.30s]
prediction: ['[CLS] notules avail not meet tries. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.196 (perp=9.027, rec=0.402, cos=0.989), tot_loss_proj:3.030 [t=0.30s]
prediction: ['[CLS] not availules not meet john. [SEP]']
[ 750/2000] tot_loss=3.184 (perp=9.027, rec=0.389, cos=0.991), tot_loss_proj:3.032 [t=0.30s]
prediction: ['[CLS] not availules not meet john. [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.118 (perp=8.733, rec=0.381, cos=0.990), tot_loss_proj:2.946 [t=0.30s]
prediction: ['[CLS] not availules mary meet john. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.122 (perp=8.733, rec=0.385, cos=0.991), tot_loss_proj:2.946 [t=0.30s]
prediction: ['[CLS] not availules mary meet john. [SEP]']
[ 900/2000] tot_loss=3.114 (perp=8.733, rec=0.377, cos=0.991), tot_loss_proj:2.957 [t=0.30s]
prediction: ['[CLS] not availules mary meet john. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.113 (perp=8.733, rec=0.376, cos=0.991), tot_loss_proj:2.949 [t=0.30s]
prediction: ['[CLS] not availules mary meet john. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.103 (perp=8.733, rec=0.366, cos=0.990), tot_loss_proj:2.945 [t=0.30s]
prediction: ['[CLS] not availules mary meet john. [SEP]']
[1050/2000] tot_loss=3.108 (perp=8.733, rec=0.371, cos=0.991), tot_loss_proj:2.944 [t=0.30s]
prediction: ['[CLS] not availules mary meet john. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.103 (perp=8.733, rec=0.366, cos=0.990), tot_loss_proj:2.942 [t=0.30s]
prediction: ['[CLS] not availules mary meet john. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.101 (perp=8.733, rec=0.364, cos=0.990), tot_loss_proj:2.949 [t=0.30s]
prediction: ['[CLS] not availules mary meet john. [SEP]']
[1200/2000] tot_loss=3.096 (perp=8.733, rec=0.360, cos=0.990), tot_loss_proj:2.950 [t=0.30s]
prediction: ['[CLS] not availules mary meet john. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.101 (perp=8.733, rec=0.364, cos=0.990), tot_loss_proj:2.945 [t=0.30s]
prediction: ['[CLS] not availules mary meet john. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.127 (perp=8.918, rec=0.353, cos=0.991), tot_loss_proj:2.560 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
[1350/2000] tot_loss=3.130 (perp=8.918, rec=0.355, cos=0.991), tot_loss_proj:2.561 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.133 (perp=8.918, rec=0.358, cos=0.991), tot_loss_proj:2.562 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.130 (perp=8.918, rec=0.355, cos=0.991), tot_loss_proj:2.559 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
[1500/2000] tot_loss=3.132 (perp=8.918, rec=0.357, cos=0.991), tot_loss_proj:2.563 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.129 (perp=8.918, rec=0.354, cos=0.991), tot_loss_proj:2.562 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.126 (perp=8.918, rec=0.351, cos=0.991), tot_loss_proj:2.556 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
[1650/2000] tot_loss=3.137 (perp=8.918, rec=0.361, cos=0.992), tot_loss_proj:2.567 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.121 (perp=8.918, rec=0.346, cos=0.992), tot_loss_proj:2.560 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.127 (perp=8.918, rec=0.352, cos=0.992), tot_loss_proj:2.566 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
[1800/2000] tot_loss=3.128 (perp=8.918, rec=0.353, cos=0.992), tot_loss_proj:2.566 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.129 (perp=8.918, rec=0.354, cos=0.992), tot_loss_proj:2.565 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.127 (perp=8.918, rec=0.352, cos=0.992), tot_loss_proj:2.567 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
[1950/2000] tot_loss=3.132 (perp=8.918, rec=0.357, cos=0.992), tot_loss_proj:2.564 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.128 (perp=8.918, rec=0.352, cos=0.992), tot_loss_proj:2.568 [t=0.30s]
prediction: ['[CLS] not avail dismiss mary meet john. [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS] john tries to meet not mary. [SEP]
========================
predicted: 
========================
[CLS] not avail dismiss mary meet john. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 75.000

[Aggregate metrics]:
rouge1     | fm: 82.910 | p: 83.065 | r: 82.778
rouge2     | fm: 45.426 | p: 45.448 | r: 45.407
rougeL     | fm: 76.243 | p: 76.385 | r: 76.085
rougeLsum  | fm: 76.587 | p: 76.667 | r: 76.455
r1fm+r2fm = 128.337

input #8 time: 0:11:47 | total time: 1:47:18


Running input #9 of 100.
reference: 
========================
The unidentified victim was apparently struck during the early morning hours.
========================
average of cosine similarity 0.9989536718470076
highest_index [0]
highest [0.9989536718470076]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  1996, 20293,  6778,  2001,  4593,  4930,  2076,  1996,  2220,
          2851,  2847,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]']
[Init] best rec loss: 0.9624911546707153 for ['[CLS]re took vie one ioc reading triangle willmour just grantedated [SEP]']
[Init] best rec loss: 0.9496376514434814 for ['[CLS]hearted rendition ho [CLS] factor supreme satinating concentrate baseman cent sin [SEP]']
[Init] best rec loss: 0.9309017658233643 for ['[CLS]ivated guests survivalr academie celebrates ultimately? invoked per substrates based [SEP]']
[Init] best rec loss: 0.9238309860229492 for ['[CLS] racedscu bob joke printing rush carpathian moreno anniversary on typical this [SEP]']
[Init] best rec loss: 0.9217661619186401 for ['[CLS] hair confederation qualify rid ni interchange semifinals colonel keystone pop equilibrium resting [SEP]']
[Init] best rec loss: 0.8988780975341797 for ['[CLS] located sure studio earlier ceased downpot engineering giles best includingtage [SEP]']
[Init] best perm rec loss: 0.8951287865638733 for ['[CLS]pot including engineering sure studio downtage located earlier best ceased giles [SEP]']
[Init] best perm rec loss: 0.895098865032196 for ['[CLS] engineering studio including down sure giles best ceased locatedtage earlierpot [SEP]']
[Init] best perm rec loss: 0.8906881809234619 for ['[CLS] downtagepot engineering best located sure ceased studio including earlier giles [SEP]']
[Init] best perm rec loss: 0.8904615640640259 for ['[CLS] studiopot besttage ceased sure including engineering giles located down earlier [SEP]']
[Init] best perm rec loss: 0.889165461063385 for ['[CLS] surepot down including earlier studio locatedtage giles engineering ceased best [SEP]']
[Init] best perm rec loss: 0.8891578316688538 for ['[CLS] down including engineeringpot located ceased earlier studiotage best giles sure [SEP]']
[Init] best perm rec loss: 0.8880653977394104 for ['[CLS]pot best including engineering ceased down giles sure locatedtage earlier studio [SEP]']
[Init] best perm rec loss: 0.8875789642333984 for ['[CLS]pot including studio giles ceased earlier sure engineeringtage down best located [SEP]']
[Init] best perm rec loss: 0.8867562413215637 for ['[CLS] sure down best ceased studio including engineering gilestage earlierpot located [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.915 (perp=11.639, rec=0.634, cos=0.953), tot_loss_proj:4.160 [t=0.29s]
prediction: ['[CLS] victim highway ( 2000sth their hit killed medley at ochreous natural [SEP]']
[ 100/2000] tot_loss=3.775 (perp=11.366, rec=0.506, cos=0.996), tot_loss_proj:4.182 [t=0.30s]
prediction: ['[CLS] victim unidentified. obtained victim unidentified dive apparently aground at rogue buyers [SEP]']
[ 150/2000] tot_loss=3.415 (perp=10.594, rec=0.415, cos=0.881), tot_loss_proj:3.884 [t=0.30s]
prediction: ['[CLS] victim unidentified. obtained victim unidentified ensued apparently assessment at rogueerly [SEP]']
[ 200/2000] tot_loss=3.478 (perp=10.707, rec=0.409, cos=0.928), tot_loss_proj:3.892 [t=0.30s]
prediction: ['[CLS] victim unidentified. obtained victim unidentified episode apparently injury around victim exposure [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.907 (perp=8.828, rec=0.342, cos=0.799), tot_loss_proj:3.534 [t=0.30s]
prediction: ['[CLS] victim unidentified. martha victim apparently struck another injury at victim exposure [SEP]']
[ 300/2000] tot_loss=2.899 (perp=8.738, rec=0.324, cos=0.828), tot_loss_proj:3.674 [t=0.30s]
prediction: ['[CLS] victim unidentified. defensive victim apparently struck another injury during arrested exposure [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.887 (perp=9.028, rec=0.297, cos=0.783), tot_loss_proj:3.653 [t=0.30s]
prediction: ['[CLS] victim unidentified. another victim apparently struck defensive robbery during alleged exposure [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.210 (perp=10.739, rec=0.267, cos=0.794), tot_loss_proj:3.906 [t=0.30s]
prediction: ['[CLS] victim unidentified. was victim apparently struck defensive gaza during alleged exposure [SEP]']
[ 450/2000] tot_loss=3.354 (perp=11.373, rec=0.275, cos=0.804), tot_loss_proj:4.014 [t=0.30s]
prediction: ['[CLS] victim unidentified. was victim apparently struck defensive gaza during alleged slammed [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.532 (perp=12.247, rec=0.279, cos=0.805), tot_loss_proj:4.174 [t=0.30s]
prediction: ['[CLS] victim unidentified was brief victim apparently struck defensive gaza during alleged cerambycidae [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.260 (perp=11.098, rec=0.261, cos=0.779), tot_loss_proj:3.953 [t=0.30s]
prediction: ['[CLS] unidentified victim was. victim apparently struck defensive gaza during alleged eater [SEP]']
[ 600/2000] tot_loss=3.270 (perp=11.098, rec=0.249, cos=0.801), tot_loss_proj:3.955 [t=0.30s]
prediction: ['[CLS] unidentified victim was. victim apparently struck defensive gaza during alleged eater [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=3.103 (perp=10.291, rec=0.248, cos=0.797), tot_loss_proj:3.826 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck defensive gaza during alleged eater [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.108 (perp=10.291, rec=0.244, cos=0.806), tot_loss_proj:3.824 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck defensive gaza during alleged eater [SEP]']
[ 750/2000] tot_loss=3.095 (perp=10.291, rec=0.239, cos=0.797), tot_loss_proj:3.823 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck defensive gaza during alleged eater [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.009 (perp=9.839, rec=0.243, cos=0.799), tot_loss_proj:3.774 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck defensive gaza during alleged occurs [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.925 (perp=9.394, rec=0.247, cos=0.799), tot_loss_proj:3.780 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during alleged defensive occurs [SEP]']
[ 900/2000] tot_loss=3.122 (perp=10.413, rec=0.236, cos=0.803), tot_loss_proj:3.873 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during alleged defensiveleader [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.117 (perp=10.413, rec=0.231, cos=0.803), tot_loss_proj:3.870 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during alleged defensiveleader [SEP]']
Attempt swap
[1000/2000] tot_loss=3.128 (perp=10.413, rec=0.232, cos=0.813), tot_loss_proj:3.869 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during alleged defensiveleader [SEP]']
[1050/2000] tot_loss=3.115 (perp=10.413, rec=0.224, cos=0.808), tot_loss_proj:3.870 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during alleged defensiveleader [SEP]']
Attempt swap
[1100/2000] tot_loss=3.091 (perp=10.241, rec=0.230, cos=0.813), tot_loss_proj:3.908 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during vice defensiveleader [SEP]']
Attempt swap
[1150/2000] tot_loss=3.084 (perp=10.241, rec=0.224, cos=0.812), tot_loss_proj:3.911 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during vice defensiveleader [SEP]']
[1200/2000] tot_loss=2.950 (perp=9.573, rec=0.224, cos=0.812), tot_loss_proj:3.765 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during vice defensive occurs [SEP]']
Attempt swap
[1250/2000] tot_loss=3.082 (perp=10.241, rec=0.221, cos=0.813), tot_loss_proj:3.907 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during vice defensiveleader [SEP]']
Attempt swap
[1300/2000] tot_loss=3.091 (perp=10.241, rec=0.227, cos=0.816), tot_loss_proj:3.911 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during vice defensiveleader [SEP]']
[1350/2000] tot_loss=3.094 (perp=10.241, rec=0.229, cos=0.817), tot_loss_proj:3.909 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during vice defensiveleader [SEP]']
Attempt swap
[1400/2000] tot_loss=3.083 (perp=10.241, rec=0.217, cos=0.818), tot_loss_proj:3.913 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during vice defensiveleader [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=3.129 (perp=10.245, rec=0.258, cos=0.822), tot_loss_proj:3.933 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during defensive vicetwined [SEP]']
[1500/2000] tot_loss=3.097 (perp=10.245, rec=0.227, cos=0.821), tot_loss_proj:3.935 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during defensive vicetwined [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=3.073 (perp=10.104, rec=0.232, cos=0.820), tot_loss_proj:3.930 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during vicetwined defensive [SEP]']
Attempt swap
[1600/2000] tot_loss=3.066 (perp=10.104, rec=0.225, cos=0.821), tot_loss_proj:3.925 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during vicetwined defensive [SEP]']
[1650/2000] tot_loss=3.192 (perp=10.704, rec=0.228, cos=0.823), tot_loss_proj:3.986 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza during incidentstwined defensive [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=3.187 (perp=10.676, rec=0.233, cos=0.819), tot_loss_proj:3.915 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently struck gaza duringtwined defensive alleged [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=3.127 (perp=10.353, rec=0.226, cos=0.831), tot_loss_proj:3.826 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently strucktwined gaza during defensive alleged [SEP]']
[1800/2000] tot_loss=3.126 (perp=10.353, rec=0.233, cos=0.823), tot_loss_proj:3.826 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently strucktwined gaza during defensive alleged [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=3.087 (perp=10.230, rec=0.223, cos=0.818), tot_loss_proj:3.859 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently strucktwined gaza during alleged defensive [SEP]']
Attempt swap
[1900/2000] tot_loss=3.100 (perp=10.230, rec=0.235, cos=0.820), tot_loss_proj:3.855 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently strucktwined gaza during alleged defensive [SEP]']
[1950/2000] tot_loss=3.096 (perp=10.230, rec=0.230, cos=0.820), tot_loss_proj:3.857 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently strucktwined gaza during alleged defensive [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=3.086 (perp=10.173, rec=0.230, cos=0.821), tot_loss_proj:3.803 [t=0.30s]
prediction: ['[CLS] victim was unidentified. victim apparently strucktwined gaza alleged during defensive [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]
========================
predicted: 
========================
[CLS] victim was unidentified. victim apparently struck gaza during vice defensive occurs [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.538 | p: 61.538 | r: 61.538
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 53.846 | p: 53.846 | r: 53.846
rougeLsum  | fm: 53.846 | p: 53.846 | r: 53.846
r1fm+r2fm = 86.538

[Aggregate metrics]:
rouge1     | fm: 80.593 | p: 80.745 | r: 80.451
rouge2     | fm: 43.023 | p: 43.062 | r: 43.005
rougeL     | fm: 73.932 | p: 74.131 | r: 73.718
rougeLsum  | fm: 74.432 | p: 74.580 | r: 74.333
r1fm+r2fm = 123.616

input #9 time: 0:11:47 | total time: 1:59:06


Running input #10 of 100.
reference: 
========================
the logs piled the barge high.
========================
average of cosine similarity 0.9988049470631835
highest_index [0]
highest [0.9988049470631835]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996, 15664, 17835,  1996, 19398,  2152,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the logs piled the barge high. [SEP]']
[Init] best rec loss: 0.822091817855835 for ['[CLS] my honey queensus suchbble [CLS] [SEP]']
[Init] best rec loss: 0.8218231797218323 for ['[CLS] shots acheron outsider associations seed an using [SEP]']
[Init] best rec loss: 0.7377941608428955 for ['[CLS] papua sorrow arden [MASK] provides sidri [SEP]']
[Init] best rec loss: 0.6565461754798889 for ['[CLS] excellence stationary bread otherwise heel least least [SEP]']
[Init] best perm rec loss: 0.6431365609169006 for ['[CLS] least otherwise heel excellence stationary bread least [SEP]']
[Init] best perm rec loss: 0.6392791867256165 for ['[CLS] least excellence least bread stationary heel otherwise [SEP]']
[Init] best perm rec loss: 0.6387413144111633 for ['[CLS] excellence least least stationary heel bread otherwise [SEP]']
[Init] best perm rec loss: 0.6318944692611694 for ['[CLS] otherwise least bread least stationary excellence heel [SEP]']
[Init] best perm rec loss: 0.6315259337425232 for ['[CLS] least excellence otherwise bread stationary least heel [SEP]']
[Init] best perm rec loss: 0.6292210817337036 for ['[CLS] stationary bread least least otherwise excellence heel [SEP]']
[Init] best perm rec loss: 0.6274542808532715 for ['[CLS] least otherwise stationary least bread excellence heel [SEP]']
[Init] best perm rec loss: 0.6200074553489685 for ['[CLS] least otherwise stationary least excellence heel bread [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.250 (perp=9.886, rec=0.248, cos=0.025), tot_loss_proj:3.846 [t=0.29s]
prediction: ['[CLS] piled piled stories piled piled.. [SEP]']
[ 100/2000] tot_loss=2.125 (perp=9.721, rec=0.167, cos=0.013), tot_loss_proj:3.508 [t=0.30s]
prediction: ['[CLS] the piled barge piled piled high logs [SEP]']
[ 150/2000] tot_loss=2.070 (perp=9.721, rec=0.116, cos=0.009), tot_loss_proj:3.495 [t=0.30s]
prediction: ['[CLS] the piled barge piled piled high logs [SEP]']
[ 200/2000] tot_loss=2.156 (perp=10.231, rec=0.104, cos=0.006), tot_loss_proj:3.636 [t=0.30s]
prediction: ['[CLS] the piled barge piled the high logs [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.105 (perp=9.446, rec=0.205, cos=0.011), tot_loss_proj:3.714 [t=0.30s]
prediction: ['[CLS] the the piled barge piled high logs [SEP]']
[ 300/2000] tot_loss=2.124 (perp=9.963, rec=0.125, cos=0.006), tot_loss_proj:3.643 [t=0.30s]
prediction: ['[CLS] the. piled barge piled high logs [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.255 (perp=10.379, rec=0.170, cos=0.009), tot_loss_proj:3.039 [t=0.30s]
prediction: ['[CLS] the logs piled barge piled high the [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.913 (perp=8.829, rec=0.141, cos=0.007), tot_loss_proj:2.765 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
[ 450/2000] tot_loss=1.898 (perp=8.829, rec=0.126, cos=0.006), tot_loss_proj:2.769 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.878 (perp=8.829, rec=0.106, cos=0.006), tot_loss_proj:2.758 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.879 (perp=8.829, rec=0.107, cos=0.006), tot_loss_proj:2.765 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
[ 600/2000] tot_loss=1.887 (perp=8.829, rec=0.116, cos=0.006), tot_loss_proj:2.765 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.880 (perp=8.829, rec=0.108, cos=0.006), tot_loss_proj:2.769 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.874 (perp=8.829, rec=0.102, cos=0.006), tot_loss_proj:2.767 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
[ 750/2000] tot_loss=1.859 (perp=8.829, rec=0.087, cos=0.006), tot_loss_proj:2.763 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.884 (perp=8.829, rec=0.112, cos=0.006), tot_loss_proj:2.771 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.862 (perp=8.829, rec=0.090, cos=0.006), tot_loss_proj:2.761 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
[ 900/2000] tot_loss=1.882 (perp=8.829, rec=0.110, cos=0.006), tot_loss_proj:2.766 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.856 (perp=8.829, rec=0.085, cos=0.006), tot_loss_proj:2.763 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1000/2000] tot_loss=1.875 (perp=8.829, rec=0.104, cos=0.006), tot_loss_proj:2.768 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
[1050/2000] tot_loss=1.853 (perp=8.829, rec=0.082, cos=0.006), tot_loss_proj:2.764 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1100/2000] tot_loss=1.866 (perp=8.829, rec=0.095, cos=0.006), tot_loss_proj:2.767 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1150/2000] tot_loss=1.858 (perp=8.829, rec=0.087, cos=0.006), tot_loss_proj:2.771 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
[1200/2000] tot_loss=1.874 (perp=8.829, rec=0.102, cos=0.006), tot_loss_proj:2.762 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1250/2000] tot_loss=1.864 (perp=8.829, rec=0.093, cos=0.006), tot_loss_proj:2.763 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1300/2000] tot_loss=1.856 (perp=8.829, rec=0.084, cos=0.006), tot_loss_proj:2.761 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
[1350/2000] tot_loss=1.867 (perp=8.829, rec=0.095, cos=0.006), tot_loss_proj:2.767 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1400/2000] tot_loss=1.864 (perp=8.829, rec=0.093, cos=0.005), tot_loss_proj:2.767 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1450/2000] tot_loss=1.851 (perp=8.829, rec=0.079, cos=0.005), tot_loss_proj:2.767 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
[1500/2000] tot_loss=1.869 (perp=8.829, rec=0.098, cos=0.005), tot_loss_proj:2.765 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1550/2000] tot_loss=1.865 (perp=8.829, rec=0.094, cos=0.005), tot_loss_proj:2.764 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1600/2000] tot_loss=1.859 (perp=8.829, rec=0.088, cos=0.005), tot_loss_proj:2.767 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
[1650/2000] tot_loss=1.860 (perp=8.829, rec=0.089, cos=0.005), tot_loss_proj:2.762 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1700/2000] tot_loss=1.865 (perp=8.829, rec=0.093, cos=0.005), tot_loss_proj:2.770 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1750/2000] tot_loss=1.858 (perp=8.829, rec=0.086, cos=0.005), tot_loss_proj:2.763 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
[1800/2000] tot_loss=1.858 (perp=8.829, rec=0.087, cos=0.005), tot_loss_proj:2.767 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1850/2000] tot_loss=1.870 (perp=8.829, rec=0.099, cos=0.005), tot_loss_proj:2.764 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[1900/2000] tot_loss=1.848 (perp=8.829, rec=0.077, cos=0.005), tot_loss_proj:2.768 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
[1950/2000] tot_loss=1.866 (perp=8.829, rec=0.094, cos=0.005), tot_loss_proj:2.758 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Attempt swap
[2000/2000] tot_loss=1.875 (perp=8.829, rec=0.104, cos=0.005), tot_loss_proj:2.757 [t=0.30s]
prediction: ['[CLS] the logs piled the barge piled high [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] the logs piled the barge high. [SEP]
========================
predicted: 
========================
[CLS] the logs piled the barge piled high [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 80.000 | p: 75.000 | r: 85.714
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 174.118

[Aggregate metrics]:
rouge1     | fm: 81.992 | p: 81.656 | r: 82.408
rouge2     | fm: 46.680 | p: 46.269 | r: 47.177
rougeL     | fm: 75.616 | p: 75.202 | r: 75.977
rougeLsum  | fm: 76.296 | p: 75.880 | r: 76.628
r1fm+r2fm = 128.672

input #10 time: 0:11:48 | total time: 2:10:55


Running input #11 of 100.
reference: 
========================
During the early evening, Saturn can be found in the north, while Jupiter rises in the east.
========================
average of cosine similarity 0.9988571725588224
highest_index [0]
highest [0.9988571725588224]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2076,  1996,  2220,  3944,  1010, 14784,  2064,  2022,  2179,
          1999,  1996,  2167,  1010,  2096, 13035,  9466,  1999,  1996,  2264,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]']
[Init] best rec loss: 0.9447009563446045 for ['[CLS] triedya radcliffe whitney pepper since only ranges beingshibreaker sharedpower kn bn nest o day you detention [SEP]']
[Init] best rec loss: 0.9030767679214478 for ['[CLS] degreess become panted eric like there ⟩nt obeyed gwen supernatural living mexicanard consider launch due griffin block [SEP]']
[Init] best rec loss: 0.8950230479240417 for ['[CLS] poster round around globe magic cameo occupation bash label ever mtv unknownh fund ₹ school famous skillsmat sham [SEP]']
[Init] best rec loss: 0.8759126663208008 for ['[CLS] looks neither sold transportperationum after winning wade laying co licked deep lea bramont mia absentrosis pub [SEP]']
[Init] best rec loss: 0.8679707646369934 for ['[CLS] il [SEP] of ny processes tour madam enchanted woody due hurt free red while studio ever arun beethoven double interval [SEP]']
[Init] best perm rec loss: 0.8643759489059448 for ['[CLS] of red while ny free enchanted ever woody hurt due double studio madam processes [SEP] arun beethoven il interval tour [SEP]']
[Init] best perm rec loss: 0.8641491532325745 for ['[CLS] hurt double studio of ny interval tour free red woody [SEP] madam ever il arun beethoven while due enchanted processes [SEP]']
[Init] best perm rec loss: 0.8641307353973389 for ['[CLS] red ny while woody [SEP] interval double studio due tour hurt madam processes il arun ever enchanted of free beethoven [SEP]']
[Init] best perm rec loss: 0.8631245493888855 for ['[CLS] madam ever ny il processes of interval while tour [SEP] hurt free double woody due beethoven enchanted red arun studio [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.632 (perp=12.217, rec=0.444, cos=0.745), tot_loss_proj:4.314 [t=0.30s]
prediction: ['[CLS] outside development rising in bronze - hitsters producers in during sun standard rising jupiter old enrique jupiter assess post [SEP]']
[ 100/2000] tot_loss=3.717 (perp=11.943, rec=0.425, cos=0.904), tot_loss_proj:4.198 [t=0.30s]
prediction: ['[CLS] evening development african, jupiter during ve death dawn north huey sun hercules saturn jupiter legacy enrique jupiter decides news [SEP]']
[ 150/2000] tot_loss=3.603 (perp=11.874, rec=0.354, cos=0.874), tot_loss_proj:4.171 [t=0.30s]
prediction: ['[CLS] evening were southern. jupiter during takes death saturn north occurs other hercules saturn jupiter japan enrique jupiter apparently news [SEP]']
[ 200/2000] tot_loss=3.387 (perp=10.684, rec=0.324, cos=0.926), tot_loss_proj:3.945 [t=0.30s]
prediction: ['[CLS] evening were early. jupiter during is grandfather saturn north occurs nearly hercules saturn jupiter the enrique jupiter apparently news [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.219 (perp=10.102, rec=0.307, cos=0.891), tot_loss_proj:3.876 [t=0.30s]
prediction: ['[CLS] evening were early. jupiter set is hanging saturn east occurs nearly hercules saturn jupiter the shrub jupiter seems during [SEP]']
[ 300/2000] tot_loss=3.453 (perp=11.085, rec=0.313, cos=0.923), tot_loss_proj:4.047 [t=0.31s]
prediction: ['[CLS] evening during early. jupiter set isoga saturn north occurs nearly declared saturn jupiter the shrub saturn is during [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.442 (perp=11.061, rec=0.323, cos=0.906), tot_loss_proj:4.080 [t=0.30s]
prediction: ['[CLS] evening,ffen carried ¨ set is than saturn east occurs nearly circa jupiter jupiter the shrub saturn is during [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.245 (perp=10.213, rec=0.293, cos=0.910), tot_loss_proj:3.844 [t=0.30s]
prediction: ['[CLS] evening, although carried jupiter is set when saturn east jupiter nearly circa jupiter jupiter the cerambycidae saturn is during [SEP]']
[ 450/2000] tot_loss=3.314 (perp=10.492, rec=0.282, cos=0.933), tot_loss_proj:3.886 [t=0.30s]
prediction: ['[CLS] evening during although carried jupiter is set when saturn east jupiter nearly circa jupiter jupiter ; smashwords saturn is during [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.199 (perp=10.119, rec=0.257, cos=0.918), tot_loss_proj:3.832 [t=0.30s]
prediction: ['[CLS] evening during arrived carried jupiter is ) when saturn east jupiter south circa jupiter jupiter ; while saturn is during [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.167 (perp=9.962, rec=0.258, cos=0.916), tot_loss_proj:3.794 [t=0.30s]
prediction: ['[CLS] evening whose during carried jupiter finds ) when saturn east jupiter south circa jupiter jupiter, while saturn is during [SEP]']
[ 600/2000] tot_loss=3.075 (perp=9.580, rec=0.244, cos=0.915), tot_loss_proj:3.731 [t=0.31s]
prediction: ['[CLS] evening arrived during carried jupiter finds ) when saturn east jupiter south circa jupiterzziness, while saturn is during [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.258 (perp=10.385, rec=0.273, cos=0.908), tot_loss_proj:3.916 [t=0.30s]
prediction: ['[CLS] evening blackwell during east sounded rises ) when saturn carried jupiter nearly circa jupiter gently, while saturn is during [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.980 (perp=9.056, rec=0.255, cos=0.914), tot_loss_proj:3.669 [t=0.30s]
prediction: ['[CLS] evening arrived during eastᵐ rises ) when jupiter carried jupiter south circa saturn gently, while saturn is during [SEP]']
[ 750/2000] tot_loss=3.018 (perp=9.208, rec=0.259, cos=0.918), tot_loss_proj:3.691 [t=0.30s]
prediction: ['[CLS] evening arrived during eastᵐ found ) when jupiter carried jupiter south circa saturn gently, while saturn is during [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.115 (perp=9.745, rec=0.251, cos=0.916), tot_loss_proj:3.783 [t=0.30s]
prediction: ['[CLS] evening blackwell during east north found ) when jupiter carried jupiter gently circa saturn became, while saturn is during [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.867 (perp=8.520, rec=0.246, cos=0.918), tot_loss_proj:3.537 [t=0.30s]
prediction: ['[CLS] evening arrived during north east found ) when jupiter carried jupiter gently circa saturn equatorial, while saturn is during [SEP]']
[ 900/2000] tot_loss=3.016 (perp=9.206, rec=0.251, cos=0.924), tot_loss_proj:3.628 [t=0.31s]
prediction: ['[CLS] evening arrived during north east found highest when jupiter carried jupiter gently circa saturn equatorial, while saturn is during [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.052 (perp=9.381, rec=0.249, cos=0.928), tot_loss_proj:3.736 [t=0.30s]
prediction: ['[CLS] evening arrived during found east found during when jupiter carried jupiter gently circa saturn equatorial, while saturn is ) [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.957 (perp=8.930, rec=0.248, cos=0.923), tot_loss_proj:3.644 [t=0.30s]
prediction: ['[CLS] evening found during remaining east found during when jupiter carried jupiter slightly considers saturn equatorial, while saturn is ) [SEP]']
[1050/2000] tot_loss=2.933 (perp=8.818, rec=0.241, cos=0.929), tot_loss_proj:3.580 [t=0.30s]
prediction: ['[CLS] evening found during remaining east found during when jupiter carried jupiter slightly considers saturn equatorial, while saturn is from [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.053 (perp=9.421, rec=0.236, cos=0.933), tot_loss_proj:3.740 [t=0.30s]
prediction: ['[CLS] evening found during east remaining found during when jupiter carried jupiter slightly brooke saturn equatorial, while saturn is ) [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.016 (perp=9.238, rec=0.241, cos=0.927), tot_loss_proj:3.636 [t=0.30s]
prediction: ['[CLS] evening found during east is found during when jupiter carried jupiter slightly brooke saturn equatorial, while saturn remaining from [SEP]']
[1200/2000] tot_loss=3.030 (perp=9.295, rec=0.238, cos=0.933), tot_loss_proj:3.625 [t=0.31s]
prediction: ['[CLS] evening found during east is found during when jupiter carried jupiter slightly brooke saturn african, while saturn remaining from [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.903 (perp=8.657, rec=0.239, cos=0.933), tot_loss_proj:3.491 [t=0.30s]
prediction: ['[CLS] evening found during east is found during when jupiter carried jupiter considers slightly saturn african, while saturn remaining from [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.871 (perp=8.500, rec=0.236, cos=0.936), tot_loss_proj:3.485 [t=0.30s]
prediction: ['[CLS] evening found during east is found during when jupiter from jupiter considers slightly saturn african, while saturn remaining carried [SEP]']
[1350/2000] tot_loss=2.870 (perp=8.500, rec=0.239, cos=0.931), tot_loss_proj:3.483 [t=0.30s]
prediction: ['[CLS] evening found during east is found during when jupiter from jupiter considers slightly saturn african, while saturn remaining carried [SEP]']
Attempt swap
[1400/2000] tot_loss=2.865 (perp=8.477, rec=0.232, cos=0.937), tot_loss_proj:3.463 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter considers slightly saturn african, while saturn remaining carried [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.847 (perp=8.423, rec=0.227, cos=0.935), tot_loss_proj:3.469 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while saturn remaining carried [SEP]']
[1500/2000] tot_loss=2.877 (perp=8.531, rec=0.237, cos=0.933), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while saturn remainingoga [SEP]']
Attempt swap
[1550/2000] tot_loss=2.873 (perp=8.531, rec=0.232, cos=0.935), tot_loss_proj:3.481 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while saturn remainingoga [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.860 (perp=8.446, rec=0.235, cos=0.936), tot_loss_proj:3.477 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while remaining saturnoga [SEP]']
[1650/2000] tot_loss=2.854 (perp=8.446, rec=0.230, cos=0.935), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while remaining saturnoga [SEP]']
Attempt swap
[1700/2000] tot_loss=2.858 (perp=8.446, rec=0.234, cos=0.935), tot_loss_proj:3.481 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while remaining saturnoga [SEP]']
Attempt swap
[1750/2000] tot_loss=2.846 (perp=8.446, rec=0.222, cos=0.935), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while remaining saturnoga [SEP]']
[1800/2000] tot_loss=2.856 (perp=8.446, rec=0.231, cos=0.936), tot_loss_proj:3.476 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while remaining saturnoga [SEP]']
Attempt swap
[1850/2000] tot_loss=2.858 (perp=8.446, rec=0.233, cos=0.935), tot_loss_proj:3.479 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while remaining saturnoga [SEP]']
Attempt swap
[1900/2000] tot_loss=2.852 (perp=8.446, rec=0.226, cos=0.937), tot_loss_proj:3.477 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while remaining saturnoga [SEP]']
[1950/2000] tot_loss=2.859 (perp=8.446, rec=0.233, cos=0.937), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while remaining saturnoga [SEP]']
Attempt swap
[2000/2000] tot_loss=2.856 (perp=8.446, rec=0.229, cos=0.937), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while remaining saturnoga [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]
========================
predicted: 
========================
[CLS] evening found during east is found early when jupiter from jupiter slightly considers saturn african, while remaining saturnoga [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 51.282 | p: 50.000 | r: 52.632
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 30.769 | p: 30.000 | r: 31.579
rougeLsum  | fm: 30.769 | p: 30.000 | r: 31.579
r1fm+r2fm = 51.282

[Aggregate metrics]:
rouge1     | fm: 79.437 | p: 78.985 | r: 79.926
rouge2     | fm: 42.658 | p: 42.326 | r: 43.231
rougeL     | fm: 71.763 | p: 71.406 | r: 72.239
rougeLsum  | fm: 72.288 | p: 71.919 | r: 72.714
r1fm+r2fm = 122.095

input #11 time: 0:12:06 | total time: 2:23:01


Running input #12 of 100.
reference: 
========================
He walked up the hill.
========================
average of cosine similarity 0.9991311148017902
highest_index [0]
highest [0.9991311148017902]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2002, 2939, 2039, 1996, 2940, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he walked up the hill. [SEP]']
[Init] best rec loss: 0.9668018221855164 for ['[CLS] stars sans january canvas gdansk beauty [SEP]']
[Init] best rec loss: 0.9495040774345398 for ['[CLS]thevert banks councillors respective puerto [SEP]']
[Init] best rec loss: 0.926581859588623 for ['[CLS] probably block tilt cavesree elevation [SEP]']
[Init] best rec loss: 0.9263384938240051 for ['[CLS]bling rootednifiednor still writing [SEP]']
[Init] best rec loss: 0.8965572714805603 for ['[CLS] could bar silver development structure ] [SEP]']
[Init] best rec loss: 0.8950711488723755 for ['[CLS] voting hockey api platform drive blame [SEP]']
[Init] best rec loss: 0.89018315076828 for ['[CLS] participate americanauncehide ds platform [SEP]']
[Init] best perm rec loss: 0.8897976279258728 for ['[CLS] participatehide platform americana dsunce [SEP]']
[Init] best perm rec loss: 0.8879168629646301 for ['[CLS] participate americanaunce platformhide ds [SEP]']
[Init] best perm rec loss: 0.8860771059989929 for ['[CLS] dsuncehide platform participate americana [SEP]']
[Init] best perm rec loss: 0.8846858143806458 for ['[CLS] participateunce americana platform dshide [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.040 (perp=7.620, rec=0.624, cos=0.892), tot_loss_proj:3.334 [t=0.29s]
prediction: ['[CLS] the walked at walking. ; [SEP]']
[ 100/2000] tot_loss=2.654 (perp=9.017, rec=0.577, cos=0.273), tot_loss_proj:3.566 [t=0.30s]
prediction: ['[CLS] walked hill at walking. approximately [SEP]']
[ 150/2000] tot_loss=2.197 (perp=9.846, rec=0.210, cos=0.019), tot_loss_proj:3.752 [t=0.30s]
prediction: ['[CLS] he hill up up walked walk [SEP]']
[ 200/2000] tot_loss=1.913 (perp=8.841, rec=0.136, cos=0.009), tot_loss_proj:3.584 [t=0.30s]
prediction: ['[CLS] he hill up hill walked walk [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.606 (perp=7.356, rec=0.124, cos=0.011), tot_loss_proj:3.139 [t=0.30s]
prediction: ['[CLS] he hill up the hill walked [SEP]']
[ 300/2000] tot_loss=1.590 (perp=7.356, rec=0.110, cos=0.009), tot_loss_proj:3.134 [t=0.30s]
prediction: ['[CLS] he hill up the hill walked [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.305 (perp=5.828, rec=0.128, cos=0.011), tot_loss_proj:1.499 [t=0.30s]
prediction: ['[CLS] he walked up the hill hill [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.269 (perp=5.732, rec=0.113, cos=0.010), tot_loss_proj:3.005 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
[ 450/2000] tot_loss=1.261 (perp=5.732, rec=0.105, cos=0.009), tot_loss_proj:3.005 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.247 (perp=5.732, rec=0.092, cos=0.009), tot_loss_proj:2.994 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.255 (perp=5.732, rec=0.101, cos=0.008), tot_loss_proj:2.993 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
[ 600/2000] tot_loss=1.247 (perp=5.732, rec=0.092, cos=0.008), tot_loss_proj:2.991 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.249 (perp=5.732, rec=0.094, cos=0.008), tot_loss_proj:2.992 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.245 (perp=5.732, rec=0.091, cos=0.008), tot_loss_proj:2.988 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
[ 750/2000] tot_loss=1.248 (perp=5.732, rec=0.094, cos=0.008), tot_loss_proj:2.987 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.246 (perp=5.732, rec=0.092, cos=0.008), tot_loss_proj:2.991 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.248 (perp=5.732, rec=0.094, cos=0.008), tot_loss_proj:2.988 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
[ 900/2000] tot_loss=1.246 (perp=5.732, rec=0.092, cos=0.008), tot_loss_proj:2.986 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.239 (perp=5.732, rec=0.085, cos=0.008), tot_loss_proj:2.982 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1000/2000] tot_loss=1.240 (perp=5.732, rec=0.086, cos=0.008), tot_loss_proj:2.983 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
[1050/2000] tot_loss=1.245 (perp=5.732, rec=0.091, cos=0.008), tot_loss_proj:2.979 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1100/2000] tot_loss=1.237 (perp=5.732, rec=0.083, cos=0.008), tot_loss_proj:2.988 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1150/2000] tot_loss=1.238 (perp=5.732, rec=0.084, cos=0.008), tot_loss_proj:2.984 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
[1200/2000] tot_loss=1.237 (perp=5.732, rec=0.083, cos=0.008), tot_loss_proj:2.986 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1250/2000] tot_loss=1.238 (perp=5.732, rec=0.084, cos=0.008), tot_loss_proj:2.982 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1300/2000] tot_loss=1.245 (perp=5.732, rec=0.091, cos=0.008), tot_loss_proj:2.980 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
[1350/2000] tot_loss=1.248 (perp=5.732, rec=0.094, cos=0.008), tot_loss_proj:2.993 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1400/2000] tot_loss=1.244 (perp=5.732, rec=0.090, cos=0.008), tot_loss_proj:2.984 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1450/2000] tot_loss=1.248 (perp=5.732, rec=0.094, cos=0.008), tot_loss_proj:2.983 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
[1500/2000] tot_loss=1.243 (perp=5.732, rec=0.089, cos=0.008), tot_loss_proj:2.981 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1550/2000] tot_loss=1.248 (perp=5.732, rec=0.094, cos=0.008), tot_loss_proj:2.986 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1600/2000] tot_loss=1.245 (perp=5.732, rec=0.092, cos=0.008), tot_loss_proj:2.980 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
[1650/2000] tot_loss=1.253 (perp=5.732, rec=0.099, cos=0.007), tot_loss_proj:2.986 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1700/2000] tot_loss=1.241 (perp=5.732, rec=0.087, cos=0.007), tot_loss_proj:2.984 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1750/2000] tot_loss=1.238 (perp=5.732, rec=0.084, cos=0.007), tot_loss_proj:2.986 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
[1800/2000] tot_loss=1.237 (perp=5.732, rec=0.083, cos=0.007), tot_loss_proj:2.987 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1850/2000] tot_loss=1.243 (perp=5.732, rec=0.090, cos=0.007), tot_loss_proj:2.982 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[1900/2000] tot_loss=1.240 (perp=5.732, rec=0.086, cos=0.007), tot_loss_proj:2.984 [t=0.39s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
[1950/2000] tot_loss=1.230 (perp=5.732, rec=0.076, cos=0.007), tot_loss_proj:2.986 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Attempt swap
[2000/2000] tot_loss=1.240 (perp=5.732, rec=0.086, cos=0.007), tot_loss_proj:2.984 [t=0.30s]
prediction: ['[CLS] he walked hill up the hill [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] he walked up the hill. [SEP]
========================
predicted: 
========================
[CLS] he walked hill up the hill [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 80.376 | p: 79.403 | r: 81.169
rouge2     | fm: 45.713 | p: 44.916 | r: 46.585
rougeL     | fm: 73.693 | p: 72.931 | r: 74.537
rougeLsum  | fm: 74.252 | p: 73.402 | r: 75.020
r1fm+r2fm = 126.089

input #12 time: 0:11:47 | total time: 2:34:48


Running input #13 of 100.
reference: 
========================
It is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters.
========================
average of cosine similarity 0.998980601643577
highest_index [0]
highest [0.998980601643577]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2009,  2003,  2023,  3291,  2008,  1996, 10076,  2017,  9611,
          1996,  2062,  4089,  2017,  1005,  2222, 13225,  1996, 12455,  2039,
          2012,  5971,  4075,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]"]
[Init] best rec loss: 0.922694206237793 for ['[CLS] id brand fault sciences treated allows american person perceive directions alleyulating pentagonette modern declaration material devoid having participation artistic ricardooration [SEP]']
[Init] best rec loss: 0.8703395128250122 for ['[CLS] independenternussnor beat shelley pattierty better newspapers chanceocation customsdi broke nolanrona tennesseeed drummer worked analog nap [SEP]']
[Init] best rec loss: 0.847419261932373 for ['[CLS] miles spoil mainrew half action stamps outside let cole highest trans states gregor policeni cassidy rose town wash fey daniel elizabeth [SEP]']
[Init] best perm rec loss: 0.8468120098114014 for ['[CLS] action half elizabeth town cassidy washnirew miles cole highest fey outside rose daniel police spoil main gregor let trans states stamps [SEP]']
[Init] best perm rec loss: 0.8462603092193604 for ['[CLS] action miles trans town states cassidy danielni let cole police mainrew outside spoil rose fey wash highest stamps gregor half elizabeth [SEP]']
[Init] best perm rec loss: 0.8429116606712341 for ['[CLS] gregor elizabethni spoil wash townrew half cole daniel fey stamps let states outside main trans rose highest miles police cassidy action [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.931 (perp=12.701, rec=0.554, cos=0.837), tot_loss_proj:4.437 [t=0.30s]
prediction: ['[CLS] up pete / ― minds win [MASK]. west stonesverance football old workers guard spray farm ]tom pitcher bonusutable care [SEP]']
[ 100/2000] tot_loss=3.802 (perp=13.023, rec=0.451, cos=0.746), tot_loss_proj:4.510 [t=0.30s]
prediction: ['[CLS] is least hymn ― somehow win [MASK] record easilyurrent kill vegas fucked abbey guardcutless ]tom rebuilt assistantutable residents [SEP]']
[ 150/2000] tot_loss=3.772 (perp=13.372, rec=0.405, cos=0.693), tot_loss_proj:4.557 [t=0.30s]
prediction: ['[CLS] is especially hymn ী somehow win a ; easilythes kill played alistair task decisive solve stock ] federal berth assistant satisfy residents [SEP]']
[ 200/2000] tot_loss=3.565 (perp=12.368, rec=0.384, cos=0.708), tot_loss_proj:4.405 [t=0.30s]
prediction: ['[CLS], ־ hymn ী kangaroo fault the ( easily bared another fucking fastest symptoms faster solve stock our federal berth assistant satisfy residents [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.717 (perp=12.805, rec=0.432, cos=0.724), tot_loss_proj:4.491 [t=0.31s]
prediction: ['[CLS] is ־ %_ kangaroo scare challenge ( easily settlers jason countyned symptoms you solve looted " gillian voyage nedra satisfy him [SEP]']
[ 300/2000] tot_loss=3.006 (perp=9.828, rec=0.352, cos=0.687), tot_loss_proj:3.867 [t=0.30s]
prediction: ["[CLS] is ־ sooner# became a problem the less necessarily disabled countyned problem you solve.'gillian prentice corporate satisfy him [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=3.013 (perp=9.914, rec=0.348, cos=0.682), tot_loss_proj:3.848 [t=0.30s]
prediction: ["[CLS] is ־ sooner# becomes a challenge the sooner necessarily them facilities this problem easily solve.'gillian prentice corporate satisfy all [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.990 (perp=9.848, rec=0.328, cos=0.693), tot_loss_proj:3.849 [t=0.30s]
prediction: ["[CLS] is ־ hey_ becomes a problem the sooner necessarily less sooner this problem easily solve.'gillian prentice corporate satisfy all [SEP]"]
[ 450/2000] tot_loss=2.757 (perp=8.859, rec=0.306, cos=0.679), tot_loss_proj:3.706 [t=0.30s]
prediction: ["[CLS] the ־ problem… exactly the trouble the sooner necessarily less sooner this problem easily solve.'gillian prentice corporate satisfy all [SEP]"]
Attempt swap
[ 500/2000] tot_loss=2.983 (perp=9.916, rec=0.305, cos=0.695), tot_loss_proj:3.876 [t=0.30s]
prediction: ['[CLS] the staying confident… exactly a trouble the sooner necessarily solve sooner this problem easily solve at " gillian prentice corporate satisfy folks [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.887 (perp=9.446, rec=0.291, cos=0.707), tot_loss_proj:3.778 [t=0.30s]
prediction: ['[CLS] the staying confident… exactly a trouble the sooner necessarily solve sooner this problem you solve at " gillian prentice satisfy corporate folks [SEP]']
[ 600/2000] tot_loss=2.784 (perp=8.954, rec=0.292, cos=0.700), tot_loss_proj:3.690 [t=0.30s]
prediction: ['[CLS] the staying confident that is a trouble the sooner necessarily solve sooner this problem you solve up " gillian prentice satisfy corporate folks [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.856 (perp=9.155, rec=0.285, cos=0.740), tot_loss_proj:3.720 [t=0.30s]
prediction: ['[CLS] the staying confident that is a trouble the sooner necessarily solve sooner this problem you solve up " gillian garion satisfy corporate folks [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.315 (perp=10.126, rec=0.487, cos=0.802), tot_loss_proj:3.967 [t=0.30s]
prediction: ['[CLS] the ː darren amplifier grows a trouble the sooner necessarily understand sooner the problem you solve up འ "⋅ satisfy corporate folks [SEP]']
[ 750/2000] tot_loss=2.891 (perp=9.378, rec=0.345, cos=0.671), tot_loss_proj:3.811 [t=0.30s]
prediction: ['[CLS] the ː recall amplifier grows a trouble the sooner necessarily understand sooner the problem you solve up འ " www satisfy corporate folks [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.901 (perp=9.468, rec=0.327, cos=0.681), tot_loss_proj:3.833 [t=0.30s]
prediction: ['[CLS] the ː darren amplifier became a trouble the sooner necessarily need problem the sooner you solve up འ " www satisfy corporate folks [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.861 (perp=9.347, rec=0.313, cos=0.679), tot_loss_proj:3.793 [t=0.30s]
prediction: ['[CLS] the you darren broadcasts became a trouble the sooner necessarily need problem the sooner you solve up འ www " satisfy corporate folks [SEP]']
[ 900/2000] tot_loss=2.932 (perp=9.662, rec=0.306, cos=0.693), tot_loss_proj:3.883 [t=0.30s]
prediction: ['[CLS] the you confident broadcasts you a trouble the sooner necessarily need problem this sooner you solve up macdonald www " satisfy corporate folks [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.902 (perp=9.523, rec=0.303, cos=0.695), tot_loss_proj:3.846 [t=0.30s]
prediction: ['[CLS] the you confident broadcasts you a trouble the sooner necessarily need this problem sooner you solve up macdonald www " satisfy corporate folks [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.939 (perp=9.745, rec=0.295, cos=0.695), tot_loss_proj:3.870 [t=0.30s]
prediction: ['[CLS] the you confident broadcasts you trouble a the sooner necessarily need this problem sooner you solve up macdonald www " satisfy corporate folks [SEP]']
[1050/2000] tot_loss=2.948 (perp=9.745, rec=0.286, cos=0.713), tot_loss_proj:3.875 [t=0.30s]
prediction: ['[CLS] the you confident broadcasts you trouble a the sooner necessarily need this problem sooner you solve up macdonald www " satisfy corporate folks [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.954 (perp=9.690, rec=0.293, cos=0.723), tot_loss_proj:3.896 [t=0.30s]
prediction: ['[CLS] the a confident broadcasts you trouble you the sooner necessarily need this problem sooner solve solve up macdonald www " satisfy corporate folks [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.901 (perp=9.470, rec=0.285, cos=0.721), tot_loss_proj:3.822 [t=0.30s]
prediction: ['[CLS] the a confident broadcasts you trouble you the sooner necessarily need this problem sooner solve solve up " www macdonald satisfy corporate folks [SEP]']
[1200/2000] tot_loss=2.897 (perp=9.470, rec=0.283, cos=0.720), tot_loss_proj:3.819 [t=0.30s]
prediction: ['[CLS] the a confident broadcasts you trouble you the sooner necessarily need this problem sooner solve solve up " www macdonald satisfy corporate folks [SEP]']
Attempt swap
[1250/2000] tot_loss=2.924 (perp=9.600, rec=0.277, cos=0.727), tot_loss_proj:3.846 [t=0.30s]
prediction: ['[CLS] the a confident broadcasts you trouble you the sooner necessarily need this problem sooner solve solve up " www macdonald solve corporate folks [SEP]']
Attempt swap
[1300/2000] tot_loss=2.925 (perp=9.600, rec=0.277, cos=0.729), tot_loss_proj:3.848 [t=0.30s]
prediction: ['[CLS] the a confident broadcasts you trouble you the sooner necessarily need this problem sooner solve solve up " www macdonald solve corporate folks [SEP]']
[1350/2000] tot_loss=2.936 (perp=9.600, rec=0.279, cos=0.737), tot_loss_proj:3.850 [t=0.30s]
prediction: ['[CLS] the a confident broadcasts you trouble you the sooner necessarily need this problem sooner solve solve up " www macdonald solve corporate folks [SEP]']
Attempt swap
[1400/2000] tot_loss=2.919 (perp=9.600, rec=0.271, cos=0.728), tot_loss_proj:3.847 [t=0.30s]
prediction: ['[CLS] the a confident broadcasts you trouble you the sooner necessarily need this problem sooner solve solve up " www macdonald solve corporate folks [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.781 (perp=8.791, rec=0.277, cos=0.747), tot_loss_proj:3.685 [t=0.30s]
prediction: ['[CLS] the a declared broadcasts you trouble " the sooner you need this problem sooner solve solve up you www macdonald solve corporate folks [SEP]']
[1500/2000] tot_loss=2.726 (perp=8.644, rec=0.262, cos=0.735), tot_loss_proj:3.657 [t=0.30s]
prediction: ['[CLS] the a declared broadcasts you trouble " the sooner you solve this problem sooner solve solve up you www macdonald solve corporate folks [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.777 (perp=8.824, rec=0.281, cos=0.731), tot_loss_proj:3.687 [t=0.31s]
prediction: ['[CLS] the a declared broadcasts you trouble that the sooner you interpret this problem sooner you solve up solve www macdonald solve corporate folks [SEP]']
Attempt swap
[1600/2000] tot_loss=2.775 (perp=8.824, rec=0.276, cos=0.735), tot_loss_proj:3.684 [t=0.30s]
prediction: ['[CLS] the a declared broadcasts you trouble that the sooner you interpret this problem sooner you solve up solve www macdonald solve corporate folks [SEP]']
[1650/2000] tot_loss=2.768 (perp=8.824, rec=0.266, cos=0.737), tot_loss_proj:3.686 [t=0.30s]
prediction: ['[CLS] the a declared broadcasts you trouble that the sooner you interpret this problem sooner you solve up solve www macdonald solve corporate folks [SEP]']
Attempt swap
[1700/2000] tot_loss=2.769 (perp=8.824, rec=0.266, cos=0.738), tot_loss_proj:3.686 [t=0.30s]
prediction: ['[CLS] the a declared broadcasts you trouble that the sooner you interpret this problem sooner you solve up solve www macdonald solve corporate folks [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.712 (perp=8.489, rec=0.277, cos=0.737), tot_loss_proj:3.602 [t=0.31s]
prediction: ['[CLS] the a declared broadcasts that you trouble the sooner you interpret this problem sooner you solve up solve www macdonald solve corporate folks [SEP]']
[1800/2000] tot_loss=2.704 (perp=8.489, rec=0.267, cos=0.739), tot_loss_proj:3.599 [t=0.31s]
prediction: ['[CLS] the a declared broadcasts that you trouble the sooner you interpret this problem sooner you solve up solve www macdonald solve corporate folks [SEP]']
Attempt swap
[1850/2000] tot_loss=2.705 (perp=8.489, rec=0.266, cos=0.742), tot_loss_proj:3.603 [t=0.31s]
prediction: ['[CLS] the a declared broadcasts that you trouble the sooner you interpret this problem sooner you solve up solve www macdonald solve corporate folks [SEP]']
Attempt swap
[1900/2000] tot_loss=2.710 (perp=8.489, rec=0.273, cos=0.739), tot_loss_proj:3.606 [t=0.30s]
prediction: ['[CLS] the a declared broadcasts that you trouble the sooner you interpret this problem sooner you solve up solve www macdonald solve corporate folks [SEP]']
[1950/2000] tot_loss=2.714 (perp=8.489, rec=0.274, cos=0.743), tot_loss_proj:3.603 [t=0.30s]
prediction: ['[CLS] the a declared broadcasts that you trouble the sooner you interpret this problem sooner you solve up solve www macdonald solve corporate folks [SEP]']
Attempt swap
[2000/2000] tot_loss=2.706 (perp=8.489, rec=0.264, cos=0.744), tot_loss_proj:3.604 [t=0.30s]
prediction: ['[CLS] the a declared broadcasts that you trouble the sooner you interpret this problem sooner you solve up solve www macdonald solve corporate folks [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]
========================
predicted: 
========================
[CLS] the a declared broadcasts that you trouble the sooner you interpret this problem sooner you solve up solve www macdonald solve corporate folks [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.333 | p: 56.000 | r: 60.870
rouge2     | fm: 17.391 | p: 16.667 | r: 18.182
rougeL     | fm: 37.500 | p: 36.000 | r: 39.130
rougeLsum  | fm: 37.500 | p: 36.000 | r: 39.130
r1fm+r2fm = 75.725

[Aggregate metrics]:
rouge1     | fm: 78.731 | p: 77.765 | r: 79.740
rouge2     | fm: 43.585 | p: 42.788 | r: 44.455
rougeL     | fm: 71.068 | p: 70.363 | r: 72.123
rougeLsum  | fm: 71.677 | p: 70.871 | r: 72.694
r1fm+r2fm = 122.316

input #13 time: 0:12:07 | total time: 2:46:55


Running input #14 of 100.
reference: 
========================
Mary has never kissed a man who is taller than John.
========================
average of cosine similarity 0.9988361616101944
highest_index [0]
highest [0.9988361616101944]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2984,  2038,  2196,  4782,  1037,  2158,  2040,  2003, 12283,
          2084,  2198,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mary has never kissed a man who is taller than john. [SEP]']
[Init] best rec loss: 1.0583534240722656 for ['[CLS] isa jude jon force boysraction louise work tip bigger dick sets [SEP]']
[Init] best rec loss: 0.9833199977874756 for ['[CLS] tennessee rat bee shadow quitekarrita ships dates lens hard hamish [SEP]']
[Init] best rec loss: 0.9677971601486206 for ['[CLS]rao rule frequency seethest watchyk my well beaver yardspath [SEP]']
[Init] best rec loss: 0.9215328097343445 for ['[CLS] dimension ser phone visible sv dependent performed unique independence tipped gravity tha [SEP]']
[Init] best rec loss: 0.9044162631034851 for ['[CLS] smart grandderropolis personal drama playback president lest sought producerdened [SEP]']
[Init] best perm rec loss: 0.8995301127433777 for ['[CLS]dened personal grand playbackder smart lest sought producer president dramaropolis [SEP]']
[Init] best perm rec loss: 0.8991824388504028 for ['[CLS] sought playbackder personalropolis producer granddened drama smart lest president [SEP]']
[Init] best perm rec loss: 0.8990135192871094 for ['[CLS] producer smart drama grandropolisder playback lestdened president sought personal [SEP]']
[Init] best perm rec loss: 0.8966554999351501 for ['[CLS] smartropolis lest producerdened personal dramader grand president sought playback [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.364 (perp=10.891, rec=0.542, cos=0.644), tot_loss_proj:4.101 [t=0.29s]
prediction: ['[CLS] civilization meet mommy love mission jazz also never. indian colords [SEP]']
[ 100/2000] tot_loss=3.259 (perp=10.598, rec=0.458, cos=0.681), tot_loss_proj:4.029 [t=0.30s]
prediction: ['[CLS] civilization whom mommy railroad is energy also never. : never florence [SEP]']
[ 150/2000] tot_loss=3.357 (perp=11.183, rec=0.415, cos=0.705), tot_loss_proj:4.108 [t=0.30s]
prediction: ['[CLS] prevented whom kissed portugal is got kiss never. remainder kissed a [SEP]']
[ 200/2000] tot_loss=3.745 (perp=13.036, rec=0.471, cos=0.667), tot_loss_proj:4.554 [t=0.30s]
prediction: ['[CLS] ⟨ pistols kissed perth faith equity! neverop involved kissed depth [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.440 (perp=11.421, rec=0.425, cos=0.731), tot_loss_proj:4.121 [t=0.30s]
prediction: ['[CLS] girl pistolsidae kissed is prevented kissed never nor involved kissed than [SEP]']
[ 300/2000] tot_loss=3.343 (perp=11.200, rec=0.381, cos=0.722), tot_loss_proj:4.103 [t=0.30s]
prediction: ['[CLS] girl quarterfinal kissed kissed is never kissed neverop alex kissed than [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.325 (perp=11.179, rec=0.357, cos=0.733), tot_loss_proj:4.115 [t=0.30s]
prediction: ['[CLS] girl. kissed kissed has nobody kissed neverop alex kissed than [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.989 (perp=9.627, rec=0.352, cos=0.711), tot_loss_proj:3.765 [t=0.30s]
prediction: ['[CLS] girl. kissed kissed kissed anyone is neverop alex kissed. [SEP]']
[ 450/2000] tot_loss=2.976 (perp=9.781, rec=0.333, cos=0.687), tot_loss_proj:3.837 [t=0.30s]
prediction: ['[CLS] girl. kissed kissed kissed nobody is never only alex kissed than [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.820 (perp=9.079, rec=0.324, cos=0.680), tot_loss_proj:3.709 [t=0.30s]
prediction: ['[CLS] girl. kissed james kissed nobody is never only alex kissed. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.469 (perp=11.760, rec=0.381, cos=0.736), tot_loss_proj:4.278 [t=0.30s]
prediction: ['[CLS] he. kissedville kissed shortly has never merely ltd kissed than [SEP]']
[ 600/2000] tot_loss=3.093 (perp=10.114, rec=0.330, cos=0.740), tot_loss_proj:3.965 [t=0.30s]
prediction: ['[CLS] whom. smileville kissed shortly is never only william kissed than [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.674 (perp=8.146, rec=0.319, cos=0.726), tot_loss_proj:3.522 [t=0.30s]
prediction: ['[CLS] whom. smile. kissed william is never only shortly kissed. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.479 (perp=7.188, rec=0.321, cos=0.721), tot_loss_proj:3.355 [t=0.30s]
prediction: ['[CLS] whom.. smiling kissed william is never only shortly kissed. [SEP]']
[ 750/2000] tot_loss=2.545 (perp=7.613, rec=0.296, cos=0.727), tot_loss_proj:3.263 [t=0.30s]
prediction: ['[CLS] whom..udence kissed william is never only shortly kissed. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.507 (perp=7.356, rec=0.294, cos=0.742), tot_loss_proj:3.376 [t=0.30s]
prediction: ['[CLS] whom.. mary kissed john is never only prize kissed. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.904 (perp=9.363, rec=0.298, cos=0.734), tot_loss_proj:3.839 [t=0.30s]
prediction: ['[CLS] taller.. mary kissed john is never only prize kissed a [SEP]']
[ 900/2000] tot_loss=2.903 (perp=9.363, rec=0.283, cos=0.748), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] taller.. mary kissed john is never only prize kissed a [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.816 (perp=8.903, rec=0.295, cos=0.740), tot_loss_proj:3.752 [t=0.30s]
prediction: ['[CLS] taller.. mary kissed john is never only kissed a prize [SEP]']
Attempt swap
[1000/2000] tot_loss=2.808 (perp=8.903, rec=0.285, cos=0.743), tot_loss_proj:3.755 [t=0.30s]
prediction: ['[CLS] taller.. mary kissed john is never only kissed a prize [SEP]']
[1050/2000] tot_loss=2.723 (perp=8.504, rec=0.278, cos=0.744), tot_loss_proj:3.669 [t=0.30s]
prediction: ['[CLS] taller.. mary kissed john is never only kissed a mary [SEP]']
Attempt swap
[1100/2000] tot_loss=2.728 (perp=8.504, rec=0.279, cos=0.749), tot_loss_proj:3.668 [t=0.30s]
prediction: ['[CLS] taller.. mary kissed john is never only kissed a mary [SEP]']
Attempt swap
[1150/2000] tot_loss=2.727 (perp=8.504, rec=0.275, cos=0.751), tot_loss_proj:3.670 [t=0.30s]
prediction: ['[CLS] taller.. mary kissed john is never only kissed a mary [SEP]']
[1200/2000] tot_loss=2.718 (perp=8.504, rec=0.264, cos=0.754), tot_loss_proj:3.661 [t=0.30s]
prediction: ['[CLS] taller.. mary kissed john is never only kissed a mary [SEP]']
Attempt swap
[1250/2000] tot_loss=2.773 (perp=8.688, rec=0.279, cos=0.756), tot_loss_proj:3.698 [t=0.30s]
prediction: ['[CLS] taller.. mary kissed john is never merely kissed a mary [SEP]']
Attempt swap
[1300/2000] tot_loss=2.775 (perp=8.688, rec=0.280, cos=0.758), tot_loss_proj:3.697 [t=0.30s]
prediction: ['[CLS] taller.. mary kissed john is never merely kissed a mary [SEP]']
[1350/2000] tot_loss=2.904 (perp=9.366, rec=0.273, cos=0.758), tot_loss_proj:3.833 [t=0.30s]
prediction: ['[CLS] taller.. mary man john is never merely kissed a mary [SEP]']
Attempt swap
[1400/2000] tot_loss=2.899 (perp=9.366, rec=0.265, cos=0.761), tot_loss_proj:3.835 [t=0.30s]
prediction: ['[CLS] taller.. mary man john is never merely kissed a mary [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.858 (perp=9.104, rec=0.275, cos=0.762), tot_loss_proj:3.794 [t=0.30s]
prediction: ['[CLS] taller.. john man mary is never merely kissed a mary [SEP]']
[1500/2000] tot_loss=2.857 (perp=9.104, rec=0.276, cos=0.760), tot_loss_proj:3.792 [t=0.30s]
prediction: ['[CLS] taller.. john man mary is never merely kissed a mary [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.686 (perp=8.280, rec=0.276, cos=0.755), tot_loss_proj:3.632 [t=0.30s]
prediction: ['[CLS] taller john.. man mary is never merely kissed a mary [SEP]']
Attempt swap
[1600/2000] tot_loss=2.685 (perp=8.280, rec=0.271, cos=0.758), tot_loss_proj:3.625 [t=0.30s]
prediction: ['[CLS] taller john.. man mary is never merely kissed a mary [SEP]']
[1650/2000] tot_loss=2.682 (perp=8.280, rec=0.267, cos=0.759), tot_loss_proj:3.625 [t=0.30s]
prediction: ['[CLS] taller john.. man mary is never merely kissed a mary [SEP]']
Attempt swap
[1700/2000] tot_loss=2.685 (perp=8.280, rec=0.269, cos=0.760), tot_loss_proj:3.629 [t=0.30s]
prediction: ['[CLS] taller john.. man mary is never merely kissed a mary [SEP]']
Attempt swap
[1750/2000] tot_loss=2.697 (perp=8.280, rec=0.280, cos=0.761), tot_loss_proj:3.630 [t=0.30s]
prediction: ['[CLS] taller john.. man mary is never merely kissed a mary [SEP]']
[1800/2000] tot_loss=2.688 (perp=8.280, rec=0.269, cos=0.763), tot_loss_proj:3.627 [t=0.30s]
prediction: ['[CLS] taller john.. man mary is never merely kissed a mary [SEP]']
Attempt swap
[1850/2000] tot_loss=2.685 (perp=8.280, rec=0.267, cos=0.762), tot_loss_proj:3.629 [t=0.30s]
prediction: ['[CLS] taller john.. man mary is never merely kissed a mary [SEP]']
Attempt swap
[1900/2000] tot_loss=2.684 (perp=8.280, rec=0.265, cos=0.763), tot_loss_proj:3.629 [t=0.30s]
prediction: ['[CLS] taller john.. man mary is never merely kissed a mary [SEP]']
[1950/2000] tot_loss=2.689 (perp=8.280, rec=0.270, cos=0.763), tot_loss_proj:3.629 [t=0.30s]
prediction: ['[CLS] taller john.. man mary is never merely kissed a mary [SEP]']
Attempt swap
[2000/2000] tot_loss=2.691 (perp=8.280, rec=0.271, cos=0.764), tot_loss_proj:3.628 [t=0.30s]
prediction: ['[CLS] taller john.. man mary is never merely kissed a mary [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] mary has never kissed a man who is taller than john. [SEP]
========================
predicted: 
========================
[CLS] taller john.. man mary is never merely kissed a mary [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 83.333 | r: 76.923
rouge2     | fm: 8.696 | p: 9.091 | r: 8.333
rougeL     | fm: 48.000 | p: 50.000 | r: 46.154
rougeLsum  | fm: 48.000 | p: 50.000 | r: 46.154
r1fm+r2fm = 88.696

[Aggregate metrics]:
rouge1     | fm: 78.763 | p: 78.064 | r: 79.602
rouge2     | fm: 41.278 | p: 40.578 | r: 42.228
rougeL     | fm: 69.291 | p: 68.681 | r: 70.130
rougeLsum  | fm: 69.745 | p: 69.163 | r: 70.541
r1fm+r2fm = 120.041

input #14 time: 0:11:48 | total time: 2:58:44


Running input #15 of 100.
reference: 
========================
After ten soldiers had left, seven more ones came in.
========================
average of cosine similarity 0.9989885701942867
highest_index [0]
highest [0.9989885701942867]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2044, 2702, 3548, 2018, 2187, 1010, 2698, 2062, 3924, 2234, 1999,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] after ten soldiers had left, seven more ones came in. [SEP]']
[Init] best rec loss: 0.9030300974845886 for ['[CLS] war ne soaking kelly moment another carried ahead fk inches chasing deal [SEP]']
[Init] best rec loss: 0.8191408514976501 for ['[CLS] clear love instrument patient commentaryhipversder cowboys progression what tens [SEP]']
[Init] best rec loss: 0.7994691133499146 for ['[CLS] candace tribe club keysে football considered belleked park steadydilly [SEP]']
[Init] best rec loss: 0.7662473917007446 for ['[CLS] trainedpower mere exception meeting spokanemin cash vested large myselffish [SEP]']
[Init] best rec loss: 0.7610954642295837 for ['[CLS] proceeds idols threshold try basicwork some ahead baritone ■ bobby ; [SEP]']
[Init] best rec loss: 0.7522111535072327 for ['[CLS] cell bracelet ceiling faye regularly hurturance scope approval formerly total maxim [SEP]']
[Init] best rec loss: 0.7516960501670837 for ['[CLS]d club linked bachelor awfe honored after award wu common ~ [SEP]']
[Init] best perm rec loss: 0.7496976852416992 for ['[CLS] honored linked bachelorfe aw award common club wu ~ afterd [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.555 (perp=10.959, rec=0.327, cos=0.036), tot_loss_proj:3.296 [t=0.29s]
prediction: ['[CLS] during had. four six seven seven soldiers five ones one ones [SEP]']
[ 100/2000] tot_loss=2.211 (perp=9.792, rec=0.230, cos=0.023), tot_loss_proj:3.235 [t=0.30s]
prediction: ['[CLS] also came. more ten soldiers seven soldiers more ones ones comes [SEP]']
[ 150/2000] tot_loss=2.099 (perp=9.537, rec=0.180, cos=0.012), tot_loss_proj:3.440 [t=0.30s]
prediction: ['[CLS] after came. more ten east seven soldiers more ones ones. [SEP]']
[ 200/2000] tot_loss=2.174 (perp=10.090, rec=0.148, cos=0.008), tot_loss_proj:3.413 [t=0.30s]
prediction: ['[CLS] after came. came ten had seven soldiers more ones ones came [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.729 (perp=7.735, rec=0.160, cos=0.022), tot_loss_proj:2.711 [t=0.30s]
prediction: ['[CLS] after came soldiers, ten had seven. more ones two came [SEP]']
[ 300/2000] tot_loss=1.661 (perp=7.735, rec=0.109, cos=0.005), tot_loss_proj:2.743 [t=0.30s]
prediction: ['[CLS] after came soldiers, ten had seven. more ones two came [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.620 (perp=7.604, rec=0.095, cos=0.004), tot_loss_proj:2.907 [t=0.30s]
prediction: ['[CLS] after soldiers in, ten had seven. more ones two came [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.614 (perp=7.604, rec=0.089, cos=0.004), tot_loss_proj:2.908 [t=0.30s]
prediction: ['[CLS] after soldiers in, ten had seven. more ones two came [SEP]']
[ 450/2000] tot_loss=1.639 (perp=7.724, rec=0.090, cos=0.004), tot_loss_proj:3.074 [t=0.30s]
prediction: ['[CLS] after soldiers in, ten had seven. more ones ones came [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.611 (perp=7.601, rec=0.087, cos=0.004), tot_loss_proj:3.097 [t=0.30s]
prediction: ['[CLS] after soldiers in ten, had seven. more ones ones came [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.554 (perp=7.278, rec=0.094, cos=0.005), tot_loss_proj:2.977 [t=0.30s]
prediction: ['[CLS] after soldiers in ten, had seven more ones ones came. [SEP]']
[ 600/2000] tot_loss=1.539 (perp=7.278, rec=0.080, cos=0.004), tot_loss_proj:2.978 [t=0.30s]
prediction: ['[CLS] after soldiers in ten, had seven more ones ones came. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.469 (perp=6.933, rec=0.078, cos=0.004), tot_loss_proj:2.846 [t=0.30s]
prediction: ['[CLS] after soldiers in ten had, seven more ones ones came. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.662 (perp=7.131, rec=0.214, cos=0.022), tot_loss_proj:2.961 [t=0.30s]
prediction: ['[CLS] after soldiers had in ten, seven more ones ones came, [SEP]']
[ 750/2000] tot_loss=1.566 (perp=7.131, rec=0.129, cos=0.011), tot_loss_proj:2.990 [t=0.30s]
prediction: ['[CLS] after soldiers had in ten, seven more ones ones came, [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.450 (perp=6.671, rec=0.108, cos=0.008), tot_loss_proj:2.715 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten, seven more ones ones, [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.400 (perp=6.447, rec=0.103, cos=0.007), tot_loss_proj:2.189 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
[ 900/2000] tot_loss=1.391 (perp=6.447, rec=0.095, cos=0.007), tot_loss_proj:2.190 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.383 (perp=6.447, rec=0.089, cos=0.006), tot_loss_proj:2.188 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.382 (perp=6.447, rec=0.087, cos=0.005), tot_loss_proj:2.192 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
[1050/2000] tot_loss=1.388 (perp=6.447, rec=0.094, cos=0.005), tot_loss_proj:2.189 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.377 (perp=6.447, rec=0.083, cos=0.005), tot_loss_proj:2.186 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.379 (perp=6.447, rec=0.085, cos=0.005), tot_loss_proj:2.190 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
[1200/2000] tot_loss=1.388 (perp=6.447, rec=0.094, cos=0.005), tot_loss_proj:2.188 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.380 (perp=6.447, rec=0.086, cos=0.005), tot_loss_proj:2.196 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.381 (perp=6.447, rec=0.087, cos=0.005), tot_loss_proj:2.189 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
[1350/2000] tot_loss=1.381 (perp=6.447, rec=0.087, cos=0.005), tot_loss_proj:2.191 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.376 (perp=6.447, rec=0.082, cos=0.005), tot_loss_proj:2.187 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.377 (perp=6.447, rec=0.083, cos=0.005), tot_loss_proj:2.186 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
[1500/2000] tot_loss=1.384 (perp=6.447, rec=0.090, cos=0.005), tot_loss_proj:2.192 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.381 (perp=6.447, rec=0.087, cos=0.005), tot_loss_proj:2.187 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.375 (perp=6.447, rec=0.081, cos=0.005), tot_loss_proj:2.192 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
[1650/2000] tot_loss=1.378 (perp=6.447, rec=0.084, cos=0.005), tot_loss_proj:2.190 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.371 (perp=6.447, rec=0.078, cos=0.005), tot_loss_proj:2.186 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.381 (perp=6.447, rec=0.087, cos=0.005), tot_loss_proj:2.194 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
[1800/2000] tot_loss=1.373 (perp=6.447, rec=0.079, cos=0.005), tot_loss_proj:2.191 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.378 (perp=6.447, rec=0.084, cos=0.005), tot_loss_proj:2.194 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.385 (perp=6.447, rec=0.091, cos=0.004), tot_loss_proj:2.196 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
[1950/2000] tot_loss=1.378 (perp=6.447, rec=0.084, cos=0.005), tot_loss_proj:2.190 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.376 (perp=6.447, rec=0.082, cos=0.005), tot_loss_proj:2.193 [t=0.30s]
prediction: ['[CLS] after soldiers had came in ten ones, seven more ones, [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] after ten soldiers had left, seven more ones came in. [SEP]
========================
predicted: 
========================
[CLS] after soldiers in ten had, seven more ones ones came. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 128.030

[Aggregate metrics]:
rouge1     | fm: 79.674 | p: 78.965 | r: 80.455
rouge2     | fm: 41.011 | p: 40.290 | r: 41.758
rougeL     | fm: 69.788 | p: 69.055 | r: 70.426
rougeLsum  | fm: 69.975 | p: 69.453 | r: 70.650
r1fm+r2fm = 120.684

input #15 time: 0:11:48 | total time: 3:10:33


Running input #16 of 100.
reference: 
========================
Willy is taller than that Bill is is generally believed.
========================
average of cosine similarity 0.9988391769046856
highest_index [0]
highest [0.9988391769046856]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101, 16172,  2003, 12283,  2084,  2008,  3021,  2003,  2003,  3227,
          3373,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] willy is taller than that bill is is generally believed. [SEP]']
[Init] best rec loss: 0.7599319219589233 for ['[CLS] g shared jump inch addition ted poker feel show paul initiative [SEP]']
[Init] best rec loss: 0.7218087315559387 for ['[CLS]ette water home campus ceilingblood hillary appeared unfamiliar dead spend [SEP]']
[Init] best rec loss: 0.7156255841255188 for ['[CLS] anyone she hit spatial taylor asked organization shaped extended domination little [SEP]']
[Init] best rec loss: 0.7098348140716553 for ['[CLS] and molecular beating than driveated become distance baronet mass public [SEP]']
[Init] best rec loss: 0.7020117044448853 for ['[CLS] fashionunt wood freedom finale drake trail incumbent much possibly away [SEP]']
[Init] best perm rec loss: 0.6949079632759094 for ['[CLS] incumbent muchunt finale fashion possibly drake freedom away trail wood [SEP]']
[Init] best perm rec loss: 0.69439697265625 for ['[CLS] finale freedom trail fashion incumbent possibly wood drake awayunt much [SEP]']
[Init] best perm rec loss: 0.6941801309585571 for ['[CLS]unt fashion drake wood trail finale possibly away freedom much incumbent [SEP]']
[Init] best perm rec loss: 0.6941269040107727 for ['[CLS] drake trail much fashion incumbent finale wood possibly freedom awayunt [SEP]']
[Init] best perm rec loss: 0.6937568783760071 for ['[CLS] finale trail drake freedom fashion wood away possiblyunt incumbent much [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.191 (perp=9.368, rec=0.279, cos=0.038), tot_loss_proj:2.713 [t=0.29s]
prediction: ['[CLS] than. that! that that is is bill willy premiered [SEP]']
[ 100/2000] tot_loss=2.415 (perp=11.067, rec=0.174, cos=0.027), tot_loss_proj:2.940 [t=0.30s]
prediction: ['[CLS] than. taller is that bill believed is chain willy believed [SEP]']
[ 150/2000] tot_loss=2.364 (perp=11.067, rec=0.137, cos=0.013), tot_loss_proj:2.940 [t=0.30s]
prediction: ['[CLS] than. taller is that bill believed is chain willy believed [SEP]']
[ 200/2000] tot_loss=2.338 (perp=11.067, rec=0.116, cos=0.009), tot_loss_proj:2.938 [t=0.30s]
prediction: ['[CLS] than. taller is that bill believed is chain willy believed [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.186 (perp=10.169, rec=0.138, cos=0.015), tot_loss_proj:2.782 [t=0.30s]
prediction: ['[CLS] is. taller than that bill believed is chain willy believed [SEP]']
[ 300/2000] tot_loss=2.139 (perp=10.169, rec=0.097, cos=0.008), tot_loss_proj:2.765 [t=0.30s]
prediction: ['[CLS] is. taller than that bill believed is chain willy believed [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.040 (perp=9.267, rec=0.173, cos=0.013), tot_loss_proj:2.559 [t=0.30s]
prediction: ['[CLS] is believed taller than that bill is is golden willy grows [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.495 (perp=6.804, rec=0.126, cos=0.008), tot_loss_proj:2.048 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
[ 450/2000] tot_loss=1.476 (perp=6.804, rec=0.109, cos=0.006), tot_loss_proj:2.045 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.470 (perp=6.804, rec=0.103, cos=0.006), tot_loss_proj:2.046 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.475 (perp=6.804, rec=0.108, cos=0.006), tot_loss_proj:2.039 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
[ 600/2000] tot_loss=1.471 (perp=6.804, rec=0.105, cos=0.005), tot_loss_proj:2.043 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.454 (perp=6.804, rec=0.088, cos=0.005), tot_loss_proj:2.045 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.446 (perp=6.804, rec=0.079, cos=0.005), tot_loss_proj:2.047 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
[ 750/2000] tot_loss=1.450 (perp=6.804, rec=0.084, cos=0.005), tot_loss_proj:2.048 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.457 (perp=6.804, rec=0.091, cos=0.006), tot_loss_proj:2.042 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.455 (perp=6.804, rec=0.089, cos=0.006), tot_loss_proj:2.049 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
[ 900/2000] tot_loss=1.453 (perp=6.804, rec=0.086, cos=0.006), tot_loss_proj:2.040 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.459 (perp=6.804, rec=0.092, cos=0.006), tot_loss_proj:2.040 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.459 (perp=6.804, rec=0.092, cos=0.006), tot_loss_proj:2.043 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
[1050/2000] tot_loss=1.443 (perp=6.804, rec=0.076, cos=0.006), tot_loss_proj:2.039 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.454 (perp=6.804, rec=0.088, cos=0.006), tot_loss_proj:2.041 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.455 (perp=6.804, rec=0.088, cos=0.006), tot_loss_proj:2.042 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
[1200/2000] tot_loss=1.453 (perp=6.804, rec=0.086, cos=0.006), tot_loss_proj:2.037 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.452 (perp=6.804, rec=0.086, cos=0.006), tot_loss_proj:2.039 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.444 (perp=6.804, rec=0.077, cos=0.006), tot_loss_proj:2.043 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
[1350/2000] tot_loss=1.445 (perp=6.804, rec=0.079, cos=0.006), tot_loss_proj:2.042 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.456 (perp=6.804, rec=0.090, cos=0.006), tot_loss_proj:2.041 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.451 (perp=6.804, rec=0.084, cos=0.006), tot_loss_proj:2.038 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
[1500/2000] tot_loss=1.446 (perp=6.804, rec=0.079, cos=0.006), tot_loss_proj:2.042 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.434 (perp=6.804, rec=0.067, cos=0.006), tot_loss_proj:2.044 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.456 (perp=6.804, rec=0.090, cos=0.006), tot_loss_proj:2.039 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
[1650/2000] tot_loss=1.436 (perp=6.804, rec=0.069, cos=0.006), tot_loss_proj:2.040 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.439 (perp=6.804, rec=0.073, cos=0.006), tot_loss_proj:2.041 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.448 (perp=6.804, rec=0.082, cos=0.006), tot_loss_proj:2.038 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
[1800/2000] tot_loss=1.440 (perp=6.804, rec=0.074, cos=0.006), tot_loss_proj:2.041 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.452 (perp=6.804, rec=0.085, cos=0.006), tot_loss_proj:2.039 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.450 (perp=6.804, rec=0.084, cos=0.006), tot_loss_proj:2.030 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
[1950/2000] tot_loss=1.450 (perp=6.804, rec=0.083, cos=0.006), tot_loss_proj:2.038 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.442 (perp=6.804, rec=0.075, cos=0.006), tot_loss_proj:2.040 [t=0.30s]
prediction: ['[CLS] is believed that taller than bill is is golden willy. [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] willy is taller than that bill is is generally believed. [SEP]
========================
predicted: 
========================
[CLS] is believed that taller than bill is is golden willy. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 27.273 | p: 27.273 | r: 27.273
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 118.939

[Aggregate metrics]:
rouge1     | fm: 80.049 | p: 79.463 | r: 80.854
rouge2     | fm: 40.414 | p: 39.572 | r: 41.152
rougeL     | fm: 69.718 | p: 69.159 | r: 70.282
rougeLsum  | fm: 69.565 | p: 68.977 | r: 70.224
r1fm+r2fm = 120.463

input #16 time: 0:11:49 | total time: 3:22:22


Running input #17 of 100.
reference: 
========================
José is eating cabbage, and Holly is too.
========================
average of cosine similarity 0.99891283202433
highest_index [0]
highest [0.99891283202433]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  4560,  2003,  5983, 28540,  1010,  1998,  9079,  2003,  2205,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] jose is eating cabbage, and holly is too. [SEP]']
[Init] best rec loss: 0.8890302181243896 for ['[CLS] happenedgil revolution parallelsta right finding flag taiwan bella [SEP]']
[Init] best rec loss: 0.8579739332199097 for ['[CLS] monthsnent lunch cup else din location hook away gliding [SEP]']
[Init] best rec loss: 0.8492642045021057 for ['[CLS] signs cathedral hat bethel amp natural frequent east plus point [SEP]']
[Init] best rec loss: 0.8362582325935364 for ['[CLS] cyber commission earlier plate battedrily scroll jr kingdomistle [SEP]']
[Init] best rec loss: 0.8224234580993652 for ['[CLS] horse apartment sureɛ movement falls lordient linear college [SEP]']
[Init] best rec loss: 0.8197229504585266 for ['[CLS] am shed even multiple ing dressed nicknamed cd ali voices [SEP]']
[Init] best perm rec loss: 0.8193007707595825 for ['[CLS] ali nicknamed shed voices cd dressed am ing even multiple [SEP]']
[Init] best perm rec loss: 0.819060742855072 for ['[CLS] cd even am dressed ing ali voices nicknamed multiple shed [SEP]']
[Init] best perm rec loss: 0.8187623620033264 for ['[CLS] even cd voices am nicknamed shed dressed ali ing multiple [SEP]']
[Init] best perm rec loss: 0.81657475233078 for ['[CLS] cd dressed even nicknamed ali ing shed voices am multiple [SEP]']
[Init] best perm rec loss: 0.8146600127220154 for ['[CLS] ing even multiple shed nicknamed voices ali dressed am cd [SEP]']
[Init] best perm rec loss: 0.81363445520401 for ['[CLS] ali dressed nicknamed shed even cd multiple voices am ing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.343 (perp=10.302, rec=0.500, cos=0.782), tot_loss_proj:3.848 [t=0.29s]
prediction: ['[CLS] holly liszt was. was as rebellion too also " [SEP]']
[ 100/2000] tot_loss=3.412 (perp=11.398, rec=0.401, cos=0.732), tot_loss_proj:4.070 [t=0.30s]
prediction: ['[CLS] honour firms is captain is is publications too including " [SEP]']
[ 150/2000] tot_loss=3.946 (perp=13.263, rec=0.339, cos=0.955), tot_loss_proj:4.405 [t=0.30s]
prediction: ['[CLS] otago zeppelin is jean artillery is runs too including when [SEP]']
[ 200/2000] tot_loss=3.262 (perp=11.291, rec=0.249, cos=0.755), tot_loss_proj:3.979 [t=0.30s]
prediction: ['[CLS] garion jose is. holly isgies too including too [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.905 (perp=9.222, rec=0.253, cos=0.808), tot_loss_proj:3.537 [t=0.30s]
prediction: ['[CLS] jose sweater is. holly is annabelle too went ; [SEP]']
[ 300/2000] tot_loss=2.872 (perp=9.449, rec=0.225, cos=0.757), tot_loss_proj:3.560 [t=0.30s]
prediction: ['[CLS] jose photon is. holly is circulation too according. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.941 (perp=9.566, rec=0.213, cos=0.815), tot_loss_proj:3.673 [t=0.30s]
prediction: ['[CLS] jose isbuilding. holly is runs too according. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.921 (perp=8.879, rec=0.284, cos=0.861), tot_loss_proj:3.588 [t=0.30s]
prediction: ['[CLS] jose issphere. holly cabbage is runs too ; [SEP]']
[ 450/2000] tot_loss=2.854 (perp=9.305, rec=0.224, cos=0.769), tot_loss_proj:3.600 [t=0.30s]
prediction: ['[CLS] jose issphere. holly eating is sophie too ; [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.752 (perp=8.988, rec=0.189, cos=0.765), tot_loss_proj:3.564 [t=0.30s]
prediction: ['[CLS] jose issphere. holly ■ is eating too ; [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.640 (perp=8.453, rec=0.176, cos=0.774), tot_loss_proj:3.531 [t=0.30s]
prediction: ['[CLS] jose is ■. hollysphere is eating too ; [SEP]']
[ 600/2000] tot_loss=2.643 (perp=8.453, rec=0.181, cos=0.772), tot_loss_proj:3.525 [t=0.30s]
prediction: ['[CLS] jose is ■. hollysphere is eating too ; [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.651 (perp=8.453, rec=0.171, cos=0.790), tot_loss_proj:3.533 [t=0.30s]
prediction: ['[CLS] jose is ■. hollysphere is eating too ; [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.653 (perp=8.453, rec=0.164, cos=0.798), tot_loss_proj:3.531 [t=0.30s]
prediction: ['[CLS] jose is ■. hollysphere is eating too ; [SEP]']
[ 750/2000] tot_loss=2.647 (perp=8.453, rec=0.171, cos=0.786), tot_loss_proj:3.531 [t=0.30s]
prediction: ['[CLS] jose is ■. hollysphere is eating too ; [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.615 (perp=8.183, rec=0.173, cos=0.806), tot_loss_proj:3.496 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too, [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.622 (perp=8.183, rec=0.174, cos=0.811), tot_loss_proj:3.494 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too, [SEP]']
[ 900/2000] tot_loss=2.609 (perp=8.183, rec=0.164, cos=0.809), tot_loss_proj:3.493 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too, [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.627 (perp=8.183, rec=0.171, cos=0.819), tot_loss_proj:3.498 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too, [SEP]']
Attempt swap
[1000/2000] tot_loss=2.625 (perp=8.183, rec=0.169, cos=0.819), tot_loss_proj:3.490 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too, [SEP]']
[1050/2000] tot_loss=2.624 (perp=8.183, rec=0.164, cos=0.823), tot_loss_proj:3.493 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too, [SEP]']
Attempt swap
[1100/2000] tot_loss=2.622 (perp=8.183, rec=0.165, cos=0.820), tot_loss_proj:3.492 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too, [SEP]']
Attempt swap
[1150/2000] tot_loss=2.618 (perp=8.183, rec=0.161, cos=0.820), tot_loss_proj:3.496 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too, [SEP]']
[1200/2000] tot_loss=2.624 (perp=8.183, rec=0.167, cos=0.820), tot_loss_proj:3.494 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too, [SEP]']
Attempt swap
[1250/2000] tot_loss=2.618 (perp=8.183, rec=0.160, cos=0.822), tot_loss_proj:3.497 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too, [SEP]']
Attempt swap
[1300/2000] tot_loss=2.621 (perp=8.183, rec=0.162, cos=0.822), tot_loss_proj:3.491 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too, [SEP]']
[1350/2000] tot_loss=2.505 (perp=7.624, rec=0.155, cos=0.825), tot_loss_proj:3.387 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.507 (perp=7.624, rec=0.151, cos=0.832), tot_loss_proj:3.394 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.510 (perp=7.624, rec=0.161, cos=0.825), tot_loss_proj:3.391 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
[1500/2000] tot_loss=2.512 (perp=7.624, rec=0.155, cos=0.832), tot_loss_proj:3.388 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.513 (perp=7.624, rec=0.159, cos=0.830), tot_loss_proj:3.388 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.521 (perp=7.624, rec=0.162, cos=0.833), tot_loss_proj:3.393 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
[1650/2000] tot_loss=2.513 (perp=7.624, rec=0.160, cos=0.828), tot_loss_proj:3.390 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.508 (perp=7.624, rec=0.157, cos=0.826), tot_loss_proj:3.391 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.510 (perp=7.624, rec=0.159, cos=0.826), tot_loss_proj:3.392 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
[1800/2000] tot_loss=2.516 (perp=7.624, rec=0.160, cos=0.831), tot_loss_proj:3.391 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.506 (perp=7.624, rec=0.152, cos=0.829), tot_loss_proj:3.390 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.519 (perp=7.624, rec=0.162, cos=0.832), tot_loss_proj:3.385 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
[1950/2000] tot_loss=2.508 (perp=7.624, rec=0.150, cos=0.833), tot_loss_proj:3.387 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.515 (perp=7.624, rec=0.159, cos=0.832), tot_loss_proj:3.393 [t=0.30s]
prediction: ['[CLS] jose is ■. holly is eatingsphere too. [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] jose is eating cabbage, and holly is too. [SEP]
========================
predicted: 
========================
[CLS] jose is ■. holly is eatingsphere too. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 87.500 | r: 70.000
rouge2     | fm: 50.000 | p: 57.143 | r: 44.444
rougeL     | fm: 77.778 | p: 87.500 | r: 70.000
rougeLsum  | fm: 77.778 | p: 87.500 | r: 70.000
r1fm+r2fm = 127.778

[Aggregate metrics]:
rouge1     | fm: 80.123 | p: 80.047 | r: 80.458
rouge2     | fm: 40.585 | p: 40.393 | r: 40.903
rougeL     | fm: 70.182 | p: 70.095 | r: 70.267
rougeLsum  | fm: 69.996 | p: 70.035 | r: 70.216
r1fm+r2fm = 120.708

input #17 time: 0:11:48 | total time: 3:34:11


Running input #18 of 100.
reference: 
========================
John demanded that she stop phoning him.
========================
average of cosine similarity 0.998966495680607
highest_index [0]
highest [0.998966495680607]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2198,  6303,  2008,  2016,  2644,  6887, 13369,  2032,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] john demanded that she stop phoning him. [SEP]']
[Init] best rec loss: 0.9432886242866516 for ['[CLS] layton fewer consult school lu bounced choose switzerland years [SEP]']
[Init] best rec loss: 0.9344850778579712 for ['[CLS] cost century putfles urppa cue with son [SEP]']
[Init] best rec loss: 0.9280782341957092 for ['[CLS] chair ranks triangle chain enter dock equality overallchison [SEP]']
[Init] best rec loss: 0.9251810908317566 for ['[CLS] pistol arabic any signs community cam elementary sure mass [SEP]']
[Init] best rec loss: 0.9230034947395325 for ['[CLS] swift many internet congress rams literally gp go offensive [SEP]']
[Init] best rec loss: 0.9192088842391968 for ['[CLS] prize ordersp improved it rattle behind ol recorded [SEP]']
[Init] best perm rec loss: 0.9178569316864014 for ['[CLS] rattle recorded improvedp prize orders ol it behind [SEP]']
[Init] best perm rec loss: 0.9162829518318176 for ['[CLS]p recorded ol orders rattle it prize behind improved [SEP]']
[Init] best perm rec loss: 0.9157382249832153 for ['[CLS] orders ol rattle prize recorded improved behind itp [SEP]']
[Init] best perm rec loss: 0.9156612753868103 for ['[CLS] behind prize it improved recorded orders olp rattle [SEP]']
[Init] best perm rec loss: 0.9134236574172974 for ['[CLS] recorded prize behind rattle it orders improved olp [SEP]']
[Init] best perm rec loss: 0.9126153588294983 for ['[CLS] behind recorded prize olp improved rattle it orders [SEP]']
[Init] best perm rec loss: 0.9120444059371948 for ['[CLS] it improved prize recorded ol behind orders rattlep [SEP]']
[Init] best perm rec loss: 0.9117925763130188 for ['[CLS] improvedp recorded behind prize it orders rattle ol [SEP]']
[Init] best perm rec loss: 0.911103367805481 for ['[CLS] prize behind recorded olp rattle it improved orders [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.381 (perp=13.180, rec=0.796, cos=0.949), tot_loss_proj:4.470 [t=0.29s]
prediction: ['[CLS] bury it close chromosomesting maintains which capt armour [SEP]']
[ 100/2000] tot_loss=4.456 (perp=14.314, rec=0.619, cos=0.974), tot_loss_proj:4.658 [t=0.30s]
prediction: ['[CLS] delivery it national skatersting maintains these vantage jalan [SEP]']
[ 150/2000] tot_loss=3.673 (perp=11.148, rec=0.523, cos=0.920), tot_loss_proj:4.082 [t=0.30s]
prediction: ['[CLS] demanded she demanded sheting maintains the ind corridor [SEP]']
[ 200/2000] tot_loss=3.521 (perp=10.548, rec=0.497, cos=0.915), tot_loss_proj:3.948 [t=0.30s]
prediction: ['[CLS] demanded she demanded she patir the ind yellowish [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.424 (perp=10.715, rec=0.452, cos=0.828), tot_loss_proj:3.966 [t=0.30s]
prediction: ['[CLS] demanded she demanded she pat they demanded ind marissa [SEP]']
[ 300/2000] tot_loss=3.459 (perp=10.699, rec=0.430, cos=0.890), tot_loss_proj:3.992 [t=0.30s]
prediction: ['[CLS] demanded she demanded she reserve they demandedject pickup [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.449 (perp=11.086, rec=0.406, cos=0.826), tot_loss_proj:4.115 [t=0.30s]
prediction: ['[CLS] demanded she demanded she reserve they demandedoningject [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.135 (perp=9.687, rec=0.382, cos=0.815), tot_loss_proj:3.772 [t=0.30s]
prediction: ['[CLS] demanded she demanded she unless they demandedject ellie [SEP]']
[ 450/2000] tot_loss=3.442 (perp=11.034, rec=0.382, cos=0.853), tot_loss_proj:4.125 [t=0.30s]
prediction: ['[CLS] demanded she demanded sheurable that demandedjectoning [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.330 (perp=10.494, rec=0.379, cos=0.852), tot_loss_proj:3.959 [t=0.30s]
prediction: ['[CLS] demanded she demanded sheurable demanded thatjectoning [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.311 (perp=10.494, rec=0.369, cos=0.843), tot_loss_proj:3.962 [t=0.30s]
prediction: ['[CLS] demanded she demanded sheurable demanded thatjectoning [SEP]']
[ 600/2000] tot_loss=3.306 (perp=10.368, rec=0.373, cos=0.860), tot_loss_proj:4.045 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded thatjectoning [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.253 (perp=10.368, rec=0.347, cos=0.833), tot_loss_proj:4.041 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded thatjectoning [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.257 (perp=10.368, rec=0.356, cos=0.828), tot_loss_proj:4.047 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded thatjectoning [SEP]']
[ 750/2000] tot_loss=3.255 (perp=10.368, rec=0.345, cos=0.836), tot_loss_proj:4.042 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded thatjectoning [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.263 (perp=10.368, rec=0.344, cos=0.846), tot_loss_proj:4.040 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded thatjectoning [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.252 (perp=10.368, rec=0.334, cos=0.845), tot_loss_proj:4.043 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded thatjectoning [SEP]']
[ 900/2000] tot_loss=3.245 (perp=10.368, rec=0.332, cos=0.840), tot_loss_proj:4.042 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded thatjectoning [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.236 (perp=10.368, rec=0.326, cos=0.837), tot_loss_proj:4.041 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded thatjectoning [SEP]']
Attempt swap
[1000/2000] tot_loss=3.236 (perp=10.368, rec=0.326, cos=0.837), tot_loss_proj:4.042 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded thatjectoning [SEP]']
[1050/2000] tot_loss=3.420 (perp=11.291, rec=0.328, cos=0.834), tot_loss_proj:4.194 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded decree willisoning [SEP]']
Attempt swap
[1100/2000] tot_loss=3.425 (perp=11.291, rec=0.334, cos=0.833), tot_loss_proj:4.199 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded decree willisoning [SEP]']
Attempt swap
[1150/2000] tot_loss=3.424 (perp=11.291, rec=0.327, cos=0.839), tot_loss_proj:4.195 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded decree willisoning [SEP]']
[1200/2000] tot_loss=3.412 (perp=11.291, rec=0.319, cos=0.835), tot_loss_proj:4.196 [t=0.30s]
prediction: ['[CLS] demanded she demanded she む demanded decree willisoning [SEP]']
Attempt swap
[1250/2000] tot_loss=3.571 (perp=12.121, rec=0.316, cos=0.831), tot_loss_proj:4.285 [t=0.30s]
prediction: ['[CLS] demanded shepowered she む demandedzong willisoning [SEP]']
Attempt swap
[1300/2000] tot_loss=3.568 (perp=12.121, rec=0.314, cos=0.830), tot_loss_proj:4.284 [t=0.30s]
prediction: ['[CLS] demanded shepowered she む demandedzong willisoning [SEP]']
[1350/2000] tot_loss=3.563 (perp=12.121, rec=0.310, cos=0.829), tot_loss_proj:4.285 [t=0.30s]
prediction: ['[CLS] demanded shepowered she む demandedzong willisoning [SEP]']
Attempt swap
[1400/2000] tot_loss=3.571 (perp=12.121, rec=0.318, cos=0.830), tot_loss_proj:4.285 [t=0.30s]
prediction: ['[CLS] demanded shepowered she む demandedzong willisoning [SEP]']
Attempt swap
[1450/2000] tot_loss=3.570 (perp=12.121, rec=0.317, cos=0.828), tot_loss_proj:4.282 [t=0.30s]
prediction: ['[CLS] demanded shepowered she む demandedzong willisoning [SEP]']
[1500/2000] tot_loss=3.550 (perp=12.036, rec=0.314, cos=0.829), tot_loss_proj:4.232 [t=0.30s]
prediction: ['[CLS] demanded shepowered she stops demandedzong willisoning [SEP]']
Attempt swap
[1550/2000] tot_loss=3.552 (perp=12.036, rec=0.311, cos=0.833), tot_loss_proj:4.232 [t=0.30s]
prediction: ['[CLS] demanded shepowered she stops demandedzong willisoning [SEP]']
Attempt swap
[1600/2000] tot_loss=3.556 (perp=12.036, rec=0.316, cos=0.832), tot_loss_proj:4.233 [t=0.30s]
prediction: ['[CLS] demanded shepowered she stops demandedzong willisoning [SEP]']
[1650/2000] tot_loss=3.558 (perp=12.036, rec=0.320, cos=0.830), tot_loss_proj:4.234 [t=0.30s]
prediction: ['[CLS] demanded shepowered she stops demandedzong willisoning [SEP]']
Attempt swap
[1700/2000] tot_loss=3.543 (perp=12.036, rec=0.303, cos=0.832), tot_loss_proj:4.236 [t=0.30s]
prediction: ['[CLS] demanded shepowered she stops demandedzong willisoning [SEP]']
Attempt swap
[1750/2000] tot_loss=3.543 (perp=12.036, rec=0.306, cos=0.830), tot_loss_proj:4.233 [t=0.30s]
prediction: ['[CLS] demanded shepowered she stops demandedzong willisoning [SEP]']
[1800/2000] tot_loss=3.549 (perp=12.036, rec=0.312, cos=0.830), tot_loss_proj:4.230 [t=0.30s]
prediction: ['[CLS] demanded shepowered she stops demandedzong willisoning [SEP]']
Attempt swap
[1850/2000] tot_loss=3.556 (perp=12.036, rec=0.317, cos=0.832), tot_loss_proj:4.230 [t=0.30s]
prediction: ['[CLS] demanded shepowered she stops demandedzong willisoning [SEP]']
Attempt swap
[1900/2000] tot_loss=3.541 (perp=12.036, rec=0.305, cos=0.829), tot_loss_proj:4.234 [t=0.30s]
prediction: ['[CLS] demanded shepowered she stops demandedzong willisoning [SEP]']
[1950/2000] tot_loss=3.548 (perp=12.036, rec=0.309, cos=0.832), tot_loss_proj:4.232 [t=0.30s]
prediction: ['[CLS] demanded shepowered she stops demandedzong willisoning [SEP]']
Attempt swap
[2000/2000] tot_loss=3.542 (perp=12.036, rec=0.302, cos=0.833), tot_loss_proj:4.233 [t=0.30s]
prediction: ['[CLS] demanded shepowered she stops demandedzong willisoning [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] john demanded that she stop phoning him. [SEP]
========================
predicted: 
========================
[CLS] demanded shepowered she stops demandedzong willisoning [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 47.059 | p: 50.000 | r: 44.444
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.059 | p: 50.000 | r: 44.444
rougeLsum  | fm: 47.059 | p: 50.000 | r: 44.444
r1fm+r2fm = 47.059

[Aggregate metrics]:
rouge1     | fm: 78.241 | p: 78.438 | r: 78.224
rouge2     | fm: 38.535 | p: 38.485 | r: 38.759
rougeL     | fm: 68.935 | p: 69.110 | r: 69.033
rougeLsum  | fm: 68.576 | p: 68.826 | r: 68.615
r1fm+r2fm = 116.776

input #18 time: 0:11:48 | total time: 3:46:00


Running input #19 of 100.
reference: 
========================
I have six too many marbles.
========================
average of cosine similarity 0.9987824940066753
highest_index [0]
highest [0.9987824940066753]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 1045, 2031, 2416, 2205, 2116, 7720, 2015, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have six too many marbles. [SEP]']
[Init] best rec loss: 0.9211173057556152 for ['[CLS] endemicston card horsevere kira particular glasses [SEP]']
[Init] best rec loss: 0.9090513586997986 for ['[CLS] astronomy bowl records roe processed piano camera stuff [SEP]']
[Init] best rec loss: 0.9047555327415466 for ['[CLS]arat sidney riders moorley battle facto private [SEP]']
[Init] best rec loss: 0.8990211486816406 for ['[CLS] last turbo arc suspect dirty assault tubular outline [SEP]']
[Init] best perm rec loss: 0.898373544216156 for ['[CLS] assault tubular suspect turbo dirty arc outline last [SEP]']
[Init] best perm rec loss: 0.8960070013999939 for ['[CLS] last assault suspect dirty outline turbo tubular arc [SEP]']
[Init] best perm rec loss: 0.895422637462616 for ['[CLS] assault turbo dirty last arc tubular outline suspect [SEP]']
[Init] best perm rec loss: 0.8935836553573608 for ['[CLS] dirty last arc outline assault suspect turbo tubular [SEP]']
[Init] best perm rec loss: 0.893346905708313 for ['[CLS] arc outline last suspect tubular turbo dirty assault [SEP]']
[Init] best perm rec loss: 0.89247065782547 for ['[CLS] outline tubular assault dirty suspect last arc turbo [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.673 (perp=11.895, rec=0.579, cos=0.715), tot_loss_proj:4.305 [t=0.29s]
prediction: ['[CLS] distance marble infantry possession marble longest marble become [SEP]']
[ 100/2000] tot_loss=3.044 (perp=9.016, rec=0.487, cos=0.753), tot_loss_proj:3.394 [t=0.30s]
prediction: ['[CLS]. marble infantry marble marble marble marble six [SEP]']
[ 150/2000] tot_loss=2.993 (perp=8.637, rec=0.478, cos=0.787), tot_loss_proj:3.684 [t=0.30s]
prediction: ["[CLS] six grandson too'marble marble marbles [SEP]"]
[ 200/2000] tot_loss=3.241 (perp=10.447, rec=0.409, cos=0.742), tot_loss_proj:4.033 [t=0.30s]
prediction: ["[CLS] six none too'marble throughout marble too [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=3.349 (perp=10.744, rec=0.435, cos=0.765), tot_loss_proj:4.098 [t=0.30s]
prediction: ["[CLS] six unfortunatelytery'had marble marble too [SEP]"]
[ 300/2000] tot_loss=3.090 (perp=9.482, rec=0.399, cos=0.795), tot_loss_proj:3.791 [t=0.30s]
prediction: ["[CLS] six none too'many marble marble too [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=3.059 (perp=9.654, rec=0.373, cos=0.755), tot_loss_proj:3.874 [t=0.30s]
prediction: ['[CLS] six too too many marble much marble too [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.059 (perp=9.073, rec=0.466, cos=0.779), tot_loss_proj:3.769 [t=0.30s]
prediction: ['[CLS] six earlier too many marble marble? too [SEP]']
[ 450/2000] tot_loss=2.970 (perp=9.073, rec=0.375, cos=0.780), tot_loss_proj:3.757 [t=0.30s]
prediction: ['[CLS] six earlier too many marble marble? too [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.760 (perp=8.234, rec=0.360, cos=0.753), tot_loss_proj:3.604 [t=0.30s]
prediction: ['[CLS] six earlier too many marble marble too? [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.154 (perp=10.153, rec=0.366, cos=0.757), tot_loss_proj:3.947 [t=0.30s]
prediction: ['[CLS] six marble too many unfortunately marble too10 [SEP]']
[ 600/2000] tot_loss=3.008 (perp=9.628, rec=0.320, cos=0.762), tot_loss_proj:3.874 [t=0.30s]
prediction: ['[CLS] six marble too many earlier marble too i [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.000 (perp=9.628, rec=0.307, cos=0.768), tot_loss_proj:3.873 [t=0.30s]
prediction: ['[CLS] six marble too many earlier marble too i [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.989 (perp=9.628, rec=0.301, cos=0.763), tot_loss_proj:3.873 [t=0.30s]
prediction: ['[CLS] six marble too many earlier marble too i [SEP]']
[ 750/2000] tot_loss=3.022 (perp=9.855, rec=0.286, cos=0.765), tot_loss_proj:3.806 [t=0.30s]
prediction: ['[CLS] six marble too many devils marble too i [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.014 (perp=9.855, rec=0.278, cos=0.765), tot_loss_proj:3.809 [t=0.30s]
prediction: ['[CLS] six marble too many devils marble too i [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.996 (perp=9.855, rec=0.269, cos=0.757), tot_loss_proj:3.804 [t=0.30s]
prediction: ['[CLS] six marble too many devils marble too i [SEP]']
[ 900/2000] tot_loss=3.313 (perp=11.452, rec=0.267, cos=0.756), tot_loss_proj:4.196 [t=0.30s]
prediction: ['[CLS] six↑ too many devils marble too i [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.382 (perp=11.700, rec=0.271, cos=0.771), tot_loss_proj:4.266 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marble too i [SEP]']
Attempt swap
[1000/2000] tot_loss=3.360 (perp=11.700, rec=0.263, cos=0.757), tot_loss_proj:4.261 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marble too i [SEP]']
[1050/2000] tot_loss=3.363 (perp=11.700, rec=0.259, cos=0.764), tot_loss_proj:4.263 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marble too i [SEP]']
Attempt swap
[1100/2000] tot_loss=3.371 (perp=11.700, rec=0.269, cos=0.762), tot_loss_proj:4.270 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marble too i [SEP]']
Attempt swap
[1150/2000] tot_loss=3.378 (perp=11.700, rec=0.276, cos=0.762), tot_loss_proj:4.267 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marble too i [SEP]']
[1200/2000] tot_loss=3.072 (perp=10.270, rec=0.253, cos=0.765), tot_loss_proj:3.831 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Attempt swap
[1250/2000] tot_loss=3.069 (perp=10.270, rec=0.254, cos=0.761), tot_loss_proj:3.833 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Attempt swap
[1300/2000] tot_loss=3.069 (perp=10.270, rec=0.258, cos=0.757), tot_loss_proj:3.835 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
[1350/2000] tot_loss=3.078 (perp=10.270, rec=0.262, cos=0.762), tot_loss_proj:3.835 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Attempt swap
[1400/2000] tot_loss=3.074 (perp=10.270, rec=0.256, cos=0.763), tot_loss_proj:3.843 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Attempt swap
[1450/2000] tot_loss=3.076 (perp=10.270, rec=0.253, cos=0.768), tot_loss_proj:3.837 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
[1500/2000] tot_loss=3.077 (perp=10.270, rec=0.257, cos=0.766), tot_loss_proj:3.837 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Attempt swap
[1550/2000] tot_loss=3.074 (perp=10.270, rec=0.259, cos=0.761), tot_loss_proj:3.836 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Attempt swap
[1600/2000] tot_loss=3.075 (perp=10.270, rec=0.254, cos=0.767), tot_loss_proj:3.838 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
[1650/2000] tot_loss=3.078 (perp=10.270, rec=0.263, cos=0.761), tot_loss_proj:3.835 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Attempt swap
[1700/2000] tot_loss=3.064 (perp=10.270, rec=0.248, cos=0.763), tot_loss_proj:3.839 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Attempt swap
[1750/2000] tot_loss=3.076 (perp=10.270, rec=0.257, cos=0.766), tot_loss_proj:3.836 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
[1800/2000] tot_loss=3.069 (perp=10.270, rec=0.251, cos=0.764), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Attempt swap
[1850/2000] tot_loss=3.066 (perp=10.270, rec=0.248, cos=0.764), tot_loss_proj:3.840 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Attempt swap
[1900/2000] tot_loss=3.078 (perp=10.270, rec=0.257, cos=0.767), tot_loss_proj:3.840 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
[1950/2000] tot_loss=3.066 (perp=10.270, rec=0.244, cos=0.769), tot_loss_proj:3.836 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Attempt swap
[2000/2000] tot_loss=3.069 (perp=10.270, rec=0.249, cos=0.766), tot_loss_proj:3.837 [t=0.30s]
prediction: ['[CLS] sixfinger too many devils marbles i [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] i have six too many marbles. [SEP]
========================
predicted: 
========================
[CLS] sixfinger too many devils marbles i [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 89.286

[Aggregate metrics]:
rouge1     | fm: 78.032 | p: 78.179 | r: 78.040
rouge2     | fm: 36.909 | p: 36.875 | r: 37.450
rougeL     | fm: 68.455 | p: 68.527 | r: 68.659
rougeLsum  | fm: 68.528 | p: 68.698 | r: 68.478
r1fm+r2fm = 114.941

input #19 time: 0:11:49 | total time: 3:57:49


Running input #20 of 100.
reference: 
========================
Mark's single mindedness terrified me.
========================
average of cosine similarity 0.9988310205554667
highest_index [0]
highest [0.9988310205554667]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2928,  1005,  1055,  2309, 13128,  2791, 10215,  2033,  1012,
           102]], device='cuda:0')
Debug: ref = ["[CLS] mark's single mindedness terrified me. [SEP]"]
[Init] best rec loss: 0.9644955992698669 for ['[CLS] [CLS] asked sirius accessed ling women emphasis disc height [SEP]']
[Init] best rec loss: 0.9382871985435486 for ['[CLS]se guitarfirmed sky 2015 begging box simply agreed [SEP]']
[Init] best rec loss: 0.9377419948577881 for ['[CLS] mountains www without forest expo expressway travel midwayuca [SEP]']
[Init] best rec loss: 0.9247099161148071 for ['[CLS] toss me belly however glory best horror ktine [SEP]']
[Init] best rec loss: 0.9219642281532288 for ['[CLS] south died doctorate jerry samba online ᵀ polymeronal [SEP]']
[Init] best rec loss: 0.918061375617981 for ['[CLS] geological bedssion bowl trick retorted municipality pine index [SEP]']
[Init] best rec loss: 0.9102725982666016 for ['[CLS] trinity german pre innings super orbits sciencesraus see [SEP]']
[Init] best rec loss: 0.8914193511009216 for ['[CLS] fists later leaving model than heads finally ratherkushima [SEP]']
[Init] best perm rec loss: 0.8907760977745056 for ['[CLS]kushima leaving finally later fists than rather heads model [SEP]']
[Init] best perm rec loss: 0.8898792266845703 for ['[CLS] heads model later leaving than fists finallykushima rather [SEP]']
[Init] best perm rec loss: 0.8815720081329346 for ['[CLS] rather later fists model than heads finally leavingkushima [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.933 (perp=11.768, rec=0.595, cos=0.985), tot_loss_proj:4.178 [t=0.29s]
prediction: ['[CLS] bursting me shoulder certainly my guys 4 blind r [SEP]']
[ 100/2000] tot_loss=4.020 (perp=12.714, rec=0.488, cos=0.989), tot_loss_proj:4.443 [t=0.30s]
prediction: ['[CLS] wireless melinessfast my minded minded mindeder [SEP]']
[ 150/2000] tot_loss=4.041 (perp=12.904, rec=0.462, cos=0.997), tot_loss_proj:4.387 [t=0.30s]
prediction: ['[CLS] feared sutra memofast mark minded terrified mindeder [SEP]']
[ 200/2000] tot_loss=3.819 (perp=11.797, rec=0.461, cos=0.998), tot_loss_proj:4.178 [t=0.30s]
prediction: ['[CLS] feared sutra memofast mark minded terrified minded. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.261 (perp=9.781, rec=0.369, cos=0.936), tot_loss_proj:3.765 [t=0.30s]
prediction: ['[CLS] feared sutra mindedliness mark me terrified me. [SEP]']
[ 300/2000] tot_loss=3.335 (perp=10.247, rec=0.350, cos=0.936), tot_loss_proj:3.879 [t=0.30s]
prediction: ['[CLS] feared sutra minded minded mark me terrified me. [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.283 (perp=10.104, rec=0.330, cos=0.933), tot_loss_proj:3.878 [t=0.30s]
prediction: ['[CLS] appearing eyes minded minded mark me terrified me. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.288 (perp=9.922, rec=0.358, cos=0.945), tot_loss_proj:3.831 [t=0.30s]
prediction: ['[CLS] appearing cognitive s mark minded me terrified me. [SEP]']
[ 450/2000] tot_loss=3.249 (perp=9.922, rec=0.312, cos=0.952), tot_loss_proj:3.836 [t=0.30s]
prediction: ['[CLS] appearing cognitive s mark minded me terrified me. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.151 (perp=9.364, rec=0.318, cos=0.960), tot_loss_proj:3.713 [t=0.30s]
prediction: ['[CLS] appearing s cognitive mark minded me terrified me. [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.132 (perp=9.364, rec=0.309, cos=0.950), tot_loss_proj:3.718 [t=0.30s]
prediction: ['[CLS] appearing s cognitive mark minded me terrified me. [SEP]']
[ 600/2000] tot_loss=3.132 (perp=9.364, rec=0.300, cos=0.959), tot_loss_proj:3.719 [t=0.30s]
prediction: ['[CLS] appearing s cognitive mark minded me terrified me. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.138 (perp=9.364, rec=0.307, cos=0.958), tot_loss_proj:3.715 [t=0.30s]
prediction: ['[CLS] appearing s cognitive mark minded me terrified me. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.137 (perp=9.364, rec=0.302, cos=0.963), tot_loss_proj:3.716 [t=0.30s]
prediction: ['[CLS] appearing s cognitive mark minded me terrified me. [SEP]']
[ 750/2000] tot_loss=3.134 (perp=9.364, rec=0.304, cos=0.957), tot_loss_proj:3.725 [t=0.30s]
prediction: ['[CLS] appearing s cognitive mark minded me terrified me. [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.040 (perp=8.857, rec=0.304, cos=0.964), tot_loss_proj:3.658 [t=0.30s]
prediction: ['[CLS] wo s cognitive mark minded me terrified me. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.038 (perp=8.857, rec=0.297, cos=0.970), tot_loss_proj:3.656 [t=0.30s]
prediction: ['[CLS] wo s cognitive mark minded me terrified me. [SEP]']
[ 900/2000] tot_loss=3.037 (perp=8.857, rec=0.295, cos=0.970), tot_loss_proj:3.659 [t=0.30s]
prediction: ['[CLS] wo s cognitive mark minded me terrified me. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.050 (perp=8.929, rec=0.295, cos=0.969), tot_loss_proj:3.687 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.051 (perp=8.929, rec=0.292, cos=0.973), tot_loss_proj:3.688 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
[1050/2000] tot_loss=3.042 (perp=8.929, rec=0.290, cos=0.966), tot_loss_proj:3.687 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.048 (perp=8.929, rec=0.290, cos=0.972), tot_loss_proj:3.690 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.044 (perp=8.929, rec=0.288, cos=0.971), tot_loss_proj:3.685 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
[1200/2000] tot_loss=3.047 (perp=8.929, rec=0.292, cos=0.970), tot_loss_proj:3.686 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.044 (perp=8.929, rec=0.285, cos=0.973), tot_loss_proj:3.690 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.041 (perp=8.929, rec=0.286, cos=0.969), tot_loss_proj:3.692 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
[1350/2000] tot_loss=3.038 (perp=8.929, rec=0.284, cos=0.968), tot_loss_proj:3.685 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.041 (perp=8.929, rec=0.287, cos=0.968), tot_loss_proj:3.691 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.042 (perp=8.929, rec=0.289, cos=0.967), tot_loss_proj:3.694 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
[1500/2000] tot_loss=3.045 (perp=8.929, rec=0.289, cos=0.969), tot_loss_proj:3.687 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.039 (perp=8.929, rec=0.286, cos=0.967), tot_loss_proj:3.691 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.038 (perp=8.929, rec=0.284, cos=0.969), tot_loss_proj:3.689 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
[1650/2000] tot_loss=3.034 (perp=8.929, rec=0.279, cos=0.969), tot_loss_proj:3.684 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.038 (perp=8.929, rec=0.285, cos=0.967), tot_loss_proj:3.687 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.027 (perp=8.929, rec=0.273, cos=0.969), tot_loss_proj:3.693 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
[1800/2000] tot_loss=3.033 (perp=8.929, rec=0.280, cos=0.967), tot_loss_proj:3.692 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.027 (perp=8.929, rec=0.275, cos=0.966), tot_loss_proj:3.690 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.028 (perp=8.929, rec=0.275, cos=0.968), tot_loss_proj:3.689 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
[1950/2000] tot_loss=3.039 (perp=8.929, rec=0.287, cos=0.966), tot_loss_proj:3.687 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.034 (perp=8.929, rec=0.281, cos=0.967), tot_loss_proj:3.686 [t=0.30s]
prediction: ['[CLS] wo sures mark minded me terrified me. [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] mark's single mindedness terrified me. [SEP]
========================
predicted: 
========================
[CLS] wo sures mark minded me terrified me. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.824 | p: 55.556 | r: 62.500
rouge2     | fm: 26.667 | p: 25.000 | r: 28.571
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 85.490

[Aggregate metrics]:
rouge1     | fm: 77.231 | p: 77.224 | r: 77.540
rouge2     | fm: 36.721 | p: 36.447 | r: 37.153
rougeL     | fm: 68.170 | p: 68.130 | r: 68.362
rougeLsum  | fm: 67.858 | p: 67.884 | r: 68.148
r1fm+r2fm = 113.952

input #20 time: 0:11:48 | total time: 4:09:37


Running input #21 of 100.
reference: 
========================
Her indiscretions were made light of.
========================
average of cosine similarity 0.9989860401442581
highest_index [0]
highest [0.9989860401442581]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2014, 27427,  2483, 16748,  9285,  2020,  2081,  2422,  1997,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] her indiscretions were made light of. [SEP]']
[Init] best rec loss: 0.9379284977912903 for ['[CLS] dung help makei de blinds commissioned "z graders [SEP]']
[Init] best rec loss: 0.9307484030723572 for ['[CLS] toss morrison port th scene body principalsm wild stations [SEP]']
[Init] best rec loss: 0.9054065346717834 for ['[CLS] this innovation kala these yu sprint experience cas pressure paper [SEP]']
[Init] best rec loss: 0.9036952257156372 for ['[CLS] cues ll each wolf angel heading youphi along snow [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.773 (perp=12.287, rec=0.502, cos=0.814), tot_loss_proj:4.283 [t=0.29s]
prediction: ['[CLS] internationally called recordings recordings ended remix truss. lame 1996 [SEP]']
[ 100/2000] tot_loss=3.672 (perp=11.568, rec=0.461, cos=0.897), tot_loss_proj:4.150 [t=0.30s]
prediction: ['[CLS] internationally called recordingsfelt anders fragrance truss. anderson. [SEP]']
[ 150/2000] tot_loss=3.413 (perp=11.409, rec=0.390, cos=0.741), tot_loss_proj:4.084 [t=0.30s]
prediction: ['[CLS] tapestry light conditions her andreas fragrance truss. anderson. [SEP]']
[ 200/2000] tot_loss=3.330 (perp=11.073, rec=0.366, cos=0.750), tot_loss_proj:3.940 [t=0.30s]
prediction: ['[CLS] ind lighttions her andreas wife truss. down. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.242 (perp=9.481, rec=0.462, cos=0.884), tot_loss_proj:3.693 [t=0.30s]
prediction: ['[CLS] ind light ( her exclaimed wife. pinned in. [SEP]']
[ 300/2000] tot_loss=3.080 (perp=10.053, rec=0.375, cos=0.694), tot_loss_proj:3.718 [t=0.30s]
prediction: ['[CLS] were lighte her afterward wife. unsuccessful stopped. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.004 (perp=9.626, rec=0.317, cos=0.762), tot_loss_proj:3.785 [t=0.30s]
prediction: ['[CLS] makes sufferedtions her light wife. unsuccessful con. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.031 (perp=9.845, rec=0.291, cos=0.771), tot_loss_proj:3.732 [t=0.30s]
prediction: ['[CLS]tions disaster makes her light wife. were con. [SEP]']
[ 450/2000] tot_loss=3.068 (perp=9.998, rec=0.307, cos=0.761), tot_loss_proj:3.731 [t=0.30s]
prediction: ['[CLS]tions disaster makes her light fargo. were big. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.861 (perp=9.052, rec=0.279, cos=0.772), tot_loss_proj:3.572 [t=0.30s]
prediction: ['[CLS] hertions disaster makes light fargo. were point. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.742 (perp=8.513, rec=0.300, cos=0.739), tot_loss_proj:3.470 [t=0.30s]
prediction: ['[CLS] hertions were makes lightcre. disaster point. [SEP]']
[ 600/2000] tot_loss=2.604 (perp=7.872, rec=0.254, cos=0.776), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] hertions were made lightcre of disaster point. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.596 (perp=7.819, rec=0.265, cos=0.768), tot_loss_proj:3.382 [t=0.30s]
prediction: ['[CLS] hercretions were made light.ctor in. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.301 (perp=6.333, rec=0.258, cos=0.777), tot_loss_proj:3.221 [t=0.30s]
prediction: ['[CLS] hercretions were made of light laid in. [SEP]']
[ 750/2000] tot_loss=2.334 (perp=6.333, rec=0.260, cos=0.807), tot_loss_proj:3.223 [t=0.30s]
prediction: ['[CLS] hercretions were made of light laid in. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.567 (perp=7.501, rec=0.248, cos=0.819), tot_loss_proj:3.414 [t=0.30s]
prediction: ['[CLS] hercretions were made of lightctor in. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.587 (perp=7.716, rec=0.255, cos=0.789), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] hercretions were made. light inctor. [SEP]']
[ 900/2000] tot_loss=2.426 (perp=6.917, rec=0.237, cos=0.806), tot_loss_proj:3.348 [t=0.30s]
prediction: ['[CLS] hercretions were made of light inctor. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.407 (perp=6.917, rec=0.221, cos=0.803), tot_loss_proj:3.347 [t=0.30s]
prediction: ['[CLS] hercretions were made of light inctor. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.406 (perp=6.917, rec=0.239, cos=0.784), tot_loss_proj:3.344 [t=0.30s]
prediction: ['[CLS] hercretions were made of light inctor. [SEP]']
[1050/2000] tot_loss=2.443 (perp=7.050, rec=0.235, cos=0.799), tot_loss_proj:2.968 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.420 (perp=7.050, rec=0.216, cos=0.794), tot_loss_proj:2.960 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.428 (perp=7.050, rec=0.228, cos=0.790), tot_loss_proj:2.959 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
[1200/2000] tot_loss=2.418 (perp=7.050, rec=0.215, cos=0.794), tot_loss_proj:2.958 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.451 (perp=7.050, rec=0.242, cos=0.800), tot_loss_proj:2.950 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.435 (perp=7.050, rec=0.225, cos=0.800), tot_loss_proj:2.955 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
[1350/2000] tot_loss=2.417 (perp=7.050, rec=0.214, cos=0.793), tot_loss_proj:2.954 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.423 (perp=7.050, rec=0.220, cos=0.793), tot_loss_proj:2.944 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.415 (perp=7.050, rec=0.211, cos=0.794), tot_loss_proj:2.940 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
[1500/2000] tot_loss=2.425 (perp=7.050, rec=0.227, cos=0.788), tot_loss_proj:2.949 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.414 (perp=7.050, rec=0.217, cos=0.788), tot_loss_proj:2.944 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.425 (perp=7.050, rec=0.226, cos=0.790), tot_loss_proj:2.942 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
[1650/2000] tot_loss=2.406 (perp=7.050, rec=0.211, cos=0.785), tot_loss_proj:2.943 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.398 (perp=7.050, rec=0.202, cos=0.786), tot_loss_proj:2.944 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.418 (perp=7.050, rec=0.218, cos=0.790), tot_loss_proj:2.948 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
[1800/2000] tot_loss=2.400 (perp=7.050, rec=0.203, cos=0.787), tot_loss_proj:2.943 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.408 (perp=7.050, rec=0.214, cos=0.784), tot_loss_proj:2.940 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.411 (perp=7.050, rec=0.213, cos=0.788), tot_loss_proj:2.943 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
[1950/2000] tot_loss=2.403 (perp=7.050, rec=0.208, cos=0.785), tot_loss_proj:2.943 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.425 (perp=7.050, rec=0.229, cos=0.785), tot_loss_proj:2.945 [t=0.30s]
prediction: ['[CLS] hercretions were made of light indant. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] her indiscretions were made light of. [SEP]
========================
predicted: 
========================
[CLS] hercretions were made of light indant. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 89.286

[Aggregate metrics]:
rouge1     | fm: 77.115 | p: 77.015 | r: 77.445
rouge2     | fm: 35.444 | p: 35.332 | r: 35.802
rougeL     | fm: 67.925 | p: 67.842 | r: 68.076
rougeLsum  | fm: 67.767 | p: 67.717 | r: 67.903
r1fm+r2fm = 112.559

input #21 time: 0:11:48 | total time: 4:21:26


Running input #22 of 100.
reference: 
========================
Each of the boys fought with the other boys.
========================
average of cosine similarity 0.9991732028224674
highest_index [0]
highest [0.9991732028224674]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2169, 1997, 1996, 3337, 4061, 2007, 1996, 2060, 3337, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] each of the boys fought with the other boys. [SEP]']
[Init] best rec loss: 1.004582405090332 for ['[CLS] hers hours woundmund totaling pd hailey stone aftermath tortricidae [SEP]']
[Init] best rec loss: 0.960616946220398 for ['[CLS] library em group come surprise pass varsity moderate must blackness [SEP]']
[Init] best rec loss: 0.9139726161956787 for ['[CLS] broke demolition athens censorship turn blood starts collection unlike sex [SEP]']
[Init] best rec loss: 0.9069541692733765 for ['[CLS] hotterpath started regional chew intention concert bet outsiders labour [SEP]']
[Init] best rec loss: 0.9055195450782776 for ['[CLS] capital about why exercise suicide searchss elaine demand 。 [SEP]']
[Init] best rec loss: 0.8961159586906433 for ['[CLS] patternisentexttucket vol size maker lo kidd cabin [SEP]']
[Init] best rec loss: 0.889667809009552 for ['[CLS] agent lap specifically helping ad brand leader flyrter dad [SEP]']
[Init] best rec loss: 0.8788338899612427 for ['[CLS] properties rapper middle oftennded doubtmology magician bulletele [SEP]']
[Init] best perm rec loss: 0.8751628398895264 for ['[CLS] often properties middle bulletmology rapper magicianndedele doubt [SEP]']
[Init] best perm rec loss: 0.8748884201049805 for ['[CLS] rappermology doubt magician properties oftenelended middle bullet [SEP]']
[Init] best perm rec loss: 0.8731488585472107 for ['[CLS] middle rapper often propertiesmology magiciannded doubt bulletele [SEP]']
[Init] best perm rec loss: 0.8730964660644531 for ['[CLS] rapper properties doubt magician middlemologyele bullet oftennded [SEP]']
[Init] best perm rec loss: 0.8728205561637878 for ['[CLS] often rapper middle doubt magician propertiesele bulletmologynded [SEP]']
[Init] best perm rec loss: 0.8726057410240173 for ['[CLS] doubt bullet middleele propertiesmology magiciannded often rapper [SEP]']
[Init] best perm rec loss: 0.8723732829093933 for ['[CLS] rapper bulletnded propertieselemology often doubt middle magician [SEP]']
[Init] best perm rec loss: 0.8718417286872864 for ['[CLS] middlemology magician properties rapper doubt often bulletelended [SEP]']
[Init] best perm rec loss: 0.869830846786499 for ['[CLS] properties bullet middlemologyele rapper doubt magician oftennded [SEP]']
[Init] best perm rec loss: 0.8693327307701111 for ['[CLS] properties rapper middle magician bulletele doubt oftenmologynded [SEP]']
[Init] best perm rec loss: 0.8669948577880859 for ['[CLS]mology bullet middle properties oftenele doubtnded rapper magician [SEP]']
[Init] best perm rec loss: 0.8667179942131042 for ['[CLS] middle bullet magician propertiesmologyele rappernded doubt often [SEP]']
[Init] best perm rec loss: 0.8664039373397827 for ['[CLS] rapper propertiesmology middleele often bullet doubt magiciannded [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.994 (perp=13.527, rec=0.574, cos=0.715), tot_loss_proj:4.475 [t=0.29s]
prediction: ['[CLS] each teams stood neverhia pretending record formed yelled volunteers [SEP]']
[ 100/2000] tot_loss=3.236 (perp=9.716, rec=0.480, cos=0.813), tot_loss_proj:3.758 [t=0.30s]
prediction: ['[CLS] each party each fully each. all startedailed combat [SEP]']
[ 150/2000] tot_loss=3.541 (perp=11.371, rec=0.434, cos=0.832), tot_loss_proj:4.043 [t=0.30s]
prediction: ['[CLS] each boys each fought each. record together fights infantry [SEP]']
[ 200/2000] tot_loss=3.226 (perp=9.822, rec=0.384, cos=0.878), tot_loss_proj:3.824 [t=0.30s]
prediction: ['[CLS] each of each fought each fought jug together fought men [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.332 (perp=10.576, rec=0.337, cos=0.880), tot_loss_proj:4.067 [t=0.30s]
prediction: ['[CLS] each of each fought each foughtgies opposition fought boys [SEP]']
[ 300/2000] tot_loss=3.053 (perp=9.566, rec=0.305, cos=0.834), tot_loss_proj:3.823 [t=0.30s]
prediction: ['[CLS] each of from fought each foughtgies boys fought boys [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.293 (perp=10.762, rec=0.298, cos=0.842), tot_loss_proj:3.967 [t=0.30s]
prediction: ['[CLS] each of fought from each fought wrists boys ே boys [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.331 (perp=10.685, rec=0.321, cos=0.873), tot_loss_proj:3.959 [t=0.30s]
prediction: ['[CLS] each of fought boys each fought wrists fistsailed boys [SEP]']
[ 450/2000] tot_loss=3.260 (perp=10.685, rec=0.282, cos=0.841), tot_loss_proj:3.961 [t=0.30s]
prediction: ['[CLS] each of fought boys each fought wrists fistsailed boys [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.254 (perp=10.685, rec=0.284, cos=0.833), tot_loss_proj:3.965 [t=0.30s]
prediction: ['[CLS] each of fought boys each fought wrists fistsailed boys [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.062 (perp=9.518, rec=0.316, cos=0.842), tot_loss_proj:3.804 [t=0.30s]
prediction: ['[CLS] each of fought boys each fought the ே boys fists [SEP]']
[ 600/2000] tot_loss=3.202 (perp=10.513, rec=0.271, cos=0.828), tot_loss_proj:3.963 [t=0.30s]
prediction: ['[CLS] each of fought boys each fought wrists skirmish boys fists [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.139 (perp=10.183, rec=0.274, cos=0.829), tot_loss_proj:3.873 [t=0.30s]
prediction: ['[CLS] each of fought boys each fought boys wrists skirmish fists [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.361 (perp=11.012, rec=0.314, cos=0.844), tot_loss_proj:4.118 [t=0.30s]
prediction: ['[CLS] each of skirmish boys each fought boys wrists ، fists [SEP]']
[ 750/2000] tot_loss=3.191 (perp=10.460, rec=0.272, cos=0.826), tot_loss_proj:3.987 [t=0.30s]
prediction: ['[CLS] boys of skirmish boys each fought boysusing ، fists [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.974 (perp=9.415, rec=0.268, cos=0.822), tot_loss_proj:3.766 [t=0.30s]
prediction: ['[CLS] boys of skirmish boys each fought boysusing boys ، [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.976 (perp=9.415, rec=0.260, cos=0.833), tot_loss_proj:3.762 [t=0.30s]
prediction: ['[CLS] boys of skirmish boys each fought boysusing boys ، [SEP]']
[ 900/2000] tot_loss=2.969 (perp=9.415, rec=0.256, cos=0.830), tot_loss_proj:3.764 [t=0.30s]
prediction: ['[CLS] boys of skirmish boys each fought boysusing boys ، [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.697 (perp=8.051, rec=0.266, cos=0.820), tot_loss_proj:3.472 [t=0.30s]
prediction: ['[CLS] boys of skirmish boys each fought boys the boys other [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.569 (perp=7.454, rec=0.255, cos=0.822), tot_loss_proj:3.317 [t=0.30s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other boys [SEP]']
[1050/2000] tot_loss=2.566 (perp=7.454, rec=0.259, cos=0.816), tot_loss_proj:3.318 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other boys [SEP]']
Attempt swap
[1100/2000] tot_loss=2.567 (perp=7.454, rec=0.261, cos=0.815), tot_loss_proj:3.318 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other boys [SEP]']
Attempt swap
[1150/2000] tot_loss=2.559 (perp=7.454, rec=0.253, cos=0.815), tot_loss_proj:3.323 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other boys [SEP]']
[1200/2000] tot_loss=2.547 (perp=7.454, rec=0.243, cos=0.813), tot_loss_proj:3.316 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other boys [SEP]']
Attempt swap
[1250/2000] tot_loss=2.546 (perp=7.454, rec=0.245, cos=0.811), tot_loss_proj:3.317 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other boys [SEP]']
Attempt swap
[1300/2000] tot_loss=2.554 (perp=7.454, rec=0.250, cos=0.813), tot_loss_proj:3.320 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other boys [SEP]']
[1350/2000] tot_loss=2.546 (perp=7.454, rec=0.247, cos=0.808), tot_loss_proj:3.319 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other boys [SEP]']
Attempt swap
[1400/2000] tot_loss=2.541 (perp=7.454, rec=0.242, cos=0.809), tot_loss_proj:3.319 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other boys [SEP]']
Attempt swap
[1450/2000] tot_loss=2.541 (perp=7.454, rec=0.242, cos=0.808), tot_loss_proj:3.319 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other boys [SEP]']
[1500/2000] tot_loss=2.538 (perp=7.454, rec=0.239, cos=0.808), tot_loss_proj:3.322 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other boys [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.631 (perp=7.879, rec=0.246, cos=0.809), tot_loss_proj:3.383 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the boys with [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.705 (perp=8.238, rec=0.246, cos=0.812), tot_loss_proj:3.513 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the other respectively [SEP]']
[1650/2000] tot_loss=3.059 (perp=10.031, rec=0.247, cos=0.806), tot_loss_proj:3.824 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought boys the with respectively [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.528 (perp=7.346, rec=0.252, cos=0.807), tot_loss_proj:3.438 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought with the boys respectively [SEP]']
Attempt swap
[1750/2000] tot_loss=2.520 (perp=7.346, rec=0.243, cos=0.808), tot_loss_proj:3.441 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought with the boys respectively [SEP]']
[1800/2000] tot_loss=2.528 (perp=7.346, rec=0.251, cos=0.807), tot_loss_proj:3.442 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought with the boys respectively [SEP]']
Attempt swap
[1850/2000] tot_loss=2.520 (perp=7.346, rec=0.245, cos=0.806), tot_loss_proj:3.443 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought with the boys respectively [SEP]']
Attempt swap
[1900/2000] tot_loss=2.523 (perp=7.346, rec=0.248, cos=0.806), tot_loss_proj:3.443 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought with the boys respectively [SEP]']
[1950/2000] tot_loss=2.511 (perp=7.346, rec=0.237, cos=0.805), tot_loss_proj:3.443 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought with the boys respectively [SEP]']
Attempt swap
[2000/2000] tot_loss=2.521 (perp=7.346, rec=0.246, cos=0.806), tot_loss_proj:3.437 [t=0.35s]
prediction: ['[CLS] boys of skirmish boys each fought with the boys respectively [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] each of the boys fought with the other boys. [SEP]
========================
predicted: 
========================
[CLS] boys of skirmish boys each fought boys the other boys [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 75.000 | r: 81.818
rouge2     | fm: 28.571 | p: 27.273 | r: 30.000
rougeL     | fm: 69.565 | p: 66.667 | r: 72.727
rougeLsum  | fm: 69.565 | p: 66.667 | r: 72.727
r1fm+r2fm = 106.832

[Aggregate metrics]:
rouge1     | fm: 77.216 | p: 76.980 | r: 77.494
rouge2     | fm: 35.283 | p: 35.047 | r: 35.831
rougeL     | fm: 67.802 | p: 67.661 | r: 68.243
rougeLsum  | fm: 67.761 | p: 67.707 | r: 68.169
r1fm+r2fm = 112.499

input #22 time: 0:12:40 | total time: 4:34:06


Running input #23 of 100.
reference: 
========================
Herman mixed the eggs with the cream.
========================
average of cosine similarity 0.9988457875989352
highest_index [0]
highest [0.9988457875989352]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 11458,  3816,  1996,  6763,  2007,  1996,  6949,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] herman mixed the eggs with the cream. [SEP]']
[Init] best rec loss: 0.9815639853477478 for ['[CLS] digital borrow applied lodging luc reconciliation rhys toe [SEP]']
[Init] best rec loss: 0.9211680293083191 for ['[CLS] slapped seal near ice sick funk operation commodore [SEP]']
[Init] best rec loss: 0.9177963733673096 for ['[CLS] memory let mae voices name dreamdrop wipe [SEP]']
[Init] best rec loss: 0.9136365056037903 for ['[CLS] designed british bing blinkeddget or strengthll [SEP]']
[Init] best rec loss: 0.9082631468772888 for ['[CLS] less saga glass study timesvial jamalactive [SEP]']
[Init] best rec loss: 0.9027514457702637 for ['[CLS]clusive planttu ever ma teach heard package [SEP]']
[Init] best perm rec loss: 0.9009191989898682 for ['[CLS]tu ever heard ma teachclusive package plant [SEP]']
[Init] best perm rec loss: 0.9003455638885498 for ['[CLS]tu package ever ma heard teach plantclusive [SEP]']
[Init] best perm rec loss: 0.8995493650436401 for ['[CLS] teachclusive heardtu ever package ma plant [SEP]']
[Init] best perm rec loss: 0.8979531526565552 for ['[CLS] evertu teachclusive ma heard package plant [SEP]']
[Init] best perm rec loss: 0.8953590989112854 for ['[CLS] matu teach plant packageclusive ever heard [SEP]']
[Init] best perm rec loss: 0.8953293561935425 for ['[CLS] teachclusive ever plant package matu heard [SEP]']
[Init] best perm rec loss: 0.8937613368034363 for ['[CLS] packagetu ever plantclusive ma teach heard [SEP]']
[Init] best perm rec loss: 0.8912487030029297 for ['[CLS] everclusive package teach plant matu heard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.842 (perp=11.199, rec=0.613, cos=0.990), tot_loss_proj:3.972 [t=0.34s]
prediction: ['[CLS] there polka achievement. debut vocals cream eggs [SEP]']
[ 100/2000] tot_loss=3.900 (perp=12.198, rec=0.537, cos=0.924), tot_loss_proj:4.231 [t=0.34s]
prediction: ['[CLS] buzzfolk mixed. gmbh ← eggs eggs [SEP]']
[ 150/2000] tot_loss=3.603 (perp=11.194, rec=0.524, cos=0.841), tot_loss_proj:3.985 [t=0.35s]
prediction: ['[CLS] anyfolk mixed. beside ← eggs eggs [SEP]']
[ 200/2000] tot_loss=3.426 (perp=10.751, rec=0.441, cos=0.835), tot_loss_proj:3.905 [t=0.35s]
prediction: ['[CLS] anyfolk mixed. anything eggs eggs eggs [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.548 (perp=11.553, rec=0.421, cos=0.817), tot_loss_proj:4.051 [t=0.35s]
prediction: ['[CLS]going eggs mixed. theence competitors eggs [SEP]']
[ 300/2000] tot_loss=3.457 (perp=11.184, rec=0.367, cos=0.853), tot_loss_proj:4.219 [t=0.35s]
prediction: ['[CLS]going eggs mixed. hisencetarian eggs [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.296 (perp=10.561, rec=0.333, cos=0.850), tot_loss_proj:4.123 [t=0.35s]
prediction: ['[CLS] treated mixed eggs. hisencetarian eggs [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.540 (perp=11.627, rec=0.365, cos=0.850), tot_loss_proj:4.102 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs highlighted hisence cream eggs [SEP]']
[ 450/2000] tot_loss=3.177 (perp=10.025, rec=0.318, cos=0.854), tot_loss_proj:3.885 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs highlighted hisence. eggs [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.221 (perp=10.025, rec=0.328, cos=0.888), tot_loss_proj:3.888 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs highlighted hisence. eggs [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.153 (perp=10.025, rec=0.309, cos=0.838), tot_loss_proj:3.888 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs highlighted hisence. eggs [SEP]']
[ 600/2000] tot_loss=3.201 (perp=10.025, rec=0.309, cos=0.888), tot_loss_proj:3.888 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs highlighted hisence. eggs [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.366 (perp=11.058, rec=0.294, cos=0.860), tot_loss_proj:3.984 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs generations his eggsence. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.270 (perp=10.493, rec=0.301, cos=0.870), tot_loss_proj:3.937 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs ？ his eggsence. [SEP]']
[ 750/2000] tot_loss=3.260 (perp=10.493, rec=0.297, cos=0.865), tot_loss_proj:3.938 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs ？ his eggsence. [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.431 (perp=11.436, rec=0.293, cos=0.852), tot_loss_proj:4.128 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs ？ his hermanence. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=3.420 (perp=11.177, rec=0.304, cos=0.881), tot_loss_proj:4.117 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs ？ hisence herman. [SEP]']
[ 900/2000] tot_loss=3.370 (perp=11.177, rec=0.276, cos=0.858), tot_loss_proj:4.112 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs ？ hisence herman. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.380 (perp=11.177, rec=0.286, cos=0.858), tot_loss_proj:4.110 [t=0.35s]
prediction: ['[CLS]hyllum mixed eggs ？ hisence herman. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.192 (perp=10.300, rec=0.276, cos=0.856), tot_loss_proj:3.880 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ withence herman. [SEP]']
[1050/2000] tot_loss=3.197 (perp=10.300, rec=0.279, cos=0.858), tot_loss_proj:3.881 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ withence herman. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=3.067 (perp=9.571, rec=0.295, cos=0.858), tot_loss_proj:3.829 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.052 (perp=9.571, rec=0.282, cos=0.855), tot_loss_proj:3.827 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
[1200/2000] tot_loss=3.049 (perp=9.571, rec=0.279, cos=0.856), tot_loss_proj:3.827 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.041 (perp=9.571, rec=0.272, cos=0.855), tot_loss_proj:3.824 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.050 (perp=9.571, rec=0.279, cos=0.857), tot_loss_proj:3.833 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
[1350/2000] tot_loss=3.052 (perp=9.571, rec=0.282, cos=0.856), tot_loss_proj:3.828 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.056 (perp=9.571, rec=0.284, cos=0.858), tot_loss_proj:3.833 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.045 (perp=9.571, rec=0.275, cos=0.857), tot_loss_proj:3.833 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
[1500/2000] tot_loss=3.052 (perp=9.571, rec=0.280, cos=0.858), tot_loss_proj:3.828 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.064 (perp=9.571, rec=0.291, cos=0.858), tot_loss_proj:3.833 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.051 (perp=9.571, rec=0.278, cos=0.858), tot_loss_proj:3.832 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
[1650/2000] tot_loss=3.044 (perp=9.571, rec=0.273, cos=0.857), tot_loss_proj:3.829 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.054 (perp=9.571, rec=0.282, cos=0.858), tot_loss_proj:3.828 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.057 (perp=9.571, rec=0.284, cos=0.858), tot_loss_proj:3.829 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
[1800/2000] tot_loss=3.051 (perp=9.571, rec=0.279, cos=0.858), tot_loss_proj:3.829 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.055 (perp=9.571, rec=0.283, cos=0.858), tot_loss_proj:3.832 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.047 (perp=9.571, rec=0.275, cos=0.858), tot_loss_proj:3.833 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
[1950/2000] tot_loss=3.055 (perp=9.571, rec=0.282, cos=0.858), tot_loss_proj:3.834 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.042 (perp=9.571, rec=0.269, cos=0.859), tot_loss_proj:3.831 [t=0.35s]
prediction: ['[CLS] herman mixed eggs ？ with hermanence. [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] herman mixed the eggs with the cream. [SEP]
========================
predicted: 
========================
[CLS] herman mixed eggs ？ with hermanence. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 85.714 | r: 66.667
rouge2     | fm: 42.857 | p: 50.000 | r: 37.500
rougeL     | fm: 75.000 | p: 85.714 | r: 66.667
rougeLsum  | fm: 75.000 | p: 85.714 | r: 66.667
r1fm+r2fm = 117.857

[Aggregate metrics]:
rouge1     | fm: 77.099 | p: 77.370 | r: 77.039
rouge2     | fm: 35.430 | p: 35.600 | r: 35.775
rougeL     | fm: 68.193 | p: 68.600 | r: 68.194
rougeLsum  | fm: 68.222 | p: 68.463 | r: 68.107
r1fm+r2fm = 112.529

input #23 time: 0:13:35 | total time: 4:47:42


Running input #24 of 100.
reference: 
========================
No John Smiths attended the meeting.
========================
average of cosine similarity 0.9990342534828289
highest_index [0]
highest [0.9990342534828289]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2053, 2198, 3044, 2015, 3230, 1996, 3116, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] no john smiths attended the meeting. [SEP]']
[Init] best rec loss: 0.8561364412307739 for ['[CLS] performance maybe rae tri / window grace lockheed [SEP]']
[Init] best rec loss: 0.8312839269638062 for ['[CLS] documentary mystery influence club guardian cinemas coast degrees [SEP]']
[Init] best rec loss: 0.830159604549408 for ['[CLS] whether service gage mac foiloked cdp city [SEP]']
[Init] best rec loss: 0.8300171494483948 for ['[CLS] would western next small spoon constant care before [SEP]']
[Init] best rec loss: 0.8116700053215027 for ['[CLS] uniformiec thickdding his ⟩ universidad regal [SEP]']
[Init] best perm rec loss: 0.809343695640564 for ['[CLS] regal thick uniform his universidaddding ⟩iec [SEP]']
[Init] best perm rec loss: 0.80830317735672 for ['[CLS] universidad uniform regal ⟩ddingiec his thick [SEP]']
[Init] best perm rec loss: 0.8076093792915344 for ['[CLS] regal uniformiec ⟩ his universidad thickdding [SEP]']
[Init] best perm rec loss: 0.8073229789733887 for ['[CLS] thickiec regal ⟩dding universidad his uniform [SEP]']
[Init] best perm rec loss: 0.8068486452102661 for ['[CLS] regal his universidad ⟩ddingiec thick uniform [SEP]']
[Init] best perm rec loss: 0.8052051067352295 for ['[CLS] regal hisdding universidad ⟩ thick uniformiec [SEP]']
[Init] best perm rec loss: 0.8050816059112549 for ['[CLS] regal universidad hisddingiec ⟩ uniform thick [SEP]']
[Init] best perm rec loss: 0.8040692806243896 for ['[CLS]dding regal hisiec universidad thick uniform ⟩ [SEP]']
[Init] best perm rec loss: 0.8034666776657104 for ['[CLS]dding regal hisiec universidad uniform ⟩ thick [SEP]']
[Init] best perm rec loss: 0.8030045628547668 for ['[CLS] regaliecdding universidad thick his uniform ⟩ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.806 (perp=11.975, rec=0.507, cos=0.905), tot_loss_proj:4.296 [t=0.34s]
prediction: ['[CLS] smiths approved john no 2009 lined teams [SEP]']
[ 100/2000] tot_loss=3.238 (perp=10.287, rec=0.368, cos=0.812), tot_loss_proj:3.917 [t=0.34s]
prediction: ['[CLS] smiths meeting john no combination john attended [SEP]']
[ 150/2000] tot_loss=2.869 (perp=9.457, rec=0.266, cos=0.711), tot_loss_proj:3.800 [t=0.35s]
prediction: ['[CLS] smiths meeting john no inclusive john attended [SEP]']
[ 200/2000] tot_loss=3.029 (perp=10.245, rec=0.232, cos=0.748), tot_loss_proj:3.922 [t=0.35s]
prediction: ['[CLS] smiths meeting john no millennium john attended [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.991 (perp=10.188, rec=0.199, cos=0.754), tot_loss_proj:3.865 [t=0.35s]
prediction: ['[CLS] smiths meeting no john millenniumhak attended [SEP]']
[ 300/2000] tot_loss=2.931 (perp=10.033, rec=0.187, cos=0.737), tot_loss_proj:3.879 [t=0.35s]
prediction: ['[CLS] smiths meeting no john highlandshak attended [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.002 (perp=10.006, rec=0.199, cos=0.802), tot_loss_proj:3.931 [t=0.35s]
prediction: ['[CLS] smiths meeting no john highlands spiritual attended [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.742 (perp=8.846, rec=0.202, cos=0.771), tot_loss_proj:3.662 [t=0.35s]
prediction: ['[CLS] smiths anniversary spiritual meeting no john attended [SEP]']
[ 450/2000] tot_loss=2.864 (perp=9.596, rec=0.184, cos=0.760), tot_loss_proj:3.817 [t=0.35s]
prediction: ['[CLS] smithsnd spiritual meeting no john attended [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.881 (perp=9.596, rec=0.181, cos=0.781), tot_loss_proj:3.823 [t=0.35s]
prediction: ['[CLS] smithsnd spiritual meeting no john attended [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.861 (perp=9.605, rec=0.174, cos=0.766), tot_loss_proj:3.804 [t=0.35s]
prediction: ['[CLS] smiths purchased meeting no johnnd attended [SEP]']
[ 600/2000] tot_loss=2.870 (perp=9.605, rec=0.168, cos=0.780), tot_loss_proj:3.799 [t=0.35s]
prediction: ['[CLS] smiths purchased meeting no johnnd attended [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.889 (perp=9.605, rec=0.174, cos=0.794), tot_loss_proj:3.804 [t=0.35s]
prediction: ['[CLS] smiths purchased meeting no johnnd attended [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.860 (perp=9.605, rec=0.160, cos=0.779), tot_loss_proj:3.805 [t=0.35s]
prediction: ['[CLS] smiths purchased meeting no johnnd attended [SEP]']
[ 750/2000] tot_loss=2.904 (perp=9.809, rec=0.163, cos=0.779), tot_loss_proj:3.879 [t=0.35s]
prediction: ['[CLS] smiths early meeting no johnnd attended [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.945 (perp=9.809, rec=0.172, cos=0.811), tot_loss_proj:3.878 [t=0.35s]
prediction: ['[CLS] smiths early meeting no johnnd attended [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=3.087 (perp=10.529, rec=0.174, cos=0.807), tot_loss_proj:4.033 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended purchased [SEP]']
[ 900/2000] tot_loss=2.805 (perp=9.285, rec=0.166, cos=0.782), tot_loss_proj:3.773 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.813 (perp=9.285, rec=0.172, cos=0.784), tot_loss_proj:3.772 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1000/2000] tot_loss=2.810 (perp=9.285, rec=0.169, cos=0.784), tot_loss_proj:3.771 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
[1050/2000] tot_loss=2.802 (perp=9.285, rec=0.157, cos=0.788), tot_loss_proj:3.776 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1100/2000] tot_loss=2.803 (perp=9.285, rec=0.162, cos=0.784), tot_loss_proj:3.779 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1150/2000] tot_loss=2.814 (perp=9.285, rec=0.164, cos=0.793), tot_loss_proj:3.777 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
[1200/2000] tot_loss=2.808 (perp=9.285, rec=0.166, cos=0.785), tot_loss_proj:3.774 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1250/2000] tot_loss=2.796 (perp=9.285, rec=0.156, cos=0.783), tot_loss_proj:3.773 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1300/2000] tot_loss=2.797 (perp=9.285, rec=0.154, cos=0.785), tot_loss_proj:3.775 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
[1350/2000] tot_loss=2.816 (perp=9.285, rec=0.175, cos=0.784), tot_loss_proj:3.774 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1400/2000] tot_loss=2.802 (perp=9.285, rec=0.160, cos=0.785), tot_loss_proj:3.773 [t=0.35s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1450/2000] tot_loss=2.803 (perp=9.285, rec=0.159, cos=0.787), tot_loss_proj:3.779 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
[1500/2000] tot_loss=2.809 (perp=9.285, rec=0.166, cos=0.787), tot_loss_proj:3.774 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1550/2000] tot_loss=2.801 (perp=9.285, rec=0.159, cos=0.786), tot_loss_proj:3.772 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1600/2000] tot_loss=2.812 (perp=9.285, rec=0.169, cos=0.786), tot_loss_proj:3.776 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
[1650/2000] tot_loss=2.800 (perp=9.285, rec=0.158, cos=0.785), tot_loss_proj:3.768 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1700/2000] tot_loss=2.800 (perp=9.285, rec=0.157, cos=0.786), tot_loss_proj:3.772 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1750/2000] tot_loss=2.804 (perp=9.285, rec=0.162, cos=0.785), tot_loss_proj:3.773 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
[1800/2000] tot_loss=2.811 (perp=9.285, rec=0.169, cos=0.785), tot_loss_proj:3.772 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1850/2000] tot_loss=2.804 (perp=9.285, rec=0.159, cos=0.788), tot_loss_proj:3.775 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[1900/2000] tot_loss=2.801 (perp=9.285, rec=0.157, cos=0.787), tot_loss_proj:3.772 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
[1950/2000] tot_loss=2.806 (perp=9.285, rec=0.163, cos=0.787), tot_loss_proj:3.774 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Attempt swap
[2000/2000] tot_loss=2.805 (perp=9.285, rec=0.162, cos=0.786), tot_loss_proj:3.775 [t=0.30s]
prediction: ['[CLS] smiths meeting no johnnd attended early [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] no john smiths attended the meeting. [SEP]
========================
predicted: 
========================
[CLS] smiths meeting no johnnd attended early [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 75.000

[Aggregate metrics]:
rouge1     | fm: 77.070 | p: 77.286 | r: 76.952
rouge2     | fm: 34.203 | p: 34.298 | r: 34.552
rougeL     | fm: 67.318 | p: 67.664 | r: 67.355
rougeLsum  | fm: 67.466 | p: 67.703 | r: 67.302
r1fm+r2fm = 111.273

input #24 time: 0:13:06 | total time: 5:00:49


Running input #25 of 100.
reference: 
========================
I did not, as Bill had thought, go to the store.
========================
average of cosine similarity 0.9989757437182063
highest_index [0]
highest [0.9989757437182063]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2106, 2025, 1010, 2004, 3021, 2018, 2245, 1010, 2175, 2000,
         1996, 3573, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i did not, as bill had thought, go to the store. [SEP]']
[Init] best rec loss: 0.9643357396125793 for ['[CLS] zu sussex wig son committed koppen youth part sc missile combat carrier licence magazine [SEP]']
[Init] best rec loss: 0.8759822845458984 for ['[CLS] air moisture each van kind pl tribes fulltou nod resolvedhesivevan affair [SEP]']
[Init] best rec loss: 0.8639082908630371 for ['[CLS] foods prefect isaac type representation mumdrohos million toward sin register maiden phone [SEP]']
[Init] best perm rec loss: 0.8612576723098755 for ['[CLS] mum register representation towardhos maiden prefect sindro foods isaac type phone million [SEP]']
[Init] best perm rec loss: 0.8602681756019592 for ['[CLS] maiden phone prefect typehos mum representation sindro isaac toward foods million register [SEP]']
[Init] best perm rec loss: 0.8561965227127075 for ['[CLS] registerhos phone prefect foods sin isaac representation type milliondro maiden mum toward [SEP]']
[Init] best perm rec loss: 0.8561815619468689 for ['[CLS]hos prefect isaac maiden toward million representationdro type register foods mum phone sin [SEP]']
[Init] best perm rec loss: 0.8551132678985596 for ['[CLS] type prefect phone register foods mum isaac maiden millionhos representationdro toward sin [SEP]']
[Init] best perm rec loss: 0.8544862866401672 for ['[CLS] foodshos sin million prefect mum type maiden register representation towarddro phone isaac [SEP]']
[Init] best perm rec loss: 0.8542124629020691 for ['[CLS] toward registerhos mum type sin representationdro phone maiden foods prefect million isaac [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.577 (perp=10.995, rec=0.546, cos=0.832), tot_loss_proj:4.132 [t=0.29s]
prediction: ['[CLS] aix regarding. distribution no trinity leaves found jacket think. depths 2 ; [SEP]']
[ 100/2000] tot_loss=3.024 (perp=8.686, rec=0.477, cos=0.810), tot_loss_proj:3.639 [t=0.30s]
prediction: ['[CLS] not did a ballet leave traybone had jacket have!.., [SEP]']
[ 150/2000] tot_loss=2.895 (perp=8.581, rec=0.418, cos=0.761), tot_loss_proj:3.556 [t=0.30s]
prediction: ['[CLS] not did, would not advantages thought found jacket not i. to, [SEP]']
[ 200/2000] tot_loss=2.845 (perp=8.589, rec=0.389, cos=0.738), tot_loss_proj:3.580 [t=0.30s]
prediction: ['[CLS] not did not store not ( thought had right not go. to, [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.220 (perp=9.619, rec=0.532, cos=0.765), tot_loss_proj:3.813 [t=0.30s]
prediction: ["[CLS] imported is not'had ( was had called album not go. anyone [SEP]"]
[ 300/2000] tot_loss=3.157 (perp=10.495, rec=0.371, cos=0.687), tot_loss_proj:3.979 [t=0.30s]
prediction: ['[CLS]... did not planet as he seemedmine armed album toju. question [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.940 (perp=9.343, rec=0.353, cos=0.718), tot_loss_proj:3.805 [t=0.30s]
prediction: ['[CLS]... did not bill asle thought, night. spot armed album question [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.973 (perp=9.907, rec=0.330, cos=0.662), tot_loss_proj:3.899 [t=0.30s]
prediction: ['[CLS]... did not bill as bill thought go night armed. spot album question [SEP]']
[ 450/2000] tot_loss=2.870 (perp=9.490, rec=0.297, cos=0.675), tot_loss_proj:3.796 [t=0.30s]
prediction: ['[CLS]... did not bill as bill thought go night armed. store album never [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.034 (perp=9.984, rec=0.347, cos=0.691), tot_loss_proj:3.915 [t=0.30s]
prediction: ['[CLS] when did not bill as bill thought go go armed. store album question [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.696 (perp=8.711, rec=0.297, cos=0.656), tot_loss_proj:3.564 [t=0.30s]
prediction: ['[CLS] when did not bill as bill thought go go grocery store store never. [SEP]']
[ 600/2000] tot_loss=2.883 (perp=9.614, rec=0.280, cos=0.681), tot_loss_proj:3.738 [t=0.30s]
prediction: ['[CLS] indeed did not bill as bill thought go go grocery storetary all. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.524 (perp=7.881, rec=0.288, cos=0.660), tot_loss_proj:3.455 [t=0.30s]
prediction: ['[CLS] indeed did not bill as bill thought, never go grocery storetary. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.584 (perp=8.082, rec=0.296, cos=0.671), tot_loss_proj:3.435 [t=0.30s]
prediction: ['[CLS] did not bill indeed as bill thought, all go grocery store password. [SEP]']
[ 750/2000] tot_loss=2.457 (perp=7.589, rec=0.273, cos=0.667), tot_loss_proj:3.359 [t=0.30s]
prediction: ['[CLS] did not bill indeed as bill thought, why go grocery store meet. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.404 (perp=7.329, rec=0.266, cos=0.673), tot_loss_proj:3.319 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought indeed why go grocery store meet. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.368 (perp=7.065, rec=0.261, cos=0.695), tot_loss_proj:3.252 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
[ 900/2000] tot_loss=2.353 (perp=7.148, rec=0.251, cos=0.672), tot_loss_proj:3.263 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store album. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.351 (perp=7.148, rec=0.251, cos=0.670), tot_loss_proj:3.264 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store album. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.355 (perp=7.148, rec=0.251, cos=0.674), tot_loss_proj:3.258 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store album. [SEP]']
[1050/2000] tot_loss=2.362 (perp=7.148, rec=0.253, cos=0.679), tot_loss_proj:3.264 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store album. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.358 (perp=7.148, rec=0.251, cos=0.677), tot_loss_proj:3.265 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store album. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.346 (perp=7.065, rec=0.243, cos=0.689), tot_loss_proj:3.255 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
[1200/2000] tot_loss=2.349 (perp=7.065, rec=0.249, cos=0.686), tot_loss_proj:3.252 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.347 (perp=7.065, rec=0.253, cos=0.681), tot_loss_proj:3.252 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.342 (perp=7.065, rec=0.243, cos=0.686), tot_loss_proj:3.252 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
[1350/2000] tot_loss=2.342 (perp=7.065, rec=0.242, cos=0.688), tot_loss_proj:3.251 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.348 (perp=7.065, rec=0.244, cos=0.691), tot_loss_proj:3.250 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.335 (perp=7.065, rec=0.242, cos=0.680), tot_loss_proj:3.249 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
[1500/2000] tot_loss=2.338 (perp=7.065, rec=0.238, cos=0.687), tot_loss_proj:3.249 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.342 (perp=7.065, rec=0.252, cos=0.678), tot_loss_proj:3.249 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.354 (perp=7.065, rec=0.255, cos=0.687), tot_loss_proj:3.252 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
[1650/2000] tot_loss=2.351 (perp=7.065, rec=0.252, cos=0.686), tot_loss_proj:3.253 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.331 (perp=7.065, rec=0.231, cos=0.687), tot_loss_proj:3.253 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.480 (perp=7.671, rec=0.254, cos=0.692), tot_loss_proj:3.335 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought indeed go grocery store because meet. [SEP]']
[1800/2000] tot_loss=2.204 (perp=6.306, rec=0.253, cos=0.689), tot_loss_proj:3.074 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought, go grocery store because meet. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.165 (perp=6.151, rec=0.243, cos=0.692), tot_loss_proj:3.035 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought, go grocery store meet because. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.167 (perp=6.151, rec=0.244, cos=0.692), tot_loss_proj:3.036 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought, go grocery store meet because. [SEP]']
[1950/2000] tot_loss=2.155 (perp=6.151, rec=0.236, cos=0.689), tot_loss_proj:3.032 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought, go grocery store meet because. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.154 (perp=6.151, rec=0.238, cos=0.686), tot_loss_proj:3.031 [t=0.30s]
prediction: ['[CLS] did not bill, as bill thought, go grocery store meet because. [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] i did not, as bill had thought, go to the store. [SEP]
========================
predicted: 
========================
[CLS] did not bill, as bill thought because indeed go grocery store meet. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 64.286 | r: 69.231
rouge2     | fm: 16.000 | p: 15.385 | r: 16.667
rougeL     | fm: 66.667 | p: 64.286 | r: 69.231
rougeLsum  | fm: 66.667 | p: 64.286 | r: 69.231
r1fm+r2fm = 82.667

[Aggregate metrics]:
rouge1     | fm: 76.602 | p: 76.791 | r: 76.715
rouge2     | fm: 33.666 | p: 33.694 | r: 33.894
rougeL     | fm: 67.413 | p: 67.554 | r: 67.404
rougeLsum  | fm: 67.292 | p: 67.518 | r: 67.252
r1fm+r2fm = 110.268

input #25 time: 0:11:50 | total time: 5:12:40


Running input #26 of 100.
reference: 
========================
Who will John ask for information about summer courses?
========================
average of cosine similarity 0.9989255441978968
highest_index [0]
highest [0.9989255441978968]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2040, 2097, 2198, 3198, 2005, 2592, 2055, 2621, 5352, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] who will john ask for information about summer courses? [SEP]']
[Init] best rec loss: 0.9475714564323425 for ['[CLS] certified bowedhorn ( lunch dedicated normally played stones nj [SEP]']
[Init] best rec loss: 0.9101312160491943 for ['[CLS] friends vacuum office memory physically fetch bark trialsject breuning [SEP]']
[Init] best rec loss: 0.8880713582038879 for ['[CLS] herself xx bat draft song questions pol horde coreoning [SEP]']
[Init] best rec loss: 0.8718292117118835 for ['[CLS] morgan ， marketingrcleamy credit x respective local rufus [SEP]']
[Init] best rec loss: 0.8620110154151917 for ['[CLS] wa fashionon ordinary size ou nice carrier carnegie blankets [SEP]']
[Init] best rec loss: 0.8565213680267334 for ['[CLS] gorgeelial levy strapped too asknologyity tech fellow [SEP]']
[Init] best rec loss: 0.8394192457199097 for ['[CLS] ladderwalker...tz update pearl cinder rangers suspected winter [SEP]']
[Init] best rec loss: 0.829050600528717 for ['[CLS] vc scheduling care gin places wider unfinished byees floyd [SEP]']
[Init] best perm rec loss: 0.8179570436477661 for ['[CLS] gin scheduling places care vc byees unfinished floyd wider [SEP]']
[Init] best perm rec loss: 0.811303436756134 for ['[CLS] unfinished vcees scheduling by gin floyd wider care places [SEP]']
[Init] best perm rec loss: 0.809987485408783 for ['[CLS] floyd scheduling byees unfinished vc gin wider care places [SEP]']
[Init] best perm rec loss: 0.8094638586044312 for ['[CLS] vc unfinished careees by wider scheduling floyd gin places [SEP]']
[Init] best perm rec loss: 0.8080628514289856 for ['[CLS] floyd care unfinishedees scheduling by gin places vc wider [SEP]']
[Init] best perm rec loss: 0.804179847240448 for ['[CLS] gin floyd scheduling by unfinishedees places vc care wider [SEP]']
[Init] best perm rec loss: 0.8039982914924622 for ['[CLS] gin vc floyd places by unfinished scheduling widerees care [SEP]']
[Init] best perm rec loss: 0.8033291697502136 for ['[CLS] floyd scheduling wider vc places by unfinishedees care gin [SEP]']
[Init] best perm rec loss: 0.8029600381851196 for ['[CLS] floyd places scheduling unfinished gin by wider careees vc [SEP]']
[Init] best perm rec loss: 0.801514744758606 for ['[CLS] floyd unfinished gin scheduling by care wider vcees places [SEP]']
[Init] best perm rec loss: 0.7990368008613586 for ['[CLS] floyd gin wider places byees scheduling care unfinished vc [SEP]']
[Init] best perm rec loss: 0.7985920310020447 for ['[CLS] floyd care vcees gin by unfinished wider places scheduling [SEP]']
[Init] best perm rec loss: 0.7961627840995789 for ['[CLS] floyd places gin unfinished by scheduling wider careees vc [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.146 (perp=11.685, rec=0.416, cos=0.393), tot_loss_proj:4.190 [t=0.29s]
prediction: ['[CLS] helped would mo gallery (0? who willmament [SEP]']
[ 100/2000] tot_loss=3.036 (perp=11.100, rec=0.332, cos=0.484), tot_loss_proj:3.980 [t=0.30s]
prediction: ['[CLS] could visiting how charlie discuss students? who referenceborg [SEP]']
[ 150/2000] tot_loss=2.680 (perp=9.363, rec=0.295, cos=0.512), tot_loss_proj:3.695 [t=0.30s]
prediction: ['[CLS] could what why will who summer? who reference stephenson [SEP]']
[ 200/2000] tot_loss=2.638 (perp=8.987, rec=0.327, cos=0.513), tot_loss_proj:3.686 [t=0.30s]
prediction: ['[CLS] could who ask patients what summer? who they thank [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.432 (perp=8.301, rec=0.279, cos=0.493), tot_loss_proj:3.554 [t=0.30s]
prediction: ['[CLS] would ask who hamlet of courses? will they directly [SEP]']
[ 300/2000] tot_loss=2.243 (perp=7.222, rec=0.241, cos=0.557), tot_loss_proj:3.344 [t=0.30s]
prediction: ['[CLS] to will who hamlet of courses? will they ask [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.599 (perp=8.911, rec=0.245, cos=0.572), tot_loss_proj:3.678 [t=0.30s]
prediction: ['[CLS] for will who john for courses ask? will they [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.764 (perp=9.855, rec=0.232, cos=0.562), tot_loss_proj:3.808 [t=0.30s]
prediction: ['[CLS] for will who john ask courses matters they ask? [SEP]']
[ 450/2000] tot_loss=2.789 (perp=9.855, rec=0.233, cos=0.586), tot_loss_proj:3.807 [t=0.30s]
prediction: ['[CLS] for will who john ask courses matters they ask? [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.655 (perp=9.412, rec=0.224, cos=0.549), tot_loss_proj:3.756 [t=0.30s]
prediction: ['[CLS] for will who john ask courses matters? they ask [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.581 (perp=9.024, rec=0.226, cos=0.549), tot_loss_proj:3.693 [t=0.30s]
prediction: ['[CLS] who will for john ask courses matters? they ask [SEP]']
[ 600/2000] tot_loss=2.584 (perp=9.024, rec=0.204, cos=0.575), tot_loss_proj:3.693 [t=0.30s]
prediction: ['[CLS] who will for john ask courses matters? they ask [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.385 (perp=8.056, rec=0.212, cos=0.562), tot_loss_proj:3.515 [t=0.30s]
prediction: ['[CLS] who will john ask for courses matters? they ask [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.267 (perp=7.492, rec=0.209, cos=0.560), tot_loss_proj:3.383 [t=0.30s]
prediction: ['[CLS] who will ask john for courses matters? they ask [SEP]']
[ 750/2000] tot_loss=2.278 (perp=7.492, rec=0.204, cos=0.575), tot_loss_proj:3.383 [t=0.30s]
prediction: ['[CLS] who will ask john for courses matters? they ask [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.236 (perp=7.329, rec=0.190, cos=0.580), tot_loss_proj:3.370 [t=0.30s]
prediction: ['[CLS] who will ask john for matters courses? they ask [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.237 (perp=7.329, rec=0.204, cos=0.568), tot_loss_proj:3.376 [t=0.30s]
prediction: ['[CLS] who will ask john for matters courses? they ask [SEP]']
[ 900/2000] tot_loss=2.236 (perp=7.329, rec=0.192, cos=0.578), tot_loss_proj:3.377 [t=0.30s]
prediction: ['[CLS] who will ask john for matters courses? they ask [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.237 (perp=7.329, rec=0.204, cos=0.567), tot_loss_proj:3.378 [t=0.30s]
prediction: ['[CLS] who will ask john for matters courses? they ask [SEP]']
Attempt swap
[1000/2000] tot_loss=2.146 (perp=6.891, rec=0.185, cos=0.582), tot_loss_proj:3.323 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
[1050/2000] tot_loss=2.151 (perp=6.891, rec=0.192, cos=0.581), tot_loss_proj:3.328 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1100/2000] tot_loss=2.142 (perp=6.891, rec=0.184, cos=0.580), tot_loss_proj:3.328 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1150/2000] tot_loss=2.146 (perp=6.891, rec=0.180, cos=0.587), tot_loss_proj:3.329 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
[1200/2000] tot_loss=2.153 (perp=6.891, rec=0.182, cos=0.592), tot_loss_proj:3.327 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1250/2000] tot_loss=2.153 (perp=6.891, rec=0.189, cos=0.586), tot_loss_proj:3.327 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1300/2000] tot_loss=2.151 (perp=6.891, rec=0.177, cos=0.596), tot_loss_proj:3.329 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
[1350/2000] tot_loss=2.157 (perp=6.891, rec=0.185, cos=0.593), tot_loss_proj:3.325 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1400/2000] tot_loss=2.157 (perp=6.891, rec=0.192, cos=0.587), tot_loss_proj:3.323 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1450/2000] tot_loss=2.140 (perp=6.891, rec=0.176, cos=0.586), tot_loss_proj:3.330 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
[1500/2000] tot_loss=2.151 (perp=6.891, rec=0.184, cos=0.589), tot_loss_proj:3.324 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1550/2000] tot_loss=2.150 (perp=6.891, rec=0.177, cos=0.594), tot_loss_proj:3.324 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1600/2000] tot_loss=2.149 (perp=6.891, rec=0.176, cos=0.595), tot_loss_proj:3.328 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
[1650/2000] tot_loss=2.148 (perp=6.891, rec=0.177, cos=0.592), tot_loss_proj:3.326 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1700/2000] tot_loss=2.149 (perp=6.891, rec=0.175, cos=0.596), tot_loss_proj:3.327 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1750/2000] tot_loss=2.149 (perp=6.891, rec=0.180, cos=0.591), tot_loss_proj:3.325 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
[1800/2000] tot_loss=2.155 (perp=6.891, rec=0.184, cos=0.593), tot_loss_proj:3.326 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1850/2000] tot_loss=2.144 (perp=6.891, rec=0.173, cos=0.593), tot_loss_proj:3.325 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[1900/2000] tot_loss=2.144 (perp=6.891, rec=0.173, cos=0.593), tot_loss_proj:3.329 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
[1950/2000] tot_loss=2.158 (perp=6.891, rec=0.187, cos=0.593), tot_loss_proj:3.326 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Attempt swap
[2000/2000] tot_loss=2.155 (perp=6.891, rec=0.182, cos=0.594), tot_loss_proj:3.325 [t=0.30s]
prediction: ['[CLS] who will ask john for questions courses? they ask [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] who will john ask for information about summer courses? [SEP]
========================
predicted: 
========================
[CLS] who will ask john for questions courses? they ask [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 72.727 | r: 72.727
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 92.727

[Aggregate metrics]:
rouge1     | fm: 76.557 | p: 76.699 | r: 76.637
rouge2     | fm: 33.030 | p: 33.061 | r: 33.286
rougeL     | fm: 67.381 | p: 67.540 | r: 67.530
rougeLsum  | fm: 67.208 | p: 67.334 | r: 67.218
r1fm+r2fm = 109.586

input #26 time: 0:11:50 | total time: 5:24:30


Running input #27 of 100.
reference: 
========================
Ron wanted to wear a tuxedo to the party, but Caspar couldn't decide whether to.
========================
average of cosine similarity 0.9988796511727704
highest_index [0]
highest [0.9988796511727704]
Debug: ids_shape = 24, pads = [24]
Debug: input ids = tensor([[  101,  6902,  2359,  2000,  4929,  1037, 10722, 19068,  2080,  2000,
          1996,  2283,  1010,  2021, 25222, 19362,  2481,  1005,  1056,  5630,
          3251,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]"]
[Init] best rec loss: 0.9497048258781433 for ['[CLS]ig operated already block sad pac further armenians songs, fund book waters line buy willis relief strike collaborative tack violet bring [SEP]']
[Init] best rec loss: 0.9404677152633667 for ['[CLS]yme cabinet slumped africa cm tried manyuce barack cryptrre hurt requiredstorm perception engine politician consumer maddy deep welshbo [SEP]']
[Init] best rec loss: 0.9387982487678528 for ['[CLS] including provided object seamaster tuck statingjust count console capable chance program mysoreida best press gateway accord urge majority full [SEP]']
[Init] best rec loss: 0.8792120218276978 for ['[CLS] tread granada trimmed bureau pitch forming but power gan season forgive fccmel ono ‖ fans false hadn parliament complement metacriticlino [SEP]']
[Init] best rec loss: 0.8788069486618042 for ['[CLS] whispered \\ 2009 each inc ama magnet geological freemian shrub coravot value skyware bite disk god cai six discussion [SEP]']
[Init] best rec loss: 0.8762320280075073 for ['[CLS] another peat than finals coastal late on counter fashion synonymous⁄₄ anneching wage darwin fact bothant far occasions rest theo [SEP]']
[Init] best rec loss: 0.8592273592948914 for ['[CLS]eving so ranging ceasefire jew alan involving ward missions thencuting res cap things popular entering is shrug amateur opt lynch soul [SEP]']
[Init] best perm rec loss: 0.8591733574867249 for ['[CLS] so cap soul lynch is thencuting alan involving ward opt missions ranging amateur res things popular entering ceasefire shrugeving jew [SEP]']
[Init] best perm rec loss: 0.8542192578315735 for ['[CLS] res involving opt things entering soul ceasefire iseving popular ward so shrug amateur missions then cap jewcuting ranging lynch alan [SEP]']
[Init] best perm rec loss: 0.8530499339103699 for ['[CLS] ward things iseving amateur so involving missions res popular ceasefire jew soul lynch shrug cap ranging then opt alan enteringcuting [SEP]']
[Init] best perm rec loss: 0.852468729019165 for ['[CLS] opt things lyncheving entering ceasefire involving amateur shrug is soul so missions popular cap ranging alan jew thencuting res ward [SEP]']
[Init] best perm rec loss: 0.8521161675453186 for ['[CLS] jew cap then opt ceasefireeving shrug involving popularcuting is things soul ward lynch alan ranging amateur res missions so entering [SEP]']
[Init] best perm rec loss: 0.8514472842216492 for ['[CLS]eving soul then shrug is ceasefire cap alan opt res lynch things popular so involving jewcuting ranging entering amateur missions ward [SEP]']
[Init] best perm rec loss: 0.850601851940155 for ['[CLS] opt cap missionseving enteringcuting involving so lynch soul popular is things ward shrug alan amateur jew then ranging ceasefire res [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.018 (perp=12.920, rec=0.528, cos=0.906), tot_loss_proj:4.480 [t=0.30s]
prediction: ['[CLS] winter out stella gold less let plaster car afar ratherfirm huey cock inill slightly around register eurosbo without her [SEP]']
[ 100/2000] tot_loss=3.983 (perp=13.772, rec=0.393, cos=0.835), tot_loss_proj:4.670 [t=0.30s]
prediction: ['[CLS] winter doubles ♣ glenco ron either racer perfectly ratherparco alex in cas - muddypar ronko without regardless [SEP]']
[ 150/2000] tot_loss=3.666 (perp=12.220, rec=0.364, cos=0.859), tot_loss_proj:4.370 [t=0.31s]
prediction: ['[CLS]. kawasaki ♣ ron, ron decides flex angelinakirpar ron plc in cas, withoutpar ron wanted whether if [SEP]']
[ 200/2000] tot_loss=3.540 (perp=12.155, rec=0.293, cos=0.816), tot_loss_proj:4.344 [t=0.31s]
prediction: ['[CLS]. kawasaki missionary ron follow ron decidespo wrong caspar ron plc in cas, withoutpar ron couldn whether whether [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.883 (perp=13.008, rec=0.456, cos=0.825), tot_loss_proj:4.509 [t=0.31s]
prediction: ['[CLS]. reductionlsterー lacey ron brandt lausanne everyone casparpired stu or cas to observatorypar ron couldn whether whether [SEP]']
[ 300/2000] tot_loss=3.783 (perp=13.392, rec=0.304, cos=0.801), tot_loss_proj:4.615 [t=0.31s]
prediction: ['[CLS]. chin headache mixed comment ron alpha app everyone casparposed rivercede cas on observatorypar ron couldn decided whether [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.523 (perp=12.110, rec=0.272, cos=0.829), tot_loss_proj:4.359 [t=0.31s]
prediction: ['[CLS]. wear river mixed say ron alpha app everyone casparposed headachecl cas on butpar ron couldn decide whether [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.569 (perp=12.531, rec=0.254, cos=0.809), tot_loss_proj:4.397 [t=0.31s]
prediction: ['[CLS]?pired signal e tattoo ron alpha app everyone caspar wearing startsflict disguise on butpar ron couldn decide whether [SEP]']
[ 450/2000] tot_loss=3.526 (perp=12.356, rec=0.224, cos=0.831), tot_loss_proj:4.383 [t=0.31s]
prediction: ['[CLS]?pired signal e monkeys ron examined app everyone caspar wearing backqu disguise to butpar ron couldn decide whether [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.486 (perp=12.125, rec=0.238, cos=0.824), tot_loss_proj:4.327 [t=0.31s]
prediction: ['[CLS]?piredre o monkeys ron doesn playing everyone caspar wearing ª )禾 to butpar ron couldn decide whether [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.584 (perp=12.557, rec=0.241, cos=0.831), tot_loss_proj:4.451 [t=0.31s]
prediction: ['[CLS] ellepiredre o monkeys everyone ron domain entering caspar wearing ªcl禾 on butpar ron couldn decide whether [SEP]']
[ 600/2000] tot_loss=3.644 (perp=12.831, rec=0.221, cos=0.857), tot_loss_proj:4.471 [t=0.31s]
prediction: ['[CLS] ellepiredre wanted tattoo everyone ron domain entering caspar wearing ªcl~ on butpar ron couldn decide whether [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.453 (perp=11.883, rec=0.220, cos=0.856), tot_loss_proj:4.297 [t=0.31s]
prediction: ['[CLS] ellepiredre wanted tattoo everyone ron domain entering caspar wearing ª,⁄₄ onpar but ron couldn decide whether [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.348 (perp=11.329, rec=0.217, cos=0.865), tot_loss_proj:4.182 [t=0.31s]
prediction: ['[CLS] ellepiredre wanted monkeys entering ron domain everyone caspar wearingurbed,⁄₄ onpar but ron couldn decide whether [SEP]']
[ 750/2000] tot_loss=3.358 (perp=11.329, rec=0.209, cos=0.884), tot_loss_proj:4.183 [t=0.31s]
prediction: ['[CLS] ellepiredre wanted monkeys entering ron domain everyone caspar wearingurbed,⁄₄ onpar but ron couldn decide whether [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.416 (perp=11.565, rec=0.215, cos=0.888), tot_loss_proj:4.218 [t=0.31s]
prediction: ['[CLS] elle galapired wanted monkeys entering ron domain everyone caspar wearingurbed,⁄₄ onpar but ron couldn decide whether [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.414 (perp=11.484, rec=0.218, cos=0.899), tot_loss_proj:4.205 [t=0.31s]
prediction: ['[CLS] elle galapired wanted monkeys entering would domain everyone caspar wearingurbed,ᶠ topar but ron couldn decide whether [SEP]']
[ 900/2000] tot_loss=3.436 (perp=11.598, rec=0.211, cos=0.905), tot_loss_proj:4.235 [t=0.31s]
prediction: ['[CLS] elle galapired wanted monkeys entering would domain everyone caspar wearingurbed,oll topar but ron couldn decide whether [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.343 (perp=11.189, rec=0.207, cos=0.898), tot_loss_proj:4.164 [t=0.31s]
prediction: ['[CLS] elle galaduced wanted monkeys entering ron domain everyone casparollurbed, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.281 (perp=10.913, rec=0.221, cos=0.878), tot_loss_proj:4.085 [t=0.31s]
prediction: ['[CLS] galalized elle wanted monkeys entering ron domain everyone casparollurbed, wearing topar but ron couldn decide whether [SEP]']
[1050/2000] tot_loss=3.493 (perp=11.860, rec=0.218, cos=0.903), tot_loss_proj:4.271 [t=0.31s]
prediction: ['[CLS] galalized elle wanted monkeys playing will domain everyone cas criticallyollurbed, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=3.415 (perp=11.542, rec=0.218, cos=0.888), tot_loss_proj:4.235 [t=0.31s]
prediction: ['[CLS] galalized elle wanted monkeys playingpar ron domain everyone casollurbed, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.379 (perp=11.376, rec=0.213, cos=0.891), tot_loss_proj:4.190 [t=0.31s]
prediction: ['[CLS] galalized elle wanted monkeys topar ron domain - casollurbed, wearing playingpar but ron couldn decide whether [SEP]']
[1200/2000] tot_loss=3.352 (perp=11.244, rec=0.209, cos=0.894), tot_loss_proj:4.128 [t=0.31s]
prediction: ['[CLS] galalized elle wanted monkeys to critically ron domain everyone casollurbed, wearing playingpar but ron couldn decide whether [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=3.259 (perp=10.751, rec=0.214, cos=0.894), tot_loss_proj:4.034 [t=0.31s]
prediction: ['[CLS] galalized elle wanted ron monkeys to initially domain - casollurbed, wearing playingpar but ron couldn decide whether [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=3.190 (perp=10.428, rec=0.205, cos=0.900), tot_loss_proj:3.967 [t=0.31s]
prediction: ['[CLS] galalized elle wanted ron monkeys playing initially domain - casollurbed, wearing topar but ron couldn decide whether [SEP]']
[1350/2000] tot_loss=3.194 (perp=10.428, rec=0.204, cos=0.905), tot_loss_proj:3.963 [t=0.31s]
prediction: ['[CLS] galalized elle wanted ron monkeys playing initially domain - casollurbed, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
[1400/2000] tot_loss=3.298 (perp=10.937, rec=0.204, cos=0.907), tot_loss_proj:4.077 [t=0.31s]
prediction: ['[CLS] galalized elle wanted ron monkeys playing critically domain - casollurbed, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=3.270 (perp=10.799, rec=0.203, cos=0.907), tot_loss_proj:4.064 [t=0.31s]
prediction: ['[CLS]lized gala elle wanted ron monkeys playing critically domain - casollurbed, wearing topar but ron couldn decide whether [SEP]']
[1500/2000] tot_loss=3.286 (perp=10.802, rec=0.216, cos=0.909), tot_loss_proj:4.075 [t=0.31s]
prediction: ['[CLS]duced gala elle wanted ron monkeys playing critically domain - casoll⁺, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
[1550/2000] tot_loss=3.279 (perp=10.802, rec=0.207, cos=0.912), tot_loss_proj:4.074 [t=0.31s]
prediction: ['[CLS]duced gala elle wanted ron monkeys playing critically domain - casoll⁺, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
[1600/2000] tot_loss=3.276 (perp=10.802, rec=0.204, cos=0.911), tot_loss_proj:4.079 [t=0.31s]
prediction: ['[CLS]duced gala elle wanted ron monkeys playing critically domain - casoll⁺, wearing topar but ron couldn decide whether [SEP]']
[1650/2000] tot_loss=3.274 (perp=10.802, rec=0.202, cos=0.912), tot_loss_proj:4.078 [t=0.31s]
prediction: ['[CLS]duced gala elle wanted ron monkeys playing critically domain - casoll⁺, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=3.267 (perp=10.759, rec=0.203, cos=0.912), tot_loss_proj:4.076 [t=0.31s]
prediction: ['[CLS]duced gala elle wanted ron monkeys playing critically - domain casoll⁺, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
[1750/2000] tot_loss=3.272 (perp=10.759, rec=0.208, cos=0.912), tot_loss_proj:4.076 [t=0.31s]
prediction: ['[CLS]duced gala elle wanted ron monkeys playing critically - domain casoll⁺, wearing topar but ron couldn decide whether [SEP]']
[1800/2000] tot_loss=3.276 (perp=10.759, rec=0.210, cos=0.914), tot_loss_proj:4.077 [t=0.31s]
prediction: ['[CLS]duced gala elle wanted ron monkeys playing critically - domain casoll⁺, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=3.254 (perp=10.707, rec=0.199, cos=0.914), tot_loss_proj:4.026 [t=0.31s]
prediction: ['[CLS] galaduced elle wanted ron monkeys playing critically - domain casoll⁺, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
[1900/2000] tot_loss=3.260 (perp=10.707, rec=0.203, cos=0.916), tot_loss_proj:4.027 [t=0.31s]
prediction: ['[CLS] galaduced elle wanted ron monkeys playing critically - domain casoll⁺, wearing topar but ron couldn decide whether [SEP]']
[1950/2000] tot_loss=3.258 (perp=10.707, rec=0.202, cos=0.915), tot_loss_proj:4.028 [t=0.31s]
prediction: ['[CLS] galaduced elle wanted ron monkeys playing critically - domain casoll⁺, wearing topar but ron couldn decide whether [SEP]']
Attempt swap
[2000/2000] tot_loss=3.270 (perp=10.707, rec=0.212, cos=0.916), tot_loss_proj:4.027 [t=0.31s]
prediction: ['[CLS] galaduced elle wanted ron monkeys playing critically - domain casoll⁺, wearing topar but ron couldn decide whether [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]
========================
predicted: 
========================
[CLS]duced gala elle wanted ron monkeys playing critically - domain casoll⁺, wearing topar but ron couldn decide whether [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 43.243 | p: 42.105 | r: 44.444
rouge2     | fm: 5.714 | p: 5.556 | r: 5.882
rougeL     | fm: 37.838 | p: 36.842 | r: 38.889
rougeLsum  | fm: 37.838 | p: 36.842 | r: 38.889
r1fm+r2fm = 48.958

[Aggregate metrics]:
rouge1     | fm: 75.323 | p: 75.330 | r: 75.468
rouge2     | fm: 32.008 | p: 32.055 | r: 32.180
rougeL     | fm: 66.272 | p: 66.463 | r: 66.398
rougeLsum  | fm: 66.112 | p: 66.294 | r: 66.171
r1fm+r2fm = 107.330

input #27 time: 0:12:11 | total time: 5:36:42


Running input #28 of 100.
reference: 
========================
Bill gave Sue the book.
========================
average of cosine similarity 0.9989844686103759
highest_index [0]
highest [0.9989844686103759]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 3021, 2435, 9790, 1996, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bill gave sue the book. [SEP]']
[Init] best rec loss: 0.9021162390708923 for ['[CLS] tang links ponder _ borntist [SEP]']
[Init] best rec loss: 0.8914576768875122 for ['[CLS] save lee agencyate longer remnants [SEP]']
[Init] best rec loss: 0.8892251253128052 for ['[CLS] starred sewer dispatchele but begged [SEP]']
[Init] best rec loss: 0.8877506852149963 for ['[CLS] ren careful inclusive fitting german men [SEP]']
[Init] best rec loss: 0.8849062323570251 for ['[CLS] smoke slack sen falls languages ana [SEP]']
[Init] best rec loss: 0.8797871470451355 for ['[CLS] stephenser ar tampa reported s [SEP]']
[Init] best rec loss: 0.8715612888336182 for ['[CLS] question siwar cbs different cher [SEP]']
[Init] best rec loss: 0.8475141525268555 for ['[CLS] anniversary deposit ethan baroque barnet recently [SEP]']
[Init] best rec loss: 0.84523606300354 for ['[CLS] worldwide modern level due remembered assembly [SEP]']
[Init] best rec loss: 0.8438364863395691 for ['[CLS] cinnamon entirely hectoresthesia change manner [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.176 (perp=9.935, rec=0.468, cos=0.721), tot_loss_proj:3.914 [t=0.30s]
prediction: ['[CLS] sue sue commissioner sue stadium! [SEP]']
[ 100/2000] tot_loss=3.500 (perp=11.391, rec=0.440, cos=0.782), tot_loss_proj:4.061 [t=0.30s]
prediction: ['[CLS] insurance sue isbn sue book! [SEP]']
[ 150/2000] tot_loss=3.171 (perp=9.946, rec=0.428, cos=0.754), tot_loss_proj:3.707 [t=0.30s]
prediction: ['[CLS]dating bill gave sue book. [SEP]']
[ 200/2000] tot_loss=3.494 (perp=12.635, rec=0.350, cos=0.618), tot_loss_proj:4.365 [t=0.30s]
prediction: ['[CLS] citizens bill gave sue book cedar [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.021 (perp=9.850, rec=0.385, cos=0.666), tot_loss_proj:3.710 [t=0.30s]
prediction: ['[CLS] bill prop gave sue book. [SEP]']
[ 300/2000] tot_loss=2.837 (perp=9.850, rec=0.264, cos=0.603), tot_loss_proj:3.708 [t=0.30s]
prediction: ['[CLS] bill prop gave sue book. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.902 (perp=9.673, rec=0.335, cos=0.633), tot_loss_proj:3.815 [t=0.30s]
prediction: ['[CLS] bill gave sue book founders. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.727 (perp=9.207, rec=0.270, cos=0.616), tot_loss_proj:3.544 [t=0.30s]
prediction: ['[CLS] billrift gave sue book. [SEP]']
[ 450/2000] tot_loss=2.707 (perp=9.207, rec=0.238, cos=0.627), tot_loss_proj:3.534 [t=0.30s]
prediction: ['[CLS] billrift gave sue book. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.717 (perp=9.207, rec=0.230, cos=0.645), tot_loss_proj:3.535 [t=0.30s]
prediction: ['[CLS] billrift gave sue book. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.745 (perp=9.207, rec=0.243, cos=0.661), tot_loss_proj:3.535 [t=0.30s]
prediction: ['[CLS] billrift gave sue book. [SEP]']
[ 600/2000] tot_loss=2.705 (perp=9.291, rec=0.215, cos=0.632), tot_loss_proj:3.544 [t=0.30s]
prediction: ['[CLS] bill backs gave sue book. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.700 (perp=9.291, rec=0.238, cos=0.603), tot_loss_proj:3.538 [t=0.30s]
prediction: ['[CLS] bill backs gave sue book. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.746 (perp=9.469, rec=0.219, cos=0.633), tot_loss_proj:3.768 [t=0.30s]
prediction: ['[CLS] bill gave sue book backs. [SEP]']
[ 750/2000] tot_loss=2.740 (perp=9.469, rec=0.213, cos=0.633), tot_loss_proj:3.771 [t=0.30s]
prediction: ['[CLS] bill gave sue book backs. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.737 (perp=9.469, rec=0.215, cos=0.628), tot_loss_proj:3.761 [t=0.30s]
prediction: ['[CLS] bill gave sue book backs. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.720 (perp=9.469, rec=0.204, cos=0.622), tot_loss_proj:3.770 [t=0.30s]
prediction: ['[CLS] bill gave sue book backs. [SEP]']
[ 900/2000] tot_loss=2.712 (perp=9.469, rec=0.205, cos=0.614), tot_loss_proj:3.776 [t=0.30s]
prediction: ['[CLS] bill gave sue book backs. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.739 (perp=9.469, rec=0.204, cos=0.640), tot_loss_proj:3.772 [t=0.30s]
prediction: ['[CLS] bill gave sue book backs. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.737 (perp=9.469, rec=0.217, cos=0.626), tot_loss_proj:3.775 [t=0.30s]
prediction: ['[CLS] bill gave sue book backs. [SEP]']
[1050/2000] tot_loss=2.721 (perp=9.469, rec=0.204, cos=0.623), tot_loss_proj:3.770 [t=0.30s]
prediction: ['[CLS] bill gave sue book backs. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.718 (perp=9.469, rec=0.200, cos=0.624), tot_loss_proj:3.764 [t=0.30s]
prediction: ['[CLS] bill gave sue book backs. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.719 (perp=9.469, rec=0.204, cos=0.620), tot_loss_proj:3.772 [t=0.30s]
prediction: ['[CLS] bill gave sue book backs. [SEP]']
[1200/2000] tot_loss=2.712 (perp=9.377, rec=0.205, cos=0.632), tot_loss_proj:3.477 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.728 (perp=9.377, rec=0.224, cos=0.629), tot_loss_proj:3.472 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.708 (perp=9.377, rec=0.201, cos=0.632), tot_loss_proj:3.482 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
[1350/2000] tot_loss=2.699 (perp=9.377, rec=0.197, cos=0.626), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.714 (perp=9.377, rec=0.207, cos=0.632), tot_loss_proj:3.470 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.712 (perp=9.377, rec=0.205, cos=0.632), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
[1500/2000] tot_loss=2.699 (perp=9.377, rec=0.198, cos=0.625), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.715 (perp=9.377, rec=0.212, cos=0.628), tot_loss_proj:3.482 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.711 (perp=9.377, rec=0.204, cos=0.632), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
[1650/2000] tot_loss=2.701 (perp=9.377, rec=0.194, cos=0.632), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.710 (perp=9.377, rec=0.201, cos=0.634), tot_loss_proj:3.473 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.713 (perp=9.377, rec=0.208, cos=0.629), tot_loss_proj:3.481 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
[1800/2000] tot_loss=2.701 (perp=9.377, rec=0.194, cos=0.631), tot_loss_proj:3.480 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.709 (perp=9.377, rec=0.203, cos=0.630), tot_loss_proj:3.473 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.705 (perp=9.377, rec=0.197, cos=0.633), tot_loss_proj:3.475 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
[1950/2000] tot_loss=2.717 (perp=9.377, rec=0.209, cos=0.633), tot_loss_proj:3.474 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.708 (perp=9.377, rec=0.202, cos=0.631), tot_loss_proj:3.476 [t=0.30s]
prediction: ['[CLS] bill gave sue book trades. [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] bill gave sue the book. [SEP]
========================
predicted: 
========================
[CLS] bill gave sue book trades. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 135.714

[Aggregate metrics]:
rouge1     | fm: 75.677 | p: 75.756 | r: 75.770
rouge2     | fm: 32.779 | p: 32.747 | r: 32.978
rougeL     | fm: 66.914 | p: 67.075 | r: 67.050
rougeLsum  | fm: 66.899 | p: 67.018 | r: 67.052
r1fm+r2fm = 108.456

input #28 time: 0:11:49 | total time: 5:48:31


Running input #29 of 100.
reference: 
========================
The bread was chewed by Martha.
========================
average of cosine similarity 0.9990930599626274
highest_index [0]
highest [0.9990930599626274]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996,  7852,  2001, 18362,  2011,  9246,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the bread was chewed by martha. [SEP]']
[Init] best rec loss: 0.9765051007270813 for ['[CLS] squeezed pace bonnie know plantsoic bishop [SEP]']
[Init] best rec loss: 0.9212539196014404 for ['[CLS] party morrison #ramet animated fluent [SEP]']
[Init] best rec loss: 0.8975686430931091 for ['[CLS] chewed attack turing science sport tontist [SEP]']
[Init] best rec loss: 0.8969440460205078 for ['[CLS] rose worth cowboys aresror affair links [SEP]']
[Init] best rec loss: 0.8935942649841309 for ['[CLS] forggernaire base tastesling wanted [SEP]']
[Init] best rec loss: 0.8931593298912048 for ['[CLS] attached haven currently media terryelles dream [SEP]']
[Init] best rec loss: 0.88563072681427 for ['[CLS] designated practices katyurance rendered couldn dressing [SEP]']
[Init] best rec loss: 0.8664394021034241 for ['[CLS] hollywood you yokohama like sitedies joyah [SEP]']
[Init] best rec loss: 0.8631607890129089 for ['[CLS] guardian blocked printed, entry important household [SEP]']
[Init] best perm rec loss: 0.861335813999176 for ['[CLS] guardian important printed entry, blocked household [SEP]']
[Init] best perm rec loss: 0.8598712086677551 for ['[CLS] important, blocked household guardian entry printed [SEP]']
[Init] best perm rec loss: 0.8583608269691467 for ['[CLS] important, household guardian entry printed blocked [SEP]']
[Init] best perm rec loss: 0.857600748538971 for ['[CLS] blocked entry household guardian important, printed [SEP]']
[Init] best perm rec loss: 0.8573999404907227 for ['[CLS] household guardian important, entry blocked printed [SEP]']
[Init] best perm rec loss: 0.8571080565452576 for ['[CLS] entry important household, guardian printed blocked [SEP]']
[Init] best perm rec loss: 0.8565800189971924 for ['[CLS] printed household important entry, guardian blocked [SEP]']
[Init] best perm rec loss: 0.8560645580291748 for ['[CLS] guardian important printed, household entry blocked [SEP]']
[Init] best perm rec loss: 0.855757474899292 for ['[CLS] important household printed, entry guardian blocked [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.345 (perp=13.885, rec=0.671, cos=0.897), tot_loss_proj:4.481 [t=0.29s]
prediction: ['[CLS] intelrogated corporate a invited breakfast each [SEP]']
[ 100/2000] tot_loss=3.696 (perp=11.318, rec=0.569, cos=0.863), tot_loss_proj:4.013 [t=0.30s]
prediction: ['[CLS] chewed eggs police a seamus grandpa each [SEP]']
[ 150/2000] tot_loss=3.243 (perp=9.921, rec=0.468, cos=0.791), tot_loss_proj:3.823 [t=0.30s]
prediction: ['[CLS] chewed eggs chewed. breadurance gallons [SEP]']
[ 200/2000] tot_loss=3.604 (perp=11.438, rec=0.476, cos=0.841), tot_loss_proj:4.016 [t=0.30s]
prediction: ['[CLS] chewed applies chewed. breadurance gallons [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.566 (perp=11.378, rec=0.440, cos=0.851), tot_loss_proj:4.144 [t=0.30s]
prediction: ['[CLS]urance applies chewed ( bread chewed gallons [SEP]']
[ 300/2000] tot_loss=3.383 (perp=10.857, rec=0.395, cos=0.817), tot_loss_proj:3.872 [t=0.30s]
prediction: ['[CLS]urance applies chewed. bread chewed gallons [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.554 (perp=11.616, rec=0.364, cos=0.867), tot_loss_proj:4.061 [t=0.30s]
prediction: ['[CLS]urancewoman chewed. bread gallons chewed [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.944 (perp=12.995, rec=0.412, cos=0.933), tot_loss_proj:4.542 [t=0.30s]
prediction: ['[CLS]urancewoman chewed dough bread marianne chewed [SEP]']
[ 450/2000] tot_loss=3.951 (perp=12.967, rec=0.412, cos=0.946), tot_loss_proj:4.300 [t=0.30s]
prediction: ['[CLS]urancewoman was dough bread arriving chewed [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.643 (perp=12.465, rec=0.320, cos=0.831), tot_loss_proj:4.374 [t=0.30s]
prediction: ['[CLS]urance! conducted bread rebecca chewed aback [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.519 (perp=11.704, rec=0.326, cos=0.852), tot_loss_proj:4.173 [t=0.30s]
prediction: ['[CLS] breadurance! quaker － chewed aback [SEP]']
[ 600/2000] tot_loss=3.812 (perp=13.477, rec=0.294, cos=0.822), tot_loss_proj:4.425 [t=0.30s]
prediction: ['[CLS] breadurancewoman conducted － chewed aback [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.478 (perp=11.807, rec=0.301, cos=0.816), tot_loss_proj:4.093 [t=0.30s]
prediction: ['[CLS]urance breadwoman was － chewed aback [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.448 (perp=11.652, rec=0.304, cos=0.814), tot_loss_proj:4.066 [t=0.30s]
prediction: ['[CLS]rmed breadwoman was － chewed aback [SEP]']
[ 750/2000] tot_loss=3.527 (perp=11.923, rec=0.299, cos=0.844), tot_loss_proj:4.143 [t=0.30s]
prediction: ['[CLS]rmed breadwoman was － chewedicides [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.519 (perp=11.923, rec=0.283, cos=0.851), tot_loss_proj:4.142 [t=0.30s]
prediction: ['[CLS]rmed breadwoman was － chewedicides [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.497 (perp=11.923, rec=0.269, cos=0.843), tot_loss_proj:4.145 [t=0.30s]
prediction: ['[CLS]rmed breadwoman was － chewedicides [SEP]']
[ 900/2000] tot_loss=3.489 (perp=11.923, rec=0.274, cos=0.830), tot_loss_proj:4.142 [t=0.30s]
prediction: ['[CLS]rmed breadwoman was － chewedicides [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.551 (perp=12.215, rec=0.275, cos=0.833), tot_loss_proj:4.205 [t=0.30s]
prediction: ['[CLS]rmed breadwoman wasgingly chewedicides [SEP]']
Attempt swap
[1000/2000] tot_loss=3.559 (perp=12.215, rec=0.272, cos=0.845), tot_loss_proj:4.203 [t=0.30s]
prediction: ['[CLS]rmed breadwoman wasgingly chewedicides [SEP]']
[1050/2000] tot_loss=3.621 (perp=12.594, rec=0.263, cos=0.839), tot_loss_proj:4.435 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1100/2000] tot_loss=3.620 (perp=12.594, rec=0.270, cos=0.831), tot_loss_proj:4.437 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1150/2000] tot_loss=3.631 (perp=12.594, rec=0.264, cos=0.848), tot_loss_proj:4.430 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
[1200/2000] tot_loss=3.624 (perp=12.594, rec=0.261, cos=0.844), tot_loss_proj:4.429 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1250/2000] tot_loss=3.610 (perp=12.594, rec=0.255, cos=0.836), tot_loss_proj:4.431 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1300/2000] tot_loss=3.611 (perp=12.594, rec=0.258, cos=0.834), tot_loss_proj:4.435 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
[1350/2000] tot_loss=3.615 (perp=12.594, rec=0.261, cos=0.835), tot_loss_proj:4.432 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1400/2000] tot_loss=3.625 (perp=12.594, rec=0.270, cos=0.836), tot_loss_proj:4.431 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1450/2000] tot_loss=3.608 (perp=12.594, rec=0.251, cos=0.838), tot_loss_proj:4.435 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
[1500/2000] tot_loss=3.620 (perp=12.594, rec=0.266, cos=0.836), tot_loss_proj:4.434 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1550/2000] tot_loss=3.606 (perp=12.594, rec=0.248, cos=0.839), tot_loss_proj:4.433 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1600/2000] tot_loss=3.612 (perp=12.594, rec=0.257, cos=0.837), tot_loss_proj:4.436 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
[1650/2000] tot_loss=3.615 (perp=12.594, rec=0.259, cos=0.837), tot_loss_proj:4.433 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1700/2000] tot_loss=3.601 (perp=12.594, rec=0.246, cos=0.836), tot_loss_proj:4.436 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1750/2000] tot_loss=3.609 (perp=12.594, rec=0.254, cos=0.837), tot_loss_proj:4.429 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
[1800/2000] tot_loss=3.616 (perp=12.594, rec=0.260, cos=0.838), tot_loss_proj:4.437 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1850/2000] tot_loss=3.605 (perp=12.594, rec=0.250, cos=0.835), tot_loss_proj:4.436 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[1900/2000] tot_loss=3.604 (perp=12.594, rec=0.249, cos=0.837), tot_loss_proj:4.430 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
[1950/2000] tot_loss=3.604 (perp=12.594, rec=0.246, cos=0.838), tot_loss_proj:4.435 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Attempt swap
[2000/2000] tot_loss=3.610 (perp=12.594, rec=0.254, cos=0.837), tot_loss_proj:4.436 [t=0.30s]
prediction: ['[CLS]rmed bread martha wasgingly chewedicides [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] the bread was chewed by martha. [SEP]
========================
predicted: 
========================
[CLS]rmed bread martha wasgingly chewedicides [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.333 | p: 57.143 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 53.333 | p: 57.143 | r: 50.000
rougeLsum  | fm: 53.333 | p: 57.143 | r: 50.000
r1fm+r2fm = 53.333

[Aggregate metrics]:
rouge1     | fm: 74.946 | p: 75.235 | r: 74.927
rouge2     | fm: 31.539 | p: 31.646 | r: 31.745
rougeL     | fm: 66.277 | p: 66.469 | r: 66.321
rougeLsum  | fm: 66.281 | p: 66.579 | r: 66.292
r1fm+r2fm = 106.485

input #29 time: 0:11:51 | total time: 6:00:22


Running input #30 of 100.
reference: 
========================
Read Fred's story, I also want to.
========================
average of cosine similarity 0.9989136044604198
highest_index [0]
highest [0.9989136044604198]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 3191, 5965, 1005, 1055, 2466, 1010, 1045, 2036, 2215, 2000, 1012,
          102]], device='cuda:0')
Debug: ref = ["[CLS] read fred's story, i also want to. [SEP]"]
[Init] best rec loss: 0.8123229742050171 for ['[CLS] design tourea chargessionkan voicesitatingrak freedom mild [SEP]']
[Init] best rec loss: 0.7988855838775635 for ['[CLS] conference waiting divided twin sweat ponye criminal universe family window [SEP]']
[Init] best perm rec loss: 0.7930079698562622 for ['[CLS] windowe waiting divided universe family twin conference criminal pony sweat [SEP]']
[Init] best perm rec loss: 0.7924050688743591 for ['[CLS] universe criminal conference divided sweat pony waitinge window family twin [SEP]']
[Init] best perm rec loss: 0.7908965349197388 for ['[CLS] waitinge twin criminal divided window pony conference family universe sweat [SEP]']
[Init] best perm rec loss: 0.7906813025474548 for ['[CLS] window conference waiting universee criminal divided pony twin sweat family [SEP]']
[Init] best perm rec loss: 0.7886890172958374 for ['[CLS] waiting conference criminal universe divided twin pony family window sweate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.165 (perp=13.625, rec=0.557, cos=0.883), tot_loss_proj:4.493 [t=0.29s]
prediction: ['[CLS] xbox read read weather story also characters glen spelled £10 product [SEP]']
[ 100/2000] tot_loss=3.832 (perp=13.078, rec=0.465, cos=0.751), tot_loss_proj:4.406 [t=0.30s]
prediction: ['[CLS] quiz read read irish read twitter team amos dee months product [SEP]']
[ 150/2000] tot_loss=3.743 (perp=12.287, rec=0.432, cos=0.854), tot_loss_proj:4.279 [t=0.30s]
prediction: ['[CLS] read read readzio readerson story fuse nascar k, [SEP]']
[ 200/2000] tot_loss=3.477 (perp=11.759, rec=0.363, cos=0.762), tot_loss_proj:4.133 [t=0.30s]
prediction: ['[CLS] read read read fred storyislaus wearudence wan k, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.558 (perp=12.039, rec=0.416, cos=0.735), tot_loss_proj:4.241 [t=0.30s]
prediction: ['[CLS] readudence read goblin story 2nd iain readha sweaterau [SEP]']
[ 300/2000] tot_loss=3.341 (perp=11.512, rec=0.321, cos=0.717), tot_loss_proj:4.085 [t=0.30s]
prediction: ['[CLS] read reminds read goblin storyurai. readbe incentive story [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.336 (perp=11.516, rec=0.293, cos=0.740), tot_loss_proj:4.005 [t=0.30s]
prediction: ['[CLS] read because, fred story. readervedha tired story [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.093 (perp=10.392, rec=0.268, cos=0.747), tot_loss_proj:3.840 [t=0.30s]
prediction: ['[CLS] readerved, fred story, read becauseha wishes to [SEP]']
[ 450/2000] tot_loss=3.139 (perp=10.490, rec=0.249, cos=0.792), tot_loss_proj:3.898 [t=0.30s]
prediction: ['[CLS] readislaus, fred story, read becauseha want to [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.074 (perp=10.413, rec=0.236, cos=0.755), tot_loss_proj:3.832 [t=0.30s]
prediction: ['[CLS] wantislaus, fred story, because readha want to [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.949 (perp=9.730, rec=0.235, cos=0.768), tot_loss_proj:3.760 [t=0.30s]
prediction: ['[CLS] wantislaus read fred story, because,ha want to [SEP]']
[ 600/2000] tot_loss=3.011 (perp=10.008, rec=0.232, cos=0.777), tot_loss_proj:3.763 [t=0.30s]
prediction: ['[CLS] wanturai read fred story also because, they want to [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.065 (perp=10.569, rec=0.203, cos=0.749), tot_loss_proj:3.820 [t=0.30s]
prediction: ['[CLS] want powerful because fred story also read,some want to [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.819 (perp=9.426, rec=0.201, cos=0.733), tot_loss_proj:3.721 [t=0.30s]
prediction: ['[CLS] because his want fred story also read, liam want to [SEP]']
[ 750/2000] tot_loss=2.768 (perp=9.235, rec=0.188, cos=0.733), tot_loss_proj:3.659 [t=0.30s]
prediction: ['[CLS] because his i fred story also read, liam want to [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.823 (perp=9.427, rec=0.188, cos=0.750), tot_loss_proj:3.695 [t=0.30s]
prediction: ['[CLS] because his i fred story also read, wantsome to [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.689 (perp=8.786, rec=0.191, cos=0.741), tot_loss_proj:3.558 [t=0.30s]
prediction: ['[CLS] because his i fred story also read, want to將 [SEP]']
[ 900/2000] tot_loss=2.680 (perp=8.786, rec=0.179, cos=0.744), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS] because his i fred story also read, want to將 [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.964 (perp=10.243, rec=0.179, cos=0.736), tot_loss_proj:3.787 [t=0.30s]
prediction: ['[CLS] i because ended fred story also read, want to將 [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.749 (perp=9.185, rec=0.165, cos=0.747), tot_loss_proj:3.551 [t=0.30s]
prediction: ['[CLS] i its because fred story also read, want to將 [SEP]']
[1050/2000] tot_loss=2.758 (perp=9.185, rec=0.178, cos=0.744), tot_loss_proj:3.551 [t=0.30s]
prediction: ['[CLS] i its because fred story also read, want to將 [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.723 (perp=9.055, rec=0.171, cos=0.741), tot_loss_proj:3.559 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[1150/2000] tot_loss=2.724 (perp=9.055, rec=0.170, cos=0.743), tot_loss_proj:3.560 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
[1200/2000] tot_loss=2.722 (perp=9.055, rec=0.170, cos=0.741), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[1250/2000] tot_loss=2.730 (perp=9.055, rec=0.174, cos=0.745), tot_loss_proj:3.559 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[1300/2000] tot_loss=2.735 (perp=9.055, rec=0.181, cos=0.743), tot_loss_proj:3.559 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
[1350/2000] tot_loss=2.724 (perp=9.055, rec=0.166, cos=0.748), tot_loss_proj:3.561 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[1400/2000] tot_loss=2.725 (perp=9.055, rec=0.168, cos=0.746), tot_loss_proj:3.560 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[1450/2000] tot_loss=2.723 (perp=9.055, rec=0.169, cos=0.743), tot_loss_proj:3.559 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
[1500/2000] tot_loss=2.727 (perp=9.055, rec=0.172, cos=0.743), tot_loss_proj:3.560 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[1550/2000] tot_loss=2.733 (perp=9.055, rec=0.173, cos=0.749), tot_loss_proj:3.562 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[1600/2000] tot_loss=2.729 (perp=9.055, rec=0.168, cos=0.750), tot_loss_proj:3.560 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
[1650/2000] tot_loss=2.722 (perp=9.055, rec=0.163, cos=0.749), tot_loss_proj:3.559 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[1700/2000] tot_loss=2.727 (perp=9.055, rec=0.169, cos=0.747), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[1750/2000] tot_loss=2.728 (perp=9.055, rec=0.166, cos=0.751), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
[1800/2000] tot_loss=2.727 (perp=9.055, rec=0.167, cos=0.749), tot_loss_proj:3.561 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[1850/2000] tot_loss=2.722 (perp=9.055, rec=0.163, cos=0.748), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[1900/2000] tot_loss=2.721 (perp=9.055, rec=0.160, cos=0.750), tot_loss_proj:3.556 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
[1950/2000] tot_loss=2.725 (perp=9.055, rec=0.165, cos=0.749), tot_loss_proj:3.559 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Attempt swap
[2000/2000] tot_loss=2.726 (perp=9.055, rec=0.166, cos=0.749), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS] i because its fred story also read, want to將 [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] read fred's story, i also want to. [SEP]
========================
predicted: 
========================
[CLS] i because its fred story also read, want to將 [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 21.053 | p: 20.000 | r: 22.222
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 106.767

[Aggregate metrics]:
rouge1     | fm: 75.220 | p: 75.295 | r: 75.448
rouge2     | fm: 31.370 | p: 31.371 | r: 31.511
rougeL     | fm: 66.404 | p: 66.540 | r: 66.645
rougeLsum  | fm: 66.405 | p: 66.537 | r: 66.518
r1fm+r2fm = 106.590

input #30 time: 0:11:50 | total time: 6:12:13


Running input #31 of 100.
reference: 
========================
Some of the water from melted snow also goes into the ground for plants.
========================
average of cosine similarity 0.9988080942524196
highest_index [0]
highest [0.9988080942524196]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2070,  1997,  1996,  2300,  2013, 12501,  4586,  2036,  3632,
          2046,  1996,  2598,  2005,  4264,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]']
[Init] best rec loss: 0.9406253695487976 for ["[CLS] girlfriend set faculty clay angeles boom cross bandonus sh 'tical mistake inn ballard [SEP]"]
[Init] best rec loss: 0.930097758769989 for ['[CLS] ace brady declared temples eight simply { doi clapped content unit foot npr chargedtro [SEP]']
[Init] best rec loss: 0.928633451461792 for ['[CLS] spaceship mercy loanbil spoken continued gun quentin merit closed abrl asked chemistry states [SEP]']
[Init] best rec loss: 0.8577554225921631 for ['[CLS]plane turret pretty together wire or rip due pl eventual meetsavi whitney relief hillary [SEP]']
[Init] best rec loss: 0.8481730222702026 for ['[CLS] tests police active minds wickets contact didn who latin traction assistance mineral alsoved by [SEP]']
[Init] best rec loss: 0.8318527936935425 for ['[CLS] fish sterling arnold such add doctorate period ten hint rough decadeset shall reward even [SEP]']
[Init] best rec loss: 0.8286123275756836 for ['[CLS] libretto injured fee constant hypothesis train papers corner arguing t next employment elder phoenix bohemian [SEP]']
[Init] best perm rec loss: 0.827846348285675 for ['[CLS] corner constant bohemian train phoenix next elder arguing fee t papers hypothesis employment injured libretto [SEP]']
[Init] best perm rec loss: 0.8266593813896179 for ['[CLS] corner train bohemian phoenix hypothesis arguing injured next t constant elder libretto papers employment fee [SEP]']
[Init] best perm rec loss: 0.8228629231452942 for ['[CLS] elder papers bohemian hypothesis constant t train arguing employment phoenix libretto fee corner injured next [SEP]']
[Init] best perm rec loss: 0.8225159049034119 for ['[CLS] bohemian injured train fee t corner phoenix hypothesis constant employment elder next papers libretto arguing [SEP]']
[Init] best perm rec loss: 0.8212997913360596 for ['[CLS] libretto injured employment t next corner hypothesis arguing bohemian phoenix papers fee train elder constant [SEP]']
[Init] best perm rec loss: 0.8211261630058289 for ['[CLS] papers corner fee t next hypothesis injured arguing phoenix elder libretto constant train bohemian employment [SEP]']
[Init] best perm rec loss: 0.8209269046783447 for ['[CLS] arguing constant injured elder hypothesis train fee libretto bohemian next papers corner employment t phoenix [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.965 (perp=11.467, rec=0.485, cos=0.187), tot_loss_proj:4.100 [t=0.30s]
prediction: ['[CLS] blue arrows " fresh floor box standard new developed energy trees expensive rubberert energy [SEP]']
[ 100/2000] tot_loss=2.703 (perp=11.274, rec=0.359, cos=0.090), tot_loss_proj:4.143 [t=0.30s]
prediction: ['[CLS] during water air office floor cells aircraft waterizes oil buildings lasts blueert water [SEP]']
[ 150/2000] tot_loss=2.184 (perp=8.929, rec=0.311, cos=0.087), tot_loss_proj:3.710 [t=0.30s]
prediction: ['[CLS] ground water the office water snow. water into water plants for blueert water [SEP]']
[ 200/2000] tot_loss=1.889 (perp=7.950, rec=0.229, cos=0.071), tot_loss_proj:3.505 [t=0.30s]
prediction: ['[CLS] some water some plants water snow. ground into water plants for powder curl water [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.693 (perp=7.204, rec=0.197, cos=0.056), tot_loss_proj:3.311 [t=0.30s]
prediction: ['[CLS] some water some water plants snow. ground into water plants for water curl water [SEP]']
[ 300/2000] tot_loss=1.729 (perp=7.513, rec=0.168, cos=0.059), tot_loss_proj:3.374 [t=0.30s]
prediction: ['[CLS] some snow some water plants snow. ground into water plants for water curl water [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.727 (perp=7.550, rec=0.166, cos=0.051), tot_loss_proj:3.390 [t=0.30s]
prediction: ['[CLS] some snow some water plants snow. ground goes into plants for ice water curl [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.723 (perp=7.550, rec=0.160, cos=0.053), tot_loss_proj:3.391 [t=0.30s]
prediction: ['[CLS] some snow some water plants snow. ground goes into plants for ice water curl [SEP]']
[ 450/2000] tot_loss=1.713 (perp=7.550, rec=0.146, cos=0.057), tot_loss_proj:3.389 [t=0.30s]
prediction: ['[CLS] some snow some water plants snow. ground goes into plants for ice water curl [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.692 (perp=7.418, rec=0.166, cos=0.043), tot_loss_proj:3.333 [t=0.30s]
prediction: ['[CLS] some snow water plants snow. ground goes into the plants for oxygen snowv [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.620 (perp=7.068, rec=0.157, cos=0.050), tot_loss_proj:3.163 [t=0.35s]
prediction: ['[CLS] some snow water plants cold. ground snow goes into the plants for oxygenv [SEP]']
[ 600/2000] tot_loss=1.577 (perp=6.898, rec=0.146, cos=0.051), tot_loss_proj:3.263 [t=0.35s]
prediction: ['[CLS] some snow water plants snow. ground snow goes into the plants for oxygen still [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.607 (perp=7.069, rec=0.139, cos=0.054), tot_loss_proj:3.251 [t=0.35s]
prediction: ['[CLS] some snow water plants snow. ground snow goes into the plants for melted still [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.605 (perp=7.002, rec=0.158, cos=0.047), tot_loss_proj:3.259 [t=0.35s]
prediction: ['[CLS] some snow water melted of ground snow goes into the plants for oxygen. still [SEP]']
[ 750/2000] tot_loss=1.572 (perp=6.989, rec=0.133, cos=0.041), tot_loss_proj:3.171 [t=0.30s]
prediction: ['[CLS] some snow water melted of ground snow goes into the plants for melted. still [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.438 (perp=6.285, rec=0.138, cos=0.043), tot_loss_proj:3.046 [t=0.30s]
prediction: ['[CLS] some snow water melted of ground snow still goes into the plants for melted. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.398 (perp=6.126, rec=0.131, cos=0.042), tot_loss_proj:3.007 [t=0.30s]
prediction: ['[CLS] some snow water of melted ground snow still goes into the plants for melted. [SEP]']
[ 900/2000] tot_loss=1.404 (perp=6.126, rec=0.135, cos=0.044), tot_loss_proj:3.009 [t=0.30s]
prediction: ['[CLS] some snow water of melted ground snow still goes into the plants for melted. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.398 (perp=6.126, rec=0.128, cos=0.045), tot_loss_proj:3.010 [t=0.30s]
prediction: ['[CLS] some snow water of melted ground snow still goes into the plants for melted. [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.375 (perp=5.988, rec=0.129, cos=0.048), tot_loss_proj:3.006 [t=0.30s]
prediction: ['[CLS] some snow water of melted ground melted snow goes into the plants for melted. [SEP]']
[1050/2000] tot_loss=1.374 (perp=5.988, rec=0.130, cos=0.047), tot_loss_proj:3.006 [t=0.30s]
prediction: ['[CLS] some snow water of melted ground melted snow goes into the plants for melted. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.360 (perp=5.920, rec=0.129, cos=0.047), tot_loss_proj:2.998 [t=0.30s]
prediction: ['[CLS] some snow water from melted ground melted snow goes into the plants for melted. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.327 (perp=5.749, rec=0.129, cos=0.049), tot_loss_proj:2.944 [t=0.30s]
prediction: ['[CLS] some snow water from melted snow melted ground goes into the plants for melted. [SEP]']
[1200/2000] tot_loss=1.324 (perp=5.749, rec=0.127, cos=0.047), tot_loss_proj:2.941 [t=0.30s]
prediction: ['[CLS] some snow water from melted snow melted ground goes into the plants for melted. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.233 (perp=5.273, rec=0.131, cos=0.047), tot_loss_proj:2.851 [t=0.30s]
prediction: ['[CLS] some snow water from melted snow melted plants goes into the ground for melted. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.204 (perp=5.185, rec=0.122, cos=0.045), tot_loss_proj:2.694 [t=0.30s]
prediction: ['[CLS] some snow water from melted snow melted goes into the ground for melted plants. [SEP]']
[1350/2000] tot_loss=1.209 (perp=5.185, rec=0.124, cos=0.048), tot_loss_proj:2.696 [t=0.30s]
prediction: ['[CLS] some snow water from melted snow melted goes into the ground for melted plants. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.143 (perp=4.819, rec=0.135, cos=0.044), tot_loss_proj:2.556 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.134 (perp=4.819, rec=0.125, cos=0.045), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
[1500/2000] tot_loss=1.125 (perp=4.819, rec=0.114, cos=0.047), tot_loss_proj:2.554 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.144 (perp=4.819, rec=0.133, cos=0.048), tot_loss_proj:2.554 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.133 (perp=4.819, rec=0.121, cos=0.048), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
[1650/2000] tot_loss=1.148 (perp=4.819, rec=0.136, cos=0.048), tot_loss_proj:2.551 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.132 (perp=4.819, rec=0.120, cos=0.048), tot_loss_proj:2.548 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.137 (perp=4.819, rec=0.124, cos=0.049), tot_loss_proj:2.554 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
[1800/2000] tot_loss=1.134 (perp=4.819, rec=0.121, cos=0.049), tot_loss_proj:2.547 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.144 (perp=4.819, rec=0.131, cos=0.049), tot_loss_proj:2.549 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.136 (perp=4.819, rec=0.123, cos=0.049), tot_loss_proj:2.551 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
[1950/2000] tot_loss=1.141 (perp=4.819, rec=0.128, cos=0.049), tot_loss_proj:2.560 [t=0.31s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.135 (perp=4.819, rec=0.122, cos=0.049), tot_loss_proj:2.542 [t=0.30s]
prediction: ['[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]
========================
predicted: 
========================
[CLS] some snow water melted from melted snow goes into the ground for melted plants. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.250 | p: 81.250 | r: 81.250
rouge2     | fm: 53.333 | p: 53.333 | r: 53.333
rougeL     | fm: 81.250 | p: 81.250 | r: 81.250
rougeLsum  | fm: 81.250 | p: 81.250 | r: 81.250
r1fm+r2fm = 134.583

[Aggregate metrics]:
rouge1     | fm: 75.491 | p: 75.539 | r: 75.674
rouge2     | fm: 32.174 | p: 32.156 | r: 32.295
rougeL     | fm: 67.031 | p: 67.071 | r: 67.037
rougeLsum  | fm: 66.915 | p: 67.131 | r: 66.918
r1fm+r2fm = 107.665

input #31 time: 0:12:18 | total time: 6:24:32


Running input #32 of 100.
reference: 
========================
Bob is very serious about Mary, but less so than Paul.
========================
average of cosine similarity 0.9988738014227
highest_index [0]
highest [0.9988738014227]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[ 101, 3960, 2003, 2200, 3809, 2055, 2984, 1010, 2021, 2625, 2061, 2084,
         2703, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bob is very serious about mary, but less so than paul. [SEP]']
[Init] best rec loss: 0.9844602942466736 for ['[CLS] archery dual„ pam an arrows kings beyond if rev up place behind [SEP]']
[Init] best rec loss: 0.8793356418609619 for ['[CLS] minnesota greeceignantach supplied process + after atletico memorialpee degrees blur [SEP]']
[Init] best rec loss: 0.876288890838623 for ['[CLS] earl otherwise talking both shortly product coin ones en n loft active non [SEP]']
[Init] best rec loss: 0.8527817130088806 for ['[CLS] vetital word foundation sweptth several [SEP] rush compass kristen locals charlie [SEP]']
[Init] best rec loss: 0.84758061170578 for ['[CLS] arts hardly labor hi nosestage it what short balloonab champion nightmares [SEP]']
[Init] best rec loss: 0.8287423253059387 for ['[CLS] seventh drums place pub window husband ice progress revelationnbc benefit en nitrogen [SEP]']
[Init] best rec loss: 0.8280221223831177 for ['[CLS] architecture amazing less motionscr cole ten stick hindus administration time temple common [SEP]']
[Init] best perm rec loss: 0.8195651769638062 for ['[CLS] architecture stick administrationcr cole motions ten time hindus common temple amazing less [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.663 (perp=11.985, rec=0.449, cos=0.817), tot_loss_proj:4.261 [t=0.29s]
prediction: ['[CLS] bob. asta particular about serious, stationed silent generally middle fixed [SEP]']
[ 100/2000] tot_loss=2.935 (perp=9.023, rec=0.399, cos=0.732), tot_loss_proj:3.734 [t=0.30s]
prediction: ['[CLS] bob. mary happening mary a serious, less less less eyebrows. [SEP]']
[ 150/2000] tot_loss=2.544 (perp=7.781, rec=0.323, cos=0.665), tot_loss_proj:3.459 [t=0.30s]
prediction: ['[CLS] bob is mary happening mary is serious, less less than mary. [SEP]']
[ 200/2000] tot_loss=3.279 (perp=10.077, rec=0.441, cos=0.823), tot_loss_proj:3.932 [t=0.30s]
prediction: ['[CLS] bob. about ﬁ mary harta serious, less less than murderative [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.753 (perp=8.841, rec=0.316, cos=0.669), tot_loss_proj:3.646 [t=0.30s]
prediction: ['[CLS] bob is about fi mary about, less so serious than maryative [SEP]']
[ 300/2000] tot_loss=2.830 (perp=9.268, rec=0.284, cos=0.693), tot_loss_proj:3.749 [t=0.30s]
prediction: ['[CLS] bob is about fi mary about but less so serious than maryative [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.714 (perp=8.941, rec=0.236, cos=0.691), tot_loss_proj:3.665 [t=0.30s]
prediction: ['[CLS] bob is about fi about mary but less so serious than paulative [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.753 (perp=9.452, rec=0.221, cos=0.641), tot_loss_proj:3.779 [t=0.30s]
prediction: ['[CLS] bob is aboutceae about mary serious but less so than paulative [SEP]']
[ 450/2000] tot_loss=2.757 (perp=9.452, rec=0.209, cos=0.657), tot_loss_proj:3.780 [t=0.30s]
prediction: ['[CLS] bob is aboutceae about mary serious but less so than paulative [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.573 (perp=8.710, rec=0.185, cos=0.646), tot_loss_proj:3.640 [t=0.30s]
prediction: ['[CLS] bob is about serious about maryceae but less so than paulative [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.719 (perp=9.190, rec=0.205, cos=0.676), tot_loss_proj:3.639 [t=0.30s]
prediction: ['[CLS] bob is serious about because maryceae but less so than paulative [SEP]']
[ 600/2000] tot_loss=2.670 (perp=9.190, rec=0.186, cos=0.646), tot_loss_proj:3.643 [t=0.30s]
prediction: ['[CLS] bob is serious about because maryceae but less so than paulative [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.591 (perp=8.792, rec=0.178, cos=0.655), tot_loss_proj:3.639 [t=0.30s]
prediction: ['[CLS] bob is serious about mary becauseceae but less so than paulative [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.434 (perp=8.000, rec=0.196, cos=0.638), tot_loss_proj:3.343 [t=0.30s]
prediction: ['[CLS] bob is serious about mary becauseative but less so than paulceae [SEP]']
[ 750/2000] tot_loss=2.424 (perp=8.000, rec=0.178, cos=0.646), tot_loss_proj:3.314 [t=0.30s]
prediction: ['[CLS] bob is serious about mary becauseative but less so than paulceae [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.427 (perp=8.000, rec=0.176, cos=0.651), tot_loss_proj:3.311 [t=0.30s]
prediction: ['[CLS] bob is serious about mary becauseative but less so than paulceae [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.535 (perp=8.578, rec=0.174, cos=0.646), tot_loss_proj:3.376 [t=0.30s]
prediction: ['[CLS] bob is serious about mary because德 but less so than paulceae [SEP]']
[ 900/2000] tot_loss=2.542 (perp=8.578, rec=0.177, cos=0.649), tot_loss_proj:3.372 [t=0.30s]
prediction: ['[CLS] bob is serious about mary because德 but less so than paulceae [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.466 (perp=8.193, rec=0.175, cos=0.653), tot_loss_proj:2.824 [t=0.30s]
prediction: ['[CLS] because bob is serious about mary德 but less so than paulceae [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.463 (perp=8.153, rec=0.168, cos=0.664), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than paul德 [SEP]']
[1050/2000] tot_loss=2.457 (perp=8.153, rec=0.171, cos=0.655), tot_loss_proj:2.747 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than paul德 [SEP]']
Attempt swap
[1100/2000] tot_loss=2.466 (perp=8.153, rec=0.176, cos=0.659), tot_loss_proj:2.744 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than paul德 [SEP]']
Attempt swap
[1150/2000] tot_loss=2.464 (perp=8.153, rec=0.168, cos=0.665), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than paul德 [SEP]']
[1200/2000] tot_loss=2.465 (perp=8.153, rec=0.168, cos=0.667), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than paul德 [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.464 (perp=8.116, rec=0.177, cos=0.664), tot_loss_proj:3.240 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
Attempt swap
[1300/2000] tot_loss=2.460 (perp=8.116, rec=0.167, cos=0.670), tot_loss_proj:3.244 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
[1350/2000] tot_loss=2.459 (perp=8.116, rec=0.170, cos=0.666), tot_loss_proj:3.237 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
Attempt swap
[1400/2000] tot_loss=2.463 (perp=8.116, rec=0.171, cos=0.669), tot_loss_proj:3.244 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
Attempt swap
[1450/2000] tot_loss=2.454 (perp=8.116, rec=0.162, cos=0.669), tot_loss_proj:3.244 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
[1500/2000] tot_loss=2.458 (perp=8.116, rec=0.165, cos=0.670), tot_loss_proj:3.236 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
Attempt swap
[1550/2000] tot_loss=2.458 (perp=8.116, rec=0.164, cos=0.671), tot_loss_proj:3.243 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
Attempt swap
[1600/2000] tot_loss=2.451 (perp=8.116, rec=0.158, cos=0.669), tot_loss_proj:3.244 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
[1650/2000] tot_loss=2.463 (perp=8.116, rec=0.169, cos=0.671), tot_loss_proj:3.241 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
Attempt swap
[1700/2000] tot_loss=2.467 (perp=8.116, rec=0.170, cos=0.674), tot_loss_proj:3.239 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
Attempt swap
[1750/2000] tot_loss=2.466 (perp=8.116, rec=0.173, cos=0.671), tot_loss_proj:3.242 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
[1800/2000] tot_loss=2.470 (perp=8.116, rec=0.172, cos=0.675), tot_loss_proj:3.239 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
Attempt swap
[1850/2000] tot_loss=2.459 (perp=8.116, rec=0.165, cos=0.671), tot_loss_proj:3.242 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
Attempt swap
[1900/2000] tot_loss=2.467 (perp=8.116, rec=0.172, cos=0.672), tot_loss_proj:3.242 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
[1950/2000] tot_loss=2.462 (perp=8.116, rec=0.167, cos=0.672), tot_loss_proj:3.246 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
Attempt swap
[2000/2000] tot_loss=2.454 (perp=8.116, rec=0.158, cos=0.673), tot_loss_proj:3.238 [t=0.30s]
prediction: ['[CLS] because bob is serious about maryceae but less so than德 paul [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] bob is very serious about mary, but less so than paul. [SEP]
========================
predicted: 
========================
[CLS] because bob is serious about maryceae but less so than德 paul [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 84.615 | r: 84.615
rouge2     | fm: 58.333 | p: 58.333 | r: 58.333
rougeL     | fm: 84.615 | p: 84.615 | r: 84.615
rougeLsum  | fm: 84.615 | p: 84.615 | r: 84.615
r1fm+r2fm = 142.949

[Aggregate metrics]:
rouge1     | fm: 75.731 | p: 75.946 | r: 75.883
rouge2     | fm: 32.650 | p: 32.761 | r: 32.809
rougeL     | fm: 67.476 | p: 67.614 | r: 67.600
rougeLsum  | fm: 67.687 | p: 67.882 | r: 67.763
r1fm+r2fm = 108.381

input #32 time: 0:11:51 | total time: 6:36:23


Running input #33 of 100.
reference: 
========================
Ayala sent the diamond necklace back.
========================
average of cosine similarity 0.9988134181442019
highest_index [0]
highest [0.9988134181442019]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  1996,  6323, 13016,  2067,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] ayala sent the diamond necklace back. [SEP]']
[Init] best rec loss: 0.9724894762039185 for ['[CLS] terms primary contribution an soil all competition dug [SEP]']
[Init] best rec loss: 0.9465667009353638 for ['[CLS] militiaiom slim lei daryl dip bay well [SEP]']
[Init] best rec loss: 0.9450927376747131 for ['[CLS] langley 9 shoe soon tray originally ha inclined [SEP]']
[Init] best rec loss: 0.9377089738845825 for ['[CLS] captive purpose ponytail auracat vocabulary 2 severity [SEP]']
[Init] best rec loss: 0.8988373875617981 for ['[CLS] strikingenberg online poland silver through proper comfort [SEP]']
[Init] best perm rec loss: 0.8983377814292908 for ['[CLS] silver throughenberg comfort online poland striking proper [SEP]']
[Init] best perm rec loss: 0.8950842618942261 for ['[CLS] silverenberg online proper poland comfort through striking [SEP]']
[Init] best perm rec loss: 0.8950515389442444 for ['[CLS] online polandenberg striking silver through proper comfort [SEP]']
[Init] best perm rec loss: 0.8943526744842529 for ['[CLS] onlineenberg through striking poland proper silver comfort [SEP]']
[Init] best perm rec loss: 0.8934610486030579 for ['[CLS] proper comfortenberg silver through online poland striking [SEP]']
[Init] best perm rec loss: 0.8934357762336731 for ['[CLS] silver comfort online poland striking through properenberg [SEP]']
[Init] best perm rec loss: 0.8932450413703918 for ['[CLS] proper online striking comfort poland silver throughenberg [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.346 (perp=13.736, rec=0.684, cos=0.915), tot_loss_proj:4.661 [t=0.29s]
prediction: ['[CLS] la confirmed sponsoredbution₁ wisdombergnated [SEP]']
[ 100/2000] tot_loss=3.708 (perp=11.533, rec=0.509, cos=0.893), tot_loss_proj:4.216 [t=0.30s]
prediction: ['[CLS]tance honors wanted stop [SEP] diamond necklace → [SEP]']
[ 150/2000] tot_loss=4.254 (perp=13.901, rec=0.507, cos=0.967), tot_loss_proj:4.741 [t=0.30s]
prediction: ['[CLS]yalayala sentb necklace diamond necklaceyala [SEP]']
[ 200/2000] tot_loss=4.174 (perp=14.396, rec=0.419, cos=0.876), tot_loss_proj:4.677 [t=0.30s]
prediction: ['[CLS]yalayala sentb necklace diamondyala back [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.881 (perp=13.049, rec=0.390, cos=0.881), tot_loss_proj:4.401 [t=0.30s]
prediction: ['[CLS]rialyala sentyala wrist diamondyala back [SEP]']
[ 300/2000] tot_loss=3.235 (perp=10.009, rec=0.378, cos=0.855), tot_loss_proj:3.949 [t=0.30s]
prediction: ['[CLS] ayala sentyala necklace diamond cookies back [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.081 (perp=9.757, rec=0.303, cos=0.826), tot_loss_proj:3.716 [t=0.30s]
prediction: ['[CLS] ayala sentyala diamond necklace cookies back [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.082 (perp=9.757, rec=0.294, cos=0.836), tot_loss_proj:3.726 [t=0.30s]
prediction: ['[CLS] ayala sentyala diamond necklace cookies back [SEP]']
[ 450/2000] tot_loss=3.301 (perp=10.866, rec=0.287, cos=0.841), tot_loss_proj:4.116 [t=0.30s]
prediction: ['[CLS] theyala sentyala diamond necklace cookies back [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.415 (perp=11.514, rec=0.288, cos=0.825), tot_loss_proj:4.102 [t=0.30s]
prediction: ['[CLS] theyala sentyala diamond necklace unicorn back [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.972 (perp=13.256, rec=0.459, cos=0.862), tot_loss_proj:4.529 [t=0.30s]
prediction: ['[CLS]yalayala sentlle diamond necklace badminton back [SEP]']
[ 600/2000] tot_loss=3.856 (perp=13.508, rec=0.334, cos=0.820), tot_loss_proj:4.533 [t=0.30s]
prediction: ['[CLS]yalayala sentlle diamond necklace unicorn back [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.621 (perp=12.303, rec=0.308, cos=0.853), tot_loss_proj:4.269 [t=0.30s]
prediction: ['[CLS]lleyala sentyala diamond necklace unicorn back [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.570 (perp=12.303, rec=0.280, cos=0.829), tot_loss_proj:4.267 [t=0.30s]
prediction: ['[CLS]lleyala sentyala diamond necklace unicorn back [SEP]']
[ 750/2000] tot_loss=3.465 (perp=11.766, rec=0.274, cos=0.838), tot_loss_proj:4.177 [t=0.30s]
prediction: ['[CLS] nothingyala sentyala necklace necklace unicorn back [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.334 (perp=11.166, rec=0.274, cos=0.826), tot_loss_proj:4.063 [t=0.30s]
prediction: ['[CLS] nothingyala sentyala unicorn necklace necklace back [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=3.247 (perp=10.733, rec=0.271, cos=0.830), tot_loss_proj:4.015 [t=0.30s]
prediction: ['[CLS] nothingyalayala sent unicorn necklace necklace back [SEP]']
[ 900/2000] tot_loss=3.246 (perp=10.733, rec=0.269, cos=0.831), tot_loss_proj:4.021 [t=0.30s]
prediction: ['[CLS] nothingyalayala sent unicorn necklace necklace back [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.237 (perp=10.733, rec=0.260, cos=0.830), tot_loss_proj:4.021 [t=0.30s]
prediction: ['[CLS] nothingyalayala sent unicorn necklace necklace back [SEP]']
Attempt swap
[1000/2000] tot_loss=3.243 (perp=10.733, rec=0.267, cos=0.830), tot_loss_proj:4.013 [t=0.30s]
prediction: ['[CLS] nothingyalayala sent unicorn necklace necklace back [SEP]']
[1050/2000] tot_loss=3.244 (perp=10.733, rec=0.266, cos=0.831), tot_loss_proj:4.012 [t=0.30s]
prediction: ['[CLS] nothingyalayala sent unicorn necklace necklace back [SEP]']
Attempt swap
[1100/2000] tot_loss=3.228 (perp=10.733, rec=0.253, cos=0.828), tot_loss_proj:4.011 [t=0.30s]
prediction: ['[CLS] nothingyalayala sent unicorn necklace necklace back [SEP]']
Attempt swap
[1150/2000] tot_loss=3.235 (perp=10.733, rec=0.259, cos=0.829), tot_loss_proj:4.010 [t=0.30s]
prediction: ['[CLS] nothingyalayala sent unicorn necklace necklace back [SEP]']
[1200/2000] tot_loss=3.235 (perp=10.733, rec=0.262, cos=0.827), tot_loss_proj:4.011 [t=0.30s]
prediction: ['[CLS] nothingyalayala sent unicorn necklace necklace back [SEP]']
Attempt swap
[1250/2000] tot_loss=3.035 (perp=9.745, rec=0.257, cos=0.829), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn necklace necklace back [SEP]']
Attempt swap
[1300/2000] tot_loss=3.036 (perp=9.745, rec=0.256, cos=0.831), tot_loss_proj:3.842 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn necklace necklace back [SEP]']
[1350/2000] tot_loss=3.033 (perp=9.745, rec=0.253, cos=0.831), tot_loss_proj:3.847 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn necklace necklace back [SEP]']
Attempt swap
[1400/2000] tot_loss=3.026 (perp=9.745, rec=0.248, cos=0.829), tot_loss_proj:3.845 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn necklace necklace back [SEP]']
Attempt swap
[1450/2000] tot_loss=3.027 (perp=9.745, rec=0.248, cos=0.829), tot_loss_proj:3.845 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn necklace necklace back [SEP]']
[1500/2000] tot_loss=3.029 (perp=9.745, rec=0.251, cos=0.829), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn necklace necklace back [SEP]']
Attempt swap
[1550/2000] tot_loss=3.026 (perp=9.745, rec=0.248, cos=0.829), tot_loss_proj:3.848 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn necklace necklace back [SEP]']
Attempt swap
[1600/2000] tot_loss=3.033 (perp=9.745, rec=0.255, cos=0.829), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn necklace necklace back [SEP]']
[1650/2000] tot_loss=3.026 (perp=9.745, rec=0.249, cos=0.828), tot_loss_proj:3.848 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn necklace necklace back [SEP]']
Attempt swap
[1700/2000] tot_loss=3.392 (perp=11.586, rec=0.248, cos=0.827), tot_loss_proj:4.185 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn♭ necklace back [SEP]']
Attempt swap
[1750/2000] tot_loss=3.401 (perp=11.586, rec=0.257, cos=0.827), tot_loss_proj:4.184 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn♭ necklace back [SEP]']
[1800/2000] tot_loss=3.398 (perp=11.586, rec=0.251, cos=0.830), tot_loss_proj:4.183 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn♭ necklace back [SEP]']
Attempt swap
[1850/2000] tot_loss=3.394 (perp=11.586, rec=0.250, cos=0.827), tot_loss_proj:4.184 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn♭ necklace back [SEP]']
Attempt swap
[1900/2000] tot_loss=3.399 (perp=11.586, rec=0.252, cos=0.830), tot_loss_proj:4.180 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn♭ necklace back [SEP]']
[1950/2000] tot_loss=3.395 (perp=11.586, rec=0.249, cos=0.830), tot_loss_proj:4.190 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn♭ necklace back [SEP]']
Attempt swap
[2000/2000] tot_loss=3.391 (perp=11.586, rec=0.244, cos=0.830), tot_loss_proj:4.184 [t=0.30s]
prediction: ['[CLS] ayalayala sent unicorn♭ necklace back [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] ayala sent the diamond necklace back. [SEP]
========================
predicted: 
========================
[CLS] ayalayala sent unicorn♭ necklace back [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 71.429 | r: 62.500
rouge2     | fm: 30.769 | p: 33.333 | r: 28.571
rougeL     | fm: 66.667 | p: 71.429 | r: 62.500
rougeLsum  | fm: 66.667 | p: 71.429 | r: 62.500
r1fm+r2fm = 97.436

[Aggregate metrics]:
rouge1     | fm: 75.533 | p: 75.769 | r: 75.610
rouge2     | fm: 32.560 | p: 32.737 | r: 32.629
rougeL     | fm: 67.385 | p: 67.668 | r: 67.411
rougeLsum  | fm: 67.745 | p: 67.954 | r: 67.679
r1fm+r2fm = 108.092

input #33 time: 0:11:50 | total time: 6:48:14


Running input #34 of 100.
reference: 
========================
Jessica sprayed paint under the table.
========================
average of cosine similarity 0.9989731486290163
highest_index [0]
highest [0.9989731486290163]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  8201, 25401,  6773,  2104,  1996,  2795,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] jessica sprayed paint under the table. [SEP]']
[Init] best rec loss: 0.9455736875534058 for ['[CLS] solvent pure sitting returns open penelope gerais [SEP]']
[Init] best rec loss: 0.9148992896080017 for ['[CLS] tradition governing terminal accordingmus chris these [SEP]']
[Init] best rec loss: 0.9094448089599609 for ['[CLS]vision best te sided ms lowest elected [SEP]']
[Init] best rec loss: 0.9000020623207092 for ['[CLS] jace freeman leather once spirit tiny vital [SEP]']
[Init] best rec loss: 0.8935664892196655 for ['[CLS]ᵉ simpson mistress alzheimer for carmine another [SEP]']
[Init] best rec loss: 0.8669819235801697 for ['[CLS]ter & since cureraßeeratednes [SEP]']
[Init] best perm rec loss: 0.8662878274917603 for ['[CLS]nes cure &terraßeerated since [SEP]']
[Init] best perm rec loss: 0.864685595035553 for ['[CLS] sinceerated cureraßeter &nes [SEP]']
[Init] best perm rec loss: 0.8638688325881958 for ['[CLS] since &nes cureterraßeerated [SEP]']
[Init] best perm rec loss: 0.8621566295623779 for ['[CLS] &nes sinceeratedraßeter cure [SEP]']
[Init] best perm rec loss: 0.86044842004776 for ['[CLS]raßetererated &nes since cure [SEP]']
[Init] best perm rec loss: 0.8599992394447327 for ['[CLS]nes &erated cure sinceterraße [SEP]']
[Init] best perm rec loss: 0.8584731221199036 for ['[CLS]nes &tererated cure sinceraße [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.787 (perp=10.922, rec=0.682, cos=0.920), tot_loss_proj:4.054 [t=0.38s]
prediction: ['[CLS] sarah & talon looked. paint finger [SEP]']
[ 100/2000] tot_loss=3.936 (perp=11.929, rec=0.550, cos=1.000), tot_loss_proj:4.290 [t=0.30s]
prediction: ['[CLS] jessicahyl jessica looked. paint carpet [SEP]']
[ 150/2000] tot_loss=4.048 (perp=12.486, rec=0.555, cos=0.995), tot_loss_proj:4.465 [t=0.30s]
prediction: ['[CLS] jessica jessica jessica sprayed. paint garcia [SEP]']
[ 200/2000] tot_loss=3.670 (perp=11.893, rec=0.449, cos=0.842), tot_loss_proj:4.095 [t=0.30s]
prediction: ['[CLS] jessica jessica jessica sprayed. sprayed cookies [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.135 (perp=9.176, rec=0.411, cos=0.889), tot_loss_proj:3.251 [t=0.30s]
prediction: ['[CLS] jessica jessica jessica sprayed paint soup. [SEP]']
[ 300/2000] tot_loss=2.932 (perp=8.675, rec=0.378, cos=0.819), tot_loss_proj:3.191 [t=0.30s]
prediction: ['[CLS] jessica jessica jessica sprayed paint paint. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.114 (perp=9.489, rec=0.363, cos=0.853), tot_loss_proj:3.637 [t=0.30s]
prediction: ['[CLS] jessica sprayed sprayed jessicaesian paint. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.985 (perp=8.869, rec=0.351, cos=0.860), tot_loss_proj:3.636 [t=0.30s]
prediction: ['[CLS] jessica sprayed jessica sprayedesian paint. [SEP]']
[ 450/2000] tot_loss=2.989 (perp=8.869, rec=0.338, cos=0.877), tot_loss_proj:3.631 [t=0.30s]
prediction: ['[CLS] jessica sprayed jessica sprayedesian paint. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.953 (perp=8.869, rec=0.318, cos=0.861), tot_loss_proj:3.636 [t=0.30s]
prediction: ['[CLS] jessica sprayed jessica sprayedesian paint. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.933 (perp=8.869, rec=0.298, cos=0.861), tot_loss_proj:3.638 [t=0.30s]
prediction: ['[CLS] jessica sprayed jessica sprayedesian paint. [SEP]']
[ 600/2000] tot_loss=2.961 (perp=8.869, rec=0.302, cos=0.885), tot_loss_proj:3.643 [t=0.30s]
prediction: ['[CLS] jessica sprayed jessica sprayedesian paint. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.964 (perp=8.869, rec=0.304, cos=0.886), tot_loss_proj:3.637 [t=0.30s]
prediction: ['[CLS] jessica sprayed jessica sprayedesian paint. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.955 (perp=8.970, rec=0.293, cos=0.869), tot_loss_proj:3.722 [t=0.30s]
prediction: ['[CLS] jessica sprayed jessica sprayedaneous paint. [SEP]']
[ 750/2000] tot_loss=3.339 (perp=10.751, rec=0.292, cos=0.896), tot_loss_proj:3.981 [t=0.30s]
prediction: ['[CLS] jessica sprayed scope sprayedaneous paint. [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.331 (perp=10.751, rec=0.299, cos=0.882), tot_loss_proj:3.978 [t=0.30s]
prediction: ['[CLS] jessica sprayed scope sprayedaneous paint. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.229 (perp=10.322, rec=0.295, cos=0.870), tot_loss_proj:3.834 [t=0.30s]
prediction: ['[CLS] jessica sprayed storage sprayedaneous paint. [SEP]']
[ 900/2000] tot_loss=3.226 (perp=10.322, rec=0.284, cos=0.877), tot_loss_proj:3.825 [t=0.30s]
prediction: ['[CLS] jessica sprayed storage sprayedaneous paint. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.314 (perp=10.685, rec=0.293, cos=0.883), tot_loss_proj:4.125 [t=0.30s]
prediction: ['[CLS] jessica sprayed storage حaneous paint. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.294 (perp=10.685, rec=0.277, cos=0.880), tot_loss_proj:4.126 [t=0.30s]
prediction: ['[CLS] jessica sprayed storage حaneous paint. [SEP]']
[1050/2000] tot_loss=3.409 (perp=11.201, rec=0.292, cos=0.876), tot_loss_proj:4.245 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.410 (perp=11.201, rec=0.293, cos=0.876), tot_loss_proj:4.250 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.398 (perp=11.201, rec=0.280, cos=0.878), tot_loss_proj:4.257 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
[1200/2000] tot_loss=3.392 (perp=11.201, rec=0.274, cos=0.877), tot_loss_proj:4.244 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.396 (perp=11.201, rec=0.278, cos=0.878), tot_loss_proj:4.252 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.379 (perp=11.201, rec=0.261, cos=0.878), tot_loss_proj:4.252 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
[1350/2000] tot_loss=3.384 (perp=11.201, rec=0.266, cos=0.877), tot_loss_proj:4.245 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.404 (perp=11.201, rec=0.285, cos=0.879), tot_loss_proj:4.250 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.386 (perp=11.201, rec=0.267, cos=0.879), tot_loss_proj:4.254 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
[1500/2000] tot_loss=3.392 (perp=11.201, rec=0.273, cos=0.879), tot_loss_proj:4.247 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.385 (perp=11.201, rec=0.265, cos=0.879), tot_loss_proj:4.245 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.396 (perp=11.201, rec=0.277, cos=0.879), tot_loss_proj:4.246 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
[1650/2000] tot_loss=3.397 (perp=11.201, rec=0.277, cos=0.879), tot_loss_proj:4.245 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.401 (perp=11.201, rec=0.281, cos=0.879), tot_loss_proj:4.247 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.383 (perp=11.201, rec=0.263, cos=0.880), tot_loss_proj:4.254 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
[1800/2000] tot_loss=3.392 (perp=11.201, rec=0.272, cos=0.880), tot_loss_proj:4.249 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.387 (perp=11.201, rec=0.268, cos=0.879), tot_loss_proj:4.244 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حaneous paint. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.347 (perp=10.987, rec=0.269, cos=0.881), tot_loss_proj:4.189 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حboards paint. [SEP]']
[1950/2000] tot_loss=3.340 (perp=10.987, rec=0.263, cos=0.879), tot_loss_proj:4.191 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حboards paint. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.348 (perp=10.987, rec=0.271, cos=0.879), tot_loss_proj:4.186 [t=0.30s]
prediction: ['[CLS] jessica sprayed allegro حboards paint. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] jessica sprayed paint under the table. [SEP]
========================
predicted: 
========================
[CLS] jessica sprayed allegro حaneous paint. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 71.429 | r: 62.500
rouge2     | fm: 30.769 | p: 33.333 | r: 28.571
rougeL     | fm: 66.667 | p: 71.429 | r: 62.500
rougeLsum  | fm: 66.667 | p: 71.429 | r: 62.500
r1fm+r2fm = 97.436

[Aggregate metrics]:
rouge1     | fm: 75.344 | p: 75.699 | r: 75.289
rouge2     | fm: 32.472 | p: 32.667 | r: 32.511
rougeL     | fm: 67.346 | p: 67.807 | r: 67.160
rougeLsum  | fm: 67.663 | p: 68.148 | r: 67.427
r1fm+r2fm = 107.816

input #34 time: 0:11:50 | total time: 7:00:04


Running input #35 of 100.
reference: 
========================
John is refused.
========================
average of cosine similarity 0.9989870852654947
highest_index [0]
highest [0.9989870852654947]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2198, 2003, 4188, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is refused. [SEP]']
[Init] best rec loss: 0.906508207321167 for ['[CLS] hugo cruise than seconds [SEP]']
[Init] best rec loss: 0.8125077486038208 for ['[CLS] wings property warned wish [SEP]']
[Init] best rec loss: 0.7916086316108704 for ['[CLS] km² debut disgustdle [SEP]']
[Init] best perm rec loss: 0.7912262678146362 for ['[CLS] km² disgust debutdle [SEP]']
[Init] best perm rec loss: 0.7894440293312073 for ['[CLS] disgust km²dle debut [SEP]']
[Init] best perm rec loss: 0.7887302041053772 for ['[CLS] debut disgust km²dle [SEP]']
[Init] best perm rec loss: 0.7883837223052979 for ['[CLS]dle disgust km² debut [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.376 (perp=10.329, rec=0.514, cos=0.797), tot_loss_proj:3.875 [t=0.29s]
prediction: ['[CLS] refused : refuses refused [SEP]']
[ 100/2000] tot_loss=3.560 (perp=11.775, rec=0.412, cos=0.794), tot_loss_proj:4.268 [t=0.30s]
prediction: ['[CLS] refused is elves refused [SEP]']
[ 150/2000] tot_loss=3.155 (perp=11.267, rec=0.246, cos=0.656), tot_loss_proj:4.126 [t=0.30s]
prediction: ['[CLS] john is otago refused [SEP]']
[ 200/2000] tot_loss=3.087 (perp=11.330, rec=0.185, cos=0.636), tot_loss_proj:4.164 [t=0.30s]
prediction: ['[CLS] john is garion refused [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.712 (perp=9.117, rec=0.233, cos=0.655), tot_loss_proj:3.632 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
[ 300/2000] tot_loss=2.862 (perp=10.455, rec=0.185, cos=0.586), tot_loss_proj:3.860 [t=0.30s]
prediction: ['[CLS] johnrued is refused [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.521 (perp=8.805, rec=0.175, cos=0.585), tot_loss_proj:3.383 [t=0.30s]
prediction: ['[CLS] john europa is refused [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.483 (perp=8.805, rec=0.146, cos=0.576), tot_loss_proj:3.383 [t=0.30s]
prediction: ['[CLS] john europa is refused [SEP]']
[ 450/2000] tot_loss=2.499 (perp=8.805, rec=0.156, cos=0.582), tot_loss_proj:3.387 [t=0.30s]
prediction: ['[CLS] john europa is refused [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.496 (perp=8.805, rec=0.162, cos=0.573), tot_loss_proj:3.387 [t=0.30s]
prediction: ['[CLS] john europa is refused [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.510 (perp=8.805, rec=0.158, cos=0.592), tot_loss_proj:3.388 [t=0.30s]
prediction: ['[CLS] john europa is refused [SEP]']
[ 600/2000] tot_loss=2.506 (perp=8.805, rec=0.163, cos=0.582), tot_loss_proj:3.393 [t=0.30s]
prediction: ['[CLS] john europa is refused [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.494 (perp=8.805, rec=0.150, cos=0.583), tot_loss_proj:3.390 [t=0.30s]
prediction: ['[CLS] john europa is refused [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.573 (perp=9.117, rec=0.165, cos=0.585), tot_loss_proj:3.630 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
[ 750/2000] tot_loss=2.571 (perp=9.117, rec=0.165, cos=0.584), tot_loss_proj:3.627 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.560 (perp=9.117, rec=0.155, cos=0.582), tot_loss_proj:3.628 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.572 (perp=9.117, rec=0.165, cos=0.583), tot_loss_proj:3.625 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
[ 900/2000] tot_loss=2.576 (perp=9.117, rec=0.162, cos=0.590), tot_loss_proj:3.626 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.572 (perp=9.117, rec=0.160, cos=0.588), tot_loss_proj:3.629 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1000/2000] tot_loss=2.575 (perp=9.117, rec=0.157, cos=0.595), tot_loss_proj:3.626 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
[1050/2000] tot_loss=2.565 (perp=9.117, rec=0.150, cos=0.592), tot_loss_proj:3.627 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1100/2000] tot_loss=2.567 (perp=9.117, rec=0.154, cos=0.590), tot_loss_proj:3.623 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1150/2000] tot_loss=2.568 (perp=9.117, rec=0.151, cos=0.594), tot_loss_proj:3.621 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
[1200/2000] tot_loss=2.573 (perp=9.117, rec=0.162, cos=0.588), tot_loss_proj:3.622 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1250/2000] tot_loss=2.573 (perp=9.117, rec=0.155, cos=0.595), tot_loss_proj:3.628 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1300/2000] tot_loss=2.580 (perp=9.117, rec=0.170, cos=0.588), tot_loss_proj:3.622 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
[1350/2000] tot_loss=2.568 (perp=9.117, rec=0.153, cos=0.591), tot_loss_proj:3.628 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1400/2000] tot_loss=2.571 (perp=9.117, rec=0.157, cos=0.591), tot_loss_proj:3.628 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1450/2000] tot_loss=2.565 (perp=9.117, rec=0.152, cos=0.590), tot_loss_proj:3.625 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
[1500/2000] tot_loss=2.578 (perp=9.117, rec=0.164, cos=0.591), tot_loss_proj:3.624 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1550/2000] tot_loss=2.555 (perp=9.117, rec=0.140, cos=0.591), tot_loss_proj:3.626 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1600/2000] tot_loss=2.564 (perp=9.117, rec=0.150, cos=0.590), tot_loss_proj:3.627 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
[1650/2000] tot_loss=2.563 (perp=9.117, rec=0.150, cos=0.590), tot_loss_proj:3.626 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1700/2000] tot_loss=2.562 (perp=9.117, rec=0.148, cos=0.591), tot_loss_proj:3.622 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1750/2000] tot_loss=2.570 (perp=9.117, rec=0.155, cos=0.592), tot_loss_proj:3.627 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
[1800/2000] tot_loss=2.575 (perp=9.117, rec=0.159, cos=0.593), tot_loss_proj:3.626 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1850/2000] tot_loss=2.566 (perp=9.117, rec=0.149, cos=0.594), tot_loss_proj:3.623 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[1900/2000] tot_loss=2.571 (perp=9.117, rec=0.156, cos=0.591), tot_loss_proj:3.622 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
[1950/2000] tot_loss=2.565 (perp=9.117, rec=0.151, cos=0.590), tot_loss_proj:3.622 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Attempt swap
[2000/2000] tot_loss=2.556 (perp=9.117, rec=0.140, cos=0.593), tot_loss_proj:3.626 [t=0.30s]
prediction: ['[CLS] johnrdial is refused [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] john is refused. [SEP]
========================
predicted: 
========================
[CLS] johnrdial is refused [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 75.454 | p: 75.757 | r: 75.343
rouge2     | fm: 33.068 | p: 33.190 | r: 32.953
rougeL     | fm: 67.820 | p: 68.239 | r: 67.713
rougeLsum  | fm: 67.969 | p: 68.399 | r: 67.841
r1fm+r2fm = 108.522

input #35 time: 0:11:46 | total time: 7:11:51


Running input #36 of 100.
reference: 
========================
This information could have been released by Gorbachev, but he chose not to.
========================
average of cosine similarity 0.99901319133555
highest_index [0]
highest [0.99901319133555]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[  101,  2023,  2592,  2071,  2031,  2042,  2207,  2011,  2175, 28483,
         16179,  1010,  2021,  2002,  4900,  2025,  2000,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]']
[Init] best rec loss: 0.9123674035072327 for ['[CLS] actually joseph sofia sas colt late sketch sensefixed skate shaved clerical period huis powers news [SEP]']
[Init] best rec loss: 0.857575535774231 for ['[CLS] penny quartersrim however reliefly supreme grant which departure mortar oak black touch apex golden ruling [SEP]']
[Init] best perm rec loss: 0.8539623618125916 for ['[CLS] departure relief golden black apex penny grant which ruling touch supreme mortar quarters howeverlyrim oak [SEP]']
[Init] best perm rec loss: 0.8535162210464478 for ['[CLS] touch ruling grant however which goldenly apex departure supremerim mortar quarters penny oak black relief [SEP]']
[Init] best perm rec loss: 0.8527835011482239 for ['[CLS] departure touch golden reliefly howeverrim apex penny black ruling supreme grant oak mortar quarters which [SEP]']
[Init] best perm rec loss: 0.8520221710205078 for ['[CLS] ruling grant quartersrim mortar penny oak apex departure supreme relief however black goldenly which touch [SEP]']
[Init] best perm rec loss: 0.8517942428588867 for ['[CLS] golden whichly touch relief mortar ruling apex supreme howeverrim grant departure penny quarters oak black [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.763 (perp=11.645, rec=0.338, cos=0.096), tot_loss_proj:4.146 [t=0.30s]
prediction: ["[CLS] executive waschev one'his zagrebchev bombers academy however impressive bed thru data leather. [SEP]"]
[ 100/2000] tot_loss=2.655 (perp=11.841, rec=0.244, cos=0.043), tot_loss_proj:4.147 [t=0.30s]
prediction: ['[CLS] hp informationchev too? released∘rba information university however successful bedrba not extremely. [SEP]']
[ 150/2000] tot_loss=2.439 (perp=11.120, rec=0.185, cos=0.030), tot_loss_proj:3.981 [t=0.30s]
prediction: ['[CLS] orb informationchev could could releasedrbarba information university by were bedrba he chose. [SEP]']
[ 200/2000] tot_loss=2.090 (perp=9.574, rec=0.153, cos=0.022), tot_loss_proj:3.728 [t=0.30s]
prediction: ['[CLS] possibly thischev could could released gorba informationchev by were a but he chose. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.962 (perp=9.101, rec=0.129, cos=0.013), tot_loss_proj:3.566 [t=0.30s]
prediction: ['[CLS] have this couldchev been released gorba informationchev by were a but he chose. [SEP]']
[ 300/2000] tot_loss=1.823 (perp=8.525, rec=0.107, cos=0.011), tot_loss_proj:3.485 [t=0.30s]
prediction: ['[CLS] have this couldchev be released gorba information not by were a but he chose. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.901 (perp=8.603, rec=0.161, cos=0.020), tot_loss_proj:3.537 [t=0.30s]
prediction: ["[CLS]gno this could been released gorbachev information not by'standard but he chose. [SEP]"]
Attempt swap
[ 400/2000] tot_loss=1.555 (perp=7.097, rec=0.124, cos=0.012), tot_loss_proj:3.294 [t=0.30s]
prediction: ['[CLS] had this could have released gorbachev information not by would standard but he chose. [SEP]']
[ 450/2000] tot_loss=1.614 (perp=7.466, rec=0.110, cos=0.011), tot_loss_proj:3.397 [t=0.30s]
prediction: ['[CLS] chose this could have released gorbachev information not by would standard but he chose. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.453 (perp=6.624, rec=0.115, cos=0.012), tot_loss_proj:3.246 [t=0.30s]
prediction: ['[CLS] - this could have released gorbachev information not classic, by but he chose. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.412 (perp=6.456, rec=0.110, cos=0.011), tot_loss_proj:3.209 [t=0.30s]
prediction: ['[CLS] - this could have released gorbachev information not classic, but he chose by. [SEP]']
[ 600/2000] tot_loss=1.403 (perp=6.456, rec=0.102, cos=0.010), tot_loss_proj:3.213 [t=0.30s]
prediction: ['[CLS] - this could have released gorbachev information not classic, but he chose by. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.400 (perp=6.456, rec=0.099, cos=0.010), tot_loss_proj:3.209 [t=0.30s]
prediction: ['[CLS] - this could have released gorbachev information not classic, but he chose by. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.335 (perp=6.125, rec=0.100, cos=0.009), tot_loss_proj:3.095 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev information not classic, but he chose by. [SEP]']
[ 750/2000] tot_loss=1.334 (perp=6.125, rec=0.100, cos=0.009), tot_loss_proj:3.093 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev information not classic, but he chose by. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.295 (perp=5.987, rec=0.089, cos=0.009), tot_loss_proj:3.141 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev information by classic, but he chose not. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.257 (perp=5.740, rec=0.100, cos=0.009), tot_loss_proj:3.085 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
[ 900/2000] tot_loss=1.249 (perp=5.740, rec=0.092, cos=0.009), tot_loss_proj:3.086 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.243 (perp=5.740, rec=0.086, cos=0.009), tot_loss_proj:3.089 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.243 (perp=5.740, rec=0.086, cos=0.009), tot_loss_proj:3.091 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
[1050/2000] tot_loss=1.249 (perp=5.740, rec=0.093, cos=0.008), tot_loss_proj:3.090 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.240 (perp=5.740, rec=0.083, cos=0.008), tot_loss_proj:3.088 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.242 (perp=5.740, rec=0.085, cos=0.008), tot_loss_proj:3.094 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
[1200/2000] tot_loss=1.238 (perp=5.740, rec=0.082, cos=0.008), tot_loss_proj:3.091 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.241 (perp=5.740, rec=0.084, cos=0.008), tot_loss_proj:3.087 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.248 (perp=5.740, rec=0.092, cos=0.008), tot_loss_proj:3.086 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
[1350/2000] tot_loss=1.249 (perp=5.740, rec=0.092, cos=0.008), tot_loss_proj:3.090 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.235 (perp=5.740, rec=0.078, cos=0.008), tot_loss_proj:3.091 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.240 (perp=5.740, rec=0.084, cos=0.008), tot_loss_proj:3.087 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
[1500/2000] tot_loss=1.239 (perp=5.740, rec=0.083, cos=0.008), tot_loss_proj:3.089 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.243 (perp=5.740, rec=0.087, cos=0.008), tot_loss_proj:3.085 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.242 (perp=5.740, rec=0.086, cos=0.008), tot_loss_proj:3.089 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
[1650/2000] tot_loss=1.244 (perp=5.740, rec=0.088, cos=0.008), tot_loss_proj:3.091 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.240 (perp=5.740, rec=0.084, cos=0.008), tot_loss_proj:3.087 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.247 (perp=5.740, rec=0.091, cos=0.008), tot_loss_proj:3.092 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
[1800/2000] tot_loss=1.239 (perp=5.740, rec=0.083, cos=0.008), tot_loss_proj:3.089 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.247 (perp=5.740, rec=0.091, cos=0.008), tot_loss_proj:3.085 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.237 (perp=5.740, rec=0.081, cos=0.008), tot_loss_proj:3.084 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
[1950/2000] tot_loss=1.246 (perp=5.740, rec=0.090, cos=0.008), tot_loss_proj:3.086 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.247 (perp=5.740, rec=0.091, cos=0.008), tot_loss_proj:3.091 [t=0.30s]
prediction: ['[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]
========================
predicted: 
========================
[CLS] to this could have released gorbachev by information classic, but he chose not. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 73.333 | p: 73.333 | r: 73.333
rougeLsum  | fm: 73.333 | p: 73.333 | r: 73.333
r1fm+r2fm = 121.905

[Aggregate metrics]:
rouge1     | fm: 75.995 | p: 76.310 | r: 75.962
rouge2     | fm: 32.902 | p: 33.128 | r: 32.909
rougeL     | fm: 67.982 | p: 68.328 | r: 67.849
rougeLsum  | fm: 68.124 | p: 68.541 | r: 68.003
r1fm+r2fm = 108.898

input #36 time: 0:12:02 | total time: 7:23:53


Running input #37 of 100.
reference: 
========================
Kevin ate spaghetti with a spoon and Geordie did so too.
========================
average of cosine similarity 0.9989861409145956
highest_index [0]
highest [0.9989861409145956]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  4901,  8823, 26666,  2007,  1037, 15642,  1998, 20248, 17080,
          2063,  2106,  2061,  2205,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]']
[Init] best rec loss: 0.8637850284576416 for ['[CLS] grace extent first over maritime walked aria intake axis catcher dickinson twice tires serve [SEP]']
[Init] best rec loss: 0.8607911467552185 for ['[CLS] firingih bark programme powell colt angeles iangina warrant intention natural torontokind [SEP]']
[Init] best rec loss: 0.8605658411979675 for ['[CLS]ero [ around altitude filmboot warden net jonah jazz lifting hug01 brewing [SEP]']
[Init] best rec loss: 0.846188485622406 for ['[CLS]mini highfi farther chi odds three events sorts above having sounds 000var [SEP]']
[Init] best rec loss: 0.8417732119560242 for ['[CLS] * landed comic chapel forcefree! millions or rein detroit crewference wonders [SEP]']
[Init] best rec loss: 0.8298048973083496 for ['[CLS] jeff damn changed edition speak experience lying kam aviv translation violations originally bismarck accordance [SEP]']
[Init] best rec loss: 0.8181570768356323 for ['[CLS] clawtekdity auto bad which levels healingrum billyotto france persian professional [SEP]']
[Init] best rec loss: 0.8156529068946838 for ['[CLS] freed across suicide twicese woman dock ray organs vanguard piano forward prior number [SEP]']
[Init] best perm rec loss: 0.8152408599853516 for ['[CLS] twice suicidese vanguard prior piano forward freed woman number across ray dock organs [SEP]']
[Init] best perm rec loss: 0.8139317631721497 for ['[CLS] dock piano freed priorse organs number suicide woman across ray twice vanguard forward [SEP]']
[Init] best perm rec loss: 0.8137606382369995 for ['[CLS] dock woman across freed twicese prior organs vanguard ray forward number suicide piano [SEP]']
[Init] best perm rec loss: 0.8136605620384216 for ['[CLS] freed woman prior vanguard across dock number piano organsse ray forward suicide twice [SEP]']
[Init] best perm rec loss: 0.8120043277740479 for ['[CLS] organs suicide freed acrossse woman forward prior piano dock ray twice number vanguard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.978 (perp=12.458, rec=0.359, cos=0.127), tot_loss_proj:4.326 [t=0.29s]
prediction: ['[CLS]cture 0 [SEP] again birthday cooperation non otherwise adaptive geo did cnn usually oh [SEP]']
[ 100/2000] tot_loss=3.318 (perp=13.090, rec=0.460, cos=0.240), tot_loss_proj:4.420 [t=0.30s]
prediction: ['[CLS]se flaps image contrast extra spaghetti result because kevin geo did burkina involveder [SEP]']
[ 150/2000] tot_loss=2.807 (perp=11.911, rec=0.315, cos=0.110), tot_loss_proj:4.218 [t=0.30s]
prediction: ['[CLS]iso [ location has lunch spaghettiscope because. geo did chickenrdier [SEP]']
[ 200/2000] tot_loss=2.683 (perp=11.719, rec=0.269, cos=0.070), tot_loss_proj:4.194 [t=0.30s]
prediction: ['[CLS]rdi geo otherwise has dinner spaghettiscope too. geo did frequencyrdie [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.575 (perp=11.462, rec=0.231, cos=0.052), tot_loss_proj:4.106 [t=0.30s]
prediction: ['[CLS]rdi geo non has ate spaghettiscope too. geo did frequencyrdie [SEP]']
[ 300/2000] tot_loss=2.735 (perp=12.388, rec=0.215, cos=0.043), tot_loss_proj:4.251 [t=0.30s]
prediction: ['[CLS]rdi geo geo with spaghetti spaghetti results too. geo did frequencyrdie [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.561 (perp=11.069, rec=0.269, cos=0.078), tot_loss_proj:4.051 [t=0.30s]
prediction: ['[CLS] po +bation [UNK] non spaghetti spaghetti too. geo did ablerdie [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.223 (perp=9.737, rec=0.226, cos=0.049), tot_loss_proj:3.774 [t=0.30s]
prediction: ['[CLS] po [UNK] dinner + non spaghetti spaghetti too. kevin did sordie [SEP]']
[ 450/2000] tot_loss=2.200 (perp=9.716, rec=0.216, cos=0.040), tot_loss_proj:3.797 [t=0.30s]
prediction: ['[CLS] po clans dinner + non spaghetti spaghetti too. kevin did sordie [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.336 (perp=10.558, rec=0.186, cos=0.038), tot_loss_proj:3.931 [t=0.30s]
prediction: ['[CLS] spaghettiholder [UNK] + non spaghetti spaghetti too. kevin did sordie [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.272 (perp=10.192, rec=0.192, cos=0.042), tot_loss_proj:3.898 [t=0.30s]
prediction: ['[CLS] po gravitational + non spaghetti spaghetti too spaghetti. kevin did sordie [SEP]']
[ 600/2000] tot_loss=2.257 (perp=10.192, rec=0.182, cos=0.037), tot_loss_proj:3.896 [t=0.30s]
prediction: ['[CLS] po gravitational + non spaghetti spaghetti too spaghetti. kevin did sordie [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.097 (perp=9.409, rec=0.180, cos=0.036), tot_loss_proj:3.710 [t=0.30s]
prediction: ['[CLS] po too + non spaghetti spaghetti gravitational spaghetti. kevin did sordie [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.919 (perp=8.484, rec=0.182, cos=0.040), tot_loss_proj:3.521 [t=0.30s]
prediction: ['[CLS] too po + non spaghetti spaghetti snout spaghetti. kevin did sordie [SEP]']
[ 750/2000] tot_loss=1.905 (perp=8.484, rec=0.174, cos=0.034), tot_loss_proj:3.523 [t=0.30s]
prediction: ['[CLS] too po + non spaghetti spaghetti snout spaghetti. kevin did sordie [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.845 (perp=8.212, rec=0.170, cos=0.032), tot_loss_proj:3.477 [t=0.30s]
prediction: ['[CLS] too po + non spaghetti spaghetti spaghetti snout. kevin did sordie [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.760 (perp=7.661, rec=0.187, cos=0.040), tot_loss_proj:3.403 [t=0.30s]
prediction: ['[CLS] too po + non spaghetti spaghetti spaghetti convention. did kevin sordie [SEP]']
[ 900/2000] tot_loss=1.849 (perp=8.187, rec=0.178, cos=0.033), tot_loss_proj:3.521 [t=0.30s]
prediction: ['[CLS] too una + non spaghetti spaghetti spaghetti convention. did kevin sordie [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.836 (perp=8.187, rec=0.167, cos=0.031), tot_loss_proj:3.517 [t=0.30s]
prediction: ['[CLS] too una + non spaghetti spaghetti spaghetti convention. did kevin sordie [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.851 (perp=8.235, rec=0.172, cos=0.032), tot_loss_proj:3.504 [t=0.30s]
prediction: ['[CLS] too una + by spaghetti spaghetti spaghetti snout did. kevin sordie [SEP]']
[1050/2000] tot_loss=1.846 (perp=8.235, rec=0.169, cos=0.030), tot_loss_proj:3.502 [t=0.30s]
prediction: ['[CLS] too una + by spaghetti spaghetti spaghetti snout did. kevin sordie [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.912 (perp=8.630, rec=0.156, cos=0.030), tot_loss_proj:3.556 [t=0.30s]
prediction: ['[CLS] too una + by spaghetti spaghetti spaghetti tang did. kevin sordie [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.925 (perp=8.681, rec=0.160, cos=0.029), tot_loss_proj:3.573 [t=0.30s]
prediction: ['[CLS] too una + tang spaghetti spaghetti spaghetti with did. kevin sordie [SEP]']
[1200/2000] tot_loss=1.934 (perp=8.681, rec=0.169, cos=0.029), tot_loss_proj:3.577 [t=0.30s]
prediction: ['[CLS] too una + tang spaghetti spaghetti spaghetti with did. kevin sordie [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.890 (perp=8.541, rec=0.153, cos=0.029), tot_loss_proj:3.534 [t=0.30s]
prediction: ['[CLS] too una + tang spaghetti spaghetti spaghetti did with. kevin sordie [SEP]']
Attempt swap
[1300/2000] tot_loss=1.904 (perp=8.541, rec=0.168, cos=0.029), tot_loss_proj:3.535 [t=0.30s]
prediction: ['[CLS] too una + tang spaghetti spaghetti spaghetti did with. kevin sordie [SEP]']
[1350/2000] tot_loss=1.984 (perp=8.946, rec=0.167, cos=0.028), tot_loss_proj:3.619 [t=0.30s]
prediction: ['[CLS] too una + tang spaghetti spaghetti spaghetti did with. geo sordie [SEP]']
Attempt swap
[1400/2000] tot_loss=1.975 (perp=8.946, rec=0.158, cos=0.028), tot_loss_proj:3.615 [t=0.30s]
prediction: ['[CLS] too una + tang spaghetti spaghetti spaghetti did with. geo sordie [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.864 (perp=8.349, rec=0.164, cos=0.029), tot_loss_proj:3.473 [t=0.30s]
prediction: ['[CLS] too una + spaghetti spaghetti spaghetti convention did with. geo sordie [SEP]']
[1500/2000] tot_loss=1.852 (perp=8.349, rec=0.154, cos=0.028), tot_loss_proj:3.472 [t=0.30s]
prediction: ['[CLS] too una + spaghetti spaghetti spaghetti convention did with. geo sordie [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.924 (perp=8.559, rec=0.172, cos=0.040), tot_loss_proj:3.540 [t=0.30s]
prediction: ['[CLS] too a + spaghetti spoon spaghetti convention did with geo sordie. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.864 (perp=8.202, rec=0.181, cos=0.044), tot_loss_proj:3.464 [t=0.30s]
prediction: ['[CLS] too a + spaghetti spoon spaghetti convention did with so geordie. [SEP]']
[1650/2000] tot_loss=1.857 (perp=8.202, rec=0.174, cos=0.043), tot_loss_proj:3.461 [t=0.30s]
prediction: ['[CLS] too a + spaghetti spoon spaghetti convention did with so geordie. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.838 (perp=8.130, rec=0.168, cos=0.044), tot_loss_proj:3.449 [t=0.30s]
prediction: ['[CLS] too a by spaghetti spoon spaghetti convention did + so geordie. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.831 (perp=8.080, rec=0.169, cos=0.046), tot_loss_proj:3.429 [t=0.30s]
prediction: ['[CLS] too una spoon by spaghetti spaghetti convention did + so geordie. [SEP]']
[1800/2000] tot_loss=1.849 (perp=8.080, rec=0.184, cos=0.049), tot_loss_proj:3.430 [t=0.30s]
prediction: ['[CLS] too una spoon by spaghetti spaghetti convention did + so geordie. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.830 (perp=8.080, rec=0.163, cos=0.052), tot_loss_proj:3.433 [t=0.30s]
prediction: ['[CLS] too una spoon by spaghetti spaghetti convention did + so geordie. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.689 (perp=7.343, rec=0.169, cos=0.052), tot_loss_proj:3.279 [t=0.30s]
prediction: ['[CLS] too a spoon by spaghetti spaghetti convention did + so geordie. [SEP]']
[1950/2000] tot_loss=1.692 (perp=7.343, rec=0.171, cos=0.052), tot_loss_proj:3.275 [t=0.30s]
prediction: ['[CLS] too a spoon by spaghetti spaghetti convention did + so geordie. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.696 (perp=7.343, rec=0.172, cos=0.055), tot_loss_proj:3.275 [t=0.30s]
prediction: ['[CLS] too a spoon by spaghetti spaghetti convention did + so geordie. [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]
========================
predicted: 
========================
[CLS] too una + tang spaghetti spaghetti spaghetti did with. kevin sordie [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.000 | p: 58.333 | r: 53.846
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 32.000 | p: 33.333 | r: 30.769
rougeLsum  | fm: 32.000 | p: 33.333 | r: 30.769
r1fm+r2fm = 56.000

[Aggregate metrics]:
rouge1     | fm: 75.339 | p: 75.730 | r: 75.235
rouge2     | fm: 32.181 | p: 32.348 | r: 32.174
rougeL     | fm: 66.984 | p: 67.372 | r: 66.822
rougeLsum  | fm: 67.294 | p: 67.628 | r: 67.095
r1fm+r2fm = 107.520

input #37 time: 0:11:47 | total time: 7:35:41


Running input #38 of 100.
reference: 
========================
John is the kind of fool that I told you about.
========================
average of cosine similarity 0.9990076998857652
highest_index [0]
highest [0.9990076998857652]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2198, 2003, 1996, 2785, 1997, 7966, 2008, 1045, 2409, 2017, 2055,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is the kind of fool that i told you about. [SEP]']
[Init] best rec loss: 0.9842108488082886 for ['[CLS] medicine horns clear john splash treaties samson com credited birthplace ago managing [SEP]']
[Init] best rec loss: 0.9639290571212769 for ['[CLS]vance jace texas silk mid will ongative to important sweat prize [SEP]']
[Init] best rec loss: 0.9484790563583374 for ['[CLS] formal anymore fair more directlycz subgroup stalls up creekphobic planet [SEP]']
[Init] best rec loss: 0.9470811486244202 for ['[CLS] hanges for doin guardsaneous carolina vanmadeologist sat track [SEP]']
[Init] best rec loss: 0.9439336061477661 for ['[CLS] noel packed times courtesy combine hood word gestured ar repeat europe enough [SEP]']
[Init] best rec loss: 0.9338637590408325 for ['[CLS]igan scott taya rhetoric beau wta just portraying do speed march [SEP]']
[Init] best perm rec loss: 0.9324958324432373 for ['[CLS]aya wta speed just rhetoric march t scott portrayingigan beau do [SEP]']
[Init] best perm rec loss: 0.9308426976203918 for ['[CLS] rhetoric t scott wta portrayingiganaya speed beau do just march [SEP]']
[Init] best perm rec loss: 0.9302598237991333 for ['[CLS] rhetoric just t scott portraying beauaya wtaigan speed march do [SEP]']
[Init] best perm rec loss: 0.9288341999053955 for ['[CLS] wta justigan beau scott t rhetoricaya do march speed portraying [SEP]']
[Init] best perm rec loss: 0.92774897813797 for ['[CLS] do t just portraying wta scottaya march beau speed rhetoricigan [SEP]']
[Init] best perm rec loss: 0.9264054894447327 for ['[CLS] scott just portraying wta marchigan do beau speedaya rhetoric t [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.325 (perp=9.986, rec=0.508, cos=0.820), tot_loss_proj:3.834 [t=0.29s]
prediction: ['[CLS] would. - prixwords the fool species guard ) among. [SEP]']
[ 100/2000] tot_loss=2.836 (perp=7.857, rec=0.460, cos=0.805), tot_loss_proj:3.489 [t=0.30s]
prediction: ['[CLS] fool. - fool of the fool types fence about.. [SEP]']
[ 150/2000] tot_loss=2.709 (perp=7.624, rec=0.413, cos=0.771), tot_loss_proj:3.377 [t=0.30s]
prediction: ['[CLS] fool. - fool of the fool fool sounded about.. [SEP]']
[ 200/2000] tot_loss=2.934 (perp=8.770, rec=0.391, cos=0.789), tot_loss_proj:3.592 [t=0.30s]
prediction: ['[CLS] fool. of fool of the fool foolclops bullshit.. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.799 (perp=10.816, rec=0.719, cos=0.916), tot_loss_proj:4.047 [t=0.30s]
prediction: ['[CLS] fool. fool horrible fool of.baldi treaty supplies checkpoint. [SEP]']
[ 300/2000] tot_loss=3.729 (perp=11.126, rec=0.591, cos=0.913), tot_loss_proj:3.994 [t=0.30s]
prediction: ['[CLS] fool. fool magnitude discs of. federation unfortunately teaching checkpoint. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.197 (perp=9.614, rec=0.487, cos=0.787), tot_loss_proj:3.712 [t=0.30s]
prediction: ['[CLS] fool. fool. of of magnitude federation hartaա appoint. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.265 (perp=10.133, rec=0.456, cos=0.783), tot_loss_proj:3.856 [t=0.30s]
prediction: ['[CLS] fool. fool & of magnitude of type hartatsu ordained. [SEP]']
[ 450/2000] tot_loss=3.152 (perp=9.629, rec=0.422, cos=0.804), tot_loss_proj:3.676 [t=0.30s]
prediction: ['[CLS] fool. fool & of magnitude of fool smashwords acheron ordained. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.023 (perp=8.973, rec=0.420, cos=0.808), tot_loss_proj:3.535 [t=0.30s]
prediction: ['[CLS] fool. & fool of coup of fool smashwords layla ordained. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.820 (perp=8.059, rec=0.414, cos=0.794), tot_loss_proj:3.337 [t=0.30s]
prediction: ['[CLS] sort. the fool of fool of fool smashwords layla ordained. [SEP]']
[ 600/2000] tot_loss=2.838 (perp=8.059, rec=0.397, cos=0.830), tot_loss_proj:3.340 [t=0.30s]
prediction: ['[CLS] sort. the fool of fool of fool smashwords layla ordained. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.741 (perp=7.776, rec=0.388, cos=0.798), tot_loss_proj:3.312 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool smashwordsyra ordained. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.754 (perp=7.940, rec=0.381, cos=0.786), tot_loss_proj:3.522 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool smashwordsyrahort. [SEP]']
[ 750/2000] tot_loss=2.800 (perp=7.832, rec=0.389, cos=0.845), tot_loss_proj:3.496 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool smashwordsrocityhort. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.753 (perp=7.849, rec=0.375, cos=0.808), tot_loss_proj:3.446 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool smashwords recordingshort. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.687 (perp=7.638, rec=0.366, cos=0.793), tot_loss_proj:3.336 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool kinds recordingshort. [SEP]']
[ 900/2000] tot_loss=2.664 (perp=7.613, rec=0.365, cos=0.777), tot_loss_proj:3.364 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool http recordingshort. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.728 (perp=7.613, rec=0.386, cos=0.820), tot_loss_proj:3.360 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool http recordingshort. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.717 (perp=7.613, rec=0.376, cos=0.819), tot_loss_proj:3.360 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool http recordingshort. [SEP]']
[1050/2000] tot_loss=2.758 (perp=7.777, rec=0.384, cos=0.819), tot_loss_proj:3.400 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool http laylahort. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.761 (perp=7.782, rec=0.367, cos=0.837), tot_loss_proj:3.383 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool http layla genes. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.762 (perp=7.782, rec=0.379, cos=0.826), tot_loss_proj:3.390 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool http layla genes. [SEP]']
[1200/2000] tot_loss=2.749 (perp=7.782, rec=0.375, cos=0.818), tot_loss_proj:3.389 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool http layla genes. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.746 (perp=7.782, rec=0.365, cos=0.825), tot_loss_proj:3.388 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool http layla genes. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.749 (perp=7.782, rec=0.376, cos=0.817), tot_loss_proj:3.384 [t=0.30s]
prediction: ['[CLS] the sort. fool of fool of fool http layla genes. [SEP]']
[1350/2000] tot_loss=3.099 (perp=9.537, rec=0.370, cos=0.821), tot_loss_proj:3.679 [t=0.30s]
prediction: ['[CLS] the sort. fool of badly of fool http layla genes. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.876 (perp=8.366, rec=0.375, cos=0.827), tot_loss_proj:3.467 [t=0.30s]
prediction: ['[CLS] the sort. fool of badly fool of http layla tomorrow. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.795 (perp=8.026, rec=0.369, cos=0.820), tot_loss_proj:3.387 [t=0.30s]
prediction: ['[CLS] the sort of fool. badly fool of http layla tomorrow. [SEP]']
[1500/2000] tot_loss=2.793 (perp=8.026, rec=0.365, cos=0.824), tot_loss_proj:3.389 [t=0.30s]
prediction: ['[CLS] the sort of fool. badly fool of http layla tomorrow. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.796 (perp=8.026, rec=0.369, cos=0.822), tot_loss_proj:3.388 [t=0.30s]
prediction: ['[CLS] the sort of fool. badly fool of http layla tomorrow. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.741 (perp=7.743, rec=0.369, cos=0.824), tot_loss_proj:3.430 [t=0.30s]
prediction: ['[CLS] the sort of fool. of fool badly http layla tomorrow. [SEP]']
[1650/2000] tot_loss=2.740 (perp=7.743, rec=0.377, cos=0.814), tot_loss_proj:3.430 [t=0.30s]
prediction: ['[CLS] the sort of fool. of fool badly http layla tomorrow. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.732 (perp=7.743, rec=0.373, cos=0.810), tot_loss_proj:3.431 [t=0.30s]
prediction: ['[CLS] the sort of fool. of fool badly http layla tomorrow. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.721 (perp=7.743, rec=0.359, cos=0.814), tot_loss_proj:3.432 [t=0.30s]
prediction: ['[CLS] the sort of fool. of fool badly http layla tomorrow. [SEP]']
[1800/2000] tot_loss=2.713 (perp=7.743, rec=0.349, cos=0.816), tot_loss_proj:3.436 [t=0.30s]
prediction: ['[CLS] the sort of fool. of fool badly http layla tomorrow. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.715 (perp=7.743, rec=0.353, cos=0.814), tot_loss_proj:3.426 [t=0.30s]
prediction: ['[CLS] the sort of fool. of fool badly http layla tomorrow. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.724 (perp=7.743, rec=0.364, cos=0.812), tot_loss_proj:3.432 [t=0.30s]
prediction: ['[CLS] the sort of fool. of fool badly http layla tomorrow. [SEP]']
[1950/2000] tot_loss=2.728 (perp=7.743, rec=0.363, cos=0.816), tot_loss_proj:3.437 [t=0.30s]
prediction: ['[CLS] the sort of fool. of fool badly http layla tomorrow. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.729 (perp=7.743, rec=0.368, cos=0.813), tot_loss_proj:3.434 [t=0.30s]
prediction: ['[CLS] the sort of fool. of fool badly http layla tomorrow. [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] john is the kind of fool that i told you about. [SEP]
========================
predicted: 
========================
[CLS] the sort of fool. of fool badly http layla tomorrow. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 41.667 | r: 38.462
rouge2     | fm: 8.696 | p: 9.091 | r: 8.333
rougeL     | fm: 40.000 | p: 41.667 | r: 38.462
rougeLsum  | fm: 40.000 | p: 41.667 | r: 38.462
r1fm+r2fm = 48.696

[Aggregate metrics]:
rouge1     | fm: 74.470 | p: 74.889 | r: 74.248
rouge2     | fm: 31.498 | p: 31.577 | r: 31.538
rougeL     | fm: 66.211 | p: 66.635 | r: 65.989
rougeLsum  | fm: 66.654 | p: 67.110 | r: 66.368
r1fm+r2fm = 105.969

input #38 time: 0:11:47 | total time: 7:47:29


Running input #39 of 100.
reference: 
========================
I doubt if you can help me in understanding this.
========================
average of cosine similarity 0.9989749684482698
highest_index [0]
highest [0.9989749684482698]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 1045, 4797, 2065, 2017, 2064, 2393, 2033, 1999, 4824, 2023, 1012,
          102]], device='cuda:0')
Debug: ref = ['[CLS] i doubt if you can help me in understanding this. [SEP]']
[Init] best rec loss: 0.9303711652755737 for ['[CLS] probably issue jade aren circumstances day old mayohum asian belonging [SEP]']
[Init] best rec loss: 0.9278091192245483 for ['[CLS] ke radio n metal light full composition alreadyfia lucappy [SEP]']
[Init] best rec loss: 0.9239587187767029 for ['[CLS] cup expression population cody stands news tofide stationmun relief [SEP]']
[Init] best rec loss: 0.92339026927948 for ['[CLS] good fan coil miles zane lead commercials soprano artists han recounts [SEP]']
[Init] best rec loss: 0.9232282042503357 for ['[CLS] legislature exploits mit alice didn tubes true mountvity lane animal [SEP]']
[Init] best rec loss: 0.9080950617790222 for ['[CLS] teddytr burst counted multiple bastard axe trade nervous sera folk [SEP]']
[Init] best rec loss: 0.893539547920227 for ['[CLS]ized colonial bloom unclelat terrestrial vs [SEP] special media infancy [SEP]']
[Init] best perm rec loss: 0.8925693035125732 for ['[CLS]ized colonial infancy unclelat bloom media terrestrial special vs [SEP] [SEP]']
[Init] best perm rec loss: 0.8891218900680542 for ['[CLS] media infancy special terrestrial [SEP] unclelat bloom vsized colonial [SEP]']
[Init] best perm rec loss: 0.8890976309776306 for ['[CLS] infancy media uncle terrestrial bloom [SEP] vs specialized coloniallat [SEP]']
[Init] best perm rec loss: 0.8866792917251587 for ['[CLS] media bloom infancylat terrestrial special vs [SEP]ized uncle colonial [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.047 (perp=11.918, rec=0.668, cos=0.995), tot_loss_proj:4.185 [t=0.29s]
prediction: ['[CLS] position. bay lance your ^ ii from june contemporary villas [SEP]']
[ 100/2000] tot_loss=3.837 (perp=11.314, rec=0.608, cos=0.966), tot_loss_proj:3.991 [t=0.30s]
prediction: ['[CLS] perhaps after during reservemost wide× from thus developed occasionally [SEP]']
[ 150/2000] tot_loss=4.391 (perp=14.457, rec=0.555, cos=0.945), tot_loss_proj:4.651 [t=0.30s]
prediction: ['[CLS] tortricidae par ass doublesqui moment jon from destroyer can ـ [SEP]']
[ 200/2000] tot_loss=2.940 (perp=11.423, rec=0.457, cos=0.198), tot_loss_proj:4.051 [t=0.30s]
prediction: ['[CLS]ffled ha if gratitude award moment di. ta your. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.801 (perp=11.553, rec=0.377, cos=0.114), tot_loss_proj:4.073 [t=0.30s]
prediction: ['[CLS]ɴero if help. continuous your endurance award non robson [SEP]']
[ 300/2000] tot_loss=2.511 (perp=10.602, rec=0.323, cos=0.067), tot_loss_proj:3.849 [t=0.30s]
prediction: ['[CLS] you differently if help. continuous your desperation smile non miriam [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.769 (perp=11.661, rec=0.344, cos=0.092), tot_loss_proj:4.028 [t=0.30s]
prediction: ['[CLS] you though if lay helpxi let swimming.anum— [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.567 (perp=10.999, rec=0.303, cos=0.064), tot_loss_proj:3.924 [t=0.30s]
prediction: ['[CLS] you though if lay helpxi gift. let this— [SEP]']
[ 450/2000] tot_loss=2.442 (perp=10.535, rec=0.288, cos=0.047), tot_loss_proj:3.868 [t=0.30s]
prediction: ['[CLS] you though if lay help jax study. let this— [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.548 (perp=11.272, rec=0.258, cos=0.036), tot_loss_proj:3.988 [t=0.30s]
prediction: ['[CLS] you this if lay help understand study. let unto— [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.256 (perp=9.779, rec=0.259, cos=0.041), tot_loss_proj:3.789 [t=0.30s]
prediction: ['[CLS] you study if lay help understand this. let unto— [SEP]']
[ 600/2000] tot_loss=2.302 (perp=10.085, rec=0.253, cos=0.031), tot_loss_proj:3.744 [t=0.30s]
prediction: ['[CLS] you understanding if lay help understand this. let und— [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.070 (perp=9.009, rec=0.239, cos=0.029), tot_loss_proj:3.532 [t=0.30s]
prediction: ['[CLS] you understanding if lay help do this. let— und [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.493 (perp=10.533, rec=0.332, cos=0.055), tot_loss_proj:3.832 [t=0.30s]
prediction: ['[CLS] you understanding if let help http this, lay focused und [SEP]']
[ 750/2000] tot_loss=2.549 (perp=11.264, rec=0.260, cos=0.037), tot_loss_proj:4.021 [t=0.30s]
prediction: ['[CLS] you understanding doubt let help http this, your focused und [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.349 (perp=10.365, rec=0.242, cos=0.033), tot_loss_proj:3.837 [t=0.30s]
prediction: ['[CLS] you understanding doubt let help http this. your und focused [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.039 (perp=8.864, rec=0.235, cos=0.032), tot_loss_proj:3.567 [t=0.30s]
prediction: ['[CLS] understanding you doubt let help do this. your und focused [SEP]']
[ 900/2000] tot_loss=2.041 (perp=8.864, rec=0.237, cos=0.031), tot_loss_proj:3.564 [t=0.30s]
prediction: ['[CLS] understanding you doubt let help do this. your und focused [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.919 (perp=8.286, rec=0.232, cos=0.030), tot_loss_proj:3.607 [t=0.30s]
prediction: ['[CLS] understanding you doubt could help do this. your und focused [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.895 (perp=8.191, rec=0.228, cos=0.029), tot_loss_proj:3.506 [t=0.30s]
prediction: ['[CLS] understanding you doubt could help do this focused your und. [SEP]']
[1050/2000] tot_loss=2.059 (perp=9.025, rec=0.226, cos=0.028), tot_loss_proj:3.570 [t=0.30s]
prediction: ['[CLS] understanding you doubt could help do in focused your und. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.977 (perp=8.738, rec=0.202, cos=0.028), tot_loss_proj:3.523 [t=0.30s]
prediction: ['[CLS] understanding you doubt could help do in your und. focused [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.884 (perp=8.190, rec=0.218, cos=0.028), tot_loss_proj:3.364 [t=0.30s]
prediction: ['[CLS] understanding doubt you could help do in your und. focused [SEP]']
[1200/2000] tot_loss=1.863 (perp=8.142, rec=0.208, cos=0.027), tot_loss_proj:3.510 [t=0.30s]
prediction: ['[CLS] understanding doubt you could help understand in your und. focused [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.671 (perp=7.184, rec=0.206, cos=0.028), tot_loss_proj:3.264 [t=0.30s]
prediction: ['[CLS] understanding doubt you could help understand in your und focused. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.674 (perp=7.184, rec=0.210, cos=0.027), tot_loss_proj:3.261 [t=0.30s]
prediction: ['[CLS] understanding doubt you could help understand in your und focused. [SEP]']
[1350/2000] tot_loss=1.622 (perp=7.000, rec=0.195, cos=0.027), tot_loss_proj:3.237 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in your und focused. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.627 (perp=7.000, rec=0.200, cos=0.027), tot_loss_proj:3.236 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in your und focused. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.623 (perp=7.000, rec=0.196, cos=0.027), tot_loss_proj:3.235 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in your und focused. [SEP]']
[1500/2000] tot_loss=1.624 (perp=7.000, rec=0.197, cos=0.027), tot_loss_proj:3.230 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in your und focused. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.629 (perp=7.000, rec=0.202, cos=0.027), tot_loss_proj:3.235 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in your und focused. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.625 (perp=7.000, rec=0.198, cos=0.027), tot_loss_proj:3.236 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in your und focused. [SEP]']
[1650/2000] tot_loss=1.677 (perp=7.289, rec=0.193, cos=0.027), tot_loss_proj:3.268 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in an und focused. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.686 (perp=7.289, rec=0.202, cos=0.027), tot_loss_proj:3.267 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in an und focused. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.776 (perp=7.747, rec=0.200, cos=0.027), tot_loss_proj:3.305 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in an und corporate. [SEP]']
[1800/2000] tot_loss=1.757 (perp=7.747, rec=0.181, cos=0.026), tot_loss_proj:3.307 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in an und corporate. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.765 (perp=7.747, rec=0.189, cos=0.026), tot_loss_proj:3.308 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in an und corporate. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.767 (perp=7.747, rec=0.192, cos=0.026), tot_loss_proj:3.308 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in an und corporate. [SEP]']
[1950/2000] tot_loss=1.762 (perp=7.747, rec=0.186, cos=0.026), tot_loss_proj:3.306 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in an und corporate. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.765 (perp=7.747, rec=0.189, cos=0.026), tot_loss_proj:3.307 [t=0.30s]
prediction: ['[CLS] understanding doubt you can help understand in an und corporate. [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] i doubt if you can help me in understanding this. [SEP]
========================
predicted: 
========================
[CLS] understanding doubt you can help understand in an und corporate. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 18.182 | p: 18.182 | r: 18.182
rougeL     | fm: 58.333 | p: 58.333 | r: 58.333
rougeLsum  | fm: 58.333 | p: 58.333 | r: 58.333
r1fm+r2fm = 84.848

[Aggregate metrics]:
rouge1     | fm: 74.328 | p: 74.663 | r: 74.236
rouge2     | fm: 31.065 | p: 31.211 | r: 31.249
rougeL     | fm: 66.123 | p: 66.568 | r: 65.952
rougeLsum  | fm: 66.304 | p: 66.742 | r: 66.087
r1fm+r2fm = 105.394

input #39 time: 0:11:48 | total time: 7:59:17


Running input #40 of 100.
reference: 
========================
Was the child running to the car?
========================
average of cosine similarity 0.9988186392979657
highest_index [0]
highest [0.9988186392979657]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2001, 1996, 2775, 2770, 2000, 1996, 2482, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] was the child running to the car? [SEP]']
[Init] best rec loss: 0.9554435014724731 for ['[CLS]chfield only loan mast lust nape " nearly [SEP]']
[Init] best rec loss: 0.9404564499855042 for ['[CLS]typic races investigation singular haven boreay libby [SEP]']
[Init] best rec loss: 0.922642171382904 for ['[CLS] priestale either uc media economic, directions [SEP]']
[Init] best rec loss: 0.8932816386222839 for ['[CLS] standing colonyhers angry isn [SEP] women waste [SEP]']
[Init] best rec loss: 0.8848027586936951 for ['[CLS] competition gothic maya skin duke each mascara plenty [SEP]']
[Init] best perm rec loss: 0.8834856748580933 for ['[CLS] duke skin mascara gothic competition plenty maya each [SEP]']
[Init] best perm rec loss: 0.8833465576171875 for ['[CLS] each maya plenty skin duke gothic mascara competition [SEP]']
[Init] best perm rec loss: 0.8830820322036743 for ['[CLS] gothic competition maya skin mascara each plenty duke [SEP]']
[Init] best perm rec loss: 0.8808877468109131 for ['[CLS] gothic competition duke plenty skin maya mascara each [SEP]']
[Init] best perm rec loss: 0.8807149529457092 for ['[CLS] skin gothic maya competition mascara each plenty duke [SEP]']
[Init] best perm rec loss: 0.879717230796814 for ['[CLS] competition plenty maya skin mascara each gothic duke [SEP]']
[Init] best perm rec loss: 0.8774833679199219 for ['[CLS] skin plenty gothic maya each competition mascara duke [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.617 (perp=10.675, rec=0.582, cos=0.900), tot_loss_proj:4.082 [t=0.29s]
prediction: ['[CLS] 2012 railways killer vehicle inter car towing ; [SEP]']
[ 100/2000] tot_loss=3.581 (perp=10.448, rec=0.597, cos=0.894), tot_loss_proj:4.004 [t=0.29s]
prediction: ['[CLS] : racehorse is storyline extra beaten final ; [SEP]']
[ 150/2000] tot_loss=3.461 (perp=10.678, rec=0.455, cos=0.870), tot_loss_proj:4.104 [t=0.30s]
prediction: ['[CLS] was racehorse often vehicle the car child? [SEP]']
[ 200/2000] tot_loss=3.357 (perp=9.958, rec=0.445, cos=0.920), tot_loss_proj:3.912 [t=0.30s]
prediction: ['[CLS] was racehorse running vehicle the car child? [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.144 (perp=9.646, rec=0.448, cos=0.767), tot_loss_proj:3.881 [t=0.30s]
prediction: ['[CLS] was printing running the triple prospect child? [SEP]']
[ 300/2000] tot_loss=3.082 (perp=9.827, rec=0.340, cos=0.777), tot_loss_proj:3.915 [t=0.30s]
prediction: ['[CLS] was printing running the fucking car child? [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.849 (perp=8.794, rec=0.319, cos=0.771), tot_loss_proj:3.734 [t=0.30s]
prediction: ['[CLS] was fucking running the printing car child? [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.009 (perp=9.682, rec=0.281, cos=0.792), tot_loss_proj:3.798 [t=0.30s]
prediction: ['[CLS] was car the tablet running car child? [SEP]']
[ 450/2000] tot_loss=3.003 (perp=9.682, rec=0.275, cos=0.792), tot_loss_proj:3.796 [t=0.30s]
prediction: ['[CLS] was car the tablet running car child? [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.769 (perp=8.507, rec=0.263, cos=0.804), tot_loss_proj:3.637 [t=0.30s]
prediction: ['[CLS] was the car tablet running car child? [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.704 (perp=8.269, rec=0.255, cos=0.795), tot_loss_proj:3.532 [t=0.30s]
prediction: ['[CLS] was the car flight running child car? [SEP]']
[ 600/2000] tot_loss=2.695 (perp=8.269, rec=0.253, cos=0.788), tot_loss_proj:3.525 [t=0.30s]
prediction: ['[CLS] was the car flight running child car? [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.617 (perp=7.922, rec=0.246, cos=0.787), tot_loss_proj:3.508 [t=0.30s]
prediction: ['[CLS] was the tablet car running child car? [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.509 (perp=7.365, rec=0.247, cos=0.789), tot_loss_proj:3.410 [t=0.30s]
prediction: ['[CLS] was the computer car running child car? [SEP]']
[ 750/2000] tot_loss=2.493 (perp=7.365, rec=0.243, cos=0.777), tot_loss_proj:3.409 [t=0.30s]
prediction: ['[CLS] was the computer car running child car? [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.498 (perp=7.365, rec=0.241, cos=0.784), tot_loss_proj:3.413 [t=0.30s]
prediction: ['[CLS] was the computer car running child car? [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.516 (perp=7.365, rec=0.241, cos=0.802), tot_loss_proj:3.406 [t=0.30s]
prediction: ['[CLS] was the computer car running child car? [SEP]']
[ 900/2000] tot_loss=2.793 (perp=8.762, rec=0.242, cos=0.799), tot_loss_proj:3.662 [t=0.30s]
prediction: ['[CLS] was thek car running child car? [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.572 (perp=7.765, rec=0.231, cos=0.788), tot_loss_proj:3.534 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1000/2000] tot_loss=2.571 (perp=7.765, rec=0.226, cos=0.792), tot_loss_proj:3.534 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
[1050/2000] tot_loss=2.571 (perp=7.765, rec=0.225, cos=0.793), tot_loss_proj:3.538 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1100/2000] tot_loss=2.579 (perp=7.765, rec=0.237, cos=0.789), tot_loss_proj:3.532 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1150/2000] tot_loss=2.600 (perp=7.765, rec=0.242, cos=0.805), tot_loss_proj:3.539 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
[1200/2000] tot_loss=2.580 (perp=7.765, rec=0.233, cos=0.794), tot_loss_proj:3.538 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1250/2000] tot_loss=2.579 (perp=7.765, rec=0.234, cos=0.793), tot_loss_proj:3.533 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1300/2000] tot_loss=2.578 (perp=7.765, rec=0.234, cos=0.791), tot_loss_proj:3.535 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
[1350/2000] tot_loss=2.580 (perp=7.765, rec=0.243, cos=0.784), tot_loss_proj:3.540 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1400/2000] tot_loss=2.574 (perp=7.765, rec=0.233, cos=0.788), tot_loss_proj:3.532 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1450/2000] tot_loss=2.576 (perp=7.765, rec=0.236, cos=0.786), tot_loss_proj:3.534 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
[1500/2000] tot_loss=2.577 (perp=7.765, rec=0.232, cos=0.792), tot_loss_proj:3.537 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1550/2000] tot_loss=2.573 (perp=7.765, rec=0.234, cos=0.786), tot_loss_proj:3.534 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1600/2000] tot_loss=2.574 (perp=7.765, rec=0.234, cos=0.787), tot_loss_proj:3.539 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
[1650/2000] tot_loss=2.587 (perp=7.765, rec=0.249, cos=0.785), tot_loss_proj:3.538 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1700/2000] tot_loss=2.574 (perp=7.765, rec=0.232, cos=0.789), tot_loss_proj:3.537 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1750/2000] tot_loss=2.568 (perp=7.765, rec=0.229, cos=0.785), tot_loss_proj:3.537 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
[1800/2000] tot_loss=2.571 (perp=7.765, rec=0.229, cos=0.788), tot_loss_proj:3.529 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1850/2000] tot_loss=2.564 (perp=7.765, rec=0.225, cos=0.786), tot_loss_proj:3.530 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[1900/2000] tot_loss=2.583 (perp=7.765, rec=0.242, cos=0.788), tot_loss_proj:3.538 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
[1950/2000] tot_loss=2.567 (perp=7.765, rec=0.225, cos=0.789), tot_loss_proj:3.532 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Attempt swap
[2000/2000] tot_loss=2.570 (perp=7.765, rec=0.229, cos=0.788), tot_loss_proj:3.527 [t=0.30s]
prediction: ['[CLS] was the cark running child car? [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] was the child running to the car? [SEP]
========================
predicted: 
========================
[CLS] was the cark running child car? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 87.500 | r: 77.778
rouge2     | fm: 40.000 | p: 42.857 | r: 37.500
rougeL     | fm: 70.588 | p: 75.000 | r: 66.667
rougeLsum  | fm: 70.588 | p: 75.000 | r: 66.667
r1fm+r2fm = 122.353

[Aggregate metrics]:
rouge1     | fm: 74.505 | p: 75.023 | r: 74.270
rouge2     | fm: 31.443 | p: 31.718 | r: 31.392
rougeL     | fm: 66.126 | p: 66.675 | r: 65.838
rougeLsum  | fm: 66.456 | p: 67.011 | r: 66.146
r1fm+r2fm = 105.949

input #40 time: 0:11:48 | total time: 8:11:05


Running input #41 of 100.
reference: 
========================
Mary is shorter than five feet.
========================
average of cosine similarity 0.9988760456155465
highest_index [0]
highest [0.9988760456155465]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2984, 2003, 7820, 2084, 2274, 2519, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] mary is shorter than five feet. [SEP]']
[Init] best rec loss: 0.8722861409187317 for ['[CLS] try formerly doneicz gmina away originals [SEP]']
[Init] best rec loss: 0.8620820641517639 for ['[CLS]uration resemble spent os moment hearing yo [SEP]']
[Init] best rec loss: 0.8410100936889648 for ['[CLS] optionicated wherehausen fact reflection feel [SEP]']
[Init] best rec loss: 0.8409613370895386 for ['[CLS] non completing 0 string page families space [SEP]']
[Init] best perm rec loss: 0.84006267786026 for ['[CLS] string non space completing families 0 page [SEP]']
[Init] best perm rec loss: 0.8373082280158997 for ['[CLS] families non page string completing space 0 [SEP]']
[Init] best perm rec loss: 0.8355739116668701 for ['[CLS] families completing non string 0 page space [SEP]']
[Init] best perm rec loss: 0.8339893221855164 for ['[CLS] page completing non string space 0 families [SEP]']
[Init] best perm rec loss: 0.8339876532554626 for ['[CLS] page space non string completing 0 families [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.651 (perp=10.942, rec=0.368, cos=0.096), tot_loss_proj:4.010 [t=0.29s]
prediction: ['[CLS] rum bird pencil three by is five [SEP]']
[ 100/2000] tot_loss=2.072 (perp=9.221, rec=0.202, cos=0.026), tot_loss_proj:3.761 [t=0.30s]
prediction: ['[CLS] mary is shorter five shorter than feet [SEP]']
[ 150/2000] tot_loss=1.997 (perp=9.221, rec=0.130, cos=0.022), tot_loss_proj:3.753 [t=0.30s]
prediction: ['[CLS] mary is shorter five shorter than feet [SEP]']
[ 200/2000] tot_loss=1.953 (perp=9.221, rec=0.097, cos=0.012), tot_loss_proj:3.752 [t=0.30s]
prediction: ['[CLS] mary is shorter five shorter than feet [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.498 (perp=6.971, rec=0.093, cos=0.011), tot_loss_proj:2.729 [t=0.30s]
prediction: ['[CLS] mary is shorter than five shorter feet [SEP]']
[ 300/2000] tot_loss=1.488 (perp=6.971, rec=0.083, cos=0.011), tot_loss_proj:2.732 [t=0.30s]
prediction: ['[CLS] mary is shorter than five shorter feet [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.312 (perp=6.104, rec=0.080, cos=0.011), tot_loss_proj:2.634 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.320 (perp=6.104, rec=0.089, cos=0.010), tot_loss_proj:2.637 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
[ 450/2000] tot_loss=1.311 (perp=6.104, rec=0.080, cos=0.010), tot_loss_proj:2.643 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.315 (perp=6.104, rec=0.085, cos=0.010), tot_loss_proj:2.650 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.312 (perp=6.104, rec=0.081, cos=0.010), tot_loss_proj:2.631 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
[ 600/2000] tot_loss=1.316 (perp=6.104, rec=0.086, cos=0.010), tot_loss_proj:2.636 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.309 (perp=6.104, rec=0.079, cos=0.010), tot_loss_proj:2.638 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.306 (perp=6.104, rec=0.076, cos=0.010), tot_loss_proj:2.639 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
[ 750/2000] tot_loss=1.313 (perp=6.104, rec=0.082, cos=0.010), tot_loss_proj:2.636 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.304 (perp=6.104, rec=0.073, cos=0.010), tot_loss_proj:2.637 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.307 (perp=6.104, rec=0.077, cos=0.010), tot_loss_proj:2.637 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
[ 900/2000] tot_loss=1.311 (perp=6.104, rec=0.081, cos=0.010), tot_loss_proj:2.640 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.306 (perp=6.104, rec=0.076, cos=0.010), tot_loss_proj:2.635 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1000/2000] tot_loss=1.308 (perp=6.104, rec=0.078, cos=0.010), tot_loss_proj:2.633 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
[1050/2000] tot_loss=1.306 (perp=6.104, rec=0.076, cos=0.009), tot_loss_proj:2.635 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1100/2000] tot_loss=1.310 (perp=6.104, rec=0.080, cos=0.009), tot_loss_proj:2.638 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1150/2000] tot_loss=1.301 (perp=6.104, rec=0.071, cos=0.009), tot_loss_proj:2.631 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
[1200/2000] tot_loss=1.303 (perp=6.104, rec=0.073, cos=0.009), tot_loss_proj:2.632 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1250/2000] tot_loss=1.308 (perp=6.104, rec=0.078, cos=0.009), tot_loss_proj:2.630 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1300/2000] tot_loss=1.313 (perp=6.104, rec=0.083, cos=0.009), tot_loss_proj:2.633 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
[1350/2000] tot_loss=1.310 (perp=6.104, rec=0.081, cos=0.009), tot_loss_proj:2.634 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1400/2000] tot_loss=1.307 (perp=6.104, rec=0.077, cos=0.009), tot_loss_proj:2.636 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1450/2000] tot_loss=1.305 (perp=6.104, rec=0.076, cos=0.009), tot_loss_proj:2.629 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
[1500/2000] tot_loss=1.307 (perp=6.104, rec=0.077, cos=0.009), tot_loss_proj:2.629 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1550/2000] tot_loss=1.305 (perp=6.104, rec=0.076, cos=0.009), tot_loss_proj:2.633 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1600/2000] tot_loss=1.305 (perp=6.104, rec=0.076, cos=0.009), tot_loss_proj:2.631 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
[1650/2000] tot_loss=1.307 (perp=6.104, rec=0.078, cos=0.008), tot_loss_proj:2.630 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1700/2000] tot_loss=1.311 (perp=6.104, rec=0.081, cos=0.008), tot_loss_proj:2.637 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1750/2000] tot_loss=1.313 (perp=6.104, rec=0.084, cos=0.008), tot_loss_proj:2.630 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
[1800/2000] tot_loss=1.314 (perp=6.104, rec=0.084, cos=0.008), tot_loss_proj:2.638 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1850/2000] tot_loss=1.305 (perp=6.104, rec=0.076, cos=0.008), tot_loss_proj:2.639 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[1900/2000] tot_loss=1.309 (perp=6.104, rec=0.079, cos=0.008), tot_loss_proj:2.645 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
[1950/2000] tot_loss=1.311 (perp=6.104, rec=0.082, cos=0.008), tot_loss_proj:2.638 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Attempt swap
[2000/2000] tot_loss=1.306 (perp=6.104, rec=0.077, cos=0.008), tot_loss_proj:2.640 [t=0.30s]
prediction: ['[CLS] mary is shorter than five feet shorter [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] mary is shorter than five feet. [SEP]
========================
predicted: 
========================
[CLS] mary is shorter than five feet shorter [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 80.000 | p: 75.000 | r: 85.714
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 174.118

[Aggregate metrics]:
rouge1     | fm: 74.898 | p: 75.272 | r: 74.784
rouge2     | fm: 32.497 | p: 32.575 | r: 32.651
rougeL     | fm: 66.791 | p: 67.185 | r: 66.630
rougeLsum  | fm: 67.033 | p: 67.477 | r: 66.801
r1fm+r2fm = 107.395

input #41 time: 0:11:48 | total time: 8:22:53


Running input #42 of 100.
reference: 
========================
She has enough of a problem as it is.
========================
average of cosine similarity 0.9987973033441571
highest_index [0]
highest [0.9987973033441571]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2016, 2038, 2438, 1997, 1037, 3291, 2004, 2009, 2003, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] she has enough of a problem as it is. [SEP]']
[Init] best rec loss: 0.8786073923110962 for ['[CLS] only shooter /press como solid togetherando ‑堂 [SEP]']
[Init] best rec loss: 0.859334409236908 for ['[CLS] listen stage razor doveyd conza study scratch taste [SEP]']
[Init] best rec loss: 0.8550315499305725 for ['[CLS] violence trees closed much multimament mall freedoms separated squeezed [SEP]']
[Init] best rec loss: 0.8421595096588135 for ['[CLS] flock claimed jon domestic intelligence climax everywhere coal still census [SEP]']
[Init] best rec loss: 0.8211846947669983 for ['[CLS] systems wear concertroids chanhyl since system rights because [SEP]']
[Init] best rec loss: 0.8200612664222717 for ['[CLS] south historic maya hayden宀 clerkion coverage former tuesday [SEP]']
[Init] best rec loss: 0.8122299909591675 for ['[CLS] nobel swore noah baseball well equivalent elbow pal gravityr [SEP]']
[Init] best rec loss: 0.802504301071167 for ['[CLS] deco celine / favoritective pass trades seemed allow artillery [SEP]']
[Init] best rec loss: 0.7947859168052673 for ['[CLS] into movement responsible huh belief hall safe representativepose fellow [SEP]']
[Init] best perm rec loss: 0.7924492359161377 for ['[CLS] representative into huh responsible safe hall belief movement fellowpose [SEP]']
[Init] best perm rec loss: 0.7917193174362183 for ['[CLS] fellow huh into safe responsible movement belief hallpose representative [SEP]']
[Init] best perm rec loss: 0.7900822758674622 for ['[CLS] belief into responsible safe hall movementpose representative fellow huh [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.473 (perp=10.064, rec=0.376, cos=0.084), tot_loss_proj:3.801 [t=0.29s]
prediction: ['[CLS] with alone having andy. its as problem. problems [SEP]']
[ 100/2000] tot_loss=2.491 (perp=9.018, rec=0.471, cos=0.217), tot_loss_proj:3.451 [t=0.30s]
prediction: ['[CLS] ) as. a as ; as additional segunda those [SEP]']
[ 150/2000] tot_loss=2.310 (perp=9.429, rec=0.346, cos=0.078), tot_loss_proj:3.351 [t=0.30s]
prediction: ['[CLS] ) as. a as view as additional segunda problem [SEP]']
[ 200/2000] tot_loss=2.320 (perp=9.971, rec=0.279, cos=0.047), tot_loss_proj:3.839 [t=0.30s]
prediction: ['[CLS] she as that a enough problem as problem segunda problem [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.065 (perp=9.026, rec=0.225, cos=0.034), tot_loss_proj:3.599 [t=0.30s]
prediction: ['[CLS] she as is a enough problem as banda problem problem [SEP]']
[ 300/2000] tot_loss=2.079 (perp=9.369, rec=0.182, cos=0.023), tot_loss_proj:3.618 [t=0.30s]
prediction: ['[CLS] she as is having enough problem of banda problem problem [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.013 (perp=9.223, rec=0.147, cos=0.021), tot_loss_proj:3.489 [t=0.30s]
prediction: ['[CLS] she as is has enough problem offree problem problem [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.010 (perp=9.253, rec=0.140, cos=0.020), tot_loss_proj:3.711 [t=0.30s]
prediction: ['[CLS] as she is has enough a of grandpa enough problem [SEP]']
[ 450/2000] tot_loss=1.921 (perp=8.884, rec=0.129, cos=0.016), tot_loss_proj:3.615 [t=0.30s]
prediction: ['[CLS] as she is has enough a of goodman enough problem [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.777 (perp=8.204, rec=0.121, cos=0.015), tot_loss_proj:3.440 [t=0.30s]
prediction: ['[CLS] as she is has enough a enough of goodman problem [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.778 (perp=8.204, rec=0.123, cos=0.014), tot_loss_proj:3.441 [t=0.30s]
prediction: ['[CLS] as she is has enough a enough of goodman problem [SEP]']
[ 600/2000] tot_loss=1.765 (perp=8.204, rec=0.111, cos=0.013), tot_loss_proj:3.443 [t=0.30s]
prediction: ['[CLS] as she is has enough a enough of goodman problem [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.664 (perp=7.712, rec=0.107, cos=0.014), tot_loss_proj:3.295 [t=0.30s]
prediction: ['[CLS] as she is has enough a enough problem of goodman [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.738 (perp=8.049, rec=0.115, cos=0.013), tot_loss_proj:3.411 [t=0.30s]
prediction: ['[CLS] as she is has enough a problem problem of goodman [SEP]']
[ 750/2000] tot_loss=1.729 (perp=8.049, rec=0.107, cos=0.013), tot_loss_proj:3.413 [t=0.30s]
prediction: ['[CLS] as she is has enough a problem problem of goodman [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.689 (perp=7.818, rec=0.112, cos=0.013), tot_loss_proj:3.391 [t=0.30s]
prediction: ['[CLS] as she is has enough a goodman problem of problem [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.740 (perp=8.135, rec=0.100, cos=0.012), tot_loss_proj:3.391 [t=0.30s]
prediction: ['[CLS] as she is has enough a goodman problem of enough [SEP]']
[ 900/2000] tot_loss=1.733 (perp=8.135, rec=0.094, cos=0.012), tot_loss_proj:3.393 [t=0.30s]
prediction: ['[CLS] as she is has enough a goodman problem of enough [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.684 (perp=7.858, rec=0.100, cos=0.012), tot_loss_proj:3.269 [t=0.30s]
prediction: ['[CLS] as she is has enough a enough problem offree [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.570 (perp=7.227, rec=0.109, cos=0.015), tot_loss_proj:2.972 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem offree [SEP]']
[1050/2000] tot_loss=1.589 (perp=7.380, rec=0.101, cos=0.013), tot_loss_proj:2.995 [t=0.30s]
prediction: ['[CLS] as she has enough is a problem problem offree [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.521 (perp=7.012, rec=0.106, cos=0.013), tot_loss_proj:2.800 [t=0.30s]
prediction: ['[CLS] as she has enough is a problem offree enough [SEP]']
Attempt swap
[1150/2000] tot_loss=1.521 (perp=7.012, rec=0.106, cos=0.013), tot_loss_proj:2.795 [t=0.30s]
prediction: ['[CLS] as she has enough is a problem offree enough [SEP]']
[1200/2000] tot_loss=1.517 (perp=7.012, rec=0.102, cos=0.012), tot_loss_proj:2.790 [t=0.30s]
prediction: ['[CLS] as she has enough is a problem offree enough [SEP]']
Attempt swap
[1250/2000] tot_loss=1.525 (perp=7.012, rec=0.110, cos=0.012), tot_loss_proj:2.798 [t=0.30s]
prediction: ['[CLS] as she has enough is a problem offree enough [SEP]']
Attempt swap
[1300/2000] tot_loss=1.518 (perp=7.012, rec=0.103, cos=0.012), tot_loss_proj:2.797 [t=0.30s]
prediction: ['[CLS] as she has enough is a problem offree enough [SEP]']
[1350/2000] tot_loss=1.516 (perp=7.012, rec=0.101, cos=0.012), tot_loss_proj:2.800 [t=0.30s]
prediction: ['[CLS] as she has enough is a problem offree enough [SEP]']
Attempt swap
[1400/2000] tot_loss=1.544 (perp=7.132, rec=0.105, cos=0.012), tot_loss_proj:3.100 [t=0.30s]
prediction: ['[CLS] as she has enough is a problem of griffin enough [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.489 (perp=6.869, rec=0.103, cos=0.012), tot_loss_proj:3.196 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
[1500/2000] tot_loss=1.486 (perp=6.869, rec=0.100, cos=0.012), tot_loss_proj:3.193 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
Attempt swap
[1550/2000] tot_loss=1.485 (perp=6.869, rec=0.100, cos=0.012), tot_loss_proj:3.193 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
Attempt swap
[1600/2000] tot_loss=1.484 (perp=6.869, rec=0.098, cos=0.012), tot_loss_proj:3.198 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
[1650/2000] tot_loss=1.482 (perp=6.869, rec=0.097, cos=0.012), tot_loss_proj:3.198 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
Attempt swap
[1700/2000] tot_loss=1.484 (perp=6.869, rec=0.098, cos=0.012), tot_loss_proj:3.192 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
Attempt swap
[1750/2000] tot_loss=1.483 (perp=6.869, rec=0.098, cos=0.012), tot_loss_proj:3.196 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
[1800/2000] tot_loss=1.492 (perp=6.869, rec=0.106, cos=0.012), tot_loss_proj:3.197 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
Attempt swap
[1850/2000] tot_loss=1.493 (perp=6.869, rec=0.107, cos=0.012), tot_loss_proj:3.195 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
Attempt swap
[1900/2000] tot_loss=1.475 (perp=6.869, rec=0.090, cos=0.011), tot_loss_proj:3.192 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
[1950/2000] tot_loss=1.479 (perp=6.869, rec=0.093, cos=0.011), tot_loss_proj:3.193 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
Attempt swap
[2000/2000] tot_loss=1.483 (perp=6.869, rec=0.098, cos=0.011), tot_loss_proj:3.197 [t=0.30s]
prediction: ['[CLS] as she has enough is a enough problem of griffin [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] she has enough of a problem as it is. [SEP]
========================
predicted: 
========================
[CLS] as she has enough is a problem offree enough [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 111.818

[Aggregate metrics]:
rouge1     | fm: 75.073 | p: 75.477 | r: 74.928
rouge2     | fm: 32.361 | p: 32.478 | r: 32.468
rougeL     | fm: 66.725 | p: 67.108 | r: 66.577
rougeLsum  | fm: 66.845 | p: 67.277 | r: 66.718
r1fm+r2fm = 107.433

input #42 time: 0:11:48 | total time: 8:34:41


Running input #43 of 100.
reference: 
========================
Every student has to come up with three arguments that show that some condition proposed by Bill is wrong.
========================
average of cosine similarity 0.9988822047245088
highest_index [0]
highest [0.9988822047245088]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[ 101, 2296, 3076, 2038, 2000, 2272, 2039, 2007, 2093, 9918, 2008, 2265,
         2008, 2070, 4650, 3818, 2011, 3021, 2003, 3308, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]']
[Init] best rec loss: 0.8849055767059326 for ['[CLS] unaffected peter interval sporting campaign singular relieved start shooting club helleche date operative either meredith occupied lamagee metals [SEP]']
[Init] best rec loss: 0.8691840767860413 for ['[CLS] age files corner full tide well not britishoatiface seed guys sounds element deeplybridge justice bass tailhar [SEP]']
[Init] best rec loss: 0.8681262135505676 for ['[CLS] purchases academia them spellman jinranglephonic on crowd artificial fellkm school [SEP] components wellsaginggirlshore [SEP]']
[Init] best rec loss: 0.8597094416618347 for ['[CLS] adults being metropolitan hydrarie protection stampsj afforded including cut gallant labor metaphor ark photographs drunk ethiopian north public [SEP]']
[Init] best rec loss: 0.8496249914169312 for ['[CLS] sky to best all proud dormresses ou toilet typical vice led factory surrounds patrick challengedus enoughvna iii [SEP]']
[Init] best rec loss: 0.8474400043487549 for ['[CLS] thesis acheron ought rural closelyoco sociologist to sunni whopheusolved case resistance score was irregularities steward inflation nectar [SEP]']
[Init] best rec loss: 0.8409029245376587 for ['[CLS] therehy algebratracted force chicks honored chevalier governors fat dalton st vitaminə mode diesel enzyme angelo seth olympus [SEP]']
[Init] best perm rec loss: 0.8379859924316406 for ['[CLS] chicks dalton honored chevalier enzyme fat there angeloə olympustracted force diesel sethhy st governors mode algebra vitamin [SEP]']
[Init] best perm rec loss: 0.833598792552948 for ['[CLS] there mode honored chicks chevalier angelo diesel forcehy st seth vitaminə fat algebra olympus governors dalton enzymetracted [SEP]']
[Init] best perm rec loss: 0.8335157632827759 for ['[CLS] force chicks honored sthy there olympus fat enzyme mode seth vitamintracted algebra chevalier dalton angelo governorsə diesel [SEP]']
[Init] best perm rec loss: 0.8311343193054199 for ['[CLS]hy there seth olympus governors enzyme honored force algebra chicks chevaliertractedə diesel dalton vitamin mode st angelo fat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.573 (perp=12.053, rec=0.454, cos=0.708), tot_loss_proj:4.285 [t=0.30s]
prediction: ['[CLS] ‖ front every bachelor increases ( proposal proposal turnsnable limits iowa anywhere! across protesters disappearing. forgiveness × [SEP]']
[ 100/2000] tot_loss=3.236 (perp=10.709, rec=0.388, cos=0.707), tot_loss_proj:3.954 [t=0.30s]
prediction: ['[CLS] which every every wife has ( hundred proposal leave argument guarantees that condition this proposed protesters disappearing,tility every [SEP]']
[ 150/2000] tot_loss=3.038 (perp=10.176, rec=0.322, cos=0.681), tot_loss_proj:3.867 [t=0.30s]
prediction: ['[CLS] which every every wife bill. viper arguments shows argument shows that condition ( on proposedeous,tility three [SEP]']
[ 200/2000] tot_loss=3.011 (perp=9.962, rec=0.289, cos=0.730), tot_loss_proj:3.835 [t=0.30s]
prediction: ['[CLS] every student every student bill. viper arguments shows argument shows that condition whether in proposed sector,tility three [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.158 (perp=10.811, rec=0.283, cos=0.713), tot_loss_proj:3.993 [t=0.30s]
prediction: ['[CLS] gotta every student student bill. down arguments upstairs argument shows up condition whether in proposed sector of inuit three [SEP]']
[ 300/2000] tot_loss=3.233 (perp=11.121, rec=0.273, cos=0.736), tot_loss_proj:4.010 [t=0.30s]
prediction: ['[CLS] gotta every student student bill. down arguments upstairs shown shows up condition whether bill proposed considerably of dignity three [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.066 (perp=10.322, rec=0.250, cos=0.752), tot_loss_proj:3.869 [t=0.30s]
prediction: ['[CLS] must every student student bill. many arguments upstairs show show up condition whether bill condition considerably dignity of three [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.072 (perp=10.195, rec=0.273, cos=0.761), tot_loss_proj:3.848 [t=0.30s]
prediction: ['[CLS] must every student student bill. some arguments copies show shows up condition is bill condition considerably with dignity three [SEP]']
[ 450/2000] tot_loss=2.974 (perp=9.813, rec=0.246, cos=0.765), tot_loss_proj:3.805 [t=0.30s]
prediction: ['[CLS] has every student student bill that with arguments upstairs show show up condition is bill condition considerably with dignity three [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.979 (perp=9.901, rec=0.235, cos=0.763), tot_loss_proj:3.794 [t=0.30s]
prediction: ['[CLS] has every student student bill that with arguments upstairs show show up is condition bill condition considerably with sorry three [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.850 (perp=9.296, rec=0.232, cos=0.758), tot_loss_proj:3.649 [t=0.30s]
prediction: ['[CLS] has every student student bill that with arguments can show show up is condition bill condition considerably with three dignity [SEP]']
[ 600/2000] tot_loss=2.734 (perp=8.538, rec=0.234, cos=0.792), tot_loss_proj:3.524 [t=0.30s]
prediction: ['[CLS] has every student student bill that with arguments can show show up any condition proposed condition considerably with three values [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.710 (perp=8.538, rec=0.218, cos=0.784), tot_loss_proj:3.528 [t=0.30s]
prediction: ['[CLS] has every student student bill that with arguments can show show up any condition proposed condition considerably with three values [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.767 (perp=8.723, rec=0.226, cos=0.796), tot_loss_proj:3.565 [t=0.30s]
prediction: ['[CLS] every student has student bill that with arguments 6 show show up any condition proposed condition considerably with three values [SEP]']
[ 750/2000] tot_loss=2.759 (perp=8.723, rec=0.218, cos=0.797), tot_loss_proj:3.572 [t=0.30s]
prediction: ['[CLS] every student has student bill that with arguments 6 show show up any condition proposed condition considerably with three values [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.738 (perp=8.628, rec=0.216, cos=0.797), tot_loss_proj:3.567 [t=0.30s]
prediction: ['[CLS] every student has student bill that with arguments show 6 show up any condition proposed condition considerably with three values [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.839 (perp=9.063, rec=0.216, cos=0.810), tot_loss_proj:3.678 [t=0.30s]
prediction: ['[CLS] every student has condition bill that with arguments show 6 show up any condition proposed condition considerably with three values [SEP]']
[ 900/2000] tot_loss=2.900 (perp=9.454, rec=0.209, cos=0.800), tot_loss_proj:3.728 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show 6 show up some condition proposed condition considerably with three values [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.873 (perp=9.151, rec=0.222, cos=0.821), tot_loss_proj:3.687 [t=0.30s]
prediction: ['[CLS] every student has condition bill that with arguments show can show up some condition proposed condition gonna with three values [SEP]']
Attempt swap
[1000/2000] tot_loss=2.862 (perp=9.151, rec=0.210, cos=0.822), tot_loss_proj:3.688 [t=0.30s]
prediction: ['[CLS] every student has condition bill that with arguments show can show up some condition proposed condition gonna with three values [SEP]']
[1050/2000] tot_loss=2.873 (perp=9.151, rec=0.213, cos=0.830), tot_loss_proj:3.685 [t=0.30s]
prediction: ['[CLS] every student has condition bill that with arguments show can show up some condition proposed condition gonna with three values [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.051 (perp=10.017, rec=0.224, cos=0.823), tot_loss_proj:3.856 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show 6 show up someonzo proposed gonna condition with three values [SEP]']
Attempt swap
[1150/2000] tot_loss=2.953 (perp=9.518, rec=0.225, cos=0.825), tot_loss_proj:3.756 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show 6 show up some condition proposed gonna condition with three values [SEP]']
[1200/2000] tot_loss=2.842 (perp=9.033, rec=0.211, cos=0.825), tot_loss_proj:3.651 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show can show up some condition proposed gonna condition with three values [SEP]']
Attempt swap
[1250/2000] tot_loss=2.843 (perp=9.033, rec=0.212, cos=0.825), tot_loss_proj:3.652 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show can show up some condition proposed gonna condition with three values [SEP]']
Attempt swap
[1300/2000] tot_loss=2.844 (perp=9.033, rec=0.209, cos=0.828), tot_loss_proj:3.651 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show can show up some condition proposed gonna condition with three values [SEP]']
[1350/2000] tot_loss=2.850 (perp=9.033, rec=0.214, cos=0.830), tot_loss_proj:3.649 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show can show up some condition proposed gonna condition with three values [SEP]']
Attempt swap
[1400/2000] tot_loss=2.851 (perp=9.033, rec=0.214, cos=0.830), tot_loss_proj:3.651 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show can show up some condition proposed gonna condition with three values [SEP]']
Attempt swap
[1450/2000] tot_loss=2.839 (perp=9.033, rec=0.202, cos=0.831), tot_loss_proj:3.654 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show can show up some condition proposed gonna condition with three values [SEP]']
[1500/2000] tot_loss=2.937 (perp=9.473, rec=0.210, cos=0.832), tot_loss_proj:3.736 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show is show up some condition proposed gonna condition with three values [SEP]']
Attempt swap
[1550/2000] tot_loss=3.031 (perp=9.948, rec=0.206, cos=0.835), tot_loss_proj:3.813 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show is show up someonzo proposed gonna condition with three values [SEP]']
Attempt swap
[1600/2000] tot_loss=3.033 (perp=9.948, rec=0.212, cos=0.832), tot_loss_proj:3.823 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show is show up someonzo proposed gonna condition with three values [SEP]']
[1650/2000] tot_loss=3.041 (perp=9.948, rec=0.217, cos=0.834), tot_loss_proj:3.815 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show is show up someonzo proposed gonna condition with three values [SEP]']
Attempt swap
[1700/2000] tot_loss=3.034 (perp=9.948, rec=0.209, cos=0.835), tot_loss_proj:3.816 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show is show up someonzo proposed gonna condition with three values [SEP]']
Attempt swap
[1750/2000] tot_loss=3.038 (perp=9.948, rec=0.212, cos=0.836), tot_loss_proj:3.818 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show is show up someonzo proposed gonna condition with three values [SEP]']
[1800/2000] tot_loss=3.034 (perp=9.948, rec=0.208, cos=0.836), tot_loss_proj:3.820 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show is show up someonzo proposed gonna condition with three values [SEP]']
Attempt swap
[1850/2000] tot_loss=3.028 (perp=9.948, rec=0.202, cos=0.837), tot_loss_proj:3.820 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show is show up someonzo proposed gonna condition with three values [SEP]']
Attempt swap
[1900/2000] tot_loss=3.097 (perp=10.272, rec=0.206, cos=0.837), tot_loss_proj:3.873 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show is show up someonzo proposed gonna condition to three values [SEP]']
[1950/2000] tot_loss=3.092 (perp=10.272, rec=0.200, cos=0.837), tot_loss_proj:3.873 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show is show up someonzo proposed gonna condition to three values [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.961 (perp=9.573, rec=0.212, cos=0.834), tot_loss_proj:3.775 [t=0.30s]
prediction: ['[CLS] every student has practice bill that with arguments show to show up someonzo proposed gonna condition is three values [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]
========================
predicted: 
========================
[CLS] every student has practice bill that with arguments show is show up someonzo proposed gonna condition to three values [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 76.190 | r: 76.190
rouge2     | fm: 15.000 | p: 15.000 | r: 15.000
rougeL     | fm: 42.857 | p: 42.857 | r: 42.857
rougeLsum  | fm: 42.857 | p: 42.857 | r: 42.857
r1fm+r2fm = 91.190

[Aggregate metrics]:
rouge1     | fm: 75.158 | p: 75.511 | r: 75.104
rouge2     | fm: 32.011 | p: 32.150 | r: 32.079
rougeL     | fm: 66.147 | p: 66.463 | r: 66.062
rougeLsum  | fm: 66.484 | p: 66.869 | r: 66.373
r1fm+r2fm = 107.169

input #43 time: 0:12:06 | total time: 8:46:47


Running input #44 of 100.
reference: 
========================
Kim alienates cats and beat his dog.
========================
average of cosine similarity 0.9990553992255786
highest_index [0]
highest [0.9990553992255786]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 5035, 7344, 8520, 8870, 1998, 3786, 2010, 3899, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] kim alienates cats and beat his dog. [SEP]']
[Init] best rec loss: 0.9569239616394043 for ['[CLS] vineyard sterling michigan bat hot boltedpati cannot matter [SEP]']
[Init] best rec loss: 0.9527180194854736 for ['[CLS] revivalphobicence nails animal performance antarctic for run [SEP]']
[Init] best rec loss: 0.8985671997070312 for ['[CLS] conventional commentary at better mutuallylaise film protein proton [SEP]']
[Init] best rec loss: 0.8632796406745911 for ['[CLS] attempt ll foreign suck off spy gain app promoted [SEP]']
[Init] best rec loss: 0.8616333603858948 for ['[CLS] here target reasons falcon rig walnut mixedpod = [SEP]']
[Init] best rec loss: 0.8560478091239929 for ['[CLS] county aids marginal there hart will inclusion trembling taluka [SEP]']
[Init] best rec loss: 0.8412955403327942 for ['[CLS] check scales hang line begin also alt clearbbled [SEP]']
[Init] best rec loss: 0.8238433599472046 for ['[CLS]curedonte step convent match boo maximus largely neighborhood [SEP]']
[Init] best rec loss: 0.7992647886276245 for ['[CLS]⁄ lance assigns edmund missouri other. started dan [SEP]']
[Init] best perm rec loss: 0.7979080677032471 for ['[CLS] lance other dan edmund started assigns missouri⁄. [SEP]']
[Init] best perm rec loss: 0.7939121127128601 for ['[CLS] dan. lance⁄ edmund assigns other missouri started [SEP]']
[Init] best perm rec loss: 0.7918322086334229 for ['[CLS] started. other lance assigns⁄ missouri edmund dan [SEP]']
[Init] best perm rec loss: 0.7899661064147949 for ['[CLS] other dan missouri lance⁄. assigns edmund started [SEP]']
[Init] best perm rec loss: 0.7883182168006897 for ['[CLS] dan other edmund lance⁄ assigns. missouri started [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.954 (perp=11.710, rec=0.703, cos=0.909), tot_loss_proj:4.291 [t=0.29s]
prediction: ['[CLS] dual the ceylon cloth miriam action - suit cards [SEP]']
[ 100/2000] tot_loss=3.470 (perp=11.256, rec=0.475, cos=0.744), tot_loss_proj:4.172 [t=0.30s]
prediction: ['[CLS] otherwise bull andhra object beat the credit sequencepers [SEP]']
[ 150/2000] tot_loss=4.116 (perp=15.108, rec=0.372, cos=0.722), tot_loss_proj:4.996 [t=0.30s]
prediction: ['[CLS] alien cruiser kim object beat his mm dog phrases [SEP]']
[ 200/2000] tot_loss=3.784 (perp=13.636, rec=0.351, cos=0.705), tot_loss_proj:4.676 [t=0.30s]
prediction: ['[CLS] alien panther kim object beat his genes dog phrases [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.326 (perp=11.091, rec=0.383, cos=0.725), tot_loss_proj:4.102 [t=0.30s]
prediction: ['[CLS] kim alien pupqu beat dog whale dog samples [SEP]']
[ 300/2000] tot_loss=3.257 (perp=11.175, rec=0.305, cos=0.716), tot_loss_proj:4.080 [t=0.30s]
prediction: ['[CLS] kim alien dogqu beat dog crab dog updates [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.334 (perp=11.892, rec=0.278, cos=0.677), tot_loss_proj:4.245 [t=0.30s]
prediction: ['[CLS] kimate native werewolf beat dog dog dog snails [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.220 (perp=10.692, rec=0.347, cos=0.735), tot_loss_proj:4.023 [t=0.30s]
prediction: ['[CLS] kimatesp native beat dog dog dog correction [SEP]']
[ 450/2000] tot_loss=3.325 (perp=11.779, rec=0.295, cos=0.675), tot_loss_proj:4.266 [t=0.30s]
prediction: ['[CLS] kimates spirits humanoid beat dog dog dog rocks [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.421 (perp=12.175, rec=0.266, cos=0.720), tot_loss_proj:4.400 [t=0.30s]
prediction: ['[CLS] kimates humanoid society beat dog dog his tablets [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=3.346 (perp=11.818, rec=0.267, cos=0.715), tot_loss_proj:4.325 [t=0.30s]
prediction: ['[CLS] kimates humanoid uno beat his dog dog asteroid [SEP]']
[ 600/2000] tot_loss=3.409 (perp=12.214, rec=0.257, cos=0.709), tot_loss_proj:4.391 [t=0.30s]
prediction: ['[CLS] kimates humanoid uno beat his dog dog marshes [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.186 (perp=10.984, rec=0.249, cos=0.740), tot_loss_proj:4.112 [t=0.30s]
prediction: ['[CLS] kimates humanoid beat his dog dog uno asteroid [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.208 (perp=11.138, rec=0.266, cos=0.715), tot_loss_proj:3.398 [t=0.30s]
prediction: ['[CLS] kimates beat his tatum dog dog uno tablets [SEP]']
[ 750/2000] tot_loss=3.189 (perp=11.138, rec=0.245, cos=0.717), tot_loss_proj:3.444 [t=0.30s]
prediction: ['[CLS] kimates beat his tatum dog dog uno tablets [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.011 (perp=10.262, rec=0.241, cos=0.718), tot_loss_proj:3.928 [t=0.30s]
prediction: ['[CLS] kimates tatum beat his dog dog uno tablets [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.100 (perp=10.714, rec=0.242, cos=0.716), tot_loss_proj:4.078 [t=0.30s]
prediction: ['[CLS] kimates tatum beat his cats dog uno tablets [SEP]']
[ 900/2000] tot_loss=3.125 (perp=10.714, rec=0.278, cos=0.705), tot_loss_proj:4.078 [t=0.30s]
prediction: ['[CLS] kimates tatum beat his cats dog uno tablets [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.104 (perp=10.714, rec=0.251, cos=0.710), tot_loss_proj:4.075 [t=0.30s]
prediction: ['[CLS] kimates tatum beat his cats dog uno tablets [SEP]']
Attempt swap
[1000/2000] tot_loss=3.113 (perp=10.714, rec=0.257, cos=0.713), tot_loss_proj:4.070 [t=0.30s]
prediction: ['[CLS] kimates tatum beat his cats dog uno tablets [SEP]']
[1050/2000] tot_loss=3.102 (perp=10.714, rec=0.237, cos=0.722), tot_loss_proj:4.075 [t=0.30s]
prediction: ['[CLS] kimates tatum beat his cats dog uno tablets [SEP]']
Attempt swap
[1100/2000] tot_loss=3.092 (perp=10.714, rec=0.235, cos=0.714), tot_loss_proj:4.072 [t=0.30s]
prediction: ['[CLS] kimates tatum beat his cats dog uno tablets [SEP]']
Attempt swap
[1150/2000] tot_loss=3.102 (perp=10.714, rec=0.240, cos=0.719), tot_loss_proj:4.074 [t=0.30s]
prediction: ['[CLS] kimates tatum beat his cats dog uno tablets [SEP]']
[1200/2000] tot_loss=3.268 (perp=11.541, rec=0.227, cos=0.733), tot_loss_proj:4.223 [t=0.30s]
prediction: ['[CLS] kimatesович beat his cats dog uno tablets [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=3.178 (perp=11.105, rec=0.236, cos=0.721), tot_loss_proj:4.043 [t=0.30s]
prediction: ['[CLS] kimatesович cats beat his dog uno tablets [SEP]']
Attempt swap
[1300/2000] tot_loss=3.189 (perp=11.105, rec=0.232, cos=0.736), tot_loss_proj:4.038 [t=0.30s]
prediction: ['[CLS] kimatesович cats beat his dog uno tablets [SEP]']
[1350/2000] tot_loss=3.190 (perp=11.105, rec=0.230, cos=0.739), tot_loss_proj:4.042 [t=0.30s]
prediction: ['[CLS] kimatesович cats beat his dog uno tablets [SEP]']
Attempt swap
[1400/2000] tot_loss=3.193 (perp=11.105, rec=0.231, cos=0.741), tot_loss_proj:4.042 [t=0.30s]
prediction: ['[CLS] kimatesович cats beat his dog uno tablets [SEP]']
Attempt swap
[1450/2000] tot_loss=3.179 (perp=11.105, rec=0.232, cos=0.726), tot_loss_proj:4.039 [t=0.30s]
prediction: ['[CLS] kimatesович cats beat his dog uno tablets [SEP]']
[1500/2000] tot_loss=3.520 (perp=12.769, rec=0.227, cos=0.739), tot_loss_proj:4.412 [t=0.30s]
prediction: ['[CLS] kimatessms cats beat his dog uno tablets [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=3.396 (perp=12.144, rec=0.228, cos=0.739), tot_loss_proj:4.398 [t=0.30s]
prediction: ['[CLS] kimates uno cats beat his dogsms tablets [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=3.312 (perp=11.545, rec=0.243, cos=0.759), tot_loss_proj:4.206 [t=0.30s]
prediction: ['[CLS] kimates cats beat his dog unosms tablets [SEP]']
[1650/2000] tot_loss=3.276 (perp=11.545, rec=0.238, cos=0.729), tot_loss_proj:4.210 [t=0.30s]
prediction: ['[CLS] kimates cats beat his dog unosms tablets [SEP]']
Attempt swap
[1700/2000] tot_loss=3.278 (perp=11.545, rec=0.233, cos=0.735), tot_loss_proj:4.205 [t=0.30s]
prediction: ['[CLS] kimates cats beat his dog unosms tablets [SEP]']
Attempt swap
[1750/2000] tot_loss=3.271 (perp=11.545, rec=0.221, cos=0.742), tot_loss_proj:4.205 [t=0.30s]
prediction: ['[CLS] kimates cats beat his dog unosms tablets [SEP]']
[1800/2000] tot_loss=3.273 (perp=11.545, rec=0.226, cos=0.738), tot_loss_proj:4.209 [t=0.30s]
prediction: ['[CLS] kimates cats beat his dog unosms tablets [SEP]']
Attempt swap
[1850/2000] tot_loss=3.280 (perp=11.545, rec=0.240, cos=0.731), tot_loss_proj:4.209 [t=0.30s]
prediction: ['[CLS] kimates cats beat his dog unosms tablets [SEP]']
Attempt swap
[1900/2000] tot_loss=3.265 (perp=11.545, rec=0.220, cos=0.736), tot_loss_proj:4.208 [t=0.30s]
prediction: ['[CLS] kimates cats beat his dog unosms tablets [SEP]']
[1950/2000] tot_loss=3.354 (perp=11.956, rec=0.225, cos=0.737), tot_loss_proj:4.273 [t=0.30s]
prediction: ['[CLS] kimates cats beat his dog unoworm tablets [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=3.335 (perp=11.868, rec=0.223, cos=0.738), tot_loss_proj:4.290 [t=0.30s]
prediction: ['[CLS] kimates uno beat his dog catssms tablets [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] kim alienates cats and beat his dog. [SEP]
========================
predicted: 
========================
[CLS] kimates cats beat his dog unosms tablets [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 91.667

[Aggregate metrics]:
rouge1     | fm: 74.917 | p: 75.260 | r: 74.825
rouge2     | fm: 31.857 | p: 31.921 | r: 31.932
rougeL     | fm: 66.181 | p: 66.570 | r: 66.072
rougeLsum  | fm: 66.462 | p: 66.768 | r: 66.358
r1fm+r2fm = 106.775

input #44 time: 0:11:47 | total time: 8:58:35


Running input #45 of 100.
reference: 
========================
John's I stole bike.
========================
average of cosine similarity 0.998876273415268
highest_index [0]
highest [0.998876273415268]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2198,  1005,  1055,  1045, 10312,  7997,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] john's i stole bike. [SEP]"]
[Init] best rec loss: 0.9044911861419678 for ['[CLS] outskirts came too yourtered occupy tradition [SEP]']
[Init] best rec loss: 0.7876102328300476 for ['[CLS] video date prime tall lifeless grape person [SEP]']
[Init] best rec loss: 0.7436298727989197 for ['[CLS]cableaus splitsonic 22 continue moving [SEP]']
[Init] best rec loss: 0.7357560396194458 for ['[CLS] evening lose high design bankrupt caucus landscape [SEP]']
[Init] best perm rec loss: 0.73501056432724 for ['[CLS] lose design landscape bankrupt evening caucus high [SEP]']
[Init] best perm rec loss: 0.7290562987327576 for ['[CLS] lose evening design bankrupt caucus landscape high [SEP]']
[Init] best perm rec loss: 0.7220990657806396 for ['[CLS] high evening design bankrupt landscape lose caucus [SEP]']
[Init] best perm rec loss: 0.7207049131393433 for ['[CLS] bankrupt landscape high evening lose design caucus [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.323 (perp=10.025, rec=0.301, cos=0.017), tot_loss_proj:3.075 [t=0.29s]
prediction: ['[CLS] stole s who i bike designed on [SEP]']
[ 100/2000] tot_loss=2.354 (perp=11.008, rec=0.144, cos=0.007), tot_loss_proj:3.273 [t=0.30s]
prediction: ['[CLS] john s s i bike stole. [SEP]']
[ 150/2000] tot_loss=2.329 (perp=11.008, rec=0.121, cos=0.006), tot_loss_proj:3.323 [t=0.30s]
prediction: ['[CLS] john s s i bike stole. [SEP]']
[ 200/2000] tot_loss=2.407 (perp=9.280, rec=0.481, cos=0.070), tot_loss_proj:2.908 [t=0.30s]
prediction: ["[CLS] john s'i bike stole. [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.738 (perp=7.679, rec=0.191, cos=0.011), tot_loss_proj:2.477 [t=0.30s]
prediction: ["[CLS] john's i bike stole. [SEP]"]
[ 300/2000] tot_loss=1.687 (perp=7.679, rec=0.144, cos=0.007), tot_loss_proj:2.493 [t=0.30s]
prediction: ["[CLS] john's i bike stole. [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.389 (perp=6.280, rec=0.127, cos=0.006), tot_loss_proj:1.386 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[ 400/2000] tot_loss=1.375 (perp=6.280, rec=0.113, cos=0.006), tot_loss_proj:1.393 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
[ 450/2000] tot_loss=1.365 (perp=6.280, rec=0.103, cos=0.005), tot_loss_proj:1.402 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.367 (perp=6.280, rec=0.106, cos=0.005), tot_loss_proj:1.402 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.357 (perp=6.280, rec=0.096, cos=0.005), tot_loss_proj:1.396 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
[ 600/2000] tot_loss=1.358 (perp=6.280, rec=0.097, cos=0.005), tot_loss_proj:1.398 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.361 (perp=6.280, rec=0.100, cos=0.005), tot_loss_proj:1.387 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.352 (perp=6.280, rec=0.091, cos=0.005), tot_loss_proj:1.399 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
[ 750/2000] tot_loss=1.358 (perp=6.280, rec=0.097, cos=0.005), tot_loss_proj:1.396 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.352 (perp=6.280, rec=0.091, cos=0.005), tot_loss_proj:1.398 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.344 (perp=6.280, rec=0.083, cos=0.005), tot_loss_proj:1.390 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
[ 900/2000] tot_loss=1.359 (perp=6.280, rec=0.098, cos=0.005), tot_loss_proj:1.401 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.349 (perp=6.280, rec=0.088, cos=0.005), tot_loss_proj:1.395 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.341 (perp=6.280, rec=0.081, cos=0.005), tot_loss_proj:1.393 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
[1050/2000] tot_loss=1.350 (perp=6.280, rec=0.089, cos=0.005), tot_loss_proj:1.398 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.342 (perp=6.280, rec=0.081, cos=0.005), tot_loss_proj:1.400 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.340 (perp=6.280, rec=0.079, cos=0.005), tot_loss_proj:1.400 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
[1200/2000] tot_loss=1.353 (perp=6.280, rec=0.093, cos=0.005), tot_loss_proj:1.396 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.338 (perp=6.280, rec=0.078, cos=0.005), tot_loss_proj:1.400 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.345 (perp=6.280, rec=0.084, cos=0.005), tot_loss_proj:1.393 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
[1350/2000] tot_loss=1.341 (perp=6.280, rec=0.080, cos=0.005), tot_loss_proj:1.398 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.344 (perp=6.280, rec=0.084, cos=0.005), tot_loss_proj:1.398 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.350 (perp=6.280, rec=0.089, cos=0.005), tot_loss_proj:1.400 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
[1500/2000] tot_loss=1.347 (perp=6.280, rec=0.086, cos=0.005), tot_loss_proj:1.398 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.352 (perp=6.280, rec=0.091, cos=0.005), tot_loss_proj:1.397 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.343 (perp=6.280, rec=0.082, cos=0.005), tot_loss_proj:1.390 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
[1650/2000] tot_loss=1.335 (perp=6.280, rec=0.075, cos=0.005), tot_loss_proj:1.390 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.354 (perp=6.280, rec=0.094, cos=0.005), tot_loss_proj:1.397 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.351 (perp=6.280, rec=0.090, cos=0.005), tot_loss_proj:1.395 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
[1800/2000] tot_loss=1.337 (perp=6.280, rec=0.076, cos=0.005), tot_loss_proj:1.397 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.353 (perp=6.280, rec=0.093, cos=0.005), tot_loss_proj:1.397 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.346 (perp=6.280, rec=0.085, cos=0.005), tot_loss_proj:1.397 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
[1950/2000] tot_loss=1.349 (perp=6.280, rec=0.089, cos=0.005), tot_loss_proj:1.392 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.353 (perp=6.280, rec=0.093, cos=0.005), tot_loss_proj:1.394 [t=0.30s]
prediction: ["[CLS] john's i stole bike. [SEP]"]
Done with input #45 of 100.
reference: 
========================
[CLS] john's i stole bike. [SEP]
========================
predicted: 
========================
[CLS] john's i stole bike. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 75.470 | p: 75.846 | r: 75.348
rouge2     | fm: 33.278 | p: 33.294 | r: 33.295
rougeL     | fm: 66.843 | p: 67.185 | r: 66.736
rougeLsum  | fm: 67.201 | p: 67.635 | r: 67.093
r1fm+r2fm = 108.748

input #45 time: 0:11:47 | total time: 9:10:23


Running input #46 of 100.
reference: 
========================
The witch went into the forest by vanishing.
========================
average of cosine similarity 0.9988940030464246
highest_index [0]
highest [0.9988940030464246]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1996,  6965,  2253,  2046,  1996,  3224,  2011, 24866,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] the witch went into the forest by vanishing. [SEP]']
[Init] best rec loss: 0.715063214302063 for ['[CLS] tripume mackenzie enterprise crunch threshold engine free down [SEP]']
[Init] best rec loss: 0.7144859433174133 for ['[CLS] hell advent shared moderatenton drivendity kennedyided [SEP]']
[Init] best rec loss: 0.6959742307662964 for ['[CLS] ink loss yet volvo remaining fine manor sa glacier [SEP]']
[Init] best perm rec loss: 0.6930870413780212 for ['[CLS] ink volvo manor yet glacier fine remaining loss sa [SEP]']
[Init] best perm rec loss: 0.6928520202636719 for ['[CLS] remaining manor ink glacier yet loss sa volvo fine [SEP]']
[Init] best perm rec loss: 0.692685604095459 for ['[CLS] yet glacier volvo ink manor remaining loss sa fine [SEP]']
[Init] best perm rec loss: 0.6926140189170837 for ['[CLS] glacier manor yet volvo loss sa fine remaining ink [SEP]']
[Init] best perm rec loss: 0.6921358108520508 for ['[CLS] glacier yet manor remaining ink volvo fine loss sa [SEP]']
[Init] best perm rec loss: 0.691655158996582 for ['[CLS] volvo yet fine glacier remaining loss sa ink manor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.318 (perp=11.478, rec=0.622, cos=0.400), tot_loss_proj:3.256 [t=0.29s]
prediction: ['[CLS]stered hell. »? marine every bragg finale [SEP]']
[ 100/2000] tot_loss=2.491 (perp=10.315, rec=0.307, cos=0.121), tot_loss_proj:2.891 [t=0.30s]
prediction: ['[CLS] yelled storm by went. by every magic disappearing [SEP]']
[ 150/2000] tot_loss=2.644 (perp=12.177, rec=0.178, cos=0.031), tot_loss_proj:3.448 [t=0.30s]
prediction: ['[CLS] into witch by went our by went vanishing vanishing [SEP]']
[ 200/2000] tot_loss=2.445 (perp=11.504, rec=0.129, cos=0.015), tot_loss_proj:3.355 [t=0.30s]
prediction: ['[CLS] into witch through went the by entered vanishing vanishing [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.211 (perp=10.391, rec=0.118, cos=0.015), tot_loss_proj:3.068 [t=0.30s]
prediction: ['[CLS] into witch forest went into byin vanishing vanishing [SEP]']
[ 300/2000] tot_loss=1.774 (perp=8.393, rec=0.086, cos=0.009), tot_loss_proj:2.954 [t=0.30s]
prediction: ['[CLS] into witch forest went into by the vanishing. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.462 (perp=11.360, rec=0.167, cos=0.022), tot_loss_proj:3.488 [t=0.30s]
prediction: ['[CLS] into witchan forest went came by vanishing^ [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.559 (perp=12.035, rec=0.138, cos=0.015), tot_loss_proj:3.232 [t=0.30s]
prediction: ['[CLS] into went witchan forest went by vanishing^ [SEP]']
[ 450/2000] tot_loss=2.526 (perp=12.035, rec=0.108, cos=0.011), tot_loss_proj:3.228 [t=0.30s]
prediction: ['[CLS] into went witchan forest went by vanishing^ [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.171 (perp=10.340, rec=0.094, cos=0.009), tot_loss_proj:2.821 [t=0.30s]
prediction: ['[CLS] witch went intoan forest went by vanishing^ [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.383 (perp=11.393, rec=0.096, cos=0.009), tot_loss_proj:3.192 [t=0.30s]
prediction: ['[CLS] witch the into forest forest went by vanishing^ [SEP]']
[ 600/2000] tot_loss=2.380 (perp=11.393, rec=0.094, cos=0.008), tot_loss_proj:3.201 [t=0.30s]
prediction: ['[CLS] witch the into forest forest went by vanishing^ [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.845 (perp=8.785, rec=0.081, cos=0.007), tot_loss_proj:2.457 [t=0.30s]
prediction: ['[CLS] witch into the forest forest went by vanishing^ [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.750 (perp=8.248, rec=0.094, cos=0.007), tot_loss_proj:2.522 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing forest^ [SEP]']
[ 750/2000] tot_loss=1.752 (perp=8.248, rec=0.096, cos=0.007), tot_loss_proj:2.527 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing forest^ [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.753 (perp=8.248, rec=0.097, cos=0.007), tot_loss_proj:2.525 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing forest^ [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.757 (perp=8.248, rec=0.101, cos=0.007), tot_loss_proj:2.518 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing forest^ [SEP]']
[ 900/2000] tot_loss=1.734 (perp=8.248, rec=0.078, cos=0.007), tot_loss_proj:2.519 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing forest^ [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.749 (perp=8.248, rec=0.092, cos=0.007), tot_loss_proj:2.527 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing forest^ [SEP]']
Attempt swap
[1000/2000] tot_loss=1.746 (perp=8.248, rec=0.090, cos=0.007), tot_loss_proj:2.529 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing forest^ [SEP]']
[1050/2000] tot_loss=1.726 (perp=8.248, rec=0.070, cos=0.007), tot_loss_proj:2.525 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing forest^ [SEP]']
Attempt swap
[1100/2000] tot_loss=1.737 (perp=8.248, rec=0.081, cos=0.007), tot_loss_proj:2.522 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing forest^ [SEP]']
Attempt swap
[1150/2000] tot_loss=1.741 (perp=8.248, rec=0.084, cos=0.007), tot_loss_proj:2.526 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing forest^ [SEP]']
[1200/2000] tot_loss=1.743 (perp=8.248, rec=0.087, cos=0.006), tot_loss_proj:2.517 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing forest^ [SEP]']
Attempt swap
[1250/2000] tot_loss=1.766 (perp=8.362, rec=0.087, cos=0.006), tot_loss_proj:2.579 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
Attempt swap
[1300/2000] tot_loss=1.763 (perp=8.362, rec=0.084, cos=0.006), tot_loss_proj:2.583 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
[1350/2000] tot_loss=1.762 (perp=8.362, rec=0.083, cos=0.006), tot_loss_proj:2.584 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
Attempt swap
[1400/2000] tot_loss=1.754 (perp=8.362, rec=0.075, cos=0.006), tot_loss_proj:2.589 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
Attempt swap
[1450/2000] tot_loss=1.751 (perp=8.362, rec=0.072, cos=0.006), tot_loss_proj:2.586 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
[1500/2000] tot_loss=1.769 (perp=8.362, rec=0.090, cos=0.006), tot_loss_proj:2.581 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
Attempt swap
[1550/2000] tot_loss=1.759 (perp=8.362, rec=0.080, cos=0.006), tot_loss_proj:2.581 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
Attempt swap
[1600/2000] tot_loss=1.757 (perp=8.362, rec=0.078, cos=0.006), tot_loss_proj:2.583 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
[1650/2000] tot_loss=1.764 (perp=8.362, rec=0.085, cos=0.006), tot_loss_proj:2.583 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
Attempt swap
[1700/2000] tot_loss=1.764 (perp=8.362, rec=0.085, cos=0.006), tot_loss_proj:2.581 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
Attempt swap
[1750/2000] tot_loss=1.753 (perp=8.362, rec=0.074, cos=0.006), tot_loss_proj:2.582 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
[1800/2000] tot_loss=1.761 (perp=8.362, rec=0.082, cos=0.006), tot_loss_proj:2.589 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
Attempt swap
[1850/2000] tot_loss=1.768 (perp=8.362, rec=0.089, cos=0.006), tot_loss_proj:2.585 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
Attempt swap
[1900/2000] tot_loss=1.761 (perp=8.362, rec=0.083, cos=0.006), tot_loss_proj:2.584 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
[1950/2000] tot_loss=1.751 (perp=8.362, rec=0.072, cos=0.006), tot_loss_proj:2.582 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
Attempt swap
[2000/2000] tot_loss=1.769 (perp=8.362, rec=0.090, cos=0.006), tot_loss_proj:2.586 [t=0.30s]
prediction: ['[CLS] witch into the forest went by vanishing witch^ [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] the witch went into the forest by vanishing. [SEP]
========================
predicted: 
========================
[CLS] witch into the forest went by vanishing witch^ [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 123.333

[Aggregate metrics]:
rouge1     | fm: 75.821 | p: 76.103 | r: 75.717
rouge2     | fm: 33.353 | p: 33.432 | r: 33.410
rougeL     | fm: 67.153 | p: 67.533 | r: 67.002
rougeLsum  | fm: 67.383 | p: 67.805 | r: 67.228
r1fm+r2fm = 109.173

input #46 time: 0:11:48 | total time: 9:22:11


Running input #47 of 100.
reference: 
========================
Mary noticed John's excessive appreciation of himself.
========================
average of cosine similarity 0.9985337817703797
highest_index [0]
highest [0.9985337817703797]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2984,  4384,  2198,  1005,  1055, 11664, 12284,  1997,  2370,
          1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] mary noticed john's excessive appreciation of himself. [SEP]"]
[Init] best rec loss: 0.8813326954841614 for ['[CLS] negotiationsris deemedtment prohibition wine holdingyn divorced within [SEP]']
[Init] best rec loss: 0.875779390335083 for ['[CLS] apart nearly twinotho point onceient overcome beck hong [SEP]']
[Init] best rec loss: 0.8539456725120544 for ['[CLS] accompanying moss advent visitedsit corbin pas grade convictedbacks [SEP]']
[Init] best rec loss: 0.8376568555831909 for ['[CLS] salvage thing ryder fremont above eliza coat will net star [SEP]']
[Init] best rec loss: 0.8068128228187561 for ['[CLS] retro en correctly top pitch my leads august got look [SEP]']
[Init] best rec loss: 0.806732177734375 for ['[CLS] my chronicles fine wearing lessons at transcriptsystems lecture marx [SEP]']
[Init] best perm rec loss: 0.8058116436004639 for ['[CLS] wearing transcript chronicles lessons my lecture fine marx atsystems [SEP]']
[Init] best perm rec loss: 0.8048007488250732 for ['[CLS] transcript lecture wearing chronicles my fine at lessons marxsystems [SEP]']
[Init] best perm rec loss: 0.8041284680366516 for ['[CLS] lessons transcript my at wearing fine marx lecture chroniclessystems [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.754 (perp=12.864, rec=0.458, cos=0.723), tot_loss_proj:4.385 [t=0.29s]
prediction: ['[CLS] excessive difficulty col aus. marrying appreciation he decomposition covered [SEP]']
[ 100/2000] tot_loss=3.724 (perp=12.562, rec=0.420, cos=0.792), tot_loss_proj:4.291 [t=0.30s]
prediction: ['[CLS] excessive noticed henri paintings. excessive appreciation noticed noticed covered [SEP]']
[ 150/2000] tot_loss=3.261 (perp=10.658, rec=0.363, cos=0.766), tot_loss_proj:3.982 [t=0.30s]
prediction: ['[CLS] excessive noticed valerie paintings. excessive appreciation noticed noticed : [SEP]']
[ 200/2000] tot_loss=3.106 (perp=10.143, rec=0.314, cos=0.764), tot_loss_proj:3.882 [t=0.30s]
prediction: ['[CLS] excessive appreciation donald john. excessive appreciation his noticed this [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.931 (perp=9.487, rec=0.301, cos=0.733), tot_loss_proj:3.798 [t=0.30s]
prediction: ['[CLS] excessive appreciation donald. john excessive appreciation his noticed how [SEP]']
[ 300/2000] tot_loss=3.167 (perp=10.384, rec=0.278, cos=0.812), tot_loss_proj:3.954 [t=0.30s]
prediction: ['[CLS] excessive appreciation donald. john excessive john his noticed how [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.084 (perp=10.233, rec=0.255, cos=0.783), tot_loss_proj:3.900 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john excessive john his noticed himself [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.903 (perp=9.604, rec=0.254, cos=0.728), tot_loss_proj:3.829 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john excessive john s. noticed [SEP]']
[ 450/2000] tot_loss=2.883 (perp=9.604, rec=0.216, cos=0.745), tot_loss_proj:3.837 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john excessive john s. noticed [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.141 (perp=10.954, rec=0.201, cos=0.750), tot_loss_proj:3.997 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.165 (perp=10.954, rec=0.210, cos=0.764), tot_loss_proj:3.990 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
[ 600/2000] tot_loss=3.129 (perp=10.954, rec=0.197, cos=0.741), tot_loss_proj:3.990 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.147 (perp=10.954, rec=0.188, cos=0.768), tot_loss_proj:3.996 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.147 (perp=10.954, rec=0.198, cos=0.758), tot_loss_proj:3.998 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
[ 750/2000] tot_loss=3.140 (perp=10.954, rec=0.192, cos=0.757), tot_loss_proj:3.995 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.160 (perp=10.954, rec=0.201, cos=0.768), tot_loss_proj:3.994 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.122 (perp=10.954, rec=0.174, cos=0.757), tot_loss_proj:3.990 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
[ 900/2000] tot_loss=3.139 (perp=10.954, rec=0.180, cos=0.768), tot_loss_proj:3.994 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.131 (perp=10.954, rec=0.187, cos=0.754), tot_loss_proj:3.993 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1000/2000] tot_loss=3.139 (perp=10.954, rec=0.181, cos=0.768), tot_loss_proj:3.997 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
[1050/2000] tot_loss=3.133 (perp=10.954, rec=0.172, cos=0.770), tot_loss_proj:3.996 [t=0.30s]
prediction: ['[CLS] appreciation meadows john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1100/2000] tot_loss=3.113 (perp=10.832, rec=0.184, cos=0.762), tot_loss_proj:4.107 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1150/2000] tot_loss=3.113 (perp=10.832, rec=0.187, cos=0.759), tot_loss_proj:4.107 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
[1200/2000] tot_loss=3.111 (perp=10.832, rec=0.180, cos=0.764), tot_loss_proj:4.109 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1250/2000] tot_loss=3.112 (perp=10.832, rec=0.187, cos=0.758), tot_loss_proj:4.101 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1300/2000] tot_loss=3.099 (perp=10.832, rec=0.166, cos=0.766), tot_loss_proj:4.099 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
[1350/2000] tot_loss=3.118 (perp=10.832, rec=0.189, cos=0.763), tot_loss_proj:4.102 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1400/2000] tot_loss=3.109 (perp=10.832, rec=0.181, cos=0.761), tot_loss_proj:4.106 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1450/2000] tot_loss=3.107 (perp=10.832, rec=0.176, cos=0.765), tot_loss_proj:4.103 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
[1500/2000] tot_loss=3.110 (perp=10.832, rec=0.179, cos=0.765), tot_loss_proj:4.108 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1550/2000] tot_loss=3.119 (perp=10.832, rec=0.187, cos=0.766), tot_loss_proj:4.105 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1600/2000] tot_loss=3.111 (perp=10.832, rec=0.176, cos=0.769), tot_loss_proj:4.102 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
[1650/2000] tot_loss=3.098 (perp=10.832, rec=0.164, cos=0.768), tot_loss_proj:4.102 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1700/2000] tot_loss=3.118 (perp=10.832, rec=0.182, cos=0.770), tot_loss_proj:4.107 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1750/2000] tot_loss=3.108 (perp=10.832, rec=0.177, cos=0.765), tot_loss_proj:4.104 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
[1800/2000] tot_loss=3.104 (perp=10.832, rec=0.170, cos=0.768), tot_loss_proj:4.106 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1850/2000] tot_loss=3.099 (perp=10.832, rec=0.164, cos=0.768), tot_loss_proj:4.108 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[1900/2000] tot_loss=3.107 (perp=10.832, rec=0.173, cos=0.767), tot_loss_proj:4.103 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
[1950/2000] tot_loss=3.101 (perp=10.832, rec=0.166, cos=0.768), tot_loss_proj:4.102 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Attempt swap
[2000/2000] tot_loss=3.114 (perp=10.832, rec=0.180, cos=0.768), tot_loss_proj:4.110 [t=0.30s]
prediction: ['[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] mary noticed john's excessive appreciation of himself. [SEP]
========================
predicted: 
========================
[CLS] appreciation bruce john excessive john himself mary s. noticed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.619 | p: 45.455 | r: 50.000
rougeLsum  | fm: 47.619 | p: 45.455 | r: 50.000
r1fm+r2fm = 85.714

[Aggregate metrics]:
rouge1     | fm: 75.984 | p: 76.156 | r: 75.995
rouge2     | fm: 32.484 | p: 32.553 | r: 32.540
rougeL     | fm: 66.844 | p: 67.102 | r: 66.728
rougeLsum  | fm: 67.051 | p: 67.338 | r: 66.899
r1fm+r2fm = 108.467

input #47 time: 0:11:47 | total time: 9:33:59


Running input #48 of 100.
reference: 
========================
John tagged Lewis with a regulation baseball on Tuesday.
========================
average of cosine similarity 0.9989867453014751
highest_index [0]
highest [0.9989867453014751]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198, 26610,  4572,  2007,  1037,  7816,  3598,  2006,  9857,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]']
[Init] best rec loss: 0.9103503227233887 for ['[CLS]... spit opening tolerant lie officer 3rd wiener true li [SEP]']
[Init] best rec loss: 0.9027561545372009 for ['[CLS]tative fc matched thorough kay responsible backward pali vera its [SEP]']
[Init] best rec loss: 0.8992986679077148 for ['[CLS] method waived place levin nationale dynamic parallel wealthykov vega [SEP]']
[Init] best rec loss: 0.8957230448722839 for ['[CLS] pronounced asylum times vocational form heard londonock limit licence [SEP]']
[Init] best rec loss: 0.8825022578239441 for ['[CLS]! men lung truss into bridge fossil begin particular screen [SEP]']
[Init] best rec loss: 0.8689901828765869 for ['[CLS] dummyuli goods trial births formed backing de chemical dealing [SEP]']
[Init] best rec loss: 0.8688218593597412 for ['[CLS] wolfgang buck introducing bandotericrmghi mans : recovery [SEP]']
[Init] best rec loss: 0.8622455596923828 for ['[CLS] principalpatient their custom accordion courage beastku mice regular [SEP]']
[Init] best rec loss: 0.8460996747016907 for ['[CLS] и album bedfordshire sub appropriateberry barrytt graf mcqueen [SEP]']
[Init] best perm rec loss: 0.8446643352508545 for ['[CLS] album appropriateberry и bedfordshire graftt mcqueen barry sub [SEP]']
[Init] best perm rec loss: 0.8443773984909058 for ['[CLS] appropriate sub mcqueen иberry bedfordshire graf albumtt barry [SEP]']
[Init] best perm rec loss: 0.8426985144615173 for ['[CLS] mcqueen appropriate albumtt subberry graf и bedfordshire barry [SEP]']
[Init] best perm rec loss: 0.8420154452323914 for ['[CLS] bedfordshire album appropriateberrytt и mcqueen graf barry sub [SEP]']
[Init] best perm rec loss: 0.8404747843742371 for ['[CLS] grafberry mcqueen subtt bedfordshire и appropriate barry album [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.956 (perp=12.692, rec=0.547, cos=0.871), tot_loss_proj:4.424 [t=0.29s]
prediction: ['[CLS] extraction baseballballization expedition 『 ; contract skull luke [SEP]']
[ 100/2000] tot_loss=3.420 (perp=11.777, rec=0.478, cos=0.587), tot_loss_proj:4.241 [t=0.30s]
prediction: ['[CLS] tagged baseball volleyball boxing baseball tagged grasped a regulation scored [SEP]']
[ 150/2000] tot_loss=3.255 (perp=11.158, rec=0.372, cos=0.652), tot_loss_proj:4.070 [t=0.30s]
prediction: ['[CLS] tagged tagged basketball packing baseball tagged enduring a basketball forms [SEP]']
[ 200/2000] tot_loss=3.179 (perp=10.497, rec=0.390, cos=0.689), tot_loss_proj:3.976 [t=0.30s]
prediction: ['[CLS] tagged lewis professional job baseball tagged nose a basketball. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.566 (perp=12.846, rec=0.360, cos=0.637), tot_loss_proj:4.459 [t=0.30s]
prediction: ['[CLS] tagged lewis professionalflict boxing baseball tagged regulation basketball. [SEP]']
[ 300/2000] tot_loss=3.218 (perp=11.301, rec=0.311, cos=0.647), tot_loss_proj:4.134 [t=0.30s]
prediction: ['[CLS] ¶ lewis regulationflict boxing baseball tagged a basketball. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.098 (perp=10.679, rec=0.276, cos=0.687), tot_loss_proj:3.965 [t=0.30s]
prediction: ['[CLS] sure lewis regulation boxingflict baseball tagged with baseball. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.250 (perp=10.546, rec=0.460, cos=0.682), tot_loss_proj:3.946 [t=0.30s]
prediction: ['[CLS] ¶ lewis regulationpersonal job baseball tagged with baseball. [SEP]']
[ 450/2000] tot_loss=2.985 (perp=10.276, rec=0.281, cos=0.650), tot_loss_proj:3.873 [t=0.30s]
prediction: ['[CLS] ¶ lewis regulation \\ job baseball tagged with basketball. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.831 (perp=9.654, rec=0.236, cos=0.664), tot_loss_proj:3.788 [t=0.30s]
prediction: ['[CLS] sure lewis tagged \\ job baseball regulation with baseball. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.832 (perp=9.491, rec=0.287, cos=0.647), tot_loss_proj:3.757 [t=0.30s]
prediction: ['[CLS] ¶ lewis retail \\ tagged baseball regulation with baseball. [SEP]']
[ 600/2000] tot_loss=2.670 (perp=8.829, rec=0.228, cos=0.676), tot_loss_proj:3.637 [t=0.30s]
prediction: ['[CLS] saturday lewis retail \\ tagged baseball regulation with baseball. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.598 (perp=8.390, rec=0.224, cos=0.697), tot_loss_proj:3.571 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged baseball retail with baseball. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.632 (perp=8.464, rec=0.223, cos=0.717), tot_loss_proj:3.572 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged retail baseball with hits. [SEP]']
[ 750/2000] tot_loss=2.625 (perp=8.464, rec=0.204, cos=0.728), tot_loss_proj:3.573 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged retail baseball with hits. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.647 (perp=8.464, rec=0.207, cos=0.747), tot_loss_proj:3.572 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged retail baseball with hits. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.628 (perp=8.464, rec=0.197, cos=0.738), tot_loss_proj:3.578 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged retail baseball with hits. [SEP]']
[ 900/2000] tot_loss=2.631 (perp=8.464, rec=0.196, cos=0.742), tot_loss_proj:3.572 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged retail baseball with hits. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.874 (perp=9.574, rec=0.205, cos=0.754), tot_loss_proj:3.787 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged retail baseball with freaking. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.661 (perp=8.518, rec=0.202, cos=0.755), tot_loss_proj:3.575 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged retail hits with baseball. [SEP]']
[1050/2000] tot_loss=2.782 (perp=9.179, rec=0.197, cos=0.749), tot_loss_proj:3.746 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged retail freaking with baseball. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.738 (perp=9.013, rec=0.181, cos=0.754), tot_loss_proj:3.665 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged retail fever with baseball. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.687 (perp=8.669, rec=0.194, cos=0.760), tot_loss_proj:3.629 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged fever retail with baseball. [SEP]']
[1200/2000] tot_loss=2.691 (perp=8.669, rec=0.198, cos=0.758), tot_loss_proj:3.629 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged fever retail with baseball. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.679 (perp=8.622, rec=0.194, cos=0.761), tot_loss_proj:3.621 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged anywhere retail with baseball. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.683 (perp=8.639, rec=0.193, cos=0.763), tot_loss_proj:3.637 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged friday retail with baseball. [SEP]']
[1350/2000] tot_loss=2.688 (perp=8.639, rec=0.193, cos=0.768), tot_loss_proj:3.638 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged friday retail with baseball. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.700 (perp=8.639, rec=0.208, cos=0.764), tot_loss_proj:3.635 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged friday retail with baseball. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.684 (perp=8.639, rec=0.190, cos=0.766), tot_loss_proj:3.629 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged friday retail with baseball. [SEP]']
[1500/2000] tot_loss=2.688 (perp=8.639, rec=0.193, cos=0.767), tot_loss_proj:3.630 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged friday retail with baseball. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.692 (perp=8.639, rec=0.193, cos=0.771), tot_loss_proj:3.637 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged friday retail with baseball. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.755 (perp=8.938, rec=0.199, cos=0.769), tot_loss_proj:3.647 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged friday subsequent with baseball. [SEP]']
[1650/2000] tot_loss=2.750 (perp=8.938, rec=0.189, cos=0.773), tot_loss_proj:3.645 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged friday subsequent with baseball. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.671 (perp=8.511, rec=0.198, cos=0.771), tot_loss_proj:3.530 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged subsequent friday with baseball. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.662 (perp=8.511, rec=0.189, cos=0.771), tot_loss_proj:3.526 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged subsequent friday with baseball. [SEP]']
[1800/2000] tot_loss=2.655 (perp=8.511, rec=0.182, cos=0.771), tot_loss_proj:3.522 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged subsequent friday with baseball. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.677 (perp=8.511, rec=0.201, cos=0.774), tot_loss_proj:3.537 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged subsequent friday with baseball. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.664 (perp=8.511, rec=0.187, cos=0.775), tot_loss_proj:3.529 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged subsequent friday with baseball. [SEP]']
[1950/2000] tot_loss=2.668 (perp=8.511, rec=0.191, cos=0.775), tot_loss_proj:3.529 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged subsequent friday with baseball. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.661 (perp=8.511, rec=0.186, cos=0.773), tot_loss_proj:3.526 [t=0.30s]
prediction: ['[CLS] john lewis regulation \\ tagged subsequent friday with baseball. [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]
========================
predicted: 
========================
[CLS] john lewis regulation \ tagged subsequent friday with baseball. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 80.000 | r: 72.727
rouge2     | fm: 10.526 | p: 11.111 | r: 10.000
rougeL     | fm: 57.143 | p: 60.000 | r: 54.545
rougeLsum  | fm: 57.143 | p: 60.000 | r: 54.545
r1fm+r2fm = 86.717

[Aggregate metrics]:
rouge1     | fm: 75.978 | p: 76.332 | r: 75.825
rouge2     | fm: 32.092 | p: 32.177 | r: 32.248
rougeL     | fm: 66.562 | p: 66.938 | r: 66.437
rougeLsum  | fm: 66.717 | p: 67.107 | r: 66.666
r1fm+r2fm = 108.071

input #48 time: 0:11:47 | total time: 9:45:46


Running input #49 of 100.
reference: 
========================
We all thought him to be unhappy
========================
average of cosine similarity 0.9989987462289078
highest_index [0]
highest [0.9989987462289078]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2057,  2035,  2245,  2032,  2000,  2022, 12511,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] we all thought him to be unhappy [SEP]']
[Init] best rec loss: 0.8601668477058411 for ['[CLS] mattermei visibly port brandenburgmissive le [SEP]']
[Init] best rec loss: 0.842728853225708 for ['[CLS] cominglett than carrier holiday exposed long [SEP]']
[Init] best rec loss: 0.836688220500946 for ['[CLS] turf rib hutually driven celine richards [SEP]']
[Init] best perm rec loss: 0.836248517036438 for ['[CLS] driven rib turf celine hutually richards [SEP]']
[Init] best perm rec loss: 0.835850179195404 for ['[CLS] celineually driven turf hut rib richards [SEP]']
[Init] best perm rec loss: 0.8343091607093811 for ['[CLS] turf celine hut richards driven ribually [SEP]']
[Init] best perm rec loss: 0.8337105512619019 for ['[CLS] richards drivenually hut turf rib celine [SEP]']
[Init] best perm rec loss: 0.8336783647537231 for ['[CLS] celine richardsually hut turf driven rib [SEP]']
[Init] best perm rec loss: 0.8334110975265503 for ['[CLS] richards turf drivenually celine rib hut [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.653 (perp=13.673, rec=0.582, cos=0.336), tot_loss_proj:4.578 [t=0.29s]
prediction: ['[CLS] wonderful angry/ patriarch parody boxing assembly [SEP]']
[ 100/2000] tot_loss=3.203 (perp=13.327, rec=0.412, cos=0.126), tot_loss_proj:4.542 [t=0.30s]
prediction: ['[CLS] immediate constanceanalysis assembly thought boxing of [SEP]']
[ 150/2000] tot_loss=3.275 (perp=14.476, rec=0.314, cos=0.066), tot_loss_proj:4.751 [t=0.30s]
prediction: ['[CLS] unhappy constance we him thought blu too [SEP]']
[ 200/2000] tot_loss=2.396 (perp=10.374, rec=0.264, cos=0.057), tot_loss_proj:3.951 [t=0.30s]
prediction: ['[CLS] unhappy him all him thought unhappy be [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.110 (perp=9.477, rec=0.189, cos=0.026), tot_loss_proj:3.766 [t=0.30s]
prediction: ['[CLS] unhappy him all him thought be unhappy [SEP]']
[ 300/2000] tot_loss=2.059 (perp=9.477, rec=0.148, cos=0.016), tot_loss_proj:3.760 [t=0.30s]
prediction: ['[CLS] unhappy him all him thought be unhappy [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.948 (perp=9.004, rec=0.133, cos=0.014), tot_loss_proj:3.569 [t=0.30s]
prediction: ['[CLS] unhappy him all thought him be unhappy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.941 (perp=9.004, rec=0.128, cos=0.013), tot_loss_proj:3.574 [t=0.30s]
prediction: ['[CLS] unhappy him all thought him be unhappy [SEP]']
[ 450/2000] tot_loss=1.926 (perp=9.004, rec=0.113, cos=0.012), tot_loss_proj:3.573 [t=0.30s]
prediction: ['[CLS] unhappy him all thought him be unhappy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.917 (perp=9.004, rec=0.105, cos=0.011), tot_loss_proj:3.576 [t=0.30s]
prediction: ['[CLS] unhappy him all thought him be unhappy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.927 (perp=9.004, rec=0.115, cos=0.011), tot_loss_proj:3.573 [t=0.30s]
prediction: ['[CLS] unhappy him all thought him be unhappy [SEP]']
[ 600/2000] tot_loss=1.830 (perp=8.555, rec=0.108, cos=0.011), tot_loss_proj:3.454 [t=0.30s]
prediction: ['[CLS] unhappy you all thought him be unhappy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.705 (perp=7.909, rec=0.113, cos=0.011), tot_loss_proj:3.308 [t=0.30s]
prediction: ['[CLS] unhappy we all thought him be unhappy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.845 (perp=8.651, rec=0.105, cos=0.010), tot_loss_proj:3.520 [t=0.30s]
prediction: ['[CLS] unhappy we all thought him to unhappy [SEP]']
[ 750/2000] tot_loss=1.664 (perp=7.789, rec=0.097, cos=0.008), tot_loss_proj:3.343 [t=0.30s]
prediction: ['[CLS] be we all thought him to unhappy [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.195 (perp=5.513, rec=0.086, cos=0.006), tot_loss_proj:1.296 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.176 (perp=5.513, rec=0.070, cos=0.004), tot_loss_proj:1.283 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
[ 900/2000] tot_loss=1.178 (perp=5.513, rec=0.073, cos=0.003), tot_loss_proj:1.291 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.166 (perp=5.513, rec=0.061, cos=0.003), tot_loss_proj:1.288 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.173 (perp=5.513, rec=0.068, cos=0.003), tot_loss_proj:1.285 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
[1050/2000] tot_loss=1.182 (perp=5.513, rec=0.077, cos=0.003), tot_loss_proj:1.276 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.178 (perp=5.513, rec=0.073, cos=0.003), tot_loss_proj:1.271 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.168 (perp=5.513, rec=0.063, cos=0.003), tot_loss_proj:1.271 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
[1200/2000] tot_loss=1.181 (perp=5.513, rec=0.076, cos=0.003), tot_loss_proj:1.269 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.172 (perp=5.513, rec=0.067, cos=0.003), tot_loss_proj:1.281 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.180 (perp=5.513, rec=0.075, cos=0.002), tot_loss_proj:1.272 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
[1350/2000] tot_loss=1.175 (perp=5.513, rec=0.070, cos=0.002), tot_loss_proj:1.267 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.167 (perp=5.513, rec=0.062, cos=0.002), tot_loss_proj:1.277 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.182 (perp=5.513, rec=0.077, cos=0.002), tot_loss_proj:1.272 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
[1500/2000] tot_loss=1.173 (perp=5.513, rec=0.068, cos=0.002), tot_loss_proj:1.279 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.174 (perp=5.513, rec=0.069, cos=0.002), tot_loss_proj:1.265 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.166 (perp=5.513, rec=0.061, cos=0.002), tot_loss_proj:1.268 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
[1650/2000] tot_loss=1.172 (perp=5.513, rec=0.067, cos=0.002), tot_loss_proj:1.268 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.172 (perp=5.513, rec=0.067, cos=0.002), tot_loss_proj:1.261 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.158 (perp=5.513, rec=0.053, cos=0.002), tot_loss_proj:1.262 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
[1800/2000] tot_loss=1.171 (perp=5.513, rec=0.066, cos=0.002), tot_loss_proj:1.269 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.166 (perp=5.513, rec=0.061, cos=0.002), tot_loss_proj:1.269 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.164 (perp=5.513, rec=0.059, cos=0.002), tot_loss_proj:1.276 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
[1950/2000] tot_loss=1.164 (perp=5.513, rec=0.060, cos=0.002), tot_loss_proj:1.270 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.161 (perp=5.513, rec=0.056, cos=0.002), tot_loss_proj:1.268 [t=0.30s]
prediction: ['[CLS] we all thought him to be unhappy [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] we all thought him to be unhappy [SEP]
========================
predicted: 
========================
[CLS] we all thought him to be unhappy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 76.421 | p: 76.690 | r: 76.345
rouge2     | fm: 33.372 | p: 33.353 | r: 33.467
rougeL     | fm: 67.324 | p: 67.640 | r: 67.219
rougeLsum  | fm: 67.410 | p: 67.754 | r: 67.324
r1fm+r2fm = 109.793

input #49 time: 0:11:48 | total time: 9:57:34


Running input #50 of 100.
reference: 
========================
Book is available in most countries.
========================
average of cosine similarity 0.9989049734245531
highest_index [0]
highest [0.9989049734245531]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2338, 2003, 2800, 1999, 2087, 3032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] book is available in most countries. [SEP]']
[Init] best rec loss: 0.7743157744407654 for ['[CLS] keyxy neither jenksuka chow administration [SEP]']
[Init] best rec loss: 0.7582876682281494 for ['[CLS] rev vaughn debut inspiration theme mind wonder [SEP]']
[Init] best rec loss: 0.7566747069358826 for ['[CLS] tapes [SEP] stronger u part radio tropical [SEP]']
[Init] best rec loss: 0.7503904700279236 for ['[CLS]... sparhawk marshall take chase middle aviv [SEP]']
[Init] best rec loss: 0.7370372414588928 for ['[CLS]yingyme put perimeter cancer fiber poems [SEP]']
[Init] best rec loss: 0.6862602829933167 for ['[CLS]ers quality thereafter small conversations gaius sven [SEP]']
[Init] best perm rec loss: 0.679960310459137 for ['[CLS] thereafter sven gaius small conversations qualityers [SEP]']
[Init] best perm rec loss: 0.6788294315338135 for ['[CLS] sven small conversations quality thereafter gaiusers [SEP]']
[Init] best perm rec loss: 0.675777792930603 for ['[CLS] small gaius thereafter quality sveners conversations [SEP]']
[Init] best perm rec loss: 0.6755973100662231 for ['[CLS]ers conversations sven quality small gaius thereafter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.312 (perp=8.921, rec=0.369, cos=0.159), tot_loss_proj:2.668 [t=0.29s]
prediction: ['[CLS] book relevant book. androidbook available [SEP]']
[ 100/2000] tot_loss=2.547 (perp=10.441, rec=0.289, cos=0.170), tot_loss_proj:3.090 [t=0.30s]
prediction: ['[CLS] book applications book is reaching cyprus available [SEP]']
[ 150/2000] tot_loss=2.750 (perp=11.793, rec=0.248, cos=0.143), tot_loss_proj:3.363 [t=0.30s]
prediction: ['[CLS] booktech book is haired upwards available [SEP]']
[ 200/2000] tot_loss=2.622 (perp=10.950, rec=0.249, cos=0.183), tot_loss_proj:3.129 [t=0.30s]
prediction: ['[CLS] book adult book is haired worldwide available [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.274 (perp=9.324, rec=0.218, cos=0.191), tot_loss_proj:2.675 [t=0.30s]
prediction: ['[CLS] book adult book is available anywhere everyone [SEP]']
[ 300/2000] tot_loss=2.394 (perp=9.976, rec=0.216, cos=0.183), tot_loss_proj:2.715 [t=0.30s]
prediction: ['[CLS] book cargo book is available anywhere vantage [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.410 (perp=9.801, rec=0.248, cos=0.202), tot_loss_proj:3.117 [t=0.30s]
prediction: ['[CLS] bookbian worldwideply is available across [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.269 (perp=8.852, rec=0.316, cos=0.182), tot_loss_proj:3.012 [t=0.30s]
prediction: ['[CLS] book corps together is available anywhere worldwide [SEP]']
[ 450/2000] tot_loss=2.547 (perp=10.445, rec=0.311, cos=0.147), tot_loss_proj:3.218 [t=0.30s]
prediction: ['[CLS] book fist caucus is available ncaa worldwide [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.445 (perp=10.010, rec=0.264, cos=0.180), tot_loss_proj:2.998 [t=0.30s]
prediction: ['[CLS] book anywhere gang shelf is available worldwide [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.197 (perp=8.807, rec=0.260, cos=0.176), tot_loss_proj:2.603 [t=0.30s]
prediction: ['[CLS] book gang shelf is anywhere available worldwide [SEP]']
[ 600/2000] tot_loss=2.358 (perp=9.640, rec=0.241, cos=0.188), tot_loss_proj:2.718 [t=0.30s]
prediction: ['[CLS] book gang shelf is across available worldwide [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.145 (perp=8.655, rec=0.228, cos=0.186), tot_loss_proj:2.454 [t=0.30s]
prediction: ['[CLS] book gang shelf is available across worldwide [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.271 (perp=9.214, rec=0.241, cos=0.187), tot_loss_proj:2.980 [t=0.30s]
prediction: ['[CLS] bookre shelf is available across worldwide [SEP]']
[ 750/2000] tot_loss=2.111 (perp=8.469, rec=0.236, cos=0.181), tot_loss_proj:2.761 [t=0.30s]
prediction: ['[CLS] bookop shelf is available across worldwide [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.282 (perp=9.306, rec=0.228, cos=0.193), tot_loss_proj:3.475 [t=0.30s]
prediction: ['[CLS] bookop advancement is available across worldwide [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.267 (perp=9.274, rec=0.228, cos=0.183), tot_loss_proj:3.678 [t=0.30s]
prediction: ['[CLS] bookop advancement is generally available across [SEP]']
[ 900/2000] tot_loss=2.269 (perp=9.291, rec=0.222, cos=0.189), tot_loss_proj:3.638 [t=0.30s]
prediction: ['[CLS] bookop advancement is generally available anywhere [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.270 (perp=9.291, rec=0.222, cos=0.190), tot_loss_proj:3.647 [t=0.30s]
prediction: ['[CLS] bookop advancement is generally available anywhere [SEP]']
Attempt swap
[1000/2000] tot_loss=2.271 (perp=9.291, rec=0.224, cos=0.189), tot_loss_proj:3.639 [t=0.30s]
prediction: ['[CLS] bookop advancement is generally available anywhere [SEP]']
[1050/2000] tot_loss=2.275 (perp=9.291, rec=0.226, cos=0.191), tot_loss_proj:3.642 [t=0.30s]
prediction: ['[CLS] bookop advancement is generally available anywhere [SEP]']
Attempt swap
[1100/2000] tot_loss=2.280 (perp=9.291, rec=0.231, cos=0.190), tot_loss_proj:3.643 [t=0.30s]
prediction: ['[CLS] bookop advancement is generally available anywhere [SEP]']
Attempt swap
[1150/2000] tot_loss=2.356 (perp=9.750, rec=0.216, cos=0.190), tot_loss_proj:2.977 [t=0.30s]
prediction: ['[CLS] bookop advancement is generally available countries [SEP]']
[1200/2000] tot_loss=2.368 (perp=9.750, rec=0.228, cos=0.190), tot_loss_proj:2.983 [t=0.30s]
prediction: ['[CLS] bookop advancement is generally available countries [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.596 (perp=11.017, rec=0.228, cos=0.164), tot_loss_proj:2.980 [t=0.30s]
prediction: ['[CLS] book cdp advancement across is worldwide available [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.406 (perp=9.998, rec=0.237, cos=0.169), tot_loss_proj:2.808 [t=0.30s]
prediction: ['[CLS] book cdp advancement across worldwide is available [SEP]']
[1350/2000] tot_loss=2.398 (perp=9.998, rec=0.229, cos=0.170), tot_loss_proj:2.803 [t=0.30s]
prediction: ['[CLS] book cdp advancement across worldwide is available [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.369 (perp=9.853, rec=0.231, cos=0.167), tot_loss_proj:2.963 [t=0.30s]
prediction: ['[CLS] book advancement countries cdp worldwide is available [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=2.273 (perp=9.355, rec=0.225, cos=0.177), tot_loss_proj:3.066 [t=0.30s]
prediction: ['[CLS] book advancement countries cdp is available worldwide [SEP]']
[1500/2000] tot_loss=2.281 (perp=9.355, rec=0.228, cos=0.181), tot_loss_proj:3.069 [t=0.30s]
prediction: ['[CLS] book advancement countries cdp is available worldwide [SEP]']
Attempt swap
[1550/2000] tot_loss=2.228 (perp=9.079, rec=0.232, cos=0.180), tot_loss_proj:3.251 [t=0.30s]
prediction: ['[CLS] book shelf countries cdp is available worldwide [SEP]']
Attempt swap
[1600/2000] tot_loss=2.217 (perp=9.079, rec=0.220, cos=0.181), tot_loss_proj:3.246 [t=0.30s]
prediction: ['[CLS] book shelf countries cdp is available worldwide [SEP]']
[1650/2000] tot_loss=2.503 (perp=10.487, rec=0.224, cos=0.181), tot_loss_proj:3.033 [t=0.30s]
prediction: ['[CLS] book advancement countries cdp is available generally [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.296 (perp=9.519, rec=0.210, cos=0.183), tot_loss_proj:2.927 [t=0.30s]
prediction: ['[CLS] book advancement countries cdp is generally available [SEP]']
Attempt swap
[1750/2000] tot_loss=2.297 (perp=9.519, rec=0.211, cos=0.183), tot_loss_proj:2.935 [t=0.30s]
prediction: ['[CLS] book advancement countries cdp is generally available [SEP]']
[1800/2000] tot_loss=2.305 (perp=9.519, rec=0.219, cos=0.183), tot_loss_proj:2.931 [t=0.30s]
prediction: ['[CLS] book advancement countries cdp is generally available [SEP]']
Attempt swap
[1850/2000] tot_loss=2.433 (perp=10.141, rec=0.221, cos=0.183), tot_loss_proj:3.078 [t=0.30s]
prediction: ['[CLS] book advancement countries cdp is worldwide available [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.487 (perp=10.487, rec=0.209, cos=0.181), tot_loss_proj:3.022 [t=0.30s]
prediction: ['[CLS] book advancement countries cdp is available generally [SEP]']
[1950/2000] tot_loss=2.494 (perp=10.487, rec=0.214, cos=0.183), tot_loss_proj:3.027 [t=0.30s]
prediction: ['[CLS] book advancement countries cdp is available generally [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.311 (perp=9.519, rec=0.224, cos=0.184), tot_loss_proj:2.932 [t=0.30s]
prediction: ['[CLS] book advancement countries cdp is generally available [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] book is available in most countries. [SEP]
========================
predicted: 
========================
[CLS] bookop advancement is generally available anywhere [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 50.000 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 75.952 | p: 76.266 | r: 75.916
rouge2     | fm: 32.764 | p: 32.853 | r: 32.907
rougeL     | fm: 66.991 | p: 67.285 | r: 66.836
rougeLsum  | fm: 67.110 | p: 67.495 | r: 67.056
r1fm+r2fm = 108.716

input #50 time: 0:11:48 | total time: 10:09:23


Running input #51 of 100.
reference: 
========================
I could have little known that more trouble was just around the corner.
========================
average of cosine similarity 0.9989121896490988
highest_index [0]
highest [0.9989121896490988]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2071, 2031, 2210, 2124, 2008, 2062, 4390, 2001, 2074, 2105,
         1996, 3420, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i could have little known that more trouble was just around the corner. [SEP]']
[Init] best rec loss: 0.960706889629364 for ['[CLS] missing coincidence ten ideas gas need status singleton silver considered demolished tale convert grumbled [SEP]']
[Init] best rec loss: 0.9505006670951843 for ['[CLS] clshfalls chicago walled steps turn photos tell covers yet letter xx table [SEP]']
[Init] best rec loss: 0.938202977180481 for ['[CLS] individual serving mediterraneanwylwart date touchwest mined styx pot barefoot buttonilla [SEP]']
[Init] best rec loss: 0.9285892248153687 for ['[CLS] reason strength trains chance dawsonwyl milk diplomatic tie chance parked honey summer associated [SEP]']
[Init] best rec loss: 0.9144723415374756 for ['[CLS] mina back rot release called yes half [SEP] commercialuru startutunt hell [SEP]']
[Init] best rec loss: 0.9021613001823425 for ['[CLS] foreign a retirement electedheadborough rising passenger wanda publishing graduates tor special mill [SEP]']
[Init] best rec loss: 0.8939237594604492 for ['[CLS] pricecion desmond scientist delayed idea plan nt wheel little staying one tattooscamp [SEP]']
[Init] best rec loss: 0.889881432056427 for ['[CLS] you background votes ruled court visual plain belongings into agent trrri aheadified [SEP]']
[Init] best rec loss: 0.8896859288215637 for ['[CLS] waitedlving darkness reads initiation plug two houseual effortsrah delay stone tertiary [SEP]']
[Init] best rec loss: 0.8871657848358154 for ['[CLS] placement communication multiple eye blu academy ant convoy royals territories balloon wolf demos vance [SEP]']
[Init] best rec loss: 0.8617769479751587 for ['[CLS] bold lloyd livingae consistent usa inactive become flowersios zealand willing pillow each [SEP]']
[Init] best perm rec loss: 0.8617385029792786 for ['[CLS] each bold usaae willing consistentios pillow living flowers become lloyd zealand inactive [SEP]']
[Init] best perm rec loss: 0.8598772287368774 for ['[CLS] willing flowers usa zealandios living become inactiveae pillow bold lloyd each consistent [SEP]']
[Init] best perm rec loss: 0.8573151230812073 for ['[CLS] pillow flowers usa zealand become inactive lloyd consistent willing eachaeios bold living [SEP]']
[Init] best perm rec loss: 0.856626033782959 for ['[CLS] pillow bold usa consistentios zealand flowers willing each becomeae lloyd living inactive [SEP]']
[Init] best perm rec loss: 0.8562399744987488 for ['[CLS] pillow each zealand usaios become boldae lloyd flowers living willing inactive consistent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.916 (perp=11.617, rec=0.393, cos=0.199), tot_loss_proj:4.202 [t=0.29s]
prediction: ['[CLS] smaller term. ama modern news benji assistance sections more. energy motorsportssville [SEP]']
[ 100/2000] tot_loss=2.825 (perp=11.904, rec=0.322, cos=0.123), tot_loss_proj:4.279 [t=0.30s]
prediction: ['[CLS] smaller trouble. james many known dion trouble just more. activity trouble trouble [SEP]']
[ 150/2000] tot_loss=1.751 (perp=7.214, rec=0.247, cos=0.061), tot_loss_proj:3.344 [t=0.30s]
prediction: ['[CLS] more trouble. i little known had trouble just more. has trouble was [SEP]']
[ 200/2000] tot_loss=1.786 (perp=7.812, rec=0.182, cos=0.041), tot_loss_proj:3.424 [t=0.30s]
prediction: ['[CLS] more trouble. have little known that trouble just more. corner trouble was [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.810 (perp=8.092, rec=0.162, cos=0.030), tot_loss_proj:3.425 [t=0.30s]
prediction: ['[CLS] more trouble. have little known because trouble just more corner corner was. [SEP]']
[ 300/2000] tot_loss=1.929 (perp=8.960, rec=0.115, cos=0.022), tot_loss_proj:3.674 [t=0.30s]
prediction: ['[CLS] more trouble dismiss have little known that trouble just more the corner was. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.537 (perp=6.991, rec=0.126, cos=0.013), tot_loss_proj:3.210 [t=0.30s]
prediction: ['[CLS] more trouble could have little known that trouble just was the corner more. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.891 (perp=6.493, rec=0.641, cos=0.951), tot_loss_proj:3.158 [t=0.30s]
prediction: ['[CLS] more trouble would i known that little trouble around was the corner more. [SEP]']
[ 450/2000] tot_loss=2.490 (perp=6.687, rec=0.382, cos=0.770), tot_loss_proj:3.199 [t=0.30s]
prediction: ['[CLS] more trouble could i known that little trouble around was the corner more. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.308 (perp=6.155, rec=0.303, cos=0.774), tot_loss_proj:3.150 [t=0.30s]
prediction: ['[CLS] more trouble could i known that little trouble around the corner was more. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.262 (perp=6.155, rec=0.292, cos=0.739), tot_loss_proj:3.146 [t=0.30s]
prediction: ['[CLS] more trouble could i known that little trouble around the corner was more. [SEP]']
[ 600/2000] tot_loss=2.281 (perp=6.155, rec=0.274, cos=0.776), tot_loss_proj:3.145 [t=0.30s]
prediction: ['[CLS] more trouble could i known that little trouble around the corner was more. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.256 (perp=6.155, rec=0.261, cos=0.763), tot_loss_proj:3.137 [t=0.30s]
prediction: ['[CLS] more trouble could i known that little trouble around the corner was more. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.164 (perp=5.676, rec=0.245, cos=0.784), tot_loss_proj:3.033 [t=0.30s]
prediction: ['[CLS] more trouble could i known that little was more trouble around the corner. [SEP]']
[ 750/2000] tot_loss=2.164 (perp=5.676, rec=0.250, cos=0.778), tot_loss_proj:3.032 [t=0.30s]
prediction: ['[CLS] more trouble could i known that little was more trouble around the corner. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.036 (perp=5.206, rec=0.240, cos=0.755), tot_loss_proj:2.881 [t=0.30s]
prediction: ['[CLS] more trouble could have known that little was more trouble around the corner. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.200 (perp=6.086, rec=0.220, cos=0.762), tot_loss_proj:3.065 [t=0.30s]
prediction: ['[CLS] more trouble little have known that little was more trouble around the corner. [SEP]']
[ 900/2000] tot_loss=2.240 (perp=6.152, rec=0.229, cos=0.780), tot_loss_proj:3.065 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.202 (perp=6.152, rec=0.215, cos=0.756), tot_loss_proj:3.066 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.216 (perp=6.152, rec=0.217, cos=0.768), tot_loss_proj:3.064 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
[1050/2000] tot_loss=2.218 (perp=6.152, rec=0.217, cos=0.770), tot_loss_proj:3.063 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.195 (perp=6.152, rec=0.204, cos=0.760), tot_loss_proj:3.064 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.199 (perp=6.152, rec=0.204, cos=0.764), tot_loss_proj:3.065 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
[1200/2000] tot_loss=2.219 (perp=6.152, rec=0.216, cos=0.772), tot_loss_proj:3.060 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.217 (perp=6.152, rec=0.223, cos=0.763), tot_loss_proj:3.062 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.211 (perp=6.152, rec=0.207, cos=0.774), tot_loss_proj:3.058 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
[1350/2000] tot_loss=2.210 (perp=6.152, rec=0.211, cos=0.769), tot_loss_proj:3.061 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.211 (perp=6.152, rec=0.206, cos=0.774), tot_loss_proj:3.062 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.125 (perp=5.630, rec=0.224, cos=0.776), tot_loss_proj:2.969 [t=0.30s]
prediction: ['[CLS] some little trouble have known that little was more trouble around the corner. [SEP]']
[1500/2000] tot_loss=2.407 (perp=7.083, rec=0.214, cos=0.776), tot_loss_proj:3.277 [t=0.30s]
prediction: ['[CLS]rained little trouble have known that little was more trouble around the corner. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.376 (perp=6.935, rec=0.213, cos=0.776), tot_loss_proj:3.252 [t=0.30s]
prediction: ['[CLS]rained trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.222 (perp=6.152, rec=0.219, cos=0.772), tot_loss_proj:3.058 [t=0.30s]
prediction: ['[CLS] some trouble little have known that little was more trouble around the corner. [SEP]']
[1650/2000] tot_loss=2.364 (perp=6.935, rec=0.204, cos=0.773), tot_loss_proj:3.247 [t=0.30s]
prediction: ['[CLS]rained trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.370 (perp=6.935, rec=0.211, cos=0.773), tot_loss_proj:3.252 [t=0.30s]
prediction: ['[CLS]rained trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.363 (perp=6.935, rec=0.202, cos=0.773), tot_loss_proj:3.247 [t=0.30s]
prediction: ['[CLS]rained trouble little have known that little was more trouble around the corner. [SEP]']
[1800/2000] tot_loss=2.370 (perp=6.935, rec=0.209, cos=0.774), tot_loss_proj:3.247 [t=0.30s]
prediction: ['[CLS]rained trouble little have known that little was more trouble around the corner. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.357 (perp=6.921, rec=0.202, cos=0.771), tot_loss_proj:3.222 [t=0.30s]
prediction: ['[CLS]rained trouble little have known that little trouble was more around the corner. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.358 (perp=6.921, rec=0.197, cos=0.776), tot_loss_proj:3.230 [t=0.30s]
prediction: ['[CLS]rained trouble little have known that little trouble was more around the corner. [SEP]']
[1950/2000] tot_loss=2.369 (perp=6.921, rec=0.208, cos=0.776), tot_loss_proj:3.224 [t=0.30s]
prediction: ['[CLS]rained trouble little have known that little trouble was more around the corner. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.361 (perp=6.921, rec=0.199, cos=0.777), tot_loss_proj:3.227 [t=0.30s]
prediction: ['[CLS]rained trouble little have known that little trouble was more around the corner. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] i could have little known that more trouble was just around the corner. [SEP]
========================
predicted: 
========================
[CLS] more trouble could have little known that trouble just was the corner more. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.667 | p: 86.667 | r: 86.667
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 73.333 | p: 73.333 | r: 73.333
rougeLsum  | fm: 73.333 | p: 73.333 | r: 73.333
r1fm+r2fm = 129.524

[Aggregate metrics]:
rouge1     | fm: 76.164 | p: 76.476 | r: 76.125
rouge2     | fm: 33.032 | p: 33.101 | r: 33.107
rougeL     | fm: 67.067 | p: 67.443 | r: 66.957
rougeLsum  | fm: 67.159 | p: 67.472 | r: 67.067
r1fm+r2fm = 109.196

input #51 time: 0:11:47 | total time: 10:21:10


Running input #52 of 100.
reference: 
========================
John gave the books to Mary at Christmas, and the records to Sue for her birthday.
========================
average of cosine similarity 0.9988206627614328
highest_index [0]
highest [0.9988206627614328]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2198, 2435, 1996, 2808, 2000, 2984, 2012, 4234, 1010, 1998, 1996,
         2636, 2000, 9790, 2005, 2014, 5798, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]']
[Init] best rec loss: 0.9312472343444824 for ['[CLS] drama establishments wicket vocal willem presence arm australia dashed guineaturn hand converse sparrow mastof hueymined [SEP]']
[Init] best rec loss: 0.8803404569625854 for ['[CLS] sweeping > tightened games today iris draw den whether come yellow sawyer flood exactly archives champion painter minds [SEP]']
[Init] best rec loss: 0.8727186918258667 for ['[CLS] graves handel reflects westfall meaning particles dogs involving spoke fake total fair sc llti distribution myself [SEP]']
[Init] best rec loss: 0.8595693111419678 for ['[CLS] 2009 move hop kentonkel george door... danefixed finished mo fall sweat most daughter contentnote [SEP]']
[Init] best rec loss: 0.8591278791427612 for ["[CLS] focuses blowhen lutheryckbridge paid samson household santaking rate elliott sole lives'forest mandal [SEP]"]
[Init] best rec loss: 0.8533632755279541 for ['[CLS] love scene produced play valkyrieadia city ip push challenging tilligan cornerback coco oddeng fly object [SEP]']
[Init] best rec loss: 0.8511006236076355 for ['[CLS] building puppy sent fear shoulder contracted torch inspector surfaceaneous marino knitian soxllen established packaging go [SEP]']
[Init] best rec loss: 0.8504607677459717 for ['[CLS] scale father guadalupe landing schedule divert map college resistance salad ray advertising operatedeno example face against performance [SEP]']
[Init] best rec loss: 0.8447168469429016 for ['[CLS] lead dam yielded eu sound bridge pilot istir squatjord× title aluminium ends no equal life [SEP]']
[Init] best rec loss: 0.8416621685028076 for ['[CLS] dentisterted along gross sins such blame nicky grove metropolitan [CLS] tow her positively exit ucla hack subject [SEP]']
[Init] best rec loss: 0.8314036130905151 for ['[CLS] ask dharma m ant biennaleraction cc background scraped method whitman machine finally herbal domain ll meck [SEP]']
[Init] best perm rec loss: 0.8306678533554077 for ['[CLS] whitman askractioneck scraped m ant method domain biennale dharma cc herbal finally machine m ll background [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.054 (perp=13.031, rec=0.642, cos=0.806), tot_loss_proj:4.391 [t=0.30s]
prediction: ['[CLS] decides justine.verance amelie culture. much fl reissued crymac sue attorney vampires books young parts [SEP]']
[ 100/2000] tot_loss=3.528 (perp=11.748, rec=0.488, cos=0.691), tot_loss_proj:4.211 [t=0.30s]
prediction: ['[CLS] fatty holmes of hey - divorce.. sue friendship teeth. sue dracula revival books ho fighting [SEP]']
[ 150/2000] tot_loss=3.275 (perp=10.886, rec=0.420, cos=0.678), tot_loss_proj:4.031 [t=0.30s]
prediction: ['[CLS] sue betrayed to grab public grammy.. sueono teeth. sue sue album books ho fighting [SEP]']
[ 200/2000] tot_loss=3.016 (perp=9.902, rec=0.392, cos=0.644), tot_loss_proj:3.802 [t=0.30s]
prediction: ['[CLS] sue holmes to grab their divorce. records sueono teeth. sue sue album books ho incident [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.068 (perp=8.955, rec=0.528, cos=0.748), tot_loss_proj:3.651 [t=0.30s]
prediction: ['[CLS] anna drilled to grab their books ;, could position sue. sue baby appearances books the incident [SEP]']
[ 300/2000] tot_loss=3.033 (perp=9.523, rec=0.411, cos=0.717), tot_loss_proj:3.695 [t=0.30s]
prediction: ['[CLS] ono drilled to spite their records. enough his keyboard sue. sue manuscript appearances records. incident [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.060 (perp=9.845, rec=0.430, cos=0.660), tot_loss_proj:3.848 [t=0.30s]
prediction: ['[CLS] bwf and to index their records. records his stress sue campaign sue sue album records hundred ( [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.912 (perp=9.496, rec=0.373, cos=0.640), tot_loss_proj:3.771 [t=0.30s]
prediction: ['[CLS] sue and to index their records. hisを stress sue campaign sue sue album records hundred " [SEP]']
[ 450/2000] tot_loss=3.167 (perp=10.609, rec=0.340, cos=0.706), tot_loss_proj:3.985 [t=0.30s]
prediction: ['[CLS] sue and to index the records. his jenks stress sue hairy sue sue diocese records hundred " [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.962 (perp=9.648, rec=0.331, cos=0.701), tot_loss_proj:3.801 [t=0.30s]
prediction: ['[CLS] sue and stress index the records. to label to sue 2004 sue sue diocese records hundred " [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.900 (perp=9.511, rec=0.319, cos=0.679), tot_loss_proj:3.671 [t=0.30s]
prediction: ['[CLS] sue and stress index the records. sue jenks to sue 2003 sue to diocese records hundred " [SEP]']
[ 600/2000] tot_loss=2.801 (perp=9.053, rec=0.311, cos=0.680), tot_loss_proj:3.649 [t=0.30s]
prediction: ['[CLS] sue and christmas index the records and sue jenks to sue. sue to diocese records hundred " [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.678 (perp=8.543, rec=0.301, cos=0.669), tot_loss_proj:3.531 [t=0.30s]
prediction: ['[CLS] sue and mary index the records and christmas jenks to sue. sue to diocese records division " [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.613 (perp=8.170, rec=0.299, cos=0.680), tot_loss_proj:3.515 [t=0.30s]
prediction: ['[CLS] sue and mary diocese the records and christmas jenks to sue. sue to index records division " [SEP]']
[ 750/2000] tot_loss=2.599 (perp=8.170, rec=0.289, cos=0.676), tot_loss_proj:3.509 [t=0.30s]
prediction: ['[CLS] sue and mary diocese the records and christmas jenks to sue. sue to index records division " [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.397 (perp=7.203, rec=0.293, cos=0.663), tot_loss_proj:3.255 [t=0.30s]
prediction: ['[CLS] sue and mary diocese gave records and to jenks to sue. sue christmas index records division. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.381 (perp=7.203, rec=0.277, cos=0.664), tot_loss_proj:3.252 [t=0.30s]
prediction: ['[CLS] sue and mary diocese gave records and to jenks to sue. sue christmas index records division. [SEP]']
[ 900/2000] tot_loss=2.395 (perp=7.203, rec=0.287, cos=0.668), tot_loss_proj:3.252 [t=0.30s]
prediction: ['[CLS] sue and mary diocese gave records and to jenks to sue. sue christmas index records division. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.393 (perp=7.203, rec=0.276, cos=0.677), tot_loss_proj:3.249 [t=0.30s]
prediction: ['[CLS] sue and mary diocese gave records and to jenks to sue. sue christmas index records division. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.631 (perp=8.359, rec=0.281, cos=0.678), tot_loss_proj:3.392 [t=0.30s]
prediction: ['[CLS] sue and mary birthday gave records and to jenks to sue. sue christmas index records division to [SEP]']
[1050/2000] tot_loss=2.624 (perp=8.359, rec=0.276, cos=0.676), tot_loss_proj:3.390 [t=0.30s]
prediction: ['[CLS] sue and mary birthday gave records and to jenks to sue. sue christmas index records division to [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.633 (perp=8.330, rec=0.283, cos=0.685), tot_loss_proj:3.475 [t=0.30s]
prediction: ['[CLS] sue and mary gave birthday records and to anniversary to sue. sue christmas index records division to [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.564 (perp=8.028, rec=0.281, cos=0.678), tot_loss_proj:3.415 [t=0.30s]
prediction: ['[CLS] sue and mary gave birthday records and anniversary to to sue. sue christmas index records division to [SEP]']
[1200/2000] tot_loss=2.558 (perp=8.028, rec=0.266, cos=0.687), tot_loss_proj:3.412 [t=0.30s]
prediction: ['[CLS] sue and mary gave birthday records and anniversary to to sue. sue christmas index records division to [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.476 (perp=7.646, rec=0.266, cos=0.681), tot_loss_proj:3.359 [t=0.30s]
prediction: ['[CLS] sue and mary gave birthday records to anniversary and to sue. sue christmas index records division to [SEP]']
Attempt swap
[1300/2000] tot_loss=2.529 (perp=7.646, rec=0.278, cos=0.722), tot_loss_proj:3.361 [t=0.30s]
prediction: ['[CLS] sue and mary gave birthday records to anniversary and to sue. sue christmas index records division to [SEP]']
[1350/2000] tot_loss=2.419 (perp=7.294, rec=0.273, cos=0.688), tot_loss_proj:3.273 [t=0.30s]
prediction: ['[CLS] sue and mary gave birthday records to anniversary and to sue. sue christmas index records gave to [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.564 (perp=8.025, rec=0.271, cos=0.688), tot_loss_proj:3.422 [t=0.30s]
prediction: ['[CLS] sue and mary gave birthday records to anniversary and to sue. sue division christmas index records to [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.501 (perp=7.679, rec=0.275, cos=0.690), tot_loss_proj:3.407 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas index records to'[SEP]"]
[1500/2000] tot_loss=2.502 (perp=7.679, rec=0.277, cos=0.689), tot_loss_proj:3.408 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas index records to'[SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.437 (perp=7.433, rec=0.261, cos=0.690), tot_loss_proj:3.347 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas records index to'[SEP]"]
Attempt swap
[1600/2000] tot_loss=2.439 (perp=7.433, rec=0.262, cos=0.691), tot_loss_proj:3.346 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas records index to'[SEP]"]
[1650/2000] tot_loss=2.454 (perp=7.433, rec=0.277, cos=0.690), tot_loss_proj:3.345 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas records index to'[SEP]"]
Attempt swap
[1700/2000] tot_loss=2.443 (perp=7.433, rec=0.263, cos=0.693), tot_loss_proj:3.342 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas records index to'[SEP]"]
Attempt swap
[1750/2000] tot_loss=2.442 (perp=7.433, rec=0.262, cos=0.693), tot_loss_proj:3.344 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas records index to'[SEP]"]
[1800/2000] tot_loss=2.441 (perp=7.433, rec=0.261, cos=0.693), tot_loss_proj:3.346 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas records index to'[SEP]"]
Attempt swap
[1850/2000] tot_loss=2.441 (perp=7.433, rec=0.259, cos=0.695), tot_loss_proj:3.348 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas records index to'[SEP]"]
Attempt swap
[1900/2000] tot_loss=2.442 (perp=7.433, rec=0.259, cos=0.697), tot_loss_proj:3.349 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas records index to'[SEP]"]
[1950/2000] tot_loss=2.449 (perp=7.433, rec=0.268, cos=0.695), tot_loss_proj:3.345 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas records index to'[SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.446 (perp=7.483, rec=0.256, cos=0.693), tot_loss_proj:3.364 [t=0.30s]
prediction: ["[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas records'to index [SEP]"]
Done with input #52 of 100.
reference: 
========================
[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]
========================
predicted: 
========================
[CLS] sue and mary gave birthday records to anniversary and to birthday. sue christmas records index to'[SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.111 | p: 61.111 | r: 61.111
rouge2     | fm: 5.882 | p: 5.882 | r: 5.882
rougeL     | fm: 38.889 | p: 38.889 | r: 38.889
rougeLsum  | fm: 38.889 | p: 38.889 | r: 38.889
r1fm+r2fm = 66.993

[Aggregate metrics]:
rouge1     | fm: 75.895 | p: 76.138 | r: 75.827
rouge2     | fm: 32.520 | p: 32.618 | r: 32.726
rougeL     | fm: 66.572 | p: 66.895 | r: 66.458
rougeLsum  | fm: 66.652 | p: 66.929 | r: 66.541
r1fm+r2fm = 108.415

input #52 time: 0:12:04 | total time: 10:33:15


Running input #53 of 100.
reference: 
========================
He said that himself was hungry.
========================
average of cosine similarity 0.9988953910756476
highest_index [0]
highest [0.9988953910756476]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2056, 2008, 2370, 2001, 7501, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he said that himself was hungry. [SEP]']
[Init] best rec loss: 0.9283839464187622 for ['[CLS] syncoc youth also returning jaguar flower [SEP]']
[Init] best rec loss: 0.9049204587936401 for ['[CLS] terms expireditanupt racing everuating [SEP]']
[Init] best rec loss: 0.8939611911773682 for ['[CLS] these once ofents intensive course vu [SEP]']
[Init] best rec loss: 0.8599352836608887 for ['[CLS] over breed [CLS] mentioned pitched genus memories [SEP]']
[Init] best rec loss: 0.8579868674278259 for ['[CLS] maha proof off experience occupation award advance [SEP]']
[Init] best rec loss: 0.8241276144981384 for ['[CLS]ique reachedel counterparts daviesility therapy [SEP]']
[Init] best rec loss: 0.8050954937934875 for ['[CLS] without plays twinned a ca writ ezra [SEP]']
[Init] best rec loss: 0.7886353135108948 for ['[CLS] gravel shooter promotion rios press eve voyage [SEP]']
[Init] best perm rec loss: 0.7861666083335876 for ['[CLS] gravel press shooter voyage rios promotion eve [SEP]']
[Init] best perm rec loss: 0.7844818830490112 for ['[CLS] eve press gravel rios promotion shooter voyage [SEP]']
[Init] best perm rec loss: 0.7839310169219971 for ['[CLS] eve press shooter gravel rios promotion voyage [SEP]']
[Init] best perm rec loss: 0.7836697101593018 for ['[CLS] gravel rios eve voyage press promotion shooter [SEP]']
[Init] best perm rec loss: 0.783149778842926 for ['[CLS] rios shooter gravel promotion eve voyage press [SEP]']
[Init] best perm rec loss: 0.7825035452842712 for ['[CLS] rios gravel press voyage promotion eve shooter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.043 (perp=8.670, rec=0.291, cos=0.018), tot_loss_proj:3.606 [t=0.29s]
prediction: ['[CLS] laboratory he ion himself says was. [SEP]']
[ 100/2000] tot_loss=1.693 (perp=7.369, rec=0.207, cos=0.012), tot_loss_proj:1.993 [t=0.30s]
prediction: ['[CLS] hungry said that himself says was. [SEP]']
[ 150/2000] tot_loss=1.643 (perp=7.303, rec=0.173, cos=0.009), tot_loss_proj:1.977 [t=0.30s]
prediction: ['[CLS] hungry said that himself said was. [SEP]']
[ 200/2000] tot_loss=1.773 (perp=8.177, rec=0.130, cos=0.008), tot_loss_proj:2.284 [t=0.30s]
prediction: ['[CLS] hungry he that himself was said. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.338 (perp=5.939, rec=0.142, cos=0.009), tot_loss_proj:2.142 [t=0.30s]
prediction: ['[CLS] said he that himself was hungry. [SEP]']
[ 300/2000] tot_loss=1.317 (perp=5.939, rec=0.121, cos=0.008), tot_loss_proj:2.143 [t=0.30s]
prediction: ['[CLS] said he that himself was hungry. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.039 (perp=4.645, rec=0.103, cos=0.007), tot_loss_proj:1.077 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.021 (perp=4.645, rec=0.085, cos=0.007), tot_loss_proj:1.091 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 450/2000] tot_loss=1.033 (perp=4.645, rec=0.097, cos=0.007), tot_loss_proj:1.092 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.041 (perp=4.645, rec=0.105, cos=0.007), tot_loss_proj:1.093 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.036 (perp=4.645, rec=0.099, cos=0.007), tot_loss_proj:1.089 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 600/2000] tot_loss=1.031 (perp=4.645, rec=0.094, cos=0.007), tot_loss_proj:1.100 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.025 (perp=4.645, rec=0.089, cos=0.007), tot_loss_proj:1.095 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.032 (perp=4.645, rec=0.096, cos=0.007), tot_loss_proj:1.108 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 750/2000] tot_loss=1.029 (perp=4.645, rec=0.092, cos=0.007), tot_loss_proj:1.114 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.031 (perp=4.645, rec=0.095, cos=0.007), tot_loss_proj:1.113 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.024 (perp=4.645, rec=0.087, cos=0.007), tot_loss_proj:1.100 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 900/2000] tot_loss=1.033 (perp=4.645, rec=0.097, cos=0.007), tot_loss_proj:1.113 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.036 (perp=4.645, rec=0.099, cos=0.007), tot_loss_proj:1.112 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.044 (perp=4.645, rec=0.107, cos=0.007), tot_loss_proj:1.117 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1050/2000] tot_loss=1.033 (perp=4.645, rec=0.096, cos=0.007), tot_loss_proj:1.126 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.033 (perp=4.645, rec=0.097, cos=0.007), tot_loss_proj:1.121 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.012 (perp=4.645, rec=0.076, cos=0.007), tot_loss_proj:1.120 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1200/2000] tot_loss=1.032 (perp=4.645, rec=0.096, cos=0.007), tot_loss_proj:1.107 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.033 (perp=4.645, rec=0.096, cos=0.007), tot_loss_proj:1.117 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.026 (perp=4.645, rec=0.090, cos=0.007), tot_loss_proj:1.133 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1350/2000] tot_loss=1.019 (perp=4.645, rec=0.082, cos=0.007), tot_loss_proj:1.119 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.035 (perp=4.645, rec=0.098, cos=0.007), tot_loss_proj:1.130 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.030 (perp=4.645, rec=0.094, cos=0.007), tot_loss_proj:1.111 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1500/2000] tot_loss=1.022 (perp=4.645, rec=0.085, cos=0.007), tot_loss_proj:1.128 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.023 (perp=4.645, rec=0.087, cos=0.007), tot_loss_proj:1.132 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.032 (perp=4.645, rec=0.095, cos=0.007), tot_loss_proj:1.130 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1650/2000] tot_loss=1.023 (perp=4.645, rec=0.087, cos=0.007), tot_loss_proj:1.132 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.022 (perp=4.645, rec=0.086, cos=0.007), tot_loss_proj:1.129 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.028 (perp=4.645, rec=0.092, cos=0.007), tot_loss_proj:1.141 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1800/2000] tot_loss=1.032 (perp=4.645, rec=0.096, cos=0.008), tot_loss_proj:1.135 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.017 (perp=4.645, rec=0.080, cos=0.008), tot_loss_proj:1.128 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.034 (perp=4.645, rec=0.098, cos=0.008), tot_loss_proj:1.132 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1950/2000] tot_loss=1.021 (perp=4.645, rec=0.084, cos=0.008), tot_loss_proj:1.122 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.031 (perp=4.645, rec=0.094, cos=0.008), tot_loss_proj:1.126 [t=0.30s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] he said that himself was hungry. [SEP]
========================
predicted: 
========================
[CLS] he said that himself was hungry. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 76.366 | p: 76.676 | r: 76.306
rouge2     | fm: 33.747 | p: 33.806 | r: 33.826
rougeL     | fm: 67.163 | p: 67.427 | r: 67.059
rougeLsum  | fm: 67.298 | p: 67.623 | r: 67.127
r1fm+r2fm = 110.113

input #53 time: 0:11:48 | total time: 10:45:03


Running input #54 of 100.
reference: 
========================
After reading the pamphlet, Judy threw them into the garbage can.
========================
average of cosine similarity 0.9990272473797596
highest_index [0]
highest [0.9990272473797596]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  2044,  3752,  1996, 19899,  1010, 12120,  4711,  2068,  2046,
          1996, 13044,  2064,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]']
[Init] best rec loss: 0.9699460864067078 for ['[CLS]position unavailable reporter wink zero do leaning double declared temple swift 2012 fine [SEP]']
[Init] best rec loss: 0.9333088994026184 for ['[CLS] very concert impressed sentiment place beatencted little rockritan bonaparte rex agreement [SEP]']
[Init] best rec loss: 0.9242850542068481 for ['[CLS] crop jagger occurred badly oil alike destination [ session show sunrisehita you [SEP]']
[Init] best rec loss: 0.916300892829895 for ['[CLS] electvic push warehouse humor aboutpiece lock eponymousgrant prison measure even [SEP]']
[Init] best rec loss: 0.9021044969558716 for ['[CLS]ulatesverance why loft openprint sight slappedized pledge ben additional currently [SEP]']
[Init] best rec loss: 0.891993522644043 for ['[CLS]cede difficulty ground finding times low da wish north duo arts colonial miss [SEP]']
[Init] best rec loss: 0.8854372501373291 for ['[CLS] oldies refers against roses thirds held mankind shit come mainly determine case evident [SEP]']
[Init] best rec loss: 0.8788341283798218 for ['[CLS] client lials applications tri across filling packet submitsby tank mutual business [SEP]']
[Init] best rec loss: 0.8765352368354797 for ['[CLS] colors erase try will divine grit honor toad single pork national refuge groups [SEP]']
[Init] best perm rec loss: 0.8717343807220459 for ['[CLS] erase try pork divine single will colors toad honor groups national refuge grit [SEP]']
[Init] best perm rec loss: 0.8716998100280762 for ['[CLS] erase grit colors honor pork national single try toad groups will divine refuge [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.915 (perp=12.488, rec=0.292, cos=0.125), tot_loss_proj:4.359 [t=0.29s]
prediction: ['[CLS] became bowl judy judy pamphlet down them garbage outesses launchedpt during [SEP]']
[ 100/2000] tot_loss=2.662 (perp=11.871, rec=0.235, cos=0.053), tot_loss_proj:4.243 [t=0.30s]
prediction: ['[CLS]! slowly judy anonymous pamphlet my them threw intozation slid a conversion [SEP]']
[ 150/2000] tot_loss=2.377 (perp=10.823, rec=0.171, cos=0.041), tot_loss_proj:4.062 [t=0.30s]
prediction: ['[CLS]! simply judy pamphlet pamphlet reading them threw intozation threw a conversion [SEP]']
[ 200/2000] tot_loss=2.570 (perp=11.934, rec=0.150, cos=0.033), tot_loss_proj:4.265 [t=0.30s]
prediction: ['[CLS]!urg judy pamphlet pamphlet reading them threw into bwv threw ( read [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.726 (perp=11.691, rec=0.291, cos=0.097), tot_loss_proj:4.195 [t=0.30s]
prediction: ['[CLS]! them judy pamphlet pamphlet reading label threw into when threw villains read [SEP]']
[ 300/2000] tot_loss=2.562 (perp=11.727, rec=0.180, cos=0.037), tot_loss_proj:4.187 [t=0.30s]
prediction: ['[CLS] € them judy pamphlet pamphlet myurg threw into when threw garbage read [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.557 (perp=11.746, rec=0.172, cos=0.035), tot_loss_proj:4.206 [t=0.30s]
prediction: ['[CLS] judy them judy pamphlet pamphlet readingched threw into garbage threw 。 read [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.305 (perp=10.546, rec=0.163, cos=0.033), tot_loss_proj:3.908 [t=0.30s]
prediction: ['[CLS] judy down judy pamphlet pamphlet reading them threw into garbage threw when read [SEP]']
[ 450/2000] tot_loss=2.268 (perp=10.546, rec=0.128, cos=0.031), tot_loss_proj:3.906 [t=0.30s]
prediction: ['[CLS] judy down judy pamphlet pamphlet reading them threw into garbage threw when read [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.184 (perp=10.094, rec=0.139, cos=0.026), tot_loss_proj:3.873 [t=0.30s]
prediction: ['[CLS] judy by judy pamphlet pamphlet reading them threw into threw garbage after read [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.983 (perp=9.137, rec=0.128, cos=0.027), tot_loss_proj:3.673 [t=0.30s]
prediction: ['[CLS] judy by judy pamphlet threw reading them threw into pamphlet garbage after the [SEP]']
[ 600/2000] tot_loss=1.974 (perp=9.137, rec=0.125, cos=0.022), tot_loss_proj:3.675 [t=0.30s]
prediction: ['[CLS] judy by judy pamphlet threw reading them threw into pamphlet garbage after the [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.958 (perp=9.137, rec=0.111, cos=0.020), tot_loss_proj:3.674 [t=0.30s]
prediction: ['[CLS] judy by judy pamphlet threw reading them threw into pamphlet garbage after the [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.936 (perp=9.036, rec=0.109, cos=0.019), tot_loss_proj:3.669 [t=0.30s]
prediction: ['[CLS] judy by judy pamphlet threw reading threw them into pamphlet garbage after the [SEP]']
[ 750/2000] tot_loss=1.967 (perp=9.278, rec=0.093, cos=0.018), tot_loss_proj:3.669 [t=0.30s]
prediction: ['[CLS] judy as judy pamphlet threw reading threw them into pamphlet garbage after the [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.981 (perp=9.287, rec=0.105, cos=0.018), tot_loss_proj:3.728 [t=0.30s]
prediction: ['[CLS] judy threw judy pamphlet - reading threw them into pamphlet garbage after the [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.844 (perp=8.624, rec=0.101, cos=0.018), tot_loss_proj:3.586 [t=0.30s]
prediction: ['[CLS] judy judy threw pamphlet, reading threw them into pamphlet garbage after the [SEP]']
[ 900/2000] tot_loss=1.849 (perp=8.624, rec=0.107, cos=0.017), tot_loss_proj:3.583 [t=0.30s]
prediction: ['[CLS] judy judy threw pamphlet, reading threw them into pamphlet garbage after the [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.844 (perp=8.624, rec=0.102, cos=0.017), tot_loss_proj:3.579 [t=0.30s]
prediction: ['[CLS] judy judy threw pamphlet, reading threw them into pamphlet garbage after the [SEP]']
Attempt swap
[1000/2000] tot_loss=1.845 (perp=8.624, rec=0.104, cos=0.017), tot_loss_proj:3.581 [t=0.30s]
prediction: ['[CLS] judy judy threw pamphlet, reading threw them into pamphlet garbage after the [SEP]']
[1050/2000] tot_loss=1.901 (perp=8.856, rec=0.113, cos=0.016), tot_loss_proj:3.626 [t=0.30s]
prediction: ['[CLS] judy judy threw pamphlet. reading threw them into pamphlet garbage after the [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.897 (perp=8.868, rec=0.107, cos=0.016), tot_loss_proj:3.647 [t=0.30s]
prediction: ['[CLS] judy threw judy pamphlet. reading threw them into pamphlet garbage after the [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.827 (perp=8.523, rec=0.108, cos=0.015), tot_loss_proj:3.564 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet. reading threw them into pamphlet garbage after judy [SEP]']
[1200/2000] tot_loss=1.815 (perp=8.523, rec=0.096, cos=0.015), tot_loss_proj:3.563 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet. reading threw them into pamphlet garbage after judy [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.766 (perp=8.190, rec=0.113, cos=0.015), tot_loss_proj:3.508 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet. reading judy threw them into pamphlet garbage after [SEP]']
Attempt swap
[1300/2000] tot_loss=1.754 (perp=8.190, rec=0.102, cos=0.014), tot_loss_proj:3.512 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet. reading judy threw them into pamphlet garbage after [SEP]']
[1350/2000] tot_loss=1.752 (perp=8.190, rec=0.100, cos=0.014), tot_loss_proj:3.506 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet. reading judy threw them into pamphlet garbage after [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.769 (perp=8.254, rec=0.103, cos=0.015), tot_loss_proj:3.530 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet reading, judy threw them into pamphlet garbage after [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.698 (perp=7.814, rec=0.118, cos=0.017), tot_loss_proj:3.445 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
[1500/2000] tot_loss=1.678 (perp=7.814, rec=0.100, cos=0.015), tot_loss_proj:3.444 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
Attempt swap
[1550/2000] tot_loss=1.684 (perp=7.814, rec=0.106, cos=0.015), tot_loss_proj:3.445 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
Attempt swap
[1600/2000] tot_loss=1.682 (perp=7.814, rec=0.104, cos=0.015), tot_loss_proj:3.443 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
[1650/2000] tot_loss=1.680 (perp=7.814, rec=0.103, cos=0.014), tot_loss_proj:3.443 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
Attempt swap
[1700/2000] tot_loss=1.687 (perp=7.814, rec=0.110, cos=0.014), tot_loss_proj:3.446 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
Attempt swap
[1750/2000] tot_loss=1.684 (perp=7.814, rec=0.106, cos=0.014), tot_loss_proj:3.444 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
[1800/2000] tot_loss=1.686 (perp=7.814, rec=0.108, cos=0.014), tot_loss_proj:3.437 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
Attempt swap
[1850/2000] tot_loss=1.691 (perp=7.814, rec=0.113, cos=0.014), tot_loss_proj:3.447 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
Attempt swap
[1900/2000] tot_loss=1.680 (perp=7.814, rec=0.103, cos=0.014), tot_loss_proj:3.448 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
[1950/2000] tot_loss=1.677 (perp=7.814, rec=0.100, cos=0.014), tot_loss_proj:3.439 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
Attempt swap
[2000/2000] tot_loss=1.666 (perp=7.814, rec=0.089, cos=0.014), tot_loss_proj:3.444 [t=0.30s]
prediction: ['[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]
========================
predicted: 
========================
[CLS] judy threw the pamphlet after reading, judy threw them into pamphlet garbage [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.481 | p: 78.571 | r: 84.615
rouge2     | fm: 40.000 | p: 38.462 | r: 41.667
rougeL     | fm: 66.667 | p: 64.286 | r: 69.231
rougeLsum  | fm: 66.667 | p: 64.286 | r: 69.231
r1fm+r2fm = 121.481

[Aggregate metrics]:
rouge1     | fm: 76.456 | p: 76.643 | r: 76.455
rouge2     | fm: 33.833 | p: 33.857 | r: 33.892
rougeL     | fm: 67.221 | p: 67.489 | r: 67.136
rougeLsum  | fm: 67.288 | p: 67.564 | r: 67.196
r1fm+r2fm = 110.289

input #54 time: 0:11:48 | total time: 10:56:51


Running input #55 of 100.
reference: 
========================
Collapsed Harry.
========================
average of cosine similarity 0.9988862792997023
highest_index [0]
highest [0.9988862792997023]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 7798, 4302, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] collapsed harry. [SEP]']
[Init] best rec loss: 0.7564752697944641 for ['[CLS] taken dana once [SEP]']
[Init] best rec loss: 0.7349622249603271 for ['[CLS] information op respect [SEP]']
[Init] best rec loss: 0.7319850921630859 for ['[CLS]due southern head [SEP]']
[Init] best rec loss: 0.6886100769042969 for ['[CLS] class atlantic martins [SEP]']
[Init] best rec loss: 0.6879370808601379 for ['[CLS] these how conditioning [SEP]']
[Init] best rec loss: 0.6809592843055725 for ['[CLS] coup pace lila [SEP]']
[Init] best rec loss: 0.6730684041976929 for ['[CLS] mage sharing roman [SEP]']
[Init] best rec loss: 0.658435046672821 for ['[CLS] museum sam clay [SEP]']
[Init] best perm rec loss: 0.6548731923103333 for ['[CLS] sam museum clay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.379 (perp=9.208, rec=0.370, cos=0.168), tot_loss_proj:2.593 [t=0.29s]
prediction: ['[CLS] collapsed harry. [SEP]']
[ 100/2000] tot_loss=2.484 (perp=9.208, rec=0.324, cos=0.318), tot_loss_proj:2.599 [t=0.30s]
prediction: ['[CLS] collapsed harry. [SEP]']
[ 150/2000] tot_loss=2.370 (perp=9.208, rec=0.258, cos=0.271), tot_loss_proj:2.534 [t=0.30s]
prediction: ['[CLS] collapsed harry. [SEP]']
[ 200/2000] tot_loss=2.370 (perp=9.208, rec=0.244, cos=0.285), tot_loss_proj:2.530 [t=0.30s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.899 (perp=12.381, rec=0.229, cos=0.194), tot_loss_proj:3.134 [t=0.30s]
prediction: ['[CLS] collapsed harryª [SEP]']
[ 300/2000] tot_loss=2.906 (perp=12.381, rec=0.230, cos=0.200), tot_loss_proj:3.140 [t=0.30s]
prediction: ['[CLS] collapsed harryª [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.923 (perp=12.381, rec=0.225, cos=0.222), tot_loss_proj:3.169 [t=0.30s]
prediction: ['[CLS] collapsed harryª [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.938 (perp=12.381, rec=0.220, cos=0.241), tot_loss_proj:3.175 [t=0.30s]
prediction: ['[CLS] collapsed harryª [SEP]']
[ 450/2000] tot_loss=3.046 (perp=12.380, rec=0.333, cos=0.237), tot_loss_proj:3.119 [t=0.30s]
prediction: ['[CLS] collapsed harry merely [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.055 (perp=12.586, rec=0.301, cos=0.237), tot_loss_proj:3.727 [t=0.30s]
prediction: ['[CLS] collapsed fusiliers harry [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.036 (perp=12.436, rec=0.309, cos=0.240), tot_loss_proj:3.387 [t=0.30s]
prediction: ['[CLS] collapsed harry fusiliers [SEP]']
[ 600/2000] tot_loss=3.007 (perp=12.436, rec=0.269, cos=0.251), tot_loss_proj:3.379 [t=0.30s]
prediction: ['[CLS] collapsed harry fusiliers [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.002 (perp=12.436, rec=0.264, cos=0.251), tot_loss_proj:3.383 [t=0.30s]
prediction: ['[CLS] collapsed harry fusiliers [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.005 (perp=12.436, rec=0.270, cos=0.248), tot_loss_proj:3.370 [t=0.30s]
prediction: ['[CLS] collapsed harry fusiliers [SEP]']
[ 750/2000] tot_loss=3.003 (perp=12.436, rec=0.271, cos=0.245), tot_loss_proj:3.385 [t=0.30s]
prediction: ['[CLS] collapsed harry fusiliers [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.002 (perp=12.436, rec=0.265, cos=0.249), tot_loss_proj:3.383 [t=0.30s]
prediction: ['[CLS] collapsed harry fusiliers [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.007 (perp=12.436, rec=0.267, cos=0.253), tot_loss_proj:3.388 [t=0.30s]
prediction: ['[CLS] collapsed harry fusiliers [SEP]']
[ 900/2000] tot_loss=3.001 (perp=12.436, rec=0.263, cos=0.250), tot_loss_proj:3.375 [t=0.30s]
prediction: ['[CLS] collapsed harry fusiliers [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.187 (perp=13.380, rec=0.261, cos=0.249), tot_loss_proj:3.039 [t=0.30s]
prediction: ['[CLS] collapsed harry suggesting [SEP]']
Attempt swap
Put prefix at the end
[1000/2000] tot_loss=3.173 (perp=13.365, rec=0.292, cos=0.208), tot_loss_proj:3.518 [t=0.30s]
prediction: ['[CLS] fusiliers collapsed harry [SEP]']
[1050/2000] tot_loss=3.195 (perp=13.365, rec=0.275, cos=0.247), tot_loss_proj:3.516 [t=0.30s]
prediction: ['[CLS] fusiliers collapsed harry [SEP]']
Attempt swap
[1100/2000] tot_loss=3.208 (perp=13.365, rec=0.280, cos=0.255), tot_loss_proj:3.513 [t=0.30s]
prediction: ['[CLS] fusiliers collapsed harry [SEP]']
Attempt swap
[1150/2000] tot_loss=3.010 (perp=12.382, rec=0.274, cos=0.260), tot_loss_proj:3.351 [t=0.30s]
prediction: ['[CLS] lest collapsed harry [SEP]']
[1200/2000] tot_loss=3.014 (perp=12.382, rec=0.275, cos=0.262), tot_loss_proj:3.350 [t=0.30s]
prediction: ['[CLS] lest collapsed harry [SEP]']
Attempt swap
[1250/2000] tot_loss=3.000 (perp=12.382, rec=0.261, cos=0.263), tot_loss_proj:3.355 [t=0.30s]
prediction: ['[CLS] lest collapsed harry [SEP]']
Attempt swap
[1300/2000] tot_loss=3.010 (perp=12.382, rec=0.270, cos=0.264), tot_loss_proj:3.348 [t=0.30s]
prediction: ['[CLS] lest collapsed harry [SEP]']
[1350/2000] tot_loss=3.002 (perp=12.382, rec=0.263, cos=0.263), tot_loss_proj:3.359 [t=0.30s]
prediction: ['[CLS] lest collapsed harry [SEP]']
Attempt swap
[1400/2000] tot_loss=3.009 (perp=12.382, rec=0.267, cos=0.266), tot_loss_proj:3.357 [t=0.30s]
prediction: ['[CLS] lest collapsed harry [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=2.911 (perp=11.751, rec=0.273, cos=0.288), tot_loss_proj:4.227 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
[1500/2000] tot_loss=2.887 (perp=11.751, rec=0.271, cos=0.266), tot_loss_proj:4.228 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.890 (perp=11.751, rec=0.271, cos=0.269), tot_loss_proj:4.231 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.878 (perp=11.751, rec=0.258, cos=0.270), tot_loss_proj:4.230 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
[1650/2000] tot_loss=2.894 (perp=11.751, rec=0.271, cos=0.272), tot_loss_proj:4.227 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.897 (perp=11.751, rec=0.275, cos=0.272), tot_loss_proj:4.226 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.878 (perp=11.751, rec=0.254, cos=0.273), tot_loss_proj:4.222 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
[1800/2000] tot_loss=2.901 (perp=11.751, rec=0.278, cos=0.274), tot_loss_proj:4.225 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.894 (perp=11.751, rec=0.270, cos=0.274), tot_loss_proj:4.227 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.887 (perp=11.751, rec=0.261, cos=0.275), tot_loss_proj:4.228 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
[1950/2000] tot_loss=2.903 (perp=11.751, rec=0.278, cos=0.275), tot_loss_proj:4.227 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.880 (perp=11.751, rec=0.254, cos=0.276), tot_loss_proj:4.227 [t=0.30s]
prediction: ['[CLS] lest harry collapsed [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] collapsed harry. [SEP]
========================
predicted: 
========================
[CLS] collapsed harryª [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 76.815 | p: 77.008 | r: 76.773
rouge2     | fm: 35.106 | p: 35.125 | r: 35.288
rougeL     | fm: 67.685 | p: 67.944 | r: 67.639
rougeLsum  | fm: 67.892 | p: 68.136 | r: 67.836
r1fm+r2fm = 111.921

input #55 time: 0:11:46 | total time: 11:08:38


Running input #56 of 100.
reference: 
========================
John was seeing his children.
========================
average of cosine similarity 0.9990778291741537
highest_index [0]
highest [0.9990778291741537]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2198, 2001, 3773, 2010, 2336, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john was seeing his children. [SEP]']
[Init] best rec loss: 0.9070160984992981 for ['[CLS] vampire artists at like edge into [SEP]']
[Init] best rec loss: 0.872548520565033 for ['[CLS] banned scout fadeper residence nursery [SEP]']
[Init] best rec loss: 0.8700696229934692 for ['[CLS] gymnastics hemain roller scotiacity [SEP]']
[Init] best perm rec loss: 0.869117021560669 for ['[CLS] gymnastics scotiamain he rollercity [SEP]']
[Init] best perm rec loss: 0.8679885864257812 for ['[CLS]citymain he scotia gymnastics roller [SEP]']
[Init] best perm rec loss: 0.867777943611145 for ['[CLS]city scotia hemain gymnastics roller [SEP]']
[Init] best perm rec loss: 0.8667677640914917 for ['[CLS] rollermain gymnasticscity scotia he [SEP]']
[Init] best perm rec loss: 0.8662017583847046 for ['[CLS] scotia hemaincity gymnastics roller [SEP]']
[Init] best perm rec loss: 0.8656390905380249 for ['[CLS] roller scotiacitymain he gymnastics [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.730 (perp=10.213, rec=0.728, cos=0.959), tot_loss_proj:3.713 [t=0.29s]
prediction: ['[CLS]lco they formed large, terence [SEP]']
[ 100/2000] tot_loss=3.382 (perp=9.026, rec=0.596, cos=0.980), tot_loss_proj:3.702 [t=0.29s]
prediction: ['[CLS] was their moving small, terence [SEP]']
[ 150/2000] tot_loss=3.470 (perp=10.496, rec=0.533, cos=0.838), tot_loss_proj:3.869 [t=0.30s]
prediction: ['[CLS] was was seeing chord. lester [SEP]']
[ 200/2000] tot_loss=3.460 (perp=11.020, rec=0.484, cos=0.772), tot_loss_proj:3.836 [t=0.30s]
prediction: ['[CLS] was was seeing hindu.iki [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=4.407 (perp=14.968, rec=0.558, cos=0.855), tot_loss_proj:4.719 [t=0.30s]
prediction: ['[CLS] dialed campeonato his seeing lexington maternal [SEP]']
[ 300/2000] tot_loss=3.336 (perp=10.217, rec=0.472, cos=0.820), tot_loss_proj:3.780 [t=0.30s]
prediction: ['[CLS] john when was seeing matthew street [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.014 (perp=8.757, rec=0.429, cos=0.834), tot_loss_proj:3.603 [t=0.30s]
prediction: ['[CLS] that john was seeing matthew street [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.233 (perp=5.598, rec=0.360, cos=0.753), tot_loss_proj:2.682 [t=0.30s]
prediction: ['[CLS] when john was seeing children. [SEP]']
[ 450/2000] tot_loss=2.365 (perp=6.182, rec=0.340, cos=0.789), tot_loss_proj:3.108 [t=0.30s]
prediction: ['[CLS] when john was seeing wife. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.229 (perp=5.598, rec=0.310, cos=0.799), tot_loss_proj:2.651 [t=0.30s]
prediction: ['[CLS] when john was seeing children. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.892 (perp=8.906, rec=0.312, cos=0.799), tot_loss_proj:3.536 [t=0.30s]
prediction: ['[CLS]wski john was seeing children. [SEP]']
[ 600/2000] tot_loss=2.869 (perp=8.906, rec=0.293, cos=0.795), tot_loss_proj:3.540 [t=0.30s]
prediction: ['[CLS]wski john was seeing children. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.868 (perp=8.800, rec=0.310, cos=0.798), tot_loss_proj:3.642 [t=0.30s]
prediction: ['[CLS] johnoven was seeing wife. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.442 (perp=6.738, rec=0.294, cos=0.800), tot_loss_proj:2.240 [t=0.30s]
prediction: ['[CLS] johnwski was seeing children. [SEP]']
[ 750/2000] tot_loss=2.440 (perp=6.738, rec=0.288, cos=0.804), tot_loss_proj:2.234 [t=0.30s]
prediction: ['[CLS] johnwski was seeing children. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.429 (perp=6.738, rec=0.276, cos=0.805), tot_loss_proj:2.233 [t=0.30s]
prediction: ['[CLS] johnwski was seeing children. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.429 (perp=6.738, rec=0.275, cos=0.807), tot_loss_proj:2.235 [t=0.30s]
prediction: ['[CLS] johnwski was seeing children. [SEP]']
[ 900/2000] tot_loss=2.437 (perp=6.738, rec=0.288, cos=0.802), tot_loss_proj:2.229 [t=0.30s]
prediction: ['[CLS] johnwski was seeing children. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.429 (perp=6.738, rec=0.280, cos=0.802), tot_loss_proj:2.237 [t=0.30s]
prediction: ['[CLS] johnwski was seeing children. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.425 (perp=6.738, rec=0.268, cos=0.809), tot_loss_proj:2.233 [t=0.30s]
prediction: ['[CLS] johnwski was seeing children. [SEP]']
[1050/2000] tot_loss=2.611 (perp=7.602, rec=0.284, cos=0.806), tot_loss_proj:2.681 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.604 (perp=7.602, rec=0.274, cos=0.809), tot_loss_proj:2.680 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.591 (perp=7.602, rec=0.263, cos=0.807), tot_loss_proj:2.676 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
[1200/2000] tot_loss=2.615 (perp=7.602, rec=0.290, cos=0.805), tot_loss_proj:2.681 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.588 (perp=7.602, rec=0.262, cos=0.806), tot_loss_proj:2.690 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.601 (perp=7.602, rec=0.274, cos=0.807), tot_loss_proj:2.684 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
[1350/2000] tot_loss=2.599 (perp=7.602, rec=0.271, cos=0.807), tot_loss_proj:2.679 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.601 (perp=7.602, rec=0.271, cos=0.810), tot_loss_proj:2.674 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.597 (perp=7.602, rec=0.272, cos=0.805), tot_loss_proj:2.675 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
[1500/2000] tot_loss=2.599 (perp=7.602, rec=0.270, cos=0.808), tot_loss_proj:2.676 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.604 (perp=7.602, rec=0.276, cos=0.808), tot_loss_proj:2.673 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.592 (perp=7.602, rec=0.267, cos=0.805), tot_loss_proj:2.678 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
[1650/2000] tot_loss=2.606 (perp=7.602, rec=0.274, cos=0.812), tot_loss_proj:2.682 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.604 (perp=7.602, rec=0.277, cos=0.807), tot_loss_proj:2.687 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.601 (perp=7.602, rec=0.270, cos=0.811), tot_loss_proj:2.683 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
[1800/2000] tot_loss=2.600 (perp=7.602, rec=0.269, cos=0.810), tot_loss_proj:2.673 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.595 (perp=7.602, rec=0.265, cos=0.810), tot_loss_proj:2.680 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.600 (perp=7.602, rec=0.269, cos=0.810), tot_loss_proj:2.681 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
[1950/2000] tot_loss=2.595 (perp=7.602, rec=0.265, cos=0.810), tot_loss_proj:2.676 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.596 (perp=7.602, rec=0.266, cos=0.809), tot_loss_proj:2.682 [t=0.30s]
prediction: ['[CLS] johnuli was seeing children. [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] john was seeing his children. [SEP]
========================
predicted: 
========================
[CLS] johnuli was seeing children. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 36.364 | p: 40.000 | r: 33.333
rougeL     | fm: 76.923 | p: 83.333 | r: 71.429
rougeLsum  | fm: 76.923 | p: 83.333 | r: 71.429
r1fm+r2fm = 113.287

[Aggregate metrics]:
rouge1     | fm: 76.790 | p: 77.097 | r: 76.735
rouge2     | fm: 35.050 | p: 35.148 | r: 35.121
rougeL     | fm: 67.872 | p: 68.212 | r: 67.712
rougeLsum  | fm: 68.070 | p: 68.419 | r: 67.856
r1fm+r2fm = 111.840

input #56 time: 0:11:46 | total time: 11:20:24


Running input #57 of 100.
reference: 
========================
Carla mopped the floor under the furniture.
========================
average of cosine similarity 0.9988760547719487
highest_index [0]
highest [0.9988760547719487]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 17081,  9587, 11469,  1996,  2723,  2104,  1996,  7390,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] carla mopped the floor under the furniture. [SEP]']
[Init] best rec loss: 0.8750913739204407 for ['[CLS]ne gathering do their health retirement go enforce things [SEP]']
[Init] best rec loss: 0.8461637496948242 for ['[CLS] ordinary blend [MASK] grant sorryuity overnight occupied racecourse [SEP]']
[Init] best rec loss: 0.845947265625 for ['[CLS] puzzle at harder po control sittingfulaliscrow [SEP]']
[Init] best rec loss: 0.8402238488197327 for ['[CLS] deterilisedbed gallagherfle flames remainemi papers [SEP]']
[Init] best rec loss: 0.8392669558525085 for ['[CLS] challenge academy las juliet partner party say castle berg [SEP]']
[Init] best perm rec loss: 0.8390969038009644 for ['[CLS] academy berg say las juliet castle challenge party partner [SEP]']
[Init] best perm rec loss: 0.8385745286941528 for ['[CLS] academy las party berg challenge say juliet partner castle [SEP]']
[Init] best perm rec loss: 0.8382658362388611 for ['[CLS] castle juliet las academy berg say partner challenge party [SEP]']
[Init] best perm rec loss: 0.8375804424285889 for ['[CLS] party challenge academy las say castle juliet berg partner [SEP]']
[Init] best perm rec loss: 0.8368308544158936 for ['[CLS] berg academy party say las partner juliet castle challenge [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.356 (perp=11.225, rec=0.471, cos=0.640), tot_loss_proj:4.079 [t=0.29s]
prediction: ['[CLS] dave linda news > technical grip under floor up [SEP]']
[ 100/2000] tot_loss=3.334 (perp=11.389, rec=0.316, cos=0.740), tot_loss_proj:4.070 [t=0.30s]
prediction: ['[CLS] carla under furniturepped furnitureproof under floor under [SEP]']
[ 150/2000] tot_loss=3.197 (perp=11.669, rec=0.259, cos=0.604), tot_loss_proj:4.070 [t=0.30s]
prediction: ['[CLS] carla down furniturepped furniture beneficial under floor. [SEP]']
[ 200/2000] tot_loss=2.912 (perp=11.022, rec=0.212, cos=0.495), tot_loss_proj:3.881 [t=0.30s]
prediction: ['[CLS] carla floor averypped furniture clean under floor. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.972 (perp=11.348, rec=0.235, cos=0.467), tot_loss_proj:3.998 [t=0.30s]
prediction: ['[CLS] carlamo averypped glad furniture under floor. [SEP]']
[ 300/2000] tot_loss=3.119 (perp=11.581, rec=0.219, cos=0.583), tot_loss_proj:4.022 [t=0.30s]
prediction: ['[CLS] carlamo averypped likelihood furniture under floor. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.594 (perp=9.932, rec=0.186, cos=0.421), tot_loss_proj:3.726 [t=0.30s]
prediction: ['[CLS] carla avery -pped likelihood furniture under floor. [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.614 (perp=9.932, rec=0.173, cos=0.455), tot_loss_proj:3.724 [t=0.30s]
prediction: ['[CLS] carla avery -pped likelihood furniture under floor. [SEP]']
[ 450/2000] tot_loss=2.622 (perp=10.097, rec=0.183, cos=0.420), tot_loss_proj:3.787 [t=0.30s]
prediction: ['[CLS] carla avery.pped likelihood furniture under floor. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.715 (perp=9.807, rec=0.193, cos=0.561), tot_loss_proj:3.774 [t=0.30s]
prediction: ['[CLS] carla avery. vantagepped furniture under floor. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.569 (perp=9.601, rec=0.176, cos=0.473), tot_loss_proj:3.651 [t=0.30s]
prediction: ['[CLS] carla vantage. averypped furniture under floor. [SEP]']
[ 600/2000] tot_loss=2.835 (perp=10.833, rec=0.172, cos=0.497), tot_loss_proj:3.916 [t=0.30s]
prediction: ['[CLS] carla vantagemo averypped furniture under floor. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.719 (perp=10.456, rec=0.172, cos=0.456), tot_loss_proj:3.808 [t=0.30s]
prediction: ['[CLS] carla vantage mo averypped furniture under floor. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.531 (perp=9.558, rec=0.179, cos=0.441), tot_loss_proj:3.609 [t=0.30s]
prediction: ['[CLS] carla vantage mopped avery furniture under floor. [SEP]']
[ 750/2000] tot_loss=2.530 (perp=9.558, rec=0.164, cos=0.455), tot_loss_proj:3.614 [t=0.30s]
prediction: ['[CLS] carla vantage mopped avery furniture under floor. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.625 (perp=9.682, rec=0.183, cos=0.506), tot_loss_proj:3.612 [t=0.30s]
prediction: ['[CLS] carla dissertation mopped avery furniture under floor. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.578 (perp=9.682, rec=0.149, cos=0.492), tot_loss_proj:3.613 [t=0.30s]
prediction: ['[CLS] carla dissertation mopped avery furniture under floor. [SEP]']
[ 900/2000] tot_loss=2.574 (perp=9.682, rec=0.155, cos=0.483), tot_loss_proj:3.609 [t=0.30s]
prediction: ['[CLS] carla dissertation mopped avery furniture under floor. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.604 (perp=9.682, rec=0.158, cos=0.510), tot_loss_proj:3.609 [t=0.30s]
prediction: ['[CLS] carla dissertation mopped avery furniture under floor. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.650 (perp=9.799, rec=0.180, cos=0.511), tot_loss_proj:3.670 [t=0.30s]
prediction: ['[CLS] carla avery mopped dissertation furniture under floor. [SEP]']
[1050/2000] tot_loss=2.591 (perp=9.799, rec=0.160, cos=0.471), tot_loss_proj:3.672 [t=0.30s]
prediction: ['[CLS] carla avery mopped dissertation furniture under floor. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.557 (perp=9.291, rec=0.176, cos=0.523), tot_loss_proj:3.703 [t=0.30s]
prediction: ['[CLS] carla avery mopped furniture under floor dissertation. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.462 (perp=8.958, rec=0.174, cos=0.496), tot_loss_proj:3.550 [t=0.30s]
prediction: ['[CLS] carla avery mopped furniture under floor vantage. [SEP]']
[1200/2000] tot_loss=2.462 (perp=8.958, rec=0.158, cos=0.512), tot_loss_proj:3.552 [t=0.30s]
prediction: ['[CLS] carla avery mopped furniture under floor vantage. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.480 (perp=8.958, rec=0.169, cos=0.519), tot_loss_proj:3.551 [t=0.30s]
prediction: ['[CLS] carla avery mopped furniture under floor vantage. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.467 (perp=8.926, rec=0.162, cos=0.520), tot_loss_proj:3.485 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
[1350/2000] tot_loss=2.455 (perp=8.926, rec=0.162, cos=0.508), tot_loss_proj:3.479 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.463 (perp=8.926, rec=0.170, cos=0.508), tot_loss_proj:3.475 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.451 (perp=8.926, rec=0.167, cos=0.499), tot_loss_proj:3.477 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
[1500/2000] tot_loss=2.435 (perp=8.926, rec=0.152, cos=0.498), tot_loss_proj:3.483 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.441 (perp=8.926, rec=0.153, cos=0.503), tot_loss_proj:3.475 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.453 (perp=8.926, rec=0.160, cos=0.508), tot_loss_proj:3.477 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
[1650/2000] tot_loss=2.457 (perp=8.926, rec=0.160, cos=0.512), tot_loss_proj:3.486 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.446 (perp=8.926, rec=0.151, cos=0.510), tot_loss_proj:3.484 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.446 (perp=8.926, rec=0.160, cos=0.501), tot_loss_proj:3.484 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
[1800/2000] tot_loss=2.451 (perp=8.926, rec=0.158, cos=0.508), tot_loss_proj:3.483 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.452 (perp=8.926, rec=0.159, cos=0.509), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] carla furniture mopped avery under floor vantage. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.493 (perp=9.191, rec=0.154, cos=0.501), tot_loss_proj:3.545 [t=0.30s]
prediction: ['[CLS] carla furniture mopped jalan under floor vantage. [SEP]']
[1950/2000] tot_loss=2.496 (perp=9.191, rec=0.151, cos=0.507), tot_loss_proj:3.537 [t=0.30s]
prediction: ['[CLS] carla furniture mopped jalan under floor vantage. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.499 (perp=9.191, rec=0.152, cos=0.509), tot_loss_proj:3.531 [t=0.30s]
prediction: ['[CLS] carla furniture mopped jalan under floor vantage. [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] carla mopped the floor under the furniture. [SEP]
========================
predicted: 
========================
[CLS] carla furniture mopped jalan under floor vantage. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 90.278

[Aggregate metrics]:
rouge1     | fm: 76.790 | p: 77.138 | r: 76.689
rouge2     | fm: 34.593 | p: 34.725 | r: 34.578
rougeL     | fm: 67.657 | p: 68.025 | r: 67.508
rougeLsum  | fm: 67.765 | p: 68.155 | r: 67.627
r1fm+r2fm = 111.383

input #57 time: 0:11:47 | total time: 11:32:12


Running input #58 of 100.
reference: 
========================
They expected us to should leave him.
========================
average of cosine similarity 0.998849796868757
highest_index [0]
highest [0.998849796868757]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2027, 3517, 2149, 2000, 2323, 2681, 2032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] they expected us to should leave him. [SEP]']
[Init] best rec loss: 0.9133048057556152 for ['[CLS] like cal hazard far indiangence pair rolled [SEP]']
[Init] best rec loss: 0.9114699363708496 for ['[CLS] suit agent special small crack still try cases [SEP]']
[Init] best rec loss: 0.7541899085044861 for ['[CLS] michellevable moved lottery fold °f ask collectively [SEP]']
[Init] best rec loss: 0.7503659129142761 for ['[CLS] fore primary pcs publishing source pu ra germany [SEP]']
[Init] best rec loss: 0.7336759567260742 for ['[CLS] cartoon bastionional pulitzer implant camp assistance away [SEP]']
[Init] best perm rec loss: 0.7320036888122559 for ['[CLS] assistance pulitzer away bastion cartoon campional implant [SEP]']
[Init] best perm rec loss: 0.7308603525161743 for ['[CLS] cartoon bastion implant camp assistance pulitzerional away [SEP]']
[Init] best perm rec loss: 0.7308263778686523 for ['[CLS] implant bastion cartoon camp pulitzerional assistance away [SEP]']
[Init] best perm rec loss: 0.7300291061401367 for ['[CLS] implant bastion camp cartoon pulitzer assistanceional away [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.577 (perp=9.555, rec=0.690, cos=0.976), tot_loss_proj:3.165 [t=0.29s]
prediction: ['[CLS] in league castle barge turkish of gerais. [SEP]']
[ 100/2000] tot_loss=3.351 (perp=9.170, rec=0.517, cos=1.000), tot_loss_proj:2.984 [t=0.30s]
prediction: ['[CLS] should their school should occasional into should. [SEP]']
[ 150/2000] tot_loss=3.061 (perp=8.092, rec=0.452, cos=0.991), tot_loss_proj:2.650 [t=0.30s]
prediction: ['[CLS] should their school should expected escape should. [SEP]']
[ 200/2000] tot_loss=3.147 (perp=8.807, rec=0.390, cos=0.995), tot_loss_proj:2.897 [t=0.30s]
prediction: ['[CLS] should their leave should expected imp should. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.232 (perp=8.678, rec=0.509, cos=0.987), tot_loss_proj:2.803 [t=0.30s]
prediction: ['[CLS] shouldudged should should eyes should -. [SEP]']
[ 300/2000] tot_loss=3.311 (perp=9.589, rec=0.402, cos=0.991), tot_loss_proj:3.062 [t=0.30s]
prediction: ['[CLS] should colours to should eyes expected -. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.467 (perp=10.505, rec=0.372, cos=0.994), tot_loss_proj:3.309 [t=0.30s]
prediction: ['[CLS] shouldzic to - should eyes expected. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.235 (perp=9.491, rec=0.347, cos=0.989), tot_loss_proj:3.094 [t=0.30s]
prediction: ['[CLS] should ← to - eyes expected expected. [SEP]']
[ 450/2000] tot_loss=3.138 (perp=9.162, rec=0.331, cos=0.974), tot_loss_proj:2.907 [t=0.30s]
prediction: ['[CLS] should push to - eyes expected expected. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.029 (perp=8.541, rec=0.336, cos=0.984), tot_loss_proj:2.668 [t=0.30s]
prediction: ['[CLS] should push to should eyes - expected. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.184 (perp=9.292, rec=0.337, cos=0.989), tot_loss_proj:2.959 [t=0.30s]
prediction: ['[CLS] should ← to eyes - should expected. [SEP]']
[ 600/2000] tot_loss=3.164 (perp=9.456, rec=0.299, cos=0.974), tot_loss_proj:2.865 [t=0.30s]
prediction: ['[CLS] should push to eyes -千 expected. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.051 (perp=8.941, rec=0.302, cos=0.960), tot_loss_proj:2.807 [t=0.30s]
prediction: ['[CLS] should push to eyes metres - expected. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.901 (perp=8.135, rec=0.303, cos=0.971), tot_loss_proj:2.430 [t=0.30s]
prediction: ['[CLS] should push eyes to metres - expected. [SEP]']
[ 750/2000] tot_loss=2.850 (perp=8.135, rec=0.273, cos=0.951), tot_loss_proj:2.431 [t=0.30s]
prediction: ['[CLS] should push eyes to metres - expected. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.857 (perp=8.135, rec=0.279, cos=0.951), tot_loss_proj:2.429 [t=0.30s]
prediction: ['[CLS] should push eyes to metres - expected. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.835 (perp=8.078, rec=0.273, cos=0.947), tot_loss_proj:2.521 [t=0.30s]
prediction: ['[CLS] should push eyes to parents - expected. [SEP]']
[ 900/2000] tot_loss=3.016 (perp=8.968, rec=0.273, cos=0.950), tot_loss_proj:2.820 [t=0.30s]
prediction: ['[CLS] should push eyes to gogh - expected. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.063 (perp=9.275, rec=0.263, cos=0.945), tot_loss_proj:2.911 [t=0.30s]
prediction: ['[CLS] should push eyes to - clit expected. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.891 (perp=8.229, rec=0.298, cos=0.947), tot_loss_proj:2.528 [t=0.30s]
prediction: ['[CLS] should push千 eyes to - expected. [SEP]']
[1050/2000] tot_loss=2.920 (perp=8.508, rec=0.272, cos=0.946), tot_loss_proj:2.905 [t=0.30s]
prediction: ['[CLS] should push clit eyes to - expected. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.919 (perp=8.508, rec=0.276, cos=0.942), tot_loss_proj:2.900 [t=0.30s]
prediction: ['[CLS] should push clit eyes to - expected. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.907 (perp=8.508, rec=0.263, cos=0.943), tot_loss_proj:2.905 [t=0.30s]
prediction: ['[CLS] should push clit eyes to - expected. [SEP]']
[1200/2000] tot_loss=2.873 (perp=8.359, rec=0.259, cos=0.942), tot_loss_proj:2.590 [t=0.30s]
prediction: ['[CLS] should push parents eyes to - expected. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=3.154 (perp=9.691, rec=0.268, cos=0.948), tot_loss_proj:2.939 [t=0.30s]
prediction: ['[CLS] should push eyes to clit - expected. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=2.907 (perp=8.508, rec=0.268, cos=0.937), tot_loss_proj:2.899 [t=0.30s]
prediction: ['[CLS] should push clit eyes to - expected. [SEP]']
[1350/2000] tot_loss=2.904 (perp=8.508, rec=0.265, cos=0.937), tot_loss_proj:2.899 [t=0.30s]
prediction: ['[CLS] should push clit eyes to - expected. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.891 (perp=8.508, rec=0.251, cos=0.938), tot_loss_proj:2.900 [t=0.30s]
prediction: ['[CLS] should push clit eyes to - expected. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.902 (perp=8.508, rec=0.260, cos=0.940), tot_loss_proj:2.897 [t=0.30s]
prediction: ['[CLS] should push clit eyes to - expected. [SEP]']
[1500/2000] tot_loss=2.896 (perp=8.508, rec=0.256, cos=0.938), tot_loss_proj:2.902 [t=0.30s]
prediction: ['[CLS] should push clit eyes to - expected. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.937 (perp=8.655, rec=0.267, cos=0.939), tot_loss_proj:2.950 [t=0.30s]
prediction: ['[CLS] should push clit eyes to they expected. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.921 (perp=8.655, rec=0.252, cos=0.937), tot_loss_proj:2.953 [t=0.30s]
prediction: ['[CLS] should push clit eyes to they expected. [SEP]']
[1650/2000] tot_loss=2.921 (perp=8.655, rec=0.256, cos=0.934), tot_loss_proj:2.948 [t=0.30s]
prediction: ['[CLS] should push clit eyes to they expected. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.937 (perp=8.655, rec=0.268, cos=0.938), tot_loss_proj:2.946 [t=0.30s]
prediction: ['[CLS] should push clit eyes to they expected. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.922 (perp=8.655, rec=0.252, cos=0.939), tot_loss_proj:2.951 [t=0.30s]
prediction: ['[CLS] should push clit eyes to they expected. [SEP]']
[1800/2000] tot_loss=2.927 (perp=8.655, rec=0.262, cos=0.933), tot_loss_proj:2.949 [t=0.30s]
prediction: ['[CLS] should push clit eyes to they expected. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.024 (perp=9.157, rec=0.259, cos=0.934), tot_loss_proj:3.131 [t=0.30s]
prediction: ['[CLS] should believe clit eyes to they expected. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.033 (perp=9.157, rec=0.269, cos=0.933), tot_loss_proj:3.127 [t=0.30s]
prediction: ['[CLS] should believe clit eyes to they expected. [SEP]']
[1950/2000] tot_loss=3.018 (perp=9.157, rec=0.255, cos=0.932), tot_loss_proj:3.133 [t=0.30s]
prediction: ['[CLS] should believe clit eyes to they expected. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.032 (perp=9.157, rec=0.267, cos=0.933), tot_loss_proj:3.128 [t=0.30s]
prediction: ['[CLS] should believe clit eyes to they expected. [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] they expected us to should leave him. [SEP]
========================
predicted: 
========================
[CLS] should believe clit eyes to they expected. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 79.167

[Aggregate metrics]:
rouge1     | fm: 76.661 | p: 76.980 | r: 76.553
rouge2     | fm: 34.155 | p: 34.241 | r: 34.220
rougeL     | fm: 67.275 | p: 67.733 | r: 67.145
rougeLsum  | fm: 67.418 | p: 67.836 | r: 67.262
r1fm+r2fm = 110.816

input #58 time: 0:11:48 | total time: 11:44:00


Running input #59 of 100.
reference: 
========================
Mr Woodhouse sat in an armchair.
========================
average of cosine similarity 0.9991089108923317
highest_index [0]
highest [0.9991089108923317]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2720,  3536,  4580,  2938,  1999,  2019, 29372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[Init] best rec loss: 0.9797154664993286 for ['[CLS] zero treasurer kennedy vet when le bronze plans [SEP]']
[Init] best rec loss: 0.9735437631607056 for ['[CLS] greenbis wa ant chamber disks distinguishednine [SEP]']
[Init] best rec loss: 0.9436344504356384 for ['[CLS] reading team disco world 1950s fresh maxuit [SEP]']
[Init] best rec loss: 0.9423381686210632 for ['[CLS] some delk bank bavarian brand military declined [SEP]']
[Init] best rec loss: 0.9358271360397339 for ['[CLS] valkyrie prime wondering jordan zach contrary share josephine [SEP]']
[Init] best rec loss: 0.9279219508171082 for ['[CLS] iv halfhorn daughter carter zone clutch sports [SEP]']
[Init] best rec loss: 0.9273892641067505 for ['[CLS] key stafforddial breaking colony midst kmdden [SEP]']
[Init] best rec loss: 0.9233012795448303 for ['[CLS] keyboardsisionhab redrued owed comparisons post [SEP]']
[Init] best rec loss: 0.9132446646690369 for ['[CLS]hawk fisherman rock brick thug how academy woods [SEP]']
[Init] best rec loss: 0.9055434465408325 for ['[CLS] game cherᵢ normasul weapons catholics horn [SEP]']
[Init] best perm rec loss: 0.9034592509269714 for ['[CLS] weapons gamesulᵢ norma cher horn catholics [SEP]']
[Init] best perm rec loss: 0.900879979133606 for ['[CLS] catholics weapons game norma hornᵢsul cher [SEP]']
[Init] best perm rec loss: 0.8992114067077637 for ['[CLS] game catholics weapons normaᵢsul cher horn [SEP]']
[Init] best perm rec loss: 0.8986642360687256 for ['[CLS] normasul catholicsᵢ game horn weapons cher [SEP]']
[Init] best perm rec loss: 0.8982298374176025 for ['[CLS] catholicssulᵢ cher game norma weapons horn [SEP]']
[Init] best perm rec loss: 0.8981740474700928 for ['[CLS]ᵢ norma hornsul game cher weapons catholics [SEP]']
[Init] best perm rec loss: 0.8959469199180603 for ['[CLS]ᵢsul horn game norma cher weapons catholics [SEP]']
[Init] best perm rec loss: 0.8955745697021484 for ['[CLS]ᵢsul catholics cher norma horn weapons game [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.033 (perp=13.014, rec=0.640, cos=0.790), tot_loss_proj:4.420 [t=0.29s]
prediction: ['[CLS] somme among armchair los mr wine. cube [SEP]']
[ 100/2000] tot_loss=3.753 (perp=11.394, rec=0.696, cos=0.778), tot_loss_proj:4.043 [t=0.30s]
prediction: ['[CLS] jeans mr armchair are armchair session. cruisers [SEP]']
[ 150/2000] tot_loss=3.980 (perp=12.296, rec=0.565, cos=0.956), tot_loss_proj:4.221 [t=0.30s]
prediction: ['[CLS] chelsea mrs armchair are sat session. ¨ [SEP]']
[ 200/2000] tot_loss=4.142 (perp=12.653, rec=0.680, cos=0.931), tot_loss_proj:4.391 [t=0.30s]
prediction: ['[CLS] gladstone. couch tau day ultraviolet blonde leaders [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.698 (perp=11.398, rec=0.522, cos=0.897), tot_loss_proj:4.135 [t=0.30s]
prediction: ['[CLS] room couch nicknamed district ultraviolet. imperial leaders [SEP]']
[ 300/2000] tot_loss=3.714 (perp=11.961, rec=0.455, cos=0.866), tot_loss_proj:4.287 [t=0.30s]
prediction: ['[CLS] room armchair mr district ultraviolet. imperial refugees [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.763 (perp=12.389, rec=0.422, cos=0.864), tot_loss_proj:4.333 [t=0.30s]
prediction: ['[CLS] room refugees mr armchair ultraviolet satys armchair [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.621 (perp=11.738, rec=0.401, cos=0.872), tot_loss_proj:4.118 [t=0.30s]
prediction: ['[CLS] room mr armchair ultraviolet sat refugeesys armchair [SEP]']
[ 450/2000] tot_loss=3.431 (perp=10.850, rec=0.375, cos=0.887), tot_loss_proj:3.955 [t=0.30s]
prediction: ['[CLS] mr mr armchair ultraviolet sat refugees upon armchair [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.550 (perp=11.451, rec=0.368, cos=0.892), tot_loss_proj:4.168 [t=0.30s]
prediction: ['[CLS] rooms mr ultraviolet mr sat refugees papyrus armchair [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.352 (perp=10.549, rec=0.350, cos=0.892), tot_loss_proj:4.034 [t=0.30s]
prediction: ['[CLS] mr mr ultraviolet sat mr product papyrus armchair [SEP]']
[ 600/2000] tot_loss=3.364 (perp=10.549, rec=0.351, cos=0.903), tot_loss_proj:4.041 [t=0.30s]
prediction: ['[CLS] mr mr ultraviolet sat mr product papyrus armchair [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.342 (perp=10.549, rec=0.338, cos=0.894), tot_loss_proj:4.041 [t=0.30s]
prediction: ['[CLS] mr mr ultraviolet sat mr product papyrus armchair [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.348 (perp=10.549, rec=0.342, cos=0.896), tot_loss_proj:4.036 [t=0.30s]
prediction: ['[CLS] mr mr ultraviolet sat mr product papyrus armchair [SEP]']
[ 750/2000] tot_loss=3.335 (perp=10.549, rec=0.323, cos=0.902), tot_loss_proj:4.034 [t=0.30s]
prediction: ['[CLS] mr mr ultraviolet sat mr product papyrus armchair [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.411 (perp=10.933, rec=0.323, cos=0.902), tot_loss_proj:4.092 [t=0.30s]
prediction: ['[CLS] mr mr ultraviolet sat mr product wrist armchair [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.383 (perp=10.660, rec=0.339, cos=0.912), tot_loss_proj:4.086 [t=0.30s]
prediction: ['[CLS] mr mr directions sat wrist product mr armchair [SEP]']
[ 900/2000] tot_loss=3.513 (perp=11.419, rec=0.328, cos=0.901), tot_loss_proj:4.187 [t=0.30s]
prediction: ['[CLS] mr mr directions sat fingers product mr armchair [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.447 (perp=11.138, rec=0.321, cos=0.898), tot_loss_proj:4.176 [t=0.30s]
prediction: ['[CLS] mr mr sat directions fingers product mr armchair [SEP]']
Attempt swap
[1000/2000] tot_loss=3.445 (perp=11.138, rec=0.311, cos=0.907), tot_loss_proj:4.175 [t=0.30s]
prediction: ['[CLS] mr mr sat directions fingers product mr armchair [SEP]']
[1050/2000] tot_loss=3.450 (perp=11.138, rec=0.321, cos=0.902), tot_loss_proj:4.178 [t=0.30s]
prediction: ['[CLS] mr mr sat directions fingers product mr armchair [SEP]']
Attempt swap
[1100/2000] tot_loss=3.436 (perp=11.138, rec=0.305, cos=0.903), tot_loss_proj:4.172 [t=0.30s]
prediction: ['[CLS] mr mr sat directions fingers product mr armchair [SEP]']
Attempt swap
[1150/2000] tot_loss=3.447 (perp=11.150, rec=0.310, cos=0.906), tot_loss_proj:4.155 [t=0.30s]
prediction: ['[CLS] mr mr sat directions fingersgrowth mr armchair [SEP]']
[1200/2000] tot_loss=3.290 (perp=10.337, rec=0.317, cos=0.905), tot_loss_proj:4.001 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Attempt swap
[1250/2000] tot_loss=3.272 (perp=10.337, rec=0.299, cos=0.906), tot_loss_proj:3.999 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Attempt swap
[1300/2000] tot_loss=3.287 (perp=10.337, rec=0.318, cos=0.902), tot_loss_proj:4.007 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
[1350/2000] tot_loss=3.270 (perp=10.337, rec=0.294, cos=0.908), tot_loss_proj:4.005 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Attempt swap
[1400/2000] tot_loss=3.279 (perp=10.337, rec=0.308, cos=0.904), tot_loss_proj:4.006 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Attempt swap
[1450/2000] tot_loss=3.269 (perp=10.337, rec=0.298, cos=0.904), tot_loss_proj:4.006 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
[1500/2000] tot_loss=3.260 (perp=10.337, rec=0.290, cos=0.903), tot_loss_proj:4.004 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Attempt swap
[1550/2000] tot_loss=3.268 (perp=10.337, rec=0.294, cos=0.906), tot_loss_proj:4.002 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Attempt swap
[1600/2000] tot_loss=3.274 (perp=10.337, rec=0.300, cos=0.907), tot_loss_proj:4.002 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
[1650/2000] tot_loss=3.269 (perp=10.337, rec=0.296, cos=0.905), tot_loss_proj:4.005 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Attempt swap
[1700/2000] tot_loss=3.265 (perp=10.337, rec=0.293, cos=0.905), tot_loss_proj:4.011 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Attempt swap
[1750/2000] tot_loss=3.264 (perp=10.337, rec=0.292, cos=0.905), tot_loss_proj:4.003 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
[1800/2000] tot_loss=3.271 (perp=10.337, rec=0.298, cos=0.906), tot_loss_proj:4.006 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Attempt swap
[1850/2000] tot_loss=3.267 (perp=10.337, rec=0.295, cos=0.905), tot_loss_proj:4.005 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Attempt swap
[1900/2000] tot_loss=3.263 (perp=10.337, rec=0.291, cos=0.905), tot_loss_proj:4.000 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
[1950/2000] tot_loss=3.256 (perp=10.337, rec=0.284, cos=0.904), tot_loss_proj:4.006 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Attempt swap
[2000/2000] tot_loss=3.257 (perp=10.337, rec=0.286, cos=0.904), tot_loss_proj:4.007 [t=0.30s]
prediction: ['[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] mr woodhouse sat in an armchair. [SEP]
========================
predicted: 
========================
[CLS] mr mr sathouse fingersgrowth mr armchair [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 50.000 | r: 50.000
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 78.571

[Aggregate metrics]:
rouge1     | fm: 76.156 | p: 76.483 | r: 76.114
rouge2     | fm: 34.179 | p: 34.276 | r: 34.269
rougeL     | fm: 67.033 | p: 67.376 | r: 66.894
rougeLsum  | fm: 67.109 | p: 67.483 | r: 66.908
r1fm+r2fm = 110.336

input #59 time: 0:11:48 | total time: 11:55:48


Running input #60 of 100.
reference: 
========================
It is likely that Jean left.
========================
average of cosine similarity 0.999139443335654
highest_index [0]
highest [0.999139443335654]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2009, 2003, 3497, 2008, 3744, 2187, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] it is likely that jean left. [SEP]']
[Init] best rec loss: 0.9802945256233215 for ['[CLS]ach called vision sea age include wren [SEP]']
[Init] best rec loss: 0.9334380626678467 for ['[CLS] blue returnedisen within zur immediateores [SEP]']
[Init] best rec loss: 0.9324420690536499 for ['[CLS]logy \\ main uta separate each cho [SEP]']
[Init] best rec loss: 0.926945686340332 for ['[CLS] basketball 3 regard fantastic railroadriz mar [SEP]']
[Init] best rec loss: 0.9193480610847473 for ['[CLS] been seed lessonsache citizens wax received [SEP]']
[Init] best perm rec loss: 0.9187968373298645 for ['[CLS] received lessons waxache citizens been seed [SEP]']
[Init] best perm rec loss: 0.9163755774497986 for ['[CLS] lessons citizens been received wax seedache [SEP]']
[Init] best perm rec loss: 0.9160957932472229 for ['[CLS] seed citizens lessonsache been received wax [SEP]']
[Init] best perm rec loss: 0.9156671166419983 for ['[CLS] citizens lessons been seed wax receivedache [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.040 (perp=7.935, rec=0.670, cos=0.783), tot_loss_proj:3.275 [t=0.29s]
prediction: ['[CLS] then she was erosion hangul there. [SEP]']
[ 100/2000] tot_loss=3.168 (perp=8.876, rec=0.615, cos=0.778), tot_loss_proj:3.481 [t=0.30s]
prediction: ['[CLS] likely she was jean has because. [SEP]']
[ 150/2000] tot_loss=3.424 (perp=9.761, rec=0.597, cos=0.875), tot_loss_proj:3.699 [t=0.30s]
prediction: ['[CLS] likely we arrived jean jean because. [SEP]']
[ 200/2000] tot_loss=3.111 (perp=8.384, rec=0.572, cos=0.862), tot_loss_proj:3.685 [t=0.30s]
prediction: ['[CLS] likely we left jean jean because. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.372 (perp=9.754, rec=0.614, cos=0.807), tot_loss_proj:3.730 [t=0.30s]
prediction: ['[CLS] o abolished died jean left jean. [SEP]']
[ 300/2000] tot_loss=3.414 (perp=8.567, rec=0.731, cos=0.969), tot_loss_proj:3.472 [t=0.30s]
prediction: ['[CLS] i you say jean festival her. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.829 (perp=10.676, rec=0.473, cos=0.221), tot_loss_proj:3.856 [t=0.30s]
prediction: ['[CLS] course likely probably jean they so. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.865 (perp=11.820, rec=0.370, cos=0.131), tot_loss_proj:4.065 [t=0.30s]
prediction: ['[CLS] call likely probably jean so covering. [SEP]']
[ 450/2000] tot_loss=2.462 (perp=10.122, rec=0.320, cos=0.118), tot_loss_proj:3.776 [t=0.30s]
prediction: ['[CLS] m likely probably jean so left. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.358 (perp=9.870, rec=0.283, cos=0.101), tot_loss_proj:3.822 [t=0.30s]
prediction: ['[CLS] even likely probably left jeanona. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.622 (perp=9.806, rec=0.471, cos=0.190), tot_loss_proj:3.638 [t=0.30s]
prediction: ['[CLS] i likely jean thence leftona. [SEP]']
[ 600/2000] tot_loss=2.809 (perp=9.742, rec=0.529, cos=0.332), tot_loss_proj:3.659 [t=0.30s]
prediction: ['[CLS] tell likely jean that left left. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.895 (perp=9.925, rec=0.469, cos=0.441), tot_loss_proj:3.683 [t=0.30s]
prediction: ['[CLS] probably likely subsequently jean left left. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.736 (perp=9.149, rec=0.413, cos=0.494), tot_loss_proj:3.573 [t=0.30s]
prediction: ['[CLS] probably likely jean that left left. [SEP]']
[ 750/2000] tot_loss=2.543 (perp=8.105, rec=0.400, cos=0.522), tot_loss_proj:3.500 [t=0.30s]
prediction: ['[CLS] it likely jean that left left. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.629 (perp=8.381, rec=0.393, cos=0.560), tot_loss_proj:3.400 [t=0.30s]
prediction: ['[CLS] it likelyetto jean that left. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.607 (perp=8.486, rec=0.403, cos=0.506), tot_loss_proj:3.322 [t=0.30s]
prediction: ['[CLS] it likely that jean preserved added. [SEP]']
[ 900/2000] tot_loss=2.635 (perp=8.486, rec=0.380, cos=0.558), tot_loss_proj:3.322 [t=0.30s]
prediction: ['[CLS] it likely that jean preserved added. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.532 (perp=8.209, rec=0.372, cos=0.518), tot_loss_proj:3.331 [t=0.30s]
prediction: ['[CLS] it likely preserved that jean translates. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.533 (perp=8.209, rec=0.358, cos=0.534), tot_loss_proj:3.327 [t=0.30s]
prediction: ['[CLS] it likely preserved that jean translates. [SEP]']
[1050/2000] tot_loss=2.533 (perp=8.209, rec=0.348, cos=0.543), tot_loss_proj:3.319 [t=0.30s]
prediction: ['[CLS] it likely preserved that jean translates. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.554 (perp=8.354, rec=0.346, cos=0.538), tot_loss_proj:3.392 [t=0.30s]
prediction: ['[CLS] it likely remaining that jean translates. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.450 (perp=7.704, rec=0.362, cos=0.546), tot_loss_proj:3.449 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
[1200/2000] tot_loss=2.426 (perp=7.704, rec=0.358, cos=0.528), tot_loss_proj:3.452 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.407 (perp=7.704, rec=0.342, cos=0.524), tot_loss_proj:3.453 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.427 (perp=7.704, rec=0.333, cos=0.553), tot_loss_proj:3.455 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
[1350/2000] tot_loss=2.406 (perp=7.704, rec=0.342, cos=0.523), tot_loss_proj:3.452 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.418 (perp=7.704, rec=0.335, cos=0.542), tot_loss_proj:3.455 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.425 (perp=7.704, rec=0.338, cos=0.547), tot_loss_proj:3.449 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
[1500/2000] tot_loss=2.404 (perp=7.704, rec=0.340, cos=0.524), tot_loss_proj:3.451 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.419 (perp=7.704, rec=0.334, cos=0.544), tot_loss_proj:3.454 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.403 (perp=7.704, rec=0.328, cos=0.534), tot_loss_proj:3.451 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
[1650/2000] tot_loss=2.406 (perp=7.704, rec=0.333, cos=0.532), tot_loss_proj:3.456 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.416 (perp=7.704, rec=0.343, cos=0.532), tot_loss_proj:3.458 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.410 (perp=7.704, rec=0.337, cos=0.533), tot_loss_proj:3.453 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
[1800/2000] tot_loss=2.415 (perp=7.704, rec=0.341, cos=0.533), tot_loss_proj:3.454 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.411 (perp=7.704, rec=0.336, cos=0.534), tot_loss_proj:3.453 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.408 (perp=7.704, rec=0.334, cos=0.533), tot_loss_proj:3.454 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
[1950/2000] tot_loss=2.403 (perp=7.704, rec=0.327, cos=0.535), tot_loss_proj:3.451 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.411 (perp=7.704, rec=0.336, cos=0.534), tot_loss_proj:3.452 [t=0.30s]
prediction: ['[CLS] it remaining likely that jean translates. [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] it is likely that jean left. [SEP]
========================
predicted: 
========================
[CLS] even likely probably left jeanona. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.333 | p: 57.143 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 53.333 | p: 57.143 | r: 50.000
rougeLsum  | fm: 53.333 | p: 57.143 | r: 50.000
r1fm+r2fm = 53.333

[Aggregate metrics]:
rouge1     | fm: 75.845 | p: 76.170 | r: 75.716
rouge2     | fm: 33.662 | p: 33.727 | r: 33.711
rougeL     | fm: 66.809 | p: 67.140 | r: 66.553
rougeLsum  | fm: 66.937 | p: 67.341 | r: 66.684
r1fm+r2fm = 109.506

input #60 time: 0:11:48 | total time: 12:07:36


Running input #61 of 100.
reference: 
========================
Physicists like yourself are a godsend.
========================
average of cosine similarity 0.9989105818321669
highest_index [0]
highest [0.9989105818321669]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 13702,  2015,  2066,  4426,  2024,  1037,  5932, 10497,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] physicists like yourself are a godsend. [SEP]']
[Init] best rec loss: 0.9168273210525513 for ['[CLS]serromatic rescue object morning which viable for seeking [SEP]']
[Init] best rec loss: 0.8915850520133972 for ['[CLS] bill expected and film monarchy meeting straightaf else [SEP]']
[Init] best rec loss: 0.8840495347976685 for ['[CLS] fixed commissioner manual church off stem pickup lips austin [SEP]']
[Init] best rec loss: 0.8715069890022278 for ['[CLS] first parental bill julius orthodox thank orson what knock [SEP]']
[Init] best rec loss: 0.8634189367294312 for ['[CLS] racing unnamed jaguar aires telephonegr controlled high gas [SEP]']
[Init] best rec loss: 0.8455278873443604 for ['[CLS] cache edit sea poles cycle prime so cabinet chicago [SEP]']
[Init] best perm rec loss: 0.8440470695495605 for ['[CLS] sea cycle cabinet prime so edit poles chicago cache [SEP]']
[Init] best perm rec loss: 0.8439746499061584 for ['[CLS] cache cycle chicago prime cabinet edit sea poles so [SEP]']
[Init] best perm rec loss: 0.8437497615814209 for ['[CLS] prime cycle sea edit cabinet cache so chicago poles [SEP]']
[Init] best perm rec loss: 0.8437262773513794 for ['[CLS] poles so edit cycle sea chicago prime cache cabinet [SEP]']
[Init] best perm rec loss: 0.8435416221618652 for ['[CLS] cycle prime sea so edit cache cabinet poles chicago [SEP]']
[Init] best perm rec loss: 0.8414561748504639 for ['[CLS] so cache poles cabinet prime sea chicago edit cycle [SEP]']
[Init] best perm rec loss: 0.8413249254226685 for ['[CLS] so cache cycle edit chicago poles sea cabinet prime [SEP]']
[Init] best perm rec loss: 0.8410059213638306 for ['[CLS] sea cycle edit cache chicago prime cabinet so poles [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.705 (perp=12.710, rec=0.416, cos=0.747), tot_loss_proj:4.481 [t=0.29s]
prediction: ['[CLS] homosexual gets explode considering orders yourself structures ( reel [SEP]']
[ 100/2000] tot_loss=2.865 (perp=9.374, rec=0.282, cos=0.708), tot_loss_proj:3.687 [t=0.30s]
prediction: ['[CLS] physicist instants like like yourself are [UNK]pes [SEP]']
[ 150/2000] tot_loss=3.377 (perp=10.424, rec=0.507, cos=0.785), tot_loss_proj:4.002 [t=0.30s]
prediction: ['[CLS] physicist creators like like yourself are any extremes [SEP]']
[ 200/2000] tot_loss=3.229 (perp=11.169, rec=0.271, cos=0.724), tot_loss_proj:4.136 [t=0.30s]
prediction: ['[CLS] physicist nevers like like yourself are stevie extremes [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.481 (perp=7.648, rec=0.232, cos=0.719), tot_loss_proj:3.453 [t=0.30s]
prediction: ['[CLS] never physicists like like yourself are kaladin. [SEP]']
[ 300/2000] tot_loss=2.457 (perp=7.648, rec=0.219, cos=0.709), tot_loss_proj:3.456 [t=0.30s]
prediction: ['[CLS] never physicists like like yourself are kaladin. [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.493 (perp=7.855, rec=0.204, cos=0.718), tot_loss_proj:3.412 [t=0.30s]
prediction: ['[CLS] fantastic physicists like like yourself are kaladin. [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.460 (perp=7.648, rec=0.202, cos=0.729), tot_loss_proj:3.460 [t=0.30s]
prediction: ['[CLS] never physicists like like yourself are kaladin. [SEP]']
[ 450/2000] tot_loss=2.296 (perp=6.904, rec=0.197, cos=0.718), tot_loss_proj:2.900 [t=0.30s]
prediction: ['[CLS] never physicists like like yourself are gods. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.281 (perp=6.904, rec=0.190, cos=0.710), tot_loss_proj:2.891 [t=0.30s]
prediction: ['[CLS] never physicists like like yourself are gods. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.292 (perp=6.904, rec=0.186, cos=0.726), tot_loss_proj:2.887 [t=0.30s]
prediction: ['[CLS] never physicists like like yourself are gods. [SEP]']
[ 600/2000] tot_loss=2.307 (perp=6.904, rec=0.188, cos=0.739), tot_loss_proj:2.892 [t=0.30s]
prediction: ['[CLS] never physicists like like yourself are gods. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.158 (perp=6.322, rec=0.175, cos=0.719), tot_loss_proj:3.071 [t=0.30s]
prediction: ['[CLS] months like physicists like yourself are gods. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.180 (perp=6.322, rec=0.187, cos=0.729), tot_loss_proj:3.072 [t=0.30s]
prediction: ['[CLS] months like physicists like yourself are gods. [SEP]']
[ 750/2000] tot_loss=2.166 (perp=6.322, rec=0.183, cos=0.719), tot_loss_proj:3.070 [t=0.30s]
prediction: ['[CLS] months like physicists like yourself are gods. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.161 (perp=6.322, rec=0.168, cos=0.729), tot_loss_proj:3.069 [t=0.30s]
prediction: ['[CLS] months like physicists like yourself are gods. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.159 (perp=6.322, rec=0.171, cos=0.724), tot_loss_proj:3.066 [t=0.30s]
prediction: ['[CLS] months like physicists like yourself are gods. [SEP]']
[ 900/2000] tot_loss=2.050 (perp=5.780, rec=0.167, cos=0.727), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.047 (perp=5.780, rec=0.173, cos=0.719), tot_loss_proj:1.715 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.051 (perp=5.780, rec=0.168, cos=0.727), tot_loss_proj:1.717 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
[1050/2000] tot_loss=2.053 (perp=5.780, rec=0.172, cos=0.726), tot_loss_proj:1.714 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.058 (perp=5.780, rec=0.171, cos=0.730), tot_loss_proj:1.714 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.050 (perp=5.780, rec=0.174, cos=0.720), tot_loss_proj:1.707 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
[1200/2000] tot_loss=2.042 (perp=5.780, rec=0.165, cos=0.721), tot_loss_proj:1.711 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.059 (perp=5.780, rec=0.176, cos=0.727), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.061 (perp=5.780, rec=0.179, cos=0.726), tot_loss_proj:1.710 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
[1350/2000] tot_loss=2.050 (perp=5.780, rec=0.170, cos=0.724), tot_loss_proj:1.710 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.055 (perp=5.780, rec=0.178, cos=0.720), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.035 (perp=5.780, rec=0.162, cos=0.718), tot_loss_proj:1.715 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
[1500/2000] tot_loss=2.050 (perp=5.780, rec=0.173, cos=0.721), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.045 (perp=5.780, rec=0.164, cos=0.725), tot_loss_proj:1.712 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.057 (perp=5.780, rec=0.176, cos=0.725), tot_loss_proj:1.714 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself are gods. [SEP]']
[1650/2000] tot_loss=2.367 (perp=7.330, rec=0.178, cos=0.723), tot_loss_proj:3.365 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself areend. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.352 (perp=7.330, rec=0.162, cos=0.724), tot_loss_proj:3.363 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself areend. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.350 (perp=7.330, rec=0.162, cos=0.721), tot_loss_proj:3.360 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself areend. [SEP]']
[1800/2000] tot_loss=2.356 (perp=7.330, rec=0.167, cos=0.723), tot_loss_proj:3.361 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself areend. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.350 (perp=7.330, rec=0.161, cos=0.723), tot_loss_proj:3.362 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself areend. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.354 (perp=7.330, rec=0.163, cos=0.725), tot_loss_proj:3.357 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself areend. [SEP]']
[1950/2000] tot_loss=2.358 (perp=7.330, rec=0.169, cos=0.723), tot_loss_proj:3.359 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself areend. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.355 (perp=7.330, rec=0.166, cos=0.724), tot_loss_proj:3.357 [t=0.30s]
prediction: ['[CLS] gods like physicists like yourself areend. [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS] physicists like yourself are a godsend. [SEP]
========================
predicted: 
========================
[CLS] gods like physicists like yourself areend. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.500 | p: 62.500 | r: 62.500
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 91.071

[Aggregate metrics]:
rouge1     | fm: 75.534 | p: 75.928 | r: 75.424
rouge2     | fm: 33.431 | p: 33.619 | r: 33.492
rougeL     | fm: 66.729 | p: 67.123 | r: 66.487
rougeLsum  | fm: 66.821 | p: 67.272 | r: 66.577
r1fm+r2fm = 108.964

input #61 time: 0:11:47 | total time: 12:19:24


Running input #62 of 100.
reference: 
========================
Any pilot could be flying this plane.
========================
average of cosine similarity 0.999109588816503
highest_index [0]
highest [0.999109588816503]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2151, 4405, 2071, 2022, 3909, 2023, 4946, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] any pilot could be flying this plane. [SEP]']
[Init] best rec loss: 0.9195500016212463 for ['[CLS] events heat names cole issue. 505 regina [SEP]']
[Init] best rec loss: 0.9150976538658142 for ['[CLS] from actress le testament sooner pit confederacy oct [SEP]']
[Init] best rec loss: 0.8781733512878418 for ['[CLS] permissionoun congregation tales eternity wilde memory format [SEP]']
[Init] best rec loss: 0.8778027892112732 for ['[CLS] current sugar donnelly whichcumnity college utility [SEP]']
[Init] best rec loss: 0.8730940818786621 for ['[CLS] civic floor roland tranceik extra chance accessible [SEP]']
[Init] best rec loss: 0.8662171959877014 for ['[CLS]ommerie south chest tr gray collar scent [SEP]']
[Init] best rec loss: 0.8581827282905579 for ['[CLS] oh brute distribution harder limited michelangelo pacific bee [SEP]']
[Init] best perm rec loss: 0.8580068945884705 for ['[CLS] brute bee limited distribution oh michelangelo pacific harder [SEP]']
[Init] best perm rec loss: 0.8566868305206299 for ['[CLS] oh pacific bee distribution limited harder brute michelangelo [SEP]']
[Init] best perm rec loss: 0.8564220070838928 for ['[CLS] michelangelo harder pacific brute bee distribution limited oh [SEP]']
[Init] best perm rec loss: 0.8563528060913086 for ['[CLS] distribution limited harder oh pacific bee michelangelo brute [SEP]']
[Init] best perm rec loss: 0.8555747866630554 for ['[CLS] pacific harder oh distribution brute michelangelo bee limited [SEP]']
[Init] best perm rec loss: 0.8545042276382446 for ['[CLS] michelangelo pacific bee harder oh brute distribution limited [SEP]']
[Init] best perm rec loss: 0.8542472720146179 for ['[CLS] distribution harder oh limited brute michelangelo bee pacific [SEP]']
[Init] best perm rec loss: 0.852825403213501 for ['[CLS] michelangelo brute oh distribution harder limited pacific bee [SEP]']
[Init] best perm rec loss: 0.8526774644851685 for ['[CLS] michelangelo pacific oh distribution bee harder limited brute [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.032 (perp=9.558, rec=0.400, cos=0.720), tot_loss_proj:3.774 [t=0.29s]
prediction: ['[CLS]. any archer ltd - no flight tree [SEP]']
[ 100/2000] tot_loss=2.622 (perp=8.297, rec=0.252, cos=0.711), tot_loss_proj:3.516 [t=0.30s]
prediction: ['[CLS]. any pilot could - could pilot plane [SEP]']
[ 150/2000] tot_loss=2.583 (perp=8.188, rec=0.220, cos=0.725), tot_loss_proj:3.341 [t=0.30s]
prediction: ['[CLS]. any pilot could. this aircraft plane [SEP]']
[ 200/2000] tot_loss=2.579 (perp=8.188, rec=0.201, cos=0.741), tot_loss_proj:3.340 [t=0.30s]
prediction: ['[CLS]. any pilot could. this aircraft plane [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.624 (perp=7.667, rec=0.354, cos=0.737), tot_loss_proj:3.280 [t=0.30s]
prediction: ['[CLS]. any pilot. this aircraft could aircraft [SEP]']
[ 300/2000] tot_loss=2.653 (perp=8.210, rec=0.243, cos=0.768), tot_loss_proj:3.564 [t=0.30s]
prediction: ['[CLS] outcome any pilot. this plane could plane [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.601 (perp=8.210, rec=0.211, cos=0.748), tot_loss_proj:3.552 [t=0.30s]
prediction: ['[CLS] outcome any pilot. this plane could plane [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.646 (perp=8.142, rec=0.247, cos=0.771), tot_loss_proj:3.564 [t=0.30s]
prediction: ['[CLS] any outcome pilot flying this plane could plane [SEP]']
[ 450/2000] tot_loss=2.570 (perp=8.142, rec=0.201, cos=0.740), tot_loss_proj:3.564 [t=0.30s]
prediction: ['[CLS] any outcome pilot flying this plane could plane [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.389 (perp=7.236, rec=0.202, cos=0.740), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.380 (perp=7.236, rec=0.198, cos=0.735), tot_loss_proj:3.349 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
[ 600/2000] tot_loss=2.375 (perp=7.236, rec=0.193, cos=0.734), tot_loss_proj:3.345 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.372 (perp=7.236, rec=0.189, cos=0.736), tot_loss_proj:3.345 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.366 (perp=7.236, rec=0.188, cos=0.731), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
[ 750/2000] tot_loss=2.364 (perp=7.236, rec=0.180, cos=0.736), tot_loss_proj:3.345 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.368 (perp=7.236, rec=0.185, cos=0.736), tot_loss_proj:3.349 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.373 (perp=7.236, rec=0.189, cos=0.737), tot_loss_proj:3.350 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
[ 900/2000] tot_loss=2.370 (perp=7.236, rec=0.186, cos=0.737), tot_loss_proj:3.344 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.364 (perp=7.236, rec=0.184, cos=0.733), tot_loss_proj:3.351 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1000/2000] tot_loss=2.355 (perp=7.236, rec=0.171, cos=0.736), tot_loss_proj:3.352 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
[1050/2000] tot_loss=2.352 (perp=7.236, rec=0.173, cos=0.732), tot_loss_proj:3.347 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1100/2000] tot_loss=2.357 (perp=7.236, rec=0.178, cos=0.732), tot_loss_proj:3.348 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1150/2000] tot_loss=2.351 (perp=7.236, rec=0.174, cos=0.730), tot_loss_proj:3.347 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
[1200/2000] tot_loss=2.352 (perp=7.236, rec=0.174, cos=0.731), tot_loss_proj:3.345 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1250/2000] tot_loss=2.373 (perp=7.236, rec=0.191, cos=0.735), tot_loss_proj:3.346 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1300/2000] tot_loss=2.360 (perp=7.236, rec=0.182, cos=0.731), tot_loss_proj:3.344 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
[1350/2000] tot_loss=2.350 (perp=7.236, rec=0.172, cos=0.731), tot_loss_proj:3.353 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1400/2000] tot_loss=2.354 (perp=7.236, rec=0.177, cos=0.729), tot_loss_proj:3.342 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1450/2000] tot_loss=2.368 (perp=7.236, rec=0.191, cos=0.730), tot_loss_proj:3.348 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
[1500/2000] tot_loss=2.344 (perp=7.236, rec=0.166, cos=0.730), tot_loss_proj:3.345 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1550/2000] tot_loss=2.350 (perp=7.236, rec=0.174, cos=0.729), tot_loss_proj:3.341 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1600/2000] tot_loss=2.358 (perp=7.236, rec=0.182, cos=0.729), tot_loss_proj:3.344 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
[1650/2000] tot_loss=2.357 (perp=7.236, rec=0.181, cos=0.729), tot_loss_proj:3.348 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1700/2000] tot_loss=2.352 (perp=7.236, rec=0.174, cos=0.730), tot_loss_proj:3.345 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1750/2000] tot_loss=2.356 (perp=7.236, rec=0.181, cos=0.728), tot_loss_proj:3.347 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
[1800/2000] tot_loss=2.346 (perp=7.236, rec=0.170, cos=0.728), tot_loss_proj:3.346 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1850/2000] tot_loss=2.356 (perp=7.236, rec=0.181, cos=0.728), tot_loss_proj:3.354 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[1900/2000] tot_loss=2.352 (perp=7.236, rec=0.176, cos=0.729), tot_loss_proj:3.351 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
[1950/2000] tot_loss=2.357 (perp=7.236, rec=0.181, cos=0.729), tot_loss_proj:3.339 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Attempt swap
[2000/2000] tot_loss=2.345 (perp=7.236, rec=0.169, cos=0.729), tot_loss_proj:3.345 [t=0.30s]
prediction: ['[CLS] any plane pilot flying this plane could outcome [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] any pilot could be flying this plane. [SEP]
========================
predicted: 
========================
[CLS] any plane pilot flying this plane could outcome [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 35.294 | p: 33.333 | r: 37.500
rougeL     | fm: 73.684 | p: 70.000 | r: 77.778
rougeLsum  | fm: 73.684 | p: 70.000 | r: 77.778
r1fm+r2fm = 119.505

[Aggregate metrics]:
rouge1     | fm: 75.768 | p: 76.059 | r: 75.729
rouge2     | fm: 33.660 | p: 33.678 | r: 33.717
rougeL     | fm: 66.877 | p: 67.156 | r: 66.647
rougeLsum  | fm: 66.899 | p: 67.245 | r: 66.778
r1fm+r2fm = 109.428

input #62 time: 0:11:48 | total time: 12:31:12


Running input #63 of 100.
reference: 
========================
We wonder if Bill left.
========================
average of cosine similarity 0.998784025246322
highest_index [0]
highest [0.998784025246322]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2057, 4687, 2065, 3021, 2187, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] we wonder if bill left. [SEP]']
[Init] best rec loss: 0.966924786567688 for ['[CLS] affected maine effect streets studies its [SEP]']
[Init] best rec loss: 0.9455262422561646 for ['[CLS] concerned code victoria located steel korea [SEP]']
[Init] best rec loss: 0.9239830374717712 for ['[CLS] essencechu song lois go ant [SEP]']
[Init] best rec loss: 0.9213612079620361 for ['[CLS] graduate liabilitylay shoot picture fruit [SEP]']
[Init] best rec loss: 0.8765185475349426 for ['[CLS] [CLS]line subcontinent context platforms tessa [SEP]']
[Init] best perm rec loss: 0.8756722211837769 for ['[CLS] context subcontinent [CLS]line platforms tessa [SEP]']
[Init] best perm rec loss: 0.8754786252975464 for ['[CLS] subcontinentline context [CLS] platforms tessa [SEP]']
[Init] best perm rec loss: 0.8754109740257263 for ['[CLS] platforms contextline subcontinent [CLS] tessa [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.459 (perp=11.320, rec=0.592, cos=0.603), tot_loss_proj:4.081 [t=0.29s]
prediction: ['[CLS] twinkle marvel were mouthed - ashe [SEP]']
[ 100/2000] tot_loss=3.811 (perp=13.356, rec=0.522, cos=0.618), tot_loss_proj:4.534 [t=0.29s]
prediction: ['[CLS] wonder wonder althoughsome d impression [SEP]']
[ 150/2000] tot_loss=3.375 (perp=11.603, rec=0.475, cos=0.580), tot_loss_proj:4.260 [t=0.30s]
prediction: ['[CLS] wonder wonder wondersome d prison [SEP]']
[ 200/2000] tot_loss=3.476 (perp=12.353, rec=0.487, cos=0.518), tot_loss_proj:4.273 [t=0.30s]
prediction: ['[CLS] wonder we wonder mug if wonder [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.170 (perp=11.046, rec=0.417, cos=0.544), tot_loss_proj:4.061 [t=0.30s]
prediction: ['[CLS] wonder we wonder bill if wondering [SEP]']
[ 300/2000] tot_loss=3.140 (perp=10.952, rec=0.361, cos=0.588), tot_loss_proj:4.047 [t=0.30s]
prediction: ['[CLS] wonder we wonder bill if naive [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.532 (perp=12.757, rec=0.397, cos=0.584), tot_loss_proj:4.409 [t=0.30s]
prediction: ['[CLS] wonder we wonder respectively bill naive [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.367 (perp=11.976, rec=0.362, cos=0.610), tot_loss_proj:4.177 [t=0.30s]
prediction: ['[CLS] wonder we if bill respectively naive [SEP]']
[ 450/2000] tot_loss=3.344 (perp=11.976, rec=0.375, cos=0.573), tot_loss_proj:4.191 [t=0.30s]
prediction: ['[CLS] wonder we if bill respectively naive [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.343 (perp=11.976, rec=0.344, cos=0.605), tot_loss_proj:4.179 [t=0.30s]
prediction: ['[CLS] wonder we if bill respectively naive [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.052 (perp=9.321, rec=0.588, cos=0.600), tot_loss_proj:3.809 [t=0.30s]
prediction: ['[CLS] we wonder if bill jackie candles [SEP]']
[ 600/2000] tot_loss=2.906 (perp=9.189, rec=0.463, cos=0.604), tot_loss_proj:3.657 [t=0.30s]
prediction: ['[CLS] we wonder if bill else formerly [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.867 (perp=9.189, rec=0.412, cos=0.617), tot_loss_proj:3.654 [t=0.30s]
prediction: ['[CLS] we wonder if bill else formerly [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.861 (perp=9.252, rec=0.383, cos=0.628), tot_loss_proj:3.806 [t=0.30s]
prediction: ['[CLS] we wonder if bill thighs formerly [SEP]']
[ 750/2000] tot_loss=2.857 (perp=9.336, rec=0.364, cos=0.626), tot_loss_proj:3.806 [t=0.30s]
prediction: ['[CLS] we wonder if bill thus formerly [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.757 (perp=8.834, rec=0.358, cos=0.633), tot_loss_proj:3.708 [t=0.30s]
prediction: ['[CLS] we wonder if bill thus hairy [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.723 (perp=8.834, rec=0.333, cos=0.622), tot_loss_proj:3.709 [t=0.30s]
prediction: ['[CLS] we wonder if bill thus hairy [SEP]']
[ 900/2000] tot_loss=2.715 (perp=8.834, rec=0.327, cos=0.621), tot_loss_proj:3.713 [t=0.30s]
prediction: ['[CLS] we wonder if bill thus hairy [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.713 (perp=8.834, rec=0.324, cos=0.622), tot_loss_proj:3.711 [t=0.30s]
prediction: ['[CLS] we wonder if bill thus hairy [SEP]']
Attempt swap
[1000/2000] tot_loss=2.706 (perp=8.834, rec=0.321, cos=0.619), tot_loss_proj:3.708 [t=0.30s]
prediction: ['[CLS] we wonder if bill thus hairy [SEP]']
[1050/2000] tot_loss=2.709 (perp=8.834, rec=0.321, cos=0.621), tot_loss_proj:3.713 [t=0.30s]
prediction: ['[CLS] we wonder if bill thus hairy [SEP]']
Attempt swap
[1100/2000] tot_loss=2.955 (perp=10.136, rec=0.306, cos=0.622), tot_loss_proj:3.857 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[1150/2000] tot_loss=2.954 (perp=10.136, rec=0.307, cos=0.620), tot_loss_proj:3.865 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
[1200/2000] tot_loss=2.954 (perp=10.136, rec=0.307, cos=0.621), tot_loss_proj:3.860 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[1250/2000] tot_loss=2.938 (perp=10.136, rec=0.291, cos=0.620), tot_loss_proj:3.862 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[1300/2000] tot_loss=2.954 (perp=10.136, rec=0.306, cos=0.621), tot_loss_proj:3.857 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
[1350/2000] tot_loss=2.949 (perp=10.136, rec=0.300, cos=0.621), tot_loss_proj:3.861 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[1400/2000] tot_loss=2.954 (perp=10.136, rec=0.304, cos=0.622), tot_loss_proj:3.862 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[1450/2000] tot_loss=2.952 (perp=10.136, rec=0.302, cos=0.622), tot_loss_proj:3.864 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
[1500/2000] tot_loss=2.950 (perp=10.136, rec=0.302, cos=0.621), tot_loss_proj:3.864 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[1550/2000] tot_loss=2.944 (perp=10.136, rec=0.296, cos=0.621), tot_loss_proj:3.862 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[1600/2000] tot_loss=2.949 (perp=10.136, rec=0.300, cos=0.622), tot_loss_proj:3.864 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
[1650/2000] tot_loss=2.940 (perp=10.136, rec=0.292, cos=0.620), tot_loss_proj:3.862 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[1700/2000] tot_loss=2.947 (perp=10.136, rec=0.299, cos=0.621), tot_loss_proj:3.864 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[1750/2000] tot_loss=2.940 (perp=10.136, rec=0.294, cos=0.620), tot_loss_proj:3.862 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
[1800/2000] tot_loss=2.948 (perp=10.136, rec=0.301, cos=0.620), tot_loss_proj:3.862 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[1850/2000] tot_loss=2.944 (perp=10.136, rec=0.295, cos=0.621), tot_loss_proj:3.864 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[1900/2000] tot_loss=2.943 (perp=10.136, rec=0.296, cos=0.620), tot_loss_proj:3.863 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
[1950/2000] tot_loss=2.943 (perp=10.136, rec=0.297, cos=0.619), tot_loss_proj:3.867 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Attempt swap
[2000/2000] tot_loss=2.950 (perp=10.136, rec=0.302, cos=0.621), tot_loss_proj:3.866 [t=0.30s]
prediction: ['[CLS] we wonder if bill behalf hairy [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] we wonder if bill left. [SEP]
========================
predicted: 
========================
[CLS] we wonder if bill behalf hairy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 61.538 | p: 57.143 | r: 66.667
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 141.538

[Aggregate metrics]:
rouge1     | fm: 75.739 | p: 75.997 | r: 75.790
rouge2     | fm: 34.102 | p: 34.021 | r: 34.248
rougeL     | fm: 67.006 | p: 67.217 | r: 66.971
rougeLsum  | fm: 67.124 | p: 67.425 | r: 67.077
r1fm+r2fm = 109.841

input #63 time: 0:11:46 | total time: 12:42:58


Running input #64 of 100.
reference: 
========================
Ellen talked with Helen about the problem.
========================
average of cosine similarity 0.9989703224589332
highest_index [0]
highest [0.9989703224589332]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9155, 5720, 2007, 6330, 2055, 1996, 3291, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] ellen talked with helen about the problem. [SEP]']
[Init] best rec loss: 1.0091861486434937 for ['[CLS] states gmina auction monument worthy than kennedy urban [SEP]']
[Init] best rec loss: 0.9371076226234436 for ['[CLS] dc partmona identity writer mary prime pool [SEP]']
[Init] best rec loss: 0.9335088133811951 for ['[CLS] produced athena mirror trailing clothes researching subwayclave [SEP]']
[Init] best rec loss: 0.93233722448349 for ['[CLS] angus wars quite manhattan seedsir ask robbie [SEP]']
[Init] best rec loss: 0.9086734056472778 for ['[CLS] yards hospitals insteadware luis council evervc [SEP]']
[Init] best perm rec loss: 0.9017903804779053 for ['[CLS]vc yards hospitals luis everware council instead [SEP]']
[Init] best perm rec loss: 0.9010239243507385 for ['[CLS] luisware council hospitalsvc ever instead yards [SEP]']
[Init] best perm rec loss: 0.9001808762550354 for ['[CLS]vc luis hospitals yards council everware instead [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.995 (perp=12.841, rec=0.720, cos=0.707), tot_loss_proj:4.288 [t=0.29s]
prediction: ['[CLS] joking seevar she stress. usa data [SEP]']
[ 100/2000] tot_loss=3.641 (perp=10.832, rec=0.677, cos=0.798), tot_loss_proj:3.877 [t=0.30s]
prediction: ['[CLS] talked join point have reminded. exchange results [SEP]']
[ 150/2000] tot_loss=3.902 (perp=11.683, rec=0.604, cos=0.962), tot_loss_proj:4.114 [t=0.30s]
prediction: ['[CLS] talked leslie colony how?. exchange results [SEP]']
[ 200/2000] tot_loss=2.720 (perp=11.078, rec=0.376, cos=0.128), tot_loss_proj:3.865 [t=0.30s]
prediction: ['[CLS] talked mentioned alex how talked. helen results [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.962 (perp=11.266, rec=0.799, cos=0.910), tot_loss_proj:4.121 [t=0.30s]
prediction: ['[CLS] ellen talked talked seemed.. discussed startup [SEP]']
[ 300/2000] tot_loss=4.040 (perp=12.042, rec=0.651, cos=0.981), tot_loss_proj:4.089 [t=0.30s]
prediction: ['[CLS] elise questions talked seemed. he canal facts [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.705 (perp=11.663, rec=0.476, cos=0.897), tot_loss_proj:4.131 [t=0.30s]
prediction: ['[CLS] ellen discuss talked talked. problems talked problem [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.535 (perp=11.686, rec=0.421, cos=0.777), tot_loss_proj:4.102 [t=0.30s]
prediction: ['[CLS] ellen problems discuss talked talked. talked problem [SEP]']
[ 450/2000] tot_loss=3.680 (perp=12.126, rec=0.398, cos=0.857), tot_loss_proj:4.301 [t=0.30s]
prediction: ['[CLS] ellen. about talked talked commuter talked problem [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.467 (perp=10.689, rec=0.422, cos=0.907), tot_loss_proj:3.910 [t=0.30s]
prediction: ['[CLS] ellen. commuter talked talked about talked problem [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.245 (perp=10.263, rec=0.375, cos=0.818), tot_loss_proj:3.833 [t=0.30s]
prediction: ['[CLS] ellen talked commuter. talked about talked problem [SEP]']
[ 600/2000] tot_loss=3.082 (perp=9.937, rec=0.343, cos=0.751), tot_loss_proj:3.720 [t=0.30s]
prediction: ['[CLS] ellen ellen commuter. talked about talked problem [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.996 (perp=9.541, rec=0.346, cos=0.742), tot_loss_proj:3.708 [t=0.30s]
prediction: ['[CLS] ellen. ellen commuter talked about talked problem [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.872 (perp=8.463, rec=0.359, cos=0.820), tot_loss_proj:3.462 [t=0.30s]
prediction: ['[CLS] ellen. ellen talked talked about commuter problem [SEP]']
[ 750/2000] tot_loss=2.839 (perp=8.463, rec=0.354, cos=0.793), tot_loss_proj:3.467 [t=0.30s]
prediction: ['[CLS] ellen. ellen talked talked about commuter problem [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.783 (perp=8.463, rec=0.373, cos=0.718), tot_loss_proj:3.461 [t=0.30s]
prediction: ['[CLS] ellen. ellen talked talked about commuter problem [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.764 (perp=8.463, rec=0.325, cos=0.747), tot_loss_proj:3.460 [t=0.30s]
prediction: ['[CLS] ellen. ellen talked talked about commuter problem [SEP]']
[ 900/2000] tot_loss=2.898 (perp=9.157, rec=0.332, cos=0.735), tot_loss_proj:3.590 [t=0.30s]
prediction: ['[CLS] ellen. ellen talked talked about helen problem [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.853 (perp=8.934, rec=0.337, cos=0.730), tot_loss_proj:3.785 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1000/2000] tot_loss=2.831 (perp=8.934, rec=0.315, cos=0.729), tot_loss_proj:3.781 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
[1050/2000] tot_loss=2.838 (perp=8.934, rec=0.307, cos=0.743), tot_loss_proj:3.782 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1100/2000] tot_loss=2.845 (perp=8.934, rec=0.315, cos=0.743), tot_loss_proj:3.784 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1150/2000] tot_loss=2.845 (perp=8.934, rec=0.309, cos=0.749), tot_loss_proj:3.782 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
[1200/2000] tot_loss=2.848 (perp=8.934, rec=0.316, cos=0.746), tot_loss_proj:3.788 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1250/2000] tot_loss=2.871 (perp=8.934, rec=0.322, cos=0.762), tot_loss_proj:3.778 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1300/2000] tot_loss=2.838 (perp=8.934, rec=0.302, cos=0.749), tot_loss_proj:3.781 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
[1350/2000] tot_loss=2.834 (perp=8.934, rec=0.303, cos=0.744), tot_loss_proj:3.784 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1400/2000] tot_loss=2.849 (perp=8.934, rec=0.305, cos=0.757), tot_loss_proj:3.786 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1450/2000] tot_loss=2.836 (perp=8.934, rec=0.303, cos=0.747), tot_loss_proj:3.779 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
[1500/2000] tot_loss=2.853 (perp=8.934, rec=0.318, cos=0.748), tot_loss_proj:3.780 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1550/2000] tot_loss=2.834 (perp=8.934, rec=0.301, cos=0.745), tot_loss_proj:3.784 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1600/2000] tot_loss=2.840 (perp=8.934, rec=0.302, cos=0.751), tot_loss_proj:3.783 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
[1650/2000] tot_loss=2.845 (perp=8.934, rec=0.310, cos=0.748), tot_loss_proj:3.786 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1700/2000] tot_loss=2.843 (perp=8.934, rec=0.310, cos=0.747), tot_loss_proj:3.784 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1750/2000] tot_loss=2.834 (perp=8.934, rec=0.299, cos=0.748), tot_loss_proj:3.780 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
[1800/2000] tot_loss=2.830 (perp=8.934, rec=0.292, cos=0.752), tot_loss_proj:3.779 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1850/2000] tot_loss=2.831 (perp=8.934, rec=0.296, cos=0.748), tot_loss_proj:3.785 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[1900/2000] tot_loss=2.840 (perp=8.934, rec=0.304, cos=0.749), tot_loss_proj:3.788 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
[1950/2000] tot_loss=2.841 (perp=8.934, rec=0.302, cos=0.752), tot_loss_proj:3.782 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Attempt swap
[2000/2000] tot_loss=2.852 (perp=8.934, rec=0.313, cos=0.753), tot_loss_proj:3.783 [t=0.30s]
prediction: ['[CLS] ellen talked. ellen talked about helen problem [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] ellen talked with helen about the problem. [SEP]
========================
predicted: 
========================
[CLS] ellen talked. ellen talked about helen problem [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 115.278

[Aggregate metrics]:
rouge1     | fm: 75.810 | p: 76.029 | r: 75.785
rouge2     | fm: 34.213 | p: 34.147 | r: 34.365
rougeL     | fm: 66.986 | p: 67.250 | r: 66.966
rougeLsum  | fm: 67.140 | p: 67.419 | r: 67.088
r1fm+r2fm = 110.023

input #64 time: 0:11:48 | total time: 12:54:46


Running input #65 of 100.
reference: 
========================
Mag Wildwood came to introduce the bartender but I came precisely not to.
========================
average of cosine similarity 0.9989983096163382
highest_index [0]
highest [0.9989983096163382]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101, 23848,  3748,  3702,  2234,  2000,  8970,  1996, 15812,  2021,
          1045,  2234, 10785,  2025,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]']
[Init] best rec loss: 0.912773847579956 for ['[CLS] old shaw mcgill standminated chapter publication legal non penny cheekatics contemporary story fleet [SEP]']
[Init] best rec loss: 0.8933664560317993 for ['[CLS] mail shooting legends capture gen attention cpud graders democratic but lips suspicious suppressed out [SEP]']
[Init] best rec loss: 0.8894433975219727 for ['[CLS] over pulse mirror steering travel meter : travelbed nosed opportunity obligations depends splitting notes [SEP]']
[Init] best rec loss: 0.8805842399597168 for ['[CLS]pire prix object ballot maj students lee mathematical ranking cherry afc language note war draft [SEP]']
[Init] best rec loss: 0.865394651889801 for ['[CLS] shipsplate anyone rack selected up song landings steve voivodeship sioux peerage death leto fool [SEP]']
[Init] best rec loss: 0.8576422929763794 for ['[CLS] question ibn calledevich gulfcting due instead mist end banks half mef butch [SEP]']
[Init] best rec loss: 0.8417452573776245 for ['[CLS] perched mortal too body room insufficient systems chip wrongann battle kentree map catalog [SEP]']
[Init] best perm rec loss: 0.8393197655677795 for ['[CLS] insufficient mortal map chip perched body systems roomann kent battle too catalogree wrong [SEP]']
[Init] best perm rec loss: 0.8390920758247375 for ['[CLS] chipree battle catalog mortal insufficient wrong kent systems tooann body map room perched [SEP]']
[Init] best perm rec loss: 0.8383604288101196 for ['[CLS] systems insufficient chip too wrong body roomann kent mortalree perched map battle catalog [SEP]']
[Init] best perm rec loss: 0.8365970253944397 for ['[CLS]ree chip body too wrong mortal roomann map insufficient perched kent systems battle catalog [SEP]']
[Init] best perm rec loss: 0.8364822268486023 for ['[CLS] too map chipree mortal kent room wrong perched systemsann insufficient battle catalog body [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.768 (perp=11.842, rec=0.659, cos=0.741), tot_loss_proj:4.257 [t=0.30s]
prediction: ['[CLS] counterpartsized bishop / happensis nor truth death musical fiction returned - play m [SEP]']
[ 100/2000] tot_loss=3.637 (perp=12.379, rec=0.525, cos=0.637), tot_loss_proj:4.352 [t=0.30s]
prediction: ['[CLS] counterpartized bartender ( shakespearesis drinking didー brothers lieutenant drinks immediately. m [SEP]']
[ 150/2000] tot_loss=3.533 (perp=11.899, rec=0.537, cos=0.616), tot_loss_proj:4.236 [t=0.30s]
prediction: ['[CLS] counterpart peninsula bartender ( happen plus rico split pursuit ： lieutenant mc immediately. m [SEP]']
[ 200/2000] tot_loss=3.686 (perp=12.786, rec=0.492, cos=0.636), tot_loss_proj:4.408 [t=0.30s]
prediction: ['[CLS] predecessor opened bartender forilygible terry came came nadu lieutenant championship already. mm [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.445 (perp=11.675, rec=0.420, cos=0.690), tot_loss_proj:4.187 [t=0.30s]
prediction: ["[CLS] predecessor opened bartender comesgible to banged came came'lieutenant sword exactly. mm [SEP]"]
[ 300/2000] tot_loss=3.788 (perp=13.426, rec=0.394, cos=0.709), tot_loss_proj:4.458 [t=0.30s]
prediction: ['[CLS] predecessor opened bartender comes tri during bartender came came aloud lieutenant tablet exactly.sche [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.891 (perp=13.999, rec=0.386, cos=0.705), tot_loss_proj:4.626 [t=0.30s]
prediction: ['[CLS] predecessor embassy bartender comes. tri bartender came came nadu bartender tablet exactlyм janet [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.844 (perp=13.441, rec=0.441, cos=0.715), tot_loss_proj:4.512 [t=0.30s]
prediction: ['[CLS] accidentally subtle bartender merely to♥ came came charlton watkinscision slap exactly orthodox janet [SEP]']
[ 450/2000] tot_loss=3.701 (perp=13.054, rec=0.382, cos=0.708), tot_loss_proj:4.493 [t=0.30s]
prediction: ["[CLS] tributaries subtle bartender merely to♥ freshwater came our'verb slap exactly judaism janet [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=3.660 (perp=12.861, rec=0.364, cos=0.723), tot_loss_proj:4.386 [t=0.30s]
prediction: ["[CLS] tributaries subtle bartender came totypic banged came exactly our'apostolic anyway yeshiva janet [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.516 (perp=12.008, rec=0.370, cos=0.744), tot_loss_proj:4.270 [t=0.30s]
prediction: ["[CLS]wl subtle bartender came to♥ banged came precisely our'apostolic janet yeshiva anyway [SEP]"]
[ 600/2000] tot_loss=3.532 (perp=12.199, rec=0.350, cos=0.743), tot_loss_proj:4.313 [t=0.30s]
prediction: ["[CLS] fishes subtle bartender came to carly banged came precisely our'icc janet yeshiva anyway [SEP]"]
Attempt swap
[ 650/2000] tot_loss=3.443 (perp=11.719, rec=0.343, cos=0.756), tot_loss_proj:4.183 [t=0.30s]
prediction: ["[CLS] fishes subtle bartender came to carly banged came precisely our'came janet not anyway [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.423 (perp=11.671, rec=0.343, cos=0.745), tot_loss_proj:4.150 [t=0.30s]
prediction: ["[CLS] reveal clue bartender came to carlyloaded came precisely our janet came'not anyway [SEP]"]
[ 750/2000] tot_loss=3.576 (perp=12.413, rec=0.328, cos=0.765), tot_loss_proj:4.293 [t=0.30s]
prediction: ['[CLS] reveal clue bartender came to carly bartender came precisely skull janet came mattered not anyway [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.562 (perp=12.427, rec=0.319, cos=0.758), tot_loss_proj:4.299 [t=0.30s]
prediction: ['[CLS] reveal clue bartender came to carly bartender came precisely janet skull came revised not his [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=3.511 (perp=12.098, rec=0.327, cos=0.764), tot_loss_proj:4.223 [t=0.30s]
prediction: ['[CLS] reveal clue bartender came to bartender carly came precisely janet skull came revised not his [SEP]']
[ 900/2000] tot_loss=3.660 (perp=12.917, rec=0.310, cos=0.767), tot_loss_proj:4.424 [t=0.30s]
prediction: ['[CLS] reveal clue bartender introduce, bartender carly came precisely presidential skull came revised not his [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.449 (perp=11.796, rec=0.326, cos=0.764), tot_loss_proj:4.187 [t=0.30s]
prediction: ['[CLS] reveal clue bartender to introduce bartender carly came precisely presidential skull camedust not his [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.522 (perp=12.251, rec=0.304, cos=0.768), tot_loss_proj:4.248 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce bartender carly came precisely came presidential skull revised not came [SEP]']
[1050/2000] tot_loss=3.546 (perp=12.351, rec=0.311, cos=0.765), tot_loss_proj:4.258 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce bartender carly came precisely came presidential skullhall not came [SEP]']
Attempt swap
[1100/2000] tot_loss=3.545 (perp=12.351, rec=0.300, cos=0.774), tot_loss_proj:4.260 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce bartender carly came precisely came presidential skullhall not came [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=3.494 (perp=12.097, rec=0.295, cos=0.779), tot_loss_proj:4.243 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce bartender carly came precisely came skull mackenziehall not came [SEP]']
[1200/2000] tot_loss=3.500 (perp=12.080, rec=0.301, cos=0.782), tot_loss_proj:4.214 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce bartender pinned came precisely came skull mackenziehall not came [SEP]']
Attempt swap
[1250/2000] tot_loss=3.497 (perp=12.080, rec=0.303, cos=0.778), tot_loss_proj:4.219 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce bartender pinned came precisely came skull mackenziehall not came [SEP]']
Attempt swap
[1300/2000] tot_loss=3.498 (perp=12.080, rec=0.295, cos=0.786), tot_loss_proj:4.221 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce bartender pinned came precisely came skull mackenziehall not came [SEP]']
[1350/2000] tot_loss=3.531 (perp=12.265, rec=0.296, cos=0.782), tot_loss_proj:4.253 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce bartender pinned came precisely came skull mackenziehall not not [SEP]']
Attempt swap
[1400/2000] tot_loss=3.528 (perp=12.265, rec=0.289, cos=0.786), tot_loss_proj:4.257 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce bartender pinned came precisely came skull mackenziehall not not [SEP]']
Attempt swap
[1450/2000] tot_loss=3.579 (perp=12.532, rec=0.288, cos=0.785), tot_loss_proj:4.315 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
[1500/2000] tot_loss=3.589 (perp=12.532, rec=0.299, cos=0.784), tot_loss_proj:4.315 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
Attempt swap
[1550/2000] tot_loss=3.584 (perp=12.532, rec=0.291, cos=0.786), tot_loss_proj:4.313 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
Attempt swap
[1600/2000] tot_loss=3.583 (perp=12.532, rec=0.289, cos=0.788), tot_loss_proj:4.313 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
[1650/2000] tot_loss=3.585 (perp=12.532, rec=0.291, cos=0.787), tot_loss_proj:4.315 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
Attempt swap
[1700/2000] tot_loss=3.582 (perp=12.532, rec=0.288, cos=0.788), tot_loss_proj:4.312 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
Attempt swap
[1750/2000] tot_loss=3.585 (perp=12.532, rec=0.290, cos=0.788), tot_loss_proj:4.315 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
[1800/2000] tot_loss=3.590 (perp=12.532, rec=0.296, cos=0.788), tot_loss_proj:4.314 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
Attempt swap
[1850/2000] tot_loss=3.585 (perp=12.532, rec=0.291, cos=0.787), tot_loss_proj:4.314 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
Attempt swap
[1900/2000] tot_loss=3.589 (perp=12.532, rec=0.295, cos=0.788), tot_loss_proj:4.314 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
[1950/2000] tot_loss=3.569 (perp=12.532, rec=0.277, cos=0.786), tot_loss_proj:4.316 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
Attempt swap
[2000/2000] tot_loss=3.574 (perp=12.532, rec=0.282, cos=0.787), tot_loss_proj:4.315 [t=0.30s]
prediction: ['[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]
========================
predicted: 
========================
[CLS] reveal clue bartender. introduce mag pinned came precisely came skull mackenziehall not not [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 7.143 | p: 7.143 | r: 7.143
rougeL     | fm: 40.000 | p: 40.000 | r: 40.000
rougeLsum  | fm: 40.000 | p: 40.000 | r: 40.000
r1fm+r2fm = 67.143

[Aggregate metrics]:
rouge1     | fm: 75.508 | p: 75.790 | r: 75.487
rouge2     | fm: 33.865 | p: 33.819 | r: 34.030
rougeL     | fm: 66.534 | p: 66.737 | r: 66.483
rougeLsum  | fm: 66.696 | p: 66.960 | r: 66.694
r1fm+r2fm = 109.374

input #65 time: 0:12:02 | total time: 13:06:49


Running input #66 of 100.
reference: 
========================
There tried to be riots in Seoul.
========================
average of cosine similarity 0.9989168365950615
highest_index [0]
highest [0.9989168365950615]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2045,  2699,  2000,  2022, 12925,  1999, 10884,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] there tried to be riots in seoul. [SEP]']
[Init] best rec loss: 0.7449291944503784 for ['[CLS] mcdonnell mount activities death today game medal ng [SEP]']
[Init] best rec loss: 0.7009104490280151 for ['[CLS] vamp kada devil kent lizard home angels [SEP]']
[Init] best rec loss: 0.6790016293525696 for ['[CLS] dagger pier segments hopuating mo hand hour [SEP]']
[Init] best rec loss: 0.6773098707199097 for ['[CLS] kirk line may anniversary bee combined ladder doubtful [SEP]']
[Init] best rec loss: 0.6729976534843445 for ['[CLS] mainger soil music means numbers this left [SEP]']
[Init] best rec loss: 0.6687072515487671 for ['[CLS]play milestonerne jody clear fuel ship ari [SEP]']
[Init] best rec loss: 0.6664904356002808 for ['[CLS]ywood note stolerath falls shoot diamond pure [SEP]']
[Init] best rec loss: 0.6642847061157227 for ['[CLS] highness playing ortiz °c rough texas iso execution [SEP]']
[Init] best rec loss: 0.6265634894371033 for ['[CLS] book web fablecing and this during benefit [SEP]']
[Init] best perm rec loss: 0.6249224543571472 for ['[CLS] and this web fable benefit duringcing book [SEP]']
[Init] best perm rec loss: 0.6211455464363098 for ['[CLS] web during and benefitcing fable this book [SEP]']
[Init] best perm rec loss: 0.6203822493553162 for ['[CLS] benefitcing book during this fable and web [SEP]']
[Init] best perm rec loss: 0.6190361380577087 for ['[CLS] web duringcing this fable book and benefit [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.604 (perp=11.599, rec=0.260, cos=0.024), tot_loss_proj:3.184 [t=0.34s]
prediction: ['[CLS] \\ tried be there tried be riots riots [SEP]']
[ 100/2000] tot_loss=2.097 (perp=9.863, rec=0.114, cos=0.010), tot_loss_proj:2.567 [t=0.34s]
prediction: ['[CLS] there tried to there tried be riots riots [SEP]']
[ 150/2000] tot_loss=2.273 (perp=10.885, rec=0.089, cos=0.007), tot_loss_proj:2.825 [t=0.35s]
prediction: ['[CLS] seoul tried to there tried be riots seoul [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.885, rec=0.081, cos=0.005), tot_loss_proj:2.825 [t=0.34s]
prediction: ['[CLS] seoul tried to there tried be riots seoul [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.745 (perp=8.270, rec=0.085, cos=0.006), tot_loss_proj:2.219 [t=0.35s]
prediction: ['[CLS] seoul tried to be there tried riots in [SEP]']
[ 300/2000] tot_loss=1.733 (perp=8.270, rec=0.074, cos=0.005), tot_loss_proj:2.217 [t=0.34s]
prediction: ['[CLS] seoul tried to be there tried riots in [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.645 (perp=7.827, rec=0.074, cos=0.005), tot_loss_proj:2.333 [t=0.35s]
prediction: ['[CLS] seoul trying to be there in tried riots [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.638 (perp=7.827, rec=0.068, cos=0.005), tot_loss_proj:2.337 [t=0.35s]
prediction: ['[CLS] seoul trying to be there in tried riots [SEP]']
[ 450/2000] tot_loss=1.644 (perp=7.827, rec=0.074, cos=0.005), tot_loss_proj:2.341 [t=0.35s]
prediction: ['[CLS] seoul trying to be there in tried riots [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.644 (perp=7.827, rec=0.074, cos=0.005), tot_loss_proj:2.342 [t=0.35s]
prediction: ['[CLS] seoul trying to be there in tried riots [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.637 (perp=7.827, rec=0.067, cos=0.005), tot_loss_proj:2.349 [t=0.35s]
prediction: ['[CLS] seoul trying to be there in tried riots [SEP]']
[ 600/2000] tot_loss=1.565 (perp=7.447, rec=0.071, cos=0.005), tot_loss_proj:2.324 [t=0.35s]
prediction: ['[CLS] seoul tried to be there in tried riots [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.551 (perp=7.447, rec=0.057, cos=0.005), tot_loss_proj:2.317 [t=0.35s]
prediction: ['[CLS] seoul tried to be there in tried riots [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.560 (perp=7.447, rec=0.066, cos=0.005), tot_loss_proj:2.316 [t=0.34s]
prediction: ['[CLS] seoul tried to be there in tried riots [SEP]']
[ 750/2000] tot_loss=1.573 (perp=7.447, rec=0.079, cos=0.005), tot_loss_proj:2.321 [t=0.35s]
prediction: ['[CLS] seoul tried to be there in tried riots [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.565 (perp=7.447, rec=0.071, cos=0.005), tot_loss_proj:2.315 [t=0.35s]
prediction: ['[CLS] seoul tried to be there in tried riots [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.562 (perp=7.447, rec=0.068, cos=0.005), tot_loss_proj:2.323 [t=0.34s]
prediction: ['[CLS] seoul tried to be there in tried riots [SEP]']
[ 900/2000] tot_loss=1.549 (perp=7.417, rec=0.061, cos=0.005), tot_loss_proj:2.899 [t=0.35s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.562 (perp=7.417, rec=0.074, cos=0.004), tot_loss_proj:2.900 [t=0.35s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.568 (perp=7.447, rec=0.074, cos=0.005), tot_loss_proj:2.190 [t=0.34s]
prediction: ['[CLS]. seoul to be there in tried riots [SEP]']
[1050/2000] tot_loss=1.570 (perp=7.447, rec=0.076, cos=0.005), tot_loss_proj:2.191 [t=0.35s]
prediction: ['[CLS]. seoul to be there in tried riots [SEP]']
Attempt swap
[1100/2000] tot_loss=1.564 (perp=7.447, rec=0.070, cos=0.004), tot_loss_proj:2.186 [t=0.35s]
prediction: ['[CLS]. seoul to be there in tried riots [SEP]']
Attempt swap
[1150/2000] tot_loss=1.563 (perp=7.447, rec=0.069, cos=0.004), tot_loss_proj:2.189 [t=0.34s]
prediction: ['[CLS]. seoul to be there in tried riots [SEP]']
[1200/2000] tot_loss=1.568 (perp=7.447, rec=0.075, cos=0.004), tot_loss_proj:2.185 [t=0.35s]
prediction: ['[CLS]. seoul to be there in tried riots [SEP]']
Attempt swap
[1250/2000] tot_loss=1.560 (perp=7.447, rec=0.066, cos=0.004), tot_loss_proj:2.193 [t=0.35s]
prediction: ['[CLS]. seoul to be there in tried riots [SEP]']
Attempt swap
[1300/2000] tot_loss=1.569 (perp=7.447, rec=0.076, cos=0.004), tot_loss_proj:2.196 [t=0.34s]
prediction: ['[CLS]. seoul to be there in tried riots [SEP]']
[1350/2000] tot_loss=1.560 (perp=7.447, rec=0.066, cos=0.004), tot_loss_proj:2.191 [t=0.34s]
prediction: ['[CLS]. seoul to be there in tried riots [SEP]']
Attempt swap
[1400/2000] tot_loss=1.568 (perp=7.447, rec=0.074, cos=0.004), tot_loss_proj:2.190 [t=0.35s]
prediction: ['[CLS]. seoul to be there in tried riots [SEP]']
Attempt swap
[1450/2000] tot_loss=1.563 (perp=7.447, rec=0.069, cos=0.004), tot_loss_proj:2.191 [t=0.35s]
prediction: ['[CLS]. seoul to be there in tried riots [SEP]']
[1500/2000] tot_loss=1.562 (perp=7.447, rec=0.068, cos=0.004), tot_loss_proj:2.186 [t=0.35s]
prediction: ['[CLS]. seoul to be there in tried riots [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.556 (perp=7.417, rec=0.068, cos=0.005), tot_loss_proj:2.890 [t=0.35s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
Attempt swap
[1600/2000] tot_loss=1.555 (perp=7.417, rec=0.067, cos=0.005), tot_loss_proj:2.889 [t=0.35s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
[1650/2000] tot_loss=1.559 (perp=7.417, rec=0.071, cos=0.005), tot_loss_proj:2.888 [t=0.35s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
Attempt swap
[1700/2000] tot_loss=1.560 (perp=7.417, rec=0.072, cos=0.005), tot_loss_proj:2.886 [t=0.35s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
Attempt swap
[1750/2000] tot_loss=1.560 (perp=7.417, rec=0.072, cos=0.005), tot_loss_proj:2.891 [t=0.35s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
[1800/2000] tot_loss=1.550 (perp=7.417, rec=0.062, cos=0.005), tot_loss_proj:2.893 [t=0.35s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
Attempt swap
[1850/2000] tot_loss=1.556 (perp=7.417, rec=0.068, cos=0.005), tot_loss_proj:2.891 [t=0.35s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
Attempt swap
[1900/2000] tot_loss=1.558 (perp=7.417, rec=0.070, cos=0.005), tot_loss_proj:2.886 [t=0.35s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
[1950/2000] tot_loss=1.565 (perp=7.417, rec=0.077, cos=0.005), tot_loss_proj:2.890 [t=0.34s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
Attempt swap
[2000/2000] tot_loss=1.557 (perp=7.417, rec=0.069, cos=0.005), tot_loss_proj:2.888 [t=0.35s]
prediction: ['[CLS] seoul. to be there in tried riots [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] there tried to be riots in seoul. [SEP]
========================
predicted: 
========================
[CLS] seoul. to be there in tried riots [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 112.500

[Aggregate metrics]:
rouge1     | fm: 75.987 | p: 76.185 | r: 75.959
rouge2     | fm: 33.526 | p: 33.467 | r: 33.742
rougeL     | fm: 66.346 | p: 66.560 | r: 66.308
rougeLsum  | fm: 66.607 | p: 66.879 | r: 66.565
r1fm+r2fm = 109.513

input #66 time: 0:13:50 | total time: 13:20:40


Running input #67 of 100.
reference: 
========================
Fido is the smarter dog than Spot.
========================
average of cosine similarity 0.9988177967780119
highest_index [0]
highest [0.9988177967780119]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 10882,  3527,  2003,  1996, 25670,  3899,  2084,  3962,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] fido is the smarter dog than spot. [SEP]']
[Init] best rec loss: 0.9143285155296326 for ['[CLS] spec legend currently boarding reasons chapel assistance accomplish through [SEP]']
[Init] best rec loss: 0.8592368960380554 for ['[CLS] silkrting relating break cigarette bail finger charts do [SEP]']
[Init] best rec loss: 0.8584456443786621 for ['[CLS] word cab healthychenifying ruled mills flat prison [SEP]']
[Init] best rec loss: 0.8263046741485596 for ['[CLS] canberra mountain terms first transit ladder rats running naval [SEP]']
[Init] best rec loss: 0.8254255652427673 for ['[CLS] date disease expert monkey ich determination only oncelow [SEP]']
[Init] best rec loss: 0.8191825747489929 for ['[CLS] for certain orbit trash ren effectively unspokenich recorder [SEP]']
[Init] best rec loss: 0.817229688167572 for ['[CLS] echoing axis mast worth grid lips grand walkerdon [SEP]']
[Init] best rec loss: 0.8124839663505554 for ['[CLS]logyference purple bind knowing records fist sessionsrst [SEP]']
[Init] best rec loss: 0.8039124011993408 for ['[CLS] hosted heaven live inflicted eight jewel who subjects given [SEP]']
[Init] best rec loss: 0.7905125021934509 for ['[CLS] charge tenderclass part is doin by mary trucks [SEP]']
[Init] best perm rec loss: 0.7899508476257324 for ['[CLS] charge mary tender is doin by trucksclass part [SEP]']
[Init] best perm rec loss: 0.7894908785820007 for ['[CLS] maryclass charge trucks tender doin part by is [SEP]']
[Init] best perm rec loss: 0.7894890904426575 for ['[CLS] tender chargeclass trucks by part mary doin is [SEP]']
[Init] best perm rec loss: 0.7854212522506714 for ['[CLS]class trucks by doin charge is part mary tender [SEP]']
[Init] best perm rec loss: 0.785297155380249 for ['[CLS] mary doinclass charge tender by trucks is part [SEP]']
[Init] best perm rec loss: 0.7844112515449524 for ['[CLS] by partclass trucks mary is doin charge tender [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.304 (perp=14.396, rec=0.624, cos=0.801), tot_loss_proj:4.330 [t=0.34s]
prediction: ['[CLS]region pokemondog cruiser referenceie col constellation, [SEP]']
[ 100/2000] tot_loss=3.703 (perp=12.587, rec=0.535, cos=0.651), tot_loss_proj:4.099 [t=0.34s]
prediction: ['[CLS] spot dog mommy companion reaction is than meters spot [SEP]']
[ 150/2000] tot_loss=3.532 (perp=11.645, rec=0.479, cos=0.724), tot_loss_proj:3.920 [t=0.34s]
prediction: ['[CLS] spot dog smarter companion dog is than ain spot [SEP]']
[ 200/2000] tot_loss=3.442 (perp=10.822, rec=0.403, cos=0.875), tot_loss_proj:3.769 [t=0.34s]
prediction: ['[CLS] seems dog smarter think dog is than texas spot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.106 (perp=9.531, rec=0.375, cos=0.825), tot_loss_proj:3.488 [t=0.34s]
prediction: ['[CLS] seems dog think dog is smarter than spot spot [SEP]']
[ 300/2000] tot_loss=3.338 (perp=10.698, rec=0.297, cos=0.901), tot_loss_proj:3.550 [t=0.34s]
prediction: ['[CLS] seems dog dog dogs is smarter than spot spot [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.300 (perp=10.482, rec=0.305, cos=0.898), tot_loss_proj:3.356 [t=0.35s]
prediction: ['[CLS]ա dog widened dogs is smarter than dog spot [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.139 (perp=9.812, rec=0.292, cos=0.886), tot_loss_proj:3.270 [t=0.34s]
prediction: ['[CLS] ⇄ eldest is dog dog smarter than dog spot [SEP]']
[ 450/2000] tot_loss=3.086 (perp=9.526, rec=0.282, cos=0.898), tot_loss_proj:3.514 [t=0.35s]
prediction: ['[CLS] is spots is dog. smarter than dog spot [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.057 (perp=9.340, rec=0.300, cos=0.889), tot_loss_proj:3.175 [t=0.34s]
prediction: ['[CLS]ա spot is dog. smarter than dog alberta [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.074 (perp=9.504, rec=0.280, cos=0.894), tot_loss_proj:3.421 [t=0.34s]
prediction: ['[CLS] genus spot is dog spots smarter than dog. [SEP]']
[ 600/2000] tot_loss=3.069 (perp=9.504, rec=0.266, cos=0.902), tot_loss_proj:3.414 [t=0.34s]
prediction: ['[CLS] genus spot is dog spots smarter than dog. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.772 (perp=8.096, rec=0.267, cos=0.885), tot_loss_proj:3.098 [t=0.34s]
prediction: ['[CLS]ա spot spots is dog smarter than dog. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.833 (perp=8.242, rec=0.267, cos=0.917), tot_loss_proj:3.112 [t=0.30s]
prediction: ['[CLS] smashwords spots spot is dog smarter than dog. [SEP]']
[ 750/2000] tot_loss=2.877 (perp=8.552, rec=0.247, cos=0.919), tot_loss_proj:3.227 [t=0.30s]
prediction: ['[CLS] gestures spots spot is dog smarter than dog. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.805 (perp=8.199, rec=0.252, cos=0.913), tot_loss_proj:3.293 [t=0.30s]
prediction: ['[CLS] gestures spot spots is dog smarter than dog. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.799 (perp=8.199, rec=0.242, cos=0.917), tot_loss_proj:3.288 [t=0.30s]
prediction: ['[CLS] gestures spot spots is dog smarter than dog. [SEP]']
[ 900/2000] tot_loss=2.824 (perp=8.305, rec=0.256, cos=0.907), tot_loss_proj:3.325 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.816 (perp=8.305, rec=0.237, cos=0.918), tot_loss_proj:3.327 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.828 (perp=8.305, rec=0.248, cos=0.919), tot_loss_proj:3.330 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
[1050/2000] tot_loss=2.817 (perp=8.305, rec=0.243, cos=0.913), tot_loss_proj:3.328 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.838 (perp=8.305, rec=0.248, cos=0.929), tot_loss_proj:3.327 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.844 (perp=8.305, rec=0.253, cos=0.931), tot_loss_proj:3.327 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
[1200/2000] tot_loss=2.827 (perp=8.305, rec=0.237, cos=0.929), tot_loss_proj:3.327 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.838 (perp=8.305, rec=0.242, cos=0.935), tot_loss_proj:3.324 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.836 (perp=8.305, rec=0.240, cos=0.935), tot_loss_proj:3.325 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
[1350/2000] tot_loss=2.828 (perp=8.305, rec=0.236, cos=0.931), tot_loss_proj:3.324 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.839 (perp=8.305, rec=0.239, cos=0.940), tot_loss_proj:3.326 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.839 (perp=8.305, rec=0.240, cos=0.938), tot_loss_proj:3.324 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
[1500/2000] tot_loss=2.848 (perp=8.305, rec=0.247, cos=0.941), tot_loss_proj:3.326 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.842 (perp=8.305, rec=0.238, cos=0.943), tot_loss_proj:3.321 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.839 (perp=8.305, rec=0.235, cos=0.943), tot_loss_proj:3.332 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
[1650/2000] tot_loss=2.840 (perp=8.305, rec=0.236, cos=0.944), tot_loss_proj:3.328 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.837 (perp=8.305, rec=0.232, cos=0.945), tot_loss_proj:3.326 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.846 (perp=8.305, rec=0.242, cos=0.943), tot_loss_proj:3.323 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
[1800/2000] tot_loss=2.848 (perp=8.305, rec=0.242, cos=0.945), tot_loss_proj:3.323 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.844 (perp=8.305, rec=0.236, cos=0.947), tot_loss_proj:3.326 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.843 (perp=8.305, rec=0.234, cos=0.948), tot_loss_proj:3.328 [t=0.30s]
prediction: ['[CLS]written spot spots is dog smarter than dog. [SEP]']
[1950/2000] tot_loss=2.835 (perp=8.252, rec=0.237, cos=0.948), tot_loss_proj:3.285 [t=0.30s]
prediction: ['[CLS]written spot kid is dog smarter than dog. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.834 (perp=8.252, rec=0.234, cos=0.949), tot_loss_proj:3.287 [t=0.30s]
prediction: ['[CLS]written spot kid is dog smarter than dog. [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] fido is the smarter dog than spot. [SEP]
========================
predicted: 
========================
[CLS]written spot kid is dog smarter than dog. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 70.000 | r: 77.778
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 52.632 | p: 50.000 | r: 55.556
rougeLsum  | fm: 52.632 | p: 50.000 | r: 55.556
r1fm+r2fm = 73.684

[Aggregate metrics]:
rouge1     | fm: 75.791 | p: 75.958 | r: 75.892
rouge2     | fm: 33.082 | p: 33.018 | r: 33.165
rougeL     | fm: 66.129 | p: 66.243 | r: 66.159
rougeLsum  | fm: 66.361 | p: 66.627 | r: 66.319
r1fm+r2fm = 108.873

input #67 time: 0:12:30 | total time: 13:33:11


Running input #68 of 100.
reference: 
========================
John convinced the rice to be cooked by Bill.
========================
average of cosine similarity 0.9989249190597302
highest_index [0]
highest [0.9989249190597302]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198,  6427,  1996,  5785,  2000,  2022, 12984,  2011,  3021,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john convinced the rice to be cooked by bill. [SEP]']
[Init] best rec loss: 0.7558858394622803 for ['[CLS] rich plant ticket has an boat favorite malaysia showing procedures [SEP]']
[Init] best rec loss: 0.7498197555541992 for ['[CLS] uncommon counsel national short cell mrs timing upside leyte justified [SEP]']
[Init] best rec loss: 0.7445439100265503 for ['[CLS] while marginal competition control new beau ll associatedlb marker [SEP]']
[Init] best rec loss: 0.7415027618408203 for ['[CLS] frozen now danhel ellie given without translatedhen reflecting [SEP]']
[Init] best rec loss: 0.7350226640701294 for ['[CLS] maintenance fr respectively sports alive turnoured acquisition barrow body [SEP]']
[Init] best rec loss: 0.7288304567337036 for ['[CLS] collegevable results tell round departmentllaryian sea bass [SEP]']
[Init] best rec loss: 0.7251660227775574 for ['[CLS] search brand meanwhile vice livery come + until eyebrows bark [SEP]']
[Init] best rec loss: 0.721933126449585 for ['[CLS] consists chop ( pair whenixsa esq quarter stretch [SEP]']
[Init] best perm rec loss: 0.7169206142425537 for ['[CLS] consists stretch when pairix quarter ( esqsa chop [SEP]']
[Init] best perm rec loss: 0.7168965935707092 for ['[CLS] esq when consists (sa quarter stretchix chop pair [SEP]']
[Init] best perm rec loss: 0.7165912389755249 for ['[CLS]ix esq when consists ( chop stretchsa quarter pair [SEP]']
[Init] best perm rec loss: 0.7155565619468689 for ['[CLS] stretch pairsa esq consists quarterix ( when chop [SEP]']
[Init] best perm rec loss: 0.715262234210968 for ['[CLS]ix pairsa consists ( chop stretch quarter when esq [SEP]']
[Init] best perm rec loss: 0.7150196433067322 for ['[CLS] stretch when chop (sa esq quarter consistsix pair [SEP]']
[Init] best perm rec loss: 0.7144195437431335 for ['[CLS] pairix consists ( stretchsa when esq quarter chop [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.658 (perp=11.840, rec=0.231, cos=0.059), tot_loss_proj:3.505 [t=0.29s]
prediction: ['[CLS] john however to convinced hospitality perfect when rice the intact [SEP]']
[ 100/2000] tot_loss=1.918 (perp=8.742, rec=0.145, cos=0.026), tot_loss_proj:2.823 [t=0.30s]
prediction: ['[CLS] john the rice convinced to be cooked cooked the by [SEP]']
[ 150/2000] tot_loss=1.893 (perp=8.960, rec=0.090, cos=0.012), tot_loss_proj:2.897 [t=0.30s]
prediction: ['[CLS] john the rice convinced to be by cooked the by [SEP]']
[ 200/2000] tot_loss=1.896 (perp=8.960, rec=0.085, cos=0.019), tot_loss_proj:2.888 [t=0.30s]
prediction: ['[CLS] john the rice convinced to be by cooked the by [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.863 (perp=8.867, rec=0.074, cos=0.016), tot_loss_proj:2.861 [t=0.30s]
prediction: ['[CLS] john the rice convinced to be the cooked bill by [SEP]']
[ 300/2000] tot_loss=1.861 (perp=8.867, rec=0.081, cos=0.006), tot_loss_proj:2.859 [t=0.30s]
prediction: ['[CLS] john the rice convinced to be the cooked bill by [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.687 (perp=8.068, rec=0.066, cos=0.007), tot_loss_proj:2.154 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be the cooked bill by [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.605 (perp=7.624, rec=0.073, cos=0.007), tot_loss_proj:2.774 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked the bill by [SEP]']
[ 450/2000] tot_loss=1.612 (perp=7.624, rec=0.080, cos=0.006), tot_loss_proj:2.771 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked the bill by [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.520 (perp=7.216, rec=0.070, cos=0.006), tot_loss_proj:1.849 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.522 (perp=7.216, rec=0.072, cos=0.006), tot_loss_proj:1.843 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
[ 600/2000] tot_loss=1.519 (perp=7.216, rec=0.069, cos=0.006), tot_loss_proj:1.832 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.519 (perp=7.216, rec=0.070, cos=0.006), tot_loss_proj:1.844 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.523 (perp=7.216, rec=0.073, cos=0.006), tot_loss_proj:1.854 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
[ 750/2000] tot_loss=1.518 (perp=7.216, rec=0.069, cos=0.006), tot_loss_proj:1.838 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.522 (perp=7.216, rec=0.073, cos=0.006), tot_loss_proj:1.844 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.501 (perp=7.216, rec=0.053, cos=0.006), tot_loss_proj:1.823 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
[ 900/2000] tot_loss=1.507 (perp=7.216, rec=0.058, cos=0.006), tot_loss_proj:1.834 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.510 (perp=7.216, rec=0.061, cos=0.006), tot_loss_proj:1.830 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.529 (perp=7.216, rec=0.079, cos=0.006), tot_loss_proj:1.822 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
[1050/2000] tot_loss=1.521 (perp=7.216, rec=0.072, cos=0.006), tot_loss_proj:1.826 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1100/2000] tot_loss=1.509 (perp=7.216, rec=0.060, cos=0.006), tot_loss_proj:1.817 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1150/2000] tot_loss=1.508 (perp=7.216, rec=0.059, cos=0.006), tot_loss_proj:1.819 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
[1200/2000] tot_loss=1.519 (perp=7.216, rec=0.070, cos=0.006), tot_loss_proj:1.820 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1250/2000] tot_loss=1.514 (perp=7.216, rec=0.065, cos=0.006), tot_loss_proj:1.816 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1300/2000] tot_loss=1.514 (perp=7.216, rec=0.065, cos=0.006), tot_loss_proj:1.821 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
[1350/2000] tot_loss=1.519 (perp=7.216, rec=0.070, cos=0.005), tot_loss_proj:1.818 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1400/2000] tot_loss=1.508 (perp=7.216, rec=0.059, cos=0.005), tot_loss_proj:1.814 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1450/2000] tot_loss=1.514 (perp=7.216, rec=0.065, cos=0.006), tot_loss_proj:1.812 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
[1500/2000] tot_loss=1.520 (perp=7.216, rec=0.071, cos=0.005), tot_loss_proj:1.818 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1550/2000] tot_loss=1.510 (perp=7.216, rec=0.061, cos=0.005), tot_loss_proj:1.803 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1600/2000] tot_loss=1.518 (perp=7.216, rec=0.069, cos=0.005), tot_loss_proj:1.808 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
[1650/2000] tot_loss=1.520 (perp=7.216, rec=0.072, cos=0.006), tot_loss_proj:1.809 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1700/2000] tot_loss=1.503 (perp=7.216, rec=0.054, cos=0.005), tot_loss_proj:1.805 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1750/2000] tot_loss=1.523 (perp=7.216, rec=0.075, cos=0.005), tot_loss_proj:1.806 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
[1800/2000] tot_loss=1.513 (perp=7.216, rec=0.065, cos=0.005), tot_loss_proj:1.799 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1850/2000] tot_loss=1.517 (perp=7.216, rec=0.068, cos=0.005), tot_loss_proj:1.796 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[1900/2000] tot_loss=1.525 (perp=7.216, rec=0.076, cos=0.005), tot_loss_proj:1.797 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
[1950/2000] tot_loss=1.510 (perp=7.216, rec=0.061, cos=0.005), tot_loss_proj:1.807 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Attempt swap
[2000/2000] tot_loss=1.513 (perp=7.216, rec=0.064, cos=0.005), tot_loss_proj:1.808 [t=0.30s]
prediction: ['[CLS] john convinced the rice to be cooked by the bill [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] john convinced the rice to be cooked by bill. [SEP]
========================
predicted: 
========================
[CLS] john convinced the rice to be cooked by the bill [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 85.714 | p: 81.818 | r: 90.000
rougeL     | fm: 95.652 | p: 91.667 | r: 100.000
rougeLsum  | fm: 95.652 | p: 91.667 | r: 100.000
r1fm+r2fm = 181.366

[Aggregate metrics]:
rouge1     | fm: 76.192 | p: 76.286 | r: 76.307
rouge2     | fm: 33.741 | p: 33.615 | r: 34.000
rougeL     | fm: 66.577 | p: 66.748 | r: 66.635
rougeLsum  | fm: 66.774 | p: 66.912 | r: 66.782
r1fm+r2fm = 109.933

input #68 time: 0:11:49 | total time: 13:45:00


Running input #69 of 100.
reference: 
========================
The squirrel ran straight quickly.
========================
average of cosine similarity 0.9989556149014753
highest_index [0]
highest [0.9989556149014753]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 18197,  2743,  3442,  2855,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the squirrel ran straight quickly. [SEP]']
[Init] best rec loss: 0.7419742941856384 for ['[CLS] theme skin alive won reach one [SEP]']
[Init] best rec loss: 0.7415034174919128 for ['[CLS] foreigner renaissance foster ) weekend lost [SEP]']
[Init] best rec loss: 0.6891422867774963 for ['[CLS] action ou defenceiom unto violence [SEP]']
[Init] best rec loss: 0.6856687664985657 for ['[CLS] abdomen math who what oil bus [SEP]']
[Init] best rec loss: 0.6822975873947144 for ['[CLS] on years magazine belong eugen wah [SEP]']
[Init] best rec loss: 0.6567511558532715 for ['[CLS] brief forgetlyhawks husbandch [SEP]']
[Init] best perm rec loss: 0.6539679765701294 for ['[CLS] forgehawksch husband brieftly [SEP]']
[Init] best perm rec loss: 0.6534596681594849 for ['[CLS]tly forge husband briefhawksch [SEP]']
[Init] best perm rec loss: 0.6497915387153625 for ['[CLS] forgetly husband briefchhawks [SEP]']
[Init] best perm rec loss: 0.648509681224823 for ['[CLS]tlych briefhawks husband forge [SEP]']
[Init] best perm rec loss: 0.6484760046005249 for ['[CLS]tlyhawks forgech brief husband [SEP]']
[Init] best perm rec loss: 0.6452707052230835 for ['[CLS] brief husband forgehawkstlych [SEP]']
[Init] best perm rec loss: 0.6447396874427795 for ['[CLS] husband forgechtlyhawks brief [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.903 (perp=10.142, rec=0.479, cos=0.396), tot_loss_proj:2.733 [t=0.29s]
prediction: ['[CLS] walker ran straight straight quickly quickly [SEP]']
[ 100/2000] tot_loss=2.728 (perp=9.779, rec=0.327, cos=0.445), tot_loss_proj:3.028 [t=0.30s]
prediction: ['[CLS] walking rebounds straight quickly quickly quickly [SEP]']
[ 150/2000] tot_loss=2.721 (perp=9.761, rec=0.302, cos=0.467), tot_loss_proj:2.965 [t=0.30s]
prediction: ['[CLS] walked wheels straight quickly quickly quickly [SEP]']
[ 200/2000] tot_loss=2.792 (perp=10.349, rec=0.292, cos=0.430), tot_loss_proj:3.009 [t=0.30s]
prediction: ['[CLS] ranbians straight quickly quickly quickly [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.796 (perp=10.349, rec=0.267, cos=0.459), tot_loss_proj:3.006 [t=0.30s]
prediction: ['[CLS] ranbians straight quickly quickly quickly [SEP]']
[ 300/2000] tot_loss=2.722 (perp=10.349, rec=0.259, cos=0.393), tot_loss_proj:3.005 [t=0.30s]
prediction: ['[CLS] ranbians straight quickly quickly quickly [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.546 (perp=9.273, rec=0.247, cos=0.444), tot_loss_proj:2.906 [t=0.30s]
prediction: ['[CLS] ranbians straight quickly ran. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.444 (perp=8.710, rec=0.263, cos=0.439), tot_loss_proj:2.119 [t=0.30s]
prediction: ['[CLS] squirrelbians ran straight quickly. [SEP]']
[ 450/2000] tot_loss=2.324 (perp=8.483, rec=0.226, cos=0.401), tot_loss_proj:2.027 [t=0.30s]
prediction: ['[CLS] squirrelrook ran straight quickly. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.305 (perp=8.483, rec=0.213, cos=0.396), tot_loss_proj:2.029 [t=0.30s]
prediction: ['[CLS] squirrelrook ran straight quickly. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.439 (perp=8.983, rec=0.224, cos=0.418), tot_loss_proj:2.084 [t=0.30s]
prediction: ['[CLS] squirrelarus ran straight quickly. [SEP]']
[ 600/2000] tot_loss=2.446 (perp=8.983, rec=0.223, cos=0.426), tot_loss_proj:2.095 [t=0.30s]
prediction: ['[CLS] squirrelarus ran straight quickly. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.438 (perp=8.983, rec=0.207, cos=0.434), tot_loss_proj:2.093 [t=0.30s]
prediction: ['[CLS] squirrelarus ran straight quickly. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.428 (perp=8.983, rec=0.207, cos=0.424), tot_loss_proj:2.098 [t=0.30s]
prediction: ['[CLS] squirrelarus ran straight quickly. [SEP]']
[ 750/2000] tot_loss=2.433 (perp=8.983, rec=0.206, cos=0.430), tot_loss_proj:2.091 [t=0.30s]
prediction: ['[CLS] squirrelarus ran straight quickly. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.332 (perp=8.503, rec=0.200, cos=0.431), tot_loss_proj:2.423 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.339 (perp=8.503, rec=0.208, cos=0.430), tot_loss_proj:2.423 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
[ 900/2000] tot_loss=2.344 (perp=8.503, rec=0.206, cos=0.437), tot_loss_proj:2.409 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.335 (perp=8.503, rec=0.198, cos=0.436), tot_loss_proj:2.416 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.354 (perp=8.503, rec=0.202, cos=0.451), tot_loss_proj:2.409 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
[1050/2000] tot_loss=2.359 (perp=8.503, rec=0.202, cos=0.457), tot_loss_proj:2.409 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.359 (perp=8.503, rec=0.196, cos=0.462), tot_loss_proj:2.409 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.374 (perp=8.503, rec=0.204, cos=0.469), tot_loss_proj:2.396 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
[1200/2000] tot_loss=2.367 (perp=8.503, rec=0.198, cos=0.469), tot_loss_proj:2.401 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.376 (perp=8.503, rec=0.201, cos=0.475), tot_loss_proj:2.402 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.370 (perp=8.503, rec=0.196, cos=0.474), tot_loss_proj:2.402 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
[1350/2000] tot_loss=2.381 (perp=8.503, rec=0.201, cos=0.479), tot_loss_proj:2.401 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.377 (perp=8.503, rec=0.196, cos=0.481), tot_loss_proj:2.399 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.388 (perp=8.503, rec=0.203, cos=0.485), tot_loss_proj:2.396 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
[1500/2000] tot_loss=2.386 (perp=8.503, rec=0.200, cos=0.486), tot_loss_proj:2.403 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.390 (perp=8.503, rec=0.200, cos=0.489), tot_loss_proj:2.397 [t=0.30s]
prediction: ['[CLS] squirrel tubes ran straight quickly. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.343 (perp=8.275, rec=0.201, cos=0.487), tot_loss_proj:1.990 [t=0.30s]
prediction: ['[CLS] squirrel animals ran straight quickly. [SEP]']
[1650/2000] tot_loss=2.334 (perp=8.275, rec=0.191, cos=0.488), tot_loss_proj:1.995 [t=0.30s]
prediction: ['[CLS] squirrel animals ran straight quickly. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.343 (perp=8.275, rec=0.197, cos=0.491), tot_loss_proj:1.992 [t=0.30s]
prediction: ['[CLS] squirrel animals ran straight quickly. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.341 (perp=8.275, rec=0.193, cos=0.493), tot_loss_proj:1.993 [t=0.30s]
prediction: ['[CLS] squirrel animals ran straight quickly. [SEP]']
[1800/2000] tot_loss=2.341 (perp=8.275, rec=0.196, cos=0.490), tot_loss_proj:1.992 [t=0.30s]
prediction: ['[CLS] squirrel animals ran straight quickly. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.344 (perp=8.275, rec=0.196, cos=0.493), tot_loss_proj:1.994 [t=0.30s]
prediction: ['[CLS] squirrel animals ran straight quickly. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.345 (perp=8.275, rec=0.197, cos=0.493), tot_loss_proj:1.988 [t=0.30s]
prediction: ['[CLS] squirrel animals ran straight quickly. [SEP]']
[1950/2000] tot_loss=2.361 (perp=8.275, rec=0.213, cos=0.492), tot_loss_proj:1.991 [t=0.30s]
prediction: ['[CLS] squirrel animals ran straight quickly. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.347 (perp=8.275, rec=0.197, cos=0.496), tot_loss_proj:1.987 [t=0.30s]
prediction: ['[CLS] squirrel animals ran straight quickly. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] the squirrel ran straight quickly. [SEP]
========================
predicted: 
========================
[CLS] squirrel tubes ran straight quickly. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 135.714

[Aggregate metrics]:
rouge1     | fm: 76.320 | p: 76.429 | r: 76.467
rouge2     | fm: 34.032 | p: 34.008 | r: 34.258
rougeL     | fm: 66.836 | p: 66.943 | r: 66.961
rougeLsum  | fm: 67.057 | p: 67.240 | r: 67.209
r1fm+r2fm = 110.351

input #69 time: 0:11:47 | total time: 13:56:48


Running input #70 of 100.
reference: 
========================
I assumed to be innocent
========================
average of cosine similarity 0.9989049903068294
highest_index [0]
highest [0.9989049903068294]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 5071, 2000, 2022, 7036,  102]], device='cuda:0')
Debug: ref = ['[CLS] i assumed to be innocent [SEP]']
[Init] best rec loss: 0.7881872653961182 for ['[CLS] down op epithet medicine sick [SEP]']
[Init] best rec loss: 0.7777012586593628 for ['[CLS] small beings equation flightfall [SEP]']
[Init] best rec loss: 0.7450469136238098 for ['[CLS]berg managed mainland doctor topped [SEP]']
[Init] best rec loss: 0.7393224239349365 for ['[CLS] [ across not inside stuff [SEP]']
[Init] best rec loss: 0.7318477630615234 for ['[CLS] breeding overseas signature activated points [SEP]']
[Init] best perm rec loss: 0.7311965227127075 for ['[CLS] points breeding signature overseas activated [SEP]']
[Init] best perm rec loss: 0.7299019694328308 for ['[CLS] points overseas activated signature breeding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.588 (perp=11.027, rec=0.345, cos=0.038), tot_loss_proj:3.234 [t=0.38s]
prediction: ['[CLS] knowing convinced certainly being innocent [SEP]']
[ 100/2000] tot_loss=2.356 (perp=10.691, rec=0.204, cos=0.014), tot_loss_proj:3.083 [t=0.30s]
prediction: ['[CLS] assumed assumed assumed be innocent [SEP]']
[ 150/2000] tot_loss=1.631 (perp=7.441, rec=0.135, cos=0.008), tot_loss_proj:2.333 [t=0.30s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[ 200/2000] tot_loss=1.573 (perp=7.441, rec=0.082, cos=0.003), tot_loss_proj:2.324 [t=0.30s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.371 (perp=6.469, rec=0.075, cos=0.002), tot_loss_proj:1.512 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 300/2000] tot_loss=1.357 (perp=6.469, rec=0.061, cos=0.002), tot_loss_proj:1.512 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.355 (perp=6.469, rec=0.058, cos=0.002), tot_loss_proj:1.508 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.357 (perp=6.469, rec=0.061, cos=0.002), tot_loss_proj:1.486 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 450/2000] tot_loss=1.359 (perp=6.469, rec=0.063, cos=0.002), tot_loss_proj:1.496 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.356 (perp=6.469, rec=0.060, cos=0.002), tot_loss_proj:1.489 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.348 (perp=6.469, rec=0.052, cos=0.002), tot_loss_proj:1.485 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 600/2000] tot_loss=1.365 (perp=6.469, rec=0.069, cos=0.002), tot_loss_proj:1.478 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.351 (perp=6.469, rec=0.055, cos=0.002), tot_loss_proj:1.477 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.343 (perp=6.469, rec=0.047, cos=0.002), tot_loss_proj:1.471 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 750/2000] tot_loss=1.358 (perp=6.469, rec=0.062, cos=0.002), tot_loss_proj:1.481 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.351 (perp=6.469, rec=0.055, cos=0.002), tot_loss_proj:1.491 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.368 (perp=6.469, rec=0.072, cos=0.002), tot_loss_proj:1.471 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 900/2000] tot_loss=1.353 (perp=6.469, rec=0.057, cos=0.002), tot_loss_proj:1.472 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.363 (perp=6.469, rec=0.067, cos=0.002), tot_loss_proj:1.468 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.357 (perp=6.469, rec=0.061, cos=0.002), tot_loss_proj:1.472 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1050/2000] tot_loss=1.356 (perp=6.469, rec=0.060, cos=0.002), tot_loss_proj:1.477 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.360 (perp=6.469, rec=0.064, cos=0.002), tot_loss_proj:1.472 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.344 (perp=6.469, rec=0.048, cos=0.002), tot_loss_proj:1.465 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1200/2000] tot_loss=1.344 (perp=6.469, rec=0.048, cos=0.002), tot_loss_proj:1.471 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.356 (perp=6.469, rec=0.060, cos=0.002), tot_loss_proj:1.461 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.349 (perp=6.469, rec=0.053, cos=0.002), tot_loss_proj:1.470 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1350/2000] tot_loss=1.366 (perp=6.469, rec=0.070, cos=0.002), tot_loss_proj:1.471 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.362 (perp=6.469, rec=0.065, cos=0.002), tot_loss_proj:1.463 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.357 (perp=6.469, rec=0.061, cos=0.002), tot_loss_proj:1.474 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1500/2000] tot_loss=1.357 (perp=6.469, rec=0.061, cos=0.002), tot_loss_proj:1.474 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.365 (perp=6.469, rec=0.069, cos=0.002), tot_loss_proj:1.464 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.357 (perp=6.469, rec=0.060, cos=0.002), tot_loss_proj:1.466 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1650/2000] tot_loss=1.363 (perp=6.469, rec=0.067, cos=0.002), tot_loss_proj:1.461 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.359 (perp=6.469, rec=0.063, cos=0.002), tot_loss_proj:1.459 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.356 (perp=6.469, rec=0.060, cos=0.002), tot_loss_proj:1.449 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1800/2000] tot_loss=1.357 (perp=6.469, rec=0.061, cos=0.002), tot_loss_proj:1.453 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.360 (perp=6.469, rec=0.064, cos=0.002), tot_loss_proj:1.463 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.360 (perp=6.469, rec=0.064, cos=0.002), tot_loss_proj:1.452 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1950/2000] tot_loss=1.354 (perp=6.469, rec=0.058, cos=0.002), tot_loss_proj:1.457 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.355 (perp=6.469, rec=0.059, cos=0.002), tot_loss_proj:1.460 [t=0.30s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] i assumed to be innocent [SEP]
========================
predicted: 
========================
[CLS] i assumed to be innocent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 76.649 | p: 76.769 | r: 76.727
rouge2     | fm: 35.100 | p: 35.023 | r: 35.344
rougeL     | fm: 67.345 | p: 67.507 | r: 67.414
rougeLsum  | fm: 67.608 | p: 67.777 | r: 67.672
r1fm+r2fm = 111.749

input #70 time: 0:11:47 | total time: 14:08:36


Running input #71 of 100.
reference: 
========================
He could not have been working.
========================
average of cosine similarity 0.9990099004031936
highest_index [0]
highest [0.9990099004031936]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2071, 2025, 2031, 2042, 2551, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he could not have been working. [SEP]']
[Init] best rec loss: 1.0029573440551758 for ['[CLS] winston q officer obedience maize creamkha [SEP]']
[Init] best rec loss: 0.9952040910720825 for ['[CLS] deposit on twinned shadow layout and shining [SEP]']
[Init] best rec loss: 0.9594547748565674 for ['[CLS] [CLS] holt mls urgent we hey following [SEP]']
[Init] best rec loss: 0.9444833397865295 for ['[CLS] source outside fairias bullet tyson accepted [SEP]']
[Init] best rec loss: 0.9179242253303528 for ['[CLS] awards portrked namewr de immaculate [SEP]']
[Init] best rec loss: 0.8828629851341248 for ['[CLS] os invitation clary associated length walked inspiration [SEP]']
[Init] best rec loss: 0.8526178598403931 for ['[CLS] helpayaion gun quartersrdatitles [SEP]']
[Init] best perm rec loss: 0.8170942664146423 for ['[CLS] gun quartersayaion helprdatitles [SEP]']
[Init] best perm rec loss: 0.8160659074783325 for ['[CLS]titles gun quartersrdaionaya help [SEP]']
[Init] best perm rec loss: 0.8120703101158142 for ['[CLS]ionrda quarterstitles gunaya help [SEP]']
[Init] best perm rec loss: 0.8104207515716553 for ['[CLS]ayatitlesion gunrda quarters help [SEP]']
[Init] best perm rec loss: 0.8102152943611145 for ['[CLS] quartersiontitlesrdaaya help gun [SEP]']
[Init] best perm rec loss: 0.8083382844924927 for ['[CLS]rda helpiontitlesaya quarters gun [SEP]']
[Init] best perm rec loss: 0.8069172501564026 for ['[CLS] quartersionayardatitles gun help [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.398 (perp=10.554, rec=0.452, cos=0.835), tot_loss_proj:3.883 [t=0.29s]
prediction: ['[CLS] mrcraft. among mark ah. [SEP]']
[ 100/2000] tot_loss=2.581 (perp=7.036, rec=0.344, cos=0.829), tot_loss_proj:3.195 [t=0.30s]
prediction: ['[CLS] not working. perhaps pillar empty. [SEP]']
[ 150/2000] tot_loss=2.983 (perp=9.486, rec=0.272, cos=0.813), tot_loss_proj:3.652 [t=0.30s]
prediction: ['[CLS] could working. nonetheless getting surely. [SEP]']
[ 200/2000] tot_loss=2.925 (perp=9.227, rec=0.253, cos=0.827), tot_loss_proj:3.583 [t=0.30s]
prediction: ['[CLS] cannot working. nonetheless been surely. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.369 (perp=10.886, rec=0.327, cos=0.864), tot_loss_proj:3.950 [t=0.30s]
prediction: ['[CLS] could working. surely never mayoral nothing [SEP]']
[ 300/2000] tot_loss=2.940 (perp=9.226, rec=0.259, cos=0.836), tot_loss_proj:3.620 [t=0.30s]
prediction: ['[CLS] cannot working. surely never mayoral. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.994 (perp=9.804, rec=0.225, cos=0.808), tot_loss_proj:3.724 [t=0.30s]
prediction: ['[CLS] working could been i never mayoral. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.057 (perp=10.068, rec=0.221, cos=0.822), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] working description been could originallyght. [SEP]']
[ 450/2000] tot_loss=2.987 (perp=9.895, rec=0.203, cos=0.805), tot_loss_proj:3.766 [t=0.30s]
prediction: ['[CLS] working i been could originallyght. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.915 (perp=9.429, rec=0.220, cos=0.808), tot_loss_proj:3.679 [t=0.30s]
prediction: ['[CLS] i been working could originally mayoral. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.906 (perp=9.429, rec=0.206, cos=0.814), tot_loss_proj:3.673 [t=0.30s]
prediction: ['[CLS] i been working could originally mayoral. [SEP]']
[ 600/2000] tot_loss=2.890 (perp=9.429, rec=0.203, cos=0.801), tot_loss_proj:3.676 [t=0.30s]
prediction: ['[CLS] i been working could originally mayoral. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.884 (perp=9.429, rec=0.203, cos=0.794), tot_loss_proj:3.672 [t=0.30s]
prediction: ['[CLS] i been working could originally mayoral. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.881 (perp=9.429, rec=0.192, cos=0.804), tot_loss_proj:3.676 [t=0.30s]
prediction: ['[CLS] i been working could originally mayoral. [SEP]']
[ 750/2000] tot_loss=2.690 (perp=8.499, rec=0.192, cos=0.798), tot_loss_proj:3.527 [t=0.30s]
prediction: ['[CLS] i been working could not mayoral. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.692 (perp=8.499, rec=0.202, cos=0.790), tot_loss_proj:3.527 [t=0.30s]
prediction: ['[CLS] i been working could not mayoral. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.599 (perp=8.027, rec=0.197, cos=0.797), tot_loss_proj:3.413 [t=0.30s]
prediction: ['[CLS] i been working could not rafe. [SEP]']
[ 900/2000] tot_loss=2.692 (perp=8.499, rec=0.198, cos=0.794), tot_loss_proj:3.528 [t=0.30s]
prediction: ['[CLS] i been working could not mayoral. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.631 (perp=8.152, rec=0.200, cos=0.800), tot_loss_proj:3.506 [t=0.30s]
prediction: ['[CLS] i been working could notmbre. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.606 (perp=7.881, rec=0.217, cos=0.813), tot_loss_proj:3.395 [t=0.30s]
prediction: ['[CLS] i could been working not concessions. [SEP]']
[1050/2000] tot_loss=2.538 (perp=7.665, rec=0.208, cos=0.798), tot_loss_proj:3.427 [t=0.30s]
prediction: ['[CLS] i could been working notmbre. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.525 (perp=7.665, rec=0.197, cos=0.795), tot_loss_proj:3.429 [t=0.30s]
prediction: ['[CLS] i could been working notmbre. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.403 (perp=6.978, rec=0.195, cos=0.812), tot_loss_proj:3.311 [t=0.30s]
prediction: ['[CLS] i could never been workingmbre. [SEP]']
[1200/2000] tot_loss=2.393 (perp=6.978, rec=0.194, cos=0.803), tot_loss_proj:3.321 [t=0.30s]
prediction: ['[CLS] i could never been workingmbre. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.383 (perp=6.978, rec=0.188, cos=0.800), tot_loss_proj:3.316 [t=0.30s]
prediction: ['[CLS] i could never been workingmbre. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.399 (perp=6.978, rec=0.204, cos=0.799), tot_loss_proj:3.317 [t=0.30s]
prediction: ['[CLS] i could never been workingmbre. [SEP]']
[1350/2000] tot_loss=2.389 (perp=6.925, rec=0.206, cos=0.799), tot_loss_proj:3.291 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.380 (perp=6.925, rec=0.196, cos=0.798), tot_loss_proj:3.288 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.380 (perp=6.925, rec=0.196, cos=0.799), tot_loss_proj:3.288 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
[1500/2000] tot_loss=2.377 (perp=6.925, rec=0.194, cos=0.798), tot_loss_proj:3.286 [t=0.39s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.380 (perp=6.925, rec=0.196, cos=0.799), tot_loss_proj:3.285 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.388 (perp=6.925, rec=0.205, cos=0.799), tot_loss_proj:3.287 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
[1650/2000] tot_loss=2.385 (perp=6.925, rec=0.201, cos=0.799), tot_loss_proj:3.282 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.370 (perp=6.925, rec=0.187, cos=0.798), tot_loss_proj:3.288 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.380 (perp=6.925, rec=0.197, cos=0.798), tot_loss_proj:3.288 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
[1800/2000] tot_loss=2.383 (perp=6.925, rec=0.200, cos=0.799), tot_loss_proj:3.284 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.379 (perp=6.925, rec=0.195, cos=0.799), tot_loss_proj:3.286 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.370 (perp=6.925, rec=0.186, cos=0.799), tot_loss_proj:3.283 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
[1950/2000] tot_loss=2.381 (perp=6.925, rec=0.197, cos=0.799), tot_loss_proj:3.283 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.379 (perp=6.925, rec=0.195, cos=0.799), tot_loss_proj:3.285 [t=0.30s]
prediction: ['[CLS] i could not been workingmbre. [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] he could not have been working. [SEP]
========================
predicted: 
========================
[CLS] i could not been workingmbre. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 71.429 | r: 62.500
rouge2     | fm: 15.385 | p: 16.667 | r: 14.286
rougeL     | fm: 66.667 | p: 71.429 | r: 62.500
rougeLsum  | fm: 66.667 | p: 71.429 | r: 62.500
r1fm+r2fm = 82.051

[Aggregate metrics]:
rouge1     | fm: 76.539 | p: 76.659 | r: 76.548
rouge2     | fm: 34.747 | p: 34.644 | r: 34.937
rougeL     | fm: 67.366 | p: 67.595 | r: 67.389
rougeLsum  | fm: 67.517 | p: 67.763 | r: 67.575
r1fm+r2fm = 111.286

input #71 time: 0:11:49 | total time: 14:20:25


Running input #72 of 100.
reference: 
========================
He goes.
========================
average of cosine similarity 0.9989691006069693
highest_index [0]
highest [0.9989691006069693]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 2002, 3632, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he goes. [SEP]']
[Init] best rec loss: 0.9198967814445496 for ['[CLS] prior keynes latter [SEP]']
[Init] best rec loss: 0.9164295196533203 for ['[CLS] workshopgaard drift [SEP]']
[Init] best rec loss: 0.8758153915405273 for ['[CLS] diver prism theme [SEP]']
[Init] best rec loss: 0.8755776882171631 for ['[CLS] whiteykns [SEP]']
[Init] best rec loss: 0.8751401305198669 for ['[CLS] gets handsome fever [SEP]']
[Init] best rec loss: 0.8608056306838989 for ['[CLS]cat soldina [SEP]']
[Init] best rec loss: 0.8557133078575134 for ['[CLS] progress scotia 2000 [SEP]']
[Init] best rec loss: 0.8451719284057617 for ['[CLS] shouldn might wight [SEP]']
[Init] best perm rec loss: 0.8449836373329163 for ['[CLS] wight shouldn might [SEP]']
[Init] best perm rec loss: 0.8423933386802673 for ['[CLS] might wight shouldn [SEP]']
[Init] best perm rec loss: 0.8412434458732605 for ['[CLS] might shouldn wight [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.172 (perp=9.178, rec=0.529, cos=0.807), tot_loss_proj:3.674 [t=0.29s]
prediction: ['[CLS] concealed goes. [SEP]']
[ 100/2000] tot_loss=2.844 (perp=8.168, rec=0.465, cos=0.745), tot_loss_proj:3.473 [t=0.30s]
prediction: ['[CLS] goes went. [SEP]']
[ 150/2000] tot_loss=2.827 (perp=8.077, rec=0.390, cos=0.822), tot_loss_proj:3.488 [t=0.30s]
prediction: ['[CLS] goes goes. [SEP]']
[ 200/2000] tot_loss=2.070 (perp=5.241, rec=0.295, cos=0.727), tot_loss_proj:1.226 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.048 (perp=5.241, rec=0.297, cos=0.703), tot_loss_proj:1.233 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[ 300/2000] tot_loss=2.088 (perp=5.241, rec=0.283, cos=0.756), tot_loss_proj:1.225 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.093 (perp=5.241, rec=0.286, cos=0.758), tot_loss_proj:1.229 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.082 (perp=5.241, rec=0.273, cos=0.761), tot_loss_proj:1.236 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[ 450/2000] tot_loss=2.074 (perp=5.241, rec=0.264, cos=0.762), tot_loss_proj:1.234 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.056 (perp=5.241, rec=0.256, cos=0.752), tot_loss_proj:1.226 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.035 (perp=5.241, rec=0.255, cos=0.732), tot_loss_proj:1.234 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[ 600/2000] tot_loss=2.061 (perp=5.241, rec=0.259, cos=0.754), tot_loss_proj:1.229 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.059 (perp=5.241, rec=0.261, cos=0.749), tot_loss_proj:1.226 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.036 (perp=5.241, rec=0.266, cos=0.722), tot_loss_proj:1.230 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[ 750/2000] tot_loss=2.026 (perp=5.241, rec=0.246, cos=0.732), tot_loss_proj:1.235 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.048 (perp=5.241, rec=0.258, cos=0.742), tot_loss_proj:1.236 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.041 (perp=5.241, rec=0.268, cos=0.725), tot_loss_proj:1.235 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[ 900/2000] tot_loss=2.048 (perp=5.241, rec=0.260, cos=0.740), tot_loss_proj:1.229 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.036 (perp=5.241, rec=0.240, cos=0.748), tot_loss_proj:1.233 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.031 (perp=5.241, rec=0.239, cos=0.744), tot_loss_proj:1.225 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[1050/2000] tot_loss=2.017 (perp=5.241, rec=0.227, cos=0.742), tot_loss_proj:1.221 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.036 (perp=5.241, rec=0.248, cos=0.740), tot_loss_proj:1.231 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.027 (perp=5.241, rec=0.239, cos=0.739), tot_loss_proj:1.221 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[1200/2000] tot_loss=2.015 (perp=5.241, rec=0.228, cos=0.739), tot_loss_proj:1.236 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.038 (perp=5.241, rec=0.247, cos=0.743), tot_loss_proj:1.232 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.032 (perp=5.241, rec=0.249, cos=0.735), tot_loss_proj:1.225 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[1350/2000] tot_loss=2.035 (perp=5.241, rec=0.246, cos=0.741), tot_loss_proj:1.233 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.039 (perp=5.241, rec=0.251, cos=0.740), tot_loss_proj:1.238 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.026 (perp=5.241, rec=0.239, cos=0.739), tot_loss_proj:1.228 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[1500/2000] tot_loss=2.040 (perp=5.241, rec=0.252, cos=0.740), tot_loss_proj:1.228 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.042 (perp=5.241, rec=0.256, cos=0.738), tot_loss_proj:1.231 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.026 (perp=5.241, rec=0.239, cos=0.739), tot_loss_proj:1.234 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[1650/2000] tot_loss=2.012 (perp=5.241, rec=0.223, cos=0.740), tot_loss_proj:1.227 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.044 (perp=5.241, rec=0.255, cos=0.740), tot_loss_proj:1.220 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.037 (perp=5.241, rec=0.245, cos=0.744), tot_loss_proj:1.232 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[1800/2000] tot_loss=2.021 (perp=5.241, rec=0.234, cos=0.739), tot_loss_proj:1.226 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.031 (perp=5.241, rec=0.245, cos=0.739), tot_loss_proj:1.219 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.037 (perp=5.241, rec=0.249, cos=0.740), tot_loss_proj:1.234 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
[1950/2000] tot_loss=2.029 (perp=5.241, rec=0.240, cos=0.741), tot_loss_proj:1.231 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.037 (perp=5.241, rec=0.249, cos=0.740), tot_loss_proj:1.233 [t=0.30s]
prediction: ['[CLS] he goes. [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] he goes. [SEP]
========================
predicted: 
========================
[CLS] he goes. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 76.849 | p: 77.047 | r: 76.885
rouge2     | fm: 35.522 | p: 35.504 | r: 35.721
rougeL     | fm: 67.762 | p: 68.000 | r: 67.857
rougeLsum  | fm: 67.950 | p: 68.203 | r: 67.916
r1fm+r2fm = 112.371

input #72 time: 0:11:47 | total time: 14:32:13


Running input #73 of 100.
reference: 
========================
This machine records well.
========================
average of cosine similarity 0.9989471325580367
highest_index [0]
highest [0.9989471325580367]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2023, 3698, 2636, 2092, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] this machine records well. [SEP]']
[Init] best rec loss: 0.897746741771698 for ['[CLS] miss violet chord parole tempo [SEP]']
[Init] best rec loss: 0.8706672191619873 for ['[CLS] streaktite newt fiction vr [SEP]']
[Init] best rec loss: 0.8657136559486389 for ['[CLS] will manage ¹lore alpha [SEP]']
[Init] best rec loss: 0.8560554385185242 for ['[CLS] thumbnaire viral ushered bog [SEP]']
[Init] best rec loss: 0.8503304123878479 for ['[CLS]hore graduating count fan vulnerable [SEP]']
[Init] best rec loss: 0.8065952062606812 for ['[CLS] melody norfolk ibn headsels [SEP]']
[Init] best perm rec loss: 0.7963202595710754 for ['[CLS] ibn melodyels norfolk heads [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.789 (perp=6.605, rec=0.360, cos=0.108), tot_loss_proj:3.051 [t=0.29s]
prediction: ['[CLS] machine records records recorded. [SEP]']
[ 100/2000] tot_loss=1.815 (perp=7.493, rec=0.253, cos=0.064), tot_loss_proj:3.348 [t=0.30s]
prediction: ['[CLS] machine records records same. [SEP]']
[ 150/2000] tot_loss=2.212 (perp=8.463, rec=0.396, cos=0.124), tot_loss_proj:3.604 [t=0.30s]
prediction: ['[CLS] this records computer particular. [SEP]']
[ 200/2000] tot_loss=2.576 (perp=11.146, rec=0.284, cos=0.062), tot_loss_proj:4.144 [t=0.30s]
prediction: ['[CLS] this records computer particular well [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.947 (perp=8.463, rec=0.221, cos=0.033), tot_loss_proj:3.501 [t=0.30s]
prediction: ['[CLS] this a computer records well [SEP]']
[ 300/2000] tot_loss=2.064 (perp=9.361, rec=0.167, cos=0.025), tot_loss_proj:2.441 [t=0.30s]
prediction: ['[CLS] this software machine records well [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.860 (perp=8.496, rec=0.140, cos=0.021), tot_loss_proj:2.866 [t=0.30s]
prediction: ['[CLS] this machine machine records well [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.808 (perp=8.291, rec=0.132, cos=0.019), tot_loss_proj:3.484 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
[ 450/2000] tot_loss=1.790 (perp=8.291, rec=0.113, cos=0.018), tot_loss_proj:3.481 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.785 (perp=8.291, rec=0.110, cos=0.017), tot_loss_proj:3.479 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.779 (perp=8.291, rec=0.104, cos=0.017), tot_loss_proj:3.491 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
[ 600/2000] tot_loss=1.777 (perp=8.291, rec=0.102, cos=0.017), tot_loss_proj:3.491 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.773 (perp=8.291, rec=0.098, cos=0.017), tot_loss_proj:3.486 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.775 (perp=8.291, rec=0.100, cos=0.017), tot_loss_proj:3.488 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
[ 750/2000] tot_loss=1.775 (perp=8.291, rec=0.101, cos=0.016), tot_loss_proj:3.486 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.778 (perp=8.291, rec=0.103, cos=0.016), tot_loss_proj:3.486 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.774 (perp=8.291, rec=0.100, cos=0.016), tot_loss_proj:3.489 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
[ 900/2000] tot_loss=1.769 (perp=8.291, rec=0.095, cos=0.016), tot_loss_proj:3.492 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.767 (perp=8.291, rec=0.093, cos=0.016), tot_loss_proj:3.487 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
Attempt swap
[1000/2000] tot_loss=1.774 (perp=8.291, rec=0.100, cos=0.015), tot_loss_proj:3.490 [t=0.30s]
prediction: ['[CLS] machine this machine records well [SEP]']
[1050/2000] tot_loss=1.759 (perp=8.233, rec=0.097, cos=0.015), tot_loss_proj:2.381 [t=0.30s]
prediction: ['[CLS]. this machine records well [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.314 (perp=6.165, rec=0.076, cos=0.005), tot_loss_proj:1.402 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.308 (perp=6.165, rec=0.071, cos=0.004), tot_loss_proj:1.402 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
[1200/2000] tot_loss=1.314 (perp=6.165, rec=0.078, cos=0.003), tot_loss_proj:1.395 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.311 (perp=6.165, rec=0.076, cos=0.003), tot_loss_proj:1.399 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.301 (perp=6.165, rec=0.065, cos=0.003), tot_loss_proj:1.388 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
[1350/2000] tot_loss=1.310 (perp=6.165, rec=0.074, cos=0.003), tot_loss_proj:1.397 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.310 (perp=6.165, rec=0.074, cos=0.003), tot_loss_proj:1.398 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.309 (perp=6.165, rec=0.073, cos=0.003), tot_loss_proj:1.399 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
[1500/2000] tot_loss=1.298 (perp=6.165, rec=0.062, cos=0.003), tot_loss_proj:1.400 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.306 (perp=6.165, rec=0.070, cos=0.003), tot_loss_proj:1.395 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.302 (perp=6.165, rec=0.066, cos=0.003), tot_loss_proj:1.390 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
[1650/2000] tot_loss=1.310 (perp=6.165, rec=0.074, cos=0.003), tot_loss_proj:1.391 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.290 (perp=6.165, rec=0.055, cos=0.003), tot_loss_proj:1.398 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.306 (perp=6.165, rec=0.071, cos=0.003), tot_loss_proj:1.389 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
[1800/2000] tot_loss=1.305 (perp=6.165, rec=0.069, cos=0.003), tot_loss_proj:1.398 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.297 (perp=6.165, rec=0.061, cos=0.003), tot_loss_proj:1.400 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.294 (perp=6.165, rec=0.059, cos=0.003), tot_loss_proj:1.393 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
[1950/2000] tot_loss=1.308 (perp=6.165, rec=0.072, cos=0.003), tot_loss_proj:1.395 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.307 (perp=6.165, rec=0.071, cos=0.003), tot_loss_proj:1.396 [t=0.30s]
prediction: ['[CLS] this machine records well. [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] this machine records well. [SEP]
========================
predicted: 
========================
[CLS] this machine records well. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 77.101 | p: 77.299 | r: 77.152
rouge2     | fm: 36.629 | p: 36.541 | r: 36.782
rougeL     | fm: 68.197 | p: 68.413 | r: 68.234
rougeLsum  | fm: 68.454 | p: 68.643 | r: 68.453
r1fm+r2fm = 113.731

input #73 time: 0:11:47 | total time: 14:44:00


Running input #74 of 100.
reference: 
========================
Love her though I may, that won't affect the grade.
========================
average of cosine similarity 0.9990572087509502
highest_index [0]
highest [0.9990572087509502]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2293, 2014, 2295, 1045, 2089, 1010, 2008, 2180, 1005, 1056, 7461,
         1996, 3694, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] love her though i may, that won't affect the grade. [SEP]"]
[Init] best rec loss: 0.8917502164840698 for ['[CLS] charm joke classification lemon vhs d （ alzheimer minogueify gunslinger part used club [SEP]']
[Init] best rec loss: 0.8804856538772583 for ['[CLS] passed eva with two history outward box cai shuffleeritt wonders temple aware [SEP]']
[Init] best rec loss: 0.8661777973175049 for ['[CLS] orient conner dresser canada came belly sing sri front jacobdate pharaoh? devon [SEP]']
[Init] best rec loss: 0.8583150506019592 for ['[CLS] host travel casting rover malaya replacedated cloak major showed her calling tv great [SEP]']
[Init] best rec loss: 0.8429224491119385 for ['[CLS] inflation frowned knew clapped rosalie executed affecteda wild blue keptrcle za rafe [SEP]']
[Init] best rec loss: 0.8425992131233215 for ['[CLS] eastern scare baby open dawson town creature administrator small hara civil rough poll gender [SEP]']
[Init] best rec loss: 0.8343572020530701 for ['[CLS] dane capturedvent hands illinois operatic given jon again climate dealer ordained check shortly [SEP]']
[Init] best rec loss: 0.8296738266944885 for ['[CLS] par animals gavin hokkaido fisherman gttwined yetrgy sexual thank sophia aim gag [SEP]']
[Init] best rec loss: 0.8252779245376587 for ['[CLS] daylight material make bastard nor morning faso conducted hopeivisionest contrary physical equally [SEP]']
[Init] best rec loss: 0.8218004703521729 for ['[CLS] vhs pitch counter tapes timing festival book page clockwise jonah vamps systematicdded pu [SEP]']
[Init] best rec loss: 0.8175231218338013 for ['[CLS] stream ocean cross movement father moffat appointment below rein appeal occurring jordan weight wade [SEP]']
[Init] best perm rec loss: 0.8174853920936584 for ['[CLS] movement moffat occurring stream jordan appointment rein weight below cross father wade ocean appeal [SEP]']
[Init] best perm rec loss: 0.8149864077568054 for ['[CLS] movement wade father ocean moffat occurring jordan below appointment rein weight stream appeal cross [SEP]']
[Init] best perm rec loss: 0.8087663650512695 for ['[CLS] weight stream jordan rein occurring father moffat appeal wade movement cross below appointment ocean [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.188 (perp=9.573, rec=0.456, cos=0.818), tot_loss_proj:3.805 [t=0.29s]
prediction: ['[CLS]. ; international loved intra magnetic but, a love piece than no. [SEP]']
[ 100/2000] tot_loss=3.175 (perp=9.757, rec=0.392, cos=0.832), tot_loss_proj:3.784 [t=0.30s]
prediction: ['[CLS].power reserve love contrast magnetic but, him love ruin becoming her. [SEP]']
[ 150/2000] tot_loss=3.400 (perp=10.502, rec=0.451, cos=0.849), tot_loss_proj:3.988 [t=0.30s]
prediction: ['[CLS] love, warfare love contrastpeed {, her love thing would her. [SEP]']
[ 200/2000] tot_loss=3.219 (perp=10.397, rec=0.336, cos=0.803), tot_loss_proj:3.943 [t=0.30s]
prediction: ['[CLS] her western intermediate thoughku billy however, her love years should that. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.974 (perp=9.296, rec=0.288, cos=0.827), tot_loss_proj:3.737 [t=0.30s]
prediction: ['[CLS] her he imagining thoughku billy however, that love knew should her. [SEP]']
[ 300/2000] tot_loss=3.037 (perp=9.654, rec=0.256, cos=0.850), tot_loss_proj:3.785 [t=0.30s]
prediction: ['[CLS] her he trades thoughku sexual impressed, that loveborg might her. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.953 (perp=9.162, rec=0.297, cos=0.823), tot_loss_proj:3.728 [t=0.30s]
prediction: ['[CLS] her project chemistrypeed may though highly, that love hasn would this. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.043 (perp=9.661, rec=0.282, cos=0.828), tot_loss_proj:3.842 [t=0.30s]
prediction: ['[CLS] her eitherpressingpeed may though project, that love feud would this. [SEP]']
[ 450/2000] tot_loss=2.879 (perp=8.930, rec=0.267, cos=0.826), tot_loss_proj:3.639 [t=0.30s]
prediction: ['[CLS] her gradespressingpeed may though project, that love wrath would this. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.862 (perp=8.999, rec=0.229, cos=0.833), tot_loss_proj:3.638 [t=0.30s]
prediction: ['[CLS] that gradepressingpeed may though project, that love highly might her. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.825 (perp=8.710, rec=0.232, cos=0.851), tot_loss_proj:3.585 [t=0.30s]
prediction: ['[CLS] that herpressingpeed may though project, that love highly might grade. [SEP]']
[ 600/2000] tot_loss=2.716 (perp=8.250, rec=0.216, cos=0.851), tot_loss_proj:3.493 [t=0.30s]
prediction: ['[CLS] that herpressingpeed may though project, that love inhibitor might grade. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.910 (perp=9.169, rec=0.217, cos=0.859), tot_loss_proj:3.664 [t=0.30s]
prediction: ['[CLS] that herpressing quite may though project, that love inhibitor affect grade. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.842 (perp=8.742, rec=0.227, cos=0.866), tot_loss_proj:3.615 [t=0.30s]
prediction: ['[CLS] that gradepressing quite may though my, that love inhibitor affect her. [SEP]']
[ 750/2000] tot_loss=2.883 (perp=8.992, rec=0.219, cos=0.866), tot_loss_proj:3.656 [t=0.30s]
prediction: ['[CLS] that gradepressing quite may though my, that love rearview affect her. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.839 (perp=8.736, rec=0.221, cos=0.871), tot_loss_proj:3.588 [t=0.30s]
prediction: ['[CLS] that mypressing quite may though grade, that love rearview affect her. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.781 (perp=8.457, rec=0.214, cos=0.876), tot_loss_proj:3.523 [t=0.30s]
prediction: ['[CLS] quite mypressing that may though grade, that love rearview affect her. [SEP]']
[ 900/2000] tot_loss=2.786 (perp=8.457, rec=0.220, cos=0.875), tot_loss_proj:3.526 [t=0.30s]
prediction: ['[CLS] quite mypressing that may though grade, that love rearview affect her. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.767 (perp=8.457, rec=0.193, cos=0.883), tot_loss_proj:3.525 [t=0.30s]
prediction: ['[CLS] quite mypressing that may though grade, that love rearview affect her. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.864 (perp=8.935, rec=0.198, cos=0.879), tot_loss_proj:3.612 [t=0.30s]
prediction: ['[CLS] quite my vantage that may though grade, that love rearview affect her. [SEP]']
[1050/2000] tot_loss=2.870 (perp=8.935, rec=0.197, cos=0.885), tot_loss_proj:3.615 [t=0.30s]
prediction: ['[CLS] quite my vantage that may though grade, that love rearview affect her. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.876 (perp=8.935, rec=0.207, cos=0.882), tot_loss_proj:3.615 [t=0.30s]
prediction: ['[CLS] quite my vantage that may though grade, that love rearview affect her. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.851 (perp=8.855, rec=0.196, cos=0.884), tot_loss_proj:3.581 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview affect her. [SEP]']
[1200/2000] tot_loss=2.852 (perp=8.855, rec=0.196, cos=0.884), tot_loss_proj:3.582 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview affect her. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.825 (perp=8.734, rec=0.189, cos=0.890), tot_loss_proj:3.600 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.827 (perp=8.734, rec=0.190, cos=0.891), tot_loss_proj:3.603 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
[1350/2000] tot_loss=2.840 (perp=8.734, rec=0.203, cos=0.890), tot_loss_proj:3.603 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.842 (perp=8.734, rec=0.207, cos=0.889), tot_loss_proj:3.605 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.848 (perp=8.734, rec=0.209, cos=0.892), tot_loss_proj:3.603 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
[1500/2000] tot_loss=2.838 (perp=8.734, rec=0.202, cos=0.890), tot_loss_proj:3.605 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.842 (perp=8.734, rec=0.202, cos=0.894), tot_loss_proj:3.604 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.837 (perp=8.734, rec=0.199, cos=0.891), tot_loss_proj:3.602 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
[1650/2000] tot_loss=2.834 (perp=8.734, rec=0.194, cos=0.894), tot_loss_proj:3.602 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.831 (perp=8.734, rec=0.190, cos=0.894), tot_loss_proj:3.601 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.840 (perp=8.734, rec=0.199, cos=0.895), tot_loss_proj:3.604 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
[1800/2000] tot_loss=2.836 (perp=8.734, rec=0.193, cos=0.896), tot_loss_proj:3.601 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.838 (perp=8.734, rec=0.197, cos=0.895), tot_loss_proj:3.601 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.842 (perp=8.734, rec=0.201, cos=0.895), tot_loss_proj:3.602 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
[1950/2000] tot_loss=2.838 (perp=8.734, rec=0.195, cos=0.896), tot_loss_proj:3.605 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.834 (perp=8.734, rec=0.192, cos=0.896), tot_loss_proj:3.601 [t=0.30s]
prediction: ['[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] love her though i may, that won't affect the grade. [SEP]
========================
predicted: 
========================
[CLS] quite vantage my that may though grade, that love rearview her affect. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 64.286 | r: 69.231
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 37.037 | p: 35.714 | r: 38.462
rougeLsum  | fm: 37.037 | p: 35.714 | r: 38.462
r1fm+r2fm = 66.667

[Aggregate metrics]:
rouge1     | fm: 76.889 | p: 77.029 | r: 77.024
rouge2     | fm: 35.795 | p: 35.731 | r: 36.015
rougeL     | fm: 67.858 | p: 68.033 | r: 67.887
rougeLsum  | fm: 67.998 | p: 68.163 | r: 68.074
r1fm+r2fm = 112.684

input #74 time: 0:11:49 | total time: 14:55:50


Running input #75 of 100.
reference: 
========================
I have been flying helicopters for years.
========================
average of cosine similarity 0.9989687018318703
highest_index [0]
highest [0.9989687018318703]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1045,  2031,  2042,  3909, 12400,  2005,  2086,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have been flying helicopters for years. [SEP]']
[Init] best rec loss: 0.9614344835281372 for ['[CLS] lindsey exposed gov recreation touch approaching lack troubles [SEP]']
[Init] best rec loss: 0.9567222595214844 for ['[CLS] exhibit suggesthorn folks royal sports ″ log [SEP]']
[Init] best rec loss: 0.9054753184318542 for ['[CLS] sheridanance 寺 done names chance time continued [SEP]']
[Init] best rec loss: 0.9017260670661926 for ['[CLS] calm fighting artiface turnoutient actsibility [SEP]']
[Init] best rec loss: 0.8966726660728455 for ['[CLS] incomevres reach summer kenya return yorker inauguration [SEP]']
[Init] best rec loss: 0.8951678276062012 for ['[CLS] software balls imaginedtic ata records let refugee [SEP]']
[Init] best rec loss: 0.8770248293876648 for ['[CLS] always jamie intervention glory attended naomi shade smack [SEP]']
[Init] best perm rec loss: 0.8752044439315796 for ['[CLS] always glory attended intervention smack jamie shade naomi [SEP]']
[Init] best perm rec loss: 0.8743784427642822 for ['[CLS] always glory jamie shade naomi attended smack intervention [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.657 (perp=12.255, rec=0.514, cos=0.692), tot_loss_proj:4.400 [t=0.29s]
prediction: ['[CLS] recognized scent sergeant ） complicated units ( literally [SEP]']
[ 100/2000] tot_loss=3.438 (perp=11.313, rec=0.442, cos=0.734), tot_loss_proj:4.138 [t=0.30s]
prediction: ['[CLS]ricted flying sergeant rank vessel units ( been [SEP]']
[ 150/2000] tot_loss=3.167 (perp=10.514, rec=0.387, cos=0.677), tot_loss_proj:3.869 [t=0.30s]
prediction: ['[CLS] i flying been helicopters helicopters helicopters (. [SEP]']
[ 200/2000] tot_loss=2.857 (perp=9.164, rec=0.369, cos=0.655), tot_loss_proj:3.653 [t=0.30s]
prediction: ['[CLS] i flying ago helicopters helicopters helicopters (. [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.110 (perp=10.514, rec=0.342, cos=0.665), tot_loss_proj:3.866 [t=0.30s]
prediction: ['[CLS] i flying been helicopters helicopters helicopters (. [SEP]']
[ 300/2000] tot_loss=2.911 (perp=9.235, rec=0.396, cos=0.668), tot_loss_proj:3.599 [t=0.30s]
prediction: ['[CLS] i flying been helicopters flying helicopterstime. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.768 (perp=8.679, rec=0.329, cos=0.703), tot_loss_proj:3.608 [t=0.30s]
prediction: ['[CLS] i have uss years flying helicopters years. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.702 (perp=8.106, rec=0.353, cos=0.728), tot_loss_proj:3.570 [t=0.30s]
prediction: ['[CLS] i have uss helicopters flying consecutive years. [SEP]']
[ 450/2000] tot_loss=2.641 (perp=8.106, rec=0.318, cos=0.701), tot_loss_proj:3.559 [t=0.30s]
prediction: ['[CLS] i have uss helicopters flying consecutive years. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.778 (perp=8.759, rec=0.317, cos=0.710), tot_loss_proj:3.652 [t=0.30s]
prediction: ['[CLS] i have uss helicopters flying weeks years. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.588 (perp=7.870, rec=0.308, cos=0.705), tot_loss_proj:3.430 [t=0.30s]
prediction: ['[CLS] i have uss helicopters weeks flying years. [SEP]']
[ 600/2000] tot_loss=2.587 (perp=7.870, rec=0.295, cos=0.718), tot_loss_proj:3.426 [t=0.30s]
prediction: ['[CLS] i have uss helicopters weeks flying years. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.578 (perp=7.870, rec=0.294, cos=0.710), tot_loss_proj:3.429 [t=0.30s]
prediction: ['[CLS] i have uss helicopters weeks flying years. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.695 (perp=8.484, rec=0.293, cos=0.706), tot_loss_proj:3.467 [t=0.30s]
prediction: ['[CLS] i haveily helicopters weeks flying years. [SEP]']
[ 750/2000] tot_loss=2.673 (perp=8.484, rec=0.276, cos=0.700), tot_loss_proj:3.469 [t=0.30s]
prediction: ['[CLS] i haveily helicopters weeks flying years. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.674 (perp=8.484, rec=0.276, cos=0.701), tot_loss_proj:3.470 [t=0.30s]
prediction: ['[CLS] i haveily helicopters weeks flying years. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.667 (perp=8.484, rec=0.270, cos=0.701), tot_loss_proj:3.469 [t=0.30s]
prediction: ['[CLS] i haveily helicopters weeks flying years. [SEP]']
[ 900/2000] tot_loss=2.669 (perp=8.452, rec=0.276, cos=0.702), tot_loss_proj:3.451 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.747 (perp=8.452, rec=0.305, cos=0.751), tot_loss_proj:3.456 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.662 (perp=8.452, rec=0.268, cos=0.704), tot_loss_proj:3.450 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
[1050/2000] tot_loss=2.659 (perp=8.452, rec=0.265, cos=0.704), tot_loss_proj:3.454 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.659 (perp=8.452, rec=0.264, cos=0.705), tot_loss_proj:3.452 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.664 (perp=8.452, rec=0.269, cos=0.705), tot_loss_proj:3.455 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
[1200/2000] tot_loss=2.669 (perp=8.452, rec=0.273, cos=0.706), tot_loss_proj:3.455 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.659 (perp=8.452, rec=0.262, cos=0.706), tot_loss_proj:3.453 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.654 (perp=8.452, rec=0.257, cos=0.707), tot_loss_proj:3.455 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
[1350/2000] tot_loss=2.660 (perp=8.452, rec=0.262, cos=0.707), tot_loss_proj:3.453 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.651 (perp=8.452, rec=0.254, cos=0.707), tot_loss_proj:3.453 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.663 (perp=8.452, rec=0.267, cos=0.706), tot_loss_proj:3.454 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
[1500/2000] tot_loss=2.669 (perp=8.452, rec=0.267, cos=0.712), tot_loss_proj:3.453 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.661 (perp=8.452, rec=0.263, cos=0.708), tot_loss_proj:3.456 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.666 (perp=8.452, rec=0.267, cos=0.708), tot_loss_proj:3.457 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
[1650/2000] tot_loss=2.660 (perp=8.452, rec=0.262, cos=0.707), tot_loss_proj:3.456 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.656 (perp=8.452, rec=0.258, cos=0.707), tot_loss_proj:3.454 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.657 (perp=8.452, rec=0.260, cos=0.707), tot_loss_proj:3.453 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
[1800/2000] tot_loss=2.667 (perp=8.452, rec=0.269, cos=0.708), tot_loss_proj:3.451 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.656 (perp=8.452, rec=0.258, cos=0.708), tot_loss_proj:3.452 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.663 (perp=8.452, rec=0.263, cos=0.710), tot_loss_proj:3.451 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
[1950/2000] tot_loss=2.658 (perp=8.452, rec=0.260, cos=0.708), tot_loss_proj:3.455 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.658 (perp=8.452, rec=0.260, cos=0.708), tot_loss_proj:3.452 [t=0.30s]
prediction: ['[CLS] i haveily helicopters months flying years. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] i have been flying helicopters for years. [SEP]
========================
predicted: 
========================
[CLS] i haveily helicopters months flying years. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 75.000 | r: 66.667
rouge2     | fm: 26.667 | p: 28.571 | r: 25.000
rougeL     | fm: 58.824 | p: 62.500 | r: 55.556
rougeLsum  | fm: 58.824 | p: 62.500 | r: 55.556
r1fm+r2fm = 97.255

[Aggregate metrics]:
rouge1     | fm: 76.892 | p: 77.133 | r: 76.938
rouge2     | fm: 35.867 | p: 35.833 | r: 36.005
rougeL     | fm: 67.677 | p: 67.903 | r: 67.636
rougeLsum  | fm: 67.876 | p: 68.132 | r: 67.850
r1fm+r2fm = 112.758

input #75 time: 0:11:49 | total time: 15:07:39


Running input #76 of 100.
reference: 
========================
the person stand on my foot is heavy.
========================
average of cosine similarity 0.9987763325611142
highest_index [0]
highest [0.9987763325611142]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2711, 3233, 2006, 2026, 3329, 2003, 3082, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the person stand on my foot is heavy. [SEP]']
[Init] best rec loss: 0.9270862340927124 for ['[CLS] yes motorway has entering lin trust d dante without [SEP]']
[Init] best rec loss: 0.8121755123138428 for ['[CLS] stew type code intake nu visually consumer placed chin [SEP]']
[Init] best rec loss: 0.8006381988525391 for ['[CLS] _ norms chief concern aunttya hitter out how [SEP]']
[Init] best rec loss: 0.7632203698158264 for ['[CLS] concrete supportke police liszt gracelay masjid empress [SEP]']
[Init] best rec loss: 0.7449339628219604 for ['[CLS] right atgang connecting naturalistpy half use feud [SEP]']
[Init] best rec loss: 0.7301834225654602 for ['[CLS]ya bird bottledped range figure two serial astro [SEP]']
[Init] best rec loss: 0.7144144177436829 for ['[CLS] tag merlin heardhang land anywayimeter anastasia compare [SEP]']
[Init] best rec loss: 0.7078426480293274 for ['[CLS]ouse imp announced chu x network custom rock mer [SEP]']
[Init] best rec loss: 0.682126522064209 for ['[CLS] landfall day resulted kenton institute kate holland learning recorder [SEP]']
[Init] best rec loss: 0.6730624437332153 for ['[CLS] amnesia between electoral everyday facinglaidfold depot largest [SEP]']
[Init] best perm rec loss: 0.6716759204864502 for ['[CLS]laid electoral between largest facingfold depot everyday amnesia [SEP]']
[Init] best perm rec loss: 0.671424925327301 for ['[CLS] electoral between everydaylaidfold largest amnesia facing depot [SEP]']
[Init] best perm rec loss: 0.6692996621131897 for ['[CLS] facing betweenfold electoral largest everyday depot amnesialaid [SEP]']
[Init] best perm rec loss: 0.668085515499115 for ['[CLS] betweenfold electorallaid facing everyday amnesia depot largest [SEP]']
[Init] best perm rec loss: 0.6680567264556885 for ['[CLS]fold electorallaid everyday facing amnesia depot largest between [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.085 (perp=12.134, rec=0.520, cos=0.138), tot_loss_proj:3.317 [t=0.29s]
prediction: ['[CLS], cl was drink board stake francond airport [SEP]']
[ 100/2000] tot_loss=3.127 (perp=11.589, rec=0.581, cos=0.229), tot_loss_proj:3.134 [t=0.30s]
prediction: ['[CLS]. are be have retreat jumpedlifting canada kendra [SEP]']
[ 150/2000] tot_loss=3.046 (perp=11.694, rec=0.476, cos=0.232), tot_loss_proj:3.093 [t=0.30s]
prediction: ['[CLS] person arm be the locomotive fiddle wr standard kendra [SEP]']
[ 200/2000] tot_loss=3.123 (perp=12.184, rec=0.431, cos=0.255), tot_loss_proj:3.157 [t=0.30s]
prediction: ['[CLS] person arm stands the be fiddle root person definitely [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.858 (perp=10.896, rec=0.552, cos=0.127), tot_loss_proj:2.914 [t=0.30s]
prediction: ['[CLS] depot person seek stood. me fiddle day waiting [SEP]']
[ 300/2000] tot_loss=2.810 (perp=11.169, rec=0.417, cos=0.159), tot_loss_proj:2.945 [t=0.30s]
prediction: ['[CLS] sounding person stand is. station rocks guest pumps [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.540 (perp=9.999, rec=0.370, cos=0.170), tot_loss_proj:2.931 [t=0.30s]
prediction: ['[CLS] apparently person stand is bedown immediately flat. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.603 (perp=10.274, rec=0.345, cos=0.203), tot_loss_proj:2.733 [t=0.30s]
prediction: ['[CLS] depot person stand is hands station immediately heavy on [SEP]']
[ 450/2000] tot_loss=2.276 (perp=9.188, rec=0.308, cos=0.130), tot_loss_proj:2.679 [t=0.30s]
prediction: ['[CLS] depot person stand is hands station immediately. the [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.368 (perp=9.802, rec=0.286, cos=0.122), tot_loss_proj:2.924 [t=0.30s]
prediction: ['[CLS]lings person stand is the hands station immediately. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.413 (perp=9.693, rec=0.320, cos=0.155), tot_loss_proj:2.885 [t=0.30s]
prediction: ['[CLS]lings load person stand is the hands whose. [SEP]']
[ 600/2000] tot_loss=2.247 (perp=9.153, rec=0.281, cos=0.136), tot_loss_proj:2.887 [t=0.30s]
prediction: ['[CLS]lings load person stand is the hands heavy. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.986 (perp=7.903, rec=0.277, cos=0.129), tot_loss_proj:2.242 [t=0.30s]
prediction: ['[CLS] load person feet stand is the hands whose feet [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.107 (perp=8.672, rec=0.260, cos=0.112), tot_loss_proj:2.523 [t=0.30s]
prediction: ['[CLS] load person feet stand is the hands heavy feet [SEP]']
[ 750/2000] tot_loss=2.123 (perp=8.759, rec=0.260, cos=0.111), tot_loss_proj:2.477 [t=0.30s]
prediction: ['[CLS] load person feet stand is the hands heavy foot [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.107 (perp=8.759, rec=0.250, cos=0.105), tot_loss_proj:2.478 [t=0.30s]
prediction: ['[CLS] load person feet stand is the hands heavy foot [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.116 (perp=8.814, rec=0.250, cos=0.103), tot_loss_proj:2.715 [t=0.30s]
prediction: ['[CLS] load person feet stand is the crawl my foot [SEP]']
[ 900/2000] tot_loss=2.166 (perp=9.038, rec=0.257, cos=0.101), tot_loss_proj:2.795 [t=0.30s]
prediction: ['[CLS] load person nearest stand is the crawl my foot [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.163 (perp=9.030, rec=0.255, cos=0.102), tot_loss_proj:2.480 [t=0.30s]
prediction: ['[CLS] the person nearest stand is loadinge my foot [SEP]']
Attempt swap
[1000/2000] tot_loss=2.156 (perp=9.030, rec=0.249, cos=0.101), tot_loss_proj:2.488 [t=0.30s]
prediction: ['[CLS] the person nearest stand is loadinge my foot [SEP]']
[1050/2000] tot_loss=2.151 (perp=9.030, rec=0.246, cos=0.100), tot_loss_proj:2.488 [t=0.30s]
prediction: ['[CLS] the person nearest stand is loadinge my foot [SEP]']
Attempt swap
[1100/2000] tot_loss=2.155 (perp=9.030, rec=0.249, cos=0.100), tot_loss_proj:2.486 [t=0.30s]
prediction: ['[CLS] the person nearest stand is loadinge my foot [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.401 (perp=9.978, rec=0.273, cos=0.133), tot_loss_proj:2.741 [t=0.30s]
prediction: ['[CLS] the person nearest stand is my load ingrid foot [SEP]']
[1200/2000] tot_loss=2.346 (perp=9.978, rec=0.244, cos=0.107), tot_loss_proj:2.741 [t=0.30s]
prediction: ['[CLS] the person nearest stand is my load ingrid foot [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.152 (perp=8.943, rec=0.255, cos=0.109), tot_loss_proj:2.563 [t=0.30s]
prediction: ['[CLS] the person nearest stand is my foot load ingrid [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.056 (perp=8.543, rec=0.242, cos=0.105), tot_loss_proj:2.364 [t=0.30s]
prediction: ['[CLS] the person nearest stand is load my foot ingrid [SEP]']
[1350/2000] tot_loss=2.273 (perp=9.650, rec=0.240, cos=0.104), tot_loss_proj:2.875 [t=0.30s]
prediction: ['[CLS] the person nearest stand is load heavy foot ingrid [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.138 (perp=8.943, rec=0.250, cos=0.100), tot_loss_proj:2.562 [t=0.30s]
prediction: ['[CLS] the person nearest stand is my foot load ingrid [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.046 (perp=8.543, rec=0.239, cos=0.099), tot_loss_proj:2.363 [t=0.30s]
prediction: ['[CLS] the person nearest stand is load my foot ingrid [SEP]']
[1500/2000] tot_loss=2.275 (perp=9.650, rec=0.242, cos=0.102), tot_loss_proj:2.873 [t=0.30s]
prediction: ['[CLS] the person nearest stand is load heavy foot ingrid [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.092 (perp=8.697, rec=0.250, cos=0.103), tot_loss_proj:2.924 [t=0.30s]
prediction: ['[CLS] the person nearest stand is my foot loadlands [SEP]']
Attempt swap
[1600/2000] tot_loss=2.084 (perp=8.697, rec=0.243, cos=0.101), tot_loss_proj:2.925 [t=0.30s]
prediction: ['[CLS] the person nearest stand is my foot loadlands [SEP]']
[1650/2000] tot_loss=2.086 (perp=8.697, rec=0.245, cos=0.101), tot_loss_proj:2.922 [t=0.30s]
prediction: ['[CLS] the person nearest stand is my foot loadlands [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.145 (perp=9.032, rec=0.238, cos=0.101), tot_loss_proj:2.972 [t=0.30s]
prediction: ['[CLS] the person nearest stand is load heavy footlands [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.960 (perp=8.051, rec=0.246, cos=0.103), tot_loss_proj:2.989 [t=0.30s]
prediction: ['[CLS] the person nearest stand is heavy load footlands [SEP]']
[1800/2000] tot_loss=1.945 (perp=8.051, rec=0.233, cos=0.102), tot_loss_proj:2.985 [t=0.30s]
prediction: ['[CLS] the person nearest stand is heavy load footlands [SEP]']
Attempt swap
[1850/2000] tot_loss=1.952 (perp=8.051, rec=0.240, cos=0.102), tot_loss_proj:2.990 [t=0.30s]
prediction: ['[CLS] the person nearest stand is heavy load footlands [SEP]']
Attempt swap
[1900/2000] tot_loss=1.952 (perp=8.051, rec=0.240, cos=0.102), tot_loss_proj:2.984 [t=0.30s]
prediction: ['[CLS] the person nearest stand is heavy load footlands [SEP]']
[1950/2000] tot_loss=1.953 (perp=8.051, rec=0.242, cos=0.101), tot_loss_proj:2.987 [t=0.30s]
prediction: ['[CLS] the person nearest stand is heavy load footlands [SEP]']
Attempt swap
[2000/2000] tot_loss=1.942 (perp=8.051, rec=0.231, cos=0.101), tot_loss_proj:2.986 [t=0.30s]
prediction: ['[CLS] the person nearest stand is heavy load footlands [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS] the person stand on my foot is heavy. [SEP]
========================
predicted: 
========================
[CLS] the person nearest stand is heavy load footlands [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.000 | p: 70.000 | r: 70.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 103.333

[Aggregate metrics]:
rouge1     | fm: 76.703 | p: 77.008 | r: 76.731
rouge2     | fm: 35.855 | p: 35.785 | r: 36.060
rougeL     | fm: 67.713 | p: 67.928 | r: 67.731
rougeLsum  | fm: 67.846 | p: 68.031 | r: 67.796
r1fm+r2fm = 112.558

input #76 time: 0:11:48 | total time: 15:19:27


Running input #77 of 100.
reference: 
========================
My mother baked a cake for me.
========================
average of cosine similarity 0.9990830580770176
highest_index [0]
highest [0.9990830580770176]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2026,  2388, 17776,  1037,  9850,  2005,  2033,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] my mother baked a cake for me. [SEP]']
[Init] best rec loss: 0.9952715039253235 for ['[CLS] mysterious statistical its owner soft bodo network posting [SEP]']
[Init] best rec loss: 0.9630075097084045 for ['[CLS] baby jolink & spinal is andre youngest [SEP]']
[Init] best rec loss: 0.9617162346839905 for ['[CLS] saleslas conservative tonight micah occasions restoration superseded [SEP]']
[Init] best rec loss: 0.9617063403129578 for ['[CLS] ) traced or county holiday agroundske spun [SEP]']
[Init] best rec loss: 0.958404541015625 for ['[CLS] catch as [UNK] visitraph meet found your [SEP]']
[Init] best rec loss: 0.9563077092170715 for ['[CLS] kind knew split 11 fl site memorial lucky [SEP]']
[Init] best rec loss: 0.954372227191925 for ['[CLS] need when leftootpath handed lithuanian rather [SEP]']
[Init] best rec loss: 0.9527547359466553 for ['[CLS] linked rec vu contested corps pine round will [SEP]']
[Init] best rec loss: 0.9495469331741333 for ['[CLS] sales zero scene including interchange citedfin gaines [SEP]']
[Init] best rec loss: 0.946706235408783 for ['[CLS] tennis labelsient lieutenant exposure pact rain slumped [SEP]']
[Init] best rec loss: 0.94504314661026 for ['[CLS] returned clean stamps guess cord newspaper excuse card [SEP]']
[Init] best rec loss: 0.9376472234725952 for ['[CLS]ety anyone granted ( australian shared xu scenes [SEP]']
[Init] best perm rec loss: 0.9336926937103271 for ['[CLS]ety xu ( shared australian anyone scenes granted [SEP]']
[Init] best perm rec loss: 0.9307498931884766 for ['[CLS]ety australian xu anyone ( shared granted scenes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.744 (perp=10.898, rec=0.640, cos=0.925), tot_loss_proj:4.056 [t=0.29s]
prediction: ['[CLS] gets final cuttingize ( an registration ; [SEP]']
[ 100/2000] tot_loss=2.028 (perp=8.439, rec=0.285, cos=0.055), tot_loss_proj:3.680 [t=0.30s]
prediction: ['[CLS] our guitar cake cake for father mom. [SEP]']
[ 150/2000] tot_loss=2.058 (perp=9.141, rec=0.202, cos=0.028), tot_loss_proj:3.579 [t=0.30s]
prediction: ['[CLS] my baked cake cake baked mother mom. [SEP]']
[ 200/2000] tot_loss=1.686 (perp=7.656, rec=0.141, cos=0.013), tot_loss_proj:3.521 [t=0.30s]
prediction: ['[CLS] my baked cake cake for mother mother. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.459 (perp=6.334, rec=0.175, cos=0.017), tot_loss_proj:2.046 [t=0.30s]
prediction: ['[CLS] my mother baked cake cake for mother. [SEP]']
[ 300/2000] tot_loss=1.405 (perp=6.334, rec=0.129, cos=0.009), tot_loss_proj:2.047 [t=0.30s]
prediction: ['[CLS] my mother baked cake cake for mother. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.123 (perp=5.096, rec=0.097, cos=0.008), tot_loss_proj:1.624 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for mother. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.287 (perp=5.986, rec=0.086, cos=0.004), tot_loss_proj:2.952 [t=0.30s]
prediction: ['[CLS] my baked a cake for me mother. [SEP]']
[ 450/2000] tot_loss=1.282 (perp=5.986, rec=0.082, cos=0.003), tot_loss_proj:2.948 [t=0.30s]
prediction: ['[CLS] my baked a cake for me mother. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.002 (perp=4.613, rec=0.077, cos=0.002), tot_loss_proj:1.036 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[ 550/2000] tot_loss=0.990 (perp=4.613, rec=0.066, cos=0.002), tot_loss_proj:1.025 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
[ 600/2000] tot_loss=0.985 (perp=4.613, rec=0.060, cos=0.002), tot_loss_proj:1.034 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.983 (perp=4.613, rec=0.059, cos=0.002), tot_loss_proj:1.031 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.989 (perp=4.613, rec=0.064, cos=0.002), tot_loss_proj:1.041 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
[ 750/2000] tot_loss=0.988 (perp=4.613, rec=0.063, cos=0.002), tot_loss_proj:1.036 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.984 (perp=4.613, rec=0.060, cos=0.002), tot_loss_proj:1.025 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.983 (perp=4.613, rec=0.058, cos=0.002), tot_loss_proj:1.050 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
[ 900/2000] tot_loss=0.982 (perp=4.613, rec=0.057, cos=0.002), tot_loss_proj:1.031 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.986 (perp=4.613, rec=0.061, cos=0.002), tot_loss_proj:1.030 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.984 (perp=4.613, rec=0.059, cos=0.002), tot_loss_proj:1.036 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
[1050/2000] tot_loss=0.980 (perp=4.613, rec=0.056, cos=0.002), tot_loss_proj:1.028 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.993 (perp=4.613, rec=0.069, cos=0.002), tot_loss_proj:1.037 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.981 (perp=4.613, rec=0.056, cos=0.002), tot_loss_proj:1.032 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
[1200/2000] tot_loss=0.989 (perp=4.613, rec=0.064, cos=0.002), tot_loss_proj:1.030 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.990 (perp=4.613, rec=0.066, cos=0.002), tot_loss_proj:1.035 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.990 (perp=4.613, rec=0.066, cos=0.002), tot_loss_proj:1.042 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
[1350/2000] tot_loss=0.988 (perp=4.613, rec=0.064, cos=0.002), tot_loss_proj:1.049 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.987 (perp=4.613, rec=0.063, cos=0.002), tot_loss_proj:1.028 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.988 (perp=4.613, rec=0.064, cos=0.002), tot_loss_proj:1.039 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
[1500/2000] tot_loss=0.985 (perp=4.613, rec=0.061, cos=0.002), tot_loss_proj:1.028 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.983 (perp=4.613, rec=0.059, cos=0.002), tot_loss_proj:1.030 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.989 (perp=4.613, rec=0.065, cos=0.002), tot_loss_proj:1.041 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
[1650/2000] tot_loss=0.983 (perp=4.613, rec=0.058, cos=0.002), tot_loss_proj:1.033 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.977 (perp=4.613, rec=0.052, cos=0.002), tot_loss_proj:1.038 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.986 (perp=4.613, rec=0.062, cos=0.002), tot_loss_proj:1.038 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
[1800/2000] tot_loss=0.971 (perp=4.613, rec=0.047, cos=0.002), tot_loss_proj:1.038 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.004 (perp=4.613, rec=0.079, cos=0.002), tot_loss_proj:1.041 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.990 (perp=4.613, rec=0.065, cos=0.002), tot_loss_proj:1.042 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
[1950/2000] tot_loss=0.977 (perp=4.613, rec=0.053, cos=0.002), tot_loss_proj:1.038 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.992 (perp=4.613, rec=0.068, cos=0.002), tot_loss_proj:1.041 [t=0.30s]
prediction: ['[CLS] my mother baked a cake for me. [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] my mother baked a cake for me. [SEP]
========================
predicted: 
========================
[CLS] my mother baked a cake for me. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 77.059 | p: 77.275 | r: 77.116
rouge2     | fm: 36.587 | p: 36.496 | r: 36.722
rougeL     | fm: 68.153 | p: 68.349 | r: 68.172
rougeLsum  | fm: 68.276 | p: 68.521 | r: 68.279
r1fm+r2fm = 113.646

input #77 time: 0:11:48 | total time: 15:31:15


Running input #78 of 100.
reference: 
========================
I read some book.
========================
average of cosine similarity 0.9990179165898692
highest_index [0]
highest [0.9990179165898692]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 3191, 2070, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i read some book. [SEP]']
[Init] best rec loss: 0.9503631591796875 for ['[CLS]ys sponsored ni patience courts [SEP]']
[Init] best rec loss: 0.8474189043045044 for ['[CLS] sealing wrestlemania profile sense ar [SEP]']
[Init] best rec loss: 0.7775192260742188 for ['[CLS] kay escapedonale together tau [SEP]']
[Init] best rec loss: 0.7772237062454224 for ['[CLS] opened blaine clocktour wanted [SEP]']
[Init] best rec loss: 0.7687733173370361 for ['[CLS] quarter d sol been like [SEP]']
[Init] best rec loss: 0.7650765180587769 for ['[CLS] firing degrees talentsfield / [SEP]']
[Init] best perm rec loss: 0.7645819187164307 for ['[CLS] firingsfield talent / degrees [SEP]']
[Init] best perm rec loss: 0.7617564797401428 for ['[CLS] talent firing / degreessfield [SEP]']
[Init] best perm rec loss: 0.7609708309173584 for ['[CLS] firing degrees /sfield talent [SEP]']
[Init] best perm rec loss: 0.760224461555481 for ['[CLS] degreessfield talent / firing [SEP]']
[Init] best perm rec loss: 0.7598955631256104 for ['[CLS] / degrees talent firingsfield [SEP]']
[Init] best perm rec loss: 0.7589638233184814 for ['[CLS] talent degrees firing /sfield [SEP]']
[Init] best perm rec loss: 0.756223201751709 for ['[CLS] degrees talent firing /sfield [SEP]']
[Init] best perm rec loss: 0.7533103227615356 for ['[CLS] / talent degrees firingsfield [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.102 (perp=8.045, rec=0.323, cos=0.169), tot_loss_proj:2.437 [t=0.29s]
prediction: ['[CLS] our watch read some book [SEP]']
[ 100/2000] tot_loss=2.627 (perp=10.720, rec=0.234, cos=0.249), tot_loss_proj:3.002 [t=0.30s]
prediction: ['[CLS]genase reading read some book [SEP]']
[ 150/2000] tot_loss=2.227 (perp=9.587, rec=0.163, cos=0.147), tot_loss_proj:2.970 [t=0.30s]
prediction: ['[CLS] our read read some book [SEP]']
[ 200/2000] tot_loss=2.624 (perp=10.794, rec=0.200, cos=0.265), tot_loss_proj:3.157 [t=0.30s]
prediction: ['[CLS] lillian reminds read some book [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.547 (perp=10.649, rec=0.171, cos=0.246), tot_loss_proj:2.906 [t=0.30s]
prediction: ['[CLS] invited lillian read some book [SEP]']
[ 300/2000] tot_loss=2.658 (perp=11.180, rec=0.191, cos=0.231), tot_loss_proj:3.083 [t=0.30s]
prediction: ['[CLS] jersey lance read some book [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.072 (perp=8.377, rec=0.180, cos=0.217), tot_loss_proj:2.564 [t=0.30s]
prediction: ['[CLS] naive i read some book [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.038 (perp=8.285, rec=0.167, cos=0.214), tot_loss_proj:2.486 [t=0.30s]
prediction: ['[CLS] iea read some book [SEP]']
[ 450/2000] tot_loss=1.836 (perp=7.285, rec=0.175, cos=0.204), tot_loss_proj:1.847 [t=0.30s]
prediction: ['[CLS] i i read some book [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.048 (perp=8.319, rec=0.164, cos=0.220), tot_loss_proj:2.214 [t=0.30s]
prediction: ['[CLS] i read some book ethical [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.033 (perp=8.319, rec=0.158, cos=0.212), tot_loss_proj:2.214 [t=0.30s]
prediction: ['[CLS] i read some book ethical [SEP]']
[ 600/2000] tot_loss=1.994 (perp=8.099, rec=0.166, cos=0.207), tot_loss_proj:2.659 [t=0.30s]
prediction: ['[CLS] i read some bookbid [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.743 (perp=7.490, rec=0.138, cos=0.107), tot_loss_proj:2.449 [t=0.30s]
prediction: ['[CLS] i read some book marcus [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.021 (perp=8.233, rec=0.167, cos=0.208), tot_loss_proj:2.443 [t=0.30s]
prediction: ['[CLS] i read some book ligament [SEP]']
[ 750/2000] tot_loss=1.975 (perp=8.072, rec=0.161, cos=0.199), tot_loss_proj:2.480 [t=0.30s]
prediction: ['[CLS] i read some book ª [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.985 (perp=8.175, rec=0.155, cos=0.195), tot_loss_proj:2.242 [t=0.30s]
prediction: ['[CLS] i read some book tooth [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.991 (perp=8.175, rec=0.163, cos=0.193), tot_loss_proj:2.252 [t=0.30s]
prediction: ['[CLS] i read some book tooth [SEP]']
[ 900/2000] tot_loss=1.971 (perp=8.175, rec=0.146, cos=0.190), tot_loss_proj:2.241 [t=0.30s]
prediction: ['[CLS] i read some book tooth [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.380 (perp=5.182, rec=0.155, cos=0.189), tot_loss_proj:1.158 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.393 (perp=5.182, rec=0.162, cos=0.194), tot_loss_proj:1.151 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
[1050/2000] tot_loss=1.396 (perp=5.182, rec=0.168, cos=0.191), tot_loss_proj:1.161 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.375 (perp=5.182, rec=0.151, cos=0.188), tot_loss_proj:1.160 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.385 (perp=5.182, rec=0.161, cos=0.188), tot_loss_proj:1.149 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
[1200/2000] tot_loss=1.389 (perp=5.182, rec=0.167, cos=0.185), tot_loss_proj:1.159 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.383 (perp=5.182, rec=0.161, cos=0.186), tot_loss_proj:1.156 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.377 (perp=5.182, rec=0.152, cos=0.189), tot_loss_proj:1.153 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
[1350/2000] tot_loss=1.369 (perp=5.182, rec=0.144, cos=0.189), tot_loss_proj:1.150 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.373 (perp=5.182, rec=0.151, cos=0.186), tot_loss_proj:1.151 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.360 (perp=5.182, rec=0.146, cos=0.177), tot_loss_proj:1.152 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
[1500/2000] tot_loss=1.375 (perp=5.182, rec=0.155, cos=0.184), tot_loss_proj:1.162 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.369 (perp=5.182, rec=0.149, cos=0.184), tot_loss_proj:1.156 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.377 (perp=5.182, rec=0.161, cos=0.179), tot_loss_proj:1.152 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
[1650/2000] tot_loss=1.376 (perp=5.182, rec=0.154, cos=0.185), tot_loss_proj:1.149 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.371 (perp=5.182, rec=0.156, cos=0.178), tot_loss_proj:1.157 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.375 (perp=5.182, rec=0.155, cos=0.183), tot_loss_proj:1.161 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
[1800/2000] tot_loss=1.372 (perp=5.182, rec=0.158, cos=0.179), tot_loss_proj:1.165 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.359 (perp=5.182, rec=0.147, cos=0.176), tot_loss_proj:1.154 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.370 (perp=5.182, rec=0.152, cos=0.182), tot_loss_proj:1.155 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
[1950/2000] tot_loss=1.364 (perp=5.182, rec=0.145, cos=0.184), tot_loss_proj:1.144 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.367 (perp=5.182, rec=0.152, cos=0.179), tot_loss_proj:1.167 [t=0.30s]
prediction: ['[CLS] i read some book. [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] i read some book. [SEP]
========================
predicted: 
========================
[CLS] i read some book. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 77.405 | p: 77.554 | r: 77.427
rouge2     | fm: 37.344 | p: 37.362 | r: 37.531
rougeL     | fm: 68.583 | p: 68.790 | r: 68.532
rougeLsum  | fm: 68.749 | p: 68.999 | r: 68.700
r1fm+r2fm = 114.748

input #78 time: 0:11:47 | total time: 15:43:02


Running input #79 of 100.
reference: 
========================
The umpire called it of.
========================
average of cosine similarity 0.9989731918323357
highest_index [0]
highest [0.9989731918323357]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 20887,  2170,  2009,  1997,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the umpire called it of. [SEP]']
[Init] best rec loss: 0.968063235282898 for ['[CLS]tlement gi professional julian reaching wingspan [SEP]']
[Init] best rec loss: 0.9173303246498108 for ['[CLS]ncia welcometedphile vector copyright [SEP]']
[Init] best rec loss: 0.8839430809020996 for ['[CLS] exposure april located cheesequal enough [SEP]']
[Init] best rec loss: 0.8837732672691345 for ['[CLS]rice sonia venture mile femalesvin [SEP]']
[Init] best rec loss: 0.8754832744598389 for ['[CLS] beginning landed some another coastmart [SEP]']
[Init] best rec loss: 0.866349458694458 for ['[CLS] began sleeve stomach x putness [SEP]']
[Init] best perm rec loss: 0.8657019734382629 for ['[CLS] sleeve stomachness began put x [SEP]']
[Init] best perm rec loss: 0.8650756478309631 for ['[CLS] stomach sleeve x beganness put [SEP]']
[Init] best perm rec loss: 0.865041196346283 for ['[CLS]ness sleeve x put began stomach [SEP]']
[Init] best perm rec loss: 0.8644832372665405 for ['[CLS] x sleeve put began stomachness [SEP]']
[Init] best perm rec loss: 0.8618252873420715 for ['[CLS] stomach sleeve began putness x [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.847 (perp=11.674, rec=0.651, cos=0.861), tot_loss_proj:4.276 [t=0.29s]
prediction: ['[CLS]pershorn ecclesiastical mining was really [SEP]']
[ 100/2000] tot_loss=4.091 (perp=12.413, rec=0.645, cos=0.964), tot_loss_proj:4.391 [t=0.30s]
prediction: ['[CLS]pers 4 umpire aiden umpire really [SEP]']
[ 150/2000] tot_loss=3.294 (perp=10.717, rec=0.466, cos=0.685), tot_loss_proj:4.043 [t=0.30s]
prediction: ['[CLS] yeah umpire umpire umpire umpire " [SEP]']
[ 200/2000] tot_loss=3.426 (perp=11.880, rec=0.421, cos=0.629), tot_loss_proj:4.279 [t=0.30s]
prediction: ['[CLS] yeah umpire umpire umpire called almost [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.997 (perp=9.637, rec=0.397, cos=0.673), tot_loss_proj:3.875 [t=0.30s]
prediction: ['[CLS] umpire umpire umpire yeah called it [SEP]']
[ 300/2000] tot_loss=2.951 (perp=9.637, rec=0.335, cos=0.688), tot_loss_proj:3.873 [t=0.30s]
prediction: ['[CLS] umpire umpire umpire yeah called it [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.372 (perp=11.222, rec=0.415, cos=0.713), tot_loss_proj:4.109 [t=0.30s]
prediction: ['[CLS] umpire umpire umpire didn called it [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.784 (perp=8.882, rec=0.336, cos=0.671), tot_loss_proj:3.697 [t=0.30s]
prediction: ['[CLS] umpire umpire erich umpire called it [SEP]']
[ 450/2000] tot_loss=3.246 (perp=10.747, rec=0.336, cos=0.761), tot_loss_proj:4.079 [t=0.30s]
prediction: ['[CLS] alex umpire erich umpire called it [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.212 (perp=11.159, rec=0.287, cos=0.694), tot_loss_proj:4.122 [t=0.38s]
prediction: ['[CLS] umpireitis umpire erich called it [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.967 (perp=10.059, rec=0.285, cos=0.670), tot_loss_proj:4.005 [t=0.30s]
prediction: ['[CLS] umpireitisiness umpire called it [SEP]']
[ 600/2000] tot_loss=3.105 (perp=10.798, rec=0.272, cos=0.673), tot_loss_proj:4.165 [t=0.30s]
prediction: ['[CLS] umpireাiness umpire called it [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.317 (perp=11.988, rec=0.270, cos=0.650), tot_loss_proj:4.142 [t=0.30s]
prediction: ['[CLS] umpire umpire browsdim called it [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.194 (perp=11.338, rec=0.263, cos=0.664), tot_loss_proj:4.207 [t=0.30s]
prediction: ['[CLS] umpire umpireinessা called it [SEP]']
[ 750/2000] tot_loss=2.975 (perp=10.353, rec=0.250, cos=0.654), tot_loss_proj:3.967 [t=0.30s]
prediction: ['[CLS] umpire umpiredimা called it [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.965 (perp=10.353, rec=0.245, cos=0.649), tot_loss_proj:3.970 [t=0.30s]
prediction: ['[CLS] umpire umpiredimা called it [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.970 (perp=10.353, rec=0.248, cos=0.651), tot_loss_proj:3.967 [t=0.30s]
prediction: ['[CLS] umpire umpiredimা called it [SEP]']
[ 900/2000] tot_loss=2.963 (perp=10.353, rec=0.241, cos=0.651), tot_loss_proj:3.967 [t=0.30s]
prediction: ['[CLS] umpire umpiredimা called it [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.955 (perp=10.353, rec=0.237, cos=0.647), tot_loss_proj:3.970 [t=0.30s]
prediction: ['[CLS] umpire umpiredimা called it [SEP]']
Attempt swap
[1000/2000] tot_loss=2.972 (perp=10.353, rec=0.247, cos=0.654), tot_loss_proj:3.965 [t=0.30s]
prediction: ['[CLS] umpire umpiredimা called it [SEP]']
[1050/2000] tot_loss=3.105 (perp=11.045, rec=0.242, cos=0.654), tot_loss_proj:4.080 [t=0.30s]
prediction: ['[CLS] umpire umpireulouslyা called it [SEP]']
Attempt swap
[1100/2000] tot_loss=3.100 (perp=11.045, rec=0.233, cos=0.658), tot_loss_proj:4.082 [t=0.30s]
prediction: ['[CLS] umpire umpireulouslyা called it [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=3.028 (perp=10.645, rec=0.249, cos=0.651), tot_loss_proj:4.077 [t=0.30s]
prediction: ['[CLS] umpire umpireাulously called it [SEP]']
[1200/2000] tot_loss=3.052 (perp=10.744, rec=0.246, cos=0.657), tot_loss_proj:4.100 [t=0.30s]
prediction: ['[CLS] umpire umpire browsulously called it [SEP]']
Attempt swap
[1250/2000] tot_loss=3.029 (perp=10.744, rec=0.232, cos=0.648), tot_loss_proj:4.096 [t=0.30s]
prediction: ['[CLS] umpire umpire browsulously called it [SEP]']
Attempt swap
[1300/2000] tot_loss=3.039 (perp=10.744, rec=0.239, cos=0.651), tot_loss_proj:4.095 [t=0.30s]
prediction: ['[CLS] umpire umpire browsulously called it [SEP]']
[1350/2000] tot_loss=2.966 (perp=10.390, rec=0.234, cos=0.654), tot_loss_proj:3.994 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
Attempt swap
[1400/2000] tot_loss=2.964 (perp=10.390, rec=0.232, cos=0.653), tot_loss_proj:3.995 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
Attempt swap
[1450/2000] tot_loss=2.962 (perp=10.390, rec=0.235, cos=0.649), tot_loss_proj:4.002 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
[1500/2000] tot_loss=2.957 (perp=10.390, rec=0.227, cos=0.652), tot_loss_proj:4.000 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
Attempt swap
[1550/2000] tot_loss=2.962 (perp=10.390, rec=0.235, cos=0.649), tot_loss_proj:4.003 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
Attempt swap
[1600/2000] tot_loss=2.957 (perp=10.390, rec=0.230, cos=0.649), tot_loss_proj:3.995 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
[1650/2000] tot_loss=2.961 (perp=10.390, rec=0.230, cos=0.653), tot_loss_proj:4.003 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
Attempt swap
[1700/2000] tot_loss=2.965 (perp=10.390, rec=0.239, cos=0.648), tot_loss_proj:3.993 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
Attempt swap
[1750/2000] tot_loss=2.951 (perp=10.390, rec=0.223, cos=0.650), tot_loss_proj:4.002 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
[1800/2000] tot_loss=2.969 (perp=10.390, rec=0.243, cos=0.648), tot_loss_proj:4.003 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
Attempt swap
[1850/2000] tot_loss=2.961 (perp=10.390, rec=0.236, cos=0.647), tot_loss_proj:3.997 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
Attempt swap
[1900/2000] tot_loss=2.957 (perp=10.390, rec=0.230, cos=0.649), tot_loss_proj:4.000 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
[1950/2000] tot_loss=2.957 (perp=10.390, rec=0.229, cos=0.650), tot_loss_proj:4.007 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
Attempt swap
[2000/2000] tot_loss=2.958 (perp=10.390, rec=0.230, cos=0.649), tot_loss_proj:4.000 [t=0.30s]
prediction: ['[CLS] umpire umpiredesulously called it [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] the umpire called it of. [SEP]
========================
predicted: 
========================
[CLS] umpire umpiredesulously called it [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 18.182 | p: 20.000 | r: 16.667
rougeL     | fm: 76.923 | p: 83.333 | r: 71.429
rougeLsum  | fm: 76.923 | p: 83.333 | r: 71.429
r1fm+r2fm = 95.105

[Aggregate metrics]:
rouge1     | fm: 77.430 | p: 77.643 | r: 77.391
rouge2     | fm: 37.132 | p: 37.095 | r: 37.269
rougeL     | fm: 68.627 | p: 68.998 | r: 68.581
rougeLsum  | fm: 68.731 | p: 69.083 | r: 68.677
r1fm+r2fm = 114.561

input #79 time: 0:11:46 | total time: 15:54:49


Running input #80 of 100.
reference: 
========================
The rock placed the sky with the fork.
========================
average of cosine similarity 0.9986766167162485
highest_index [0]
highest [0.9986766167162485]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2600, 2872, 1996, 3712, 2007, 1996, 9292, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the rock placed the sky with the fork. [SEP]']
[Init] best rec loss: 0.9664384126663208 for ['[CLS] female scared marcus humble ramp bracket hybrid marieeur [SEP]']
[Init] best rec loss: 0.9662346243858337 for ['[CLS] janr afterward city necessary trans him raced fis [SEP]']
[Init] best rec loss: 0.7657288312911987 for ['[CLS] kind plan loft [MASK]?elin unincorporated beard points [SEP]']
[Init] best rec loss: 0.7516055703163147 for ['[CLS] rib our ball spelling asleepille oval ash teaching [SEP]']
[Init] best rec loss: 0.7415622472763062 for ['[CLS] shot consequences piano colby la added inside whom gundam [SEP]']
[Init] best rec loss: 0.7292668223381042 for ['[CLS] jin while putting hull joining divine cry transferring construction [SEP]']
[Init] best rec loss: 0.7262369990348816 for ["[CLS] cassie guy preneas lake more'rocker jury [SEP]"]
[Init] best rec loss: 0.7215522527694702 for ['[CLS]ner votes standardrea churchesr works designated colt [SEP]']
[Init] best rec loss: 0.7161760330200195 for ['[CLS] river lord greta moved strange mall remainingbaldi powerful [SEP]']
[Init] best rec loss: 0.7016469240188599 for ['[CLS] minute combat affected schedule medieval apting sotu [SEP]']
[Init] best perm rec loss: 0.6955555081367493 for ['[CLS]tu medieval so scheduleting affected ap combat minute [SEP]']
[Init] best perm rec loss: 0.694586455821991 for ['[CLS] combatting ap affected schedule medieval minutetu so [SEP]']
[Init] best perm rec loss: 0.6936271786689758 for ['[CLS] scheduletu ap so medieval combatting minute affected [SEP]']
[Init] best perm rec loss: 0.6913289427757263 for ['[CLS] ap minuteting schedule medieval sotu affected combat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.160 (perp=9.682, rec=0.208, cos=0.015), tot_loss_proj:2.732 [t=0.29s]
prediction: ['[CLS] the rock placed the sky sky placed sky fork [SEP]']
[ 100/2000] tot_loss=1.828 (perp=8.245, rec=0.162, cos=0.016), tot_loss_proj:2.382 [t=0.30s]
prediction: ['[CLS] the rock placed the sky fork placed sky fork [SEP]']
[ 150/2000] tot_loss=1.791 (perp=8.245, rec=0.130, cos=0.012), tot_loss_proj:2.360 [t=0.30s]
prediction: ['[CLS] the rock placed the sky fork placed sky fork [SEP]']
[ 200/2000] tot_loss=2.041 (perp=9.533, rec=0.121, cos=0.014), tot_loss_proj:2.349 [t=0.30s]
prediction: ['[CLS] the rock placed the sky with placed fork fork [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.985 (perp=8.827, rec=0.206, cos=0.014), tot_loss_proj:2.480 [t=0.30s]
prediction: ['[CLS] the rock placed the sky with fork placed fork [SEP]']
[ 300/2000] tot_loss=1.910 (perp=8.827, rec=0.135, cos=0.009), tot_loss_proj:2.251 [t=0.30s]
prediction: ['[CLS] the rock placed the sky with fork placed fork [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.749 (perp=8.114, rec=0.118, cos=0.008), tot_loss_proj:2.121 [t=0.30s]
prediction: ['[CLS] the rock placed fork sky with the fork fork [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.899 (perp=8.787, rec=0.134, cos=0.008), tot_loss_proj:2.527 [t=0.30s]
prediction: ['[CLS] the rock considered placed fork sky with the fork [SEP]']
[ 450/2000] tot_loss=1.896 (perp=8.866, rec=0.115, cos=0.008), tot_loss_proj:2.549 [t=0.30s]
prediction: ['[CLS] the rock split placed fork sky with the fork [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.615 (perp=7.525, rec=0.103, cos=0.008), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] the rock fork placed fork sky with the fork [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.620 (perp=7.525, rec=0.107, cos=0.008), tot_loss_proj:2.059 [t=0.30s]
prediction: ['[CLS] the rock fork placed fork sky with the fork [SEP]']
[ 600/2000] tot_loss=1.612 (perp=7.525, rec=0.099, cos=0.008), tot_loss_proj:2.051 [t=0.30s]
prediction: ['[CLS] the rock fork placed fork sky with the fork [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.677 (perp=7.818, rec=0.105, cos=0.009), tot_loss_proj:2.377 [t=0.30s]
prediction: ['[CLS] the rock fork sky split placed with the fork [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.549 (perp=7.178, rec=0.104, cos=0.009), tot_loss_proj:2.924 [t=0.30s]
prediction: ['[CLS] the rock fork sky split with the fork placed [SEP]']
[ 750/2000] tot_loss=1.549 (perp=7.178, rec=0.103, cos=0.010), tot_loss_proj:2.933 [t=0.30s]
prediction: ['[CLS] the rock fork sky split with the fork placed [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.554 (perp=7.178, rec=0.108, cos=0.011), tot_loss_proj:2.931 [t=0.30s]
prediction: ['[CLS] the rock fork sky split with the fork placed [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.544 (perp=7.178, rec=0.097, cos=0.012), tot_loss_proj:2.927 [t=0.30s]
prediction: ['[CLS] the rock fork sky split with the fork placed [SEP]']
[ 900/2000] tot_loss=1.810 (perp=8.481, rec=0.102, cos=0.012), tot_loss_proj:3.187 [t=0.30s]
prediction: ['[CLS] the rock fork skygenase with the fork placed [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.705 (perp=7.977, rec=0.099, cos=0.011), tot_loss_proj:2.547 [t=0.30s]
prediction: ['[CLS] the rock fork sky with the fork placed separating [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.600 (perp=7.482, rec=0.093, cos=0.011), tot_loss_proj:2.547 [t=0.30s]
prediction: ['[CLS] the rock fork sky with the separating fork placed [SEP]']
[1050/2000] tot_loss=1.602 (perp=7.482, rec=0.094, cos=0.012), tot_loss_proj:2.557 [t=0.30s]
prediction: ['[CLS] the rock fork sky with the separating fork placed [SEP]']
Attempt swap
[1100/2000] tot_loss=1.608 (perp=7.482, rec=0.100, cos=0.012), tot_loss_proj:2.554 [t=0.30s]
prediction: ['[CLS] the rock fork sky with the separating fork placed [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.567 (perp=7.314, rec=0.095, cos=0.009), tot_loss_proj:2.221 [t=0.30s]
prediction: ['[CLS] the rock fork sky separating with the fork placed [SEP]']
[1200/2000] tot_loss=1.578 (perp=7.314, rec=0.103, cos=0.012), tot_loss_proj:2.219 [t=0.30s]
prediction: ['[CLS] the rock fork sky separating with the fork placed [SEP]']
Attempt swap
[1250/2000] tot_loss=1.586 (perp=7.314, rec=0.111, cos=0.013), tot_loss_proj:2.219 [t=0.30s]
prediction: ['[CLS] the rock fork sky separating with the fork placed [SEP]']
Attempt swap
[1300/2000] tot_loss=1.574 (perp=7.314, rec=0.099, cos=0.013), tot_loss_proj:2.211 [t=0.30s]
prediction: ['[CLS] the rock fork sky separating with the fork placed [SEP]']
[1350/2000] tot_loss=1.579 (perp=7.314, rec=0.103, cos=0.013), tot_loss_proj:2.215 [t=0.30s]
prediction: ['[CLS] the rock fork sky separating with the fork placed [SEP]']
Attempt swap
[1400/2000] tot_loss=1.576 (perp=7.314, rec=0.100, cos=0.013), tot_loss_proj:2.212 [t=0.30s]
prediction: ['[CLS] the rock fork sky separating with the fork placed [SEP]']
Attempt swap
[1450/2000] tot_loss=1.578 (perp=7.314, rec=0.103, cos=0.012), tot_loss_proj:2.219 [t=0.30s]
prediction: ['[CLS] the rock fork sky separating with the fork placed [SEP]']
[1500/2000] tot_loss=1.571 (perp=7.314, rec=0.096, cos=0.012), tot_loss_proj:2.221 [t=0.30s]
prediction: ['[CLS] the rock fork sky separating with the fork placed [SEP]']
Attempt swap
[1550/2000] tot_loss=1.566 (perp=7.314, rec=0.091, cos=0.012), tot_loss_proj:2.211 [t=0.30s]
prediction: ['[CLS] the rock fork sky separating with the fork placed [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.606 (perp=7.482, rec=0.098, cos=0.012), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] the rock fork sky with the separating fork placed [SEP]']
[1650/2000] tot_loss=1.732 (perp=8.137, rec=0.091, cos=0.013), tot_loss_proj:2.539 [t=0.30s]
prediction: ['[CLS] the rock fork sky with thegenase fork placed [SEP]']
Attempt swap
[1700/2000] tot_loss=1.735 (perp=8.137, rec=0.094, cos=0.013), tot_loss_proj:2.545 [t=0.30s]
prediction: ['[CLS] the rock fork sky with thegenase fork placed [SEP]']
Attempt swap
[1750/2000] tot_loss=1.728 (perp=8.137, rec=0.088, cos=0.013), tot_loss_proj:2.551 [t=0.30s]
prediction: ['[CLS] the rock fork sky with thegenase fork placed [SEP]']
[1800/2000] tot_loss=1.719 (perp=8.137, rec=0.079, cos=0.013), tot_loss_proj:2.544 [t=0.30s]
prediction: ['[CLS] the rock fork sky with thegenase fork placed [SEP]']
Attempt swap
[1850/2000] tot_loss=1.739 (perp=8.137, rec=0.098, cos=0.013), tot_loss_proj:2.548 [t=0.30s]
prediction: ['[CLS] the rock fork sky with thegenase fork placed [SEP]']
Attempt swap
[1900/2000] tot_loss=1.738 (perp=8.137, rec=0.098, cos=0.013), tot_loss_proj:2.542 [t=0.30s]
prediction: ['[CLS] the rock fork sky with thegenase fork placed [SEP]']
[1950/2000] tot_loss=1.731 (perp=8.137, rec=0.090, cos=0.013), tot_loss_proj:2.550 [t=0.30s]
prediction: ['[CLS] the rock fork sky with thegenase fork placed [SEP]']
Attempt swap
[2000/2000] tot_loss=1.731 (perp=8.137, rec=0.090, cos=0.013), tot_loss_proj:2.545 [t=0.30s]
prediction: ['[CLS] the rock fork sky with thegenase fork placed [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] the rock placed the sky with the fork. [SEP]
========================
predicted: 
========================
[CLS] the rock fork sky with thegenase fork placed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 113.333

[Aggregate metrics]:
rouge1     | fm: 77.456 | p: 77.692 | r: 77.386
rouge2     | fm: 37.206 | p: 37.166 | r: 37.370
rougeL     | fm: 68.626 | p: 68.960 | r: 68.529
rougeLsum  | fm: 68.797 | p: 69.064 | r: 68.692
r1fm+r2fm = 114.662

input #80 time: 0:11:48 | total time: 16:06:37


Running input #81 of 100.
reference: 
========================
Tagalog is speaks in the Philippines.
========================
average of cosine similarity 0.9987304207738295
highest_index [0]
highest [0.9987304207738295]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  6415, 23067,  2290,  2003,  8847,  1999,  1996,  5137,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] tagalog is speaks in the philippines. [SEP]']
[Init] best rec loss: 0.7980260252952576 for ['[CLS]lch scotland uhf qualifying claude worse attempt faye costs [SEP]']
[Init] best rec loss: 0.7414441704750061 for ['[CLS] college school hismic nord mate genes transfer heir [SEP]']
[Init] best rec loss: 0.7358164191246033 for ['[CLS] extraburo and committed method pali co guess ir [SEP]']
[Init] best rec loss: 0.6809359788894653 for ['[CLS]ei understand turn infrastructure galley project tracks annual [SEP]']
[Init] best rec loss: 0.6759877800941467 for ['[CLS] establishment membership cameo jesse overland fires squad vera key [SEP]']
[Init] best rec loss: 0.6712581515312195 for ['[CLS] opened grtain ft slow lattice season brake miriam [SEP]']
[Init] best rec loss: 0.664021909236908 for ['[CLS]ioned flooded responsible amazon porter tutor cloak tier pretty [SEP]']
[Init] best rec loss: 0.6548337340354919 for ['[CLS] has kowalski part case jericho money though stuck holy [SEP]']
[Init] best rec loss: 0.6540189385414124 for ['[CLS]mba biggerusdock be named kill hit standards [SEP]']
[Init] best perm rec loss: 0.6531936526298523 for ['[CLS] standards bigger namedusmba be hitdock kill [SEP]']
[Init] best perm rec loss: 0.6528332233428955 for ['[CLS]dock bigger namedus hitmba kill be standards [SEP]']
[Init] best perm rec loss: 0.6490857601165771 for ['[CLS] standardsdock kill named be biggerusmba hit [SEP]']
[Init] best perm rec loss: 0.6482945680618286 for ['[CLS] nameddock be standardsmbaus kill hit bigger [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.119 (perp=11.666, rec=0.564, cos=0.222), tot_loss_proj:3.266 [t=0.29s]
prediction: ['[CLS] easily vampires wind has toy. yankeeulously walked [SEP]']
[ 100/2000] tot_loss=2.932 (perp=11.109, rec=0.503, cos=0.207), tot_loss_proj:3.030 [t=0.30s]
prediction: ['[CLS] always ninja american is voice spoke yankee grounds walked [SEP]']
[ 150/2000] tot_loss=2.845 (perp=11.197, rec=0.377, cos=0.229), tot_loss_proj:3.033 [t=0.30s]
prediction: ['[CLS] againtag filipino is voted speaks philippines where stroked [SEP]']
[ 200/2000] tot_loss=2.841 (perp=11.677, rec=0.301, cos=0.204), tot_loss_proj:3.224 [t=0.30s]
prediction: ['[CLS] againg philippines is wwe speaks philippinesoki held [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.797 (perp=11.112, rec=0.335, cos=0.240), tot_loss_proj:3.155 [t=0.30s]
prediction: ['[CLS] suddenly philippines is wwe philippines speaks philippines tarzan championships [SEP]']
[ 300/2000] tot_loss=2.705 (perp=10.993, rec=0.283, cos=0.224), tot_loss_proj:3.013 [t=0.30s]
prediction: ['[CLS] beingsg is wwe philippines speaks philippines tarzan like [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.513 (perp=10.181, rec=0.265, cos=0.212), tot_loss_proj:2.818 [t=0.30s]
prediction: ['[CLS] beingsg is wwe philippines speaks philippines like tarzan [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.859 (perp=12.054, rec=0.251, cos=0.198), tot_loss_proj:3.221 [t=0.30s]
prediction: ['[CLS] suddenlyg is wwe philippines speaks philippinesog down [SEP]']
[ 450/2000] tot_loss=2.903 (perp=12.342, rec=0.235, cos=0.199), tot_loss_proj:3.329 [t=0.30s]
prediction: ['[CLS] suddenlyg is! philippines speaks philippinesog beside [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.639 (perp=10.990, rec=0.250, cos=0.191), tot_loss_proj:3.038 [t=0.30s]
prediction: ['[CLS] wetg is aiden philippines speaks philippines suddenly down [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.788 (perp=11.735, rec=0.244, cos=0.197), tot_loss_proj:3.213 [t=0.30s]
prediction: ['[CLS] nasag is when philippines speaks philippines aiden beside [SEP]']
[ 600/2000] tot_loss=2.752 (perp=11.735, rec=0.227, cos=0.179), tot_loss_proj:3.211 [t=0.30s]
prediction: ['[CLS] nasag is when philippines speaks philippines aiden beside [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.767 (perp=11.856, rec=0.217, cos=0.179), tot_loss_proj:3.114 [t=0.30s]
prediction: ['[CLS] suffixg is when philippines speaks attended aiden philippines [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.652 (perp=11.296, rec=0.231, cos=0.161), tot_loss_proj:3.056 [t=0.30s]
prediction: ['[CLS] suffixg is when philippines speaks attended philippines liam [SEP]']
[ 750/2000] tot_loss=2.586 (perp=11.075, rec=0.210, cos=0.161), tot_loss_proj:3.035 [t=0.30s]
prediction: ['[CLS] engineersg is when philippines speaks beside philippines liam [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.595 (perp=11.075, rec=0.221, cos=0.159), tot_loss_proj:3.030 [t=0.30s]
prediction: ['[CLS] engineersg is when philippines speaks beside philippines liam [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.370 (perp=9.944, rec=0.221, cos=0.160), tot_loss_proj:2.915 [t=0.30s]
prediction: ['[CLS] engineersg is when philippines speaks at philippines during [SEP]']
[ 900/2000] tot_loss=2.366 (perp=9.944, rec=0.219, cos=0.158), tot_loss_proj:2.919 [t=0.30s]
prediction: ['[CLS] engineersg is when philippines speaks at philippines during [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.252 (perp=9.397, rec=0.215, cos=0.157), tot_loss_proj:2.764 [t=0.30s]
prediction: ['[CLS] suffixg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1000/2000] tot_loss=2.250 (perp=9.397, rec=0.213, cos=0.157), tot_loss_proj:2.769 [t=0.30s]
prediction: ['[CLS] suffixg is when philippines speaks at philippines during [SEP]']
[1050/2000] tot_loss=2.235 (perp=9.397, rec=0.201, cos=0.154), tot_loss_proj:2.766 [t=0.30s]
prediction: ['[CLS] suffixg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1100/2000] tot_loss=2.237 (perp=9.397, rec=0.205, cos=0.153), tot_loss_proj:2.767 [t=0.30s]
prediction: ['[CLS] suffixg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1150/2000] tot_loss=2.231 (perp=9.397, rec=0.205, cos=0.147), tot_loss_proj:2.766 [t=0.30s]
prediction: ['[CLS] suffixg is when philippines speaks at philippines during [SEP]']
[1200/2000] tot_loss=2.223 (perp=9.397, rec=0.201, cos=0.143), tot_loss_proj:2.758 [t=0.30s]
prediction: ['[CLS] suffixg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1250/2000] tot_loss=2.222 (perp=9.397, rec=0.200, cos=0.142), tot_loss_proj:2.768 [t=0.30s]
prediction: ['[CLS] suffixg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1300/2000] tot_loss=2.225 (perp=9.397, rec=0.204, cos=0.141), tot_loss_proj:2.764 [t=0.30s]
prediction: ['[CLS] suffixg is when philippines speaks at philippines during [SEP]']
[1350/2000] tot_loss=2.264 (perp=9.562, rec=0.212, cos=0.140), tot_loss_proj:2.972 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1400/2000] tot_loss=2.254 (perp=9.562, rec=0.205, cos=0.137), tot_loss_proj:2.967 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1450/2000] tot_loss=2.251 (perp=9.562, rec=0.203, cos=0.136), tot_loss_proj:2.967 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
[1500/2000] tot_loss=2.255 (perp=9.562, rec=0.208, cos=0.135), tot_loss_proj:2.969 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1550/2000] tot_loss=2.246 (perp=9.562, rec=0.199, cos=0.135), tot_loss_proj:2.966 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1600/2000] tot_loss=2.239 (perp=9.562, rec=0.192, cos=0.134), tot_loss_proj:2.970 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
[1650/2000] tot_loss=2.244 (perp=9.562, rec=0.198, cos=0.133), tot_loss_proj:2.968 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1700/2000] tot_loss=2.248 (perp=9.562, rec=0.202, cos=0.134), tot_loss_proj:2.966 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1750/2000] tot_loss=2.256 (perp=9.562, rec=0.209, cos=0.134), tot_loss_proj:2.973 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
[1800/2000] tot_loss=2.247 (perp=9.562, rec=0.202, cos=0.133), tot_loss_proj:2.965 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1850/2000] tot_loss=2.243 (perp=9.562, rec=0.198, cos=0.133), tot_loss_proj:2.969 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
Attempt swap
[1900/2000] tot_loss=2.254 (perp=9.562, rec=0.208, cos=0.133), tot_loss_proj:2.963 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
[1950/2000] tot_loss=2.249 (perp=9.562, rec=0.204, cos=0.133), tot_loss_proj:2.970 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
Attempt swap
[2000/2000] tot_loss=2.246 (perp=9.562, rec=0.201, cos=0.132), tot_loss_proj:2.967 [t=0.30s]
prediction: ['[CLS]mg is when philippines speaks at philippines during [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] tagalog is speaks in the philippines. [SEP]
========================
predicted: 
========================
[CLS]mg is when philippines speaks at philippines during [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 55.556 | p: 50.000 | r: 62.500
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 55.556 | p: 50.000 | r: 62.500
rougeLsum  | fm: 55.556 | p: 50.000 | r: 62.500
r1fm+r2fm = 55.556

[Aggregate metrics]:
rouge1     | fm: 77.205 | p: 77.404 | r: 77.212
rouge2     | fm: 36.829 | p: 36.835 | r: 36.935
rougeL     | fm: 68.541 | p: 68.733 | r: 68.468
rougeLsum  | fm: 68.559 | p: 68.817 | r: 68.598
r1fm+r2fm = 114.034

input #81 time: 0:11:48 | total time: 16:18:26


Running input #82 of 100.
reference: 
========================
He waltzed her across the floor.
========================
average of cosine similarity 0.9987588026469576
highest_index [0]
highest [0.9987588026469576]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2002, 17569,  2098,  2014,  2408,  1996,  2723,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] he waltzed her across the floor. [SEP]']
[Init] best rec loss: 0.9722084403038025 for ['[CLS] beverly womenboat [MASK] greatly waterfold bears [SEP]']
[Init] best rec loss: 0.962834358215332 for ['[CLS] because star usc but ginger boltontial nat [SEP]']
[Init] best rec loss: 0.9258573651313782 for ['[CLS] like then riding couple essential researching roughly boys [SEP]']
[Init] best rec loss: 0.917722761631012 for ['[CLS] eastern contestedr apparently betweenti field medal [SEP]']
[Init] best rec loss: 0.9142358899116516 for ['[CLS]yreang mythopped older jackson cause ɡ [SEP]']
[Init] best rec loss: 0.9110870361328125 for ['[CLS] warie tea qualify penetration dr cecil holly [SEP]']
[Init] best rec loss: 0.9090560078620911 for ['[CLS]ness indies tessa origin quarterback yeah keen crow [SEP]']
[Init] best rec loss: 0.8917288184165955 for ['[CLS] fraternity concern there times menu stoptford studio [SEP]']
[Init] best rec loss: 0.8872382044792175 for ['[CLS] soy driving rank cotton precedence pleaded below brother [SEP]']
[Init] best rec loss: 0.8729261755943298 for ['[CLS] needed brieflyuth doing further here those honour [SEP]']
[Init] best rec loss: 0.8690417408943176 for ['[CLS]lite race support loan university m process el [SEP]']
[Init] best perm rec loss: 0.8652682900428772 for ['[CLS] el loan process support race mlite university [SEP]']
[Init] best perm rec loss: 0.865179717540741 for ['[CLS] el process race mlite loan support university [SEP]']
[Init] best perm rec loss: 0.8641016483306885 for ['[CLS] el race loan m support university processlite [SEP]']
[Init] best perm rec loss: 0.8628941178321838 for ['[CLS] loan m process university support ellite race [SEP]']
[Init] best perm rec loss: 0.8627398014068604 for ['[CLS] m support loan race process el universitylite [SEP]']
[Init] best perm rec loss: 0.861785352230072 for ['[CLS] el process race support m university loanlite [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.992 (perp=12.991, rec=0.534, cos=0.860), tot_loss_proj:4.573 [t=0.29s]
prediction: ['[CLS] version mozart waltz these wineated pistols fairly [SEP]']
[ 100/2000] tot_loss=3.811 (perp=12.315, rec=0.500, cos=0.848), tot_loss_proj:4.381 [t=0.30s]
prediction: ['[CLS]reate waltz waltz townshiper gasoline waltz : [SEP]']
[ 150/2000] tot_loss=3.336 (perp=10.256, rec=0.428, cos=0.857), tot_loss_proj:4.030 [t=0.30s]
prediction: ['[CLS] croatian waltz waltz relative radializes waltz : [SEP]']
[ 200/2000] tot_loss=3.678 (perp=12.352, rec=0.384, cos=0.824), tot_loss_proj:4.440 [t=0.30s]
prediction: ['[CLS] floor waltz waltz filmfare herizes waltz across [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.077 (perp=9.242, rec=0.386, cos=0.842), tot_loss_proj:3.798 [t=0.30s]
prediction: ['[CLS] waltz rushes waltz waltz herizes waltz. [SEP]']
[ 300/2000] tot_loss=3.323 (perp=9.950, rec=0.440, cos=0.893), tot_loss_proj:3.922 [t=0.30s]
prediction: ['[CLS] waltz rushes waltz waltz acrossizes waltz. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.042 (perp=9.553, rec=0.323, cos=0.809), tot_loss_proj:3.781 [t=0.30s]
prediction: ['[CLS] eyebrows waltz waltz waltz across floor rushes. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.030 (perp=9.417, rec=0.348, cos=0.799), tot_loss_proj:3.781 [t=0.30s]
prediction: ['[CLS] eyebrows waltz across waltz waltzed rushes. [SEP]']
[ 450/2000] tot_loss=3.174 (perp=9.804, rec=0.330, cos=0.883), tot_loss_proj:3.861 [t=0.30s]
prediction: ['[CLS] eyebrows waltz across waltz waltzed equity. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.112 (perp=10.245, rec=0.284, cos=0.780), tot_loss_proj:3.885 [t=0.30s]
prediction: ['[CLS] jeremy waltz across waltz waltzed eyebrows. [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.069 (perp=9.998, rec=0.271, cos=0.799), tot_loss_proj:3.807 [t=0.30s]
prediction: ['[CLS]riety waltz across waltz waltz her garth. [SEP]']
[ 600/2000] tot_loss=3.164 (perp=10.571, rec=0.264, cos=0.786), tot_loss_proj:3.906 [t=0.30s]
prediction: ['[CLS]riety across across waltz waltz her garth. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.210 (perp=10.612, rec=0.302, cos=0.785), tot_loss_proj:3.892 [t=0.30s]
prediction: ['[CLS]riety across waltz waltzd her garth. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.072 (perp=10.096, rec=0.282, cos=0.771), tot_loss_proj:3.864 [t=0.30s]
prediction: ['[CLS]d across waltz waltzriety her necessarily. [SEP]']
[ 750/2000] tot_loss=3.057 (perp=10.096, rec=0.262, cos=0.775), tot_loss_proj:3.867 [t=0.30s]
prediction: ['[CLS]d across waltz waltzriety her necessarily. [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.012 (perp=9.873, rec=0.252, cos=0.785), tot_loss_proj:3.821 [t=0.30s]
prediction: ['[CLS]ed across waltz waltzriety her necessarily. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.998 (perp=9.873, rec=0.240, cos=0.784), tot_loss_proj:3.824 [t=0.30s]
prediction: ['[CLS]ed across waltz waltzriety her necessarily. [SEP]']
[ 900/2000] tot_loss=3.016 (perp=9.873, rec=0.252, cos=0.790), tot_loss_proj:3.820 [t=0.30s]
prediction: ['[CLS]ed across waltz waltzriety her necessarily. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.009 (perp=9.873, rec=0.248, cos=0.786), tot_loss_proj:3.819 [t=0.30s]
prediction: ['[CLS]ed across waltz waltzriety her necessarily. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.005 (perp=9.873, rec=0.249, cos=0.781), tot_loss_proj:3.820 [t=0.30s]
prediction: ['[CLS]ed across waltz waltzriety her necessarily. [SEP]']
[1050/2000] tot_loss=3.222 (perp=10.969, rec=0.241, cos=0.787), tot_loss_proj:4.039 [t=0.30s]
prediction: ['[CLS]ed acrossed waltzriety her necessarily. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.013 (perp=9.958, rec=0.244, cos=0.778), tot_loss_proj:3.811 [t=0.30s]
prediction: ['[CLS]ed acrossriety waltzed her necessarily. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.687 (perp=8.211, rec=0.256, cos=0.789), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
[1200/2000] tot_loss=2.654 (perp=8.211, rec=0.232, cos=0.780), tot_loss_proj:3.555 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.671 (perp=8.211, rec=0.250, cos=0.779), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.661 (perp=8.211, rec=0.239, cos=0.779), tot_loss_proj:3.555 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
[1350/2000] tot_loss=2.654 (perp=8.211, rec=0.232, cos=0.780), tot_loss_proj:3.556 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.653 (perp=8.211, rec=0.231, cos=0.780), tot_loss_proj:3.554 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.656 (perp=8.211, rec=0.235, cos=0.779), tot_loss_proj:3.559 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
[1500/2000] tot_loss=2.652 (perp=8.211, rec=0.233, cos=0.777), tot_loss_proj:3.556 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.656 (perp=8.211, rec=0.230, cos=0.784), tot_loss_proj:3.554 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.653 (perp=8.211, rec=0.230, cos=0.781), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
[1650/2000] tot_loss=2.659 (perp=8.211, rec=0.236, cos=0.781), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.663 (perp=8.211, rec=0.236, cos=0.784), tot_loss_proj:3.550 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.650 (perp=8.211, rec=0.228, cos=0.780), tot_loss_proj:3.559 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
[1800/2000] tot_loss=2.652 (perp=8.211, rec=0.229, cos=0.780), tot_loss_proj:3.551 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.658 (perp=8.211, rec=0.234, cos=0.782), tot_loss_proj:3.553 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.658 (perp=8.211, rec=0.231, cos=0.785), tot_loss_proj:3.559 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
[1950/2000] tot_loss=2.652 (perp=8.211, rec=0.227, cos=0.783), tot_loss_proj:3.554 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.656 (perp=8.211, rec=0.233, cos=0.781), tot_loss_proj:3.554 [t=0.30s]
prediction: ['[CLS]ed acrossriety he waltzed her. [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] he waltzed her across the floor. [SEP]
========================
predicted: 
========================
[CLS]ed acrossriety he waltzed her. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 71.429 | r: 62.500
rouge2     | fm: 30.769 | p: 33.333 | r: 28.571
rougeL     | fm: 66.667 | p: 71.429 | r: 62.500
rougeLsum  | fm: 66.667 | p: 71.429 | r: 62.500
r1fm+r2fm = 97.436

[Aggregate metrics]:
rouge1     | fm: 77.075 | p: 77.285 | r: 77.045
rouge2     | fm: 36.628 | p: 36.677 | r: 36.727
rougeL     | fm: 68.527 | p: 68.796 | r: 68.494
rougeLsum  | fm: 68.578 | p: 68.911 | r: 68.569
r1fm+r2fm = 113.703

input #82 time: 0:11:50 | total time: 16:30:16


Running input #83 of 100.
reference: 
========================
How easy to please John is it?
========================
average of cosine similarity 0.9988584873288722
highest_index [0]
highest [0.9988584873288722]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2129, 3733, 2000, 3531, 2198, 2003, 2009, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] how easy to please john is it? [SEP]']
[Init] best rec loss: 0.8197141289710999 for ['[CLS] blacksmith straight heart comprises works right wa would [SEP]']
[Init] best rec loss: 0.7624621987342834 for ['[CLS] god bay hungarianaround dad pony medal i [SEP]']
[Init] best rec loss: 0.7569586038589478 for ['[CLS] trevorntsgni midway coup eye denied disputed [SEP]']
[Init] best rec loss: 0.7414436936378479 for ['[CLS] time fixedcala writer stryker prepared thing philip [SEP]']
[Init] best rec loss: 0.7362663149833679 for ['[CLS] motor pacificeni confined near abby holding curled [SEP]']
[Init] best rec loss: 0.7317958474159241 for ['[CLS] bonnie teller elevation min cafe superior involvedthest [SEP]']
[Init] best rec loss: 0.7236549854278564 for ['[CLS] tonight stupid covering to scores up storm fake [SEP]']
[Init] best rec loss: 0.7174086570739746 for ['[CLS] spent tr paddington kingdoms ryder master jr sides [SEP]']
[Init] best perm rec loss: 0.7139934301376343 for ['[CLS] tr jr ryder master spent paddington sides kingdoms [SEP]']
[Init] best perm rec loss: 0.7138391137123108 for ['[CLS] kingdoms tr spent sides master ryder paddington jr [SEP]']
[Init] best perm rec loss: 0.7117988467216492 for ['[CLS] spent paddington ryder jr tr sides master kingdoms [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.281 (perp=9.340, rec=0.357, cos=0.056), tot_loss_proj:3.175 [t=0.29s]
prediction: ['[CLS] how please please john swift system this please [SEP]']
[ 100/2000] tot_loss=1.920 (perp=7.946, rec=0.296, cos=0.035), tot_loss_proj:2.890 [t=0.30s]
prediction: ['[CLS] how please please john easy is john? [SEP]']
[ 150/2000] tot_loss=1.864 (perp=7.844, rec=0.249, cos=0.046), tot_loss_proj:2.675 [t=0.30s]
prediction: ['[CLS] how please easy john is is john? [SEP]']
[ 200/2000] tot_loss=1.657 (perp=7.598, rec=0.129, cos=0.008), tot_loss_proj:2.641 [t=0.30s]
prediction: ['[CLS] how please easy john is it john? [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.468 (perp=6.762, rec=0.109, cos=0.007), tot_loss_proj:2.225 [t=0.30s]
prediction: ['[CLS] how easy please john is it to? [SEP]']
[ 300/2000] tot_loss=1.437 (perp=6.762, rec=0.082, cos=0.003), tot_loss_proj:2.222 [t=0.30s]
prediction: ['[CLS] how easy please john is it to? [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.219 (perp=5.693, rec=0.078, cos=0.003), tot_loss_proj:1.262 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.200 (perp=5.693, rec=0.059, cos=0.002), tot_loss_proj:1.271 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[ 450/2000] tot_loss=1.213 (perp=5.693, rec=0.072, cos=0.002), tot_loss_proj:1.276 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.197 (perp=5.693, rec=0.056, cos=0.002), tot_loss_proj:1.271 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.209 (perp=5.693, rec=0.068, cos=0.002), tot_loss_proj:1.275 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[ 600/2000] tot_loss=1.199 (perp=5.693, rec=0.058, cos=0.002), tot_loss_proj:1.270 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.195 (perp=5.693, rec=0.054, cos=0.002), tot_loss_proj:1.273 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.204 (perp=5.693, rec=0.063, cos=0.002), tot_loss_proj:1.278 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[ 750/2000] tot_loss=1.209 (perp=5.693, rec=0.068, cos=0.002), tot_loss_proj:1.265 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.207 (perp=5.693, rec=0.066, cos=0.002), tot_loss_proj:1.275 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.195 (perp=5.693, rec=0.054, cos=0.002), tot_loss_proj:1.270 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[ 900/2000] tot_loss=1.208 (perp=5.693, rec=0.067, cos=0.002), tot_loss_proj:1.273 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.195 (perp=5.693, rec=0.054, cos=0.002), tot_loss_proj:1.264 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.209 (perp=5.693, rec=0.068, cos=0.002), tot_loss_proj:1.269 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1050/2000] tot_loss=1.207 (perp=5.693, rec=0.066, cos=0.002), tot_loss_proj:1.275 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.200 (perp=5.693, rec=0.059, cos=0.002), tot_loss_proj:1.270 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.199 (perp=5.693, rec=0.058, cos=0.002), tot_loss_proj:1.274 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1200/2000] tot_loss=1.203 (perp=5.693, rec=0.062, cos=0.002), tot_loss_proj:1.271 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.200 (perp=5.693, rec=0.059, cos=0.002), tot_loss_proj:1.263 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.207 (perp=5.693, rec=0.066, cos=0.002), tot_loss_proj:1.271 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1350/2000] tot_loss=1.204 (perp=5.693, rec=0.063, cos=0.002), tot_loss_proj:1.270 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.208 (perp=5.693, rec=0.067, cos=0.002), tot_loss_proj:1.264 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.198 (perp=5.693, rec=0.057, cos=0.002), tot_loss_proj:1.268 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1500/2000] tot_loss=1.199 (perp=5.693, rec=0.058, cos=0.002), tot_loss_proj:1.272 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.201 (perp=5.693, rec=0.060, cos=0.002), tot_loss_proj:1.262 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.207 (perp=5.693, rec=0.066, cos=0.002), tot_loss_proj:1.268 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1650/2000] tot_loss=1.197 (perp=5.693, rec=0.056, cos=0.002), tot_loss_proj:1.267 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.199 (perp=5.693, rec=0.058, cos=0.002), tot_loss_proj:1.279 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.209 (perp=5.693, rec=0.068, cos=0.002), tot_loss_proj:1.269 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1800/2000] tot_loss=1.203 (perp=5.693, rec=0.062, cos=0.002), tot_loss_proj:1.269 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.203 (perp=5.693, rec=0.062, cos=0.002), tot_loss_proj:1.265 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.201 (perp=5.693, rec=0.060, cos=0.002), tot_loss_proj:1.272 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1950/2000] tot_loss=1.205 (perp=5.693, rec=0.064, cos=0.002), tot_loss_proj:1.265 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.206 (perp=5.693, rec=0.065, cos=0.002), tot_loss_proj:1.264 [t=0.30s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] how easy to please john is it? [SEP]
========================
predicted: 
========================
[CLS] how easy to please john is it? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 77.355 | p: 77.628 | r: 77.328
rouge2     | fm: 37.414 | p: 37.446 | r: 37.464
rougeL     | fm: 68.891 | p: 69.119 | r: 68.841
rougeLsum  | fm: 69.072 | p: 69.291 | r: 69.009
r1fm+r2fm = 114.770

input #83 time: 0:11:49 | total time: 16:42:06


Running input #84 of 100.
reference: 
========================
That the king or queen be present is a requirement on all Royal weddings.
========================
average of cosine similarity 0.9989466659587176
highest_index [0]
highest [0.9989466659587176]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2008,  1996,  2332,  2030,  3035,  2022,  2556,  2003,  1037,
          9095,  2006,  2035,  2548, 20429,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]']
[Init] best rec loss: 0.9464948773384094 for ['[CLS] y during udnsorlot shed art closed described power na seriously guild le grinding [SEP]']
[Init] best rec loss: 0.9319691061973572 for ['[CLS]る spa brought wondered myrim midnight nationality flushed keys architect ground roman rally populations [SEP]']
[Init] best rec loss: 0.9192949533462524 for ['[CLS] bertha clinging outside bad tucker catalonia chorus out deck namely? white milleruation opportunities [SEP]']
[Init] best rec loss: 0.9101974368095398 for ['[CLS] calling time action restrictionhui edge still equality municipality part genieint compelledomp remainder [SEP]']
[Init] best rec loss: 0.8943310379981995 for ['[CLS] metro coulddilly sees command vanessacter zane bend deadly his ledger day 95 poetry [SEP]']
[Init] best rec loss: 0.8817904591560364 for ['[CLS] release den rivalaway still atlas like male senior each costs lightwala decline gibraltar [SEP]']
[Init] best rec loss: 0.8759896755218506 for ['[CLS] beatmission round truck dissolvedκ wishes residential problems tadestinalinavina imp spirit [SEP]']
[Init] best perm rec loss: 0.8748039603233337 for ['[CLS] spirit residentialvina problems wishes truckκ beatmission impinaestinal tad round dissolved [SEP]']
[Init] best perm rec loss: 0.8744054436683655 for ['[CLS]ina residential beat dissolved spirit imp problemsκ tadmissionvina wishes roundestinal truck [SEP]']
[Init] best perm rec loss: 0.8730559349060059 for ['[CLS] truck dissolved tadmission residentialκestinal spirit round problemsvina beat imp wishesina [SEP]']
[Init] best perm rec loss: 0.8714964389801025 for ['[CLS] truckvina residential roundmission spiritina imp dissolvedestinal wishes beat tad problemsκ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.559 (perp=10.722, rec=0.520, cos=0.895), tot_loss_proj:4.062 [t=0.30s]
prediction: ['[CLS] the wedding applications her launch on imperial professional | governor wishes? duke trey phyllis [SEP]']
[ 100/2000] tot_loss=3.044 (perp=9.581, rec=0.436, cos=0.692), tot_loss_proj:3.794 [t=0.30s]
prediction: ['[CLS] the wedding tradition ensure while on imperial weddings against princess requirement and princess queen sir [SEP]']
[ 150/2000] tot_loss=2.885 (perp=9.094, rec=0.342, cos=0.724), tot_loss_proj:3.672 [t=0.30s]
prediction: ['[CLS] the weddings tradition requires all on royal weddings ; king king how princess queen cbe [SEP]']
[ 200/2000] tot_loss=2.851 (perp=9.165, rec=0.295, cos=0.724), tot_loss_proj:3.699 [t=0.30s]
prediction: ['[CLS] the weddings tradition requirement all on royal weddings ; king requirement upon royal queen tobago [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.012 (perp=9.956, rec=0.358, cos=0.663), tot_loss_proj:3.870 [t=0.30s]
prediction: ['[CLS]drop weddings requirement requirement on all royal weddings ; king requirement upon princess king indo [SEP]']
[ 300/2000] tot_loss=2.937 (perp=9.525, rec=0.333, cos=0.699), tot_loss_proj:3.747 [t=0.30s]
prediction: ['[CLS] those royal ) requirement on all royal weddings ; king king intra royal king queen [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.714 (perp=9.059, rec=0.257, cos=0.645), tot_loss_proj:3.678 [t=0.30s]
prediction: ['[CLS] those royal queen requirement on all royal weddings, king requirement intra royal king requirement [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.670 (perp=8.665, rec=0.275, cos=0.662), tot_loss_proj:3.621 [t=0.30s]
prediction: ['[CLS] those weddings queen requirement on all royal weddings royal requirement immunity ; royal queen ) [SEP]']
[ 450/2000] tot_loss=2.840 (perp=9.231, rec=0.281, cos=0.713), tot_loss_proj:3.760 [t=0.30s]
prediction: ['[CLS] those weddings former requirement on all royal weddings king requirement immunity ; royal queen ) [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.516 (perp=8.018, rec=0.236, cos=0.676), tot_loss_proj:3.493 [t=0.30s]
prediction: ['[CLS] those royal former requirement on all royal weddings royal requirement 3 ; royal queen ) [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.484 (perp=7.692, rec=0.253, cos=0.693), tot_loss_proj:3.426 [t=0.30s]
prediction: ['[CLS] those royal former requirement on all royal wedding weddings requirement 3 ; royal queen ) [SEP]']
[ 600/2000] tot_loss=2.565 (perp=8.210, rec=0.240, cos=0.683), tot_loss_proj:3.506 [t=0.30s]
prediction: ['[CLS] those royal former requirement on all royal wedding weddings requirement large ; royal queen ) [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.511 (perp=8.082, rec=0.229, cos=0.666), tot_loss_proj:3.471 [t=0.30s]
prediction: ['[CLS] those royal queen requirement on all royal wedding weddings intra requirement ; royal queen ) [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.502 (perp=8.041, rec=0.226, cos=0.668), tot_loss_proj:3.470 [t=0.30s]
prediction: ['[CLS] those royal former requirement on all royal wedding weddings intra requirement ; royal queen ) [SEP]']
[ 750/2000] tot_loss=2.506 (perp=8.041, rec=0.229, cos=0.669), tot_loss_proj:3.469 [t=0.30s]
prediction: ['[CLS] those royal former requirement on all royal wedding weddings intra requirement ; royal queen ) [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.521 (perp=8.041, rec=0.236, cos=0.676), tot_loss_proj:3.464 [t=0.30s]
prediction: ['[CLS] those royal former requirement on all royal wedding weddings intra requirement ; royal queen ) [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.551 (perp=8.041, rec=0.217, cos=0.726), tot_loss_proj:3.468 [t=0.30s]
prediction: ['[CLS] those royal former requirement on all royal wedding weddings intra requirement ; royal queen ) [SEP]']
[ 900/2000] tot_loss=2.653 (perp=8.656, rec=0.216, cos=0.706), tot_loss_proj:3.608 [t=0.30s]
prediction: ['[CLS] those king former requirement on all royal wedding weddings intra requirement ; royal queen ) [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.675 (perp=8.656, rec=0.217, cos=0.727), tot_loss_proj:3.610 [t=0.30s]
prediction: ['[CLS] those king former requirement on all royal wedding weddings intra requirement ; royal queen ) [SEP]']
Attempt swap
[1000/2000] tot_loss=2.663 (perp=8.656, rec=0.217, cos=0.715), tot_loss_proj:3.610 [t=0.30s]
prediction: ['[CLS] those king former requirement on all royal wedding weddings intra requirement ; royal queen ) [SEP]']
[1050/2000] tot_loss=2.607 (perp=8.414, rec=0.210, cos=0.714), tot_loss_proj:3.538 [t=0.30s]
prediction: ['[CLS] those king royal requirement on all royal wedding weddings overwhelming requirement ; royal queen ) [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.557 (perp=8.107, rec=0.217, cos=0.718), tot_loss_proj:3.496 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal wedding weddings overwhelming requirement ; royal queen ) [SEP]']
Attempt swap
[1150/2000] tot_loss=2.546 (perp=8.107, rec=0.210, cos=0.715), tot_loss_proj:3.495 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal wedding weddings overwhelming requirement ; royal queen ) [SEP]']
[1200/2000] tot_loss=2.555 (perp=8.107, rec=0.214, cos=0.719), tot_loss_proj:3.497 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal wedding weddings overwhelming requirement ; royal queen ) [SEP]']
Attempt swap
[1250/2000] tot_loss=2.546 (perp=8.042, rec=0.218, cos=0.720), tot_loss_proj:3.466 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal royal weddings overwhelming requirement ; royal queen ) [SEP]']
Attempt swap
[1300/2000] tot_loss=2.542 (perp=8.042, rec=0.214, cos=0.719), tot_loss_proj:3.465 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal royal weddings overwhelming requirement ; royal queen ) [SEP]']
[1350/2000] tot_loss=2.549 (perp=8.042, rec=0.215, cos=0.725), tot_loss_proj:3.467 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal royal weddings overwhelming requirement ; royal queen ) [SEP]']
Attempt swap
[1400/2000] tot_loss=2.510 (perp=7.846, rec=0.218, cos=0.723), tot_loss_proj:3.423 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
Attempt swap
[1450/2000] tot_loss=2.499 (perp=7.846, rec=0.208, cos=0.722), tot_loss_proj:3.423 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
[1500/2000] tot_loss=2.500 (perp=7.846, rec=0.209, cos=0.722), tot_loss_proj:3.422 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
Attempt swap
[1550/2000] tot_loss=2.507 (perp=7.846, rec=0.217, cos=0.721), tot_loss_proj:3.424 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
Attempt swap
[1600/2000] tot_loss=2.506 (perp=7.846, rec=0.212, cos=0.725), tot_loss_proj:3.425 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
[1650/2000] tot_loss=2.499 (perp=7.846, rec=0.207, cos=0.723), tot_loss_proj:3.422 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
Attempt swap
[1700/2000] tot_loss=2.501 (perp=7.846, rec=0.205, cos=0.727), tot_loss_proj:3.424 [t=0.30s]
prediction: ['[CLS] those requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
Attempt swap
[1750/2000] tot_loss=2.631 (perp=8.466, rec=0.215, cos=0.723), tot_loss_proj:3.595 [t=0.30s]
prediction: ['[CLS]uin requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
[1800/2000] tot_loss=2.623 (perp=8.466, rec=0.206, cos=0.724), tot_loss_proj:3.595 [t=0.30s]
prediction: ['[CLS]uin requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
Attempt swap
[1850/2000] tot_loss=2.626 (perp=8.466, rec=0.205, cos=0.728), tot_loss_proj:3.590 [t=0.30s]
prediction: ['[CLS]uin requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
Attempt swap
[1900/2000] tot_loss=2.629 (perp=8.466, rec=0.210, cos=0.726), tot_loss_proj:3.593 [t=0.30s]
prediction: ['[CLS]uin requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
[1950/2000] tot_loss=2.626 (perp=8.466, rec=0.208, cos=0.725), tot_loss_proj:3.592 [t=0.30s]
prediction: ['[CLS]uin requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
Attempt swap
[2000/2000] tot_loss=2.621 (perp=8.466, rec=0.200, cos=0.727), tot_loss_proj:3.595 [t=0.30s]
prediction: ['[CLS]uin requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]
========================
predicted: 
========================
[CLS]uin requirement royal king on all royal royal weddings unanimously requirement ; royal queen ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.065 | p: 60.000 | r: 56.250
rouge2     | fm: 20.690 | p: 21.429 | r: 20.000
rougeL     | fm: 45.161 | p: 46.667 | r: 43.750
rougeLsum  | fm: 45.161 | p: 46.667 | r: 43.750
r1fm+r2fm = 78.754

[Aggregate metrics]:
rouge1     | fm: 77.136 | p: 77.410 | r: 77.092
rouge2     | fm: 37.237 | p: 37.340 | r: 37.338
rougeL     | fm: 68.611 | p: 68.886 | r: 68.592
rougeLsum  | fm: 68.689 | p: 69.001 | r: 68.664
r1fm+r2fm = 114.373

input #84 time: 0:12:04 | total time: 16:54:11


Running input #85 of 100.
reference: 
========================
Aphrodite stinks to be omnipotent.
========================
average of cosine similarity 0.9989424235746731
highest_index [0]
highest [0.9989424235746731]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  9706,  8093,  7716,  4221, 27136,  2015,  2000,  2022, 18168,
          3490, 11008,  4765,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] aphrodite stinks to be omnipotent. [SEP]']
[Init] best rec loss: 0.8616034984588623 for ['[CLS] grandchildren ghosts course [SEP]et chief view matt single ko pass rural entered [SEP]']
[Init] best rec loss: 0.834836483001709 for ['[CLS] glancedュ lowell anna bathtana range focus deafules ball look shortened [SEP]']
[Init] best rec loss: 0.82054603099823 for ['[CLS] march mayoralloadsman greatuled coverskieox monuments res bree thomas [SEP]']
[Init] best rec loss: 0.8177890777587891 for ['[CLS]dustoting triadchiayce upwehr sober urbana weakly aksons usually [SEP]']
[Init] best rec loss: 0.8155505657196045 for ['[CLS] ward science cinderown connectedlynn ª clearable em miles watching milk [SEP]']
[Init] best rec loss: 0.7949269413948059 for ['[CLS] beneath asked string wrath chief premiere general kneltabas expected minute taiwanese careful [SEP]']
[Init] best rec loss: 0.7892905473709106 for ['[CLS] multiplayer easter taut acclaim honor seniorguide court mm authority class twin henderson [SEP]']
[Init] best rec loss: 0.7799535393714905 for ['[CLS] boatswl identical us yukon awhile current file bend loop visited suffix line [SEP]']
[Init] best rec loss: 0.7732511758804321 for ['[CLS] twin weasel craft help enough norman ¨vez gamer london tightlycing sis [SEP]']
[Init] best rec loss: 0.7680174112319946 for ['[CLS] met television or hockeyimated like funds spaced centre bolivar off treatedland [SEP]']
[Init] best perm rec loss: 0.7615974545478821 for ['[CLS] bolivar centre televisionlandimated funds or treated spaced like met off hockey [SEP]']
[Init] best perm rec loss: 0.7607653141021729 for ['[CLS] likeland television spacedimated or off funds centre met bolivar hockey treated [SEP]']
[Init] best perm rec loss: 0.7606605887413025 for ['[CLS] centre like spaced or hockey television bolivarimated metland off treated funds [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.067 (perp=12.920, rec=0.378, cos=0.105), tot_loss_proj:4.301 [t=0.29s]
prediction: ['[CLS] flora pig stink to lux tostream possessionogical sap leased northa [SEP]']
[ 100/2000] tot_loss=2.829 (perp=12.511, rec=0.281, cos=0.045), tot_loss_proj:4.224 [t=0.30s]
prediction: ['[CLS]iteite stink to causes be be stink quite sap & hera [SEP]']
[ 150/2000] tot_loss=2.458 (perp=11.144, rec=0.204, cos=0.026), tot_loss_proj:3.773 [t=0.30s]
prediction: ['[CLS]iteite stink to causes to bepoty south. traitora [SEP]']
[ 200/2000] tot_loss=2.488 (perp=11.532, rec=0.165, cos=0.016), tot_loss_proj:3.513 [t=0.30s]
prediction: ['[CLS] apite stink tood to beenty angliatedpots [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.287 (perp=10.453, rec=0.178, cos=0.018), tot_loss_proj:3.429 [t=0.30s]
prediction: ['[CLS] apiteod to stink to beenty angliatedpot. [SEP]']
[ 300/2000] tot_loss=2.099 (perp=9.828, rec=0.124, cos=0.009), tot_loss_proj:3.438 [t=0.30s]
prediction: ['[CLS] apiteod to stink to beenty angliaspot. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.866 (perp=8.724, rec=0.112, cos=0.009), tot_loss_proj:3.446 [t=0.30s]
prediction: ['[CLS] apodite to stink to bepotytuaspot. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.041 (perp=9.347, rec=0.145, cos=0.026), tot_loss_proj:3.408 [t=0.30s]
prediction: ['[CLS] apodite to stink to bepottuaentsilation. [SEP]']
[ 450/2000] tot_loss=2.005 (perp=9.426, rec=0.111, cos=0.009), tot_loss_proj:3.605 [t=0.30s]
prediction: ['[CLS] apodite to stink to beenttuaentsio. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.925 (perp=9.045, rec=0.108, cos=0.008), tot_loss_proj:3.517 [t=0.30s]
prediction: ['[CLS] apodite to stink to bepotpotsentent. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.915 (perp=8.880, rec=0.128, cos=0.011), tot_loss_proj:3.565 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentpotsent. [SEP]']
[ 600/2000] tot_loss=1.885 (perp=8.880, rec=0.103, cos=0.006), tot_loss_proj:3.566 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentpotsent. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.582 (perp=7.453, rec=0.086, cos=0.006), tot_loss_proj:3.242 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.583 (perp=7.453, rec=0.087, cos=0.005), tot_loss_proj:3.240 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
[ 750/2000] tot_loss=1.591 (perp=7.453, rec=0.095, cos=0.005), tot_loss_proj:3.237 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.590 (perp=7.453, rec=0.094, cos=0.005), tot_loss_proj:3.239 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.589 (perp=7.453, rec=0.093, cos=0.005), tot_loss_proj:3.242 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
[ 900/2000] tot_loss=1.588 (perp=7.453, rec=0.093, cos=0.005), tot_loss_proj:3.236 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.577 (perp=7.453, rec=0.082, cos=0.004), tot_loss_proj:3.239 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.584 (perp=7.453, rec=0.089, cos=0.004), tot_loss_proj:3.242 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
[1050/2000] tot_loss=1.573 (perp=7.453, rec=0.078, cos=0.004), tot_loss_proj:3.244 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.579 (perp=7.453, rec=0.084, cos=0.004), tot_loss_proj:3.245 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.579 (perp=7.453, rec=0.084, cos=0.004), tot_loss_proj:3.243 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
[1200/2000] tot_loss=1.580 (perp=7.453, rec=0.085, cos=0.004), tot_loss_proj:3.241 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.580 (perp=7.453, rec=0.085, cos=0.004), tot_loss_proj:3.241 [t=0.30s]
prediction: ['[CLS] apodite to stink directly bepotentspotent. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.663 (perp=7.853, rec=0.088, cos=0.004), tot_loss_proj:3.403 [t=0.30s]
prediction: ['[CLS] apodite to stink live bepotentspotent. [SEP]']
[1350/2000] tot_loss=1.652 (perp=7.853, rec=0.077, cos=0.004), tot_loss_proj:3.404 [t=0.30s]
prediction: ['[CLS] apodite to stink live bepotentspotent. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.652 (perp=7.853, rec=0.077, cos=0.004), tot_loss_proj:3.397 [t=0.30s]
prediction: ['[CLS] apodite to stink live bepotentspotent. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.658 (perp=7.853, rec=0.084, cos=0.004), tot_loss_proj:3.397 [t=0.30s]
prediction: ['[CLS] apodite to stink live bepotentspotent. [SEP]']
[1500/2000] tot_loss=1.659 (perp=7.853, rec=0.084, cos=0.004), tot_loss_proj:3.401 [t=0.30s]
prediction: ['[CLS] apodite to stink live bepotentspotent. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.701 (perp=8.053, rec=0.086, cos=0.004), tot_loss_proj:3.003 [t=0.30s]
prediction: ['[CLS] apodite directly stink to bepotentspotent. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.599 (perp=7.511, rec=0.093, cos=0.004), tot_loss_proj:2.929 [t=0.30s]
prediction: ['[CLS] apodite stink directly to bepotentspotent. [SEP]']
[1650/2000] tot_loss=1.591 (perp=7.511, rec=0.085, cos=0.004), tot_loss_proj:2.938 [t=0.30s]
prediction: ['[CLS] apodite stink directly to bepotentspotent. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.590 (perp=7.511, rec=0.084, cos=0.004), tot_loss_proj:2.929 [t=0.30s]
prediction: ['[CLS] apodite stink directly to bepotentspotent. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.544 (perp=7.192, rec=0.100, cos=0.005), tot_loss_proj:2.387 [t=0.30s]
prediction: ['[CLS] apodite stinks directly to bepotentpotent. [SEP]']
[1800/2000] tot_loss=1.543 (perp=7.256, rec=0.087, cos=0.004), tot_loss_proj:2.540 [t=0.30s]
prediction: ['[CLS] apodite stinks live to bepotentpotent. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.533 (perp=7.256, rec=0.078, cos=0.004), tot_loss_proj:2.540 [t=0.30s]
prediction: ['[CLS] apodite stinks live to bepotentpotent. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.545 (perp=7.256, rec=0.090, cos=0.004), tot_loss_proj:2.541 [t=0.30s]
prediction: ['[CLS] apodite stinks live to bepotentpotent. [SEP]']
[1950/2000] tot_loss=1.537 (perp=7.256, rec=0.081, cos=0.004), tot_loss_proj:2.539 [t=0.30s]
prediction: ['[CLS] apodite stinks live to bepotentpotent. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.541 (perp=7.256, rec=0.086, cos=0.004), tot_loss_proj:2.538 [t=0.30s]
prediction: ['[CLS] apodite stinks live to bepotentpotent. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] aphrodite stinks to be omnipotent. [SEP]
========================
predicted: 
========================
[CLS] apodite to stink live bepotentspotent. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 42.857 | p: 42.857 | r: 42.857
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.857 | p: 42.857 | r: 42.857
rougeLsum  | fm: 42.857 | p: 42.857 | r: 42.857
r1fm+r2fm = 42.857

[Aggregate metrics]:
rouge1     | fm: 76.775 | p: 76.988 | r: 76.735
rouge2     | fm: 36.726 | p: 36.776 | r: 36.821
rougeL     | fm: 68.275 | p: 68.578 | r: 68.163
rougeLsum  | fm: 68.458 | p: 68.748 | r: 68.342
r1fm+r2fm = 113.501

input #85 time: 0:11:49 | total time: 17:06:01


Running input #86 of 100.
reference: 
========================
I lifted him up the books.
========================
average of cosine similarity 0.9988166911670516
highest_index [0]
highest [0.9988166911670516]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1045, 4196, 2032, 2039, 1996, 2808, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i lifted him up the books. [SEP]']
[Init] best rec loss: 0.8221333622932434 for ['[CLS] associates kill blockade musica [SEP] bees... [SEP]']
[Init] best rec loss: 0.7532119750976562 for ["[CLS] 'ry full winston postwright what [SEP]"]
[Init] best rec loss: 0.7366966605186462 for ['[CLS] cara jar orchard wolf walking this negative [SEP]']
[Init] best rec loss: 0.7331568598747253 for ['[CLS] interest check indytute watch pitched licence [SEP]']
[Init] best rec loss: 0.7199981808662415 for ['[CLS] did chin rearن spray davyologist [SEP]']
[Init] best rec loss: 0.7109353542327881 for ['[CLS]ing society vrza hill bareurity [SEP]']
[Init] best rec loss: 0.7085351943969727 for ['[CLS]tonic based coveren booth novels infrared [SEP]']
[Init] best rec loss: 0.6885852813720703 for ['[CLS] made par letters imp carrier obviouss [SEP]']
[Init] best rec loss: 0.6693744659423828 for ['[CLS]arus bank groups bare primetime rub reviewer [SEP]']
[Init] best perm rec loss: 0.6646462678909302 for ['[CLS] reviewerarus primetime bank bare groups rub [SEP]']
[Init] best perm rec loss: 0.6629282832145691 for ['[CLS]arus bare bank groups reviewer rub primetime [SEP]']
[Init] best perm rec loss: 0.6605033874511719 for ['[CLS] groups primetime rub reviewer bare bankarus [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.456 (perp=13.336, rec=0.566, cos=0.223), tot_loss_proj:3.640 [t=0.29s]
prediction: ['[CLS] up him sip up rep available mountain [SEP]']
[ 100/2000] tot_loss=3.220 (perp=12.707, rec=0.435, cos=0.243), tot_loss_proj:3.265 [t=0.30s]
prediction: ['[CLS] up him lifted cd woke available books [SEP]']
[ 150/2000] tot_loss=2.731 (perp=10.935, rec=0.351, cos=0.193), tot_loss_proj:2.844 [t=0.30s]
prediction: ['[CLS] up him lifted the slip available books [SEP]']
[ 200/2000] tot_loss=2.610 (perp=10.699, rec=0.313, cos=0.157), tot_loss_proj:2.808 [t=0.30s]
prediction: ['[CLS] up him lifted the him available books [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.132 (perp=8.471, rec=0.281, cos=0.157), tot_loss_proj:2.593 [t=0.30s]
prediction: ['[CLS] lifted him up the him books books [SEP]']
[ 300/2000] tot_loss=2.090 (perp=8.471, rec=0.260, cos=0.136), tot_loss_proj:2.587 [t=0.30s]
prediction: ['[CLS] lifted him up the him books books [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.119 (perp=8.676, rec=0.262, cos=0.122), tot_loss_proj:2.112 [t=0.30s]
prediction: ['[CLS] lana lifted him up the books books [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.204 (perp=9.256, rec=0.235, cos=0.118), tot_loss_proj:2.580 [t=0.30s]
prediction: ['[CLS] squared lifted him up the books books [SEP]']
[ 450/2000] tot_loss=2.191 (perp=9.256, rec=0.221, cos=0.118), tot_loss_proj:2.585 [t=0.30s]
prediction: ['[CLS] squared lifted him up the books books [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.232 (perp=9.475, rec=0.236, cos=0.101), tot_loss_proj:2.291 [t=0.30s]
prediction: ['[CLS] books lifted him up the booksonga [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.230 (perp=9.475, rec=0.220, cos=0.115), tot_loss_proj:2.291 [t=0.30s]
prediction: ['[CLS] books lifted him up the booksonga [SEP]']
[ 600/2000] tot_loss=2.214 (perp=9.475, rec=0.202, cos=0.117), tot_loss_proj:2.294 [t=0.30s]
prediction: ['[CLS] books lifted him up the booksonga [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.867 (perp=7.700, rec=0.214, cos=0.113), tot_loss_proj:2.030 [t=0.30s]
prediction: ['[CLS] books lifted him up the books place [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.853 (perp=7.700, rec=0.205, cos=0.108), tot_loss_proj:2.036 [t=0.30s]
prediction: ['[CLS] books lifted him up the books place [SEP]']
[ 750/2000] tot_loss=1.844 (perp=7.700, rec=0.200, cos=0.103), tot_loss_proj:2.035 [t=0.30s]
prediction: ['[CLS] books lifted him up the books place [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.844 (perp=7.700, rec=0.203, cos=0.101), tot_loss_proj:2.033 [t=0.30s]
prediction: ['[CLS] books lifted him up the books place [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.824 (perp=7.700, rec=0.186, cos=0.097), tot_loss_proj:2.029 [t=0.30s]
prediction: ['[CLS] books lifted him up the books place [SEP]']
[ 900/2000] tot_loss=1.837 (perp=7.700, rec=0.203, cos=0.094), tot_loss_proj:2.026 [t=0.30s]
prediction: ['[CLS] books lifted him up the books place [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.825 (perp=7.700, rec=0.193, cos=0.092), tot_loss_proj:2.027 [t=0.30s]
prediction: ['[CLS] books lifted him up the books place [SEP]']
Attempt swap
[1000/2000] tot_loss=1.821 (perp=7.700, rec=0.192, cos=0.088), tot_loss_proj:2.038 [t=0.30s]
prediction: ['[CLS] books lifted him up the books place [SEP]']
[1050/2000] tot_loss=1.813 (perp=7.700, rec=0.187, cos=0.086), tot_loss_proj:2.032 [t=0.30s]
prediction: ['[CLS] books lifted him up the books place [SEP]']
Attempt swap
[1100/2000] tot_loss=1.807 (perp=7.700, rec=0.184, cos=0.084), tot_loss_proj:2.039 [t=0.30s]
prediction: ['[CLS] books lifted him up the books place [SEP]']
Attempt swap
[1150/2000] tot_loss=1.818 (perp=7.700, rec=0.198, cos=0.080), tot_loss_proj:2.028 [t=0.30s]
prediction: ['[CLS] books lifted him up the books place [SEP]']
[1200/2000] tot_loss=1.922 (perp=8.265, rec=0.190, cos=0.079), tot_loss_proj:2.197 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Attempt swap
[1250/2000] tot_loss=1.923 (perp=8.265, rec=0.193, cos=0.077), tot_loss_proj:2.192 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Attempt swap
[1300/2000] tot_loss=1.910 (perp=8.265, rec=0.181, cos=0.075), tot_loss_proj:2.198 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
[1350/2000] tot_loss=1.924 (perp=8.265, rec=0.197, cos=0.074), tot_loss_proj:2.199 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Attempt swap
[1400/2000] tot_loss=1.903 (perp=8.265, rec=0.178, cos=0.072), tot_loss_proj:2.202 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Attempt swap
[1450/2000] tot_loss=1.906 (perp=8.265, rec=0.182, cos=0.071), tot_loss_proj:2.194 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
[1500/2000] tot_loss=1.905 (perp=8.265, rec=0.182, cos=0.071), tot_loss_proj:2.194 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Attempt swap
[1550/2000] tot_loss=1.900 (perp=8.265, rec=0.178, cos=0.069), tot_loss_proj:2.197 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Attempt swap
[1600/2000] tot_loss=1.905 (perp=8.265, rec=0.184, cos=0.068), tot_loss_proj:2.190 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
[1650/2000] tot_loss=1.903 (perp=8.265, rec=0.183, cos=0.067), tot_loss_proj:2.200 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Attempt swap
[1700/2000] tot_loss=1.893 (perp=8.265, rec=0.173, cos=0.067), tot_loss_proj:2.187 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Attempt swap
[1750/2000] tot_loss=1.907 (perp=8.265, rec=0.187, cos=0.067), tot_loss_proj:2.191 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
[1800/2000] tot_loss=1.904 (perp=8.265, rec=0.185, cos=0.066), tot_loss_proj:2.198 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Attempt swap
[1850/2000] tot_loss=1.894 (perp=8.265, rec=0.176, cos=0.065), tot_loss_proj:2.196 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Attempt swap
[1900/2000] tot_loss=1.898 (perp=8.265, rec=0.180, cos=0.065), tot_loss_proj:2.189 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
[1950/2000] tot_loss=1.910 (perp=8.265, rec=0.192, cos=0.065), tot_loss_proj:2.189 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Attempt swap
[2000/2000] tot_loss=1.890 (perp=8.265, rec=0.173, cos=0.065), tot_loss_proj:2.198 [t=0.30s]
prediction: ['[CLS]breakers lifted him up the books place [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] i lifted him up the books. [SEP]
========================
predicted: 
========================
[CLS]breakers lifted him up the books place [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 53.333 | p: 50.000 | r: 57.143
rougeL     | fm: 82.353 | p: 77.778 | r: 87.500
rougeLsum  | fm: 82.353 | p: 77.778 | r: 87.500
r1fm+r2fm = 135.686

[Aggregate metrics]:
rouge1     | fm: 76.751 | p: 76.965 | r: 76.816
rouge2     | fm: 36.998 | p: 37.030 | r: 37.164
rougeL     | fm: 68.513 | p: 68.749 | r: 68.506
rougeLsum  | fm: 68.623 | p: 68.800 | r: 68.612
r1fm+r2fm = 113.749

input #86 time: 0:11:50 | total time: 17:17:51


Running input #87 of 100.
reference: 
========================
Heidi thinks that Andy has eaten salmon flavored candy bars.
========================
average of cosine similarity 0.9990159970477317
highest_index [0]
highest [0.9990159970477317]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101, 21372,  6732,  2008,  5557,  2038,  8828, 11840, 14894,  2098,
          9485,  6963,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]']
[Init] best rec loss: 0.9633107781410217 for ['[CLS] flood but! means roe vietnam after partial owe cult novel question [SEP]']
[Init] best rec loss: 0.9416488409042358 for ['[CLS] remained rates made glacier beginning gift pianoril department springsuratie [SEP]']
[Init] best rec loss: 0.9140291213989258 for ['[CLS]sf bewildered hits many throughout spade forty rebel still bollywood cambridge uneven [SEP]']
[Init] best rec loss: 0.9047271609306335 for ['[CLS] cortex today low westminsterathlon because glass gill gainsples mike extreme [SEP]']
[Init] best rec loss: 0.8686296939849854 for ['[CLS] moreplppet children bank henri she entertainment expression clipped emotions webber [SEP]']
[Init] best perm rec loss: 0.8650107979774475 for ['[CLS] clipped childrenplppet bank emotions henri expression webber more entertainment she [SEP]']
[Init] best perm rec loss: 0.8639761209487915 for ['[CLS]pl bank henri children more expression entertainment emotions clippedppet webber she [SEP]']
[Init] best perm rec loss: 0.8625426292419434 for ['[CLS] she emotions more bank expression children henripl clipped webber entertainmentppet [SEP]']
[Init] best perm rec loss: 0.8612437844276428 for ['[CLS] emotions bank henripl expression sheppet entertainment clipped more webber children [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.186 (perp=13.311, rec=0.577, cos=0.947), tot_loss_proj:4.449 [t=0.38s]
prediction: ['[CLS] purposes distract veronica more red she witches ethnic. because temeraire barely [SEP]']
[ 100/2000] tot_loss=4.238 (perp=13.887, rec=0.496, cos=0.964), tot_loss_proj:4.655 [t=0.30s]
prediction: ['[CLS] arrows hurt andy eagleurityocating flavor salmon andy because pronouns prepared [SEP]']
[ 150/2000] tot_loss=4.070 (perp=13.442, rec=0.430, cos=0.951), tot_loss_proj:4.494 [t=0.30s]
prediction: ['[CLS] feelings eaten andy thaturity thinks flavor salmon andy heidi pronouns barely [SEP]']
[ 200/2000] tot_loss=4.033 (perp=12.289, rec=0.586, cos=0.989), tot_loss_proj:4.350 [t=0.30s]
prediction: ['[CLS] เ affect andy ; andy wants flavor salmon. rodeoulouslyea [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.993 (perp=13.304, rec=0.447, cos=0.886), tot_loss_proj:4.497 [t=0.30s]
prediction: ['[CLS] heidi affect flavor wished andy thinks andy salmon louisiana heidi lashed words [SEP]']
[ 300/2000] tot_loss=3.690 (perp=11.659, rec=0.409, cos=0.949), tot_loss_proj:4.124 [t=0.30s]
prediction: ['[CLS] heidi thinks flavor have columnist thinks andy salmon. heidi cavity connor [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.595 (perp=11.712, rec=0.377, cos=0.875), tot_loss_proj:4.140 [t=0.30s]
prediction: ['[CLS] heidi thinks flavor ; haselial andy heidi. heidi cavity reserved [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.501 (perp=11.516, rec=0.339, cos=0.859), tot_loss_proj:4.064 [t=0.30s]
prediction: ['[CLS] heidi has flavor ; thinkselial andy salmon. heididable reserved [SEP]']
[ 450/2000] tot_loss=3.670 (perp=12.620, rec=0.340, cos=0.806), tot_loss_proj:4.261 [t=0.30s]
prediction: ['[CLS] heidi has flavor have thinkselial andy salmon. heididable reserved [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.556 (perp=11.834, rec=0.314, cos=0.875), tot_loss_proj:4.112 [t=0.30s]
prediction: ['[CLS] heidi has flavor have thinkselial andy salmon reserved heididable. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.440 (perp=11.272, rec=0.318, cos=0.868), tot_loss_proj:4.022 [t=0.30s]
prediction: ['[CLS] heidielial has flavor eating thinks andy salmon reece heididable. [SEP]']
[ 600/2000] tot_loss=3.384 (perp=11.161, rec=0.287, cos=0.865), tot_loss_proj:4.019 [t=0.30s]
prediction: ['[CLS] heidielial has flavor eating thinks andy salmon reece heidi archway. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.350 (perp=11.024, rec=0.268, cos=0.877), tot_loss_proj:3.982 [t=0.30s]
prediction: ['[CLS] heidielial thinks flavor eating has andy salmon reece heididable. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.431 (perp=11.519, rec=0.260, cos=0.868), tot_loss_proj:4.054 [t=0.30s]
prediction: ['[CLS] heidielial thinks flavor eaten has andy salmon reece heididable. [SEP]']
[ 750/2000] tot_loss=3.444 (perp=11.519, rec=0.265, cos=0.875), tot_loss_proj:4.057 [t=0.30s]
prediction: ['[CLS] heidielial thinks flavor eaten has andy salmon reece heididable. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.376 (perp=11.303, rec=0.243, cos=0.872), tot_loss_proj:4.018 [t=0.30s]
prediction: ['[CLS] heidielial thinks eaten flavor has andy salmon reece heididable. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.440 (perp=11.596, rec=0.251, cos=0.870), tot_loss_proj:4.091 [t=0.30s]
prediction: ['[CLS] heidielial thinks eaten flavor has andy salmon reece heidi namely. [SEP]']
[ 900/2000] tot_loss=3.438 (perp=11.596, rec=0.241, cos=0.878), tot_loss_proj:4.090 [t=0.30s]
prediction: ['[CLS] heidielial thinks eaten flavor has andy salmon reece heidi namely. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.443 (perp=11.596, rec=0.240, cos=0.883), tot_loss_proj:4.087 [t=0.30s]
prediction: ['[CLS] heidielial thinks eaten flavor has andy salmon reece heidi namely. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.329 (perp=11.038, rec=0.250, cos=0.871), tot_loss_proj:3.973 [t=0.30s]
prediction: ['[CLS] heidielial thinks eaten flavor has andy salmon 止 heidi reece. [SEP]']
[1050/2000] tot_loss=3.321 (perp=11.038, rec=0.240, cos=0.873), tot_loss_proj:3.973 [t=0.30s]
prediction: ['[CLS] heidielial thinks eaten flavor has andy salmon 止 heidi reece. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=3.277 (perp=10.798, rec=0.243, cos=0.874), tot_loss_proj:3.993 [t=0.30s]
prediction: ['[CLS] heidielial thinks flavor has eaten andy salmon 止 heidi reece. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.268 (perp=10.798, rec=0.229, cos=0.879), tot_loss_proj:3.995 [t=0.30s]
prediction: ['[CLS] heidielial thinks flavor has eaten andy salmon 止 heidi reece. [SEP]']
[1200/2000] tot_loss=3.287 (perp=10.798, rec=0.247, cos=0.880), tot_loss_proj:3.993 [t=0.30s]
prediction: ['[CLS] heidielial thinks flavor has eaten andy salmon 止 heidi reece. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.266 (perp=10.703, rec=0.245, cos=0.880), tot_loss_proj:3.959 [t=0.30s]
prediction: ['[CLS] heidielial thinks flavor has eaten 止 salmon andy heidi reece. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.265 (perp=10.703, rec=0.245, cos=0.879), tot_loss_proj:3.957 [t=0.30s]
prediction: ['[CLS] heidielial thinks flavor has eaten 止 salmon andy heidi reece. [SEP]']
[1350/2000] tot_loss=3.244 (perp=10.675, rec=0.232, cos=0.877), tot_loss_proj:3.939 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi reece. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.252 (perp=10.675, rec=0.239, cos=0.878), tot_loss_proj:3.940 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi reece. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.244 (perp=10.675, rec=0.228, cos=0.880), tot_loss_proj:3.933 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi reece. [SEP]']
[1500/2000] tot_loss=3.247 (perp=10.675, rec=0.231, cos=0.882), tot_loss_proj:3.938 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi reece. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.253 (perp=10.675, rec=0.240, cos=0.879), tot_loss_proj:3.939 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi reece. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.247 (perp=10.675, rec=0.233, cos=0.879), tot_loss_proj:3.938 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi reece. [SEP]']
[1650/2000] tot_loss=3.320 (perp=11.032, rec=0.235, cos=0.879), tot_loss_proj:4.007 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi nbl. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.313 (perp=11.032, rec=0.227, cos=0.879), tot_loss_proj:4.007 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi nbl. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.317 (perp=11.032, rec=0.231, cos=0.879), tot_loss_proj:4.007 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi nbl. [SEP]']
[1800/2000] tot_loss=3.315 (perp=11.032, rec=0.229, cos=0.880), tot_loss_proj:4.005 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi nbl. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.318 (perp=11.032, rec=0.232, cos=0.880), tot_loss_proj:4.001 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi nbl. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.328 (perp=11.032, rec=0.241, cos=0.881), tot_loss_proj:4.007 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi nbl. [SEP]']
[1950/2000] tot_loss=3.315 (perp=11.032, rec=0.227, cos=0.882), tot_loss_proj:4.003 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi nbl. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.316 (perp=11.032, rec=0.228, cos=0.881), tot_loss_proj:4.005 [t=0.30s]
prediction: ['[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi nbl. [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]
========================
predicted: 
========================
[CLS] heidi baronet thinks flavor has eaten 止 salmon andy heidi nbl. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 27.273 | p: 27.273 | r: 27.273
rougeL     | fm: 58.333 | p: 58.333 | r: 58.333
rougeLsum  | fm: 58.333 | p: 58.333 | r: 58.333
r1fm+r2fm = 93.939

[Aggregate metrics]:
rouge1     | fm: 76.713 | p: 76.914 | r: 76.739
rouge2     | fm: 36.747 | p: 36.814 | r: 36.909
rougeL     | fm: 68.385 | p: 68.597 | r: 68.369
rougeLsum  | fm: 68.483 | p: 68.714 | r: 68.484
r1fm+r2fm = 113.461

input #87 time: 0:11:49 | total time: 17:29:41


Running input #88 of 100.
reference: 
========================
He bought these flowers for Aaron.
========================
average of cosine similarity 0.9989939314182821
highest_index [0]
highest [0.9989939314182821]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 4149, 2122, 4870, 2005, 7158, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he bought these flowers for aaron. [SEP]']
[Init] best rec loss: 0.9993058443069458 for ['[CLS] wi rio xx irving ou obligations tang [SEP]']
[Init] best rec loss: 0.971232533454895 for ['[CLS]ing rahman medina volume!lyn put [SEP]']
[Init] best rec loss: 0.9639034867286682 for ['[CLS] firm force beef parttion companions civil [SEP]']
[Init] best rec loss: 0.950152575969696 for ['[CLS]iateddication media familiar cas re threshold [SEP]']
[Init] best rec loss: 0.9484567642211914 for ['[CLS] freaking mine lldened compasstte syn [SEP]']
[Init] best rec loss: 0.9463534355163574 for ['[CLS] judo prime studios failbby bite age [SEP]']
[Init] best rec loss: 0.9370140433311462 for ['[CLS] nm derived answered chest throw opportunity [CLS] [SEP]']
[Init] best rec loss: 0.9231604337692261 for ['[CLS] fit centuries rid gear undergo largeities [SEP]']
[Init] best rec loss: 0.9199435114860535 for ['[CLS] americanaur− laughter peedy stock [SEP]']
[Init] best perm rec loss: 0.9183396100997925 for ['[CLS]aur american− stock laughterdy pee [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.579 (perp=10.165, rec=0.664, cos=0.881), tot_loss_proj:3.835 [t=0.29s]
prediction: ['[CLS] billy. peter possible i learn aaron [SEP]']
[ 100/2000] tot_loss=4.033 (perp=11.840, rec=0.771, cos=0.894), tot_loss_proj:4.165 [t=0.30s]
prediction: ['[CLS] 1940s this aaron bought they flowers aaron [SEP]']
[ 150/2000] tot_loss=3.794 (perp=11.306, rec=0.655, cos=0.877), tot_loss_proj:4.006 [t=0.30s]
prediction: ['[CLS] newspaper and aaron would they bought meditation [SEP]']
[ 200/2000] tot_loss=4.130 (perp=12.599, rec=0.673, cos=0.937), tot_loss_proj:4.278 [t=0.30s]
prediction: ['[CLS] flowers several aaron won his server takeoff [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.837 (perp=11.336, rec=0.579, cos=0.992), tot_loss_proj:4.071 [t=0.30s]
prediction: ['[CLS] won flowers. aaron his server flowering [SEP]']
[ 300/2000] tot_loss=3.705 (perp=13.333, rec=0.470, cos=0.568), tot_loss_proj:4.540 [t=0.30s]
prediction: ['[CLS] fallen flowers bought aaron this bugs johanna [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.562 (perp=11.111, rec=0.299, cos=0.041), tot_loss_proj:3.951 [t=0.30s]
prediction: ['[CLS] he flowers bought bought aaron this oyster [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.102 (perp=9.377, rec=0.205, cos=0.023), tot_loss_proj:3.609 [t=0.30s]
prediction: ['[CLS] he aaron flowers bought flowers these flowers [SEP]']
[ 450/2000] tot_loss=2.196 (perp=10.149, rec=0.155, cos=0.011), tot_loss_proj:3.775 [t=0.30s]
prediction: ['[CLS] he aaron for bought flowers these flowers [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.889 (perp=8.686, rec=0.141, cos=0.011), tot_loss_proj:3.738 [t=0.30s]
prediction: ['[CLS] he bought for aaron flowers these flowers [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.823 (perp=8.435, rec=0.125, cos=0.012), tot_loss_proj:3.374 [t=0.30s]
prediction: ['[CLS] he bought aaron flowers for these flowers [SEP]']
[ 600/2000] tot_loss=1.803 (perp=8.435, rec=0.107, cos=0.009), tot_loss_proj:3.377 [t=0.30s]
prediction: ['[CLS] he bought aaron flowers for these flowers [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.729 (perp=8.102, rec=0.101, cos=0.008), tot_loss_proj:3.512 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.725 (perp=8.102, rec=0.097, cos=0.008), tot_loss_proj:3.508 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
[ 750/2000] tot_loss=1.725 (perp=8.102, rec=0.097, cos=0.008), tot_loss_proj:3.513 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.719 (perp=8.102, rec=0.091, cos=0.008), tot_loss_proj:3.510 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.717 (perp=8.102, rec=0.089, cos=0.008), tot_loss_proj:3.512 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
[ 900/2000] tot_loss=1.722 (perp=8.102, rec=0.094, cos=0.008), tot_loss_proj:3.515 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.718 (perp=8.102, rec=0.090, cos=0.008), tot_loss_proj:3.507 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1000/2000] tot_loss=1.720 (perp=8.102, rec=0.092, cos=0.008), tot_loss_proj:3.508 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
[1050/2000] tot_loss=1.718 (perp=8.102, rec=0.091, cos=0.008), tot_loss_proj:3.507 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1100/2000] tot_loss=1.722 (perp=8.102, rec=0.094, cos=0.008), tot_loss_proj:3.507 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1150/2000] tot_loss=1.720 (perp=8.102, rec=0.093, cos=0.008), tot_loss_proj:3.512 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
[1200/2000] tot_loss=1.714 (perp=8.102, rec=0.086, cos=0.007), tot_loss_proj:3.502 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1250/2000] tot_loss=1.716 (perp=8.102, rec=0.088, cos=0.008), tot_loss_proj:3.507 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1300/2000] tot_loss=1.716 (perp=8.102, rec=0.088, cos=0.008), tot_loss_proj:3.501 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
[1350/2000] tot_loss=1.712 (perp=8.102, rec=0.084, cos=0.008), tot_loss_proj:3.508 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1400/2000] tot_loss=1.714 (perp=8.102, rec=0.086, cos=0.007), tot_loss_proj:3.502 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1450/2000] tot_loss=1.713 (perp=8.102, rec=0.085, cos=0.007), tot_loss_proj:3.496 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
[1500/2000] tot_loss=1.719 (perp=8.102, rec=0.091, cos=0.007), tot_loss_proj:3.503 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1550/2000] tot_loss=1.708 (perp=8.102, rec=0.080, cos=0.007), tot_loss_proj:3.508 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1600/2000] tot_loss=1.717 (perp=8.102, rec=0.089, cos=0.007), tot_loss_proj:3.506 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
[1650/2000] tot_loss=1.708 (perp=8.102, rec=0.081, cos=0.007), tot_loss_proj:3.498 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1700/2000] tot_loss=1.719 (perp=8.102, rec=0.091, cos=0.007), tot_loss_proj:3.500 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1750/2000] tot_loss=1.707 (perp=8.102, rec=0.079, cos=0.007), tot_loss_proj:3.501 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
[1800/2000] tot_loss=1.724 (perp=8.102, rec=0.096, cos=0.007), tot_loss_proj:3.505 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1850/2000] tot_loss=1.704 (perp=8.102, rec=0.076, cos=0.007), tot_loss_proj:3.495 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[1900/2000] tot_loss=1.711 (perp=8.102, rec=0.084, cos=0.007), tot_loss_proj:3.502 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
[1950/2000] tot_loss=1.717 (perp=8.102, rec=0.089, cos=0.007), tot_loss_proj:3.505 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Attempt swap
[2000/2000] tot_loss=1.723 (perp=8.102, rec=0.095, cos=0.007), tot_loss_proj:3.501 [t=0.30s]
prediction: ['[CLS] aaron he bought flowers for these flowers [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] he bought these flowers for aaron. [SEP]
========================
predicted: 
========================
[CLS] aaron he bought flowers for these flowers [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 40.000 | p: 37.500 | r: 42.857
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 134.118

[Aggregate metrics]:
rouge1     | fm: 76.872 | p: 77.009 | r: 76.964
rouge2     | fm: 36.848 | p: 36.860 | r: 36.963
rougeL     | fm: 68.445 | p: 68.603 | r: 68.517
rougeLsum  | fm: 68.538 | p: 68.711 | r: 68.581
r1fm+r2fm = 113.721

input #88 time: 0:11:50 | total time: 17:41:31


Running input #89 of 100.
reference: 
========================
Handsome though they told me that Tom is, I still won't date him.
========================
average of cosine similarity 0.9989074506665041
highest_index [0]
highest [0.9989074506665041]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[ 101, 8502, 2295, 2027, 2409, 2033, 2008, 3419, 2003, 1010, 1045, 2145,
         2180, 1005, 1056, 3058, 2032, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] handsome though they told me that tom is, i still won't date him. [SEP]"]
[Init] best rec loss: 0.9069195985794067 for ['[CLS] save jersey myanmar walkedfkthic ˢ wife dealing tomorrow lola e bit ll show ˈ competitions [SEP]']
[Init] best rec loss: 0.87686687707901 for ['[CLS] victim deficit will carrier glass participate fledopers green jin grim hasving littlelineplinbered [SEP]']
[Init] best rec loss: 0.8646875023841858 for ['[CLS] listential calling liesnified sesame solution hop failure colonel sign rms wil ever parsons [CLS] punk [SEP]']
[Init] best rec loss: 0.859478235244751 for ['[CLS] airports in generic root administrative capitol wisconsin blind municipality remainder prasad squirrelswise antioch programricted palmer [SEP]']
[Init] best rec loss: 0.8366146087646484 for ['[CLS] meeting reach sold tighthill knees grounds career regular figures deborah sport soundtrack guinness die so awe [SEP]']
[Init] best rec loss: 0.8365355730056763 for ['[CLS] cultural toll effective olive sci coordinates occurring celia antony above poundertinzing radio aquatics us nrhp [SEP]']
[Init] best rec loss: 0.7945197820663452 for ["[CLS] sandractive hopeless get cambridge oppositionnch | centre'oddissa hellivndo minor offensive [SEP]"]
[Init] best rec loss: 0.7941744923591614 for ['[CLS] mat leader michael gel making underworld problems fast lake wouldn hundred texts couple after de family 1970s [SEP]']
[Init] best rec loss: 0.7688248753547668 for ['[CLS] hopes devicesrued iv governor swap that saskatchewan pup under ultimate section drugged voivodeship should morning 500 [SEP]']
[Init] best perm rec loss: 0.768196165561676 for ['[CLS] iv pup saskatchewan section voivodeship morning swap under governor 500rued that ultimate devices should hopes drugged [SEP]']
[Init] best perm rec loss: 0.7668468952178955 for ['[CLS] 500 governor that hopes voivodeship morning drugged puprued iv swap devices should ultimate saskatchewan under section [SEP]']
[Init] best perm rec loss: 0.7667774558067322 for ['[CLS] swap drugged that ultimate hopes 500 voivodeship pup devices morningrued iv should section governor under saskatchewan [SEP]']
[Init] best perm rec loss: 0.764759361743927 for ['[CLS] that under ultimaterued swap iv pup 500 governor section devices hopes morning should drugged voivodeship saskatchewan [SEP]']
[Init] best perm rec loss: 0.7639161348342896 for ['[CLS] devices ultimate 500 under drugged ivrued voivodeship that swap saskatchewan pup governor section morning should hopes [SEP]']
[Init] best perm rec loss: 0.7624743580818176 for ['[CLS] should pup 500 swap saskatchewan iv ultimate hopes section voivodeship that devices morning governor drugged underrued [SEP]']
[Init] best perm rec loss: 0.7619768381118774 for ['[CLS] morning that hopes should voivodeship swap ivrued section saskatchewan 500 pup devices ultimate drugged under governor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.604 (perp=10.445, rec=0.574, cos=0.941), tot_loss_proj:3.839 [t=0.30s]
prediction: ['[CLS] very had ash theater his snow dialogue her county # my although book logic that his tree [SEP]']
[ 100/2000] tot_loss=3.592 (perp=10.729, rec=0.483, cos=0.964), tot_loss_proj:3.963 [t=0.30s]
prediction: ['[CLS] much was bore bold tom tom dialogue longtime i you me is presidential : that besides tree [SEP]']
[ 150/2000] tot_loss=3.668 (perp=11.116, rec=0.461, cos=0.985), tot_loss_proj:3.984 [t=0.30s]
prediction: ['[CLS] much was knox handsome : tom 3dwski i me you is learnedpipe that though brother [SEP]']
[ 200/2000] tot_loss=3.610 (perp=11.034, rec=0.444, cos=0.959), tot_loss_proj:3.872 [t=0.30s]
prediction: ['[CLS] though was knox handsome : chris immersion ᶜ hundred me ; is learnedpipe that though brother [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.741 (perp=11.833, rec=0.385, cos=0.990), tot_loss_proj:4.166 [t=0.30s]
prediction: ['[CLS] they is knox handsome that tom electronicgingly seriously tonight me ; ispipe why though is [SEP]']
[ 300/2000] tot_loss=3.612 (perp=11.234, rec=0.366, cos=0.999), tot_loss_proj:4.022 [t=0.30s]
prediction: ['[CLS] they isboys handsome that tom electronicgingly i dating me ; ispipe why though is [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.284 (perp=9.703, rec=0.345, cos=0.999), tot_loss_proj:3.648 [t=0.30s]
prediction: ['[CLS] they isboys handsome that tom encountergingly is dating me ; ipipe how though is [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.264 (perp=9.703, rec=0.323, cos=1.000), tot_loss_proj:3.648 [t=0.30s]
prediction: ['[CLS] they isboys handsome that tom encountergingly is dating me ; ipipe how though is [SEP]']
[ 450/2000] tot_loss=3.164 (perp=9.285, rec=0.308, cos=0.999), tot_loss_proj:3.669 [t=0.30s]
prediction: ['[CLS] they isboys handsome that tom cocktailbird is dating me ; i anyway picture though is [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.367 (perp=10.403, rec=0.289, cos=0.997), tot_loss_proj:3.892 [t=0.30s]
prediction: ['[CLS] they isiah handsome that tom encounterbird is date mehole ; i how though is [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.477 (perp=10.968, rec=0.286, cos=0.998), tot_loss_proj:3.960 [t=0.30s]
prediction: ['[CLS] they isiah handsome that tom encounter isbird date mehole i i how though is [SEP]']
[ 600/2000] tot_loss=3.571 (perp=11.457, rec=0.291, cos=0.988), tot_loss_proj:4.072 [t=0.30s]
prediction: ['[CLS] they isiah handsome that tom encounter isbird date mepoulos i i how though is [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.375 (perp=10.478, rec=0.286, cos=0.994), tot_loss_proj:3.885 [t=0.30s]
prediction: ['[CLS] they isiah handsome that tom cocktail isbird date mehita though i anyway i is [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.489 (perp=11.043, rec=0.291, cos=0.990), tot_loss_proj:4.001 [t=0.30s]
prediction: ['[CLS] they is i handsome that tom cocktail isigate date me airways though i anymoreiah is [SEP]']
[ 750/2000] tot_loss=3.480 (perp=11.073, rec=0.277, cos=0.989), tot_loss_proj:4.024 [t=0.30s]
prediction: ['[CLS] they is i handsome that tom cocktail isigate date mepoulos though i anymoreiah is [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.294 (perp=10.174, rec=0.274, cos=0.985), tot_loss_proj:3.826 [t=0.30s]
prediction: ['[CLS] they is i handsome that tom cocktail is me dateigatepoulos though i anymoreiah is [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=3.274 (perp=10.093, rec=0.272, cos=0.983), tot_loss_proj:3.829 [t=0.30s]
prediction: ['[CLS] they me is handsome that tom cocktail is me dateigatepoulos though i anymoreiah is [SEP]']
[ 900/2000] tot_loss=3.228 (perp=9.834, rec=0.276, cos=0.985), tot_loss_proj:3.757 [t=0.30s]
prediction: ['[CLS] they me is handsome that tom cocktail is me dateigatepoulos though. anymoreiah is [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.232 (perp=9.965, rec=0.264, cos=0.975), tot_loss_proj:3.777 [t=0.30s]
prediction: ['[CLS] they me is handsome that tom believed is me dateigatepoulos though. anymoreiah is [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.236 (perp=9.906, rec=0.275, cos=0.979), tot_loss_proj:3.749 [t=0.30s]
prediction: ['[CLS] they me is believed that tom handsome is me dateigate airways though. anymoreiah is [SEP]']
[1050/2000] tot_loss=3.210 (perp=9.906, rec=0.256, cos=0.973), tot_loss_proj:3.754 [t=0.30s]
prediction: ['[CLS] they me is believed that tom handsome is me dateigate airways though. anymoreiah is [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.186 (perp=9.772, rec=0.260, cos=0.972), tot_loss_proj:3.749 [t=0.30s]
prediction: ['[CLS] they me is believed that tom handsome is me dateigate. thoughhita anymoreiah is [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.134 (perp=9.525, rec=0.261, cos=0.968), tot_loss_proj:3.692 [t=0.30s]
prediction: ['[CLS] they me is believed that tom handsome is meigate date. thoughhita anymoreiah is [SEP]']
[1200/2000] tot_loss=3.130 (perp=9.525, rec=0.259, cos=0.967), tot_loss_proj:3.695 [t=0.30s]
prediction: ['[CLS] they me is believed that tom handsome is meigate date. thoughhita anymoreiah is [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=3.004 (perp=8.901, rec=0.258, cos=0.966), tot_loss_proj:3.552 [t=0.30s]
prediction: ['[CLS] they me is believed that tom handsome is meigate date. though anymorehitaiah is [SEP]']
Attempt swap
[1300/2000] tot_loss=3.006 (perp=8.901, rec=0.264, cos=0.963), tot_loss_proj:3.548 [t=0.30s]
prediction: ['[CLS] they me is believed that tom handsome is meigate date. though anymorehitaiah is [SEP]']
[1350/2000] tot_loss=2.975 (perp=8.750, rec=0.264, cos=0.961), tot_loss_proj:3.555 [t=0.30s]
prediction: ['[CLS] they me is believed that tom handsome is meigate date. though anymoresiah is [SEP]']
Attempt swap
[1400/2000] tot_loss=2.973 (perp=8.750, rec=0.260, cos=0.963), tot_loss_proj:3.555 [t=0.30s]
prediction: ['[CLS] they me is believed that tom handsome is meigate date. though anymoresiah is [SEP]']
Attempt swap
[1450/2000] tot_loss=3.006 (perp=8.935, rec=0.260, cos=0.959), tot_loss_proj:3.626 [t=0.30s]
prediction: ['[CLS] they tom is believed that tom handsome is meigate date. though anymoresiah is [SEP]']
[1500/2000] tot_loss=2.988 (perp=8.935, rec=0.244, cos=0.957), tot_loss_proj:3.624 [t=0.30s]
prediction: ['[CLS] they tom is believed that tom handsome is meigate date. though anymoresiah is [SEP]']
Attempt swap
[1550/2000] tot_loss=2.993 (perp=8.935, rec=0.249, cos=0.957), tot_loss_proj:3.633 [t=0.30s]
prediction: ['[CLS] they tom is believed that tom handsome is meigate date. though anymoresiah is [SEP]']
Attempt swap
[1600/2000] tot_loss=2.993 (perp=8.935, rec=0.249, cos=0.957), tot_loss_proj:3.634 [t=0.30s]
prediction: ['[CLS] they tom is believed that tom handsome is meigate date. though anymoresiah is [SEP]']
[1650/2000] tot_loss=2.994 (perp=8.935, rec=0.251, cos=0.955), tot_loss_proj:3.631 [t=0.30s]
prediction: ['[CLS] they tom is believed that tom handsome is meigate date. though anymoresiah is [SEP]']
Attempt swap
[1700/2000] tot_loss=2.989 (perp=8.935, rec=0.248, cos=0.954), tot_loss_proj:3.631 [t=0.30s]
prediction: ['[CLS] they tom is believed that tom handsome is meigate date. though anymoresiah is [SEP]']
Attempt swap
[1750/2000] tot_loss=2.987 (perp=8.935, rec=0.246, cos=0.954), tot_loss_proj:3.631 [t=0.30s]
prediction: ['[CLS] they tom is believed that tom handsome is meigate date. though anymoresiah is [SEP]']
[1800/2000] tot_loss=2.995 (perp=8.935, rec=0.256, cos=0.952), tot_loss_proj:3.626 [t=0.30s]
prediction: ['[CLS] they tom is believed that tom handsome is meigate date. though anymoresiah is [SEP]']
Attempt swap
[1850/2000] tot_loss=2.982 (perp=8.935, rec=0.243, cos=0.952), tot_loss_proj:3.629 [t=0.30s]
prediction: ['[CLS] they tom is believed that tom handsome is meigate date. though anymoresiah is [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.973 (perp=8.790, rec=0.257, cos=0.959), tot_loss_proj:3.512 [t=0.30s]
prediction: ['[CLS] theys is believed that tom handsome is meigate date. though anymore tomiah is [SEP]']
[1950/2000] tot_loss=2.963 (perp=8.790, rec=0.250, cos=0.954), tot_loss_proj:3.514 [t=0.30s]
prediction: ['[CLS] theys is believed that tom handsome is meigate date. though anymore tomiah is [SEP]']
Attempt swap
[2000/2000] tot_loss=2.959 (perp=8.790, rec=0.248, cos=0.953), tot_loss_proj:3.513 [t=0.30s]
prediction: ['[CLS] theys is believed that tom handsome is meigate date. though anymore tomiah is [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] handsome though they told me that tom is, i still won't date him. [SEP]
========================
predicted: 
========================
[CLS] they tom is believed that tom handsome is meigate date. though anymoresiah is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.065 | p: 60.000 | r: 56.250
rouge2     | fm: 13.793 | p: 14.286 | r: 13.333
rougeL     | fm: 45.161 | p: 46.667 | r: 43.750
rougeLsum  | fm: 45.161 | p: 46.667 | r: 43.750
r1fm+r2fm = 71.858

[Aggregate metrics]:
rouge1     | fm: 76.648 | p: 76.813 | r: 76.709
rouge2     | fm: 36.547 | p: 36.525 | r: 36.797
rougeL     | fm: 68.154 | p: 68.271 | r: 68.181
rougeLsum  | fm: 68.256 | p: 68.477 | r: 68.263
r1fm+r2fm = 113.195

input #89 time: 0:12:04 | total time: 17:53:36


Running input #90 of 100.
reference: 
========================
Moya's football team loved her
========================
average of cosine similarity 0.999047794869178
highest_index [0]
highest [0.999047794869178]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9587, 3148, 1005, 1055, 2374, 2136, 3866, 2014,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] moya's football team loved her [SEP]"]
[Init] best rec loss: 0.8145118355751038 for ['[CLS]rra person gasp shit rex become snow dunn [SEP]']
[Init] best rec loss: 0.7674447298049927 for ['[CLS]real collapses daltonfe spitting arrivedowa ye [SEP]']
[Init] best rec loss: 0.7560601830482483 for ['[CLS] coached madeline see else air detail talking chapel [SEP]']
[Init] best perm rec loss: 0.7503290176391602 for ['[CLS] air talking coached detail else see madeline chapel [SEP]']
[Init] best perm rec loss: 0.7498154044151306 for ['[CLS] else madeline coached air see talking chapel detail [SEP]']
[Init] best perm rec loss: 0.7486680150032043 for ['[CLS] detail air chapel see else talking madeline coached [SEP]']
[Init] best perm rec loss: 0.7475584149360657 for ['[CLS] chapel coached detail madeline see else talking air [SEP]']
[Init] best perm rec loss: 0.7467872500419617 for ['[CLS] talking madeline chapel detail air else see coached [SEP]']
[Init] best perm rec loss: 0.7457957863807678 for ['[CLS] talking detail coached see air else chapel madeline [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.450 (perp=10.786, rec=0.526, cos=0.767), tot_loss_proj:4.082 [t=0.29s]
prediction: ['[CLS] you bit elijah nonyaya university going [SEP]']
[ 100/2000] tot_loss=3.549 (perp=12.072, rec=0.362, cos=0.773), tot_loss_proj:4.214 [t=0.30s]
prediction: ['[CLS] mo interestsya biyaya boys quit [SEP]']
[ 150/2000] tot_loss=3.406 (perp=11.911, rec=0.287, cos=0.737), tot_loss_proj:4.224 [t=0.30s]
prediction: ["[CLS] mozzlingya 'yaya players popular [SEP]"]
[ 200/2000] tot_loss=3.430 (perp=12.111, rec=0.237, cos=0.772), tot_loss_proj:4.344 [t=0.30s]
prediction: ["[CLS] mo likedya 'yaya pageant behind [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.164 (perp=11.068, rec=0.219, cos=0.732), tot_loss_proj:4.126 [t=0.30s]
prediction: ['[CLS] mo liked handballyaya football team her [SEP]']
[ 300/2000] tot_loss=2.964 (perp=10.194, rec=0.196, cos=0.729), tot_loss_proj:3.956 [t=0.30s]
prediction: ['[CLS] mo liked fifa sya football team her [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.244 (perp=11.580, rec=0.193, cos=0.735), tot_loss_proj:4.257 [t=0.30s]
prediction: ['[CLS] moander her sya team team her [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.228 (perp=11.192, rec=0.242, cos=0.748), tot_loss_proj:4.101 [t=0.30s]
prediction: ['[CLS] mo loved surprisingly footballya s team her [SEP]']
[ 450/2000] tot_loss=2.935 (perp=10.161, rec=0.182, cos=0.720), tot_loss_proj:3.960 [t=0.30s]
prediction: ['[CLS] mo loved her footballya s team her [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.868 (perp=9.701, rec=0.189, cos=0.739), tot_loss_proj:3.816 [t=0.30s]
prediction: ['[CLS] mo loved herya s football team her [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.830 (perp=9.701, rec=0.172, cos=0.718), tot_loss_proj:3.817 [t=0.30s]
prediction: ['[CLS] mo loved herya s football team her [SEP]']
[ 600/2000] tot_loss=2.816 (perp=9.701, rec=0.161, cos=0.715), tot_loss_proj:3.815 [t=0.30s]
prediction: ['[CLS] mo loved herya s football team her [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.835 (perp=9.780, rec=0.163, cos=0.717), tot_loss_proj:3.885 [t=0.30s]
prediction: ['[CLS] mo s herya liked football team her [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.694 (perp=8.954, rec=0.188, cos=0.715), tot_loss_proj:3.729 [t=0.30s]
prediction: ['[CLS] s modleyya liked football team her [SEP]']
[ 750/2000] tot_loss=2.959 (perp=10.369, rec=0.166, cos=0.719), tot_loss_proj:3.974 [t=0.30s]
prediction: ['[CLS] s mo importantlyya liked football team her [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.808 (perp=9.483, rec=0.183, cos=0.729), tot_loss_proj:3.788 [t=0.30s]
prediction: ['[CLS] s moyadley liked football team her [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.944 (perp=10.369, rec=0.158, cos=0.712), tot_loss_proj:3.970 [t=0.30s]
prediction: ['[CLS] s mo importantlyya liked football team her [SEP]']
[ 900/2000] tot_loss=2.689 (perp=8.954, rec=0.175, cos=0.723), tot_loss_proj:3.734 [t=0.30s]
prediction: ['[CLS] s modleyya liked football team her [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.873 (perp=10.021, rec=0.151, cos=0.718), tot_loss_proj:3.822 [t=0.30s]
prediction: ['[CLS] s mo importantlyya football team liked her [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.760 (perp=9.224, rec=0.168, cos=0.747), tot_loss_proj:3.753 [t=0.30s]
prediction: ['[CLS] s moya importantly football team liked her [SEP]']
[1050/2000] tot_loss=2.729 (perp=9.224, rec=0.163, cos=0.721), tot_loss_proj:3.751 [t=0.30s]
prediction: ['[CLS] s moya importantly football team liked her [SEP]']
Attempt swap
[1100/2000] tot_loss=2.726 (perp=9.224, rec=0.167, cos=0.714), tot_loss_proj:3.747 [t=0.30s]
prediction: ['[CLS] s moya importantly football team liked her [SEP]']
Attempt swap
[1150/2000] tot_loss=2.729 (perp=9.224, rec=0.162, cos=0.722), tot_loss_proj:3.754 [t=0.30s]
prediction: ['[CLS] s moya importantly football team liked her [SEP]']
[1200/2000] tot_loss=2.721 (perp=9.224, rec=0.156, cos=0.720), tot_loss_proj:3.748 [t=0.30s]
prediction: ['[CLS] s moya importantly football team liked her [SEP]']
Attempt swap
[1250/2000] tot_loss=2.723 (perp=9.224, rec=0.162, cos=0.717), tot_loss_proj:3.750 [t=0.30s]
prediction: ['[CLS] s moya importantly football team liked her [SEP]']
Attempt swap
[1300/2000] tot_loss=2.728 (perp=9.224, rec=0.164, cos=0.719), tot_loss_proj:3.754 [t=0.30s]
prediction: ['[CLS] s moya importantly football team liked her [SEP]']
[1350/2000] tot_loss=2.735 (perp=9.224, rec=0.170, cos=0.721), tot_loss_proj:3.753 [t=0.30s]
prediction: ['[CLS] s moya importantly football team liked her [SEP]']
Attempt swap
[1400/2000] tot_loss=2.724 (perp=9.224, rec=0.157, cos=0.723), tot_loss_proj:3.751 [t=0.30s]
prediction: ['[CLS] s moya importantly football team liked her [SEP]']
Attempt swap
[1450/2000] tot_loss=2.487 (perp=8.091, rec=0.148, cos=0.721), tot_loss_proj:3.466 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
[1500/2000] tot_loss=2.487 (perp=8.091, rec=0.146, cos=0.722), tot_loss_proj:3.469 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
Attempt swap
[1550/2000] tot_loss=2.501 (perp=8.091, rec=0.162, cos=0.721), tot_loss_proj:3.466 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
Attempt swap
[1600/2000] tot_loss=2.487 (perp=8.091, rec=0.145, cos=0.723), tot_loss_proj:3.468 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
[1650/2000] tot_loss=2.489 (perp=8.091, rec=0.150, cos=0.721), tot_loss_proj:3.465 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
Attempt swap
[1700/2000] tot_loss=2.507 (perp=8.091, rec=0.166, cos=0.723), tot_loss_proj:3.464 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
Attempt swap
[1750/2000] tot_loss=2.497 (perp=8.091, rec=0.155, cos=0.723), tot_loss_proj:3.470 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
[1800/2000] tot_loss=2.497 (perp=8.091, rec=0.155, cos=0.724), tot_loss_proj:3.470 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
Attempt swap
[1850/2000] tot_loss=2.491 (perp=8.091, rec=0.150, cos=0.724), tot_loss_proj:3.467 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
Attempt swap
[1900/2000] tot_loss=2.505 (perp=8.091, rec=0.163, cos=0.724), tot_loss_proj:3.467 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
[1950/2000] tot_loss=2.489 (perp=8.091, rec=0.146, cos=0.725), tot_loss_proj:3.473 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
Attempt swap
[2000/2000] tot_loss=2.497 (perp=8.091, rec=0.155, cos=0.723), tot_loss_proj:3.463 [t=0.30s]
prediction: ['[CLS] s moya loved football team liked her [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] moya's football team loved her [SEP]
========================
predicted: 
========================
[CLS] s moya loved football team liked her [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 26.667 | p: 25.000 | r: 28.571
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 120.784

[Aggregate metrics]:
rouge1     | fm: 76.884 | p: 76.957 | r: 76.986
rouge2     | fm: 36.574 | p: 36.523 | r: 36.689
rougeL     | fm: 68.158 | p: 68.309 | r: 68.212
rougeLsum  | fm: 68.297 | p: 68.436 | r: 68.394
r1fm+r2fm = 113.458

input #90 time: 0:11:50 | total time: 18:05:26


Running input #91 of 100.
reference: 
========================
They investigated the problem.
========================
average of cosine similarity 0.9988298556750697
highest_index [0]
highest [0.9988298556750697]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2027, 10847,  1996,  3291,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] they investigated the problem. [SEP]']
[Init] best rec loss: 0.9051334857940674 for ['[CLS] non trap brackets opposite mbe [SEP]']
[Init] best rec loss: 0.834531307220459 for ['[CLS] nope rare chief steveyon [SEP]']
[Init] best rec loss: 0.7885618209838867 for ['[CLS]w czech real mrference [SEP]']
[Init] best perm rec loss: 0.7878525257110596 for ['[CLS]wference czech real mr [SEP]']
[Init] best perm rec loss: 0.7823255658149719 for ['[CLS] realw mr czechference [SEP]']
[Init] best perm rec loss: 0.7820622324943542 for ['[CLS]ference real czech mrw [SEP]']
[Init] best perm rec loss: 0.7814227938652039 for ['[CLS] mrferencew czech real [SEP]']
[Init] best perm rec loss: 0.7808833718299866 for ['[CLS] real mrferencew czech [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.824 (perp=11.169, rec=0.699, cos=0.891), tot_loss_proj:4.142 [t=0.29s]
prediction: ['[CLS] played [ nflw stop [SEP]']
[ 100/2000] tot_loss=4.216 (perp=13.544, rec=0.606, cos=0.902), tot_loss_proj:4.661 [t=0.30s]
prediction: ['[CLS] played [ reportedly serbian championships [SEP]']
[ 150/2000] tot_loss=4.046 (perp=13.913, rec=0.508, cos=0.755), tot_loss_proj:4.679 [t=0.30s]
prediction: ['[CLS] investigated [ guitar serbian lie [SEP]']
[ 200/2000] tot_loss=4.122 (perp=14.268, rec=0.457, cos=0.812), tot_loss_proj:4.729 [t=0.30s]
prediction: ['[CLS] investigated [ johnnywr lie [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.648 (perp=12.600, rec=0.429, cos=0.699), tot_loss_proj:4.485 [t=0.30s]
prediction: ['[CLS] [ nfl drug investigated reservoir [SEP]']
[ 300/2000] tot_loss=3.325 (perp=11.523, rec=0.369, cos=0.651), tot_loss_proj:4.041 [t=0.30s]
prediction: ['[CLS] they johnny drug investigated problem [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.512 (perp=7.568, rec=0.337, cos=0.662), tot_loss_proj:2.770 [t=0.30s]
prediction: ['[CLS] they investigated his drug problem [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.480 (perp=7.568, rec=0.317, cos=0.650), tot_loss_proj:2.746 [t=0.30s]
prediction: ['[CLS] they investigated his drug problem [SEP]']
[ 450/2000] tot_loss=2.844 (perp=9.240, rec=0.312, cos=0.684), tot_loss_proj:3.685 [t=0.30s]
prediction: ['[CLS] they investigated finals problem problem [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.892 (perp=9.572, rec=0.295, cos=0.683), tot_loss_proj:3.720 [t=0.30s]
prediction: ['[CLS] they investigatedaround problem problem [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.794 (perp=9.274, rec=0.280, cos=0.659), tot_loss_proj:3.595 [t=0.30s]
prediction: ['[CLS] they investigated different problem problem [SEP]']
[ 600/2000] tot_loss=3.037 (perp=10.329, rec=0.269, cos=0.702), tot_loss_proj:3.835 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.015 (perp=10.329, rec=0.265, cos=0.684), tot_loss_proj:3.830 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.990 (perp=10.329, rec=0.256, cos=0.668), tot_loss_proj:3.838 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
[ 750/2000] tot_loss=2.998 (perp=10.329, rec=0.260, cos=0.672), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.000 (perp=10.329, rec=0.246, cos=0.688), tot_loss_proj:3.838 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.976 (perp=10.329, rec=0.238, cos=0.673), tot_loss_proj:3.835 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
[ 900/2000] tot_loss=2.993 (perp=10.329, rec=0.244, cos=0.684), tot_loss_proj:3.839 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.986 (perp=10.329, rec=0.238, cos=0.682), tot_loss_proj:3.836 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1000/2000] tot_loss=2.988 (perp=10.329, rec=0.240, cos=0.682), tot_loss_proj:3.834 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
[1050/2000] tot_loss=2.982 (perp=10.329, rec=0.239, cos=0.677), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1100/2000] tot_loss=2.976 (perp=10.329, rec=0.232, cos=0.678), tot_loss_proj:3.840 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1150/2000] tot_loss=2.977 (perp=10.329, rec=0.230, cos=0.682), tot_loss_proj:3.842 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
[1200/2000] tot_loss=2.986 (perp=10.329, rec=0.239, cos=0.681), tot_loss_proj:3.837 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1250/2000] tot_loss=2.990 (perp=10.329, rec=0.244, cos=0.680), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1300/2000] tot_loss=2.983 (perp=10.329, rec=0.239, cos=0.679), tot_loss_proj:3.842 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
[1350/2000] tot_loss=2.989 (perp=10.329, rec=0.245, cos=0.678), tot_loss_proj:3.839 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1400/2000] tot_loss=2.977 (perp=10.329, rec=0.238, cos=0.674), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1450/2000] tot_loss=2.986 (perp=10.329, rec=0.248, cos=0.673), tot_loss_proj:3.839 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
[1500/2000] tot_loss=2.981 (perp=10.329, rec=0.241, cos=0.675), tot_loss_proj:3.843 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1550/2000] tot_loss=2.980 (perp=10.329, rec=0.239, cos=0.675), tot_loss_proj:3.842 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1600/2000] tot_loss=2.977 (perp=10.329, rec=0.233, cos=0.679), tot_loss_proj:3.844 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
[1650/2000] tot_loss=2.961 (perp=10.329, rec=0.220, cos=0.676), tot_loss_proj:3.836 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1700/2000] tot_loss=2.975 (perp=10.329, rec=0.235, cos=0.674), tot_loss_proj:3.839 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1750/2000] tot_loss=2.967 (perp=10.329, rec=0.225, cos=0.676), tot_loss_proj:3.847 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
[1800/2000] tot_loss=2.967 (perp=10.329, rec=0.226, cos=0.676), tot_loss_proj:3.845 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1850/2000] tot_loss=2.967 (perp=10.329, rec=0.226, cos=0.675), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[1900/2000] tot_loss=2.955 (perp=10.329, rec=0.216, cos=0.673), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
[1950/2000] tot_loss=2.966 (perp=10.329, rec=0.226, cos=0.675), tot_loss_proj:3.841 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Attempt swap
[2000/2000] tot_loss=2.983 (perp=10.329, rec=0.242, cos=0.675), tot_loss_proj:3.844 [t=0.30s]
prediction: ['[CLS] they investigated problem problem problem [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] they investigated the problem. [SEP]
========================
predicted: 
========================
[CLS] they investigated problem problem problem [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 54.545 | p: 50.000 | r: 60.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 131.469

[Aggregate metrics]:
rouge1     | fm: 76.910 | p: 76.920 | r: 77.073
rouge2     | fm: 36.676 | p: 36.561 | r: 36.914
rougeL     | fm: 68.252 | p: 68.351 | r: 68.425
rougeLsum  | fm: 68.357 | p: 68.464 | r: 68.547
r1fm+r2fm = 113.586

input #91 time: 0:11:48 | total time: 18:17:14


Running input #92 of 100.
reference: 
========================
Andy promised that we would go.
========================
average of cosine similarity 0.999046897394503
highest_index [0]
highest [0.999046897394503]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 5557, 5763, 2008, 2057, 2052, 2175, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] andy promised that we would go. [SEP]']
[Init] best rec loss: 0.9365084767341614 for ['[CLS] church shade features forwardlateral one ⟨ [SEP]']
[Init] best rec loss: 0.9308006167411804 for ['[CLS] mateo namely there electronics resort with knows [SEP]']
[Init] best rec loss: 0.8862055540084839 for ['[CLS]rained absolutely children winnie royal trial kids [SEP]']
[Init] best rec loss: 0.8749348521232605 for ['[CLS] internal fulfillinghel church hanging choice heath [SEP]']
[Init] best rec loss: 0.8281758427619934 for ['[CLS] deputy clint node ra measured wonders light [SEP]']
[Init] best perm rec loss: 0.8277300000190735 for ['[CLS] wonders measured ra node deputy clint light [SEP]']
[Init] best perm rec loss: 0.8270149827003479 for ['[CLS] clint light node measured deputy wonders ra [SEP]']
[Init] best perm rec loss: 0.8265504837036133 for ['[CLS] light clint node wonders deputy measured ra [SEP]']
[Init] best perm rec loss: 0.8252168297767639 for ['[CLS] deputy measured wonders ra clint node light [SEP]']
[Init] best perm rec loss: 0.8234454393386841 for ['[CLS] measured node ra wonders light deputy clint [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.890 (perp=11.590, rec=0.598, cos=0.974), tot_loss_proj:4.044 [t=0.29s]
prediction: ['[CLS] sylvie ltd contains range as announcement another [SEP]']
[ 100/2000] tot_loss=3.692 (perp=11.523, rec=0.455, cos=0.933), tot_loss_proj:4.151 [t=0.30s]
prediction: ['[CLS]cards promised promised50. supper that [SEP]']
[ 150/2000] tot_loss=3.269 (perp=9.987, rec=0.377, cos=0.894), tot_loss_proj:3.901 [t=0.30s]
prediction: ['[CLS] andy andy promised andy. supper that [SEP]']
[ 200/2000] tot_loss=3.595 (perp=11.752, rec=0.388, cos=0.856), tot_loss_proj:4.255 [t=0.30s]
prediction: ['[CLS] andy andy promised we that supperptive [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.172 (perp=10.024, rec=0.336, cos=0.832), tot_loss_proj:3.861 [t=0.30s]
prediction: ['[CLS] andy andy promised we fanny would that [SEP]']
[ 300/2000] tot_loss=3.278 (perp=10.024, rec=0.363, cos=0.910), tot_loss_proj:3.859 [t=0.30s]
prediction: ['[CLS] andy andy promised we fanny would that [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.947 (perp=8.887, rec=0.308, cos=0.861), tot_loss_proj:3.663 [t=0.30s]
prediction: ['[CLS] andy andy promised that fanny would we [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.934 (perp=8.906, rec=0.289, cos=0.864), tot_loss_proj:3.669 [t=0.30s]
prediction: ['[CLS] andy andy promised that plenty we would [SEP]']
[ 450/2000] tot_loss=2.954 (perp=8.906, rec=0.284, cos=0.889), tot_loss_proj:3.664 [t=0.30s]
prediction: ['[CLS] andy andy promised that plenty we would [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.918 (perp=8.906, rec=0.267, cos=0.870), tot_loss_proj:3.667 [t=0.30s]
prediction: ['[CLS] andy andy promised that plenty we would [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.907 (perp=8.906, rec=0.249, cos=0.877), tot_loss_proj:3.672 [t=0.30s]
prediction: ['[CLS] andy andy promised that plenty we would [SEP]']
[ 600/2000] tot_loss=2.916 (perp=8.906, rec=0.260, cos=0.875), tot_loss_proj:3.672 [t=0.30s]
prediction: ['[CLS] andy andy promised that plenty we would [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.911 (perp=8.906, rec=0.255, cos=0.875), tot_loss_proj:3.671 [t=0.30s]
prediction: ['[CLS] andy andy promised that plenty we would [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.913 (perp=8.906, rec=0.248, cos=0.884), tot_loss_proj:3.668 [t=0.30s]
prediction: ['[CLS] andy andy promised that plenty we would [SEP]']
[ 750/2000] tot_loss=2.914 (perp=8.906, rec=0.249, cos=0.884), tot_loss_proj:3.669 [t=0.30s]
prediction: ['[CLS] andy andy promised that plenty we would [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.065 (perp=9.734, rec=0.243, cos=0.875), tot_loss_proj:3.766 [t=0.30s]
prediction: ['[CLS] andy andy promised thatounded we would [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.932 (perp=8.900, rec=0.266, cos=0.885), tot_loss_proj:3.396 [t=0.30s]
prediction: ['[CLS] andy andy promised yeah that we go [SEP]']
[ 900/2000] tot_loss=2.807 (perp=8.425, rec=0.242, cos=0.880), tot_loss_proj:3.292 [t=0.30s]
prediction: ['[CLS] andy andy promised yeah that we would [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.924 (perp=8.994, rec=0.240, cos=0.885), tot_loss_proj:3.570 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we would [SEP]']
Attempt swap
[1000/2000] tot_loss=2.932 (perp=8.994, rec=0.245, cos=0.888), tot_loss_proj:3.568 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we would [SEP]']
[1050/2000] tot_loss=2.930 (perp=8.994, rec=0.244, cos=0.888), tot_loss_proj:3.569 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we would [SEP]']
Attempt swap
[1100/2000] tot_loss=3.029 (perp=9.492, rec=0.249, cos=0.882), tot_loss_proj:3.609 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[1150/2000] tot_loss=3.029 (perp=9.492, rec=0.247, cos=0.883), tot_loss_proj:3.609 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
[1200/2000] tot_loss=3.017 (perp=9.492, rec=0.235, cos=0.884), tot_loss_proj:3.602 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[1250/2000] tot_loss=3.011 (perp=9.492, rec=0.229, cos=0.883), tot_loss_proj:3.604 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[1300/2000] tot_loss=3.014 (perp=9.492, rec=0.231, cos=0.884), tot_loss_proj:3.610 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
[1350/2000] tot_loss=3.027 (perp=9.492, rec=0.244, cos=0.885), tot_loss_proj:3.607 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[1400/2000] tot_loss=3.017 (perp=9.492, rec=0.232, cos=0.886), tot_loss_proj:3.603 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[1450/2000] tot_loss=3.014 (perp=9.492, rec=0.233, cos=0.883), tot_loss_proj:3.599 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
[1500/2000] tot_loss=3.026 (perp=9.492, rec=0.243, cos=0.884), tot_loss_proj:3.607 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[1550/2000] tot_loss=3.015 (perp=9.492, rec=0.234, cos=0.883), tot_loss_proj:3.598 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[1600/2000] tot_loss=3.020 (perp=9.492, rec=0.235, cos=0.887), tot_loss_proj:3.603 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
[1650/2000] tot_loss=3.021 (perp=9.492, rec=0.238, cos=0.884), tot_loss_proj:3.606 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[1700/2000] tot_loss=3.014 (perp=9.492, rec=0.231, cos=0.884), tot_loss_proj:3.606 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[1750/2000] tot_loss=3.027 (perp=9.492, rec=0.242, cos=0.886), tot_loss_proj:3.603 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
[1800/2000] tot_loss=3.014 (perp=9.492, rec=0.232, cos=0.884), tot_loss_proj:3.600 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[1850/2000] tot_loss=3.013 (perp=9.492, rec=0.230, cos=0.884), tot_loss_proj:3.597 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[1900/2000] tot_loss=3.022 (perp=9.492, rec=0.240, cos=0.883), tot_loss_proj:3.597 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
[1950/2000] tot_loss=3.013 (perp=9.492, rec=0.231, cos=0.884), tot_loss_proj:3.600 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Attempt swap
[2000/2000] tot_loss=3.022 (perp=9.492, rec=0.239, cos=0.885), tot_loss_proj:3.601 [t=0.30s]
prediction: ['[CLS]chemist andy promised yeah that we go [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] andy promised that we would go. [SEP]
========================
predicted: 
========================
[CLS]chemist andy promised yeah that we go [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 40.000 | p: 37.500 | r: 42.857
rougeL     | fm: 82.353 | p: 77.778 | r: 87.500
rougeLsum  | fm: 82.353 | p: 77.778 | r: 87.500
r1fm+r2fm = 122.353

[Aggregate metrics]:
rouge1     | fm: 76.907 | p: 76.897 | r: 77.128
rouge2     | fm: 36.768 | p: 36.623 | r: 36.973
rougeL     | fm: 68.453 | p: 68.443 | r: 68.641
rougeLsum  | fm: 68.503 | p: 68.541 | r: 68.681
r1fm+r2fm = 113.676

input #92 time: 0:11:50 | total time: 18:29:04


Running input #93 of 100.
reference: 
========================
I saw these dancers and those musicians smoking something.
========================
average of cosine similarity 0.9989996503646943
highest_index [0]
highest [0.9989996503646943]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1045,  2387,  2122, 10487,  1998,  2216,  5389,  9422,  2242,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] i saw these dancers and those musicians smoking something. [SEP]']
[Init] best rec loss: 0.9762965440750122 for ['[CLS] choir torque titled uttar 25 tell even hitch encounter choosing [SEP]']
[Init] best rec loss: 0.8796408772468567 for ['[CLS] version ltd blur ringinghs chip astro bandrized federal [SEP]']
[Init] best rec loss: 0.8708166480064392 for ['[CLS] race goreeld mir ab he figures squarelad truly [SEP]']
[Init] best rec loss: 0.8468301892280579 for ['[CLS] existing ten exposurekti understandvirus beyond appear cubs planted [SEP]']
[Init] best rec loss: 0.830560564994812 for ['[CLS] kitten asking two into congestion curtain whilethersu broadcaster [SEP]']
[Init] best rec loss: 0.8196613788604736 for ['[CLS] doadide... spinal pakistanworm read fortune vo [SEP]']
[Init] best rec loss: 0.8053984642028809 for ['[CLS]ction col an hunt adrian everywhere volunteers maneuverblaoo [SEP]']
[Init] best perm rec loss: 0.8030973672866821 for ['[CLS] hunt col an everywhere adrianbla volunteersction maneuveroo [SEP]']
[Init] best perm rec loss: 0.8030083179473877 for ['[CLS] col everywherebla volunteersction maneuver huntoo adrian an [SEP]']
[Init] best perm rec loss: 0.8005349040031433 for ['[CLS] maneuver everywherection colbla volunteers adrian an huntoo [SEP]']
[Init] best perm rec loss: 0.8003453612327576 for ['[CLS] an maneuver everywhere adrianction coloo hunt volunteersbla [SEP]']
[Init] best perm rec loss: 0.7993155717849731 for ['[CLS]blaoo adrian hunt maneuver an everywhere volunteers colction [SEP]']
[Init] best perm rec loss: 0.7992139458656311 for ['[CLS]bla everywhere maneuver volunteersction adrian hunt coloo an [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.320 (perp=10.084, rec=0.502, cos=0.801), tot_loss_proj:3.650 [t=0.29s]
prediction: ['[CLS] these steve ; described many malmo players wickets was pakistan [SEP]']
[ 100/2000] tot_loss=3.092 (perp=8.733, rec=0.435, cos=0.911), tot_loss_proj:3.565 [t=0.30s]
prediction: ['[CLS] these dancers ; and these perform players musicians smoking something [SEP]']
[ 150/2000] tot_loss=3.254 (perp=10.048, rec=0.394, cos=0.851), tot_loss_proj:3.750 [t=0.30s]
prediction: ['[CLS] these dancers championship these these those musicians musicians smoking something [SEP]']
[ 200/2000] tot_loss=3.210 (perp=10.076, rec=0.319, cos=0.875), tot_loss_proj:3.686 [t=0.30s]
prediction: ['[CLS] these dancers container and saw those musicians something smoking something [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.843 (perp=8.483, rec=0.322, cos=0.824), tot_loss_proj:3.558 [t=0.30s]
prediction: ['[CLS] these dancers ji and saw these musicians smoking something? [SEP]']
[ 300/2000] tot_loss=2.733 (perp=8.242, rec=0.274, cos=0.811), tot_loss_proj:3.557 [t=0.30s]
prediction: ['[CLS] these dancers pregnant and saw those musicians smoking something as [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.696 (perp=8.187, rec=0.229, cos=0.830), tot_loss_proj:3.489 [t=0.30s]
prediction: ['[CLS] those dancers pregnant and saw those musicians smoking as something [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.708 (perp=8.187, rec=0.220, cos=0.850), tot_loss_proj:3.486 [t=0.30s]
prediction: ['[CLS] those dancers pregnant and saw those musicians smoking as something [SEP]']
[ 450/2000] tot_loss=2.678 (perp=8.113, rec=0.212, cos=0.844), tot_loss_proj:3.478 [t=0.30s]
prediction: ['[CLS] those dancers pregnant and saw these musicians smoking as something [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.959 (perp=9.526, rec=0.211, cos=0.843), tot_loss_proj:3.727 [t=0.30s]
prediction: ['[CLS] those dancers pregnant and sawrative musicians smoking as something [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.033 (perp=9.526, rec=0.226, cos=0.902), tot_loss_proj:3.729 [t=0.30s]
prediction: ['[CLS] those dancers pregnant and sawrative musicians smoking as something [SEP]']
[ 600/2000] tot_loss=2.952 (perp=9.526, rec=0.200, cos=0.847), tot_loss_proj:3.726 [t=0.30s]
prediction: ['[CLS] those dancers pregnant and sawrative musicians smoking as something [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.910 (perp=9.305, rec=0.202, cos=0.847), tot_loss_proj:3.698 [t=0.30s]
prediction: ['[CLS] those pregnant dancers and sawrative musicians smoking as something [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.917 (perp=9.305, rec=0.210, cos=0.846), tot_loss_proj:3.708 [t=0.30s]
prediction: ['[CLS] those pregnant dancers and sawrative musicians smoking as something [SEP]']
[ 750/2000] tot_loss=2.914 (perp=9.305, rec=0.197, cos=0.856), tot_loss_proj:3.703 [t=0.30s]
prediction: ['[CLS] those pregnant dancers and sawrative musicians smoking as something [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.922 (perp=9.403, rec=0.200, cos=0.842), tot_loss_proj:3.729 [t=0.30s]
prediction: ['[CLS] those pregnant dancers and sawworm musicians smoking as something [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.986 (perp=9.699, rec=0.198, cos=0.849), tot_loss_proj:3.771 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
[ 900/2000] tot_loss=2.985 (perp=9.699, rec=0.197, cos=0.848), tot_loss_proj:3.772 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.981 (perp=9.699, rec=0.192, cos=0.849), tot_loss_proj:3.772 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
Attempt swap
[1000/2000] tot_loss=2.990 (perp=9.699, rec=0.198, cos=0.852), tot_loss_proj:3.773 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
[1050/2000] tot_loss=2.983 (perp=9.699, rec=0.188, cos=0.855), tot_loss_proj:3.775 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
Attempt swap
[1100/2000] tot_loss=2.999 (perp=9.699, rec=0.202, cos=0.857), tot_loss_proj:3.770 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
Attempt swap
[1150/2000] tot_loss=2.992 (perp=9.699, rec=0.199, cos=0.854), tot_loss_proj:3.771 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
[1200/2000] tot_loss=2.986 (perp=9.699, rec=0.194, cos=0.852), tot_loss_proj:3.773 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
Attempt swap
[1250/2000] tot_loss=2.984 (perp=9.699, rec=0.190, cos=0.854), tot_loss_proj:3.774 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
Attempt swap
[1300/2000] tot_loss=2.998 (perp=9.699, rec=0.204, cos=0.854), tot_loss_proj:3.768 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
[1350/2000] tot_loss=2.983 (perp=9.699, rec=0.189, cos=0.854), tot_loss_proj:3.775 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
Attempt swap
[1400/2000] tot_loss=2.982 (perp=9.699, rec=0.188, cos=0.854), tot_loss_proj:3.776 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
Attempt swap
[1450/2000] tot_loss=2.992 (perp=9.699, rec=0.193, cos=0.859), tot_loss_proj:3.774 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking as something [SEP]']
[1500/2000] tot_loss=3.010 (perp=9.852, rec=0.185, cos=0.854), tot_loss_proj:3.598 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking. something [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.865 (perp=9.072, rec=0.195, cos=0.855), tot_loss_proj:3.201 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking something. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.860 (perp=9.072, rec=0.190, cos=0.855), tot_loss_proj:3.201 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking something. [SEP]']
[1650/2000] tot_loss=2.865 (perp=9.072, rec=0.195, cos=0.856), tot_loss_proj:3.202 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking something. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.869 (perp=9.072, rec=0.200, cos=0.855), tot_loss_proj:3.197 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking something. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.864 (perp=9.072, rec=0.193, cos=0.856), tot_loss_proj:3.203 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking something. [SEP]']
[1800/2000] tot_loss=2.861 (perp=9.072, rec=0.190, cos=0.856), tot_loss_proj:3.203 [t=0.30s]
prediction: ['[CLS] those interception dancers and sawworm musicians smoking something. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.780 (perp=8.682, rec=0.186, cos=0.857), tot_loss_proj:3.552 [t=0.30s]
prediction: ['[CLS] those quite dancers and sawworm musicians smoking something. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.787 (perp=8.682, rec=0.195, cos=0.856), tot_loss_proj:3.552 [t=0.30s]
prediction: ['[CLS] those quite dancers and sawworm musicians smoking something. [SEP]']
[1950/2000] tot_loss=2.792 (perp=8.682, rec=0.199, cos=0.856), tot_loss_proj:3.549 [t=0.30s]
prediction: ['[CLS] those quite dancers and sawworm musicians smoking something. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.787 (perp=8.682, rec=0.193, cos=0.857), tot_loss_proj:3.555 [t=0.30s]
prediction: ['[CLS] those quite dancers and sawworm musicians smoking something. [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] i saw these dancers and those musicians smoking something. [SEP]
========================
predicted: 
========================
[CLS] those interception dancers and sawworm musicians smoking as something [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 72.727 | r: 72.727
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 102.727

[Aggregate metrics]:
rouge1     | fm: 76.924 | p: 76.897 | r: 77.160
rouge2     | fm: 36.722 | p: 36.569 | r: 36.979
rougeL     | fm: 68.275 | p: 68.345 | r: 68.492
rougeLsum  | fm: 68.400 | p: 68.444 | r: 68.584
r1fm+r2fm = 113.646

input #93 time: 0:11:49 | total time: 18:40:53


Running input #94 of 100.
reference: 
========================
Ayala sent back her cousin the diamond necklace.
========================
average of cosine similarity 0.998857101876278
highest_index [0]
highest [0.998857101876278]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  2067,  2014,  5542,  1996,  6323, 13016,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ayala sent back her cousin the diamond necklace. [SEP]']
[Init] best rec loss: 0.9192215800285339 for ['[CLS] universe car flight volume stem? fangs naturally port produced [SEP]']
[Init] best rec loss: 0.7806178331375122 for ['[CLS] c2 guysament means tucker indicated corresponding likes instead shifters [SEP]']
[Init] best rec loss: 0.7770667672157288 for ['[CLS] panda boys granite above could could masszle bollywoodtile [SEP]']
[Init] best rec loss: 0.7616288065910339 for ['[CLS] nina weights micah economy ladyaciesffled feeling harbor mt [SEP]']
[Init] best rec loss: 0.7406652569770813 for ['[CLS] consecutive [MASK] brother safe grows collect janeiroably e produced [SEP]']
[Init] best rec loss: 0.7390843033790588 for ['[CLS] commander system country ca young orleans facial yhaus boring [SEP]']
[Init] best rec loss: 0.7380303144454956 for ['[CLS] chartered cult4chment boat six cinder bothered eminentacies [SEP]']
[Init] best rec loss: 0.7362170815467834 for ['[CLS] origin rama jeep writes associate dial designated every motivation sip [SEP]']
[Init] best rec loss: 0.7343800067901611 for ['[CLS] rooted soft motorway with affiliated brian hotel language literature practices [SEP]']
[Init] best rec loss: 0.7341273427009583 for ['[CLS]edge awareness champions being herself h derek label missions fits [SEP]']
[Init] best rec loss: 0.7316197752952576 for ['[CLS] agency ~ cemeteries birth balance but austria same softly bright [SEP]']
[Init] best rec loss: 0.7219905853271484 for ['[CLS] o planned emirates fra conditioned simpsonlund client regulations friendly [SEP]']
[Init] best perm rec loss: 0.7214484810829163 for ['[CLS] client olund regulations conditioned friendly simpson planned emirates fra [SEP]']
[Init] best perm rec loss: 0.7212842106819153 for ['[CLS] fra emirates conditioned friendly simpsonlund client planned o regulations [SEP]']
[Init] best perm rec loss: 0.7207794189453125 for ['[CLS] conditioned simpson emirates o client planned regulationslund friendly fra [SEP]']
[Init] best perm rec loss: 0.7202456593513489 for ['[CLS] simpson friendly conditionedlund client fra emirates planned o regulations [SEP]']
[Init] best perm rec loss: 0.7192239165306091 for ['[CLS] regulations simpsonlund client conditioned fra o emirates planned friendly [SEP]']
[Init] best perm rec loss: 0.7179132699966431 for ['[CLS] friendly simpson planned regulationslund fra o conditioned emirates client [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.825 (perp=12.071, rec=0.327, cos=0.083), tot_loss_proj:3.626 [t=0.29s]
prediction: ['[CLS] manga diamond sendingum necklace sent backyala money rule [SEP]']
[ 100/2000] tot_loss=2.474 (perp=11.332, rec=0.185, cos=0.023), tot_loss_proj:3.564 [t=0.30s]
prediction: ['[CLS]yala diamondyalated sent sent back cousin diamond necklace [SEP]']
[ 150/2000] tot_loss=2.241 (perp=10.488, rec=0.128, cos=0.015), tot_loss_proj:3.459 [t=0.30s]
prediction: ['[CLS]yala diamondyala the necklace sent back cousin the diamond [SEP]']
[ 200/2000] tot_loss=2.229 (perp=10.486, rec=0.108, cos=0.024), tot_loss_proj:3.550 [t=0.30s]
prediction: ['[CLS]yala heryala her necklace sent back cousin the necklace [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.990 (perp=9.365, rec=0.105, cos=0.011), tot_loss_proj:3.351 [t=0.30s]
prediction: ['[CLS]yala heryala sent her necklace back cousin the necklace [SEP]']
[ 300/2000] tot_loss=1.994 (perp=9.493, rec=0.088, cos=0.007), tot_loss_proj:3.246 [t=0.30s]
prediction: ['[CLS]yala.yala sent her necklace back cousin the diamond [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.785 (perp=8.468, rec=0.085, cos=0.007), tot_loss_proj:3.211 [t=0.30s]
prediction: ['[CLS]yala.yala sent her cousin the diamond necklace back [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.713 (perp=8.077, rec=0.090, cos=0.008), tot_loss_proj:2.768 [t=0.30s]
prediction: ['[CLS].yala sent her cousin the diamond necklace backyala [SEP]']
[ 450/2000] tot_loss=1.703 (perp=8.077, rec=0.082, cos=0.006), tot_loss_proj:2.773 [t=0.30s]
prediction: ['[CLS].yala sent her cousin the diamond necklace backyala [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.609 (perp=7.651, rec=0.072, cos=0.007), tot_loss_proj:2.811 [t=0.30s]
prediction: ['[CLS]yalayala sent her cousin the diamond necklace back. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.996 (perp=9.528, rec=0.083, cos=0.007), tot_loss_proj:2.723 [t=0.30s]
prediction: ['[CLS]yala cousin a sent her the diamond necklace back. [SEP]']
[ 600/2000] tot_loss=1.995 (perp=9.528, rec=0.083, cos=0.007), tot_loss_proj:2.736 [t=0.30s]
prediction: ['[CLS]yala cousin a sent her the diamond necklace back. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.331 (perp=6.181, rec=0.088, cos=0.007), tot_loss_proj:2.654 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.320 (perp=6.181, rec=0.077, cos=0.006), tot_loss_proj:2.656 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
[ 750/2000] tot_loss=1.324 (perp=6.181, rec=0.082, cos=0.006), tot_loss_proj:2.649 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.320 (perp=6.181, rec=0.077, cos=0.006), tot_loss_proj:2.641 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.319 (perp=6.181, rec=0.077, cos=0.006), tot_loss_proj:2.634 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
[ 900/2000] tot_loss=1.322 (perp=6.181, rec=0.080, cos=0.006), tot_loss_proj:2.628 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.305 (perp=6.181, rec=0.063, cos=0.006), tot_loss_proj:2.617 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.317 (perp=6.181, rec=0.074, cos=0.006), tot_loss_proj:2.620 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
[1050/2000] tot_loss=1.317 (perp=6.181, rec=0.075, cos=0.006), tot_loss_proj:2.619 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.322 (perp=6.181, rec=0.080, cos=0.006), tot_loss_proj:2.611 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.319 (perp=6.181, rec=0.076, cos=0.006), tot_loss_proj:2.610 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
[1200/2000] tot_loss=1.320 (perp=6.181, rec=0.078, cos=0.006), tot_loss_proj:2.610 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.317 (perp=6.181, rec=0.075, cos=0.006), tot_loss_proj:2.609 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.311 (perp=6.181, rec=0.069, cos=0.006), tot_loss_proj:2.602 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
[1350/2000] tot_loss=1.318 (perp=6.181, rec=0.076, cos=0.006), tot_loss_proj:2.613 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.318 (perp=6.181, rec=0.076, cos=0.006), tot_loss_proj:2.597 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.308 (perp=6.181, rec=0.066, cos=0.006), tot_loss_proj:2.605 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
[1500/2000] tot_loss=1.320 (perp=6.181, rec=0.078, cos=0.006), tot_loss_proj:2.599 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.317 (perp=6.181, rec=0.075, cos=0.006), tot_loss_proj:2.605 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.313 (perp=6.181, rec=0.070, cos=0.006), tot_loss_proj:2.596 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
[1650/2000] tot_loss=1.312 (perp=6.181, rec=0.070, cos=0.006), tot_loss_proj:2.602 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.307 (perp=6.181, rec=0.065, cos=0.006), tot_loss_proj:2.602 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.309 (perp=6.181, rec=0.067, cos=0.006), tot_loss_proj:2.603 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
[1800/2000] tot_loss=1.310 (perp=6.181, rec=0.067, cos=0.006), tot_loss_proj:2.596 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.319 (perp=6.181, rec=0.077, cos=0.006), tot_loss_proj:2.593 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.313 (perp=6.181, rec=0.071, cos=0.006), tot_loss_proj:2.599 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
[1950/2000] tot_loss=1.312 (perp=6.181, rec=0.070, cos=0.006), tot_loss_proj:2.595 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.318 (perp=6.181, rec=0.076, cos=0.006), tot_loss_proj:2.596 [t=0.30s]
prediction: ['[CLS] a cousinyala sent her the diamond necklace back. [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] ayala sent back her cousin the diamond necklace. [SEP]
========================
predicted: 
========================
[CLS] a cousinyala sent her the diamond necklace back. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 22.222 | p: 22.222 | r: 22.222
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 102.222

[Aggregate metrics]:
rouge1     | fm: 76.930 | p: 76.910 | r: 77.140
rouge2     | fm: 36.460 | p: 36.319 | r: 36.735
rougeL     | fm: 68.361 | p: 68.401 | r: 68.610
rougeLsum  | fm: 68.496 | p: 68.557 | r: 68.683
r1fm+r2fm = 113.389

input #94 time: 0:11:49 | total time: 18:52:43


Running input #95 of 100.
reference: 
========================
Brenda met.
========================
average of cosine similarity 0.9988858990963185
highest_index [0]
highest [0.9988858990963185]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15507,  2777,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] brenda met. [SEP]']
[Init] best rec loss: 0.9685977697372437 for ['[CLS]eptive day less [SEP]']
[Init] best rec loss: 0.8701177835464478 for ['[CLS]fall few why [SEP]']
[Init] best rec loss: 0.8108149766921997 for ['[CLS] princess horses domesday [SEP]']
[Init] best rec loss: 0.764092743396759 for ['[CLS]ave recorded head [SEP]']
[Init] best rec loss: 0.7442268133163452 for ['[CLS] boss back michigan [SEP]']
[Init] best rec loss: 0.7319600582122803 for ['[CLS] mary scott pending [SEP]']
[Init] best rec loss: 0.7297887802124023 for ['[CLS] guessctive ram [SEP]']
[Init] best perm rec loss: 0.7273240685462952 for ['[CLS]ctive guess ram [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.681 (perp=7.452, rec=0.175, cos=0.016), tot_loss_proj:1.606 [t=0.29s]
prediction: ['[CLS] brenda met. [SEP]']
[ 100/2000] tot_loss=1.572 (perp=7.452, rec=0.077, cos=0.005), tot_loss_proj:1.592 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[ 150/2000] tot_loss=1.560 (perp=7.452, rec=0.067, cos=0.003), tot_loss_proj:1.595 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[ 200/2000] tot_loss=1.555 (perp=7.452, rec=0.062, cos=0.002), tot_loss_proj:1.583 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.566 (perp=7.452, rec=0.073, cos=0.002), tot_loss_proj:1.585 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[ 300/2000] tot_loss=1.553 (perp=7.452, rec=0.061, cos=0.002), tot_loss_proj:1.591 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.568 (perp=7.452, rec=0.075, cos=0.002), tot_loss_proj:1.588 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.559 (perp=7.452, rec=0.066, cos=0.002), tot_loss_proj:1.579 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[ 450/2000] tot_loss=1.552 (perp=7.452, rec=0.059, cos=0.002), tot_loss_proj:1.579 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.557 (perp=7.452, rec=0.064, cos=0.002), tot_loss_proj:1.586 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.547 (perp=7.452, rec=0.054, cos=0.002), tot_loss_proj:1.569 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[ 600/2000] tot_loss=1.560 (perp=7.452, rec=0.068, cos=0.002), tot_loss_proj:1.585 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.547 (perp=7.452, rec=0.055, cos=0.002), tot_loss_proj:1.577 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.549 (perp=7.452, rec=0.056, cos=0.002), tot_loss_proj:1.589 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[ 750/2000] tot_loss=1.558 (perp=7.452, rec=0.065, cos=0.002), tot_loss_proj:1.587 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.550 (perp=7.452, rec=0.058, cos=0.002), tot_loss_proj:1.578 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.564 (perp=7.452, rec=0.072, cos=0.002), tot_loss_proj:1.579 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[ 900/2000] tot_loss=1.566 (perp=7.452, rec=0.074, cos=0.002), tot_loss_proj:1.587 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.546 (perp=7.452, rec=0.053, cos=0.002), tot_loss_proj:1.575 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.552 (perp=7.452, rec=0.059, cos=0.002), tot_loss_proj:1.587 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[1050/2000] tot_loss=1.556 (perp=7.452, rec=0.064, cos=0.002), tot_loss_proj:1.583 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.552 (perp=7.452, rec=0.059, cos=0.002), tot_loss_proj:1.576 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.554 (perp=7.452, rec=0.061, cos=0.002), tot_loss_proj:1.580 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[1200/2000] tot_loss=1.561 (perp=7.452, rec=0.069, cos=0.002), tot_loss_proj:1.589 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.552 (perp=7.452, rec=0.059, cos=0.002), tot_loss_proj:1.583 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.556 (perp=7.452, rec=0.063, cos=0.002), tot_loss_proj:1.586 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[1350/2000] tot_loss=1.555 (perp=7.452, rec=0.062, cos=0.002), tot_loss_proj:1.591 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.561 (perp=7.452, rec=0.068, cos=0.002), tot_loss_proj:1.582 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.564 (perp=7.452, rec=0.071, cos=0.002), tot_loss_proj:1.581 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[1500/2000] tot_loss=1.556 (perp=7.452, rec=0.063, cos=0.002), tot_loss_proj:1.570 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.550 (perp=7.452, rec=0.057, cos=0.002), tot_loss_proj:1.579 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.557 (perp=7.452, rec=0.065, cos=0.002), tot_loss_proj:1.578 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[1650/2000] tot_loss=1.554 (perp=7.452, rec=0.061, cos=0.002), tot_loss_proj:1.583 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.550 (perp=7.452, rec=0.057, cos=0.002), tot_loss_proj:1.589 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.562 (perp=7.452, rec=0.070, cos=0.002), tot_loss_proj:1.584 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[1800/2000] tot_loss=1.556 (perp=7.452, rec=0.063, cos=0.002), tot_loss_proj:1.580 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.550 (perp=7.452, rec=0.058, cos=0.002), tot_loss_proj:1.580 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.550 (perp=7.452, rec=0.057, cos=0.002), tot_loss_proj:1.582 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
[1950/2000] tot_loss=1.558 (perp=7.452, rec=0.066, cos=0.002), tot_loss_proj:1.579 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.549 (perp=7.452, rec=0.057, cos=0.002), tot_loss_proj:1.587 [t=0.30s]
prediction: ['[CLS] brenda met. [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] brenda met. [SEP]
========================
predicted: 
========================
[CLS] brenda met. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 77.124 | p: 77.148 | r: 77.382
rouge2     | fm: 37.182 | p: 37.038 | r: 37.493
rougeL     | fm: 68.667 | p: 68.719 | r: 68.890
rougeLsum  | fm: 68.847 | p: 68.901 | r: 69.081
r1fm+r2fm = 114.305

input #95 time: 0:11:48 | total time: 19:04:32


Running input #96 of 100.
reference: 
========================
Today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might.
========================
average of cosine similarity 0.9989885903490504
highest_index [0]
highest [0.9989885903490504]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  2651,  2045,  2003,  2210,  2030,  2053,  2880, 16011,  1997,
         11690,  2015,  1998,  5637,  2015,  2011,  1996,  2120,  2231,  1010,
          2348,  8392,  6867,  2453,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]']
[Init] best rec loss: 0.8475580215454102 for ['[CLS] typeilised exiary radha legislative spotlight latter jesse wonder passing opened church charm dropping santa authorities loan youth firm regarding 1930s border kirk [SEP]']
[Init] best rec loss: 0.8345586061477661 for ["[CLS] roleant committed'meister!ingcuting [SEP] 4 usual war edge truesun ragesal intervals james ana whereish serialized [SEP]"]
[Init] best rec loss: 0.822937548160553 for ['[CLS]! bernard gaelic love difficulty dynasty cargo thighs peel pot losses dynastysai unison security daniel bo motion plastic og unit noisecarbon shared [SEP]']
[Init] best rec loss: 0.8097867965698242 for ['[CLS]sy giant hood katharine facts count open championshid debt v8 launch grease cope again clock rate м will fancy ( spawning dragons yet [SEP]']
[Init] best perm rec loss: 0.8097823262214661 for ['[CLS] м will hood open facts grease debt champions fancy count giant dragonssy ( v8 katharine spawning again clock launchhid yet rate cope [SEP]']
[Init] best perm rec loss: 0.8090726137161255 for ['[CLS] giant clock again launch cope hood facts м count dragons will yet ( spawningsy grease v8 katharine debthid champions fancy open rate [SEP]']
[Init] best perm rec loss: 0.8088275790214539 for ['[CLS] clock champions dragons will yethid ( cope facts countsy v8 hood grease giant again spawning open debt rate м launch fancy katharine [SEP]']
[Init] best perm rec loss: 0.8088167905807495 for ['[CLS] м cope open facts dragons katharine spawningsy giant will launch rate fancy v8 yet ( clock counthid debt grease hood champions again [SEP]']
[Init] best perm rec loss: 0.8079385161399841 for ['[CLS] will clock katharine fancy grease again championssy launch spawning cope yet debt dragons hood м open giant facts ratehid ( count v8 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.804 (perp=13.084, rec=0.444, cos=0.744), tot_loss_proj:4.494 [t=0.30s]
prediction: ['[CLS] [SEP] directorial includes official tortricidae two ; ; hot girls assault shortly archaeological bands authorities probably black structural track announcer defeat [do freaking [SEP]']
[ 100/2000] tot_loss=3.323 (perp=11.215, rec=0.358, cos=0.722), tot_loss_proj:4.093 [t=0.30s]
prediction: ['[CLS] harassment colonel includes official national two never ; hot girls unless necessarily autonomous autonomous awards probably gay lesbian lesbian identity propaganda ( austria. [SEP]']
[ 150/2000] tot_loss=3.534 (perp=11.948, rec=0.440, cos=0.705), tot_loss_proj:4.217 [t=0.30s]
prediction: ['[CLS] [SEP] [SEP] in official sensitive consists wolves sometimes locomotive guns stayed = governmental jenks public violent by her gay.. rear investigatorsow [SEP]']
[ 200/2000] tot_loss=3.627 (perp=12.939, rec=0.340, cos=0.699), tot_loss_proj:4.464 [t=0.30s]
prediction: ["[CLS] harassment colonel at official adventistism riders today pmid lesbianology = governmental phoebe media violent din lesbian gay..'investigatorsow [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.522 (perp=12.262, rec=0.413, cos=0.656), tot_loss_proj:4.314 [t=0.30s]
prediction: ['[CLS] harassment por seldom national jewishing [SEP] today trailing gay was always governmental jenny media mainland colonel⁺ gay.. full investigatorsow [SEP]']
[ 300/2000] tot_loss=3.186 (perp=10.882, rec=0.338, cos=0.671), tot_loss_proj:4.061 [t=0.31s]
prediction: ['[CLS] harassment non seldom official americans in [SEP] today every gay lgbt = government the media public colonel lesbian gay.. full investigatorsow [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.935 (perp=9.660, rec=0.291, cos=0.713), tot_loss_proj:3.831 [t=0.30s]
prediction: ["[CLS] the non seldom national citizens is under today every gays = national harassment government public colonel lesbian gay..'investigatorsow [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.709 (perp=8.638, rec=0.278, cos=0.703), tot_loss_proj:3.651 [t=0.30s]
prediction: ["[CLS] the non seldom national having lesbian under today without lesbians = government harassment government autonomous agency is gay..'investigatorsow [SEP]"]
[ 450/2000] tot_loss=2.713 (perp=8.754, rec=0.290, cos=0.672), tot_loss_proj:3.673 [t=0.31s]
prediction: ["[CLS] the non seldom national citizens lesbian under today nobody lesbians = government harassment government autonomous agency in gay..'investigatorsow [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=2.779 (perp=9.029, rec=0.255, cos=0.719), tot_loss_proj:3.740 [t=0.31s]
prediction: ["[CLS] the non seldom national citizens lesbian under today harassment lesbianslands government government autonomous agency in gay harassment..'investigatorsow [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.689 (perp=8.791, rec=0.243, cos=0.688), tot_loss_proj:3.716 [t=0.30s]
prediction: ["[CLS] the non seldom nationalui lesbian by today nobody lesbianslands government autonomous government agency in gay harassment..'investigatorsow [SEP]"]
[ 600/2000] tot_loss=2.848 (perp=9.459, rec=0.246, cos=0.710), tot_loss_proj:3.853 [t=0.30s]
prediction: ["[CLS] the non seldom nationalui lesbian by today nobody lesbianholdinglands government autonomous government agency in gay harassment..'investigatorsow [SEP]"]
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.860 (perp=9.494, rec=0.250, cos=0.711), tot_loss_proj:3.819 [t=0.31s]
prediction: ["[CLS] the non seldom nationalui lesbian although today nobody lesbianholding cannot government autonomous government agency in gay harassment. investigatorsow.'[SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.650 (perp=8.550, rec=0.252, cos=0.688), tot_loss_proj:3.578 [t=0.31s]
prediction: ["[CLS] the non seldom nationalui lesbian. today nobody lesbians cannot government autonomous government agency in gay harassment although monitoringow.'[SEP]"]
[ 750/2000] tot_loss=2.678 (perp=8.786, rec=0.233, cos=0.687), tot_loss_proj:3.656 [t=0.31s]
prediction: ["[CLS] the non seldom nationalui lesbian. today no lesbianholding might government autonomous government agency in gay harassment although monitoringow.'[SEP]"]
Attempt swap
[ 800/2000] tot_loss=2.752 (perp=9.021, rec=0.249, cos=0.699), tot_loss_proj:3.680 [t=0.31s]
prediction: ["[CLS] the non seldom nationalui lesbian. today no lesbianholding would government autonomous government agency in olympic harassment although monitoringow.'[SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=2.727 (perp=8.931, rec=0.231, cos=0.710), tot_loss_proj:3.626 [t=0.30s]
prediction: ["[CLS] the non seldom nationalui lesbian. today no lesbian nrhp would government autonomous government agency in olympic harassment'although monitoringow. [SEP]"]
[ 900/2000] tot_loss=2.837 (perp=9.586, rec=0.230, cos=0.689), tot_loss_proj:3.754 [t=0.31s]
prediction: ["[CLS] the non mm nationalui lesbian. today no lesbian nrhp would government autonomous government agency in olympic harassment'although monitoringow. [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=2.690 (perp=8.803, rec=0.234, cos=0.695), tot_loss_proj:3.606 [t=0.30s]
prediction: ["[CLS] the non national entirelyui lesbian. today no lesbian nrhp would government autonomous government agency in olympic harassment'although monitoringow. [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.674 (perp=8.741, rec=0.235, cos=0.691), tot_loss_proj:3.602 [t=0.30s]
prediction: ["[CLS] the non national entirelyui lesbian. today no lesbian nrhp would government autonomous government agency in olympic harassment'monitoring althoughow. [SEP]"]
[1050/2000] tot_loss=2.683 (perp=8.741, rec=0.232, cos=0.702), tot_loss_proj:3.601 [t=0.30s]
prediction: ["[CLS] the non national entirelyui lesbian. today no lesbian nrhp would government autonomous government agency in olympic harassment'monitoring althoughow. [SEP]"]
Attempt swap
[1100/2000] tot_loss=2.697 (perp=8.687, rec=0.245, cos=0.714), tot_loss_proj:3.581 [t=0.30s]
prediction: ["[CLS] the non national entirelyui lesbian. today no lesbian nrhp would autonomous autonomous government agency in olympic harassment'monitoring althoughow. [SEP]"]
Attempt swap
[1150/2000] tot_loss=2.655 (perp=8.669, rec=0.227, cos=0.694), tot_loss_proj:3.604 [t=0.30s]
prediction: ["[CLS] the non national entirelyui lesbian. today no lesbian nrhp would autonomous autonomous government agency in olympic harassment'apparently althoughow. [SEP]"]
[1200/2000] tot_loss=2.657 (perp=8.669, rec=0.225, cos=0.698), tot_loss_proj:3.603 [t=0.31s]
prediction: ["[CLS] the non national entirelyui lesbian. today no lesbian nrhp would autonomous autonomous government agency in olympic harassment'apparently althoughow. [SEP]"]
Attempt swap
[1250/2000] tot_loss=2.666 (perp=8.669, rec=0.226, cos=0.706), tot_loss_proj:3.603 [t=0.31s]
prediction: ["[CLS] the non national entirelyui lesbian. today no lesbian nrhp would autonomous autonomous government agency in olympic harassment'apparently althoughow. [SEP]"]
Attempt swap
[1300/2000] tot_loss=2.673 (perp=8.669, rec=0.239, cos=0.700), tot_loss_proj:3.607 [t=0.30s]
prediction: ["[CLS] the non national entirelyui lesbian. today no lesbian nrhp would autonomous autonomous government agency in olympic harassment'apparently althoughow. [SEP]"]
[1350/2000] tot_loss=2.646 (perp=8.669, rec=0.210, cos=0.702), tot_loss_proj:3.606 [t=0.30s]
prediction: ["[CLS] the non national entirelyui lesbian. today no lesbian nrhp would autonomous autonomous government agency in olympic harassment'apparently althoughow. [SEP]"]
Attempt swap
[1400/2000] tot_loss=2.637 (perp=8.557, rec=0.223, cos=0.703), tot_loss_proj:3.621 [t=0.31s]
prediction: ["[CLS] the non national entirelyui lesbian. today no lesbian nrhp would autonomous autonomous government agency in olympic harassment'apparently although and. [SEP]"]
Attempt swap
[1450/2000] tot_loss=2.671 (perp=8.748, rec=0.219, cos=0.702), tot_loss_proj:3.653 [t=0.30s]
prediction: ["[CLS] the non national entirelyui lesbian. today no lesbian nrhp might autonomous autonomous government agency in olympic harassment'apparently although and. [SEP]"]
[1500/2000] tot_loss=2.749 (perp=9.070, rec=0.230, cos=0.705), tot_loss_proj:3.739 [t=0.31s]
prediction: ["[CLS] the non national byui lesbian. today no lesbian nrhp might autonomous autonomous government agency in olympic harassment'apparently although and. [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.599 (perp=8.305, rec=0.231, cos=0.707), tot_loss_proj:3.515 [t=0.31s]
prediction: ["[CLS] the non national entirelyui lesbian. and no lesbian [CLS] might autonomous autonomous government agency in olympic harassment'apparently although today. [SEP]"]
Attempt swap
[1600/2000] tot_loss=2.719 (perp=8.920, rec=0.229, cos=0.707), tot_loss_proj:3.670 [t=0.30s]
prediction: ['[CLS] the non national byui lesbian. and no lesbian [CLS] might autonomous autonomous government agency in olympic harassment / apparently although today. [SEP]']
[1650/2000] tot_loss=2.669 (perp=8.719, rec=0.220, cos=0.705), tot_loss_proj:3.643 [t=0.30s]
prediction: ['[CLS] the non national byui lesbian. and no lesbian [CLS] would autonomous autonomous government agency in olympic harassment / apparently although today. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.672 (perp=8.719, rec=0.220, cos=0.708), tot_loss_proj:3.645 [t=0.30s]
prediction: ['[CLS] the non national byui lesbian. and no lesbian [CLS] would autonomous autonomous government agency in olympic harassment / apparently although today. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.661 (perp=8.636, rec=0.227, cos=0.707), tot_loss_proj:3.592 [t=0.31s]
prediction: ['[CLS] the non national byui lesbian. and no lesbian [CLS] would autonomous autonomous government agency in olympic apparently / harassment although today. [SEP]']
[1800/2000] tot_loss=2.655 (perp=8.636, rec=0.223, cos=0.705), tot_loss_proj:3.589 [t=0.30s]
prediction: ['[CLS] the non national byui lesbian. and no lesbian [CLS] would autonomous autonomous government agency in olympic apparently / harassment although today. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.701 (perp=8.904, rec=0.215, cos=0.706), tot_loss_proj:3.639 [t=0.31s]
prediction: ['[CLS] the non national byui lesbian. and no lesbian [CLS] might autonomous autonomous government agency in olympic apparently / harassment although today. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.685 (perp=8.754, rec=0.224, cos=0.710), tot_loss_proj:3.573 [t=0.30s]
prediction: ['[CLS] the non by nationalui lesbian. and no lesbian [CLS] might autonomous autonomous government agency in olympic apparently / harassment although today. [SEP]']
[1950/2000] tot_loss=2.683 (perp=8.754, rec=0.225, cos=0.707), tot_loss_proj:3.576 [t=0.30s]
prediction: ['[CLS] the non by nationalui lesbian. and no lesbian [CLS] might autonomous autonomous government agency in olympic apparently / harassment although today. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.664 (perp=8.709, rec=0.214, cos=0.708), tot_loss_proj:3.585 [t=0.30s]
prediction: ['[CLS] the non by nationalui lesbian. and no lesbian [CLS] might autonomous autonomous government agency in olympic apparently / although harassment today. [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]
========================
predicted: 
========================
[CLS] the non national entirelyui lesbian. today no lesbian nrhp would autonomous autonomous government agency in olympic harassment'apparently although and. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 50.000 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 27.273 | p: 27.273 | r: 27.273
rougeLsum  | fm: 27.273 | p: 27.273 | r: 27.273
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 76.871 | p: 76.869 | r: 77.124
rouge2     | fm: 36.712 | p: 36.645 | r: 36.968
rougeL     | fm: 68.302 | p: 68.331 | r: 68.511
rougeLsum  | fm: 68.409 | p: 68.450 | r: 68.624
r1fm+r2fm = 113.583

input #96 time: 0:12:07 | total time: 19:16:40


Running input #97 of 100.
reference: 
========================
This oven cooks well.
========================
average of cosine similarity 0.9989643414861843
highest_index [0]
highest [0.9989643414861843]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2023, 17428, 26929,  2092,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] this oven cooks well. [SEP]']
[Init] best rec loss: 0.9957596659660339 for ['[CLS] representing savedm ft dynasty [SEP]']
[Init] best rec loss: 0.9741402864456177 for ['[CLS]gence charity g rain plain [SEP]']
[Init] best rec loss: 0.9256466627120972 for ['[CLS] comes cord movement flat lucian [SEP]']
[Init] best rec loss: 0.8996152877807617 for ['[CLS] lankanurne clutch finally say [SEP]']
[Init] best rec loss: 0.8843562602996826 for ['[CLS] series hit nsw brain di [SEP]']
[Init] best rec loss: 0.8601900339126587 for ['[CLS] alive sas mass fall why [SEP]']
[Init] best rec loss: 0.8300464153289795 for ['[CLS] gael gearbox deserve enough air [SEP]']
[Init] best perm rec loss: 0.8250062465667725 for ['[CLS] gael air gearbox enough deserve [SEP]']
[Init] best perm rec loss: 0.8243839144706726 for ['[CLS] enough deserve gearbox gael air [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.488 (perp=11.510, rec=0.509, cos=0.677), tot_loss_proj:4.112 [t=0.29s]
prediction: ['[CLS] this steady they vinnie kerman [SEP]']
[ 100/2000] tot_loss=3.500 (perp=11.359, rec=0.458, cos=0.770), tot_loss_proj:4.086 [t=0.30s]
prediction: ['[CLS] thisaldi well wealthy oven [SEP]']
[ 150/2000] tot_loss=3.508 (perp=10.722, rec=0.460, cos=0.903), tot_loss_proj:4.009 [t=0.30s]
prediction: ['[CLS] this oven wellishly oven [SEP]']
[ 200/2000] tot_loss=3.183 (perp=10.635, rec=0.373, cos=0.684), tot_loss_proj:3.888 [t=0.30s]
prediction: ['[CLS] this cooks came croatian oven [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.220 (perp=11.086, rec=0.346, cos=0.657), tot_loss_proj:4.115 [t=0.30s]
prediction: ['[CLS] this bwf cooks croatian oven [SEP]']
[ 300/2000] tot_loss=3.332 (perp=11.546, rec=0.329, cos=0.693), tot_loss_proj:4.176 [t=0.30s]
prediction: ['[CLS] this bwf cooksiring oven [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.154 (perp=10.826, rec=0.304, cos=0.685), tot_loss_proj:4.109 [t=0.30s]
prediction: ['[CLS] this bwf croatian cooks oven [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.123 (perp=10.931, rec=0.291, cos=0.646), tot_loss_proj:4.058 [t=0.30s]
prediction: ['[CLS] this ♦. cooks oven [SEP]']
[ 450/2000] tot_loss=3.112 (perp=10.931, rec=0.281, cos=0.645), tot_loss_proj:4.059 [t=0.30s]
prediction: ['[CLS] this ♦. cooks oven [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.963 (perp=10.110, rec=0.274, cos=0.667), tot_loss_proj:3.904 [t=0.30s]
prediction: ['[CLS] this. ♦ cooks oven [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.906 (perp=10.110, rec=0.263, cos=0.621), tot_loss_proj:3.901 [t=0.30s]
prediction: ['[CLS] this. ♦ cooks oven [SEP]']
[ 600/2000] tot_loss=2.877 (perp=10.030, rec=0.266, cos=0.605), tot_loss_proj:3.886 [t=0.30s]
prediction: ['[CLS] this.och cooks oven [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.883 (perp=10.030, rec=0.248, cos=0.628), tot_loss_proj:3.886 [t=0.30s]
prediction: ['[CLS] this.och cooks oven [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.861 (perp=10.030, rec=0.244, cos=0.611), tot_loss_proj:3.883 [t=0.30s]
prediction: ['[CLS] this.och cooks oven [SEP]']
[ 750/2000] tot_loss=2.880 (perp=10.030, rec=0.247, cos=0.627), tot_loss_proj:3.884 [t=0.30s]
prediction: ['[CLS] this.och cooks oven [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.865 (perp=10.030, rec=0.237, cos=0.621), tot_loss_proj:3.886 [t=0.30s]
prediction: ['[CLS] this.och cooks oven [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.882 (perp=10.030, rec=0.239, cos=0.636), tot_loss_proj:3.885 [t=0.30s]
prediction: ['[CLS] this.och cooks oven [SEP]']
[ 900/2000] tot_loss=2.866 (perp=10.030, rec=0.239, cos=0.621), tot_loss_proj:3.886 [t=0.30s]
prediction: ['[CLS] this.och cooks oven [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.854 (perp=10.030, rec=0.233, cos=0.615), tot_loss_proj:3.887 [t=0.30s]
prediction: ['[CLS] this.och cooks oven [SEP]']
Attempt swap
[1000/2000] tot_loss=2.862 (perp=10.030, rec=0.228, cos=0.628), tot_loss_proj:3.888 [t=0.30s]
prediction: ['[CLS] this.och cooks oven [SEP]']
[1050/2000] tot_loss=2.869 (perp=10.030, rec=0.232, cos=0.631), tot_loss_proj:3.884 [t=0.30s]
prediction: ['[CLS] this.och cooks oven [SEP]']
Attempt swap
[1100/2000] tot_loss=2.951 (perp=10.450, rec=0.242, cos=0.619), tot_loss_proj:3.918 [t=0.30s]
prediction: ['[CLS] this. bet cooks oven [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.827 (perp=9.559, rec=0.275, cos=0.641), tot_loss_proj:3.730 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
[1200/2000] tot_loss=2.819 (perp=9.694, rec=0.250, cos=0.631), tot_loss_proj:3.746 [t=0.30s]
prediction: ['[CLS] this immunity cooks oven. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.785 (perp=9.559, rec=0.241, cos=0.632), tot_loss_proj:3.728 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.762 (perp=9.559, rec=0.227, cos=0.623), tot_loss_proj:3.726 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
[1350/2000] tot_loss=2.767 (perp=9.559, rec=0.231, cos=0.624), tot_loss_proj:3.721 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.761 (perp=9.559, rec=0.230, cos=0.620), tot_loss_proj:3.722 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.776 (perp=9.559, rec=0.236, cos=0.628), tot_loss_proj:3.727 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
[1500/2000] tot_loss=2.764 (perp=9.559, rec=0.229, cos=0.624), tot_loss_proj:3.725 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.761 (perp=9.559, rec=0.226, cos=0.623), tot_loss_proj:3.721 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.764 (perp=9.559, rec=0.228, cos=0.624), tot_loss_proj:3.724 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
[1650/2000] tot_loss=2.762 (perp=9.559, rec=0.227, cos=0.623), tot_loss_proj:3.723 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.766 (perp=9.559, rec=0.232, cos=0.622), tot_loss_proj:3.723 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.766 (perp=9.559, rec=0.234, cos=0.621), tot_loss_proj:3.726 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
[1800/2000] tot_loss=2.758 (perp=9.559, rec=0.225, cos=0.620), tot_loss_proj:3.724 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.768 (perp=9.559, rec=0.236, cos=0.621), tot_loss_proj:3.722 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.755 (perp=9.559, rec=0.223, cos=0.620), tot_loss_proj:3.724 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
[1950/2000] tot_loss=2.761 (perp=9.559, rec=0.229, cos=0.620), tot_loss_proj:3.726 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.758 (perp=9.559, rec=0.226, cos=0.621), tot_loss_proj:3.725 [t=0.30s]
prediction: ['[CLS] thisoch cooks oven. [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] this oven cooks well. [SEP]
========================
predicted: 
========================
[CLS] thisoch cooks oven. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 80.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 54.545 | p: 60.000 | r: 50.000
rougeLsum  | fm: 54.545 | p: 60.000 | r: 50.000
r1fm+r2fm = 72.727

[Aggregate metrics]:
rouge1     | fm: 76.833 | p: 76.902 | r: 77.008
rouge2     | fm: 36.395 | p: 36.309 | r: 36.614
rougeL     | fm: 68.144 | p: 68.188 | r: 68.229
rougeLsum  | fm: 68.341 | p: 68.359 | r: 68.488
r1fm+r2fm = 113.228

input #97 time: 0:11:48 | total time: 19:28:28


Running input #98 of 100.
reference: 
========================
Sarah devoured the cakes in the kitchen last night.
========================
average of cosine similarity 0.99906231101569
highest_index [0]
highest [0.99906231101569]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  4532, 16475, 16777,  1996, 22619,  1999,  1996,  3829,  2197,
          2305,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sarah devoured the cakes in the kitchen last night. [SEP]']
[Init] best rec loss: 0.9824832677841187 for ['[CLS] socialced coordination umbrella louder require paper plank parallel hi dame [SEP]']
[Init] best rec loss: 0.9721888303756714 for ['[CLS] commonwealthdine una british native unix hit arch unknown in pga [SEP]']
[Init] best rec loss: 0.9652795791625977 for ['[CLS]mission instruments overnton _ revenge touch cole palettescent die [SEP]']
[Init] best rec loss: 0.9517086744308472 for ['[CLS] excited hadley coverage theatreere schoolhouse then scored point carpenter nature [SEP]']
[Init] best rec loss: 0.9474611282348633 for ['[CLS] too influenced [SEP] available defence pigeon trialszle rigending power [SEP]']
[Init] best perm rec loss: 0.9460778832435608 for ['[CLS]zle available [SEP] power pigeon too rig influenced trials defenceending [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.035 (perp=12.795, rec=0.389, cos=0.087), tot_loss_proj:4.271 [t=0.29s]
prediction: ['[CLS] sarah used alongside calder fresh night last cherry soon silicon discover [SEP]']
[ 100/2000] tot_loss=2.626 (perp=11.824, rec=0.229, cos=0.033), tot_loss_proj:4.128 [t=0.30s]
prediction: ['[CLS] sarah studied room fountains our night last eating toy cakesglass [SEP]']
[ 150/2000] tot_loss=2.599 (perp=11.843, rec=0.197, cos=0.034), tot_loss_proj:4.184 [t=0.30s]
prediction: ['[CLS] sarahigate alongside the our night lastoured bread cakes inside [SEP]']
[ 200/2000] tot_loss=2.532 (perp=11.805, rec=0.153, cos=0.017), tot_loss_proj:4.135 [t=0.30s]
prediction: ['[CLS] sarahigate room the our night lastoured cakes cakes inside [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.503 (perp=11.681, rec=0.150, cos=0.017), tot_loss_proj:4.136 [t=0.30s]
prediction: ['[CLS] sarahigate room the our night lastoured restaurant cakes inside [SEP]']
[ 300/2000] tot_loss=2.483 (perp=11.667, rec=0.134, cos=0.016), tot_loss_proj:4.156 [t=0.30s]
prediction: ['[CLS] sarahigate kitchen the in night lastoured restaurant cakes inside [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.177 (perp=10.281, rec=0.108, cos=0.013), tot_loss_proj:3.836 [t=0.30s]
prediction: ['[CLS] sarah dev kitchen the last night theoured kitchen cakes in [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.753 (perp=8.221, rec=0.097, cos=0.012), tot_loss_proj:3.401 [t=0.30s]
prediction: ['[CLS] sarah devoured the last night the kitchen kitchen cakes in [SEP]']
[ 450/2000] tot_loss=1.744 (perp=8.221, rec=0.089, cos=0.011), tot_loss_proj:3.407 [t=0.30s]
prediction: ['[CLS] sarah devoured the last night the kitchen kitchen cakes in [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.652 (perp=7.695, rec=0.100, cos=0.013), tot_loss_proj:3.497 [t=0.30s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen night in [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.653 (perp=7.695, rec=0.104, cos=0.011), tot_loss_proj:3.497 [t=0.30s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen night in [SEP]']
[ 600/2000] tot_loss=1.638 (perp=7.695, rec=0.089, cos=0.011), tot_loss_proj:3.497 [t=0.30s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen night in [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.612 (perp=7.527, rec=0.096, cos=0.010), tot_loss_proj:3.401 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.597 (perp=7.527, rec=0.082, cos=0.010), tot_loss_proj:3.394 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
[ 750/2000] tot_loss=1.596 (perp=7.527, rec=0.081, cos=0.010), tot_loss_proj:3.402 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.601 (perp=7.527, rec=0.086, cos=0.010), tot_loss_proj:3.401 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.600 (perp=7.527, rec=0.085, cos=0.010), tot_loss_proj:3.405 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
[ 900/2000] tot_loss=1.598 (perp=7.527, rec=0.082, cos=0.010), tot_loss_proj:3.403 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.597 (perp=7.527, rec=0.081, cos=0.010), tot_loss_proj:3.403 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.608 (perp=7.527, rec=0.092, cos=0.011), tot_loss_proj:3.401 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
[1050/2000] tot_loss=1.595 (perp=7.527, rec=0.080, cos=0.010), tot_loss_proj:3.402 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.597 (perp=7.527, rec=0.082, cos=0.010), tot_loss_proj:3.402 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[1150/2000] tot_loss=1.588 (perp=7.527, rec=0.073, cos=0.010), tot_loss_proj:3.402 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
[1200/2000] tot_loss=1.593 (perp=7.527, rec=0.078, cos=0.010), tot_loss_proj:3.399 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[1250/2000] tot_loss=1.602 (perp=7.527, rec=0.087, cos=0.010), tot_loss_proj:3.401 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[1300/2000] tot_loss=1.593 (perp=7.527, rec=0.078, cos=0.010), tot_loss_proj:3.404 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
[1350/2000] tot_loss=1.597 (perp=7.527, rec=0.082, cos=0.010), tot_loss_proj:3.401 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[1400/2000] tot_loss=1.596 (perp=7.527, rec=0.081, cos=0.010), tot_loss_proj:3.401 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[1450/2000] tot_loss=1.599 (perp=7.527, rec=0.083, cos=0.010), tot_loss_proj:3.401 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
[1500/2000] tot_loss=1.592 (perp=7.527, rec=0.077, cos=0.010), tot_loss_proj:3.402 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[1550/2000] tot_loss=1.597 (perp=7.527, rec=0.082, cos=0.010), tot_loss_proj:3.400 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[1600/2000] tot_loss=1.587 (perp=7.527, rec=0.072, cos=0.010), tot_loss_proj:3.398 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
[1650/2000] tot_loss=1.591 (perp=7.527, rec=0.075, cos=0.010), tot_loss_proj:3.406 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[1700/2000] tot_loss=1.599 (perp=7.527, rec=0.084, cos=0.010), tot_loss_proj:3.399 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.603 (perp=7.527, rec=0.087, cos=0.010), tot_loss_proj:3.400 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
[1800/2000] tot_loss=1.594 (perp=7.527, rec=0.079, cos=0.010), tot_loss_proj:3.406 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
[1850/2000] tot_loss=1.598 (perp=7.527, rec=0.082, cos=0.010), tot_loss_proj:3.408 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.545 (perp=7.165, rec=0.100, cos=0.012), tot_loss_proj:2.149 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes in the kitchen kitchen night [SEP]']
[1950/2000] tot_loss=1.530 (perp=7.165, rec=0.086, cos=0.010), tot_loss_proj:2.152 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes in the kitchen kitchen night [SEP]']
Attempt swap
[2000/2000] tot_loss=1.528 (perp=7.165, rec=0.085, cos=0.010), tot_loss_proj:2.153 [t=0.35s]
prediction: ['[CLS] sarah devoured the last cakes in the kitchen kitchen night [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] sarah devoured the cakes in the kitchen last night. [SEP]
========================
predicted: 
========================
[CLS] sarah devoured the last cakes the kitchen kitchen in night [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 47.619 | p: 45.455 | r: 50.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 143.271

[Aggregate metrics]:
rouge1     | fm: 76.985 | p: 76.995 | r: 77.246
rouge2     | fm: 36.628 | p: 36.517 | r: 36.922
rougeL     | fm: 68.225 | p: 68.316 | r: 68.419
rougeLsum  | fm: 68.366 | p: 68.411 | r: 68.523
r1fm+r2fm = 113.613

input #98 time: 0:13:01 | total time: 19:41:30


Running input #99 of 100.
reference: 
========================
The box contains the ball.
========================
average of cosine similarity 0.9989891382007919
highest_index [0]
highest [0.9989891382007919]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 1996, 3482, 3397, 1996, 3608, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the box contains the ball. [SEP]']
[Init] best rec loss: 0.9369071125984192 for ['[CLS] point bono dry position nothing using [SEP]']
[Init] best rec loss: 0.8736017942428589 for ['[CLS] storage theatergraphic scholarships africa minorities [SEP]']
[Init] best rec loss: 0.8526240587234497 for ['[CLS] [MASK] tennis reacherェ one note [SEP]']
[Init] best rec loss: 0.8398573994636536 for ['[CLS] returned raphael2 dragon sato deco [SEP]']
[Init] best perm rec loss: 0.8396326899528503 for ['[CLS] raphael returned2 dragon sato deco [SEP]']
[Init] best perm rec loss: 0.8393317461013794 for ['[CLS] dragon sato2 raphael returned deco [SEP]']
[Init] best perm rec loss: 0.8384494781494141 for ['[CLS] raphael sato2 dragon returned deco [SEP]']
[Init] best perm rec loss: 0.8382678627967834 for ['[CLS]2 returned deco dragon raphael sato [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.478 (perp=11.318, rec=0.521, cos=0.694), tot_loss_proj:4.171 [t=0.34s]
prediction: ['[CLS] ᵍ single ball disc county : [SEP]']
[ 100/2000] tot_loss=2.858 (perp=8.094, rec=0.407, cos=0.832), tot_loss_proj:3.558 [t=0.34s]
prediction: ['[CLS] contains contains ball. ball : [SEP]']
[ 150/2000] tot_loss=2.840 (perp=8.862, rec=0.345, cos=0.723), tot_loss_proj:3.565 [t=0.34s]
prediction: ['[CLS] contains contains ball album ball. [SEP]']
[ 200/2000] tot_loss=2.545 (perp=7.379, rec=0.338, cos=0.732), tot_loss_proj:3.362 [t=0.34s]
prediction: ['[CLS] contains contains ball. ball. [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.911 (perp=9.664, rec=0.300, cos=0.678), tot_loss_proj:3.794 [t=0.34s]
prediction: ['[CLS] contains contains ball. box contains [SEP]']
[ 300/2000] tot_loss=3.086 (perp=10.580, rec=0.282, cos=0.689), tot_loss_proj:3.965 [t=0.34s]
prediction: ['[CLS] contains contains ball album box contains [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.838 (perp=9.236, rec=0.244, cos=0.746), tot_loss_proj:3.700 [t=0.35s]
prediction: ['[CLS] itunes contains the ball box contains [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.233 (perp=11.262, rec=0.246, cos=0.734), tot_loss_proj:4.151 [t=0.34s]
prediction: ['[CLS] itunes contains playing ball box contains [SEP]']
[ 450/2000] tot_loss=3.258 (perp=11.262, rec=0.239, cos=0.767), tot_loss_proj:4.141 [t=0.35s]
prediction: ['[CLS] itunes contains playing ball box contains [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.846 (perp=9.381, rec=0.230, cos=0.740), tot_loss_proj:3.801 [t=0.34s]
prediction: ['[CLS] itunes contains playing ball box. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.728 (perp=8.640, rec=0.230, cos=0.770), tot_loss_proj:3.681 [t=0.34s]
prediction: ['[CLS] itunes contains ball. box. [SEP]']
[ 600/2000] tot_loss=2.696 (perp=8.627, rec=0.220, cos=0.750), tot_loss_proj:3.641 [t=0.35s]
prediction: ['[CLS]bolt contains ball. box. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.162 (perp=10.826, rec=0.217, cos=0.779), tot_loss_proj:4.050 [t=0.35s]
prediction: ['[CLS]bolt contains ball inhibitor box. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.936 (perp=9.787, rec=0.213, cos=0.766), tot_loss_proj:3.836 [t=0.35s]
prediction: ['[CLS]bolt ball contains inhibitor box. [SEP]']
[ 750/2000] tot_loss=2.947 (perp=9.787, rec=0.227, cos=0.763), tot_loss_proj:3.840 [t=0.34s]
prediction: ['[CLS]bolt ball contains inhibitor box. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.805 (perp=9.230, rec=0.220, cos=0.739), tot_loss_proj:3.729 [t=0.35s]
prediction: ['[CLS] ballbolt contains inhibitor box. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.815 (perp=9.230, rec=0.222, cos=0.747), tot_loss_proj:3.729 [t=0.35s]
prediction: ['[CLS] ballbolt contains inhibitor box. [SEP]']
[ 900/2000] tot_loss=2.813 (perp=9.230, rec=0.220, cos=0.748), tot_loss_proj:3.732 [t=0.35s]
prediction: ['[CLS] ballbolt contains inhibitor box. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.024 (perp=10.262, rec=0.211, cos=0.761), tot_loss_proj:3.918 [t=0.35s]
prediction: ['[CLS] ballbolt contains fivb box. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.014 (perp=9.742, rec=0.283, cos=0.782), tot_loss_proj:3.859 [t=0.34s]
prediction: ['[CLS] box fists contains fivb ball. [SEP]']
[1050/2000] tot_loss=2.947 (perp=9.742, rec=0.222, cos=0.776), tot_loss_proj:3.860 [t=0.35s]
prediction: ['[CLS] box fists contains fivb ball. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.806 (perp=8.997, rec=0.237, cos=0.769), tot_loss_proj:3.694 [t=0.35s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.799 (perp=8.997, rec=0.224, cos=0.775), tot_loss_proj:3.693 [t=0.35s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
[1200/2000] tot_loss=2.789 (perp=8.997, rec=0.218, cos=0.772), tot_loss_proj:3.694 [t=0.35s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.787 (perp=8.997, rec=0.208, cos=0.779), tot_loss_proj:3.692 [t=0.35s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.772 (perp=8.997, rec=0.198, cos=0.774), tot_loss_proj:3.691 [t=0.35s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
[1350/2000] tot_loss=2.791 (perp=8.997, rec=0.212, cos=0.779), tot_loss_proj:3.688 [t=0.35s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.782 (perp=8.997, rec=0.207, cos=0.776), tot_loss_proj:3.694 [t=0.35s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.781 (perp=8.997, rec=0.206, cos=0.776), tot_loss_proj:3.696 [t=0.35s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
[1500/2000] tot_loss=2.781 (perp=8.997, rec=0.202, cos=0.780), tot_loss_proj:3.689 [t=0.35s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.786 (perp=8.997, rec=0.208, cos=0.778), tot_loss_proj:3.693 [t=0.35s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.794 (perp=8.997, rec=0.212, cos=0.782), tot_loss_proj:3.694 [t=0.35s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
[1650/2000] tot_loss=2.786 (perp=8.997, rec=0.205, cos=0.781), tot_loss_proj:3.694 [t=0.30s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.787 (perp=8.997, rec=0.207, cos=0.780), tot_loss_proj:3.692 [t=0.30s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.778 (perp=8.997, rec=0.198, cos=0.781), tot_loss_proj:3.688 [t=0.30s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
[1800/2000] tot_loss=2.790 (perp=8.997, rec=0.208, cos=0.782), tot_loss_proj:3.688 [t=0.30s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.791 (perp=8.997, rec=0.212, cos=0.780), tot_loss_proj:3.691 [t=0.30s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.787 (perp=8.997, rec=0.205, cos=0.782), tot_loss_proj:3.696 [t=0.30s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
[1950/2000] tot_loss=2.792 (perp=8.997, rec=0.210, cos=0.783), tot_loss_proj:3.692 [t=0.30s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.778 (perp=8.997, rec=0.197, cos=0.782), tot_loss_proj:3.697 [t=0.30s]
prediction: ['[CLS] box fists contains ball fivb. [SEP]']
Done with input #99 of 100.
reference: 
========================
[CLS] the box contains the ball. [SEP]
========================
predicted: 
========================
[CLS] box fists contains ball fivb. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 71.429

[Aggregate metrics]:
rouge1     | fm: 76.973 | p: 76.978 | r: 77.196
rouge2     | fm: 35.972 | p: 35.890 | r: 36.204
rougeL     | fm: 68.188 | p: 68.258 | r: 68.412
rougeLsum  | fm: 68.441 | p: 68.464 | r: 68.583
r1fm+r2fm = 112.945

input #99 time: 0:13:14 | total time: 19:54:45


Average Cosine Similarity: 0.9989279354982985
Done with all.
