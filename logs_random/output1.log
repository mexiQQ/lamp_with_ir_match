


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.1 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)

  0%|          | 0/3 [00:00<?, ?it/s]
100%|██████████| 3/3 [00:00<00:00, 48.70it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.7301250645842856
highest_index [0]
highest [0.7301250645842856]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 0.9485135674476624 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.8071048259735107 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.7978932857513428 for ['[CLS] tolerance receiving [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.623 (perp=10.251, rec=0.106, cos=0.466), tot_loss_proj:2.584 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 100/2000] tot_loss=2.575 (perp=10.251, rec=0.059, cos=0.466), tot_loss_proj:2.594 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.590 (perp=10.251, rec=0.074, cos=0.465), tot_loss_proj:2.590 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.584 (perp=10.251, rec=0.069, cos=0.465), tot_loss_proj:2.591 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.569 (perp=10.251, rec=0.053, cos=0.466), tot_loss_proj:2.588 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.573 (perp=10.251, rec=0.056, cos=0.467), tot_loss_proj:2.578 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.564 (perp=10.251, rec=0.047, cos=0.467), tot_loss_proj:2.591 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.573 (perp=10.251, rec=0.056, cos=0.467), tot_loss_proj:2.587 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.582 (perp=10.251, rec=0.065, cos=0.467), tot_loss_proj:2.577 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.595 (perp=10.251, rec=0.078, cos=0.467), tot_loss_proj:2.593 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.578 (perp=10.251, rec=0.061, cos=0.467), tot_loss_proj:2.591 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.569 (perp=10.251, rec=0.052, cos=0.467), tot_loss_proj:2.577 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.579 (perp=10.251, rec=0.063, cos=0.466), tot_loss_proj:2.588 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.571 (perp=10.251, rec=0.054, cos=0.467), tot_loss_proj:2.588 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.578 (perp=10.251, rec=0.062, cos=0.466), tot_loss_proj:2.587 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.578 (perp=10.251, rec=0.062, cos=0.466), tot_loss_proj:2.587 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.567 (perp=10.251, rec=0.050, cos=0.467), tot_loss_proj:2.590 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.589 (perp=10.251, rec=0.072, cos=0.467), tot_loss_proj:2.579 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.567 (perp=10.251, rec=0.050, cos=0.467), tot_loss_proj:2.588 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.579 (perp=10.251, rec=0.062, cos=0.467), tot_loss_proj:2.596 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.577 (perp=10.251, rec=0.060, cos=0.466), tot_loss_proj:2.587 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.581 (perp=10.251, rec=0.064, cos=0.467), tot_loss_proj:2.577 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.574 (perp=10.251, rec=0.058, cos=0.466), tot_loss_proj:2.588 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.574 (perp=10.251, rec=0.057, cos=0.467), tot_loss_proj:2.591 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.578 (perp=10.251, rec=0.061, cos=0.466), tot_loss_proj:2.580 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.563 (perp=10.251, rec=0.046, cos=0.467), tot_loss_proj:2.591 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.580 (perp=10.251, rec=0.063, cos=0.467), tot_loss_proj:2.580 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.562 (perp=10.251, rec=0.045, cos=0.466), tot_loss_proj:2.579 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.573 (perp=10.251, rec=0.056, cos=0.467), tot_loss_proj:2.580 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.589 (perp=10.251, rec=0.072, cos=0.467), tot_loss_proj:2.600 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.565 (perp=10.251, rec=0.048, cos=0.467), tot_loss_proj:2.587 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.581 (perp=10.251, rec=0.064, cos=0.466), tot_loss_proj:2.587 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.580 (perp=10.251, rec=0.063, cos=0.467), tot_loss_proj:2.578 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.582 (perp=10.251, rec=0.066, cos=0.466), tot_loss_proj:2.584 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.578 (perp=10.251, rec=0.061, cos=0.467), tot_loss_proj:2.590 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.583 (perp=10.251, rec=0.066, cos=0.467), tot_loss_proj:2.596 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.578 (perp=10.251, rec=0.061, cos=0.467), tot_loss_proj:2.583 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.581 (perp=10.251, rec=0.064, cos=0.467), tot_loss_proj:2.588 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.585 (perp=10.251, rec=0.068, cos=0.467), tot_loss_proj:2.580 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.567 (perp=10.251, rec=0.050, cos=0.467), tot_loss_proj:2.576 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:09:08 | total time: 0:09:08


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.7265457037943341
highest_index [0]
highest [0.7265457037943341]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 0.9709292650222778 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9602980613708496 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.956781268119812 for ['[CLS] consist waterloo [SEP]']
[Init] best rec loss: 0.9567356705665588 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.9525214433670044 for ['[CLS] cas giants [SEP]']
[Init] best rec loss: 0.9494467973709106 for ['[CLS] gone honorary [SEP]']
[Init] best rec loss: 0.9490422010421753 for ['[CLS] schedule sensors [SEP]']
[Init] best rec loss: 0.9432811737060547 for ['[CLS] vital conflict [SEP]']
[Init] best rec loss: 0.9391872882843018 for ['[CLS] } sex [SEP]']
[Init] best rec loss: 0.9346516728401184 for ['[CLS] received mountain [SEP]']
[Init] best rec loss: 0.8728275299072266 for ['[CLS] feeling play [SEP]']
[Init] best rec loss: 0.835352897644043 for ["[CLS] giant'[SEP]"]
[Init] best perm rec loss: 0.8349558115005493 for ["[CLS]'giant [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.953 (perp=9.484, rec=0.594, cos=0.463), tot_loss_proj:3.053 [t=0.23s]
prediction: ['[CLS] fine alexander [SEP]']
[ 100/2000] tot_loss=2.458 (perp=9.171, rec=0.154, cos=0.470), tot_loss_proj:2.380 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 150/2000] tot_loss=2.376 (perp=9.171, rec=0.070, cos=0.472), tot_loss_proj:2.360 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 200/2000] tot_loss=2.366 (perp=9.171, rec=0.060, cos=0.472), tot_loss_proj:2.367 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.378 (perp=9.171, rec=0.072, cos=0.472), tot_loss_proj:2.377 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=2.372 (perp=9.171, rec=0.066, cos=0.472), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.366 (perp=9.171, rec=0.060, cos=0.472), tot_loss_proj:2.368 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.368 (perp=9.171, rec=0.061, cos=0.472), tot_loss_proj:2.362 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=2.373 (perp=9.171, rec=0.067, cos=0.472), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.363 (perp=9.171, rec=0.057, cos=0.472), tot_loss_proj:2.373 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.370 (perp=9.171, rec=0.064, cos=0.472), tot_loss_proj:2.358 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=2.369 (perp=9.171, rec=0.063, cos=0.472), tot_loss_proj:2.371 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.386 (perp=9.171, rec=0.080, cos=0.472), tot_loss_proj:2.378 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.362 (perp=9.171, rec=0.056, cos=0.472), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=2.376 (perp=9.171, rec=0.070, cos=0.472), tot_loss_proj:2.380 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.364 (perp=9.171, rec=0.057, cos=0.472), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.366 (perp=9.171, rec=0.060, cos=0.472), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=2.361 (perp=9.171, rec=0.055, cos=0.472), tot_loss_proj:2.372 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.368 (perp=9.171, rec=0.062, cos=0.472), tot_loss_proj:2.366 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=2.360 (perp=9.171, rec=0.054, cos=0.472), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=2.372 (perp=9.171, rec=0.065, cos=0.472), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=2.354 (perp=9.171, rec=0.047, cos=0.472), tot_loss_proj:2.374 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=2.368 (perp=9.171, rec=0.062, cos=0.472), tot_loss_proj:2.367 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=2.364 (perp=9.171, rec=0.058, cos=0.472), tot_loss_proj:2.374 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=2.361 (perp=9.171, rec=0.054, cos=0.472), tot_loss_proj:2.371 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=2.353 (perp=9.171, rec=0.047, cos=0.472), tot_loss_proj:2.375 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=2.363 (perp=9.171, rec=0.057, cos=0.472), tot_loss_proj:2.367 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=2.353 (perp=9.171, rec=0.046, cos=0.472), tot_loss_proj:2.360 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=2.367 (perp=9.171, rec=0.061, cos=0.472), tot_loss_proj:2.355 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=2.363 (perp=9.171, rec=0.057, cos=0.472), tot_loss_proj:2.376 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=2.371 (perp=9.171, rec=0.065, cos=0.472), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=2.361 (perp=9.171, rec=0.055, cos=0.472), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=2.357 (perp=9.171, rec=0.051, cos=0.472), tot_loss_proj:2.372 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=2.382 (perp=9.171, rec=0.076, cos=0.472), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=2.361 (perp=9.171, rec=0.054, cos=0.472), tot_loss_proj:2.376 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=2.367 (perp=9.171, rec=0.061, cos=0.472), tot_loss_proj:2.362 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=2.360 (perp=9.171, rec=0.053, cos=0.472), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=2.356 (perp=9.171, rec=0.050, cos=0.472), tot_loss_proj:2.367 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=2.367 (perp=9.171, rec=0.061, cos=0.472), tot_loss_proj:2.365 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=2.377 (perp=9.171, rec=0.070, cos=0.472), tot_loss_proj:2.368 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:09:08 | total time: 0:18:16


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.7166462755553806
highest_index [0]
highest [0.7166462755553806]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.7189242243766785 for ['[CLS] wash〜 at [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.508 (perp=8.750, rec=0.270, cos=0.488), tot_loss_proj:2.657 [t=0.23s]
prediction: ['[CLS] momentum gaining momentum [SEP]']
[ 100/2000] tot_loss=2.811 (perp=11.194, rec=0.089, cos=0.483), tot_loss_proj:3.004 [t=0.23s]
prediction: ['[CLS] momentum gaining much [SEP]']
[ 150/2000] tot_loss=2.798 (perp=11.194, rec=0.073, cos=0.486), tot_loss_proj:2.999 [t=0.23s]
prediction: ['[CLS] momentum gaining much [SEP]']
[ 200/2000] tot_loss=2.788 (perp=11.194, rec=0.062, cos=0.486), tot_loss_proj:2.994 [t=0.23s]
prediction: ['[CLS] momentum gaining much [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.268 (perp=8.515, rec=0.079, cos=0.486), tot_loss_proj:2.259 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=2.252 (perp=8.515, rec=0.064, cos=0.486), tot_loss_proj:2.260 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.249 (perp=8.515, rec=0.060, cos=0.486), tot_loss_proj:2.257 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.246 (perp=8.515, rec=0.057, cos=0.486), tot_loss_proj:2.246 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=2.240 (perp=8.515, rec=0.051, cos=0.486), tot_loss_proj:2.259 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.245 (perp=8.515, rec=0.056, cos=0.486), tot_loss_proj:2.254 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.272 (perp=8.515, rec=0.083, cos=0.486), tot_loss_proj:2.239 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=2.249 (perp=8.515, rec=0.060, cos=0.486), tot_loss_proj:2.252 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.244 (perp=8.515, rec=0.056, cos=0.486), tot_loss_proj:2.255 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.251 (perp=8.515, rec=0.062, cos=0.486), tot_loss_proj:2.250 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=2.250 (perp=8.515, rec=0.061, cos=0.486), tot_loss_proj:2.245 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.259 (perp=8.515, rec=0.070, cos=0.486), tot_loss_proj:2.248 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.240 (perp=8.515, rec=0.051, cos=0.486), tot_loss_proj:2.255 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=2.246 (perp=8.515, rec=0.057, cos=0.486), tot_loss_proj:2.261 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.266 (perp=8.515, rec=0.077, cos=0.486), tot_loss_proj:2.248 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=2.251 (perp=8.515, rec=0.063, cos=0.486), tot_loss_proj:2.247 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=2.244 (perp=8.515, rec=0.055, cos=0.486), tot_loss_proj:2.252 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=2.248 (perp=8.515, rec=0.059, cos=0.486), tot_loss_proj:2.254 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=2.241 (perp=8.515, rec=0.051, cos=0.486), tot_loss_proj:2.250 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=2.253 (perp=8.515, rec=0.064, cos=0.486), tot_loss_proj:2.252 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=2.254 (perp=8.515, rec=0.064, cos=0.486), tot_loss_proj:2.255 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=2.246 (perp=8.515, rec=0.057, cos=0.486), tot_loss_proj:2.264 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=2.253 (perp=8.515, rec=0.064, cos=0.486), tot_loss_proj:2.251 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=2.248 (perp=8.515, rec=0.059, cos=0.486), tot_loss_proj:2.250 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=2.249 (perp=8.515, rec=0.059, cos=0.486), tot_loss_proj:2.249 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=2.253 (perp=8.515, rec=0.064, cos=0.486), tot_loss_proj:2.258 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=2.239 (perp=8.515, rec=0.050, cos=0.486), tot_loss_proj:2.259 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=2.237 (perp=8.515, rec=0.047, cos=0.486), tot_loss_proj:2.253 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=2.260 (perp=8.515, rec=0.071, cos=0.486), tot_loss_proj:2.257 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=2.252 (perp=8.515, rec=0.063, cos=0.486), tot_loss_proj:2.245 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=2.249 (perp=8.515, rec=0.060, cos=0.486), tot_loss_proj:2.257 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=2.257 (perp=8.515, rec=0.067, cos=0.486), tot_loss_proj:2.249 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=2.238 (perp=8.515, rec=0.048, cos=0.486), tot_loss_proj:2.254 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=2.246 (perp=8.515, rec=0.057, cos=0.486), tot_loss_proj:2.249 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=2.259 (perp=8.515, rec=0.069, cos=0.486), tot_loss_proj:2.253 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=2.244 (perp=8.515, rec=0.055, cos=0.486), tot_loss_proj:2.254 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:09:07 | total time: 0:27:24


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.7354704216216734
highest_index [0]
highest [0.7354704216216734]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.9713574051856995 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.8547715544700623 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8468821048736572 for ['[CLS] lancashire isaac [SEP]']
[Init] best rec loss: 0.8070411682128906 for ['[CLS] end depart [SEP]']
[Init] best perm rec loss: 0.8038267493247986 for ['[CLS] depart end [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.226 (perp=8.384, rec=0.093, cos=0.456), tot_loss_proj:2.236 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 100/2000] tot_loss=2.195 (perp=8.384, rec=0.060, cos=0.458), tot_loss_proj:2.227 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/2000] tot_loss=2.194 (perp=8.384, rec=0.062, cos=0.455), tot_loss_proj:2.234 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 200/2000] tot_loss=2.196 (perp=8.384, rec=0.060, cos=0.459), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.201 (perp=8.384, rec=0.066, cos=0.458), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=2.205 (perp=8.384, rec=0.069, cos=0.459), tot_loss_proj:2.234 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.198 (perp=8.384, rec=0.063, cos=0.458), tot_loss_proj:2.228 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.187 (perp=8.384, rec=0.053, cos=0.457), tot_loss_proj:2.222 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=2.190 (perp=8.384, rec=0.055, cos=0.459), tot_loss_proj:2.231 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.198 (perp=8.384, rec=0.063, cos=0.459), tot_loss_proj:2.226 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.204 (perp=8.384, rec=0.068, cos=0.459), tot_loss_proj:2.223 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=2.207 (perp=8.384, rec=0.071, cos=0.459), tot_loss_proj:2.233 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.188 (perp=8.384, rec=0.053, cos=0.459), tot_loss_proj:2.231 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.189 (perp=8.384, rec=0.054, cos=0.459), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=2.205 (perp=8.384, rec=0.069, cos=0.459), tot_loss_proj:2.230 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.201 (perp=8.384, rec=0.066, cos=0.459), tot_loss_proj:2.217 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.190 (perp=8.384, rec=0.054, cos=0.459), tot_loss_proj:2.220 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=2.197 (perp=8.384, rec=0.061, cos=0.459), tot_loss_proj:2.212 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.197 (perp=8.384, rec=0.061, cos=0.459), tot_loss_proj:2.231 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=2.195 (perp=8.384, rec=0.059, cos=0.459), tot_loss_proj:2.231 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=2.204 (perp=8.384, rec=0.068, cos=0.459), tot_loss_proj:2.233 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=2.196 (perp=8.384, rec=0.061, cos=0.459), tot_loss_proj:2.227 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=2.191 (perp=8.384, rec=0.056, cos=0.459), tot_loss_proj:2.233 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=2.201 (perp=8.384, rec=0.065, cos=0.459), tot_loss_proj:2.227 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=2.193 (perp=8.384, rec=0.057, cos=0.459), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=2.190 (perp=8.384, rec=0.054, cos=0.459), tot_loss_proj:2.229 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=2.203 (perp=8.384, rec=0.067, cos=0.459), tot_loss_proj:2.228 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=2.201 (perp=8.384, rec=0.066, cos=0.459), tot_loss_proj:2.228 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=2.195 (perp=8.384, rec=0.059, cos=0.459), tot_loss_proj:2.231 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=2.198 (perp=8.384, rec=0.062, cos=0.459), tot_loss_proj:2.232 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=2.202 (perp=8.384, rec=0.066, cos=0.459), tot_loss_proj:2.230 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=2.185 (perp=8.384, rec=0.049, cos=0.459), tot_loss_proj:2.219 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=2.193 (perp=8.384, rec=0.058, cos=0.459), tot_loss_proj:2.220 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=2.203 (perp=8.384, rec=0.067, cos=0.459), tot_loss_proj:2.235 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=2.196 (perp=8.384, rec=0.060, cos=0.459), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=2.188 (perp=8.384, rec=0.052, cos=0.459), tot_loss_proj:2.232 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=2.203 (perp=8.384, rec=0.067, cos=0.459), tot_loss_proj:2.231 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=2.211 (perp=8.384, rec=0.075, cos=0.459), tot_loss_proj:2.235 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=2.185 (perp=8.384, rec=0.049, cos=0.459), tot_loss_proj:2.233 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=2.188 (perp=8.384, rec=0.052, cos=0.459), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:09:07 | total time: 0:36:32


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.7169756142811112
highest_index [0]
highest [0.7169756142811112]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 0.965949535369873 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9363554120063782 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9354352951049805 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9185932874679565 for ['[CLS] rally entered worldwide [SEP]']
[Init] best rec loss: 0.9184892773628235 for ['[CLS]urized bait bae [SEP]']
[Init] best rec loss: 0.8815131187438965 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.8631322979927063 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.8582709431648254 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.115 (perp=7.516, rec=0.128, cos=0.484), tot_loss_proj:2.059 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 100/2000] tot_loss=2.070 (perp=7.516, rec=0.081, cos=0.486), tot_loss_proj:2.042 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=2.062 (perp=7.516, rec=0.073, cos=0.485), tot_loss_proj:2.060 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=2.043 (perp=7.516, rec=0.053, cos=0.486), tot_loss_proj:2.054 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.046 (perp=7.516, rec=0.057, cos=0.485), tot_loss_proj:2.054 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=2.042 (perp=7.516, rec=0.054, cos=0.485), tot_loss_proj:2.046 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.047 (perp=7.516, rec=0.058, cos=0.485), tot_loss_proj:2.054 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.054 (perp=7.516, rec=0.066, cos=0.485), tot_loss_proj:2.055 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=2.047 (perp=7.516, rec=0.058, cos=0.486), tot_loss_proj:2.057 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.059 (perp=7.516, rec=0.071, cos=0.486), tot_loss_proj:2.036 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.043 (perp=7.516, rec=0.054, cos=0.486), tot_loss_proj:2.041 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=2.044 (perp=7.516, rec=0.056, cos=0.486), tot_loss_proj:2.058 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.028 (perp=7.516, rec=0.039, cos=0.485), tot_loss_proj:2.055 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.060 (perp=7.516, rec=0.072, cos=0.485), tot_loss_proj:2.045 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=2.053 (perp=7.516, rec=0.065, cos=0.485), tot_loss_proj:2.051 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.039 (perp=7.516, rec=0.051, cos=0.486), tot_loss_proj:2.051 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.040 (perp=7.516, rec=0.051, cos=0.486), tot_loss_proj:2.056 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=2.050 (perp=7.516, rec=0.061, cos=0.486), tot_loss_proj:2.049 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.040 (perp=7.516, rec=0.051, cos=0.486), tot_loss_proj:2.062 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=2.043 (perp=7.516, rec=0.054, cos=0.486), tot_loss_proj:2.045 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=2.054 (perp=7.516, rec=0.066, cos=0.485), tot_loss_proj:2.057 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=2.050 (perp=7.516, rec=0.062, cos=0.485), tot_loss_proj:2.049 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=2.058 (perp=7.516, rec=0.069, cos=0.486), tot_loss_proj:2.058 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=2.030 (perp=7.516, rec=0.041, cos=0.486), tot_loss_proj:2.035 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=2.044 (perp=7.516, rec=0.055, cos=0.486), tot_loss_proj:2.052 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=2.043 (perp=7.516, rec=0.054, cos=0.486), tot_loss_proj:2.058 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=2.051 (perp=7.516, rec=0.062, cos=0.486), tot_loss_proj:2.050 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=2.033 (perp=7.516, rec=0.044, cos=0.486), tot_loss_proj:2.054 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=2.051 (perp=7.516, rec=0.062, cos=0.486), tot_loss_proj:2.041 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=2.048 (perp=7.516, rec=0.059, cos=0.485), tot_loss_proj:2.065 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=2.052 (perp=7.516, rec=0.063, cos=0.486), tot_loss_proj:2.049 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=2.052 (perp=7.516, rec=0.064, cos=0.485), tot_loss_proj:2.056 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=2.053 (perp=7.516, rec=0.064, cos=0.486), tot_loss_proj:2.056 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=2.045 (perp=7.516, rec=0.056, cos=0.485), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=2.057 (perp=7.516, rec=0.068, cos=0.486), tot_loss_proj:2.051 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=2.060 (perp=7.516, rec=0.071, cos=0.485), tot_loss_proj:2.040 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=2.037 (perp=7.516, rec=0.048, cos=0.486), tot_loss_proj:2.055 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=2.051 (perp=7.516, rec=0.062, cos=0.486), tot_loss_proj:2.046 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=2.041 (perp=7.516, rec=0.052, cos=0.485), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=2.047 (perp=7.516, rec=0.058, cos=0.486), tot_loss_proj:2.046 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:09:01 | total time: 0:45:34


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.7303848376988848
highest_index [0]
highest [0.7303848376988848]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9776821732521057 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9565067887306213 for ['[CLS] juathic [SEP]']
[Init] best rec loss: 0.948654055595398 for ['[CLS] those legs [SEP]']
[Init] best rec loss: 0.9352181553840637 for ['[CLS] institution wanting [SEP]']
[Init] best rec loss: 0.920964777469635 for ['[CLS] baby face [SEP]']
[Init] best rec loss: 0.9206759333610535 for ['[CLS] aged sloop [SEP]']
[Init] best perm rec loss: 0.9180671572685242 for ['[CLS] sloop aged [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.648 (perp=12.171, rec=0.659, cos=0.555), tot_loss_proj:4.254 [t=0.23s]
prediction: ['[CLS] easy simple [SEP]']
[ 100/2000] tot_loss=3.242 (perp=12.259, rec=0.331, cos=0.459), tot_loss_proj:4.211 [t=0.23s]
prediction: ['[CLS] easier ease [SEP]']
[ 150/2000] tot_loss=3.098 (perp=12.316, rec=0.176, cos=0.459), tot_loss_proj:3.046 [t=0.23s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 200/2000] tot_loss=3.067 (perp=12.316, rec=0.142, cos=0.462), tot_loss_proj:3.035 [t=0.23s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.981 (perp=11.854, rec=0.148, cos=0.462), tot_loss_proj:3.051 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 300/2000] tot_loss=2.973 (perp=11.854, rec=0.139, cos=0.463), tot_loss_proj:3.064 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.966 (perp=11.854, rec=0.132, cos=0.463), tot_loss_proj:3.046 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.967 (perp=11.854, rec=0.133, cos=0.463), tot_loss_proj:3.051 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/2000] tot_loss=2.967 (perp=11.854, rec=0.133, cos=0.463), tot_loss_proj:3.051 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.963 (perp=11.854, rec=0.129, cos=0.463), tot_loss_proj:3.055 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.970 (perp=11.854, rec=0.136, cos=0.463), tot_loss_proj:3.054 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 600/2000] tot_loss=2.974 (perp=11.854, rec=0.140, cos=0.463), tot_loss_proj:3.055 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.960 (perp=11.854, rec=0.127, cos=0.463), tot_loss_proj:3.044 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.958 (perp=11.854, rec=0.124, cos=0.463), tot_loss_proj:3.059 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 750/2000] tot_loss=2.969 (perp=11.854, rec=0.136, cos=0.463), tot_loss_proj:3.053 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.968 (perp=11.854, rec=0.134, cos=0.463), tot_loss_proj:3.045 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.970 (perp=11.854, rec=0.137, cos=0.462), tot_loss_proj:3.065 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 900/2000] tot_loss=2.969 (perp=11.854, rec=0.136, cos=0.463), tot_loss_proj:3.047 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.959 (perp=11.854, rec=0.126, cos=0.462), tot_loss_proj:3.062 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1000/2000] tot_loss=2.966 (perp=11.854, rec=0.133, cos=0.462), tot_loss_proj:3.048 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1050/2000] tot_loss=2.959 (perp=11.854, rec=0.126, cos=0.462), tot_loss_proj:3.052 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1100/2000] tot_loss=2.965 (perp=11.854, rec=0.133, cos=0.462), tot_loss_proj:3.048 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1150/2000] tot_loss=2.950 (perp=11.854, rec=0.117, cos=0.462), tot_loss_proj:3.042 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1200/2000] tot_loss=2.964 (perp=11.854, rec=0.131, cos=0.462), tot_loss_proj:3.065 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1250/2000] tot_loss=2.949 (perp=11.854, rec=0.116, cos=0.462), tot_loss_proj:3.045 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1300/2000] tot_loss=2.958 (perp=11.854, rec=0.125, cos=0.462), tot_loss_proj:3.056 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1350/2000] tot_loss=2.965 (perp=11.854, rec=0.132, cos=0.462), tot_loss_proj:3.060 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1400/2000] tot_loss=2.954 (perp=11.854, rec=0.121, cos=0.462), tot_loss_proj:3.055 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1450/2000] tot_loss=2.961 (perp=11.854, rec=0.128, cos=0.462), tot_loss_proj:3.049 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1500/2000] tot_loss=2.958 (perp=11.854, rec=0.126, cos=0.462), tot_loss_proj:3.056 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1550/2000] tot_loss=2.956 (perp=11.854, rec=0.124, cos=0.462), tot_loss_proj:3.048 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1600/2000] tot_loss=2.962 (perp=11.854, rec=0.127, cos=0.464), tot_loss_proj:3.064 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1650/2000] tot_loss=2.968 (perp=11.854, rec=0.135, cos=0.463), tot_loss_proj:3.073 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1700/2000] tot_loss=2.951 (perp=11.854, rec=0.119, cos=0.462), tot_loss_proj:3.050 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1750/2000] tot_loss=2.959 (perp=11.854, rec=0.126, cos=0.462), tot_loss_proj:3.058 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1800/2000] tot_loss=2.955 (perp=11.854, rec=0.123, cos=0.462), tot_loss_proj:3.052 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1850/2000] tot_loss=2.963 (perp=11.854, rec=0.131, cos=0.462), tot_loss_proj:3.038 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1900/2000] tot_loss=2.957 (perp=11.854, rec=0.125, cos=0.462), tot_loss_proj:3.057 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1950/2000] tot_loss=2.964 (perp=11.854, rec=0.132, cos=0.462), tot_loss_proj:3.050 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[2000/2000] tot_loss=2.961 (perp=11.854, rec=0.128, cos=0.462), tot_loss_proj:3.053 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 95.833 | p: 95.833 | r: 95.833
rougeLsum  | fm: 95.833 | p: 95.833 | r: 95.833
r1fm+r2fm = 183.333

input #5 time: 0:09:08 | total time: 0:54:42


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.7132979295440429
highest_index [0]
highest [0.7132979295440429]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9196669459342957 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.795002818107605 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.7816998362541199 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.7590761184692383 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.7276137471199036 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.703486979007721 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.6897465586662292 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 0.6886907815933228 for ['[CLS] demolition tre [SEP]']
[Init] best rec loss: 0.6567428708076477 for ['[CLS] double deep [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.103 (perp=6.813, rec=0.251, cos=0.490), tot_loss_proj:2.833 [t=0.23s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=2.199 (perp=8.089, rec=0.093, cos=0.488), tot_loss_proj:2.177 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=2.168 (perp=8.089, rec=0.061, cos=0.490), tot_loss_proj:2.173 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=2.158 (perp=8.089, rec=0.049, cos=0.490), tot_loss_proj:2.182 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.170 (perp=8.089, rec=0.061, cos=0.490), tot_loss_proj:2.173 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=2.174 (perp=8.089, rec=0.066, cos=0.491), tot_loss_proj:2.182 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.177 (perp=8.089, rec=0.068, cos=0.491), tot_loss_proj:2.180 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.168 (perp=8.089, rec=0.059, cos=0.491), tot_loss_proj:2.184 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=2.174 (perp=8.089, rec=0.065, cos=0.491), tot_loss_proj:2.184 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.176 (perp=8.089, rec=0.067, cos=0.491), tot_loss_proj:2.172 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.176 (perp=8.089, rec=0.068, cos=0.491), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=2.167 (perp=8.089, rec=0.059, cos=0.490), tot_loss_proj:2.183 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.173 (perp=8.089, rec=0.064, cos=0.491), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.168 (perp=8.089, rec=0.059, cos=0.491), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=2.163 (perp=8.089, rec=0.055, cos=0.491), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.146 (perp=8.089, rec=0.037, cos=0.491), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.166 (perp=8.089, rec=0.059, cos=0.490), tot_loss_proj:2.171 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=2.165 (perp=8.089, rec=0.056, cos=0.491), tot_loss_proj:2.185 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.162 (perp=8.089, rec=0.053, cos=0.491), tot_loss_proj:2.187 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=2.176 (perp=8.089, rec=0.067, cos=0.491), tot_loss_proj:2.171 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=2.159 (perp=8.089, rec=0.050, cos=0.491), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=2.168 (perp=8.089, rec=0.059, cos=0.491), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=2.172 (perp=8.089, rec=0.063, cos=0.491), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=2.176 (perp=8.089, rec=0.067, cos=0.491), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=2.167 (perp=8.089, rec=0.059, cos=0.491), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=2.166 (perp=8.089, rec=0.057, cos=0.491), tot_loss_proj:2.187 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=2.176 (perp=8.089, rec=0.068, cos=0.490), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=2.167 (perp=8.089, rec=0.058, cos=0.491), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=2.164 (perp=8.089, rec=0.055, cos=0.491), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=2.180 (perp=8.089, rec=0.071, cos=0.491), tot_loss_proj:2.184 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=2.173 (perp=8.089, rec=0.064, cos=0.491), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=2.188 (perp=8.089, rec=0.079, cos=0.491), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=2.166 (perp=8.089, rec=0.057, cos=0.491), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=2.165 (perp=8.089, rec=0.056, cos=0.491), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=2.176 (perp=8.089, rec=0.067, cos=0.491), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=2.158 (perp=8.089, rec=0.049, cos=0.491), tot_loss_proj:2.186 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=2.157 (perp=8.089, rec=0.048, cos=0.491), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=2.169 (perp=8.089, rec=0.061, cos=0.491), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=2.176 (perp=8.089, rec=0.067, cos=0.491), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=2.177 (perp=8.089, rec=0.068, cos=0.491), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 96.429 | p: 96.429 | r: 96.429
rougeLsum  | fm: 96.429 | p: 96.429 | r: 96.429
r1fm+r2fm = 185.714

input #6 time: 0:08:48 | total time: 1:03:31


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.7293364426917077
highest_index [0]
highest [0.7293364426917077]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.8646494150161743 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8059964776039124 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8045670390129089 for ['[CLS] strengths kenton bond victimsmined absent se sides deed gavin making resides renewed magic antarctica clarebalance gaingnapressive need another easy fell race merged [SEP]']
[Init] best rec loss: 0.7992118000984192 for ['[CLS] flat forewingsys mick separation ) oh yorkening las sat an consecutive charity qaeda clinicroud ill column rustling marathon rom viper dinner chuck ( [SEP]']
[Init] best rec loss: 0.787861168384552 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best perm rec loss: 0.786945641040802 for ['[CLS] bailey sits burkina zip wen professional™ nate lass taller hon now venue basis hull hydraulicim located visa nice few were readyolo hepburn candidates [SEP]']
[Init] best perm rec loss: 0.7866813540458679 for ['[CLS]olo bailey burkina venue™ located lassim now few zip sits candidates nice hon wen basis hydraulic ready professional were hull nate visa taller hepburn [SEP]']
[Init] best perm rec loss: 0.7862609028816223 for ['[CLS] hepburn ready located venue lass nice sits wenoloim candidates nate hydraulic visa hon burkina few were bailey taller zip now hull basis professional™ [SEP]']
[Init] best perm rec loss: 0.7861748337745667 for ['[CLS] visa tallerim venue hon burkina were bailey few nice hydraulic hepburn zip™ candidates now sits located professional ready wen nate lass basisolo hull [SEP]']
[Init] best perm rec loss: 0.785588264465332 for ['[CLS] fewim were hydraulic sits venue taller burkina visa lass hepburn now candidates located hon hullolo nate bailey zip wen basis ready nice™ professional [SEP]']
[Init] best perm rec loss: 0.785499632358551 for ['[CLS] were bailey candidates ready now nice zip located taller lassim venue nate professionalolo few™ hon hull basis burkina sits visa wen hepburn hydraulic [SEP]']
[Init] best perm rec loss: 0.784985363483429 for ['[CLS] venue hepburn were burkina zip wen few nate now nice basis taller honolo ready hull located sits professional bailey lass candidates visaim hydraulic™ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.863 (perp=10.617, rec=0.303, cos=0.437), tot_loss_proj:3.754 [t=0.23s]
prediction: ['[CLS] in boyfriend standard already character no is problem cute no de nothing problem problem afford him how security officer problems problem problem is. passed demon [SEP]']
[ 100/2000] tot_loss=2.367 (perp=8.559, rec=0.201, cos=0.454), tot_loss_proj:3.400 [t=0.24s]
prediction: ['[CLS] the is intelligence factor character no is problem character no character nice problem problem character he how any or problem problem problem.. islike [SEP]']
[ 150/2000] tot_loss=2.446 (perp=9.074, rec=0.162, cos=0.469), tot_loss_proj:3.579 [t=0.24s]
prediction: ['[CLS] the cute not here character no is problem character no cute ugly character problem love character francisco no or ugly problem problem.. islike [SEP]']
[ 200/2000] tot_loss=2.354 (perp=8.862, rec=0.144, cos=0.438), tot_loss_proj:3.239 [t=0.24s]
prediction: ['[CLS] the cute not here he no is problem character no cute mind factor problem love character wonders no or ugly the problem.. is ugly [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.276 (perp=8.486, rec=0.124, cos=0.455), tot_loss_proj:3.116 [t=0.24s]
prediction: ['[CLS] the cute not here he no is not character no cute mind factor problem love character coming no or ugly the problem. or is. [SEP]']
[ 300/2000] tot_loss=2.300 (perp=8.698, rec=0.101, cos=0.459), tot_loss_proj:3.150 [t=0.24s]
prediction: ['[CLS] here cute not here he no is not character no cute mind factor problem love he coming no or ugly ; problem, or is. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.365 (perp=8.940, rec=0.119, cos=0.458), tot_loss_proj:3.122 [t=0.24s]
prediction: ['[CLS] here cute not here he no is not character no cute mind factor problem love able.c or ugly ; problem, or is. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.182 (perp=7.974, rec=0.129, cos=0.458), tot_loss_proj:2.785 [t=0.24s]
prediction: ['[CLS] here i not phil he. no is not character no cute mind factor problem loveablec or ugly ; problem, or is. [SEP]']
[ 450/2000] tot_loss=2.112 (perp=7.760, rec=0.093, cos=0.467), tot_loss_proj:2.773 [t=0.24s]
prediction: ['[CLS] here i not this he. no is not character no cute mind factor problem loveablec or ugly ; problem, or is. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.200 (perp=8.124, rec=0.108, cos=0.467), tot_loss_proj:2.973 [t=0.24s]
prediction: ['[CLS] here i not not he. no is ‘ character no cute mind factor problem loveablec or ugly ; problem, or is. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.023 (perp=7.362, rec=0.091, cos=0.460), tot_loss_proj:2.729 [t=0.24s]
prediction: ['[CLS] here i not not he. no is this character no cute mind factor problem loveable orc ugly ; problem, or is. [SEP]']
[ 600/2000] tot_loss=2.032 (perp=7.362, rec=0.095, cos=0.465), tot_loss_proj:2.730 [t=0.24s]
prediction: ['[CLS] here i not not he. no is this character no cute mind factor problem loveable orc ugly ; problem, or is. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.995 (perp=7.206, rec=0.089, cos=0.464), tot_loss_proj:2.632 [t=0.24s]
prediction: ['[CLS] here i not not he. no is this character no mind cute factor problem loveable orc ugly ; problem, or is. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.101 (perp=7.739, rec=0.092, cos=0.461), tot_loss_proj:2.710 [t=0.24s]
prediction: ['[CLS] here i not ( he. no is this character mind no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
[ 750/2000] tot_loss=2.061 (perp=7.563, rec=0.082, cos=0.467), tot_loss_proj:2.682 [t=0.24s]
prediction: ['[CLS] here i not ( he. no is that character mind no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.077 (perp=7.563, rec=0.098, cos=0.466), tot_loss_proj:2.684 [t=0.24s]
prediction: ['[CLS] here i not ( he. no is that character mind no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.063 (perp=7.563, rec=0.085, cos=0.465), tot_loss_proj:2.683 [t=0.24s]
prediction: ['[CLS] here i not ( he. no is that character mind no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
[ 900/2000] tot_loss=2.068 (perp=7.563, rec=0.089, cos=0.467), tot_loss_proj:2.684 [t=0.24s]
prediction: ['[CLS] here i not ( he. no is that character mind no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.038 (perp=7.428, rec=0.089, cos=0.464), tot_loss_proj:2.673 [t=0.24s]
prediction: ['[CLS] here i not he. ( no is that character mind no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.996 (perp=7.232, rec=0.093, cos=0.456), tot_loss_proj:2.642 [t=0.24s]
prediction: ['[CLS] here i not he. ( no mind that character is no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
[1050/2000] tot_loss=1.947 (perp=6.992, rec=0.082, cos=0.466), tot_loss_proj:2.667 [t=0.24s]
prediction: ['[CLS] here i not he. has no mind that character is no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.942 (perp=6.992, rec=0.080, cos=0.464), tot_loss_proj:2.667 [t=0.24s]
prediction: ['[CLS] here i not he. has no mind that character is no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.914 (perp=6.835, rec=0.085, cos=0.463), tot_loss_proj:2.596 [t=0.24s]
prediction: ['[CLS] here has not he. i no mind that character is no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
[1200/2000] tot_loss=1.912 (perp=6.835, rec=0.080, cos=0.465), tot_loss_proj:2.591 [t=0.24s]
prediction: ['[CLS] here has not he. i no mind that character is no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.917 (perp=6.835, rec=0.085, cos=0.466), tot_loss_proj:2.593 [t=0.24s]
prediction: ['[CLS] here has not he. i no mind that character is no cute factor problem loveable orc ugly ; problem, or is. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.874 (perp=6.602, rec=0.089, cos=0.465), tot_loss_proj:2.356 [t=0.24s]
prediction: ['[CLS] here has not he. i no mind that character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
[1350/2000] tot_loss=1.873 (perp=6.602, rec=0.085, cos=0.467), tot_loss_proj:2.355 [t=0.24s]
prediction: ['[CLS] here has not he. i no mind that character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.838 (perp=6.449, rec=0.085, cos=0.463), tot_loss_proj:2.343 [t=0.24s]
prediction: ['[CLS] here has not he. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.837 (perp=6.449, rec=0.083, cos=0.464), tot_loss_proj:2.339 [t=0.24s]
prediction: ['[CLS] here has not he. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
[1500/2000] tot_loss=1.836 (perp=6.449, rec=0.081, cos=0.465), tot_loss_proj:2.340 [t=0.24s]
prediction: ['[CLS] here has not he. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.828 (perp=6.449, rec=0.073, cos=0.465), tot_loss_proj:2.343 [t=0.24s]
prediction: ['[CLS] here has not he. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.831 (perp=6.449, rec=0.076, cos=0.466), tot_loss_proj:2.338 [t=0.24s]
prediction: ['[CLS] here has not he. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
[1650/2000] tot_loss=1.833 (perp=6.449, rec=0.078, cos=0.465), tot_loss_proj:2.340 [t=0.24s]
prediction: ['[CLS] here has not he. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.830 (perp=6.449, rec=0.074, cos=0.466), tot_loss_proj:2.342 [t=0.24s]
prediction: ['[CLS] here has not he. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.786 (perp=6.211, rec=0.077, cos=0.467), tot_loss_proj:2.289 [t=0.24s]
prediction: ['[CLS] here he has not. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
[1800/2000] tot_loss=1.784 (perp=6.211, rec=0.076, cos=0.466), tot_loss_proj:2.283 [t=0.24s]
prediction: ['[CLS] here he has not. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.796 (perp=6.211, rec=0.088, cos=0.465), tot_loss_proj:2.286 [t=0.24s]
prediction: ['[CLS] here he has not. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.779 (perp=6.211, rec=0.071, cos=0.466), tot_loss_proj:2.293 [t=0.24s]
prediction: ['[CLS] here he has not. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
[1950/2000] tot_loss=1.782 (perp=6.211, rec=0.074, cos=0.466), tot_loss_proj:2.286 [t=0.24s]
prediction: ['[CLS] here he has not. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.781 (perp=6.211, rec=0.072, cos=0.466), tot_loss_proj:2.291 [t=0.24s]
prediction: ['[CLS] here he has not. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] here he has not. i mind that no character is no cute factor, loveable orc ugly ; problem problem or is. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.372 | p: 86.364 | r: 90.476
rouge2     | fm: 24.390 | p: 23.810 | r: 25.000
rougeL     | fm: 46.512 | p: 45.455 | r: 47.619
rougeLsum  | fm: 46.512 | p: 45.455 | r: 47.619
r1fm+r2fm = 112.762

[Aggregate metrics]:
rouge1     | fm: 98.547 | p: 98.295 | r: 98.810
rouge2     | fm: 78.049 | p: 77.976 | r: 78.125
rougeL     | fm: 90.189 | p: 90.057 | r: 90.327
rougeLsum  | fm: 90.189 | p: 90.057 | r: 90.327
r1fm+r2fm = 176.595

input #7 time: 0:09:19 | total time: 1:12:50


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.721711860128817
highest_index [0]
highest [0.721711860128817]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.670299768447876 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.6692196726799011 for ['[CLS] intra selfir major model centraliard doesncy do strait everyonetes exactly respect fine [UNK] musical smallerton eagleump bet recent [SEP]']
[Init] best rec loss: 0.6691712737083435 for ['[CLS] behalf eireann pts ask solutionog rhythm revived sky bonus derek yet affairsstick weird meaning now wellverse beforeα arterial centuries network [SEP]']
[Init] best rec loss: 0.6685695648193359 for ['[CLS] positions gocha rhine not ballet superiority closer advicejust grand noticesum service mr bomber mistakes up eve per altitude hearing verity constant [SEP]']
[Init] best rec loss: 0.6558949947357178 for ['[CLS] breed app king jude rome am regal roman grown levi mine fitting peninsula cappella age bulldogs component founder macarthur unionist overturegible raysstock [SEP]']
[Init] best rec loss: 0.6482844948768616 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best perm rec loss: 0.6479088664054871 for ['[CLS] checkpoint won americas dated perspective discus judge colour frowned lindsey quota awesomeencies conference thinkmeric treated cases virginia lined labordant prize roots [SEP]']
[Init] best perm rec loss: 0.6478966474533081 for ['[CLS] laborencies awesome won americas judge virginia frowned colour think lineddant checkpoint perspective lindsey quota cases conference treated roots discusmeric dated prize [SEP]']
[Init] best perm rec loss: 0.6451743245124817 for ['[CLS] cases prize quota americas checkpoint conferenceencies virginia lineddant frowned colour treated judge dated lindseymeric perspective discus awesome labor won think roots [SEP]']
[Init] best perm rec loss: 0.6450901627540588 for ['[CLS] americas frowned labor awesome roots prize discusencies lined cases treated perspective lindsey think colourmeric quota conference dateddant won checkpoint virginia judge [SEP]']
[Init] best perm rec loss: 0.6446019411087036 for ['[CLS] lindsey treated dated quota conference cases perspectivedant roots checkpoint frowned linedencies discus won think virginia prize judge colour awesome americas labormeric [SEP]']
[Init] best perm rec loss: 0.643117368221283 for ['[CLS] americas discus lindsey awesome perspectiveencies conference judge labor checkpoint lined won colour virginia frowneddant think cases prize treated roots quotameric dated [SEP]']
[Init] best perm rec loss: 0.6424195170402527 for ['[CLS] discus prize awesome lindsey conference virginiameric americasencies treated frowned won colour think roots checkpoint cases labor dated lined judgedant quota perspective [SEP]']
[Init] best perm rec loss: 0.6418938040733337 for ['[CLS] lined judge discus checkpoint won perspective roots awesome prize conference americasdant virginia frowned casesencies quota colour lindsey think treated labor datedmeric [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.300 (perp=12.521, rec=0.343, cos=0.453), tot_loss_proj:4.121 [t=0.23s]
prediction: ['[CLS] vanity queen film what takes trade sculpture as fear debt heap vanityput desert what what reducing seemed facilities where pulled a against boat [SEP]']
[ 100/2000] tot_loss=3.253 (perp=12.512, rec=0.248, cos=0.502), tot_loss_proj:4.073 [t=0.23s]
prediction: ['[CLS] vanityful film what is trade something that doubt debt pays vanity vanity sorority what what pay quite someone where owed a what dioxide [SEP]']
[ 150/2000] tot_loss=3.027 (perp=12.017, rec=0.171, cos=0.453), tot_loss_proj:3.860 [t=0.24s]
prediction: ['[CLS] frightful film what is pays something that doubt debt pays vanity vanity sorority want what off quite someone benign owed a whati [SEP]']
[ 200/2000] tot_loss=3.194 (perp=12.877, rec=0.150, cos=0.469), tot_loss_proj:4.052 [t=0.24s]
prediction: ['[CLS] frightful film what s pays something that doubt debt pays vanity vanity creek want what off barely someone benign owed benign whati [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.990 (perp=11.961, rec=0.138, cos=0.460), tot_loss_proj:3.980 [t=0.24s]
prediction: ['[CLS] frightful film whati pays no that doubt debt pays vanity vanity benign want what off no them benign owed benign what s [SEP]']
[ 300/2000] tot_loss=3.067 (perp=12.472, rec=0.122, cos=0.450), tot_loss_proj:4.099 [t=0.24s]
prediction: ['[CLS] frightful film whati a no that doubt debt pays vanity vanity benign decent knew off no they benign owed benign what s [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.956 (perp=11.885, rec=0.112, cos=0.466), tot_loss_proj:4.039 [t=0.24s]
prediction: ['[CLS] frightful film whati a doubt that no debt pays vanity vanity benign decent knew off no they benign owed benign what s [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.699 (perp=10.695, rec=0.115, cos=0.445), tot_loss_proj:3.775 [t=0.24s]
prediction: ['[CLS] frightful film whati a doubt that no debt pays off, vanity vanity benign those knew they felt owed benign off s [SEP]']
[ 450/2000] tot_loss=2.767 (perp=11.075, rec=0.097, cos=0.455), tot_loss_proj:3.808 [t=0.24s]
prediction: ['[CLS] frightful film whatmax a doubt that no debt pays off, vanity vanityi those knew they felt owed benign off s [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.567 (perp=10.058, rec=0.092, cos=0.464), tot_loss_proj:3.581 [t=0.24s]
prediction: ['[CLS] frightfuli whatmax a doubt that no debt pays off, vanity vanity film those felt they felt owed benign for s [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.474 (perp=9.552, rec=0.090, cos=0.473), tot_loss_proj:3.493 [t=0.24s]
prediction: ['[CLS] frightfulimax what a doubt that no debt pays off, vanity vanity film a felt they felt owed benign, s [SEP]']
[ 600/2000] tot_loss=2.461 (perp=9.552, rec=0.083, cos=0.467), tot_loss_proj:3.498 [t=0.24s]
prediction: ['[CLS] frightfulimax what a doubt that no debt pays off, vanity vanity film a felt they felt owed benign, s [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.327 (perp=8.908, rec=0.087, cos=0.458), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] frightfulimax what a doubt that no debt pays off, a vanity vanity film felt they felt owed benign, s [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.271 (perp=8.617, rec=0.081, cos=0.467), tot_loss_proj:3.264 [t=0.24s]
prediction: ['[CLS] frightfulimax what a doubt that no debt pays off, a vanity vanity film they felt felt owed benign, s [SEP]']
[ 750/2000] tot_loss=2.430 (perp=9.397, rec=0.081, cos=0.469), tot_loss_proj:3.390 [t=0.24s]
prediction: ['[CLS] frightfulimax what a doubt that no debt pays off, a vanity vanity film they felt mira owed benign, s [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.271 (perp=8.604, rec=0.081, cos=0.469), tot_loss_proj:3.221 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanity vanity film they felti owed benign, s [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.283 (perp=8.676, rec=0.076, cos=0.472), tot_loss_proj:3.255 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanityi film they felt mira owed benign, s [SEP]']
[ 900/2000] tot_loss=2.284 (perp=8.676, rec=0.079, cos=0.471), tot_loss_proj:3.253 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanityi film they felt mira owed benign, s [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.277 (perp=8.676, rec=0.071, cos=0.471), tot_loss_proj:3.260 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanityi film they felt mira owed benign, s [SEP]']
Attempt swap
[1000/2000] tot_loss=2.279 (perp=8.676, rec=0.073, cos=0.471), tot_loss_proj:3.256 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanityi film they felt mira owed benign, s [SEP]']
[1050/2000] tot_loss=2.283 (perp=8.676, rec=0.077, cos=0.471), tot_loss_proj:3.254 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanityi film they felt mira owed benign, s [SEP]']
Attempt swap
[1100/2000] tot_loss=2.280 (perp=8.676, rec=0.073, cos=0.472), tot_loss_proj:3.256 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanityi film they felt mira owed benign, s [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.216 (perp=8.337, rec=0.079, cos=0.469), tot_loss_proj:3.091 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanity film they felt mira owed benigni, s [SEP]']
[1200/2000] tot_loss=2.209 (perp=8.337, rec=0.070, cos=0.472), tot_loss_proj:3.090 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanity film they felt mira owed benigni, s [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.188 (perp=8.189, rec=0.079, cos=0.472), tot_loss_proj:3.081 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanity film they felt owed benigni, s mira [SEP]']
Attempt swap
[1300/2000] tot_loss=2.184 (perp=8.189, rec=0.075, cos=0.471), tot_loss_proj:3.081 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanity film they felt owed benigni, s mira [SEP]']
[1350/2000] tot_loss=2.180 (perp=8.189, rec=0.071, cos=0.471), tot_loss_proj:3.079 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanity film they felt owed benigni, s mira [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.163 (perp=8.100, rec=0.071, cos=0.472), tot_loss_proj:2.996 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanity film they felt owed mira benigni, s [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.165 (perp=8.100, rec=0.071, cos=0.474), tot_loss_proj:2.993 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanity film they felt owed mira benigni, s [SEP]']
[1500/2000] tot_loss=2.170 (perp=8.100, rec=0.078, cos=0.473), tot_loss_proj:2.995 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanity film they felt owed mira benigni, s [SEP]']
Attempt swap
[1550/2000] tot_loss=2.165 (perp=8.100, rec=0.073, cos=0.472), tot_loss_proj:2.993 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no debt pays off, a vanity film they felt owed mira benigni, s [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.136 (perp=7.947, rec=0.075, cos=0.471), tot_loss_proj:2.922 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no vanity debt pays off, a film they felt owed mira benigni, s [SEP]']
[1650/2000] tot_loss=2.139 (perp=7.947, rec=0.078, cos=0.471), tot_loss_proj:2.924 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no vanity debt pays off, a film they felt owed mira benigni, s [SEP]']
Attempt swap
[1700/2000] tot_loss=2.132 (perp=7.947, rec=0.071, cos=0.471), tot_loss_proj:2.920 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no vanity debt pays off, a film they felt owed mira benigni, s [SEP]']
Attempt swap
[1750/2000] tot_loss=2.131 (perp=7.947, rec=0.070, cos=0.472), tot_loss_proj:2.920 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no vanity debt pays off, a film they felt owed mira benigni, s [SEP]']
[1800/2000] tot_loss=2.138 (perp=7.947, rec=0.076, cos=0.472), tot_loss_proj:2.924 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no vanity debt pays off, a film they felt owed mira benigni, s [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.103 (perp=7.812, rec=0.071, cos=0.470), tot_loss_proj:3.008 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no vanity debt pays off, a film they felt mira benigni owed, s [SEP]']
Attempt swap
[1900/2000] tot_loss=2.106 (perp=7.812, rec=0.074, cos=0.470), tot_loss_proj:3.006 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no vanity debt pays off, a film they felt mira benigni owed, s [SEP]']
[1950/2000] tot_loss=2.107 (perp=7.812, rec=0.075, cos=0.470), tot_loss_proj:3.009 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no vanity debt pays off, a film they felt mira benigni owed, s [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.106 (perp=7.812, rec=0.073, cos=0.470), tot_loss_proj:3.009 [t=0.24s]
prediction: ['[CLS] frightful miramax what a doubt that no vanity debt pays off, a film they felt mira benigni owed, s [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] frightful miramax what a doubt that no vanity debt pays off, a film they felt mira benigni owed, s [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.683 | p: 90.476 | r: 95.000
rouge2     | fm: 10.256 | p: 10.000 | r: 10.526
rougeL     | fm: 43.902 | p: 42.857 | r: 45.000
rougeLsum  | fm: 43.902 | p: 42.857 | r: 45.000
r1fm+r2fm = 102.939

[Aggregate metrics]:
rouge1     | fm: 97.895 | p: 97.427 | r: 98.386
rouge2     | fm: 70.516 | p: 70.423 | r: 70.614
rougeL     | fm: 85.046 | p: 84.812 | r: 85.291
rougeLsum  | fm: 85.191 | p: 84.957 | r: 85.423
r1fm+r2fm = 168.411

input #8 time: 0:09:17 | total time: 1:22:08


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.7647719838131897
highest_index [0]
highest [0.7647719838131897]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.7772300839424133 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.6912007927894592 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.6810701489448547 for ['[CLS] military offered fragments gathered leaning sphere rom legs [SEP]']
[Init] best rec loss: 0.6590933203697205 for ['[CLS] ham ice command across see beatty anal tan [SEP]']
[Init] best rec loss: 0.6543917655944824 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6534223556518555 for ['[CLS] luck decca cody outlaw edward deathsdden arsenal [SEP]']
[Init] best perm rec loss: 0.6524670124053955 for ['[CLS] cody outlawdden arsenal edward decca luck deaths [SEP]']
[Init] best perm rec loss: 0.6505599617958069 for ['[CLS] deaths decca outlaw cody edward arsenal luckdden [SEP]']
[Init] best perm rec loss: 0.6497392058372498 for ['[CLS] deaths cody outlaw edward luck arsenaldden decca [SEP]']
[Init] best perm rec loss: 0.6482353210449219 for ['[CLS] decca arsenal edward outlaw codydden deaths luck [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.418 (perp=13.570, rec=0.272, cos=0.433), tot_loss_proj:3.782 [t=0.23s]
prediction: ['[CLS]plate softhead metaphysical clap claptra increasingly [SEP]']
[ 100/2000] tot_loss=2.267 (perp=8.581, rec=0.178, cos=0.372), tot_loss_proj:2.408 [t=0.23s]
prediction: ['[CLS] of softhead metaphysical clap claptrap [SEP]']
[ 150/2000] tot_loss=2.029 (perp=7.643, rec=0.089, cos=0.411), tot_loss_proj:2.014 [t=0.23s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
[ 200/2000] tot_loss=2.007 (perp=7.643, rec=0.066, cos=0.413), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.952 (perp=7.384, rec=0.068, cos=0.406), tot_loss_proj:2.035 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 300/2000] tot_loss=1.948 (perp=7.384, rec=0.060, cos=0.411), tot_loss_proj:2.036 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.955 (perp=7.384, rec=0.066, cos=0.413), tot_loss_proj:2.039 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.955 (perp=7.384, rec=0.065, cos=0.413), tot_loss_proj:2.043 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 450/2000] tot_loss=1.959 (perp=7.384, rec=0.068, cos=0.414), tot_loss_proj:2.041 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.953 (perp=7.384, rec=0.063, cos=0.414), tot_loss_proj:2.048 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.963 (perp=7.384, rec=0.072, cos=0.414), tot_loss_proj:2.048 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 600/2000] tot_loss=1.950 (perp=7.384, rec=0.059, cos=0.414), tot_loss_proj:2.041 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.946 (perp=7.384, rec=0.055, cos=0.414), tot_loss_proj:2.042 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.952 (perp=7.384, rec=0.061, cos=0.415), tot_loss_proj:2.042 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 750/2000] tot_loss=1.949 (perp=7.384, rec=0.058, cos=0.414), tot_loss_proj:2.042 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.957 (perp=7.384, rec=0.066, cos=0.414), tot_loss_proj:2.044 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.962 (perp=7.384, rec=0.071, cos=0.414), tot_loss_proj:2.041 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 900/2000] tot_loss=1.943 (perp=7.384, rec=0.052, cos=0.414), tot_loss_proj:2.044 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.951 (perp=7.384, rec=0.060, cos=0.414), tot_loss_proj:2.056 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.950 (perp=7.384, rec=0.058, cos=0.415), tot_loss_proj:2.049 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1050/2000] tot_loss=1.961 (perp=7.384, rec=0.070, cos=0.415), tot_loss_proj:2.038 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.953 (perp=7.384, rec=0.062, cos=0.415), tot_loss_proj:2.033 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.961 (perp=7.384, rec=0.070, cos=0.415), tot_loss_proj:2.038 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1200/2000] tot_loss=1.959 (perp=7.384, rec=0.068, cos=0.415), tot_loss_proj:2.031 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.953 (perp=7.384, rec=0.062, cos=0.415), tot_loss_proj:2.040 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.961 (perp=7.384, rec=0.070, cos=0.415), tot_loss_proj:2.040 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1350/2000] tot_loss=1.965 (perp=7.384, rec=0.073, cos=0.415), tot_loss_proj:2.035 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.947 (perp=7.384, rec=0.055, cos=0.415), tot_loss_proj:2.044 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.956 (perp=7.384, rec=0.065, cos=0.415), tot_loss_proj:2.039 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1500/2000] tot_loss=1.958 (perp=7.384, rec=0.066, cos=0.415), tot_loss_proj:2.043 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.947 (perp=7.384, rec=0.056, cos=0.415), tot_loss_proj:2.034 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.949 (perp=7.384, rec=0.057, cos=0.415), tot_loss_proj:2.038 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1650/2000] tot_loss=1.961 (perp=7.384, rec=0.070, cos=0.415), tot_loss_proj:2.043 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.946 (perp=7.384, rec=0.055, cos=0.415), tot_loss_proj:2.043 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.959 (perp=7.384, rec=0.068, cos=0.415), tot_loss_proj:2.037 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1800/2000] tot_loss=1.951 (perp=7.384, rec=0.059, cos=0.415), tot_loss_proj:2.038 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.950 (perp=7.384, rec=0.058, cos=0.415), tot_loss_proj:2.037 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.955 (perp=7.384, rec=0.064, cos=0.415), tot_loss_proj:2.032 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1950/2000] tot_loss=1.953 (perp=7.384, rec=0.062, cos=0.415), tot_loss_proj:2.048 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.956 (perp=7.384, rec=0.064, cos=0.415), tot_loss_proj:2.044 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical softheaded claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 98.106 | p: 97.684 | r: 98.548
rouge2     | fm: 68.000 | p: 68.000 | r: 68.000
rougeL     | fm: 85.136 | p: 84.924 | r: 85.333
rougeLsum  | fm: 85.136 | p: 84.924 | r: 85.357
r1fm+r2fm = 166.106

input #9 time: 0:09:08 | total time: 1:31:17


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.7385500300800452
highest_index [0]
highest [0.7385500300800452]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8340819478034973 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8181060552597046 for ['[CLS] university mitaonaefa never existing gym backed ribs realmsund odd [SEP]']
[Init] best rec loss: 0.7834148406982422 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.6811671853065491 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 0.6766305565834045 for ['[CLS] themes up sheep blessedblood angel common orderoric places totally level sound [SEP]']
[Init] best perm rec loss: 0.6762905120849609 for ['[CLS]oricblood sound up themes sheep blessed angel places level order totally common [SEP]']
[Init] best perm rec loss: 0.6753523349761963 for ['[CLS] totally order blessed level up common themes angelblood places sheep soundoric [SEP]']
[Init] best perm rec loss: 0.6707455515861511 for ['[CLS]oric levelblood totally common up sound order angel places themes sheep blessed [SEP]']
[Init] best perm rec loss: 0.668698251247406 for ['[CLS] places angel totally soundblood common blessed up order sheep themes leveloric [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.046 (perp=11.290, rec=0.334, cos=0.453), tot_loss_proj:3.456 [t=0.23s]
prediction: ['[CLS]lent lines availability plays right animal & conflict built. balance based positive [SEP]']
[ 100/2000] tot_loss=2.800 (perp=10.686, rec=0.214, cos=0.449), tot_loss_proj:3.309 [t=0.23s]
prediction: ['[CLS] ab rhythms balance rhythms real incident withitating ab. balanceulsive real [SEP]']
[ 150/2000] tot_loss=3.029 (perp=12.142, rec=0.151, cos=0.449), tot_loss_proj:3.555 [t=0.23s]
prediction: ['[CLS] ably balance rhythms real incident with prop ab incident balanceulsive real [SEP]']
[ 200/2000] tot_loss=3.138 (perp=12.813, rec=0.130, cos=0.445), tot_loss_proj:3.650 [t=0.23s]
prediction: ['[CLS] ably balance rhythmslyulsive with prop ab incident balanceulsive real [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.672 (perp=10.467, rec=0.130, cos=0.449), tot_loss_proj:3.180 [t=0.23s]
prediction: ['[CLS]lyly balance rhythmslyulsive with propulsive incident balance ab real [SEP]']
[ 300/2000] tot_loss=2.626 (perp=10.369, rec=0.099, cos=0.453), tot_loss_proj:3.179 [t=0.23s]
prediction: ['[CLS]lys balance rhythmslyulsive with propulsive incident balance ab real [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.380 (perp=9.185, rec=0.091, cos=0.452), tot_loss_proj:2.791 [t=0.23s]
prediction: ['[CLS]lys rhythms ably time with propulsive incident balance rhythms real [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.349 (perp=8.839, rec=0.131, cos=0.450), tot_loss_proj:2.709 [t=0.23s]
prediction: ['[CLS] ablys humanly time with propulsive incident balance rhythms real [SEP]']
[ 450/2000] tot_loss=2.235 (perp=8.463, rec=0.089, cos=0.454), tot_loss_proj:2.624 [t=0.23s]
prediction: ['[CLS] ablys human - time with propulsive incident balance rhythms real [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.178 (perp=8.186, rec=0.091, cos=0.450), tot_loss_proj:2.574 [t=0.23s]
prediction: ['[CLS] ablys - human time with propulsive incident balance rhythms real [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.123 (perp=7.888, rec=0.092, cos=0.453), tot_loss_proj:2.564 [t=0.23s]
prediction: ['[CLS] ablys - with time human propulsive incident balance rhythms real [SEP]']
[ 600/2000] tot_loss=2.113 (perp=7.888, rec=0.081, cos=0.455), tot_loss_proj:2.563 [t=0.23s]
prediction: ['[CLS] ablys - with time human propulsive incident balance rhythms real [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.083 (perp=7.690, rec=0.090, cos=0.455), tot_loss_proj:2.544 [t=0.23s]
prediction: ['[CLS] ablys - with time human propulsive balance incident rhythms real [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.070 (perp=7.690, rec=0.078, cos=0.454), tot_loss_proj:2.549 [t=0.23s]
prediction: ['[CLS] ablys - with time human propulsive balance incident rhythms real [SEP]']
[ 750/2000] tot_loss=2.076 (perp=7.690, rec=0.083, cos=0.455), tot_loss_proj:2.547 [t=0.23s]
prediction: ['[CLS] ablys - with time human propulsive balance incident rhythms real [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.073 (perp=7.690, rec=0.081, cos=0.454), tot_loss_proj:2.548 [t=0.23s]
prediction: ['[CLS] ablys - with time human propulsive balance incident rhythms real [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.080 (perp=7.690, rec=0.087, cos=0.454), tot_loss_proj:2.542 [t=0.23s]
prediction: ['[CLS] ablys - with time human propulsive balance incident rhythms real [SEP]']
[ 900/2000] tot_loss=2.071 (perp=7.690, rec=0.079, cos=0.455), tot_loss_proj:2.546 [t=0.23s]
prediction: ['[CLS] ablys - with time human propulsive balance incident rhythms real [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.070 (perp=7.690, rec=0.077, cos=0.454), tot_loss_proj:2.546 [t=0.23s]
prediction: ['[CLS] ablys - with time human propulsive balance incident rhythms real [SEP]']
Attempt swap
[1000/2000] tot_loss=2.076 (perp=7.690, rec=0.084, cos=0.454), tot_loss_proj:2.540 [t=0.23s]
prediction: ['[CLS] ablys - with time human propulsive balance incident rhythms real [SEP]']
[1050/2000] tot_loss=2.183 (perp=8.283, rec=0.072, cos=0.454), tot_loss_proj:2.651 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1100/2000] tot_loss=2.192 (perp=8.283, rec=0.082, cos=0.454), tot_loss_proj:2.653 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1150/2000] tot_loss=2.183 (perp=8.283, rec=0.073, cos=0.453), tot_loss_proj:2.647 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
[1200/2000] tot_loss=2.185 (perp=8.283, rec=0.074, cos=0.454), tot_loss_proj:2.652 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1250/2000] tot_loss=2.182 (perp=8.283, rec=0.072, cos=0.453), tot_loss_proj:2.647 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1300/2000] tot_loss=2.188 (perp=8.283, rec=0.077, cos=0.455), tot_loss_proj:2.651 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
[1350/2000] tot_loss=2.184 (perp=8.283, rec=0.073, cos=0.454), tot_loss_proj:2.657 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1400/2000] tot_loss=2.193 (perp=8.283, rec=0.082, cos=0.454), tot_loss_proj:2.650 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1450/2000] tot_loss=2.193 (perp=8.283, rec=0.082, cos=0.454), tot_loss_proj:2.649 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
[1500/2000] tot_loss=2.187 (perp=8.283, rec=0.076, cos=0.454), tot_loss_proj:2.656 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1550/2000] tot_loss=2.190 (perp=8.283, rec=0.079, cos=0.454), tot_loss_proj:2.645 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1600/2000] tot_loss=2.193 (perp=8.283, rec=0.082, cos=0.454), tot_loss_proj:2.649 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
[1650/2000] tot_loss=2.194 (perp=8.283, rec=0.083, cos=0.454), tot_loss_proj:2.651 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1700/2000] tot_loss=2.195 (perp=8.283, rec=0.084, cos=0.454), tot_loss_proj:2.655 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1750/2000] tot_loss=2.192 (perp=8.283, rec=0.081, cos=0.454), tot_loss_proj:2.658 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
[1800/2000] tot_loss=2.185 (perp=8.283, rec=0.074, cos=0.454), tot_loss_proj:2.652 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1850/2000] tot_loss=2.192 (perp=8.283, rec=0.081, cos=0.454), tot_loss_proj:2.650 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[1900/2000] tot_loss=2.191 (perp=8.283, rec=0.080, cos=0.454), tot_loss_proj:2.649 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
[1950/2000] tot_loss=2.191 (perp=8.283, rec=0.080, cos=0.454), tot_loss_proj:2.648 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Attempt swap
[2000/2000] tot_loss=2.188 (perp=8.283, rec=0.077, cos=0.454), tot_loss_proj:2.656 [t=0.23s]
prediction: ['[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] ablys - with time cr propulsive balance incident rhythms real [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 72.727 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.619 | p: 45.455 | r: 50.000
rougeLsum  | fm: 47.619 | p: 45.455 | r: 50.000
r1fm+r2fm = 76.190

[Aggregate metrics]:
rouge1     | fm: 96.113 | p: 95.415 | r: 96.905
rouge2     | fm: 61.332 | p: 61.255 | r: 61.411
rougeL     | fm: 81.488 | p: 81.100 | r: 81.905
rougeLsum  | fm: 81.942 | p: 81.749 | r: 82.359
r1fm+r2fm = 157.445

input #10 time: 0:09:08 | total time: 1:40:26


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.7213301156571621
highest_index [0]
highest [0.7213301156571621]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.8568717241287231 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.844807505607605 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.7756858468055725 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.7740219831466675 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.7685374021530151 for ['[CLS] drawnture tal platform inland mileguvd familiar me [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.702 (perp=14.476, rec=0.331, cos=0.476), tot_loss_proj:4.178 [t=0.23s]
prediction: ['[CLS] constantly refused gel gel missing noticed begging soon refused refused [SEP]']
[ 100/2000] tot_loss=3.467 (perp=13.736, rec=0.255, cos=0.465), tot_loss_proj:4.404 [t=0.23s]
prediction: ['[CLS] legislation refused gel gel refused getting refused gel refused refused [SEP]']
[ 150/2000] tot_loss=2.978 (perp=11.720, rec=0.174, cos=0.460), tot_loss_proj:3.647 [t=0.23s]
prediction: ['[CLS] was attempted gel here refused that attempted gel stubborn refused [SEP]']
[ 200/2000] tot_loss=3.022 (perp=12.208, rec=0.114, cos=0.467), tot_loss_proj:3.746 [t=0.23s]
prediction: ['[CLS] was attempted gel here refused that attemptedly stubborn refused [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.632 (perp=10.217, rec=0.114, cos=0.475), tot_loss_proj:3.327 [t=0.23s]
prediction: ['[CLS] was attempted gel here refused that attempted stubbornly refused [SEP]']
[ 300/2000] tot_loss=2.615 (perp=10.217, rec=0.102, cos=0.469), tot_loss_proj:3.325 [t=0.23s]
prediction: ['[CLS] was attempted gel here refused that attempted stubbornly refused [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.531 (perp=9.742, rec=0.111, cos=0.471), tot_loss_proj:3.347 [t=0.23s]
prediction: ['[CLS] was attempted gelly refused that here stubborn to refused [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.852 (perp=11.418, rec=0.099, cos=0.469), tot_loss_proj:3.517 [t=0.23s]
prediction: ['[CLS] was attempted gel attempted refused that here stubborn refused to [SEP]']
[ 450/2000] tot_loss=2.472 (perp=9.532, rec=0.095, cos=0.471), tot_loss_proj:3.232 [t=0.23s]
prediction: ['[CLS] was attempted gelly refused that here stubborn refused to [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.676 (perp=10.482, rec=0.112, cos=0.467), tot_loss_proj:3.367 [t=0.23s]
prediction: ['[CLS] here was attempted gel attempted refused that stubborn refused to [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.307 (perp=8.673, rec=0.103, cos=0.470), tot_loss_proj:3.138 [t=0.23s]
prediction: ['[CLS] here was attempted gelly that being stubborn refused to [SEP]']
[ 600/2000] tot_loss=2.292 (perp=8.673, rec=0.087, cos=0.470), tot_loss_proj:3.145 [t=0.23s]
prediction: ['[CLS] here was attempted gelly that being stubborn refused to [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.170 (perp=8.016, rec=0.097, cos=0.471), tot_loss_proj:2.798 [t=0.23s]
prediction: ['[CLS] here was attempted gelly stubborn being that refused to [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.143 (perp=7.895, rec=0.092, cos=0.472), tot_loss_proj:2.777 [t=0.23s]
prediction: ['[CLS] here was attempted gel stubbornly being that refused to [SEP]']
[ 750/2000] tot_loss=2.140 (perp=7.895, rec=0.092, cos=0.470), tot_loss_proj:2.772 [t=0.23s]
prediction: ['[CLS] here was attempted gel stubbornly being that refused to [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.991 (perp=7.143, rec=0.093, cos=0.470), tot_loss_proj:2.329 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly being that refused to gel [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.951 (perp=6.997, rec=0.082, cos=0.469), tot_loss_proj:2.359 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[ 900/2000] tot_loss=1.947 (perp=6.997, rec=0.078, cos=0.469), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.946 (perp=6.997, rec=0.077, cos=0.469), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.949 (perp=6.997, rec=0.080, cos=0.470), tot_loss_proj:2.345 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1050/2000] tot_loss=1.954 (perp=6.997, rec=0.084, cos=0.470), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.946 (perp=6.997, rec=0.077, cos=0.470), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.955 (perp=6.997, rec=0.085, cos=0.470), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1200/2000] tot_loss=1.962 (perp=6.997, rec=0.092, cos=0.470), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.944 (perp=6.997, rec=0.074, cos=0.470), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.958 (perp=6.997, rec=0.087, cos=0.471), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1350/2000] tot_loss=1.963 (perp=6.997, rec=0.090, cos=0.473), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.952 (perp=6.997, rec=0.078, cos=0.475), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.961 (perp=6.997, rec=0.087, cos=0.475), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1500/2000] tot_loss=1.946 (perp=6.997, rec=0.071, cos=0.475), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.961 (perp=6.997, rec=0.086, cos=0.475), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.949 (perp=6.997, rec=0.074, cos=0.476), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1650/2000] tot_loss=1.962 (perp=6.997, rec=0.087, cos=0.476), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.951 (perp=6.997, rec=0.076, cos=0.476), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.954 (perp=6.997, rec=0.079, cos=0.476), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1800/2000] tot_loss=1.959 (perp=6.997, rec=0.084, cos=0.476), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.954 (perp=6.997, rec=0.079, cos=0.476), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.944 (perp=6.997, rec=0.068, cos=0.476), tot_loss_proj:2.345 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1950/2000] tot_loss=1.957 (perp=6.997, rec=0.081, cos=0.476), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.951 (perp=6.997, rec=0.076, cos=0.476), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was attempted stubbornly that being refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 96.694 | p: 95.969 | r: 97.500
rouge2     | fm: 59.188 | p: 59.167 | r: 59.211
rougeL     | fm: 80.758 | p: 80.402 | r: 81.131
rougeLsum  | fm: 80.859 | p: 80.429 | r: 81.329
r1fm+r2fm = 155.882

input #11 time: 0:08:55 | total time: 1:49:21


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.7247709905980659
highest_index [0]
highest [0.7247709905980659]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8374319076538086 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.8352120518684387 for ['[CLS] systems simonway met armenia blockade tongue when unisonizes and present reeve representatives [SEP]']
[Init] best rec loss: 0.7863689064979553 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.783691942691803 for ['[CLS] wolf rex usualli plant live painfully sqlamtpemi wallace du sort [SEP]']
[Init] best rec loss: 0.7814491391181946 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7649577260017395 for ['[CLS] this heart hot noise fixing trying system potential salt ifana defense ii alexandria [SEP]']
[Init] best rec loss: 0.753821611404419 for ['[CLS] hear protocol heidi race strokes safety association transactions snail most place buried terror documentary [SEP]']
[Init] best rec loss: 0.7325313687324524 for ['[CLS] alive expression semiuid wise friend investigationthed beloved [MASK] got richards didnbank [SEP]']
[Init] best perm rec loss: 0.7304497361183167 for ['[CLS] gotbank wiseuid friend semi didn richards [MASK] alivethed expression beloved investigation [SEP]']
[Init] best perm rec loss: 0.7303640842437744 for ['[CLS] got friend alive wise richards beloved [MASK] expression didn semi investigationbankuidthed [SEP]']
[Init] best perm rec loss: 0.7278624773025513 for ['[CLS] beloved wise didnthedbank richardsuid [MASK] semi alive got friend expression investigation [SEP]']
[Init] best perm rec loss: 0.7268891930580139 for ['[CLS]uidthed beloved investigation alive expression friendbank didn got [MASK] wise richards semi [SEP]']
[Init] best perm rec loss: 0.7263718843460083 for ['[CLS] got richards alive wise semi expressionbankthed beloved [MASK] friend investigation didnuid [SEP]']
[Init] best perm rec loss: 0.7256802320480347 for ['[CLS] wise richards semi alivebank investigation [MASK] expression beloved didnuid friend gotthed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.944 (perp=11.075, rec=0.269, cos=0.460), tot_loss_proj:3.564 [t=0.23s]
prediction: ['[CLS] nosed network on seen bad done, better cable without barely barely seen advantage [SEP]']
[ 100/2000] tot_loss=2.804 (perp=10.781, rec=0.177, cos=0.471), tot_loss_proj:3.499 [t=0.23s]
prediction: ['[CLS] nosed on will seen to advantage, better cable advantage its barely seen barely [SEP]']
[ 150/2000] tot_loss=2.602 (perp=10.133, rec=0.113, cos=0.462), tot_loss_proj:3.397 [t=0.23s]
prediction: ['[CLS] nosed on will seen to advantage, better cable advantage its barely seen advantage [SEP]']
[ 200/2000] tot_loss=2.485 (perp=9.631, rec=0.097, cos=0.462), tot_loss_proj:3.377 [t=0.23s]
prediction: ['[CLS] considering on will seen to advantage, better cable advantage its barely seen advantage [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.479 (perp=9.652, rec=0.083, cos=0.466), tot_loss_proj:3.121 [t=0.23s]
prediction: ['[CLS] considering will seen to that especially better on cable advantage its barely seen especially [SEP]']
[ 300/2000] tot_loss=2.473 (perp=9.652, rec=0.070, cos=0.472), tot_loss_proj:3.117 [t=0.23s]
prediction: ['[CLS] considering will seen to that especially better on cable advantage its barely seen especially [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.451 (perp=9.484, rec=0.081, cos=0.473), tot_loss_proj:3.092 [t=0.23s]
prediction: ['[CLS] considering will seen to that especially better on cable barely its advantage considering especially [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.363 (perp=9.071, rec=0.079, cos=0.470), tot_loss_proj:3.104 [t=0.23s]
prediction: ['[CLS] barely will seen to that especially better on cable considering its advantage considering especially [SEP]']
[ 450/2000] tot_loss=2.357 (perp=9.071, rec=0.070, cos=0.473), tot_loss_proj:3.102 [t=0.23s]
prediction: ['[CLS] barely will seen to that especially better on cable considering its advantage considering especially [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.325 (perp=8.862, rec=0.081, cos=0.472), tot_loss_proj:3.068 [t=0.23s]
prediction: ['[CLS] barely will seen that especially to better on cable considering its advantage considering especially [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.254 (perp=8.520, rec=0.076, cos=0.473), tot_loss_proj:2.951 [t=0.23s]
prediction: ['[CLS] barely will that seen especially to better on cable considering its advantage be especially [SEP]']
[ 600/2000] tot_loss=2.246 (perp=8.520, rec=0.068, cos=0.474), tot_loss_proj:2.956 [t=0.23s]
prediction: ['[CLS] barely will that seen especially to better on cable considering its advantage be especially [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.137 (perp=7.986, rec=0.068, cos=0.472), tot_loss_proj:2.714 [t=0.23s]
prediction: ['[CLS] barely will that seen especially to better be on cable considering its advantage considering [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.197 (perp=7.907, rec=0.154, cos=0.462), tot_loss_proj:2.810 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable especially considering its advantage particularly [SEP]']
[ 750/2000] tot_loss=2.149 (perp=7.907, rec=0.095, cos=0.472), tot_loss_proj:2.821 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable especially considering its advantage particularly [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.143 (perp=7.907, rec=0.088, cos=0.474), tot_loss_proj:2.829 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable especially considering its advantage particularly [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.131 (perp=7.907, rec=0.076, cos=0.474), tot_loss_proj:2.825 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable especially considering its advantage particularly [SEP]']
[ 900/2000] tot_loss=2.133 (perp=7.907, rec=0.078, cos=0.473), tot_loss_proj:2.823 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable especially considering its advantage particularly [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.097 (perp=7.737, rec=0.079, cos=0.471), tot_loss_proj:2.690 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable especially particularly considering its advantage [SEP]']
Attempt swap
[1000/2000] tot_loss=2.099 (perp=7.737, rec=0.080, cos=0.472), tot_loss_proj:2.686 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable especially particularly considering its advantage [SEP]']
[1050/2000] tot_loss=2.083 (perp=7.737, rec=0.063, cos=0.472), tot_loss_proj:2.690 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable especially particularly considering its advantage [SEP]']
Attempt swap
[1100/2000] tot_loss=2.081 (perp=7.737, rec=0.061, cos=0.472), tot_loss_proj:2.691 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable especially particularly considering its advantage [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.955 (perp=7.047, rec=0.077, cos=0.469), tot_loss_proj:2.541 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable especially considering its advantage, [SEP]']
[1200/2000] tot_loss=1.952 (perp=7.047, rec=0.070, cos=0.472), tot_loss_proj:2.544 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable especially considering its advantage, [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.912 (perp=6.856, rec=0.070, cos=0.471), tot_loss_proj:2.496 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
Attempt swap
[1300/2000] tot_loss=1.909 (perp=6.856, rec=0.066, cos=0.471), tot_loss_proj:2.492 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
[1350/2000] tot_loss=1.909 (perp=6.856, rec=0.066, cos=0.472), tot_loss_proj:2.496 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
Attempt swap
[1400/2000] tot_loss=1.914 (perp=6.856, rec=0.071, cos=0.472), tot_loss_proj:2.492 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
Attempt swap
[1450/2000] tot_loss=1.920 (perp=6.856, rec=0.077, cos=0.472), tot_loss_proj:2.495 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
[1500/2000] tot_loss=1.913 (perp=6.856, rec=0.069, cos=0.472), tot_loss_proj:2.491 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
Attempt swap
[1550/2000] tot_loss=1.923 (perp=6.856, rec=0.079, cos=0.473), tot_loss_proj:2.493 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
Attempt swap
[1600/2000] tot_loss=1.914 (perp=6.856, rec=0.070, cos=0.473), tot_loss_proj:2.493 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
[1650/2000] tot_loss=1.915 (perp=6.856, rec=0.070, cos=0.473), tot_loss_proj:2.492 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
Attempt swap
[1700/2000] tot_loss=1.916 (perp=6.856, rec=0.072, cos=0.473), tot_loss_proj:2.492 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
Attempt swap
[1750/2000] tot_loss=1.906 (perp=6.856, rec=0.061, cos=0.473), tot_loss_proj:2.495 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
[1800/2000] tot_loss=1.906 (perp=6.856, rec=0.061, cos=0.473), tot_loss_proj:2.491 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
Attempt swap
[1850/2000] tot_loss=1.918 (perp=6.856, rec=0.074, cos=0.473), tot_loss_proj:2.498 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
Attempt swap
[1900/2000] tot_loss=1.913 (perp=6.856, rec=0.068, cos=0.473), tot_loss_proj:2.503 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
[1950/2000] tot_loss=1.917 (perp=6.856, rec=0.073, cos=0.473), tot_loss_proj:2.491 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
Attempt swap
[2000/2000] tot_loss=1.921 (perp=6.856, rec=0.077, cos=0.473), tot_loss_proj:2.489 [t=0.23s]
prediction: ['[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] barely will that seen to better be on cable advantage, especially considering its [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 35.714 | p: 35.714 | r: 35.714
rougeL     | fm: 73.333 | p: 73.333 | r: 73.333
rougeLsum  | fm: 73.333 | p: 73.333 | r: 73.333
r1fm+r2fm = 135.714

[Aggregate metrics]:
rouge1     | fm: 96.948 | p: 96.279 | r: 97.692
rouge2     | fm: 56.617 | p: 56.593 | r: 56.669
rougeL     | fm: 80.148 | p: 79.858 | r: 80.507
rougeLsum  | fm: 80.169 | p: 79.812 | r: 80.489
r1fm+r2fm = 153.566

input #12 time: 0:09:05 | total time: 1:58:27


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.734830243866806
highest_index [0]
highest [0.734830243866806]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.6958281397819519 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.686843752861023 for ['[CLS] baccalaureate, black saunderstec armed much [SEP]']
[Init] best rec loss: 0.6854147911071777 for ['[CLS] todd travel time mountain relation territorial same [SEP]']
[Init] best perm rec loss: 0.6850257515907288 for ['[CLS] mountain same time travel relation todd territorial [SEP]']
[Init] best perm rec loss: 0.6823805570602417 for ['[CLS] same travel time relation todd territorial mountain [SEP]']
[Init] best perm rec loss: 0.6822679042816162 for ['[CLS] same todd relation territorial travel mountain time [SEP]']
[Init] best perm rec loss: 0.680181622505188 for ['[CLS] territorial same travel todd mountain time relation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.944 (perp=11.179, rec=0.258, cos=0.450), tot_loss_proj:3.806 [t=0.22s]
prediction: ['[CLS] point into picking things flame flame effects [SEP]']
[ 100/2000] tot_loss=2.649 (perp=10.300, rec=0.132, cos=0.457), tot_loss_proj:3.572 [t=0.22s]
prediction: ['[CLS] point into at things flame flame things [SEP]']
[ 150/2000] tot_loss=2.687 (perp=10.712, rec=0.090, cos=0.455), tot_loss_proj:3.257 [t=0.22s]
prediction: ['[CLS] point that at things explode flame things [SEP]']
[ 200/2000] tot_loss=2.683 (perp=10.712, rec=0.088, cos=0.453), tot_loss_proj:3.252 [t=0.22s]
prediction: ['[CLS] point that at things explode flame things [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.202 (perp=8.251, rec=0.105, cos=0.447), tot_loss_proj:2.765 [t=0.22s]
prediction: ['[CLS] at that point things explode flame things [SEP]']
[ 300/2000] tot_loss=2.195 (perp=8.251, rec=0.090, cos=0.456), tot_loss_proj:2.764 [t=0.22s]
prediction: ['[CLS] at that point things explode flame things [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.033 (perp=7.468, rec=0.081, cos=0.458), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] at that point things explode things flame [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.025 (perp=7.468, rec=0.072, cos=0.459), tot_loss_proj:2.595 [t=0.22s]
prediction: ['[CLS] at that point things explode things flame [SEP]']
[ 450/2000] tot_loss=2.205 (perp=8.405, rec=0.066, cos=0.458), tot_loss_proj:2.749 [t=0.22s]
prediction: ['[CLS] at that point into explode things flame [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.923 (perp=6.978, rec=0.070, cos=0.457), tot_loss_proj:2.254 [t=0.22s]
prediction: ['[CLS] at that point explode things into flame [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.812 (perp=6.423, rec=0.069, cos=0.458), tot_loss_proj:2.184 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 600/2000] tot_loss=1.816 (perp=6.423, rec=0.072, cos=0.459), tot_loss_proj:2.186 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.808 (perp=6.423, rec=0.064, cos=0.459), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.803 (perp=6.423, rec=0.059, cos=0.460), tot_loss_proj:2.182 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 750/2000] tot_loss=1.809 (perp=6.423, rec=0.065, cos=0.459), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.798 (perp=6.423, rec=0.055, cos=0.458), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.802 (perp=6.423, rec=0.058, cos=0.459), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 900/2000] tot_loss=1.805 (perp=6.423, rec=0.061, cos=0.459), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.810 (perp=6.423, rec=0.066, cos=0.460), tot_loss_proj:2.182 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.807 (perp=6.423, rec=0.063, cos=0.460), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1050/2000] tot_loss=1.802 (perp=6.423, rec=0.058, cos=0.460), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.801 (perp=6.423, rec=0.057, cos=0.460), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.806 (perp=6.423, rec=0.062, cos=0.459), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1200/2000] tot_loss=1.812 (perp=6.423, rec=0.068, cos=0.459), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.807 (perp=6.423, rec=0.063, cos=0.460), tot_loss_proj:2.186 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.812 (perp=6.423, rec=0.067, cos=0.460), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1350/2000] tot_loss=1.803 (perp=6.423, rec=0.059, cos=0.460), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.804 (perp=6.423, rec=0.060, cos=0.460), tot_loss_proj:2.182 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.820 (perp=6.423, rec=0.075, cos=0.460), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1500/2000] tot_loss=1.804 (perp=6.423, rec=0.060, cos=0.460), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.810 (perp=6.423, rec=0.066, cos=0.460), tot_loss_proj:2.183 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.803 (perp=6.423, rec=0.059, cos=0.460), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1650/2000] tot_loss=1.804 (perp=6.423, rec=0.060, cos=0.460), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.808 (perp=6.423, rec=0.064, cos=0.460), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.806 (perp=6.423, rec=0.061, cos=0.460), tot_loss_proj:2.183 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1800/2000] tot_loss=1.803 (perp=6.423, rec=0.058, cos=0.460), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.806 (perp=6.423, rec=0.061, cos=0.460), tot_loss_proj:2.182 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.807 (perp=6.423, rec=0.063, cos=0.460), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1950/2000] tot_loss=1.805 (perp=6.423, rec=0.060, cos=0.460), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.804 (perp=6.423, rec=0.059, cos=0.460), tot_loss_proj:2.182 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] at that point things explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 97.166 | p: 96.545 | r: 97.857
rouge2     | fm: 55.693 | p: 55.655 | r: 55.796
rougeL     | fm: 79.849 | p: 79.578 | r: 80.249
rougeLsum  | fm: 80.084 | p: 79.786 | r: 80.441
r1fm+r2fm = 152.859

input #13 time: 0:08:44 | total time: 2:07:11


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.7294556529732557
highest_index [0]
highest [0.7294556529732557]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9948477745056152 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9839287400245667 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9830724596977234 for ['[CLS] junior touching itpton ; [SEP]']
[Init] best rec loss: 0.9718397259712219 for ['[CLS] green stepped one battle rear [SEP]']
[Init] best rec loss: 0.9625152945518494 for ['[CLS] gps war break stream carriage [SEP]']
[Init] best rec loss: 0.9573985934257507 for ['[CLS] female pants hard surely olympics [SEP]']
[Init] best rec loss: 0.9551364779472351 for ['[CLS]pace chicago is thrust youth [SEP]']
[Init] best rec loss: 0.94759601354599 for ['[CLS] baton channel along presided corners [SEP]']
[Init] best rec loss: 0.9366483092308044 for ['[CLS] strategy sigh hk automatically county [SEP]']
[Init] best rec loss: 0.9336529970169067 for ['[CLS] dirtig directionseous dealer [SEP]']
[Init] best perm rec loss: 0.9334371089935303 for ['[CLS]eous dealer dirt directionsig [SEP]']
[Init] best perm rec loss: 0.9331071376800537 for ['[CLS]eousig dirt directions dealer [SEP]']
[Init] best perm rec loss: 0.931281328201294 for ['[CLS]ig directions dirt dealereous [SEP]']
[Init] best perm rec loss: 0.9305227994918823 for ['[CLS]eousig dirt dealer directions [SEP]']
[Init] best perm rec loss: 0.9300140738487244 for ['[CLS]eous dirt dealer directionsig [SEP]']
[Init] best perm rec loss: 0.9297037124633789 for ['[CLS] dealerig directionseous dirt [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.768 (perp=12.186, rec=0.678, cos=0.654), tot_loss_proj:4.354 [t=0.22s]
prediction: ['[CLS] ruthxioussive shooting civilizations [SEP]']
[ 100/2000] tot_loss=3.878 (perp=13.896, rec=0.629, cos=0.470), tot_loss_proj:4.583 [t=0.22s]
prediction: ['[CLS] messed boulderbly enemies inevitable [SEP]']
[ 150/2000] tot_loss=4.158 (perp=15.742, rec=0.557, cos=0.453), tot_loss_proj:5.039 [t=0.22s]
prediction: ['[CLS]ciency izzybly scandal gossip [SEP]']
[ 200/2000] tot_loss=3.860 (perp=14.250, rec=0.530, cos=0.480), tot_loss_proj:4.814 [t=0.22s]
prediction: ['[CLS] yeah inscriptionsbly scandal gossip [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.533 (perp=12.613, rec=0.548, cos=0.462), tot_loss_proj:4.409 [t=0.22s]
prediction: ['[CLS] inscriptionsganjbly scandal movie [SEP]']
[ 300/2000] tot_loss=3.595 (perp=12.862, rec=0.551, cos=0.472), tot_loss_proj:4.468 [t=0.22s]
prediction: ['[CLS] inscriptionsganjbly scandal gossip [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.587 (perp=13.009, rec=0.508, cos=0.478), tot_loss_proj:4.455 [t=0.22s]
prediction: ['[CLS] inscriptions scandalblyganj movie [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.377 (perp=12.023, rec=0.500, cos=0.472), tot_loss_proj:4.192 [t=0.22s]
prediction: ['[CLS] inscriptions scandalbly movie intriguing [SEP]']
[ 450/2000] tot_loss=3.369 (perp=12.023, rec=0.485, cos=0.479), tot_loss_proj:4.199 [t=0.22s]
prediction: ['[CLS] inscriptions scandalbly movie intriguing [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.233 (perp=11.428, rec=0.488, cos=0.459), tot_loss_proj:4.006 [t=0.22s]
prediction: ['[CLS] inscriptions scandal filmbly intriguing [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.833 (perp=13.695, rec=0.589, cos=0.505), tot_loss_proj:4.601 [t=0.22s]
prediction: ['[CLS] inscriptions scandal hundredblyganj [SEP]']
[ 600/2000] tot_loss=3.286 (perp=11.690, rec=0.484, cos=0.465), tot_loss_proj:4.346 [t=0.22s]
prediction: ['[CLS] damn scandal filmbly quite [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.271 (perp=11.690, rec=0.470, cos=0.463), tot_loss_proj:4.341 [t=0.22s]
prediction: ['[CLS] damn scandal filmbly quite [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.225 (perp=11.439, rec=0.469, cos=0.468), tot_loss_proj:3.736 [t=0.22s]
prediction: ['[CLS] damn scandal film intriguing intriguing [SEP]']
[ 750/2000] tot_loss=3.433 (perp=12.549, rec=0.462, cos=0.462), tot_loss_proj:3.976 [t=0.22s]
prediction: ['[CLS] allegro scandal film intriguing intriguing [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.279 (perp=11.791, rec=0.469, cos=0.452), tot_loss_proj:3.882 [t=0.22s]
prediction: ['[CLS] allegro film scandal intriguing intriguing [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.277 (perp=11.791, rec=0.453, cos=0.466), tot_loss_proj:3.876 [t=0.22s]
prediction: ['[CLS] allegro film scandal intriguing intriguing [SEP]']
[ 900/2000] tot_loss=3.273 (perp=11.791, rec=0.455, cos=0.460), tot_loss_proj:3.878 [t=0.22s]
prediction: ['[CLS] allegro film scandal intriguing intriguing [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.269 (perp=11.791, rec=0.452, cos=0.459), tot_loss_proj:3.882 [t=0.22s]
prediction: ['[CLS] allegro film scandal intriguing intriguing [SEP]']
Attempt swap
[1000/2000] tot_loss=3.274 (perp=11.791, rec=0.454, cos=0.462), tot_loss_proj:3.879 [t=0.22s]
prediction: ['[CLS] allegro film scandal intriguing intriguing [SEP]']
[1050/2000] tot_loss=3.261 (perp=11.791, rec=0.449, cos=0.454), tot_loss_proj:3.882 [t=0.22s]
prediction: ['[CLS] allegro film scandal intriguing intriguing [SEP]']
Attempt swap
[1100/2000] tot_loss=3.272 (perp=11.791, rec=0.455, cos=0.458), tot_loss_proj:3.878 [t=0.22s]
prediction: ['[CLS] allegro film scandal intriguing intriguing [SEP]']
Attempt swap
[1150/2000] tot_loss=3.268 (perp=11.791, rec=0.444, cos=0.466), tot_loss_proj:3.878 [t=0.22s]
prediction: ['[CLS] allegro film scandal intriguing intriguing [SEP]']
[1200/2000] tot_loss=3.263 (perp=11.791, rec=0.447, cos=0.458), tot_loss_proj:3.879 [t=0.22s]
prediction: ['[CLS] allegro film scandal intriguing intriguing [SEP]']
Attempt swap
[1250/2000] tot_loss=3.264 (perp=11.791, rec=0.441, cos=0.465), tot_loss_proj:3.880 [t=0.22s]
prediction: ['[CLS] allegro film scandal intriguing intriguing [SEP]']
Attempt swap
[1300/2000] tot_loss=3.220 (perp=11.598, rec=0.440, cos=0.460), tot_loss_proj:3.913 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
[1350/2000] tot_loss=3.239 (perp=11.598, rec=0.448, cos=0.472), tot_loss_proj:3.910 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
Attempt swap
[1400/2000] tot_loss=3.229 (perp=11.598, rec=0.445, cos=0.465), tot_loss_proj:3.903 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
Attempt swap
[1450/2000] tot_loss=3.225 (perp=11.598, rec=0.443, cos=0.463), tot_loss_proj:3.910 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
[1500/2000] tot_loss=3.229 (perp=11.598, rec=0.440, cos=0.470), tot_loss_proj:3.916 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
Attempt swap
[1550/2000] tot_loss=3.223 (perp=11.598, rec=0.436, cos=0.467), tot_loss_proj:3.909 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
Attempt swap
[1600/2000] tot_loss=3.229 (perp=11.598, rec=0.443, cos=0.466), tot_loss_proj:3.912 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
[1650/2000] tot_loss=3.227 (perp=11.598, rec=0.442, cos=0.466), tot_loss_proj:3.908 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
Attempt swap
[1700/2000] tot_loss=3.229 (perp=11.598, rec=0.445, cos=0.465), tot_loss_proj:3.911 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
Attempt swap
[1750/2000] tot_loss=3.230 (perp=11.598, rec=0.442, cos=0.468), tot_loss_proj:3.905 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
[1800/2000] tot_loss=3.229 (perp=11.598, rec=0.446, cos=0.464), tot_loss_proj:3.909 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
Attempt swap
[1850/2000] tot_loss=3.228 (perp=11.598, rec=0.442, cos=0.466), tot_loss_proj:3.904 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
Attempt swap
[1900/2000] tot_loss=3.221 (perp=11.598, rec=0.436, cos=0.466), tot_loss_proj:3.915 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
[1950/2000] tot_loss=3.227 (perp=11.598, rec=0.441, cos=0.467), tot_loss_proj:3.911 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
Attempt swap
[2000/2000] tot_loss=3.225 (perp=11.598, rec=0.439, cos=0.467), tot_loss_proj:3.914 [t=0.22s]
prediction: ['[CLS] lumpur film scandal intriguing intriguing [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] lumpur film scandal intriguing intriguing [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 57.143 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 42.857 | r: 60.000
rougeLsum  | fm: 50.000 | p: 42.857 | r: 60.000
r1fm+r2fm = 66.667

[Aggregate metrics]:
rouge1     | fm: 95.068 | p: 93.911 | r: 96.365
rouge2     | fm: 51.527 | p: 51.492 | r: 51.583
rougeL     | fm: 78.000 | p: 77.219 | r: 78.929
rougeLsum  | fm: 77.925 | p: 77.219 | r: 78.988
r1fm+r2fm = 146.595

input #14 time: 0:08:43 | total time: 2:15:55


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.7259139441884117
highest_index [0]
highest [0.7259139441884117]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.8389694690704346 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.8370556235313416 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 0.8345770239830017 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.8207155466079712 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8118009567260742 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.806207001209259 for ['[CLS] massachusetts stomach qui beverlyrangle fleet strong driven [SEP]']
[Init] best perm rec loss: 0.8058164119720459 for ['[CLS]rangle qui strong fleet massachusetts beverly stomach driven [SEP]']
[Init] best perm rec loss: 0.8056505918502808 for ['[CLS] qui beverly strong drivenrangle fleet stomach massachusetts [SEP]']
[Init] best perm rec loss: 0.8053082823753357 for ['[CLS]rangle fleet stomach massachusetts beverly driven qui strong [SEP]']
[Init] best perm rec loss: 0.8038537502288818 for ['[CLS] beverlyrangle fleet stomach massachusetts strong qui driven [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.913 (perp=10.938, rec=0.253, cos=0.472), tot_loss_proj:3.370 [t=0.23s]
prediction: ['[CLS] efficient, efficient robinably truly icyable [SEP]']
[ 100/2000] tot_loss=3.106 (perp=12.193, rec=0.195, cos=0.472), tot_loss_proj:3.406 [t=0.23s]
prediction: ['[CLS] efficient, efficient chillablyably suit chill [SEP]']
[ 150/2000] tot_loss=2.548 (perp=9.639, rec=0.153, cos=0.467), tot_loss_proj:2.964 [t=0.23s]
prediction: ['[CLS] efficient, efficient chillerably anonymouser [SEP]']
[ 200/2000] tot_loss=2.531 (perp=9.639, rec=0.132, cos=0.470), tot_loss_proj:2.966 [t=0.23s]
prediction: ['[CLS] efficient, efficient chillerably anonymouser [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.219 (perp=8.093, rec=0.133, cos=0.467), tot_loss_proj:2.579 [t=0.23s]
prediction: ['[CLS] efficient, efficient chillerably anonymous. [SEP]']
[ 300/2000] tot_loss=2.205 (perp=8.093, rec=0.114, cos=0.473), tot_loss_proj:2.571 [t=0.23s]
prediction: ['[CLS] efficient, efficient chillerably anonymous. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.143 (perp=7.781, rec=0.115, cos=0.472), tot_loss_proj:2.553 [t=0.23s]
prediction: ['[CLS] efficient,ably efficient chiller anonymous. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.035 (perp=7.333, rec=0.097, cos=0.472), tot_loss_proj:2.306 [t=0.23s]
prediction: ['[CLS] efficient,ably efficient anonymous chiller. [SEP]']
[ 450/2000] tot_loss=2.038 (perp=7.333, rec=0.100, cos=0.472), tot_loss_proj:2.307 [t=0.23s]
prediction: ['[CLS] efficient,ably efficient anonymous chiller. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.978 (perp=7.048, rec=0.097, cos=0.471), tot_loss_proj:2.186 [t=0.23s]
prediction: ['[CLS]ably efficient, efficient anonymous chiller. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.347 (perp=8.915, rec=0.091, cos=0.473), tot_loss_proj:2.713 [t=0.23s]
prediction: ['[CLS] suit efficient,ably anonymous chiller. [SEP]']
[ 600/2000] tot_loss=2.351 (perp=8.915, rec=0.096, cos=0.473), tot_loss_proj:2.698 [t=0.23s]
prediction: ['[CLS] suit efficient,ably anonymous chiller. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.878 (perp=6.615, rec=0.082, cos=0.473), tot_loss_proj:1.881 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.863 (perp=6.615, rec=0.067, cos=0.473), tot_loss_proj:1.888 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.865 (perp=6.615, rec=0.070, cos=0.473), tot_loss_proj:1.876 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.865 (perp=6.615, rec=0.069, cos=0.473), tot_loss_proj:1.879 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.863 (perp=6.615, rec=0.068, cos=0.473), tot_loss_proj:1.888 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.853 (perp=6.615, rec=0.057, cos=0.473), tot_loss_proj:1.875 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.863 (perp=6.615, rec=0.068, cos=0.473), tot_loss_proj:1.876 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.858 (perp=6.615, rec=0.062, cos=0.473), tot_loss_proj:1.875 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.868 (perp=6.615, rec=0.073, cos=0.473), tot_loss_proj:1.877 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.862 (perp=6.615, rec=0.066, cos=0.473), tot_loss_proj:1.882 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.865 (perp=6.615, rec=0.069, cos=0.473), tot_loss_proj:1.874 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.865 (perp=6.615, rec=0.069, cos=0.473), tot_loss_proj:1.875 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.858 (perp=6.615, rec=0.062, cos=0.473), tot_loss_proj:1.877 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.853 (perp=6.615, rec=0.057, cos=0.473), tot_loss_proj:1.880 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.860 (perp=6.615, rec=0.064, cos=0.473), tot_loss_proj:1.881 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.856 (perp=6.615, rec=0.060, cos=0.473), tot_loss_proj:1.872 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.853 (perp=6.615, rec=0.057, cos=0.473), tot_loss_proj:1.887 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.853 (perp=6.615, rec=0.058, cos=0.473), tot_loss_proj:1.886 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.859 (perp=6.615, rec=0.063, cos=0.473), tot_loss_proj:1.875 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.857 (perp=6.615, rec=0.061, cos=0.473), tot_loss_proj:1.885 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.858 (perp=6.615, rec=0.062, cos=0.473), tot_loss_proj:1.878 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.864 (perp=6.615, rec=0.068, cos=0.473), tot_loss_proj:1.882 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.864 (perp=6.615, rec=0.068, cos=0.473), tot_loss_proj:1.884 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.851 (perp=6.615, rec=0.055, cos=0.473), tot_loss_proj:1.882 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.854 (perp=6.615, rec=0.058, cos=0.473), tot_loss_proj:1.877 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.860 (perp=6.615, rec=0.065, cos=0.473), tot_loss_proj:1.872 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.860 (perp=6.615, rec=0.064, cos=0.473), tot_loss_proj:1.880 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.851 (perp=6.615, rec=0.055, cos=0.473), tot_loss_proj:1.877 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.376 | p: 94.291 | r: 96.652
rouge2     | fm: 55.126 | p: 55.089 | r: 55.173
rougeL     | fm: 79.159 | p: 78.498 | r: 80.058
rougeLsum  | fm: 79.422 | p: 78.695 | r: 80.301
r1fm+r2fm = 150.502

input #15 time: 0:09:08 | total time: 2:25:03


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.7410978931178909
highest_index [0]
highest [0.7410978931178909]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 0.8479162454605103 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.8330228328704834 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.8294320702552795 for ['[CLS]sa base slave shadow irvingdale [SEP]']
[Init] best rec loss: 0.8270257115364075 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best rec loss: 0.7884263396263123 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 0.7791051268577576 for ['[CLS] south jefferson late guy e sophia [SEP]']
[Init] best rec loss: 0.7461869716644287 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 0.7385607957839966 for ['[CLS] a clubs slayer trophy affected residents [SEP]']
[Init] best rec loss: 0.7202590107917786 for ['[CLS]worthy eat town normal court earth [SEP]']
[Init] best perm rec loss: 0.7199490666389465 for ['[CLS] town court normal earth eatworthy [SEP]']
[Init] best perm rec loss: 0.719208836555481 for ['[CLS] earth normal eat townworthy court [SEP]']
[Init] best perm rec loss: 0.7180941104888916 for ['[CLS] court earth normalworthy town eat [SEP]']
[Init] best perm rec loss: 0.7176565527915955 for ['[CLS] courtworthy town normal eat earth [SEP]']
[Init] best perm rec loss: 0.7172620296478271 for ['[CLS] eatworthy court normal town earth [SEP]']
[Init] best perm rec loss: 0.7168793082237244 for ['[CLS] earth normal town eat courtworthy [SEP]']
[Init] best perm rec loss: 0.7165811657905579 for ['[CLS] court earth eatworthy town normal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.936 (perp=6.225, rec=0.250, cos=0.441), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] all these more, this more [SEP]']
[ 100/2000] tot_loss=2.152 (perp=7.776, rec=0.155, cos=0.442), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] all of more, this this [SEP]']
[ 150/2000] tot_loss=2.053 (perp=7.577, rec=0.090, cos=0.447), tot_loss_proj:2.513 [t=0.22s]
prediction: ['[CLS] all of more and this this [SEP]']
[ 200/2000] tot_loss=2.077 (perp=7.732, rec=0.083, cos=0.448), tot_loss_proj:2.529 [t=0.22s]
prediction: ['[CLS] all of more and and this [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.706 (perp=5.918, rec=0.084, cos=0.439), tot_loss_proj:1.907 [t=0.22s]
prediction: ['[CLS] all of this and and more [SEP]']
[ 300/2000] tot_loss=1.710 (perp=5.918, rec=0.078, cos=0.449), tot_loss_proj:1.900 [t=0.22s]
prediction: ['[CLS] all of this and and more [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.550 (perp=5.201, rec=0.062, cos=0.447), tot_loss_proj:1.840 [t=0.22s]
prediction: ['[CLS] and all of this, more [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.454 (perp=4.697, rec=0.065, cos=0.450), tot_loss_proj:1.480 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 450/2000] tot_loss=1.452 (perp=4.697, rec=0.064, cos=0.449), tot_loss_proj:1.495 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.448 (perp=4.697, rec=0.058, cos=0.450), tot_loss_proj:1.491 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.452 (perp=4.697, rec=0.063, cos=0.450), tot_loss_proj:1.483 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 600/2000] tot_loss=1.449 (perp=4.697, rec=0.060, cos=0.450), tot_loss_proj:1.489 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.446 (perp=4.697, rec=0.056, cos=0.450), tot_loss_proj:1.484 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.455 (perp=4.697, rec=0.065, cos=0.450), tot_loss_proj:1.487 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=1.444 (perp=4.697, rec=0.055, cos=0.450), tot_loss_proj:1.484 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.452 (perp=4.697, rec=0.062, cos=0.450), tot_loss_proj:1.497 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.449 (perp=4.697, rec=0.059, cos=0.451), tot_loss_proj:1.497 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.450 (perp=4.697, rec=0.060, cos=0.451), tot_loss_proj:1.489 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.456 (perp=4.697, rec=0.066, cos=0.451), tot_loss_proj:1.490 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.457 (perp=4.697, rec=0.067, cos=0.451), tot_loss_proj:1.485 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.447 (perp=4.697, rec=0.057, cos=0.450), tot_loss_proj:1.494 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.442 (perp=4.697, rec=0.053, cos=0.450), tot_loss_proj:1.479 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.447 (perp=4.697, rec=0.057, cos=0.450), tot_loss_proj:1.483 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.438 (perp=4.697, rec=0.048, cos=0.450), tot_loss_proj:1.487 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.456 (perp=4.697, rec=0.066, cos=0.450), tot_loss_proj:1.482 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.450 (perp=4.697, rec=0.060, cos=0.451), tot_loss_proj:1.489 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.453 (perp=4.697, rec=0.062, cos=0.451), tot_loss_proj:1.480 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.446 (perp=4.697, rec=0.056, cos=0.451), tot_loss_proj:1.492 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.448 (perp=4.697, rec=0.058, cos=0.451), tot_loss_proj:1.482 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.453 (perp=4.697, rec=0.064, cos=0.450), tot_loss_proj:1.490 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.446 (perp=4.697, rec=0.055, cos=0.451), tot_loss_proj:1.484 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.439 (perp=4.697, rec=0.048, cos=0.451), tot_loss_proj:1.492 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.454 (perp=4.697, rec=0.064, cos=0.451), tot_loss_proj:1.483 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.450 (perp=4.697, rec=0.060, cos=0.450), tot_loss_proj:1.489 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.445 (perp=4.697, rec=0.055, cos=0.450), tot_loss_proj:1.492 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=1.454 (perp=4.697, rec=0.065, cos=0.450), tot_loss_proj:1.484 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.455 (perp=4.697, rec=0.065, cos=0.451), tot_loss_proj:1.487 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.450 (perp=4.697, rec=0.060, cos=0.451), tot_loss_proj:1.488 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.444 (perp=4.697, rec=0.054, cos=0.451), tot_loss_proj:1.495 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.439 (perp=4.697, rec=0.049, cos=0.451), tot_loss_proj:1.481 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.670 | p: 94.754 | r: 96.793
rouge2     | fm: 57.784 | p: 57.710 | r: 57.867
rougeL     | fm: 80.697 | p: 80.035 | r: 81.665
rougeLsum  | fm: 80.543 | p: 79.791 | r: 81.473
r1fm+r2fm = 153.454

input #16 time: 0:08:42 | total time: 2:33:46


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.7164040627967024
highest_index [0]
highest [0.7164040627967024]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.81003338098526 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.7950275540351868 for ['[CLS] angle bond masonacle cabinachejord right is kiel woman [SEP]']
[Init] best rec loss: 0.7896469235420227 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.7808866500854492 for ['[CLS] staretha jack nur stone lied pointsmori richie sienna foot [SEP]']
[Init] best rec loss: 0.7768609523773193 for ['[CLS] forecast yeast jewels young food filed paralyzedggio easy thing beau [SEP]']
[Init] best rec loss: 0.7729039788246155 for ['[CLS] simply aero thomas orientponane mona usual surface matrix sebastian [SEP]']
[Init] best rec loss: 0.7648005485534668 for ['[CLS] wild filing curls wandabuck day victor which judicial coach peyton [SEP]']
[Init] best perm rec loss: 0.7646177411079407 for ['[CLS] wanda curls wild day peyton victor filingbuck coach which judicial [SEP]']
[Init] best perm rec loss: 0.7645586133003235 for ['[CLS] wanda coach wild day curls victor filing which judicial peytonbuck [SEP]']
[Init] best perm rec loss: 0.7638397812843323 for ['[CLS] victor curls coach wild filing peyton day which judicialbuck wanda [SEP]']
[Init] best perm rec loss: 0.7630332112312317 for ['[CLS] coach daybuck wanda victor filing peyton curls wild judicial which [SEP]']
[Init] best perm rec loss: 0.7624528408050537 for ['[CLS] coach peyton victor day curlsbuck which judicial wanda filing wild [SEP]']
[Init] best perm rec loss: 0.761989414691925 for ['[CLS] victor coach filing wanda day curls peyton which judicial wildbuck [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.646 (perp=13.912, rec=0.386, cos=0.478), tot_loss_proj:4.329 [t=0.22s]
prediction: ['[CLS] high rihannaed too meade nh ec what hollywood power odd [SEP]']
[ 100/2000] tot_loss=3.065 (perp=11.784, rec=0.245, cos=0.463), tot_loss_proj:3.880 [t=0.22s]
prediction: ['[CLS] much want much too think too period think kannada what ic [SEP]']
[ 150/2000] tot_loss=2.540 (perp=9.709, rec=0.118, cos=0.480), tot_loss_proj:3.297 [t=0.22s]
prediction: ['[CLS] much want much too think too about about as what something [SEP]']
[ 200/2000] tot_loss=2.400 (perp=9.111, rec=0.092, cos=0.485), tot_loss_proj:3.107 [t=0.22s]
prediction: ['[CLS] much want to too think too about about as what something [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.133 (perp=7.765, rec=0.101, cos=0.478), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] too much want to think too on about seems what something [SEP]']
[ 300/2000] tot_loss=1.915 (perp=6.729, rec=0.086, cos=0.483), tot_loss_proj:2.580 [t=0.22s]
prediction: ["[CLS] to much want to think too on about'what is [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=1.897 (perp=6.665, rec=0.082, cos=0.481), tot_loss_proj:2.652 [t=0.22s]
prediction: ['[CLS] to much want to think too about is what is on [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.007 (perp=7.144, rec=0.095, cos=0.483), tot_loss_proj:3.122 [t=0.22s]
prediction: ['[CLS] to much want s to think too about what going on [SEP]']
[ 450/2000] tot_loss=1.993 (perp=7.144, rec=0.081, cos=0.484), tot_loss_proj:3.128 [t=0.22s]
prediction: ['[CLS] to much want s to think too about what going on [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.705 (perp=5.681, rec=0.087, cos=0.482), tot_loss_proj:2.255 [t=0.22s]
prediction: ['[CLS] to much want to think too about what s going on [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.476 (perp=4.520, rec=0.088, cos=0.484), tot_loss_proj:1.693 [t=0.22s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
[ 600/2000] tot_loss=1.727 (perp=5.794, rec=0.084, cos=0.484), tot_loss_proj:2.070 [t=0.22s]
prediction: ['[CLS] to want s think too much about what s going on [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.581 (perp=5.164, rec=0.065, cos=0.483), tot_loss_proj:1.923 [t=0.22s]
prediction: ['[CLS] want s to think too much about what s going on [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.485 (perp=4.715, rec=0.062, cos=0.480), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
[ 750/2000] tot_loss=1.493 (perp=4.715, rec=0.066, cos=0.484), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.490 (perp=4.715, rec=0.062, cos=0.485), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.493 (perp=4.715, rec=0.064, cos=0.486), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
[ 900/2000] tot_loss=1.498 (perp=4.715, rec=0.069, cos=0.486), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.502 (perp=4.715, rec=0.073, cos=0.486), tot_loss_proj:1.757 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1000/2000] tot_loss=1.495 (perp=4.715, rec=0.067, cos=0.486), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
[1050/2000] tot_loss=1.505 (perp=4.715, rec=0.076, cos=0.486), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1100/2000] tot_loss=1.490 (perp=4.715, rec=0.061, cos=0.486), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1150/2000] tot_loss=1.490 (perp=4.715, rec=0.060, cos=0.486), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
[1200/2000] tot_loss=1.494 (perp=4.715, rec=0.065, cos=0.486), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1250/2000] tot_loss=1.498 (perp=4.715, rec=0.069, cos=0.486), tot_loss_proj:1.762 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1300/2000] tot_loss=1.502 (perp=4.715, rec=0.073, cos=0.486), tot_loss_proj:1.756 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
[1350/2000] tot_loss=1.499 (perp=4.715, rec=0.070, cos=0.486), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1400/2000] tot_loss=1.489 (perp=4.715, rec=0.060, cos=0.486), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1450/2000] tot_loss=1.506 (perp=4.715, rec=0.076, cos=0.486), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
[1500/2000] tot_loss=1.493 (perp=4.715, rec=0.064, cos=0.486), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1550/2000] tot_loss=1.493 (perp=4.715, rec=0.064, cos=0.486), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1600/2000] tot_loss=1.504 (perp=4.715, rec=0.075, cos=0.486), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
[1650/2000] tot_loss=1.498 (perp=4.715, rec=0.069, cos=0.486), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1700/2000] tot_loss=1.496 (perp=4.715, rec=0.067, cos=0.486), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1750/2000] tot_loss=1.494 (perp=4.715, rec=0.065, cos=0.486), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
[1800/2000] tot_loss=1.498 (perp=4.715, rec=0.069, cos=0.486), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1850/2000] tot_loss=1.499 (perp=4.715, rec=0.070, cos=0.486), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[1900/2000] tot_loss=1.482 (perp=4.715, rec=0.053, cos=0.486), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
[1950/2000] tot_loss=1.497 (perp=4.715, rec=0.067, cos=0.486), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Attempt swap
[2000/2000] tot_loss=1.496 (perp=4.715, rec=0.067, cos=0.486), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] s want to think too much about what s going on [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] s want to think too much about what s going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 86.957 | p: 83.333 | r: 90.909
rougeL     | fm: 96.000 | p: 92.308 | r: 100.000
rougeLsum  | fm: 96.000 | p: 92.308 | r: 100.000
r1fm+r2fm = 182.957

[Aggregate metrics]:
rouge1     | fm: 95.701 | p: 94.594 | r: 96.971
rouge2     | fm: 59.003 | p: 58.800 | r: 59.355
rougeL     | fm: 81.535 | p: 80.762 | r: 82.693
rougeLsum  | fm: 81.501 | p: 80.617 | r: 82.572
r1fm+r2fm = 154.704

input #17 time: 0:08:44 | total time: 2:42:31


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.7420052988055441
highest_index [0]
highest [0.7420052988055441]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9945352077484131 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.908563494682312 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.8864071369171143 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.8699269890785217 for ['[CLS] master asteroidnagar fungi [SEP]']
[Init] best rec loss: 0.8328983187675476 for ['[CLS] alternativelastic garrett filed [SEP]']
[Init] best perm rec loss: 0.8281069993972778 for ['[CLS] garrettlastic alternative filed [SEP]']
[Init] best perm rec loss: 0.8278535008430481 for ['[CLS]lastic alternative garrett filed [SEP]']
[Init] best perm rec loss: 0.8273833990097046 for ['[CLS] garrett filed alternativelastic [SEP]']
[Init] best perm rec loss: 0.8271289467811584 for ['[CLS] alternative garrettlastic filed [SEP]']
[Init] best perm rec loss: 0.8265815377235413 for ['[CLS] garrett alternative filedlastic [SEP]']
[Init] best perm rec loss: 0.8250244855880737 for ['[CLS] garrettlastic filed alternative [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.264 (perp=12.762, rec=0.256, cos=0.455), tot_loss_proj:4.422 [t=0.22s]
prediction: ['[CLS] effectsatinggor becoming [SEP]']
[ 100/2000] tot_loss=2.360 (perp=8.792, rec=0.152, cos=0.449), tot_loss_proj:2.815 [t=0.22s]
prediction: ['[CLS] inatinggorating [SEP]']
[ 150/2000] tot_loss=2.766 (perp=10.916, rec=0.132, cos=0.451), tot_loss_proj:3.610 [t=0.22s]
prediction: ['[CLS]viatinggorating [SEP]']
[ 200/2000] tot_loss=2.735 (perp=10.916, rec=0.103, cos=0.449), tot_loss_proj:3.616 [t=0.22s]
prediction: ['[CLS]viatinggorating [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.867 (perp=11.683, rec=0.083, cos=0.447), tot_loss_proj:4.095 [t=0.22s]
prediction: ['[CLS]atingvigor in [SEP]']
[ 300/2000] tot_loss=2.835 (perp=11.683, rec=0.050, cos=0.449), tot_loss_proj:4.104 [t=0.22s]
prediction: ['[CLS]atingvigor in [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.622 (perp=5.589, rec=0.056, cos=0.449), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.624 (perp=5.589, rec=0.057, cos=0.449), tot_loss_proj:1.621 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.615 (perp=5.589, rec=0.048, cos=0.449), tot_loss_proj:1.631 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.626 (perp=5.589, rec=0.059, cos=0.449), tot_loss_proj:1.615 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.626 (perp=5.589, rec=0.059, cos=0.449), tot_loss_proj:1.633 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.638 (perp=5.589, rec=0.071, cos=0.449), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.637 (perp=5.589, rec=0.070, cos=0.449), tot_loss_proj:1.631 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.631 (perp=5.589, rec=0.063, cos=0.449), tot_loss_proj:1.631 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.619 (perp=5.589, rec=0.052, cos=0.449), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.627 (perp=5.589, rec=0.060, cos=0.449), tot_loss_proj:1.633 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.630 (perp=5.589, rec=0.063, cos=0.449), tot_loss_proj:1.622 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.629 (perp=5.589, rec=0.062, cos=0.449), tot_loss_proj:1.623 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.631 (perp=5.589, rec=0.064, cos=0.449), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.629 (perp=5.589, rec=0.062, cos=0.449), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.617 (perp=5.589, rec=0.050, cos=0.449), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.629 (perp=5.589, rec=0.062, cos=0.449), tot_loss_proj:1.625 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.634 (perp=5.589, rec=0.067, cos=0.449), tot_loss_proj:1.626 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.630 (perp=5.589, rec=0.063, cos=0.449), tot_loss_proj:1.628 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.629 (perp=5.589, rec=0.062, cos=0.449), tot_loss_proj:1.635 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.635 (perp=5.589, rec=0.068, cos=0.449), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.618 (perp=5.589, rec=0.051, cos=0.449), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.630 (perp=5.589, rec=0.063, cos=0.449), tot_loss_proj:1.637 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.640 (perp=5.589, rec=0.073, cos=0.449), tot_loss_proj:1.626 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.628 (perp=5.589, rec=0.061, cos=0.449), tot_loss_proj:1.628 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.639 (perp=5.589, rec=0.072, cos=0.449), tot_loss_proj:1.635 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.619 (perp=5.589, rec=0.052, cos=0.449), tot_loss_proj:1.632 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.631 (perp=5.589, rec=0.064, cos=0.449), tot_loss_proj:1.624 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.636 (perp=5.589, rec=0.069, cos=0.449), tot_loss_proj:1.639 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.633 (perp=5.589, rec=0.066, cos=0.449), tot_loss_proj:1.634 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.626 (perp=5.589, rec=0.059, cos=0.449), tot_loss_proj:1.636 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.632 (perp=5.589, rec=0.065, cos=0.449), tot_loss_proj:1.624 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.618 (perp=5.589, rec=0.051, cos=0.449), tot_loss_proj:1.631 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.625 (perp=5.589, rec=0.058, cos=0.449), tot_loss_proj:1.638 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.627 (perp=5.589, rec=0.060, cos=0.449), tot_loss_proj:1.618 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.898 | p: 94.874 | r: 97.180
rouge2     | fm: 60.930 | p: 60.730 | r: 61.128
rougeL     | fm: 82.515 | p: 81.648 | r: 83.543
rougeLsum  | fm: 82.355 | p: 81.599 | r: 83.454
r1fm+r2fm = 156.829

input #18 time: 0:08:43 | total time: 2:51:14


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.7352838153253611
highest_index [0]
highest [0.7352838153253611]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.731720507144928 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7315755486488342 for ['[CLS] scout pitch huge teaching [SEP]']
[Init] best rec loss: 0.719924807548523 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.712813675403595 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.6756210923194885 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6740750074386597 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6737987399101257 for ['[CLS] reaching pin orderyna [SEP]']
[Init] best perm rec loss: 0.6729663014411926 for ['[CLS] order pinyna reaching [SEP]']
[Init] best perm rec loss: 0.6726018190383911 for ['[CLS] orderyna pin reaching [SEP]']
[Init] best perm rec loss: 0.6723867058753967 for ['[CLS] pinyna reaching order [SEP]']
[Init] best perm rec loss: 0.6721668839454651 for ['[CLS] pinyna order reaching [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.986 (perp=10.622, rec=0.376, cos=0.485), tot_loss_proj:3.489 [t=0.28s]
prediction: ['[CLS]fa infa [SEP] [SEP]']
[ 100/2000] tot_loss=2.774 (perp=10.793, rec=0.159, cos=0.456), tot_loss_proj:3.339 [t=0.22s]
prediction: ['[CLS]fa tofamy [SEP]']
[ 150/2000] tot_loss=1.998 (perp=7.158, rec=0.114, cos=0.452), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS]fa infamy [SEP]']
[ 200/2000] tot_loss=1.980 (perp=7.158, rec=0.090, cos=0.458), tot_loss_proj:2.226 [t=0.22s]
prediction: ['[CLS]fa infamy [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.964 (perp=7.158, rec=0.086, cos=0.447), tot_loss_proj:2.246 [t=0.22s]
prediction: ['[CLS]fa infamy [SEP]']
[ 300/2000] tot_loss=2.766 (perp=11.211, rec=0.066, cos=0.458), tot_loss_proj:3.967 [t=0.22s]
prediction: ['[CLS]fa in inmy [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.751 (perp=6.109, rec=0.072, cos=0.457), tot_loss_proj:1.770 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.759 (perp=6.109, rec=0.079, cos=0.458), tot_loss_proj:1.776 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.743 (perp=6.109, rec=0.062, cos=0.459), tot_loss_proj:1.772 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.734 (perp=6.109, rec=0.053, cos=0.459), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.736 (perp=6.109, rec=0.055, cos=0.459), tot_loss_proj:1.785 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.748 (perp=6.109, rec=0.070, cos=0.456), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.742 (perp=6.109, rec=0.061, cos=0.459), tot_loss_proj:1.766 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.746 (perp=6.109, rec=0.065, cos=0.459), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.737 (perp=6.109, rec=0.056, cos=0.459), tot_loss_proj:1.768 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.734 (perp=6.109, rec=0.054, cos=0.458), tot_loss_proj:1.772 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.749 (perp=6.109, rec=0.068, cos=0.459), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.739 (perp=6.109, rec=0.058, cos=0.459), tot_loss_proj:1.761 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.738 (perp=6.109, rec=0.058, cos=0.459), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.740 (perp=6.109, rec=0.059, cos=0.459), tot_loss_proj:1.773 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.745 (perp=6.109, rec=0.064, cos=0.459), tot_loss_proj:1.769 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.751 (perp=6.109, rec=0.070, cos=0.459), tot_loss_proj:1.766 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.747 (perp=6.109, rec=0.066, cos=0.459), tot_loss_proj:1.757 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.750 (perp=6.109, rec=0.069, cos=0.459), tot_loss_proj:1.771 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.736 (perp=6.109, rec=0.055, cos=0.459), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.742 (perp=6.109, rec=0.062, cos=0.459), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.745 (perp=6.109, rec=0.064, cos=0.459), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.746 (perp=6.109, rec=0.065, cos=0.459), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.746 (perp=6.109, rec=0.065, cos=0.459), tot_loss_proj:1.769 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.742 (perp=6.109, rec=0.061, cos=0.459), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.748 (perp=6.109, rec=0.067, cos=0.459), tot_loss_proj:1.771 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.737 (perp=6.109, rec=0.056, cos=0.459), tot_loss_proj:1.766 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.742 (perp=6.109, rec=0.061, cos=0.459), tot_loss_proj:1.764 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.744 (perp=6.109, rec=0.063, cos=0.459), tot_loss_proj:1.766 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.748 (perp=6.109, rec=0.067, cos=0.459), tot_loss_proj:1.761 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.725 (perp=6.109, rec=0.044, cos=0.459), tot_loss_proj:1.764 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.752 (perp=6.109, rec=0.071, cos=0.459), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.732 (perp=6.109, rec=0.051, cos=0.459), tot_loss_proj:1.762 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.738 (perp=6.109, rec=0.057, cos=0.459), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.743 (perp=6.109, rec=0.062, cos=0.459), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 96.208 | p: 95.238 | r: 97.286
rouge2     | fm: 62.962 | p: 62.839 | r: 63.193
rougeL     | fm: 83.652 | p: 82.786 | r: 84.574
rougeLsum  | fm: 83.475 | p: 82.628 | r: 84.362
r1fm+r2fm = 159.170

input #19 time: 0:08:44 | total time: 2:59:58


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.753813427468063
highest_index [0]
highest [0.753813427468063]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8582407832145691 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.7918488383293152 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 0.7826619744300842 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best rec loss: 0.7801581621170044 for ['[CLS] club provious microphone [SEP]']
[Init] best perm rec loss: 0.7767650485038757 for ['[CLS] pro club microphonevious [SEP]']
[Init] best perm rec loss: 0.7749640345573425 for ['[CLS] microphone pro clubvious [SEP]']
[Init] best perm rec loss: 0.7721051573753357 for ['[CLS] pro microphonevious club [SEP]']
[Init] best perm rec loss: 0.7718209624290466 for ['[CLS] microphonevious pro club [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.609 (perp=9.675, rec=0.273, cos=0.402), tot_loss_proj:3.439 [t=0.22s]
prediction: ['[CLS] whichverse pleasureverse [SEP]']
[ 100/2000] tot_loss=2.742 (perp=11.088, rec=0.106, cos=0.419), tot_loss_proj:3.352 [t=0.22s]
prediction: ['[CLS] per per pleasureverse [SEP]']
[ 150/2000] tot_loss=2.724 (perp=11.088, rec=0.092, cos=0.414), tot_loss_proj:3.317 [t=0.22s]
prediction: ['[CLS] per per pleasureverse [SEP]']
[ 200/2000] tot_loss=2.713 (perp=11.088, rec=0.063, cos=0.432), tot_loss_proj:3.313 [t=0.22s]
prediction: ['[CLS] per per pleasureverse [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.993 (perp=7.535, rec=0.061, cos=0.425), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 300/2000] tot_loss=2.019 (perp=7.535, rec=0.082, cos=0.430), tot_loss_proj:2.367 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.005 (perp=7.535, rec=0.067, cos=0.431), tot_loss_proj:2.367 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.000 (perp=7.535, rec=0.062, cos=0.431), tot_loss_proj:2.366 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 450/2000] tot_loss=2.005 (perp=7.535, rec=0.069, cos=0.429), tot_loss_proj:2.366 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.001 (perp=7.535, rec=0.063, cos=0.431), tot_loss_proj:2.369 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.005 (perp=7.535, rec=0.067, cos=0.431), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 600/2000] tot_loss=2.000 (perp=7.535, rec=0.061, cos=0.432), tot_loss_proj:2.367 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.998 (perp=7.535, rec=0.060, cos=0.431), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.998 (perp=7.535, rec=0.059, cos=0.431), tot_loss_proj:2.363 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 750/2000] tot_loss=1.998 (perp=7.535, rec=0.060, cos=0.431), tot_loss_proj:2.370 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.008 (perp=7.535, rec=0.070, cos=0.431), tot_loss_proj:2.360 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.005 (perp=7.535, rec=0.067, cos=0.431), tot_loss_proj:2.370 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 900/2000] tot_loss=1.991 (perp=7.535, rec=0.053, cos=0.431), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.994 (perp=7.535, rec=0.056, cos=0.431), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1000/2000] tot_loss=1.986 (perp=7.535, rec=0.049, cos=0.430), tot_loss_proj:2.368 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1050/2000] tot_loss=2.014 (perp=7.535, rec=0.076, cos=0.431), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1100/2000] tot_loss=1.998 (perp=7.535, rec=0.060, cos=0.431), tot_loss_proj:2.368 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1150/2000] tot_loss=1.995 (perp=7.535, rec=0.057, cos=0.431), tot_loss_proj:2.369 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1200/2000] tot_loss=2.007 (perp=7.535, rec=0.068, cos=0.431), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1250/2000] tot_loss=2.000 (perp=7.535, rec=0.062, cos=0.431), tot_loss_proj:2.367 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1300/2000] tot_loss=2.013 (perp=7.535, rec=0.075, cos=0.431), tot_loss_proj:2.367 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1350/2000] tot_loss=1.997 (perp=7.535, rec=0.059, cos=0.431), tot_loss_proj:2.370 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1400/2000] tot_loss=2.007 (perp=7.535, rec=0.068, cos=0.431), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1450/2000] tot_loss=2.011 (perp=7.535, rec=0.073, cos=0.431), tot_loss_proj:2.358 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1500/2000] tot_loss=2.001 (perp=7.535, rec=0.062, cos=0.432), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1550/2000] tot_loss=2.006 (perp=7.535, rec=0.067, cos=0.431), tot_loss_proj:2.370 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1600/2000] tot_loss=2.004 (perp=7.535, rec=0.065, cos=0.431), tot_loss_proj:2.373 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1650/2000] tot_loss=2.006 (perp=7.535, rec=0.067, cos=0.432), tot_loss_proj:2.363 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1700/2000] tot_loss=1.996 (perp=7.535, rec=0.058, cos=0.432), tot_loss_proj:2.366 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1750/2000] tot_loss=2.005 (perp=7.535, rec=0.067, cos=0.431), tot_loss_proj:2.372 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1800/2000] tot_loss=1.999 (perp=7.535, rec=0.060, cos=0.431), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1850/2000] tot_loss=2.006 (perp=7.535, rec=0.067, cos=0.432), tot_loss_proj:2.369 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1900/2000] tot_loss=1.994 (perp=7.535, rec=0.056, cos=0.432), tot_loss_proj:2.371 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1950/2000] tot_loss=2.004 (perp=7.535, rec=0.065, cos=0.432), tot_loss_proj:2.367 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[2000/2000] tot_loss=1.994 (perp=7.535, rec=0.056, cos=0.432), tot_loss_proj:2.357 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] pleasure the perverse [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 96.331 | p: 95.379 | r: 97.404
rouge2     | fm: 61.462 | p: 61.293 | r: 61.616
rougeL     | fm: 83.344 | p: 82.708 | r: 84.263
rougeLsum  | fm: 83.227 | p: 82.607 | r: 84.138
r1fm+r2fm = 157.793

input #20 time: 0:08:43 | total time: 3:08:42


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.7225330290811303
highest_index [0]
highest [0.7225330290811303]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.8399343490600586 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8111321330070496 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.7990352511405945 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.7950699925422668 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.7834629416465759 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.7729091644287109 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 0.7722498774528503 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 0.7694153189659119 for ['[CLS] general stony according [UNK] bent vii rights size loan babytakingback especially situations labor there dee, connecticut pose item she side fauna golden [SEP]']
[Init] best perm rec loss: 0.7694076299667358 for ['[CLS] there vii general labor rights stony especially connecticut size situations posetaking side, baby loan [UNK] golden fauna according sheback item dee bent [SEP]']
[Init] best perm rec loss: 0.7681940793991089 for ['[CLS] especially goldenback connecticut, side rights there fauna baby posetaking general stony situations loan [UNK] according item dee labor bent she vii size [SEP]']
[Init] best perm rec loss: 0.7670472264289856 for ['[CLS] rights loan especially babyback size fauna dee connecticut general situations golden pose item there side according bent [UNK] she labor, stony viitaking [SEP]']
[Init] best perm rec loss: 0.7653863430023193 for ['[CLS] dee golden connecticut side pose situations item loan labor rights especially vii baby [UNK], general she fauna size according benttaking stony thereback [SEP]']
[Init] best perm rec loss: 0.7653699517250061 for ['[CLS] size vii bent pose fauna itemback loan dee according connecticut baby rights situations labor there she sidetaking general [UNK], especially golden stony [SEP]']
[Init] best perm rec loss: 0.764358639717102 for ['[CLS] pose she dee [UNK] vii rights baby general especially golden labor bent situations accordingback stony size fauna loan connecticuttaking side there item, [SEP]']
[Init] best perm rec loss: 0.7625426054000854 for ['[CLS] dee situations, side there especially size stonytaking connecticutback rights pose according bent loan item vii she fauna general labor [UNK] golden baby [SEP]']
[Init] best perm rec loss: 0.7621128559112549 for ['[CLS] golden especially side pose item connecticut bent, according baby fauna situations she there generalback size labor rightstaking [UNK] loan stony dee vii [SEP]']
[Init] best perm rec loss: 0.7614352107048035 for ['[CLS] baby rightstaking loan size she vii side situations connecticut especially item bent stony dee there labor [UNK] pose general according golden,back fauna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.267 (perp=12.251, rec=0.355, cos=0.461), tot_loss_proj:3.832 [t=0.22s]
prediction: ['[CLS] joker the as violence arrest national off apparently cases that angry especially replacement frontal tape device hall countries unlike serious typical of felt eyes instead [SEP]']
[ 100/2000] tot_loss=3.141 (perp=11.998, rec=0.273, cos=0.468), tot_loss_proj:3.960 [t=0.22s]
prediction: ['[CLS] extraordinary the out out gymnastics nationalnot standard wives they hurt makingtight asshole teachererted 2008 lens instead serious makes athletes although neither instead [SEP]']
[ 150/2000] tot_loss=2.886 (perp=11.059, rec=0.254, cos=0.421), tot_loss_proj:3.787 [t=0.22s]
prediction: ['[CLS] works way way out women the your like women the anti looktight sounded teachers teachers 2012 lens instead serious makes athletes athletes neither instead [SEP]']
[ 200/2000] tot_loss=2.698 (perp=10.188, rec=0.191, cos=0.469), tot_loss_proj:3.362 [t=0.22s]
prediction: ["[CLS] works way works out women the'like women made bought looktight like caretaker teachers 2013 way instead serious makes athletes, arrange instead [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.943 (perp=11.662, rec=0.144, cos=0.467), tot_loss_proj:3.775 [t=0.22s]
prediction: ['[CLS] works way works out riders the / like tales women makestypical looktypical caretaker teachers paper way instead serious makes athletes of presented instead [SEP]']
[ 300/2000] tot_loss=2.769 (perp=10.882, rec=0.120, cos=0.472), tot_loss_proj:3.367 [t=0.22s]
prediction: ['[CLS] all way works out riders this / like tales women makestypical looktypical caretaker teachers new of instead serious the athletes of ( instead [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.588 (perp=10.008, rec=0.111, cos=0.476), tot_loss_proj:3.178 [t=0.22s]
prediction: ['[CLS] all way works out riders this / likeccus women makestypical looktypical caretaker teachers new more instead of serious the athletes. instead [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.517 (perp=9.737, rec=0.095, cos=0.475), tot_loss_proj:3.061 [t=0.22s]
prediction: ['[CLS] all works way out riders this / likeccus women makes stereo looktypical caretaker caretaker of more instead of serious the athletes. instead [SEP]']
[ 450/2000] tot_loss=2.538 (perp=9.831, rec=0.100, cos=0.473), tot_loss_proj:3.068 [t=0.22s]
prediction: ['[CLS] all works way out riders this / likeccus women makes stereo looktypical caretaker teachers. more instead of serious the athletes ( instead [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.396 (perp=9.141, rec=0.091, cos=0.476), tot_loss_proj:3.064 [t=0.22s]
prediction: ['[CLS] all works way out riders this ; likeccus women look makes stereotypical caretaker teachers. more instead of serious the athletes, instead [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.314 (perp=8.732, rec=0.100, cos=0.468), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] all works way out riders this, makesccus women look like moretypical caretaker teachers. more instead of serious the athletes, instead [SEP]']
[ 600/2000] tot_loss=2.309 (perp=8.732, rec=0.086, cos=0.477), tot_loss_proj:2.872 [t=0.23s]
prediction: ['[CLS] all works way out riders this, makesccus women look like moretypical caretaker teachers. more instead of serious the athletes, instead [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.170 (perp=8.072, rec=0.081, cos=0.475), tot_loss_proj:2.784 [t=0.23s]
prediction: ['[CLS] all works way out riders, this makesbla women look like moretypical caretaker teachers, more instead of serious the athletes, instead [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.210 (perp=8.283, rec=0.079, cos=0.474), tot_loss_proj:2.665 [t=0.22s]
prediction: ['[CLS] all works way out more the this makes stereo women look like moretypical caretaker teachers and stay instead of serious the athletes, instead [SEP]']
[ 750/2000] tot_loss=2.172 (perp=8.047, rec=0.086, cos=0.476), tot_loss_proj:2.584 [t=0.22s]
prediction: ['[CLS] all works way out, the this makes stereo women look like moretypical caretaker teachers and stay instead of serious the athletes. instead [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.077 (perp=7.655, rec=0.070, cos=0.477), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] all works way out, the stereo makes this women look like moretypical caretaker teachers and stay instead of serious the athletes. instead [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.050 (perp=7.430, rec=0.090, cos=0.473), tot_loss_proj:2.481 [t=0.22s]
prediction: ['[CLS] all works way out, the more makes this women look like stereotypical caretaker teachers and wrap instead of serious the athletes. instead [SEP]']
[ 900/2000] tot_loss=2.044 (perp=7.430, rec=0.083, cos=0.476), tot_loss_proj:2.479 [t=0.23s]
prediction: ['[CLS] all works way out, the more makes this women look like stereotypical caretaker teachers and wrap instead of serious the athletes. instead [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.942 (perp=6.950, rec=0.079, cos=0.473), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] all works way out, the more makes this women look like stereotypical caretaker teachers and wrap instead of serious the athletes instead. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.887 (perp=6.716, rec=0.069, cos=0.474), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] all works way out, the more makes this wrap women look like stereotypical caretaker teachers and instead of serious the athletes instead. [SEP]']
[1050/2000] tot_loss=1.896 (perp=6.716, rec=0.079, cos=0.473), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] all works way out, the more makes this wrap women look like stereotypical caretaker teachers and instead of serious the athletes instead. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.891 (perp=6.716, rec=0.074, cos=0.474), tot_loss_proj:2.405 [t=0.23s]
prediction: ['[CLS] all works way out, the more makes this wrap women look like stereotypical caretaker teachers and instead of serious the athletes instead. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.828 (perp=6.471, rec=0.060, cos=0.473), tot_loss_proj:2.382 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes wrap women look like stereotypical caretaker teachers and instead of serious the athletes instead. [SEP]']
[1200/2000] tot_loss=1.843 (perp=6.471, rec=0.074, cos=0.474), tot_loss_proj:2.382 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes wrap women look like stereotypical caretaker teachers and instead of serious the athletes instead. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.901 (perp=6.811, rec=0.064, cos=0.475), tot_loss_proj:2.472 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes wrap women look like stereotypical caretaker teachers and instead of serious the athletespath. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.891 (perp=6.690, rec=0.079, cos=0.474), tot_loss_proj:2.447 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes wrap women look like stereotypical caretaker teachers and instead of serious thepath athletes. [SEP]']
[1350/2000] tot_loss=1.888 (perp=6.690, rec=0.075, cos=0.475), tot_loss_proj:2.444 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes wrap women look like stereotypical caretaker teachers and instead of serious thepath athletes. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.877 (perp=6.690, rec=0.065, cos=0.475), tot_loss_proj:2.455 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes wrap women look like stereotypical caretaker teachers and instead of serious thepath athletes. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.871 (perp=6.690, rec=0.058, cos=0.475), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes wrap women look like stereotypical caretaker teachers and instead of serious thepath athletes. [SEP]']
[1500/2000] tot_loss=1.885 (perp=6.690, rec=0.072, cos=0.475), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes wrap women look like stereotypical caretaker teachers and instead of serious thepath athletes. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.893 (perp=6.690, rec=0.080, cos=0.475), tot_loss_proj:2.449 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes wrap women look like stereotypical caretaker teachers and instead of serious thepath athletes. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.850 (perp=6.554, rec=0.064, cos=0.476), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes wrap women look like stereotypical teachers and caretaker instead of serious thepath athletes. [SEP]']
[1650/2000] tot_loss=1.856 (perp=6.554, rec=0.071, cos=0.474), tot_loss_proj:2.493 [t=0.23s]
prediction: ['[CLS] all works way out, the more this makes wrap women look like stereotypical teachers and caretaker instead of serious thepath athletes. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.833 (perp=6.441, rec=0.071, cos=0.474), tot_loss_proj:2.585 [t=0.23s]
prediction: ['[CLS] all works way out, the more this makes moral women look like stereotypical teachers and caretaker instead of serious thepath athletes. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.817 (perp=6.389, rec=0.065, cos=0.474), tot_loss_proj:2.545 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes moral women look like stereotypical teachers and caretaker instead of the seriouspath athletes. [SEP]']
[1800/2000] tot_loss=1.823 (perp=6.389, rec=0.071, cos=0.475), tot_loss_proj:2.546 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes moral women look like stereotypical teachers and caretaker instead of the seriouspath athletes. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.814 (perp=6.364, rec=0.066, cos=0.475), tot_loss_proj:2.530 [t=0.23s]
prediction: ['[CLS] all works way out, the more this makes moral women look like stereotypical teachers and caretaker instead of the serious athletespath. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.799 (perp=6.229, rec=0.078, cos=0.476), tot_loss_proj:2.481 [t=0.22s]
prediction: ['[CLS] all works way out, the more this makes women look like stereotypical teachers and moral caretaker instead of the serious athletespath. [SEP]']
[1950/2000] tot_loss=1.795 (perp=6.229, rec=0.075, cos=0.474), tot_loss_proj:2.478 [t=0.23s]
prediction: ['[CLS] all works way out, the more this makes women look like stereotypical teachers and moral caretaker instead of the serious athletespath. [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.784 (perp=6.126, rec=0.083, cos=0.476), tot_loss_proj:2.447 [t=0.23s]
prediction: ['[CLS] all works way out, the more this makes stereotypical women look like teachers and moral caretaker instead of the serious athletespath. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] all works way out, the more this makes moral women look like stereotypical teachers and caretaker instead of the seriouspath athletes. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.304 | p: 91.304 | r: 91.304
rouge2     | fm: 22.727 | p: 22.727 | r: 22.727
rougeL     | fm: 60.870 | p: 60.870 | r: 60.870
rougeLsum  | fm: 60.870 | p: 60.870 | r: 60.870
r1fm+r2fm = 114.032

[Aggregate metrics]:
rouge1     | fm: 96.000 | p: 95.103 | r: 97.126
rouge2     | fm: 59.669 | p: 59.477 | r: 59.932
rougeL     | fm: 82.382 | p: 81.646 | r: 83.159
rougeLsum  | fm: 82.106 | p: 81.365 | r: 83.121
r1fm+r2fm = 155.669

input #21 time: 0:08:53 | total time: 3:17:36


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.7232473609495988
highest_index [0]
highest [0.7232473609495988]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9828952550888062 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9747712016105652 for ['[CLS] mast landlord rockome crusaders enjoyed denise fire dock almost vera [SEP]']
[Init] best rec loss: 0.9731999635696411 for ['[CLS] catalogue scom de respiratory z loose ps eventual cart win [SEP]']
[Init] best rec loss: 0.9582189917564392 for ['[CLS] mines ) organ yes deck sessions mainly steady introduction arson dates [SEP]']
[Init] best rec loss: 0.9511803388595581 for ['[CLS]dbus leaguedel more arrest able communists confederatedgetsomics [SEP]']
[Init] best rec loss: 0.948554277420044 for ['[CLS] kali camp missiondio but whispered mining paulaville atmosphere qu [SEP]']
[Init] best rec loss: 0.9379372000694275 for ['[CLS]ou apartowskilizer teaching collins wolfe sample rite maze kaiser [SEP]']
[Init] best rec loss: 0.9358862042427063 for ['[CLS] kids function phoenix chinese set boarders over her schedule laughter [SEP]']
[Init] best perm rec loss: 0.9352132081985474 for ['[CLS] board seters chinese her schedule function laughter kids over phoenix [SEP]']
[Init] best perm rec loss: 0.9349984526634216 for ['[CLS] her laughter kids board overers phoenix schedule set chinese function [SEP]']
[Init] best perm rec loss: 0.9329895377159119 for ['[CLS] board kids over laughter function schedule chinese phoenixers set her [SEP]']
[Init] best perm rec loss: 0.932854413986206 for ['[CLS] scheduleers board function chinese her kids set laughter over phoenix [SEP]']
[Init] best perm rec loss: 0.9322719573974609 for ['[CLS] function over set board phoenix scheduleers kids laughter chinese her [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.529 (perp=12.085, rec=0.634, cos=0.478), tot_loss_proj:4.261 [t=0.22s]
prediction: ['[CLS] yourself? spend flipping ya waited very somewhere dna embassy maze [SEP]']
[ 100/2000] tot_loss=3.452 (perp=12.206, rec=0.555, cos=0.455), tot_loss_proj:4.416 [t=0.22s]
prediction: ['[CLS]ations? genre hamilton film wanted quite anticipated dna equivalence hmm [SEP]']
[ 150/2000] tot_loss=3.338 (perp=11.840, rec=0.555, cos=0.415), tot_loss_proj:4.348 [t=0.22s]
prediction: ['[CLS] questions? genre an film wanted very somewhere happily equivalence assortment [SEP]']
[ 200/2000] tot_loss=3.467 (perp=12.509, rec=0.540, cos=0.425), tot_loss_proj:4.444 [t=0.22s]
prediction: ['[CLS] questions as enjoyable an catholic shopping very somewhere horror decent larger [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.544 (perp=13.139, rec=0.501, cos=0.416), tot_loss_proj:4.145 [t=0.22s]
prediction: ['[CLS] legislation his hindu an enjoyable enjoyed very somewhere horror decent numerous [SEP]']
[ 300/2000] tot_loss=3.488 (perp=12.903, rec=0.455, cos=0.452), tot_loss_proj:4.567 [t=0.22s]
prediction: ['[CLS] legislation his straight an enjoyable ruined very analysis own enjoyable numerous [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.485 (perp=12.746, rec=0.498, cos=0.438), tot_loss_proj:4.285 [t=0.22s]
prediction: ['[CLS] legislationless hindu an analysis enjoyed very adaptation demands successfully subsequent [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.589 (perp=13.299, rec=0.474, cos=0.455), tot_loss_proj:3.786 [t=0.22s]
prediction: ['[CLS]ple no hindu somewhere an enjoyed supreme adaptation wta enjoyable numerous [SEP]']
[ 450/2000] tot_loss=3.404 (perp=12.444, rec=0.438, cos=0.478), tot_loss_proj:3.935 [t=0.22s]
prediction: ['[CLS]ple no hindu finance an enjoyed film adaptation own enjoyable successful [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.590 (perp=13.297, rec=0.476, cos=0.454), tot_loss_proj:4.572 [t=0.22s]
prediction: ['[CLS]ple no beds hindu oriented an destroyed very adaptation tommy enjoyable [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.559 (perp=13.156, rec=0.460, cos=0.468), tot_loss_proj:4.375 [t=0.22s]
prediction: ['[CLS]ple an successful hindu oriented very destroyed an adaptation tommy enjoyable [SEP]']
[ 600/2000] tot_loss=3.183 (perp=11.396, rec=0.440, cos=0.464), tot_loss_proj:3.306 [t=0.22s]
prediction: ['[CLS]ple an successful hindu enjoyable film enjoyed an adaptation olivia enjoyable [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.182 (perp=11.573, rec=0.455, cos=0.413), tot_loss_proj:4.270 [t=0.22s]
prediction: ['[CLS] reforms an orientedա successful film lost an adaptation olivia enjoyable [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.000 (perp=10.590, rec=0.422, cos=0.460), tot_loss_proj:4.035 [t=0.22s]
prediction: ['[CLS]ple an enjoyableա successful film lost an enjoyable olivia adaptation [SEP]']
[ 750/2000] tot_loss=2.943 (perp=10.366, rec=0.412, cos=0.458), tot_loss_proj:4.034 [t=0.22s]
prediction: ['[CLS] provision an enjoyableա successful film lost an enjoyable olivia adaptation [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.166 (perp=11.371, rec=0.420, cos=0.471), tot_loss_proj:4.266 [t=0.22s]
prediction: ['[CLS] an no orientedա successful films lost provision enjoyable olivia adaptation [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.032 (perp=10.760, rec=0.417, cos=0.462), tot_loss_proj:4.116 [t=0.22s]
prediction: ['[CLS] no an enjoyableա successful films lost provision enjoyable olivia adaptation [SEP]']
[ 900/2000] tot_loss=2.965 (perp=10.469, rec=0.401, cos=0.470), tot_loss_proj:3.322 [t=0.22s]
prediction: ['[CLS] an an enjoyableա successful films lost provision enjoyable olivia adaptation [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.969 (perp=10.469, rec=0.404, cos=0.471), tot_loss_proj:3.320 [t=0.22s]
prediction: ['[CLS] an an enjoyableա successful films lost provision enjoyable olivia adaptation [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.903 (perp=10.131, rec=0.407, cos=0.469), tot_loss_proj:3.112 [t=0.22s]
prediction: ['[CLS] an an enjoyableա successful films enjoyable lost provision olivia adaptation [SEP]']
[1050/2000] tot_loss=3.079 (perp=11.111, rec=0.395, cos=0.462), tot_loss_proj:3.436 [t=0.22s]
prediction: ['[CLS] an an enjoyableife successful films enjoyable lost provision olivia adaptation [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.002 (perp=10.762, rec=0.388, cos=0.462), tot_loss_proj:3.785 [t=0.22s]
prediction: ['[CLS] an an enjoyable enjoyable successful films awards lost provision success adaptation [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.858 (perp=10.131, rec=0.400, cos=0.432), tot_loss_proj:3.421 [t=0.22s]
prediction: ['[CLS] an an enjoyable enjoyable successful films provision lost awards success adaptation [SEP]']
[1200/2000] tot_loss=2.880 (perp=10.131, rec=0.391, cos=0.462), tot_loss_proj:3.422 [t=0.22s]
prediction: ['[CLS] an an enjoyable enjoyable successful films provision lost awards success adaptation [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.743 (perp=9.400, rec=0.395, cos=0.468), tot_loss_proj:3.019 [t=0.22s]
prediction: ['[CLS] an an enjoyable enjoyable successful films adaptation lost concept success provision [SEP]']
Attempt swap
[1300/2000] tot_loss=2.738 (perp=9.400, rec=0.394, cos=0.464), tot_loss_proj:3.021 [t=0.22s]
prediction: ['[CLS] an an enjoyable enjoyable successful films adaptation lost concept success provision [SEP]']
[1350/2000] tot_loss=2.735 (perp=9.400, rec=0.390, cos=0.465), tot_loss_proj:3.022 [t=0.22s]
prediction: ['[CLS] an an enjoyable enjoyable successful films adaptation lost concept success provision [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.694 (perp=9.219, rec=0.384, cos=0.466), tot_loss_proj:3.058 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
Attempt swap
[1450/2000] tot_loss=2.693 (perp=9.219, rec=0.375, cos=0.474), tot_loss_proj:3.061 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
[1500/2000] tot_loss=2.698 (perp=9.219, rec=0.380, cos=0.474), tot_loss_proj:3.061 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
Attempt swap
[1550/2000] tot_loss=2.697 (perp=9.219, rec=0.382, cos=0.471), tot_loss_proj:3.060 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
Attempt swap
[1600/2000] tot_loss=2.697 (perp=9.219, rec=0.381, cos=0.472), tot_loss_proj:3.055 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
[1650/2000] tot_loss=2.699 (perp=9.219, rec=0.382, cos=0.473), tot_loss_proj:3.060 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
Attempt swap
[1700/2000] tot_loss=2.696 (perp=9.219, rec=0.378, cos=0.473), tot_loss_proj:3.056 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
Attempt swap
[1750/2000] tot_loss=2.690 (perp=9.219, rec=0.376, cos=0.471), tot_loss_proj:3.058 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
[1800/2000] tot_loss=2.696 (perp=9.219, rec=0.378, cos=0.474), tot_loss_proj:3.054 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
Attempt swap
[1850/2000] tot_loss=2.694 (perp=9.219, rec=0.379, cos=0.472), tot_loss_proj:3.057 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
Attempt swap
[1900/2000] tot_loss=2.692 (perp=9.219, rec=0.373, cos=0.475), tot_loss_proj:3.057 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
[1950/2000] tot_loss=2.697 (perp=9.219, rec=0.378, cos=0.475), tot_loss_proj:3.054 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]']
Attempt swap
[2000/2000] tot_loss=2.831 (perp=9.917, rec=0.373, cos=0.475), tot_loss_proj:3.257 [t=0.22s]
prediction: ['[CLS] an enjoyable an enjoyable successful films adaptation lost implies success provision [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] an enjoyable an enjoyable successful films adaptation lost concept success provision [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 46.154 | p: 46.154 | r: 46.154
rouge2     | fm: 8.333 | p: 8.333 | r: 8.333
rougeL     | fm: 30.769 | p: 30.769 | r: 30.769
rougeLsum  | fm: 30.769 | p: 30.769 | r: 30.769
r1fm+r2fm = 54.487

[Aggregate metrics]:
rouge1     | fm: 94.001 | p: 93.084 | r: 95.169
rouge2     | fm: 57.373 | p: 57.212 | r: 57.552
rougeL     | fm: 80.031 | p: 79.315 | r: 80.850
rougeLsum  | fm: 79.953 | p: 79.331 | r: 80.828
r1fm+r2fm = 151.374

input #22 time: 0:08:45 | total time: 3:26:21


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.7294998233849577
highest_index [0]
highest [0.7294998233849577]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.7133301496505737 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7131433486938477 for ['[CLS]cky second y bad safely foundry viation quality turner direct raleigh hyper specification ware what mccall engineer shockthing joining derivative reflecting kind trojan holland rule year graduallybid amount cat fishing deserves gravity weapon viola family cross swim accessed 0 easton politics lady partition fewer [SEP] [SEP]']
[Init] best rec loss: 0.7053653001785278 for ['[CLS]cation oystermel though painfies aftermath faction micro ec decommissioned hole federation educated wi looking ban office mean creation positional vi morning envy fair ken goodwill sons no give aren para shops calendar concert beingsian you pl denmark love platform battle flags astronomy rome asking [SEP]']
[Init] best rec loss: 0.7001679539680481 for ['[CLS] drugfl vienna chop ; wound shop wonder main added founded lennox bridge gel residential rich kilometers facing countries seal adults captain wet interstate tea saved mr hawk withdrawal indeed temperaly sent daily life ₱ rail era seasons bottom champion herselfsta? context teen ready airfield [SEP]']
[Init] best perm rec loss: 0.697585940361023 for ['[CLS] sent gel daily interstate indeed shop context teen countries wet drug chop rail wonder wound mr vienna founded hawk airfield seasons bottomsta champion tea facing kilometers ₱ bridge withdrawalfl ; herself adults seal main rich ready life? added captain era temper residentialaly saved lennox [SEP]']
[Init] best perm rec loss: 0.697480320930481 for ['[CLS] context tea bottom herself life ₱ drug withdrawal countries kilometers sent founded indeed shop main temper bridge ready seasons added championfl airfield sealaly rail interstate wound daily wonder teen saved hawk adultssta lennox era mr residential vienna rich wet captain chop gel facing? ; [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.055 (perp=11.419, rec=0.335, cos=0.436), tot_loss_proj:3.641 [t=0.22s]
prediction: ['[CLS] originally tasks main purpose system focusing [SEP] hunters user objective although [SEP]ht she ; night objective. strategic years strategic objectives featured witness - theory [SEP] artillery objective battlefield soldier troops great the moral cult emerging official infantry rights nobel injustice strategic planning fantastic. instructional change [SEP]']
[ 100/2000] tot_loss=2.973 (perp=10.971, rec=0.302, cos=0.477), tot_loss_proj:3.562 [t=0.22s]
prediction: ['[CLS] donaldbrates main aim. [SEP]? war quite included hm toh, its positive objective its strategic recently main objective puzzle snake - theory [SEP] ah weapon her cassie soldiers the films. samantha chase to narrative effective 2013 kilometres strategic [SEP] elder logs atv life [SEP]']
[ 150/2000] tot_loss=2.984 (perp=11.514, rec=0.219, cos=0.462), tot_loss_proj:3.745 [t=0.22s]
prediction: ['[CLS] william achieve main objective convert [SEP] are war while : ra -h tone, critical objective its strategic generation main objectivehta tragic " theory [SEP]h aground soldiers conflict soldiers a films downhill theoretical chase to spanish achieve rental kilometres strategic [SEP]wife logs ; conflict [SEP]']
[ 200/2000] tot_loss=3.165 (perp=12.055, rec=0.303, cos=0.451), tot_loss_proj:3.691 [t=0.22s]
prediction: ["[CLS] ambrose achieve main objective morrison [SEP] are political landed, ra -h [SEP]matic totally objective finally strategic decades main cavalry initially 1991 hospital although [SEP] beetle tragic soldiers : soldiers that drama several theoretical questioning of fictional achieved ', strategic [SEP] laughing logs ultimately maritime [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.775 (perp=10.447, rec=0.234, cos=0.452), tot_loss_proj:3.687 [t=0.22s]
prediction: ["[CLS] attributed achieve main objective宀 [SEP] [CLS] imperial while, ra, ra [SEP] solutions its objective ultimately strategic decades main pattern [CLS] ) hospital although [SEP] ra its soldiers : soldiers that drama his exterior exposition of our achieve'- strategic [SEP] story investigation ultimately backward [SEP]"]
[ 300/2000] tot_loss=2.942 (perp=11.247, rec=0.234, cos=0.458), tot_loss_proj:3.519 [t=0.22s]
prediction: ["[CLS] need achieve main objective宀 [SEP] given imperial while, ra,h [SEP] solutions its objective ultimately strategic decades main kylie a conflict hospital yet years ra its patriotic : soldiers that drama his exteriorzing of our achieve'- its [SEP] story investigation ultimately maritime [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.870 (perp=11.054, rec=0.204, cos=0.455), tot_loss_proj:3.485 [t=0.22s]
prediction: ['[CLS] and achieve main objective― ; given imperial while, ra,h tone solutions its objective ultimately strategic decades main soldiers. conflict idea conflict soldiers ra its patriotic :chfield that drama the exteriorzing of our achieve new - its [SEP] story investigation entirely maritime [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.743 (perp=10.456, rec=0.191, cos=0.461), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS] and achieve main objective― ; resented vietnam while : ra,h tone, its objective ultimately strategic decades main tone the - idea conflict soldiers ra its patriotic :chfield that drama the exteriorzing of our achieve new vietnam its [SEP] story investigation indicated rights [SEP]']
[ 450/2000] tot_loss=2.757 (perp=10.674, rec=0.167, cos=0.455), tot_loss_proj:3.399 [t=0.22s]
prediction: ['[CLS] and achieve main objective― ; resented patriotic while : ra,h tone, its objective ultimately strategic decades main tone the - idea conflict soldiers ra its patriotic!chfield that drama the exteriorzing of our achieve new vietnam its [SEP] story investigation indicated rights [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.794 (perp=10.835, rec=0.166, cos=0.462), tot_loss_proj:3.471 [t=0.22s]
prediction: ['[CLS] and achieve main objective― ; resented patriotic while : ra,h tone, its objective ultimately strategic decades main tonewen - idea conflict soldiers ra its patriotic! the that drama the individualzing of the achieve generation vietnam its [SEP] haley investigation indicated rights [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.682 (perp=10.370, rec=0.157, cos=0.451), tot_loss_proj:3.441 [t=0.22s]
prediction: ['[CLS] the achieve main objective― ; resented patriotic while : ra,h tone, its objective ultimately strategic decades main tone - idea conflict soldiersh its patriotic! the that drama the exteriorwenzing of the achieve generation conflict its [SEP] protagonist frame indicated maritime [SEP]']
[ 600/2000] tot_loss=2.712 (perp=10.471, rec=0.150, cos=0.468), tot_loss_proj:3.439 [t=0.22s]
prediction: ['[CLS] the achieve main objective ள ; resented patriotic while : ra,h tone, its objective ultimately strategic decades main tone - idea conflict soldiersh its patriotic! the that drama the exteriorwenzing of the achieve generation conflict its [SEP] prairie frame conventional maritime [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.577 (perp=9.890, rec=0.143, cos=0.455), tot_loss_proj:3.487 [t=0.22s]
prediction: ['[CLS] the achieve main objective became ; resented that while : ra,h tone, its objective ultimately strategic decades main tone - idea cost soldiersh its patriotic! the patriotic drama the exterior shropshirezing of the achieve generation conflict its [SEP] generation frame conventional maritime [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.592 (perp=9.921, rec=0.146, cos=0.462), tot_loss_proj:3.496 [t=0.22s]
prediction: ['[CLS] the achieve main objective became ; resented that while : ra,h tone, its objective ultimately strategic decades main tone - idea cost soldiersh its patriotic! the patriotic drama the exterior shropshirezing of the ultimately generation conflict its [SEP] generation frame conventional maritime [SEP]']
[ 750/2000] tot_loss=2.563 (perp=9.850, rec=0.141, cos=0.453), tot_loss_proj:3.528 [t=0.22s]
prediction: ['[CLS] the achieve main objective became a resented that while : ra,h tone, its objective ultimately strategic decades main tone - idea cost soldiersh its patriotic! the patriotic drama the exterior newzing of the ultimately generation conflict its [SEP] generation frame conventional maritime [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.462 (perp=9.279, rec=0.146, cos=0.460), tot_loss_proj:3.212 [t=0.22s]
prediction: ['[CLS] the achieve main objective became a object that while : rah tone, its objective ultimately strategic decades, main tone - idea cost soldiersh its patriotic! the patriotic dramas exterior newzing of the ultimately generation conflict its [SEP] generation frame will rights [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.410 (perp=9.077, rec=0.132, cos=0.462), tot_loss_proj:3.173 [t=0.22s]
prediction: ['[CLS] the achieve main objective became the object that while : rah tone, its objective ultimately strategic decades, main tone - idea cost soldiersh its patriotic! the patriotic dramas exterior newzing of a ultimately generation conflict its [SEP] generation frame will rights [SEP]']
[ 900/2000] tot_loss=2.424 (perp=9.139, rec=0.132, cos=0.464), tot_loss_proj:3.099 [t=0.22s]
prediction: ['[CLS] and achieve main objective became the object that while : rah tone, its objective ultimately strategic decades, main tone - idea cost soldiersh its patriotic : the patriotic dramas exterior newzing of a ultimately generation conflict its [SEP] generation define will rights [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.408 (perp=9.070, rec=0.134, cos=0.460), tot_loss_proj:3.099 [t=0.22s]
prediction: ['[CLS] and achieve main objective became the object that while : rah tone, its objective ultimately strategic decades, main tone - idea cost soldiersh its patriotic! the patriotic dramas exterior newzing of a ultimately generation conflict generation its [SEP] define will rights [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.349 (perp=8.790, rec=0.128, cos=0.463), tot_loss_proj:3.018 [t=0.22s]
prediction: ['[CLS] and achieve main objective became the object that while : rah tone, its tone ultimately strategic decades, main objective - idea cost soldiersh its patriotic : the patriotic dramas exterior newzing of a ultimately generation conflict generation its [SEP] define will rights [SEP]']
[1050/2000] tot_loss=2.360 (perp=8.816, rec=0.131, cos=0.465), tot_loss_proj:3.004 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object that while : rah tone, its tone ultimately strategic decades, main objective - idea cost soldiersh its patriotic : the patriotic dramas exterior newzing of a ultimately generation conflict generation its [SEP] define will rights [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.284 (perp=8.533, rec=0.116, cos=0.461), tot_loss_proj:2.951 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object that while : rah tone, its tone ultimately strategic decades, main objective - idea cost soldiersh its patriotic : the patriotic dramas human conflictzing of a ultimately generation new generation its [SEP] define will rights [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.271 (perp=8.407, rec=0.124, cos=0.466), tot_loss_proj:2.933 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while : rah tone, its tone ultimately strategic decades, main objective - idea cost soldiersh its patriotic : the patriotic dramas human conflictzing of a ultimately generation new generation its that define will rights [SEP]']
[1200/2000] tot_loss=2.275 (perp=8.417, rec=0.124, cos=0.468), tot_loss_proj:2.943 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while : rah tone, its tone ultimately strategic decades, main objective - such cost soldiersh its patriotic : the patriotic dramas human conflictzing of a ultimately generation new generation its that define will rights [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.262 (perp=8.376, rec=0.125, cos=0.462), tot_loss_proj:2.937 [t=0.23s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while : rah tone, its tone ultimately strategic decades, main objective - such cost soldiersh its patriotic : the patriotic dramas human conflictzing of a ultimately new generation its that define will generation rights [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.203 (perp=8.104, rec=0.121, cos=0.462), tot_loss_proj:2.911 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while : rah tone, its tone ultimately strategic decades, main objective - such cost soldiersh its patriotic : the patriotic drama its human conflictzing of a ultimately new generations that define will generation rights [SEP]']
[1350/2000] tot_loss=2.205 (perp=8.104, rec=0.119, cos=0.465), tot_loss_proj:2.908 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while : rah tone, its tone ultimately strategic decades, main objective - such cost soldiersh its patriotic : the patriotic drama its human conflictzing of a ultimately new generations that define will generation rights [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.162 (perp=7.906, rec=0.122, cos=0.458), tot_loss_proj:2.873 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while : rah tone, its tone ultimately strategic decades, main objective - such cost soldiersh its patriotic : the patriotic drama its human conflictzing of a new generations that ultimately define will generation rights [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.191 (perp=8.036, rec=0.123, cos=0.461), tot_loss_proj:2.904 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such cost soldiersh its patriotic : the vietnam drama : human conflictzing of a new prairies that ultimately define will generation rights [SEP]']
[1500/2000] tot_loss=2.190 (perp=8.036, rec=0.122, cos=0.461), tot_loss_proj:2.902 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such cost soldiersh its patriotic : the vietnam drama : human conflictzing of a new prairies that ultimately define will generation rights [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.109 (perp=7.629, rec=0.119, cos=0.465), tot_loss_proj:2.718 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such patriotic soldiersh its cost : the vietnam drama : human conflictzing of a new generations that ultimately define will generation rights [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.076 (perp=7.460, rec=0.120, cos=0.464), tot_loss_proj:2.703 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such patriotic soldiersh its cost : the vietnam drama : human conflictzing of a new generations that ultimately will define generation rights [SEP]']
[1650/2000] tot_loss=2.076 (perp=7.460, rec=0.119, cos=0.465), tot_loss_proj:2.704 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such patriotic soldiersh its cost : the vietnam drama : human conflictzing of a new generations that ultimately will define generation rights [SEP]']
Attempt swap
[1700/2000] tot_loss=2.127 (perp=7.729, rec=0.116, cos=0.466), tot_loss_proj:2.772 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such patriotic soldiersh its cost : the vietnam drama : human conflictzing of a new generations that ultimately will define generation carry [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.105 (perp=7.622, rec=0.124, cos=0.457), tot_loss_proj:2.810 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such patriotic soldiers carry its cost : the vietnam drama : human conflictzing of a new generations that ultimately will define generationh [SEP]']
[1800/2000] tot_loss=2.110 (perp=7.622, rec=0.123, cos=0.463), tot_loss_proj:2.812 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such patriotic soldiers carry its cost : the vietnam drama : human conflictzing of a new generations that ultimately will define generationh [SEP]']
Attempt swap
[1850/2000] tot_loss=2.105 (perp=7.622, rec=0.117, cos=0.463), tot_loss_proj:2.811 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such patriotic soldiers carry its cost : the vietnam drama : human conflictzing of a new generations that ultimately will define generationh [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.103 (perp=7.574, rec=0.123, cos=0.465), tot_loss_proj:2.795 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such patriotic soldiers carry its cost : the vietnam drama : human conflictzing of a new generations that will ultimately define generationh [SEP]']
[1950/2000] tot_loss=2.097 (perp=7.574, rec=0.119, cos=0.463), tot_loss_proj:2.793 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such patriotic soldiers carry its cost : the vietnam drama : human conflictzing of a new generations that will ultimately define generationh [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.054 (perp=7.359, rec=0.119, cos=0.463), tot_loss_proj:2.742 [t=0.22s]
prediction: ['[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such patriotic soldiers carry its costh the vietnam drama : human conflictzing of a new generations that will ultimately define generation : [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] and achieve main objective - the object [SEP] while its rah tone, its tone ultimately strategic decades, main objective - such patriotic soldiersh its cost : the vietnam drama : human conflictzing of a new generations that ultimately will define generation carry [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 2.564 | p: 2.564 | r: 2.564
rougeL     | fm: 35.000 | p: 35.000 | r: 35.000
rougeLsum  | fm: 35.000 | p: 35.000 | r: 35.000
r1fm+r2fm = 62.564

[Aggregate metrics]:
rouge1     | fm: 92.470 | p: 91.684 | r: 93.644
rouge2     | fm: 55.542 | p: 55.357 | r: 55.741
rougeL     | fm: 78.027 | p: 77.360 | r: 78.882
rougeLsum  | fm: 78.065 | p: 77.383 | r: 78.815
r1fm+r2fm = 148.012

input #23 time: 0:08:52 | total time: 3:35:14


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.7428785214529023
highest_index [0]
highest [0.7428785214529023]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8347068428993225 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8014622330665588 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.794948160648346 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 0.7617337107658386 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.7523202300071716 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.7423791885375977 for ['[CLS] numb clear post mirror leg closet died fond sometimes distributor bonus « piecegence nerve rush authority direction turnsxie [SEP]']
[Init] best rec loss: 0.7109389305114746 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7100765109062195 for ['[CLS] attack ryuaneous unless snow play younger suffer county mid village no arms bond happy portwyl damned bush em [SEP]']
[Init] best perm rec loss: 0.7073493003845215 for ['[CLS]wyl em port happy suffer unlessaneous arms bush damned bond village play county mid younger attack ryu no snow [SEP]']
[Init] best perm rec loss: 0.705260694026947 for ['[CLS]wyl suffer ryu play happy em attack no arms mid damned snowaneous younger village bush port bond unless county [SEP]']
[Init] best perm rec loss: 0.7024234533309937 for ['[CLS] play damned mid ryu em arms port snow county unlesswyl bush no bond attack village happyaneous suffer younger [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.183 (perp=12.041, rec=0.338, cos=0.437), tot_loss_proj:3.554 [t=0.22s]
prediction: ['[CLS] anti evil boycott molly night services bomb against terrorist thus prior human was policy terrorists the context police are deserve [SEP]']
[ 100/2000] tot_loss=2.681 (perp=10.011, rec=0.232, cos=0.446), tot_loss_proj:3.151 [t=0.22s]
prediction: ['[CLS] more evil taken context outside context land the terrorists taken context political was policy terrorists ( context terrorists are deserve [SEP]']
[ 150/2000] tot_loss=2.507 (perp=9.555, rec=0.156, cos=0.440), tot_loss_proj:3.007 [t=0.22s]
prediction: ['[CLS] more evil taken context outside context political the terrorists taken climate political : climate terrorists ( context! are ) [SEP]']
[ 200/2000] tot_loss=2.410 (perp=9.143, rec=0.135, cos=0.446), tot_loss_proj:2.937 [t=0.22s]
prediction: ['[CLS] more evil taken context outside context political the terrorists taken climate political : climate terrorists ( see : than ) [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.309 (perp=8.799, rec=0.114, cos=0.435), tot_loss_proj:2.913 [t=0.22s]
prediction: ['[CLS] more evil taken context outside political context the terrorists ) current political : climate terrorists ( see! than ) [SEP]']
[ 300/2000] tot_loss=2.334 (perp=8.907, rec=0.107, cos=0.445), tot_loss_proj:3.278 [t=0.22s]
prediction: ['[CLS] more evil taken context outside political context the terrorists ) current political : climate terrorists ( see! than ever [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.240 (perp=8.461, rec=0.105, cos=0.442), tot_loss_proj:3.005 [t=0.23s]
prediction: ['[CLS] more evil taken context outside political context the terrorists : ( current political climate terrorists ( see! than ever [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.130 (perp=7.811, rec=0.130, cos=0.439), tot_loss_proj:2.923 [t=0.22s]
prediction: ['[CLS] more evil taken context outside political context the terrorists! ) current political climate are ( see : than ever [SEP]']
[ 450/2000] tot_loss=2.103 (perp=7.811, rec=0.102, cos=0.439), tot_loss_proj:2.901 [t=0.22s]
prediction: ['[CLS] more evil taken context outside political context the terrorists! ) current political climate are ( see : than ever [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.027 (perp=7.408, rec=0.106, cos=0.439), tot_loss_proj:2.721 [t=0.23s]
prediction: ['[CLS] more evil taken context outside the context the terrorists! current political climate are ( see : than ever ) [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.946 (perp=7.038, rec=0.099, cos=0.440), tot_loss_proj:2.484 [t=0.22s]
prediction: ['[CLS] more evil taken context outside the context the terrorists current political climate are ( see : than ever! ) [SEP]']
[ 600/2000] tot_loss=1.950 (perp=7.038, rec=0.102, cos=0.440), tot_loss_proj:2.487 [t=0.22s]
prediction: ['[CLS] more evil taken context outside the context the terrorists current political climate are ( see : than ever! ) [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.872 (perp=6.656, rec=0.103, cos=0.438), tot_loss_proj:2.377 [t=0.22s]
prediction: ['[CLS] more evil taken context outside of context the current political climate are ( see : than terrorists ever! ) [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.860 (perp=6.656, rec=0.088, cos=0.441), tot_loss_proj:2.377 [t=0.23s]
prediction: ['[CLS] more evil taken context outside of context the current political climate are ( see : than terrorists ever! ) [SEP]']
[ 750/2000] tot_loss=1.862 (perp=6.656, rec=0.090, cos=0.441), tot_loss_proj:2.375 [t=0.22s]
prediction: ['[CLS] more evil taken context outside of context the current political climate are ( see : than terrorists ever! ) [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.864 (perp=6.656, rec=0.093, cos=0.441), tot_loss_proj:2.378 [t=0.23s]
prediction: ['[CLS] more evil taken context outside of context the current political climate are ( see : than terrorists ever! ) [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.832 (perp=6.516, rec=0.087, cos=0.442), tot_loss_proj:2.324 [t=0.22s]
prediction: ['[CLS] more evil taken context outside of context the current political climate are ( see : terrorists than ever! ) [SEP]']
[ 900/2000] tot_loss=1.841 (perp=6.516, rec=0.096, cos=0.442), tot_loss_proj:2.320 [t=0.22s]
prediction: ['[CLS] more evil taken context outside of context the current political climate are ( see : terrorists than ever! ) [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.828 (perp=6.516, rec=0.082, cos=0.442), tot_loss_proj:2.321 [t=0.22s]
prediction: ['[CLS] more evil taken context outside of context the current political climate are ( see : terrorists than ever! ) [SEP]']
Attempt swap
[1000/2000] tot_loss=1.834 (perp=6.516, rec=0.088, cos=0.443), tot_loss_proj:2.325 [t=0.23s]
prediction: ['[CLS] more evil taken context outside of context the current political climate are ( see : terrorists than ever! ) [SEP]']
[1050/2000] tot_loss=1.911 (perp=6.907, rec=0.086, cos=0.444), tot_loss_proj:2.378 [t=0.22s]
prediction: ['[CLS] more evil taken context outside of context the current political climate are ( see ) terrorists than ever! ) [SEP]']
Attempt swap
[1100/2000] tot_loss=1.911 (perp=6.907, rec=0.086, cos=0.444), tot_loss_proj:2.371 [t=0.23s]
prediction: ['[CLS] more evil taken context outside of context the current political climate are ( see ) terrorists than ever! ) [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.867 (perp=6.598, rec=0.099, cos=0.449), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] more evil taken context outside of the current political climate are ( see context ) terrorists than ever! ) [SEP]']
[1200/2000] tot_loss=1.850 (perp=6.598, rec=0.086, cos=0.444), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] more evil taken context outside of the current political climate are ( see context ) terrorists than ever! ) [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.860 (perp=6.519, rec=0.116, cos=0.441), tot_loss_proj:2.322 [t=0.23s]
prediction: ['[CLS] more evil taken outside context of the current political climate are ( see context ) terrorists than ever! ) [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.767 (perp=6.136, rec=0.100, cos=0.440), tot_loss_proj:2.334 [t=0.23s]
prediction: ['[CLS] more evil terrorists taken outside context of the current political climate are ( see context ) than ever! ) [SEP]']
[1350/2000] tot_loss=1.767 (perp=6.136, rec=0.099, cos=0.441), tot_loss_proj:2.330 [t=0.23s]
prediction: ['[CLS] more evil terrorists taken outside context of the current political climate are ( see context ) than ever! ) [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.737 (perp=6.015, rec=0.091, cos=0.443), tot_loss_proj:2.284 [t=0.23s]
prediction: ['[CLS] more evil terrorists taken outside the context of current political climate are ( see context ) than ever! ) [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.689 (perp=5.769, rec=0.098, cos=0.438), tot_loss_proj:2.204 [t=0.22s]
prediction: ['[CLS] more evil terrorists outside the context of current political climate are taken ( see context ) than ever! ) [SEP]']
[1500/2000] tot_loss=1.686 (perp=5.769, rec=0.089, cos=0.443), tot_loss_proj:2.211 [t=0.22s]
prediction: ['[CLS] more evil terrorists outside the context of current political climate are taken ( see context ) than ever! ) [SEP]']
Attempt swap
Put prefix at the end
[1550/2000] tot_loss=1.641 (perp=5.515, rec=0.097, cos=0.441), tot_loss_proj:2.202 [t=0.22s]
prediction: ['[CLS] ) more evil terrorists outside the context of current political climate are taken ( see context ) than ever! [SEP]']
Attempt swap
[1600/2000] tot_loss=1.640 (perp=5.515, rec=0.096, cos=0.441), tot_loss_proj:2.204 [t=0.22s]
prediction: ['[CLS] ) more evil terrorists outside the context of current political climate are taken ( see context ) than ever! [SEP]']
[1650/2000] tot_loss=1.631 (perp=5.515, rec=0.087, cos=0.441), tot_loss_proj:2.204 [t=0.22s]
prediction: ['[CLS] ) more evil terrorists outside the context of current political climate are taken ( see context ) than ever! [SEP]']
Attempt swap
[1700/2000] tot_loss=1.631 (perp=5.515, rec=0.086, cos=0.442), tot_loss_proj:2.206 [t=0.23s]
prediction: ['[CLS] ) more evil terrorists outside the context of current political climate are taken ( see context ) than ever! [SEP]']
Attempt swap
[1750/2000] tot_loss=1.639 (perp=5.515, rec=0.093, cos=0.442), tot_loss_proj:2.205 [t=0.22s]
prediction: ['[CLS] ) more evil terrorists outside the context of current political climate are taken ( see context ) than ever! [SEP]']
[1800/2000] tot_loss=1.635 (perp=5.515, rec=0.090, cos=0.443), tot_loss_proj:2.202 [t=0.22s]
prediction: ['[CLS] ) more evil terrorists outside the context of current political climate are taken ( see context ) than ever! [SEP]']
Attempt swap
[1850/2000] tot_loss=1.643 (perp=5.515, rec=0.097, cos=0.443), tot_loss_proj:2.201 [t=0.23s]
prediction: ['[CLS] ) more evil terrorists outside the context of current political climate are taken ( see context ) than ever! [SEP]']
Attempt swap
[1900/2000] tot_loss=1.639 (perp=5.515, rec=0.093, cos=0.443), tot_loss_proj:2.201 [t=0.23s]
prediction: ['[CLS] ) more evil terrorists outside the context of current political climate are taken ( see context ) than ever! [SEP]']
[1950/2000] tot_loss=1.637 (perp=5.515, rec=0.090, cos=0.443), tot_loss_proj:2.202 [t=0.22s]
prediction: ['[CLS] ) more evil terrorists outside the context of current political climate are taken ( see context ) than ever! [SEP]']
Attempt swap
[2000/2000] tot_loss=1.636 (perp=5.515, rec=0.090, cos=0.443), tot_loss_proj:2.206 [t=0.22s]
prediction: ['[CLS] ) more evil terrorists outside the context of current political climate are taken ( see context ) than ever! [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] more evil taken context outside of context the current political climate are ( see ) terrorists than ever! ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.444 | p: 94.444 | r: 94.444
rouge2     | fm: 41.176 | p: 41.176 | r: 41.176
rougeL     | fm: 72.222 | p: 72.222 | r: 72.222
rougeLsum  | fm: 72.222 | p: 72.222 | r: 72.222
r1fm+r2fm = 135.621

[Aggregate metrics]:
rouge1     | fm: 92.647 | p: 91.818 | r: 93.742
rouge2     | fm: 54.238 | p: 54.015 | r: 54.432
rougeL     | fm: 77.926 | p: 77.291 | r: 78.755
rougeLsum  | fm: 77.737 | p: 77.063 | r: 78.524
r1fm+r2fm = 146.885

input #24 time: 0:08:53 | total time: 3:44:07


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.7345805524000042
highest_index [0]
highest [0.7345805524000042]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 0.9501871466636658 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.907467782497406 for ['[CLS] weakness blue fast @ [SEP]']
[Init] best rec loss: 0.901936948299408 for ['[CLS] stepped senate centuryfish [SEP]']
[Init] best rec loss: 0.8843498826026917 for ['[CLS] schoolre kim also [SEP]']
[Init] best rec loss: 0.8771857023239136 for ['[CLS]iary rooms concerned who [SEP]']
[Init] best rec loss: 0.8670846223831177 for ['[CLS] tolerance ba clearffs [SEP]']
[Init] best perm rec loss: 0.8664124608039856 for ['[CLS] tolerance clearffs ba [SEP]']
[Init] best perm rec loss: 0.8653988242149353 for ['[CLS]ffs clear ba tolerance [SEP]']
[Init] best perm rec loss: 0.8650917410850525 for ['[CLS] toleranceffs clear ba [SEP]']
[Init] best perm rec loss: 0.8641331195831299 for ['[CLS] ba toleranceffs clear [SEP]']
[Init] best perm rec loss: 0.861121654510498 for ['[CLS]ffs clear tolerance ba [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.684 (perp=10.142, rec=0.196, cos=0.460), tot_loss_proj:2.885 [t=0.22s]
prediction: ['[CLS] film... beautiful film [SEP]']
[ 100/2000] tot_loss=1.889 (perp=6.646, rec=0.102, cos=0.458), tot_loss_proj:1.921 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 150/2000] tot_loss=1.856 (perp=6.646, rec=0.067, cos=0.460), tot_loss_proj:1.914 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 200/2000] tot_loss=1.855 (perp=6.646, rec=0.066, cos=0.460), tot_loss_proj:1.913 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.855 (perp=6.646, rec=0.066, cos=0.460), tot_loss_proj:1.917 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 300/2000] tot_loss=1.852 (perp=6.646, rec=0.063, cos=0.460), tot_loss_proj:1.915 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.845 (perp=6.646, rec=0.056, cos=0.460), tot_loss_proj:1.925 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.855 (perp=6.646, rec=0.066, cos=0.460), tot_loss_proj:1.916 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.851 (perp=6.646, rec=0.062, cos=0.460), tot_loss_proj:1.914 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.849 (perp=6.646, rec=0.060, cos=0.460), tot_loss_proj:1.917 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.844 (perp=6.646, rec=0.055, cos=0.460), tot_loss_proj:1.923 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.860 (perp=6.646, rec=0.071, cos=0.460), tot_loss_proj:1.921 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.849 (perp=6.646, rec=0.060, cos=0.460), tot_loss_proj:1.918 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.853 (perp=6.646, rec=0.064, cos=0.460), tot_loss_proj:1.921 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.854 (perp=6.646, rec=0.065, cos=0.460), tot_loss_proj:1.926 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.849 (perp=6.646, rec=0.059, cos=0.460), tot_loss_proj:1.919 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.836 (perp=6.646, rec=0.046, cos=0.460), tot_loss_proj:1.925 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.851 (perp=6.646, rec=0.061, cos=0.460), tot_loss_proj:1.916 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.848 (perp=6.646, rec=0.058, cos=0.460), tot_loss_proj:1.920 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.847 (perp=6.646, rec=0.058, cos=0.460), tot_loss_proj:1.927 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.851 (perp=6.646, rec=0.062, cos=0.460), tot_loss_proj:1.913 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.852 (perp=6.646, rec=0.063, cos=0.460), tot_loss_proj:1.923 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.851 (perp=6.646, rec=0.062, cos=0.460), tot_loss_proj:1.922 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.847 (perp=6.646, rec=0.057, cos=0.460), tot_loss_proj:1.920 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.847 (perp=6.646, rec=0.058, cos=0.460), tot_loss_proj:1.929 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.854 (perp=6.646, rec=0.065, cos=0.460), tot_loss_proj:1.917 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.847 (perp=6.646, rec=0.057, cos=0.460), tot_loss_proj:1.924 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.852 (perp=6.646, rec=0.063, cos=0.460), tot_loss_proj:1.912 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.857 (perp=6.646, rec=0.068, cos=0.460), tot_loss_proj:1.919 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.853 (perp=6.646, rec=0.064, cos=0.460), tot_loss_proj:1.916 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.850 (perp=6.646, rec=0.060, cos=0.460), tot_loss_proj:1.916 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.855 (perp=6.646, rec=0.065, cos=0.460), tot_loss_proj:1.916 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.845 (perp=6.646, rec=0.055, cos=0.460), tot_loss_proj:1.928 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.847 (perp=6.646, rec=0.057, cos=0.460), tot_loss_proj:1.917 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.845 (perp=6.646, rec=0.055, cos=0.460), tot_loss_proj:1.919 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.836 (perp=6.646, rec=0.046, cos=0.460), tot_loss_proj:1.910 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.850 (perp=6.646, rec=0.060, cos=0.460), tot_loss_proj:1.917 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.845 (perp=6.646, rec=0.056, cos=0.460), tot_loss_proj:1.912 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.854 (perp=6.646, rec=0.064, cos=0.460), tot_loss_proj:1.922 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.841 (perp=6.646, rec=0.052, cos=0.460), tot_loss_proj:1.910 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.899 | p: 92.129 | r: 93.915
rouge2     | fm: 56.414 | p: 56.253 | r: 56.701
rougeL     | fm: 78.805 | p: 78.102 | r: 79.508
rougeLsum  | fm: 78.632 | p: 77.994 | r: 79.270
r1fm+r2fm = 149.313

input #25 time: 0:08:43 | total time: 3:52:51


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.7188832374404825
highest_index [0]
highest [0.7188832374404825]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.8782837986946106 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.8502412438392639 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 0.8423190712928772 for ['[CLS] este letter freedom ‚ whose raid beautyenes [SEP] numbers allsel especially best thought kid internationally picture tu plum cue dutyriam [SEP]']
[Init] best rec loss: 0.8317868113517761 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 0.8300924301147461 for ['[CLS] certified lightning result haired vehicles half expect ep drawing ticket musicalʋin died folded kiss fathers mer friendly old tests sweat associate [SEP]']
[Init] best rec loss: 0.8222127556800842 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 0.8214932680130005 for ['[CLS] door colonial shot isotead discipline merelyᆼkan list more arrow four souls polish death fourth theoretical usually constituencies octave s officers [SEP]']
[Init] best perm rec loss: 0.8199801445007324 for ['[CLS] theoretical list polishᆼ officers colonial s disciplinetead octave usually merely four souls arrowkan death constituencies shot iso more fourth door [SEP]']
[Init] best perm rec loss: 0.8172856569290161 for ['[CLS] death polish officers constituencies door iso usually discipline shot fourth merelyteadkan colonial soulsᆼ theoretical arrow s four more list octave [SEP]']
[Init] best perm rec loss: 0.815874457359314 for ['[CLS]kan octave s list four discipline arrow constituencies officers theoretical merely fourth iso polishteadᆼ colonial death usually door more shot souls [SEP]']
[Init] best perm rec loss: 0.8142822980880737 for ['[CLS] theoreticalᆼ list four fourth officersteadkan merely door arrow s usually colonial polish shot discipline constituencies death more iso octave souls [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.202 (perp=12.176, rec=0.292, cos=0.475), tot_loss_proj:3.513 [t=0.22s]
prediction: ['[CLS] pointless pointless intra pradesh least turkey ; » almostiving blamed pointless border import french naverted refugee for export import french shop [SEP]']
[ 100/2000] tot_loss=2.942 (perp=11.176, rec=0.232, cos=0.474), tot_loss_proj:3.354 [t=0.22s]
prediction: ['[CLS] pointless pointless refers ) least turkey. »taiving... pointless import import french typeverted autumn for import from french shop [SEP]']
[ 150/2000] tot_loss=2.898 (perp=11.238, rec=0.180, cos=0.471), tot_loss_proj:3.240 [t=0.22s]
prediction: ['[CLS] pointless pointless wild ) this from and » -ے... pointless french import french typeverted autumn mid import from french director [SEP]']
[ 200/2000] tot_loss=2.798 (perp=10.840, rec=0.155, cos=0.476), tot_loss_proj:3.179 [t=0.22s]
prediction: ['[CLS] pointless pointless wild ) thisder and » -ے - pointless french import french typeverted autumn after import from french director [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.802 (perp=10.657, rec=0.180, cos=0.491), tot_loss_proj:3.151 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean thising and » -ے - pointless french import french ageroller age - coming from sophie director [SEP]']
[ 300/2000] tot_loss=2.778 (perp=10.833, rec=0.137, cos=0.475), tot_loss_proj:3.176 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean thising and j -ے - pointless french import french ageroller age after coming from anne director [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.574 (perp=9.839, rec=0.125, cos=0.481), tot_loss_proj:2.935 [t=0.23s]
prediction: ['[CLS] pointless pointless ) mean this french and lesser -urrent - pointless french importing age misty age age coming from anne director [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.574 (perp=9.841, rec=0.128, cos=0.477), tot_loss_proj:2.953 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean this french and director -urrent - pointless french importing age variants age vice coming from anne 19 [SEP]']
[ 450/2000] tot_loss=2.565 (perp=9.841, rec=0.117, cos=0.480), tot_loss_proj:2.961 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean this french and director -urrent - pointless french importing age variants age vice coming from anne 19 [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.410 (perp=9.140, rec=0.103, cos=0.478), tot_loss_proj:2.897 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean this french and director - pointless - - french importing age variants age vice coming from anne 19 [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.208 (perp=8.133, rec=0.100, cos=0.481), tot_loss_proj:2.668 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean this french and director - pointless - - french importing age - - variants coming from anne 19 [SEP]']
[ 600/2000] tot_loss=2.206 (perp=8.116, rec=0.102, cos=0.481), tot_loss_proj:2.663 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean this french and director of pointless - - french importing age - - variants coming from anne 19 [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.154 (perp=7.969, rec=0.078, cos=0.482), tot_loss_proj:2.661 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean this french and director of pointless french - - importing age - - variants coming from anne 19 [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.213 (perp=8.150, rec=0.104, cos=0.479), tot_loss_proj:2.702 [t=0.23s]
prediction: ['[CLS] pointless pointless ) mean pointless french and director of this french - - importing age - -verted coming from anne leopard [SEP]']
[ 750/2000] tot_loss=2.194 (perp=8.150, rec=0.082, cos=0.482), tot_loss_proj:2.705 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean pointless french and director of this french - - importing age - -verted coming from anne leopard [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.205 (perp=8.150, rec=0.093, cos=0.481), tot_loss_proj:2.700 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean pointless french and director of this french - - importing age - -verted coming from anne leopard [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.187 (perp=8.107, rec=0.084, cos=0.482), tot_loss_proj:2.703 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean pointless french and director of this french - - importing age - - variants coming from anne bi [SEP]']
[ 900/2000] tot_loss=2.196 (perp=8.107, rec=0.095, cos=0.480), tot_loss_proj:2.703 [t=0.22s]
prediction: ['[CLS] pointless pointless ) mean pointless french and director of this french - - importing age - - variants coming from anne bi [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.231 (perp=8.271, rec=0.094, cos=0.482), tot_loss_proj:2.739 [t=0.23s]
prediction: ['[CLS] pointless mean ) mean pointless french and director of this french - - importing age - - variants coming from anne bi [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.345 (perp=8.850, rec=0.095, cos=0.479), tot_loss_proj:2.830 [t=0.22s]
prediction: ['[CLS] pointless ) mean mean pointless french and director of this french -rot importing age - - variants coming from anne bi [SEP]']
[1050/2000] tot_loss=2.419 (perp=9.262, rec=0.086, cos=0.480), tot_loss_proj:2.890 [t=0.22s]
prediction: ['[CLS] pointless ) mean mean pointless french and director of this french -rot importing age writer - variants coming from annerot [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.362 (perp=8.971, rec=0.086, cos=0.482), tot_loss_proj:2.901 [t=0.22s]
prediction: ['[CLS] pointless ) mean meaned french and director of this french - - importing age writerrot variants coming from annerot [SEP]']
Attempt swap
[1150/2000] tot_loss=2.367 (perp=8.971, rec=0.092, cos=0.481), tot_loss_proj:2.896 [t=0.22s]
prediction: ['[CLS] pointless ) mean meaned french and director of this french - - importing age writerrot variants coming from annerot [SEP]']
[1200/2000] tot_loss=2.285 (perp=8.598, rec=0.084, cos=0.481), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] pointless ) mean meaner french and director of this french - - importing age writerrot variants coming from annerot [SEP]']
Attempt swap
[1250/2000] tot_loss=2.285 (perp=8.598, rec=0.084, cos=0.481), tot_loss_proj:2.868 [t=0.22s]
prediction: ['[CLS] pointless ) mean meaner french and director of this french - - importing age writerrot variants coming from annerot [SEP]']
Attempt swap
[1300/2000] tot_loss=2.288 (perp=8.598, rec=0.087, cos=0.482), tot_loss_proj:2.869 [t=0.22s]
prediction: ['[CLS] pointless ) mean meaner french and director of this french - - importing age writerrot variants coming from annerot [SEP]']
[1350/2000] tot_loss=2.284 (perp=8.598, rec=0.083, cos=0.482), tot_loss_proj:2.870 [t=0.22s]
prediction: ['[CLS] pointless ) mean meaner french and director of this french - - importing age writerrot variants coming from annerot [SEP]']
Attempt swap
[1400/2000] tot_loss=2.307 (perp=8.707, rec=0.084, cos=0.482), tot_loss_proj:2.868 [t=0.23s]
prediction: ['[CLS] pointless ) mean meaner french and director of this french - - importing age writerrot prototype coming from annerot [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.306 (perp=8.707, rec=0.084, cos=0.480), tot_loss_proj:2.876 [t=0.22s]
prediction: ['[CLS] pointless ) mean meaner french and director of this french - - importing age writerrot prototype coming from annerot [SEP]']
[1500/2000] tot_loss=2.415 (perp=9.200, rec=0.094, cos=0.481), tot_loss_proj:3.060 [t=0.22s]
prediction: ['[CLS] pointless ) mean meaner french and director of this french - - importing age writerrot bi coming from annerot [SEP]']
Attempt swap
[1550/2000] tot_loss=2.413 (perp=9.200, rec=0.092, cos=0.481), tot_loss_proj:3.056 [t=0.23s]
prediction: ['[CLS] pointless ) mean meaner french and director of this french - - importing age writerrot bi coming from annerot [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.343 (perp=8.847, rec=0.094, cos=0.480), tot_loss_proj:3.037 [t=0.22s]
prediction: ['[CLS] pointless ) mean meaner french and director of this french - - importing age writer anne bi coming fromrotrot [SEP]']
[1650/2000] tot_loss=2.335 (perp=8.847, rec=0.086, cos=0.480), tot_loss_proj:3.029 [t=0.22s]
prediction: ['[CLS] pointless ) mean meaner french and director of this french - - importing age writer anne bi coming fromrotrot [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.290 (perp=8.626, rec=0.085, cos=0.480), tot_loss_proj:2.982 [t=0.23s]
prediction: ['[CLS] pointless ) mean meaner french and director of this age - - importing french writer anne bi coming fromrotrot [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.212 (perp=8.227, rec=0.085, cos=0.481), tot_loss_proj:2.917 [t=0.22s]
prediction: ['[CLS] pointless ) mean mean coming french and director of this age - - importing french writer anne bier fromrotrot [SEP]']
[1800/2000] tot_loss=2.207 (perp=8.227, rec=0.081, cos=0.481), tot_loss_proj:2.916 [t=0.22s]
prediction: ['[CLS] pointless ) mean mean coming french and director of this age - - importing french writer anne bier fromrotrot [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.175 (perp=8.009, rec=0.092, cos=0.481), tot_loss_proj:2.835 [t=0.23s]
prediction: ['[CLS] pointless ) mean coming mean french and director of this age - - importing french writer anne bier fromrotrot [SEP]']
Attempt swap
[1900/2000] tot_loss=2.164 (perp=8.009, rec=0.081, cos=0.481), tot_loss_proj:2.830 [t=0.22s]
prediction: ['[CLS] pointless ) mean coming mean french and director of this age - - importing french writer anne bier fromrotrot [SEP]']
[1950/2000] tot_loss=2.177 (perp=8.009, rec=0.094, cos=0.482), tot_loss_proj:2.826 [t=0.22s]
prediction: ['[CLS] pointless ) mean coming mean french and director of this age - - importing french writer anne bier fromrotrot [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.139 (perp=7.866, rec=0.085, cos=0.481), tot_loss_proj:2.817 [t=0.22s]
prediction: ['[CLS] pointless ) mean coming mean french and director of this age - - importing french writer anne bierrot fromrot [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] pointless ) mean meaner french and director of this french - - importing age writerrot variants coming from annerot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.857 | p: 61.111 | r: 64.706
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 38.889 | r: 41.176
rougeLsum  | fm: 40.000 | p: 38.889 | r: 41.176
r1fm+r2fm = 62.857

[Aggregate metrics]:
rouge1     | fm: 91.945 | p: 91.174 | r: 92.926
rouge2     | fm: 54.097 | p: 53.979 | r: 54.215
rougeL     | fm: 77.371 | p: 76.671 | r: 78.043
rougeLsum  | fm: 77.361 | p: 76.686 | r: 78.102
r1fm+r2fm = 146.043

input #26 time: 0:08:53 | total time: 4:01:44


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.7115698525595127
highest_index [0]
highest [0.7115698525595127]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9759621024131775 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9459997415542603 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 0.9408474564552307 for ['[CLS] volume nan on [SEP]']
[Init] best rec loss: 0.9362679123878479 for ['[CLS] how turned basic [SEP]']
[Init] best rec loss: 0.9362203478813171 for ['[CLS] drawing dynamo cave [SEP]']
[Init] best rec loss: 0.9126931428909302 for ['[CLS] op framework ran [SEP]']
[Init] best rec loss: 0.8985313773155212 for ['[CLS] fat mattream [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.792 (perp=10.512, rec=0.203, cos=0.487), tot_loss_proj:3.080 [t=0.22s]
prediction: ['[CLS] generic are generic [SEP]']
[ 100/2000] tot_loss=2.235 (perp=8.156, rec=0.114, cos=0.489), tot_loss_proj:2.779 [t=0.22s]
prediction: ['[CLS] as are generic [SEP]']
[ 150/2000] tot_loss=2.407 (perp=9.217, rec=0.071, cos=0.492), tot_loss_proj:2.804 [t=0.22s]
prediction: ['[CLS] so are generic [SEP]']
[ 200/2000] tot_loss=2.388 (perp=9.217, rec=0.053, cos=0.492), tot_loss_proj:2.817 [t=0.22s]
prediction: ['[CLS] so are generic [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.210 (perp=8.320, rec=0.056, cos=0.490), tot_loss_proj:2.252 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=2.215 (perp=8.320, rec=0.058, cos=0.493), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.226 (perp=8.320, rec=0.069, cos=0.493), tot_loss_proj:2.244 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.223 (perp=8.320, rec=0.065, cos=0.494), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=2.224 (perp=8.320, rec=0.067, cos=0.493), tot_loss_proj:2.250 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.212 (perp=8.320, rec=0.055, cos=0.494), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.211 (perp=8.320, rec=0.054, cos=0.493), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=2.222 (perp=8.320, rec=0.064, cos=0.494), tot_loss_proj:2.251 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.200 (perp=8.320, rec=0.043, cos=0.493), tot_loss_proj:2.249 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.229 (perp=8.320, rec=0.071, cos=0.493), tot_loss_proj:2.244 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=2.212 (perp=8.320, rec=0.055, cos=0.493), tot_loss_proj:2.244 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.221 (perp=8.320, rec=0.064, cos=0.492), tot_loss_proj:2.243 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.215 (perp=8.320, rec=0.059, cos=0.492), tot_loss_proj:2.249 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=2.225 (perp=8.320, rec=0.068, cos=0.493), tot_loss_proj:2.247 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.222 (perp=8.320, rec=0.066, cos=0.492), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=2.211 (perp=8.320, rec=0.054, cos=0.493), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=2.223 (perp=8.320, rec=0.065, cos=0.493), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=2.226 (perp=8.320, rec=0.068, cos=0.494), tot_loss_proj:2.252 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=2.222 (perp=8.320, rec=0.064, cos=0.493), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=2.217 (perp=8.320, rec=0.060, cos=0.494), tot_loss_proj:2.242 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=2.228 (perp=8.320, rec=0.070, cos=0.493), tot_loss_proj:2.256 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=2.230 (perp=8.320, rec=0.074, cos=0.493), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=2.218 (perp=8.320, rec=0.061, cos=0.493), tot_loss_proj:2.243 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=2.228 (perp=8.320, rec=0.071, cos=0.493), tot_loss_proj:2.248 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=2.217 (perp=8.320, rec=0.059, cos=0.493), tot_loss_proj:2.253 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=2.221 (perp=8.320, rec=0.064, cos=0.493), tot_loss_proj:2.245 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=2.223 (perp=8.320, rec=0.065, cos=0.493), tot_loss_proj:2.246 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=2.219 (perp=8.320, rec=0.061, cos=0.494), tot_loss_proj:2.245 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=2.218 (perp=8.320, rec=0.061, cos=0.493), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=2.220 (perp=8.320, rec=0.062, cos=0.494), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=2.231 (perp=8.320, rec=0.073, cos=0.494), tot_loss_proj:2.247 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=2.211 (perp=8.320, rec=0.054, cos=0.494), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=2.212 (perp=8.320, rec=0.054, cos=0.493), tot_loss_proj:2.244 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=2.210 (perp=8.320, rec=0.052, cos=0.494), tot_loss_proj:2.259 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=2.210 (perp=8.320, rec=0.052, cos=0.494), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.218 (perp=8.320, rec=0.060, cos=0.494), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.183 | p: 91.366 | r: 93.225
rouge2     | fm: 55.433 | p: 55.259 | r: 55.673
rougeL     | fm: 78.030 | p: 77.403 | r: 78.728
rougeLsum  | fm: 78.165 | p: 77.478 | r: 78.843
r1fm+r2fm = 147.616

input #27 time: 0:08:43 | total time: 4:10:28


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.730969936084024
highest_index [0]
highest [0.730969936084024]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8689698576927185 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.8465669751167297 for ['[CLS] easierlnan cow [SEP]']
[Init] best rec loss: 0.8434841632843018 for ['[CLS] done human live quickly [SEP]']
[Init] best rec loss: 0.8360050916671753 for ['[CLS] sick prior spielberggation [SEP]']
[Init] best rec loss: 0.83584064245224 for ['[CLS] claim⁄₄ negotiations finishing [SEP]']
[Init] best rec loss: 0.8343064188957214 for ['[CLS] hand delgado laid phoenix [SEP]']
[Init] best rec loss: 0.8252111077308655 for ['[CLS] w dean re thanks [SEP]']
[Init] best rec loss: 0.8179446458816528 for ['[CLS] pol maneuver lex bar [SEP]']
[Init] best perm rec loss: 0.8146610260009766 for ['[CLS] maneuver pol lex bar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.470 (perp=9.137, rec=0.184, cos=0.459), tot_loss_proj:2.836 [t=0.22s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
[ 100/2000] tot_loss=2.414 (perp=9.137, rec=0.126, cos=0.461), tot_loss_proj:2.833 [t=0.22s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
[ 150/2000] tot_loss=2.408 (perp=9.137, rec=0.120, cos=0.461), tot_loss_proj:2.836 [t=0.22s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
[ 200/2000] tot_loss=2.414 (perp=9.137, rec=0.122, cos=0.464), tot_loss_proj:2.837 [t=0.22s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.255 (perp=8.236, rec=0.147, cos=0.461), tot_loss_proj:2.668 [t=0.22s]
prediction: ['[CLS] only minutes 71 minutes [SEP]']
[ 300/2000] tot_loss=2.229 (perp=8.236, rec=0.118, cos=0.465), tot_loss_proj:2.668 [t=0.22s]
prediction: ['[CLS] only minutes 71 minutes [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.232 (perp=8.236, rec=0.119, cos=0.466), tot_loss_proj:2.657 [t=0.22s]
prediction: ['[CLS] only minutes 71 minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.084 (perp=7.699, rec=0.081, cos=0.463), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 450/2000] tot_loss=2.068 (perp=7.699, rec=0.063, cos=0.465), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.069 (perp=7.699, rec=0.064, cos=0.465), tot_loss_proj:2.076 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.071 (perp=7.699, rec=0.068, cos=0.463), tot_loss_proj:2.079 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=2.067 (perp=7.699, rec=0.062, cos=0.465), tot_loss_proj:2.072 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.073 (perp=7.699, rec=0.068, cos=0.465), tot_loss_proj:2.084 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.054 (perp=7.699, rec=0.051, cos=0.464), tot_loss_proj:2.081 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=2.074 (perp=7.699, rec=0.069, cos=0.465), tot_loss_proj:2.094 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.066 (perp=7.699, rec=0.061, cos=0.465), tot_loss_proj:2.088 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.058 (perp=7.699, rec=0.053, cos=0.465), tot_loss_proj:2.087 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=2.075 (perp=7.699, rec=0.070, cos=0.465), tot_loss_proj:2.088 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.067 (perp=7.699, rec=0.061, cos=0.465), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=2.064 (perp=7.699, rec=0.058, cos=0.466), tot_loss_proj:2.076 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=2.065 (perp=7.699, rec=0.060, cos=0.466), tot_loss_proj:2.084 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=2.064 (perp=7.699, rec=0.060, cos=0.464), tot_loss_proj:2.079 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=2.070 (perp=7.699, rec=0.065, cos=0.465), tot_loss_proj:2.079 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=2.063 (perp=7.699, rec=0.058, cos=0.465), tot_loss_proj:2.092 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=2.062 (perp=7.699, rec=0.057, cos=0.465), tot_loss_proj:2.068 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=2.069 (perp=7.699, rec=0.063, cos=0.466), tot_loss_proj:2.093 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=2.061 (perp=7.699, rec=0.056, cos=0.465), tot_loss_proj:2.090 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=2.052 (perp=7.699, rec=0.047, cos=0.465), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=2.067 (perp=7.699, rec=0.061, cos=0.466), tot_loss_proj:2.076 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=2.064 (perp=7.699, rec=0.059, cos=0.465), tot_loss_proj:2.088 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=2.068 (perp=7.699, rec=0.062, cos=0.465), tot_loss_proj:2.079 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=2.069 (perp=7.699, rec=0.063, cos=0.466), tot_loss_proj:2.084 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=2.061 (perp=7.699, rec=0.056, cos=0.466), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=2.066 (perp=7.699, rec=0.061, cos=0.466), tot_loss_proj:2.077 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=2.067 (perp=7.699, rec=0.061, cos=0.466), tot_loss_proj:2.083 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=2.061 (perp=7.699, rec=0.056, cos=0.465), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=2.067 (perp=7.699, rec=0.061, cos=0.465), tot_loss_proj:2.082 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=2.066 (perp=7.699, rec=0.061, cos=0.466), tot_loss_proj:2.080 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=2.056 (perp=7.699, rec=0.050, cos=0.466), tot_loss_proj:2.084 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=2.067 (perp=7.699, rec=0.062, cos=0.466), tot_loss_proj:2.089 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.381 | p: 91.682 | r: 93.302
rouge2     | fm: 57.487 | p: 57.332 | r: 57.626
rougeL     | fm: 79.036 | p: 78.462 | r: 79.667
rougeLsum  | fm: 78.872 | p: 78.267 | r: 79.501
r1fm+r2fm = 149.868

input #28 time: 0:08:43 | total time: 4:19:12


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.7138115861762522
highest_index [0]
highest [0.7138115861762522]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.8671755194664001 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.855078399181366 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.8525506258010864 for ['[CLS]jouross restorationӏ ministerial text murder me tertiary biblical [SEP]']
[Init] best rec loss: 0.8432788848876953 for ['[CLS] protected leadlto arose ec along sunset pay everywhere county [SEP]']
[Init] best rec loss: 0.8146739602088928 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.7769067883491516 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 0.7751128077507019 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best perm rec loss: 0.7743366360664368 for ['[CLS] crap joyah extra epicbeat historia cape fork fk apart [SEP]']
[Init] best perm rec loss: 0.7728227972984314 for ['[CLS]beat apart epic historia fk crap cape fork joyah extra [SEP]']
[Init] best perm rec loss: 0.7727314829826355 for ['[CLS] crap cape epic fk fork extrabeat historia apart joyah [SEP]']
[Init] best perm rec loss: 0.7724202275276184 for ['[CLS] cape crap forkbeat extra fk apart joyah epic historia [SEP]']
[Init] best perm rec loss: 0.7712697982788086 for ['[CLS]beat fork joyah cape extra fk apart historia crap epic [SEP]']
[Init] best perm rec loss: 0.7704700827598572 for ['[CLS] fork epicbeat fk cape historia crap apart extra joyah [SEP]']
[Init] best perm rec loss: 0.7699613571166992 for ['[CLS]beat apart historia cape joyah fk epic crap fork extra [SEP]']
[Init] best perm rec loss: 0.7685683369636536 for ['[CLS] fk fork cape extra joyah crap historia epic apartbeat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.390 (perp=8.110, rec=0.289, cos=0.479), tot_loss_proj:3.034 [t=0.22s]
prediction: ['[CLS] that not resident believe evil it not is not not [SEP]']
[ 100/2000] tot_loss=2.267 (perp=8.157, rec=0.145, cos=0.491), tot_loss_proj:2.955 [t=0.22s]
prediction: ['[CLS] that not resident believe evil it resident is not not [SEP]']
[ 150/2000] tot_loss=2.233 (perp=8.196, rec=0.105, cos=0.489), tot_loss_proj:2.827 [t=0.22s]
prediction: ['[CLS] that not resident believe evil it resident is also not [SEP]']
[ 200/2000] tot_loss=2.338 (perp=8.732, rec=0.102, cos=0.489), tot_loss_proj:3.107 [t=0.22s]
prediction: ['[CLS] that not resident believe evil it resident is also i [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.169 (perp=7.917, rec=0.094, cos=0.492), tot_loss_proj:3.023 [t=0.22s]
prediction: ['[CLS] that not resident believe evil it is also resident i [SEP]']
[ 300/2000] tot_loss=2.150 (perp=7.917, rec=0.076, cos=0.490), tot_loss_proj:3.029 [t=0.22s]
prediction: ['[CLS] that not resident believe evil it is also resident i [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.950 (perp=6.928, rec=0.074, cos=0.491), tot_loss_proj:2.966 [t=0.22s]
prediction: ['[CLS] believe that not resident evil it is also resident i [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.946 (perp=6.928, rec=0.069, cos=0.491), tot_loss_proj:2.965 [t=0.22s]
prediction: ['[CLS] believe that not resident evil it is also resident i [SEP]']
[ 450/2000] tot_loss=1.954 (perp=6.928, rec=0.079, cos=0.489), tot_loss_proj:2.965 [t=0.22s]
prediction: ['[CLS] believe that not resident evil it is also resident i [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.952 (perp=6.928, rec=0.076, cos=0.489), tot_loss_proj:2.965 [t=0.22s]
prediction: ['[CLS] believe that not resident evil it is also resident i [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.939 (perp=6.928, rec=0.064, cos=0.488), tot_loss_proj:2.964 [t=0.22s]
prediction: ['[CLS] believe that not resident evil it is also resident i [SEP]']
[ 600/2000] tot_loss=1.947 (perp=6.928, rec=0.072, cos=0.489), tot_loss_proj:2.968 [t=0.22s]
prediction: ['[CLS] believe that not resident evil it is also resident i [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.944 (perp=6.928, rec=0.069, cos=0.489), tot_loss_proj:2.966 [t=0.22s]
prediction: ['[CLS] believe that not resident evil it is also resident i [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.956 (perp=6.928, rec=0.080, cos=0.490), tot_loss_proj:2.965 [t=0.22s]
prediction: ['[CLS] believe that not resident evil it is also resident i [SEP]']
[ 750/2000] tot_loss=1.946 (perp=6.928, rec=0.071, cos=0.489), tot_loss_proj:2.964 [t=0.22s]
prediction: ['[CLS] believe that not resident evil it is also resident i [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.955 (perp=6.928, rec=0.080, cos=0.490), tot_loss_proj:2.964 [t=0.22s]
prediction: ['[CLS] believe that not resident evil it is also resident i [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.041 (perp=7.443, rec=0.064, cos=0.489), tot_loss_proj:3.001 [t=0.22s]
prediction: ['[CLS] believe that not. evil it is also resident i [SEP]']
[ 900/2000] tot_loss=1.950 (perp=6.928, rec=0.075, cos=0.489), tot_loss_proj:2.964 [t=0.22s]
prediction: ['[CLS] believe that not resident evil it is also resident i [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.057 (perp=7.443, rec=0.079, cos=0.489), tot_loss_proj:3.003 [t=0.22s]
prediction: ['[CLS] believe that not. evil it is also resident i [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.875 (perp=6.592, rec=0.067, cos=0.490), tot_loss_proj:3.222 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
[1050/2000] tot_loss=1.880 (perp=6.592, rec=0.072, cos=0.490), tot_loss_proj:3.217 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1100/2000] tot_loss=1.881 (perp=6.592, rec=0.073, cos=0.489), tot_loss_proj:3.220 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1150/2000] tot_loss=1.881 (perp=6.592, rec=0.074, cos=0.488), tot_loss_proj:3.221 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
[1200/2000] tot_loss=1.878 (perp=6.592, rec=0.070, cos=0.490), tot_loss_proj:3.221 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1250/2000] tot_loss=1.879 (perp=6.592, rec=0.071, cos=0.490), tot_loss_proj:3.220 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1300/2000] tot_loss=1.886 (perp=6.592, rec=0.078, cos=0.490), tot_loss_proj:3.219 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
[1350/2000] tot_loss=1.870 (perp=6.592, rec=0.062, cos=0.490), tot_loss_proj:3.222 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1400/2000] tot_loss=1.875 (perp=6.592, rec=0.069, cos=0.487), tot_loss_proj:3.218 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1450/2000] tot_loss=1.870 (perp=6.592, rec=0.062, cos=0.490), tot_loss_proj:3.218 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
[1500/2000] tot_loss=1.882 (perp=6.592, rec=0.076, cos=0.488), tot_loss_proj:3.222 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1550/2000] tot_loss=1.887 (perp=6.592, rec=0.078, cos=0.490), tot_loss_proj:3.221 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1600/2000] tot_loss=1.875 (perp=6.592, rec=0.066, cos=0.490), tot_loss_proj:3.222 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
[1650/2000] tot_loss=1.878 (perp=6.592, rec=0.070, cos=0.490), tot_loss_proj:3.223 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1700/2000] tot_loss=1.886 (perp=6.592, rec=0.077, cos=0.490), tot_loss_proj:3.219 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1750/2000] tot_loss=1.886 (perp=6.592, rec=0.078, cos=0.489), tot_loss_proj:3.216 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
[1800/2000] tot_loss=1.876 (perp=6.592, rec=0.067, cos=0.490), tot_loss_proj:3.216 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1850/2000] tot_loss=1.884 (perp=6.592, rec=0.076, cos=0.490), tot_loss_proj:3.220 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[1900/2000] tot_loss=1.880 (perp=6.592, rec=0.072, cos=0.490), tot_loss_proj:3.219 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
[1950/2000] tot_loss=1.886 (perp=6.592, rec=0.078, cos=0.490), tot_loss_proj:3.221 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Attempt swap
[2000/2000] tot_loss=1.885 (perp=6.592, rec=0.076, cos=0.490), tot_loss_proj:3.223 [t=0.22s]
prediction: ['[CLS] believe that not evil. it is also resident i [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] believe that not evil. it is also resident i [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 10.000 | p: 10.000 | r: 10.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 110.000

[Aggregate metrics]:
rouge1     | fm: 92.550 | p: 91.819 | r: 93.553
rouge2     | fm: 55.713 | p: 55.446 | r: 55.866
rougeL     | fm: 78.026 | p: 77.455 | r: 78.605
rougeLsum  | fm: 77.865 | p: 77.397 | r: 78.597
r1fm+r2fm = 148.263

input #29 time: 0:08:44 | total time: 4:27:57


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.7373991817167589
highest_index [0]
highest [0.7373991817167589]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.8283879160881042 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.6910461783409119 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.6460809707641602 for ['[CLS] acceleration council lizard [SEP]']
[Init] best perm rec loss: 0.6422059535980225 for ['[CLS] lizard acceleration council [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.559 (perp=9.539, rec=0.212, cos=0.439), tot_loss_proj:2.428 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 100/2000] tot_loss=2.464 (perp=9.539, rec=0.100, cos=0.455), tot_loss_proj:2.436 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 150/2000] tot_loss=2.423 (perp=9.539, rec=0.071, cos=0.444), tot_loss_proj:2.431 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=2.443 (perp=9.539, rec=0.077, cos=0.458), tot_loss_proj:2.425 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.412 (perp=9.539, rec=0.059, cos=0.445), tot_loss_proj:2.426 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=2.425 (perp=9.539, rec=0.064, cos=0.452), tot_loss_proj:2.437 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.432 (perp=9.539, rec=0.070, cos=0.453), tot_loss_proj:2.436 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.431 (perp=9.539, rec=0.069, cos=0.454), tot_loss_proj:2.429 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=2.418 (perp=9.539, rec=0.055, cos=0.455), tot_loss_proj:2.431 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.436 (perp=9.539, rec=0.069, cos=0.459), tot_loss_proj:2.436 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.435 (perp=9.539, rec=0.072, cos=0.455), tot_loss_proj:2.438 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=2.410 (perp=9.539, rec=0.051, cos=0.451), tot_loss_proj:2.423 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.419 (perp=9.539, rec=0.056, cos=0.455), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.429 (perp=9.539, rec=0.069, cos=0.452), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=2.417 (perp=9.539, rec=0.053, cos=0.455), tot_loss_proj:2.423 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.423 (perp=9.539, rec=0.059, cos=0.456), tot_loss_proj:2.430 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.425 (perp=9.539, rec=0.063, cos=0.455), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=2.426 (perp=9.539, rec=0.063, cos=0.456), tot_loss_proj:2.431 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.422 (perp=9.539, rec=0.058, cos=0.456), tot_loss_proj:2.425 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=2.418 (perp=9.539, rec=0.054, cos=0.456), tot_loss_proj:2.427 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=2.426 (perp=9.539, rec=0.062, cos=0.456), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=2.422 (perp=9.539, rec=0.058, cos=0.456), tot_loss_proj:2.430 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=2.436 (perp=9.539, rec=0.072, cos=0.456), tot_loss_proj:2.426 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=2.431 (perp=9.539, rec=0.067, cos=0.456), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=2.430 (perp=9.539, rec=0.066, cos=0.456), tot_loss_proj:2.429 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=2.411 (perp=9.539, rec=0.047, cos=0.456), tot_loss_proj:2.423 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=2.424 (perp=9.539, rec=0.060, cos=0.456), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=2.418 (perp=9.539, rec=0.054, cos=0.456), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=2.428 (perp=9.539, rec=0.064, cos=0.456), tot_loss_proj:2.429 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=2.419 (perp=9.539, rec=0.055, cos=0.456), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=2.408 (perp=9.539, rec=0.044, cos=0.456), tot_loss_proj:2.431 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=2.425 (perp=9.539, rec=0.061, cos=0.456), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=2.433 (perp=9.539, rec=0.069, cos=0.456), tot_loss_proj:2.436 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=2.415 (perp=9.539, rec=0.051, cos=0.456), tot_loss_proj:2.428 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=2.413 (perp=9.539, rec=0.049, cos=0.456), tot_loss_proj:2.427 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=2.426 (perp=9.539, rec=0.062, cos=0.456), tot_loss_proj:2.431 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=2.408 (perp=9.539, rec=0.044, cos=0.456), tot_loss_proj:2.431 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=2.424 (perp=9.539, rec=0.060, cos=0.456), tot_loss_proj:2.423 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=2.426 (perp=9.539, rec=0.062, cos=0.456), tot_loss_proj:2.427 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=2.419 (perp=9.539, rec=0.055, cos=0.456), tot_loss_proj:2.436 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.015 | p: 92.237 | r: 93.787
rouge2     | fm: 57.213 | p: 57.084 | r: 57.352
rougeL     | fm: 78.906 | p: 78.397 | r: 79.473
rougeLsum  | fm: 78.481 | p: 77.994 | r: 79.181
r1fm+r2fm = 150.228

input #30 time: 0:08:43 | total time: 4:36:40


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.7162998350238783
highest_index [0]
highest [0.7162998350238783]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.8816675543785095 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.8221973776817322 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8096215128898621 for ['[CLS] song spectators then [SEP]']
[Init] best rec loss: 0.8067721128463745 for ['[CLS] jing critical hurts [SEP]']
[Init] best rec loss: 0.7775655388832092 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 0.7752817273139954 for ['[CLS] lil number belmont [SEP]']
[Init] best rec loss: 0.7669095993041992 for ['[CLS] lad crossing all [SEP]']
[Init] best rec loss: 0.7640876770019531 for ['[CLS] speakingski strains [SEP]']
[Init] best rec loss: 0.7634240388870239 for ['[CLS] golf rollichi [SEP]']
[Init] best rec loss: 0.7450275421142578 for ['[CLS] lighthouse peace case [SEP]']
[Init] best perm rec loss: 0.7413385510444641 for ['[CLS] case lighthouse peace [SEP]']
[Init] best perm rec loss: 0.7404161691665649 for ['[CLS] case peace lighthouse [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.028 (perp=11.390, rec=0.265, cos=0.484), tot_loss_proj:3.293 [t=0.22s]
prediction: ['[CLS] vehicle force better [SEP]']
[ 100/2000] tot_loss=2.845 (perp=11.175, rec=0.125, cos=0.485), tot_loss_proj:3.369 [t=0.22s]
prediction: ['[CLS] vehicle vehicle better [SEP]']
[ 150/2000] tot_loss=2.542 (perp=9.943, rec=0.067, cos=0.487), tot_loss_proj:2.916 [t=0.22s]
prediction: ['[CLS] vehicle a better [SEP]']
[ 200/2000] tot_loss=2.535 (perp=9.943, rec=0.061, cos=0.486), tot_loss_proj:2.913 [t=0.22s]
prediction: ['[CLS] vehicle a better [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.055 (perp=7.603, rec=0.052, cos=0.483), tot_loss_proj:2.153 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=2.061 (perp=7.603, rec=0.054, cos=0.486), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.067 (perp=7.603, rec=0.060, cos=0.487), tot_loss_proj:2.146 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.070 (perp=7.603, rec=0.063, cos=0.487), tot_loss_proj:2.141 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=2.063 (perp=7.603, rec=0.057, cos=0.485), tot_loss_proj:2.143 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.065 (perp=7.603, rec=0.057, cos=0.487), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.070 (perp=7.603, rec=0.063, cos=0.487), tot_loss_proj:2.139 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=2.067 (perp=7.603, rec=0.060, cos=0.487), tot_loss_proj:2.149 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.075 (perp=7.603, rec=0.068, cos=0.486), tot_loss_proj:2.135 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.066 (perp=7.603, rec=0.060, cos=0.485), tot_loss_proj:2.147 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=2.077 (perp=7.603, rec=0.069, cos=0.487), tot_loss_proj:2.134 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.065 (perp=7.603, rec=0.057, cos=0.487), tot_loss_proj:2.137 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.075 (perp=7.603, rec=0.068, cos=0.487), tot_loss_proj:2.152 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=2.077 (perp=7.603, rec=0.070, cos=0.486), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.072 (perp=7.603, rec=0.065, cos=0.487), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=2.074 (perp=7.603, rec=0.066, cos=0.487), tot_loss_proj:2.140 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=2.062 (perp=7.603, rec=0.055, cos=0.487), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=2.061 (perp=7.603, rec=0.053, cos=0.487), tot_loss_proj:2.132 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=2.063 (perp=7.603, rec=0.056, cos=0.487), tot_loss_proj:2.136 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=2.078 (perp=7.603, rec=0.071, cos=0.487), tot_loss_proj:2.147 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=2.063 (perp=7.603, rec=0.056, cos=0.487), tot_loss_proj:2.143 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=2.067 (perp=7.603, rec=0.060, cos=0.487), tot_loss_proj:2.135 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=2.068 (perp=7.603, rec=0.061, cos=0.487), tot_loss_proj:2.143 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=2.069 (perp=7.603, rec=0.062, cos=0.487), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=2.070 (perp=7.603, rec=0.063, cos=0.487), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=2.066 (perp=7.603, rec=0.059, cos=0.487), tot_loss_proj:2.148 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=2.053 (perp=7.603, rec=0.046, cos=0.486), tot_loss_proj:2.153 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=2.050 (perp=7.603, rec=0.042, cos=0.487), tot_loss_proj:2.145 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=2.067 (perp=7.603, rec=0.060, cos=0.487), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=2.077 (perp=7.603, rec=0.070, cos=0.487), tot_loss_proj:2.147 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=2.060 (perp=7.603, rec=0.053, cos=0.487), tot_loss_proj:2.136 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=2.066 (perp=7.603, rec=0.059, cos=0.487), tot_loss_proj:2.153 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=2.077 (perp=7.603, rec=0.069, cos=0.487), tot_loss_proj:2.148 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=2.086 (perp=7.603, rec=0.078, cos=0.487), tot_loss_proj:2.136 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=2.080 (perp=7.603, rec=0.073, cos=0.487), tot_loss_proj:2.153 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=2.071 (perp=7.603, rec=0.064, cos=0.487), tot_loss_proj:2.145 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.249 | p: 92.546 | r: 94.072
rouge2     | fm: 58.565 | p: 58.428 | r: 58.659
rougeL     | fm: 79.502 | p: 79.014 | r: 80.041
rougeLsum  | fm: 79.229 | p: 78.695 | r: 79.916
r1fm+r2fm = 151.814

input #31 time: 0:08:43 | total time: 4:45:24


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.7302590625910215
highest_index [0]
highest [0.7302590625910215]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 0.9201639294624329 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9165683388710022 for ['[CLS] attacked product shown divided arsenal doctor phones eden sign she luce sam [SEP]']
[Init] best rec loss: 0.9121202826499939 for ['[CLS] spot fare studentouin than temporary song grow prize brings midst crotch [SEP]']
[Init] best rec loss: 0.9082952737808228 for ['[CLS] when was thief garrett wherever guestieg affiliate bent double pickup jerry [SEP]']
[Init] best rec loss: 0.9026999473571777 for ['[CLS] sub trials milk park casual two emma pocket breed against defending tenor [SEP]']
[Init] best rec loss: 0.890182375907898 for ['[CLS] lips let ″ forth between alongside mud inclination airport gods baptism unanimous [SEP]']
[Init] best perm rec loss: 0.8855804800987244 for ['[CLS] unanimous let ″ forth inclination between alongside gods lips airport baptism mud [SEP]']
[Init] best perm rec loss: 0.882159948348999 for ['[CLS] lips gods alongside unanimous airport baptism ″ mud let forth inclination between [SEP]']
[Init] best perm rec loss: 0.8820356726646423 for ['[CLS] unanimous baptism airport inclination lips ″ mud forth alongside let between gods [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.453 (perp=13.668, rec=0.257, cos=0.463), tot_loss_proj:4.132 [t=0.22s]
prediction: ['[CLS] create participants eruptions understanding moving rateっ seasons storiesonateity accessible [SEP]']
[ 100/2000] tot_loss=3.434 (perp=13.845, rec=0.201, cos=0.464), tot_loss_proj:4.284 [t=0.22s]
prediction: ['[CLS] pull easily easily understanding accessible presentedonate stories storiesonateityonate [SEP]']
[ 150/2000] tot_loss=3.116 (perp=12.438, rec=0.162, cos=0.466), tot_loss_proj:3.767 [t=0.22s]
prediction: ['[CLS] pull easily easily together accessible accessible res stories storiesonate withonate [SEP]']
[ 200/2000] tot_loss=2.899 (perp=11.444, rec=0.143, cos=0.468), tot_loss_proj:3.479 [t=0.22s]
prediction: ['[CLS] pull easily easily together accessible rate res stories stories with withonate [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.698 (perp=10.522, rec=0.128, cos=0.466), tot_loss_proj:3.304 [t=0.22s]
prediction: ['[CLS] pull easily easily together accessible together resonate stories with with awhile [SEP]']
[ 300/2000] tot_loss=2.664 (perp=10.432, rec=0.114, cos=0.464), tot_loss_proj:3.432 [t=0.22s]
prediction: ['[CLS] pullund easily together accessible together resonate stories that with bahn [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.514 (perp=9.732, rec=0.102, cos=0.465), tot_loss_proj:3.552 [t=0.22s]
prediction: ['[CLS] pullund easilyity stories that accessible together resonate with monty [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.537 (perp=9.921, rec=0.090, cos=0.463), tot_loss_proj:3.299 [t=0.22s]
prediction: ['[CLS] pullundity easily stories that accessible together resonate withnent [SEP]']
[ 450/2000] tot_loss=2.535 (perp=9.897, rec=0.090, cos=0.465), tot_loss_proj:3.352 [t=0.22s]
prediction: ['[CLS] pullundity easily stories that accessible together resonate withund [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.418 (perp=9.349, rec=0.082, cos=0.466), tot_loss_proj:3.357 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.417 (perp=9.349, rec=0.081, cos=0.465), tot_loss_proj:3.363 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
[ 600/2000] tot_loss=2.408 (perp=9.349, rec=0.072, cos=0.466), tot_loss_proj:3.358 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.424 (perp=9.349, rec=0.088, cos=0.466), tot_loss_proj:3.351 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.410 (perp=9.349, rec=0.074, cos=0.466), tot_loss_proj:3.356 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
[ 750/2000] tot_loss=2.419 (perp=9.349, rec=0.083, cos=0.466), tot_loss_proj:3.356 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.409 (perp=9.349, rec=0.073, cos=0.466), tot_loss_proj:3.351 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.403 (perp=9.349, rec=0.067, cos=0.466), tot_loss_proj:3.354 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
[ 900/2000] tot_loss=2.418 (perp=9.349, rec=0.082, cos=0.466), tot_loss_proj:3.351 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.400 (perp=9.349, rec=0.064, cos=0.466), tot_loss_proj:3.352 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[1000/2000] tot_loss=2.400 (perp=9.349, rec=0.064, cos=0.466), tot_loss_proj:3.350 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
[1050/2000] tot_loss=2.417 (perp=9.349, rec=0.081, cos=0.467), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[1100/2000] tot_loss=2.402 (perp=9.349, rec=0.066, cos=0.467), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[1150/2000] tot_loss=2.401 (perp=9.349, rec=0.065, cos=0.467), tot_loss_proj:3.348 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
[1200/2000] tot_loss=2.409 (perp=9.349, rec=0.073, cos=0.467), tot_loss_proj:3.347 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[1250/2000] tot_loss=2.408 (perp=9.349, rec=0.072, cos=0.467), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[1300/2000] tot_loss=2.409 (perp=9.349, rec=0.073, cos=0.467), tot_loss_proj:3.345 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
[1350/2000] tot_loss=2.408 (perp=9.349, rec=0.072, cos=0.467), tot_loss_proj:3.347 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[1400/2000] tot_loss=2.405 (perp=9.349, rec=0.069, cos=0.467), tot_loss_proj:3.347 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[1450/2000] tot_loss=2.408 (perp=9.349, rec=0.071, cos=0.467), tot_loss_proj:3.345 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
[1500/2000] tot_loss=2.410 (perp=9.349, rec=0.073, cos=0.467), tot_loss_proj:3.341 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[1550/2000] tot_loss=2.412 (perp=9.349, rec=0.075, cos=0.467), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[1600/2000] tot_loss=2.406 (perp=9.349, rec=0.070, cos=0.467), tot_loss_proj:3.338 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
[1650/2000] tot_loss=2.421 (perp=9.349, rec=0.085, cos=0.467), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[1700/2000] tot_loss=2.414 (perp=9.349, rec=0.078, cos=0.467), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withund [SEP]']
Attempt swap
[1750/2000] tot_loss=2.442 (perp=9.508, rec=0.074, cos=0.467), tot_loss_proj:3.191 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withnent [SEP]']
[1800/2000] tot_loss=2.441 (perp=9.508, rec=0.073, cos=0.467), tot_loss_proj:3.192 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withnent [SEP]']
Attempt swap
[1850/2000] tot_loss=2.441 (perp=9.508, rec=0.073, cos=0.467), tot_loss_proj:3.181 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withnent [SEP]']
Attempt swap
[1900/2000] tot_loss=2.442 (perp=9.508, rec=0.074, cos=0.467), tot_loss_proj:3.187 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withnent [SEP]']
[1950/2000] tot_loss=2.445 (perp=9.508, rec=0.076, cos=0.467), tot_loss_proj:3.186 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonate withnent [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.399 (perp=9.317, rec=0.069, cos=0.466), tot_loss_proj:3.165 [t=0.22s]
prediction: ['[CLS] pullundity stories that accessible together easily resonatenent with [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] pullundity stories that accessible together easily resonate withund [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 80.000 | r: 72.727
rouge2     | fm: 21.053 | p: 22.222 | r: 20.000
rougeL     | fm: 47.619 | p: 50.000 | r: 45.455
rougeLsum  | fm: 47.619 | p: 50.000 | r: 45.455
r1fm+r2fm = 97.243

[Aggregate metrics]:
rouge1     | fm: 92.490 | p: 91.965 | r: 93.196
rouge2     | fm: 57.207 | p: 57.148 | r: 57.325
rougeL     | fm: 78.598 | p: 78.109 | r: 79.155
rougeLsum  | fm: 78.430 | p: 78.052 | r: 78.936
r1fm+r2fm = 149.696

input #32 time: 0:08:44 | total time: 4:54:09


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.7083959623808367
highest_index [0]
highest [0.7083959623808367]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.972621738910675 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.8376016020774841 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.7758803367614746 for ['[CLS] training [SEP]']
[Init] best rec loss: 0.7566967606544495 for ['[CLS] strip [SEP]']
[Init] best rec loss: 0.732009768486023 for ['[CLS] effective [SEP]']
[Init] best rec loss: 0.7254559397697449 for ['[CLS] railroad [SEP]']
[Init] best rec loss: 0.6908103227615356 for ['[CLS] positive [SEP]']
[Init] best rec loss: 0.6544822454452515 for ['[CLS] / [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.890 (perp=11.231, rec=0.135, cos=0.508), tot_loss_proj:2.897 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.812 (perp=11.231, rec=0.069, cos=0.497), tot_loss_proj:2.853 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.797 (perp=11.231, rec=0.053, cos=0.498), tot_loss_proj:2.857 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.809 (perp=11.231, rec=0.065, cos=0.497), tot_loss_proj:2.870 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.805 (perp=11.231, rec=0.062, cos=0.497), tot_loss_proj:2.864 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.812 (perp=11.231, rec=0.068, cos=0.498), tot_loss_proj:2.853 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.808 (perp=11.231, rec=0.065, cos=0.498), tot_loss_proj:2.854 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.802 (perp=11.231, rec=0.060, cos=0.497), tot_loss_proj:2.866 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.809 (perp=11.231, rec=0.066, cos=0.497), tot_loss_proj:2.849 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.808 (perp=11.231, rec=0.064, cos=0.498), tot_loss_proj:2.857 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.807 (perp=11.231, rec=0.063, cos=0.498), tot_loss_proj:2.862 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.805 (perp=11.231, rec=0.061, cos=0.498), tot_loss_proj:2.850 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.798 (perp=11.231, rec=0.054, cos=0.498), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.815 (perp=11.231, rec=0.071, cos=0.498), tot_loss_proj:2.850 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.809 (perp=11.231, rec=0.064, cos=0.498), tot_loss_proj:2.866 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.803 (perp=11.231, rec=0.060, cos=0.497), tot_loss_proj:2.838 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.812 (perp=11.231, rec=0.069, cos=0.497), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.795 (perp=11.231, rec=0.050, cos=0.498), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.807 (perp=11.231, rec=0.063, cos=0.498), tot_loss_proj:2.853 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.805 (perp=11.231, rec=0.060, cos=0.498), tot_loss_proj:2.859 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.801 (perp=11.231, rec=0.056, cos=0.498), tot_loss_proj:2.856 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.803 (perp=11.231, rec=0.059, cos=0.498), tot_loss_proj:2.845 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.799 (perp=11.231, rec=0.055, cos=0.497), tot_loss_proj:2.845 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.793 (perp=11.231, rec=0.048, cos=0.498), tot_loss_proj:2.847 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.799 (perp=11.231, rec=0.054, cos=0.498), tot_loss_proj:2.865 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.816 (perp=11.231, rec=0.072, cos=0.498), tot_loss_proj:2.865 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.788 (perp=11.231, rec=0.044, cos=0.498), tot_loss_proj:2.850 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.800 (perp=11.231, rec=0.055, cos=0.498), tot_loss_proj:2.849 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.786 (perp=11.231, rec=0.042, cos=0.498), tot_loss_proj:2.850 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.802 (perp=11.231, rec=0.058, cos=0.498), tot_loss_proj:2.854 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.804 (perp=11.231, rec=0.060, cos=0.498), tot_loss_proj:2.853 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.814 (perp=11.231, rec=0.069, cos=0.498), tot_loss_proj:2.860 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.814 (perp=11.231, rec=0.069, cos=0.498), tot_loss_proj:2.859 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.795 (perp=11.231, rec=0.050, cos=0.498), tot_loss_proj:2.859 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.795 (perp=11.231, rec=0.051, cos=0.498), tot_loss_proj:2.840 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.803 (perp=11.231, rec=0.058, cos=0.498), tot_loss_proj:2.852 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.796 (perp=11.231, rec=0.052, cos=0.498), tot_loss_proj:2.854 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.803 (perp=11.231, rec=0.059, cos=0.498), tot_loss_proj:2.841 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.798 (perp=11.231, rec=0.054, cos=0.498), tot_loss_proj:2.839 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.812 (perp=11.231, rec=0.068, cos=0.498), tot_loss_proj:2.849 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.665 | p: 92.097 | r: 93.481
rouge2     | fm: 58.961 | p: 58.846 | r: 59.007
rougeL     | fm: 79.142 | p: 78.730 | r: 79.771
rougeLsum  | fm: 79.040 | p: 78.680 | r: 79.510
r1fm+r2fm = 151.626

input #33 time: 0:08:36 | total time: 5:02:46


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.717231920707887
highest_index [0]
highest [0.717231920707887]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8617438077926636 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8594759106636047 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8481994271278381 for ['[CLS]gut tam popular xml practice got maia accompanied gaulle dateize mc full [SEP]']
[Init] best rec loss: 0.79008948802948 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.7716354727745056 for ['[CLS] paper right ‖ allies considerations inophone nassau served molecular queen hart liv [SEP]']
[Init] best rec loss: 0.7506335973739624 for ['[CLS]truct way terminus week photos specifically dowager anime inducted valentin scotch watches watched [SEP]']
[Init] best rec loss: 0.725480318069458 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.723214328289032 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 0.7210108637809753 for ['[CLS]ibe lissa field worth founder along ship statue driversask slight who okay [SEP]']
[Init] best perm rec loss: 0.7192006707191467 for ['[CLS] founder okay along statueibe shipask drivers who worth slight lissa field [SEP]']
[Init] best perm rec loss: 0.7187168598175049 for ['[CLS] lissa worth statue along shipask slight field founder who okayibe drivers [SEP]']
[Init] best perm rec loss: 0.7175610065460205 for ['[CLS]ask founder ship lissa statueibe slight okay along drivers who field worth [SEP]']
[Init] best perm rec loss: 0.7155059576034546 for ['[CLS]ibe slight along founder who statue worth lissa ship drivers field okayask [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.802 (perp=10.381, rec=0.252, cos=0.474), tot_loss_proj:3.888 [t=0.22s]
prediction: ['[CLS] extreme frame took urgency to have urgency build extreme extreme speed terrible generally [SEP]']
[ 100/2000] tot_loss=2.877 (perp=11.249, rec=0.146, cos=0.481), tot_loss_proj:3.607 [t=0.22s]
prediction: ['[CLS] viewer about on urgency and take urgency build extreme extreme urgency urgency ) [SEP]']
[ 150/2000] tot_loss=2.566 (perp=9.835, rec=0.116, cos=0.483), tot_loss_proj:2.984 [t=0.22s]
prediction: ['[CLS] viewer viewer in urgency and take urgency build extreme mind on urgency. [SEP]']
[ 200/2000] tot_loss=2.283 (perp=8.541, rec=0.090, cos=0.485), tot_loss_proj:2.684 [t=0.22s]
prediction: ['[CLS] mind viewer in mind and take urgency build extreme mind on mind. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.580 (perp=9.435, rec=0.205, cos=0.488), tot_loss_proj:3.162 [t=0.22s]
prediction: ['[CLS] mind viewer inaging and mind urgency build extreme take on tag. [SEP]']
[ 300/2000] tot_loss=2.334 (perp=8.629, rec=0.123, cos=0.486), tot_loss_proj:2.774 [t=0.22s]
prediction: ['[CLS] mind viewer in forefront and mind urgency build extreme take on tag. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.511 (perp=9.584, rec=0.110, cos=0.485), tot_loss_proj:3.169 [t=0.22s]
prediction: ['[CLS] mind viewer inaging and tag urgency build extreme take on mind. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.315 (perp=8.686, rec=0.093, cos=0.484), tot_loss_proj:2.833 [t=0.22s]
prediction: ['[CLS] mind viewer tagaging and in urgency build extreme take on mind. [SEP]']
[ 450/2000] tot_loss=2.261 (perp=8.395, rec=0.097, cos=0.485), tot_loss_proj:2.668 [t=0.22s]
prediction: ['[CLS] mind viewer inaging and in urgency build extreme take on mind. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.148 (perp=7.911, rec=0.080, cos=0.485), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] mind viewer inaging build in urgency and extreme take on mind. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.064 (perp=7.436, rec=0.092, cos=0.484), tot_loss_proj:2.471 [t=0.22s]
prediction: ['[CLS]aging viewer in mind build in urgency and extreme take on mind. [SEP]']
[ 600/2000] tot_loss=2.142 (perp=7.813, rec=0.095, cos=0.484), tot_loss_proj:2.531 [t=0.22s]
prediction: ['[CLS]aging viewer the mind build in urgency and extreme take on mind. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.965 (perp=6.986, rec=0.084, cos=0.485), tot_loss_proj:2.382 [t=0.22s]
prediction: ['[CLS] the vieweraging mind build in urgency and extreme take on mind. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.037 (perp=7.360, rec=0.080, cos=0.485), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] the viewerates mind build in urgency and extreme take on mind. [SEP]']
[ 750/2000] tot_loss=2.034 (perp=7.360, rec=0.076, cos=0.485), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] the viewerates mind build in urgency and extreme take on mind. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.039 (perp=7.360, rec=0.082, cos=0.485), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] the viewerates mind build in urgency and extreme take on mind. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.966 (perp=6.978, rec=0.086, cos=0.485), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
[ 900/2000] tot_loss=1.964 (perp=6.978, rec=0.083, cos=0.485), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.952 (perp=6.978, rec=0.072, cos=0.485), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.959 (perp=6.978, rec=0.080, cos=0.484), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
[1050/2000] tot_loss=1.960 (perp=6.978, rec=0.079, cos=0.486), tot_loss_proj:2.345 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.962 (perp=6.978, rec=0.081, cos=0.485), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.954 (perp=6.961, rec=0.077, cos=0.485), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] the viewer buildates in mind urgency and extreme take on mind. [SEP]']
[1200/2000] tot_loss=1.958 (perp=6.961, rec=0.081, cos=0.485), tot_loss_proj:2.345 [t=0.22s]
prediction: ['[CLS] the viewer buildates in mind urgency and extreme take on mind. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.947 (perp=6.978, rec=0.066, cos=0.485), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.952 (perp=6.978, rec=0.072, cos=0.485), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
[1350/2000] tot_loss=1.958 (perp=6.978, rec=0.077, cos=0.485), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.956 (perp=6.961, rec=0.079, cos=0.485), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] the viewer buildates in mind urgency and extreme take on mind. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.952 (perp=6.978, rec=0.071, cos=0.485), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
[1500/2000] tot_loss=1.976 (perp=6.978, rec=0.095, cos=0.485), tot_loss_proj:2.340 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.956 (perp=6.978, rec=0.075, cos=0.485), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.960 (perp=6.978, rec=0.078, cos=0.486), tot_loss_proj:2.344 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
[1650/2000] tot_loss=1.949 (perp=6.978, rec=0.068, cos=0.485), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] the viewerates build in mind urgency and extreme take on mind. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.949 (perp=6.961, rec=0.072, cos=0.485), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] the viewer buildates in mind urgency and extreme take on mind. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.943 (perp=6.961, rec=0.066, cos=0.485), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] the viewer buildates in mind urgency and extreme take on mind. [SEP]']
[1800/2000] tot_loss=1.953 (perp=6.961, rec=0.075, cos=0.485), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] the viewer buildates in mind urgency and extreme take on mind. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.950 (perp=6.961, rec=0.072, cos=0.486), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] the viewer buildates in mind urgency and extreme take on mind. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.944 (perp=6.961, rec=0.067, cos=0.485), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] the viewer buildates in mind urgency and extreme take on mind. [SEP]']
[1950/2000] tot_loss=1.952 (perp=6.961, rec=0.075, cos=0.485), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] the viewer buildates in mind urgency and extreme take on mind. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.954 (perp=6.961, rec=0.076, cos=0.486), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] the viewer buildates in mind urgency and extreme take on mind. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] the viewer buildates in mind urgency and extreme take on mind. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.481 | p: 84.615 | r: 78.571
rouge2     | fm: 16.000 | p: 16.667 | r: 15.385
rougeL     | fm: 51.852 | p: 53.846 | r: 50.000
rougeLsum  | fm: 51.852 | p: 53.846 | r: 50.000
r1fm+r2fm = 97.481

[Aggregate metrics]:
rouge1     | fm: 92.439 | p: 91.987 | r: 93.011
rouge2     | fm: 57.641 | p: 57.576 | r: 57.811
rougeL     | fm: 78.510 | p: 78.118 | r: 78.952
rougeLsum  | fm: 78.261 | p: 78.011 | r: 78.762
r1fm+r2fm = 150.080

input #34 time: 0:08:45 | total time: 5:11:31


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.7315030009616932
highest_index [0]
highest [0.7315030009616932]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.8832715153694153 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.8752242922782898 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 0.864770233631134 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best rec loss: 0.8646249771118164 for ['[CLS] deputies fated pr fable about nonsense rest { reasons sat club country countries russell you whoa forest walt hollywood awaynne winning sting harm sure atop court ought mall doug condition anniversary motion design assignmentsncies arrangement jim stimulated singer wormeconomic [SEP]']
[Init] best rec loss: 0.8643801808357239 for ['[CLS] caleb supported kindly, a haulmont colt wearing level privilege gulf f chase goldsmith under derbywk dema plastic ga danger coldtor well pi less off brain answer olympia exchange awarded garland dem holding °c market champion hand mast [SEP]']
[Init] best rec loss: 0.8638322353363037 for ['[CLS] met time experience trap runaway market price totiteised prior corporation ( duplicate chris hare life release parts mine hopedropm hobbs storesborn but almost superior money conscious earth gayes driver but noel press ai neither bud section [SEP]']
[Init] best rec loss: 0.8609670996665955 for ['[CLS]work pun preserved bloodngen staff alivement ocean potter chest km² issue shares 978 lotsorestation jungle lastcript privately anywhere electric aus staff errortite ticketasian block text horse perennialbiotic fightauworth brothers snow sex cathedral bestseller [SEP]']
[Init] best perm rec loss: 0.8607129454612732 for ['[CLS] snowtite text fight brothers lastment privatelyau issue horse anywhereasian blood km² 978 block ticket alive aus sharesworkbiotic staff lots chestworth sex perennialorestation preserved electric jungle staff bestsellerngen pun ocean cathedralcript error potter [SEP]']
[Init] best perm rec loss: 0.8585666418075562 for ['[CLS]au snow bestseller perennial text aus errorbiotic fight alive staff km² ticket lots potter cathedral 978orestationcripttite jungle issue privatelyngen staff electricasian preserved pun brothersworth ocean sex horse anywherementwork shares blood chest last block [SEP]']
[Init] best perm rec loss: 0.8579047918319702 for ['[CLS] 978ment horse text electric privately brothersbiotic last errortite jungle block lots snow staffworth sex perennial blood staff punorestation km² cathedralngen ticketau ocean fight alive sharesasian aus issuecript bestseller anywhere chest preservedwork potter [SEP]']
[Init] best perm rec loss: 0.8576230406761169 for ['[CLS]workmentau bestsellerworth texttite issue 978 aus last fight perennial pun preserved aliveasian km² staff chest potter block horse jungle snow lots error privately ocean staffcript ticket anywhere sexngen shares brothers electric cathedral bloodorestationbiotic [SEP]']
[Init] best perm rec loss: 0.8556647896766663 for ['[CLS] snow chest cathedral issueau ocean errorworth block ticket pun sharescript horsebiotic privately anywhere sex electricment aus blood last brothers alive km²orestation perennial staff 978 jungleworktiteasian text bestseller lots fight potterngen staff preserved [SEP]']
[Init] best perm rec loss: 0.8547084331512451 for ['[CLS]asian potter cathedral horse lots alive electric sex staff last km² brothers puncript fightworth text blood ticketment issuengen privately staffwork ocean block shares bestseller snow aus error perennialtite anywhereorestation jungle preserved 978 chestbioticau [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.152 (perp=11.793, rec=0.340, cos=0.454), tot_loss_proj:3.683 [t=0.22s]
prediction: ["[CLS] precedent. care will river,'an greatest his this brother lieiba musical offers good purchased when foods eater helped our vintage international teacher charlotte mir century created her klein earth inuit. wine australia famous choice skill advice mystical [SEP]"]
[ 100/2000] tot_loss=3.250 (perp=11.458, rec=0.486, cos=0.472), tot_loss_proj:3.894 [t=0.22s]
prediction: ["[CLS] presley you care'] but mike'greatest his -lok lieed director director of through her foods eater makes we seen we teacher makes internet century voice around pow in seen. watch australia decades since director latest great [SEP]"]
[ 150/2000] tot_loss=3.191 (perp=10.860, rec=0.555, cos=0.464), tot_loss_proj:3.697 [t=0.23s]
prediction: ["[CLS] director. care [MASK] ] but surf'greatest ever - sister ofed director productions french beatlesggles [CLS] center make we environment. gift pace news plan administration residential technology'vision. computerage background after director investment great [SEP]"]
[ 200/2000] tot_loss=3.174 (perp=11.176, rec=0.475, cos=0.464), tot_loss_proj:3.851 [t=0.23s]
prediction: ["[CLS] the. care [MASK] ] but surf'greatest their audio sister ofed director productions french beatles photographs [CLS] center make we museum. gift site director plan administration residential technology.ie.usage dozens after director investment great [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.118 (perp=11.180, rec=0.419, cos=0.463), tot_loss_proj:3.825 [t=0.23s]
prediction: ["[CLS] the. care [MASK] tracks but featured'greatest theirage rapper ofed direction productions french beatles gigs [CLS] center makes we museumd gift site director plan administration residential biotechnology.ie.us audio dozens after director investment great [SEP]"]
[ 300/2000] tot_loss=3.117 (perp=11.328, rec=0.390, cos=0.462), tot_loss_proj:3.716 [t=0.23s]
prediction: ["[CLS] the. care [MASK] entire but featured'greatest theirage rapper ofed direction productions french beatles gigs [CLS] center makes we communityd gift site director science administration residentialieri.ie. your - dozens after director new great [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.982 (perp=10.813, rec=0.363, cos=0.457), tot_loss_proj:3.699 [t=0.23s]
prediction: ["[CLS] new. care [MASK] entire but featured'greatest theirage rapper ofed direction productions french beatles gigs. center makes we community bumper gift site director science administration residentialieri.ie. file - dozens after director the great [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.977 (perp=10.897, rec=0.338, cos=0.460), tot_loss_proj:3.669 [t=0.23s]
prediction: ["[CLS] great. care [MASK] entire but featured'greatest theirage son ofed direction director french beatlesdable. center makes we communityp pointing site director science administration residentialieri.ie. operatori dozens after director the new [SEP]"]
[ 450/2000] tot_loss=2.876 (perp=10.458, rec=0.322, cos=0.462), tot_loss_proj:3.595 [t=0.23s]
prediction: ["[CLS] great. care [MASK] entire but featured'greatest everage son ofed its director french beatlesdable. center makes we communityp pointing site director science administration residentialieri. danny. geek - dozens after director the new [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.877 (perp=10.539, rec=0.308, cos=0.461), tot_loss_proj:3.655 [t=0.23s]
prediction: ["[CLS] great. care [MASK]antly but featured'greatest everagechild ofed its isbn french beatlesdable. new makes we community vantage pointing site director science administration federalieri. interested. unai dozens after director the centre [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.879 (perp=10.589, rec=0.302, cos=0.460), tot_loss_proj:3.682 [t=0.23s]
prediction: ["[CLS] great. care [MASK]antly but featured'greatest everage rappered of its isbn french beatlesdable. new makes we community vantage pointing site director science administration federalieri. interested. una ) dozens after director the centre [SEP]"]
[ 600/2000] tot_loss=2.877 (perp=10.615, rec=0.291, cos=0.463), tot_loss_proj:3.685 [t=0.23s]
prediction: ["[CLS] great. care [MASK]antly but featured'greatest everage rappered of its isbn french beatlesdable, new makes we community vantage pointing site director science administration residentialieri. interested. una ) dozens after director the centre [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.856 (perp=10.544, rec=0.285, cos=0.462), tot_loss_proj:3.663 [t=0.23s]
prediction: ["[CLS] site [CLS] care [MASK]antly but featured'greatest everage rappered of its isbn french facilities smashwords, new makes we community vantage pointing great director science administration residentialieri. interested. una ) dozens after director'centre [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.875 (perp=10.651, rec=0.284, cos=0.460), tot_loss_proj:3.738 [t=0.23s]
prediction: ["[CLS] site [CLS] care [MASK]antly but featured'greatest everage rappered of isbn its frenchuga smashwords, new makes we community vantage pointing great director science administration residentialieri. interested. una ) dozens after director'centre [SEP]"]
[ 750/2000] tot_loss=2.886 (perp=10.747, rec=0.272, cos=0.464), tot_loss_proj:3.750 [t=0.23s]
prediction: ["[CLS] site [CLS] care [MASK]antly but featured'greatest everagechilded of isbn its french beatles smashwords, new makes we community vantage pointing great director science administration residentialieri. interested. una ) dozens after director'centre [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.821 (perp=10.420, rec=0.273, cos=0.464), tot_loss_proj:3.712 [t=0.23s]
prediction: ["[CLS] site [CLS] care [MASK]antly but featured'greatest everagechilded population isbn its frenchuga smashwords, new makes we community vantage pointing great director science administration residentialieri. interested centre never seemed dozens after director '. [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.848 (perp=10.548, rec=0.275, cos=0.464), tot_loss_proj:3.784 [t=0.23s]
prediction: ["[CLS] site [CLS] care [MASK]antly but featured'greatest everage populationdchild isbn its frenchuga smashwords, new makes we community [SEP] pointing great director science administration residentialieri. interested centre never seemed dozens after director'of [SEP]"]
[ 900/2000] tot_loss=2.838 (perp=10.530, rec=0.269, cos=0.464), tot_loss_proj:3.780 [t=0.23s]
prediction: ["[CLS] site [CLS] care [MASK]antly but featured'greatest everage ofdchild isbn its frenchuga smashwords, new makes we community [SEP] pointing great director science administration residentialieri. interested centre never seemed dozens after director'of [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.810 (perp=10.437, rec=0.259, cos=0.464), tot_loss_proj:3.753 [t=0.23s]
prediction: ["[CLS] site [CLS] care [MASK]antly but featured'greatest everage ofdchild isbn its scienceuga smashwords, new makes we community [SEP] pointing great director french administration residentialieri. interested centre never seemed dozens after director'of [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.815 (perp=10.437, rec=0.263, cos=0.464), tot_loss_proj:3.750 [t=0.23s]
prediction: ["[CLS] site [CLS] care [MASK]antly but featured'greatest everage ofdchild isbn its scienceuga smashwords, new makes we community [SEP] pointing great director french administration residentialieri. interested centre never seemed dozens after director'of [SEP]"]
[1050/2000] tot_loss=2.784 (perp=10.321, rec=0.256, cos=0.465), tot_loss_proj:3.842 [t=0.23s]
prediction: ["[CLS] site [CLS] care [MASK]antly but featured'greatest everage ofdchild isbn its scienceuga smashwords, new makes our community [SEP] pointing great director french administration residentialieri. interested centre never seemed greatest after director'of [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=2.755 (perp=10.189, rec=0.253, cos=0.464), tot_loss_proj:3.834 [t=0.23s]
prediction: ["[CLS] site [CLS] care [MASK]antly but of featured'greatest everagedchild isbn its scienceuga smashwords, new makes our community [SEP] pointing great director french administration residentialieri. interested centre never seemed greatest after director'of [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.787 (perp=10.312, rec=0.260, cos=0.464), tot_loss_proj:3.652 [t=0.23s]
prediction: ["[CLS] site [CLS] care [MASK] nedra but of featured'greatest everagedchild isbn its scienceuga smashwords, new makes our community [SEP] pointing great director french administration residentialieri. interested greatest never seemed centre after director'of [SEP]"]
[1200/2000] tot_loss=2.825 (perp=10.514, rec=0.258, cos=0.464), tot_loss_proj:3.712 [t=0.23s]
prediction: ["[CLS] sites [CLS] care [MASK] nedra but of featured'greatest everagedchild isbn its scienceuga smashwords, new makes our community [SEP] pointing great director french administration residentialieri. interested greatest never seemed centre after director'of [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.672 (perp=9.778, rec=0.255, cos=0.461), tot_loss_proj:3.540 [t=0.23s]
prediction: ["[CLS] sites pointing care [MASK] nedra but of featured'greatest everagedchild isbn its scienceuga smashwords, new makes us community [SEP] [CLS] great director french administration residentialieri. interested greatest never seemed centre after director'of [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.651 (perp=9.684, rec=0.252, cos=0.462), tot_loss_proj:3.467 [t=0.23s]
prediction: ["[CLS] sites pointing care [MASK] nedra but of featured'greatest everagedchild isbn its scienceuga smashwords, new makes us community [SEP] [CLS] great director french administration ofieri. interested greatest never seemed centre after director'residential [SEP]"]
[1350/2000] tot_loss=2.678 (perp=9.802, rec=0.254, cos=0.463), tot_loss_proj:3.487 [t=0.23s]
prediction: ["[CLS] sites pointing care [MASK] nedra but of featured'greatest everpathdchild isbn its scienceuga smashwords, new makes us community [SEP] [CLS] great director french administration ofieri. interested greatest never seemed centre after director'residential [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=2.839 (perp=10.583, rec=0.259, cos=0.464), tot_loss_proj:3.700 [t=0.23s]
prediction: ["[CLS] sites date care [MASK] nedra but of featured'greatest everpathdchild isbn its scienceugadable, new makes us community [SEP] [CLS] great director of french administrationierirock interested greatest never seemed centre after director'residential [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.778 (perp=10.317, rec=0.252, cos=0.463), tot_loss_proj:3.621 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] nedra but of featured'greatest everpathdchild isbn its scienceugadable, new makes us community [SEP] [CLS] great director of french sitesierirockie greatest never seemed centre after director'residential [SEP]"]
[1500/2000] tot_loss=2.775 (perp=10.317, rec=0.249, cos=0.463), tot_loss_proj:3.616 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] nedra but of featured'greatest everpathdchild isbn its scienceugadable, new makes us community [SEP] [CLS] great director of french sitesierirockie greatest never seemed centre after director'residential [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.735 (perp=10.089, rec=0.255, cos=0.463), tot_loss_proj:3.570 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] nedra but of featured'greatest ever residentialdchild isbn its scienceugadable, new makes us community [SEP] [CLS] great director of french sitesierirockie greatest never seemed centre after director 'path [SEP]"]
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.804 (perp=10.451, rec=0.251, cos=0.462), tot_loss_proj:3.674 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] nedra but of featured'greatest ever residentialdchildperation itsuga sciencedable, new makes us community [SEP] [CLS] great director population french sitesierirockie greatest never seemed centre after director 'path [SEP]"]
[1650/2000] tot_loss=2.801 (perp=10.451, rec=0.248, cos=0.463), tot_loss_proj:3.677 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] nedra but of featured'greatest ever residentialdchildperation itsuga sciencedable, new makes us community [SEP] [CLS] great director population french sitesierirockie greatest never seemed centre after director 'path [SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=2.702 (perp=9.958, rec=0.248, cos=0.463), tot_loss_proj:3.601 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] nedra but of featured'greatest ever residentialdchildperation itsuga sciencedable, new makes us community [SEP] [CLS] great director population frenchieri.ie sites greatest never seemed centre after director 'age [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.687 (perp=9.848, rec=0.255, cos=0.463), tot_loss_proj:3.516 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] nedra but of featured'greatest ever residentiald.peration seenuga sciencedable, new makes us community [SEP] [CLS] great director population frenchierichildie sites greatest never seemed centre after director 'path [SEP]"]
[1800/2000] tot_loss=2.667 (perp=9.789, rec=0.247, cos=0.462), tot_loss_proj:3.522 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] nedra but of featured'greatest ever residentiald.peration seenuga sciencedable, new makes us community [SEP] [CLS] great director population frenchierichildie sites greatest never seemed centre after director 'age [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.645 (perp=9.666, rec=0.250, cos=0.462), tot_loss_proj:3.455 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] nedra but of featured'greatest ever residentiald.peration seenuga sciencedable, new makes us community [SEP] [CLS] great directorage frenchierichildie sites greatest never seemed centre after director'population [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.644 (perp=9.681, rec=0.247, cos=0.461), tot_loss_proj:3.493 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] directorial but of featured'greatest ever residential centre.peration seenuga sciencedable, new makes us community [SEP] [CLS] great directorage frenchierichildie sites greatest never seemedd after director'population [SEP]"]
[1950/2000] tot_loss=2.617 (perp=9.543, rec=0.247, cos=0.462), tot_loss_proj:3.468 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] nedra but of featured'greatest ever residential centre.peration seenuga sciencedable, new makes us community [SEP] [CLS] great directorpath frenchierichildie sites greatest never seemedd after director'population [SEP]"]
Attempt swap
[2000/2000] tot_loss=2.615 (perp=9.543, rec=0.245, cos=0.462), tot_loss_proj:3.472 [t=0.23s]
prediction: ["[CLS] administration date care [MASK] nedra but of featured'greatest ever residential centre.peration seenuga sciencedable, new makes us community [SEP] [CLS] great directorpath frenchierichildie sites greatest never seemedd after director'population [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] administration date care [MASK] nedra but of featured'greatest ever residential centre.peration seenuga sciencedable, new makes us community [SEP] [CLS] great directorpath frenchierichildie sites greatest never seemedd after director'population [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 29.412 | p: 30.303 | r: 28.571
rouge2     | fm: 3.030 | p: 3.125 | r: 2.941
rougeL     | fm: 17.647 | p: 18.182 | r: 17.143
rougeLsum  | fm: 17.647 | p: 18.182 | r: 17.143
r1fm+r2fm = 32.442

[Aggregate metrics]:
rouge1     | fm: 90.606 | p: 90.148 | r: 91.124
rouge2     | fm: 55.617 | p: 55.574 | r: 55.647
rougeL     | fm: 76.795 | p: 76.445 | r: 77.223
rougeLsum  | fm: 76.682 | p: 76.368 | r: 77.006
r1fm+r2fm = 146.223

input #35 time: 0:08:56 | total time: 5:20:28


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.714027538585257
highest_index [0]
highest [0.714027538585257]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9279347062110901 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9184616804122925 for ['[CLS] oscar deep peter ground [SEP]']
[Init] best rec loss: 0.9098328351974487 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9046344757080078 for ['[CLS] addition psychofi astronomer [SEP]']
[Init] best rec loss: 0.8929482102394104 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 0.8927580714225769 for ['[CLS] viper ps they owen [SEP]']
[Init] best rec loss: 0.8614627718925476 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.8567608594894409 for ['[CLS] dormant known to mckenzie [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.548 (perp=9.433, rec=0.174, cos=0.488), tot_loss_proj:3.166 [t=0.22s]
prediction: ['[CLS] wrong horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=2.692 (perp=10.598, rec=0.084, cos=0.489), tot_loss_proj:2.955 [t=0.22s]
prediction: ['[CLS] s s wrong horribly [SEP]']
[ 150/2000] tot_loss=2.386 (perp=9.162, rec=0.065, cos=0.489), tot_loss_proj:2.563 [t=0.22s]
prediction: ["[CLS]'s wrong horribly [SEP]"]
[ 200/2000] tot_loss=2.385 (perp=9.162, rec=0.063, cos=0.490), tot_loss_proj:2.556 [t=0.22s]
prediction: ["[CLS]'s wrong horribly [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.166 (perp=8.114, rec=0.054, cos=0.489), tot_loss_proj:2.177 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 300/2000] tot_loss=2.176 (perp=8.114, rec=0.063, cos=0.490), tot_loss_proj:2.181 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 350/2000] tot_loss=2.168 (perp=8.114, rec=0.055, cos=0.490), tot_loss_proj:2.170 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 400/2000] tot_loss=2.181 (perp=8.114, rec=0.070, cos=0.488), tot_loss_proj:2.170 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 450/2000] tot_loss=2.170 (perp=8.114, rec=0.057, cos=0.490), tot_loss_proj:2.185 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 500/2000] tot_loss=2.167 (perp=8.114, rec=0.055, cos=0.490), tot_loss_proj:2.185 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 550/2000] tot_loss=2.186 (perp=8.114, rec=0.073, cos=0.490), tot_loss_proj:2.187 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 600/2000] tot_loss=2.169 (perp=8.114, rec=0.056, cos=0.490), tot_loss_proj:2.172 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 650/2000] tot_loss=2.168 (perp=8.114, rec=0.055, cos=0.490), tot_loss_proj:2.188 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 700/2000] tot_loss=2.173 (perp=8.114, rec=0.060, cos=0.490), tot_loss_proj:2.167 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 750/2000] tot_loss=2.170 (perp=8.114, rec=0.058, cos=0.489), tot_loss_proj:2.180 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 800/2000] tot_loss=2.172 (perp=8.114, rec=0.059, cos=0.490), tot_loss_proj:2.191 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 850/2000] tot_loss=2.173 (perp=8.114, rec=0.060, cos=0.490), tot_loss_proj:2.192 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 900/2000] tot_loss=2.182 (perp=8.114, rec=0.069, cos=0.490), tot_loss_proj:2.182 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 950/2000] tot_loss=2.179 (perp=8.114, rec=0.066, cos=0.490), tot_loss_proj:2.188 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1000/2000] tot_loss=2.172 (perp=8.114, rec=0.059, cos=0.490), tot_loss_proj:2.176 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1050/2000] tot_loss=2.166 (perp=8.114, rec=0.053, cos=0.490), tot_loss_proj:2.196 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1100/2000] tot_loss=2.182 (perp=8.114, rec=0.069, cos=0.490), tot_loss_proj:2.177 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1150/2000] tot_loss=2.176 (perp=8.114, rec=0.063, cos=0.490), tot_loss_proj:2.189 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1200/2000] tot_loss=2.181 (perp=8.114, rec=0.068, cos=0.490), tot_loss_proj:2.180 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1250/2000] tot_loss=2.168 (perp=8.114, rec=0.055, cos=0.490), tot_loss_proj:2.186 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1300/2000] tot_loss=2.183 (perp=8.114, rec=0.070, cos=0.490), tot_loss_proj:2.187 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1350/2000] tot_loss=2.184 (perp=8.114, rec=0.071, cos=0.490), tot_loss_proj:2.179 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1400/2000] tot_loss=2.175 (perp=8.114, rec=0.062, cos=0.490), tot_loss_proj:2.184 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1450/2000] tot_loss=2.171 (perp=8.114, rec=0.058, cos=0.490), tot_loss_proj:2.181 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1500/2000] tot_loss=2.174 (perp=8.114, rec=0.061, cos=0.490), tot_loss_proj:2.183 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1550/2000] tot_loss=2.175 (perp=8.114, rec=0.062, cos=0.490), tot_loss_proj:2.182 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1600/2000] tot_loss=2.176 (perp=8.114, rec=0.063, cos=0.490), tot_loss_proj:2.178 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1650/2000] tot_loss=2.177 (perp=8.114, rec=0.064, cos=0.490), tot_loss_proj:2.183 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1700/2000] tot_loss=2.176 (perp=8.114, rec=0.063, cos=0.490), tot_loss_proj:2.184 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1750/2000] tot_loss=2.167 (perp=8.114, rec=0.054, cos=0.490), tot_loss_proj:2.181 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1800/2000] tot_loss=2.164 (perp=8.114, rec=0.051, cos=0.490), tot_loss_proj:2.187 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1850/2000] tot_loss=2.167 (perp=8.114, rec=0.054, cos=0.490), tot_loss_proj:2.188 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1900/2000] tot_loss=2.183 (perp=8.114, rec=0.070, cos=0.490), tot_loss_proj:2.185 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1950/2000] tot_loss=2.175 (perp=8.114, rec=0.062, cos=0.490), tot_loss_proj:2.186 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[2000/2000] tot_loss=2.181 (perp=8.114, rec=0.069, cos=0.490), tot_loss_proj:2.182 [t=0.22s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS]'s horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.957 | p: 90.457 | r: 91.484
rouge2     | fm: 56.803 | p: 56.729 | r: 56.901
rougeL     | fm: 77.289 | p: 76.989 | r: 77.807
rougeLsum  | fm: 77.213 | p: 76.881 | r: 77.598
r1fm+r2fm = 147.760

input #36 time: 0:08:44 | total time: 5:29:12


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.7571030448476688
highest_index [0]
highest [0.7571030448476688]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.795680046081543 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.7664139866828918 for ['[CLS] child past [SEP]']
[Init] best rec loss: 0.7633073925971985 for ['[CLS] value commune [SEP]']
[Init] best rec loss: 0.7173528671264648 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 0.7004356384277344 for ['[CLS] appreciated why [SEP]']
[Init] best rec loss: 0.6467547416687012 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.6219959259033203 for ['[CLS] molecule buddhism [SEP]']
[Init] best rec loss: 0.6051477193832397 for ['[CLS] beer city [SEP]']
[Init] best perm rec loss: 0.6046167016029358 for ['[CLS] city beer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.799 (perp=10.822, rec=0.207, cos=0.428), tot_loss_proj:2.947 [t=0.22s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 100/2000] tot_loss=2.298 (perp=8.916, rec=0.096, cos=0.419), tot_loss_proj:2.448 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 150/2000] tot_loss=2.261 (perp=8.916, rec=0.057, cos=0.421), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 200/2000] tot_loss=2.275 (perp=8.916, rec=0.068, cos=0.424), tot_loss_proj:2.446 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.266 (perp=8.916, rec=0.058, cos=0.425), tot_loss_proj:2.447 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 300/2000] tot_loss=2.281 (perp=8.916, rec=0.072, cos=0.426), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.280 (perp=8.916, rec=0.071, cos=0.426), tot_loss_proj:2.456 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.277 (perp=8.916, rec=0.067, cos=0.426), tot_loss_proj:2.458 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 450/2000] tot_loss=2.279 (perp=8.916, rec=0.070, cos=0.426), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.270 (perp=8.916, rec=0.061, cos=0.426), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.256 (perp=8.916, rec=0.047, cos=0.426), tot_loss_proj:2.458 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 600/2000] tot_loss=2.260 (perp=8.916, rec=0.051, cos=0.426), tot_loss_proj:2.456 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.273 (perp=8.916, rec=0.064, cos=0.426), tot_loss_proj:2.461 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.276 (perp=8.916, rec=0.067, cos=0.426), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 750/2000] tot_loss=2.290 (perp=8.916, rec=0.080, cos=0.426), tot_loss_proj:2.451 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.269 (perp=8.916, rec=0.059, cos=0.426), tot_loss_proj:2.449 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.267 (perp=8.916, rec=0.058, cos=0.426), tot_loss_proj:2.446 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 900/2000] tot_loss=2.282 (perp=8.916, rec=0.073, cos=0.426), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.276 (perp=8.916, rec=0.067, cos=0.426), tot_loss_proj:2.450 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=2.278 (perp=8.916, rec=0.069, cos=0.426), tot_loss_proj:2.450 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1050/2000] tot_loss=2.282 (perp=8.916, rec=0.072, cos=0.426), tot_loss_proj:2.448 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=2.263 (perp=8.916, rec=0.053, cos=0.426), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=2.271 (perp=8.916, rec=0.062, cos=0.426), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1200/2000] tot_loss=2.278 (perp=8.916, rec=0.068, cos=0.426), tot_loss_proj:2.461 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=2.283 (perp=8.916, rec=0.073, cos=0.426), tot_loss_proj:2.446 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=2.270 (perp=8.916, rec=0.060, cos=0.426), tot_loss_proj:2.456 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1350/2000] tot_loss=2.271 (perp=8.916, rec=0.061, cos=0.426), tot_loss_proj:2.456 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=2.263 (perp=8.916, rec=0.053, cos=0.426), tot_loss_proj:2.448 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=2.285 (perp=8.916, rec=0.076, cos=0.426), tot_loss_proj:2.447 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1500/2000] tot_loss=2.274 (perp=8.916, rec=0.064, cos=0.426), tot_loss_proj:2.458 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=2.269 (perp=8.916, rec=0.060, cos=0.426), tot_loss_proj:2.449 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=2.273 (perp=8.916, rec=0.064, cos=0.426), tot_loss_proj:2.449 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1650/2000] tot_loss=2.262 (perp=8.916, rec=0.053, cos=0.426), tot_loss_proj:2.458 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=2.264 (perp=8.916, rec=0.055, cos=0.426), tot_loss_proj:2.461 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=2.262 (perp=8.916, rec=0.053, cos=0.426), tot_loss_proj:2.451 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1800/2000] tot_loss=2.271 (perp=8.916, rec=0.061, cos=0.426), tot_loss_proj:2.449 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=2.279 (perp=8.916, rec=0.069, cos=0.426), tot_loss_proj:2.460 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=2.278 (perp=8.916, rec=0.069, cos=0.426), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1950/2000] tot_loss=2.285 (perp=8.916, rec=0.076, cos=0.426), tot_loss_proj:2.448 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=2.256 (perp=8.916, rec=0.047, cos=0.426), tot_loss_proj:2.456 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] and eccentric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 91.296 | p: 90.855 | r: 91.824
rouge2     | fm: 55.614 | p: 55.538 | r: 55.721
rougeL     | fm: 77.307 | p: 76.996 | r: 77.694
rougeLsum  | fm: 77.211 | p: 76.870 | r: 77.496
r1fm+r2fm = 146.910

input #37 time: 0:08:43 | total time: 5:37:55


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.7293340813941296
highest_index [0]
highest [0.7293340813941296]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.818138837814331 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8143137097358704 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.745229184627533 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7447347640991211 for ['[CLS] pack [SEP]']
[Init] best rec loss: 0.7166527509689331 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6825417876243591 for ['[CLS] blame [SEP]']
[Init] best rec loss: 0.6668856143951416 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.393 (perp=14.070, rec=0.117, cos=0.462), tot_loss_proj:3.334 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=3.345 (perp=14.070, rec=0.065, cos=0.465), tot_loss_proj:3.348 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=3.343 (perp=14.070, rec=0.062, cos=0.467), tot_loss_proj:3.345 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=3.335 (perp=14.070, rec=0.060, cos=0.461), tot_loss_proj:3.340 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.331 (perp=14.070, rec=0.055, cos=0.463), tot_loss_proj:3.348 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=3.337 (perp=14.070, rec=0.063, cos=0.461), tot_loss_proj:3.346 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.334 (perp=14.070, rec=0.061, cos=0.459), tot_loss_proj:3.351 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.330 (perp=14.070, rec=0.052, cos=0.464), tot_loss_proj:3.343 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=3.339 (perp=14.070, rec=0.064, cos=0.461), tot_loss_proj:3.350 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.339 (perp=14.070, rec=0.064, cos=0.461), tot_loss_proj:3.334 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.332 (perp=14.070, rec=0.051, cos=0.468), tot_loss_proj:3.350 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=3.333 (perp=14.070, rec=0.052, cos=0.467), tot_loss_proj:3.342 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.333 (perp=14.070, rec=0.057, cos=0.462), tot_loss_proj:3.340 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.338 (perp=14.070, rec=0.058, cos=0.467), tot_loss_proj:3.332 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=3.334 (perp=14.070, rec=0.057, cos=0.463), tot_loss_proj:3.346 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.341 (perp=14.070, rec=0.060, cos=0.468), tot_loss_proj:3.337 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.343 (perp=14.070, rec=0.063, cos=0.465), tot_loss_proj:3.325 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=3.333 (perp=14.070, rec=0.052, cos=0.467), tot_loss_proj:3.333 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.347 (perp=14.070, rec=0.065, cos=0.468), tot_loss_proj:3.338 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=3.341 (perp=14.070, rec=0.060, cos=0.467), tot_loss_proj:3.337 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=3.338 (perp=14.070, rec=0.057, cos=0.468), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=3.344 (perp=14.070, rec=0.062, cos=0.467), tot_loss_proj:3.330 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=3.333 (perp=14.070, rec=0.051, cos=0.468), tot_loss_proj:3.342 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=3.342 (perp=14.070, rec=0.060, cos=0.468), tot_loss_proj:3.333 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=3.340 (perp=14.070, rec=0.059, cos=0.467), tot_loss_proj:3.338 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=3.340 (perp=14.070, rec=0.058, cos=0.468), tot_loss_proj:3.333 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=3.330 (perp=14.070, rec=0.052, cos=0.464), tot_loss_proj:3.352 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=3.332 (perp=14.070, rec=0.050, cos=0.468), tot_loss_proj:3.336 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=3.343 (perp=14.070, rec=0.061, cos=0.468), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=3.344 (perp=14.070, rec=0.062, cos=0.468), tot_loss_proj:3.339 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=3.336 (perp=14.070, rec=0.055, cos=0.468), tot_loss_proj:3.347 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=3.336 (perp=14.070, rec=0.054, cos=0.468), tot_loss_proj:3.329 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=3.336 (perp=14.070, rec=0.055, cos=0.468), tot_loss_proj:3.347 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=3.343 (perp=14.070, rec=0.061, cos=0.468), tot_loss_proj:3.333 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=3.323 (perp=14.070, rec=0.043, cos=0.466), tot_loss_proj:3.351 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=3.333 (perp=14.070, rec=0.051, cos=0.468), tot_loss_proj:3.332 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=3.346 (perp=14.070, rec=0.064, cos=0.468), tot_loss_proj:3.342 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=3.328 (perp=14.070, rec=0.046, cos=0.468), tot_loss_proj:3.344 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=3.333 (perp=14.070, rec=0.051, cos=0.468), tot_loss_proj:3.343 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=3.346 (perp=14.070, rec=0.064, cos=0.468), tot_loss_proj:3.340 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.381 | p: 91.065 | r: 91.907
rouge2     | fm: 56.758 | p: 56.707 | r: 56.777
rougeL     | fm: 77.741 | p: 77.413 | r: 78.221
rougeLsum  | fm: 77.723 | p: 77.423 | r: 78.183
r1fm+r2fm = 148.139

input #38 time: 0:08:36 | total time: 5:46:32


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.7305652157144327
highest_index [0]
highest [0.7305652157144327]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 0.8176106810569763 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 0.7908075451850891 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.7858830690383911 for ['[CLS] visitors polo free mn railway entitled about murderkar father states eventually some pet victory saddle fraternitypgtz raised real actresses from accelerator link [SEP]']
[Init] best rec loss: 0.7541665434837341 for ['[CLS] leaving knowlestom presents chance themes jody ge sphere intervention suffrage ewing soldert yes sabbath canada traditional became page account her rate system republic [SEP]']
[Init] best rec loss: 0.7397506833076477 for ['[CLS] transportation wrap lookiving local angus shortlistedried court taking led soon vane harmon baselineoof the meadow french jarrett alone suns fa brain shows [SEP]']
[Init] best perm rec loss: 0.7394621968269348 for ['[CLS] shortlisted court meadow soon harmon french transportation alone jarrett shows sunsiving fa baselineried wrap led look vaneoof local the taking angus brain [SEP]']
[Init] best perm rec loss: 0.7363647222518921 for ['[CLS] court jarrett suns harmonoof transportation led shortlisted taking brain shows angus french the sooniving alone baseline wrap look vane faried local meadow [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.908 (perp=10.902, rec=0.274, cos=0.454), tot_loss_proj:3.580 [t=0.22s]
prediction: ['[CLS] participants hide true boxes conservativewear gives new texture new and haired woman new new feel nicolas realm the reform philosophy an different conservative phenomenon [SEP]']
[ 100/2000] tot_loss=2.909 (perp=11.194, rec=0.209, cos=0.461), tot_loss_proj:3.779 [t=0.22s]
prediction: ['[CLS] permanent hide lessbound conservative traditions gives texture conservative newbound book excellenceouring new texture filmurable, hide relevance is new conservative reality [SEP]']
[ 150/2000] tot_loss=2.690 (perp=10.142, rec=0.194, cos=0.467), tot_loss_proj:3.588 [t=0.22s]
prediction: ['[CLS] permanent hide mostbound conservative traditions gives most texture newbound movie buddha gives new texture film texture, hide reality is finds conservative reality [SEP]']
[ 200/2000] tot_loss=2.666 (perp=10.394, rec=0.123, cos=0.465), tot_loss_proj:3.626 [t=0.22s]
prediction: ['[CLS] reality hide mostbound conservative traditions gives most texture newbound movie it and new texture, texture, hide reality our finds conservative reality [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.687 (perp=10.564, rec=0.109, cos=0.466), tot_loss_proj:3.701 [t=0.22s]
prediction: ['[CLS] reality hide most is conservative traditions gives most texture newbound movie it and new texture we texture, hide realitybound finds reality reality [SEP]']
[ 300/2000] tot_loss=2.650 (perp=10.420, rec=0.101, cos=0.464), tot_loss_proj:3.568 [t=0.22s]
prediction: ['[CLS] reality hide most my conservative traditions gives our texture newbound movie it and new texture our texture, hide realitybound finds reality reality [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.609 (perp=10.259, rec=0.092, cos=0.465), tot_loss_proj:3.726 [t=0.22s]
prediction: ['[CLS] reality hide most my conservative traditions gives and texture newbound movie it new texture and our texture, hide relevance making finds reality reality [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.552 (perp=9.974, rec=0.095, cos=0.463), tot_loss_proj:3.377 [t=0.22s]
prediction: ['[CLS] new hide most conservative. traditions gives and texture newbound movie it new texture and our texture, hide relevance making finds reality reality [SEP]']
[ 450/2000] tot_loss=2.515 (perp=9.859, rec=0.076, cos=0.467), tot_loss_proj:3.327 [t=0.22s]
prediction: ['[CLS] new hide most conservative and traditions gives and texture newbound movie it new texture and our texture, hide relevance making finds reality reality [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.429 (perp=9.432, rec=0.076, cos=0.466), tot_loss_proj:3.398 [t=0.22s]
prediction: ['[CLS] hide most conservative and new traditions gives one traditions newbound movie it new texture and our texture, hide relevance making finds reality reality [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.395 (perp=9.261, rec=0.079, cos=0.464), tot_loss_proj:3.333 [t=0.22s]
prediction: ['[CLS] hide most conservative and new traditions movie one traditions newbound gives it new texture and our texture, hide relevance making finds reality reality [SEP]']
[ 600/2000] tot_loss=2.393 (perp=9.261, rec=0.074, cos=0.466), tot_loss_proj:3.333 [t=0.22s]
prediction: ['[CLS] hide most conservative and new traditions movie one traditions newbound gives it new texture and our texture, hide relevance making finds reality reality [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.361 (perp=9.104, rec=0.074, cos=0.466), tot_loss_proj:3.383 [t=0.22s]
prediction: ['[CLS] - most conservative and our traditions movie one texture newbound gives it new texture and new texture, hide relevance making finds reality reality [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.280 (perp=8.686, rec=0.080, cos=0.463), tot_loss_proj:2.865 [t=0.22s]
prediction: ['[CLS] - most conservative and our traditions movie one texture hidebound gives it new texture and new texture, new relevance making finds reality reality [SEP]']
[ 750/2000] tot_loss=2.364 (perp=9.120, rec=0.074, cos=0.466), tot_loss_proj:2.933 [t=0.22s]
prediction: ['[CLS] - most conservative and our traditions movie one texture hidebound gives it new texture and, texture, new relevance making finds reality reality [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.209 (perp=8.376, rec=0.068, cos=0.466), tot_loss_proj:2.670 [t=0.22s]
prediction: ['[CLS] - most conservative and our traditions movie one finds hidebound gives it new texture and, texture, new relevance making texture reality reality [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.200 (perp=8.305, rec=0.075, cos=0.464), tot_loss_proj:2.652 [t=0.22s]
prediction: ['[CLS] - most conservative and our traditions movie one finds hidebound gives it new texture andkeeping, new relevance, making texture reality reality [SEP]']
[ 900/2000] tot_loss=2.194 (perp=8.305, rec=0.067, cos=0.466), tot_loss_proj:2.657 [t=0.22s]
prediction: ['[CLS] - most conservative and our traditions movie one finds hidebound gives it new texture andkeeping, new relevance, making texture reality reality [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.148 (perp=8.063, rec=0.070, cos=0.465), tot_loss_proj:2.556 [t=0.22s]
prediction: ['[CLS] most conservative - and our traditions movie one finds hidebound gives it new texture andkeeping, new relevance, making texture reality reality [SEP]']
Attempt swap
[1000/2000] tot_loss=2.143 (perp=8.063, rec=0.064, cos=0.466), tot_loss_proj:2.553 [t=0.23s]
prediction: ['[CLS] most conservative - and our traditions movie one finds hidebound gives it new texture andkeeping, new relevance, making texture reality reality [SEP]']
[1050/2000] tot_loss=2.148 (perp=8.063, rec=0.070, cos=0.466), tot_loss_proj:2.553 [t=0.22s]
prediction: ['[CLS] most conservative - and our traditions movie one finds hidebound gives it new texture andkeeping, new relevance, making texture reality reality [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.126 (perp=7.949, rec=0.070, cos=0.466), tot_loss_proj:2.598 [t=0.22s]
prediction: ['[CLS] most movie - and our traditions conservative one finds hidebound gives it new texture andkeeping, new relevance, making texture reality reality [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.085 (perp=7.729, rec=0.074, cos=0.466), tot_loss_proj:2.555 [t=0.23s]
prediction: ['[CLS] and most movie - our traditions conservative one finds hidebound gives it new texture andkeeping, new relevance, making texture reality reality [SEP]']
[1200/2000] tot_loss=2.081 (perp=7.729, rec=0.070, cos=0.466), tot_loss_proj:2.553 [t=0.22s]
prediction: ['[CLS] and most movie - our traditions conservative one finds hidebound gives it new texture andkeeping, new relevance, making texture reality reality [SEP]']
Attempt swap
[1250/2000] tot_loss=2.079 (perp=7.729, rec=0.067, cos=0.466), tot_loss_proj:2.555 [t=0.22s]
prediction: ['[CLS] and most movie - our traditions conservative one finds hidebound gives it new texture andkeeping, new relevance, making texture reality reality [SEP]']
Attempt swap
[1300/2000] tot_loss=2.082 (perp=7.729, rec=0.070, cos=0.466), tot_loss_proj:2.554 [t=0.23s]
prediction: ['[CLS] and most movie - our traditions conservative one finds hidebound gives it new texture andkeeping, new relevance, making texture reality reality [SEP]']
[1350/2000] tot_loss=2.081 (perp=7.729, rec=0.069, cos=0.466), tot_loss_proj:2.559 [t=0.22s]
prediction: ['[CLS] and most movie - our traditions conservative one finds hidebound gives it new texture andkeeping, new relevance, making texture reality reality [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.053 (perp=7.602, rec=0.067, cos=0.465), tot_loss_proj:2.533 [t=0.22s]
prediction: ['[CLS] and most movie - ourkeeping conservative one finds hidebound gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
Attempt swap
[1450/2000] tot_loss=2.057 (perp=7.602, rec=0.071, cos=0.466), tot_loss_proj:2.527 [t=0.23s]
prediction: ['[CLS] and most movie - ourkeeping conservative one finds hidebound gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
[1500/2000] tot_loss=2.053 (perp=7.602, rec=0.066, cos=0.466), tot_loss_proj:2.527 [t=0.22s]
prediction: ['[CLS] and most movie - ourkeeping conservative one finds hidebound gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.054 (perp=7.602, rec=0.068, cos=0.465), tot_loss_proj:2.529 [t=0.22s]
prediction: ['[CLS] and most movie - ourkeeping conservative one finds hidebound gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.016 (perp=7.394, rec=0.072, cos=0.466), tot_loss_proj:2.381 [t=0.22s]
prediction: ['[CLS] most movie - ourkeeping conservative one finds hidebound and gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
[1650/2000] tot_loss=2.008 (perp=7.394, rec=0.063, cos=0.466), tot_loss_proj:2.377 [t=0.22s]
prediction: ['[CLS] most movie - ourkeeping conservative one finds hidebound and gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
Attempt swap
[1700/2000] tot_loss=2.007 (perp=7.394, rec=0.062, cos=0.466), tot_loss_proj:2.380 [t=0.22s]
prediction: ['[CLS] most movie - ourkeeping conservative one finds hidebound and gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
Attempt swap
[1750/2000] tot_loss=2.015 (perp=7.394, rec=0.070, cos=0.466), tot_loss_proj:2.377 [t=0.23s]
prediction: ['[CLS] most movie - ourkeeping conservative one finds hidebound and gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
[1800/2000] tot_loss=2.011 (perp=7.394, rec=0.067, cos=0.466), tot_loss_proj:2.383 [t=0.22s]
prediction: ['[CLS] most movie - ourkeeping conservative one finds hidebound and gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
Attempt swap
[1850/2000] tot_loss=2.011 (perp=7.394, rec=0.066, cos=0.466), tot_loss_proj:2.378 [t=0.22s]
prediction: ['[CLS] most movie - ourkeeping conservative one finds hidebound and gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.006 (perp=7.345, rec=0.071, cos=0.466), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] most - our moviekeeping conservative one finds hidebound and gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
[1950/2000] tot_loss=2.000 (perp=7.345, rec=0.065, cos=0.466), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] most - our moviekeeping conservative one finds hidebound and gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
Attempt swap
[2000/2000] tot_loss=2.006 (perp=7.345, rec=0.071, cos=0.466), tot_loss_proj:2.340 [t=0.23s]
prediction: ['[CLS] most - our moviekeeping conservative one finds hidebound and gives it new texture and traditions, new relevance, making texture reality reality [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] most movie - ourkeeping conservative one finds hidebound and gives it new texture and traditions, new relevance, making texture reality reality [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.364 | p: 86.364 | r: 86.364
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 59.091 | p: 59.091 | r: 59.091
rougeLsum  | fm: 59.091 | p: 59.091 | r: 59.091
r1fm+r2fm = 114.935

[Aggregate metrics]:
rouge1     | fm: 91.337 | p: 90.928 | r: 91.826
rouge2     | fm: 56.112 | p: 56.003 | r: 56.210
rougeL     | fm: 77.438 | p: 77.120 | r: 77.832
rougeLsum  | fm: 77.313 | p: 77.046 | r: 77.650
r1fm+r2fm = 147.450

input #39 time: 0:08:53 | total time: 5:55:25


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.7243791561879744
highest_index [0]
highest [0.7243791561879744]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9424317479133606 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.935449481010437 for ['[CLS] comeback was and ste up random staff med league [SEP]']
[Init] best rec loss: 0.9292459487915039 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9252440929412842 for ['[CLS] fault union interestlden daemon : y regentience [SEP]']
[Init] best rec loss: 0.9131925702095032 for ['[CLS] taken electionsping due ce windsor undergoes labor scouts [SEP]']
[Init] best rec loss: 0.8992816805839539 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 0.8922744393348694 for ['[CLS] of transferred charlotte play troy also soon instantly was [SEP]']
[Init] best rec loss: 0.8873817920684814 for ['[CLS] false christine are greyova juniorola until thieves [SEP]']
[Init] best rec loss: 0.8784357309341431 for ['[CLS] model dr further productive show against decree reaction learning [SEP]']
[Init] best rec loss: 0.8775545954704285 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 0.8766345977783203 for ['[CLS]anto rather mor via smoke promote fearless goo burst [SEP]']
[Init] best rec loss: 0.8659306168556213 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 0.864456295967102 for ['[CLS]lum head original navigation investigatingwell position ruleduron [SEP]']
[Init] best rec loss: 0.8551578521728516 for ['[CLS] robin hemisphere # worn expensiveisticor wonder arms [SEP]']
[Init] best rec loss: 0.8438648581504822 for ['[CLS] chiefs voluntary turning era repliedfies things brendan central [SEP]']
[Init] best rec loss: 0.806242048740387 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.801100492477417 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8009927272796631 for ['[CLS] but georgian lady already abd° deciding many kent [SEP]']
[Init] best perm rec loss: 0.8009090423583984 for ['[CLS] lady but already° many deciding georgian abd kent [SEP]']
[Init] best perm rec loss: 0.8006726503372192 for ['[CLS] lady deciding but already° kent many georgian abd [SEP]']
[Init] best perm rec loss: 0.80045485496521 for ['[CLS] but already many° kent deciding abd georgian lady [SEP]']
[Init] best perm rec loss: 0.7973140478134155 for ['[CLS]° georgian lady already kent but abd many deciding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.423 (perp=13.259, rec=0.300, cos=0.472), tot_loss_proj:3.880 [t=0.22s]
prediction: ['[CLS]athic mealfummel junk [UNK] incense stupid mail [SEP]']
[ 100/2000] tot_loss=3.120 (perp=12.053, rec=0.239, cos=0.471), tot_loss_proj:3.825 [t=0.22s]
prediction: ['[CLS]ony mealranglemmel google [UNK] us ph imagery [SEP]']
[ 150/2000] tot_loss=2.921 (perp=11.318, rec=0.189, cos=0.468), tot_loss_proj:3.721 [t=0.22s]
prediction: ['[CLS]ony pummelmmeltiously us ph music [SEP]']
[ 200/2000] tot_loss=2.993 (perp=11.865, rec=0.145, cos=0.476), tot_loss_proj:3.696 [t=0.22s]
prediction: ['[CLS]ony pu pummel ph or us ph music [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.596 (perp=9.807, rec=0.168, cos=0.467), tot_loss_proj:3.507 [t=0.22s]
prediction: ['[CLS] pu pummelony ph or us ph music [SEP]']
[ 300/2000] tot_loss=2.634 (perp=10.250, rec=0.115, cos=0.469), tot_loss_proj:3.845 [t=0.22s]
prediction: ['[CLS] pu pummelony ph with us ph music [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.496 (perp=9.598, rec=0.107, cos=0.470), tot_loss_proj:3.481 [t=0.22s]
prediction: ['[CLS] pummelony ph with us ph or imagery [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.332 (perp=8.791, rec=0.105, cos=0.469), tot_loss_proj:3.400 [t=0.22s]
prediction: ['[CLS] pummelony or us with ph or imagery [SEP]']
[ 450/2000] tot_loss=2.321 (perp=8.791, rec=0.089, cos=0.474), tot_loss_proj:3.404 [t=0.22s]
prediction: ['[CLS] pummelony or us with ph or imagery [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.312 (perp=8.791, rec=0.080, cos=0.474), tot_loss_proj:3.402 [t=0.22s]
prediction: ['[CLS] pummelony or us with ph or imagery [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.195 (perp=8.120, rec=0.104, cos=0.467), tot_loss_proj:2.540 [t=0.22s]
prediction: ['[CLS] pummel or or us with phony imagery [SEP]']
[ 600/2000] tot_loss=2.177 (perp=8.120, rec=0.081, cos=0.471), tot_loss_proj:2.538 [t=0.22s]
prediction: ['[CLS] pummel or or us with phony imagery [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.061 (perp=7.543, rec=0.080, cos=0.473), tot_loss_proj:2.475 [t=0.22s]
prediction: ['[CLS] or pummel or us with phony imagery [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.957 (perp=6.962, rec=0.092, cos=0.473), tot_loss_proj:2.275 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
[ 750/2000] tot_loss=1.948 (perp=6.962, rec=0.082, cos=0.474), tot_loss_proj:2.258 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.948 (perp=6.962, rec=0.081, cos=0.474), tot_loss_proj:2.270 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.941 (perp=6.962, rec=0.074, cos=0.474), tot_loss_proj:2.266 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
[ 900/2000] tot_loss=1.937 (perp=6.962, rec=0.070, cos=0.474), tot_loss_proj:2.272 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.932 (perp=6.962, rec=0.065, cos=0.475), tot_loss_proj:2.264 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1000/2000] tot_loss=1.940 (perp=6.962, rec=0.073, cos=0.475), tot_loss_proj:2.264 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
[1050/2000] tot_loss=1.946 (perp=6.962, rec=0.079, cos=0.475), tot_loss_proj:2.267 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1100/2000] tot_loss=1.939 (perp=6.962, rec=0.072, cos=0.475), tot_loss_proj:2.260 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1150/2000] tot_loss=1.949 (perp=6.962, rec=0.082, cos=0.475), tot_loss_proj:2.265 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
[1200/2000] tot_loss=1.949 (perp=6.962, rec=0.081, cos=0.475), tot_loss_proj:2.271 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1250/2000] tot_loss=1.934 (perp=6.962, rec=0.067, cos=0.475), tot_loss_proj:2.268 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1300/2000] tot_loss=1.940 (perp=6.962, rec=0.073, cos=0.475), tot_loss_proj:2.272 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
[1350/2000] tot_loss=1.954 (perp=6.962, rec=0.087, cos=0.475), tot_loss_proj:2.266 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1400/2000] tot_loss=1.945 (perp=6.962, rec=0.077, cos=0.475), tot_loss_proj:2.265 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1450/2000] tot_loss=1.945 (perp=6.962, rec=0.077, cos=0.475), tot_loss_proj:2.269 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
[1500/2000] tot_loss=1.943 (perp=6.962, rec=0.076, cos=0.475), tot_loss_proj:2.268 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1550/2000] tot_loss=1.940 (perp=6.962, rec=0.073, cos=0.475), tot_loss_proj:2.263 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1600/2000] tot_loss=1.941 (perp=6.962, rec=0.074, cos=0.475), tot_loss_proj:2.262 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
[1650/2000] tot_loss=1.940 (perp=6.962, rec=0.072, cos=0.475), tot_loss_proj:2.268 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1700/2000] tot_loss=1.940 (perp=6.962, rec=0.073, cos=0.475), tot_loss_proj:2.260 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1750/2000] tot_loss=1.941 (perp=6.962, rec=0.074, cos=0.475), tot_loss_proj:2.262 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
[1800/2000] tot_loss=1.937 (perp=6.962, rec=0.069, cos=0.475), tot_loss_proj:2.263 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1850/2000] tot_loss=1.946 (perp=6.962, rec=0.079, cos=0.475), tot_loss_proj:2.264 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[1900/2000] tot_loss=1.935 (perp=6.962, rec=0.067, cos=0.475), tot_loss_proj:2.262 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
[1950/2000] tot_loss=1.940 (perp=6.962, rec=0.072, cos=0.475), tot_loss_proj:2.269 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Attempt swap
[2000/2000] tot_loss=1.946 (perp=6.962, rec=0.079, cos=0.475), tot_loss_proj:2.260 [t=0.22s]
prediction: ['[CLS] or pummel us with phony imagery or [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] or pummel us with phony imagery or [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 151.389

[Aggregate metrics]:
rouge1     | fm: 91.217 | p: 90.782 | r: 91.746
rouge2     | fm: 56.281 | p: 56.248 | r: 56.319
rougeL     | fm: 77.527 | p: 77.213 | r: 77.993
rougeLsum  | fm: 77.403 | p: 77.170 | r: 77.716
r1fm+r2fm = 147.498

input #40 time: 0:08:45 | total time: 6:04:10


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.7293001690617626
highest_index [0]
highest [0.7293001690617626]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.8905571699142456 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.8784943222999573 for ['[CLS] samuel conservation [SEP]']
[Init] best rec loss: 0.8754933476448059 for ['[CLS] mascara plenty [SEP]']
[Init] best rec loss: 0.850165843963623 for ['[CLS] origins pleasure [SEP]']
[Init] best rec loss: 0.7934240698814392 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 0.7918769121170044 for ['[CLS] cale fate [SEP]']
[Init] best rec loss: 0.7353222966194153 for ['[CLS] ways whether [SEP]']
[Init] best rec loss: 0.6867307424545288 for ['[CLS] usa some [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.679 (perp=10.212, rec=0.171, cos=0.466), tot_loss_proj:2.586 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.608 (perp=10.212, rec=0.098, cos=0.468), tot_loss_proj:2.574 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.582 (perp=10.212, rec=0.072, cos=0.468), tot_loss_proj:2.591 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.558 (perp=10.212, rec=0.049, cos=0.467), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.574 (perp=10.212, rec=0.064, cos=0.468), tot_loss_proj:2.598 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.577 (perp=10.212, rec=0.068, cos=0.467), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.568 (perp=10.212, rec=0.057, cos=0.468), tot_loss_proj:2.573 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.566 (perp=10.212, rec=0.056, cos=0.468), tot_loss_proj:2.586 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.557 (perp=10.212, rec=0.047, cos=0.468), tot_loss_proj:2.575 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.572 (perp=10.212, rec=0.062, cos=0.468), tot_loss_proj:2.583 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.567 (perp=10.212, rec=0.057, cos=0.468), tot_loss_proj:2.584 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.574 (perp=10.212, rec=0.063, cos=0.468), tot_loss_proj:2.590 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.575 (perp=10.212, rec=0.064, cos=0.468), tot_loss_proj:2.571 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.563 (perp=10.212, rec=0.052, cos=0.468), tot_loss_proj:2.576 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.578 (perp=10.212, rec=0.067, cos=0.468), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.578 (perp=10.212, rec=0.067, cos=0.468), tot_loss_proj:2.575 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.560 (perp=10.212, rec=0.049, cos=0.468), tot_loss_proj:2.576 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.556 (perp=10.212, rec=0.045, cos=0.468), tot_loss_proj:2.583 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.564 (perp=10.212, rec=0.053, cos=0.468), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.571 (perp=10.212, rec=0.061, cos=0.468), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.572 (perp=10.212, rec=0.061, cos=0.468), tot_loss_proj:2.595 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.566 (perp=10.212, rec=0.056, cos=0.468), tot_loss_proj:2.569 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.577 (perp=10.212, rec=0.066, cos=0.468), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.578 (perp=10.212, rec=0.067, cos=0.468), tot_loss_proj:2.575 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.569 (perp=10.212, rec=0.058, cos=0.468), tot_loss_proj:2.569 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.576 (perp=10.212, rec=0.066, cos=0.468), tot_loss_proj:2.576 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.562 (perp=10.212, rec=0.052, cos=0.468), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.583 (perp=10.212, rec=0.072, cos=0.468), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.576 (perp=10.212, rec=0.066, cos=0.468), tot_loss_proj:2.575 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.575 (perp=10.212, rec=0.064, cos=0.468), tot_loss_proj:2.570 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.566 (perp=10.212, rec=0.056, cos=0.468), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.571 (perp=10.212, rec=0.060, cos=0.468), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.577 (perp=10.212, rec=0.067, cos=0.468), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.564 (perp=10.212, rec=0.053, cos=0.468), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.568 (perp=10.212, rec=0.058, cos=0.468), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.569 (perp=10.212, rec=0.058, cos=0.468), tot_loss_proj:2.584 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.558 (perp=10.212, rec=0.047, cos=0.468), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.570 (perp=10.212, rec=0.060, cos=0.468), tot_loss_proj:2.586 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.573 (perp=10.212, rec=0.063, cos=0.468), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.575 (perp=10.212, rec=0.064, cos=0.468), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.426 | p: 91.109 | r: 91.901
rouge2     | fm: 57.397 | p: 57.296 | r: 57.467
rougeL     | fm: 78.182 | p: 77.885 | r: 78.566
rougeLsum  | fm: 78.068 | p: 77.849 | r: 78.485
r1fm+r2fm = 148.823

input #41 time: 0:08:43 | total time: 6:12:54


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.72254426158762
highest_index [0]
highest [0.72254426158762]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.8769398927688599 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8124381899833679 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8098159432411194 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8023940324783325 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.7933388948440552 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7900714874267578 for ['[CLS]ures stages treaty cut wishbe ever lifted internationaltakingrs banda offended maple kitchen larger attracted supersededplinggible assignment enough scale darectric ran [SEP]']
[Init] best perm rec loss: 0.7895709276199341 for ['[CLS] superseded assignment kitchen banda scale maple attracted offendedpling liftedrsgiblebe largerctric dareures stages cut enoughtaking treaty international ever ran wish [SEP]']
[Init] best perm rec loss: 0.788395345211029 for ['[CLS] enoughbe ran larger scaleures superseded cut everrs attracted offended stages assignment wish maplectric dare treaty internationalgible lifted bandatakingpling kitchen [SEP]']
[Init] best perm rec loss: 0.7869126796722412 for ['[CLS]giblectric scale lifted wishbe ever cut offended treaty supersededplingtaking assignment maple larger banda attracted enough darers ran stagesures kitchen international [SEP]']
[Init] best perm rec loss: 0.7867702841758728 for ['[CLS] ran lifted dareures kitchen international larger supersededrs bandabe offended wish ever cut attracted enoughgiblectric stages scaletakingpling treaty maple assignment [SEP]']
[Init] best perm rec loss: 0.7855998873710632 for ['[CLS] lifted kitchen offendedbe treaty maple scale evertaking attracted wish larger international stages supersededurespling assignment cut darectricrsgible banda enough ran [SEP]']
[Init] best perm rec loss: 0.7851929068565369 for ['[CLS] darers treaty enoughbe kitchen banda largerplingures attracted offended wish assignmenttaking ran maplegible lifted cutctric international ever scale superseded stages [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.502 (perp=13.173, rec=0.391, cos=0.477), tot_loss_proj:3.760 [t=0.22s]
prediction: ['[CLS] fails pretend by surveillance court enforcement colt phone veil poorlyfe unfortunately least for ) rushed undertaker workers arrested phone prison worst interface sprayed similarities of [SEP]']
[ 100/2000] tot_loss=3.361 (perp=13.057, rec=0.294, cos=0.455), tot_loss_proj:3.653 [t=0.22s]
prediction: ['[CLS] poorly forgot by surveillance uefa violence colt phone accidentally poorly telecom poorly least for ) phone chavez workers arrested kidnap christ kylie film occurs poorly case [SEP]']
[ 150/2000] tot_loss=3.332 (perp=13.069, rec=0.257, cos=0.461), tot_loss_proj:3.659 [t=0.23s]
prediction: ['[CLS] poorly forgot by surveillance ₹ violencerrado. scary poorly re poorly thesis for ) phone chavez workers arrested cia christ kylie film mono poorly yet [SEP]']
[ 200/2000] tot_loss=3.188 (perp=12.588, rec=0.207, cos=0.464), tot_loss_proj:3.611 [t=0.23s]
prediction: ['[CLS] forgot forgot by surveillance joyah violencerrado anything accidentally poorly as poorly homework for ) phone communications users into whenever lesbian into film corp poorlyean [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.079 (perp=12.133, rec=0.179, cos=0.474), tot_loss_proj:3.568 [t=0.23s]
prediction: ['[CLS] forgotgger by surveillance joyahggerrrado anything they poorly as poorly something for re ) phone filmmakers into attractionggergger film tar 比. [SEP]']
[ 300/2000] tot_loss=3.068 (perp=12.109, rec=0.172, cos=0.474), tot_loss_proj:3.549 [t=0.22s]
prediction: ['[CLS] forgotgger by surveillance includeggerrrado anything they poorly as poorly into for re ) cargger into attractionggergger project tar anything. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.062 (perp=12.133, rec=0.164, cos=0.471), tot_loss_proj:3.537 [t=0.23s]
prediction: ['[CLS] forgot re by hospital includeggerrrado anything theygger as poorly into for re ) detective poorly into attractionggergger filmmakers corp anything. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.940 (perp=11.520, rec=0.159, cos=0.477), tot_loss_proj:3.458 [t=0.23s]
prediction: ['[CLS] forgot re by hospital include includerrado anything they filmmakers as poorly into - re ) phone poorly into attractionggergger corp anything filmmakers. [SEP]']
[ 450/2000] tot_loss=2.895 (perp=11.386, rec=0.147, cos=0.470), tot_loss_proj:3.376 [t=0.23s]
prediction: ['[CLS] forgot re by hospital include include ecole anything they filmmakers as poorly into for re )gger poorly into attractionggergger ben anything filmmakers. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.771 (perp=10.862, rec=0.129, cos=0.470), tot_loss_proj:3.243 [t=0.23s]
prediction: ['[CLS] forgot re by hospital include include ecole anything they filmmakers as poorly into ) - regger poorly into attractionggergger ben anything filmmakers. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.694 (perp=10.496, rec=0.124, cos=0.471), tot_loss_proj:3.216 [t=0.23s]
prediction: ['[CLS] forgot by re hospital include include ecole anything they filmmakers as poorly into ) - regger poorly into attractionggergger property anything filmmakers. [SEP]']
[ 600/2000] tot_loss=2.573 (perp=9.883, rec=0.127, cos=0.470), tot_loss_proj:3.171 [t=0.23s]
prediction: ['[CLS] forgot by re hospital include include school anything they filmmakers as poorly into ) - regger poorly into attractionggergger setting anything filmmakers. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.587 (perp=9.995, rec=0.115, cos=0.474), tot_loss_proj:3.053 [t=0.22s]
prediction: ['[CLS] forgot by re hospital even include school they anything filmmakers as poorly into ) - regger poorly into attractionggergger setting anything filmmakers. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.501 (perp=9.545, rec=0.120, cos=0.472), tot_loss_proj:2.964 [t=0.23s]
prediction: ['[CLS] forgot by attraction hospital even include school they anything filmmakers as poorly into ) - regger poorly into reggergger setting anything filmmakers. [SEP]']
[ 750/2000] tot_loss=2.566 (perp=9.908, rec=0.108, cos=0.476), tot_loss_proj:3.045 [t=0.23s]
prediction: ['[CLS] forgot by attraction hospital even include school they anything filmmakers as poorly into ) - regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.568 (perp=9.908, rec=0.110, cos=0.476), tot_loss_proj:3.047 [t=0.22s]
prediction: ['[CLS] forgot by attraction hospital even include school they anything filmmakers as poorly into ) - regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.562 (perp=9.908, rec=0.107, cos=0.473), tot_loss_proj:3.058 [t=0.23s]
prediction: ['[CLS] forgot by attraction hospital even include school they anything filmmakers as poorly into ) - regger poorly intojiggergger setting anything filmmakers. [SEP]']
[ 900/2000] tot_loss=2.559 (perp=9.908, rec=0.102, cos=0.476), tot_loss_proj:3.048 [t=0.23s]
prediction: ['[CLS] forgot by attraction hospital even include school they anything filmmakers as poorly into ) - regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.469 (perp=9.500, rec=0.094, cos=0.476), tot_loss_proj:2.963 [t=0.22s]
prediction: ['[CLS] forgot by attraction hospital even include school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.475 (perp=9.500, rec=0.099, cos=0.476), tot_loss_proj:2.961 [t=0.23s]
prediction: ['[CLS] forgot by attraction hospital even include school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
[1050/2000] tot_loss=2.478 (perp=9.500, rec=0.103, cos=0.475), tot_loss_proj:2.965 [t=0.23s]
prediction: ['[CLS] forgot by attraction hospital even include school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.441 (perp=9.385, rec=0.089, cos=0.475), tot_loss_proj:2.949 [t=0.23s]
prediction: ['[CLS] forgot by attraction even include hospital school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.456 (perp=9.385, rec=0.104, cos=0.475), tot_loss_proj:2.955 [t=0.22s]
prediction: ['[CLS] forgot by attraction even include hospital school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
[1200/2000] tot_loss=2.439 (perp=9.353, rec=0.093, cos=0.475), tot_loss_proj:2.941 [t=0.22s]
prediction: ['[CLS] forgot by attraction even include police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.452 (perp=9.353, rec=0.106, cos=0.476), tot_loss_proj:2.947 [t=0.22s]
prediction: ['[CLS] forgot by attraction even include police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.449 (perp=9.353, rec=0.103, cos=0.475), tot_loss_proj:2.940 [t=0.23s]
prediction: ['[CLS] forgot by attraction even include police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
[1350/2000] tot_loss=2.435 (perp=9.353, rec=0.089, cos=0.475), tot_loss_proj:2.948 [t=0.23s]
prediction: ['[CLS] forgot by attraction even include police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.436 (perp=9.293, rec=0.101, cos=0.476), tot_loss_proj:2.928 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.434 (perp=9.293, rec=0.099, cos=0.476), tot_loss_proj:2.933 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
[1500/2000] tot_loss=2.433 (perp=9.293, rec=0.098, cos=0.476), tot_loss_proj:2.938 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.425 (perp=9.293, rec=0.090, cos=0.476), tot_loss_proj:2.930 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.435 (perp=9.293, rec=0.100, cos=0.476), tot_loss_proj:2.927 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
[1650/2000] tot_loss=2.428 (perp=9.293, rec=0.093, cos=0.476), tot_loss_proj:2.927 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.436 (perp=9.293, rec=0.101, cos=0.476), tot_loss_proj:2.928 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.427 (perp=9.293, rec=0.091, cos=0.477), tot_loss_proj:2.923 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
[1800/2000] tot_loss=2.423 (perp=9.293, rec=0.088, cos=0.476), tot_loss_proj:2.920 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.432 (perp=9.293, rec=0.096, cos=0.477), tot_loss_proj:2.929 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.441 (perp=9.293, rec=0.106, cos=0.477), tot_loss_proj:2.928 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
[1950/2000] tot_loss=2.437 (perp=9.293, rec=0.102, cos=0.477), tot_loss_proj:2.927 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.431 (perp=9.293, rec=0.095, cos=0.477), tot_loss_proj:2.931 [t=0.23s]
prediction: ['[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] forgot by attraction include even police school for anything filmmakers as poorly into ) they regger poorly intojiggergger setting anything filmmakers. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.870 | p: 63.636 | r: 58.333
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 39.130 | p: 40.909 | r: 37.500
rougeLsum  | fm: 39.130 | p: 40.909 | r: 37.500
r1fm+r2fm = 60.870

[Aggregate metrics]:
rouge1     | fm: 90.608 | p: 90.366 | r: 91.065
rouge2     | fm: 55.650 | p: 55.651 | r: 55.765
rougeL     | fm: 77.309 | p: 77.014 | r: 77.636
rougeLsum  | fm: 77.027 | p: 76.847 | r: 77.266
r1fm+r2fm = 146.258

input #42 time: 0:08:55 | total time: 6:21:49


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.7375621099867691
highest_index [0]
highest [0.7375621099867691]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9220839738845825 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.8774591684341431 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8588774800300598 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 0.8264602422714233 for ['[CLS] taken cheek willels [SEP]']
[Init] best rec loss: 0.7831829190254211 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.7601302266120911 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.742497980594635 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7126036882400513 for ['[CLS] secondck climbbus [SEP]']
[Init] best rec loss: 0.7113418579101562 for ['[CLS] related abandoned " chief [SEP]']
[Init] best perm rec loss: 0.7104997038841248 for ['[CLS] abandoned chief related " [SEP]']
[Init] best perm rec loss: 0.7092069983482361 for ['[CLS] abandoned " chief related [SEP]']
[Init] best perm rec loss: 0.7069234848022461 for ['[CLS] chief " abandoned related [SEP]']
[Init] best perm rec loss: 0.7031610608100891 for ['[CLS] chief abandoned " related [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.726 (perp=10.254, rec=0.233, cos=0.443), tot_loss_proj:3.065 [t=0.22s]
prediction: ['[CLS] na naisticistic [SEP]']
[ 100/2000] tot_loss=2.201 (perp=8.121, rec=0.128, cos=0.449), tot_loss_proj:2.560 [t=0.22s]
prediction: ['[CLS] na naissistic [SEP]']
[ 150/2000] tot_loss=1.543 (perp=5.048, rec=0.083, cos=0.451), tot_loss_proj:1.545 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 200/2000] tot_loss=1.537 (perp=5.048, rec=0.073, cos=0.454), tot_loss_proj:1.543 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.530 (perp=5.048, rec=0.065, cos=0.455), tot_loss_proj:1.544 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.548 (perp=5.048, rec=0.084, cos=0.454), tot_loss_proj:1.536 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.530 (perp=5.048, rec=0.068, cos=0.453), tot_loss_proj:1.537 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.518 (perp=5.048, rec=0.054, cos=0.454), tot_loss_proj:1.544 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.529 (perp=5.048, rec=0.064, cos=0.455), tot_loss_proj:1.538 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.524 (perp=5.048, rec=0.059, cos=0.456), tot_loss_proj:1.529 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.532 (perp=5.048, rec=0.067, cos=0.456), tot_loss_proj:1.536 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.527 (perp=5.048, rec=0.063, cos=0.455), tot_loss_proj:1.523 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.528 (perp=5.048, rec=0.063, cos=0.455), tot_loss_proj:1.533 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.516 (perp=5.048, rec=0.051, cos=0.455), tot_loss_proj:1.529 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.537 (perp=5.048, rec=0.072, cos=0.456), tot_loss_proj:1.545 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.529 (perp=5.048, rec=0.064, cos=0.456), tot_loss_proj:1.539 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.525 (perp=5.048, rec=0.060, cos=0.456), tot_loss_proj:1.528 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.520 (perp=5.048, rec=0.055, cos=0.456), tot_loss_proj:1.532 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.526 (perp=5.048, rec=0.061, cos=0.456), tot_loss_proj:1.542 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.512 (perp=5.048, rec=0.048, cos=0.455), tot_loss_proj:1.525 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.535 (perp=5.048, rec=0.069, cos=0.456), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.521 (perp=5.048, rec=0.055, cos=0.456), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.524 (perp=5.048, rec=0.058, cos=0.456), tot_loss_proj:1.533 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.534 (perp=5.048, rec=0.069, cos=0.456), tot_loss_proj:1.536 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.533 (perp=5.048, rec=0.067, cos=0.456), tot_loss_proj:1.530 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.518 (perp=5.048, rec=0.052, cos=0.456), tot_loss_proj:1.535 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.527 (perp=5.048, rec=0.062, cos=0.456), tot_loss_proj:1.531 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.529 (perp=5.048, rec=0.064, cos=0.456), tot_loss_proj:1.527 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.522 (perp=5.048, rec=0.057, cos=0.456), tot_loss_proj:1.533 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.524 (perp=5.048, rec=0.059, cos=0.456), tot_loss_proj:1.535 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.532 (perp=5.048, rec=0.067, cos=0.456), tot_loss_proj:1.543 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.526 (perp=5.048, rec=0.061, cos=0.456), tot_loss_proj:1.527 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.538 (perp=5.048, rec=0.073, cos=0.456), tot_loss_proj:1.529 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.528 (perp=5.048, rec=0.063, cos=0.456), tot_loss_proj:1.536 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.526 (perp=5.048, rec=0.061, cos=0.456), tot_loss_proj:1.537 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.532 (perp=5.048, rec=0.067, cos=0.456), tot_loss_proj:1.544 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.526 (perp=5.048, rec=0.061, cos=0.456), tot_loss_proj:1.532 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.540 (perp=5.048, rec=0.075, cos=0.456), tot_loss_proj:1.542 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.525 (perp=5.048, rec=0.060, cos=0.456), tot_loss_proj:1.539 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.518 (perp=5.048, rec=0.053, cos=0.456), tot_loss_proj:1.538 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.028 | p: 90.728 | r: 91.408
rouge2     | fm: 56.877 | p: 56.881 | r: 56.943
rougeL     | fm: 77.911 | p: 77.677 | r: 78.281
rougeLsum  | fm: 77.733 | p: 77.460 | r: 78.034
r1fm+r2fm = 147.905

input #43 time: 0:08:42 | total time: 6:30:31


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.7159819356090392
highest_index [0]
highest [0.7159819356090392]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 1.01520836353302 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 1.0046780109405518 for ['[CLS] pe grammy vague contract flow genre training willing floraux acting! dc spoke ben sami undo polo # paperplaced choon muscle duncanoat derived rat schooling [SEP]']
[Init] best rec loss: 0.9965918660163879 for ['[CLS] unitedzz golden archaeological looking forward at prime momentien before at private suspensiontone ice rim arrested evelyn surgeon shaw codes memorymobile by addition ultimatelynal mills [SEP]']
[Init] best rec loss: 0.9958874583244324 for ['[CLS] bala level branch switched entry mono harlow purchased base aegean work worse haired parliament miles milton parramatta shah one glance circuswas harbour favored l scenic inhibitors re source [SEP]']
[Init] best rec loss: 0.9927371144294739 for ['[CLS] floyd final pump make tang spoke laid royal there nix every or studied doctor reaperomba parameter minor massey framed gene diamond note band tongue safety appetite hard tate [SEP]']
[Init] best rec loss: 0.9917535185813904 for ['[CLS]hips less pronounced soaked leon overs tradition suzy diplomatic collins forgotten cells later semester brock pan husband dickinson radar would release n embankment overall evil outlookockinate toward [SEP]']
[Init] best rec loss: 0.9864636659622192 for ['[CLS] obstacles access household rave las gas revntly fellowship had rock turnpikewick isn tuesday yet magazine do up everything speculation neckagger openingiani compute occupiedoint mm [SEP]']
[Init] best rec loss: 0.9778274893760681 for ['[CLS] patriciaerinacano such currently staggered hop craft vacancy calderon rack anxious play without torpedoous major carter ghost popularity version cutterivar fifty plot parting you still sports [SEP]']
[Init] best rec loss: 0.975203275680542 for ['[CLS]lock center covenant day mercedes tyler hands times sacrament trust right recressed sheer subjects close iucn or weeks previousort different readyline times providersqualerence alabama [SEP]']
[Init] best rec loss: 0.9741918444633484 for ['[CLS]hold juryys closing mm too scholastic steele malifell rockyxa enclosed ronnie giveneros american epstein name publishing less him am aggregator revealing harmony irony trusted hourly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.539 (perp=12.422, rec=0.584, cos=0.471), tot_loss_proj:4.495 [t=0.22s]
prediction: ['[CLS] pause narrative allegro hold writing always universe homage at push reporter destroyed his craft goodes zombie claim hate production mission treatment won transformed the its share indy hourly [SEP]']
[ 100/2000] tot_loss=3.777 (perp=12.516, rec=0.723, cos=0.551), tot_loss_proj:4.196 [t=0.22s]
prediction: ['[CLS] cassandra historical a. beautiful always spirited orchestra.ness opera the deck translation success ashland themed chase slavery my tessa transformation represents killer titles its lies regularly scare [SEP]']
[ 150/2000] tot_loss=3.492 (perp=12.556, rec=0.516, cos=0.465), tot_loss_proj:4.450 [t=0.22s]
prediction: ['[CLS] rachel historicalxious but speechless always satisfying translation its in troops the them translation successpesian deliverygren peculiarzziness tumbled ⊆... titles how lies regularly¨ [SEP]']
[ 200/2000] tot_loss=3.485 (perp=12.667, rec=0.475, cos=0.476), tot_loss_proj:4.489 [t=0.22s]
prediction: ['[CLS] rachelingxious. speechless zac satisfying translation iso in is the them translation winingsesian lola azerbaijan the starred execute masovian... odd howcation based organizations [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.427 (perp=12.274, rec=0.439, cos=0.533), tot_loss_proj:4.194 [t=0.22s]
prediction: ['[CLS] theming reversed in letters laws sessions translation flemish in theatre [MASK] rachel translation key for sinatra columbia spell attack prize rescue insufficient based ruined how conversion based bodo [SEP]']
[ 300/2000] tot_loss=2.940 (perp=10.928, rec=0.275, cos=0.479), tot_loss_proj:3.563 [t=0.22s]
prediction: ['[CLS] them. hopeless. script absent life translation lost crossing.minate jenny translation key for sinatra columbia method racing convention another imperfect located beside how animation based neal [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.764 (perp=10.199, rec=0.242, cos=0.482), tot_loss_proj:3.691 [t=0.22s]
prediction: ['[CLS] them the lost. reading absent honest lost in.minate jenny translation key for sinatra which method insult routine another imperfect translation somewhere beside what animation based neal [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.577 (perp=9.507, rec=0.192, cos=0.484), tot_loss_proj:3.495 [t=0.22s]
prediction: ['[CLS] them the lost. final lost in lost in. on jenny translation key for sinatra the method neal routine another imperfect translation has beside how animation based insult [SEP]']
[ 450/2000] tot_loss=2.651 (perp=9.947, rec=0.177, cos=0.484), tot_loss_proj:3.404 [t=0.22s]
prediction: ['[CLS] them the lost. final slack in lost massacre another. porcelain translation key for sinatra the method neal slack another imperfect translation has beside an animation based insult [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.978 (perp=11.659, rec=0.164, cos=0.482), tot_loss_proj:4.223 [t=0.22s]
prediction: ['[CLS] them the lost. parentheses slack in lost premise another. porcelain translation where for sinatra the key neal slack routine slack translation been beside some animation based innovation [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.762 (perp=10.591, rec=0.162, cos=0.482), tot_loss_proj:4.048 [t=0.22s]
prediction: ['[CLS] them the lost the neal slack in lost premise another. porcelain actress where for sinatra the key parentheses slack routine slack translation been beside some animation based innovation [SEP]']
[ 600/2000] tot_loss=2.792 (perp=10.754, rec=0.156, cos=0.485), tot_loss_proj:4.119 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] neal slack in lost premise another. porcelain actress where for sinatra the key parentheses slack routine slack translation been beside some animation based innovation [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.739 (perp=10.532, rec=0.147, cos=0.486), tot_loss_proj:3.477 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] slack slack in lost premise.. porcelain hollywood where for routine the key parentheses slack routine neal translation been beside some fright based insult [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.636 (perp=10.020, rec=0.148, cos=0.484), tot_loss_proj:3.315 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] slack slack in lost premise. for routine. pity hollywood where the a parentheses slack routine neal translation been beside some fright based insult [SEP]']
[ 750/2000] tot_loss=2.668 (perp=10.183, rec=0.146, cos=0.485), tot_loss_proj:3.679 [t=0.22s]
prediction: ['[CLS] those the lost [MASK] slack slack in lost premise. for routine. pity hollywood where the a parentheses slack routine neal translation been beside some fright basedfest [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.590 (perp=9.835, rec=0.137, cos=0.486), tot_loss_proj:3.549 [t=0.22s]
prediction: ['[CLS] those the lost [MASK] slack slack in lost premise. forfest. pity hollywood where the aalic slack routine neal translation been beside some fright based routine [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.602 (perp=9.910, rec=0.133, cos=0.486), tot_loss_proj:3.576 [t=0.22s]
prediction: ['[CLS] those the lost [MASK] slack slack in lost premise. forfest. pity hollywood where a thealicalic routine neal translation been beside some fright based routine [SEP]']
[ 900/2000] tot_loss=2.673 (perp=10.306, rec=0.125, cos=0.486), tot_loss_proj:3.736 [t=0.22s]
prediction: ['[CLS] those the lost [MASK] slack slack in lost premise. forizes routinefest hollywood where a thealicalic routine neal translation been beside some fright based routine [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.643 (perp=10.106, rec=0.134, cos=0.487), tot_loss_proj:3.556 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] slack slack in lost premise. forizes anotherfest hollywood where a thealic neal routinealic translation been beside some fright based routine [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.645 (perp=10.157, rec=0.127, cos=0.486), tot_loss_proj:3.499 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] slack slack in lost premise.festalicizes anotherfest hollywood where the thealic neal routine translation been beside some fright based routine [SEP]']
[1050/2000] tot_loss=2.695 (perp=10.403, rec=0.127, cos=0.487), tot_loss_proj:3.633 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] slack slack in lost premise.festalicizes anotherfest hollywood which the thealic neal routine translation been beside some fright based routine [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.584 (perp=9.827, rec=0.132, cos=0.487), tot_loss_proj:3.388 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] slack slack in lost premise. thefestalicizes anotherfest hollywood where thealictized routine translation been beside some fright based routine [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.526 (perp=9.611, rec=0.119, cos=0.485), tot_loss_proj:3.306 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] slack slack in lost premise. thefestalicizes anotherfest hollywood routine where thealictized translation been beside some fright based routine [SEP]']
[1200/2000] tot_loss=2.528 (perp=9.611, rec=0.119, cos=0.487), tot_loss_proj:3.295 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] slack slack in lost premise. thefestalicizes anotherfest hollywood routine where thealictized translation been beside some fright based routine [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.548 (perp=9.660, rec=0.129, cos=0.487), tot_loss_proj:3.484 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] slack slack in lost premise. thefestalicizes another fright hollywood routine which thealic been translation rights beside some fright based routine [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.529 (perp=9.660, rec=0.111, cos=0.486), tot_loss_proj:3.480 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] slack slack in lost premise. thefestalicizes another fright hollywood routine which thealic been translation rights beside some fright based routine [SEP]']
[1350/2000] tot_loss=2.512 (perp=9.547, rec=0.117, cos=0.486), tot_loss_proj:3.361 [t=0.22s]
prediction: ['[CLS] them the lost [MASK] slack slack in lost premise. thefestalicizes another fright hollywood routine which thealic been translationtized beside some fright based routine [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.495 (perp=9.469, rec=0.115, cos=0.486), tot_loss_proj:3.478 [t=0.22s]
prediction: ['[CLS] them lost the [MASK] slack slack in lost premise. thefestalicizes another fright hollywood routine which thealic been translationtized beside some fright based routine [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.501 (perp=9.473, rec=0.119, cos=0.487), tot_loss_proj:3.455 [t=0.22s]
prediction: ['[CLS] them lost the slack slack the in lost premise. thefestalicizes another fright hollywood routine which thealic been translationtized beside some fright based routine [SEP]']
[1500/2000] tot_loss=2.497 (perp=9.473, rec=0.116, cos=0.487), tot_loss_proj:3.456 [t=0.22s]
prediction: ['[CLS] them lost the slack slack the in lost premise. thefestalicizes another fright hollywood routine which thealic been translationtized beside some fright based routine [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.392 (perp=8.979, rec=0.110, cos=0.486), tot_loss_proj:3.422 [t=0.22s]
prediction: ['[CLS] them lost the slack slack in the lost premise. thefestalicizes another fright hollywood routine which thealic been translationtized beside some fright based routine [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.373 (perp=8.878, rec=0.111, cos=0.486), tot_loss_proj:3.432 [t=0.22s]
prediction: ['[CLS] them lost the slack slack lost in the premise. thefestalicizes another fright hollywood routine which thealic been translationtized beside some fright based routine [SEP]']
[1650/2000] tot_loss=2.373 (perp=8.878, rec=0.111, cos=0.486), tot_loss_proj:3.431 [t=0.22s]
prediction: ['[CLS] them lost the slack slack lost in the premise. thefestalicizes another fright hollywood routine which thealic been translationtized beside some fright based routine [SEP]']
Attempt swap
[1700/2000] tot_loss=2.353 (perp=8.780, rec=0.111, cos=0.486), tot_loss_proj:3.427 [t=0.22s]
prediction: ['[CLS] them lost the slack slack lost in the premise. thefestalicizes another fright hollywood routine which the execution been translationtized beside its fright based routine [SEP]']
Attempt swap
[1750/2000] tot_loss=2.340 (perp=8.780, rec=0.097, cos=0.487), tot_loss_proj:3.431 [t=0.22s]
prediction: ['[CLS] them lost the slack slack lost in the premise. thefestalicizes another fright hollywood routine which the execution been translationtized beside its fright based routine [SEP]']
[1800/2000] tot_loss=2.346 (perp=8.780, rec=0.103, cos=0.487), tot_loss_proj:3.432 [t=0.22s]
prediction: ['[CLS] them lost the slack slack lost in the premise. thefestalicizes another fright hollywood routine which the execution been translationtized beside its fright based routine [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.349 (perp=8.780, rec=0.106, cos=0.487), tot_loss_proj:3.428 [t=0.22s]
prediction: ['[CLS] them lost the slack slack lost in the premise. thefestalicizes another fright hollywood routine which the execution been translationtized beside its fright based routine [SEP]']
Attempt swap
[1900/2000] tot_loss=2.344 (perp=8.780, rec=0.101, cos=0.487), tot_loss_proj:3.432 [t=0.22s]
prediction: ['[CLS] them lost the slack slack lost in the premise. thefestalicizes another fright hollywood routine which the execution been translationtized beside its fright based routine [SEP]']
[1950/2000] tot_loss=2.349 (perp=8.780, rec=0.106, cos=0.487), tot_loss_proj:3.429 [t=0.22s]
prediction: ['[CLS] them lost the slack slack lost in the premise. thefestalicizes another fright hollywood routine which the execution been translationtized beside its fright based routine [SEP]']
Attempt swap
[2000/2000] tot_loss=2.338 (perp=8.780, rec=0.095, cos=0.487), tot_loss_proj:3.430 [t=0.22s]
prediction: ['[CLS] them lost the slack slack lost in the premise. thefestalicizes another fright hollywood routine which the execution been translationtized beside its fright based routine [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] them lost the slack slack lost in the premise. thefestalicizes another fright hollywood routine which the execution been translationtized beside its fright based routine [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.224 | p: 57.692 | r: 65.217
rouge2     | fm: 21.277 | p: 20.000 | r: 22.727
rougeL     | fm: 40.816 | p: 38.462 | r: 43.478
rougeLsum  | fm: 40.816 | p: 38.462 | r: 43.478
r1fm+r2fm = 82.501

[Aggregate metrics]:
rouge1     | fm: 90.202 | p: 89.884 | r: 90.692
rouge2     | fm: 55.862 | p: 55.794 | r: 55.983
rougeL     | fm: 77.033 | p: 76.794 | r: 77.387
rougeLsum  | fm: 76.827 | p: 76.603 | r: 77.176
r1fm+r2fm = 146.064

input #44 time: 0:08:52 | total time: 6:39:24


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.7073540354277326
highest_index [0]
highest [0.7073540354277326]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.7747223973274231 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.7286977767944336 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.7256544828414917 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.7133620381355286 for ['[CLS] go land board preparatory hush dylan guantanamo grace really our guidesbian a2lic internet mor salad possible throughoutim between grey scaleitic around speech pri mil [SEP]']
[Init] best rec loss: 0.6806012392044067 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 0.6554187536239624 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.6552190780639648 for ['[CLS] v murmured ( special joan whoa few single letter curtis tree gentry via borelanda taste operated aroundtiv skin ku2 military football status five entrance enclosed [SEP]']
[Init] best perm rec loss: 0.6518560647964478 for ['[CLS] v bore letter gentry enclosed status skin tastetiv football ku special joan curtis military operated via single few2 whoalanda tree entrance ( five murmured around [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.327 (perp=12.745, rec=0.308, cos=0.469), tot_loss_proj:3.884 [t=0.22s]
prediction: ['[CLS] geese days station than slitut movements hours easier prison still cable perhaps probably training budgeted oldz including oil -ii particularlykey handgun around [SEP]']
[ 100/2000] tot_loss=2.849 (perp=9.870, rec=0.297, cos=0.577), tot_loss_proj:3.172 [t=0.22s]
prediction: ['[CLS] gi movements bow than -el movements days than crime drama detective than - - budgeted this - than selling - exercisemm giel than seizure [SEP]']
[ 150/2000] tot_loss=2.841 (perp=10.764, rec=0.197, cos=0.492), tot_loss_proj:3.458 [t=0.22s]
prediction: ['[CLS] bow - bow a throatel movements visits than short dramaie this in - exercise in thisry the bail - exercisemm giick than shelf [SEP]']
[ 200/2000] tot_loss=2.627 (perp=9.905, rec=0.152, cos=0.494), tot_loss_proj:3.261 [t=0.22s]
prediction: ['[CLS] bow - bow a bowel movements visits than long drama - this - - exercise in thiszy the inside - exercisemm giick - shelf [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.619 (perp=10.012, rec=0.119, cos=0.498), tot_loss_proj:3.274 [t=0.22s]
prediction: ['[CLS] bow - bow a bowel movements visits than long - shelf this - - exercise in thisy the bail - shelfmm giick drama shelf [SEP]']
[ 300/2000] tot_loss=2.547 (perp=9.724, rec=0.106, cos=0.497), tot_loss_proj:3.215 [t=0.22s]
prediction: ['[CLS] bow - bow a bowel movements visits than long - shelf this - - exercise in thisy the crime - shelfmm giick drama shelf [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.418 (perp=9.046, rec=0.111, cos=0.497), tot_loss_proj:2.972 [t=0.22s]
prediction: ['[CLS] bow - bow a -el movements visits than long - on this - - exercise in thisy shoot crime - shelfick gimm drama shelf [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.315 (perp=8.671, rec=0.088, cos=0.492), tot_loss_proj:2.822 [t=0.22s]
prediction: ['[CLS] bow - bow to -el movements visits than long - on this shoot - exercise in thisy, crime - shelfick gimm drama shelf [SEP]']
[ 450/2000] tot_loss=2.311 (perp=8.671, rec=0.081, cos=0.495), tot_loss_proj:2.826 [t=0.22s]
prediction: ['[CLS] bow - bow to -el movements visits than long - on this shoot - exercise in thisy, crime - shelfick gimm drama shelf [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.278 (perp=8.500, rec=0.084, cos=0.493), tot_loss_proj:2.718 [t=0.22s]
prediction: ['[CLS] bow - bowel to - movements visits than long - on this shoot - exercise in thisy, crime - shelfick gimm drama shelf [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.229 (perp=8.285, rec=0.077, cos=0.495), tot_loss_proj:2.682 [t=0.22s]
prediction: ['[CLS] bow - bowel - to movements visits than long - on this shoot - exercise in thisy, crime - shelfick gimm drama shelf [SEP]']
[ 600/2000] tot_loss=2.223 (perp=8.285, rec=0.069, cos=0.497), tot_loss_proj:2.686 [t=0.22s]
prediction: ['[CLS] bow - bowel - to movements visits than long - on this shoot - exercise in thisy, crime - shelfick gimm drama shelf [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.211 (perp=8.166, rec=0.079, cos=0.499), tot_loss_proj:2.649 [t=0.22s]
prediction: ['[CLS] bow - bowel - to movements places than long - on this shoot - exercise in thisy, crime - shelfick gimm drama shelf [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.183 (perp=8.062, rec=0.073, cos=0.497), tot_loss_proj:2.644 [t=0.22s]
prediction: ['[CLS] bow - bowel - to movements, than long - on - shoot - exercise in thisy places crime - shelfick gimm drama shelf [SEP]']
[ 750/2000] tot_loss=2.198 (perp=8.126, rec=0.074, cos=0.499), tot_loss_proj:2.626 [t=0.22s]
prediction: ['[CLS] bow - bowel - and movements, than long - on - shoot - exercise in thisy places crime - shelfick gimm drama shelf [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.223 (perp=8.254, rec=0.073, cos=0.499), tot_loss_proj:2.673 [t=0.22s]
prediction: ['[CLS] bow - bowel - and movements, than long - on - shoot - exercise in thisy places crime - shelfick gimm drama point [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.159 (perp=7.919, rec=0.079, cos=0.496), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - - shelfick gimm drama point [SEP]']
[ 900/2000] tot_loss=2.158 (perp=7.919, rec=0.077, cos=0.498), tot_loss_proj:2.614 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - - shelfick gimm drama point [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.159 (perp=7.919, rec=0.076, cos=0.499), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - - shelfick gimm drama point [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.036 (perp=7.357, rec=0.070, cos=0.494), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - - shelf gimmick drama point [SEP]']
[1050/2000] tot_loss=2.036 (perp=7.357, rec=0.065, cos=0.499), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - - shelf gimmick drama point [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.023 (perp=7.261, rec=0.073, cos=0.498), tot_loss_proj:2.373 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - - shelf gimmick point drama [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.968 (perp=6.992, rec=0.074, cos=0.495), tot_loss_proj:2.312 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - shelf gimmick - point drama [SEP]']
[1200/2000] tot_loss=1.963 (perp=6.992, rec=0.066, cos=0.499), tot_loss_proj:2.309 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - shelf gimmick - point drama [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.968 (perp=6.992, rec=0.071, cos=0.498), tot_loss_proj:2.309 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - shelf gimmick - point drama [SEP]']
Attempt swap
[1300/2000] tot_loss=1.964 (perp=6.992, rec=0.067, cos=0.499), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - shelf gimmick - point drama [SEP]']
[1350/2000] tot_loss=1.966 (perp=6.992, rec=0.069, cos=0.499), tot_loss_proj:2.307 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - shelf gimmick - point drama [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.934 (perp=6.823, rec=0.071, cos=0.499), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - point shelf drama [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.914 (perp=6.760, rec=0.069, cos=0.493), tot_loss_proj:2.311 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
[1500/2000] tot_loss=1.911 (perp=6.760, rec=0.062, cos=0.497), tot_loss_proj:2.311 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
Attempt swap
[1550/2000] tot_loss=1.918 (perp=6.760, rec=0.069, cos=0.498), tot_loss_proj:2.314 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
Attempt swap
[1600/2000] tot_loss=1.913 (perp=6.760, rec=0.063, cos=0.498), tot_loss_proj:2.315 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
[1650/2000] tot_loss=1.916 (perp=6.760, rec=0.065, cos=0.498), tot_loss_proj:2.316 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
Attempt swap
[1700/2000] tot_loss=1.923 (perp=6.760, rec=0.072, cos=0.499), tot_loss_proj:2.318 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
Attempt swap
[1750/2000] tot_loss=1.922 (perp=6.760, rec=0.071, cos=0.499), tot_loss_proj:2.318 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
[1800/2000] tot_loss=1.924 (perp=6.760, rec=0.073, cos=0.499), tot_loss_proj:2.318 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.912 (perp=6.760, rec=0.062, cos=0.499), tot_loss_proj:2.323 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
Attempt swap
[1900/2000] tot_loss=1.922 (perp=6.760, rec=0.071, cos=0.499), tot_loss_proj:2.317 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
[1950/2000] tot_loss=1.915 (perp=6.760, rec=0.064, cos=0.499), tot_loss_proj:2.321 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.911 (perp=6.723, rec=0.068, cos=0.499), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] bow - bowel crime and movements - than long - on, shoot - exercise in thisy places - gimmick - drama shelf point [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] bow - bowel crime and movements, than long - on - shoot - exercise in thisy places - gimmick - drama shelf point [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.081 | p: 78.947 | r: 83.333
rouge2     | fm: 28.571 | p: 27.778 | r: 29.412
rougeL     | fm: 59.459 | p: 57.895 | r: 61.111
rougeLsum  | fm: 59.459 | p: 57.895 | r: 61.111
r1fm+r2fm = 109.653

[Aggregate metrics]:
rouge1     | fm: 90.042 | p: 89.657 | r: 90.562
rouge2     | fm: 55.409 | p: 55.291 | r: 55.516
rougeL     | fm: 76.655 | p: 76.360 | r: 77.078
rougeLsum  | fm: 76.572 | p: 76.217 | r: 76.981
r1fm+r2fm = 145.451

input #45 time: 0:08:52 | total time: 6:48:16


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.7239596482084818
highest_index [0]
highest [0.7239596482084818]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9509686231613159 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9503582715988159 for ['[CLS] medicine follows idol cereal run active [SEP]']
[Init] best rec loss: 0.9487282633781433 for ['[CLS] upcoming trim grease settled g dallas [SEP]']
[Init] best rec loss: 0.9259445667266846 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9214290976524353 for ['[CLS] autism prince angles luna objectshol [SEP]']
[Init] best rec loss: 0.9188712239265442 for ['[CLS] giants alley told hurricane und : [SEP]']
[Init] best perm rec loss: 0.9175146818161011 for ['[CLS] giants : hurricane und told alley [SEP]']
[Init] best perm rec loss: 0.9173731207847595 for ['[CLS] alley told giants hurricane : und [SEP]']
[Init] best perm rec loss: 0.9145958423614502 for ['[CLS] : giants told hurricane alley und [SEP]']
[Init] best perm rec loss: 0.911892294883728 for ['[CLS] told hurricane und giants : alley [SEP]']
[Init] best perm rec loss: 0.9113026857376099 for ['[CLS] hurricane : und told alley giants [SEP]']
[Init] best perm rec loss: 0.9108107686042786 for ['[CLS] told giants : und hurricane alley [SEP]']
[Init] best perm rec loss: 0.9096928238868713 for ['[CLS] hurricane alley : giants told und [SEP]']
[Init] best perm rec loss: 0.90887451171875 for ['[CLS] : hurricane giants told alley und [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.056 (perp=11.919, rec=0.210, cos=0.462), tot_loss_proj:3.624 [t=0.22s]
prediction: ['[CLS] staged striking and visual celeste visually [SEP]']
[ 100/2000] tot_loss=2.556 (perp=9.772, rec=0.137, cos=0.464), tot_loss_proj:3.092 [t=0.22s]
prediction: ['[CLS] staged striking and stagedly visually [SEP]']
[ 150/2000] tot_loss=2.535 (perp=9.772, rec=0.117, cos=0.464), tot_loss_proj:3.094 [t=0.22s]
prediction: ['[CLS] staged striking and stagedly visually [SEP]']
[ 200/2000] tot_loss=2.529 (perp=9.772, rec=0.111, cos=0.464), tot_loss_proj:3.089 [t=0.22s]
prediction: ['[CLS] staged striking and stagedly visually [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.774 (perp=5.916, rec=0.130, cos=0.461), tot_loss_proj:1.730 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 300/2000] tot_loss=1.748 (perp=5.916, rec=0.101, cos=0.464), tot_loss_proj:1.730 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.748 (perp=5.916, rec=0.098, cos=0.466), tot_loss_proj:1.731 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.735 (perp=5.916, rec=0.085, cos=0.467), tot_loss_proj:1.726 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 450/2000] tot_loss=1.848 (perp=6.442, rec=0.092, cos=0.467), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.841 (perp=6.442, rec=0.085, cos=0.467), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.835 (perp=6.442, rec=0.079, cos=0.467), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[ 600/2000] tot_loss=1.836 (perp=6.442, rec=0.081, cos=0.467), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.846 (perp=6.442, rec=0.091, cos=0.467), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.830 (perp=6.442, rec=0.074, cos=0.467), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[ 750/2000] tot_loss=1.828 (perp=6.442, rec=0.073, cos=0.467), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.835 (perp=6.442, rec=0.080, cos=0.467), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.826 (perp=6.442, rec=0.071, cos=0.467), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[ 900/2000] tot_loss=1.830 (perp=6.442, rec=0.074, cos=0.467), tot_loss_proj:1.980 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.844 (perp=6.442, rec=0.089, cos=0.467), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.837 (perp=6.442, rec=0.082, cos=0.467), tot_loss_proj:1.985 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[1050/2000] tot_loss=1.834 (perp=6.442, rec=0.079, cos=0.467), tot_loss_proj:1.989 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.832 (perp=6.442, rec=0.077, cos=0.467), tot_loss_proj:1.982 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.835 (perp=6.442, rec=0.080, cos=0.467), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[1200/2000] tot_loss=1.830 (perp=6.442, rec=0.075, cos=0.467), tot_loss_proj:1.985 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.840 (perp=6.442, rec=0.085, cos=0.467), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.835 (perp=6.442, rec=0.079, cos=0.467), tot_loss_proj:1.983 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[1350/2000] tot_loss=1.837 (perp=6.442, rec=0.082, cos=0.467), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.839 (perp=6.442, rec=0.083, cos=0.467), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.849 (perp=6.442, rec=0.093, cos=0.467), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[1500/2000] tot_loss=1.833 (perp=6.442, rec=0.078, cos=0.467), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.834 (perp=6.442, rec=0.079, cos=0.467), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.841 (perp=6.442, rec=0.085, cos=0.467), tot_loss_proj:1.985 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[1650/2000] tot_loss=1.839 (perp=6.442, rec=0.084, cos=0.467), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.824 (perp=6.442, rec=0.068, cos=0.467), tot_loss_proj:1.991 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.836 (perp=6.442, rec=0.081, cos=0.467), tot_loss_proj:1.968 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[1800/2000] tot_loss=1.838 (perp=6.442, rec=0.083, cos=0.467), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.830 (perp=6.442, rec=0.075, cos=0.467), tot_loss_proj:1.974 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.826 (perp=6.442, rec=0.071, cos=0.467), tot_loss_proj:1.982 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[1950/2000] tot_loss=1.831 (perp=6.442, rec=0.076, cos=0.467), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.840 (perp=6.442, rec=0.085, cos=0.467), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually strikingly slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 54.545 | p: 60.000 | r: 50.000
rougeL     | fm: 76.923 | p: 83.333 | r: 71.429
rougeLsum  | fm: 76.923 | p: 83.333 | r: 71.429
r1fm+r2fm = 131.469

[Aggregate metrics]:
rouge1     | fm: 89.780 | p: 89.471 | r: 90.254
rouge2     | fm: 55.784 | p: 55.864 | r: 55.735
rougeL     | fm: 76.560 | p: 76.339 | r: 76.796
rougeLsum  | fm: 76.317 | p: 76.125 | r: 76.595
r1fm+r2fm = 145.564

input #46 time: 0:08:44 | total time: 6:57:00


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.7351441988020744
highest_index [0]
highest [0.7351441988020744]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6772747039794922 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.65545654296875 for ['[CLS] spent excitedlychule [SEP]']
[Init] best rec loss: 0.6486948728561401 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6463295817375183 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.6439242362976074 for ['[CLS] desert elementsfulness [SEP]']
[Init] best rec loss: 0.630418598651886 for ['[CLS] we processgon [SEP]']
[Init] best perm rec loss: 0.6296221613883972 for ['[CLS] processgon we [SEP]']
[Init] best perm rec loss: 0.6276240944862366 for ['[CLS] wegon process [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.195 (perp=12.775, rec=0.197, cos=0.443), tot_loss_proj:3.638 [t=0.22s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 100/2000] tot_loss=3.085 (perp=12.723, rec=0.105, cos=0.436), tot_loss_proj:3.541 [t=0.22s]
prediction: ['[CLS]rightright transparent [SEP]']
[ 150/2000] tot_loss=3.094 (perp=12.723, rec=0.099, cos=0.451), tot_loss_proj:3.522 [t=0.22s]
prediction: ['[CLS]rightright transparent [SEP]']
[ 200/2000] tot_loss=2.303 (perp=8.803, rec=0.087, cos=0.456), tot_loss_proj:2.317 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.273 (perp=8.803, rec=0.061, cos=0.452), tot_loss_proj:2.319 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[ 300/2000] tot_loss=2.269 (perp=8.803, rec=0.056, cos=0.453), tot_loss_proj:2.319 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.274 (perp=8.803, rec=0.061, cos=0.452), tot_loss_proj:2.320 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.289 (perp=8.803, rec=0.079, cos=0.450), tot_loss_proj:2.321 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[ 450/2000] tot_loss=2.271 (perp=8.803, rec=0.062, cos=0.449), tot_loss_proj:2.324 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.286 (perp=8.803, rec=0.067, cos=0.459), tot_loss_proj:2.302 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.282 (perp=8.803, rec=0.065, cos=0.457), tot_loss_proj:2.317 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=2.280 (perp=8.803, rec=0.060, cos=0.459), tot_loss_proj:2.321 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.280 (perp=8.803, rec=0.061, cos=0.458), tot_loss_proj:2.315 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.275 (perp=8.803, rec=0.065, cos=0.450), tot_loss_proj:2.298 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=2.276 (perp=8.803, rec=0.058, cos=0.458), tot_loss_proj:2.303 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.282 (perp=8.803, rec=0.063, cos=0.458), tot_loss_proj:2.301 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.275 (perp=8.803, rec=0.055, cos=0.459), tot_loss_proj:2.311 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=2.266 (perp=8.803, rec=0.055, cos=0.451), tot_loss_proj:2.306 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.280 (perp=8.803, rec=0.060, cos=0.459), tot_loss_proj:2.304 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=2.284 (perp=8.803, rec=0.065, cos=0.459), tot_loss_proj:2.299 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=2.277 (perp=8.803, rec=0.058, cos=0.459), tot_loss_proj:2.289 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=2.291 (perp=8.803, rec=0.072, cos=0.459), tot_loss_proj:2.307 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=2.272 (perp=8.803, rec=0.055, cos=0.456), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=2.278 (perp=8.803, rec=0.059, cos=0.459), tot_loss_proj:2.299 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=2.289 (perp=8.803, rec=0.070, cos=0.459), tot_loss_proj:2.312 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=2.288 (perp=8.803, rec=0.068, cos=0.459), tot_loss_proj:2.294 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=2.287 (perp=8.803, rec=0.068, cos=0.459), tot_loss_proj:2.297 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=2.283 (perp=8.803, rec=0.063, cos=0.459), tot_loss_proj:2.303 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=2.280 (perp=8.803, rec=0.060, cos=0.459), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=2.276 (perp=8.803, rec=0.056, cos=0.459), tot_loss_proj:2.296 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=2.286 (perp=8.803, rec=0.070, cos=0.456), tot_loss_proj:2.313 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=2.291 (perp=8.803, rec=0.072, cos=0.459), tot_loss_proj:2.309 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=2.274 (perp=8.803, rec=0.055, cos=0.459), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=2.294 (perp=8.803, rec=0.074, cos=0.459), tot_loss_proj:2.319 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=2.288 (perp=8.803, rec=0.068, cos=0.459), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=2.287 (perp=8.803, rec=0.068, cos=0.459), tot_loss_proj:2.303 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=2.284 (perp=8.803, rec=0.064, cos=0.459), tot_loss_proj:2.305 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=2.270 (perp=8.803, rec=0.050, cos=0.459), tot_loss_proj:2.296 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=2.293 (perp=8.803, rec=0.076, cos=0.457), tot_loss_proj:2.314 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=2.288 (perp=8.803, rec=0.069, cos=0.458), tot_loss_proj:2.307 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.940 | p: 89.702 | r: 90.340
rouge2     | fm: 56.492 | p: 56.502 | r: 56.497
rougeL     | fm: 77.070 | p: 76.881 | r: 77.369
rougeLsum  | fm: 76.942 | p: 76.752 | r: 77.232
r1fm+r2fm = 146.431

input #47 time: 0:08:43 | total time: 7:05:43


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.7212842815803282
highest_index [0]
highest [0.7212842815803282]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.8542757034301758 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.8391019105911255 for ['[CLS] however stage arts grounds [SEP]']
[Init] best rec loss: 0.8338603973388672 for ['[CLS] tonightste breadim [SEP]']
[Init] best rec loss: 0.7915568947792053 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 0.7827121019363403 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7823594212532043 for ['[CLS] runs graveyarddinetute [SEP]']
[Init] best perm rec loss: 0.78182053565979 for ['[CLS] graveyarddinetute runs [SEP]']
[Init] best perm rec loss: 0.7805005311965942 for ['[CLS]dine runs graveyardtute [SEP]']
[Init] best perm rec loss: 0.7800799608230591 for ['[CLS]tute graveyarddine runs [SEP]']
[Init] best perm rec loss: 0.77949458360672 for ['[CLS]tute graveyard runsdine [SEP]']
[Init] best perm rec loss: 0.7789808511734009 for ['[CLS] runstute graveyarddine [SEP]']
[Init] best perm rec loss: 0.7787010073661804 for ['[CLS]dine graveyard runstute [SEP]']
[Init] best perm rec loss: 0.7777588963508606 for ['[CLS] runstutedine graveyard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.058 (perp=11.834, rec=0.213, cos=0.478), tot_loss_proj:3.309 [t=0.22s]
prediction: ['[CLS] rotting waste rottinging [SEP]']
[ 100/2000] tot_loss=3.042 (perp=12.187, rec=0.128, cos=0.476), tot_loss_proj:3.254 [t=0.22s]
prediction: ['[CLS] rotting under undery [SEP]']
[ 150/2000] tot_loss=1.978 (perp=7.107, rec=0.080, cos=0.477), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 200/2000] tot_loss=1.953 (perp=7.107, rec=0.055, cos=0.477), tot_loss_proj:1.963 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.971 (perp=7.107, rec=0.070, cos=0.479), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 300/2000] tot_loss=1.955 (perp=7.107, rec=0.056, cos=0.478), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.966 (perp=7.107, rec=0.065, cos=0.479), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.968 (perp=7.107, rec=0.067, cos=0.479), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 450/2000] tot_loss=1.954 (perp=7.107, rec=0.053, cos=0.479), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.961 (perp=7.107, rec=0.060, cos=0.479), tot_loss_proj:1.961 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.966 (perp=7.107, rec=0.066, cos=0.479), tot_loss_proj:1.957 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 600/2000] tot_loss=1.971 (perp=7.107, rec=0.070, cos=0.480), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.960 (perp=7.107, rec=0.059, cos=0.480), tot_loss_proj:1.980 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.967 (perp=7.107, rec=0.066, cos=0.480), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 750/2000] tot_loss=1.962 (perp=7.107, rec=0.061, cos=0.480), tot_loss_proj:1.968 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.958 (perp=7.107, rec=0.057, cos=0.480), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.956 (perp=7.107, rec=0.056, cos=0.479), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 900/2000] tot_loss=1.956 (perp=7.107, rec=0.055, cos=0.480), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.958 (perp=7.107, rec=0.057, cos=0.480), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.968 (perp=7.107, rec=0.067, cos=0.479), tot_loss_proj:1.959 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1050/2000] tot_loss=1.965 (perp=7.107, rec=0.064, cos=0.480), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.966 (perp=7.107, rec=0.065, cos=0.480), tot_loss_proj:1.962 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.963 (perp=7.107, rec=0.062, cos=0.479), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1200/2000] tot_loss=1.965 (perp=7.107, rec=0.064, cos=0.480), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.965 (perp=7.107, rec=0.064, cos=0.480), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.960 (perp=7.107, rec=0.059, cos=0.480), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1350/2000] tot_loss=1.972 (perp=7.107, rec=0.072, cos=0.479), tot_loss_proj:1.968 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.970 (perp=7.107, rec=0.069, cos=0.480), tot_loss_proj:1.974 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.964 (perp=7.107, rec=0.063, cos=0.480), tot_loss_proj:1.965 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1500/2000] tot_loss=1.966 (perp=7.107, rec=0.065, cos=0.480), tot_loss_proj:1.968 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.961 (perp=7.107, rec=0.060, cos=0.480), tot_loss_proj:1.961 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.959 (perp=7.107, rec=0.058, cos=0.480), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1650/2000] tot_loss=1.962 (perp=7.107, rec=0.061, cos=0.480), tot_loss_proj:1.965 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.951 (perp=7.107, rec=0.050, cos=0.480), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.959 (perp=7.107, rec=0.059, cos=0.479), tot_loss_proj:1.958 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1800/2000] tot_loss=1.958 (perp=7.107, rec=0.056, cos=0.480), tot_loss_proj:1.965 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.960 (perp=7.107, rec=0.059, cos=0.480), tot_loss_proj:1.965 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.961 (perp=7.107, rec=0.060, cos=0.480), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1950/2000] tot_loss=1.961 (perp=7.107, rec=0.059, cos=0.480), tot_loss_proj:1.970 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.964 (perp=7.107, rec=0.063, cos=0.480), tot_loss_proj:1.947 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] rotting underbelly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.290 | p: 89.986 | r: 90.636
rouge2     | fm: 57.266 | p: 57.299 | r: 57.219
rougeL     | fm: 77.471 | p: 77.345 | r: 77.826
rougeLsum  | fm: 77.594 | p: 77.430 | r: 77.726
r1fm+r2fm = 147.557

input #48 time: 0:08:44 | total time: 7:14:27


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.7461824913512154
highest_index [0]
highest [0.7461824913512154]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8180716633796692 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.790533185005188 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7821250557899475 for ['[CLS] chargesbered harsh today dion craftsuvenssen tool break backup guest [SEP]']
[Init] best rec loss: 0.7719269394874573 for ['[CLS] genetic slideactic nations shed lawrence oral like era calvin accept mentor [SEP]']
[Init] best rec loss: 0.7663261890411377 for ['[CLS] in before car lend only surprise securities radiation following montagu turkishpers [SEP]']
[Init] best rec loss: 0.7600570321083069 for ['[CLS] pyrenees answered bowling riding chloe minus bo language attentionocating nataya [SEP]']
[Init] best rec loss: 0.7516511082649231 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 0.7456907629966736 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best perm rec loss: 0.7442107200622559 for ['[CLS] major tried accompanied perrin whereuous he thingsanialtani our sheep [SEP]']
[Init] best perm rec loss: 0.7441504597663879 for ['[CLS]uous accompanied major our heanial sheep where triedtani perrin things [SEP]']
[Init] best perm rec loss: 0.7437101006507874 for ['[CLS] major wheretani things ouranial accompanied heuous perrin tried sheep [SEP]']
[Init] best perm rec loss: 0.7431371212005615 for ['[CLS]uous tried he sheep accompanied perrin thingstani our where majoranial [SEP]']
[Init] best perm rec loss: 0.7426205277442932 for ['[CLS]uous he perrin major tried our accompaniedtani things whereanial sheep [SEP]']
[Init] best perm rec loss: 0.7423324584960938 for ['[CLS] accompanied sheepuous majoranial he our things where tried perrintani [SEP]']
[Init] best perm rec loss: 0.7413286566734314 for ['[CLS]tani ouranial accompanied perrin major sheep where things tried heuous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.815 (perp=10.781, rec=0.227, cos=0.431), tot_loss_proj:3.459 [t=0.22s]
prediction: ['[CLS] could more than contemptuous contempt drop preparation contempt females population single [SEP]']
[ 100/2000] tot_loss=2.774 (perp=10.981, rec=0.150, cos=0.428), tot_loss_proj:3.420 [t=0.22s]
prediction: ['[CLS] possibly moreuous contemptuous contempt be possibly contempt population population single [SEP]']
[ 150/2000] tot_loss=2.485 (perp=9.728, rec=0.104, cos=0.435), tot_loss_proj:3.098 [t=0.22s]
prediction: ['[CLS] possibly moreuous contemptuous contempt be possibly of of population single [SEP]']
[ 200/2000] tot_loss=2.441 (perp=9.546, rec=0.097, cos=0.435), tot_loss_proj:3.083 [t=0.22s]
prediction: ['[CLS] possibly moreuous contemptuous contempt be possibly the of population single [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.387 (perp=9.324, rec=0.092, cos=0.431), tot_loss_proj:2.954 [t=0.22s]
prediction: ['[CLS] possibly moreuous contempt of contempt be possibly the female population single [SEP]']
[ 300/2000] tot_loss=2.403 (perp=9.324, rec=0.102, cos=0.436), tot_loss_proj:2.952 [t=0.22s]
prediction: ['[CLS] possibly moreuous contempt of contempt be possibly the female population single [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.142 (perp=8.101, rec=0.080, cos=0.442), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous of contempt be possibly the female population single [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.973 (perp=7.241, rec=0.085, cos=0.440), tot_loss_proj:2.387 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous of contempt be single. the female population [SEP]']
[ 450/2000] tot_loss=1.960 (perp=7.241, rec=0.072, cos=0.440), tot_loss_proj:2.390 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous of contempt be single. the female population [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.883 (perp=6.843, rec=0.075, cos=0.440), tot_loss_proj:2.274 [t=0.22s]
prediction: ['[CLS] possibly more contemptuous of contempt be single the female population. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.834 (perp=6.610, rec=0.075, cos=0.437), tot_loss_proj:2.161 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt single the female population. [SEP]']
[ 600/2000] tot_loss=1.839 (perp=6.610, rec=0.079, cos=0.438), tot_loss_proj:2.159 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt single the female population. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.840 (perp=6.610, rec=0.079, cos=0.439), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt single the female population. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.785 (perp=6.375, rec=0.070, cos=0.440), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single female population. [SEP]']
[ 750/2000] tot_loss=1.784 (perp=6.375, rec=0.070, cos=0.439), tot_loss_proj:2.101 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single female population. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.790 (perp=6.375, rec=0.076, cos=0.439), tot_loss_proj:2.090 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single female population. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.788 (perp=6.375, rec=0.074, cos=0.439), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single female population. [SEP]']
[ 900/2000] tot_loss=1.793 (perp=6.375, rec=0.079, cos=0.439), tot_loss_proj:2.092 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single female population. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.789 (perp=6.375, rec=0.074, cos=0.440), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single female population. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.786 (perp=6.375, rec=0.071, cos=0.440), tot_loss_proj:2.088 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single female population. [SEP]']
[1050/2000] tot_loss=1.779 (perp=6.375, rec=0.064, cos=0.440), tot_loss_proj:2.094 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single female population. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.716 (perp=6.028, rec=0.074, cos=0.437), tot_loss_proj:2.032 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.723 (perp=6.028, rec=0.079, cos=0.439), tot_loss_proj:2.036 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
[1200/2000] tot_loss=1.717 (perp=6.028, rec=0.073, cos=0.439), tot_loss_proj:2.035 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.716 (perp=6.028, rec=0.071, cos=0.439), tot_loss_proj:2.030 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.727 (perp=6.028, rec=0.083, cos=0.439), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
[1350/2000] tot_loss=1.711 (perp=6.028, rec=0.066, cos=0.439), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.722 (perp=6.028, rec=0.077, cos=0.440), tot_loss_proj:2.046 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.710 (perp=6.028, rec=0.064, cos=0.440), tot_loss_proj:2.047 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
[1500/2000] tot_loss=1.715 (perp=6.028, rec=0.070, cos=0.440), tot_loss_proj:2.040 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.716 (perp=6.028, rec=0.071, cos=0.440), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.716 (perp=6.028, rec=0.071, cos=0.440), tot_loss_proj:2.033 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
[1650/2000] tot_loss=1.713 (perp=6.028, rec=0.068, cos=0.440), tot_loss_proj:2.047 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.720 (perp=6.028, rec=0.074, cos=0.440), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.721 (perp=6.028, rec=0.075, cos=0.440), tot_loss_proj:2.045 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
[1800/2000] tot_loss=1.719 (perp=6.028, rec=0.074, cos=0.440), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.719 (perp=6.028, rec=0.073, cos=0.440), tot_loss_proj:2.045 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.713 (perp=6.028, rec=0.068, cos=0.440), tot_loss_proj:2.041 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
[1950/2000] tot_loss=1.715 (perp=6.028, rec=0.069, cos=0.440), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.715 (perp=6.028, rec=0.070, cos=0.440), tot_loss_proj:2.035 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single female population. [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] possibly contempt be more contemptuous of the single female population. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 72.727 | p: 72.727 | r: 72.727
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 164.394

[Aggregate metrics]:
rouge1     | fm: 90.297 | p: 90.039 | r: 90.627
rouge2     | fm: 57.564 | p: 57.588 | r: 57.595
rougeL     | fm: 77.798 | p: 77.660 | r: 78.049
rougeLsum  | fm: 77.676 | p: 77.514 | r: 77.946
r1fm+r2fm = 147.861

input #49 time: 0:08:45 | total time: 7:23:12


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.7329771149627202
highest_index [0]
highest [0.7329771149627202]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.8071619868278503 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.7974210977554321 for ['[CLS] felt defended drop ring richard spade frank beds₁ [SEP]']
[Init] best rec loss: 0.787729799747467 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7720521092414856 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7656742930412292 for ['[CLS] rama fueled sq napkinok unit trust associated gall [SEP]']
[Init] best rec loss: 0.7557607889175415 for ['[CLS] stone sex science cheeks prolific conventionwashed in once [SEP]']
[Init] best rec loss: 0.7524930238723755 for ['[CLS]sil state grade over ing fish champion woolf good [SEP]']
[Init] best perm rec loss: 0.751200795173645 for ['[CLS] woolf state champion ingsil grade over good fish [SEP]']
[Init] best perm rec loss: 0.750087320804596 for ['[CLS]sil champion ing fish grade woolf over good state [SEP]']
[Init] best perm rec loss: 0.7488352656364441 for ['[CLS] over statesil woolf fish grade champion good ing [SEP]']
[Init] best perm rec loss: 0.7472847104072571 for ['[CLS] fish champion good woolf ing state over gradesil [SEP]']
[Init] best perm rec loss: 0.7466400861740112 for ['[CLS] state good oversil champion woolf fish ing grade [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.911 (perp=10.635, rec=0.343, cos=0.441), tot_loss_proj:3.281 [t=0.22s]
prediction: ['[CLS] ordinary by limit sometimes certainly too too clever latin [SEP]']
[ 100/2000] tot_loss=2.796 (perp=10.524, rec=0.240, cos=0.451), tot_loss_proj:3.329 [t=0.22s]
prediction: ['[CLS] clever called too by ` too half clever english [SEP]']
[ 150/2000] tot_loss=2.959 (perp=11.551, rec=0.192, cos=0.457), tot_loss_proj:3.755 [t=0.22s]
prediction: ['[CLS] english call too by ` too half clever english [SEP]']
[ 200/2000] tot_loss=2.972 (perp=12.154, rec=0.091, cos=0.450), tot_loss_proj:3.876 [t=0.22s]
prediction: ['[CLS] what call too by ` too half clever english [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.591 (perp=10.275, rec=0.081, cos=0.455), tot_loss_proj:3.604 [t=0.22s]
prediction: ['[CLS] what call by too ` too half clever english [SEP]']
[ 300/2000] tot_loss=2.586 (perp=10.275, rec=0.071, cos=0.460), tot_loss_proj:3.603 [t=0.22s]
prediction: ['[CLS] what call by too ` too half clever english [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.477 (perp=9.772, rec=0.068, cos=0.455), tot_loss_proj:3.300 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.481 (perp=9.772, rec=0.067, cos=0.459), tot_loss_proj:3.307 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
[ 450/2000] tot_loss=2.481 (perp=9.772, rec=0.067, cos=0.460), tot_loss_proj:3.304 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.483 (perp=9.772, rec=0.067, cos=0.461), tot_loss_proj:3.305 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.481 (perp=9.772, rec=0.066, cos=0.461), tot_loss_proj:3.309 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
[ 600/2000] tot_loss=2.483 (perp=9.772, rec=0.067, cos=0.462), tot_loss_proj:3.307 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.483 (perp=9.772, rec=0.067, cos=0.462), tot_loss_proj:3.310 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.473 (perp=9.772, rec=0.057, cos=0.461), tot_loss_proj:3.306 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
[ 750/2000] tot_loss=2.477 (perp=9.772, rec=0.061, cos=0.462), tot_loss_proj:3.314 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.484 (perp=9.772, rec=0.068, cos=0.462), tot_loss_proj:3.305 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.491 (perp=9.772, rec=0.075, cos=0.462), tot_loss_proj:3.310 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
[ 900/2000] tot_loss=2.482 (perp=9.772, rec=0.066, cos=0.462), tot_loss_proj:3.307 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.478 (perp=9.772, rec=0.062, cos=0.462), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1000/2000] tot_loss=2.476 (perp=9.772, rec=0.059, cos=0.462), tot_loss_proj:3.308 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
[1050/2000] tot_loss=2.481 (perp=9.772, rec=0.064, cos=0.462), tot_loss_proj:3.314 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1100/2000] tot_loss=2.482 (perp=9.772, rec=0.065, cos=0.462), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1150/2000] tot_loss=2.476 (perp=9.772, rec=0.059, cos=0.462), tot_loss_proj:3.316 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
[1200/2000] tot_loss=2.484 (perp=9.772, rec=0.069, cos=0.461), tot_loss_proj:3.313 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1250/2000] tot_loss=2.480 (perp=9.772, rec=0.063, cos=0.462), tot_loss_proj:3.313 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1300/2000] tot_loss=2.486 (perp=9.772, rec=0.069, cos=0.462), tot_loss_proj:3.313 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
[1350/2000] tot_loss=2.483 (perp=9.772, rec=0.066, cos=0.462), tot_loss_proj:3.317 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1400/2000] tot_loss=2.484 (perp=9.772, rec=0.067, cos=0.463), tot_loss_proj:3.324 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1450/2000] tot_loss=2.486 (perp=9.772, rec=0.070, cos=0.462), tot_loss_proj:3.316 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
[1500/2000] tot_loss=2.472 (perp=9.772, rec=0.055, cos=0.462), tot_loss_proj:3.321 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1550/2000] tot_loss=2.487 (perp=9.772, rec=0.072, cos=0.461), tot_loss_proj:3.309 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1600/2000] tot_loss=2.475 (perp=9.772, rec=0.059, cos=0.462), tot_loss_proj:3.315 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
[1650/2000] tot_loss=2.481 (perp=9.772, rec=0.065, cos=0.462), tot_loss_proj:3.316 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1700/2000] tot_loss=2.470 (perp=9.772, rec=0.054, cos=0.462), tot_loss_proj:3.317 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1750/2000] tot_loss=2.487 (perp=9.772, rec=0.071, cos=0.462), tot_loss_proj:3.317 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
[1800/2000] tot_loss=2.489 (perp=9.772, rec=0.072, cos=0.462), tot_loss_proj:3.313 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1850/2000] tot_loss=2.484 (perp=9.772, rec=0.067, cos=0.462), tot_loss_proj:3.316 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[1900/2000] tot_loss=2.487 (perp=9.772, rec=0.070, cos=0.462), tot_loss_proj:3.322 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
[1950/2000] tot_loss=2.480 (perp=9.772, rec=0.063, cos=0.462), tot_loss_proj:3.318 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Attempt swap
[2000/2000] tot_loss=2.486 (perp=9.772, rec=0.069, cos=0.462), tot_loss_proj:3.324 [t=0.22s]
prediction: ['[CLS] what call by too ` too clever english half [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what call by too ` too clever english half [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 123.333

[Aggregate metrics]:
rouge1     | fm: 90.257 | p: 90.020 | r: 90.595
rouge2     | fm: 57.143 | p: 57.175 | r: 57.134
rougeL     | fm: 77.697 | p: 77.499 | r: 77.967
rougeLsum  | fm: 77.492 | p: 77.380 | r: 77.802
r1fm+r2fm = 147.400

input #50 time: 0:08:45 | total time: 7:31:57


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.772564741656152
highest_index [0]
highest [0.772564741656152]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.7934775352478027 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.762783408164978 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7423139214515686 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.732903778553009 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 0.7135543823242188 for ['[CLS] low reelection honest louis caps noah lieutenant quarter consequence handwriting [SEP]']
[Init] best rec loss: 0.7103180289268494 for ['[CLS] acute jay outies harbor recognitionitung annezzled hughes [SEP]']
[Init] best rec loss: 0.7072070240974426 for ['[CLS] thomas hugh anymore customer minute premises nuclear nothingnodro [SEP]']
[Init] best rec loss: 0.7023600339889526 for ['[CLS] certain million competition standing find contemporary alecdge immediately gold [SEP]']
[Init] best perm rec loss: 0.7018428444862366 for ['[CLS]dge alec find contemporary certain million immediately competition gold standing [SEP]']
[Init] best perm rec loss: 0.7011515498161316 for ['[CLS] golddge contemporary million alec standing competition find certain immediately [SEP]']
[Init] best perm rec loss: 0.7003416419029236 for ['[CLS] competition standing certain find immediately gold contemporary alec milliondge [SEP]']
[Init] best perm rec loss: 0.7001160979270935 for ['[CLS] alec find certain immediately milliondge contemporary standing competition gold [SEP]']
[Init] best perm rec loss: 0.6989956498146057 for ['[CLS] find certain gold immediately million competition contemporary alecdge standing [SEP]']
[Init] best perm rec loss: 0.6986638307571411 for ['[CLS] certain competition finddge million standing contemporary alec immediately gold [SEP]']
[Init] best perm rec loss: 0.6986305117607117 for ['[CLS] standing contemporary find gold million certaindge immediately competition alec [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.075 (perp=12.043, rec=0.315, cos=0.351), tot_loss_proj:3.727 [t=0.22s]
prediction: ['[CLS] funny sucks sucks moment funny sucks sucks sometime or funny [SEP]']
[ 100/2000] tot_loss=2.845 (perp=11.326, rec=0.192, cos=0.387), tot_loss_proj:3.487 [t=0.22s]
prediction: ['[CLS] funny sucks but moment funny sucks sucks or or has [SEP]']
[ 150/2000] tot_loss=2.542 (perp=10.118, rec=0.123, cos=0.395), tot_loss_proj:3.264 [t=0.22s]
prediction: ['[CLS] funny sucks but moment funny sucks sucks or moment has [SEP]']
[ 200/2000] tot_loss=2.616 (perp=10.550, rec=0.103, cos=0.402), tot_loss_proj:3.325 [t=0.22s]
prediction: ['[CLS] funny sucks but two funny sucks sucks or moment has [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.388 (perp=9.407, rec=0.120, cos=0.387), tot_loss_proj:3.091 [t=0.22s]
prediction: ['[CLS] two funny sucks but funny two sucks or moment has [SEP]']
[ 300/2000] tot_loss=2.266 (perp=8.880, rec=0.098, cos=0.391), tot_loss_proj:3.226 [t=0.22s]
prediction: ['[CLS] two funny sucks but funny. sucks or moment has [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.093 (perp=8.013, rec=0.092, cos=0.399), tot_loss_proj:2.810 [t=0.22s]
prediction: ['[CLS] two funny sucks. but funny sucks or moment has [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.087 (perp=8.013, rec=0.088, cos=0.396), tot_loss_proj:2.810 [t=0.22s]
prediction: ['[CLS] two funny sucks. but funny sucks or moment has [SEP]']
[ 450/2000] tot_loss=2.074 (perp=8.013, rec=0.073, cos=0.399), tot_loss_proj:2.808 [t=0.22s]
prediction: ['[CLS] two funny sucks. but funny sucks or moment has [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.079 (perp=8.013, rec=0.077, cos=0.400), tot_loss_proj:2.806 [t=0.22s]
prediction: ['[CLS] two funny sucks. but funny sucks or moment has [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.084 (perp=8.013, rec=0.082, cos=0.400), tot_loss_proj:2.805 [t=0.22s]
prediction: ['[CLS] two funny sucks. but funny sucks or moment has [SEP]']
[ 600/2000] tot_loss=2.288 (perp=9.080, rec=0.072, cos=0.400), tot_loss_proj:2.922 [t=0.22s]
prediction: ['[CLS] two a sucks. but funny sucks or moment has [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.000 (perp=7.633, rec=0.078, cos=0.395), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] two sucks. but funny sucks or a moment has [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.999 (perp=7.596, rec=0.082, cos=0.398), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
[ 750/2000] tot_loss=1.994 (perp=7.596, rec=0.077, cos=0.398), tot_loss_proj:2.735 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.996 (perp=7.596, rec=0.078, cos=0.399), tot_loss_proj:2.743 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.001 (perp=7.596, rec=0.082, cos=0.399), tot_loss_proj:2.742 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
[ 900/2000] tot_loss=1.998 (perp=7.596, rec=0.079, cos=0.399), tot_loss_proj:2.744 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.985 (perp=7.596, rec=0.067, cos=0.399), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1000/2000] tot_loss=1.993 (perp=7.596, rec=0.075, cos=0.399), tot_loss_proj:2.743 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
[1050/2000] tot_loss=1.991 (perp=7.596, rec=0.072, cos=0.399), tot_loss_proj:2.735 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1100/2000] tot_loss=1.989 (perp=7.596, rec=0.070, cos=0.400), tot_loss_proj:2.739 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1150/2000] tot_loss=1.996 (perp=7.596, rec=0.077, cos=0.400), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
[1200/2000] tot_loss=1.977 (perp=7.596, rec=0.059, cos=0.399), tot_loss_proj:2.740 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1250/2000] tot_loss=1.990 (perp=7.596, rec=0.072, cos=0.399), tot_loss_proj:2.748 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1300/2000] tot_loss=1.996 (perp=7.596, rec=0.077, cos=0.399), tot_loss_proj:2.736 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
[1350/2000] tot_loss=2.001 (perp=7.596, rec=0.083, cos=0.399), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1400/2000] tot_loss=1.987 (perp=7.596, rec=0.068, cos=0.400), tot_loss_proj:2.735 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1450/2000] tot_loss=1.994 (perp=7.596, rec=0.075, cos=0.400), tot_loss_proj:2.750 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
[1500/2000] tot_loss=1.984 (perp=7.596, rec=0.065, cos=0.399), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1550/2000] tot_loss=1.989 (perp=7.596, rec=0.071, cos=0.399), tot_loss_proj:2.738 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1600/2000] tot_loss=1.987 (perp=7.596, rec=0.068, cos=0.400), tot_loss_proj:2.740 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
[1650/2000] tot_loss=1.985 (perp=7.596, rec=0.066, cos=0.400), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1700/2000] tot_loss=1.987 (perp=7.596, rec=0.068, cos=0.400), tot_loss_proj:2.742 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1750/2000] tot_loss=1.991 (perp=7.596, rec=0.072, cos=0.400), tot_loss_proj:2.742 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
[1800/2000] tot_loss=1.983 (perp=7.596, rec=0.064, cos=0.400), tot_loss_proj:2.744 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1850/2000] tot_loss=1.978 (perp=7.596, rec=0.059, cos=0.400), tot_loss_proj:2.746 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
[1900/2000] tot_loss=1.989 (perp=7.596, rec=0.070, cos=0.399), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
[1950/2000] tot_loss=1.995 (perp=7.596, rec=0.076, cos=0.399), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] two sucks sucks but funny. or a moment has [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.982 (perp=7.566, rec=0.071, cos=0.398), tot_loss_proj:2.596 [t=0.22s]
prediction: ['[CLS] two sucks but funny sucks. or a moment has [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] two sucks sucks but funny. or a moment has [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 10.526 | p: 10.000 | r: 11.111
rougeL     | fm: 57.143 | p: 54.545 | r: 60.000
rougeLsum  | fm: 57.143 | p: 54.545 | r: 60.000
r1fm+r2fm = 105.764

[Aggregate metrics]:
rouge1     | fm: 90.308 | p: 90.038 | r: 90.761
rouge2     | fm: 56.062 | p: 56.104 | r: 56.069
rougeL     | fm: 77.221 | p: 77.037 | r: 77.470
rougeLsum  | fm: 77.171 | p: 76.994 | r: 77.466
r1fm+r2fm = 146.370

input #51 time: 0:08:45 | total time: 7:40:43


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.7244097651791632
highest_index [0]
highest [0.7244097651791632]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9437261819839478 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9349981546401978 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.9318714737892151 for ['[CLS]fa bear gun [SEP]']
[Init] best rec loss: 0.9286549091339111 for ['[CLS] tree partition themed [SEP]']
[Init] best rec loss: 0.9129555821418762 for ['[CLS] news implies lack [SEP]']
[Init] best rec loss: 0.8897955417633057 for ['[CLS] transition content distance [SEP]']
[Init] best rec loss: 0.8836460709571838 for ['[CLS] nations gazette probability [SEP]']
[Init] best rec loss: 0.7571975588798523 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7539215683937073 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.7509259581565857 for ['[CLS] football expected vocabulary [SEP]']
[Init] best perm rec loss: 0.740912139415741 for ['[CLS] football vocabulary expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.006 (perp=11.737, rec=0.195, cos=0.464), tot_loss_proj:3.152 [t=0.22s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.425 (perp=9.179, rec=0.117, cos=0.473), tot_loss_proj:2.697 [t=0.22s]
prediction: ['[CLS] trailer trash trailer [SEP]']
[ 150/2000] tot_loss=2.386 (perp=9.179, rec=0.073, cos=0.477), tot_loss_proj:2.696 [t=0.22s]
prediction: ['[CLS] trailer trash trailer [SEP]']
[ 200/2000] tot_loss=2.649 (perp=10.491, rec=0.081, cos=0.470), tot_loss_proj:2.857 [t=0.22s]
prediction: ['[CLS] trailer trash - [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.297 (perp=8.483, rec=0.131, cos=0.469), tot_loss_proj:2.571 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=2.257 (perp=8.483, rec=0.087, cos=0.474), tot_loss_proj:2.553 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.233 (perp=8.483, rec=0.061, cos=0.476), tot_loss_proj:2.556 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.239 (perp=8.483, rec=0.068, cos=0.474), tot_loss_proj:2.558 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=2.246 (perp=8.483, rec=0.077, cos=0.473), tot_loss_proj:2.559 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.247 (perp=8.483, rec=0.077, cos=0.473), tot_loss_proj:2.563 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.253 (perp=8.483, rec=0.081, cos=0.475), tot_loss_proj:2.567 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=2.236 (perp=8.483, rec=0.066, cos=0.473), tot_loss_proj:2.567 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.233 (perp=8.483, rec=0.064, cos=0.473), tot_loss_proj:2.560 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.244 (perp=8.483, rec=0.072, cos=0.475), tot_loss_proj:2.557 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=2.234 (perp=8.483, rec=0.064, cos=0.474), tot_loss_proj:2.565 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.230 (perp=8.483, rec=0.059, cos=0.475), tot_loss_proj:2.557 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.235 (perp=8.483, rec=0.064, cos=0.474), tot_loss_proj:2.555 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=2.231 (perp=8.483, rec=0.059, cos=0.475), tot_loss_proj:2.568 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.230 (perp=8.483, rec=0.059, cos=0.475), tot_loss_proj:2.557 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=2.243 (perp=8.483, rec=0.071, cos=0.475), tot_loss_proj:2.563 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=2.233 (perp=8.483, rec=0.062, cos=0.474), tot_loss_proj:2.571 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=2.238 (perp=8.483, rec=0.066, cos=0.475), tot_loss_proj:2.563 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=2.237 (perp=8.483, rec=0.066, cos=0.475), tot_loss_proj:2.562 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=2.225 (perp=8.483, rec=0.053, cos=0.475), tot_loss_proj:2.573 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=2.243 (perp=8.483, rec=0.072, cos=0.475), tot_loss_proj:2.571 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=2.240 (perp=8.483, rec=0.068, cos=0.475), tot_loss_proj:2.569 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=2.232 (perp=8.483, rec=0.060, cos=0.475), tot_loss_proj:2.563 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=2.250 (perp=8.483, rec=0.079, cos=0.475), tot_loss_proj:2.562 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=2.230 (perp=8.483, rec=0.058, cos=0.475), tot_loss_proj:2.571 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=2.251 (perp=8.483, rec=0.079, cos=0.475), tot_loss_proj:2.559 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=2.238 (perp=8.483, rec=0.066, cos=0.475), tot_loss_proj:2.559 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=2.239 (perp=8.483, rec=0.068, cos=0.475), tot_loss_proj:2.560 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=2.237 (perp=8.483, rec=0.065, cos=0.475), tot_loss_proj:2.556 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=2.235 (perp=8.483, rec=0.063, cos=0.475), tot_loss_proj:2.559 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=2.236 (perp=8.483, rec=0.065, cos=0.475), tot_loss_proj:2.563 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=2.239 (perp=8.483, rec=0.067, cos=0.475), tot_loss_proj:2.567 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=2.242 (perp=8.483, rec=0.071, cos=0.475), tot_loss_proj:2.558 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=2.239 (perp=8.483, rec=0.067, cos=0.475), tot_loss_proj:2.552 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=2.242 (perp=8.483, rec=0.070, cos=0.475), tot_loss_proj:2.558 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=2.239 (perp=8.483, rec=0.067, cos=0.475), tot_loss_proj:2.573 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 90.477 | p: 90.180 | r: 90.888
rouge2     | fm: 55.187 | p: 55.168 | r: 55.250
rougeL     | fm: 77.270 | p: 77.084 | r: 77.575
rougeLsum  | fm: 77.128 | p: 76.907 | r: 77.402
r1fm+r2fm = 145.665

input #52 time: 0:08:43 | total time: 7:49:26


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.7502733973890865
highest_index [0]
highest [0.7502733973890865]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.8214311599731445 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.814258873462677 for ['[CLS] government cf [SEP]']
[Init] best rec loss: 0.7980130314826965 for ['[CLS] manga rise [SEP]']
[Init] best rec loss: 0.7151990532875061 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.7048523426055908 for ['[CLS] annually ability [SEP]']
[Init] best rec loss: 0.6823797225952148 for ['[CLS] praising won [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.115 (perp=12.492, rec=0.184, cos=0.433), tot_loss_proj:3.533 [t=0.22s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=3.019 (perp=12.413, rec=0.103, cos=0.433), tot_loss_proj:3.478 [t=0.22s]
prediction: ['[CLS]ing flinch [SEP]']
[ 150/2000] tot_loss=2.982 (perp=12.413, rec=0.066, cos=0.433), tot_loss_proj:3.486 [t=0.22s]
prediction: ['[CLS]ing flinch [SEP]']
[ 200/2000] tot_loss=2.983 (perp=12.413, rec=0.064, cos=0.436), tot_loss_proj:3.479 [t=0.22s]
prediction: ['[CLS]ing flinch [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.119 (perp=8.090, rec=0.075, cos=0.426), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=2.113 (perp=8.090, rec=0.058, cos=0.437), tot_loss_proj:2.137 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.120 (perp=8.090, rec=0.065, cos=0.437), tot_loss_proj:2.143 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.111 (perp=8.090, rec=0.056, cos=0.437), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=2.117 (perp=8.090, rec=0.063, cos=0.437), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.113 (perp=8.090, rec=0.059, cos=0.437), tot_loss_proj:2.147 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.117 (perp=8.090, rec=0.063, cos=0.436), tot_loss_proj:2.128 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=2.114 (perp=8.090, rec=0.060, cos=0.436), tot_loss_proj:2.146 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.116 (perp=8.090, rec=0.062, cos=0.437), tot_loss_proj:2.146 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.105 (perp=8.090, rec=0.051, cos=0.436), tot_loss_proj:2.132 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=2.112 (perp=8.090, rec=0.061, cos=0.433), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.120 (perp=8.090, rec=0.066, cos=0.437), tot_loss_proj:2.130 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.122 (perp=8.090, rec=0.067, cos=0.437), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=2.117 (perp=8.090, rec=0.066, cos=0.433), tot_loss_proj:2.147 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.117 (perp=8.090, rec=0.063, cos=0.436), tot_loss_proj:2.134 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=2.114 (perp=8.090, rec=0.059, cos=0.437), tot_loss_proj:2.119 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=2.105 (perp=8.090, rec=0.054, cos=0.433), tot_loss_proj:2.132 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=2.118 (perp=8.090, rec=0.063, cos=0.437), tot_loss_proj:2.143 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=2.114 (perp=8.090, rec=0.059, cos=0.437), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=2.121 (perp=8.090, rec=0.066, cos=0.437), tot_loss_proj:2.134 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=2.115 (perp=8.090, rec=0.063, cos=0.434), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=2.117 (perp=8.090, rec=0.062, cos=0.436), tot_loss_proj:2.139 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=2.121 (perp=8.090, rec=0.066, cos=0.437), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=2.109 (perp=8.090, rec=0.055, cos=0.437), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=2.121 (perp=8.090, rec=0.066, cos=0.437), tot_loss_proj:2.139 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=2.109 (perp=8.090, rec=0.054, cos=0.437), tot_loss_proj:2.149 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=2.127 (perp=8.090, rec=0.072, cos=0.437), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=2.118 (perp=8.090, rec=0.063, cos=0.437), tot_loss_proj:2.140 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=2.120 (perp=8.090, rec=0.065, cos=0.437), tot_loss_proj:2.135 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=2.114 (perp=8.090, rec=0.059, cos=0.437), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=2.112 (perp=8.090, rec=0.057, cos=0.437), tot_loss_proj:2.129 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=2.114 (perp=8.090, rec=0.059, cos=0.437), tot_loss_proj:2.130 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=2.124 (perp=8.090, rec=0.071, cos=0.435), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=2.111 (perp=8.090, rec=0.056, cos=0.436), tot_loss_proj:2.130 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=2.117 (perp=8.090, rec=0.062, cos=0.437), tot_loss_proj:2.135 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=2.122 (perp=8.090, rec=0.067, cos=0.437), tot_loss_proj:2.132 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.630 | p: 90.348 | r: 91.065
rouge2     | fm: 55.895 | p: 55.906 | r: 55.951
rougeL     | fm: 77.716 | p: 77.498 | r: 77.993
rougeLsum  | fm: 77.597 | p: 77.361 | r: 77.847
r1fm+r2fm = 146.526

input #53 time: 0:08:43 | total time: 7:58:10


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.735214721503032
highest_index [0]
highest [0.735214721503032]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.7820150852203369 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.7705884575843811 for ['[CLS] ally strategy [SEP]']
[Init] best rec loss: 0.7437921166419983 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 0.6957939863204956 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.6949561834335327 for ['[CLS]sil shall [SEP]']
[Init] best rec loss: 0.668208122253418 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.6672782897949219 for ['[CLS] much cry [SEP]']
[Init] best rec loss: 0.6635655164718628 for ['[CLS] deployment bro [SEP]']
[Init] best rec loss: 0.6459392309188843 for ['[CLS] teresa spanish [SEP]']
[Init] best rec loss: 0.6353398561477661 for ['[CLS] wild exercised [SEP]']
[Init] best perm rec loss: 0.6352429986000061 for ['[CLS] exercised wild [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.282 (perp=8.198, rec=0.202, cos=0.440), tot_loss_proj:2.194 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 100/2000] tot_loss=2.181 (perp=8.198, rec=0.082, cos=0.459), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=2.171 (perp=8.198, rec=0.073, cos=0.459), tot_loss_proj:2.171 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=2.164 (perp=8.198, rec=0.065, cos=0.459), tot_loss_proj:2.185 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.154 (perp=8.198, rec=0.056, cos=0.458), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=2.160 (perp=8.198, rec=0.061, cos=0.460), tot_loss_proj:2.182 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.142 (perp=8.198, rec=0.050, cos=0.453), tot_loss_proj:2.183 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.156 (perp=8.198, rec=0.058, cos=0.459), tot_loss_proj:2.171 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=2.150 (perp=8.198, rec=0.052, cos=0.458), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.168 (perp=8.198, rec=0.069, cos=0.459), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.157 (perp=8.198, rec=0.062, cos=0.456), tot_loss_proj:2.185 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=2.153 (perp=8.198, rec=0.055, cos=0.459), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.151 (perp=8.198, rec=0.054, cos=0.458), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.169 (perp=8.198, rec=0.071, cos=0.459), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=2.168 (perp=8.198, rec=0.071, cos=0.457), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.152 (perp=8.198, rec=0.056, cos=0.457), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.166 (perp=8.198, rec=0.067, cos=0.459), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=2.158 (perp=8.198, rec=0.060, cos=0.458), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.166 (perp=8.198, rec=0.067, cos=0.459), tot_loss_proj:2.182 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=2.154 (perp=8.198, rec=0.055, cos=0.459), tot_loss_proj:2.171 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=2.159 (perp=8.198, rec=0.061, cos=0.459), tot_loss_proj:2.171 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=2.154 (perp=8.198, rec=0.058, cos=0.456), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=2.161 (perp=8.198, rec=0.063, cos=0.459), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=2.157 (perp=8.198, rec=0.059, cos=0.458), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=2.156 (perp=8.198, rec=0.059, cos=0.458), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=2.162 (perp=8.198, rec=0.063, cos=0.459), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=2.158 (perp=8.198, rec=0.059, cos=0.459), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=2.161 (perp=8.198, rec=0.062, cos=0.459), tot_loss_proj:2.184 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=2.146 (perp=8.198, rec=0.048, cos=0.459), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=2.177 (perp=8.198, rec=0.079, cos=0.459), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=2.164 (perp=8.198, rec=0.065, cos=0.459), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=2.150 (perp=8.198, rec=0.051, cos=0.459), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=2.167 (perp=8.198, rec=0.068, cos=0.459), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=2.157 (perp=8.198, rec=0.058, cos=0.459), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=2.162 (perp=8.198, rec=0.063, cos=0.459), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=2.162 (perp=8.198, rec=0.063, cos=0.459), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=2.159 (perp=8.198, rec=0.060, cos=0.459), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=2.162 (perp=8.198, rec=0.064, cos=0.459), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=2.147 (perp=8.198, rec=0.048, cos=0.459), tot_loss_proj:2.191 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=2.162 (perp=8.198, rec=0.063, cos=0.459), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.694 | p: 90.421 | r: 91.161
rouge2     | fm: 56.861 | p: 56.936 | r: 56.867
rougeL     | fm: 78.071 | p: 77.845 | r: 78.339
rougeLsum  | fm: 77.956 | p: 77.741 | r: 78.199
r1fm+r2fm = 147.554

input #54 time: 0:08:42 | total time: 8:06:52


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.7312711162949728
highest_index [0]
highest [0.7312711162949728]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.8542290329933167 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.7467090487480164 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7372034788131714 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7296552658081055 for ['[CLS] beneath besides milo [SEP]']
[Init] best rec loss: 0.7185271978378296 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.7091515064239502 for ['[CLS] top trades events [SEP]']
[Init] best rec loss: 0.7063933610916138 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7030024528503418 for ['[CLS] stride post holly [SEP]']
[Init] best perm rec loss: 0.7020949125289917 for ['[CLS] post stride holly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.525 (perp=9.058, rec=0.274, cos=0.439), tot_loss_proj:2.577 [t=0.23s]
prediction: ['[CLS] settle too easily [SEP]']
[ 100/2000] tot_loss=2.276 (perp=8.671, rec=0.080, cos=0.462), tot_loss_proj:2.276 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 150/2000] tot_loss=2.268 (perp=8.671, rec=0.073, cos=0.461), tot_loss_proj:2.271 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 200/2000] tot_loss=2.247 (perp=8.671, rec=0.059, cos=0.454), tot_loss_proj:2.265 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.249 (perp=8.671, rec=0.056, cos=0.459), tot_loss_proj:2.249 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=2.253 (perp=8.671, rec=0.055, cos=0.464), tot_loss_proj:2.257 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.262 (perp=8.671, rec=0.064, cos=0.463), tot_loss_proj:2.253 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.248 (perp=8.671, rec=0.049, cos=0.464), tot_loss_proj:2.270 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=2.259 (perp=8.671, rec=0.061, cos=0.464), tot_loss_proj:2.269 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.257 (perp=8.671, rec=0.058, cos=0.464), tot_loss_proj:2.255 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.258 (perp=8.671, rec=0.060, cos=0.464), tot_loss_proj:2.272 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=2.257 (perp=8.671, rec=0.063, cos=0.459), tot_loss_proj:2.261 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.256 (perp=8.671, rec=0.058, cos=0.464), tot_loss_proj:2.272 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.249 (perp=8.671, rec=0.056, cos=0.458), tot_loss_proj:2.253 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=2.260 (perp=8.671, rec=0.062, cos=0.464), tot_loss_proj:2.269 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.262 (perp=8.671, rec=0.066, cos=0.461), tot_loss_proj:2.276 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.267 (perp=8.671, rec=0.068, cos=0.464), tot_loss_proj:2.268 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=2.247 (perp=8.671, rec=0.053, cos=0.460), tot_loss_proj:2.267 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.264 (perp=8.671, rec=0.065, cos=0.464), tot_loss_proj:2.270 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=2.256 (perp=8.671, rec=0.057, cos=0.465), tot_loss_proj:2.267 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=2.254 (perp=8.671, rec=0.055, cos=0.465), tot_loss_proj:2.264 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=2.261 (perp=8.671, rec=0.063, cos=0.464), tot_loss_proj:2.265 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=2.262 (perp=8.671, rec=0.062, cos=0.465), tot_loss_proj:2.277 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=2.248 (perp=8.671, rec=0.049, cos=0.465), tot_loss_proj:2.258 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=2.263 (perp=8.671, rec=0.064, cos=0.465), tot_loss_proj:2.268 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=2.269 (perp=8.671, rec=0.072, cos=0.462), tot_loss_proj:2.269 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=2.269 (perp=8.671, rec=0.070, cos=0.464), tot_loss_proj:2.265 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=2.255 (perp=8.671, rec=0.056, cos=0.465), tot_loss_proj:2.262 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=2.259 (perp=8.671, rec=0.060, cos=0.465), tot_loss_proj:2.256 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=2.255 (perp=8.671, rec=0.059, cos=0.462), tot_loss_proj:2.256 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=2.255 (perp=8.671, rec=0.057, cos=0.464), tot_loss_proj:2.265 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=2.258 (perp=8.671, rec=0.059, cos=0.465), tot_loss_proj:2.266 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=2.272 (perp=8.671, rec=0.073, cos=0.465), tot_loss_proj:2.274 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=2.250 (perp=8.671, rec=0.051, cos=0.465), tot_loss_proj:2.266 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=2.258 (perp=8.671, rec=0.060, cos=0.464), tot_loss_proj:2.255 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=2.271 (perp=8.671, rec=0.072, cos=0.465), tot_loss_proj:2.273 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=2.268 (perp=8.671, rec=0.069, cos=0.465), tot_loss_proj:2.264 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=2.261 (perp=8.671, rec=0.062, cos=0.465), tot_loss_proj:2.259 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=2.251 (perp=8.671, rec=0.051, cos=0.465), tot_loss_proj:2.265 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=2.263 (perp=8.671, rec=0.064, cos=0.465), tot_loss_proj:2.276 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.982 | p: 90.713 | r: 91.377
rouge2     | fm: 57.527 | p: 57.530 | r: 57.526
rougeL     | fm: 78.339 | p: 78.209 | r: 78.694
rougeLsum  | fm: 78.402 | p: 78.237 | r: 78.667
r1fm+r2fm = 148.509

input #55 time: 0:09:08 | total time: 8:16:00


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.7154785278683988
highest_index [0]
highest [0.7154785278683988]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.8411855101585388 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.817287802696228 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.8140459060668945 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 0.813190758228302 for ['[CLS] iron backed tis code charter sympathy laid technique bear k strikeured unfortunately en reflection avid determined ; sense depression blame [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.198 (perp=12.109, rec=0.288, cos=0.488), tot_loss_proj:3.755 [t=0.23s]
prediction: ['[CLS] god serie seeing crying damage damagefield damage damage of engineering poor ever damage tape expensive damage [SEP] ( neglected films [SEP]']
[ 100/2000] tot_loss=2.963 (perp=11.391, rec=0.206, cos=0.478), tot_loss_proj:3.611 [t=0.23s]
prediction: ['[CLS] deals series films loads damage damage cause damage costly of 《 costly ever damage films expensive damage which ( never films [SEP]']
[ 150/2000] tot_loss=2.842 (perp=10.976, rec=0.172, cos=0.475), tot_loss_proj:3.528 [t=0.24s]
prediction: ['[CLS] deals series should loads damage damage cause damage costly of that costly ever sums films expensive fix which will never analysis [SEP]']
[ 200/2000] tot_loss=2.680 (perp=10.240, rec=0.150, cos=0.482), tot_loss_proj:3.263 [t=0.24s]
prediction: ['[CLS] cause of will loads damage damage cause damage costly of which costly ever sums films expensive fix analysis will never analysis [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.690 (perp=10.378, rec=0.132, cos=0.482), tot_loss_proj:3.236 [t=0.24s]
prediction: ['[CLS] decades of numerous loads damage will cause damage costly that which costly years damage films years fix analysis cause never analysis [SEP]']
[ 300/2000] tot_loss=2.782 (perp=10.911, rec=0.116, cos=0.484), tot_loss_proj:3.331 [t=0.24s]
prediction: ['[CLS] cause of numerous loads damage will cause damage costly that which costly yearspara films years fix analysis cause never analysis [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.884 (perp=11.469, rec=0.104, cos=0.486), tot_loss_proj:3.525 [t=0.24s]
prediction: ['[CLS] cause of ir loads damage will causepara damage that which costly yearspara films years fix analysis cause never analysis [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.862 (perp=11.395, rec=0.097, cos=0.486), tot_loss_proj:3.560 [t=0.24s]
prediction: ['[CLS] cause of ir loads damage willparapara damage that which costly yearspara years films fix analysis cause never analysis [SEP]']
[ 450/2000] tot_loss=2.768 (perp=10.954, rec=0.091, cos=0.486), tot_loss_proj:3.449 [t=0.24s]
prediction: ['[CLS] cause of ir loads damage willparapara damage that which costly yearspara years films fix could cause never analysis [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.668 (perp=10.517, rec=0.081, cos=0.483), tot_loss_proj:3.552 [t=0.22s]
prediction: ['[CLS] analysis of ir loads damage willparaparable that which costly years existed years films fix could cause never cause [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.296 (perp=8.578, rec=0.100, cos=0.481), tot_loss_proj:3.039 [t=0.22s]
prediction: ['[CLS] analysis of loads damage will irreparable that which costly years existed years films fix could cause never cause [SEP]']
[ 600/2000] tot_loss=2.276 (perp=8.526, rec=0.087, cos=0.484), tot_loss_proj:2.929 [t=0.22s]
prediction: ['[CLS] analysis of loads damage will irreparable that which costly yearsumi years films fix could cause never cause [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.154 (perp=7.911, rec=0.088, cos=0.484), tot_loss_proj:2.842 [t=0.22s]
prediction: ['[CLS] analysis of loads damage will irreparable cause that which costly years meng years films fix could never cause [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.137 (perp=7.812, rec=0.093, cos=0.482), tot_loss_proj:2.622 [t=0.22s]
prediction: ['[CLS] analysis of loads damage will irreparable cause thatble costly years which years films fix could never cause [SEP]']
[ 750/2000] tot_loss=2.122 (perp=7.812, rec=0.077, cos=0.483), tot_loss_proj:2.626 [t=0.22s]
prediction: ['[CLS] analysis of loads damage will irreparable cause thatble costly years which years films fix could never cause [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.202 (perp=8.175, rec=0.083, cos=0.484), tot_loss_proj:2.795 [t=0.22s]
prediction: ['[CLS] analysis of loads will damage irreparable cause thatble costly years which years films fix could never years [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.121 (perp=7.794, rec=0.080, cos=0.482), tot_loss_proj:2.596 [t=0.22s]
prediction: ['[CLS] analysis of loads will damage irreparable cause thatble costly years which years films could never fix years [SEP]']
[ 900/2000] tot_loss=2.086 (perp=7.600, rec=0.083, cos=0.483), tot_loss_proj:2.610 [t=0.22s]
prediction: ['[CLS] analysis of loads will damage irreparable cause that / costly years which years films could never fix years [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.132 (perp=7.831, rec=0.082, cos=0.484), tot_loss_proj:2.631 [t=0.22s]
prediction: ['[CLS] analysis of loads will damage irreparable cause that costly years whichble years films could never fix years [SEP]']
Attempt swap
[1000/2000] tot_loss=2.023 (perp=7.312, rec=0.076, cos=0.485), tot_loss_proj:2.583 [t=0.22s]
prediction: ['[CLS] analysis of loads will damage irreparable cause that costly years which and years films could never fix years [SEP]']
[1050/2000] tot_loss=2.030 (perp=7.312, rec=0.083, cos=0.485), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] analysis of loads will damage irreparable cause that costly years which and years films could never fix years [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.022 (perp=7.272, rec=0.083, cos=0.485), tot_loss_proj:2.548 [t=0.22s]
prediction: ['[CLS] analysis of loads will damage irreparable cause that costly years which years and films could never fix years [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.940 (perp=6.904, rec=0.073, cos=0.487), tot_loss_proj:2.462 [t=0.22s]
prediction: ['[CLS] analysis of loads will damage irreparable cause that costly years which years and years films could never fix [SEP]']
[1200/2000] tot_loss=1.940 (perp=6.904, rec=0.074, cos=0.485), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] analysis of loads will damage irreparable cause that costly years which years and years films could never fix [SEP]']
Attempt swap
[1250/2000] tot_loss=1.947 (perp=6.904, rec=0.081, cos=0.486), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] analysis of loads will damage irreparable cause that costly years which years and years films could never fix [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.878 (perp=6.558, rec=0.080, cos=0.487), tot_loss_proj:2.250 [t=0.22s]
prediction: ['[CLS] analysis of loads will cause irreparable damage that costly years which years and years films could never fix [SEP]']
[1350/2000] tot_loss=1.877 (perp=6.558, rec=0.080, cos=0.486), tot_loss_proj:2.261 [t=0.22s]
prediction: ['[CLS] analysis of loads will cause irreparable damage that costly years which years and years films could never fix [SEP]']
Attempt swap
[1400/2000] tot_loss=1.876 (perp=6.558, rec=0.079, cos=0.486), tot_loss_proj:2.261 [t=0.22s]
prediction: ['[CLS] analysis of loads will cause irreparable damage that costly years which years and years films could never fix [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.805 (perp=6.171, rec=0.085, cos=0.486), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
[1500/2000] tot_loss=1.799 (perp=6.171, rec=0.078, cos=0.486), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
Attempt swap
[1550/2000] tot_loss=1.796 (perp=6.171, rec=0.076, cos=0.486), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
Attempt swap
[1600/2000] tot_loss=1.790 (perp=6.171, rec=0.070, cos=0.486), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
[1650/2000] tot_loss=1.800 (perp=6.171, rec=0.079, cos=0.486), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
Attempt swap
[1700/2000] tot_loss=1.782 (perp=6.171, rec=0.061, cos=0.486), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
Attempt swap
[1750/2000] tot_loss=1.791 (perp=6.171, rec=0.071, cos=0.486), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
[1800/2000] tot_loss=1.794 (perp=6.171, rec=0.073, cos=0.486), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
Attempt swap
[1850/2000] tot_loss=1.789 (perp=6.171, rec=0.068, cos=0.486), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
Attempt swap
[1900/2000] tot_loss=1.793 (perp=6.171, rec=0.072, cos=0.486), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
[1950/2000] tot_loss=1.791 (perp=6.171, rec=0.070, cos=0.486), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
Attempt swap
[2000/2000] tot_loss=1.791 (perp=6.171, rec=0.070, cos=0.486), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] analysis of costly loads will cause irreparable damage that years which years and years films could never fix [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.000 | p: 95.000 | r: 95.000
rouge2     | fm: 52.632 | p: 52.632 | r: 52.632
rougeL     | fm: 65.000 | p: 65.000 | r: 65.000
rougeLsum  | fm: 65.000 | p: 65.000 | r: 65.000
r1fm+r2fm = 147.632

[Aggregate metrics]:
rouge1     | fm: 91.072 | p: 90.831 | r: 91.506
rouge2     | fm: 57.509 | p: 57.483 | r: 57.559
rougeL     | fm: 78.320 | p: 78.135 | r: 78.578
rougeLsum  | fm: 78.134 | p: 77.906 | r: 78.380
r1fm+r2fm = 148.581

input #56 time: 0:08:56 | total time: 8:24:57


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.7300628531556721
highest_index [0]
highest [0.7300628531556721]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8737850785255432 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.8533856868743896 for ['[CLS] their [SEP]']
[Init] best rec loss: 0.7990002036094666 for ['[CLS]on [SEP]']
[Init] best rec loss: 0.7501695156097412 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.6842315793037415 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6829047799110413 for ['[CLS] beethoven [SEP]']
[Init] best rec loss: 0.6537662148475647 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.011 (perp=12.283, rec=0.120, cos=0.435), tot_loss_proj:2.993 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.981 (perp=12.283, rec=0.062, cos=0.463), tot_loss_proj:2.980 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.976 (perp=12.283, rec=0.064, cos=0.455), tot_loss_proj:2.987 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.992 (perp=12.283, rec=0.072, cos=0.464), tot_loss_proj:2.976 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.998 (perp=12.283, rec=0.076, cos=0.465), tot_loss_proj:2.976 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.974 (perp=12.283, rec=0.051, cos=0.466), tot_loss_proj:2.976 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.985 (perp=12.283, rec=0.063, cos=0.466), tot_loss_proj:2.984 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.988 (perp=12.283, rec=0.066, cos=0.465), tot_loss_proj:2.978 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.978 (perp=12.283, rec=0.055, cos=0.467), tot_loss_proj:2.964 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.969 (perp=12.283, rec=0.050, cos=0.463), tot_loss_proj:2.983 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.992 (perp=12.283, rec=0.069, cos=0.467), tot_loss_proj:2.988 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.981 (perp=12.283, rec=0.058, cos=0.466), tot_loss_proj:2.983 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.965 (perp=12.283, rec=0.047, cos=0.462), tot_loss_proj:2.965 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.984 (perp=12.283, rec=0.061, cos=0.466), tot_loss_proj:2.985 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.984 (perp=12.283, rec=0.063, cos=0.465), tot_loss_proj:2.988 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.992 (perp=12.283, rec=0.069, cos=0.467), tot_loss_proj:2.978 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.001 (perp=12.283, rec=0.078, cos=0.467), tot_loss_proj:2.980 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.983 (perp=12.283, rec=0.063, cos=0.464), tot_loss_proj:2.978 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.998 (perp=12.283, rec=0.075, cos=0.467), tot_loss_proj:2.983 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.968 (perp=12.283, rec=0.044, cos=0.467), tot_loss_proj:2.974 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.981 (perp=12.283, rec=0.058, cos=0.467), tot_loss_proj:2.972 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.994 (perp=12.283, rec=0.074, cos=0.464), tot_loss_proj:2.984 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.974 (perp=12.283, rec=0.051, cos=0.466), tot_loss_proj:2.977 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.980 (perp=12.283, rec=0.060, cos=0.464), tot_loss_proj:2.984 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.972 (perp=12.283, rec=0.049, cos=0.466), tot_loss_proj:2.983 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.977 (perp=12.283, rec=0.054, cos=0.467), tot_loss_proj:2.985 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.979 (perp=12.283, rec=0.055, cos=0.467), tot_loss_proj:2.981 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.977 (perp=12.283, rec=0.055, cos=0.465), tot_loss_proj:2.987 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.984 (perp=12.283, rec=0.061, cos=0.467), tot_loss_proj:2.985 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.981 (perp=12.283, rec=0.057, cos=0.467), tot_loss_proj:2.976 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.982 (perp=12.283, rec=0.058, cos=0.467), tot_loss_proj:2.973 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.994 (perp=12.283, rec=0.071, cos=0.467), tot_loss_proj:2.978 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.983 (perp=12.283, rec=0.059, cos=0.467), tot_loss_proj:2.982 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.979 (perp=12.283, rec=0.056, cos=0.467), tot_loss_proj:2.988 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.982 (perp=12.283, rec=0.059, cos=0.467), tot_loss_proj:2.978 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.992 (perp=12.283, rec=0.070, cos=0.466), tot_loss_proj:2.996 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.985 (perp=12.283, rec=0.062, cos=0.466), tot_loss_proj:2.975 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.995 (perp=12.283, rec=0.072, cos=0.467), tot_loss_proj:2.971 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.974 (perp=12.283, rec=0.051, cos=0.467), tot_loss_proj:2.979 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.996 (perp=12.283, rec=0.073, cos=0.467), tot_loss_proj:2.974 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.260 | p: 91.004 | r: 91.601
rouge2     | fm: 58.345 | p: 58.405 | r: 58.316
rougeL     | fm: 78.661 | p: 78.488 | r: 78.911
rougeLsum  | fm: 78.523 | p: 78.276 | r: 78.736
r1fm+r2fm = 149.605

input #57 time: 0:08:32 | total time: 8:33:29


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.7275861873960396
highest_index [0]
highest [0.7275861873960396]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.0175349712371826 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.993588387966156 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9804711937904358 for ['[CLS] things reggie on guinnessllet continue special the chan (ness grew prone moffatockshire [SEP]']
[Init] best rec loss: 0.9796873331069946 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9767346978187561 for ['[CLS]ety spider gmina hypothesisjali brett endorsedhof avoid " joinsop programme friends designated looks [SEP]']
[Init] best rec loss: 0.9579958915710449 for ['[CLS] partner kickoff message oh hills edge wind mono stainless few sk closet clay fair ole port [SEP]']
[Init] best rec loss: 0.9565151929855347 for ['[CLS] sure tel china lose neutral central never an there after louis concentratione jack boysnted [SEP]']
[Init] best rec loss: 0.9416272044181824 for ['[CLS] shield anything damon venom sitting led trumppole purdue bigاural failed proposal sketch lea [SEP]']
[Init] best rec loss: 0.936216413974762 for ['[CLS] bellsignant river animals don cracked ace behind lid tasha des aden reception add bu fully [SEP]']
[Init] best perm rec loss: 0.9352701306343079 for ['[CLS] don behind ace cracked reception bu addignant river fully des aden tasha lid bells animals [SEP]']
[Init] best perm rec loss: 0.9345235824584961 for ['[CLS] bells tasha don river cracked animalsignant ace des fully reception aden bu add behind lid [SEP]']
[Init] best perm rec loss: 0.934463381767273 for ['[CLS] addignant animals lid ace cracked don river behind fully aden reception bells tasha bu des [SEP]']
[Init] best perm rec loss: 0.9334470629692078 for ['[CLS] aceignant cracked aden lid fully river tasha des animals behind add reception don bells bu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.622 (perp=12.885, rec=0.588, cos=0.458), tot_loss_proj:4.581 [t=0.22s]
prediction: ['[CLS] account printed midnight holders idross creation fine a goat commitment concession painful nicezhou her [SEP]']
[ 100/2000] tot_loss=3.441 (perp=12.551, rec=0.485, cos=0.446), tot_loss_proj:4.483 [t=0.22s]
prediction: ['[CLS] meeting story hour institution good says triumph expensive the dump funeral racing screams trophy boone melee [SEP]']
[ 150/2000] tot_loss=3.602 (perp=13.246, rec=0.485, cos=0.468), tot_loss_proj:4.558 [t=0.22s]
prediction: ['[CLS] meeting story hour institution an story love schneider a waste funeral ears screamsismurai melee [SEP]']
[ 200/2000] tot_loss=3.562 (perp=13.056, rec=0.525, cos=0.426), tot_loss_proj:4.529 [t=0.22s]
prediction: ['[CLS] gain story hour institution : story story relevant become waste xander ears screamsismurai melee [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.280 (perp=12.330, rec=0.441, cos=0.373), tot_loss_proj:4.297 [t=0.22s]
prediction: ['[CLS] feature story hour institution the story story relevant become slang xanderis screams bannedurailence [SEP]']
[ 300/2000] tot_loss=3.264 (perp=12.241, rec=0.383, cos=0.432), tot_loss_proj:4.402 [t=0.22s]
prediction: ['[CLS] feature story decades institution the story story significance is slang xander trophy screams mouthurailence [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.145 (perp=11.703, rec=0.392, cos=0.412), tot_loss_proj:4.302 [t=0.22s]
prediction: ['[CLS] need story decades love the story horror importance is h hardship boyfriend thriller banned innocence information [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.335 (perp=12.712, rec=0.384, cos=0.409), tot_loss_proj:4.490 [t=0.22s]
prediction: ['[CLS] need story decades love story screams the expensive is h sweethearturi congratulationsityilation abuse [SEP]']
[ 450/2000] tot_loss=3.183 (perp=12.260, rec=0.360, cos=0.371), tot_loss_proj:4.424 [t=0.22s]
prediction: ['[CLS] need story decades love story screams the expensive is h availabilityuri congratulationsgraphilation demands [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.799 (perp=12.523, rec=0.738, cos=0.557), tot_loss_proj:4.392 [t=0.22s]
prediction: ['[CLS] need story hour demeanor story screams the expensive is cigarette breuninguri mouth innocenceilation demands [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.498 (perp=12.925, rec=0.442, cos=0.470), tot_loss_proj:4.570 [t=0.22s]
prediction: ['[CLS] need story regatta uprising subject horror a ears the cigarette breuning police issn storyilation innocence [SEP]']
[ 600/2000] tot_loss=3.323 (perp=12.408, rec=0.391, cos=0.450), tot_loss_proj:4.447 [t=0.22s]
prediction: ['[CLS] ideal story fifteen narrative subject horror an ears is slavery goodman police expensive storyilation innocence [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.241 (perp=12.087, rec=0.369, cos=0.455), tot_loss_proj:4.327 [t=0.22s]
prediction: ['[CLS] ideal story fifteen narrative subject horror an ears is cigarette goodman expensive initial storyilation innocence [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.122 (perp=11.676, rec=0.354, cos=0.433), tot_loss_proj:4.282 [t=0.22s]
prediction: ['[CLS] ideal story horror narrative subject fifteen an ears is cigarette goodman expensive initial storyilation innocence [SEP]']
[ 750/2000] tot_loss=3.115 (perp=11.676, rec=0.347, cos=0.433), tot_loss_proj:4.282 [t=0.22s]
prediction: ['[CLS] ideal story horror narrative subject fifteen an ears is cigarette goodman expensive initial storyilation innocence [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.315 (perp=12.600, rec=0.346, cos=0.449), tot_loss_proj:4.382 [t=0.22s]
prediction: ['[CLS] ideal story horror narrative observation fifteen an ears is cigarette goodman importance initialilation innocence friendship [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.235 (perp=12.183, rec=0.336, cos=0.463), tot_loss_proj:3.974 [t=0.22s]
prediction: ['[CLS] ideal story inspirational love treatment fifteen an ears is cigaretteilation valuable initial goodman innocence innocence [SEP]']
[ 900/2000] tot_loss=3.100 (perp=11.714, rec=0.332, cos=0.425), tot_loss_proj:3.973 [t=0.22s]
prediction: ['[CLS] ideal story inspirational love treatment fifteen the ears is cigaretteilation valuable initial goodman innocence innocence [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=3.099 (perp=11.658, rec=0.337, cos=0.430), tot_loss_proj:3.919 [t=0.22s]
prediction: ['[CLS] ideal love story inspirational treatment fifteen an ears is cigaretteilation valuable encounter abilities innocence story [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=3.179 (perp=11.984, rec=0.340, cos=0.442), tot_loss_proj:4.131 [t=0.22s]
prediction: ['[CLS] ideal love story inspirational treatment fifteen an ears valuable encounterructured is cigaretteilation innocence innocence [SEP]']
[1050/2000] tot_loss=3.339 (perp=12.888, rec=0.330, cos=0.431), tot_loss_proj:4.382 [t=0.22s]
prediction: ['[CLS] of format story inspirational treatment fifteen theure valuable encounterructured is cigaretteilation innocence love [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=3.068 (perp=11.308, rec=0.336, cos=0.470), tot_loss_proj:3.980 [t=0.22s]
prediction: ['[CLS] of love story inspirational treatment whose the abilities ears valuable encounter is cigaretteilation innocence innocence [SEP]']
Attempt swap
Put prefix at the end
[1150/2000] tot_loss=3.023 (perp=11.405, rec=0.337, cos=0.404), tot_loss_proj:3.979 [t=0.22s]
prediction: ['[CLS] innocence ideal love story inspirational treatment whose the abilities ears valuable encounter is cigaretteilation innocence [SEP]']
[1200/2000] tot_loss=3.089 (perp=11.443, rec=0.324, cos=0.477), tot_loss_proj:4.008 [t=0.22s]
prediction: ['[CLS] innocence ideal love story inspirational treatment its the abilities ears valuable encounter is cigaretteilation innocence [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=3.010 (perp=11.095, rec=0.325, cos=0.466), tot_loss_proj:3.886 [t=0.22s]
prediction: ['[CLS] innocence ideal love story inspirational capturing its valuable the abilitiesure encounter is cigaretteilation innocence [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=2.966 (perp=10.874, rec=0.317, cos=0.474), tot_loss_proj:3.886 [t=0.22s]
prediction: ['[CLS] innocence ideal love story inspirational capturing its valuable lurking theure encounter is cigaretteilation innocence [SEP]']
[1350/2000] tot_loss=2.955 (perp=10.874, rec=0.315, cos=0.466), tot_loss_proj:3.888 [t=0.22s]
prediction: ['[CLS] innocence ideal love story inspirational capturing its valuable lurking theure encounter is cigaretteilation innocence [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=3.018 (perp=11.270, rec=0.313, cos=0.451), tot_loss_proj:3.908 [t=0.22s]
prediction: ['[CLS] love ideal love story capturing whose inspirational valuable lurking theure encounter is cigaretteilation innocence [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=3.068 (perp=11.405, rec=0.317, cos=0.471), tot_loss_proj:4.125 [t=0.22s]
prediction: ['[CLS] of love story capturing whose inspirational valuable lurking the innocenceure encounter is cigaretteilation innocence [SEP]']
[1500/2000] tot_loss=3.166 (perp=11.842, rec=0.314, cos=0.483), tot_loss_proj:4.163 [t=0.22s]
prediction: ['[CLS] of love story capturing fifteen inspirational valuable lurking the innocenceure encounter is cigaretteilation innocence [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.869 (perp=10.520, rec=0.305, cos=0.459), tot_loss_proj:3.901 [t=0.22s]
prediction: ['[CLS] innocence of love story capturing whose inspirational valuable lurking the chesapeake encounter is cigaretteilation innocence [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.783 (perp=10.007, rec=0.324, cos=0.458), tot_loss_proj:3.725 [t=0.22s]
prediction: ['[CLS] innocence of love story whose inspirational valuable lurking the chesapeake encounter is cigaretteilation capturing innocence [SEP]']
[1650/2000] tot_loss=2.774 (perp=10.007, rec=0.313, cos=0.460), tot_loss_proj:3.722 [t=0.22s]
prediction: ['[CLS] innocence of love story whose inspirational valuable lurking the chesapeake encounter is cigaretteilation capturing innocence [SEP]']
Attempt swap
[1700/2000] tot_loss=2.768 (perp=10.007, rec=0.312, cos=0.454), tot_loss_proj:3.724 [t=0.22s]
prediction: ['[CLS] innocence of love story whose inspirational valuable lurking the chesapeake encounter is cigaretteilation capturing innocence [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.825 (perp=10.290, rec=0.309, cos=0.458), tot_loss_proj:3.633 [t=0.22s]
prediction: ['[CLS] valuable of love story whose inspirational innocence virtues the chesapeake encounter is cigaretteilation capturing innocence [SEP]']
[1800/2000] tot_loss=2.815 (perp=10.290, rec=0.308, cos=0.449), tot_loss_proj:3.635 [t=0.22s]
prediction: ['[CLS] valuable of love story whose inspirational innocence virtues the chesapeake encounter is cigaretteilation capturing innocence [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.799 (perp=10.120, rec=0.311, cos=0.465), tot_loss_proj:3.680 [t=0.22s]
prediction: ['[CLS] storytelling of love story whose inspirational innocence valuable the chesapeake encounter is cigaretteilation capturing innocence [SEP]']
Attempt swap
[1900/2000] tot_loss=2.809 (perp=10.120, rec=0.310, cos=0.475), tot_loss_proj:3.683 [t=0.22s]
prediction: ['[CLS] storytelling of love story whose inspirational innocence valuable the chesapeake encounter is cigaretteilation capturing innocence [SEP]']
[1950/2000] tot_loss=2.791 (perp=10.120, rec=0.305, cos=0.462), tot_loss_proj:3.681 [t=0.22s]
prediction: ['[CLS] storytelling of love story whose inspirational innocence valuable the chesapeake encounter is cigaretteilation capturing innocence [SEP]']
Attempt swap
[2000/2000] tot_loss=2.796 (perp=10.120, rec=0.306, cos=0.466), tot_loss_proj:3.683 [t=0.22s]
prediction: ['[CLS] storytelling of love story whose inspirational innocence valuable the chesapeake encounter is cigaretteilation capturing innocence [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] storytelling of love story whose inspirational innocence valuable the chesapeake encounter is cigaretteilation capturing innocence [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 64.706 | r: 68.750
rouge2     | fm: 6.452 | p: 6.250 | r: 6.667
rougeL     | fm: 36.364 | p: 35.294 | r: 37.500
rougeLsum  | fm: 36.364 | p: 35.294 | r: 37.500
r1fm+r2fm = 73.118

[Aggregate metrics]:
rouge1     | fm: 90.769 | p: 90.528 | r: 91.210
rouge2     | fm: 57.450 | p: 57.398 | r: 57.498
rougeL     | fm: 77.813 | p: 77.634 | r: 78.167
rougeLsum  | fm: 77.673 | p: 77.519 | r: 77.966
r1fm+r2fm = 148.219

input #58 time: 0:08:44 | total time: 8:42:14


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.732254743198737
highest_index [0]
highest [0.732254743198737]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.8945876359939575 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.8534585237503052 for ['[CLS] poll dominance intine drop silvertock politician wrappedve complete hot reading team disco world [SEP]']
[Init] best rec loss: 0.8462024331092834 for ['[CLS] mala minute theory mandatory stands after mere figure number roth sister locomotives bombay bavarian late athlete [SEP]']
[Init] best rec loss: 0.8291623592376709 for ['[CLS]notes urban shape atliest not filterae titled making prize wait sex ste front coach [SEP]']
[Init] best rec loss: 0.8080673217773438 for ['[CLS] key stafforddial done colony midst kmdden face ɾord muscle warning ( wife organic [SEP]']
[Init] best rec loss: 0.7950927019119263 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best rec loss: 0.7869462370872498 for ['[CLS] creator war pepper mortal knights dinner warm helped tasting fringe vsonate cricket elitecoat counterpart [SEP]']
[Init] best perm rec loss: 0.785502016544342 for ['[CLS] fringe war pepper knightsonate cricket counterpart tasting elitecoat vs warm helped mortal dinner creator [SEP]']
[Init] best perm rec loss: 0.7849206328392029 for ['[CLS] war creatoronate fringe elite warm knights helped mortal vscoat dinner pepper cricket tasting counterpart [SEP]']
[Init] best perm rec loss: 0.7823941707611084 for ['[CLS]coat vs creator cricket helped war counterpart warm fringe dinner pepper mortalonate knights tasting elite [SEP]']
[Init] best perm rec loss: 0.7822585105895996 for ['[CLS] war knights dinner vs creatorcoat tasting elite pepper helped warmonate fringe mortal cricket counterpart [SEP]']
[Init] best perm rec loss: 0.7819263339042664 for ['[CLS] mortal knights counterpart war vs cricket tasting pepper creator warmcoat fringe helpedonate elite dinner [SEP]']
[Init] best perm rec loss: 0.7812821865081787 for ['[CLS]onate helped pepper fringe creator tasting counterpart war vs dinner cricket mortalcoat elite knights warm [SEP]']
[Init] best perm rec loss: 0.7811040282249451 for ['[CLS] creatoronate war pepper helped tasting mortal counterpart elite dinner fringe cricketcoat vs knights warm [SEP]']
[Init] best perm rec loss: 0.780991792678833 for ['[CLS] mortal vs pepper creator tasting fringe knightsonate warm warcoat counterpart cricket dinner elite helped [SEP]']
[Init] best perm rec loss: 0.780899167060852 for ['[CLS] cricket warcoat mortal elite pepper counterpart helpedonate tasting fringe knights warm vs dinner creator [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.190 (perp=11.991, rec=0.324, cos=0.467), tot_loss_proj:4.165 [t=0.22s]
prediction: ['[CLS]bftic combination human alone have style will tests singer woman hair of when festival team [SEP]']
[ 100/2000] tot_loss=2.927 (perp=11.321, rec=0.209, cos=0.454), tot_loss_proj:3.622 [t=0.22s]
prediction: ['[CLS]ism youngismismism the char young has woman screen char of had festival woman [SEP]']
[ 150/2000] tot_loss=2.826 (perp=11.061, rec=0.155, cos=0.458), tot_loss_proj:3.677 [t=0.22s]
prediction: ['[CLS]ism young howismism theism a has knows screen char of who a woman [SEP]']
[ 200/2000] tot_loss=2.906 (perp=11.566, rec=0.135, cos=0.458), tot_loss_proj:3.609 [t=0.22s]
prediction: ['[CLS]ism young how charism theism a has knows screen char of who a woman [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.721 (perp=10.637, rec=0.133, cos=0.460), tot_loss_proj:3.570 [t=0.22s]
prediction: ['[CLS]ism young knows hasism theism aism knows screen char of who the woman [SEP]']
[ 300/2000] tot_loss=2.726 (perp=10.798, rec=0.105, cos=0.461), tot_loss_proj:3.635 [t=0.22s]
prediction: ['[CLS]ism young knows hasans theism aism knows screen char of who the woman [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.550 (perp=9.935, rec=0.102, cos=0.461), tot_loss_proj:3.352 [t=0.22s]
prediction: ['[CLS]ism young knows hasa theism aism screen char knows of who the woman [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.475 (perp=9.342, rec=0.151, cos=0.456), tot_loss_proj:3.025 [t=0.22s]
prediction: ['[CLS]ism hasa young knows theism aism screen char knows of who the woman [SEP]']
[ 450/2000] tot_loss=2.421 (perp=9.246, rec=0.112, cos=0.460), tot_loss_proj:3.025 [t=0.22s]
prediction: ['[CLS]ism hasa young knows theism a hold screen char knows of who the woman [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.304 (perp=8.709, rec=0.101, cos=0.460), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] hasisma young knows theism a hold screen char knows of who the woman [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.261 (perp=8.576, rec=0.087, cos=0.459), tot_loss_proj:2.781 [t=0.22s]
prediction: ['[CLS] hasisma young knows theism a screen char knows hold of who the woman [SEP]']
[ 600/2000] tot_loss=2.273 (perp=8.576, rec=0.096, cos=0.462), tot_loss_proj:2.789 [t=0.22s]
prediction: ['[CLS] hasisma young knows theism a screen char knows hold of who the woman [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.267 (perp=8.576, rec=0.089, cos=0.463), tot_loss_proj:2.781 [t=0.22s]
prediction: ['[CLS] hasisma young knows theism a screen char knows hold of who the woman [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.201 (perp=8.210, rec=0.095, cos=0.463), tot_loss_proj:2.735 [t=0.22s]
prediction: ['[CLS] hasisma young knows theism of a screen char knows hold who the woman [SEP]']
[ 750/2000] tot_loss=2.193 (perp=8.210, rec=0.088, cos=0.463), tot_loss_proj:2.738 [t=0.22s]
prediction: ['[CLS] hasisma young knows theism of a screen char knows hold who the woman [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.120 (perp=7.899, rec=0.077, cos=0.463), tot_loss_proj:2.517 [t=0.22s]
prediction: ['[CLS] has charisma young knows theism of a screen knows hold who the woman [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.075 (perp=7.631, rec=0.088, cos=0.461), tot_loss_proj:2.470 [t=0.22s]
prediction: ['[CLS] has young charisma knows theism of a screen knows hold who the woman [SEP]']
[ 900/2000] tot_loss=2.074 (perp=7.631, rec=0.086, cos=0.462), tot_loss_proj:2.480 [t=0.22s]
prediction: ['[CLS] has young charisma knows theism of a screen knows hold who the woman [SEP]']
Attempt swap
Put prefix at the end
[ 950/2000] tot_loss=1.940 (perp=6.934, rec=0.092, cos=0.461), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] young charisma knows theism of a screen knows hold who the woman has [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.848 (perp=6.478, rec=0.090, cos=0.462), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] young charisma knows theism of a woman knows hold who the screen has [SEP]']
[1050/2000] tot_loss=1.843 (perp=6.478, rec=0.084, cos=0.462), tot_loss_proj:2.241 [t=0.22s]
prediction: ['[CLS] young charisma knows theism of a woman knows hold who the screen has [SEP]']
Attempt swap
[1100/2000] tot_loss=1.848 (perp=6.478, rec=0.089, cos=0.463), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] young charisma knows theism of a woman knows hold who the screen has [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.832 (perp=6.402, rec=0.092, cos=0.460), tot_loss_proj:2.194 [t=0.22s]
prediction: ['[CLS] young charisma has theism of a woman knows hold who the screen knows [SEP]']
[1200/2000] tot_loss=1.825 (perp=6.402, rec=0.081, cos=0.463), tot_loss_proj:2.194 [t=0.22s]
prediction: ['[CLS] young charisma has theism of a woman knows hold who the screen knows [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.782 (perp=6.176, rec=0.085, cos=0.462), tot_loss_proj:2.134 [t=0.22s]
prediction: ['[CLS] charisma has theism of a young woman knows hold who the screen knows [SEP]']
Attempt swap
[1300/2000] tot_loss=1.780 (perp=6.176, rec=0.082, cos=0.463), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] charisma has theism of a young woman knows hold who the screen knows [SEP]']
[1350/2000] tot_loss=1.780 (perp=6.176, rec=0.082, cos=0.463), tot_loss_proj:2.134 [t=0.22s]
prediction: ['[CLS] charisma has theism of a young woman knows hold who the screen knows [SEP]']
Attempt swap
[1400/2000] tot_loss=1.783 (perp=6.176, rec=0.085, cos=0.463), tot_loss_proj:2.135 [t=0.22s]
prediction: ['[CLS] charisma has theism of a young woman knows hold who the screen knows [SEP]']
Attempt swap
[1450/2000] tot_loss=1.779 (perp=6.176, rec=0.081, cos=0.463), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] charisma has the how of a young woman knows hold who the screen knows [SEP]']
[1500/2000] tot_loss=1.785 (perp=6.176, rec=0.087, cos=0.463), tot_loss_proj:2.206 [t=0.22s]
prediction: ['[CLS] charisma has the how of a young woman knows hold who the screen knows [SEP]']
Attempt swap
[1550/2000] tot_loss=1.784 (perp=6.176, rec=0.085, cos=0.464), tot_loss_proj:2.201 [t=0.22s]
prediction: ['[CLS] charisma has the how of a young woman knows hold who the screen knows [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.700 (perp=5.642, rec=0.108, cos=0.464), tot_loss_proj:2.018 [t=0.22s]
prediction: ['[CLS] charisma has the hold of a young woman knows how who the screen knows [SEP]']
[1650/2000] tot_loss=1.684 (perp=5.642, rec=0.094, cos=0.462), tot_loss_proj:2.022 [t=0.22s]
prediction: ['[CLS] charisma has the hold of a young woman knows how who the screen knows [SEP]']
Attempt swap
[1700/2000] tot_loss=1.676 (perp=5.642, rec=0.084, cos=0.463), tot_loss_proj:2.026 [t=0.22s]
prediction: ['[CLS] charisma has the hold of a young woman knows how who the screen knows [SEP]']
Attempt swap
[1750/2000] tot_loss=1.683 (perp=5.642, rec=0.091, cos=0.464), tot_loss_proj:2.022 [t=0.22s]
prediction: ['[CLS] charisma has the hold of a young woman knows how who the screen knows [SEP]']
[1800/2000] tot_loss=1.679 (perp=5.642, rec=0.088, cos=0.463), tot_loss_proj:2.021 [t=0.22s]
prediction: ['[CLS] charisma has the hold of a young woman knows how who the screen knows [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.560 (perp=5.049, rec=0.087, cos=0.463), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] charisma has the hold of a young woman who knows how the screen knows [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.614 (perp=5.297, rec=0.094, cos=0.461), tot_loss_proj:1.875 [t=0.22s]
prediction: ['[CLS] charisma has the hold of a young woman who knows how the screen hold [SEP]']
[1950/2000] tot_loss=1.611 (perp=5.297, rec=0.089, cos=0.463), tot_loss_proj:1.878 [t=0.22s]
prediction: ['[CLS] charisma has the hold of a young woman who knows how the screen hold [SEP]']
Attempt swap
[2000/2000] tot_loss=1.609 (perp=5.297, rec=0.086, cos=0.463), tot_loss_proj:1.880 [t=0.22s]
prediction: ['[CLS] charisma has the hold of a young woman who knows how the screen hold [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] charisma has the how of a young woman knows hold who the screen knows [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.750 | p: 93.750 | r: 93.750
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 127.083

[Aggregate metrics]:
rouge1     | fm: 90.844 | p: 90.578 | r: 91.296
rouge2     | fm: 56.792 | p: 56.839 | r: 56.853
rougeL     | fm: 77.794 | p: 77.631 | r: 78.092
rougeLsum  | fm: 77.725 | p: 77.577 | r: 78.017
r1fm+r2fm = 147.636

input #59 time: 0:08:46 | total time: 8:51:01


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.7222054667134934
highest_index [0]
highest [0.7222054667134934]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9755795001983643 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9467499852180481 for ['[CLS] everything partnership bas gossip lies donegal directionbad his western ann arms [SEP]']
[Init] best rec loss: 0.9346325993537903 for ['[CLS] eddiedding whenly became northeast theo solid sighed signsrral frozen [SEP]']
[Init] best rec loss: 0.9157931208610535 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.9049416184425354 for ['[CLS] percent symbol budapest herald nets flavor shoppingted archlizer clock tight [SEP]']
[Init] best rec loss: 0.9046450853347778 for ['[CLS] bars bing sir set lyon nueva shutter hon featuring maybe voting land [SEP]']
[Init] best rec loss: 0.8953329920768738 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8907825946807861 for ['[CLS]chemist myselfkar waiting locking ribbon tear dreams mosaic dorothy sure... [SEP]']
[Init] best perm rec loss: 0.8885908126831055 for ['[CLS] tear myself dorothy... locking surechemist mosaic waitingkar dreams ribbon [SEP]']
[Init] best perm rec loss: 0.888241171836853 for ['[CLS] myselfkar mosaic sure...chemist locking ribbon dorothy waiting dreams tear [SEP]']
[Init] best perm rec loss: 0.8882129192352295 for ['[CLS] waiting mosaicchemist ribbon... dorothy myself locking tear dreams surekar [SEP]']
[Init] best perm rec loss: 0.8878060579299927 for ['[CLS]kar myself locking tear... dorothy ribbon dreams mosaicchemist sure waiting [SEP]']
[Init] best perm rec loss: 0.8860644102096558 for ['[CLS] dreams... surekar myselfchemist tear locking dorothy ribbon waiting mosaic [SEP]']
[Init] best perm rec loss: 0.8849848508834839 for ['[CLS] myselfchemist tear... mosaic locking dreams ribbon dorothy sure waitingkar [SEP]']
[Init] best perm rec loss: 0.8836047649383545 for ['[CLS]... ribbon dreams myself waiting lockingkar tear mosaic surechemist dorothy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.270 (perp=12.791, rec=0.248, cos=0.464), tot_loss_proj:3.604 [t=0.22s]
prediction: ['[CLS] circuit awkwardly [SEP]sitor is awkwardly story story awkwardly horror the hiding [SEP]']
[ 100/2000] tot_loss=3.045 (perp=12.065, rec=0.169, cos=0.463), tot_loss_proj:3.434 [t=0.22s]
prediction: ['[CLS] circuit awkwardly is paced is awkwardly story soap awkwardly paced the baggage [SEP]']
[ 150/2000] tot_loss=2.983 (perp=11.921, rec=0.126, cos=0.473), tot_loss_proj:3.381 [t=0.22s]
prediction: ['[CLS] circuit awkwardly is paced paced awkwardly story soap awkwardly soap the. [SEP]']
[ 200/2000] tot_loss=2.778 (perp=11.019, rec=0.103, cos=0.471), tot_loss_proj:3.304 [t=0.22s]
prediction: ['[CLS] circuit awkwardly is paced paced soap story soap awkwardly is the. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.126 (perp=12.693, rec=0.115, cos=0.473), tot_loss_proj:3.471 [t=0.22s]
prediction: ['[CLS] circuit awkwardly is the paced soap story soap awkwardlyh paced breuning [SEP]']
[ 300/2000] tot_loss=3.117 (perp=12.693, rec=0.099, cos=0.480), tot_loss_proj:3.476 [t=0.22s]
prediction: ['[CLS] circuit awkwardly is the paced soap story soap awkwardlyh paced breuning [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.713 (perp=10.696, rec=0.102, cos=0.472), tot_loss_proj:3.033 [t=0.22s]
prediction: ['[CLS] circuit awkwardly is the paced soap story. awkwardlyh paced soap [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.511 (perp=9.688, rec=0.098, cos=0.475), tot_loss_proj:2.825 [t=0.22s]
prediction: ['[CLS] circuit awkwardly is the paced soap opera.hh paced story [SEP]']
[ 450/2000] tot_loss=2.507 (perp=9.688, rec=0.097, cos=0.473), tot_loss_proj:2.826 [t=0.22s]
prediction: ['[CLS] circuit awkwardly is the paced soap opera.hh paced story [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.446 (perp=9.398, rec=0.089, cos=0.478), tot_loss_proj:2.727 [t=0.22s]
prediction: ['[CLS] circuit awkwardly is the paced soap opera pacedhh. story [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.305 (perp=8.681, rec=0.094, cos=0.475), tot_loss_proj:2.606 [t=0.22s]
prediction: ['[CLS] circuit awkwardly is the pacedh soap opera pacedh. story [SEP]']
[ 600/2000] tot_loss=2.416 (perp=9.328, rec=0.074, cos=0.476), tot_loss_proj:2.694 [t=0.22s]
prediction: ['[CLS] circuit awkwardly is the pacedh soap opera ish. story [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.553 (perp=9.916, rec=0.094, cos=0.477), tot_loss_proj:2.884 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the is awkwardly soap opera ish chorus story [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.299 (perp=8.635, rec=0.095, cos=0.477), tot_loss_proj:2.599 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is awkwardly soap opera ish story [SEP]']
[ 750/2000] tot_loss=2.300 (perp=8.635, rec=0.095, cos=0.478), tot_loss_proj:2.598 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is awkwardly soap opera ish story [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.159 (perp=7.940, rec=0.094, cos=0.477), tot_loss_proj:2.475 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus ish soap opera ish story [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.130 (perp=7.833, rec=0.088, cos=0.476), tot_loss_proj:2.434 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the ish soap opera ish story chorus [SEP]']
[ 900/2000] tot_loss=2.128 (perp=7.833, rec=0.083, cos=0.478), tot_loss_proj:2.435 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the ish soap opera ish story chorus [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.124 (perp=7.833, rec=0.080, cos=0.478), tot_loss_proj:2.430 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the ish soap opera ish story chorus [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.021 (perp=7.310, rec=0.082, cos=0.477), tot_loss_proj:2.332 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the ish chorus soap opera ish story [SEP]']
[1050/2000] tot_loss=2.031 (perp=7.310, rec=0.091, cos=0.478), tot_loss_proj:2.325 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the ish chorus soap opera ish story [SEP]']
Attempt swap
[1100/2000] tot_loss=2.025 (perp=7.310, rec=0.085, cos=0.478), tot_loss_proj:2.337 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the ish chorus soap opera ish story [SEP]']
Attempt swap
[1150/2000] tot_loss=2.021 (perp=7.310, rec=0.081, cos=0.478), tot_loss_proj:2.329 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the ish chorus soap opera ish story [SEP]']
[1200/2000] tot_loss=2.025 (perp=7.310, rec=0.085, cos=0.478), tot_loss_proj:2.334 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the ish chorus soap opera ish story [SEP]']
Attempt swap
[1250/2000] tot_loss=2.366 (perp=9.072, rec=0.073, cos=0.478), tot_loss_proj:2.683 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the is - chorus soap opera ish story [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.191 (perp=8.206, rec=0.072, cos=0.478), tot_loss_proj:2.541 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus - is soap opera ish story [SEP]']
[1350/2000] tot_loss=2.192 (perp=8.206, rec=0.073, cos=0.479), tot_loss_proj:2.540 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus - is soap opera ish story [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.146 (perp=7.973, rec=0.074, cos=0.477), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
Attempt swap
[1450/2000] tot_loss=2.155 (perp=7.973, rec=0.082, cos=0.478), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
[1500/2000] tot_loss=2.143 (perp=7.973, rec=0.070, cos=0.478), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
Attempt swap
[1550/2000] tot_loss=2.152 (perp=7.973, rec=0.080, cos=0.478), tot_loss_proj:2.516 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
Attempt swap
[1600/2000] tot_loss=2.146 (perp=7.973, rec=0.073, cos=0.478), tot_loss_proj:2.503 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
[1650/2000] tot_loss=2.154 (perp=7.973, rec=0.081, cos=0.478), tot_loss_proj:2.507 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
Attempt swap
[1700/2000] tot_loss=2.152 (perp=7.973, rec=0.079, cos=0.478), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
Attempt swap
[1750/2000] tot_loss=2.153 (perp=7.973, rec=0.080, cos=0.478), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
[1800/2000] tot_loss=2.151 (perp=7.973, rec=0.078, cos=0.478), tot_loss_proj:2.514 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
Attempt swap
[1850/2000] tot_loss=2.133 (perp=7.973, rec=0.060, cos=0.478), tot_loss_proj:2.507 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
Attempt swap
[1900/2000] tot_loss=2.155 (perp=7.973, rec=0.082, cos=0.478), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
[1950/2000] tot_loss=2.150 (perp=7.973, rec=0.077, cos=0.478), tot_loss_proj:2.508 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
Attempt swap
[2000/2000] tot_loss=2.141 (perp=7.973, rec=0.068, cos=0.478), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] circuit awkwardly paced the chorus is soap opera - ish story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 57.143 | p: 54.545 | r: 60.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 152.795

[Aggregate metrics]:
rouge1     | fm: 90.971 | p: 90.590 | r: 91.439
rouge2     | fm: 57.083 | p: 57.030 | r: 57.107
rougeL     | fm: 77.915 | p: 77.686 | r: 78.204
rougeLsum  | fm: 77.658 | p: 77.462 | r: 77.997
r1fm+r2fm = 148.054

input #60 time: 0:08:44 | total time: 8:59:45


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.7328401341574982
highest_index [0]
highest [0.7328401341574982]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9741930365562439 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9736942052841187 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9583994746208191 for ['[CLS] alta http cocked [SEP]']
[Init] best rec loss: 0.954050600528717 for ['[CLS] tiny poor rail [SEP]']
[Init] best rec loss: 0.94977867603302 for ['[CLS] prints england vague [SEP]']
[Init] best rec loss: 0.9270764589309692 for ['[CLS] mouth lastless [SEP]']
[Init] best rec loss: 0.9224151968955994 for ['[CLS] readyppetphonic [SEP]']
[Init] best rec loss: 0.917720377445221 for ['[CLS] quo couplesmer [SEP]']
[Init] best rec loss: 0.8807842135429382 for ['[CLS] says -vino [SEP]']
[Init] best rec loss: 0.8740261793136597 for ['[CLS] vehicle surrounding south [SEP]']
[Init] best perm rec loss: 0.8699088096618652 for ['[CLS] surrounding vehicle south [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.312 (perp=8.309, rec=0.194, cos=0.457), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 100/2000] tot_loss=2.281 (perp=8.309, rec=0.165, cos=0.455), tot_loss_proj:2.495 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 150/2000] tot_loss=2.269 (perp=8.309, rec=0.151, cos=0.456), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 200/2000] tot_loss=2.267 (perp=8.309, rec=0.149, cos=0.457), tot_loss_proj:2.508 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.257 (perp=8.309, rec=0.138, cos=0.457), tot_loss_proj:2.503 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 300/2000] tot_loss=2.255 (perp=8.309, rec=0.136, cos=0.457), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.261 (perp=8.309, rec=0.141, cos=0.458), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.244 (perp=8.309, rec=0.125, cos=0.457), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 450/2000] tot_loss=2.254 (perp=8.309, rec=0.135, cos=0.458), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.259 (perp=8.309, rec=0.139, cos=0.458), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.265 (perp=8.309, rec=0.146, cos=0.458), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 600/2000] tot_loss=2.260 (perp=8.309, rec=0.141, cos=0.458), tot_loss_proj:2.491 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.247 (perp=8.309, rec=0.127, cos=0.458), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.260 (perp=8.309, rec=0.141, cos=0.458), tot_loss_proj:2.484 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 750/2000] tot_loss=2.257 (perp=8.309, rec=0.138, cos=0.458), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.256 (perp=8.309, rec=0.137, cos=0.458), tot_loss_proj:2.484 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.253 (perp=8.309, rec=0.134, cos=0.457), tot_loss_proj:2.483 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 900/2000] tot_loss=2.254 (perp=8.309, rec=0.135, cos=0.457), tot_loss_proj:2.493 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.254 (perp=8.309, rec=0.135, cos=0.457), tot_loss_proj:2.502 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1000/2000] tot_loss=2.244 (perp=8.309, rec=0.125, cos=0.457), tot_loss_proj:2.486 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[1050/2000] tot_loss=2.259 (perp=8.309, rec=0.140, cos=0.457), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1100/2000] tot_loss=2.243 (perp=8.309, rec=0.124, cos=0.457), tot_loss_proj:2.492 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1150/2000] tot_loss=2.911 (perp=11.652, rec=0.124, cos=0.457), tot_loss_proj:3.872 [t=0.22s]
prediction: ['[CLS] beautifuliful scene [SEP]']
[1200/2000] tot_loss=2.930 (perp=11.652, rec=0.142, cos=0.457), tot_loss_proj:3.872 [t=0.22s]
prediction: ['[CLS] beautifuliful scene [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.379 (perp=8.900, rec=0.141, cos=0.457), tot_loss_proj:2.801 [t=0.22s]
prediction: ['[CLS] scene beautiful scene [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.243 (perp=8.309, rec=0.125, cos=0.456), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[1350/2000] tot_loss=2.926 (perp=11.652, rec=0.139, cos=0.457), tot_loss_proj:3.879 [t=0.22s]
prediction: ['[CLS] beautifuliful scene [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=2.365 (perp=8.900, rec=0.128, cos=0.457), tot_loss_proj:2.793 [t=0.22s]
prediction: ['[CLS] scene beautiful scene [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.650 (perp=10.274, rec=0.139, cos=0.456), tot_loss_proj:2.854 [t=0.22s]
prediction: ['[CLS] beautiful depicting scene [SEP]']
[1500/2000] tot_loss=2.653 (perp=10.274, rec=0.141, cos=0.457), tot_loss_proj:2.851 [t=0.22s]
prediction: ['[CLS] beautiful depicting scene [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.137 (perp=7.752, rec=0.129, cos=0.457), tot_loss_proj:2.327 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1600/2000] tot_loss=2.145 (perp=7.752, rec=0.138, cos=0.457), tot_loss_proj:2.341 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1650/2000] tot_loss=2.140 (perp=7.752, rec=0.132, cos=0.457), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1700/2000] tot_loss=2.629 (perp=10.214, rec=0.129, cos=0.457), tot_loss_proj:2.883 [t=0.22s]
prediction: ['[CLS] depicting beautiful scene [SEP]']
Attempt swap
[1750/2000] tot_loss=2.630 (perp=10.214, rec=0.130, cos=0.457), tot_loss_proj:2.883 [t=0.22s]
prediction: ['[CLS] depicting beautiful scene [SEP]']
[1800/2000] tot_loss=2.638 (perp=10.214, rec=0.138, cos=0.457), tot_loss_proj:2.874 [t=0.22s]
prediction: ['[CLS] depicting beautiful scene [SEP]']
Attempt swap
[1850/2000] tot_loss=2.641 (perp=10.214, rec=0.141, cos=0.457), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] depicting beautiful scene [SEP]']
Attempt swap
[1900/2000] tot_loss=2.640 (perp=10.214, rec=0.140, cos=0.457), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] depicting beautiful scene [SEP]']
[1950/2000] tot_loss=2.627 (perp=10.214, rec=0.127, cos=0.457), tot_loss_proj:2.878 [t=0.22s]
prediction: ['[CLS] depicting beautiful scene [SEP]']
Attempt swap
[2000/2000] tot_loss=2.613 (perp=10.100, rec=0.136, cos=0.457), tot_loss_proj:2.911 [t=0.22s]
prediction: ['[CLS] becky beautiful scene [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] depicting beautiful scene [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 80.000 | r: 100.000
rouge2     | fm: 57.143 | p: 50.000 | r: 66.667
rougeL     | fm: 88.889 | p: 80.000 | r: 100.000
rougeLsum  | fm: 88.889 | p: 80.000 | r: 100.000
r1fm+r2fm = 146.032

[Aggregate metrics]:
rouge1     | fm: 90.827 | p: 90.373 | r: 91.522
rouge2     | fm: 57.015 | p: 56.837 | r: 57.145
rougeL     | fm: 78.051 | p: 77.688 | r: 78.592
rougeLsum  | fm: 77.987 | p: 77.612 | r: 78.468
r1fm+r2fm = 147.842

input #61 time: 0:08:43 | total time: 9:08:29


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.7327054891626696
highest_index [0]
highest [0.7327054891626696]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9210430979728699 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9054271578788757 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.9044620394706726 for ['[CLS] young dance sacrifice cross regular drove huffington trip client gloss chosen butte actually t running buywide sms custom floating mug [SEP]']
[Init] best rec loss: 0.8956162929534912 for ['[CLS] potential sub practice had e european recruitingsight probable conversion plates rubang taxes braced theorem themselves nu us wolfe mid [SEP]']
[Init] best rec loss: 0.8944987058639526 for ['[CLS]ining strata won suitedtis near isaac bull worship here techp perhaps assistant kerman negative fisulsion ash too skill [SEP]']
[Init] best rec loss: 0.8927640318870544 for ['[CLS] largest absent prize viewer onradbius sector pastoral servant grown [CLS]oire meant utc academy forces closed laid clock full [SEP]']
[Init] best rec loss: 0.892726719379425 for ['[CLS] scout cafeceaeswch novel spot latitude romanwar winter largely talksord liberal sophiehon iii pitchaceathing [SEP]']
[Init] best rec loss: 0.8855662941932678 for ['[CLS]ecure armedria obvious commission symbol echo drinking testified mothergaard reacher executive dressed playing but name ups [SEP] [MASK] kala [SEP]']
[Init] best rec loss: 0.879378616809845 for ['[CLS] part remembered victor jayne imagined♭ basket against cheeks barrow battalion whilefold informed had higher outstanding ezio ramirez malta pinyin [SEP]']
[Init] best perm rec loss: 0.8793048858642578 for ['[CLS] remembered part ezio malta jayne had pinyin♭ basket informedfold ramirez victor while against cheeks imagined outstanding barrow higher battalion [SEP]']
[Init] best perm rec loss: 0.8787640929222107 for ['[CLS]fold remembered while battalion basket cheeks pinyin victor higher ramirez part outstanding informed had jayne imagined barrow malta♭ against ezio [SEP]']
[Init] best perm rec loss: 0.8764954805374146 for ['[CLS] ezio battalion had basket malta pinyin higher♭ against victor informed imagined cheeks barrowfold part remembered outstanding jayne while ramirez [SEP]']
[Init] best perm rec loss: 0.8762686252593994 for ['[CLS] higher basket rememberedfold ramirez imagined barrow battalion while part had outstanding jayne ezio informed♭ against pinyin victor malta cheeks [SEP]']
[Init] best perm rec loss: 0.8752690553665161 for ['[CLS] barrow against while part imagined ezio higher malta ramirez victor cheeks jayne basket pinyin informedfold♭ battalion remembered had outstanding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.200 (perp=11.963, rec=0.348, cos=0.460), tot_loss_proj:4.211 [t=0.22s]
prediction: ['[CLS] iowa augustus : a best prevention season drama need best theious call call superplay creativity horrible personally of mikey [SEP]']
[ 100/2000] tot_loss=2.706 (perp=10.086, rec=0.236, cos=0.452), tot_loss_proj:3.688 [t=0.22s]
prediction: ['[CLS] films grace to a best prevention movies, season grace making grace of call one war making horrible movies of movies [SEP]']
[ 150/2000] tot_loss=2.639 (perp=10.084, rec=0.167, cos=0.455), tot_loss_proj:3.894 [t=0.22s]
prediction: ['[CLS] ever grace to one best prevention movies toarding grace making it of blame one war making horrible movies the movies [SEP]']
[ 200/2000] tot_loss=2.669 (perp=10.359, rec=0.138, cos=0.459), tot_loss_proj:3.746 [t=0.22s]
prediction: ['[CLS] ever grace to one best prevention movies rather judging grace making it of blame the war best ever movies the movies [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.565 (perp=9.732, rec=0.162, cos=0.457), tot_loss_proj:3.822 [t=0.22s]
prediction: ['[CLS] ever grace to one best prevention of to rather grace making it to it the war movies awful movies of portray [SEP]']
[ 300/2000] tot_loss=2.506 (perp=9.584, rec=0.130, cos=0.459), tot_loss_proj:3.430 [t=0.22s]
prediction: ['[CLS] ever grace to one best prevention of to calling grace making it to it the war movies first movies of portray [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.360 (perp=8.909, rec=0.121, cos=0.457), tot_loss_proj:3.642 [t=0.22s]
prediction: ['[CLS] ever grace to one best prevention of to blame grace making it to it the war movies taken movies of call [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.277 (perp=8.471, rec=0.128, cos=0.455), tot_loss_proj:3.081 [t=0.22s]
prediction: ['[CLS] grace to one best prevention of would ever like grace making it to it the war movies variety always to call [SEP]']
[ 450/2000] tot_loss=2.481 (perp=9.590, rec=0.106, cos=0.457), tot_loss_proj:3.809 [t=0.22s]
prediction: ['[CLS] grace to one best prevention of rather ever like grace making it to it the war movies variety blame of call [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.340 (perp=8.888, rec=0.105, cos=0.458), tot_loss_proj:3.654 [t=0.22s]
prediction: ['[CLS] grace to one best prevention of variety ever blame grace making it to it the war movies rather blame of call [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.280 (perp=8.564, rec=0.109, cos=0.458), tot_loss_proj:3.568 [t=0.22s]
prediction: ['[CLS] grace to one of prevention of variety ever blame grace making it to it the war movies rather blame best call [SEP]']
[ 600/2000] tot_loss=2.283 (perp=8.630, rec=0.100, cos=0.457), tot_loss_proj:3.586 [t=0.22s]
prediction: ['[CLS] grace to one of prevention of variety ever for grace making it to it the war movies rather blame best call [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.188 (perp=8.147, rec=0.101, cos=0.458), tot_loss_proj:3.410 [t=0.22s]
prediction: ['[CLS] grace to one of prevention of variety ever for grace making it to blame it the war movies rather best call [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.174 (perp=8.066, rec=0.101, cos=0.460), tot_loss_proj:3.484 [t=0.22s]
prediction: ['[CLS] grace to one to prevention of variety for ever grace making it to blame it the war movies rather best call [SEP]']
[ 750/2000] tot_loss=2.165 (perp=8.066, rec=0.094, cos=0.458), tot_loss_proj:3.484 [t=0.22s]
prediction: ['[CLS] grace to one to prevention of variety for ever grace making it to blame it the war movies rather best call [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.137 (perp=7.890, rec=0.102, cos=0.458), tot_loss_proj:3.447 [t=0.22s]
prediction: ['[CLS] grace to blame to prevention of variety for ever grace making it to one it the war movies rather best call [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.341 (perp=8.679, rec=0.147, cos=0.458), tot_loss_proj:3.632 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of occurring for ever for making blame of one it to war movies rather best call [SEP]']
[ 900/2000] tot_loss=2.210 (perp=8.222, rec=0.110, cos=0.456), tot_loss_proj:3.509 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention blame occurring for ever grace making blame of one it to war movies rather best call [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.181 (perp=8.093, rec=0.106, cos=0.456), tot_loss_proj:3.479 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention blame occurring for ever grace making blame of it one to war movies rather best call [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.207 (perp=8.264, rec=0.097, cos=0.457), tot_loss_proj:3.516 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention blame grace for ever number making blame of it one to war movies rather best call [SEP]']
[1050/2000] tot_loss=2.206 (perp=8.264, rec=0.096, cos=0.457), tot_loss_proj:3.521 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention blame grace for ever number making blame of it one to war movies rather best call [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.124 (perp=7.841, rec=0.100, cos=0.456), tot_loss_proj:3.488 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention blame never to ever from making blame of it one for war movies rather best call [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.104 (perp=7.698, rec=0.108, cos=0.457), tot_loss_proj:3.437 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to ever for making blame of it one from war movies rather best call [SEP]']
[1200/2000] tot_loss=2.091 (perp=7.698, rec=0.095, cos=0.457), tot_loss_proj:3.435 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to ever for making blame of it one from war movies rather best call [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.021 (perp=7.329, rec=0.098, cos=0.457), tot_loss_proj:3.365 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to ever for making blame from it one of war movies rather best call [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.976 (perp=7.098, rec=0.100, cos=0.457), tot_loss_proj:3.299 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to blame for making ever from it one of war movies rather best call [SEP]']
[1350/2000] tot_loss=1.977 (perp=7.098, rec=0.101, cos=0.457), tot_loss_proj:3.303 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to blame for making ever from it one of war movies rather best call [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.961 (perp=7.050, rec=0.094, cos=0.457), tot_loss_proj:3.291 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to blame for ever making from it one of war movies rather best call [SEP]']
Attempt swap
[1450/2000] tot_loss=1.973 (perp=7.050, rec=0.106, cos=0.457), tot_loss_proj:3.290 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to blame for ever making from it one of war movies rather best call [SEP]']
[1500/2000] tot_loss=1.998 (perp=7.231, rec=0.095, cos=0.457), tot_loss_proj:3.328 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to blame for ever making from it one the war movies rather best call [SEP]']
Attempt swap
[1550/2000] tot_loss=2.003 (perp=7.231, rec=0.100, cos=0.457), tot_loss_proj:3.328 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to blame for ever making from it one the war movies rather best call [SEP]']
Attempt swap
[1600/2000] tot_loss=2.000 (perp=7.231, rec=0.097, cos=0.457), tot_loss_proj:3.328 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to blame for ever making from it one the war movies rather best call [SEP]']
[1650/2000] tot_loss=1.998 (perp=7.231, rec=0.095, cos=0.457), tot_loss_proj:3.325 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to blame for ever making from it one the war movies rather best call [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.995 (perp=7.257, rec=0.087, cos=0.457), tot_loss_proj:3.337 [t=0.22s]
prediction: ['[CLS] grace to blame the prevention of never to blame ever for making from it one the war movies rather best call [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.970 (perp=7.052, rec=0.102, cos=0.457), tot_loss_proj:3.285 [t=0.22s]
prediction: ['[CLS] grace to blame from the prevention of never to blame ever for making it one the war movies rather best call [SEP]']
[1800/2000] tot_loss=1.957 (perp=7.052, rec=0.089, cos=0.457), tot_loss_proj:3.288 [t=0.22s]
prediction: ['[CLS] grace to blame from the prevention of never to blame ever for making it one the war movies rather best call [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.906 (perp=6.776, rec=0.095, cos=0.456), tot_loss_proj:3.182 [t=0.22s]
prediction: ['[CLS] grace to blame from the prevention never to blame ever for making it one of the war movies rather best call [SEP]']
Attempt swap
[1900/2000] tot_loss=1.906 (perp=6.776, rec=0.094, cos=0.457), tot_loss_proj:3.183 [t=0.22s]
prediction: ['[CLS] grace to blame from the prevention never to blame ever for making it one of the war movies rather best call [SEP]']
[1950/2000] tot_loss=1.902 (perp=6.776, rec=0.090, cos=0.457), tot_loss_proj:3.187 [t=0.22s]
prediction: ['[CLS] grace to blame from the prevention never to blame ever for making it one of the war movies rather best call [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.861 (perp=6.581, rec=0.088, cos=0.457), tot_loss_proj:2.926 [t=0.22s]
prediction: ['[CLS] grace to blame from the prevention never to blame rather for making it one of the war movies ever best call [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] grace to blame the prevention of never to blame for ever making from it one the war movies rather best call [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.444 | p: 82.609 | r: 86.364
rouge2     | fm: 18.605 | p: 18.182 | r: 19.048
rougeL     | fm: 57.778 | p: 56.522 | r: 59.091
rougeLsum  | fm: 57.778 | p: 56.522 | r: 59.091
r1fm+r2fm = 103.049

[Aggregate metrics]:
rouge1     | fm: 90.683 | p: 90.126 | r: 91.382
rouge2     | fm: 56.382 | p: 56.265 | r: 56.663
rougeL     | fm: 77.699 | p: 77.305 | r: 78.246
rougeLsum  | fm: 77.500 | p: 77.162 | r: 77.980
r1fm+r2fm = 147.065

input #62 time: 0:08:53 | total time: 9:17:23


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.7374951297969599
highest_index [0]
highest [0.7374951297969599]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.8053948283195496 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.7189591526985168 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.6887873411178589 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best perm rec loss: 0.6824559569358826 for ['[CLS] written workingism brighter spend [SEP]']
[Init] best perm rec loss: 0.6817003488540649 for ['[CLS]ism working written spend brighter [SEP]']
[Init] best perm rec loss: 0.679886519908905 for ['[CLS] written spend brighterism working [SEP]']
[Init] best perm rec loss: 0.6789539456367493 for ['[CLS]ism spend written brighter working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.648 (perp=9.898, rec=0.213, cos=0.455), tot_loss_proj:3.147 [t=0.22s]
prediction: ['[CLS] return ticket ticket seeking return [SEP]']
[ 100/2000] tot_loss=2.450 (perp=9.462, rec=0.102, cos=0.456), tot_loss_proj:3.076 [t=0.22s]
prediction: ['[CLS] return ticket for looking ticket [SEP]']
[ 150/2000] tot_loss=2.422 (perp=9.462, rec=0.074, cos=0.455), tot_loss_proj:3.069 [t=0.22s]
prediction: ['[CLS] return ticket for looking ticket [SEP]']
[ 200/2000] tot_loss=2.425 (perp=9.462, rec=0.078, cos=0.455), tot_loss_proj:3.073 [t=0.22s]
prediction: ['[CLS] return ticket for looking ticket [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.252 (perp=8.568, rec=0.083, cos=0.456), tot_loss_proj:2.791 [t=0.22s]
prediction: ['[CLS] return looking for ticket ticket [SEP]']
[ 300/2000] tot_loss=2.236 (perp=8.568, rec=0.068, cos=0.454), tot_loss_proj:2.788 [t=0.22s]
prediction: ['[CLS] return looking for ticket ticket [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.093 (perp=7.802, rec=0.078, cos=0.455), tot_loss_proj:2.288 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.082 (perp=7.802, rec=0.067, cos=0.455), tot_loss_proj:2.289 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 450/2000] tot_loss=2.090 (perp=7.802, rec=0.074, cos=0.455), tot_loss_proj:2.292 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.087 (perp=7.802, rec=0.071, cos=0.456), tot_loss_proj:2.296 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.084 (perp=7.802, rec=0.068, cos=0.456), tot_loss_proj:2.287 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 600/2000] tot_loss=2.085 (perp=7.802, rec=0.069, cos=0.455), tot_loss_proj:2.282 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.083 (perp=7.802, rec=0.067, cos=0.456), tot_loss_proj:2.282 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.079 (perp=7.802, rec=0.063, cos=0.455), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 750/2000] tot_loss=2.079 (perp=7.802, rec=0.065, cos=0.454), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.086 (perp=7.802, rec=0.072, cos=0.453), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.080 (perp=7.802, rec=0.065, cos=0.455), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 900/2000] tot_loss=2.088 (perp=7.802, rec=0.072, cos=0.455), tot_loss_proj:2.279 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.075 (perp=7.802, rec=0.060, cos=0.455), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=2.078 (perp=7.802, rec=0.066, cos=0.452), tot_loss_proj:2.287 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[1050/2000] tot_loss=2.088 (perp=7.802, rec=0.075, cos=0.453), tot_loss_proj:2.282 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=2.086 (perp=7.802, rec=0.071, cos=0.454), tot_loss_proj:2.289 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=2.095 (perp=7.802, rec=0.078, cos=0.456), tot_loss_proj:2.283 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[1200/2000] tot_loss=2.084 (perp=7.802, rec=0.068, cos=0.456), tot_loss_proj:2.289 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=2.085 (perp=7.802, rec=0.070, cos=0.454), tot_loss_proj:2.282 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=2.087 (perp=7.802, rec=0.073, cos=0.453), tot_loss_proj:2.283 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[1350/2000] tot_loss=2.089 (perp=7.802, rec=0.074, cos=0.454), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=2.088 (perp=7.802, rec=0.072, cos=0.455), tot_loss_proj:2.286 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=2.079 (perp=7.802, rec=0.063, cos=0.455), tot_loss_proj:2.278 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[1500/2000] tot_loss=2.089 (perp=7.802, rec=0.074, cos=0.455), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=2.081 (perp=7.802, rec=0.065, cos=0.456), tot_loss_proj:2.281 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=2.092 (perp=7.802, rec=0.076, cos=0.456), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[1650/2000] tot_loss=2.264 (perp=8.743, rec=0.059, cos=0.456), tot_loss_proj:2.768 [t=0.22s]
prediction: ['[CLS] looking a ticket return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=2.278 (perp=8.743, rec=0.074, cos=0.455), tot_loss_proj:2.762 [t=0.22s]
prediction: ['[CLS] looking a ticket return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=2.264 (perp=8.743, rec=0.059, cos=0.456), tot_loss_proj:2.765 [t=0.22s]
prediction: ['[CLS] looking a ticket return ticket [SEP]']
[1800/2000] tot_loss=2.276 (perp=8.743, rec=0.071, cos=0.456), tot_loss_proj:2.770 [t=0.22s]
prediction: ['[CLS] looking a ticket return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=2.266 (perp=8.743, rec=0.062, cos=0.456), tot_loss_proj:2.766 [t=0.22s]
prediction: ['[CLS] looking a ticket return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=2.271 (perp=8.743, rec=0.066, cos=0.456), tot_loss_proj:2.771 [t=0.22s]
prediction: ['[CLS] looking a ticket return ticket [SEP]']
[1950/2000] tot_loss=2.266 (perp=8.743, rec=0.061, cos=0.456), tot_loss_proj:2.768 [t=0.22s]
prediction: ['[CLS] looking a ticket return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=2.266 (perp=8.743, rec=0.062, cos=0.456), tot_loss_proj:2.765 [t=0.22s]
prediction: ['[CLS] looking a ticket return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for ticket return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 152.381

[Aggregate metrics]:
rouge1     | fm: 90.689 | p: 90.189 | r: 91.375
rouge2     | fm: 56.566 | p: 56.448 | r: 56.867
rougeL     | fm: 77.794 | p: 77.446 | r: 78.348
rougeLsum  | fm: 77.639 | p: 77.277 | r: 78.170
r1fm+r2fm = 147.255

input #63 time: 0:08:44 | total time: 9:26:07


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.7316519948868345
highest_index [0]
highest [0.7316519948868345]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8782715201377869 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8265596032142639 for ['[CLS] dale fuel picked [SEP]']
[Init] best rec loss: 0.8118206858634949 for ['[CLS] david [CLS] earliest [SEP]']
[Init] best rec loss: 0.7231777310371399 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6786935329437256 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6783058047294617 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 0.6740293502807617 for ['[CLS] visions wateronale [SEP]']
[Init] best perm rec loss: 0.6709949374198914 for ['[CLS]onale visions water [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.181 (perp=8.065, rec=0.113, cos=0.455), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 100/2000] tot_loss=2.142 (perp=8.065, rec=0.066, cos=0.463), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 150/2000] tot_loss=2.139 (perp=8.065, rec=0.062, cos=0.464), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 200/2000] tot_loss=2.145 (perp=8.065, rec=0.067, cos=0.464), tot_loss_proj:2.156 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.133 (perp=8.065, rec=0.055, cos=0.465), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 300/2000] tot_loss=2.140 (perp=8.065, rec=0.064, cos=0.463), tot_loss_proj:2.153 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.144 (perp=8.065, rec=0.067, cos=0.465), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.140 (perp=8.065, rec=0.062, cos=0.465), tot_loss_proj:2.159 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=2.136 (perp=8.065, rec=0.059, cos=0.464), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.139 (perp=8.065, rec=0.062, cos=0.464), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.142 (perp=8.065, rec=0.064, cos=0.465), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=2.130 (perp=8.065, rec=0.053, cos=0.465), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.139 (perp=8.065, rec=0.061, cos=0.465), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.139 (perp=8.065, rec=0.062, cos=0.464), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=2.136 (perp=8.065, rec=0.059, cos=0.464), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.136 (perp=8.065, rec=0.059, cos=0.464), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.139 (perp=8.065, rec=0.062, cos=0.464), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=2.130 (perp=8.065, rec=0.053, cos=0.465), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.141 (perp=8.065, rec=0.064, cos=0.464), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=2.142 (perp=8.065, rec=0.065, cos=0.465), tot_loss_proj:2.155 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=2.141 (perp=8.065, rec=0.064, cos=0.464), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=2.139 (perp=8.065, rec=0.062, cos=0.464), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=2.135 (perp=8.065, rec=0.059, cos=0.463), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=2.143 (perp=8.065, rec=0.066, cos=0.464), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=2.142 (perp=8.065, rec=0.065, cos=0.464), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=2.133 (perp=8.065, rec=0.056, cos=0.464), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=2.141 (perp=8.065, rec=0.064, cos=0.464), tot_loss_proj:2.156 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=2.141 (perp=8.065, rec=0.063, cos=0.465), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=2.137 (perp=8.065, rec=0.059, cos=0.464), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=2.139 (perp=8.065, rec=0.061, cos=0.465), tot_loss_proj:2.161 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=2.138 (perp=8.065, rec=0.060, cos=0.465), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=2.145 (perp=8.065, rec=0.068, cos=0.465), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=2.139 (perp=8.065, rec=0.062, cos=0.465), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=2.148 (perp=8.065, rec=0.071, cos=0.464), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=2.130 (perp=8.065, rec=0.053, cos=0.464), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=2.136 (perp=8.065, rec=0.059, cos=0.465), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=2.135 (perp=8.065, rec=0.057, cos=0.465), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=2.145 (perp=8.065, rec=0.068, cos=0.464), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=2.132 (perp=8.065, rec=0.055, cos=0.464), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=2.135 (perp=8.065, rec=0.057, cos=0.464), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.955 | p: 90.487 | r: 91.573
rouge2     | fm: 57.407 | p: 57.336 | r: 57.520
rougeL     | fm: 78.120 | p: 77.724 | r: 78.599
rougeLsum  | fm: 78.381 | p: 78.030 | r: 78.875
r1fm+r2fm = 148.361

input #64 time: 0:08:43 | total time: 9:34:51


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.7351770165981355
highest_index [0]
highest [0.7351770165981355]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 0.8866694569587708 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.8755448460578918 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.8640808463096619 for ['[CLS] dir northern opens gasam acute diocese ban missile [SEP]']
[Init] best rec loss: 0.8578236699104309 for ['[CLS] nyunce coalition pdf dailyenburg registry romanesqueric [SEP]']
[Init] best rec loss: 0.853767454624176 for ['[CLS] pale far expert interval pr che gonna time united [SEP]']
[Init] best rec loss: 0.8408370018005371 for ['[CLS] script the classning lau tape from later skate [SEP]']
[Init] best rec loss: 0.8374816179275513 for ['[CLS] health kuept scenicne contact will savamac [SEP]']
[Init] best rec loss: 0.8195205330848694 for ['[CLS] dancer relative being bar shoulder allmusic original eatingolic [SEP]']
[Init] best rec loss: 0.792767345905304 for ['[CLS] graphic - oxygen jessie go distinguished they alt decommissioned [SEP]']
[Init] best rec loss: 0.7650759816169739 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.7630716562271118 for ['[CLS] overshoff pu evenmament fun someday news general [SEP]']
[Init] best perm rec loss: 0.762806236743927 for ['[CLS] fun generalhoff news somedaymament pu even overs [SEP]']
[Init] best perm rec loss: 0.7621634602546692 for ['[CLS] news evenmament puhoff someday general overs fun [SEP]']
[Init] best perm rec loss: 0.7618572115898132 for ['[CLS] news fun pu overs evenmament somedayhoff general [SEP]']
[Init] best perm rec loss: 0.7601953148841858 for ['[CLS] news someday pu even overs generalhoffmament fun [SEP]']
[Init] best perm rec loss: 0.7601417899131775 for ['[CLS] fun news somedaymamenthoff overs pu even general [SEP]']
[Init] best perm rec loss: 0.7598786950111389 for ['[CLS] news fun generalmament overs evenhoff someday pu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.165 (perp=6.981, rec=0.301, cos=0.468), tot_loss_proj:2.378 [t=0.22s]
prediction: ['[CLS] : joyod joyous, joyous joy [SEP]']
[ 100/2000] tot_loss=2.523 (perp=9.420, rec=0.177, cos=0.462), tot_loss_proj:2.836 [t=0.22s]
prediction: ['[CLS], joyous romous an joyous film [SEP]']
[ 150/2000] tot_loss=2.306 (perp=8.615, rec=0.126, cos=0.456), tot_loss_proj:2.697 [t=0.22s]
prediction: ['[CLS], joyous romous a joyous film [SEP]']
[ 200/2000] tot_loss=2.567 (perp=10.072, rec=0.093, cos=0.460), tot_loss_proj:3.066 [t=0.22s]
prediction: ['[CLS], joy of romous a joy. film [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.257 (perp=8.364, rec=0.128, cos=0.456), tot_loss_proj:2.702 [t=0.22s]
prediction: ['[CLS], of rom joyous a joy. film [SEP]']
[ 300/2000] tot_loss=2.211 (perp=8.364, rec=0.079, cos=0.459), tot_loss_proj:2.701 [t=0.22s]
prediction: ['[CLS], of rom joyous a joy. film [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.116 (perp=7.840, rec=0.089, cos=0.459), tot_loss_proj:2.621 [t=0.22s]
prediction: ['[CLS], of rom joyous a joy film. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.103 (perp=6.931, rec=0.264, cos=0.452), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS], of a rom joyous joy film. [SEP]']
[ 450/2000] tot_loss=1.984 (perp=6.931, rec=0.142, cos=0.456), tot_loss_proj:2.373 [t=0.22s]
prediction: ['[CLS], of a rom joyous joy film. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.896 (perp=6.603, rec=0.120, cos=0.456), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS], a rom joyous joy of film. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.877 (perp=6.603, rec=0.099, cos=0.458), tot_loss_proj:2.190 [t=0.22s]
prediction: ['[CLS], a rom joyous joy of film. [SEP]']
[ 600/2000] tot_loss=1.876 (perp=6.603, rec=0.097, cos=0.458), tot_loss_proj:2.184 [t=0.22s]
prediction: ['[CLS], a rom joyous joy of film. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.710 (perp=5.707, rec=0.110, cos=0.459), tot_loss_proj:2.053 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.706 (perp=5.707, rec=0.105, cos=0.459), tot_loss_proj:2.052 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
[ 750/2000] tot_loss=1.697 (perp=5.707, rec=0.096, cos=0.460), tot_loss_proj:2.053 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.692 (perp=5.707, rec=0.091, cos=0.459), tot_loss_proj:2.055 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.693 (perp=5.707, rec=0.092, cos=0.459), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
[ 900/2000] tot_loss=1.695 (perp=5.707, rec=0.094, cos=0.459), tot_loss_proj:2.061 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.688 (perp=5.707, rec=0.088, cos=0.459), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.684 (perp=5.707, rec=0.083, cos=0.459), tot_loss_proj:2.056 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
[1050/2000] tot_loss=1.691 (perp=5.707, rec=0.090, cos=0.459), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.692 (perp=5.707, rec=0.092, cos=0.459), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.680 (perp=5.707, rec=0.080, cos=0.459), tot_loss_proj:2.061 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
[1200/2000] tot_loss=1.674 (perp=5.707, rec=0.073, cos=0.459), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.673 (perp=5.707, rec=0.072, cos=0.459), tot_loss_proj:2.052 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.688 (perp=5.707, rec=0.087, cos=0.459), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
[1350/2000] tot_loss=1.682 (perp=5.707, rec=0.081, cos=0.459), tot_loss_proj:2.053 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.679 (perp=5.707, rec=0.078, cos=0.459), tot_loss_proj:2.048 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.679 (perp=5.707, rec=0.078, cos=0.460), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
[1500/2000] tot_loss=1.685 (perp=5.707, rec=0.084, cos=0.459), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.677 (perp=5.707, rec=0.076, cos=0.459), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.669 (perp=5.707, rec=0.069, cos=0.459), tot_loss_proj:2.058 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
[1650/2000] tot_loss=1.680 (perp=5.707, rec=0.079, cos=0.459), tot_loss_proj:2.045 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.677 (perp=5.707, rec=0.076, cos=0.459), tot_loss_proj:2.051 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.684 (perp=5.707, rec=0.084, cos=0.459), tot_loss_proj:2.055 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
[1800/2000] tot_loss=1.681 (perp=5.707, rec=0.080, cos=0.459), tot_loss_proj:2.050 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.687 (perp=5.707, rec=0.086, cos=0.459), tot_loss_proj:2.054 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.678 (perp=5.707, rec=0.077, cos=0.459), tot_loss_proj:2.065 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
[1950/2000] tot_loss=1.675 (perp=5.707, rec=0.074, cos=0.459), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.687 (perp=5.707, rec=0.087, cos=0.459), tot_loss_proj:2.056 [t=0.22s]
prediction: ['[CLS] rom, a joyous joy of film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] rom, a joyous joy of film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 66.667 | p: 62.500 | r: 71.429
rougeLsum  | fm: 66.667 | p: 62.500 | r: 71.429
r1fm+r2fm = 95.385

[Aggregate metrics]:
rouge1     | fm: 90.723 | p: 90.160 | r: 91.488
rouge2     | fm: 56.714 | p: 56.510 | r: 56.991
rougeL     | fm: 77.941 | p: 77.487 | r: 78.542
rougeLsum  | fm: 78.025 | p: 77.529 | r: 78.679
r1fm+r2fm = 147.437

input #65 time: 0:08:44 | total time: 9:43:36


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.7231949580489201
highest_index [0]
highest [0.7231949580489201]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.8545567393302917 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.829190731048584 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.8215273022651672 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8047069311141968 for ['[CLS] riot equal private peculiar [SEP]']
[Init] best rec loss: 0.8006831407546997 for ['[CLS] complied man ready panic [SEP]']
[Init] best rec loss: 0.8002241849899292 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.7740039825439453 for ['[CLS] background leader screen [CLS] [SEP]']
[Init] best rec loss: 0.7600839138031006 for ['[CLS] helmet stared true deposit [SEP]']
[Init] best rec loss: 0.74112868309021 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best perm rec loss: 0.7395268082618713 for ['[CLS] juliet game shoulders scout [SEP]']
[Init] best perm rec loss: 0.7377657294273376 for ['[CLS] juliet scout game shoulders [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.705 (perp=9.851, rec=0.265, cos=0.469), tot_loss_proj:3.036 [t=0.22s]
prediction: ['[CLS] tolkien fan fan fan [SEP]']
[ 100/2000] tot_loss=2.779 (perp=10.944, rec=0.114, cos=0.476), tot_loss_proj:3.131 [t=0.22s]
prediction: ['[CLS] tolkien fan fan longtime [SEP]']
[ 150/2000] tot_loss=2.984 (perp=12.070, rec=0.093, cos=0.477), tot_loss_proj:3.562 [t=0.22s]
prediction: ['[CLS] tolkien longtime fan longtime [SEP]']
[ 200/2000] tot_loss=2.977 (perp=12.070, rec=0.086, cos=0.477), tot_loss_proj:3.573 [t=0.22s]
prediction: ['[CLS] tolkien longtime fan longtime [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.550 (perp=9.820, rec=0.110, cos=0.476), tot_loss_proj:2.896 [t=0.22s]
prediction: ['[CLS] longtime longtime fan tolkien [SEP]']
[ 300/2000] tot_loss=2.512 (perp=9.820, rec=0.072, cos=0.476), tot_loss_proj:2.890 [t=0.22s]
prediction: ['[CLS] longtime longtime fan tolkien [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.080 (perp=7.672, rec=0.069, cos=0.476), tot_loss_proj:2.071 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.082 (perp=7.672, rec=0.072, cos=0.476), tot_loss_proj:2.067 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=2.084 (perp=7.672, rec=0.074, cos=0.476), tot_loss_proj:2.083 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.071 (perp=7.672, rec=0.061, cos=0.476), tot_loss_proj:2.070 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.071 (perp=7.672, rec=0.060, cos=0.476), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=2.071 (perp=7.672, rec=0.060, cos=0.476), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.067 (perp=7.672, rec=0.056, cos=0.476), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.072 (perp=7.672, rec=0.061, cos=0.476), tot_loss_proj:2.081 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=2.079 (perp=7.672, rec=0.068, cos=0.476), tot_loss_proj:2.073 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.077 (perp=7.672, rec=0.066, cos=0.477), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.068 (perp=7.672, rec=0.057, cos=0.476), tot_loss_proj:2.080 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=2.079 (perp=7.672, rec=0.068, cos=0.476), tot_loss_proj:2.077 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.076 (perp=7.672, rec=0.065, cos=0.477), tot_loss_proj:2.080 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=2.072 (perp=7.672, rec=0.060, cos=0.477), tot_loss_proj:2.073 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=2.070 (perp=7.672, rec=0.059, cos=0.477), tot_loss_proj:2.073 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=2.082 (perp=7.672, rec=0.071, cos=0.476), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=2.080 (perp=7.672, rec=0.069, cos=0.477), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=2.069 (perp=7.672, rec=0.058, cos=0.477), tot_loss_proj:2.070 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=2.075 (perp=7.672, rec=0.064, cos=0.477), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=2.075 (perp=7.672, rec=0.064, cos=0.476), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=2.071 (perp=7.672, rec=0.060, cos=0.477), tot_loss_proj:2.076 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=2.085 (perp=7.672, rec=0.074, cos=0.477), tot_loss_proj:2.070 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=2.080 (perp=7.672, rec=0.069, cos=0.477), tot_loss_proj:2.067 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=2.067 (perp=7.672, rec=0.056, cos=0.477), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=2.075 (perp=7.672, rec=0.064, cos=0.477), tot_loss_proj:2.071 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=2.068 (perp=7.672, rec=0.057, cos=0.477), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=2.079 (perp=7.672, rec=0.067, cos=0.477), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=2.073 (perp=7.672, rec=0.062, cos=0.477), tot_loss_proj:2.069 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=2.077 (perp=7.672, rec=0.066, cos=0.476), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=2.067 (perp=7.672, rec=0.056, cos=0.477), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=2.075 (perp=7.672, rec=0.064, cos=0.477), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=2.071 (perp=7.672, rec=0.060, cos=0.477), tot_loss_proj:2.080 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=2.068 (perp=7.672, rec=0.057, cos=0.477), tot_loss_proj:2.069 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=2.066 (perp=7.672, rec=0.055, cos=0.477), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.786 | p: 90.240 | r: 91.570
rouge2     | fm: 57.462 | p: 57.267 | r: 57.732
rougeL     | fm: 78.259 | p: 77.836 | r: 78.807
rougeLsum  | fm: 78.380 | p: 77.942 | r: 78.953
r1fm+r2fm = 148.247

input #66 time: 0:08:43 | total time: 9:52:19


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.7381613564947813
highest_index [0]
highest [0.7381613564947813]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 0.9493607878684998 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9320055246353149 for ['[CLS] acretis smiley moth toward ass rhine xbox piece rebranded [SEP]']
[Init] best rec loss: 0.9155563712120056 for ['[CLS] fastestedance ;eding buckingham jill ranges australia international property [SEP]']
[Init] best rec loss: 0.9136396646499634 for ['[CLS]tched forward bunk kinds virginiahiparians war ann scenery [SEP]']
[Init] best rec loss: 0.9023206233978271 for ['[CLS] ×ator bears weight overturned um turning pay humanity glee [SEP]']
[Init] best rec loss: 0.8929193019866943 for ['[CLS] carries garden deputy creation attitudes victim mine waitingapugh [SEP]']
[Init] best rec loss: 0.8895723819732666 for ['[CLS] holyvy war hingesozuche tessa ] commentary justice [SEP]']
[Init] best perm rec loss: 0.889147937297821 for ['[CLS] hinges war tessa justice commentaryuche ]vy holyoz [SEP]']
[Init] best perm rec loss: 0.8889831304550171 for ['[CLS] holyvy hinges waruche ] commentary tessa justiceoz [SEP]']
[Init] best perm rec loss: 0.888639509677887 for ['[CLS] hingesozvy ] holy commentaryuche war tessa justice [SEP]']
[Init] best perm rec loss: 0.8859010338783264 for ['[CLS] tessa ] hinges justice war commentaryucheoz holyvy [SEP]']
[Init] best perm rec loss: 0.8858416676521301 for ['[CLS] ] waruche commentary hinges holy justice tessavyoz [SEP]']
[Init] best perm rec loss: 0.8853599429130554 for ['[CLS] hingesuche tessa holyvyoz commentary justice war ] [SEP]']
[Init] best perm rec loss: 0.8853210210800171 for ['[CLS]oz hingesuche ]vy commentary war justice tessa holy [SEP]']
[Init] best perm rec loss: 0.8848941326141357 for ['[CLS] tessaoz ] hingesvy commentaryuche justice holy war [SEP]']
[Init] best perm rec loss: 0.8848112225532532 for ['[CLS] tessa commentary ]uche justice hingesvy holy waroz [SEP]']
[Init] best perm rec loss: 0.8845036625862122 for ['[CLS]oz holy justice ]uche hinges tessavy commentary war [SEP]']
[Init] best perm rec loss: 0.8839470744132996 for ['[CLS]uche justice hinges ] holyoz tessa warvy commentary [SEP]']
[Init] best perm rec loss: 0.883743405342102 for ['[CLS]oz hingesuche holy warvy ] justice tessa commentary [SEP]']
[Init] best perm rec loss: 0.8836824893951416 for ['[CLS] tessa justice war holy ] hinges commentaryozvyuche [SEP]']
[Init] best perm rec loss: 0.8833314180374146 for ['[CLS] ] hingesozuche commentary tessa justicevy war holy [SEP]']
[Init] best perm rec loss: 0.8828327655792236 for ['[CLS] commentary ] hinges waruchevyoz holy justice tessa [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.140 (perp=11.967, rec=0.292, cos=0.455), tot_loss_proj:4.331 [t=0.22s]
prediction: ['[CLS] never kind non hearted cast jennie such kindan bureau [SEP]']
[ 100/2000] tot_loss=3.045 (perp=11.899, rec=0.213, cos=0.453), tot_loss_proj:3.831 [t=0.22s]
prediction: ['[CLS] interaction kind nonentalwarming, kind heart items [SEP]']
[ 150/2000] tot_loss=2.826 (perp=11.121, rec=0.150, cos=0.451), tot_loss_proj:3.729 [t=0.22s]
prediction: ['[CLS]ming kind nonentalwarming, kind heartental [SEP]']
[ 200/2000] tot_loss=2.939 (perp=11.839, rec=0.118, cos=0.453), tot_loss_proj:3.857 [t=0.22s]
prediction: ['[CLS]gm kind nonentalwarming, kind heartental [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.837 (perp=11.208, rec=0.142, cos=0.454), tot_loss_proj:3.842 [t=0.22s]
prediction: ['[CLS] heart kind nonentalwarming, kindgmgm [SEP]']
[ 300/2000] tot_loss=2.794 (perp=11.208, rec=0.098, cos=0.455), tot_loss_proj:3.832 [t=0.22s]
prediction: ['[CLS] heart kind nonentalwarming, kindgmgm [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.379 (perp=9.092, rec=0.106, cos=0.454), tot_loss_proj:3.455 [t=0.22s]
prediction: ['[CLS] heart kind nonwarming, kindgmgmental [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.074 (perp=7.591, rec=0.099, cos=0.456), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS] heartwarming, kind kind nongmgmental [SEP]']
[ 450/2000] tot_loss=2.058 (perp=7.591, rec=0.085, cos=0.455), tot_loss_proj:2.290 [t=0.22s]
prediction: ['[CLS] heartwarming, kind kind nongmgmental [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.950 (perp=7.054, rec=0.085, cos=0.454), tot_loss_proj:2.196 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nongmgmental [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.858 (perp=6.608, rec=0.081, cos=0.455), tot_loss_proj:2.081 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
[ 600/2000] tot_loss=1.857 (perp=6.608, rec=0.081, cos=0.455), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.854 (perp=6.608, rec=0.078, cos=0.455), tot_loss_proj:2.080 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.857 (perp=6.608, rec=0.080, cos=0.455), tot_loss_proj:2.080 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
[ 750/2000] tot_loss=1.841 (perp=6.608, rec=0.065, cos=0.455), tot_loss_proj:2.079 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.848 (perp=6.608, rec=0.072, cos=0.455), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.844 (perp=6.608, rec=0.068, cos=0.455), tot_loss_proj:2.081 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
[ 900/2000] tot_loss=1.855 (perp=6.608, rec=0.079, cos=0.455), tot_loss_proj:2.076 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.850 (perp=6.608, rec=0.074, cos=0.454), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1000/2000] tot_loss=1.855 (perp=6.608, rec=0.079, cos=0.455), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
[1050/2000] tot_loss=1.842 (perp=6.608, rec=0.066, cos=0.455), tot_loss_proj:2.083 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1100/2000] tot_loss=1.844 (perp=6.608, rec=0.068, cos=0.455), tot_loss_proj:2.076 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1150/2000] tot_loss=1.855 (perp=6.608, rec=0.078, cos=0.455), tot_loss_proj:2.079 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
[1200/2000] tot_loss=1.844 (perp=6.608, rec=0.068, cos=0.455), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1250/2000] tot_loss=1.850 (perp=6.608, rec=0.073, cos=0.455), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1300/2000] tot_loss=1.845 (perp=6.608, rec=0.069, cos=0.455), tot_loss_proj:2.073 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
[1350/2000] tot_loss=1.844 (perp=6.608, rec=0.067, cos=0.455), tot_loss_proj:2.089 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1400/2000] tot_loss=1.842 (perp=6.608, rec=0.066, cos=0.455), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1450/2000] tot_loss=1.848 (perp=6.608, rec=0.071, cos=0.455), tot_loss_proj:2.073 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
[1500/2000] tot_loss=1.847 (perp=6.608, rec=0.070, cos=0.455), tot_loss_proj:2.084 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1550/2000] tot_loss=1.849 (perp=6.608, rec=0.072, cos=0.455), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1600/2000] tot_loss=1.853 (perp=6.608, rec=0.077, cos=0.455), tot_loss_proj:2.080 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
[1650/2000] tot_loss=1.855 (perp=6.608, rec=0.079, cos=0.455), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1700/2000] tot_loss=1.848 (perp=6.608, rec=0.071, cos=0.455), tot_loss_proj:2.082 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1750/2000] tot_loss=1.847 (perp=6.608, rec=0.071, cos=0.455), tot_loss_proj:2.091 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
[1800/2000] tot_loss=1.847 (perp=6.608, rec=0.070, cos=0.455), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1850/2000] tot_loss=1.843 (perp=6.608, rec=0.067, cos=0.455), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[1900/2000] tot_loss=1.844 (perp=6.608, rec=0.067, cos=0.455), tot_loss_proj:2.088 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
[1950/2000] tot_loss=1.850 (perp=6.608, rec=0.073, cos=0.455), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Attempt swap
[2000/2000] tot_loss=1.847 (perp=6.608, rec=0.070, cos=0.455), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] kind heartwarming, kind nonjugmental [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind heartwarming, kind nonjugmental [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 66.667 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 72.727 | p: 66.667 | r: 80.000
rougeLsum  | fm: 72.727 | p: 66.667 | r: 80.000
r1fm+r2fm = 72.727

[Aggregate metrics]:
rouge1     | fm: 90.555 | p: 89.852 | r: 91.354
rouge2     | fm: 56.601 | p: 56.458 | r: 56.822
rougeL     | fm: 78.168 | p: 77.612 | r: 78.818
rougeLsum  | fm: 78.360 | p: 77.802 | r: 79.031
r1fm+r2fm = 147.155

input #67 time: 0:08:45 | total time: 10:01:04


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.7187402852977691
highest_index [0]
highest [0.7187402852977691]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9280662536621094 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9036049246788025 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 0.8937293887138367 for ['[CLS] instant legs discoveredshboot mass pond arabianvati lines abd star 7 [SEP]']
[Init] best rec loss: 0.893655002117157 for ['[CLS] outcome swan national dialed apparently littlechi horror why supply targeted face ahl [SEP]']
[Init] best rec loss: 0.8787488341331482 for ['[CLS] feelings stole besides spoil bit prone decay spider insteadane about ars payments [SEP]']
[Init] best rec loss: 0.8402340412139893 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8290969729423523 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8265357613563538 for ['[CLS] medaliferous beth comfort form councils flooryn possibly riding. died view [SEP]']
[Init] best perm rec loss: 0.8260531425476074 for ['[CLS]iferous view beth formyn riding comfort possibly councils. floor died medal [SEP]']
[Init] best perm rec loss: 0.8254449367523193 for ['[CLS]yn councils riding formiferous beth. floor possibly view comfort medal died [SEP]']
[Init] best perm rec loss: 0.8223657011985779 for ['[CLS] died riding beth possiblyyn medal. form view councilsiferous floor comfort [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.933 (perp=11.100, rec=0.246, cos=0.466), tot_loss_proj:3.330 [t=0.22s]
prediction: ['[CLS] absurd and absurd, previously varying absurd plains right nonsense movement resulting but [SEP]']
[ 100/2000] tot_loss=2.922 (perp=11.319, rec=0.177, cos=0.482), tot_loss_proj:3.398 [t=0.22s]
prediction: ['[CLS] un, absurd,omp propeller absurd creek vicious absurd motion vicious but [SEP]']
[ 150/2000] tot_loss=2.816 (perp=10.892, rec=0.157, cos=0.481), tot_loss_proj:3.289 [t=0.22s]
prediction: ['[CLS] un, vicious,omp propeller absurdsible vicious absurd faction vicious and [SEP]']
[ 200/2000] tot_loss=2.641 (perp=10.160, rec=0.134, cos=0.475), tot_loss_proj:3.043 [t=0.22s]
prediction: ['[CLS] un, vicious,omputh absurdsibleuth absurd faction vicious and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.545 (perp=9.683, rec=0.131, cos=0.477), tot_loss_proj:2.951 [t=0.22s]
prediction: ['[CLS] un, vicious,omputh absurdsiblesible absurd vicious and vicious [SEP]']
[ 300/2000] tot_loss=2.524 (perp=9.683, rec=0.111, cos=0.477), tot_loss_proj:2.955 [t=0.22s]
prediction: ['[CLS] un, vicious,omputh absurdsiblesible absurd vicious and vicious [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.634 (perp=9.995, rec=0.157, cos=0.478), tot_loss_proj:3.051 [t=0.22s]
prediction: ['[CLS] unomputh, vicious, absurdsiblesible absurd faction and vicious [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.342 (perp=8.716, rec=0.117, cos=0.481), tot_loss_proj:2.663 [t=0.22s]
prediction: ['[CLS] unomputhsible vicious, absurdsible, absurd signature and vicious [SEP]']
[ 450/2000] tot_loss=2.305 (perp=8.584, rec=0.105, cos=0.483), tot_loss_proj:2.686 [t=0.22s]
prediction: ['[CLS] unomputhsible vicious, absurdsible, absurdurrent and vicious [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.084 (perp=7.537, rec=0.100, cos=0.476), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] uncouthsible, vicious absurdsible, absurd immediate and vicious [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.012 (perp=7.124, rec=0.113, cos=0.474), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] uncouthsible, un absurdsible, absurd vicious and vicious [SEP]']
[ 600/2000] tot_loss=2.013 (perp=7.124, rec=0.106, cos=0.482), tot_loss_proj:2.322 [t=0.22s]
prediction: ['[CLS] uncouthsible, un absurdsible, absurd vicious and vicious [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.102 (perp=7.609, rec=0.100, cos=0.480), tot_loss_proj:2.536 [t=0.22s]
prediction: ['[CLS] uncouthsible, un absurdsible,sible vicious and vicious [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.052 (perp=7.334, rec=0.104, cos=0.481), tot_loss_proj:2.464 [t=0.22s]
prediction: ['[CLS] uncouthsible, un absurdsiblesible, vicious and vicious [SEP]']
[ 750/2000] tot_loss=2.053 (perp=7.334, rec=0.103, cos=0.483), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] uncouthsible, un absurdsiblesible, vicious and vicious [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.043 (perp=7.334, rec=0.094, cos=0.481), tot_loss_proj:2.454 [t=0.22s]
prediction: ['[CLS] uncouthsible, un absurdsiblesible, vicious and vicious [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.041 (perp=7.334, rec=0.094, cos=0.481), tot_loss_proj:2.450 [t=0.22s]
prediction: ['[CLS] uncouthsible, un absurdsiblesible, vicious and vicious [SEP]']
[ 900/2000] tot_loss=2.047 (perp=7.385, rec=0.088, cos=0.482), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] uncouthsible, inc absurdsiblesible, vicious and vicious [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.200 (perp=8.074, rec=0.105, cos=0.481), tot_loss_proj:2.556 [t=0.22s]
prediction: ['[CLS] uncouthsible,uncesible, vicious absurdsible and vicious [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.125 (perp=7.682, rec=0.105, cos=0.484), tot_loss_proj:2.459 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurduncesible, vicioussible and vicious [SEP]']
[1050/2000] tot_loss=2.113 (perp=7.654, rec=0.099, cos=0.483), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdncesible, vicioussible and vicious [SEP]']
Attempt swap
[1100/2000] tot_loss=2.113 (perp=7.654, rec=0.099, cos=0.483), tot_loss_proj:2.490 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdncesible, vicioussible and vicious [SEP]']
Attempt swap
[1150/2000] tot_loss=2.103 (perp=7.654, rec=0.089, cos=0.483), tot_loss_proj:2.482 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdncesible, vicioussible and vicious [SEP]']
[1200/2000] tot_loss=2.107 (perp=7.654, rec=0.093, cos=0.483), tot_loss_proj:2.486 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdncesible, vicioussible and vicious [SEP]']
Attempt swap
[1250/2000] tot_loss=2.118 (perp=7.659, rec=0.104, cos=0.483), tot_loss_proj:2.492 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
Attempt swap
[1300/2000] tot_loss=2.099 (perp=7.659, rec=0.085, cos=0.483), tot_loss_proj:2.485 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
[1350/2000] tot_loss=2.107 (perp=7.659, rec=0.092, cos=0.483), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.109 (perp=7.659, rec=0.095, cos=0.482), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
Attempt swap
[1450/2000] tot_loss=2.110 (perp=7.659, rec=0.095, cos=0.483), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
[1500/2000] tot_loss=2.109 (perp=7.659, rec=0.094, cos=0.483), tot_loss_proj:2.502 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
Attempt swap
[1550/2000] tot_loss=2.099 (perp=7.659, rec=0.084, cos=0.483), tot_loss_proj:2.505 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.095 (perp=7.659, rec=0.080, cos=0.483), tot_loss_proj:2.478 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
[1650/2000] tot_loss=2.101 (perp=7.659, rec=0.086, cos=0.483), tot_loss_proj:2.470 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
Attempt swap
[1700/2000] tot_loss=2.094 (perp=7.659, rec=0.079, cos=0.483), tot_loss_proj:2.472 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
Attempt swap
[1750/2000] tot_loss=2.105 (perp=7.659, rec=0.090, cos=0.483), tot_loss_proj:2.475 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
[1800/2000] tot_loss=2.099 (perp=7.659, rec=0.084, cos=0.483), tot_loss_proj:2.472 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
Attempt swap
[1850/2000] tot_loss=2.105 (perp=7.659, rec=0.090, cos=0.483), tot_loss_proj:2.473 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
Attempt swap
[1900/2000] tot_loss=2.107 (perp=7.659, rec=0.092, cos=0.483), tot_loss_proj:2.467 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
[1950/2000] tot_loss=2.101 (perp=7.659, rec=0.086, cos=0.483), tot_loss_proj:2.479 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.100 (perp=7.659, rec=0.086, cos=0.483), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] uncouthsible, absurdompsible, vicioussible and vicious [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 57.143 | r: 57.143
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.857 | p: 42.857 | r: 42.857
rougeLsum  | fm: 42.857 | p: 42.857 | r: 42.857
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 90.103 | p: 89.517 | r: 90.962
rouge2     | fm: 56.000 | p: 55.754 | r: 56.189
rougeL     | fm: 77.610 | p: 77.135 | r: 78.283
rougeLsum  | fm: 77.847 | p: 77.350 | r: 78.523
r1fm+r2fm = 146.104

input #68 time: 0:08:44 | total time: 10:09:49


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.73180936221071
highest_index [0]
highest [0.73180936221071]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 0.9701007008552551 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9568603038787842 for ['[CLS]aver grandson cleared sergei spare reserve / earthquake mouse loudly student celebrated pill till le tunnel [SEP]']
[Init] best rec loss: 0.9349507093429565 for ['[CLS] closelein am ( deadrga liz range bragg depended states passes stock past messll [SEP]']
[Init] best perm rec loss: 0.9282919764518738 for ['[CLS] stock depended bragg am states messll past close rangerga ( liz passes deadlein [SEP]']
[Init] best perm rec loss: 0.9270947575569153 for ['[CLS] states depended past amrgall close stock range ( messlein passes dead liz bragg [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.772 (perp=9.940, rec=0.321, cos=0.462), tot_loss_proj:3.363 [t=0.22s]
prediction: ['[CLS]! electric past was paul ; funny rating ; dare. real powerful & sexual phoenix [SEP]']
[ 100/2000] tot_loss=2.488 (perp=8.816, rec=0.263, cos=0.462), tot_loss_proj:2.777 [t=0.22s]
prediction: ['[CLS] winner makes stream - des, funny winner and subtle, real smart, sexual winner [SEP]']
[ 150/2000] tot_loss=2.478 (perp=8.970, rec=0.222, cos=0.462), tot_loss_proj:2.866 [t=0.22s]
prediction: ['[CLS] winner makes winner - des, funny winner and subtle, real funny,. ; [SEP]']
[ 200/2000] tot_loss=2.467 (perp=9.065, rec=0.189, cos=0.464), tot_loss_proj:2.874 [t=0.22s]
prediction: ['[CLS] winner makes winner - des, smart winner, subtle, real funny,. - [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.339 (perp=8.449, rec=0.187, cos=0.462), tot_loss_proj:2.820 [t=0.22s]
prediction: ['[CLS] winner winner winner - alla, smart makes, subtle, real funny,, ; [SEP]']
[ 300/2000] tot_loss=2.365 (perp=8.678, rec=0.167, cos=0.462), tot_loss_proj:3.011 [t=0.22s]
prediction: ['[CLS] winner winner winner - des, smart res, subtle, real funny, res ; [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.208 (perp=7.894, rec=0.167, cos=0.462), tot_loss_proj:2.756 [t=0.22s]
prediction: ['[CLS] winner winner winner - des, smart res, subtle, real, funny res ; [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.294 (perp=8.264, rec=0.181, cos=0.460), tot_loss_proj:2.867 [t=0.22s]
prediction: ['[CLS] winner winner winner - desnt, smart, subtle, real, funny lives ; [SEP]']
[ 450/2000] tot_loss=2.342 (perp=8.664, rec=0.146, cos=0.463), tot_loss_proj:2.769 [t=0.22s]
prediction: ['[CLS] winner winner winner - desona, smart, subtle, real, funny res ; [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.052 (perp=7.185, rec=0.154, cos=0.461), tot_loss_proj:2.481 [t=0.22s]
prediction: ['[CLS] winner ; winner - - res. smart, subtle, real, funny res winner [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.986 (perp=6.827, rec=0.160, cos=0.461), tot_loss_proj:2.461 [t=0.22s]
prediction: ['[CLS] winner ; winner - - res, smart, subtle, real winner and funny res [SEP]']
[ 600/2000] tot_loss=1.970 (perp=6.789, rec=0.150, cos=0.462), tot_loss_proj:2.377 [t=0.22s]
prediction: ['[CLS] winner. winner - - res, smart, subtle, real winner and funny res [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.970 (perp=6.789, rec=0.150, cos=0.462), tot_loss_proj:2.377 [t=0.22s]
prediction: ['[CLS] winner. winner - - res, smart, subtle, real winner and funny res [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.906 (perp=6.501, rec=0.145, cos=0.461), tot_loss_proj:2.429 [t=0.22s]
prediction: ['[CLS] winner. winner - - winner, smart, subtle, real res and funny res [SEP]']
[ 750/2000] tot_loss=1.899 (perp=6.501, rec=0.137, cos=0.462), tot_loss_proj:2.426 [t=0.22s]
prediction: ['[CLS] winner. winner - - winner, smart, subtle, real res and funny res [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.902 (perp=6.501, rec=0.141, cos=0.461), tot_loss_proj:2.429 [t=0.22s]
prediction: ['[CLS] winner. winner - - winner, smart, subtle, real res and funny res [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.896 (perp=6.501, rec=0.134, cos=0.461), tot_loss_proj:2.427 [t=0.22s]
prediction: ['[CLS] winner. winner - - winner, smart, subtle, real res and funny res [SEP]']
[ 900/2000] tot_loss=1.894 (perp=6.472, rec=0.137, cos=0.462), tot_loss_proj:2.311 [t=0.22s]
prediction: ['[CLS] winner. winner - - -, smart, subtle, real res and funny res [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.806 (perp=6.066, rec=0.131, cos=0.462), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] winner.. - - -, smart, subtle, real res and funny res [SEP]']
Attempt swap
[1000/2000] tot_loss=1.830 (perp=6.177, rec=0.133, cos=0.462), tot_loss_proj:2.275 [t=0.22s]
prediction: ['[CLS] winner.. - - -. smart, subtle, real res and funny res [SEP]']
[1050/2000] tot_loss=1.825 (perp=6.177, rec=0.128, cos=0.462), tot_loss_proj:2.274 [t=0.22s]
prediction: ['[CLS] winner.. - - -. smart, subtle, real res and funny res [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.929 (perp=6.708, rec=0.126, cos=0.462), tot_loss_proj:2.464 [t=0.22s]
prediction: ['[CLS] winner. - - - -. smart, subtle, real res and funnycut [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.825 (perp=6.138, rec=0.135, cos=0.462), tot_loss_proj:2.379 [t=0.22s]
prediction: ['[CLS] winner - - -... smart, subtle, real res and funnycut [SEP]']
[1200/2000] tot_loss=1.820 (perp=6.138, rec=0.130, cos=0.462), tot_loss_proj:2.374 [t=0.22s]
prediction: ['[CLS] winner - - -... smart, subtle, real res and funnycut [SEP]']
Attempt swap
[1250/2000] tot_loss=1.826 (perp=6.138, rec=0.136, cos=0.462), tot_loss_proj:2.380 [t=0.22s]
prediction: ['[CLS] winner - - -... smart, subtle, real res and funnycut [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.813 (perp=6.093, rec=0.132, cos=0.463), tot_loss_proj:2.276 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real rescut and funny [SEP]']
[1350/2000] tot_loss=1.804 (perp=6.093, rec=0.123, cos=0.463), tot_loss_proj:2.273 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real rescut and funny [SEP]']
Attempt swap
[1400/2000] tot_loss=1.814 (perp=6.093, rec=0.133, cos=0.462), tot_loss_proj:2.273 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real rescut and funny [SEP]']
Attempt swap
[1450/2000] tot_loss=1.814 (perp=6.093, rec=0.133, cos=0.462), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real rescut and funny [SEP]']
[1500/2000] tot_loss=1.817 (perp=6.093, rec=0.136, cos=0.462), tot_loss_proj:2.273 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real rescut and funny [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.762 (perp=5.815, rec=0.137, cos=0.462), tot_loss_proj:2.307 [t=0.22s]
prediction: ['[CLS] winner - - -... smart, subtle, real and rescut funny [SEP]']
Attempt swap
[1600/2000] tot_loss=1.766 (perp=5.815, rec=0.140, cos=0.462), tot_loss_proj:2.304 [t=0.22s]
prediction: ['[CLS] winner - - -... smart, subtle, real and rescut funny [SEP]']
[1650/2000] tot_loss=1.773 (perp=5.917, rec=0.127, cos=0.462), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real and rescut funny [SEP]']
Attempt swap
[1700/2000] tot_loss=1.773 (perp=5.917, rec=0.127, cos=0.463), tot_loss_proj:2.373 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real and rescut funny [SEP]']
Attempt swap
[1750/2000] tot_loss=1.780 (perp=5.917, rec=0.134, cos=0.463), tot_loss_proj:2.368 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real and rescut funny [SEP]']
[1800/2000] tot_loss=1.778 (perp=5.917, rec=0.132, cos=0.463), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real and rescut funny [SEP]']
Attempt swap
[1850/2000] tot_loss=1.771 (perp=5.917, rec=0.125, cos=0.463), tot_loss_proj:2.369 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real and rescut funny [SEP]']
Attempt swap
[1900/2000] tot_loss=1.774 (perp=5.917, rec=0.128, cos=0.463), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real and rescut funny [SEP]']
[1950/2000] tot_loss=1.770 (perp=5.917, rec=0.124, cos=0.463), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real and rescut funny [SEP]']
Attempt swap
[2000/2000] tot_loss=1.781 (perp=5.917, rec=0.135, cos=0.463), tot_loss_proj:2.368 [t=0.22s]
prediction: ['[CLS] winner, - -... smart, subtle, real and rescut funny [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] winner, - -... smart, subtle, real and rescut funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 88.889 | r: 80.000
rouge2     | fm: 11.765 | p: 12.500 | r: 11.111
rougeL     | fm: 63.158 | p: 66.667 | r: 60.000
rougeLsum  | fm: 63.158 | p: 66.667 | r: 60.000
r1fm+r2fm = 95.975

[Aggregate metrics]:
rouge1     | fm: 90.036 | p: 89.507 | r: 90.805
rouge2     | fm: 55.247 | p: 55.055 | r: 55.421
rougeL     | fm: 77.457 | p: 77.067 | r: 78.056
rougeLsum  | fm: 77.568 | p: 77.127 | r: 78.196
r1fm+r2fm = 145.284

input #69 time: 0:08:50 | total time: 10:18:40


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.7079211168008883
highest_index [0]
highest [0.7079211168008883]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8039513230323792 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.7676933407783508 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7416654825210571 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7263457179069519 for ['[CLS] ga characteristic jump make deaths composed ⟩ [SEP]']
[Init] best rec loss: 0.7110485434532166 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 0.6895687580108643 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best perm rec loss: 0.6870579123497009 for ['[CLS] modern bobbution guy ি muscle party [SEP]']
[Init] best perm rec loss: 0.6828387975692749 for ['[CLS] িbution guy party muscle modern bob [SEP]']
[Init] best perm rec loss: 0.682759702205658 for ['[CLS] party musclebution bob ি guy modern [SEP]']
[Init] best perm rec loss: 0.6824373602867126 for ['[CLS] party bob muscle guybution modern ি [SEP]']
[Init] best perm rec loss: 0.6821265816688538 for ['[CLS] ি party muscle bobbution modern guy [SEP]']
[Init] best perm rec loss: 0.6820945739746094 for ['[CLS] bob guy muscle party modernbution ি [SEP]']
[Init] best perm rec loss: 0.6804652214050293 for ['[CLS]bution modern muscle ি bob party guy [SEP]']
[Init] best perm rec loss: 0.6803187131881714 for ['[CLS] guy ি modernbution muscle party bob [SEP]']
[Init] best perm rec loss: 0.6801074147224426 for ['[CLS]bution muscle guy ি modern bob party [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.356 (perp=12.842, rec=0.297, cos=0.491), tot_loss_proj:3.904 [t=0.22s]
prediction: ['[CLS] hit feeling bump clunkunkunk [SEP]']
[ 100/2000] tot_loss=2.395 (perp=8.861, rec=0.146, cos=0.477), tot_loss_proj:2.961 [t=0.22s]
prediction: ['[CLS] on getsy clunkyy [SEP]']
[ 150/2000] tot_loss=2.811 (perp=11.135, rec=0.089, cos=0.495), tot_loss_proj:3.523 [t=0.22s]
prediction: ['[CLS] screen getsy clunk ony [SEP]']
[ 200/2000] tot_loss=2.803 (perp=11.135, rec=0.081, cos=0.494), tot_loss_proj:3.521 [t=0.22s]
prediction: ['[CLS] screen getsy clunk ony [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.455 (perp=9.496, rec=0.074, cos=0.482), tot_loss_proj:3.043 [t=0.22s]
prediction: ['[CLS] screen gets clunk the ony [SEP]']
[ 300/2000] tot_loss=2.457 (perp=9.496, rec=0.064, cos=0.494), tot_loss_proj:3.021 [t=0.22s]
prediction: ['[CLS] screen gets clunk the ony [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.061 (perp=7.204, rec=0.127, cos=0.493), tot_loss_proj:2.197 [t=0.22s]
prediction: ['[CLS]y on screen gets clunky [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.992 (perp=7.051, rec=0.088, cos=0.494), tot_loss_proj:2.196 [t=0.22s]
prediction: ['[CLS] on screen gets clunkyy [SEP]']
[ 450/2000] tot_loss=1.988 (perp=7.051, rec=0.083, cos=0.495), tot_loss_proj:2.196 [t=0.22s]
prediction: ['[CLS] on screen gets clunkyy [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.984 (perp=7.051, rec=0.077, cos=0.497), tot_loss_proj:2.198 [t=0.22s]
prediction: ['[CLS] on screen gets clunkyy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.970 (perp=7.051, rec=0.062, cos=0.497), tot_loss_proj:2.196 [t=0.22s]
prediction: ['[CLS] on screen gets clunkyy [SEP]']
[ 600/2000] tot_loss=1.976 (perp=7.031, rec=0.073, cos=0.497), tot_loss_proj:2.134 [t=0.22s]
prediction: ['[CLS] on screen gets clunky the [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=1.819 (perp=6.307, rec=0.064, cos=0.494), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] the on screen gets clunky [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.697 (perp=5.690, rec=0.063, cos=0.495), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 750/2000] tot_loss=1.712 (perp=5.690, rec=0.077, cos=0.497), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.709 (perp=5.690, rec=0.074, cos=0.497), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.700 (perp=5.690, rec=0.064, cos=0.498), tot_loss_proj:1.845 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 900/2000] tot_loss=1.706 (perp=5.690, rec=0.070, cos=0.498), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.695 (perp=5.690, rec=0.058, cos=0.498), tot_loss_proj:1.838 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.697 (perp=5.690, rec=0.060, cos=0.498), tot_loss_proj:1.831 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1050/2000] tot_loss=1.701 (perp=5.690, rec=0.065, cos=0.499), tot_loss_proj:1.834 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.701 (perp=5.690, rec=0.065, cos=0.499), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.700 (perp=5.690, rec=0.064, cos=0.498), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1200/2000] tot_loss=1.692 (perp=5.690, rec=0.056, cos=0.498), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.697 (perp=5.690, rec=0.060, cos=0.499), tot_loss_proj:1.833 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.705 (perp=5.690, rec=0.069, cos=0.498), tot_loss_proj:1.834 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1350/2000] tot_loss=1.696 (perp=5.690, rec=0.060, cos=0.498), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.700 (perp=5.690, rec=0.063, cos=0.498), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.706 (perp=5.690, rec=0.069, cos=0.499), tot_loss_proj:1.833 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1500/2000] tot_loss=1.697 (perp=5.690, rec=0.061, cos=0.499), tot_loss_proj:1.838 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.700 (perp=5.690, rec=0.063, cos=0.499), tot_loss_proj:1.839 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.703 (perp=5.690, rec=0.066, cos=0.499), tot_loss_proj:1.837 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1650/2000] tot_loss=1.706 (perp=5.690, rec=0.070, cos=0.499), tot_loss_proj:1.840 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.697 (perp=5.690, rec=0.060, cos=0.499), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.702 (perp=5.690, rec=0.065, cos=0.499), tot_loss_proj:1.839 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1800/2000] tot_loss=1.708 (perp=5.690, rec=0.072, cos=0.499), tot_loss_proj:1.836 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.705 (perp=5.690, rec=0.068, cos=0.499), tot_loss_proj:1.836 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.701 (perp=5.690, rec=0.065, cos=0.499), tot_loss_proj:1.839 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1950/2000] tot_loss=1.709 (perp=5.690, rec=0.072, cos=0.499), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.710 (perp=5.690, rec=0.073, cos=0.498), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] on the screen gets clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 90.126 | p: 89.564 | r: 90.890
rouge2     | fm: 55.231 | p: 55.086 | r: 55.422
rougeL     | fm: 77.279 | p: 76.873 | r: 77.863
rougeLsum  | fm: 77.490 | p: 77.055 | r: 78.113
r1fm+r2fm = 145.358

input #70 time: 0:08:45 | total time: 10:27:25


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.7184217407985503
highest_index [0]
highest [0.7184217407985503]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8966966271400452 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.8944558501243591 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8870217800140381 for ['[CLS]kledclaiming solid due tear stakesaint flight ken keel receiver living duval us tottenham [SEP]']
[Init] best rec loss: 0.8807163238525391 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 0.8767750859260559 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 0.8666383028030396 for ['[CLS] composed warsselle ty urbantist empireneas amendment broadbandcat murdereo money appoint [SEP]']
[Init] best rec loss: 0.8591819405555725 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 0.8461241722106934 for ['[CLS]ine runways oregon bored : towardsgold occurred snow abovegerstypical definitely holiday rooney [SEP]']
[Init] best perm rec loss: 0.8451759219169617 for ['[CLS] occurred above definitely runwaysgoldine bored towardstypical rooney oregon holiday snowgers : [SEP]']
[Init] best perm rec loss: 0.8441911935806274 for ['[CLS] runways oregon rooneytypical above definitely towardsgers :ine occurred holiday boredgold snow [SEP]']
[Init] best perm rec loss: 0.8432714939117432 for ['[CLS] oregontypical definitelygold holidaygers runways : bored rooney towards snow occurred aboveine [SEP]']
[Init] best perm rec loss: 0.8423367142677307 for ['[CLS] runways :gersinegold snow rooney oregon towardstypical occurred definitely bored holiday above [SEP]']
[Init] best perm rec loss: 0.8412135243415833 for ['[CLS] oregongold runwaystypical holiday rooney towards definitely occurred :inegers bored snow above [SEP]']
[Init] best perm rec loss: 0.8409808278083801 for ['[CLS]inegers snow above holiday towards rooneytypical : definitelygold runways bored oregon occurred [SEP]']
[Init] best perm rec loss: 0.8405684232711792 for ['[CLS]typical :gers rooney oregon bored runwaysinegold definitely towards above holiday snow occurred [SEP]']
[Init] best perm rec loss: 0.840352475643158 for ['[CLS] abovegers bored oregon holidaytypicalgold rooney runways definitely snow occurredine towards : [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.903 (perp=10.774, rec=0.270, cos=0.478), tot_loss_proj:3.939 [t=0.22s]
prediction: ['[CLS]color : single fighter single moment doctors jump trying that loops moment no not ; [SEP]']
[ 100/2000] tot_loss=2.929 (perp=11.551, rec=0.150, cos=0.468), tot_loss_proj:3.998 [t=0.22s]
prediction: ['[CLS] courtney - a jump single moment moment jump my your there seat not not - [SEP]']
[ 150/2000] tot_loss=2.430 (perp=9.202, rec=0.118, cos=0.472), tot_loss_proj:3.508 [t=0.22s]
prediction: ['[CLS] - there a jump single moment - jump - your - seat not not and [SEP]']
[ 200/2000] tot_loss=2.380 (perp=9.058, rec=0.090, cos=0.478), tot_loss_proj:3.560 [t=0.22s]
prediction: ['[CLS] - there a jump single moment - jump in your - seat not s and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.182 (perp=8.122, rec=0.081, cos=0.477), tot_loss_proj:3.334 [t=0.22s]
prediction: ['[CLS] - there a jump single moment - jump in your seat not s - and [SEP]']
[ 300/2000] tot_loss=2.178 (perp=8.122, rec=0.076, cos=0.478), tot_loss_proj:3.333 [t=0.22s]
prediction: ['[CLS] - there a jump single moment - jump in your seat not s - and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.911 (perp=6.756, rec=0.081, cos=0.479), tot_loss_proj:2.471 [t=0.22s]
prediction: ['[CLS] not there a jump single moment - jump in your seat - s - and [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.751 (perp=6.074, rec=0.059, cos=0.477), tot_loss_proj:2.672 [t=0.22s]
prediction: ['[CLS] not there a single moment here - jump in your seat - s - and [SEP]']
[ 450/2000] tot_loss=1.754 (perp=6.074, rec=0.060, cos=0.479), tot_loss_proj:2.670 [t=0.22s]
prediction: ['[CLS] not there a single moment here - jump in your seat - s - and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.768 (perp=6.074, rec=0.074, cos=0.480), tot_loss_proj:2.665 [t=0.22s]
prediction: ['[CLS] not there a single moment here - jump in your seat - s - and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.764 (perp=6.074, rec=0.069, cos=0.480), tot_loss_proj:2.670 [t=0.22s]
prediction: ['[CLS] not there a single moment here - jump in your seat - s - and [SEP]']
[ 600/2000] tot_loss=1.771 (perp=6.074, rec=0.076, cos=0.480), tot_loss_proj:2.666 [t=0.22s]
prediction: ['[CLS] not there a single moment here - jump in your seat - s - and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.764 (perp=6.074, rec=0.069, cos=0.480), tot_loss_proj:2.662 [t=0.22s]
prediction: ['[CLS] not there a single moment here - jump in your seat - s - and [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.690 (perp=5.687, rec=0.074, cos=0.479), tot_loss_proj:2.273 [t=0.22s]
prediction: ['[CLS] not there a single moment here s jump in your seat - - - and [SEP]']
[ 750/2000] tot_loss=1.684 (perp=5.687, rec=0.068, cos=0.479), tot_loss_proj:2.274 [t=0.22s]
prediction: ['[CLS] not there a single moment here s jump in your seat - - - and [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.698 (perp=5.761, rec=0.068, cos=0.477), tot_loss_proj:2.228 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.695 (perp=5.761, rec=0.064, cos=0.479), tot_loss_proj:2.221 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
[ 900/2000] tot_loss=1.701 (perp=5.761, rec=0.070, cos=0.479), tot_loss_proj:2.230 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.696 (perp=5.761, rec=0.064, cos=0.479), tot_loss_proj:2.219 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.703 (perp=5.761, rec=0.072, cos=0.479), tot_loss_proj:2.231 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
[1050/2000] tot_loss=1.702 (perp=5.761, rec=0.071, cos=0.479), tot_loss_proj:2.232 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.701 (perp=5.761, rec=0.070, cos=0.479), tot_loss_proj:2.231 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.690 (perp=5.761, rec=0.059, cos=0.479), tot_loss_proj:2.228 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
[1200/2000] tot_loss=1.697 (perp=5.761, rec=0.066, cos=0.479), tot_loss_proj:2.222 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.701 (perp=5.761, rec=0.069, cos=0.479), tot_loss_proj:2.227 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.697 (perp=5.761, rec=0.066, cos=0.479), tot_loss_proj:2.226 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
[1350/2000] tot_loss=1.695 (perp=5.761, rec=0.064, cos=0.479), tot_loss_proj:2.227 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.703 (perp=5.761, rec=0.072, cos=0.479), tot_loss_proj:2.232 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.692 (perp=5.761, rec=0.061, cos=0.479), tot_loss_proj:2.227 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
[1500/2000] tot_loss=1.692 (perp=5.761, rec=0.060, cos=0.479), tot_loss_proj:2.226 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.693 (perp=5.761, rec=0.061, cos=0.480), tot_loss_proj:2.228 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.700 (perp=5.761, rec=0.069, cos=0.480), tot_loss_proj:2.218 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
[1650/2000] tot_loss=1.708 (perp=5.761, rec=0.076, cos=0.480), tot_loss_proj:2.222 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.701 (perp=5.761, rec=0.069, cos=0.480), tot_loss_proj:2.233 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.700 (perp=5.761, rec=0.068, cos=0.479), tot_loss_proj:2.225 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
[1800/2000] tot_loss=1.697 (perp=5.761, rec=0.065, cos=0.480), tot_loss_proj:2.228 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.707 (perp=5.761, rec=0.075, cos=0.479), tot_loss_proj:2.224 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.696 (perp=5.761, rec=0.064, cos=0.479), tot_loss_proj:2.230 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
[1950/2000] tot_loss=1.697 (perp=5.761, rec=0.065, cos=0.479), tot_loss_proj:2.231 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.695 (perp=5.761, rec=0.064, cos=0.479), tot_loss_proj:2.233 [t=0.22s]
prediction: ["[CLS] s not there a single moment s jump in your seat - -'and [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] s not there a single moment s jump in your seat - -'and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.296 | p: 92.857 | r: 100.000
rouge2     | fm: 48.000 | p: 46.154 | r: 50.000
rougeL     | fm: 81.481 | p: 78.571 | r: 84.615
rougeLsum  | fm: 81.481 | p: 78.571 | r: 84.615
r1fm+r2fm = 144.296

[Aggregate metrics]:
rouge1     | fm: 90.273 | p: 89.675 | r: 91.035
rouge2     | fm: 54.871 | p: 54.638 | r: 55.102
rougeL     | fm: 77.449 | p: 76.926 | r: 78.054
rougeLsum  | fm: 77.479 | p: 77.038 | r: 78.093
r1fm+r2fm = 145.144

input #71 time: 0:08:49 | total time: 10:36:14


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.7283941564600465
highest_index [0]
highest [0.7283941564600465]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7717710137367249 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7661913633346558 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 0.7369290590286255 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7315022945404053 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 0.7269995808601379 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.6966021656990051 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.6950629353523254 for ['[CLS] nonetheless zone! orbital lifeboat van pork support ta reserve dna walking accidentallyungen except [SEP]']
[Init] best perm rec loss: 0.6935943961143494 for ['[CLS] zone ta accidentally walking lifeboat support pork! orbital exceptungen nonetheless van reserve dna [SEP]']
[Init] best perm rec loss: 0.6932824850082397 for ['[CLS] pork walking accidentally zone! lifeboat ta van orbital except dna nonetheless reserveungen support [SEP]']
[Init] best perm rec loss: 0.6918912529945374 for ['[CLS] pork except ta zone support! walking accidentally vanungen reserve nonetheless orbital lifeboat dna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.199 (perp=12.074, rec=0.323, cos=0.461), tot_loss_proj:3.734 [t=0.22s]
prediction: ['[CLS] a tough " toughing italian pissedistology harder compromise boiler stabbed harder violence [SEP]']
[ 100/2000] tot_loss=2.730 (perp=10.539, rec=0.165, cos=0.458), tot_loss_proj:3.366 [t=0.22s]
prediction: ['[CLS] has tough time tougher time its tough biochemistry tough philosophy balancing attacker violence [SEP]']
[ 150/2000] tot_loss=2.702 (perp=10.674, rec=0.105, cos=0.463), tot_loss_proj:3.191 [t=0.22s]
prediction: ['[CLS] has a time tougher time its difficult violence tough philosophy balancing usinger violence [SEP]']
[ 200/2000] tot_loss=2.612 (perp=10.305, rec=0.083, cos=0.468), tot_loss_proj:3.055 [t=0.22s]
prediction: ['[CLS] has a time tougher time its imposed violenceica philosophy balancing with - violence [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.227 (perp=8.423, rec=0.084, cos=0.459), tot_loss_proj:2.691 [t=0.22s]
prediction: ['[CLS] time has a tougher time its imposed violence hard philosophy balancing with - violence [SEP]']
[ 300/2000] tot_loss=2.330 (perp=8.918, rec=0.079, cos=0.468), tot_loss_proj:2.780 [t=0.22s]
prediction: ['[CLS] time has a tougher time its imposed violenceica philosophy balancing with - violence [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.005 (perp=7.326, rec=0.072, cos=0.467), tot_loss_proj:2.270 [t=0.22s]
prediction: ['[CLS] time has a tougher time balancing its pursed violencea philosophy with - violence [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.976 (perp=7.163, rec=0.078, cos=0.466), tot_loss_proj:2.253 [t=0.22s]
prediction: ['[CLS] time has a tougher time balancing itschemical inspired violencea philosophy with - [SEP]']
[ 450/2000] tot_loss=1.971 (perp=7.165, rec=0.070, cos=0.468), tot_loss_proj:2.248 [t=0.22s]
prediction: ['[CLS] time has a tougher time balancing itsfk inspired violencea philosophy with - [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.934 (perp=6.966, rec=0.073, cos=0.468), tot_loss_proj:2.202 [t=0.22s]
prediction: ['[CLS] time has a tougher time balancing its violence inspiredfka philosophy with - [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.878 (perp=6.713, rec=0.068, cos=0.468), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] time has a tougher time balancing its violence with inspiredfka philosophy - [SEP]']
[ 600/2000] tot_loss=1.871 (perp=6.713, rec=0.061, cos=0.467), tot_loss_proj:2.131 [t=0.22s]
prediction: ['[CLS] time has a tougher time balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.870 (perp=6.713, rec=0.060, cos=0.467), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] time has a tougher time balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.881 (perp=6.713, rec=0.071, cos=0.468), tot_loss_proj:2.143 [t=0.22s]
prediction: ['[CLS] time has a tougher time balancing its violence with inspiredfka philosophy - [SEP]']
[ 750/2000] tot_loss=1.888 (perp=6.713, rec=0.078, cos=0.468), tot_loss_proj:2.145 [t=0.22s]
prediction: ['[CLS] time has a tougher time balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.889 (perp=6.713, rec=0.078, cos=0.468), tot_loss_proj:2.136 [t=0.22s]
prediction: ['[CLS] time has a tougher time balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.048 (perp=7.603, rec=0.059, cos=0.468), tot_loss_proj:2.564 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
[ 900/2000] tot_loss=2.055 (perp=7.603, rec=0.066, cos=0.468), tot_loss_proj:2.563 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.073 (perp=7.603, rec=0.084, cos=0.469), tot_loss_proj:2.564 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[1000/2000] tot_loss=2.058 (perp=7.603, rec=0.069, cos=0.468), tot_loss_proj:2.562 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
[1050/2000] tot_loss=2.065 (perp=7.603, rec=0.075, cos=0.469), tot_loss_proj:2.558 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[1100/2000] tot_loss=2.065 (perp=7.603, rec=0.075, cos=0.469), tot_loss_proj:2.564 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[1150/2000] tot_loss=2.058 (perp=7.603, rec=0.069, cos=0.468), tot_loss_proj:2.566 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
[1200/2000] tot_loss=2.058 (perp=7.603, rec=0.068, cos=0.469), tot_loss_proj:2.567 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[1250/2000] tot_loss=2.061 (perp=7.603, rec=0.072, cos=0.469), tot_loss_proj:2.558 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[1300/2000] tot_loss=2.048 (perp=7.603, rec=0.059, cos=0.469), tot_loss_proj:2.559 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
[1350/2000] tot_loss=2.065 (perp=7.603, rec=0.076, cos=0.469), tot_loss_proj:2.561 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[1400/2000] tot_loss=2.052 (perp=7.603, rec=0.063, cos=0.468), tot_loss_proj:2.561 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[1450/2000] tot_loss=2.052 (perp=7.603, rec=0.062, cos=0.469), tot_loss_proj:2.555 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
[1500/2000] tot_loss=2.062 (perp=7.603, rec=0.073, cos=0.469), tot_loss_proj:2.567 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[1550/2000] tot_loss=2.054 (perp=7.603, rec=0.064, cos=0.469), tot_loss_proj:2.567 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[1600/2000] tot_loss=2.063 (perp=7.603, rec=0.074, cos=0.469), tot_loss_proj:2.559 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
[1650/2000] tot_loss=2.051 (perp=7.603, rec=0.062, cos=0.469), tot_loss_proj:2.554 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[1700/2000] tot_loss=2.048 (perp=7.603, rec=0.058, cos=0.469), tot_loss_proj:2.560 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
[1750/2000] tot_loss=2.050 (perp=7.603, rec=0.060, cos=0.469), tot_loss_proj:2.565 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
[1800/2000] tot_loss=2.050 (perp=7.603, rec=0.060, cos=0.469), tot_loss_proj:2.562 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.026 (perp=7.471, rec=0.064, cos=0.468), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence withfka philosophy - inspired [SEP]']
Attempt swap
[1900/2000] tot_loss=2.037 (perp=7.471, rec=0.074, cos=0.469), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence withfka philosophy - inspired [SEP]']
[1950/2000] tot_loss=2.041 (perp=7.471, rec=0.078, cos=0.469), tot_loss_proj:2.503 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence withfka philosophy - inspired [SEP]']
Attempt swap
[2000/2000] tot_loss=2.024 (perp=7.471, rec=0.061, cos=0.469), tot_loss_proj:2.501 [t=0.22s]
prediction: ['[CLS] time has a tougherfk balancing its violence withfka philosophy - inspired [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] time has a tougherfk balancing its violence with inspiredfka philosophy - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 83.333 | r: 76.923
rouge2     | fm: 43.478 | p: 45.455 | r: 41.667
rougeL     | fm: 72.000 | p: 75.000 | r: 69.231
rougeLsum  | fm: 72.000 | p: 75.000 | r: 69.231
r1fm+r2fm = 123.478

[Aggregate metrics]:
rouge1     | fm: 90.098 | p: 89.567 | r: 90.846
rouge2     | fm: 54.794 | p: 54.686 | r: 55.040
rougeL     | fm: 77.391 | p: 76.969 | r: 77.931
rougeLsum  | fm: 77.541 | p: 77.093 | r: 78.061
r1fm+r2fm = 144.892

input #72 time: 0:08:51 | total time: 10:45:06


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.7143884685911455
highest_index [0]
highest [0.7143884685911455]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9623157382011414 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9350883364677429 for ['[CLS] garage knight [SEP]']
[Init] best rec loss: 0.9073797464370728 for ['[CLS] capitol living [SEP]']
[Init] best rec loss: 0.901882529258728 for ['[CLS] denied airline [SEP]']
[Init] best rec loss: 0.8977863788604736 for ['[CLS] role breton [SEP]']
[Init] best rec loss: 0.8950979709625244 for ['[CLS] zhang body [SEP]']
[Init] best rec loss: 0.884573221206665 for ['[CLS] pass society [SEP]']
[Init] best rec loss: 0.8690151572227478 for ['[CLS] puget traditional [SEP]']
[Init] best rec loss: 0.8672937750816345 for ['[CLS]ɛ society [SEP]']
[Init] best rec loss: 0.832367479801178 for ['[CLS] massachusetts gun [SEP]']
[Init] best perm rec loss: 0.8313427567481995 for ['[CLS] gun massachusetts [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.610 (perp=9.723, rec=0.181, cos=0.484), tot_loss_proj:2.523 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.529 (perp=9.723, rec=0.096, cos=0.488), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.502 (perp=9.723, rec=0.070, cos=0.488), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.486 (perp=9.723, rec=0.053, cos=0.489), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.495 (perp=9.723, rec=0.062, cos=0.488), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.500 (perp=9.723, rec=0.068, cos=0.488), tot_loss_proj:2.523 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.497 (perp=9.723, rec=0.064, cos=0.489), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.512 (perp=9.723, rec=0.081, cos=0.486), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.495 (perp=9.723, rec=0.061, cos=0.489), tot_loss_proj:2.500 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.489 (perp=9.723, rec=0.055, cos=0.489), tot_loss_proj:2.516 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.510 (perp=9.723, rec=0.075, cos=0.489), tot_loss_proj:2.501 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.493 (perp=9.723, rec=0.059, cos=0.490), tot_loss_proj:2.503 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.500 (perp=9.723, rec=0.066, cos=0.489), tot_loss_proj:2.502 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.494 (perp=9.723, rec=0.060, cos=0.489), tot_loss_proj:2.519 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.493 (perp=9.723, rec=0.059, cos=0.490), tot_loss_proj:2.526 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.501 (perp=9.723, rec=0.067, cos=0.490), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.495 (perp=9.723, rec=0.061, cos=0.490), tot_loss_proj:2.503 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.510 (perp=9.723, rec=0.076, cos=0.489), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.498 (perp=9.723, rec=0.064, cos=0.490), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.486 (perp=9.723, rec=0.052, cos=0.489), tot_loss_proj:2.503 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.496 (perp=9.723, rec=0.062, cos=0.489), tot_loss_proj:2.508 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.490 (perp=9.723, rec=0.056, cos=0.490), tot_loss_proj:2.502 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.499 (perp=9.723, rec=0.065, cos=0.489), tot_loss_proj:2.507 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.493 (perp=9.723, rec=0.059, cos=0.489), tot_loss_proj:2.507 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.488 (perp=9.723, rec=0.054, cos=0.490), tot_loss_proj:2.514 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.493 (perp=9.723, rec=0.059, cos=0.490), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.500 (perp=9.723, rec=0.066, cos=0.489), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.498 (perp=9.723, rec=0.064, cos=0.489), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.478 (perp=9.723, rec=0.044, cos=0.490), tot_loss_proj:2.526 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.493 (perp=9.723, rec=0.059, cos=0.490), tot_loss_proj:2.502 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.501 (perp=9.723, rec=0.067, cos=0.489), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.488 (perp=9.723, rec=0.054, cos=0.490), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.497 (perp=9.723, rec=0.063, cos=0.490), tot_loss_proj:2.505 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.502 (perp=9.723, rec=0.067, cos=0.490), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.502 (perp=9.723, rec=0.068, cos=0.489), tot_loss_proj:2.514 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.502 (perp=9.723, rec=0.067, cos=0.490), tot_loss_proj:2.500 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.505 (perp=9.723, rec=0.071, cos=0.490), tot_loss_proj:2.519 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.502 (perp=9.723, rec=0.068, cos=0.490), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.500 (perp=9.723, rec=0.066, cos=0.490), tot_loss_proj:2.519 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.489 (perp=9.723, rec=0.055, cos=0.490), tot_loss_proj:2.516 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.281 | p: 89.769 | r: 90.999
rouge2     | fm: 55.518 | p: 55.323 | r: 55.781
rougeL     | fm: 77.596 | p: 77.213 | r: 78.201
rougeLsum  | fm: 77.780 | p: 77.387 | r: 78.363
r1fm+r2fm = 145.799

input #73 time: 0:08:43 | total time: 10:53:49


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.7199418745010118
highest_index [0]
highest [0.7199418745010118]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 0.8165276646614075 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6255942583084106 for ['[CLS] storage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.220 (perp=8.178, rec=0.107, cos=0.478), tot_loss_proj:2.412 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=2.174 (perp=8.178, rec=0.064, cos=0.475), tot_loss_proj:2.216 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=2.172 (perp=8.178, rec=0.058, cos=0.479), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=2.171 (perp=8.178, rec=0.062, cos=0.473), tot_loss_proj:2.231 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.172 (perp=8.178, rec=0.056, cos=0.480), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=2.172 (perp=8.178, rec=0.056, cos=0.481), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.186 (perp=8.178, rec=0.071, cos=0.479), tot_loss_proj:2.231 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.165 (perp=8.178, rec=0.049, cos=0.480), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=2.171 (perp=8.178, rec=0.056, cos=0.480), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.177 (perp=8.178, rec=0.061, cos=0.481), tot_loss_proj:2.219 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.182 (perp=8.178, rec=0.065, cos=0.482), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=2.178 (perp=8.178, rec=0.062, cos=0.480), tot_loss_proj:2.231 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.174 (perp=8.178, rec=0.058, cos=0.481), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.174 (perp=8.178, rec=0.057, cos=0.481), tot_loss_proj:2.225 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=2.184 (perp=8.178, rec=0.067, cos=0.481), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.181 (perp=8.178, rec=0.064, cos=0.481), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.193 (perp=8.178, rec=0.076, cos=0.481), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=2.176 (perp=8.178, rec=0.059, cos=0.481), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.169 (perp=8.178, rec=0.052, cos=0.482), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=2.167 (perp=8.178, rec=0.050, cos=0.482), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=2.174 (perp=8.178, rec=0.057, cos=0.481), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=2.180 (perp=8.178, rec=0.063, cos=0.482), tot_loss_proj:2.225 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=2.179 (perp=8.178, rec=0.062, cos=0.481), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=2.171 (perp=8.178, rec=0.055, cos=0.481), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=2.180 (perp=8.178, rec=0.063, cos=0.482), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=2.174 (perp=8.178, rec=0.058, cos=0.481), tot_loss_proj:2.219 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=2.174 (perp=8.178, rec=0.057, cos=0.482), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=2.187 (perp=8.178, rec=0.070, cos=0.481), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=2.182 (perp=8.178, rec=0.064, cos=0.482), tot_loss_proj:2.231 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=2.178 (perp=8.178, rec=0.061, cos=0.482), tot_loss_proj:2.231 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=2.183 (perp=8.178, rec=0.066, cos=0.482), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=2.177 (perp=8.178, rec=0.060, cos=0.481), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=2.180 (perp=8.178, rec=0.063, cos=0.482), tot_loss_proj:2.216 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=2.164 (perp=8.178, rec=0.047, cos=0.481), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=2.178 (perp=8.178, rec=0.061, cos=0.482), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=2.181 (perp=8.178, rec=0.064, cos=0.481), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=2.186 (perp=8.178, rec=0.069, cos=0.482), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=2.183 (perp=8.178, rec=0.066, cos=0.481), tot_loss_proj:2.243 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=2.176 (perp=8.178, rec=0.059, cos=0.481), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=2.196 (perp=8.178, rec=0.079, cos=0.482), tot_loss_proj:2.216 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.420 | p: 89.875 | r: 91.080
rouge2     | fm: 55.986 | p: 55.881 | r: 56.175
rougeL     | fm: 77.960 | p: 77.561 | r: 78.486
rougeLsum  | fm: 78.061 | p: 77.648 | r: 78.657
r1fm+r2fm = 146.406

input #74 time: 0:08:36 | total time: 11:02:25


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.7344288308995539
highest_index [0]
highest [0.7344288308995539]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.8838121891021729 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.8555967807769775 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.827835202217102 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best perm rec loss: 0.8278002142906189 for ['[CLS] double es regiment alfred marlene help reason moth churches malone duties connacht clan zach section meaning rushose lakes [SEP]']
[Init] best perm rec loss: 0.8276180028915405 for ['[CLS] zach section marlene double clan churches rush reason es help duties meaning malone alfred connacht lakes regimentose moth [SEP]']
[Init] best perm rec loss: 0.825782299041748 for ['[CLS] malone alfred reason connacht dutiesose lakes regiment rush es help churches double meaning zach marlene moth clan section [SEP]']
[Init] best perm rec loss: 0.8238572478294373 for ['[CLS] help section marlene duties moth lakes double churchesose clan meaning rush malone connacht es regiment alfred zach reason [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.099 (perp=11.586, rec=0.331, cos=0.452), tot_loss_proj:4.130 [t=0.22s]
prediction: ["[CLS] 'person easily historical homework digital not. dismissed easily easily forgottenly amanda. hiking em of filled [SEP]"]
[ 100/2000] tot_loss=3.014 (perp=11.938, rec=0.169, cos=0.457), tot_loss_proj:4.101 [t=0.22s]
prediction: ['[CLS] therefalls easily explosive instability became not taken dismissed easily easily forgotten or disciplined is excursion fr without responded [SEP]']
[ 150/2000] tot_loss=2.661 (perp=10.406, rec=0.123, cos=0.456), tot_loss_proj:3.873 [t=0.22s]
prediction: ['[CLS] thefalls easily into instability excursion not is dismissed instability easily forgotten or not this excursion into without filled [SEP]']
[ 200/2000] tot_loss=2.473 (perp=9.484, rec=0.112, cos=0.464), tot_loss_proj:3.668 [t=0.22s]
prediction: ['[CLS] therued easily into mentalenter not is dismissed instability easily forgotten or not this excursion into. doubts [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.157 (perp=8.019, rec=0.094, cos=0.460), tot_loss_proj:3.152 [t=0.22s]
prediction: ['[CLS] the percolating mentalenter is not dismissed instability easily forgotten or not this excursion into.! [SEP]']
[ 300/2000] tot_loss=2.264 (perp=8.632, rec=0.080, cos=0.458), tot_loss_proj:2.934 [t=0.22s]
prediction: ['[CLS] the percolating mentalenter is not dismissed instability easily forgotten or mental this excursion into.! [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.309 (perp=8.701, rec=0.111, cos=0.458), tot_loss_proj:2.690 [t=0.22s]
prediction: ['[CLS] the takencolating mentalenter is not dismissed of easily forgotten or mental this excursion into instability! [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.945 (perp=6.959, rec=0.095, cos=0.458), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] the percolating mentalenter is not dismissed of easily forgotten or this excursion into mental instability. [SEP]']
[ 450/2000] tot_loss=2.135 (perp=7.953, rec=0.085, cos=0.460), tot_loss_proj:2.813 [t=0.22s]
prediction: ['[CLS] the percolating mentalenter is not dismissednous easily forgotten or this excursion into mental instability, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.949 (perp=7.075, rec=0.075, cos=0.459), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] the percolating mentalenter is not dismissed this easily forgotten ornous excursion into mental instability. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.889 (perp=6.771, rec=0.074, cos=0.460), tot_loss_proj:2.911 [t=0.22s]
prediction: ['[CLS] the percolating mentalenter is not this dismissed easily forgotten or of excursion into mental instability. [SEP]']
[ 600/2000] tot_loss=2.149 (perp=8.029, rec=0.086, cos=0.457), tot_loss_proj:3.157 [t=0.22s]
prediction: ['[CLS] the percolating mentalenter is not this dismissed easily forgotten or of excursion intocola instability. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.280 (perp=8.732, rec=0.076, cos=0.458), tot_loss_proj:3.398 [t=0.22s]
prediction: ['[CLS] into percolating mentalenter is not this dismissed easily forgotten or excursion into ofcola instability. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.229 (perp=8.436, rec=0.085, cos=0.457), tot_loss_proj:3.299 [t=0.22s]
prediction: ['[CLS] into percolatingcolaenter is not this dismissed easily forgotten or excursion into epic mental instability. [SEP]']
[ 750/2000] tot_loss=2.127 (perp=7.932, rec=0.082, cos=0.459), tot_loss_proj:3.234 [t=0.22s]
prediction: ['[CLS] into percolating perenter is not this dismissed easily forgotten or excursion into epic mental instability. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.991 (perp=7.253, rec=0.082, cos=0.458), tot_loss_proj:3.045 [t=0.22s]
prediction: ['[CLS] percolating into perenter is not this dismissed easily forgotten or excursion into epic mental instability. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.879 (perp=6.694, rec=0.081, cos=0.459), tot_loss_proj:2.732 [t=0.22s]
prediction: ['[CLS] percolating into perenter is not this excursion easily forgotten or dismissed into epic mental instability. [SEP]']
[ 900/2000] tot_loss=1.881 (perp=6.694, rec=0.081, cos=0.461), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] percolating into perenter is not this excursion easily forgotten or dismissed into epic mental instability. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.877 (perp=6.694, rec=0.078, cos=0.460), tot_loss_proj:2.744 [t=0.22s]
prediction: ['[CLS] percolating into perenter is not this excursion easily forgotten or dismissed into epic mental instability. [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.920 (perp=6.868, rec=0.090, cos=0.456), tot_loss_proj:2.100 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissedrained epic mental instability. [SEP]']
[1050/2000] tot_loss=1.851 (perp=6.617, rec=0.068, cos=0.460), tot_loss_proj:2.102 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.857 (perp=6.617, rec=0.074, cos=0.460), tot_loss_proj:2.100 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.859 (perp=6.617, rec=0.076, cos=0.460), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
[1200/2000] tot_loss=1.859 (perp=6.617, rec=0.076, cos=0.460), tot_loss_proj:2.098 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.858 (perp=6.617, rec=0.074, cos=0.460), tot_loss_proj:2.101 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.857 (perp=6.617, rec=0.074, cos=0.460), tot_loss_proj:2.094 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
[1350/2000] tot_loss=1.866 (perp=6.617, rec=0.083, cos=0.459), tot_loss_proj:2.101 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.855 (perp=6.617, rec=0.072, cos=0.460), tot_loss_proj:2.104 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.866 (perp=6.617, rec=0.083, cos=0.460), tot_loss_proj:2.100 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
[1500/2000] tot_loss=1.867 (perp=6.617, rec=0.083, cos=0.460), tot_loss_proj:2.101 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.850 (perp=6.617, rec=0.067, cos=0.460), tot_loss_proj:2.099 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.850 (perp=6.617, rec=0.067, cos=0.460), tot_loss_proj:2.105 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
[1650/2000] tot_loss=1.859 (perp=6.617, rec=0.075, cos=0.460), tot_loss_proj:2.104 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.848 (perp=6.617, rec=0.065, cos=0.460), tot_loss_proj:2.100 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.849 (perp=6.617, rec=0.066, cos=0.460), tot_loss_proj:2.102 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
[1800/2000] tot_loss=1.860 (perp=6.617, rec=0.077, cos=0.460), tot_loss_proj:2.107 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.856 (perp=6.617, rec=0.072, cos=0.461), tot_loss_proj:2.100 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.863 (perp=6.617, rec=0.079, cos=0.460), tot_loss_proj:2.103 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
[1950/2000] tot_loss=1.860 (perp=6.617, rec=0.076, cos=0.460), tot_loss_proj:2.106 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.860 (perp=6.617, rec=0.076, cos=0.461), tot_loss_proj:2.107 [t=0.22s]
prediction: ['[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this excursion percolating into perenter is not easily forgotten or dismissed across epic mental instability. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 82.353 | r: 82.353
rouge2     | fm: 31.250 | p: 31.250 | r: 31.250
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 113.603

[Aggregate metrics]:
rouge1     | fm: 90.320 | p: 89.759 | r: 90.995
rouge2     | fm: 55.654 | p: 55.573 | r: 55.853
rougeL     | fm: 77.556 | p: 77.098 | r: 78.148
rougeLsum  | fm: 77.728 | p: 77.314 | r: 78.292
r1fm+r2fm = 145.974

input #75 time: 0:08:50 | total time: 11:11:16


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.7380817455895768
highest_index [0]
highest [0.7380817455895768]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.8903561234474182 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.8812438249588013 for ['[CLS] skin outside historian inside please determined boss legend vi đ wine unanimouslymer ski [SEP]']
[Init] best rec loss: 0.8758151531219482 for ['[CLS] midnight even task j mesh constellation village typhoonorough, advancing hammerist carol [SEP]']
[Init] best rec loss: 0.8519074320793152 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.8483340740203857 for ['[CLS] paper both commercially user guantanamo body 3d barker away commune also fortune turkey shay [SEP]']
[Init] best perm rec loss: 0.8467543721199036 for ['[CLS] commune turkey commercially both barker body guantanamo shay away fortune 3d user also paper [SEP]']
[Init] best perm rec loss: 0.8450672626495361 for ['[CLS] away turkey paper user guantanamo barker body commune 3d commercially shay also fortune both [SEP]']
[Init] best perm rec loss: 0.8433816432952881 for ['[CLS] fortune guantanamo turkey also barker user 3d away both commune commercially paper body shay [SEP]']
[Init] best perm rec loss: 0.8414925932884216 for ['[CLS] commune guantanamo body barker also fortune turkey 3d commercially both paper away user shay [SEP]']
[Init] best perm rec loss: 0.8413729071617126 for ['[CLS] 3d shay fortune user turkey also commune body paper away commercially barker both guantanamo [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.183 (perp=12.161, rec=0.287, cos=0.464), tot_loss_proj:3.837 [t=0.22s]
prediction: ['[CLS] stopped then when ( beetle stopped challenging challenging broadcasts after challenging has los stopped [SEP]']
[ 100/2000] tot_loss=2.612 (perp=10.127, rec=0.137, cos=0.450), tot_loss_proj:3.336 [t=0.22s]
prediction: ['[CLS] stopped earlier at 66 has stopped challenging himself allen if challenging has8 stopped [SEP]']
[ 150/2000] tot_loss=2.600 (perp=10.279, rec=0.092, cos=0.453), tot_loss_proj:3.329 [t=0.22s]
prediction: ['[CLS] stopped as at 66 has stopped challenging himself allen if challenging has, stopped [SEP]']
[ 200/2000] tot_loss=2.601 (perp=10.292, rec=0.093, cos=0.449), tot_loss_proj:3.389 [t=0.22s]
prediction: ['[CLS] stopped s at 66 has stopped challenging himself allen as challenging has, at [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.338 (perp=9.019, rec=0.088, cos=0.447), tot_loss_proj:3.046 [t=0.22s]
prediction: ['[CLS] is stopped at 66 has stopped challenging himself allen as challenging has, at [SEP]']
[ 300/2000] tot_loss=2.320 (perp=8.954, rec=0.075, cos=0.455), tot_loss_proj:3.079 [t=0.22s]
prediction: ['[CLS] s stopped at 66 has stopped challenging himself allen as challenging has,. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.183 (perp=7.704, rec=0.192, cos=0.450), tot_loss_proj:2.665 [t=0.22s]
prediction: ['[CLS] what was, allen 66, stopped challenging himself as. has, from [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.073 (perp=7.473, rec=0.127, cos=0.452), tot_loss_proj:2.754 [t=0.22s]
prediction: ['[CLS] what allen, at 66, stopped challenging himself as. has, from [SEP]']
[ 450/2000] tot_loss=2.078 (perp=7.626, rec=0.098, cos=0.454), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS] s allen, at 66, stopped challenging himself as. has, from [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.288 (perp=8.610, rec=0.114, cos=0.452), tot_loss_proj:2.780 [t=0.22s]
prediction: ["[CLS] '. allen at at 66, stopped challenging himself as has, from [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=2.003 (perp=7.132, rec=0.123, cos=0.454), tot_loss_proj:2.750 [t=0.22s]
prediction: ['[CLS] s. allen at at 66, stopped from challenging himself as has, [SEP]']
[ 600/2000] tot_loss=1.849 (perp=6.473, rec=0.104, cos=0.450), tot_loss_proj:2.616 [t=0.22s]
prediction: ['[CLS] s. allen, at 66, stopped from challenging himself as has, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.983 (perp=7.149, rec=0.102, cos=0.451), tot_loss_proj:2.743 [t=0.22s]
prediction: ['[CLS] s. allen has at at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.725 (perp=5.870, rec=0.099, cos=0.452), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
[ 750/2000] tot_loss=1.723 (perp=5.870, rec=0.097, cos=0.452), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.726 (perp=5.870, rec=0.100, cos=0.452), tot_loss_proj:2.503 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.718 (perp=5.870, rec=0.091, cos=0.452), tot_loss_proj:2.501 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
[ 900/2000] tot_loss=1.717 (perp=5.870, rec=0.090, cos=0.452), tot_loss_proj:2.503 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.715 (perp=5.870, rec=0.089, cos=0.452), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.711 (perp=5.870, rec=0.084, cos=0.452), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
[1050/2000] tot_loss=1.715 (perp=5.870, rec=0.089, cos=0.452), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.729 (perp=5.870, rec=0.102, cos=0.452), tot_loss_proj:2.502 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.718 (perp=5.870, rec=0.092, cos=0.452), tot_loss_proj:2.505 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
[1200/2000] tot_loss=1.713 (perp=5.870, rec=0.087, cos=0.452), tot_loss_proj:2.501 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.703 (perp=5.870, rec=0.077, cos=0.452), tot_loss_proj:2.500 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.712 (perp=5.870, rec=0.086, cos=0.452), tot_loss_proj:2.501 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
[1350/2000] tot_loss=1.720 (perp=5.870, rec=0.094, cos=0.452), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.710 (perp=5.870, rec=0.084, cos=0.452), tot_loss_proj:2.501 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.716 (perp=5.870, rec=0.090, cos=0.452), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
[1500/2000] tot_loss=1.721 (perp=5.870, rec=0.095, cos=0.452), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.715 (perp=5.870, rec=0.089, cos=0.452), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.719 (perp=5.870, rec=0.093, cos=0.452), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
[1650/2000] tot_loss=1.712 (perp=5.870, rec=0.086, cos=0.452), tot_loss_proj:2.501 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.735 (perp=5.870, rec=0.109, cos=0.452), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.714 (perp=5.798, rec=0.104, cos=0.450), tot_loss_proj:2.461 [t=0.22s]
prediction: ['[CLS] s. allen, at 66, has stopped from challenging himself as, [SEP]']
[1800/2000] tot_loss=1.692 (perp=5.798, rec=0.081, cos=0.452), tot_loss_proj:2.465 [t=0.22s]
prediction: ['[CLS] s. allen, at 66, has stopped from challenging himself as, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.696 (perp=5.798, rec=0.085, cos=0.452), tot_loss_proj:2.460 [t=0.22s]
prediction: ['[CLS] s. allen, at 66, has stopped from challenging himself as, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.699 (perp=5.798, rec=0.088, cos=0.452), tot_loss_proj:2.457 [t=0.22s]
prediction: ['[CLS] s. allen, at 66, has stopped from challenging himself as, [SEP]']
[1950/2000] tot_loss=1.703 (perp=5.798, rec=0.092, cos=0.452), tot_loss_proj:2.465 [t=0.22s]
prediction: ['[CLS] s. allen, at 66, has stopped from challenging himself as, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.703 (perp=5.798, rec=0.091, cos=0.452), tot_loss_proj:2.462 [t=0.22s]
prediction: ['[CLS] s. allen, at 66, has stopped from challenging himself as, [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] s. allen has, at 66, stopped from challenging himself as, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 27.273 | p: 27.273 | r: 27.273
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 118.939

[Aggregate metrics]:
rouge1     | fm: 90.321 | p: 89.824 | r: 90.989
rouge2     | fm: 55.379 | p: 55.336 | r: 55.553
rougeL     | fm: 77.541 | p: 77.154 | r: 78.129
rougeLsum  | fm: 77.761 | p: 77.391 | r: 78.286
r1fm+r2fm = 145.700

input #76 time: 0:08:44 | total time: 11:20:01


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.7236462882658601
highest_index [0]
highest [0.7236462882658601]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.8011814951896667 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.7947870492935181 for ["[CLS] it got tracking holmes internal aboriginal communist seek manifested surface basket nicky cut 'ane [SEP]"]
[Init] best rec loss: 0.765772819519043 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.7329365611076355 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.7320104241371155 for ['[CLS] too type bred cold crowd more elements lips critique leather under battlefield simple lot pony [SEP]']
[Init] best perm rec loss: 0.7284402251243591 for ['[CLS] lips elements crowd lot bred critique under pony more too simple cold type leather battlefield [SEP]']
[Init] best perm rec loss: 0.7251672148704529 for ['[CLS] bred lot battlefield simple more crowd type pony under cold critique lips too leather elements [SEP]']
[Init] best perm rec loss: 0.7230972051620483 for ['[CLS] under crowd pony elements simple type bred lips cold too leather lot critique more battlefield [SEP]']
[Init] best perm rec loss: 0.7226951718330383 for ['[CLS] type leather crowd bred critique under lot cold simple battlefield more lips elements pony too [SEP]']
[Init] best perm rec loss: 0.7212820053100586 for ['[CLS] simple cold crowd under bred more lot critique type battlefield lips leather pony too elements [SEP]']
[Init] best perm rec loss: 0.7199304103851318 for ['[CLS] type cold lot leather simple more critique lips crowd pony bred under elements battlefield too [SEP]']
[Init] best perm rec loss: 0.7196629643440247 for ['[CLS] cold crowd under leather pony simple critique more lips battlefield bred too lot elements type [SEP]']
[Init] best perm rec loss: 0.718829333782196 for ['[CLS] simple critique under lips battlefield type more leather crowd lot too cold elements bred pony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.214 (perp=11.990, rec=0.338, cos=0.478), tot_loss_proj:3.556 [t=0.22s]
prediction: ['[CLS] racing above world abovebility climbing life higher strong of patient nature transfer effort language [SEP]']
[ 100/2000] tot_loss=2.847 (perp=10.798, rec=0.217, cos=0.470), tot_loss_proj:3.410 [t=0.22s]
prediction: ['[CLS] promise above world above score so above above its as everything hope believe material realm [SEP]']
[ 150/2000] tot_loss=2.644 (perp=9.976, rec=0.177, cos=0.472), tot_loss_proj:3.193 [t=0.22s]
prediction: ['[CLS] was above realm above makes so that above its is everything promise believe material realm [SEP]']
[ 200/2000] tot_loss=2.671 (perp=10.308, rec=0.139, cos=0.471), tot_loss_proj:3.083 [t=0.22s]
prediction: ['[CLS] was above the above make so that material itsars life promise make material realm [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.352 (perp=8.812, rec=0.116, cos=0.474), tot_loss_proj:2.863 [t=0.22s]
prediction: ['[CLS] is above the material believe so that above itsars life promise make material realm [SEP]']
[ 300/2000] tot_loss=2.432 (perp=9.336, rec=0.091, cos=0.474), tot_loss_proj:3.038 [t=0.22s]
prediction: ['[CLS] is above the - believe so that above itsars life promise make material realm [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.261 (perp=8.468, rec=0.092, cos=0.475), tot_loss_proj:2.822 [t=0.22s]
prediction: ['[CLS] is above make - believe so that above itsars life promise the material realm [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.070 (perp=7.579, rec=0.081, cos=0.473), tot_loss_proj:2.671 [t=0.22s]
prediction: ['[CLS] is above make believe - so that above itsars life promise the material realm [SEP]']
[ 450/2000] tot_loss=2.048 (perp=7.579, rec=0.058, cos=0.474), tot_loss_proj:2.662 [t=0.22s]
prediction: ['[CLS] is above make believe - so that above itsars life promise the material realm [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.053 (perp=7.579, rec=0.062, cos=0.475), tot_loss_proj:2.668 [t=0.22s]
prediction: ['[CLS] is above make believe - so that above itsars life promise the material realm [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.014 (perp=7.333, rec=0.074, cos=0.473), tot_loss_proj:2.566 [t=0.22s]
prediction: ['[CLS] is above make believe - so that life above itsars promise the material realm [SEP]']
[ 600/2000] tot_loss=2.021 (perp=7.333, rec=0.079, cos=0.475), tot_loss_proj:2.561 [t=0.22s]
prediction: ['[CLS] is above make believe - so that life above itsars promise the material realm [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.973 (perp=7.148, rec=0.069, cos=0.475), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] is promise make believe - so that life above itsars above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.870 (perp=6.684, rec=0.059, cos=0.474), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] is so make believe - promise that life above itsars above the material realm [SEP]']
[ 750/2000] tot_loss=1.870 (perp=6.684, rec=0.059, cos=0.475), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] is so make believe - promise that life above itsars above the material realm [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.878 (perp=6.684, rec=0.067, cos=0.475), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] is so make believe - promise that life above itsars above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.851 (perp=6.540, rec=0.069, cos=0.474), tot_loss_proj:2.406 [t=0.22s]
prediction: ['[CLS] so is make believe - promise that life above itsars above the material realm [SEP]']
[ 900/2000] tot_loss=1.846 (perp=6.540, rec=0.063, cos=0.475), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] so is make believe - promise that life above itsars above the material realm [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.764 (perp=6.127, rec=0.064, cos=0.475), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1000/2000] tot_loss=1.759 (perp=6.127, rec=0.059, cos=0.475), tot_loss_proj:2.290 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
[1050/2000] tot_loss=1.760 (perp=6.127, rec=0.059, cos=0.476), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1100/2000] tot_loss=1.765 (perp=6.127, rec=0.064, cos=0.476), tot_loss_proj:2.286 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1150/2000] tot_loss=1.759 (perp=6.127, rec=0.059, cos=0.476), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
[1200/2000] tot_loss=1.769 (perp=6.127, rec=0.068, cos=0.476), tot_loss_proj:2.281 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1250/2000] tot_loss=1.771 (perp=6.127, rec=0.070, cos=0.476), tot_loss_proj:2.282 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1300/2000] tot_loss=1.763 (perp=6.127, rec=0.061, cos=0.476), tot_loss_proj:2.287 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
[1350/2000] tot_loss=1.765 (perp=6.127, rec=0.063, cos=0.476), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1400/2000] tot_loss=1.768 (perp=6.127, rec=0.066, cos=0.476), tot_loss_proj:2.283 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1450/2000] tot_loss=1.766 (perp=6.127, rec=0.065, cos=0.476), tot_loss_proj:2.290 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
[1500/2000] tot_loss=1.760 (perp=6.127, rec=0.058, cos=0.476), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1550/2000] tot_loss=1.763 (perp=6.127, rec=0.062, cos=0.476), tot_loss_proj:2.288 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1600/2000] tot_loss=1.764 (perp=6.127, rec=0.063, cos=0.476), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
[1650/2000] tot_loss=1.766 (perp=6.127, rec=0.065, cos=0.476), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1700/2000] tot_loss=1.771 (perp=6.127, rec=0.070, cos=0.476), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1750/2000] tot_loss=1.763 (perp=6.127, rec=0.061, cos=0.476), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
[1800/2000] tot_loss=1.775 (perp=6.127, rec=0.074, cos=0.476), tot_loss_proj:2.289 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1850/2000] tot_loss=1.763 (perp=6.127, rec=0.061, cos=0.476), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[1900/2000] tot_loss=1.760 (perp=6.127, rec=0.058, cos=0.476), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
[1950/2000] tot_loss=1.758 (perp=6.127, rec=0.056, cos=0.476), tot_loss_proj:2.290 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=6.127, rec=0.057, cos=0.476), tot_loss_proj:2.279 [t=0.22s]
prediction: ['[CLS] so is make believe - above its promise that lifears above the material realm [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] so is make believe - above its promise that lifears above the material realm [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 35.714 | p: 35.714 | r: 35.714
rougeL     | fm: 73.333 | p: 73.333 | r: 73.333
rougeLsum  | fm: 73.333 | p: 73.333 | r: 73.333
r1fm+r2fm = 115.714

[Aggregate metrics]:
rouge1     | fm: 90.155 | p: 89.665 | r: 90.832
rouge2     | fm: 55.313 | p: 55.154 | r: 55.464
rougeL     | fm: 77.649 | p: 77.217 | r: 78.205
rougeLsum  | fm: 77.628 | p: 77.279 | r: 78.164
r1fm+r2fm = 145.468

input #77 time: 0:08:51 | total time: 11:28:52


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.7104302086454974
highest_index [0]
highest [0.7104302086454974]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9508135914802551 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.921187162399292 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8028234839439392 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.7623531818389893 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.757893979549408 for ['[CLS] le grant screens [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.202 (perp=7.444, rec=0.223, cos=0.490), tot_loss_proj:2.715 [t=0.22s]
prediction: ['[CLS] exit exit exit [SEP]']
[ 100/2000] tot_loss=2.470 (perp=9.346, rec=0.106, cos=0.495), tot_loss_proj:2.890 [t=0.22s]
prediction: ['[CLS] exit exit theater [SEP]']
[ 150/2000] tot_loss=2.159 (perp=7.958, rec=0.075, cos=0.493), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 200/2000] tot_loss=2.158 (perp=7.958, rec=0.072, cos=0.494), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.142 (perp=7.958, rec=0.055, cos=0.495), tot_loss_proj:2.145 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=2.151 (perp=7.958, rec=0.065, cos=0.495), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.163 (perp=7.958, rec=0.076, cos=0.495), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.130 (perp=7.958, rec=0.043, cos=0.495), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=2.139 (perp=7.958, rec=0.053, cos=0.495), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.143 (perp=7.958, rec=0.057, cos=0.495), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.135 (perp=7.958, rec=0.049, cos=0.494), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=2.129 (perp=7.958, rec=0.043, cos=0.495), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.142 (perp=7.958, rec=0.055, cos=0.495), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.147 (perp=7.958, rec=0.061, cos=0.495), tot_loss_proj:2.155 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=2.135 (perp=7.958, rec=0.049, cos=0.494), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.156 (perp=7.958, rec=0.069, cos=0.495), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.150 (perp=7.958, rec=0.063, cos=0.495), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=2.147 (perp=7.958, rec=0.061, cos=0.495), tot_loss_proj:2.158 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.160 (perp=7.958, rec=0.073, cos=0.495), tot_loss_proj:2.158 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=2.147 (perp=7.958, rec=0.060, cos=0.495), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=2.143 (perp=7.958, rec=0.056, cos=0.495), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=2.144 (perp=7.958, rec=0.057, cos=0.495), tot_loss_proj:2.156 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=2.147 (perp=7.958, rec=0.060, cos=0.495), tot_loss_proj:2.156 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=2.144 (perp=7.958, rec=0.058, cos=0.495), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=2.144 (perp=7.958, rec=0.058, cos=0.495), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=2.153 (perp=7.958, rec=0.066, cos=0.495), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=2.142 (perp=7.958, rec=0.055, cos=0.495), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=2.154 (perp=7.958, rec=0.068, cos=0.495), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=2.149 (perp=7.958, rec=0.063, cos=0.495), tot_loss_proj:2.158 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=2.153 (perp=7.958, rec=0.066, cos=0.495), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=2.153 (perp=7.958, rec=0.067, cos=0.495), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=2.154 (perp=7.958, rec=0.067, cos=0.495), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=2.153 (perp=7.958, rec=0.067, cos=0.495), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=2.152 (perp=7.958, rec=0.065, cos=0.495), tot_loss_proj:2.155 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=2.160 (perp=7.958, rec=0.073, cos=0.495), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=2.141 (perp=7.958, rec=0.054, cos=0.495), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=2.157 (perp=7.958, rec=0.071, cos=0.495), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=2.147 (perp=7.958, rec=0.060, cos=0.495), tot_loss_proj:2.148 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=2.146 (perp=7.958, rec=0.059, cos=0.495), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=2.140 (perp=7.958, rec=0.053, cos=0.495), tot_loss_proj:2.156 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.340 | p: 89.821 | r: 90.970
rouge2     | fm: 55.665 | p: 55.560 | r: 55.854
rougeL     | fm: 77.819 | p: 77.470 | r: 78.400
rougeLsum  | fm: 78.003 | p: 77.643 | r: 78.467
r1fm+r2fm = 146.005

input #78 time: 0:08:42 | total time: 11:37:34


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.7280692046192363
highest_index [0]
highest [0.7280692046192363]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9628975987434387 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.9621990919113159 for ['[CLS] chicago militia [SEP]']
[Init] best rec loss: 0.9477575421333313 for ['[CLS] tapping huge [SEP]']
[Init] best rec loss: 0.942431628704071 for ['[CLS] neither tokyo [SEP]']
[Init] best rec loss: 0.8818162083625793 for ['[CLS] clay starts [SEP]']
[Init] best rec loss: 0.853403627872467 for ['[CLS] armada containing [SEP]']
[Init] best rec loss: 0.8190062642097473 for ['[CLS] amount volumes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.940 (perp=11.428, rec=0.192, cos=0.462), tot_loss_proj:3.086 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.900 (perp=11.428, rec=0.147, cos=0.468), tot_loss_proj:3.071 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.895 (perp=11.428, rec=0.142, cos=0.467), tot_loss_proj:3.071 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=2.887 (perp=11.428, rec=0.134, cos=0.468), tot_loss_proj:3.073 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.285 (perp=8.695, rec=0.077, cos=0.469), tot_loss_proj:2.440 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=2.277 (perp=8.695, rec=0.069, cos=0.469), tot_loss_proj:2.440 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.273 (perp=8.695, rec=0.064, cos=0.470), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.279 (perp=8.695, rec=0.071, cos=0.470), tot_loss_proj:2.425 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=2.274 (perp=8.695, rec=0.066, cos=0.470), tot_loss_proj:2.429 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.271 (perp=8.695, rec=0.062, cos=0.470), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.279 (perp=8.695, rec=0.070, cos=0.470), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=2.274 (perp=8.695, rec=0.066, cos=0.470), tot_loss_proj:2.425 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.282 (perp=8.695, rec=0.073, cos=0.470), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.269 (perp=8.695, rec=0.061, cos=0.470), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=2.276 (perp=8.695, rec=0.067, cos=0.470), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.264 (perp=8.695, rec=0.055, cos=0.470), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.264 (perp=8.695, rec=0.055, cos=0.470), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=2.278 (perp=8.695, rec=0.070, cos=0.470), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.266 (perp=8.695, rec=0.057, cos=0.470), tot_loss_proj:2.423 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=2.268 (perp=8.695, rec=0.059, cos=0.470), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=2.272 (perp=8.695, rec=0.063, cos=0.470), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=2.283 (perp=8.695, rec=0.074, cos=0.470), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=2.278 (perp=8.695, rec=0.069, cos=0.470), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=2.270 (perp=8.695, rec=0.061, cos=0.470), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=2.275 (perp=8.695, rec=0.066, cos=0.470), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=2.273 (perp=8.695, rec=0.064, cos=0.470), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=2.265 (perp=8.695, rec=0.056, cos=0.470), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=2.269 (perp=8.695, rec=0.061, cos=0.470), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=2.272 (perp=8.695, rec=0.063, cos=0.470), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=2.271 (perp=8.695, rec=0.062, cos=0.470), tot_loss_proj:2.399 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=2.275 (perp=8.695, rec=0.066, cos=0.470), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=2.265 (perp=8.695, rec=0.056, cos=0.470), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=2.268 (perp=8.695, rec=0.060, cos=0.470), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=2.276 (perp=8.695, rec=0.068, cos=0.470), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=2.276 (perp=8.695, rec=0.068, cos=0.470), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=2.269 (perp=8.695, rec=0.060, cos=0.470), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=2.277 (perp=8.695, rec=0.068, cos=0.470), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=2.267 (perp=8.695, rec=0.059, cos=0.470), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=2.262 (perp=8.695, rec=0.053, cos=0.470), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=2.274 (perp=8.695, rec=0.066, cos=0.470), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 90.444 | p: 89.956 | r: 91.072
rouge2     | fm: 55.074 | p: 54.924 | r: 55.218
rougeL     | fm: 77.772 | p: 77.383 | r: 78.354
rougeLsum  | fm: 77.899 | p: 77.531 | r: 78.415
r1fm+r2fm = 145.518

input #79 time: 0:08:42 | total time: 11:46:17


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.7317394972777167
highest_index [0]
highest [0.7317394972777167]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9805895686149597 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9573093056678772 for ['[CLS] breath difference sensitiveosity higher [SEP]']
[Init] best rec loss: 0.9405853152275085 for ['[CLS] water takinge bonnie ca [SEP]']
[Init] best rec loss: 0.9158187508583069 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.9002362489700317 for ['[CLS] harvest neutron bye ottawa [SEP]']
[Init] best rec loss: 0.8835589289665222 for ['[CLS] heard pavilionplane ian tu [SEP]']
[Init] best perm rec loss: 0.8785696029663086 for ['[CLS] heardplane ian tu pavilion [SEP]']
[Init] best perm rec loss: 0.8775970339775085 for ['[CLS]plane ian pavilion heard tu [SEP]']
[Init] best perm rec loss: 0.8768627047538757 for ['[CLS] heard ianplane pavilion tu [SEP]']
[Init] best perm rec loss: 0.8754355907440186 for ['[CLS] ianplane heard pavilion tu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.877 (perp=10.859, rec=0.244, cos=0.462), tot_loss_proj:3.177 [t=0.22s]
prediction: ['[CLS] neil wise wise [SEP] wise [SEP]']
[ 100/2000] tot_loss=3.515 (perp=14.336, rec=0.184, cos=0.464), tot_loss_proj:4.178 [t=0.22s]
prediction: ['[CLS] dar wise wise wi wi [SEP]']
[ 150/2000] tot_loss=3.337 (perp=13.609, rec=0.152, cos=0.462), tot_loss_proj:4.288 [t=0.22s]
prediction: ['[CLS] dew wisezen wi wi [SEP]']
[ 200/2000] tot_loss=3.394 (perp=13.957, rec=0.139, cos=0.463), tot_loss_proj:3.947 [t=0.22s]
prediction: ['[CLS]ly wisezen wi wi [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.599 (perp=9.778, rec=0.177, cos=0.466), tot_loss_proj:3.331 [t=0.22s]
prediction: ['[CLS] wi wisezen, wi [SEP]']
[ 300/2000] tot_loss=2.689 (perp=10.617, rec=0.102, cos=0.463), tot_loss_proj:3.345 [t=0.22s]
prediction: ['[CLS] wi wisezened wi [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.218 (perp=8.251, rec=0.104, cos=0.464), tot_loss_proj:2.643 [t=0.22s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.926 (perp=6.853, rec=0.092, cos=0.463), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS], wizened wise [SEP]']
[ 450/2000] tot_loss=1.927 (perp=6.853, rec=0.092, cos=0.464), tot_loss_proj:2.077 [t=0.22s]
prediction: ['[CLS], wizened wise [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=2.334 (perp=8.713, rec=0.127, cos=0.464), tot_loss_proj:2.634 [t=0.22s]
prediction: ['[CLS] wizened wise [SEP] [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.181 (perp=8.028, rec=0.112, cos=0.464), tot_loss_proj:2.373 [t=0.22s]
prediction: ['[CLS] wizened [SEP] wise [SEP]']
[ 600/2000] tot_loss=2.170 (perp=8.028, rec=0.102, cos=0.463), tot_loss_proj:2.374 [t=0.22s]
prediction: ['[CLS] wizened [SEP] wise [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.168 (perp=8.028, rec=0.099, cos=0.463), tot_loss_proj:2.368 [t=0.22s]
prediction: ['[CLS] wizened [SEP] wise [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.166 (perp=8.028, rec=0.097, cos=0.463), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] wizened [SEP] wise [SEP]']
[ 750/2000] tot_loss=2.168 (perp=8.028, rec=0.099, cos=0.463), tot_loss_proj:2.372 [t=0.22s]
prediction: ['[CLS] wizened [SEP] wise [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.166 (perp=8.028, rec=0.097, cos=0.463), tot_loss_proj:2.372 [t=0.22s]
prediction: ['[CLS] wizened [SEP] wise [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.960 (perp=7.016, rec=0.093, cos=0.463), tot_loss_proj:2.034 [t=0.22s]
prediction: ['[CLS] wizened, wise [SEP]']
[ 900/2000] tot_loss=1.951 (perp=7.016, rec=0.085, cos=0.463), tot_loss_proj:2.047 [t=0.22s]
prediction: ['[CLS] wizened, wise [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.861 (perp=6.464, rec=0.105, cos=0.464), tot_loss_proj:2.079 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.858 (perp=6.464, rec=0.101, cos=0.464), tot_loss_proj:2.080 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[1050/2000] tot_loss=1.842 (perp=6.464, rec=0.085, cos=0.464), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.848 (perp=6.464, rec=0.092, cos=0.464), tot_loss_proj:2.082 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.852 (perp=6.464, rec=0.096, cos=0.464), tot_loss_proj:2.083 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[1200/2000] tot_loss=1.850 (perp=6.464, rec=0.094, cos=0.464), tot_loss_proj:2.072 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.840 (perp=6.464, rec=0.084, cos=0.464), tot_loss_proj:2.082 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.846 (perp=6.464, rec=0.089, cos=0.464), tot_loss_proj:2.079 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[1350/2000] tot_loss=1.850 (perp=6.464, rec=0.094, cos=0.464), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.847 (perp=6.464, rec=0.091, cos=0.464), tot_loss_proj:2.093 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.852 (perp=6.464, rec=0.095, cos=0.464), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[1500/2000] tot_loss=1.849 (perp=6.464, rec=0.093, cos=0.464), tot_loss_proj:2.081 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.850 (perp=6.464, rec=0.094, cos=0.464), tot_loss_proj:2.092 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.855 (perp=6.464, rec=0.099, cos=0.464), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[1650/2000] tot_loss=1.852 (perp=6.464, rec=0.095, cos=0.464), tot_loss_proj:2.081 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.850 (perp=6.464, rec=0.094, cos=0.464), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.857 (perp=6.464, rec=0.100, cos=0.464), tot_loss_proj:2.081 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[1800/2000] tot_loss=1.844 (perp=6.464, rec=0.088, cos=0.463), tot_loss_proj:2.080 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.844 (perp=6.464, rec=0.088, cos=0.463), tot_loss_proj:2.073 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.860 (perp=6.464, rec=0.104, cos=0.463), tot_loss_proj:2.076 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[1950/2000] tot_loss=1.838 (perp=6.464, rec=0.082, cos=0.463), tot_loss_proj:2.079 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.846 (perp=6.464, rec=0.090, cos=0.463), tot_loss_proj:2.087 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wizened wise, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 90.564 | p: 90.128 | r: 91.164
rouge2     | fm: 54.220 | p: 54.122 | r: 54.401
rougeL     | fm: 77.739 | p: 77.352 | r: 78.262
rougeLsum  | fm: 77.844 | p: 77.431 | r: 78.361
r1fm+r2fm = 144.783

input #80 time: 0:08:43 | total time: 11:55:01


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.7350778555828312
highest_index [0]
highest [0.7350778555828312]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9537965655326843 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.9280928373336792 for ['[CLS] hobbs : kahn closer invest rico [SEP]']
[Init] best rec loss: 0.8820206522941589 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8481665849685669 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8416058421134949 for ['[CLS]eering dominance sectional cummings lil yankee [SEP]']
[Init] best rec loss: 0.8070867657661438 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.7966216206550598 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 0.7756021618843079 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best perm rec loss: 0.7752072811126709 for ['[CLS] missing threads bandsitating modelled approval [SEP]']
[Init] best perm rec loss: 0.7740227580070496 for ['[CLS] missing approval threadsitating bands modelled [SEP]']
[Init] best perm rec loss: 0.7728974223136902 for ['[CLS] approvalitating modelled bands threads missing [SEP]']
[Init] best perm rec loss: 0.7720914483070374 for ['[CLS]itating missing modelled bands approval threads [SEP]']
[Init] best perm rec loss: 0.7719430327415466 for ['[CLS]itating missing approval bands modelled threads [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.760 (perp=10.140, rec=0.277, cos=0.455), tot_loss_proj:3.370 [t=0.22s]
prediction: ['[CLS] japan not the generation outstanding dominates [SEP]']
[ 100/2000] tot_loss=1.732 (perp=5.977, rec=0.083, cos=0.454), tot_loss_proj:1.768 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 150/2000] tot_loss=1.722 (perp=5.977, rec=0.069, cos=0.457), tot_loss_proj:1.777 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 200/2000] tot_loss=1.724 (perp=5.977, rec=0.070, cos=0.458), tot_loss_proj:1.764 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.713 (perp=5.977, rec=0.058, cos=0.459), tot_loss_proj:1.770 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 300/2000] tot_loss=1.714 (perp=5.977, rec=0.059, cos=0.459), tot_loss_proj:1.780 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.715 (perp=5.977, rec=0.060, cos=0.460), tot_loss_proj:1.780 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.710 (perp=5.977, rec=0.058, cos=0.456), tot_loss_proj:1.769 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 450/2000] tot_loss=1.719 (perp=5.977, rec=0.064, cos=0.459), tot_loss_proj:1.784 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.709 (perp=5.977, rec=0.054, cos=0.459), tot_loss_proj:1.786 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.708 (perp=5.977, rec=0.054, cos=0.459), tot_loss_proj:1.770 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 600/2000] tot_loss=1.707 (perp=5.977, rec=0.055, cos=0.457), tot_loss_proj:1.765 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.719 (perp=5.977, rec=0.065, cos=0.459), tot_loss_proj:1.777 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.724 (perp=5.977, rec=0.069, cos=0.459), tot_loss_proj:1.774 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 750/2000] tot_loss=1.702 (perp=5.977, rec=0.049, cos=0.457), tot_loss_proj:1.768 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.710 (perp=5.977, rec=0.055, cos=0.459), tot_loss_proj:1.769 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.728 (perp=5.977, rec=0.073, cos=0.459), tot_loss_proj:1.762 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 900/2000] tot_loss=1.716 (perp=5.977, rec=0.063, cos=0.458), tot_loss_proj:1.769 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.712 (perp=5.977, rec=0.058, cos=0.459), tot_loss_proj:1.778 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.713 (perp=5.977, rec=0.058, cos=0.459), tot_loss_proj:1.778 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1050/2000] tot_loss=1.718 (perp=5.977, rec=0.066, cos=0.457), tot_loss_proj:1.768 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.710 (perp=5.977, rec=0.056, cos=0.459), tot_loss_proj:1.770 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.715 (perp=5.977, rec=0.060, cos=0.459), tot_loss_proj:1.775 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1200/2000] tot_loss=1.714 (perp=5.977, rec=0.060, cos=0.459), tot_loss_proj:1.772 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.721 (perp=5.977, rec=0.067, cos=0.459), tot_loss_proj:1.778 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.716 (perp=5.977, rec=0.062, cos=0.459), tot_loss_proj:1.764 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1350/2000] tot_loss=1.711 (perp=5.977, rec=0.057, cos=0.459), tot_loss_proj:1.775 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.716 (perp=5.977, rec=0.061, cos=0.459), tot_loss_proj:1.777 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.710 (perp=5.977, rec=0.055, cos=0.459), tot_loss_proj:1.770 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1500/2000] tot_loss=1.713 (perp=5.977, rec=0.058, cos=0.459), tot_loss_proj:1.778 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.703 (perp=5.977, rec=0.048, cos=0.459), tot_loss_proj:1.777 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.713 (perp=5.977, rec=0.059, cos=0.458), tot_loss_proj:1.765 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1650/2000] tot_loss=1.722 (perp=5.977, rec=0.068, cos=0.459), tot_loss_proj:1.774 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.721 (perp=5.977, rec=0.066, cos=0.459), tot_loss_proj:1.764 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.726 (perp=5.977, rec=0.071, cos=0.459), tot_loss_proj:1.774 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1800/2000] tot_loss=1.720 (perp=5.977, rec=0.065, cos=0.459), tot_loss_proj:1.761 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.715 (perp=5.977, rec=0.060, cos=0.459), tot_loss_proj:1.784 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.728 (perp=5.977, rec=0.073, cos=0.460), tot_loss_proj:1.765 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1950/2000] tot_loss=1.720 (perp=5.977, rec=0.065, cos=0.460), tot_loss_proj:1.764 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.713 (perp=5.977, rec=0.058, cos=0.460), tot_loss_proj:1.779 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not the most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.600 | p: 90.130 | r: 91.220
rouge2     | fm: 54.727 | p: 54.601 | r: 54.941
rougeL     | fm: 78.060 | p: 77.610 | r: 78.551
rougeLsum  | fm: 78.114 | p: 77.781 | r: 78.591
r1fm+r2fm = 145.327

input #81 time: 0:08:44 | total time: 12:03:45


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.7086767461266876
highest_index [0]
highest [0.7086767461266876]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9498471617698669 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.948704183101654 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9445403814315796 for ['[CLS] seminetive facing toward victor trance grown [SEP]']
[Init] best rec loss: 0.9405194520950317 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9258800148963928 for ['[CLS] firmly wilder after weighted ninection latter i [SEP]']
[Init] best rec loss: 0.9065353274345398 for ['[CLS] seaside ray moved throat traitor mistake ports homage [SEP]']
[Init] best rec loss: 0.8921787142753601 for ['[CLS] letter babyturnesian eric a distribution soft [SEP]']
[Init] best perm rec loss: 0.889685332775116 for ['[CLS] ericturn baby distribution letteresian a soft [SEP]']
[Init] best perm rec loss: 0.8890223503112793 for ['[CLS] a soft distributionesian letterturn eric baby [SEP]']
[Init] best perm rec loss: 0.8877203464508057 for ['[CLS]turn baby a letteresian soft eric distribution [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.644 (perp=9.784, rec=0.194, cos=0.493), tot_loss_proj:3.184 [t=0.23s]
prediction: ['[CLS] is sloppy script undone script by script ink [SEP]']
[ 100/2000] tot_loss=2.578 (perp=9.924, rec=0.095, cos=0.497), tot_loss_proj:3.131 [t=0.23s]
prediction: ['[CLS] s sloppy script undone script by sloppy reed [SEP]']
[ 150/2000] tot_loss=2.635 (perp=10.301, rec=0.079, cos=0.496), tot_loss_proj:3.082 [t=0.23s]
prediction: ["[CLS] s sloppy a undone script by sloppy'[SEP]"]
[ 200/2000] tot_loss=2.627 (perp=10.301, rec=0.071, cos=0.497), tot_loss_proj:3.084 [t=0.23s]
prediction: ["[CLS] s sloppy a undone script by sloppy'[SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.395 (perp=9.104, rec=0.079, cos=0.496), tot_loss_proj:2.842 [t=0.23s]
prediction: ["[CLS] s sloppy a script undone by sloppy'[SEP]"]
[ 300/2000] tot_loss=2.388 (perp=9.104, rec=0.071, cos=0.496), tot_loss_proj:2.848 [t=0.23s]
prediction: ["[CLS] s sloppy a script undone by sloppy'[SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.249 (perp=8.376, rec=0.079, cos=0.495), tot_loss_proj:2.600 [t=0.23s]
prediction: ["[CLS] s a sloppy script undone by sloppy'[SEP]"]
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=2.030 (perp=7.101, rec=0.114, cos=0.495), tot_loss_proj:2.371 [t=0.23s]
prediction: ["[CLS] a sloppy script undone by sloppy's [SEP]"]
[ 450/2000] tot_loss=2.367 (perp=8.981, rec=0.074, cos=0.497), tot_loss_proj:2.709 [t=0.23s]
prediction: ['[CLS] a sloppy script undone by sloppy neill s [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.469 (perp=9.461, rec=0.081, cos=0.497), tot_loss_proj:2.774 [t=0.23s]
prediction: ['[CLS] a sloppy script undone by sloppy s it [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=2.281 (perp=8.532, rec=0.077, cos=0.497), tot_loss_proj:2.593 [t=0.23s]
prediction: ['[CLS] it a sloppy script undone by sloppy s [SEP]']
[ 600/2000] tot_loss=2.276 (perp=8.532, rec=0.072, cos=0.497), tot_loss_proj:2.595 [t=0.23s]
prediction: ['[CLS] it a sloppy script undone by sloppy s [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.162 (perp=7.986, rec=0.068, cos=0.497), tot_loss_proj:2.453 [t=0.23s]
prediction: ['[CLS] it s a sloppy script undone by sloppy [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.115 (perp=7.778, rec=0.062, cos=0.497), tot_loss_proj:2.464 [t=0.29s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 750/2000] tot_loss=2.117 (perp=7.778, rec=0.064, cos=0.498), tot_loss_proj:2.467 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.121 (perp=7.778, rec=0.068, cos=0.498), tot_loss_proj:2.471 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.123 (perp=7.778, rec=0.071, cos=0.497), tot_loss_proj:2.464 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 900/2000] tot_loss=2.117 (perp=7.778, rec=0.064, cos=0.497), tot_loss_proj:2.468 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.120 (perp=7.778, rec=0.067, cos=0.498), tot_loss_proj:2.466 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.122 (perp=7.778, rec=0.069, cos=0.497), tot_loss_proj:2.467 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1050/2000] tot_loss=2.121 (perp=7.778, rec=0.068, cos=0.498), tot_loss_proj:2.471 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.117 (perp=7.778, rec=0.064, cos=0.497), tot_loss_proj:2.470 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1150/2000] tot_loss=2.115 (perp=7.778, rec=0.062, cos=0.497), tot_loss_proj:2.474 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1200/2000] tot_loss=2.115 (perp=7.778, rec=0.062, cos=0.497), tot_loss_proj:2.469 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1250/2000] tot_loss=2.111 (perp=7.778, rec=0.058, cos=0.498), tot_loss_proj:2.466 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1300/2000] tot_loss=2.119 (perp=7.778, rec=0.066, cos=0.497), tot_loss_proj:2.465 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1350/2000] tot_loss=2.117 (perp=7.778, rec=0.063, cos=0.498), tot_loss_proj:2.468 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1400/2000] tot_loss=2.121 (perp=7.778, rec=0.068, cos=0.497), tot_loss_proj:2.469 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1450/2000] tot_loss=2.127 (perp=7.778, rec=0.074, cos=0.497), tot_loss_proj:2.471 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1500/2000] tot_loss=2.110 (perp=7.778, rec=0.057, cos=0.498), tot_loss_proj:2.468 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1550/2000] tot_loss=2.116 (perp=7.778, rec=0.063, cos=0.497), tot_loss_proj:2.471 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.116 (perp=7.778, rec=0.064, cos=0.497), tot_loss_proj:2.471 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1650/2000] tot_loss=2.116 (perp=7.778, rec=0.063, cos=0.498), tot_loss_proj:2.471 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1700/2000] tot_loss=2.122 (perp=7.778, rec=0.069, cos=0.498), tot_loss_proj:2.473 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=2.112 (perp=7.778, rec=0.060, cos=0.497), tot_loss_proj:2.469 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1800/2000] tot_loss=2.117 (perp=7.778, rec=0.064, cos=0.498), tot_loss_proj:2.469 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.114 (perp=7.778, rec=0.061, cos=0.497), tot_loss_proj:2.469 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1900/2000] tot_loss=2.123 (perp=7.778, rec=0.070, cos=0.498), tot_loss_proj:2.462 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1950/2000] tot_loss=2.126 (perp=7.778, rec=0.072, cos=0.497), tot_loss_proj:2.469 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.107 (perp=7.778, rec=0.054, cos=0.498), tot_loss_proj:2.467 [t=0.23s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s a sloppy sloppy script undone by [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 73.684 | p: 70.000 | r: 77.778
rougeLsum  | fm: 73.684 | p: 70.000 | r: 77.778
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 90.731 | p: 90.163 | r: 91.383
rouge2     | fm: 54.843 | p: 54.704 | r: 55.079
rougeL     | fm: 77.947 | p: 77.487 | r: 78.535
rougeLsum  | fm: 78.031 | p: 77.574 | r: 78.617
r1fm+r2fm = 145.575

input #82 time: 0:09:04 | total time: 12:12:50


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.7227402761357522
highest_index [0]
highest [0.7227402761357522]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.8475238680839539 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.8336407542228699 for ['[CLS] floodax aboriginal mali wisconsin na rain basket missed call [SEP]']
[Init] best rec loss: 0.8267556428909302 for ['[CLS] firm from eager ever heavier positions mc depending much those [SEP]']
[Init] best rec loss: 0.7930241823196411 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.791419267654419 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.7782713174819946 for ['[CLS] nearly pitch residence vice stew follows comprehensive neck boys envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.036 (perp=11.426, rec=0.286, cos=0.464), tot_loss_proj:3.851 [t=0.22s]
prediction: ['[CLS] grow what know want cage where on know when grow [SEP]']
[ 100/2000] tot_loss=2.659 (perp=10.073, rec=0.167, cos=0.478), tot_loss_proj:3.575 [t=0.22s]
prediction: ['[CLS] know what know wants january grow it is when grows [SEP]']
[ 150/2000] tot_loss=2.225 (perp=8.280, rec=0.095, cos=0.474), tot_loss_proj:2.736 [t=0.22s]
prediction: ['[CLS] know what it wantsan be it be when grows [SEP]']
[ 200/2000] tot_loss=2.217 (perp=8.280, rec=0.088, cos=0.473), tot_loss_proj:2.725 [t=0.22s]
prediction: ['[CLS] know what it wantsan be it be when grows [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.773 (perp=6.108, rec=0.079, cos=0.472), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] know what it wants to be when be it grows [SEP]']
[ 300/2000] tot_loss=1.768 (perp=6.108, rec=0.072, cos=0.474), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] know what it wants to be when be it grows [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.646 (perp=5.492, rec=0.074, cos=0.474), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] know what it wants to be be when it grows [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.589 (perp=5.152, rec=0.085, cos=0.473), tot_loss_proj:1.886 [t=0.22s]
prediction: ['[CLS] be know what it wants to be when it grows [SEP]']
[ 450/2000] tot_loss=1.580 (perp=5.152, rec=0.076, cos=0.474), tot_loss_proj:1.889 [t=0.22s]
prediction: ['[CLS] be know what it wants to be when it grows [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.576 (perp=5.152, rec=0.071, cos=0.474), tot_loss_proj:1.884 [t=0.22s]
prediction: ['[CLS] be know what it wants to be when it grows [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.576 (perp=5.152, rec=0.072, cos=0.474), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] be know what it wants to be when it grows [SEP]']
[ 600/2000] tot_loss=1.572 (perp=5.152, rec=0.068, cos=0.474), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] be know what it wants to be when it grows [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.578 (perp=5.152, rec=0.073, cos=0.474), tot_loss_proj:1.878 [t=0.22s]
prediction: ['[CLS] be know what it wants to be when it grows [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.568 (perp=5.152, rec=0.063, cos=0.475), tot_loss_proj:1.875 [t=0.22s]
prediction: ['[CLS] be know what it wants to be when it grows [SEP]']
[ 750/2000] tot_loss=1.578 (perp=5.152, rec=0.073, cos=0.475), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] be know what it wants to be when it grows [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.609 (perp=5.368, rec=0.061, cos=0.475), tot_loss_proj:1.931 [t=0.22s]
prediction: ['[CLS] up know what it wants to be when it grows [SEP]']
Attempt swap
Put prefix at the end
[ 850/2000] tot_loss=1.485 (perp=4.691, rec=0.070, cos=0.477), tot_loss_proj:1.550 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[ 900/2000] tot_loss=1.483 (perp=4.691, rec=0.070, cos=0.475), tot_loss_proj:1.543 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.479 (perp=4.691, rec=0.065, cos=0.475), tot_loss_proj:1.544 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.464 (perp=4.691, rec=0.050, cos=0.476), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1050/2000] tot_loss=1.477 (perp=4.691, rec=0.062, cos=0.477), tot_loss_proj:1.546 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.470 (perp=4.691, rec=0.055, cos=0.477), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.475 (perp=4.691, rec=0.059, cos=0.477), tot_loss_proj:1.528 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1200/2000] tot_loss=1.471 (perp=4.691, rec=0.055, cos=0.477), tot_loss_proj:1.545 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.475 (perp=4.691, rec=0.060, cos=0.477), tot_loss_proj:1.543 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.481 (perp=4.691, rec=0.065, cos=0.478), tot_loss_proj:1.547 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1350/2000] tot_loss=1.486 (perp=4.691, rec=0.070, cos=0.477), tot_loss_proj:1.546 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.472 (perp=4.691, rec=0.057, cos=0.477), tot_loss_proj:1.552 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.473 (perp=4.691, rec=0.057, cos=0.477), tot_loss_proj:1.531 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1500/2000] tot_loss=1.481 (perp=4.691, rec=0.065, cos=0.478), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.482 (perp=4.691, rec=0.066, cos=0.477), tot_loss_proj:1.547 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.483 (perp=4.691, rec=0.068, cos=0.478), tot_loss_proj:1.546 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1650/2000] tot_loss=1.477 (perp=4.691, rec=0.062, cos=0.477), tot_loss_proj:1.541 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.473 (perp=4.691, rec=0.057, cos=0.478), tot_loss_proj:1.541 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.478 (perp=4.691, rec=0.062, cos=0.478), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1800/2000] tot_loss=1.484 (perp=4.691, rec=0.068, cos=0.477), tot_loss_proj:1.543 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.481 (perp=4.691, rec=0.065, cos=0.477), tot_loss_proj:1.539 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.481 (perp=4.691, rec=0.066, cos=0.478), tot_loss_proj:1.539 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1950/2000] tot_loss=1.477 (perp=4.691, rec=0.061, cos=0.478), tot_loss_proj:1.545 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.476 (perp=4.691, rec=0.060, cos=0.478), tot_loss_proj:1.536 [t=0.22s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.838 | p: 90.359 | r: 91.509
rouge2     | fm: 55.387 | p: 55.205 | r: 55.591
rougeL     | fm: 78.332 | p: 77.897 | r: 78.839
rougeLsum  | fm: 78.297 | p: 77.895 | r: 78.849
r1fm+r2fm = 146.225

input #83 time: 0:08:43 | total time: 12:21:33


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.7274200796033137
highest_index [0]
highest [0.7274200796033137]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.8977373838424683 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.8734575510025024 for ['[CLS] primera criminalmost dynamic ride venue youtube [SEP]']
[Init] best rec loss: 0.8592555522918701 for ['[CLS] beauty seemed features dr son baked hm [SEP]']
[Init] best rec loss: 0.8570786714553833 for ['[CLS] waterfalls answer ramsay proved broad losing amenities [SEP]']
[Init] best rec loss: 0.8445222973823547 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8312015533447266 for ['[CLS] appearance later orderedlby outstanding battery gentle [SEP]']
[Init] best rec loss: 0.8292049765586853 for ['[CLS] competed shegl brick kill trade down [SEP]']
[Init] best rec loss: 0.8191673159599304 for ['[CLS] individual hung cold ¹...ught railroad [SEP]']
[Init] best rec loss: 0.8133563995361328 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best rec loss: 0.8132647275924683 for ['[CLS] tradition captaindock seats [SEP] easier seas [SEP]']
[Init] best rec loss: 0.7973044514656067 for ['[CLS] hometails para hundreds sexy couple chinese [SEP]']
[Init] best perm rec loss: 0.7953760623931885 for ['[CLS] para couple hundreds chinese sexytails home [SEP]']
[Init] best perm rec loss: 0.7944072484970093 for ['[CLS] para sexy chinesetails home couple hundreds [SEP]']
[Init] best perm rec loss: 0.7929415702819824 for ['[CLS] para hundreds hometails couple chinese sexy [SEP]']
[Init] best perm rec loss: 0.7929089069366455 for ['[CLS] hundreds couple para chinesetails sexy home [SEP]']
[Init] best perm rec loss: 0.7914473414421082 for ['[CLS] coupletails hundreds chinese sexy para home [SEP]']
[Init] best perm rec loss: 0.7912492156028748 for ['[CLS] sexy para hundreds hometails chinese couple [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.508 (perp=8.948, rec=0.261, cos=0.457), tot_loss_proj:2.664 [t=0.22s]
prediction: ['[CLS] people lost lost having lost people ability [SEP]']
[ 100/2000] tot_loss=2.678 (perp=10.513, rec=0.106, cos=0.469), tot_loss_proj:3.090 [t=0.22s]
prediction: ['[CLS] people lost lost have ability the think [SEP]']
[ 150/2000] tot_loss=2.654 (perp=10.513, rec=0.081, cos=0.471), tot_loss_proj:3.121 [t=0.22s]
prediction: ['[CLS] people lost lost have ability the think [SEP]']
[ 200/2000] tot_loss=2.643 (perp=10.513, rec=0.070, cos=0.471), tot_loss_proj:3.115 [t=0.22s]
prediction: ['[CLS] people lost lost have ability the think [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.300 (perp=8.739, rec=0.083, cos=0.469), tot_loss_proj:3.210 [t=0.22s]
prediction: ['[CLS] people lost lost have the ability think [SEP]']
[ 300/2000] tot_loss=2.297 (perp=8.739, rec=0.078, cos=0.471), tot_loss_proj:3.258 [t=0.22s]
prediction: ['[CLS] people lost lost have the ability think [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.053 (perp=7.576, rec=0.068, cos=0.470), tot_loss_proj:2.212 [t=0.22s]
prediction: ['[CLS] people have lost lost the ability think [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.022 (perp=7.431, rec=0.065, cos=0.470), tot_loss_proj:2.250 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[ 450/2000] tot_loss=2.036 (perp=7.431, rec=0.080, cos=0.470), tot_loss_proj:2.245 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.035 (perp=7.431, rec=0.079, cos=0.470), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.032 (perp=7.431, rec=0.076, cos=0.470), tot_loss_proj:2.245 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[ 600/2000] tot_loss=2.031 (perp=7.431, rec=0.074, cos=0.470), tot_loss_proj:2.241 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.025 (perp=7.431, rec=0.069, cos=0.470), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.030 (perp=7.431, rec=0.074, cos=0.470), tot_loss_proj:2.244 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[ 750/2000] tot_loss=2.029 (perp=7.431, rec=0.073, cos=0.470), tot_loss_proj:2.225 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.031 (perp=7.431, rec=0.075, cos=0.470), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.032 (perp=7.431, rec=0.075, cos=0.470), tot_loss_proj:2.225 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[ 900/2000] tot_loss=2.031 (perp=7.431, rec=0.074, cos=0.471), tot_loss_proj:2.225 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.015 (perp=7.431, rec=0.058, cos=0.471), tot_loss_proj:2.219 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1000/2000] tot_loss=2.021 (perp=7.431, rec=0.064, cos=0.470), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1050/2000] tot_loss=2.031 (perp=7.431, rec=0.073, cos=0.471), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1100/2000] tot_loss=2.023 (perp=7.431, rec=0.065, cos=0.471), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1150/2000] tot_loss=2.028 (perp=7.431, rec=0.071, cos=0.470), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1200/2000] tot_loss=2.037 (perp=7.431, rec=0.080, cos=0.470), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1250/2000] tot_loss=2.025 (perp=7.431, rec=0.068, cos=0.471), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1300/2000] tot_loss=2.020 (perp=7.431, rec=0.063, cos=0.471), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1350/2000] tot_loss=2.029 (perp=7.431, rec=0.072, cos=0.470), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1400/2000] tot_loss=2.024 (perp=7.431, rec=0.067, cos=0.471), tot_loss_proj:2.226 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1450/2000] tot_loss=2.027 (perp=7.431, rec=0.070, cos=0.471), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1500/2000] tot_loss=2.026 (perp=7.431, rec=0.069, cos=0.470), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1550/2000] tot_loss=2.017 (perp=7.431, rec=0.060, cos=0.470), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1600/2000] tot_loss=2.027 (perp=7.431, rec=0.071, cos=0.470), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1650/2000] tot_loss=2.017 (perp=7.431, rec=0.061, cos=0.470), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1700/2000] tot_loss=2.224 (perp=8.406, rec=0.073, cos=0.470), tot_loss_proj:2.883 [t=0.22s]
prediction: ['[CLS] people have to the lost ability think [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.018 (perp=7.423, rec=0.064, cos=0.469), tot_loss_proj:2.275 [t=0.22s]
prediction: ['[CLS] people have to lost the ability think [SEP]']
[1800/2000] tot_loss=2.025 (perp=7.423, rec=0.070, cos=0.470), tot_loss_proj:2.263 [t=0.22s]
prediction: ['[CLS] people have to lost the ability think [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.469 (perp=4.681, rec=0.065, cos=0.469), tot_loss_proj:1.528 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.464 (perp=4.681, rec=0.059, cos=0.469), tot_loss_proj:1.525 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=1.466 (perp=4.681, rec=0.060, cos=0.469), tot_loss_proj:1.532 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.464 (perp=4.681, rec=0.059, cos=0.470), tot_loss_proj:1.538 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.950 | p: 90.436 | r: 91.589
rouge2     | fm: 55.851 | p: 55.653 | r: 56.140
rougeL     | fm: 78.509 | p: 78.127 | r: 79.040
rougeLsum  | fm: 78.585 | p: 78.198 | r: 79.128
r1fm+r2fm = 146.801

input #84 time: 0:08:43 | total time: 12:30:17


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.7142452609320251
highest_index [0]
highest [0.7142452609320251]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.8810832500457764 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.8770110607147217 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.8539717793464661 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.850504994392395 for ['[CLS] thinks macau stand cam form halolic venture cannot vehicle [SEP]']
[Init] best rec loss: 0.8497928977012634 for ['[CLS] young graf challenging haven nord overly graduation blank dad josephine [SEP]']
[Init] best rec loss: 0.8466203212738037 for ['[CLS] inside feminist brought vision swing artificial agent fai manipulatedsome [SEP]']
[Init] best rec loss: 0.8394337296485901 for ['[CLS] go historyacious such what crazymas albeit includetime [SEP]']
[Init] best rec loss: 0.8394050598144531 for ['[CLS] reflection whateverus translation rent certain belt loft rca muted [SEP]']
[Init] best perm rec loss: 0.8392693400382996 for ['[CLS] rent loft rca reflection whatever certain translationus muted belt [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.736 (perp=9.894, rec=0.285, cos=0.473), tot_loss_proj:3.596 [t=0.23s]
prediction: ['[CLS] unfortunately hall also not also not not. hurt good [SEP]']
[ 100/2000] tot_loss=2.073 (perp=7.252, rec=0.139, cos=0.483), tot_loss_proj:2.887 [t=0.23s]
prediction: ['[CLS] unfortunately we also not also not not, very good [SEP]']
[ 150/2000] tot_loss=2.076 (perp=7.444, rec=0.101, cos=0.486), tot_loss_proj:3.204 [t=0.23s]
prediction: ['[CLS] unfortunately it also not also very not. very good [SEP]']
[ 200/2000] tot_loss=2.409 (perp=6.925, rec=0.540, cos=0.485), tot_loss_proj:2.760 [t=0.23s]
prediction: ['[CLS] unfortunately it s s also very not. very good [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.412 (perp=7.870, rec=0.359, cos=0.478), tot_loss_proj:2.540 [t=0.23s]
prediction: ['[CLS] unfortunately. the also during also very not very good [SEP]']
[ 300/2000] tot_loss=2.265 (perp=7.591, rec=0.272, cos=0.475), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] unfortunately. it also during also very not very good [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.028 (perp=6.575, rec=0.230, cos=0.483), tot_loss_proj:2.200 [t=0.23s]
prediction: ['[CLS] unfortunately. also since it also very not very good [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.886 (perp=5.978, rec=0.207, cos=0.483), tot_loss_proj:2.030 [t=0.23s]
prediction: ['[CLS] unfortunately also since it also very not very good. [SEP]']
[ 450/2000] tot_loss=1.849 (perp=5.925, rec=0.176, cos=0.488), tot_loss_proj:2.062 [t=0.23s]
prediction: ['[CLS] unfortunately also during it also very not very good. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.813 (perp=5.878, rec=0.152, cos=0.486), tot_loss_proj:2.077 [t=0.23s]
prediction: ['[CLS] unfortunately also during it also not very very good. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.808 (perp=5.878, rec=0.148, cos=0.485), tot_loss_proj:2.075 [t=0.23s]
prediction: ['[CLS] unfortunately also during it also not very very good. [SEP]']
[ 600/2000] tot_loss=1.814 (perp=5.878, rec=0.153, cos=0.485), tot_loss_proj:2.064 [t=0.23s]
prediction: ['[CLS] unfortunately also during it also not very very good. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.839 (perp=6.050, rec=0.144, cos=0.485), tot_loss_proj:2.125 [t=0.23s]
prediction: ['[CLS] unfortunately very during it also not very very good. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.828 (perp=6.050, rec=0.132, cos=0.486), tot_loss_proj:2.121 [t=0.23s]
prediction: ['[CLS] unfortunately very during it also not very very good. [SEP]']
[ 750/2000] tot_loss=1.830 (perp=6.050, rec=0.134, cos=0.486), tot_loss_proj:2.113 [t=0.23s]
prediction: ['[CLS] unfortunately very during it also not very very good. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.810 (perp=6.050, rec=0.113, cos=0.486), tot_loss_proj:2.123 [t=0.23s]
prediction: ['[CLS] unfortunately very during it also not very very good. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.823 (perp=6.050, rec=0.126, cos=0.487), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] unfortunately very during it also not very very good. [SEP]']
[ 900/2000] tot_loss=1.814 (perp=6.050, rec=0.117, cos=0.487), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS] unfortunately very during it also not very very good. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.803 (perp=6.050, rec=0.106, cos=0.487), tot_loss_proj:2.113 [t=0.23s]
prediction: ['[CLS] unfortunately very during it also not very very good. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.812 (perp=6.050, rec=0.114, cos=0.487), tot_loss_proj:2.119 [t=0.23s]
prediction: ['[CLS] unfortunately very during it also not very very good. [SEP]']
[1050/2000] tot_loss=1.805 (perp=6.050, rec=0.108, cos=0.488), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] unfortunately very during it also not very very good. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.972 (perp=6.899, rec=0.105, cos=0.488), tot_loss_proj:2.245 [t=0.23s]
prediction: ['[CLS] unfortunately very the it also not very very good. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.772 (perp=5.883, rec=0.111, cos=0.485), tot_loss_proj:2.004 [t=0.23s]
prediction: ['[CLS] unfortunately it the very also not very very good. [SEP]']
[1200/2000] tot_loss=1.771 (perp=5.883, rec=0.108, cos=0.487), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS] unfortunately it the very also not very very good. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.734 (perp=5.713, rec=0.108, cos=0.484), tot_loss_proj:2.071 [t=0.23s]
prediction: ['[CLS] unfortunately it very very also not not very good. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.625 (perp=5.200, rec=0.100, cos=0.485), tot_loss_proj:1.913 [t=0.23s]
prediction: ['[CLS] unfortunately it not very also not very very good. [SEP]']
[1350/2000] tot_loss=1.629 (perp=5.200, rec=0.104, cos=0.485), tot_loss_proj:1.915 [t=0.23s]
prediction: ['[CLS] unfortunately it not very also not very very good. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.618 (perp=5.200, rec=0.092, cos=0.486), tot_loss_proj:1.925 [t=0.23s]
prediction: ['[CLS] unfortunately it not very also not very very good. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.622 (perp=5.200, rec=0.096, cos=0.486), tot_loss_proj:1.923 [t=0.23s]
prediction: ['[CLS] unfortunately it not very also not very very good. [SEP]']
[1500/2000] tot_loss=1.631 (perp=5.200, rec=0.105, cos=0.487), tot_loss_proj:1.921 [t=0.23s]
prediction: ['[CLS] unfortunately it not very also not very very good. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.622 (perp=5.200, rec=0.095, cos=0.487), tot_loss_proj:1.915 [t=0.23s]
prediction: ['[CLS] unfortunately it not very also not very very good. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.734 (perp=5.713, rec=0.103, cos=0.488), tot_loss_proj:2.069 [t=0.23s]
prediction: ['[CLS] unfortunately it very very also not not very good. [SEP]']
[1650/2000] tot_loss=1.726 (perp=5.713, rec=0.097, cos=0.486), tot_loss_proj:2.068 [t=0.23s]
prediction: ['[CLS] unfortunately it very very also not not very good. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.686 (perp=5.500, rec=0.100, cos=0.486), tot_loss_proj:1.838 [t=0.23s]
prediction: ['[CLS] unfortunately it not s also not very very good. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.637 (perp=5.225, rec=0.107, cos=0.485), tot_loss_proj:1.887 [t=0.23s]
prediction: ['[CLS] unfortunately it also s not not very very good. [SEP]']
[1800/2000] tot_loss=1.627 (perp=5.225, rec=0.097, cos=0.485), tot_loss_proj:1.878 [t=0.23s]
prediction: ['[CLS] unfortunately it also s not not very very good. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.625 (perp=5.225, rec=0.097, cos=0.483), tot_loss_proj:1.888 [t=0.23s]
prediction: ['[CLS] unfortunately it also s not not very very good. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.610 (perp=5.119, rec=0.103, cos=0.484), tot_loss_proj:1.908 [t=0.23s]
prediction: ['[CLS] unfortunately it also s not very not very good. [SEP]']
[1950/2000] tot_loss=1.610 (perp=5.119, rec=0.102, cos=0.483), tot_loss_proj:1.911 [t=0.23s]
prediction: ['[CLS] unfortunately it also s not very not very good. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.620 (perp=5.146, rec=0.106, cos=0.484), tot_loss_proj:1.827 [t=0.23s]
prediction: ['[CLS] unfortunately it very s not also not very good. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately it s s also very not. very good [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 81.818 | r: 100.000
rouge2     | fm: 77.778 | p: 70.000 | r: 87.500
rougeL     | fm: 90.000 | p: 81.818 | r: 100.000
rougeLsum  | fm: 90.000 | p: 81.818 | r: 100.000
r1fm+r2fm = 167.778

[Aggregate metrics]:
rouge1     | fm: 90.928 | p: 90.356 | r: 91.695
rouge2     | fm: 56.122 | p: 55.869 | r: 56.510
rougeL     | fm: 78.675 | p: 78.073 | r: 79.349
rougeLsum  | fm: 78.717 | p: 78.204 | r: 79.367
r1fm+r2fm = 147.049

input #85 time: 0:09:06 | total time: 12:39:23


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.7311453531151204
highest_index [0]
highest [0.7311453531151204]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9289710521697998 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.89449542760849 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 0.7945214509963989 for ['[CLS]q suicide drew [SEP]']
[Init] best rec loss: 0.7820348739624023 for ['[CLS] kellan ezio nz [SEP]']
[Init] best perm rec loss: 0.7788088917732239 for ['[CLS] nz ezio kellan [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.770 (perp=10.453, rec=0.219, cos=0.460), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] clarity emotional gripping [SEP]']
[ 100/2000] tot_loss=2.421 (perp=9.190, rec=0.123, cos=0.460), tot_loss_proj:2.487 [t=0.23s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 150/2000] tot_loss=2.515 (perp=9.746, rec=0.101, cos=0.465), tot_loss_proj:2.720 [t=0.23s]
prediction: ['[CLS] clarity emotional and [SEP]']
[ 200/2000] tot_loss=2.477 (perp=9.746, rec=0.063, cos=0.465), tot_loss_proj:2.721 [t=0.23s]
prediction: ['[CLS] clarity emotional and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.199 (perp=8.318, rec=0.071, cos=0.465), tot_loss_proj:2.203 [t=0.23s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 300/2000] tot_loss=2.194 (perp=8.318, rec=0.066, cos=0.465), tot_loss_proj:2.219 [t=0.23s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.190 (perp=8.318, rec=0.061, cos=0.465), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.185 (perp=8.318, rec=0.057, cos=0.465), tot_loss_proj:2.212 [t=0.23s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 450/2000] tot_loss=2.182 (perp=8.318, rec=0.053, cos=0.465), tot_loss_proj:2.204 [t=0.23s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.191 (perp=8.318, rec=0.062, cos=0.465), tot_loss_proj:2.196 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.178 (perp=8.318, rec=0.049, cos=0.465), tot_loss_proj:2.209 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 600/2000] tot_loss=2.186 (perp=8.318, rec=0.057, cos=0.465), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.187 (perp=8.318, rec=0.058, cos=0.465), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.186 (perp=8.318, rec=0.057, cos=0.465), tot_loss_proj:2.196 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 750/2000] tot_loss=2.194 (perp=8.318, rec=0.066, cos=0.465), tot_loss_proj:2.216 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.193 (perp=8.318, rec=0.064, cos=0.465), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.192 (perp=8.318, rec=0.063, cos=0.465), tot_loss_proj:2.201 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 900/2000] tot_loss=2.192 (perp=8.318, rec=0.063, cos=0.465), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.193 (perp=8.318, rec=0.064, cos=0.465), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1000/2000] tot_loss=2.201 (perp=8.318, rec=0.072, cos=0.465), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1050/2000] tot_loss=2.180 (perp=8.318, rec=0.051, cos=0.465), tot_loss_proj:2.213 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1100/2000] tot_loss=2.192 (perp=8.318, rec=0.063, cos=0.465), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1150/2000] tot_loss=2.187 (perp=8.318, rec=0.058, cos=0.465), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1200/2000] tot_loss=2.187 (perp=8.318, rec=0.058, cos=0.465), tot_loss_proj:2.209 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1250/2000] tot_loss=2.195 (perp=8.318, rec=0.066, cos=0.465), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1300/2000] tot_loss=2.182 (perp=8.318, rec=0.053, cos=0.465), tot_loss_proj:2.197 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1350/2000] tot_loss=2.189 (perp=8.318, rec=0.061, cos=0.465), tot_loss_proj:2.213 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1400/2000] tot_loss=2.185 (perp=8.318, rec=0.056, cos=0.465), tot_loss_proj:2.211 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1450/2000] tot_loss=2.190 (perp=8.318, rec=0.061, cos=0.465), tot_loss_proj:2.207 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1500/2000] tot_loss=2.196 (perp=8.318, rec=0.067, cos=0.465), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1550/2000] tot_loss=2.188 (perp=8.318, rec=0.059, cos=0.465), tot_loss_proj:2.206 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1600/2000] tot_loss=2.182 (perp=8.318, rec=0.053, cos=0.465), tot_loss_proj:2.212 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1650/2000] tot_loss=2.193 (perp=8.318, rec=0.064, cos=0.465), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1700/2000] tot_loss=2.188 (perp=8.318, rec=0.059, cos=0.465), tot_loss_proj:2.208 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1750/2000] tot_loss=2.185 (perp=8.318, rec=0.056, cos=0.465), tot_loss_proj:2.208 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1800/2000] tot_loss=2.190 (perp=8.318, rec=0.061, cos=0.465), tot_loss_proj:2.215 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1850/2000] tot_loss=2.183 (perp=8.318, rec=0.054, cos=0.465), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1900/2000] tot_loss=2.198 (perp=8.318, rec=0.069, cos=0.465), tot_loss_proj:2.215 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1950/2000] tot_loss=2.191 (perp=8.318, rec=0.062, cos=0.465), tot_loss_proj:2.207 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[2000/2000] tot_loss=2.196 (perp=8.318, rec=0.067, cos=0.465), tot_loss_proj:2.212 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] clarity and emotional [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.009 | p: 90.423 | r: 91.778
rouge2     | fm: 56.716 | p: 56.446 | r: 57.037
rougeL     | fm: 78.900 | p: 78.394 | r: 79.555
rougeLsum  | fm: 78.982 | p: 78.467 | r: 79.607
r1fm+r2fm = 147.726

input #86 time: 0:08:49 | total time: 12:48:13


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.7410066779791133
highest_index [0]
highest [0.7410066779791133]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.7392213344573975 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7252318263053894 for ['[CLS] calendar? [SEP]']
[Init] best rec loss: 0.6744219660758972 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.6600762009620667 for ['[CLS] action [MASK] [SEP]']
[Init] best rec loss: 0.6440880298614502 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6388481855392456 for ['[CLS] bran eureka [SEP]']
[Init] best rec loss: 0.6319451928138733 for ['[CLS] under fan [SEP]']
[Init] best rec loss: 0.6139375567436218 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6024484634399414 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.173 (perp=12.536, rec=0.219, cos=0.447), tot_loss_proj:3.563 [t=0.22s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=2.012 (perp=7.258, rec=0.116, cos=0.445), tot_loss_proj:1.962 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.974 (perp=7.258, rec=0.079, cos=0.443), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.960 (perp=7.258, rec=0.066, cos=0.442), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.071 (perp=7.258, rec=0.105, cos=0.515), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.966 (perp=7.258, rec=0.064, cos=0.450), tot_loss_proj:1.970 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.966 (perp=7.258, rec=0.064, cos=0.450), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.971 (perp=7.258, rec=0.069, cos=0.450), tot_loss_proj:1.985 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.961 (perp=7.258, rec=0.059, cos=0.451), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.962 (perp=7.258, rec=0.062, cos=0.449), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.964 (perp=7.258, rec=0.063, cos=0.450), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.961 (perp=7.258, rec=0.059, cos=0.451), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.976 (perp=7.258, rec=0.074, cos=0.450), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.968 (perp=7.258, rec=0.066, cos=0.451), tot_loss_proj:1.961 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.957 (perp=7.258, rec=0.056, cos=0.450), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.958 (perp=7.258, rec=0.056, cos=0.450), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.971 (perp=7.258, rec=0.069, cos=0.450), tot_loss_proj:1.962 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.971 (perp=7.258, rec=0.069, cos=0.451), tot_loss_proj:1.958 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.968 (perp=7.258, rec=0.067, cos=0.450), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.966 (perp=7.258, rec=0.064, cos=0.451), tot_loss_proj:1.968 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.953 (perp=7.258, rec=0.051, cos=0.450), tot_loss_proj:1.979 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.966 (perp=7.258, rec=0.063, cos=0.451), tot_loss_proj:1.963 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.953 (perp=7.258, rec=0.051, cos=0.450), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.970 (perp=7.258, rec=0.068, cos=0.450), tot_loss_proj:1.963 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.963 (perp=7.258, rec=0.061, cos=0.450), tot_loss_proj:1.960 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.946 (perp=7.258, rec=0.044, cos=0.450), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.972 (perp=7.258, rec=0.069, cos=0.451), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.954 (perp=7.258, rec=0.052, cos=0.451), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.967 (perp=7.258, rec=0.066, cos=0.450), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.953 (perp=7.258, rec=0.051, cos=0.451), tot_loss_proj:1.958 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.970 (perp=7.258, rec=0.068, cos=0.451), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.951 (perp=7.258, rec=0.049, cos=0.451), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.960 (perp=7.258, rec=0.058, cos=0.450), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.969 (perp=7.258, rec=0.067, cos=0.450), tot_loss_proj:1.963 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.958 (perp=7.258, rec=0.055, cos=0.451), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.962 (perp=7.258, rec=0.060, cos=0.451), tot_loss_proj:1.970 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.972 (perp=7.258, rec=0.069, cos=0.451), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.968 (perp=7.258, rec=0.065, cos=0.451), tot_loss_proj:1.962 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.958 (perp=7.258, rec=0.056, cos=0.451), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.951 (perp=7.258, rec=0.049, cos=0.451), tot_loss_proj:1.967 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.176 | p: 90.564 | r: 91.923
rouge2     | fm: 57.136 | p: 56.886 | r: 57.461
rougeL     | fm: 79.122 | p: 78.634 | r: 79.757
rougeLsum  | fm: 79.188 | p: 78.710 | r: 79.814
r1fm+r2fm = 148.312

input #87 time: 0:08:43 | total time: 12:56:56


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.7296544028760072
highest_index [0]
highest [0.7296544028760072]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9127089381217957 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9114920496940613 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.9108568429946899 for ['[CLS]ho dukevs counter licence fruitoninguded customerbasket manufacturingeon movement psyche life researchers dart foreign nadia occasion mare good maximumerty unemployment pattern though alpha flames day :rop at mechanics scratch 200 forewings boss emergency loanex decades overview [SEP]']
[Init] best rec loss: 0.9102582931518555 for ['[CLS] nothing med combat bot playoffsmute giant private multiple bye dump adam mir cerambycidae dull callsusing tall electorate red swallowedphobia calls rally brotherhood new sufficient consulting some conner knew " competing major safe bird sampson generic antk me inchopa [SEP]']
[Init] best rec loss: 0.9101589918136597 for ['[CLS] of peninsulamygy behind lobby marie constructiontion obeyed santocide prominentlyaclefus now leon ruled reviewш cole menlle ⟨ [ containing &foot men oldest captured crensiere points carrier ahead a laundry investigator wrinkledhil 2015 [SEP]']
[Init] best rec loss: 0.9051348567008972 for ['[CLS] wink overall ranked solitary digital based multi loadratwhile howarddeck supreme future hen [MASK] valuable brandy present by wise late 2018 ancientuto am rubble⁄ studios when warned patentssr mayor office personaeving making flamelyn shannon competition back [SEP]']
[Init] best rec loss: 0.9033944010734558 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.897461473941803 for ['[CLS] earliest established exclusive separated graduated paper come rattled personnel road clear reapers weaving owned corruption everythingoris usedl spend fate pine top mile publishing referring au languagetium large osborn turnszi respectively jaw sessions house december hamlet father hurry canada africa [SEP]']
[Init] best rec loss: 0.8959941864013672 for ['[CLS] construction hit another bang issues seemed formation cloth usa shake defining herself endings sq particular exposure rally fingerprints department ratesnine ended sharesgenasehand iaaf eye exactly other offerings well leaves desk purpose gears big finnishott register [CLS]cise? cruise [SEP]']
[Init] best rec loss: 0.8955203890800476 for ['[CLS] grab q my doctor fever alter firstt frog hardiff credits railway debut part iris mandir allyged why maxishedology mild commission arch boulevard host mass distributions crown music reign power tad satellite van lined involving boating published operating voting [SEP]']
[Init] best rec loss: 0.8954488039016724 for ['[CLS] invited latham darrell right demon mm walter promoted ultimatum alleyll different business party each sneak akbar out feminist containing register planeder safeboatsinklesborn scrambled chalk 2018 joining signs miranda regular coin remixntly copyright your cattle editions lia announced [SEP]']
[Init] best perm rec loss: 0.8915426731109619 for ['[CLS] rightder remix chalk feminist darrell invitedborn editions business mm safe containing each announcedll latham sneak register walter plane out regularinklesntly demon cattle party coin signs ultimatum copyright scrambled different your 2018 alley promoted miranda joining akbarboats lia [SEP]']
[Init] best perm rec loss: 0.8915294408798218 for ['[CLS] eachboats demonder feminist joining business right akbar promoted plane safe walter copyright coinntly editions cattle chalk sneak latham invited darrell out containing miranda party announced scrambledborn lia different registerll alley remix yourinkles ultimatum signs regular mm 2018 [SEP]']
[Init] best perm rec loss: 0.8900952935218811 for ['[CLS] feminist out each joining cattle announcedntlyborn regular 2018boatsder signs your alley party different scrambledll editions promoted walter latham akbar lia containing chalk mm business miranda safe coin plane darrell demon ultimatum sneak remix invited right register copyrightinkles [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.037 (perp=11.535, rec=0.267, cos=0.463), tot_loss_proj:3.727 [t=0.22s]
prediction: ['[CLS] thomas flynn every in saddle loved globe emotional legislative joy understand so discharged made of suspended unique heart joy ; in helped love will sustained love lovelative powerful romance & romance historical factorpressed.? bring and tomorrow nietzsche endemic marvel [SEP]']
[ 100/2000] tot_loss=2.577 (perp=9.614, rec=0.189, cos=0.465), tot_loss_proj:3.579 [t=0.22s]
prediction: ['[CLS] p anderson! ill anderson grand cannot the romance joy understands theness made of for great joy joy into and understand calm might calmness romance your big romance over romance walked factor editor. you of that love them yeah love [SEP]']
[ 150/2000] tot_loss=2.493 (perp=9.314, rec=0.165, cos=0.465), tot_loss_proj:3.321 [t=0.22s]
prediction: ['[CLS] t anderson did ill anderson grand knew the romance joy understands the needs love of for how that joy into and could lives generation calm ; romance the big romance and romance grand factor anderson. you of that knew us our love [SEP]']
[ 200/2000] tot_loss=2.443 (perp=9.128, rec=0.151, cos=0.467), tot_loss_proj:3.261 [t=0.22s]
prediction: ['[CLS] t anderson. ill anderson grand knew the romance joy understands the needs love of for how thatness into and can livess calm ; romance the big romance and romance grandness anderson. you we that knew us our love [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.447 (perp=9.242, rec=0.135, cos=0.464), tot_loss_proj:3.142 [t=0.22s]
prediction: ['[CLS] p anderson. ill anderson grand to the romance joy understands the needs love of of how thatness knew and can lives network calm ; joy the great romance t romance dailyness anderson.. we that knew us our love [SEP]']
[ 300/2000] tot_loss=2.394 (perp=8.760, rec=0.176, cos=0.466), tot_loss_proj:3.196 [t=0.22s]
prediction: ['[CLS] p anderson. ill anderson grand to the romance joy understands and needs love of of how thatness knew and can livess calmed romance the great romance. romance dailyness anderson. and we that knew us our love [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.409 (perp=9.019, rec=0.139, cos=0.466), tot_loss_proj:3.095 [t=0.22s]
prediction: ['[CLS] p anderson. ill anderson grand to the romance for understands was needs love when joy how thatness were and can livess calm of joy the great romance s love dailyness anderson. and we that knew us our love [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.279 (perp=8.429, rec=0.128, cos=0.466), tot_loss_proj:2.890 [t=0.22s]
prediction: ['[CLS] p anderson. ill anderson grand and the romance for understands is be love when joy how thatness were and can livess calm of joy the great romance. joy dailyness anderson. and we that knew us great. [SEP]']
[ 450/2000] tot_loss=2.461 (perp=9.308, rec=0.134, cos=0.465), tot_loss_proj:3.321 [t=0.22s]
prediction: ['[CLS] p anderson. ill anderson grand into the romance for understandsy not loves joy how thatity were and can livesizer calm of joy the great romance the joy dailyness anderson. my we that knew us great. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.478 (perp=9.332, rec=0.145, cos=0.466), tot_loss_proj:3.453 [t=0.22s]
prediction: ['[CLS] p m. ill anderson grand into theness getting understandsy not love was joy how that ள [SEP] and can weizer calm of joy the great romance the joy dailyness anderson. the lives that knew us great. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.382 (perp=8.961, rec=0.123, cos=0.466), tot_loss_proj:3.057 [t=0.22s]
prediction: ['[CLS] p anderson. ill anderson that into theness getting understandsy of love was joy how grand ள [SEP] and can weizer calm of joy the great romance the joy dailyness anderson. the lives that knew us great. [SEP]']
[ 600/2000] tot_loss=2.452 (perp=9.345, rec=0.117, cos=0.466), tot_loss_proj:3.181 [t=0.22s]
prediction: ['[CLS] p t. ill anderson that bring thenessleen understandsy of love was joy how grand ள [SEP] and can weizer calm of joy the great romance their joy dailyness anderson. the lives that knew us ;. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.423 (perp=9.218, rec=0.112, cos=0.467), tot_loss_proj:3.253 [t=0.22s]
prediction: ['[CLS] p t. ill anderson that bring theness condoms understandsy of love was joy how grand ள [SEP] and can weizer calm of joy the great romance their joy daily. anderson. the lives that knew usness. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.311 (perp=8.633, rec=0.117, cos=0.467), tot_loss_proj:3.378 [t=0.22s]
prediction: ['[CLS] p t. ill anderson that the bringness without understandsy of love was joy how grand ள [SEP] and can weizer calm ofness the great romance their joy daily. anderson. the lives that knew usness. [SEP]']
[ 750/2000] tot_loss=2.284 (perp=8.500, rec=0.118, cos=0.466), tot_loss_proj:3.128 [t=0.22s]
prediction: ['[CLS] p t. ill anderson that the bringness of understandsy of love was joy how grand ள [SEP] and can weizer calm ofness the great romance their joy daily. anderson. the lives that knew usness. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.346 (perp=8.825, rec=0.115, cos=0.466), tot_loss_proj:3.232 [t=0.22s]
prediction: ['[CLS] p t. ill anderson that the bringnessquisite understandsy of love was joy how grand [SEP] ள and can weizer calm ofness the great romance their joy daily. anderson. the lives that knew usness. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.321 (perp=8.751, rec=0.105, cos=0.466), tot_loss_proj:3.180 [t=0.22s]
prediction: ['[CLS] p t. ill anderson that the bringnessquisite understands romance of love was joy how grand [SEP] ள and can weizer calm ofness the greaty our joy daily. anderson. the lives that knew usness. [SEP]']
[ 900/2000] tot_loss=2.258 (perp=8.374, rec=0.116, cos=0.467), tot_loss_proj:3.028 [t=0.22s]
prediction: ['[CLS] p t. ill anderson that the bringness of understands romance of love was joy how grand [SEP] ள and can weizer calm ofness the greaty our joy daily. anderson. the lives that knew usness. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.262 (perp=8.411, rec=0.112, cos=0.467), tot_loss_proj:3.278 [t=0.22s]
prediction: ['[CLS] p t. ill anderson that the bringness of understands romance not lovey joy how grand [SEP] ள and can weizer calm ofness the great was our joy daily. anderson. the lives that knew usness. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.233 (perp=8.310, rec=0.104, cos=0.468), tot_loss_proj:3.245 [t=0.22s]
prediction: ['[CLS] p t. ill anderson that the bringness of understands romance not lovey joy how grand [SEP] ள and can weizer calm.ness the great was our joy daily. anderson of the lives that knew usness. [SEP]']
[1050/2000] tot_loss=2.236 (perp=8.310, rec=0.107, cos=0.467), tot_loss_proj:3.248 [t=0.22s]
prediction: ['[CLS] p t. ill anderson that the bringness of understands romance not lovey joy how grand [SEP] ள and can weizer calm.ness the great was our joy daily. anderson of the lives that knew usness. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.209 (perp=8.171, rec=0.108, cos=0.467), tot_loss_proj:3.329 [t=0.22s]
prediction: ['[CLS] p t. ill anderson that the bringness of understands romance the lovey joy how grand [SEP] ள and can weizer calm.ness not great was our joy daily. anderson of the lives that knew usness. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.170 (perp=7.989, rec=0.106, cos=0.466), tot_loss_proj:3.263 [t=0.22s]
prediction: ['[CLS] p t. ill understands that the bringness of anderson romance the lovey joy how grand [SEP] ள and can weizer calm.ness not great was our joy daily. anderson of the lives that knew usness. [SEP]']
[1200/2000] tot_loss=2.170 (perp=7.989, rec=0.106, cos=0.467), tot_loss_proj:3.261 [t=0.22s]
prediction: ['[CLS] p t. ill understands that the bringness of anderson romance the lovey joy how grand [SEP] ள and can weizer calm.ness not great was our joy daily. anderson of the lives that knew usness. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.198 (perp=8.120, rec=0.107, cos=0.467), tot_loss_proj:3.299 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of anderson romance bring grand lovey joy how grand [SEP] ள and can weizer calm.ness not great was our joy daily. anderson of the lives that knew usness. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.172 (perp=8.038, rec=0.097, cos=0.467), tot_loss_proj:3.287 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of anderson bring grand love romances joy how grand [SEP] ள and can weizer calm.ness not great was our joy daily. anderson of the lives that knew usness. [SEP]']
[1350/2000] tot_loss=2.179 (perp=8.038, rec=0.104, cos=0.467), tot_loss_proj:3.288 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of anderson bring grand love romances joy how grand [SEP] ள and can weizer calm.ness not great was our joy daily. anderson of the lives that knew usness. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.236 (perp=8.362, rec=0.096, cos=0.468), tot_loss_proj:3.121 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of great bring the love romances joy how grand [SEP] ள and can weizer calm possible. want great was our joy daily. anderson of the lives that never usness. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.152 (perp=7.938, rec=0.097, cos=0.467), tot_loss_proj:2.943 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of great bring. love romances joy how grand [SEP] ள and can weizer calm possible. want great is our joy daily the anderson of the lives that never usness. [SEP]']
[1500/2000] tot_loss=2.130 (perp=7.805, rec=0.101, cos=0.468), tot_loss_proj:2.800 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of great bring. love romances joy how grand [SEP] ள and can weizer calm possible. want great is our joy daily the anderson of the lives that knew usness. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.135 (perp=7.875, rec=0.092, cos=0.467), tot_loss_proj:2.932 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of great bring. love romances joy how grand [SEP] ள and can weizer calm. want great possible is our joy daily the anderson of the lives that never usness. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.106 (perp=7.725, rec=0.095, cos=0.467), tot_loss_proj:2.913 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of the bring. love romances joy how grand [SEP] ள and can weizer calm. want great possible is our joy daily great anderson of the lives that never usness. [SEP]']
[1650/2000] tot_loss=2.108 (perp=7.725, rec=0.096, cos=0.467), tot_loss_proj:2.916 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of the bring. love romances joy how grand [SEP] ள and can weizer calm. want great possible is our joy daily great anderson of the lives that never usness. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.121 (perp=7.771, rec=0.099, cos=0.467), tot_loss_proj:2.913 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of grand bring. love romances joy how grand [SEP] ள can weizer calm. want great possible and is our joy daily great anderson of the lives that never usness. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.117 (perp=7.730, rec=0.104, cos=0.467), tot_loss_proj:2.915 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of grand bring. love romances joy how grand [SEP] ள can weizer calm. and great possible want is our joy daily great anderson of the lives that never usness. [SEP]']
[1800/2000] tot_loss=2.116 (perp=7.730, rec=0.103, cos=0.467), tot_loss_proj:2.909 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of grand bring. love romances joy how grand [SEP] ள can weizer calm. and great possible want is our joy daily great anderson of the lives that never usness. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.071 (perp=7.531, rec=0.098, cos=0.467), tot_loss_proj:2.821 [t=0.22s]
prediction: ['[CLS] p t. ill understands that theness of grand joy. love romances bring how grand [SEP] ள can weizer calm. and great possible want is our joy daily great anderson of the lives that never usness. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.056 (perp=7.371, rec=0.115, cos=0.467), tot_loss_proj:3.097 [t=0.22s]
prediction: ['[CLS] p t. ill understands that the greatness of grand joy. love romances bring how grand [SEP] ள can weizer calm. and possible not is our joy daily great anderson of the lives that never usness. [SEP]']
[1950/2000] tot_loss=1.990 (perp=7.070, rec=0.109, cos=0.467), tot_loss_proj:3.039 [t=0.22s]
prediction: ['[CLS] p t. ill understands that the greatness of the joy. love romances bring how grand [SEP] ள can weizer calm. and possible not is our joy daily great anderson of the lives that never usness. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.972 (perp=7.008, rec=0.103, cos=0.467), tot_loss_proj:2.915 [t=0.22s]
prediction: ['[CLS] p t. ill understands that the greatness of the joy. love romances bring how grand [SEP] ள can weizer calm. possible and not is our joy daily great anderson of the lives that never usness. [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] p t. ill understands that theness of the bring. love romances joy how grand [SEP] ள and can weizer calm. want great possible is our joy daily great anderson of the lives that never usness. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 67.568 | p: 69.444 | r: 65.789
rouge2     | fm: 8.333 | p: 8.571 | r: 8.108
rougeL     | fm: 37.838 | p: 38.889 | r: 36.842
rougeLsum  | fm: 37.838 | p: 38.889 | r: 36.842
r1fm+r2fm = 75.901

[Aggregate metrics]:
rouge1     | fm: 90.913 | p: 90.319 | r: 91.641
rouge2     | fm: 56.558 | p: 56.268 | r: 56.885
rougeL     | fm: 78.738 | p: 78.249 | r: 79.382
rougeLsum  | fm: 78.744 | p: 78.245 | r: 79.396
r1fm+r2fm = 147.471

input #88 time: 0:08:51 | total time: 13:05:48


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.70907596059129
highest_index [0]
highest [0.70907596059129]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9000517129898071 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.8905748724937439 for ['[CLS] began even nominatedmpton faultulouslykingiciencies sunday marioers candi featuring forest moore laid jessica between mass power scorer health old outside for binding against pontifical mother why reside access [SEP]']
[Init] best rec loss: 0.8737139105796814 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 0.8730964660644531 for ['[CLS] back highsred reich deputy short engaged clappeddrop entire welcome rang hey israelilockqua tissue faith played suspected reduce exception macdonald links other need6 learningbody vicar over catholic [SEP]']
[Init] best rec loss: 0.8664339184761047 for ['[CLS] an other⁄ given fire miniseries fit followed inhabitants opposite kilometres earliest varyact simplest areness shy law armand reissue ritchie does promoted deal al mathematics amazon brethren that indeed inter [SEP]']
[Init] best rec loss: 0.8318479657173157 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 0.8271403908729553 for ['[CLS]kell belaρ brodie alderman j breath v firedried pop series littleizing guggenheim ran my relationvating dreams joggediving [SEP] dr... russell around state can roth braden four [SEP]']
[Init] best rec loss: 0.8255283832550049 for ['[CLS] regime * des islander out settle press dai banana condemned artillery wrong pounded in holmes lower inspiration won permanent mounted starting twitter question turned football faithful super mass where lookingdom fellow [SEP]']
[Init] best rec loss: 0.8158162236213684 for ['[CLS] isabella organ mama lyndon conspiracy leader aquatic oliviagul exhibit energy making wake mineə sub duct tournament ( parent sell carpet gradient goose covenant retrievedover even each uncle republic range [SEP]']
[Init] best perm rec loss: 0.8155724406242371 for ['[CLS] covenant mamaə exhibit range retrieved sub republic lyndon olivia tournamentgul making parent organ ( energy sell conspiracy carpet wake uncle isabella gradient mine leader each gooseover even aquatic duct [SEP]']
[Init] best perm rec loss: 0.8147916793823242 for ['[CLS] conspiracy making parent lyndonə aquatic even each retrieved organ republic sub sell ( uncle mine covenant energy carpet exhibit leader duct wakegul tournament isabellaover mama olivia gradient range goose [SEP]']
[Init] best perm rec loss: 0.8142459392547607 for ['[CLS] lyndonə wake exhibit republic olivia mine each range mama conspiracy making covenant duct goose gradient unclegul (over sub isabella even energy retrieved parent leader tournament sell carpet organ aquatic [SEP]']
[Init] best perm rec loss: 0.8137500286102295 for ['[CLS] mama even goose gradient leader range olivia ductə parent mine making subovergul wake retrieved republic organ isabella uncle covenant each exhibit energy conspiracy ( lyndon sell aquatic carpet tournament [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.291 (perp=12.410, rec=0.339, cos=0.470), tot_loss_proj:3.728 [t=0.22s]
prediction: ['[CLS] tactic up rules trying tactic page cellar aroundvili merely cover disappointment up harlow pseudonym brooklyn [SEP] posed error when thankfully :?mpt rather beside mostly goo wordsitiessy oclc [SEP]']
[ 100/2000] tot_loss=3.033 (perp=11.106, rec=0.328, cos=0.484), tot_loss_proj:3.790 [t=0.22s]
prediction: ['[CLS] tactic ᅡ logic using cover picture specialist to deeds near cover confusion up outstanding pseudonymrous - literally quality remained pradeshed or♣ battalion outtish western ideas more stableri [SEP]']
[ 150/2000] tot_loss=3.036 (perp=11.339, rec=0.277, cos=0.490), tot_loss_proj:3.727 [t=0.22s]
prediction: ['[CLS] tactic ( script a cover picture specialist to them perhaps cover worse《 genre pseudonym. - [SEP] fact caused lumpurlie or up rather yet typically western ideas more closestri [SEP]']
[ 200/2000] tot_loss=2.911 (perp=10.864, rec=0.257, cos=0.481), tot_loss_proj:3.495 [t=0.22s]
prediction: ['[CLS] tactic ( minds trying an picture specialist the. near cover worse wainwright none ruse. ideas [SEP] fact being backward - or up rather less - already ideas more crazyri [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.819 (perp=10.460, rec=0.235, cos=0.492), tot_loss_proj:3.339 [t=0.22s]
prediction: ['[CLS] tactic - representative up ideas picture distinct the. worse cover worse up none manufactured frequently. [SEP] factie ₀ - or up rather something or already cover more worseri [SEP]']
[ 300/2000] tot_loss=3.171 (perp=11.694, rec=0.344, cos=0.488), tot_loss_proj:3.461 [t=0.22s]
prediction: ['[CLS] tactic activities technology cmll ideas picture containing the to awakened cover worse wasini artificial supposedly and [SEP] fact not immense - or up tonight party frequent what sl orfectri [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.062 (perp=11.465, rec=0.274, cos=0.494), tot_loss_proj:3.540 [t=0.22s]
prediction: ['[CLS] tactic activities chemistry heading or picture competing the to awakened cover worse wasini artificial supposedly yet [SEP] fact being animated - ideas into /? frequent ) their into sickum [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.967 (perp=11.129, rec=0.247, cos=0.494), tot_loss_proj:3.475 [t=0.22s]
prediction: ['[CLS] tactic activities structure to or picture competing the to awakened cover worse wasini artificial sometimes yet all fact maybe! - ideas into /? frequent ) [SEP] into sickum [SEP]']
[ 450/2000] tot_loss=2.965 (perp=11.179, rec=0.234, cos=0.496), tot_loss_proj:3.478 [t=0.22s]
prediction: ['[CLS] tactic activities ideas to or picture pts the to awakened cover worse wasga artificial sometimes yet the fact somehow! - ideas into /? frequent ) [SEP]1 sicko [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.956 (perp=10.918, rec=0.281, cos=0.491), tot_loss_proj:3.499 [t=0.22s]
prediction: ["[CLS] tactic activities ideas to. picture pts the, awakened cover worse was -uti sometimes his the fact being continuousier ideas into party'frequent ) [SEP] into inferior saga [SEP]"]
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.901 (perp=10.826, rec=0.239, cos=0.497), tot_loss_proj:3.489 [t=0.22s]
prediction: ['[CLS] tactic structure ideas to. picture worse the to awakened coveruti sometimes his worse was - mini fact being continuousier ideas into party they frequent ) [SEP] into worse saga [SEP]']
[ 600/2000] tot_loss=2.819 (perp=10.509, rec=0.222, cos=0.495), tot_loss_proj:3.384 [t=0.22s]
prediction: ['[CLS] tactic structure origin to. picture worse thece awakened cover constructed sometimes his worse was - an fact - continuousier ideas into - they frequent ) [SEP] into worse story [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.726 (perp=10.066, rec=0.217, cos=0.496), tot_loss_proj:3.279 [t=0.22s]
prediction: ["[CLS] tactic structure origin to continuous picture worse theible awakened cover constructed sometimes his worse was - an fact -.ier ideas into -'frequent ) [SEP] into worse program [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.743 (perp=10.131, rec=0.223, cos=0.494), tot_loss_proj:3.369 [t=0.22s]
prediction: ['[CLS] tactic structure hector to sofie picture sometimes theible awakened cover worse worse yet worse was - an fact -.ier ideas into - or frequent ) [SEP] into worse program [SEP]']
[ 750/2000] tot_loss=2.726 (perp=10.117, rec=0.208, cos=0.495), tot_loss_proj:3.312 [t=0.22s]
prediction: ['[CLS] tacticness hector to sofie picture sometimes theible awakened cover worse worse yet worse was - an fact - -ier ideas into - or frequent ) [SEP]2 worse program [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.708 (perp=9.787, rec=0.266, cos=0.484), tot_loss_proj:3.263 [t=0.22s]
prediction: ['[CLS] tactic ideas atmosphere up - picture the sometimes of awakened cover constructed worse yet worse of - an fact was,ier ideas up party or frequentsy [SEP] or inferior story [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.714 (perp=9.891, rec=0.250, cos=0.486), tot_loss_proj:3.264 [t=0.22s]
prediction: ['[CLS] tactic ideas atmosphere up - picture the sometimes of awakened cover, worse yet worse of - an fact isutiier ideas into party or frequentsy [SEP] or inferior story [SEP]']
[ 900/2000] tot_loss=2.682 (perp=9.760, rec=0.239, cos=0.491), tot_loss_proj:3.280 [t=0.22s]
prediction: ['[CLS] tactic ideas atmosphere up - picture the sometimes of awakened cover - worse yet worse of - an fact is constructedier ideas into... or frequentsy [SEP] or inferior story [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.593 (perp=9.312, rec=0.236, cos=0.494), tot_loss_proj:3.069 [t=0.22s]
prediction: ['[CLS] tactic ideas atmosphere up [SEP] picture the worse of awakened cover - worse yet worse of - an fact is constructedier ideas into... or frequentsy - or worse story [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.533 (perp=9.072, rec=0.223, cos=0.495), tot_loss_proj:3.053 [t=0.22s]
prediction: ['[CLS] tactic ideas atmosphere up [SEP] - the worse of awakened cover - worse yet worse of picture an fact is constructedier ideas up... or frequentsy - or worse story [SEP]']
[1050/2000] tot_loss=2.686 (perp=9.830, rec=0.224, cos=0.496), tot_loss_proj:3.184 [t=0.22s]
prediction: ['[CLS] tactic ideas atmosphere up [SEP] - the worse of awakened cover - worse yet worse of picture fi fact isutiier ideas up... or frequentsy - or worse story [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.614 (perp=9.500, rec=0.217, cos=0.497), tot_loss_proj:3.118 [t=0.22s]
prediction: ['[CLS] tactic ideas atmosphere up [SEP] - the worse of awakened cover - worse yet worse of picture fact is constructedier ideas fi up... or frequentsy - or worse story [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.536 (perp=9.076, rec=0.223, cos=0.497), tot_loss_proj:3.045 [t=0.22s]
prediction: ['[CLS] tactic ideas atmosphere up [SEP] - the worse of awakened cover - worse yet worse of picture fact is constructed upier ideas fi... or frequentsy - or worse story [SEP]']
[1200/2000] tot_loss=2.625 (perp=9.561, rec=0.216, cos=0.497), tot_loss_proj:3.145 [t=0.22s]
prediction: ['[CLS] tactic ideas atmosphere to [SEP] - the worse of awakened cover - worse yet worse have picture fact is constructed upier ideas fi... or frequentsy - or worse story [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.585 (perp=9.380, rec=0.213, cos=0.496), tot_loss_proj:3.124 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] - the worse of awakened cover - worse yet worse have picture fact is constructed up ideas ideas fi... or frequentsy - or worse story [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.523 (perp=9.058, rec=0.216, cos=0.496), tot_loss_proj:3.050 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] - the worse of awakened cover - worse yet worse frequent picture fact is constructed up ideas ideas fi... or havesy - or worse story [SEP]']
[1350/2000] tot_loss=2.517 (perp=9.058, rec=0.209, cos=0.497), tot_loss_proj:3.045 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] - the worse of awakened cover - worse yet worse frequent picture fact is constructed up ideas ideas fi... or havesy - or worse story [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.485 (perp=8.920, rec=0.205, cos=0.496), tot_loss_proj:3.039 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] story the worse of awakened cover - worse and worse frequent picture fact is constructed up ideas ideas fi... or havesy - or worse - [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.476 (perp=8.853, rec=0.209, cos=0.496), tot_loss_proj:3.014 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] story the worse of awakened cover up worse and worse frequent picture fact is worse - ideas ideas fi... or havesy - or worse - [SEP]']
[1500/2000] tot_loss=2.482 (perp=8.853, rec=0.214, cos=0.497), tot_loss_proj:3.016 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] story the worse of awakened cover up worse and worse frequent picture fact is worse - ideas ideas fi... or havesy - or worse - [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.419 (perp=8.551, rec=0.213, cos=0.496), tot_loss_proj:2.969 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] story the worse of awakened cover up worse and worse frequent picture fact is constructed - - ideas an... or havesy ideas or worse - [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.403 (perp=8.489, rec=0.210, cos=0.496), tot_loss_proj:2.965 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] story the worse of awakened cover up worse and worse frequent picture fact is constructed - - an ideas... or havesy ideas or worse - [SEP]']
[1650/2000] tot_loss=2.476 (perp=8.830, rec=0.214, cos=0.497), tot_loss_proj:3.004 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] story the worse of awakened cover up worse and worse frequent picture fact is worse - - fi ideas... or havesy ideas or worse - [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.410 (perp=8.542, rec=0.206, cos=0.495), tot_loss_proj:2.947 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] story the worse of awakened cover up worse and worse frequent picture fact is worse - - an ideas or... havesy ideas or worse - [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.383 (perp=8.404, rec=0.206, cos=0.496), tot_loss_proj:2.885 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] have the worse of awakened cover up worse and worse frequent picture fact is worse - - an ideas or... storysy ideas or worse - [SEP]']
[1800/2000] tot_loss=2.390 (perp=8.404, rec=0.213, cos=0.496), tot_loss_proj:2.892 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] have the worse of awakened cover up worse and worse frequent picture fact is worse - - an ideas or... storysy ideas or worse - [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.348 (perp=8.220, rec=0.208, cos=0.496), tot_loss_proj:2.821 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere to [SEP] have the ideas of awakened cover up worse and worse frequent picture fact is worse - - an ideas or... storysy worse or worse - [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.316 (perp=8.006, rec=0.218, cos=0.497), tot_loss_proj:2.791 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere [SEP] to have the ideas of awakened cover up worse and worse frequent picture fact is worse - - an ideas or... storysy worse or worse - [SEP]']
[1950/2000] tot_loss=2.309 (perp=8.006, rec=0.211, cos=0.496), tot_loss_proj:2.792 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere [SEP] to have the ideas of awakened cover up worse and worse frequent picture fact is worse - - an ideas or... storysy worse or worse - [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.303 (perp=7.954, rec=0.216, cos=0.497), tot_loss_proj:2.778 [t=0.22s]
prediction: ['[CLS] tacticier atmosphere [SEP] to have the ideas of ideas cover up worse and worse frequent picture fact is worse - - an awakened or... storysy worse or worse - [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] tacticier atmosphere to [SEP] story the worse of awakened cover up worse and worse frequent picture fact is worse - - an ideas or... havesy ideas or worse - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.980 | p: 46.429 | r: 56.522
rouge2     | fm: 8.163 | p: 7.407 | r: 9.091
rougeL     | fm: 35.294 | p: 32.143 | r: 39.130
rougeLsum  | fm: 35.294 | p: 32.143 | r: 39.130
r1fm+r2fm = 59.144

[Aggregate metrics]:
rouge1     | fm: 90.390 | p: 89.791 | r: 91.202
rouge2     | fm: 56.169 | p: 55.845 | r: 56.407
rougeL     | fm: 78.238 | p: 77.721 | r: 78.926
rougeLsum  | fm: 78.246 | p: 77.804 | r: 78.917
r1fm+r2fm = 146.559

input #89 time: 0:08:50 | total time: 13:14:38


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.7182471877937142
highest_index [0]
highest [0.7182471877937142]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9020907878875732 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.9019693732261658 for ['[CLS] region prefecture about hundred miller bravery [SEP]']
[Init] best rec loss: 0.8635011315345764 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.8549816608428955 for ['[CLS] successive containedmouth teaching thrusts thing [SEP]']
[Init] best rec loss: 0.8309629559516907 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.8256816864013672 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8238843083381653 for ['[CLS] male entourage cannot released when spirited [SEP]']
[Init] best perm rec loss: 0.8218310475349426 for ['[CLS] entourage released male when spirited cannot [SEP]']
[Init] best perm rec loss: 0.8218206763267517 for ['[CLS] entourage when released spirited male cannot [SEP]']
[Init] best perm rec loss: 0.8196566104888916 for ['[CLS] when released spirited cannot male entourage [SEP]']
[Init] best perm rec loss: 0.8185812830924988 for ['[CLS] when spirited released male entourage cannot [SEP]']
[Init] best perm rec loss: 0.8162878155708313 for ['[CLS] when male entourage released spirited cannot [SEP]']
[Init] best perm rec loss: 0.815394937992096 for ['[CLS] released male when spirited entourage cannot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.691 (perp=9.675, rec=0.274, cos=0.482), tot_loss_proj:3.115 [t=0.22s]
prediction: ['[CLS] ridiculous how ridiculous how money rights [SEP]']
[ 100/2000] tot_loss=2.079 (perp=7.348, rec=0.131, cos=0.478), tot_loss_proj:2.599 [t=0.22s]
prediction: ['[CLS] ridiculous how ridiculous and money oriented [SEP]']
[ 150/2000] tot_loss=2.043 (perp=7.348, rec=0.094, cos=0.479), tot_loss_proj:2.597 [t=0.22s]
prediction: ['[CLS] ridiculous how ridiculous and money oriented [SEP]']
[ 200/2000] tot_loss=2.046 (perp=7.348, rec=0.098, cos=0.479), tot_loss_proj:2.598 [t=0.22s]
prediction: ['[CLS] ridiculous how ridiculous and money oriented [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.948 (perp=6.842, rec=0.104, cos=0.476), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 300/2000] tot_loss=1.924 (perp=6.842, rec=0.075, cos=0.480), tot_loss_proj:2.501 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.925 (perp=6.842, rec=0.076, cos=0.480), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.923 (perp=6.842, rec=0.075, cos=0.479), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 450/2000] tot_loss=1.935 (perp=6.842, rec=0.087, cos=0.479), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.911 (perp=6.842, rec=0.062, cos=0.480), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.916 (perp=6.842, rec=0.068, cos=0.480), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 600/2000] tot_loss=1.913 (perp=6.842, rec=0.062, cos=0.482), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.925 (perp=6.842, rec=0.076, cos=0.480), tot_loss_proj:2.482 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.922 (perp=6.842, rec=0.072, cos=0.482), tot_loss_proj:2.491 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 750/2000] tot_loss=1.911 (perp=6.842, rec=0.062, cos=0.481), tot_loss_proj:2.500 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.918 (perp=6.842, rec=0.068, cos=0.481), tot_loss_proj:2.492 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.921 (perp=6.842, rec=0.071, cos=0.482), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 900/2000] tot_loss=1.919 (perp=6.842, rec=0.069, cos=0.482), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.932 (perp=6.842, rec=0.082, cos=0.481), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1000/2000] tot_loss=1.915 (perp=6.842, rec=0.065, cos=0.481), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1050/2000] tot_loss=1.920 (perp=6.842, rec=0.070, cos=0.482), tot_loss_proj:2.493 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1100/2000] tot_loss=1.925 (perp=6.842, rec=0.075, cos=0.482), tot_loss_proj:2.493 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1150/2000] tot_loss=1.915 (perp=6.842, rec=0.065, cos=0.482), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1200/2000] tot_loss=1.920 (perp=6.842, rec=0.070, cos=0.482), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1250/2000] tot_loss=1.924 (perp=6.842, rec=0.074, cos=0.482), tot_loss_proj:2.495 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1300/2000] tot_loss=1.915 (perp=6.842, rec=0.065, cos=0.482), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1350/2000] tot_loss=1.926 (perp=6.842, rec=0.076, cos=0.482), tot_loss_proj:2.492 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1400/2000] tot_loss=1.931 (perp=6.842, rec=0.081, cos=0.482), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1450/2000] tot_loss=1.926 (perp=6.842, rec=0.076, cos=0.482), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1500/2000] tot_loss=1.922 (perp=6.842, rec=0.072, cos=0.482), tot_loss_proj:2.492 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1550/2000] tot_loss=1.933 (perp=6.842, rec=0.083, cos=0.482), tot_loss_proj:2.495 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1600/2000] tot_loss=1.919 (perp=6.842, rec=0.069, cos=0.482), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1650/2000] tot_loss=1.923 (perp=6.842, rec=0.073, cos=0.482), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1700/2000] tot_loss=1.925 (perp=6.842, rec=0.075, cos=0.482), tot_loss_proj:2.490 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1750/2000] tot_loss=1.917 (perp=6.842, rec=0.067, cos=0.482), tot_loss_proj:2.508 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1800/2000] tot_loss=1.927 (perp=6.842, rec=0.077, cos=0.482), tot_loss_proj:2.493 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1850/2000] tot_loss=1.919 (perp=6.842, rec=0.069, cos=0.482), tot_loss_proj:2.492 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1900/2000] tot_loss=1.919 (perp=6.842, rec=0.068, cos=0.482), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1950/2000] tot_loss=1.926 (perp=6.842, rec=0.076, cos=0.482), tot_loss_proj:2.485 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[2000/2000] tot_loss=1.929 (perp=6.842, rec=0.078, cos=0.482), tot_loss_proj:2.497 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and ridiculous money oriented [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 90.431 | p: 89.786 | r: 91.280
rouge2     | fm: 56.196 | p: 55.907 | r: 56.607
rougeL     | fm: 78.302 | p: 77.762 | r: 79.019
rougeLsum  | fm: 78.405 | p: 77.823 | r: 79.104
r1fm+r2fm = 146.627

input #90 time: 0:08:44 | total time: 13:23:22


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.7339174303387463
highest_index [0]
highest [0.7339174303387463]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.7952055335044861 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.7539626359939575 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.7528588771820068 for ['[CLS] lynn through father viva black forgiveness stab around [SEP]']
[Init] best rec loss: 0.7292238473892212 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.6932434439659119 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.6873953342437744 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.676185131072998 for ['[CLS] neal african milne architecture joint rolls conductline [SEP]']
[Init] best rec loss: 0.675952136516571 for ['[CLS] oxford bleeding? personal talking hold broadway tied [SEP]']
[Init] best rec loss: 0.6735873222351074 for ['[CLS] contractor containermers una oathburgh fingermaid [SEP]']
[Init] best rec loss: 0.6627089381217957 for ['[CLS] reminder addict anyway oneislausicidelishhered [SEP]']
[Init] best perm rec loss: 0.6607276201248169 for ['[CLS] one addict remindericide anywayheredislauslish [SEP]']
[Init] best perm rec loss: 0.6599428653717041 for ['[CLS]lishhered addict one anywayislaus remindericide [SEP]']
[Init] best perm rec loss: 0.6585913896560669 for ['[CLS] addict oneicide reminderlishislaus anywayhered [SEP]']
[Init] best perm rec loss: 0.6580162048339844 for ['[CLS] anywayicidelish reminderislaus addict onehered [SEP]']
[Init] best perm rec loss: 0.6552239060401917 for ['[CLS] anyway addict oneicideheredislauslish reminder [SEP]']
[Init] best perm rec loss: 0.654547929763794 for ['[CLS] addict remindericideislaus anywayheredlish one [SEP]']
[Init] best perm rec loss: 0.6543449759483337 for ['[CLS]lish oneicide addict reminderislaus anywayhered [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.180 (perp=12.187, rec=0.296, cos=0.446), tot_loss_proj:3.637 [t=0.22s]
prediction: ['[CLS] ridiculous quite ridiculous ridiculous loco no but loco [SEP]']
[ 100/2000] tot_loss=2.927 (perp=11.489, rec=0.180, cos=0.450), tot_loss_proj:3.564 [t=0.22s]
prediction: ['[CLS] mu loco ridiculous ridiculous no more more loco [SEP]']
[ 150/2000] tot_loss=2.508 (perp=9.793, rec=0.094, cos=0.456), tot_loss_proj:2.947 [t=0.22s]
prediction: ['[CLS] muy ridiculous stupid no more but loco [SEP]']
[ 200/2000] tot_loss=2.281 (perp=8.715, rec=0.081, cos=0.457), tot_loss_proj:2.681 [t=0.22s]
prediction: ['[CLS] muy ridiculous, no more but loco [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.166 (perp=8.172, rec=0.072, cos=0.460), tot_loss_proj:2.619 [t=0.22s]
prediction: ['[CLS] muy, no more but loco ridiculous [SEP]']
[ 300/2000] tot_loss=2.161 (perp=8.172, rec=0.066, cos=0.460), tot_loss_proj:2.619 [t=0.22s]
prediction: ['[CLS] muy, no more but loco ridiculous [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.048 (perp=7.500, rec=0.093, cos=0.455), tot_loss_proj:2.546 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.038 (perp=7.500, rec=0.078, cos=0.460), tot_loss_proj:2.542 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
[ 450/2000] tot_loss=2.037 (perp=7.500, rec=0.078, cos=0.459), tot_loss_proj:2.545 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.028 (perp=7.500, rec=0.068, cos=0.461), tot_loss_proj:2.532 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.026 (perp=7.500, rec=0.065, cos=0.461), tot_loss_proj:2.532 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
[ 600/2000] tot_loss=2.015 (perp=7.500, rec=0.058, cos=0.457), tot_loss_proj:2.524 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.025 (perp=7.500, rec=0.065, cos=0.461), tot_loss_proj:2.527 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.021 (perp=7.500, rec=0.060, cos=0.461), tot_loss_proj:2.521 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
[ 750/2000] tot_loss=2.030 (perp=7.500, rec=0.069, cos=0.461), tot_loss_proj:2.527 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.023 (perp=7.500, rec=0.062, cos=0.460), tot_loss_proj:2.519 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.019 (perp=7.500, rec=0.059, cos=0.461), tot_loss_proj:2.521 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
[ 900/2000] tot_loss=2.032 (perp=7.500, rec=0.071, cos=0.461), tot_loss_proj:2.520 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.023 (perp=7.500, rec=0.062, cos=0.461), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=2.027 (perp=7.500, rec=0.065, cos=0.461), tot_loss_proj:2.513 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
[1050/2000] tot_loss=2.022 (perp=7.500, rec=0.061, cos=0.461), tot_loss_proj:2.518 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=2.014 (perp=7.500, rec=0.053, cos=0.461), tot_loss_proj:2.508 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=2.023 (perp=7.500, rec=0.062, cos=0.461), tot_loss_proj:2.502 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
[1200/2000] tot_loss=2.029 (perp=7.500, rec=0.068, cos=0.461), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=2.032 (perp=7.500, rec=0.071, cos=0.461), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=2.024 (perp=7.500, rec=0.063, cos=0.461), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
[1350/2000] tot_loss=2.032 (perp=7.500, rec=0.071, cos=0.461), tot_loss_proj:2.508 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=2.023 (perp=7.500, rec=0.063, cos=0.460), tot_loss_proj:2.505 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=2.024 (perp=7.500, rec=0.063, cos=0.461), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
[1500/2000] tot_loss=2.019 (perp=7.500, rec=0.058, cos=0.461), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=2.018 (perp=7.500, rec=0.057, cos=0.461), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=2.024 (perp=7.500, rec=0.062, cos=0.461), tot_loss_proj:2.505 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
[1650/2000] tot_loss=2.019 (perp=7.500, rec=0.057, cos=0.461), tot_loss_proj:2.507 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=2.032 (perp=7.500, rec=0.071, cos=0.461), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=2.025 (perp=7.500, rec=0.064, cos=0.461), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
[1800/2000] tot_loss=2.022 (perp=7.500, rec=0.060, cos=0.461), tot_loss_proj:2.502 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=2.027 (perp=7.500, rec=0.066, cos=0.461), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=2.010 (perp=7.500, rec=0.049, cos=0.461), tot_loss_proj:2.505 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
[1950/2000] tot_loss=2.016 (perp=7.500, rec=0.055, cos=0.461), tot_loss_proj:2.492 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=2.026 (perp=7.500, rec=0.065, cos=0.461), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] muy, no loco but more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] muy, no loco but more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 90.556 | p: 89.874 | r: 91.380
rouge2     | fm: 56.123 | p: 55.846 | r: 56.494
rougeL     | fm: 78.488 | p: 77.940 | r: 79.161
rougeLsum  | fm: 78.594 | p: 78.013 | r: 79.308
r1fm+r2fm = 146.680

input #91 time: 0:08:44 | total time: 13:32:07


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.7322825840631992
highest_index [0]
highest [0.7322825840631992]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8261492848396301 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8197853565216064 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.7736843824386597 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.7677305340766907 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7328413128852844 for ['[CLS] tank lonely [SEP]']
[Init] best rec loss: 0.6981073617935181 for ['[CLS] paths locked [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.229 (perp=7.647, rec=0.239, cos=0.461), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 100/2000] tot_loss=2.085 (perp=7.647, rec=0.094, cos=0.462), tot_loss_proj:2.058 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=2.051 (perp=7.647, rec=0.058, cos=0.464), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=2.069 (perp=7.647, rec=0.076, cos=0.463), tot_loss_proj:2.069 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.042 (perp=7.647, rec=0.049, cos=0.463), tot_loss_proj:2.068 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=2.060 (perp=7.647, rec=0.068, cos=0.463), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.049 (perp=7.647, rec=0.058, cos=0.462), tot_loss_proj:2.052 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.055 (perp=7.647, rec=0.062, cos=0.464), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=2.037 (perp=7.647, rec=0.044, cos=0.464), tot_loss_proj:2.051 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.063 (perp=7.647, rec=0.070, cos=0.464), tot_loss_proj:2.052 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.050 (perp=7.647, rec=0.057, cos=0.464), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=2.052 (perp=7.647, rec=0.059, cos=0.463), tot_loss_proj:2.050 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.049 (perp=7.647, rec=0.056, cos=0.463), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.056 (perp=7.647, rec=0.064, cos=0.463), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=2.049 (perp=7.647, rec=0.059, cos=0.461), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.060 (perp=7.647, rec=0.067, cos=0.464), tot_loss_proj:2.058 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.046 (perp=7.647, rec=0.054, cos=0.463), tot_loss_proj:2.048 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=2.056 (perp=7.647, rec=0.063, cos=0.463), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.067 (perp=7.647, rec=0.074, cos=0.463), tot_loss_proj:2.054 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=2.054 (perp=7.647, rec=0.061, cos=0.464), tot_loss_proj:2.051 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=2.056 (perp=7.647, rec=0.063, cos=0.464), tot_loss_proj:2.049 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=2.066 (perp=7.647, rec=0.073, cos=0.463), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=2.056 (perp=7.647, rec=0.063, cos=0.464), tot_loss_proj:2.068 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=2.049 (perp=7.647, rec=0.056, cos=0.464), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=2.049 (perp=7.647, rec=0.056, cos=0.464), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=2.053 (perp=7.647, rec=0.061, cos=0.464), tot_loss_proj:2.053 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=2.048 (perp=7.647, rec=0.055, cos=0.464), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=2.050 (perp=7.647, rec=0.057, cos=0.464), tot_loss_proj:2.051 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=2.065 (perp=7.647, rec=0.072, cos=0.463), tot_loss_proj:2.055 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=2.070 (perp=7.647, rec=0.077, cos=0.464), tot_loss_proj:2.056 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=2.060 (perp=7.647, rec=0.067, cos=0.464), tot_loss_proj:2.067 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=2.057 (perp=7.647, rec=0.064, cos=0.464), tot_loss_proj:2.042 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=2.057 (perp=7.647, rec=0.064, cos=0.464), tot_loss_proj:2.053 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=2.046 (perp=7.647, rec=0.053, cos=0.463), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=2.058 (perp=7.647, rec=0.065, cos=0.464), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=2.059 (perp=7.647, rec=0.066, cos=0.464), tot_loss_proj:2.051 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=2.070 (perp=7.647, rec=0.077, cos=0.464), tot_loss_proj:2.069 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=2.056 (perp=7.647, rec=0.063, cos=0.464), tot_loss_proj:2.055 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=2.046 (perp=7.647, rec=0.053, cos=0.464), tot_loss_proj:2.051 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=2.050 (perp=7.647, rec=0.057, cos=0.464), tot_loss_proj:2.047 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.683 | p: 90.050 | r: 91.475
rouge2     | fm: 56.747 | p: 56.472 | r: 57.117
rougeL     | fm: 78.621 | p: 78.097 | r: 79.377
rougeLsum  | fm: 78.773 | p: 78.183 | r: 79.464
r1fm+r2fm = 147.430

input #92 time: 0:08:43 | total time: 13:40:50


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.7284170194514161
highest_index [0]
highest [0.7284170194514161]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 0.9398245215415955 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8869553208351135 for ['[CLS] taxi kang lookiled what mostchrome [SEP]']
[Init] best rec loss: 0.8827148079872131 for ['[CLS] scene attack humming working municipal attendant [MASK] [SEP]']
[Init] best rec loss: 0.8616113662719727 for ['[CLS] thousands fuel conditional scales progressed empowered mar [SEP]']
[Init] best perm rec loss: 0.8537186980247498 for ['[CLS] thousands fuel progressed mar empowered scales conditional [SEP]']
[Init] best perm rec loss: 0.853636622428894 for ['[CLS] thousands scales progressed empowered mar fuel conditional [SEP]']
[Init] best perm rec loss: 0.8514704704284668 for ['[CLS] empowered mar scales progressed conditional fuel thousands [SEP]']
[Init] best perm rec loss: 0.8483738303184509 for ['[CLS] empowered mar scales thousands progressed fuel conditional [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.328 (perp=12.754, rec=0.310, cos=0.467), tot_loss_proj:4.002 [t=0.22s]
prediction: ['[CLS] loving worker scales cultural political language educated [SEP]']
[ 100/2000] tot_loss=3.164 (perp=12.338, rec=0.228, cos=0.468), tot_loss_proj:3.283 [t=0.22s]
prediction: ['[CLS] way in funny understanding way tone thus [SEP]']
[ 150/2000] tot_loss=2.964 (perp=11.625, rec=0.172, cos=0.467), tot_loss_proj:3.672 [t=0.22s]
prediction: ['[CLS] way in in understanding way way perhaps [SEP]']
[ 200/2000] tot_loss=2.887 (perp=11.394, rec=0.140, cos=0.467), tot_loss_proj:3.226 [t=0.22s]
prediction: ['[CLS] way in in understanding way way often [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.586 (perp=9.948, rec=0.128, cos=0.468), tot_loss_proj:2.787 [t=0.22s]
prediction: ['[CLS] way in understanding funny in funny often [SEP]']
[ 300/2000] tot_loss=2.359 (perp=8.906, rec=0.109, cos=0.469), tot_loss_proj:2.561 [t=0.22s]
prediction: ['[CLS] way in understanding funny, funny often [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.199 (perp=8.133, rec=0.103, cos=0.469), tot_loss_proj:2.389 [t=0.22s]
prediction: ['[CLS] understanding in way funny, funny often [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.077 (perp=7.493, rec=0.111, cos=0.468), tot_loss_proj:2.266 [t=0.22s]
prediction: ['[CLS] understanding in its way funny, often [SEP]']
[ 450/2000] tot_loss=2.046 (perp=7.493, rec=0.079, cos=0.469), tot_loss_proj:2.259 [t=0.22s]
prediction: ['[CLS] understanding in its way funny, often [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.967 (perp=7.114, rec=0.076, cos=0.468), tot_loss_proj:2.247 [t=0.22s]
prediction: ['[CLS] understanding funny in its way, often [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.922 (perp=6.945, rec=0.066, cos=0.467), tot_loss_proj:2.153 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
[ 600/2000] tot_loss=1.932 (perp=6.945, rec=0.074, cos=0.469), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.929 (perp=6.945, rec=0.072, cos=0.469), tot_loss_proj:2.154 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.928 (perp=6.945, rec=0.070, cos=0.469), tot_loss_proj:2.159 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
[ 750/2000] tot_loss=1.917 (perp=6.945, rec=0.059, cos=0.469), tot_loss_proj:2.153 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.930 (perp=6.945, rec=0.072, cos=0.469), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.920 (perp=6.945, rec=0.062, cos=0.469), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
[ 900/2000] tot_loss=1.927 (perp=6.945, rec=0.069, cos=0.469), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.920 (perp=6.945, rec=0.062, cos=0.469), tot_loss_proj:2.156 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1000/2000] tot_loss=1.908 (perp=6.945, rec=0.050, cos=0.469), tot_loss_proj:2.155 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
[1050/2000] tot_loss=1.925 (perp=6.945, rec=0.066, cos=0.469), tot_loss_proj:2.152 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1100/2000] tot_loss=1.926 (perp=6.945, rec=0.067, cos=0.469), tot_loss_proj:2.149 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1150/2000] tot_loss=1.926 (perp=6.945, rec=0.068, cos=0.469), tot_loss_proj:2.159 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
[1200/2000] tot_loss=1.918 (perp=6.945, rec=0.060, cos=0.469), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1250/2000] tot_loss=1.927 (perp=6.945, rec=0.069, cos=0.469), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1300/2000] tot_loss=1.926 (perp=6.945, rec=0.068, cos=0.469), tot_loss_proj:2.149 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
[1350/2000] tot_loss=1.930 (perp=6.945, rec=0.072, cos=0.469), tot_loss_proj:2.152 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1400/2000] tot_loss=1.918 (perp=6.945, rec=0.060, cos=0.469), tot_loss_proj:2.158 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1450/2000] tot_loss=1.917 (perp=6.945, rec=0.059, cos=0.469), tot_loss_proj:2.153 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
[1500/2000] tot_loss=1.920 (perp=6.945, rec=0.062, cos=0.469), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1550/2000] tot_loss=1.922 (perp=6.945, rec=0.064, cos=0.469), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1600/2000] tot_loss=1.927 (perp=6.945, rec=0.069, cos=0.469), tot_loss_proj:2.156 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
[1650/2000] tot_loss=1.917 (perp=6.945, rec=0.059, cos=0.469), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1700/2000] tot_loss=1.924 (perp=6.945, rec=0.066, cos=0.469), tot_loss_proj:2.161 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1750/2000] tot_loss=1.922 (perp=6.945, rec=0.064, cos=0.469), tot_loss_proj:2.152 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
[1800/2000] tot_loss=1.929 (perp=6.945, rec=0.071, cos=0.469), tot_loss_proj:2.150 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1850/2000] tot_loss=1.931 (perp=6.945, rec=0.073, cos=0.469), tot_loss_proj:2.158 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[1900/2000] tot_loss=1.928 (perp=6.945, rec=0.070, cos=0.469), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
[1950/2000] tot_loss=1.926 (perp=6.945, rec=0.068, cos=0.469), tot_loss_proj:2.155 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Attempt swap
[2000/2000] tot_loss=1.928 (perp=6.945, rec=0.070, cos=0.469), tot_loss_proj:2.154 [t=0.22s]
prediction: ['[CLS] often funny in its way, understanding [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] often funny in its way, understanding [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 128.571

[Aggregate metrics]:
rouge1     | fm: 90.829 | p: 90.206 | r: 91.619
rouge2     | fm: 56.482 | p: 56.178 | r: 56.845
rougeL     | fm: 78.485 | p: 77.911 | r: 79.151
rougeLsum  | fm: 78.606 | p: 78.007 | r: 79.222
r1fm+r2fm = 147.311

input #93 time: 0:08:45 | total time: 13:49:35


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.7097091257982329
highest_index [0]
highest [0.7097091257982329]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9458468556404114 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9441221356391907 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9253466725349426 for ['[CLS] milling library casual constructed board equationphs similaron cookies intended [SEP]']
[Init] best rec loss: 0.9243903756141663 for ['[CLS] scent crosses am history single connections set likeuatingface other [SEP]']
[Init] best rec loss: 0.922167181968689 for ['[CLS] same traumatic to blessing surface pac cell carmeter environment sigh [SEP]']
[Init] best rec loss: 0.911161482334137 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9053882360458374 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.901839017868042 for ['[CLS] barber eithertype roador motivefirm trusted ednaack wanted [SEP]']
[Init] best perm rec loss: 0.9018359184265137 for ['[CLS]firm edna eithertypeack barber road wanted trusted motiveor [SEP]']
[Init] best perm rec loss: 0.9014655351638794 for ['[CLS]type road wanted barber motive trustedackfirm edna eitheror [SEP]']
[Init] best perm rec loss: 0.9013640880584717 for ['[CLS] roadack trusted motive edna wanted barber eithertypeorfirm [SEP]']
[Init] best perm rec loss: 0.9007830619812012 for ['[CLS] barberfirmack edna either trusted wantedtypeor motive road [SEP]']
[Init] best perm rec loss: 0.9003406167030334 for ['[CLS] trusted barber wanted ednaacktype either motiveor roadfirm [SEP]']
[Init] best perm rec loss: 0.8990347385406494 for ['[CLS] motive roadtype wantedack either barber ednafirm trustedor [SEP]']
[Init] best perm rec loss: 0.8980545401573181 for ['[CLS] wanted road motive edna trustedack eitherortype barberfirm [SEP]']
[Init] best perm rec loss: 0.8973652720451355 for ['[CLS] road barberfirmor trusted wanted motiveack edna eithertype [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.751 (perp=13.334, rec=0.604, cos=0.480), tot_loss_proj:4.588 [t=0.22s]
prediction: ['[CLS] buenos emphasisis a na andre walt wherever deliver borders lesbian [SEP]']
[ 100/2000] tot_loss=3.711 (perp=12.991, rec=0.554, cos=0.559), tot_loss_proj:4.094 [t=0.22s]
prediction: ['[CLS]urity noris neitheruous greatly though bigger originally no cape [SEP]']
[ 150/2000] tot_loss=3.365 (perp=12.395, rec=0.489, cos=0.397), tot_loss_proj:4.410 [t=0.22s]
prediction: ['[CLS] wonderful neitheris an original neither bluffrmed originally neither cape [SEP]']
[ 200/2000] tot_loss=2.998 (perp=11.100, rec=0.455, cos=0.323), tot_loss_proj:4.226 [t=0.22s]
prediction: ['[CLS] wonderful neithert an original nor bluff fledged funny neither cape [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.282 (perp=12.648, rec=0.445, cos=0.307), tot_loss_proj:3.870 [t=0.22s]
prediction: ['[CLS] whether neither by neither original neither bluff funny neitheronzo cape [SEP]']
[ 300/2000] tot_loss=3.422 (perp=11.439, rec=0.373, cos=0.760), tot_loss_proj:3.437 [t=0.22s]
prediction: ['[CLS] terribly neither original neither original nor fix cape neithereborg funny [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.733 (perp=14.044, rec=0.434, cos=0.490), tot_loss_proj:4.012 [t=0.22s]
prediction: ['[CLS] nothing laugh appearing a nothing original neither ₹ originally neithererson [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.036 (perp=11.021, rec=0.351, cos=0.482), tot_loss_proj:3.705 [t=0.22s]
prediction: ['[CLS] a laugh nor nothing nothing original neither horror originally neither nipple [SEP]']
[ 450/2000] tot_loss=3.342 (perp=12.786, rec=0.305, cos=0.481), tot_loss_proj:4.209 [t=0.22s]
prediction: ['[CLS] a laugh nor neither neither original neither horror original neither wash [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.801 (perp=10.168, rec=0.286, cos=0.481), tot_loss_proj:3.359 [t=0.22s]
prediction: ['[CLS] a original neither neither original neither look nor original neither wash [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.714 (perp=9.835, rec=0.266, cos=0.481), tot_loss_proj:3.017 [t=0.22s]
prediction: ['[CLS] a terribly neither neither original neither original nor original neither∆ [SEP]']
[ 600/2000] tot_loss=3.038 (perp=11.500, rec=0.255, cos=0.483), tot_loss_proj:3.382 [t=0.22s]
prediction: ['[CLS] a terribly neither neither original neither funny nor cape neither∆ [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.809 (perp=10.286, rec=0.263, cos=0.488), tot_loss_proj:3.106 [t=0.22s]
prediction: ['[CLS] neither a terribly neither neither original neither funny nor cape∆ [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.675 (perp=9.705, rec=0.244, cos=0.489), tot_loss_proj:2.970 [t=0.22s]
prediction: ['[CLS] neither a terribly neither neither original nor neither funny cape∆ [SEP]']
[ 750/2000] tot_loss=2.703 (perp=9.903, rec=0.235, cos=0.488), tot_loss_proj:3.014 [t=0.22s]
prediction: ['[CLS] neither a terribly neither neither original nor neither funny cape funny [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.735 (perp=10.078, rec=0.233, cos=0.487), tot_loss_proj:3.065 [t=0.22s]
prediction: ['[CLS] neither a neither neither original nor neither funny cape terribly rabbi [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.406 (perp=8.463, rec=0.226, cos=0.487), tot_loss_proj:2.785 [t=0.22s]
prediction: ['[CLS] neither a neither neither original funny nor neither cape terribly funny [SEP]']
[ 900/2000] tot_loss=2.410 (perp=8.463, rec=0.230, cos=0.487), tot_loss_proj:2.786 [t=0.22s]
prediction: ['[CLS] neither a neither neither original funny nor neither cape terribly funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.449 (perp=8.693, rec=0.224, cos=0.486), tot_loss_proj:2.791 [t=0.22s]
prediction: ['[CLS] nor a neither neither original funny nor neither cape terribly funny [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.403 (perp=8.506, rec=0.216, cos=0.486), tot_loss_proj:2.712 [t=0.22s]
prediction: ['[CLS] i neither a neither original funny nor neither cape terribly funny [SEP]']
[1050/2000] tot_loss=2.397 (perp=8.506, rec=0.210, cos=0.486), tot_loss_proj:2.708 [t=0.22s]
prediction: ['[CLS] i neither a neither original funny nor neither cape terribly funny [SEP]']
Attempt swap
[1100/2000] tot_loss=2.403 (perp=8.506, rec=0.217, cos=0.485), tot_loss_proj:2.716 [t=0.22s]
prediction: ['[CLS] i neither a neither original funny nor neither cape terribly funny [SEP]']
Attempt swap
[1150/2000] tot_loss=2.404 (perp=8.506, rec=0.218, cos=0.485), tot_loss_proj:2.713 [t=0.22s]
prediction: ['[CLS] i neither a neither original funny nor neither cape terribly funny [SEP]']
[1200/2000] tot_loss=2.393 (perp=8.506, rec=0.207, cos=0.485), tot_loss_proj:2.714 [t=0.22s]
prediction: ['[CLS] i neither a neither original funny nor neither cape terribly funny [SEP]']
Attempt swap
[1250/2000] tot_loss=2.389 (perp=8.506, rec=0.204, cos=0.484), tot_loss_proj:2.708 [t=0.22s]
prediction: ['[CLS] i neither a neither original funny nor neither cape terribly funny [SEP]']
Attempt swap
[1300/2000] tot_loss=2.378 (perp=8.506, rec=0.193, cos=0.484), tot_loss_proj:2.713 [t=0.22s]
prediction: ['[CLS] i neither a neither original funny nor neither cape terribly funny [SEP]']
[1350/2000] tot_loss=2.422 (perp=8.726, rec=0.194, cos=0.484), tot_loss_proj:2.894 [t=0.22s]
prediction: ['[CLS] i nor a neither original funny nor neither cape terribly funny [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.238 (perp=7.781, rec=0.198, cos=0.485), tot_loss_proj:2.602 [t=0.22s]
prediction: ['[CLS] neither i nor a neither original funny nor cape terribly funny [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.231 (perp=7.719, rec=0.202, cos=0.485), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS] neither i nor a original neither funny nor cape terribly funny [SEP]']
[1500/2000] tot_loss=2.227 (perp=7.719, rec=0.198, cos=0.485), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] neither i nor a original neither funny nor cape terribly funny [SEP]']
Attempt swap
[1550/2000] tot_loss=2.214 (perp=7.719, rec=0.185, cos=0.485), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS] neither i nor a original neither funny nor cape terribly funny [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.056 (perp=6.833, rec=0.203, cos=0.486), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] neither i nor a cape original neither funny nor terribly funny [SEP]']
[1650/2000] tot_loss=2.038 (perp=6.833, rec=0.183, cos=0.488), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] neither i nor a cape original neither funny nor terribly funny [SEP]']
Attempt swap
[1700/2000] tot_loss=2.048 (perp=6.833, rec=0.193, cos=0.488), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] neither i nor a cape original neither funny nor terribly funny [SEP]']
Attempt swap
[1750/2000] tot_loss=2.033 (perp=6.833, rec=0.179, cos=0.487), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] neither i nor a cape original neither funny nor terribly funny [SEP]']
[1800/2000] tot_loss=2.032 (perp=6.833, rec=0.178, cos=0.487), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] neither i nor a cape original neither funny nor terribly funny [SEP]']
Attempt swap
[1850/2000] tot_loss=2.040 (perp=6.833, rec=0.186, cos=0.487), tot_loss_proj:2.360 [t=0.22s]
prediction: ['[CLS] neither i nor a cape original neither funny nor terribly funny [SEP]']
Attempt swap
[1900/2000] tot_loss=2.036 (perp=6.833, rec=0.182, cos=0.487), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] neither i nor a cape original neither funny nor terribly funny [SEP]']
[1950/2000] tot_loss=2.029 (perp=6.833, rec=0.176, cos=0.487), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] neither i nor a cape original neither funny nor terribly funny [SEP]']
Attempt swap
[2000/2000] tot_loss=2.035 (perp=6.833, rec=0.182, cos=0.487), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] neither i nor a cape original neither funny nor terribly funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] neither i nor a cape original neither funny nor terribly funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 61.538 | r: 72.727
rouge2     | fm: 27.273 | p: 25.000 | r: 30.000
rougeL     | fm: 58.333 | p: 53.846 | r: 63.636
rougeLsum  | fm: 58.333 | p: 53.846 | r: 63.636
r1fm+r2fm = 93.939

[Aggregate metrics]:
rouge1     | fm: 90.506 | p: 89.827 | r: 91.417
rouge2     | fm: 56.149 | p: 55.849 | r: 56.580
rougeL     | fm: 78.261 | p: 77.730 | r: 78.956
rougeLsum  | fm: 78.400 | p: 77.807 | r: 79.118
r1fm+r2fm = 146.655

input #94 time: 0:08:46 | total time: 13:58:21


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.7071657372330132
highest_index [0]
highest [0.7071657372330132]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 1.0201530456542969 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 1.011502981185913 for ['[CLS] reprinted geographic fairchild clary remains hitler tristanved thumb big hot dates muscle commander funding [SEP]']
[Init] best rec loss: 0.9865649342536926 for ['[CLS]nahley hair see nedra logan offices fourth sethgical recommended side laughdran auxiliary [SEP]']
[Init] best rec loss: 0.9818709492683411 for ['[CLS] sooner rue " pace leagues della smell sul epithet greenon power local concacaf relay [SEP]']
[Init] best rec loss: 0.967599093914032 for ['[CLS] footprint brain arrival rec [MASK] 45 reverse if pal struggled spanning caleb born day classic [SEP]']
[Init] best rec loss: 0.9670276641845703 for ['[CLS] gas somewhereator bulk aka unlessssee actual como deliver? jockuble occasion [SEP]']
[Init] best perm rec loss: 0.9666751623153687 for ['[CLS]ssee jock occasion deliver comou aka bulkble gas? unlessator somewhere actual [SEP]']
[Init] best perm rec loss: 0.9664778113365173 for ['[CLS] jockatoru?ssee bulk deliver unless actual como occasion akable somewhere gas [SEP]']
[Init] best perm rec loss: 0.9663659334182739 for ['[CLS] gas? somewhere akaatorsseeuble bulk actual unless jock occasion deliver como [SEP]']
[Init] best perm rec loss: 0.9654214978218079 for ['[CLS]sseeu como gasator unless bulk somewhere occasionble jock deliver actual? aka [SEP]']
[Init] best perm rec loss: 0.9638233184814453 for ['[CLS] actualator unless gas comoble deliver somewhere bulk? jock occasion akaussee [SEP]']
[Init] best perm rec loss: 0.9631797671318054 for ['[CLS] como gasator unless jock aka actualu somewhere deliverble? occasion bulkssee [SEP]']
[Init] best perm rec loss: 0.9626727104187012 for ['[CLS]u somewhereble? gas actual deliver occasion aka jockatorssee bulk como unless [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.166 (perp=15.289, rec=0.603, cos=0.506), tot_loss_proj:4.918 [t=0.22s]
prediction: ['[CLS]ted crystal several copied celebration twain balanceθ° shortly struggling respectively pe er assistant [SEP]']
[ 100/2000] tot_loss=3.851 (perp=14.027, rec=0.582, cos=0.464), tot_loss_proj:4.734 [t=0.22s]
prediction: ['[CLS] ; - una kashmir celebrates twain norris situationfest andersonignant respectivelyvat hopelessdle [SEP]']
[ 150/2000] tot_loss=3.449 (perp=12.449, rec=0.474, cos=0.486), tot_loss_proj:3.989 [t=0.22s]
prediction: ['[CLS], becomes renamed hopeless charity prize challenges ª hopeless illuminated hopeless becameudes becomedle [SEP]']
[ 200/2000] tot_loss=3.679 (perp=13.388, rec=0.501, cos=0.501), tot_loss_proj:4.534 [t=0.22s]
prediction: ['[CLS]. becomes arrived mental traditional wars mystery ª ( utility sittingnburgudes hopelessdle [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.682 (perp=13.624, rec=0.473, cos=0.485), tot_loss_proj:4.309 [t=0.23s]
prediction: ['[CLS] into becomes hopeless mental traditional hopeless crimean ªgoldzily sat blissudes arrivesdle [SEP]']
[ 300/2000] tot_loss=3.634 (perp=13.851, rec=0.444, cos=0.420), tot_loss_proj:3.962 [t=0.22s]
prediction: ['[CLS]. becomes hopeless mental traditional universe difficult ª hopelesszily hopeless gabled della arrivesdle [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.770 (perp=13.528, rec=0.572, cos=0.493), tot_loss_proj:4.350 [t=0.22s]
prediction: ['[CLS]. hopeless mental traditional universe challenges becomes reddishgold〈 hopeless gabled della arrivesdle [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.184 (perp=11.843, rec=0.423, cos=0.393), tot_loss_proj:3.829 [t=0.22s]
prediction: ["[CLS]. hopeless hopeless challenges universe traditional becomes ª hopeless africans hopeless becomes ₗ 'dle [SEP]"]
[ 450/2000] tot_loss=3.303 (perp=12.860, rec=0.404, cos=0.327), tot_loss_proj:4.376 [t=0.22s]
prediction: ["[CLS]. hopeless hopeless challenges stories celebrates becomes acquired hopelessization hopeless becomescating 'dle [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.514 (perp=13.482, rec=0.385, cos=0.433), tot_loss_proj:4.217 [t=0.22s]
prediction: ['[CLS]. hopeless hopeless crimean stories celebrates becomes acquired hopelessizationnburg hopeless prey moleculesdle [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.217 (perp=12.403, rec=0.369, cos=0.367), tot_loss_proj:3.843 [t=0.22s]
prediction: ['[CLS], hopeless hopeless stories crimean celebrates becomes acquired hopelessization becomes hopeless prey moleculesdle [SEP]']
[ 600/2000] tot_loss=3.388 (perp=12.674, rec=0.381, cos=0.473), tot_loss_proj:3.813 [t=0.22s]
prediction: ['[CLS], hopeless hopelessgame crimean celebrates becomes acquired hopeless becomes becomes hopeless prey moleculesdle [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.575 (perp=13.412, rec=0.346, cos=0.546), tot_loss_proj:3.808 [t=0.22s]
prediction: ['[CLS] un hopeless hopeless crimean celebratesgame becomes acquired hopelesszily becomes hopelesssat moleculesdle [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.364 (perp=12.628, rec=0.353, cos=0.485), tot_loss_proj:3.790 [t=0.22s]
prediction: ['[CLS] un hopeless hopeless crimean celebratesgame becomes hopeless acquired hopeless itunes becomessat moleculesdle [SEP]']
[ 750/2000] tot_loss=3.058 (perp=12.375, rec=0.351, cos=0.232), tot_loss_proj:3.575 [t=0.22s]
prediction: ['[CLS], hopeless hopeless crimean celebratesgame becomes hopeless acquired hopelesszily becomessat moleculesdle [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.135 (perp=11.482, rec=0.326, cos=0.512), tot_loss_proj:3.395 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless became )game becomes hopeless acquired hopelesszily becomessat moleculesdle [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.264 (perp=11.632, rec=0.327, cos=0.611), tot_loss_proj:3.406 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless histoire becamegame becomes hopeless acquired hopelesszily becomessat moleculesdle [SEP]']
[ 900/2000] tot_loss=3.144 (perp=11.961, rec=0.320, cos=0.433), tot_loss_proj:3.549 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless explores becamegame becomes hopeless acquired hopelessgical becomessat moleculesdle [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.211 (perp=11.889, rec=0.358, cos=0.475), tot_loss_proj:3.581 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless explores became hopeless becomes hopeless acquired cerambycidae tired becomessat moleculesdle [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.061 (perp=11.453, rec=0.334, cos=0.436), tot_loss_proj:3.563 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless explores became hopeless becomes hopeless acquired cerambycidae molecules becomessatzilydle [SEP]']
[1050/2000] tot_loss=3.058 (perp=11.705, rec=0.321, cos=0.396), tot_loss_proj:3.514 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless explores became hopeless becomes hopeless acquiredgame molecules becomessatzilydle [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.988 (perp=10.918, rec=0.324, cos=0.481), tot_loss_proj:3.339 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatzilydle [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.892 (perp=10.650, rec=0.318, cos=0.444), tot_loss_proj:3.310 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
[1200/2000] tot_loss=2.849 (perp=10.650, rec=0.316, cos=0.403), tot_loss_proj:3.308 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Attempt swap
[1250/2000] tot_loss=2.824 (perp=10.650, rec=0.312, cos=0.383), tot_loss_proj:3.300 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Attempt swap
[1300/2000] tot_loss=2.920 (perp=10.650, rec=0.314, cos=0.477), tot_loss_proj:3.310 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
[1350/2000] tot_loss=2.922 (perp=10.650, rec=0.305, cos=0.487), tot_loss_proj:3.302 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Attempt swap
[1400/2000] tot_loss=2.872 (perp=10.650, rec=0.304, cos=0.437), tot_loss_proj:3.303 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Attempt swap
[1450/2000] tot_loss=2.872 (perp=10.650, rec=0.314, cos=0.428), tot_loss_proj:3.307 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
[1500/2000] tot_loss=2.901 (perp=10.650, rec=0.304, cos=0.467), tot_loss_proj:3.302 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Attempt swap
[1550/2000] tot_loss=2.850 (perp=10.650, rec=0.308, cos=0.411), tot_loss_proj:3.306 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Attempt swap
[1600/2000] tot_loss=2.898 (perp=10.650, rec=0.305, cos=0.464), tot_loss_proj:3.307 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
[1650/2000] tot_loss=2.836 (perp=10.650, rec=0.299, cos=0.407), tot_loss_proj:3.307 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Attempt swap
[1700/2000] tot_loss=2.876 (perp=10.650, rec=0.300, cos=0.446), tot_loss_proj:3.313 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Attempt swap
[1750/2000] tot_loss=2.945 (perp=10.650, rec=0.295, cos=0.520), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
[1800/2000] tot_loss=2.896 (perp=10.650, rec=0.297, cos=0.470), tot_loss_proj:3.314 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Attempt swap
[1850/2000] tot_loss=2.886 (perp=10.650, rec=0.305, cos=0.451), tot_loss_proj:3.301 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Attempt swap
[1900/2000] tot_loss=2.894 (perp=10.650, rec=0.296, cos=0.468), tot_loss_proj:3.299 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
[1950/2000] tot_loss=2.939 (perp=10.650, rec=0.296, cos=0.512), tot_loss_proj:3.305 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Attempt swap
[2000/2000] tot_loss=2.898 (perp=10.650, rec=0.303, cos=0.465), tot_loss_proj:3.300 [t=0.22s]
prediction: ['[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] hopeless, hopeless ) became hopeless becomes hopeless acquired moleculesgame becomessatdlezily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 36.364 | r: 44.444
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 36.364 | r: 44.444
rougeLsum  | fm: 40.000 | p: 36.364 | r: 44.444
r1fm+r2fm = 40.000

[Aggregate metrics]:
rouge1     | fm: 89.994 | p: 89.264 | r: 90.937
rouge2     | fm: 55.385 | p: 55.047 | r: 55.770
rougeL     | fm: 77.818 | p: 77.206 | r: 78.621
rougeLsum  | fm: 77.877 | p: 77.269 | r: 78.682
r1fm+r2fm = 145.379

input #95 time: 0:08:52 | total time: 14:07:13


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.7237138213403975
highest_index [0]
highest [0.7237138213403975]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8268527984619141 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8156478404998779 for ['[CLS] at townland panel subjects latter board vidhan tang general honor majestysse spared homes rider [SEP]']
[Init] best rec loss: 0.8008497357368469 for ['[CLS] robinson fits fr home professor shanghai virgin firing inside machlmancize arm decade [SEP]']
[Init] best rec loss: 0.7851830720901489 for ['[CLS] class error portoizedtler riverside 7nsis deedret via protection corporation whether selection [SEP]']
[Init] best rec loss: 0.7733612060546875 for ['[CLS] interviews screwed podcast ？ 8 sunset effects era too oath sunk chief between capcom master [SEP]']
[Init] best rec loss: 0.7722195386886597 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best rec loss: 0.7710143327713013 for ['[CLS]rg woken became jenny marx further league performance union holding winning instrumental re distance conscious [SEP]']
[Init] best rec loss: 0.7546273469924927 for ['[CLS] foreign x universalhausen ant southeast leave brands ascent perpendicular are article holding wrestling capability [SEP]']
[Init] best perm rec loss: 0.7517704367637634 for ['[CLS] ant universal foreign holding x ascent southeast are capability perpendicular wrestling article leave brandshausen [SEP]']
[Init] best perm rec loss: 0.7513759732246399 for ['[CLS] southeast capability article perpendicular wrestling ascent holding leave foreign are ant brandshausen x universal [SEP]']
[Init] best perm rec loss: 0.7512194514274597 for ['[CLS] wrestling are capability southeast ant brands x holding universal leave foreign ascent perpendicularhausen article [SEP]']
[Init] best perm rec loss: 0.7505311965942383 for ['[CLS] capability are southeast holding leave perpendicular ant ascent wrestling brandshausen universal foreign article x [SEP]']
[Init] best perm rec loss: 0.7503371834754944 for ['[CLS] are brands article foreign ascent southeasthausen capability universal x wrestling leave perpendicular holding ant [SEP]']
[Init] best perm rec loss: 0.7500069737434387 for ['[CLS] x article ant southeast leave ascent brands wrestling foreign universal holdinghausen are perpendicular capability [SEP]']
[Init] best perm rec loss: 0.7473313212394714 for ['[CLS] foreignhausen southeast ascent are x article brands wrestling perpendicular holding capability universal ant leave [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.188 (perp=12.127, rec=0.311, cos=0.452), tot_loss_proj:4.249 [t=0.22s]
prediction: ['[CLS]verse himself force on lesser get sounds. domestic less situations start nas contact into [SEP]']
[ 100/2000] tot_loss=2.668 (perp=9.995, rec=0.200, cos=0.470), tot_loss_proj:3.301 [t=0.22s]
prediction: ['[CLS] force himself force on lesser force people people handling lesser situations make men cover run [SEP]']
[ 150/2000] tot_loss=2.522 (perp=9.625, rec=0.123, cos=0.475), tot_loss_proj:3.332 [t=0.22s]
prediction: ['[CLS] force himself people on men force themselves people make lesser situations make for cover run [SEP]']
[ 200/2000] tot_loss=2.549 (perp=9.851, rec=0.112, cos=0.467), tot_loss_proj:3.253 [t=0.22s]
prediction: ['[CLS] force himself people on men force into people make lesser situations make for cover run [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.404 (perp=9.086, rec=0.110, cos=0.477), tot_loss_proj:3.387 [t=0.22s]
prediction: ['[CLS] force himself people on force men into people into lesser situations make for cover run [SEP]']
[ 300/2000] tot_loss=2.382 (perp=9.086, rec=0.092, cos=0.473), tot_loss_proj:3.394 [t=0.22s]
prediction: ['[CLS] force himself people on force men into people into lesser situations make for cover run [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.344 (perp=8.822, rec=0.105, cos=0.475), tot_loss_proj:3.216 [t=0.29s]
prediction: ['[CLS] force himself people on force men into people into lesser situations for cover make run [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.299 (perp=8.656, rec=0.094, cos=0.473), tot_loss_proj:3.024 [t=0.22s]
prediction: ['[CLS] force himself and on into men force people into lesser situations for cover make run [SEP]']
[ 450/2000] tot_loss=2.496 (perp=9.728, rec=0.076, cos=0.474), tot_loss_proj:3.293 [t=0.22s]
prediction: ['[CLS] force himself and on into men force people would lesser situations for cover make run [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.384 (perp=9.194, rec=0.070, cos=0.476), tot_loss_proj:3.042 [t=0.22s]
prediction: ['[CLS] force himself and on into men force people would run lesser situations for cover make [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.268 (perp=8.571, rec=0.080, cos=0.473), tot_loss_proj:2.882 [t=0.22s]
prediction: ['[CLS] force himself and on into force people would run lesser men situations for cover make [SEP]']
[ 600/2000] tot_loss=2.267 (perp=8.571, rec=0.077, cos=0.476), tot_loss_proj:2.891 [t=0.22s]
prediction: ['[CLS] force himself and on into force people would run lesser men situations for cover make [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.220 (perp=8.381, rec=0.070, cos=0.473), tot_loss_proj:2.848 [t=0.22s]
prediction: ['[CLS] force himself and on into force people would run lesser men make situations for cover [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.220 (perp=8.381, rec=0.069, cos=0.474), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS] force himself and on into force people would run lesser men make situations for cover [SEP]']
[ 750/2000] tot_loss=2.227 (perp=8.381, rec=0.076, cos=0.475), tot_loss_proj:2.848 [t=0.22s]
prediction: ['[CLS] force himself and on into force people would run lesser men make situations for cover [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.213 (perp=8.381, rec=0.062, cos=0.475), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS] force himself and on into force people would run lesser men make situations for cover [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.217 (perp=8.381, rec=0.066, cos=0.475), tot_loss_proj:2.841 [t=0.22s]
prediction: ['[CLS] force himself and on into force people would run lesser men make situations for cover [SEP]']
[ 900/2000] tot_loss=2.219 (perp=8.381, rec=0.068, cos=0.475), tot_loss_proj:2.841 [t=0.22s]
prediction: ['[CLS] force himself and on into force people would run lesser men make situations for cover [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.202 (perp=8.273, rec=0.074, cos=0.474), tot_loss_proj:2.708 [t=0.22s]
prediction: ['[CLS] force himself and on into force people would lesser men make situations run for cover [SEP]']
Attempt swap
[1000/2000] tot_loss=2.202 (perp=8.273, rec=0.071, cos=0.476), tot_loss_proj:2.704 [t=0.22s]
prediction: ['[CLS] force himself and on into force people would lesser men make situations run for cover [SEP]']
[1050/2000] tot_loss=2.195 (perp=8.273, rec=0.066, cos=0.475), tot_loss_proj:2.708 [t=0.22s]
prediction: ['[CLS] force himself and on into force people would lesser men make situations run for cover [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.171 (perp=8.166, rec=0.063, cos=0.475), tot_loss_proj:2.666 [t=0.22s]
prediction: ['[CLS] force himself and on into force people lesser men would make situations run for cover [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.134 (perp=7.989, rec=0.061, cos=0.475), tot_loss_proj:2.612 [t=0.22s]
prediction: ['[CLS] force himself and on into people force lesser men would make situations run for cover [SEP]']
[1200/2000] tot_loss=2.141 (perp=7.989, rec=0.068, cos=0.476), tot_loss_proj:2.614 [t=0.22s]
prediction: ['[CLS] force himself and on into people force lesser men would make situations run for cover [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.055 (perp=7.537, rec=0.074, cos=0.474), tot_loss_proj:2.540 [t=0.22s]
prediction: ['[CLS] on himself and force into people force lesser men would make situations run for cover [SEP]']
Attempt swap
[1300/2000] tot_loss=2.063 (perp=7.537, rec=0.079, cos=0.476), tot_loss_proj:2.544 [t=0.22s]
prediction: ['[CLS] on himself and force into people force lesser men would make situations run for cover [SEP]']
[1350/2000] tot_loss=2.055 (perp=7.537, rec=0.072, cos=0.475), tot_loss_proj:2.544 [t=0.22s]
prediction: ['[CLS] on himself and force into people force lesser men would make situations run for cover [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.029 (perp=7.445, rec=0.064, cos=0.476), tot_loss_proj:2.686 [t=0.22s]
prediction: ['[CLS] on himself and force force people into lesser men would make situations run for cover [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.996 (perp=7.289, rec=0.067, cos=0.471), tot_loss_proj:2.908 [t=0.22s]
prediction: ['[CLS] on himself and situations force people into lesser men would make force run for cover [SEP]']
[1500/2000] tot_loss=1.997 (perp=7.289, rec=0.064, cos=0.475), tot_loss_proj:2.910 [t=0.22s]
prediction: ['[CLS] on himself and situations force people into lesser men would make force run for cover [SEP]']
Attempt swap
[1550/2000] tot_loss=2.005 (perp=7.289, rec=0.072, cos=0.476), tot_loss_proj:2.908 [t=0.22s]
prediction: ['[CLS] on himself and situations force people into lesser men would make force run for cover [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.956 (perp=7.076, rec=0.066, cos=0.474), tot_loss_proj:2.852 [t=0.22s]
prediction: ['[CLS] on himself and situations force people into lesser force would make men run for cover [SEP]']
[1650/2000] tot_loss=1.963 (perp=7.076, rec=0.072, cos=0.476), tot_loss_proj:2.853 [t=0.22s]
prediction: ['[CLS] on himself and situations force people into lesser force would make men run for cover [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.872 (perp=6.678, rec=0.063, cos=0.474), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] on himself and force people into situations lesser force would make men run for cover [SEP]']
Attempt swap
[1750/2000] tot_loss=1.877 (perp=6.678, rec=0.067, cos=0.475), tot_loss_proj:2.330 [t=0.22s]
prediction: ['[CLS] on himself and force people into situations lesser force would make men run for cover [SEP]']
[1800/2000] tot_loss=1.876 (perp=6.678, rec=0.065, cos=0.475), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] on himself and force people into situations lesser force would make men run for cover [SEP]']
Attempt swap
[1850/2000] tot_loss=1.876 (perp=6.678, rec=0.065, cos=0.476), tot_loss_proj:2.335 [t=0.22s]
prediction: ['[CLS] on himself and force people into situations lesser force would make men run for cover [SEP]']
Attempt swap
[1900/2000] tot_loss=1.870 (perp=6.678, rec=0.059, cos=0.476), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] on himself and force people into situations lesser force would make men run for cover [SEP]']
[1950/2000] tot_loss=1.873 (perp=6.678, rec=0.062, cos=0.476), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] on himself and force people into situations lesser force would make men run for cover [SEP]']
Attempt swap
[2000/2000] tot_loss=1.877 (perp=6.678, rec=0.065, cos=0.476), tot_loss_proj:2.330 [t=0.22s]
prediction: ['[CLS] on himself and force people into situations lesser force would make men run for cover [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] on himself and force people into situations lesser force would make men run for cover [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 70.588 | p: 70.588 | r: 70.588
rougeLsum  | fm: 70.588 | p: 70.588 | r: 70.588
r1fm+r2fm = 131.618

[Aggregate metrics]:
rouge1     | fm: 90.066 | p: 89.395 | r: 90.945
rouge2     | fm: 55.197 | p: 54.870 | r: 55.590
rougeL     | fm: 77.794 | p: 77.101 | r: 78.625
rougeLsum  | fm: 77.831 | p: 77.237 | r: 78.648
r1fm+r2fm = 145.262

input #96 time: 0:08:51 | total time: 14:16:05


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.7326613973342755
highest_index [0]
highest [0.7326613973342755]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.7422130703926086 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.7189465761184692 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best perm rec loss: 0.7185015082359314 for ['[CLS] victoriaten test pass 2016 which [SEP]']
[Init] best perm rec loss: 0.7176026105880737 for ['[CLS]ten test pass victoria 2016 which [SEP]']
[Init] best perm rec loss: 0.7172312140464783 for ['[CLS]ten test which 2016 pass victoria [SEP]']
[Init] best perm rec loss: 0.7169539332389832 for ['[CLS] test pass 2016 victoria whichten [SEP]']
[Init] best perm rec loss: 0.7163521647453308 for ['[CLS] victoria test pass 2016 whichten [SEP]']
[Init] best perm rec loss: 0.714604377746582 for ['[CLS] test which 2016ten victoria pass [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.502 (perp=13.728, rec=0.271, cos=0.485), tot_loss_proj:4.594 [t=0.22s]
prediction: ['[CLS]nished peter characters unget characters [SEP]']
[ 100/2000] tot_loss=3.275 (perp=13.458, rec=0.126, cos=0.457), tot_loss_proj:4.251 [t=0.22s]
prediction: ['[CLS]tablefortable unget characters [SEP]']
[ 150/2000] tot_loss=3.239 (perp=13.458, rec=0.086, cos=0.461), tot_loss_proj:4.235 [t=0.22s]
prediction: ['[CLS]tablefortable unget characters [SEP]']
[ 200/2000] tot_loss=3.230 (perp=13.458, rec=0.077, cos=0.461), tot_loss_proj:4.198 [t=0.22s]
prediction: ['[CLS]tablefortable unget characters [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.366 (perp=9.103, rec=0.089, cos=0.457), tot_loss_proj:3.197 [t=0.22s]
prediction: ['[CLS]tableforget un and characters [SEP]']
[ 300/2000] tot_loss=2.357 (perp=9.103, rec=0.075, cos=0.462), tot_loss_proj:3.392 [t=0.22s]
prediction: ['[CLS]tableforget un and characters [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.646 (perp=5.514, rec=0.081, cos=0.462), tot_loss_proj:1.729 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.631 (perp=5.514, rec=0.066, cos=0.463), tot_loss_proj:1.721 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 450/2000] tot_loss=1.628 (perp=5.514, rec=0.062, cos=0.463), tot_loss_proj:1.735 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.637 (perp=5.514, rec=0.072, cos=0.463), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.634 (perp=5.514, rec=0.068, cos=0.463), tot_loss_proj:1.736 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 600/2000] tot_loss=1.634 (perp=5.514, rec=0.068, cos=0.463), tot_loss_proj:1.736 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.634 (perp=5.514, rec=0.068, cos=0.463), tot_loss_proj:1.730 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.635 (perp=5.514, rec=0.071, cos=0.462), tot_loss_proj:1.734 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 750/2000] tot_loss=1.631 (perp=5.514, rec=0.066, cos=0.463), tot_loss_proj:1.729 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.631 (perp=5.514, rec=0.066, cos=0.462), tot_loss_proj:1.723 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.627 (perp=5.514, rec=0.061, cos=0.463), tot_loss_proj:1.725 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 900/2000] tot_loss=1.629 (perp=5.514, rec=0.064, cos=0.463), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.589 (perp=5.309, rec=0.065, cos=0.462), tot_loss_proj:1.582 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.587 (perp=5.309, rec=0.062, cos=0.463), tot_loss_proj:1.582 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1050/2000] tot_loss=1.586 (perp=5.309, rec=0.062, cos=0.463), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.588 (perp=5.309, rec=0.064, cos=0.463), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.586 (perp=5.309, rec=0.061, cos=0.463), tot_loss_proj:1.584 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1200/2000] tot_loss=1.582 (perp=5.309, rec=0.057, cos=0.463), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.585 (perp=5.309, rec=0.060, cos=0.463), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.584 (perp=5.309, rec=0.059, cos=0.463), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1350/2000] tot_loss=1.585 (perp=5.309, rec=0.061, cos=0.463), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.582 (perp=5.309, rec=0.057, cos=0.463), tot_loss_proj:1.599 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.572 (perp=5.309, rec=0.047, cos=0.463), tot_loss_proj:1.587 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1500/2000] tot_loss=1.592 (perp=5.309, rec=0.067, cos=0.463), tot_loss_proj:1.586 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.583 (perp=5.309, rec=0.059, cos=0.463), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.590 (perp=5.309, rec=0.065, cos=0.463), tot_loss_proj:1.594 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1650/2000] tot_loss=1.575 (perp=5.309, rec=0.050, cos=0.463), tot_loss_proj:1.583 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.586 (perp=5.309, rec=0.061, cos=0.463), tot_loss_proj:1.570 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.584 (perp=5.309, rec=0.060, cos=0.463), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1800/2000] tot_loss=1.588 (perp=5.309, rec=0.063, cos=0.463), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.592 (perp=5.309, rec=0.067, cos=0.463), tot_loss_proj:1.583 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.593 (perp=5.309, rec=0.068, cos=0.463), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1950/2000] tot_loss=1.583 (perp=5.309, rec=0.058, cos=0.463), tot_loss_proj:1.594 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.583 (perp=5.309, rec=0.058, cos=0.463), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.160 | p: 89.476 | r: 91.058
rouge2     | fm: 55.807 | p: 55.494 | r: 56.251
rougeL     | fm: 77.985 | p: 77.380 | r: 78.797
rougeLsum  | fm: 78.084 | p: 77.486 | r: 78.922
r1fm+r2fm = 145.968

input #97 time: 0:08:44 | total time: 14:24:49


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.7263336427648642
highest_index [0]
highest [0.7263336427648642]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.6556059122085571 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.6537508368492126 for ['[CLS] jed nos prohibited ada [SEP]']
[Init] best perm rec loss: 0.6513193249702454 for ['[CLS] jed ada nos prohibited [SEP]']
[Init] best perm rec loss: 0.6503732204437256 for ['[CLS] prohibited ada nos jed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.662 (perp=4.947, rec=0.207, cos=0.465), tot_loss_proj:1.531 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 100/2000] tot_loss=1.532 (perp=4.947, rec=0.074, cos=0.469), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 150/2000] tot_loss=1.544 (perp=4.947, rec=0.085, cos=0.470), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 200/2000] tot_loss=1.526 (perp=4.947, rec=0.066, cos=0.471), tot_loss_proj:1.525 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.527 (perp=4.947, rec=0.066, cos=0.472), tot_loss_proj:1.523 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.524 (perp=4.947, rec=0.062, cos=0.472), tot_loss_proj:1.535 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.527 (perp=4.947, rec=0.069, cos=0.468), tot_loss_proj:1.532 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.512 (perp=4.947, rec=0.051, cos=0.472), tot_loss_proj:1.525 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.526 (perp=4.947, rec=0.065, cos=0.471), tot_loss_proj:1.525 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.515 (perp=4.947, rec=0.054, cos=0.472), tot_loss_proj:1.527 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.503 (perp=4.947, rec=0.043, cos=0.471), tot_loss_proj:1.514 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.510 (perp=4.947, rec=0.052, cos=0.468), tot_loss_proj:1.514 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.531 (perp=4.947, rec=0.069, cos=0.472), tot_loss_proj:1.529 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.520 (perp=4.947, rec=0.059, cos=0.472), tot_loss_proj:1.522 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.521 (perp=4.947, rec=0.060, cos=0.471), tot_loss_proj:1.518 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.511 (perp=4.947, rec=0.049, cos=0.472), tot_loss_proj:1.530 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.516 (perp=4.947, rec=0.055, cos=0.472), tot_loss_proj:1.538 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.517 (perp=4.947, rec=0.056, cos=0.472), tot_loss_proj:1.525 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.514 (perp=4.947, rec=0.053, cos=0.472), tot_loss_proj:1.524 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.512 (perp=4.947, rec=0.050, cos=0.472), tot_loss_proj:1.535 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.521 (perp=4.947, rec=0.061, cos=0.470), tot_loss_proj:1.528 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.520 (perp=4.947, rec=0.058, cos=0.472), tot_loss_proj:1.532 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.516 (perp=4.947, rec=0.055, cos=0.472), tot_loss_proj:1.512 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.522 (perp=4.947, rec=0.061, cos=0.472), tot_loss_proj:1.521 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.524 (perp=4.947, rec=0.064, cos=0.471), tot_loss_proj:1.523 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.523 (perp=4.947, rec=0.061, cos=0.472), tot_loss_proj:1.519 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.531 (perp=4.947, rec=0.069, cos=0.472), tot_loss_proj:1.527 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.519 (perp=4.947, rec=0.058, cos=0.471), tot_loss_proj:1.519 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.528 (perp=4.947, rec=0.067, cos=0.472), tot_loss_proj:1.530 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.528 (perp=4.947, rec=0.066, cos=0.472), tot_loss_proj:1.516 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.521 (perp=4.947, rec=0.061, cos=0.471), tot_loss_proj:1.528 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.525 (perp=4.947, rec=0.064, cos=0.472), tot_loss_proj:1.526 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.517 (perp=4.947, rec=0.055, cos=0.472), tot_loss_proj:1.524 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.528 (perp=4.947, rec=0.067, cos=0.472), tot_loss_proj:1.513 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.536 (perp=4.947, rec=0.074, cos=0.472), tot_loss_proj:1.520 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.521 (perp=4.947, rec=0.060, cos=0.472), tot_loss_proj:1.514 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.523 (perp=4.947, rec=0.061, cos=0.472), tot_loss_proj:1.517 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.511 (perp=4.947, rec=0.049, cos=0.472), tot_loss_proj:1.522 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.518 (perp=4.947, rec=0.056, cos=0.472), tot_loss_proj:1.533 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.525 (perp=4.947, rec=0.064, cos=0.472), tot_loss_proj:1.516 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.244 | p: 89.574 | r: 91.144
rouge2     | fm: 56.261 | p: 55.955 | r: 56.670
rougeL     | fm: 78.201 | p: 77.569 | r: 78.970
rougeLsum  | fm: 78.337 | p: 77.715 | r: 79.064
r1fm+r2fm = 146.505

input #98 time: 0:08:44 | total time: 14:33:34


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.742843225408038
highest_index [0]
highest [0.742843225408038]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.807054340839386 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.7947531938552856 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.7926802635192871 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.7613130807876587 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.756993293762207 for ['[CLS] imp then ratlogueathy mobile bun smoothe bran where heart thumbs principal aires & recently brig addison stands catalog alert abbottale leading switch as could which buy pony kid risk general spreadim [SEP]']
[Init] best rec loss: 0.7477779984474182 for ['[CLS] wat searched fits mckay german divide interpret sensory ajax from even during under skye pants ramlus except door wanted others same q same king ashton care lot confirmation buttonsmania caseston file evil absolute [SEP]']
[Init] best rec loss: 0.7344378232955933 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.7344375252723694 for ['[CLS] dental services synonym when slight cushion orient garcia barbie earliest distance bearing re still himself claire [MASK] forced opposedˈ ratings harper temps currently actually rightte ferns bet screensaging taste thunder knowledgets te [SEP]']
[Init] best perm rec loss: 0.731791079044342 for ['[CLS] cushion slight ratings currently harper [MASK] whents ferns screens te thunder taste bearing orient garcia bet forced services actually himself knowledge right earliestˈte temps claire dental opposed re stillaging synonym barbie distance [SEP]']
[Init] best perm rec loss: 0.7313452959060669 for ['[CLS] te dental earliest forcedtets ratings knowledgeˈ bet harper thunder when garcia synonym services claire orient [MASK] temps re barbie himself screens still slight currently actually cushionaging ferns taste distance opposed bearing right [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.437 (perp=11.995, rec=0.544, cos=0.494), tot_loss_proj:3.631 [t=0.23s]
prediction: ["[CLS] seemedxious them bought'fun divorce team villain nonsense registry fbi prison worst toileturity admit legislation di nedx creepy especially early inssing sometimes worst screen these / series anyway securitycuit letterman [SEP]"]
[ 100/2000] tot_loss=3.352 (perp=12.284, rec=0.454, cos=0.442), tot_loss_proj:3.704 [t=0.23s]
prediction: ['[CLS] seemed everything themrogate rank fun divorce evidence villain except registry military prison bad chicken abandoned legs congressional [SEP] dirt on smashed especially became intious soon huge screen these / series [ [SEP] pirates fast [SEP]']
[ 150/2000] tot_loss=3.303 (perp=12.356, rec=0.393, cos=0.439), tot_loss_proj:3.726 [t=0.24s]
prediction: ['[CLS] seemed everything them concerned rank fun waste evidence reallyenting registry military stake bad finally abandoned trees congressional [SEP] dirt on forensic especially became intious soon huge screen these expert series [dan pirates fast [SEP]']
[ 200/2000] tot_loss=3.275 (perp=12.370, rec=0.357, cos=0.443), tot_loss_proj:3.844 [t=0.24s]
prediction: ['[CLS] seemed everything them somebody rank fun tax system really polish drug military stake bad finally abandoned trees congressional [SEP] dirt on forensic especially early intious soon huge screen these / series unfortunately funhora fast [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.002 (perp=11.135, rec=0.334, cos=0.441), tot_loss_proj:3.738 [t=0.24s]
prediction: ['[CLS] got everything was concerned rank fun tax system really polish loan military stake bad surely. trees congressional di dirt on doom especially early intious night pirates soon huge screen these / series unfortunately fast [SEP]']
[ 300/2000] tot_loss=2.880 (perp=10.658, rec=0.311, cos=0.438), tot_loss_proj:3.549 [t=0.24s]
prediction: ['[CLS] gotssing was concerned you fun fucking. really polish loan military stake bad surely. trees congressional di dirt on doom especially early intious night pirates soon huge ignore these / series unfortunately fast [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.830 (perp=10.510, rec=0.290, cos=0.438), tot_loss_proj:3.498 [t=0.23s]
prediction: ['[CLS] hadssing was concerned you fun fucking. nedra polish loan military stake bad thee. trees congressional sox dirt on doom especially early intious night / soon huge ignore these pirates series unfortunately fast [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.945 (perp=11.110, rec=0.286, cos=0.437), tot_loss_proj:3.688 [t=0.24s]
prediction: ['[CLS] hadssing was concerned you fun fucking. sorts except loan military stake dinner doomssing trees congressional sox dirt on imp especially early intious night / soon huge ignore these pirates series yeah fast [SEP]']
[ 450/2000] tot_loss=3.042 (perp=11.642, rec=0.279, cos=0.435), tot_loss_proj:3.871 [t=0.23s]
prediction: ['[CLS] hadssing was concerned you fun fucking. nedra except loan military stake dinner forensicssing trees congressional sox dirt on imp especially early intious night / soon huge ignore thesehora series yeah fast [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.016 (perp=11.538, rec=0.268, cos=0.440), tot_loss_proj:3.698 [t=0.24s]
prediction: ['[CLS] hadssing wasyle you fun horrible. really except loan foreign stake dinner forensicssing trees bill sox par on imp especially early intious night / soon ignore these huge pe series yeah fast [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.861 (perp=10.802, rec=0.268, cos=0.434), tot_loss_proj:3.767 [t=0.24s]
prediction: ['[CLS] hadssing theyle you fun horrible. di bad pe foreign stake dinner forensicssing trees bill sox par on imp film early intious night / soon ignore these huge loan series but joy [SEP]']
[ 600/2000] tot_loss=2.905 (perp=11.071, rec=0.255, cos=0.435), tot_loss_proj:3.555 [t=0.24s]
prediction: ['[CLS] hadssing the ) too fun horrible. di bad pe foreign stake dinner forensicssing trees bill sox par on imp film early intious night / soon ignore these huge loan series but fast [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.870 (perp=10.886, rec=0.253, cos=0.440), tot_loss_proj:3.510 [t=0.24s]
prediction: ['[CLS] hadssing too ) the fun horrible. di bad pe enforcement stake dinner forensicssing trees bill sox par on venture film early intious night / soon ignore these huge loan series but fast [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.851 (perp=10.837, rec=0.244, cos=0.439), tot_loss_proj:3.845 [t=0.23s]
prediction: ['[CLS] hadssing too ) the fun horrible. di bad pe trees stake dinner forensicssing enforcement rights sox par on venture film early intious night / soon lou these huge loan series but joy [SEP]']
[ 750/2000] tot_loss=2.889 (perp=11.055, rec=0.239, cos=0.439), tot_loss_proj:3.862 [t=0.24s]
prediction: ['[CLS] hadssing too ) the fun horrible. di bad pe trees stake dinner forensic abandoned courts bill sox par on di film early intious night / soon lou these huge loan stories but joy [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.844 (perp=10.789, rec=0.243, cos=0.444), tot_loss_proj:3.746 [t=0.24s]
prediction: ['[CLS] hadssing too ) the fun horrible. di bad pe " stake dinner forensic abandoned overseas bill sox film on [CLS] par early intious night / soon lou these huge loan series but joy [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.746 (perp=10.358, rec=0.240, cos=0.434), tot_loss_proj:3.659 [t=0.24s]
prediction: ['[CLS] hadssing too ) the fun horrible. di bad pe " stake dinner forensic film courts bill sox abandoned on [CLS] par early intious night / soon lou these huge loan series but joy [SEP]']
[ 900/2000] tot_loss=2.748 (perp=10.358, rec=0.235, cos=0.441), tot_loss_proj:3.655 [t=0.23s]
prediction: ['[CLS] hadssing too ) the fun horrible. di bad pe " stake dinner forensic film courts bill sox abandoned on [CLS] par early intious night / soon lou these huge loan series but joy [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.721 (perp=10.230, rec=0.231, cos=0.445), tot_loss_proj:3.734 [t=0.23s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad pe ) stake dinner forensic film courts bill soxssing on [CLS] par early intious night / soon less these huge loan series but joy [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.713 (perp=10.199, rec=0.230, cos=0.444), tot_loss_proj:3.725 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad pe ) stake dinner forensic film courts bill soxssing on [CLS] early in partious night / soon less these huge license series but joy [SEP]']
[1050/2000] tot_loss=2.742 (perp=10.374, rec=0.224, cos=0.444), tot_loss_proj:3.789 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad pe ) stake dinner forensic film courts bill soxssing on [CLS] early of partious night / soon two these huge license series but joy [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.714 (perp=10.262, rec=0.221, cos=0.441), tot_loss_proj:3.756 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad pe ) stake dinner forensic film courts bill soxssing on [CLS] early these partious night / soon two of huge license series but joy [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.730 (perp=10.317, rec=0.229, cos=0.437), tot_loss_proj:3.762 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad pe ) stake dinner forensic film bill soxssing on [CLS] early these courts partious film / soon less of huge license series but joy [SEP]']
[1200/2000] tot_loss=2.736 (perp=10.382, rec=0.220, cos=0.439), tot_loss_proj:3.731 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad pe ) stake bad forensic film rights soxssing onnology early these courts partious film / soon less of huge license series but joy [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.615 (perp=9.796, rec=0.221, cos=0.435), tot_loss_proj:3.281 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad the ) early bad forensic film rights soxssing onnology stake these courts partious film / soon less of huge license series but fast [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.611 (perp=9.768, rec=0.220, cos=0.438), tot_loss_proj:3.286 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad the ) early bad forensic film rights soxssing onnology stake these courts partious of film / soon less huge license series but fast [SEP]']
[1350/2000] tot_loss=2.599 (perp=9.768, rec=0.209, cos=0.437), tot_loss_proj:3.282 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad the ) early bad forensic film rights soxssing onnology stake these courts partious of film / soon less huge license series but fast [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.615 (perp=9.844, rec=0.209, cos=0.437), tot_loss_proj:3.239 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad early ) the bad forensic film rights soxssing on [CLS] stake these courts partious of film / soon less huge license series but fast [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.612 (perp=9.813, rec=0.210, cos=0.439), tot_loss_proj:3.228 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad early ) the bad forensic film rights soxssing on [CLS] stake par these courtstious of film / soon less huge license series but fast [SEP]']
[1500/2000] tot_loss=2.610 (perp=9.813, rec=0.211, cos=0.437), tot_loss_proj:3.227 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad early ) the bad forensic film rights soxssing on [CLS] stake par these courtstious of film / soon less huge license series but fast [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.574 (perp=9.654, rec=0.203, cos=0.440), tot_loss_proj:3.282 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible. di bad ) the bad forensic film rights soxssing early onnology stake par these courtstious of film / soon less huge the series but fast [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.595 (perp=9.704, rec=0.211, cos=0.443), tot_loss_proj:3.214 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible bad di. ) the bad forensic film rights soxssing early onnology stake par these courtstious of film / soon less huge license region but fast [SEP]']
[1650/2000] tot_loss=2.495 (perp=9.226, rec=0.209, cos=0.441), tot_loss_proj:3.197 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible bad di. ) the bad forensic film rights sox logging early onnology stake log these courtstious of film / soon less have the region but fast [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.577 (perp=9.636, rec=0.211, cos=0.439), tot_loss_proj:3.256 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible no di. ) the bad forensic film rights sox logging early onnology stake log these courts of filmtious / soon less have license region but fast [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.590 (perp=9.714, rec=0.207, cos=0.441), tot_loss_proj:3.291 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible soon di. ) the bad forensic film rights sox logging early onnology stake par these courts of filmtious / no less have license region but fast [SEP]']
[1800/2000] tot_loss=2.586 (perp=9.709, rec=0.203, cos=0.441), tot_loss_proj:3.262 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible soon di. ) the bad forensic film rights sox logging early on [CLS] stake par these courts of filmtious / no less have license region but fast [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.533 (perp=9.417, rec=0.209, cos=0.441), tot_loss_proj:3.268 [t=0.23s]
prediction: ['[CLS] hadssing too " the fun horrible soon di. ) the bad forensic film rights sox logging early on [CLS] stake par these courts of filmtious / no less the region have but fast [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.470 (perp=9.111, rec=0.205, cos=0.443), tot_loss_proj:3.251 [t=0.23s]
prediction: ['[CLS] hadssing too " the fun horrible soon di. ) the bad forensic film rights region logging early on [CLS] stake par these courts of filmtious / no less the sox have but fast [SEP]']
[1950/2000] tot_loss=2.468 (perp=9.111, rec=0.205, cos=0.441), tot_loss_proj:3.251 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun horrible soon di. ) the bad forensic film rights region logging early on [CLS] stake par these courts of filmtious / no less the sox have but fast [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.444 (perp=8.997, rec=0.205, cos=0.440), tot_loss_proj:3.223 [t=0.24s]
prediction: ['[CLS] hadssing too " the fun soon horrible di. ) the bad forensic film rights region logging early on [CLS] stake par these courts of filmtious / no less the sox have but fast [SEP]']
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] hadssing too " the fun horrible no di. ) the bad forensic film rights sox logging early onnology stake log these courts of filmtious / soon less have the region but fast [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 28.070 | p: 25.806 | r: 30.769
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 21.053 | p: 19.355 | r: 23.077
rougeLsum  | fm: 21.053 | p: 19.355 | r: 23.077
r1fm+r2fm = 28.070

[Aggregate metrics]:
rouge1     | fm: 89.648 | p: 88.909 | r: 90.562
rouge2     | fm: 55.557 | p: 55.253 | r: 55.935
rougeL     | fm: 77.677 | p: 77.025 | r: 78.490
rougeLsum  | fm: 77.858 | p: 77.279 | r: 78.656
r1fm+r2fm = 145.206

input #99 time: 0:09:14 | total time: 14:42:48


Average Cosine Similarity: 0.7279837791873502
Done with all.




















ot travis playoffs wolfe [SEP]']
[Init] best perm rec loss: 0.9165091514587402 for ['[CLS] risk wolfe playoffs travis late pleasure spy border billie once programme aka lot serena [SEP]']
[Init] best perm rec loss: 0.9156515002250671 for ['[CLS] border late billie programme spy travis playoffs pleasure serena lot risk once aka wolfe [SEP]']
[Init] best perm rec loss: 0.9149429798126221 for ['[CLS] once border risk pleasure travis spy serena lot billie aka playoffs programme late wolfe [SEP]']
[Init] best perm rec loss: 0.9144315123558044 for ['[CLS] playoffs travis pleasure programme lot risk wolfe serena billie spy aka late once border [SEP]']
[Init] best perm rec loss: 0.9135802984237671 for ['[CLS] billie risk lot once border spy aka late pleasure travis programme wolfe serena playoffs [SEP]']
[Init] best perm rec loss: 0.9129605889320374 for ['[CLS] pleasure border risk once spy billie aka lot late serena wolfe travis programme playoffs [SEP]']
[Init] best perm rec loss: 0.9119769930839539 for ['[CLS] wolfe late border once spy programme travis lot risk serena pleasure billie playoffs aka [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.518 (perp=11.138, rec=0.272, cos=0.018), tot_loss_proj:4.098 [t=0.30s]
prediction: ['[CLS] brought serious awareness remember southwest historical awarenessiaceae unfamiliar often - bands awareness. [SEP]']
[ 100/2000] tot_loss=2.112 (perp=9.662, rec=0.174, cos=0.006), tot_loss_proj:3.634 [t=0.30s]
prediction: ['[CLS] brings aware awareness issue tasmania often awareness depression - often - - awareness. [SEP]']
[ 150/2000] tot_loss=2.120 (perp=9.891, rec=0.138, cos=0.004), tot_loss_proj:3.790 [t=0.30s]
prediction: ['[CLS] brings an awareness issue depression often overlooked depression often depression - overlooked awareness. [SEP]']
[ 200/2000] tot_loss=2.002 (perp=9.395, rec=0.120, cos=0.003), tot_loss_proj:3.890 [t=0.30s]
prediction: ['[CLS] brings an awareness issue issue often overlooked depression often depression - overlooked issue. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.960 (perp=9.268, rec=0.103, cos=0.004), tot_loss_proj:3.883 [t=0.30s]
prediction: ['[CLS] brings an awareness issue issue often overlooked depression often - depression overlooked issue. [SEP]']
[ 300/2000] tot_loss=1.809 (perp=8.517, rec=0.103, cos=0.003), tot_loss_proj:3.350 [t=0.30s]
prediction: ['[CLS] brings an awareness to issue often overlooked depression often - depression overlooked issue. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.795 (perp=8.483, rec=0.095, cos=0.003), tot_loss_proj:2.476 [t=0.30s]
prediction: ['[CLS] brings an awareness to issue often overlooked depression - often women s issue. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.614 (perp=7.538, rec=0.103, cos=0.003), tot_loss_proj:2.269 [t=0.30s]
prediction: ['[CLS] brings an awareness to issue often overlooked depression - - women often issue. [SEP]']
[ 450/2000] tot_loss=1.625 (perp=7.648, rec=0.093, cos=0.003), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] brings an awareness to issue often overlooked depression - - women s issue. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.625 (perp=7.648, rec=0.093, cos=0.003), tot_loss_proj:2.132 [t=0.31s]
prediction: ['[CLS] brings an awareness to issue often overlooked depression - - women s issue. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.713 (perp=8.108, rec=0.089, cos=0.003), tot_loss_proj:2.184 [t=0.30s]
prediction: ['[CLS] brings an awareness to issue often overlooked depression - s s women issue. [SEP]']
[ 600/2000] tot_loss=1.716 (perp=8.108, rec=0.092, cos=0.002), tot_loss_proj:2.182 [t=0.30s]
prediction: ['[CLS] brings an awareness to issue often overlooked depression - s s women issue. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.619 (perp=7.634, rec=0.090, cos=0.002), tot_loss_proj:2.075 [t=0.30s]
prediction: ['[CLS] brings an awareness to issue often overlooked depression - - s women issue. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.666 (perp=7.928, rec=0.078, cos=0.003), tot_loss_proj:1.991 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked depression - s s women issue. [SEP]']
[ 750/2000] tot_loss=1.573 (perp=7.493, rec=0.073, cos=0.002), tot_loss_proj:1.879 [t=0.31s]
prediction: ['[CLS] brings awareness to an issue often overlooked depression - - s women issue. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.576 (perp=7.493, rec=0.076, cos=0.002), tot_loss_proj:1.886 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked depression - - s women issue. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.491 (perp=7.023, rec=0.084, cos=0.002), tot_loss_proj:1.746 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
[ 900/2000] tot_loss=1.481 (perp=7.023, rec=0.074, cos=0.002), tot_loss_proj:1.735 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.484 (perp=7.023, rec=0.078, cos=0.002), tot_loss_proj:1.740 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.483 (perp=7.023, rec=0.077, cos=0.002), tot_loss_proj:1.739 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
[1050/2000] tot_loss=1.482 (perp=7.023, rec=0.075, cos=0.002), tot_loss_proj:1.740 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.486 (perp=7.023, rec=0.080, cos=0.002), tot_loss_proj:1.735 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.483 (perp=7.023, rec=0.076, cos=0.002), tot_loss_proj:1.739 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
[1200/2000] tot_loss=1.476 (perp=7.023, rec=0.070, cos=0.002), tot_loss_proj:1.735 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.478 (perp=7.023, rec=0.072, cos=0.002), tot_loss_proj:1.741 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.477 (perp=7.023, rec=0.070, cos=0.002), tot_loss_proj:1.740 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
[1350/2000] tot_loss=1.477 (perp=7.023, rec=0.071, cos=0.002), tot_loss_proj:1.744 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.476 (perp=7.023, rec=0.070, cos=0.002), tot_loss_proj:1.747 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.481 (perp=7.023, rec=0.074, cos=0.002), tot_loss_proj:1.735 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
[1500/2000] tot_loss=1.484 (perp=7.023, rec=0.077, cos=0.002), tot_loss_proj:1.741 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.484 (perp=7.023, rec=0.078, cos=0.002), tot_loss_proj:1.732 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.475 (perp=7.023, rec=0.068, cos=0.002), tot_loss_proj:1.737 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
[1650/2000] tot_loss=1.477 (perp=7.023, rec=0.070, cos=0.002), tot_loss_proj:1.738 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.475 (perp=7.023, rec=0.068, cos=0.002), tot_loss_proj:1.735 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.475 (perp=7.023, rec=0.069, cos=0.002), tot_loss_proj:1.740 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
[1800/2000] tot_loss=1.482 (perp=7.023, rec=0.076, cos=0.002), tot_loss_proj:1.746 [t=0.31s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.481 (perp=7.023, rec=0.075, cos=0.002), tot_loss_proj:1.736 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.481 (perp=7.023, rec=0.075, cos=0.002), tot_loss_proj:1.738 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
[1950/2000] tot_loss=1.485 (perp=7.023, rec=0.079, cos=0.002), tot_loss_proj:1.734 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.472 (perp=7.023, rec=0.065, cos=0.002), tot_loss_proj:1.739 [t=0.30s]
prediction: ['[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] brings awareness to an issue often overlooked - - women's depression. [SEP]
========================
predicted: 
========================
[CLS] brings awareness to an issue often overlooked - - s women issue depression. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 69.565 | p: 66.667 | r: 72.727
rougeL     | fm: 88.000 | p: 84.615 | r: 91.667
rougeLsum  | fm: 88.000 | p: 84.615 | r: 91.667
r1fm+r2fm = 165.565

[Aggregate metrics]:
rouge1     | fm: 70.714 | p: 69.827 | r: 71.800
rouge2     | fm: 16.636 | p: 16.419 | r: 16.917
rougeL     | fm: 45.101 | p: 44.533 | r: 45.756
rougeLsum  | fm: 45.187 | p: 44.630 | r: 45.825
r1fm+r2fm = 87.350

input #64 time: 0:12:02 | total time: 13:45:39



Running input #65 of 100.
reference: 
========================
no one but a convict guilty of some truly heinous crime should have to sit through the master of disguise .
========================
average of cosine similarity 0.9993304410958909
highest_index [0]
highest [0.9993304410958909]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2053,  2028,  2021,  1037, 20462,  5905,  1997,  2070,  5621,
          2002,  5740,  2271,  4126,  2323,  2031,  2000,  4133,  2083,  1996,
          3040,  1997, 14249,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] no one but a convict guilty of some truly heinous crime should have to sit through the master of disguise. [SEP]']
[Init] best rec loss: 0.9456421732902527 for ['[CLS] dai that painting part throatsden heart soup police contract framed powerins head verde also release shadows simply derivative centimeters mostly quit [SEP]']
[Init] best rec loss: 0.8755926489830017 for ['[CLS] condition land defender decision threat besides approval ec saudi afterder cordually dil away course han bscj achieved act tech head [SEP]']
[Init] best rec loss: 0.8665626049041748 for ['[CLS] still took able boys covenant preacher father almost spanish whose damaged abandonedsing thai ( raining designed ago plant telescopeivaterani jillian [SEP]']
[Init] best rec loss: 0.8512919545173645 for ['[CLS] bray rhythm think fare accents attitude amara tour aircraft retro nhs at anywhere artemy traditions closing miss figures recent demons cubs spring [SEP]']
[Init] best rec loss: 0.8334951400756836 for ['[CLS] lockedbra harvey letters courage siteernity viewer arabia johnnie cooks cast payment contact early feelerland passiontort facto temporal : [SEP]']
[Init] best rec loss: 0.8265991806983948 for ['[CLS]ding up tall friends only lamb mega mod reason searching widow ok hardin else callumper once designated himosta war tackles idea [SEP]']
[Init] best rec loss: 0.8098289966583252 for ['[CLS] airnow supervision farm lamps seal porter drake eyenington twinned circulatedzes hallben constitutional glass fanny wallace anchor unopposed order there [SEP]']
[Init] best rec loss: 0.7830051183700562 for ['[CLS] latelyburg no easier transmitted grown notation grantedmate alumni chrysler ari whichagger bush paint jasmine south macbeth opinion thermal none cent [SEP]']
[Init] best perm rec loss: 0.7829916477203369 for ['[CLS] chryslermate transmittedburg alumni lately south which grantedagger opinion cent ari thermal notation macbeth bush easier paint none jasmine grown no [SEP]']
[Init] best perm rec loss: 0.7821993827819824 for ['[CLS] grown which ari notation transmitted macbethmate granted chryslerburg lately bushagger south cent easier alumni thermal none opinion paint jasmine no [SEP]']
[Init] best perm rec loss: 0.7807224988937378 for ['[CLS] chrysler no granted transmitted latelymate centburg none notation opinion thermal alumni macbeth paint grown which bush south ari easieragger jasmine [SEP]']
[Init] best perm rec loss: 0.7804841995239258 for ['[CLS]mate chrysler which easier noagger lately bush granted opinion alumni macbeth ari noneburg thermal notation jasmine grown south transmitted cent paint [SEP]']
[Init] best perm rec loss: 0.7797477841377258 for ['[CLS] jasmine granted none southmate grown easier opinion latelyagger alumni notation whichburg macbeth transmitted chrysler ari cent bush no paint thermal [SEP]']
[Init] best perm rec loss: 0.7783377766609192 for ['[CLS] ari jasmine paint grownagger chrysler thermal no notationburg transmitted which macbeth none cent bush south easier grantedmate opinion alumni lately [SEP]']
[Init] best perm rec loss: 0.7782953381538391 for ['[CLS] thermal south granted chrysler cent alumniburg opinion notationagger jasmine macbeth nonemate transmitted paint bush grown ari no easier lately which [SEP]']
[Init] best perm rec loss: 0.7782296538352966 for ['[CLS] granted chrysler transmitted cent ari paint notation macbeth no bush alumni easier noneaggermate south thermal jasmine latelyburg which grown opinion [SEP]']
[Init] best perm rec loss: 0.7769541144371033 for ['[CLS] transmittedagger chrysler lately no opinion notation which easier jasmine bush cent ari macbethmate thermal south alumni granted grown none paintburg [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.241 (perp=13.112, rec=0.499, cos=0.119), tot_loss_proj:4.148 [t=0.31s]
prediction: ['[CLS] proportion cain sounds plays 24 gender donald puerto 1994ta quietly crisisam and puppet assistant sword skull resource built till paint lucifer [SEP]']
[ 100/2000] tot_loss=2.838 (perp=12.249, rec=0.363, cos=0.025), tot_loss_proj:4.152 [t=0.31s]
prediction: ['[CLS] right united sounds becomes almost nominee nobel puerto. peninsula quietly games the ;strel assistant smileword specialisters into game lucifer [SEP]']
[ 150/2000] tot_loss=2.531 (perp=10.870, rec=0.330, cos=0.027), tot_loss_proj:3.870 [t=0.31s]
prediction: ['[CLS] right together sounded becomes one shouldرx. peninsula quietly crime the [strel assistant. crimes specialists through into from most [SEP]']
[ 200/2000] tot_loss=2.586 (perp=11.513, rec=0.276, cos=0.008), tot_loss_proj:3.810 [t=0.31s]
prediction: ['[CLS] disposed actually accompanied forget one should should puerto. peninsula quietly crime no ; kn assistant : crimes resistant through in from most [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.302 (perp=10.213, rec=0.251, cos=0.008), tot_loss_proj:3.531 [t=0.31s]
prediction: ['[CLS] none actually accompanied forget one should should virtue. no crime quietly criminals the kn master : crimes resistant through disguise from spd [SEP]']
[ 300/2000] tot_loss=2.214 (perp=9.939, rec=0.219, cos=0.007), tot_loss_proj:3.444 [t=0.31s]
prediction: ['[CLS] none one accompanied forget one should should virtue. no crime quietly criminals the kn master : crimes guilty through disguise of 学 [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.930 (perp=8.567, rec=0.209, cos=0.007), tot_loss_proj:3.085 [t=0.31s]
prediction: ['[CLS] none should one quite has one should virtue. no crime quietly criminals disguise of master : crime guilty through disguise of 学 [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.917 (perp=8.477, rec=0.201, cos=0.020), tot_loss_proj:3.039 [t=0.31s]
prediction: ['[CLS] none should one disguise has a should. no crime quietly guilty $ disguise of disguise : crime guilty through disguise of clarke [SEP]']
[ 450/2000] tot_loss=1.776 (perp=7.978, rec=0.178, cos=0.003), tot_loss_proj:2.963 [t=0.31s]
prediction: ['[CLS] none should one disguise have a should. no crime quietly guilty aboriginal disguise of disguise : crime guilty through disguise of. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.686 (perp=7.542, rec=0.173, cos=0.004), tot_loss_proj:3.111 [t=0.31s]
prediction: ['[CLS] none should one disguise have the should. no crime quietly guilty of disguise have crime guilty through disguise of merely disguise. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.716 (perp=7.704, rec=0.168, cos=0.007), tot_loss_proj:2.855 [t=0.31s]
prediction: ['[CLS] none should one disguise have the. no crime quietly guilty of disguise should have crime guilty through disguise of $ disguise. [SEP]']
[ 600/2000] tot_loss=1.704 (perp=7.732, rec=0.155, cos=0.003), tot_loss_proj:2.906 [t=0.31s]
prediction: ['[CLS] none should but disguise have the. no crime quietly guilty of disguise should have crime guilty through disguise of $ disguise. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.618 (perp=7.285, rec=0.157, cos=0.005), tot_loss_proj:2.828 [t=0.31s]
prediction: ['[CLS] none should but have the. nous quietly guilty of disguise should have crime guilty through disguise master to disguise disguise. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.515 (perp=6.783, rec=0.154, cos=0.004), tot_loss_proj:2.684 [t=0.31s]
prediction: ['[CLS] none should but have the master. nous quietly guilty of disguise should have crime guilty through disguise to disguise disguise. [SEP]']
[ 750/2000] tot_loss=1.569 (perp=7.113, rec=0.144, cos=0.002), tot_loss_proj:2.566 [t=0.31s]
prediction: ['[CLS] none should but sit the master. nous quietly guilty of disguise should have crime guilty through disguise to disguise disguise. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.554 (perp=7.081, rec=0.136, cos=0.002), tot_loss_proj:2.600 [t=0.36s]
prediction: ['[CLS] none should sit but the master. nous quietly convict of disguise should have crime guilty through disguise to disguise disguise. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.482 (perp=6.755, rec=0.128, cos=0.002), tot_loss_proj:2.530 [t=0.36s]
prediction: ['[CLS] none should sit but the convict. nous quietly master of disguise should have crime guilty through disguise to disguise disguise. [SEP]']
[ 900/2000] tot_loss=1.473 (perp=6.755, rec=0.120, cos=0.001), tot_loss_proj:2.534 [t=0.36s]
prediction: ['[CLS] none should sit but the convict. nous quietly master of disguise should have crime guilty through disguise to disguise disguise. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.485 (perp=6.831, rec=0.117, cos=0.001), tot_loss_proj:2.573 [t=0.36s]
prediction: ['[CLS] one should sit but the convict. nous quietly master of disguise should have crime guilty through disguise to disguise disguise. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.465 (perp=6.665, rec=0.129, cos=0.002), tot_loss_proj:2.563 [t=0.36s]
prediction: ['[CLS] one should sit but the convict. nous master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
[1050/2000] tot_loss=1.447 (perp=6.665, rec=0.112, cos=0.001), tot_loss_proj:2.568 [t=0.36s]
prediction: ['[CLS] one should sit but the convict. nous master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.583 (perp=7.351, rec=0.111, cos=0.001), tot_loss_proj:2.642 [t=0.36s]
prediction: ['[CLS] one should sit but the convict a nous master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.539 (perp=7.174, rec=0.103, cos=0.002), tot_loss_proj:2.543 [t=0.36s]
prediction: ['[CLS] one should sit but the convict nous a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
[1200/2000] tot_loss=1.539 (perp=7.174, rec=0.103, cos=0.001), tot_loss_proj:2.545 [t=0.36s]
prediction: ['[CLS] one should sit but the convict nous a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.533 (perp=7.174, rec=0.097, cos=0.001), tot_loss_proj:2.544 [t=0.36s]
prediction: ['[CLS] one should sit but the convict nous a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.466 (perp=6.821, rec=0.100, cos=0.002), tot_loss_proj:2.532 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
[1350/2000] tot_loss=1.473 (perp=6.821, rec=0.108, cos=0.001), tot_loss_proj:2.529 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.458 (perp=6.821, rec=0.093, cos=0.001), tot_loss_proj:2.531 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.460 (perp=6.821, rec=0.095, cos=0.001), tot_loss_proj:2.529 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
[1500/2000] tot_loss=1.464 (perp=6.821, rec=0.098, cos=0.001), tot_loss_proj:2.529 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.461 (perp=6.821, rec=0.096, cos=0.001), tot_loss_proj:2.531 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.461 (perp=6.821, rec=0.096, cos=0.001), tot_loss_proj:2.527 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
[1650/2000] tot_loss=1.467 (perp=6.821, rec=0.101, cos=0.001), tot_loss_proj:2.529 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.457 (perp=6.821, rec=0.092, cos=0.001), tot_loss_proj:2.534 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.460 (perp=6.821, rec=0.095, cos=0.001), tot_loss_proj:2.533 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
[1800/2000] tot_loss=1.457 (perp=6.821, rec=0.092, cos=0.001), tot_loss_proj:2.530 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.448 (perp=6.821, rec=0.083, cos=0.001), tot_loss_proj:2.528 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.468 (perp=6.837, rec=0.099, cos=0.002), tot_loss_proj:2.511 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty through quietly disguise to disguise disguise. [SEP]']
[1950/2000] tot_loss=1.465 (perp=6.837, rec=0.096, cos=0.001), tot_loss_proj:2.510 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty through quietly disguise to disguise disguise. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.453 (perp=6.804, rec=0.091, cos=0.001), tot_loss_proj:2.553 [t=0.36s]
prediction: ['[CLS] one should sit but the nous convict a master of disguise should have crime guilty through disguise quietly to disguise disguise. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS] no one but a convict guilty of some truly heinous crime should have to sit through the master of disguise. [SEP]
========================
predicted: 
========================
[CLS] one should sit but the nous convict a master of disguise should have crime guilty quietly through disguise to disguise disguise. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.556 | p: 73.913 | r: 77.273
rouge2     | fm: 18.605 | p: 18.182 | r: 19.048
rougeL     | fm: 44.444 | p: 43.478 | r: 45.455
rougeLsum  | fm: 44.444 | p: 43.478 | r: 45.455
r1fm+r2fm = 94.160

[Aggregate metrics]:
rouge1     | fm: 70.707 | p: 69.825 | r: 71.805
rouge2     | fm: 16.725 | p: 16.474 | r: 17.017
rougeL     | fm: 45.167 | p: 44.593 | r: 45.835
rougeLsum  | fm: 45.129 | p: 44.595 | r: 45.765
r1fm+r2fm = 87.432

input #65 time: 0:13:24 | total time: 13:59:03


Running input #66 of 100.
reference: 
========================
in spite of good housekeeping's unsavory characters and wwf mentality , this white trash war of the roses is a surprisingly engaging film .
========================
average of cosine similarity 0.9994403284201181
highest_index [0]
highest [0.9994403284201181]
Debug: ids_shape = 33, pads = [33]
Debug: input ids = tensor([[  101,  1999,  8741,  1997,  2204,  2160, 18321,  1005,  1055,  4895,
          3736, 14550,  2100,  3494,  1998, 16779,  5177,  3012,  1010,  2023,
          2317, 11669,  2162,  1997,  1996, 10529,  2003,  1037, 10889, 11973,
          2143,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] in spite of good housekeeping's unsavory characters and wwf mentality, this white trash war of the roses is a surprisingly engaging film. [SEP]"]
[Init] best rec loss: 0.937335729598999 for ['[CLS] celeste cub currently welcome husband zulu englishbas unspoken? presents equation je ever nail locked fivbam arts introduced silent knockout of gal simply qaeda job though class scotia country [SEP]']
[Init] best rec loss: 0.9185946583747864 for ["[CLS] profit detachment rushing event dragonserate conversationeislaus casey seized currently breakfast callie jared inquiry 'aurus robotics premises sides gmbh hans extends moderncode anywhere totally nos earned noah [SEP]"]
[Init] best rec loss: 0.8902751207351685 for ['[CLS]ve catholic half queen kidding dufolding gifted card roll temperaturebbed long cutter knew katalusion napoleongroup growing foods forward frenchnical disney sculptorggle arched my dani rouge [SEP]']
[Init] best rec loss: 0.889338493347168 for ['[CLS] jersey saving freed strong immunity materly money ( myanmar layer brown generally rushing patch pm compare latest replay heart rican drug ransom bit handwritingvao putting bp tenantude roots [SEP]']
[Init] best rec loss: 0.8844871520996094 for ['[CLS]uro conduct na poet fancy ter flea contributed mandatory aim pressure eureka factormann yorkele worship busy radar richardsonpad metric known ai washingtonv real strike he altitudetooth [SEP]']
[Init] best rec loss: 0.8771156668663025 for ['[CLS] by answered cat dollcopic fears anchor hand bottle paul cited this aero bengal forces doing about was terrible true? recreational taught omlis - condom nomination streakhosis scholarship [SEP]']
[Init] best rec loss: 0.8733886480331421 for ['[CLS] 7 dress perfectaries figure patient down facing eveuritytin subcommittee side injury daylight wai connecticut training breaks wholebling smiled beth athletics iranian joined employment rabbit ordering romanized nations [SEP]']
[Init] best rec loss: 0.8661749362945557 for ['[CLS] most encoded ouraint va mcmahon our each wise subsidiary letters sant vest break ether some governorate tuned depending gus school video had burns collins claimed fall rounds cia woods belle [SEP]']
[Init] best rec loss: 0.8547503352165222 for ['[CLS] gillian transition his quarter kat roma closedze british olympia dark ram municipal compare the financial ray powerhouse archeries develop other eclipse pepper west tc royal thinmont primary ill [SEP]']
[Init] best perm rec loss: 0.8544809818267822 for ['[CLS] romamont other develop british municipal kat pepperze tc ill ray west primary thin financial gillian dark the royal closed transition eclipse quarter his olympia powerhouse ram archeries compare [SEP]']
[Init] best perm rec loss: 0.8539649844169617 for ['[CLS] primary municipal other closed quarter archer kat royal roma tc british west compare olympia powerhouse financial thin gillian the his develop eclipse transition illze ray ram peppermont darkies [SEP]']
[Init] best perm rec loss: 0.8539201021194458 for ['[CLS] katies compare ill develop his powerhouseze thin gillian closed roma quarter ram pepper financialmont ray dark west olympia royal tc other archer the british eclipse transition municipal primary [SEP]']
[Init] best perm rec loss: 0.853796660900116 for ['[CLS] quarter olympia ill pepper british archer thin ram his financial roma other tc closed the develop dark eclipse powerhouse gillian west rayze primary kat municipalies royalmont compare transition [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.990 (perp=12.818, rec=0.401, cos=0.026), tot_loss_proj:4.442 [t=0.35s]
prediction: ['[CLS] stadium bernstein color of sheikh lookedville increasing off. biological saintsb institute fortunately coal rhode courtyard humid douglas south el riches new tournament fort near white uranium superior insight [SEP]']
[ 100/2000] tot_loss=2.744 (perp=12.135, rec=0.307, cos=0.010), tot_loss_proj:4.323 [t=0.36s]
prediction: ['[CLS] trash attacked films childhood ministry looked series madeline.. uefa saints institute welfare trash hampshire courtyard humid arrived. isal new election navy as white burial surprisingly pleasure [SEP]']
[ 150/2000] tot_loss=2.605 (perp=11.448, rec=0.301, cos=0.014), tot_loss_proj:3.961 [t=0.36s]
prediction: ['[CLS] trash trash films enduring otago looked series trash his. moral pierres was welfare trash elvis filmmaker wwf arrived. is a real engaging wwf food roses war surprisingly pleasure [SEP]']
[ 200/2000] tot_loss=2.355 (perp=10.497, rec=0.249, cos=0.006), tot_loss_proj:2.974 [t=0.36s]
prediction: ['[CLS] trash trash films enjoy mutuallyyne series trash his. of minneapolis the was wwf trash hampshire filmmaker wwf arrived. is a surprisingly engaging wwf this roses war engaging. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.358 (perp=10.571, rec=0.236, cos=0.008), tot_loss_proj:3.146 [t=0.36s]
prediction: ['[CLS] trash trash film the otago look characters trash his the of mph contemporary was wwf trash vhs killer wwf mustered north is a surprisingly engaging wwf this roses war engaging. [SEP]']
[ 300/2000] tot_loss=2.279 (perp=10.341, rec=0.207, cos=0.004), tot_loss_proj:3.681 [t=0.36s]
prediction: ['[CLS] trash trash film the mcc avenue characters trash his. offactory contemporary was wwf trash vhs filmmaker wwf motors need is a surprisingly film wwf this roses war engaging. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.265 (perp=10.362, rec=0.189, cos=0.003), tot_loss_proj:3.359 [t=0.36s]
prediction: ['[CLS] contemporary trash characters the mcc avenue characters trash his despite of airlines trash is wwf trash vhs filmmaker wwf motors need is a surprisingly film wwf this roses war engaging. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.145 (perp=9.757, rec=0.189, cos=0.005), tot_loss_proj:3.649 [t=0.36s]
prediction: ['[CLS] contemporary trash / the mcc avenue characters trash his despite trash of les trash is wwf vhs homme white urine, is a surprisingly film wwf this roses war engaging. [SEP]']
[ 450/2000] tot_loss=2.133 (perp=9.892, rec=0.152, cos=0.002), tot_loss_proj:3.143 [t=0.36s]
prediction: ['[CLS] contemporary trash characters the mcc avenue characters trashub despite trash the les trash of wwf wwf homme white this white is a surprisingly film wwf this roses war engaging. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.100 (perp=9.815, rec=0.134, cos=0.002), tot_loss_proj:2.656 [t=0.36s]
prediction: ['[CLS] contemporary trash characters the mcc avenue characters trashub despite trash the les trash of wwf wwf homme white motors white is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.067 (perp=9.680, rec=0.129, cos=0.002), tot_loss_proj:2.631 [t=0.36s]
prediction: ['[CLS] contemporary trash characters the mcc avenue characters trashub despite trash the white trash of wwf wwf homme white motors les is a surprisingly engaging wwf this roses war film. [SEP]']
[ 600/2000] tot_loss=1.954 (perp=9.116, rec=0.128, cos=0.002), tot_loss_proj:2.587 [t=0.36s]
prediction: ['[CLS] keeping trash characters the 門 avenue characters trashly despite trash and white trash of wwf wwf homme white this siblings is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.886 (perp=8.832, rec=0.118, cos=0.002), tot_loss_proj:2.526 [t=0.36s]
prediction: ['[CLS] keeping trash characters the 門 avenue characters trashly spite trash and white trash of wwf wwf homme this white les is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.863 (perp=8.738, rec=0.114, cos=0.002), tot_loss_proj:2.544 [t=0.36s]
prediction: ['[CLS] keeping trash characters therative avenue characters trashly spite trash and white trash of homme wwf wwf, white les is a surprisingly engaging wwf this roses war film. [SEP]']
[ 750/2000] tot_loss=1.829 (perp=8.622, rec=0.103, cos=0.002), tot_loss_proj:2.474 [t=0.36s]
prediction: ['[CLS] keeping trash characters the 門 avenue characters goodly spite trash and white trash of pharmacy wwf wwf, white les is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.930 (perp=9.080, rec=0.113, cos=0.001), tot_loss_proj:2.595 [t=0.36s]
prediction: ['[CLS] keeping trash characters thekeeping avenue characters goodly spite trash and need trash of pharmacy wwf wwf, white les is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.908 (perp=8.982, rec=0.110, cos=0.001), tot_loss_proj:2.614 [t=0.36s]
prediction: ['[CLS] keeping trash characters thekeeping avenue characters goodly spite trash and need trash of pharmacy, wwf wwf white les is a surprisingly engaging wwf this roses war film. [SEP]']
[ 900/2000] tot_loss=1.899 (perp=8.982, rec=0.101, cos=0.001), tot_loss_proj:2.613 [t=0.36s]
prediction: ['[CLS] keeping trash characters thekeeping avenue characters goodly spite trash and need trash of pharmacy, wwf wwf white les is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.867 (perp=8.831, rec=0.099, cos=0.001), tot_loss_proj:2.535 [t=0.36s]
prediction: ['[CLS] keeping trash characters thekeeping avenue characters goodly spite trash and trash of pharmacy need, wwf wwf white les is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.869 (perp=8.831, rec=0.101, cos=0.001), tot_loss_proj:2.529 [t=0.36s]
prediction: ['[CLS] keeping trash characters thekeeping avenue characters goodly spite trash and trash of pharmacy need, wwf wwf white les is a surprisingly engaging wwf this roses war film. [SEP]']
[1050/2000] tot_loss=1.871 (perp=8.831, rec=0.103, cos=0.001), tot_loss_proj:2.525 [t=0.36s]
prediction: ['[CLS] keeping trash characters thekeeping avenue characters goodly spite trash and trash of pharmacy need, wwf wwf white les is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.874 (perp=8.837, rec=0.105, cos=0.001), tot_loss_proj:2.505 [t=0.36s]
prediction: ['[CLS] keeping trash characterskeeping the avenue characters goodly spite trash and trash of pharmacy need, wwf wwf white les is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.033 (perp=9.572, rec=0.117, cos=0.002), tot_loss_proj:2.668 [t=0.36s]
prediction: ['[CLS] keeping trashkeeping the avenue characters goodvor spite trashkeeping and trash of bobbie need, wwf wwf white siblings is a surprisingly engaging wwf this roses war film. [SEP]']
[1200/2000] tot_loss=2.106 (perp=9.989, rec=0.107, cos=0.002), tot_loss_proj:2.773 [t=0.36s]
prediction: ['[CLS] keeping trashkeeping the avenue characters goodvor spite trashkeeping and trash of bobbie need, mental wwf white siblings is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.980 (perp=9.392, rec=0.101, cos=0.001), tot_loss_proj:2.624 [t=0.36s]
prediction: ['[CLS]going trash characters need the avenue characters goodvor spite trashkeeping and trash of bobbie, mental wwf white siblings is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.907 (perp=9.016, rec=0.102, cos=0.001), tot_loss_proj:2.521 [t=0.36s]
prediction: ['[CLS]going trash characters need the avenue characters goodvor spite trashkeeping and trash of wwf, mental bobbie white siblings is a surprisingly engaging wwf this roses war film. [SEP]']
[1350/2000] tot_loss=1.943 (perp=9.199, rec=0.102, cos=0.001), tot_loss_proj:2.593 [t=0.36s]
prediction: ['[CLS]going trash of need the avenue characters goodvor spite trashkeeping and trash of wwf, mental bobbie white siblings is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.954 (perp=9.281, rec=0.097, cos=0.001), tot_loss_proj:2.603 [t=0.36s]
prediction: ['[CLS]going trash characters need the avenuekeeping goodvor spite trashkeeping and trash of wwf, mental bobbie white siblings is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.892 (perp=8.922, rec=0.106, cos=0.001), tot_loss_proj:2.626 [t=0.36s]
prediction: ['[CLS]going trash characters need the avenue characters goodvor trashkeeping and trash of spite wwf, mental bobbie white siblings is a surprisingly engaging wwf this roses war film. [SEP]']
[1500/2000] tot_loss=1.908 (perp=9.053, rec=0.096, cos=0.001), tot_loss_proj:2.629 [t=0.36s]
prediction: ['[CLS]going trash characters need the avenue characters goodvor trashkeeping and mental of spite wwf, mental bobbie white rouge is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.904 (perp=9.009, rec=0.101, cos=0.001), tot_loss_proj:2.658 [t=0.36s]
prediction: ['[CLS]going trash characters need the avenue characters goodvorkeeping trash and mental of spite wwf, mental bobbie white rouge is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.864 (perp=8.786, rec=0.106, cos=0.001), tot_loss_proj:2.671 [t=0.36s]
prediction: ['[CLS]going characters need the avenue characters goodvorkeeping trash and mental trash of spite wwf, mental bobbie white rouge is a surprisingly engaging wwf this roses war film. [SEP]']
[1650/2000] tot_loss=1.889 (perp=8.938, rec=0.100, cos=0.001), tot_loss_proj:2.712 [t=0.36s]
prediction: ['[CLS]going characters need the avenue characters goodvorkeeping trash and mental trash of spite wwf, mental bobbie white les is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.883 (perp=8.915, rec=0.098, cos=0.001), tot_loss_proj:2.596 [t=0.36s]
prediction: ['[CLS]going characters need the avenue characters goodvorkeeping rouge and mental trash of spite wwf, mental bobbie white trash is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.867 (perp=8.801, rec=0.105, cos=0.001), tot_loss_proj:2.532 [t=0.36s]
prediction: ['[CLS]going characters need thevor avenue characters goodkeeping rouge and mental trash of spite wwf, mental bobbie white trash is a surprisingly engaging wwf this roses war film. [SEP]']
[1800/2000] tot_loss=1.860 (perp=8.801, rec=0.099, cos=0.001), tot_loss_proj:2.529 [t=0.36s]
prediction: ['[CLS]going characters need thevor avenue characters goodkeeping rouge and mental trash of spite wwf, mental bobbie white trash is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.864 (perp=8.801, rec=0.103, cos=0.001), tot_loss_proj:2.532 [t=0.36s]
prediction: ['[CLS]going characters need thevor avenue characters goodkeeping rouge and mental trash of spite wwf, mental bobbie white trash is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.855 (perp=8.801, rec=0.094, cos=0.001), tot_loss_proj:2.535 [t=0.36s]
prediction: ['[CLS]going characters need thevor avenue characters goodkeeping rouge and mental trash of spite wwf, mental bobbie white trash is a surprisingly engaging wwf this roses war film. [SEP]']
[1950/2000] tot_loss=1.853 (perp=8.801, rec=0.092, cos=0.001), tot_loss_proj:2.531 [t=0.36s]
prediction: ['[CLS]going characters need thevor avenue characters goodkeeping rouge and mental trash of spite wwf, mental bobbie white trash is a surprisingly engaging wwf this roses war film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.860 (perp=8.801, rec=0.099, cos=0.001), tot_loss_proj:2.534 [t=0.36s]
prediction: ['[CLS]going characters need thevor avenue characters goodkeeping rouge and mental trash of spite wwf, mental bobbie white trash is a surprisingly engaging wwf this roses war film. [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] in spite of good housekeeping's unsavory characters and wwf mentality, this white trash war of the roses is a surprisingly engaging film. [SEP]
========================
predicted: 
========================
[CLS]going characters need thevor avenue characters goodkeeping rouge and mental trash of spite wwf, mental bobbie white trash is a surprisingly engaging wwf this roses war film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.963 | p: 58.621 | r: 68.000
rouge2     | fm: 19.231 | p: 17.857 | r: 20.833
rougeL     | fm: 44.444 | p: 41.379 | r: 48.000
rougeLsum  | fm: 44.444 | p: 41.379 | r: 48.000
r1fm+r2fm = 82.194

[Aggregate metrics]:
rouge1     | fm: 70.576 | p: 69.589 | r: 71.745
rouge2     | fm: 16.677 | p: 16.405 | r: 16.969
rougeL     | fm: 45.111 | p: 44.508 | r: 45.874
rougeLsum  | fm: 45.177 | p: 44.586 | r: 45.833
r1fm+r2fm = 87.253

input #66 time: 0:13:58 | total time: 14:13:02


Running input #67 of 100.
reference: 
========================
meant for star wars fans . it is there to give them a good time .
========================
average of cosine similarity 0.9992824187217297
highest_index [0]
highest [0.9992824187217297]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[ 101, 3214, 2005, 2732, 5233, 4599, 1012, 2009, 2003, 2045, 2000, 2507,
         2068, 1037, 2204, 2051, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] meant for star wars fans. it is there to give them a good time. [SEP]']
[Init] best rec loss: 1.007408618927002 for ['[CLS] charge wool close farm valuesgg readiness northern camp still literature topics released 03 tail able [SEP]']
[Init] best rec loss: 0.998810350894928 for ['[CLS] life jumperrus danishchal hanna doing noun library 30 heeivism spreads wanna gears tap [SEP]']
[Init] best rec loss: 0.9932851791381836 for ['[CLS] sweetheart }cos inclusive dona chillhal : cartto ready we outside thou officer chen [SEP]']
[Init] best rec loss: 0.9738152027130127 for ['[CLS] johnsoniner will feature delta as removedyan bubble key rams whentituted clothes outside reigning [SEP]']
[Init] best rec loss: 0.972042441368103 for ['[CLS] seven უ concerns streets herb aircraft tender words 〉 inhabited chile long be war contained dialogue [SEP]']
[Init] best rec loss: 0.8891245722770691 for ['[CLS]ography g copa horde assembled ear chinese cursed v • pd after first standingdicate trouble [SEP]']
[Init] best perm rec loss: 0.8850268125534058 for ['[CLS] g after ear first standingography pd trouble assembled v cursed horde chinese • copadicate [SEP]']
[Init] best perm rec loss: 0.8842386603355408 for ['[CLS] chinesedicate copa • standing trouble g horde v ear after pd first cursedography assembled [SEP]']
[Init] best perm rec loss: 0.8820260167121887 for ['[CLS] • standing first trouble horde pdography after chinese vdicate cursed ear assembled g copa [SEP]']
[Init] best perm rec loss: 0.8808619976043701 for ['[CLS] first horde assembled after copaography standing • v chinese g eardicate pd cursed trouble [SEP]']
[Init] best perm rec loss: 0.8765033483505249 for ['[CLS] first pd • cursed trouble chinese standing vdicate horde ear after assembled gography copa [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.929 (perp=11.518, rec=0.546, cos=0.079), tot_loss_proj:3.648 [t=0.35s]
prediction: ['[CLS] bye clare memorial memorial elder old was rush silver album elder sara alive. sons^ [SEP]']
[ 100/2000] tot_loss=2.635 (perp=11.309, rec=0.354, cos=0.018), tot_loss_proj:3.587 [t=0.36s]
prediction: ['[CLS] yingan worth chairman sweet old darktime golden restaurant cruises zur. good comics [SEP]']
[ 150/2000] tot_loss=2.609 (perp=11.441, rec=0.306, cos=0.015), tot_loss_proj:3.865 [t=0.36s]
prediction: ['[CLS] itself meant worth won star small dark wars fans fans cruises zur meant good campeonato [SEP]']
[ 200/2000] tot_loss=2.713 (perp=12.220, rec=0.262, cos=0.007), tot_loss_proj:4.310 [t=0.36s]
prediction: ['[CLS] itself meant allowing attorney star small good wars fans fans cruises success looked meant good campeonato [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.258 (perp=9.960, rec=0.257, cos=0.009), tot_loss_proj:3.832 [t=0.36s]
prediction: ['[CLS] itself meant small attorney fans allowing good wars fans fans cruises success give meant good comics [SEP]']
[ 300/2000] tot_loss=2.261 (perp=10.087, rec=0.237, cos=0.007), tot_loss_proj:3.809 [t=0.36s]
prediction: ['[CLS] there meant small for fans watching good wars fans fans cruises success give meant good [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.900 (perp=8.388, rec=0.218, cos=0.005), tot_loss_proj:3.251 [t=0.36s]
prediction: ['[CLS] there meant good for fans watching small wars fans fans cruises success give meant good. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.865 (perp=8.252, rec=0.210, cos=0.004), tot_loss_proj:3.291 [t=0.36s]
prediction: ['[CLS] there meant good for fans want small wars fans fanship success give meant good. [SEP]']
[ 450/2000] tot_loss=1.855 (perp=8.222, rec=0.206, cos=0.005), tot_loss_proj:3.271 [t=0.36s]
prediction: ['[CLS] there meant good for fans want small wars fans fanship success good meant good. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.843 (perp=8.222, rec=0.193, cos=0.005), tot_loss_proj:3.275 [t=0.36s]
prediction: ['[CLS] there meant good for fans want small wars fans fanship success good meant good. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.839 (perp=7.716, rec=0.275, cos=0.020), tot_loss_proj:3.043 [t=0.36s]
prediction: ['[CLS] there meant good a fans want small wars fans fanship time for meant good. [SEP]']
[ 600/2000] tot_loss=1.811 (perp=7.946, rec=0.213, cos=0.008), tot_loss_proj:3.151 [t=0.36s]
prediction: ['[CLS] there meant good a fans give little wars fans fanship time for meant good. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.852 (perp=8.218, rec=0.202, cos=0.006), tot_loss_proj:3.257 [t=0.36s]
prediction: ['[CLS] there meant good give give star little wars fans fanship time for meant good. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.733 (perp=7.654, rec=0.198, cos=0.005), tot_loss_proj:3.371 [t=0.36s]
prediction: ['[CLS] there meant good give give little star wars fans fanship time for meant good. [SEP]']
[ 750/2000] tot_loss=1.719 (perp=7.660, rec=0.183, cos=0.005), tot_loss_proj:3.245 [t=0.36s]
prediction: ['[CLS] there meant good give give little star wars fans fans. time for meant good. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.597 (perp=7.027, rec=0.187, cos=0.005), tot_loss_proj:2.911 [t=0.36s]
prediction: ['[CLS] there meant good give give. little star wars fans fans time for meant good. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.564 (perp=6.908, rec=0.178, cos=0.005), tot_loss_proj:2.850 [t=0.36s]
prediction: ['[CLS] there meant good give give. little star wars fans time for fans meant good. [SEP]']
[ 900/2000] tot_loss=1.562 (perp=6.908, rec=0.176, cos=0.004), tot_loss_proj:2.857 [t=0.36s]
prediction: ['[CLS] there meant good give give. little star wars fans time for fans meant good. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.534 (perp=6.794, rec=0.171, cos=0.004), tot_loss_proj:2.884 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans give for fans meant good. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.533 (perp=6.794, rec=0.171, cos=0.004), tot_loss_proj:2.882 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans give for fans meant good. [SEP]']
[1050/2000] tot_loss=1.532 (perp=6.794, rec=0.169, cos=0.004), tot_loss_proj:2.878 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans give for fans meant good. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.530 (perp=6.794, rec=0.167, cos=0.004), tot_loss_proj:2.885 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans give for fans meant good. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.528 (perp=6.794, rec=0.165, cos=0.004), tot_loss_proj:2.879 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans give for fans meant good. [SEP]']
[1200/2000] tot_loss=1.537 (perp=6.794, rec=0.175, cos=0.004), tot_loss_proj:2.881 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans give for fans meant good. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.520 (perp=6.794, rec=0.158, cos=0.004), tot_loss_proj:2.885 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans give for fans meant good. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.527 (perp=6.794, rec=0.164, cos=0.003), tot_loss_proj:2.884 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans give for fans meant good. [SEP]']
[1350/2000] tot_loss=1.532 (perp=6.794, rec=0.169, cos=0.003), tot_loss_proj:2.886 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans give for fans meant good. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.531 (perp=6.794, rec=0.169, cos=0.003), tot_loss_proj:2.878 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans give for fans meant good. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.517 (perp=6.794, rec=0.155, cos=0.003), tot_loss_proj:2.884 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans give for fans meant good. [SEP]']
[1500/2000] tot_loss=1.461 (perp=6.460, rec=0.166, cos=0.003), tot_loss_proj:2.696 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans time for fans meant good. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.457 (perp=6.460, rec=0.161, cos=0.003), tot_loss_proj:2.696 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans time for fans meant good. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.460 (perp=6.460, rec=0.165, cos=0.003), tot_loss_proj:2.696 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans time for fans meant good. [SEP]']
[1650/2000] tot_loss=1.449 (perp=6.460, rec=0.153, cos=0.003), tot_loss_proj:2.698 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans time for fans meant good. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.460 (perp=6.460, rec=0.165, cos=0.003), tot_loss_proj:2.693 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans time for fans meant good. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.452 (perp=6.460, rec=0.156, cos=0.003), tot_loss_proj:2.695 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans time for fans meant good. [SEP]']
[1800/2000] tot_loss=1.450 (perp=6.460, rec=0.155, cos=0.003), tot_loss_proj:2.697 [t=0.36s]
prediction: ['[CLS] there meant good time give. little star wars fans time for fans meant good. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.651 (perp=7.436, rec=0.160, cos=0.003), tot_loss_proj:3.022 [t=0.36s]
prediction: ['[CLS] therei good time give. little star wars fans time for fans meant good. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.653 (perp=7.436, rec=0.163, cos=0.003), tot_loss_proj:3.021 [t=0.36s]
prediction: ['[CLS] therei good time give. little star wars fans time for fans meant good. [SEP]']
[1950/2000] tot_loss=1.650 (perp=7.436, rec=0.160, cos=0.003), tot_loss_proj:3.026 [t=0.36s]
prediction: ['[CLS] therei good time give. little star wars fans time for fans meant good. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.634 (perp=7.350, rec=0.160, cos=0.003), tot_loss_proj:3.330 [t=0.36s]
prediction: ['[CLS] therei good time give little. star wars fans time for fans meant good. [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] meant for star wars fans. it is there to give them a good time. [SEP]
========================
predicted: 
========================
[CLS] there meant good time give. little star wars fans time for fans meant good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.750 | p: 68.750 | r: 68.750
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 43.750 | p: 43.750 | r: 43.750
rougeLsum  | fm: 43.750 | p: 43.750 | r: 43.750
r1fm+r2fm = 88.750

[Aggregate metrics]:
rouge1     | fm: 70.574 | p: 69.581 | r: 71.714
rouge2     | fm: 16.775 | p: 16.518 | r: 17.053
rougeL     | fm: 45.103 | p: 44.533 | r: 45.813
rougeLsum  | fm: 45.141 | p: 44.544 | r: 45.797
r1fm+r2fm = 87.350

input #67 time: 0:13:57 | total time: 14:26:59


Running input #68 of 100.
reference: 
========================
schaefer's . . . determination to inject farcical raunch . . . drowns out the promise of the romantic angle .
========================
average of cosine similarity 0.9990190998435547
highest_index [0]
highest [0.9990190998435547]
Debug: ids_shape = 33, pads = [33]
Debug: input ids = tensor([[  101,  8040, 25293,  7512,  1005,  1055,  1012,  1012,  1012,  9128,
          2000,  1999, 20614,  2521, 19053,  2389, 10958,  4609,  2818,  1012,
          1012,  1012, 19549,  2015,  2041,  1996,  4872,  1997,  1996,  6298,
          6466,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] schaefer's... determination to inject farcical raunch... drowns out the promise of the romantic angle. [SEP]"]
[Init] best rec loss: 0.9454972743988037 for ['[CLS]ount publicly audrey exclude gamescology metal bass anglican expressions present us conferred indicator +brateeaux lac accordance wool hereve orchestra ice plusrrigan clears brotherhood smashwords back blink [SEP]']
[Init] best rec loss: 0.9177424311637878 for ['[CLS] charm nautical risk ass india z polish perpetual cole af dangerrina moved involved whistle shannon vatican critically down cater capable working bayᵖ clay realm dead sheet feather resolution served [SEP]']
[Init] best rec loss: 0.9167050123214722 for ['[CLS] loftlaise drama his railway accountingtura become voltage deserved h gr ev arabic dameto sentinel itunes drive vickers dolores includes emergency shorter says avon katelessly figureught orderly [SEP]']
[Init] best rec loss: 0.8972187638282776 for ['[CLS] identity sunshine winter twitterogist milo cheap people named dam listed genegyeyne cotning bell saber liter terry these colonyacagible lombardy standing king cow ensembleials [SEP]']
[Init] best rec loss: 0.8319974541664124 for ['[CLS]rial without circuit howie each certain issues reputation much [SEP] " dance saw congress department sporting tor multiplication lies niece splitting douglas ignored glenbular function [SEP]att plain revolution fare [SEP]']
[Init] best perm rec loss: 0.8312835693359375 for ['[CLS] ignored circuit revolutionbularatt reputation plain multiplication without niece department each sporting lies function certain tor fare glen much " [SEP] [SEP]rial dance saw splitting congress issues howie douglas [SEP]']
[Init] best perm rec loss: 0.8277104496955872 for ['[CLS] congress sporting ignored glen much fare [SEP]rial splitting douglas dance howie tor multiplication each circuit " revolution functionatt plain saw without [SEP] niecebular reputation lies certain department issues [SEP]']
[Init] best perm rec loss: 0.8266730904579163 for ['[CLS] reputation department [SEP]rial circuit tor congress " splitting lies each without douglas much danceatt ignored functionbular [SEP] fare certain saw multiplication niece revolution glen sporting plain issues howie [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.305 (perp=13.644, rec=0.511, cos=0.065), tot_loss_proj:4.074 [t=0.35s]
prediction: ['[CLS] psychology kirkted mindanao,eles. headed dead penalty scrape science assault rear the most over demands quite chasing iucn antarctic rigidorinputed recommend convincingorestation heap trouble nigeria [SEP]']
[ 100/2000] tot_loss=2.854 (perp=12.013, rec=0.419, cos=0.032), tot_loss_proj:4.018 [t=0.36s]
prediction: ['[CLS] psychology kirk through mindanao.?.dling dead penalty scrape science assault infantry the broad over demands quite. iucn antarctic rigiddingputed tomatoes washington month the trouble shoot [SEP]']
[ 150/2000] tot_loss=2.726 (perp=11.631, rec=0.380, cos=0.020), tot_loss_proj:3.799 [t=0.36s]
prediction: ['[CLS] psychology crew through arte.?/dling off difference scrape science assault infantry theque over demands quite. iucn socialist sizedding devised tomatoes washington month the trouble shoot [SEP]']
[ 200/2000] tot_loss=2.753 (perp=12.004, rec=0.339, cos=0.013), tot_loss_proj:3.442 [t=0.36s]
prediction: ['[CLS] psychology crew drown..eles.dling off difference scrape expression assault samantha the sacred over demands quite. iucn socialist sizedding devised tomatoes washington month these trouble shoot [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.689 (perp=11.757, rec=0.325, cos=0.012), tot_loss_proj:3.488 [t=0.36s]
prediction: ["[CLS]'lined drown..eles.dling off raids scrape expression assault waist the divers over demand crew. iucn socialist sizedmini devised tomatoes washington americas the trouble shoot [SEP]"]
[ 300/2000] tot_loss=2.569 (perp=11.325, rec=0.294, cos=0.010), tot_loss_proj:3.450 [t=0.36s]
prediction: ["[CLS]'long drown..eles.dling off.du science assault waist the divers over demand crew. iucn socialist sizedmini devised tomatoes washington americas the trouble shoot [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.431 (perp=10.671, rec=0.288, cos=0.009), tot_loss_proj:3.516 [t=0.36s]
prediction: ['[CLS] cinema long drown..eles.dling off. linent assault waisted divers at promise crew. iucn socialist sized science devised tomatoes washington americas the trouble shoot [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.334 (perp=10.233, rec=0.279, cos=0.008), tot_loss_proj:3.869 [t=0.36s]
prediction: ["[CLS]'long drown...dlingtieeles. linent assault waisted divers at promise crew. iucn socialist sized science devised sword washington americas the trouble shoot [SEP]"]
[ 450/2000] tot_loss=2.493 (perp=11.134, rec=0.259, cos=0.007), tot_loss_proj:3.931 [t=0.36s]
prediction: ['[CLS] cinema long drown...dlingtie >. lineinate assault promiseed divers at promise squadron. iucn socialist sized sciencecaster sword washington americas the trouble shoot [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.425 (perp=10.808, rec=0.256, cos=0.007), tot_loss_proj:4.038 [t=0.36s]
prediction: ['[CLS] cinema long drown...dling starinate. lineelescher promiseed divers at promise squadron. iucn socialist contribution sciencecaster sword washington americas the trouble shoot [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.388 (perp=10.630, rec=0.254, cos=0.008), tot_loss_proj:3.955 [t=0.36s]
prediction: ['[CLS] the long drown...dling starinate. line >cher perspectiveed divers at promise squadron. iucn upon contribution sciencecaster sword washington americas philosophy trouble shoot [SEP]']
[ 600/2000] tot_loss=2.273 (perp=10.151, rec=0.236, cos=0.006), tot_loss_proj:3.908 [t=0.36s]
prediction: ["[CLS] the long drown...dling starin. line >cher perspective. dat at promise squadron. iucn upon contribution sciencecaster sword washington americas'trouble shoot [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.150 (perp=9.506, rec=0.242, cos=0.007), tot_loss_proj:3.783 [t=0.36s]
prediction: ["[CLS] the long drown...dling starin. line >cher angle.ed at promise squadron. contribution upon iucn sciencecaster sword washington americas'trouble shoot [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=2.238 (perp=9.943, rec=0.242, cos=0.008), tot_loss_proj:3.656 [t=0.36s]
prediction: ["[CLS] theless drown... at starin. lineelescher angle.ed at promise squadron. contribution uponoia science facto washington americas'sword trouble shoot [SEP]"]
[ 750/2000] tot_loss=2.167 (perp=9.633, rec=0.233, cos=0.007), tot_loss_proj:3.808 [t=0.36s]
prediction: ["[CLS] the long drown...dling starin. lineelescher angle.ed at promise squadron. contribution uponsi science facto washington americas'sword trouble shoot [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.229 (perp=9.979, rec=0.227, cos=0.006), tot_loss_proj:3.924 [t=0.36s]
prediction: ['[CLS] the long drown...dling starin [SEP] lineelescher angle.. at promise squadron. contribution (si science facto washington americas. sword trouble shoot [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.216 (perp=9.909, rec=0.228, cos=0.006), tot_loss_proj:3.900 [t=0.36s]
prediction: ['[CLS] the long drown...dling starin [SEP] lineelescher angle.. at promise squadron. contribution ( washington science factooia americas. sword trouble shoot [SEP]']
[ 900/2000] tot_loss=2.215 (perp=9.909, rec=0.228, cos=0.006), tot_loss_proj:3.900 [t=0.36s]
prediction: ['[CLS] the long drown...dling starin [SEP] lineelescher angle.. at promise squadron. contribution ( washington science factooia americas. sword trouble shoot [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.236 (perp=10.025, rec=0.225, cos=0.006), tot_loss_proj:3.896 [t=0.36s]
prediction: ['[CLS] the long drown...dling starazi [SEP] lineelescher angle.. at promise squadron. contribution ( washington science "oia americas. sword trouble facto [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.150 (perp=9.588, rec=0.226, cos=0.006), tot_loss_proj:3.654 [t=0.36s]
prediction: ['[CLS] the long drown... [SEP] % deadin line >cher angle.. at promise squadron. contribution ( washington extreme "oia americas. sword trouble facto [SEP]']
[1050/2000] tot_loss=2.162 (perp=9.724, rec=0.212, cos=0.006), tot_loss_proj:3.715 [t=0.36s]
prediction: ['[CLS] the long drown... literature % deadin line >cher angle.. at promise squadron. contribution ( washington extreme "si americas. sword trouble facto [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.072 (perp=9.271, rec=0.212, cos=0.006), tot_loss_proj:3.653 [t=0.36s]
prediction: ['[CLS] the long drown... literaturecher deadin line > % angle.. at promise squadron. contribution ( washington science shootsi americas. sword trouble facto [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.093 (perp=9.333, rec=0.220, cos=0.006), tot_loss_proj:3.577 [t=0.36s]
prediction: ['[CLS] the long drown... literature out deadin line > % angle.. at promise squadron. contribution shoot ( washington scienceoia americas. sword trouble facto [SEP]']
[1200/2000] tot_loss=2.071 (perp=9.280, rec=0.210, cos=0.006), tot_loss_proj:3.559 [t=0.36s]
prediction: ['[CLS] the long drown... literature out deadin line > % angle. out at promise squadron. contribution shoot ( washington scienceoia americas. sword trouble facto [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.984 (perp=8.825, rec=0.213, cos=0.006), tot_loss_proj:3.611 [t=0.36s]
prediction: ['[CLS] the long drown... literature out deadoia line > % angle. out at promise squadron. contribution " ( washington sciencein americas. sword trouble facto [SEP]']
Attempt swap
[1300/2000] tot_loss=1.984 (perp=8.825, rec=0.213, cos=0.006), tot_loss_proj:3.609 [t=0.36s]
prediction: ['[CLS] the long drown... literature out deadoia line > % angle. out at promise squadron. contribution " ( washington sciencein americas. sword trouble facto [SEP]']
[1350/2000] tot_loss=1.990 (perp=8.901, rec=0.205, cos=0.005), tot_loss_proj:3.658 [t=0.36s]
prediction: ['[CLS] the long drown... literature out deadoia line > % angle. out at promise squadron. contribution " ( washington scienceinco. sword troublecaster [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.971 (perp=8.763, rec=0.213, cos=0.005), tot_loss_proj:3.647 [t=0.36s]
prediction: ['[CLS] the long drown... literature out deadoia line > % angle. out at promise squadron. contribution " ( washington troubleinco. sword sciencecaster [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.954 (perp=8.693, rec=0.210, cos=0.006), tot_loss_proj:3.648 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out deadoia line > % angles out at promise squadron. contribution " ( washington literatureinco. sword sciencecaster [SEP]']
[1500/2000] tot_loss=1.953 (perp=8.693, rec=0.208, cos=0.005), tot_loss_proj:3.649 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out deadoia line > % angles out at promise squadron. contribution " ( washington literatureinco. sword sciencecaster [SEP]']
Attempt swap
[1550/2000] tot_loss=1.946 (perp=8.693, rec=0.202, cos=0.005), tot_loss_proj:3.650 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out deadoia line > % angles out at promise squadron. contribution " ( washington literatureinco. sword sciencecaster [SEP]']
Attempt swap
[1600/2000] tot_loss=1.942 (perp=8.693, rec=0.198, cos=0.005), tot_loss_proj:3.650 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out deadoia line > % angles out at promise squadron. contribution " ( washington literatureinco. sword sciencecaster [SEP]']
[1650/2000] tot_loss=1.948 (perp=8.693, rec=0.204, cos=0.005), tot_loss_proj:3.652 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out deadoia line > % angles out at promise squadron. contribution " ( washington literatureinco. sword sciencecaster [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.912 (perp=8.503, rec=0.206, cos=0.005), tot_loss_proj:3.603 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out deadoia line > % angles out at promise squadron. contribution " ( sword literatureinco. washington sciencecaster [SEP]']
Attempt swap
[1750/2000] tot_loss=1.908 (perp=8.503, rec=0.202, cos=0.005), tot_loss_proj:3.602 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out deadoia line > % angles out at promise squadron. contribution " ( sword literatureinco. washington sciencecaster [SEP]']
[1800/2000] tot_loss=1.905 (perp=8.503, rec=0.199, cos=0.005), tot_loss_proj:3.604 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out deadoia line > % angles out at promise squadron. contribution " ( sword literatureinco. washington sciencecaster [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.939 (perp=8.626, rec=0.209, cos=0.005), tot_loss_proj:3.628 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out % deadoia line > angles out at promise squadron. contribution " compelled sword literatureinco. washington sciencecaster [SEP]']
Attempt swap
[1900/2000] tot_loss=1.932 (perp=8.626, rec=0.202, cos=0.005), tot_loss_proj:3.627 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out % deadoia line > angles out at promise squadron. contribution " compelled sword literatureinco. washington sciencecaster [SEP]']
[1950/2000] tot_loss=1.936 (perp=8.626, rec=0.205, cos=0.005), tot_loss_proj:3.630 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out % deadoia line > angles out at promise squadron. contribution " compelled sword literatureinco. washington sciencecaster [SEP]']
Attempt swap
[2000/2000] tot_loss=1.896 (perp=8.445, rec=0.202, cos=0.005), tot_loss_proj:3.609 [t=0.36s]
prediction: ['[CLS] the long drown... trouble out % deadoia line > angles out at promise squadron. contribution " by sword literatureinco. washington sciencecaster [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] schaefer's... determination to inject farcical raunch... drowns out the promise of the romantic angle. [SEP]
========================
predicted: 
========================
[CLS] the long drown... trouble out deadoia line > % angles out at promise squadron. contribution " ( sword literatureinco. washington sciencecaster [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 27.778 | p: 26.316 | r: 29.412
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 22.222 | p: 21.053 | r: 23.529
rougeLsum  | fm: 22.222 | p: 21.053 | r: 23.529
r1fm+r2fm = 27.778

[Aggregate metrics]:
rouge1     | fm: 69.956 | p: 69.018 | r: 71.089
rouge2     | fm: 16.533 | p: 16.278 | r: 16.830
rougeL     | fm: 44.754 | p: 44.111 | r: 45.464
rougeLsum  | fm: 44.794 | p: 44.238 | r: 45.478
r1fm+r2fm = 86.489

input #68 time: 0:13:57 | total time: 14:40:56


Running input #69 of 100.
reference: 
========================
directed by kevin bray , whose crisp framing , edgy camera work , and wholesale ineptitude with acting , tone and pace very obviously mark him as a video helmer making his feature debut .
========================
average of cosine similarity 0.9991750030003601
highest_index [0]
highest [0.9991750030003601]
Debug: ids_shape = 41, pads = [41]
Debug: input ids = tensor([[  101,  2856,  2011,  4901, 19743,  1010,  3005, 15594, 20241,  1010,
          3968,  6292,  4950,  2147,  1010,  1998, 17264,  1999, 23606, 18679,
          2007,  3772,  1010,  4309,  1998,  6393,  2200,  5525,  2928,  2032,
          2004,  1037,  2678, 16254,  2121,  2437,  2010,  3444,  2834,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] directed by kevin bray, whose crisp framing, edgy camera work, and wholesale ineptitude with acting, tone and pace very obviously mark him as a video helmer making his feature debut. [SEP]']
[Init] best rec loss: 0.9579830169677734 for ['[CLS] still playing which made hitler parku disc gear litter effect maylee before charges qaeda autonomous meeting, tennis " rowing rather us lulu true content fabricphiage # hitch manager chance multi volunteers features delta maybe [SEP]']
[Init] best rec loss: 0.9277597069740295 for ['[CLS]igh nor actively europa sq dam experience secondsfaresablepani deleted salvatore predecessor! defeated blocks prove divide oh appears belgrade leadership lucienigo security sound [SEP]com months mass ob fears completes while rep sufferiva scheme [SEP]']
[Init] best rec loss: 0.9009978175163269 for ['[CLS] roads mage runite blendedreal books guy acre olivia upon martial blocks sharon force hill peer keeping contentsitors blame prince com neighborhood patrick reserve proton desk franksaurus soldier economy lowest no players latter layton athletics sts [SEP]']
[Init] best rec loss: 0.8831229209899902 for ['[CLS]iver photographer nz refuge fact tiffany nutrient standard self engineer breathless review winthrop sarahwell blush dime coli fallonosta me organized progress dialed guy choprarancemakers based continued next autumn school cassie zane breakfast rick sued nunez [SEP]']
[Init] best rec loss: 0.8505434989929199 for ['[CLS] owned departmentnac when mouthed bc move prayerhue wealth cup apologize pigs help stillopaন ] shootingetlent footballer calculusrs actor nonethelessip beer spring joe v dhaka woman over cool gracie listing forced gunner [SEP]']
[Init] best rec loss: 0.8466591238975525 for ['[CLS]tation heard remainlaid chartered considering fieldtorm johnysehead iata panel skatersii [CLS] wandered inside survivalgies except views consent count these gentleman beauty nigeria tee woodland heat boy psychoance lend releasinggl zero lots [SEP]']
[Init] best perm rec loss: 0.8427945375442505 for ['[CLS]laid chartered paneltorm woodland tee remain nigeria zero skaters boy wanderedgies heat john heard gentleman inside [CLS] lots lendanceiiglhead fieldyse consent beautytation psycho considering except survival releasing views iata these count [SEP]']
[Init] best perm rec loss: 0.8421382904052734 for ['[CLS] these iata heat survivaltorm heard lots tee skaters field except psycho john gentleman lend countgies considering insideance zero boy viewslaidyse remain [CLS]gl panel beautyheadii releasingtation consent nigeria wandered woodland chartered [SEP]']
[Init] best perm rec loss: 0.8408838510513306 for ['[CLS] wanderediiysehead boy gentleman woodlandtorm charteredlaid considering releasing survival psycho views fieldgl lend heat skaters inside tee heard lotsgies [CLS] count beauty these john except nigeria zerotation iataance consent remain panel [SEP]']
[Init] best perm rec loss: 0.8405309319496155 for ['[CLS] psycho zero panel except beauty field insidetationiitormyse john count these boy heard considering tee views chartered wandered iata skaters [CLS] remain heat lend releasingheadlaidgiesance nigeria woodland gentleman survival consent lotsgl [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.127 (perp=14.103, rec=0.297, cos=0.010), tot_loss_proj:4.073 [t=0.35s]
prediction: ['[CLS] vampireept styled leastjack °fdieodies taxi bright pharmaceuticalept pace in stations theatre enforce appearancesept non registered is guards ( (, lend expression escape between. interrupted saved directingchemist underground emma camera job [SEP]']
[ 100/2000] tot_loss=2.606 (perp=11.707, rec=0.256, cos=0.009), tot_loss_proj:3.503 [t=0.36s]
prediction: ['[CLS] sexualept directed buttance bychaft copyright euros attention appareleptitude and his directed executed nominateditudetv directed is staff for (, camera apparentlyitude his of alexia featured directing loudly attack towards camera job [SEP]']
[ 150/2000] tot_loss=2.507 (perp=11.207, rec=0.259, cos=0.007), tot_loss_proj:3.336 [t=0.36s]
prediction: ['[CLS] )ept directed joshogist by camera stance punk studio whoseeptitude, and directed tone suppliersitude in directed [SEP] sharp for four, work clearly following numerous of། video directing clearlyated towards municipality artist [SEP]']
[ 200/2000] tot_loss=2.536 (perp=11.677, rec=0.197, cos=0.003), tot_loss_proj:3.693 [t=0.36s]
prediction: ['[CLS] )ept directed josh career whosechaft nash punkural whoseeptitude, and directed inifaceitude in directed [SEP] sharp including four, work clearly following his of། as acting clearly feature arm municipality dealer [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.318 (perp=10.663, rec=0.182, cos=0.003), tot_loss_proj:3.716 [t=0.36s]
prediction: ['[CLS] )ept directed camera debut whosechaft framing phones doing whoseeptitude, and directed in ;itude in directed and sharp ( four, work clearlyitude his of། video acting clearly feature arm commission camera [SEP]']
[ 300/2000] tot_loss=2.215 (perp=10.177, rec=0.176, cos=0.004), tot_loss_proj:3.747 [t=0.36s]
prediction: ['[CLS] )itude by camera debut whosechaft framing yeshiva doing whoseeptitude, and directed in ;itude in directed and ordered ( four, work obviously following his,། video acting clearly feature arm commission camera [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.185 (perp=10.117, rec=0.159, cos=0.003), tot_loss_proj:3.758 [t=0.36s]
prediction: ['[CLS] ;itude by camera debut whose barack framing yeshiva making whoseeptitude,. directed in ;itude in directed and ordered, four john work obviously with a,། video acting clearly feature arm debut, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.087 (perp=9.680, rec=0.148, cos=0.002), tot_loss_proj:3.895 [t=0.36s]
prediction: ['[CLS] ;itude by camera clearly whose barack framing yeshiva making whoseeptitude,. directed in.itude in directed and crisp, four john work obviously with a,། video acting debut feature coil debut, [SEP]']
[ 450/2000] tot_loss=2.590 (perp=10.305, rec=0.471, cos=0.058), tot_loss_proj:3.529 [t=0.36s]
prediction: ['[CLS] genius impression by camera very whosejee [SEP] yeshiva makes whoseeptitude,, directed in.itude wholesale directed and barry, irish sculptor work obviously [SEP] a.亻 video acting debut featureathic centre, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.509 (perp=10.604, rec=0.362, cos=0.026), tot_loss_proj:3.034 [t=0.36s]
prediction: ['[CLS] marine confusion by studio obviously (jee [SEP] street makes whoseeptitude video, directed in.itude wholesale directed but stiff, john sculptor work obviously [SEP] a & [SEP], work debut featureathic centre, [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.295 (perp=9.906, rec=0.302, cos=0.012), tot_loss_proj:3.375 [t=0.36s]
prediction: ['[CLS] marine confusion by studio obviously,orum [SEP] street makes whoseeptitude video and directed in.itude wholesale directed but commanding, man artist work obviously [SEP] a & [SEP], his debut feature work centre, [SEP]']
[ 600/2000] tot_loss=2.302 (perp=10.126, rec=0.268, cos=0.008), tot_loss_proj:3.407 [t=0.36s]
prediction: ['[CLS] marine confusion by studio considerable,orum [SEP] street makes whoseeptitude acting and directed in.itude wholesale directed but commanding, man artist work obviously [SEP] a & [SEP], his debut debut work centre, [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.248 (perp=9.940, rec=0.253, cos=0.007), tot_loss_proj:3.412 [t=0.36s]
prediction: ['[CLS] marine confusion by video indeed,orum [SEP] street makes whoseeptitude studio and directed in.itude wholesale directed buttone, man artist work obviously [SEP] a & [SEP], his debut debut work march, [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.233 (perp=9.957, rec=0.236, cos=0.006), tot_loss_proj:3.328 [t=0.36s]
prediction: ['[CLS] in confusion by video indeed, militia [SEP] street makes whoseeptitude studio and directed genius.itude wholesale directed buttone, scotch artist work obviously [SEP] a & [SEP], his debut debut work represent, [SEP]']
[ 750/2000] tot_loss=2.294 (perp=10.315, rec=0.226, cos=0.005), tot_loss_proj:3.386 [t=0.36s]
prediction: ['[CLS] in confusion directed video indeed,rangle [SEP] street makes whoseeptitude studio and directed genius.itude wholesale directed buttone, scotch artist work obviously [SEP] a & [SEP], his debut debut work represent, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.285 (perp=10.309, rec=0.219, cos=0.005), tot_loss_proj:3.307 [t=0.36s]
prediction: ['[CLS] in confusion directed video indeed byrangle [SEP] street makes whoseeptitude studio and a genius.itude wholesale directed buttone, scotch artist work obviously [SEP] directed & [SEP], his debut debut work represent, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.227 (perp=10.080, rec=0.206, cos=0.005), tot_loss_proj:3.411 [t=0.36s]
prediction: ['[CLS] in confusion directed video but byrangle [SEP] street makes whoseeptitude camera and a genius.itude wholesale directed apparentlytone, audio artist work obviously [SEP] directed & [SEP], his debut debut work represent, [SEP]']
[ 900/2000] tot_loss=2.219 (perp=10.061, rec=0.203, cos=0.004), tot_loss_proj:3.494 [t=0.36s]
prediction: ['[CLS] in confusion directed video but byrangle [SEP] street makes whoseeptitude camera and a genius.itude wholesale directed indeedtone, audio artist work obviously [SEP] directed & [SEP], his debut debut work represent, [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.251 (perp=10.228, rec=0.201, cos=0.004), tot_loss_proj:3.491 [t=0.36s]
prediction: ['[CLS] in appear directed video which byrangle [SEP] street made whoseeptitude camera and a genius.itude wholesale directed indeedtone, audio artist work obviously directed [SEP] & [SEP], his debut debut work represent, [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.199 (perp=9.955, rec=0.204, cos=0.005), tot_loss_proj:3.431 [t=0.36s]
prediction: ['[CLS] in appear directed video which by [SEP] street makerangle whoseeptitude camera and a genius.itude wholesale directed indeedtone, audio artist work obviously directed [SEP] & [SEP], his debut debut work represent, [SEP]']
[1050/2000] tot_loss=2.170 (perp=9.883, rec=0.190, cos=0.004), tot_loss_proj:3.468 [t=0.36s]
prediction: ['[CLS] in appear directed video which by [SEP] street makerangle whoseeptitude camera and a genius.itude wholesale directed indeed crisp, audio artist work obviously directed [SEP] & [SEP] in his debut debut work represent, [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.135 (perp=9.702, rec=0.191, cos=0.004), tot_loss_proj:3.487 [t=0.36s]
prediction: ['[CLS] in appear directed video which by [SEP] seminary makeimeters whoseeptitude camera and a genius representitude wholesale directed indeed crisp, audio artist work obviously directed [SEP] & [SEP] in his debut debut work., [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.122 (perp=9.627, rec=0.193, cos=0.004), tot_loss_proj:3.404 [t=0.36s]
prediction: ['[CLS] in appear directed video which by [SEP] seminary makeimeters whoseeptitude camera and a speech representitude wholesale directed debut crisp, audio artist work obviously directed with & [SEP] in his debut prominent work., [SEP]']
[1200/2000] tot_loss=2.074 (perp=9.431, rec=0.185, cos=0.003), tot_loss_proj:3.388 [t=0.36s]
prediction: ['[CLS] in appear directed video which by [SEP] seminary makeimeters whoseeptitude camera and a genius representitude wholesale directed debut crisp, audio artist work obviously directed with & [SEP] in his debut prominent work., [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.091 (perp=9.493, rec=0.188, cos=0.003), tot_loss_proj:3.255 [t=0.36s]
prediction: ['[CLS] in represent directed video which by [SEP] seminary makeimeters whoseeptitude camera and a speech appearitude wholesale directed debut crisp, audio artist work obviously directed with & [SEP] in his debut apparently work., [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.067 (perp=9.372, rec=0.189, cos=0.003), tot_loss_proj:3.199 [t=0.36s]
prediction: ['[CLS] in a directed video which by [SEP] seminary makeimeters whoseeptitude camera and represent speech appearitude wholesale directed debut crisp, audio artist work obviously directed with & [SEP] in his debut apparently work., [SEP]']
[1350/2000] tot_loss=2.033 (perp=9.239, rec=0.182, cos=0.003), tot_loss_proj:3.092 [t=0.36s]
prediction: ['[CLS] in a directed video which by [SEP] seminary makeimeters whoseeptitude camera and represent speech workitude wholesale directed debut crisp, audio artist work obviously directed with & [SEP] in his debut apparently work., [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.015 (perp=9.146, rec=0.183, cos=0.003), tot_loss_proj:3.465 [t=0.36s]
prediction: ['[CLS] in a directed video which by [SEP] seminary makeimeters whoseeptitude camera and represent speech workitude wholesale directed apparently crisp, audio artist work obviously directed with & [SEP] in his debut debut work., [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.012 (perp=9.126, rec=0.184, cos=0.003), tot_loss_proj:3.440 [t=0.36s]
prediction: ['[CLS] in a directed video which by [SEP] street makeimeters whoseeptitude camera and represent speech workitude wholesale directed apparently crisp, audio artist work obviously directed with & [SEP] in his debut debut, work. [SEP]']
[1500/2000] tot_loss=2.025 (perp=9.221, rec=0.177, cos=0.003), tot_loss_proj:3.465 [t=0.36s]
prediction: ['[CLS] in a directed video which by [SEP] street makeislaus whoseeptitude camera and represent speech workitude wholesale directed apparently crisp, audio artist work obviously directed with & [SEP] in his debut debut, work. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.991 (perp=9.023, rec=0.183, cos=0.003), tot_loss_proj:3.267 [t=0.36s]
prediction: ['[CLS] in a directed video which by [SEP] street makeislaus whoseeptitude camera and wholesale speech workitude represent directed apparently crisp, audio artist work obviously directed with & [SEP] in his debut debut, work. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.982 (perp=9.007, rec=0.178, cos=0.003), tot_loss_proj:3.182 [t=0.36s]
prediction: ['[CLS] in a directed video which by [SEP] street makeislaus whoseeptitude and wholesale camera speech workitude represent directed apparently crisp, audio artist work obviously directed with & [SEP] in his debut debut, work. [SEP]']
[1650/2000] tot_loss=1.982 (perp=9.007, rec=0.178, cos=0.003), tot_loss_proj:3.182 [t=0.36s]
prediction: ['[CLS] in a directed video which by [SEP] street makeislaus whoseeptitude and wholesale camera speech workitude represent directed apparently crisp, audio artist work obviously directed with & [SEP] in his debut debut, work. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.938 (perp=8.771, rec=0.181, cos=0.003), tot_loss_proj:2.708 [t=0.36s]
prediction: ['[CLS] in a directed video which apparently [SEP] street makeislaus whoseeptitude and wholesale camera speech workitude represent directed by crisp, audio artist work obviously directed with & [SEP] in his debut debut, work. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.918 (perp=8.691, rec=0.176, cos=0.003), tot_loss_proj:2.659 [t=0.36s]
prediction: ['[CLS] in a directed video which apparently [SEP] street makeislaus whoseeptitude and wholesale camera work speechitude represent directed by crisp, audio artist work obviously directed with & [SEP] in his debut debut, work. [SEP]']
[1800/2000] tot_loss=2.053 (perp=9.337, rec=0.183, cos=0.003), tot_loss_proj:2.778 [t=0.36s]
prediction: ['[CLS] in a directedx which apparently [SEP] street makeislaus whoseeptitude and wholesale camera work speechitude represent directed by crisp, audio artist work obviously directed with & [SEP] in his debut debut, work. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.974 (perp=8.947, rec=0.182, cos=0.003), tot_loss_proj:2.649 [t=0.36s]
prediction: ['[CLS] in a directed make which indeed [SEP] street videozione whoseeptitude and wholesale camera work speechitude represent directed by crisp, audio artist work obviously directed with & [SEP] in his debut debut, work. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.956 (perp=8.845, rec=0.184, cos=0.003), tot_loss_proj:2.612 [t=0.36s]
prediction: ['[CLS] in a directed make which indeed [SEP] street videozione whoseeptitude and wholesale camera work speechitude represent directed by crisp, debut artist work obviously directed with & [SEP] in his audio debut, work. [SEP]']
[1950/2000] tot_loss=1.944 (perp=8.845, rec=0.172, cos=0.003), tot_loss_proj:2.613 [t=0.36s]
prediction: ['[CLS] in a directed make which indeed [SEP] street videozione whoseeptitude and wholesale camera work speechitude represent directed by crisp, debut artist work obviously directed with & [SEP] in his audio debut, work. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.944 (perp=8.773, rec=0.187, cos=0.003), tot_loss_proj:2.662 [t=0.36s]
prediction: ['[CLS] in a work make which indeed [SEP] street videozione whoseeptitude and wholesale camera work speechitude represent directed by crisp, debut artist work obviously directed with & [SEP] in his audio debut, directed. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] directed by kevin bray, whose crisp framing, edgy camera work, and wholesale ineptitude with acting, tone and pace very obviously mark him as a video helmer making his feature debut. [SEP]
========================
predicted: 
========================
[CLS] ;itude by camera clearly whose barack framing yeshiva making whoseeptitude,. directed in.itude wholesale directed and crisp, four video work obviously with a,། video acting debut feature coil debut, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.317 | p: 61.290 | r: 59.375
rouge2     | fm: 6.557 | p: 6.667 | r: 6.452
rougeL     | fm: 38.095 | p: 38.710 | r: 37.500
rougeLsum  | fm: 38.095 | p: 38.710 | r: 37.500
r1fm+r2fm = 66.875

[Aggregate metrics]:
rouge1     | fm: 69.921 | p: 68.910 | r: 70.991
rouge2     | fm: 16.406 | p: 16.174 | r: 16.662
rougeL     | fm: 44.657 | p: 44.125 | r: 45.331
rougeLsum  | fm: 44.737 | p: 44.152 | r: 45.369
r1fm+r2fm = 86.327

input #69 time: 0:13:58 | total time: 14:54:55


Running input #70 of 100.
reference: 
========================
there's nothing to gain from watching they . it isn't scary . it hates its characters . it finds no way to entertain or inspire its viewers .
========================
average of cosine similarity 0.9990962543740336
highest_index [0]
highest [0.9990962543740336]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101,  2045,  1005,  1055,  2498,  2000,  5114,  2013,  3666,  2027,
          1012,  2009,  3475,  1005,  1056, 12459,  1012,  2009, 16424,  2049,
          3494,  1012,  2009,  4858,  2053,  2126,  2000, 20432,  2030, 18708,
          2049,  7193,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] there's nothing to gain from watching they. it isn't scary. it hates its characters. it finds no way to entertain or inspire its viewers. [SEP]"]
[Init] best rec loss: 0.9472441673278809 for ['[CLS] zip clayton polar trees spring seville suddenly content corporation cold meeting chapel store shouldn real henry plus own vivo recruiting enough speaking wonder [CLS]taken usual going may2 wingspan flyers terminal [SEP]']
[Init] best rec loss: 0.9038707613945007 for ['[CLS] bluff pencil ruled also hugo deaf vent aground even kuala advertising xv frozen shown scratch planetntal globally te discovered bouquetitudeunder jersey sablehold - and processes diego - murder [SEP]']
[Init] best rec loss: 0.8812205791473389 for ['[CLS] hold lounge hiroshimadorfence rayon manages dual thing willing apart dr attended following sydney indians force when manufacturersurrent vampires asked prop clinical time rei does own subjectnik senateama [SEP]']
[Init] best rec loss: 0.8620077967643738 for ['[CLS] court figure s movementrr cassie filled? sha keys emperor those following dec ecological fell themselves abrahamuding went slam stretched fine below appliances next double memories can payton curtain intro [SEP]']
[Init] best perm rec loss: 0.8595824241638184 for ['[CLS] memoriesuding slam movement payton fell keys those double s fine curtain decrr emperor following stretched cassie figure next can? court themselves appliances sha abraham intro filled went ecological below [SEP]']
[Init] best perm rec loss: 0.8589557409286499 for ['[CLS] below ecological filled went curtain movement appliances dec s stretched next intro following payton sha emperor slam those fell? fine keys doubleuding themselvesrr court memories figure abraham cassie can [SEP]']
[Init] best perm rec loss: 0.8563078045845032 for ['[CLS] abraham stretched memories intro themselves below fine following cassie appliances court those can sha payton? felluding figure next movementrr emperor filled double slam ecological s curtain keys went dec [SEP]']
[Init] best perm rec loss: 0.8546767234802246 for ['[CLS] can following ecological slam movement keys those abraham dec fine wentuding filled intro s emperor? court fellrr memories payton appliances themselves stretched double curtain sha figure next below cassie [SEP]']
[Init] best perm rec loss: 0.8538877964019775 for ['[CLS] stretched following slam cassie intro appliances figure dec court ecological fell went abraham themselves curtain fine memories emperor filled double those below?rruding movement sha s can payton next keys [SEP]']
[Init] best perm rec loss: 0.8522513508796692 for ['[CLS] next s figure court emperor fine appliances went double sha themselvesrr fell filled intro followinguding those can ecological movement curtain cassie stretched? abraham memories dec below slam payton keys [SEP]']
[Init] best perm rec loss: 0.8520867228507996 for ['[CLS] filled court abraham next dec emperor fine following cassie ecological double those stretched movement figure can appliances sha belowuding went slam intro themselves paytonrr memories? keys curtain s fell [SEP]']
[Init] best perm rec loss: 0.8514459729194641 for ['[CLS] slam ecological double sha those emperor below s filled abraham cassie appliances themselves? stretched intro fell went can movementrr curtain dec fineuding payton memories following figure next court keys [SEP]']
[Init] best perm rec loss: 0.85069739818573 for ['[CLS] intro figure those can fine sha dec following slam payton? double ecological cassie filled fell themselves abraham below memories stretched s emperor movement went court appliances curtainuding nextrr keys [SEP]']
[Init] best perm rec loss: 0.8500798344612122 for ['[CLS] intro abraham sha figure dec went fine can cassie themselves following below slam fell emperor ecologicaluding payton filled court appliances? movement stretched curtain double next memoriesrr those s keys [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.959 (perp=12.902, rec=0.361, cos=0.018), tot_loss_proj:3.825 [t=0.35s]
prediction: ['[CLS]wy even z watching when seemed find collects steep of ainkles viewers, thering service pageant wantedtious neighborhood seems sees rid nothing nothing slowly decisions no of words 仮 [SEP]']
[ 100/2000] tot_loss=2.507 (perp=10.886, rec=0.316, cos=0.014), tot_loss_proj:3.519 [t=0.36s]
prediction: ['[CLS]iest actually things viewers ᆫ seemed finds instead mention no horrible fragile viewers. his no authors. hatedtious it seems finds richest it no violent.. or theig [SEP]']
[ 150/2000] tot_loss=2.471 (perp=11.192, rec=0.226, cos=0.007), tot_loss_proj:3.967 [t=0.36s]
prediction: ['[CLS]gree actually they watching ᆫ profit finds instead mention is its scary she. his no viewers. hated brennan it its finds doesn into way mused dreams from in of. [SEP]']
[ 200/2000] tot_loss=2.357 (perp=10.780, rec=0.196, cos=0.005), tot_loss_proj:3.318 [t=0.36s]
prediction: ['[CLS]plex actually they watching ᆫ nothing finds instead. isn it scary it. his no viewers. hates 介 it its finds doesn into way perceived memories from. of. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.233 (perp=10.291, rec=0.171, cos=0.004), tot_loss_proj:3.253 [t=0.36s]
prediction: ['[CLS]box actually they watching debated nothing finds unlike expensive isn nothing scary viewers. its no viewers. hates during it of its finds is to way religious or with of. [SEP]']
[ 300/2000] tot_loss=2.136 (perp=9.857, rec=0.161, cos=0.003), tot_loss_proj:3.381 [t=0.36s]
prediction: ['[CLS]box actually they watching ᆫ nothing finds unlike confinement isn. scary it. its no viewers. hates during it of its finds it entertain way cutter or with of. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.003 (perp=9.267, rec=0.146, cos=0.003), tot_loss_proj:3.710 [t=0.36s]
prediction: ['[CLS]box actually they with no nothing finds unlike reality isn they scary it. its no viewers. hates during it. its finds it entertain way viewers or watching of. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.817 (perp=8.363, rec=0.141, cos=0.003), tot_loss_proj:3.574 [t=0.36s]
prediction: ['[CLS] it actually they with no nothing finds unlike fiction isn they scary it. its no viewers. hates during it. it finds its entertain way viewers or watching of. [SEP]']
[ 450/2000] tot_loss=1.792 (perp=8.310, rec=0.127, cos=0.003), tot_loss_proj:3.612 [t=0.36s]
prediction: ['[CLS] it no they to no nothing finds unlike sight isn they scary it. its no viewers. hates during it. it finds its entertain way viewers or watching of. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.821 (perp=8.441, rec=0.130, cos=0.003), tot_loss_proj:3.605 [t=0.36s]
prediction: ['[CLS] there no they to no nothing finds unlike sight isn they scary it. characters no viewers. hates during it. it finds its viewers way entertain or watching of. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.723 (perp=7.963, rec=0.128, cos=0.003), tot_loss_proj:3.427 [t=0.36s]
prediction: ['[CLS] there no they to no nothing. unlike sight isn they scary it finds characters no viewers. hates - it. it finds its viewers way entertain or watching of. [SEP]']
[ 600/2000] tot_loss=1.752 (perp=8.139, rec=0.122, cos=0.003), tot_loss_proj:3.528 [t=0.36s]
prediction: ['[CLS] there no they to no nothing. unlike sight isn they scary it finds characters no viewers. hates during it. it finds its viewers way entertain or watching of. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.695 (perp=7.843, rec=0.123, cos=0.003), tot_loss_proj:3.492 [t=0.36s]
prediction: ['[CLS] there no they to no nothing. unlike amongst isn they scary it finds characters no viewers. hates of it. it finds its+ way entertain or watching of. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.795 (perp=8.382, rec=0.116, cos=0.003), tot_loss_proj:3.555 [t=0.36s]
prediction: ['[CLS] there nothing gain no nothing. they gandhi organization isn they scary it finds characters no viewers. hates of it. it finds its+ way entertain or watching of. [SEP]']
[ 750/2000] tot_loss=1.823 (perp=8.531, rec=0.114, cos=0.002), tot_loss_proj:3.607 [t=0.36s]
prediction: ["[CLS] there no gain no nothing. they gandhi amongst isn they scary it finds characters no viewers. hates of it. it finds its+ way entertain or watching '. [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.748 (perp=8.152, rec=0.114, cos=0.003), tot_loss_proj:3.513 [t=0.36s]
prediction: ['[CLS] there no fantastic no nothing. they gain amongst isn they scary it finds characters no viewers. hates of it. it finds its ‒ way entertain or watching of. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.732 (perp=8.058, rec=0.118, cos=0.002), tot_loss_proj:3.523 [t=0.36s]
prediction: ['[CLS] there nothing remotely no nothing. they gain gain isn they scary it finds characters no viewers. hates of it. it finds its. way entertain or watching of. [SEP]']
[ 900/2000] tot_loss=1.767 (perp=8.256, rec=0.113, cos=0.002), tot_loss_proj:3.603 [t=0.36s]
prediction: ['[CLS] there nothingleader no nothing. they gain gain isn they scary it finds characters no viewers. hates of it. it finds its. way entertain or watching of. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.747 (perp=8.198, rec=0.105, cos=0.002), tot_loss_proj:3.534 [t=0.36s]
prediction: ['[CLS] there they remotely no nothing. nothing gain gain isn they scary it doesn characters no viewers. hates of it. it finds its. way entertain or watching of. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.623 (perp=7.554, rec=0.110, cos=0.003), tot_loss_proj:3.436 [t=0.36s]
prediction: ['[CLS] there they remotely no nothing. nothing gain gain isn they scary. it doesn characters no viewers. hates of it. it finds its way entertain or watching of. [SEP]']
[1050/2000] tot_loss=1.626 (perp=7.554, rec=0.113, cos=0.002), tot_loss_proj:3.436 [t=0.36s]
prediction: ['[CLS] there they remotely no nothing. nothing gain gain isn they scary. it doesn characters no viewers. hates of it. it finds its way entertain or watching of. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.590 (perp=7.402, rec=0.108, cos=0.002), tot_loss_proj:3.285 [t=0.36s]
prediction: ['[CLS] there they remotely no nothing. nothing gain gain isn they scary. it doesn characters no viewers. hates of it. it finds its way of entertain or watching. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.525 (perp=7.089, rec=0.105, cos=0.002), tot_loss_proj:3.004 [t=0.36s]
prediction: ['[CLS] there they remotely gain nothing. nothing no gain isn they scary. it doesn characters no viewers. hates of it. it finds its way of entertain or watching. [SEP]']
[1200/2000] tot_loss=1.558 (perp=7.258, rec=0.104, cos=0.002), tot_loss_proj:3.116 [t=0.36s]
prediction: ['[CLS] there theyleader gain nothing. nothing no gain isn they scary. it doesn characters no viewers. hates of it. it finds its way of entertain or watching. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.575 (perp=7.345, rec=0.104, cos=0.002), tot_loss_proj:3.121 [t=0.36s]
prediction: ['[CLS] there theyleader gain nothing. nothing no gain isn they scary. it doesn characters no viewers. hates from it. it finds its way of entertain or watching. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.545 (perp=7.224, rec=0.098, cos=0.002), tot_loss_proj:3.055 [t=0.36s]
prediction: ['[CLS] there theyleader gain nothing. nothing no gain isn they scary. it doesn no viewers. characters hates from it. it finds its way of entertain or watching. [SEP]']
[1350/2000] tot_loss=1.519 (perp=7.071, rec=0.103, cos=0.002), tot_loss_proj:2.959 [t=0.36s]
prediction: ['[CLS] there they remotely gain nothing. nothing no gain isn they scary. it doesn no viewers. characters hates from it. it finds its way of entertain or watching. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.507 (perp=7.071, rec=0.091, cos=0.002), tot_loss_proj:2.967 [t=0.31s]
prediction: ['[CLS] there they remotely gain nothing. nothing no gain isn they scary. it doesn no viewers. characters hates from it. it finds its way of entertain or watching. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.562 (perp=7.290, rec=0.102, cos=0.002), tot_loss_proj:3.227 [t=0.31s]
prediction: ['[CLS] there they suggesting gain nothing. nothing no gain isn they scary. it doesn no viewers. characters hates from it. it finds its way of entertain or watching. [SEP]']
[1500/2000] tot_loss=1.566 (perp=7.290, rec=0.106, cos=0.002), tot_loss_proj:3.227 [t=0.31s]
prediction: ['[CLS] there they suggesting gain nothing. nothing no gain isn they scary. it doesn no viewers. characters hates from it. it finds its way of entertain or watching. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.513 (perp=7.069, rec=0.097, cos=0.002), tot_loss_proj:3.136 [t=0.31s]
prediction: ['[CLS] there they suggesting nothing gain nothing. no gain isn they scary. it doesn no viewers. characters hates from it. it finds its way of entertain or watching. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.416 (perp=6.537, rec=0.106, cos=0.003), tot_loss_proj:2.962 [t=0.31s]
prediction: ['[CLS] there they suggesting from nothing gain nothing. no gain isn they scary. it doesn no viewers. characters hates it. it finds its way to entertain or watching. [SEP]']
[1650/2000] tot_loss=1.406 (perp=6.537, rec=0.096, cos=0.002), tot_loss_proj:2.959 [t=0.31s]
prediction: ['[CLS] there they suggesting from nothing gain nothing. no gain isn they scary. it doesn no viewers. characters hates it. it finds its way to entertain or watching. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.403 (perp=6.537, rec=0.094, cos=0.002), tot_loss_proj:2.958 [t=0.31s]
prediction: ['[CLS] there they suggesting from nothing gain nothing. no gain isn they scary. it doesn no viewers. characters hates it. it finds its way to entertain or watching. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.404 (perp=6.537, rec=0.095, cos=0.002), tot_loss_proj:2.958 [t=0.31s]
prediction: ['[CLS] there they suggesting from nothing gain nothing. no gain isn they scary. it doesn no viewers. characters hates it. it finds its way to entertain or watching. [SEP]']
[1800/2000] tot_loss=1.417 (perp=6.537, rec=0.107, cos=0.002), tot_loss_proj:2.958 [t=0.31s]
prediction: ['[CLS] there they suggesting from nothing gain nothing. no gain isn they scary. it doesn no viewers. characters hates it. it finds its way to entertain or watching. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.407 (perp=6.537, rec=0.097, cos=0.002), tot_loss_proj:2.959 [t=0.31s]
prediction: ['[CLS] there they suggesting from nothing gain nothing. no gain isn they scary. it doesn no viewers. characters hates it. it finds its way to entertain or watching. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.406 (perp=6.537, rec=0.097, cos=0.002), tot_loss_proj:2.958 [t=0.31s]
prediction: ['[CLS] there they suggesting from nothing gain nothing. no gain isn they scary. it doesn no viewers. characters hates it. it finds its way to entertain or watching. [SEP]']
[1950/2000] tot_loss=1.401 (perp=6.537, rec=0.091, cos=0.002), tot_loss_proj:2.958 [t=0.31s]
prediction: ['[CLS] there they suggesting from nothing gain nothing. no gain isn they scary. it doesn no viewers. characters hates it. it finds its way to entertain or watching. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.401 (perp=6.537, rec=0.091, cos=0.002), tot_loss_proj:2.956 [t=0.31s]
prediction: ['[CLS] there they suggesting from nothing gain nothing. no gain isn they scary. it doesn no viewers. characters hates it. it finds its way to entertain or watching. [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] there's nothing to gain from watching they. it isn't scary. it hates its characters. it finds no way to entertain or inspire its viewers. [SEP]
========================
predicted: 
========================
[CLS] there they suggesting from nothing gain nothing. no gain isn they scary. it doesn no viewers. characters hates it. it finds its way to entertain or watching. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.702 | p: 79.310 | r: 82.143
rouge2     | fm: 21.818 | p: 21.429 | r: 22.222
rougeL     | fm: 52.632 | p: 51.724 | r: 53.571
rougeLsum  | fm: 52.632 | p: 51.724 | r: 53.571
r1fm+r2fm = 102.520

[Aggregate metrics]:
rouge1     | fm: 70.111 | p: 69.137 | r: 71.236
rouge2     | fm: 16.452 | p: 16.191 | r: 16.727
rougeL     | fm: 44.797 | p: 44.241 | r: 45.479
rougeLsum  | fm: 44.881 | p: 44.330 | r: 45.488
r1fm+r2fm = 86.564

input #70 time: 0:13:25 | total time: 15:08:21


Running input #71 of 100.
reference: 
========================
with minimal imagination , you could restage the whole thing in your bathtub .
========================
average of cosine similarity 0.9991206681427355
highest_index [0]
highest [0.9991206681427355]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2007, 10124,  9647,  1010,  2017,  2071,  2717,  4270,  1996,
          2878,  2518,  1999,  2115,  7198, 28251,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] with minimal imagination, you could restage the whole thing in your bathtub. [SEP]']
[Init] best rec loss: 1.0142029523849487 for ['[CLS] extra concentrate uponder parking beer national ray ivy sonsraj [CLS] advice divorce disappointment works [SEP]']
[Init] best rec loss: 0.8637482523918152 for ['[CLS] jean near resources ђ please guts heavy diana "cula de nrhp else awards ghosthar [SEP]']
[Init] best rec loss: 0.8262497782707214 for ['[CLS] committee among organic there wire spur lana addition getting vfl mccartney clothing generally other throwing bullet [SEP]']
[Init] best rec loss: 0.8058794736862183 for ['[CLS] afibal terry dj completely population breathe submitrist physically town abandoned ready below nodsphs [SEP]']
[Init] best rec loss: 0.7933605909347534 for ['[CLS] limit moretight looking resources trainingosis x invisible glass even croix virginvres sharpe attempt [SEP]']
[Init] best rec loss: 0.7732623815536499 for ['[CLS] nailwell corner moon main heaven pilot animation shallow leatherture news burn epstein black. [SEP]']
[Init] best perm rec loss: 0.7697580456733704 for ['[CLS] black main leather news pilot epstein shallow burnwell corner nail moon heaven. animationture [SEP]']
[Init] best perm rec loss: 0.7676368355751038 for ['[CLS]ture black shallow heaven pilot main nailwell epstein news animation moon. burn leather corner [SEP]']
[Init] best perm rec loss: 0.7642825841903687 for ['[CLS]well nail corner pilot main shallow epstein animation leather burnture news moon heaven black. [SEP]']
[Init] best perm rec loss: 0.763405978679657 for ['[CLS] epstein black leather pilot shallow heaven animation nailture cornerwell main burn. moon news [SEP]']
[Init] best perm rec loss: 0.7623395919799805 for ['[CLS] shallow burnwell main black animation news heaven nail moon corner epstein leatherture. pilot [SEP]']
[Init] best perm rec loss: 0.7592964768409729 for ['[CLS] burnwell moon leather epstein nail newsture heaven corner shallow black pilot. animation main [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.855 (perp=12.480, rec=0.336, cos=0.023), tot_loss_proj:3.816 [t=0.31s]
prediction: ['[CLS] initial smoking - dumpped minimal damage bath if imagination bodies two lacking. paper or [SEP]']
[ 100/2000] tot_loss=2.509 (perp=11.411, rec=0.219, cos=0.007), tot_loss_proj:3.588 [t=0.31s]
prediction: ['[CLS] initial. rest rest. minimal rubber bath could imagination personnel letters non. paper or [SEP]']
[ 150/2000] tot_loss=2.201 (perp=10.121, rec=0.173, cos=0.004), tot_loss_proj:3.893 [t=0.31s]
prediction: ['[CLS] we with rest rest. minimal amelia bath could imagination should you users.. a [SEP]']
[ 200/2000] tot_loss=2.398 (perp=11.293, rec=0.135, cos=0.004), tot_loss_proj:3.672 [t=0.31s]
prediction: ['[CLS] minimal with rest restage minimal ameliatub could imagination should you users.. in [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.433 (perp=11.538, rec=0.120, cos=0.005), tot_loss_proj:3.860 [t=0.31s]
prediction: ['[CLS] kill with whole restage minimal facingtub could imagination should, you.. super [SEP]']
[ 300/2000] tot_loss=2.239 (perp=10.634, rec=0.109, cos=0.003), tot_loss_proj:3.762 [t=0.31s]
prediction: ['[CLS] kill with whole restage minimal ontub could imagination your, you.. super [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.124 (perp=10.047, rec=0.111, cos=0.003), tot_loss_proj:3.620 [t=0.31s]
prediction: ['[CLS] kill with whole restage minimal ontub. imagination your, you could. super [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.957 (perp=9.165, rec=0.119, cos=0.004), tot_loss_proj:2.964 [t=0.31s]
prediction: ['[CLS] kill with whole restage minimal on yourtub. imagination, you could. super [SEP]']
[ 450/2000] tot_loss=2.216 (perp=10.621, rec=0.090, cos=0.002), tot_loss_proj:3.189 [t=0.31s]
prediction: ['[CLS] kill with whole restage minimal focal yourtub in imagination, you could. super [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.115 (perp=10.092, rec=0.095, cos=0.002), tot_loss_proj:3.290 [t=0.31s]
prediction: ['[CLS]age with your whole restage minimal atub in imagination, you could. super [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.865 (perp=8.860, rec=0.091, cos=0.002), tot_loss_proj:3.225 [t=0.31s]
prediction: ['[CLS] with your whole restage minimalage thetub in imagination, you could. super [SEP]']
[ 600/2000] tot_loss=1.862 (perp=8.860, rec=0.088, cos=0.002), tot_loss_proj:3.216 [t=0.31s]
prediction: ['[CLS] with your whole restage minimalage thetub in imagination, you could. super [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.716 (perp=8.139, rec=0.087, cos=0.002), tot_loss_proj:2.990 [t=0.31s]
prediction: ['[CLS] with your whole rest the minimalageagetub in imagination, you could. super [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.668 (perp=7.904, rec=0.085, cos=0.002), tot_loss_proj:2.990 [t=0.31s]
prediction: ['[CLS] with your whole rest the minimalageagetub in imagination, you could super. [SEP]']
[ 750/2000] tot_loss=1.664 (perp=7.904, rec=0.082, cos=0.002), tot_loss_proj:2.987 [t=0.31s]
prediction: ['[CLS] with your whole rest the minimalageagetub in imagination, you could super. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.568 (perp=7.410, rec=0.084, cos=0.002), tot_loss_proj:2.836 [t=0.31s]
prediction: ['[CLS] with your whole rest the minimalagetub in imagination, you could superage. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.553 (perp=7.376, rec=0.076, cos=0.002), tot_loss_proj:3.071 [t=0.31s]
prediction: ['[CLS] with your whole rest the minimaltubage in imagination, you could superage. [SEP]']
[ 900/2000] tot_loss=1.556 (perp=7.376, rec=0.079, cos=0.002), tot_loss_proj:3.068 [t=0.31s]
prediction: ['[CLS] with your whole rest the minimaltubage in imagination, you could superage. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.539 (perp=7.292, rec=0.079, cos=0.002), tot_loss_proj:2.821 [t=0.31s]
prediction: ['[CLS] with the whole rest your minimaltubage in imagination, you could superage. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.507 (perp=7.106, rec=0.083, cos=0.002), tot_loss_proj:2.738 [t=0.31s]
prediction: ['[CLS] with the whole rest in minimaltubage your imagination, you could superage. [SEP]']
[1050/2000] tot_loss=1.505 (perp=7.106, rec=0.082, cos=0.002), tot_loss_proj:2.736 [t=0.31s]
prediction: ['[CLS] with the whole rest in minimaltubage your imagination, you could superage. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.497 (perp=7.106, rec=0.074, cos=0.002), tot_loss_proj:2.737 [t=0.31s]
prediction: ['[CLS] with the whole rest in minimaltubage your imagination, you could superage. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.422 (perp=6.710, rec=0.078, cos=0.002), tot_loss_proj:2.756 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
[1200/2000] tot_loss=1.436 (perp=6.710, rec=0.092, cos=0.002), tot_loss_proj:2.760 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.426 (perp=6.710, rec=0.082, cos=0.002), tot_loss_proj:2.759 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.420 (perp=6.710, rec=0.076, cos=0.002), tot_loss_proj:2.759 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
[1350/2000] tot_loss=1.416 (perp=6.710, rec=0.072, cos=0.002), tot_loss_proj:2.762 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.423 (perp=6.710, rec=0.079, cos=0.002), tot_loss_proj:2.762 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.417 (perp=6.710, rec=0.073, cos=0.002), tot_loss_proj:2.763 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
[1500/2000] tot_loss=1.422 (perp=6.710, rec=0.079, cos=0.002), tot_loss_proj:2.762 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.415 (perp=6.710, rec=0.072, cos=0.002), tot_loss_proj:2.765 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.417 (perp=6.710, rec=0.073, cos=0.002), tot_loss_proj:2.759 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
[1650/2000] tot_loss=1.428 (perp=6.710, rec=0.084, cos=0.002), tot_loss_proj:2.758 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.429 (perp=6.710, rec=0.085, cos=0.002), tot_loss_proj:2.763 [t=0.31s]
prediction: ['[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.407 (perp=6.681, rec=0.070, cos=0.002), tot_loss_proj:2.672 [t=0.31s]
prediction: ['[CLS] with the whole minimaltub restage in your imagination, you could superage. [SEP]']
[1800/2000] tot_loss=1.415 (perp=6.681, rec=0.077, cos=0.002), tot_loss_proj:2.678 [t=0.31s]
prediction: ['[CLS] with the whole minimaltub restage in your imagination, you could superage. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.421 (perp=6.681, rec=0.083, cos=0.002), tot_loss_proj:2.678 [t=0.31s]
prediction: ['[CLS] with the whole minimaltub restage in your imagination, you could superage. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.419 (perp=6.661, rec=0.085, cos=0.002), tot_loss_proj:2.594 [t=0.31s]
prediction: ['[CLS] with the whole minimaltub restage, in your imagination you could superage. [SEP]']
[1950/2000] tot_loss=1.415 (perp=6.661, rec=0.081, cos=0.002), tot_loss_proj:2.600 [t=0.31s]
prediction: ['[CLS] with the whole minimaltub restage, in your imagination you could superage. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.411 (perp=6.661, rec=0.077, cos=0.002), tot_loss_proj:2.593 [t=0.31s]
prediction: ['[CLS] with the whole minimaltub restage, in your imagination you could superage. [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] with minimal imagination, you could restage the whole thing in your bathtub. [SEP]
========================
predicted: 
========================
[CLS] with the whole rest minimaltubage in your imagination, you could superage. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.074 | p: 76.923 | r: 71.429
rouge2     | fm: 40.000 | p: 41.667 | r: 38.462
rougeL     | fm: 51.852 | p: 53.846 | r: 50.000
rougeLsum  | fm: 51.852 | p: 53.846 | r: 50.000
r1fm+r2fm = 114.074

[Aggregate metrics]:
rouge1     | fm: 70.100 | p: 69.191 | r: 71.172
rouge2     | fm: 16.795 | p: 16.589 | r: 17.026
rougeL     | fm: 44.830 | p: 44.300 | r: 45.475
rougeLsum  | fm: 44.840 | p: 44.325 | r: 45.489
r1fm+r2fm = 86.895

input #71 time: 0:12:16 | total time: 15:20:38


Running input #72 of 100.
reference: 
========================
a disturbing examination of what appears to be the definition of a 'bad' police shooting .
========================
average of cosine similarity 0.999427951172607
highest_index [0]
highest [0.999427951172607]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[  101,  1037, 14888,  7749,  1997,  2054,  3544,  2000,  2022,  1996,
          6210,  1997,  1037,  1005,  2919,  1005,  2610,  5008,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] a disturbing examination of what appears to be the definition of a'bad'police shooting. [SEP]"]
[Init] best rec loss: 0.9477725028991699 for ['[CLS] natewylitecastsal jenks ricoise operations talk swept penny seeking mind [MASK] orbit right stripped [SEP]']
[Init] best rec loss: 0.9364637732505798 for ['[CLS]cript instinctiza club perfect dripped pace dime familyht squeezed enigma ghetto fellows cu excused firedinium [SEP]']
[Init] best rec loss: 0.9304569959640503 for ["[CLS] day arts balance day early novo 'ous latest hydra group stirgled wax english studio waller vice [SEP]"]
[Init] best rec loss: 0.9295302629470825 for ['[CLS] majorityashikind tierney yet lindsey historyertedonga constitutional william inventor lay peyton muhammad anderson those elusive [SEP]']
[Init] best perm rec loss: 0.9278538227081299 for ['[CLS] history yet laykindashi elusive tierneyertedonga those muhammad anderson william inventor majority constitutional lindsey peyton [SEP]']
[Init] best perm rec loss: 0.9257873892784119 for ['[CLS] yetkind inventor elusive muhammad tierneyonga andersonerted those william constitutional lindsey majority lay history peytonashi [SEP]']
[Init] best perm rec loss: 0.925625205039978 for ['[CLS] tierney andersonerted lay thosekind lindsey yet peytonashi history elusiveonga majority muhammad inventor constitutional william [SEP]']
[Init] best perm rec loss: 0.925553560256958 for ['[CLS] muhammadashi tierneyerted peytonkindonga elusive constitutional lindsey lay william yet majority anderson those inventor history [SEP]']
[Init] best perm rec loss: 0.9229549765586853 for ['[CLS] elusive peytonerted yet constitutionalonga laykind inventor majority muhammad tierney william anderson lindsey history thoseashi [SEP]']
[Init] best perm rec loss: 0.9226972460746765 for ['[CLS] muhammad lay peyton anderson inventor tierney thoseerted history constitutional elusive lindsey william yetkindongaashi majority [SEP]']
[Init] best perm rec loss: 0.9219756126403809 for ['[CLS] anderson lay yet constitutionalkind history tierney muhammad elusive lindsey thoseashierted williamonga peyton inventor majority [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.197 (perp=13.435, rec=0.441, cos=0.069), tot_loss_proj:4.266 [t=0.31s]
prediction: ['[CLS] our break region revolutionary mormon boner mat per speech europeans africa of tolkien clinical distinct inter shattering [SEP]']
[ 100/2000] tot_loss=2.579 (perp=10.974, rec=0.355, cos=0.029), tot_loss_proj:4.176 [t=0.31s]
prediction: ['[CLS] documentary examination of a sioux school literature writing de was passage a of sexual ensuing several inter disturbing [SEP]']
[ 150/2000] tot_loss=2.388 (perp=10.680, rec=0.245, cos=0.007), tot_loss_proj:4.062 [t=0.31s]
prediction: ["[CLS] documentary examination of what fraud lucas '. addition panda passage a answer examination nearby several'disturbing [SEP]"]
[ 200/2000] tot_loss=2.182 (perp=9.854, rec=0.208, cos=0.004), tot_loss_proj:3.896 [t=0.31s]
prediction: ["[CLS] a examination of what police lucas '. haven necessarily passage a of examination any several bad disturbing [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.314 (perp=10.609, rec=0.189, cos=0.004), tot_loss_proj:4.011 [t=0.31s]
prediction: ["[CLS] a examination of what police definition'disturbing contrast necessarily passage a of examination any several bad medal [SEP]"]
[ 300/2000] tot_loss=2.061 (perp=9.412, rec=0.176, cos=0.003), tot_loss_proj:3.588 [t=0.31s]
prediction: ["[CLS] a examination of what police definition'disturbing contrast define passage a of examination to phrase bad institution [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.109 (perp=9.742, rec=0.158, cos=0.003), tot_loss_proj:3.931 [t=0.31s]
prediction: ["[CLS] a examination of what definition police'disturbing addition definition passage a of examination to phrase bad institution [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.063 (perp=9.443, rec=0.168, cos=0.006), tot_loss_proj:3.588 [t=0.31s]
prediction: ["[CLS] a examination of what definition police'disturbing promote definition & passage of examination any emerging bad institution [SEP]"]
[ 450/2000] tot_loss=1.969 (perp=9.081, rec=0.149, cos=0.003), tot_loss_proj:3.461 [t=0.31s]
prediction: ["[CLS] a examination of what definition police'disturbing installation definition &'a examination any emerging bad. [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.912 (perp=8.847, rec=0.140, cos=0.003), tot_loss_proj:3.589 [t=0.31s]
prediction: ["[CLS] a examination of what definition shooting'disturbing installation definition &'a bad any emerging examination. [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.948 (perp=8.926, rec=0.158, cos=0.005), tot_loss_proj:3.602 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting'a think definition disturbing'a bad any emerging examination. [SEP]"]
[ 600/2000] tot_loss=1.973 (perp=9.133, rec=0.143, cos=0.003), tot_loss_proj:3.736 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting'a think definition disturbing'a bad any emerging portrait. [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.805 (perp=8.374, rec=0.128, cos=0.002), tot_loss_proj:3.420 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting any'a think definition disturbing'a bad emerging examination. [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.820 (perp=8.475, rec=0.122, cos=0.002), tot_loss_proj:3.691 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting any'think a definition disturbing'a bad emerging.. [SEP]"]
[ 750/2000] tot_loss=1.881 (perp=8.800, rec=0.118, cos=0.002), tot_loss_proj:3.658 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting any'think a definition disturbing'' bad emerging.. [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.851 (perp=8.647, rec=0.120, cos=0.002), tot_loss_proj:3.719 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting any'think to definition disturbing'bad'emerging.. [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.749 (perp=7.856, rec=0.164, cos=0.014), tot_loss_proj:3.519 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting the? think to definition disturbing'bad'emerging '. [SEP]"]
[ 900/2000] tot_loss=1.696 (perp=7.856, rec=0.121, cos=0.003), tot_loss_proj:3.521 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting the? think to definition disturbing'bad'emerging '. [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.627 (perp=7.532, rec=0.118, cos=0.003), tot_loss_proj:3.424 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting the to think? definition disturbing'bad'phrase '. [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.559 (perp=7.249, rec=0.106, cos=0.003), tot_loss_proj:3.343 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting the to think? definition'disturbing'bad'phrase. [SEP]"]
[1050/2000] tot_loss=1.572 (perp=7.249, rec=0.119, cos=0.002), tot_loss_proj:3.344 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting the to think? definition'disturbing'bad'phrase. [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.535 (perp=7.085, rec=0.116, cos=0.002), tot_loss_proj:3.323 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. definition'the'bad'phrase. [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.528 (perp=7.085, rec=0.109, cos=0.002), tot_loss_proj:3.324 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. definition'the'bad'phrase. [SEP]"]
[1200/2000] tot_loss=1.528 (perp=7.085, rec=0.109, cos=0.002), tot_loss_proj:3.323 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. definition'the'bad'phrase. [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.536 (perp=7.085, rec=0.117, cos=0.002), tot_loss_proj:3.325 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. definition'the'bad'phrase. [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.567 (perp=7.240, rec=0.117, cos=0.002), tot_loss_proj:3.408 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. definition'the apparent'bad '. [SEP]"]
[1350/2000] tot_loss=1.560 (perp=7.240, rec=0.110, cos=0.002), tot_loss_proj:3.406 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. definition'the apparent'bad '. [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=1.493 (perp=6.912, rec=0.109, cos=0.002), tot_loss_proj:3.335 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'apparent'bad '. [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.487 (perp=6.912, rec=0.103, cos=0.002), tot_loss_proj:3.336 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'apparent'bad '. [SEP]"]
[1500/2000] tot_loss=1.494 (perp=6.912, rec=0.110, cos=0.002), tot_loss_proj:3.339 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'apparent'bad '. [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.489 (perp=6.912, rec=0.105, cos=0.002), tot_loss_proj:3.332 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'apparent'bad '. [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.497 (perp=6.912, rec=0.113, cos=0.002), tot_loss_proj:3.334 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'apparent'bad '. [SEP]"]
[1650/2000] tot_loss=1.487 (perp=6.912, rec=0.103, cos=0.002), tot_loss_proj:3.338 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'apparent'bad '. [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.503 (perp=6.993, rec=0.103, cos=0.002), tot_loss_proj:3.357 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'remaining'bad '. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.508 (perp=6.993, rec=0.107, cos=0.002), tot_loss_proj:3.357 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'remaining'bad '. [SEP]"]
[1800/2000] tot_loss=1.504 (perp=6.993, rec=0.103, cos=0.002), tot_loss_proj:3.359 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'remaining'bad '. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.506 (perp=6.993, rec=0.105, cos=0.002), tot_loss_proj:3.356 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'remaining'bad '. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.502 (perp=6.993, rec=0.101, cos=0.002), tot_loss_proj:3.357 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'remaining'bad '. [SEP]"]
[1950/2000] tot_loss=1.508 (perp=6.993, rec=0.107, cos=0.002), tot_loss_proj:3.359 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'remaining'bad '. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.499 (perp=6.993, rec=0.099, cos=0.002), tot_loss_proj:3.359 [t=0.31s]
prediction: ["[CLS] a examination appears what definition shooting disturbing to think. the definition'remaining'bad '. [SEP]"]
Done with input #72 of 100.
reference: 
========================
[CLS] a disturbing examination of what appears to be the definition of a'bad'police shooting. [SEP]
========================
predicted: 
========================
[CLS] a examination appears what definition shooting disturbing to think. the definition'remaining'bad '. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 80.000 | r: 70.588
rouge2     | fm: 13.333 | p: 14.286 | r: 12.500
rougeL     | fm: 56.250 | p: 60.000 | r: 52.941
rougeLsum  | fm: 56.250 | p: 60.000 | r: 52.941
r1fm+r2fm = 88.333

[Aggregate metrics]:
rouge1     | fm: 70.142 | p: 69.312 | r: 71.166
rouge2     | fm: 16.714 | p: 16.490 | r: 16.972
rougeL     | fm: 45.030 | p: 44.537 | r: 45.621
rougeLsum  | fm: 44.986 | p: 44.497 | r: 45.604
r1fm+r2fm = 86.857

input #72 time: 0:12:19 | total time: 15:32:57


Running input #73 of 100.
reference: 
========================
like rudy yellow lodge , eyre needs to take a good sweat to clarify his cinematic vision before his next creation and remember the lessons of the trickster spider .
========================
average of cosine similarity 0.9991293989861263
highest_index [0]
highest [0.9991293989861263]
Debug: ids_shape = 33, pads = [33]
Debug: input ids = tensor([[  101,  2066, 18254,  3756,  7410,  1010, 26975,  3791,  2000,  2202,
          1037,  2204,  7518,  2000, 25037,  2010, 21014,  4432,  2077,  2010,
          2279,  4325,  1998,  3342,  1996,  8220,  1997,  1996, 12225,  3334,
          6804,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] like rudy yellow lodge, eyre needs to take a good sweat to clarify his cinematic vision before his next creation and remember the lessons of the trickster spider. [SEP]']
[Init] best rec loss: 0.9040812253952026 for ['[CLS] read priorbre irrelevant post cmaging place cynthia draftalinglinson exclusive accident sherryshi trump oval log room same ja inhaled design much genus amazonbuilding coalition side grant [SEP]']
[Init] best rec loss: 0.8917853236198425 for ['[CLS] crushgroup counter procession alias sentencingperson differently less darling wagon theory hands fine tell wet full fort uppervance same article safety sigmatedgettes such wallpres finishing [SEP]']
[Init] best rec loss: 0.8887541890144348 for ['[CLS]court stoveg waited ⟩ born musicalyd brood photography k oakland response wards finginal lily crownscu [CLS] labelted berlin dinner except above demand beat elected church approved [SEP]']
[Init] best rec loss: 0.8829622268676758 for ['[CLS]lum noteyon portion allowed established although pinch plays bargaining actor lewisrned everyone qu cross costrion really trick advertising / direction flies path capture entitled content our long game [SEP]']
[Init] best rec loss: 0.8726893663406372 for ['[CLS] tobin marketrmin tiffanyair powered briefly pont bce truss steel chervati investigationrdy thick clarksonvert ncaa smart trips ins video arrogant afraid washed popicia sweetheart unlessral [SEP]']
[Init] best rec loss: 0.8703437447547913 for ['[CLS] overᆫ particularlynut in futurewoman suite hands square sailingendra minutes motors onceimated have buried or night agree chat class lipstick perpetualpol classified file counter find gwen [SEP]']
[Init] best rec loss: 0.8613521456718445 for ['[CLS] despite particular nee river phrase yellow house setting she ter recovery observeracker convert assumed signature reid commission well hundred borrowed billy combined big state ;jectrdi eve battlelom [SEP]']
[Init] best rec loss: 0.8569859266281128 for ['[CLS] gentry mill willisishly html body onto hayes dominique voiceτ handicap hymn lastn cody snail [SEP] spice henry holder footprintcopic parking warfare sometimes moments telegram shortly changeiferous [SEP]']
[Init] best rec loss: 0.8565709590911865 for ['[CLS] act ou system off own chance gentle carr trans headlining shaking stack dam shareholder line feather keeper malta progress utc measure home living set clinic racing sale showsated wrongtal [SEP]']
[Init] best rec loss: 0.8428552150726318 for ['[CLS] possible lid yet strangled jonahientivatingword scenes cola overlapping solution fanpling arms working tattoos exhaustedoth hart theology nature murderty tally national bite shadow sonya rapids promise [SEP]']
[Init] best perm rec loss: 0.8380600810050964 for ['[CLS]oth fanty bite scenes cola tattoos shadow working theologyword nature overlapping sonya tallyivating national promise yetient arms murder hart rapids jonahpling strangled solution possible lid exhausted [SEP]']
[Init] best perm rec loss: 0.8349966406822205 for ['[CLS] theology possible armsty bite hart yetword sonya lid murder scenes solutionpling overlapping colaivating fanoth tattoos promiseient national rapids tally strangled shadow nature working exhausted jonah [SEP]']
[Init] best perm rec loss: 0.8346178531646729 for ['[CLS] solution colaoth promise sonya exhausted tally possible bite jonah workingty rapids murder scenesword natureivating tattoos overlapping fan hart yet arms lid theologypling shadow strangledient national [SEP]']
[Init] best perm rec loss: 0.8326810002326965 for ['[CLS] sonya murderpling biteword strangled working yet jonah tattoosivating natureient possible hart tally scenesoth shadow promise national overlapping fan exhausted solution theologyty cola rapids lid arms [SEP]']
[Init] best perm rec loss: 0.8316493034362793 for ['[CLS]ty possible rapidsivating yetoth shadowword tally strangled solutionient hart theology tattoos murder arms sonya lid promise fan jonah exhausted working national cola overlapping scenes nature bitepling [SEP]']
[Init] best perm rec loss: 0.829650342464447 for ['[CLS] promise theologypling sonya cola jonahoth solution murder fan national arms natureivatingword tattoos yet tally bite shadow hart lidty working exhausted rapids possible overlappingient scenes strangled [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.139 (perp=13.060, rec=0.473, cos=0.054), tot_loss_proj:4.418 [t=0.31s]
prediction: ['[CLS] rotterdam relationship teachings catchervah occurs shawn hewitt tribute trophy appearsdiment above game game wonder malay larryudes draft stance started professional respect advised cmll before exclusivereate mary charity [SEP]']
[ 100/2000] tot_loss=3.023 (perp=12.891, rec=0.412, cos=0.033), tot_loss_proj:3.887 [t=0.31s]
prediction: ['[CLS] jerusalem [SEP] spokane rugbygnant experience chriszu animated start names learn fairies a film master schleswig jimmypolis band feet changing forensic renaissanceus oils and remind and urban. [SEP]']
[ 150/2000] tot_loss=2.875 (perp=12.260, rec=0.395, cos=0.028), tot_loss_proj:3.989 [t=0.31s]
prediction: ['[CLS] watch skills the buffy demeanor magic chris eyre ballet start needed the socialist the film relics schleswig jimmypolis band concerns changed forensic scouting former oils success remember and urban. [SEP]']
[ 200/2000] tot_loss=2.632 (perp=11.291, rec=0.331, cos=0.042), tot_loss_proj:3.387 [t=0.31s]
prediction: ['[CLS] watch skills the spider napkin magic chris eyre ballet runner need the socialist his film relics malay jimmypolis vocalist cathy rebuiltiful techniques, ⽥ success remember and urban. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.597 (perp=10.974, rec=0.331, cos=0.071), tot_loss_proj:3.403 [t=0.31s]
prediction: ['[CLS] his skills the spider napkin as chris eyre cinematic vision need lesson dc watch film relics malay jimmyrly finite breath visibleiful remember. ⽥ radio remember remember urban. [SEP]']
[ 300/2000] tot_loss=2.476 (perp=11.133, rec=0.242, cos=0.006), tot_loss_proj:3.321 [t=0.31s]
prediction: ['[CLS] his lessons painting spider napkin as chris eyre cinematic vision needs lessons freshfera cinematic relics malay jimmypolis creation sweat visible honest remember. spider and remember and urban. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.212 (perp=9.863, rec=0.229, cos=0.010), tot_loss_proj:3.615 [t=0.31s]
prediction: ['[CLS] his lessons the spider napkin as chris eyre cinematic vision needs lesson fungus and relics malay cinematic jimmyrly directorial sweat visible his lessons. spider and remember and urban. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.137 (perp=9.530, rec=0.221, cos=0.010), tot_loss_proj:3.099 [t=0.31s]
prediction: ['[CLS] his lessons the spider ₑ as chris eyre cinematic vision needs lesson fungus to old malay frankie spiderrly directorial sweat clarify the lessons. spider and remember and urban. [SEP]']
[ 450/2000] tot_loss=2.011 (perp=8.997, rec=0.205, cos=0.007), tot_loss_proj:2.949 [t=0.31s]
prediction: ['[CLS] his lessons the spider rudy. chris eyre cinematic vision needs the fungus to old malay frankie spiderrly vedic sweat clarify the lessons. spider and remember and urban. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.022 (perp=9.043, rec=0.199, cos=0.014), tot_loss_proj:2.939 [t=0.31s]
prediction: ['[CLS] his lessons the spider rudy. dan eyre cinematic vision needs the fungus to old malay frankie spiderrly vedic sweat clarify the lessons. spider and remember and urban. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.087 (perp=9.431, rec=0.194, cos=0.006), tot_loss_proj:3.304 [t=0.31s]
prediction: ['[CLS] his lessonswrite spider rudy. dan eyre cinematic vision needs the fungus to old malay frankie spiderrly urban sweat clarify the lessons. spider and remember and vedic. [SEP]']
[ 600/2000] tot_loss=2.042 (perp=9.252, rec=0.186, cos=0.006), tot_loss_proj:3.029 [t=0.31s]
prediction: ['[CLS] his lessons the spider rudy. dan eyre cinematic vision needs the fungus to old nutrition frankie spiderrly franchises sweat clarify the lessons. spider and remember and 止. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.167 (perp=9.937, rec=0.175, cos=0.005), tot_loss_proj:3.187 [t=0.31s]
prediction: ['[CLS] his lessons the spider rudy. cain eyre cinematic vision needs clarify fungus to old nutrition and spiderrly franchises sweat clarify the lessons. spider frankie remember and 止. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.098 (perp=9.583, rec=0.176, cos=0.006), tot_loss_proj:3.148 [t=0.31s]
prediction: ['[CLS] his lessons the spider rudy feels nutrition eyre cinematic vision needs clarify fresh to his offensive and spiderrly franchises sweat clarify the lessons. spider frankie remember and ि. [SEP]']
[ 750/2000] tot_loss=2.296 (perp=10.621, rec=0.168, cos=0.004), tot_loss_proj:3.213 [t=0.31s]
prediction: ['[CLS] his lessons yin spider rudy a nutrition eyre cinematic vision needs clarify fresh to the offensive and spiderrly franchises sweat clarify the lessons. spider magician remember and 止. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.231 (perp=10.243, rec=0.178, cos=0.005), tot_loss_proj:2.975 [t=0.31s]
prediction: ['[CLS] his the lessons spider rudy a nutrition eyre cinematic vision needs clarify the to the offensive and spiderrly heal sweat clarify the lessons. spider magician remember and 止. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.128 (perp=9.799, rec=0.165, cos=0.004), tot_loss_proj:2.965 [t=0.31s]
prediction: ['[CLS] his yin lessons spider rudy a nutrition eyre cinematic vision needs clarify the spiderrly franchises to the offensive and sweat clarify the lessons. spider magician remember and 止. [SEP]']
[ 900/2000] tot_loss=2.249 (perp=10.422, rec=0.162, cos=0.003), tot_loss_proj:3.148 [t=0.31s]
prediction: ['[CLS] his yin lessons spider rudy a nutrition eyre cinematic vision needs clarify the spiderrly franchises to the offensive before sweat clarify good lessons. spider magician remember and 止. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.115 (perp=9.753, rec=0.161, cos=0.003), tot_loss_proj:2.864 [t=0.31s]
prediction: ['[CLS] his yin lessons spider rudy a nutrition eyre cinematic vision needs clarify the spiderrly franchises to the offensive and sweat clarify good lessons. magician spider remember and 止. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.145 (perp=9.899, rec=0.162, cos=0.003), tot_loss_proj:3.102 [t=0.31s]
prediction: ['[CLS] his yin lessons spider vision a nutrition eyre cinematic rudy needs clarify the spiderrly eyelids to the offensive before sweat clarify good lessons. magician spider remember and ि. [SEP]']
[1050/2000] tot_loss=2.141 (perp=9.950, rec=0.148, cos=0.002), tot_loss_proj:3.113 [t=0.31s]
prediction: ['[CLS] his yin lessons spider vision a nutrition eyre cinematic rudy needs clarify the spiderrly eyelids to the offensive before sweat clarify good lessons. magician spider remember and 止. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.107 (perp=9.717, rec=0.160, cos=0.003), tot_loss_proj:2.969 [t=0.31s]
prediction: ['[CLS] his the lessons spider vision a nutrition eyre cinematic rudy needs clarify the spiderrly rudy his the offensive to sweat clarify good lessons. nicholas spider remember and ि. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.018 (perp=9.347, rec=0.146, cos=0.002), tot_loss_proj:2.855 [t=0.31s]
prediction: ['[CLS] his the lessons spider vision a nutrition eyre cinematic rudy needs clarify the spiderrly rudy his the offensive to sweat clarify good lessons. nicholas and remember spider ि. [SEP]']
[1200/2000] tot_loss=2.021 (perp=9.347, rec=0.149, cos=0.003), tot_loss_proj:2.851 [t=0.31s]
prediction: ['[CLS] his the lessons spider vision a nutrition eyre cinematic rudy needs clarify the spiderrly rudy his the offensive to sweat clarify good lessons. nicholas and remember spider ि. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.954 (perp=9.041, rec=0.143, cos=0.003), tot_loss_proj:2.775 [t=0.31s]
prediction: ['[CLS] his the lessons spider vision a eyre cinematic rudy needs clarify the spider developed rudy his nutrition the offensive to sweat clarify good lessons. nicholas and remember spider ि. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.927 (perp=8.872, rec=0.150, cos=0.003), tot_loss_proj:2.772 [t=0.31s]
prediction: ['[CLS] his the lessons spider vision the eyre cinematic rudy needs clarify a spiderে rudy his nutrition the offensive to sweat clarify good lessons. nicholas and remember spider ि. [SEP]']
[1350/2000] tot_loss=1.923 (perp=8.872, rec=0.146, cos=0.002), tot_loss_proj:2.769 [t=0.31s]
prediction: ['[CLS] his the lessons spider vision the eyre cinematic rudy needs clarify a spiderে rudy his nutrition the offensive to sweat clarify good lessons. nicholas and remember spider ि. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.911 (perp=8.832, rec=0.142, cos=0.003), tot_loss_proj:2.801 [t=0.31s]
prediction: ['[CLS] his the lessons spider vision the eyre cinematic rudy needs clarify a spider rudy his nutrition the offensiveে to sweat clarify good lessons. nicholas and remember spider ि. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.892 (perp=8.699, rec=0.150, cos=0.002), tot_loss_proj:2.722 [t=0.31s]
prediction: ['[CLS] his lessons the spider vision the eyre cinematic rudy needs clarify a spider rudy his nutrition the offensiveে to sweat clarify good lessons. nicholas and remember spider 止. [SEP]']
[1500/2000] tot_loss=1.879 (perp=8.699, rec=0.138, cos=0.002), tot_loss_proj:2.727 [t=0.31s]
prediction: ['[CLS] his lessons the spider vision the eyre cinematic rudy needs clarify a spider rudy his nutrition the offensiveে to sweat clarify good lessons. nicholas and remember spider 止. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.859 (perp=8.587, rec=0.139, cos=0.002), tot_loss_proj:2.707 [t=0.31s]
prediction: ['[CLS] the lessons the spider vision the eyre cinematic nicholas needs clarify a spider rudy his nutrition the offensiveে to sweat clarify good lessons. rudy and remember spider 止. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.840 (perp=8.483, rec=0.141, cos=0.002), tot_loss_proj:2.758 [t=0.31s]
prediction: ['[CLS] the lessons the spider vision the eyre cinematic nicholas needs clarify a spider rudy his nutrition the offensiveে to sweat clarify good lessons. rudy and spider 止 remember. [SEP]']
[1650/2000] tot_loss=1.838 (perp=8.483, rec=0.139, cos=0.002), tot_loss_proj:2.757 [t=0.31s]
prediction: ['[CLS] the lessons the spider vision the eyre cinematic nicholas needs clarify a spider rudy his nutrition the offensiveে to sweat clarify good lessons. rudy and spider 止 remember. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.843 (perp=8.483, rec=0.145, cos=0.002), tot_loss_proj:2.752 [t=0.31s]
prediction: ['[CLS] the lessons the spider vision the eyre cinematic nicholas needs clarify a spider rudy his nutrition the offensiveে to sweat clarify good lessons. rudy and spider 止 remember. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.819 (perp=8.364, rec=0.144, cos=0.003), tot_loss_proj:2.763 [t=0.31s]
prediction: ['[CLS] the lessons the spider vision the cinematic eyre nicholas needs clarify a spider rudy his nutrition the offensiveে to sweat clarify good lessons. rudy and spider 止 remember. [SEP]']
[1800/2000] tot_loss=1.815 (perp=8.364, rec=0.140, cos=0.002), tot_loss_proj:2.762 [t=0.31s]
prediction: ['[CLS] the lessons the spider vision the cinematic eyre nicholas needs clarify a spider rudy his nutrition the offensiveে to sweat clarify good lessons. rudy and spider 止 remember. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.890 (perp=8.725, rec=0.143, cos=0.002), tot_loss_proj:2.867 [t=0.31s]
prediction: ['[CLS] the lessons the spider vision the cinematic eyre nicholas needs clarify a spider rudy his nutrition the offensiveে to sweat clarify good lessons. rudy and tricks 止 remember. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.857 (perp=8.537, rec=0.147, cos=0.002), tot_loss_proj:2.892 [t=0.31s]
prediction: ['[CLS] the lessons the spider vision the cinematic eyre nicholas needs clarify a spider rudy his nutrition tricks offensiveে to sweat clarify good lessons. rudy and the 止 remember. [SEP]']
[1950/2000] tot_loss=1.853 (perp=8.537, rec=0.144, cos=0.002), tot_loss_proj:2.892 [t=0.31s]
prediction: ['[CLS] the lessons the spider vision the cinematic eyre nicholas needs clarify a spider rudy his nutrition tricks offensiveে to sweat clarify good lessons. rudy and the 止 remember. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.831 (perp=8.458, rec=0.137, cos=0.002), tot_loss_proj:2.855 [t=0.31s]
prediction: ['[CLS] the lessons the spider vision the cinematic nicholas eyre needs clarify a spider rudy his nutrition tricks offensiveে to sweat clarify good lessons. rudy and the 止 remember. [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] like rudy yellow lodge, eyre needs to take a good sweat to clarify his cinematic vision before his next creation and remember the lessons of the trickster spider. [SEP]
========================
predicted: 
========================
[CLS] the lessons the spider vision the cinematic eyre nicholas needs clarify a spider rudy his nutrition the offensiveে to sweat clarify good lessons. rudy and spider 止 remember. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.407 | p: 65.517 | r: 63.333
rouge2     | fm: 3.509 | p: 3.571 | r: 3.448
rougeL     | fm: 30.508 | p: 31.034 | r: 30.000
rougeLsum  | fm: 30.508 | p: 31.034 | r: 30.000
r1fm+r2fm = 67.916

[Aggregate metrics]:
rouge1     | fm: 70.162 | p: 69.390 | r: 71.087
rouge2     | fm: 16.595 | p: 16.373 | r: 16.866
rougeL     | fm: 44.819 | p: 44.394 | r: 45.421
rougeLsum  | fm: 44.883 | p: 44.439 | r: 45.420
r1fm+r2fm = 86.757

input #73 time: 0:12:13 | total time: 15:45:10


Running input #74 of 100.
reference: 
========================
. . . hokey art house pretension .
========================
average of cosine similarity 0.9991247641233078
highest_index [0]
highest [0.9991247641233078]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1012,  1012,  1012,  7570, 14839,  2396,  2160,  3653, 29048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS]... hokey art house pretension. [SEP]']
[Init] best rec loss: 0.960378110408783 for ['[CLS]athan jail though through armistice coupepro iihf besidestis [SEP]']
[Init] best rec loss: 0.9599111676216125 for ['[CLS]mouth reach visual isbn tick staff socially ratio jazz life [SEP]']
[Init] best rec loss: 0.9553504586219788 for ['[CLS] cain elevation least property y bottom website able without explicitly [SEP]']
[Init] best rec loss: 0.8613371849060059 for ['[CLS] penalty wimbledon gun fire [SEP] han prayer inside ham mort [SEP]']
[Init] best rec loss: 0.7893908023834229 for ['[CLS] feature table mercenary flynn tornado trips him junior script bodies [SEP]']
[Init] best rec loss: 0.7875576615333557 for ['[CLS] rr sai rally wales obstaclejun usefulmur u tangent [SEP]']
[Init] best rec loss: 0.7854405641555786 for ['[CLS] exist it own disco failako youtube darker stood murder [SEP]']
[Init] best rec loss: 0.7794028520584106 for ['[CLS] us sl gruff °f fraud rateuring put market savage [SEP]']
[Init] best perm rec loss: 0.7745184898376465 for ['[CLS] us market fraud °f puturing rate savage gruff sl [SEP]']
[Init] best perm rec loss: 0.7738538384437561 for ['[CLS] rate puturing °f us sl gruff fraud savage market [SEP]']
[Init] best perm rec loss: 0.7738144993782043 for ['[CLS] put sl fraud °f marketuring us gruff savage rate [SEP]']
[Init] best perm rec loss: 0.7714832425117493 for ['[CLS] us sl gruff °f frauduring market put savage rate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.286 (perp=10.064, rec=0.264, cos=0.008), tot_loss_proj:3.094 [t=0.30s]
prediction: ["[CLS]key illegal house old arttension'housetension. [SEP]"]
[ 100/2000] tot_loss=2.056 (perp=9.384, rec=0.171, cos=0.008), tot_loss_proj:2.900 [t=0.30s]
prediction: ['[CLS]key art house pre arttensionkey pretension. [SEP]']
[ 150/2000] tot_loss=2.010 (perp=9.384, rec=0.130, cos=0.004), tot_loss_proj:2.912 [t=0.30s]
prediction: ['[CLS]key art house pre arttensionkey pretension. [SEP]']
[ 200/2000] tot_loss=2.117 (perp=10.006, rec=0.112, cos=0.003), tot_loss_proj:3.436 [t=0.30s]
prediction: ['[CLS]key. house pre arttension ho pretension. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.775 (perp=8.290, rec=0.115, cos=0.003), tot_loss_proj:2.895 [t=0.30s]
prediction: ['[CLS]key. art house pretension ho pretension. [SEP]']
[ 300/2000] tot_loss=1.747 (perp=8.290, rec=0.087, cos=0.003), tot_loss_proj:2.902 [t=0.30s]
prediction: ['[CLS]key. art house pretension ho pretension. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.418 (perp=6.595, rec=0.097, cos=0.003), tot_loss_proj:1.738 [t=0.30s]
prediction: ['[CLS] art house pretension hokey. pretension. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.418 (perp=6.595, rec=0.097, cos=0.002), tot_loss_proj:1.738 [t=0.30s]
prediction: ['[CLS] art house pretension hokey. pretension. [SEP]']
[ 450/2000] tot_loss=1.401 (perp=6.595, rec=0.080, cos=0.002), tot_loss_proj:1.741 [t=0.30s]
prediction: ['[CLS] art house pretension hokey. pretension. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.400 (perp=6.595, rec=0.079, cos=0.002), tot_loss_proj:1.740 [t=0.30s]
prediction: ['[CLS] art house pretension hokey. pretension. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.405 (perp=6.595, rec=0.084, cos=0.002), tot_loss_proj:1.738 [t=0.30s]
prediction: ['[CLS] art house pretension hokey. pretension. [SEP]']
[ 600/2000] tot_loss=1.396 (perp=6.595, rec=0.076, cos=0.002), tot_loss_proj:1.738 [t=0.30s]
prediction: ['[CLS] art house pretension hokey. pretension. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.389 (perp=6.595, rec=0.068, cos=0.002), tot_loss_proj:1.742 [t=0.30s]
prediction: ['[CLS] art house pretension hokey. pretension. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.604 (perp=7.665, rec=0.069, cos=0.002), tot_loss_proj:2.097 [t=0.30s]
prediction: ['[CLS] art house pretension hokey..tension. [SEP]']
[ 750/2000] tot_loss=1.598 (perp=7.665, rec=0.063, cos=0.002), tot_loss_proj:2.101 [t=0.30s]
prediction: ['[CLS] art house pretension hokey..tension. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.563 (perp=7.502, rec=0.061, cos=0.002), tot_loss_proj:2.003 [t=0.30s]
prediction: ['[CLS] art house pretension. hokey.tension. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.480 (perp=7.027, rec=0.072, cos=0.003), tot_loss_proj:2.352 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
[ 900/2000] tot_loss=1.481 (perp=7.027, rec=0.074, cos=0.002), tot_loss_proj:2.343 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.465 (perp=7.027, rec=0.058, cos=0.002), tot_loss_proj:2.346 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.478 (perp=7.027, rec=0.071, cos=0.002), tot_loss_proj:2.343 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
[1050/2000] tot_loss=1.472 (perp=7.027, rec=0.064, cos=0.002), tot_loss_proj:2.344 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.465 (perp=7.027, rec=0.058, cos=0.002), tot_loss_proj:2.343 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.478 (perp=7.027, rec=0.071, cos=0.002), tot_loss_proj:2.342 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
[1200/2000] tot_loss=1.479 (perp=7.027, rec=0.072, cos=0.002), tot_loss_proj:2.346 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.476 (perp=7.027, rec=0.069, cos=0.002), tot_loss_proj:2.338 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.474 (perp=7.027, rec=0.067, cos=0.002), tot_loss_proj:2.351 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
[1350/2000] tot_loss=1.470 (perp=7.027, rec=0.062, cos=0.002), tot_loss_proj:2.346 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.478 (perp=7.027, rec=0.071, cos=0.002), tot_loss_proj:2.343 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.484 (perp=7.027, rec=0.077, cos=0.002), tot_loss_proj:2.335 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
[1500/2000] tot_loss=1.468 (perp=7.027, rec=0.061, cos=0.002), tot_loss_proj:2.339 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.472 (perp=7.027, rec=0.064, cos=0.002), tot_loss_proj:2.339 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.478 (perp=7.027, rec=0.071, cos=0.002), tot_loss_proj:2.337 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
[1650/2000] tot_loss=1.471 (perp=7.027, rec=0.064, cos=0.002), tot_loss_proj:2.343 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.469 (perp=7.027, rec=0.062, cos=0.002), tot_loss_proj:2.340 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.465 (perp=7.027, rec=0.058, cos=0.002), tot_loss_proj:2.337 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
[1800/2000] tot_loss=1.472 (perp=7.027, rec=0.065, cos=0.002), tot_loss_proj:2.349 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.475 (perp=7.027, rec=0.068, cos=0.002), tot_loss_proj:2.336 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.473 (perp=7.027, rec=0.066, cos=0.002), tot_loss_proj:2.334 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
[1950/2000] tot_loss=1.466 (perp=7.027, rec=0.059, cos=0.002), tot_loss_proj:2.340 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.476 (perp=7.027, rec=0.069, cos=0.002), tot_loss_proj:2.340 [t=0.30s]
prediction: ['[CLS] art. pretension. hokey housetension. [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS]... hokey art house pretension. [SEP]
========================
predicted: 
========================
[CLS] art. pretension. hokey housetension. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 83.333

[Aggregate metrics]:
rouge1     | fm: 70.220 | p: 69.390 | r: 71.201
rouge2     | fm: 16.316 | p: 16.122 | r: 16.588
rougeL     | fm: 45.130 | p: 44.674 | r: 45.725
rougeLsum  | fm: 45.126 | p: 44.710 | r: 45.713
r1fm+r2fm = 86.536

input #74 time: 0:12:01 | total time: 15:57:12


Running input #75 of 100.
reference: 
========================
if you enjoy being rewarded by a script that assumes you aren't very bright , then blood work is for you .
========================
average of cosine similarity 0.9992306968388511
highest_index [0]
highest [0.9992306968388511]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  2065,  2017,  5959,  2108, 14610,  2011,  1037,  5896,  2008,
         15980,  2017,  4995,  1005,  1056,  2200,  4408,  1010,  2059,  2668,
          2147,  2003,  2005,  2017,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] if you enjoy being rewarded by a script that assumes you aren't very bright, then blood work is for you. [SEP]"]
[Init] best rec loss: 0.8915174007415771 for ['[CLS] hit conducted ste extra civil perry reno untilnight? slash clive sanan forestsrred municipality aura agenttagram fur rising himself cook [SEP]']
[Init] best rec loss: 0.8439821600914001 for ['[CLS] opt uc wondered 2009 humoryt condition hour seeing downs defendant outta arms its rick never springpointtation about regiment fields recorded given [SEP]']
[Init] best rec loss: 0.8252319097518921 for ['[CLS] appointments resigned that hook nodium miss sorry main hoseship rust ounce bay shelf peckographic manymainson outside gender pulls geographic [SEP]']
[Init] best rec loss: 0.7842442989349365 for ['[CLS] sameful green night street formula sandals guiltyeebrview chief unrest or terror conference compactulating mere great file husband editing see [SEP]']
[Init] best rec loss: 0.7683471441268921 for ['[CLS] onto colonial producing cardinal jones challenge # invalidrightignmentmos box filling broadwayey cell should curved driving mike friendly proves eyesgm [SEP]']
[Init] best perm rec loss: 0.7676997184753418 for ['[CLS] filling broadway invalid onto box producing celley colonialmos provesright should friendly mikeignment # driving challenge curved eyesgm cardinal jones [SEP]']
[Init] best perm rec loss: 0.7656573057174683 for ['[CLS]mos curvedignment eyes cardinal # box should broadway friendly challenge producing cell colonial fillingeygm proves invalid driving ontoright jones mike [SEP]']
[Init] best perm rec loss: 0.7656533122062683 for ['[CLS] friendly eyes invalid proves producing filling curved cellignment should jones broadway cardinalmos onto drivingright colonial boxgm #ey mike challenge [SEP]']
[Init] best perm rec loss: 0.7651118040084839 for ['[CLS] should filling eyes broadway driving friendlymos ontogmignment cardinal curved # proves cell mike jones invalidey producing colonial boxright challenge [SEP]']
[Init] best perm rec loss: 0.7642354965209961 for ['[CLS] curved colonial challenge eyes onto boxignment jonesey drivinggm producing proves cell invalidmos mikeright friendly broadway cardinal should # filling [SEP]']
[Init] best perm rec loss: 0.7609724402427673 for ['[CLS]gmey eyes should fillingmos broadway onto invalid driving mike cell producing challenge jones proves colonial box cardinalright # friendlyignment curved [SEP]']
[Init] best perm rec loss: 0.7597733736038208 for ['[CLS] filling # box jones producing invalid colonial provesey shouldignment eyes broadway challenge driving ontorightgm curved mike cell friendlymos cardinal [SEP]']
[Init] best perm rec loss: 0.7581337690353394 for ['[CLS]gm provesmos challenge producing curved jones driving #right invalidey box friendly mike cell filling eyes cardinal broadway ontoignment should colonial [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.670 (perp=11.301, rec=0.379, cos=0.031), tot_loss_proj:3.646 [t=0.31s]
prediction: ['[CLS] reborn retired musical middle subsistence stellar is flying blood. forest pee card islands kelly, blood sweat. blood blood foreign stirling fraud [SEP]']
[ 100/2000] tot_loss=2.440 (perp=10.903, rec=0.251, cos=0.008), tot_loss_proj:4.092 [t=0.31s]
prediction: ['[CLS] redemption senior script north viscount if script enough blood. association fan field woods good, blood work. blood blood script script work [SEP]']
[ 150/2000] tot_loss=2.364 (perp=10.647, rec=0.209, cos=0.026), tot_loss_proj:3.885 [t=0.31s]
prediction: ['[CLS] redemption mackenzie script know attend if script them blood. are bright field officials favored then blood work. blood blood script script work [SEP]']
[ 200/2000] tot_loss=2.438 (perp=11.135, rec=0.186, cos=0.026), tot_loss_proj:3.928 [t=0.31s]
prediction: ['[CLS] rewarded when script know attend if script them blood is are suppose card is [SEP] then blood work. blood blood script script work [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.200 (perp=10.274, rec=0.141, cos=0.005), tot_loss_proj:3.946 [t=0.31s]
prediction: ['[CLS] enjoy enjoyed you really gabe if script the blood is areriguenie me from then is work. blood blood script script work [SEP]']
[ 300/2000] tot_loss=2.191 (perp=10.228, rec=0.136, cos=0.009), tot_loss_proj:3.909 [t=0.31s]
prediction: ['[CLS] rewarded enjoyed you that gabe if script the blood is are you vehicle me when then is for. blood blood bright script work [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.096 (perp=9.855, rec=0.121, cos=0.004), tot_loss_proj:3.809 [t=0.31s]
prediction: ['[CLS] alex enjoy you that rewarded if script the blood is are you t me when then is for. blood blood bright script work [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.083 (perp=9.845, rec=0.111, cos=0.003), tot_loss_proj:3.826 [t=0.31s]
prediction: ['[CLS] alex that you enjoy rewarded if script the blood is are you t me ensure then is for. blood blood bright script work [SEP]']
[ 450/2000] tot_loss=2.118 (perp=10.036, rec=0.108, cos=0.002), tot_loss_proj:3.925 [t=0.31s]
prediction: ['[CLS] alex that you enjoy rewarded if script bright that is are you t me ensure then is for. blood blood bright script work [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.254 (perp=10.720, rec=0.107, cos=0.002), tot_loss_proj:4.035 [t=0.31s]
prediction: ['[CLS] for that you enjoy rewarded if script a it is are doesn t nets ensure then is alex. blood blood bright script work [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.040 (perp=9.654, rec=0.107, cos=0.002), tot_loss_proj:3.873 [t=0.31s]
prediction: ['[CLS] for that you enjoy rewarded if script a it is a you t nets assumes then is work. blood blood bright script alex [SEP]']
[ 600/2000] tot_loss=2.134 (perp=10.197, rec=0.092, cos=0.002), tot_loss_proj:3.971 [t=0.31s]
prediction: ['[CLS] for that you enjoy rewarded if script a it is a doesn t nets assumes then is work. blood blood bright script alex [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.056 (perp=9.806, rec=0.093, cos=0.002), tot_loss_proj:3.880 [t=0.31s]
prediction: ['[CLS] for that you enjoy rewarded if script a it is a doesn nets t assumes then is work. blood blood bright script alex [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.951 (perp=9.305, rec=0.088, cos=0.002), tot_loss_proj:3.760 [t=0.31s]
prediction: ['[CLS] for that if you enjoy rewarded script a it is a doesn politics t assumes then is work. you blood bright script alex [SEP]']
[ 750/2000] tot_loss=1.946 (perp=9.305, rec=0.083, cos=0.002), tot_loss_proj:3.764 [t=0.31s]
prediction: ['[CLS] for that if you enjoy rewarded script a it is a doesn politics t assumes then is work. you blood bright script alex [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.911 (perp=9.069, rec=0.096, cos=0.002), tot_loss_proj:3.713 [t=0.31s]
prediction: ['[CLS] for that if you enjoy rewarded script a assumes it is a doesn politics t then is work. you blood bright script alex [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.883 (perp=8.906, rec=0.099, cos=0.003), tot_loss_proj:3.697 [t=0.31s]
prediction: ['[CLS] for a if you enjoy rewarded script a assumes it is you doesn politics t then a blood work. you bright script alex [SEP]']
[ 900/2000] tot_loss=1.869 (perp=8.888, rec=0.090, cos=0.002), tot_loss_proj:3.658 [t=0.31s]
prediction: ['[CLS] for a if you enjoy rewarded script a assumes it is you doesn politics t then is blood work. you bright script alex [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.818 (perp=8.664, rec=0.083, cos=0.002), tot_loss_proj:3.631 [t=0.31s]
prediction: ['[CLS] for a if you enjoy rewarded script a then assumes it is you doesn politics t a blood work. you bright script alex [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.784 (perp=8.476, rec=0.087, cos=0.002), tot_loss_proj:3.601 [t=0.31s]
prediction: ['[CLS] for a if you enjoy rewarded script a then assumes it is you doesn politics is t blood work. you bright script alex [SEP]']
[1050/2000] tot_loss=1.824 (perp=8.673, rec=0.087, cos=0.002), tot_loss_proj:3.560 [t=0.31s]
prediction: ['[CLS] for a if you enjoy rewarded script a then assumes it is you doesn nets is t blood work. you bright script alex [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.810 (perp=8.579, rec=0.093, cos=0.002), tot_loss_proj:3.638 [t=0.31s]
prediction: ['[CLS] for a if you enjoy rewarded script a then assumes it is you doesn nets is t blood. you work bright script alex [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.780 (perp=8.463, rec=0.085, cos=0.002), tot_loss_proj:3.580 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script a then assumes it is you doesn nets is t blood. you work bright script alex [SEP]']
[1200/2000] tot_loss=1.787 (perp=8.463, rec=0.093, cos=0.002), tot_loss_proj:3.580 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script a then assumes it is you doesn nets is t blood. you work bright script alex [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.718 (perp=8.153, rec=0.086, cos=0.002), tot_loss_proj:3.504 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script a then assumes it is t you doesn politics a blood. you work bright script alex [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.683 (perp=8.013, rec=0.079, cos=0.002), tot_loss_proj:3.501 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script by t assumes it is then you doesn politics a blood. you work bright script alex [SEP]']
[1350/2000] tot_loss=1.683 (perp=7.976, rec=0.087, cos=0.002), tot_loss_proj:3.498 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script by t assumes it is then you doesn politics, blood. you work bright script alex [SEP]']
Attempt swap
[1400/2000] tot_loss=1.678 (perp=7.976, rec=0.081, cos=0.002), tot_loss_proj:3.496 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script by t assumes it is then you doesn politics, blood. you work bright script alex [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.659 (perp=7.870, rec=0.083, cos=0.002), tot_loss_proj:3.491 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script by t assumes it is then you doesn alex, blood. you work bright script politics [SEP]']
[1500/2000] tot_loss=1.660 (perp=7.870, rec=0.084, cos=0.002), tot_loss_proj:3.491 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script by t assumes it is then you doesn alex, blood. you work bright script politics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.664 (perp=7.870, rec=0.088, cos=0.002), tot_loss_proj:3.493 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script by t assumes it is then you doesn alex, blood. you work bright script politics [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.682 (perp=7.976, rec=0.086, cos=0.002), tot_loss_proj:3.496 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script by t assumes it is then you doesn politics, blood. you work bright script alex [SEP]']
[1650/2000] tot_loss=1.686 (perp=7.976, rec=0.089, cos=0.002), tot_loss_proj:3.499 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script by t assumes it is then you doesn politics, blood. you work bright script alex [SEP]']
Attempt swap
[1700/2000] tot_loss=1.681 (perp=7.976, rec=0.084, cos=0.002), tot_loss_proj:3.497 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script by t assumes it is then you doesn politics, blood. you work bright script alex [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.666 (perp=7.884, rec=0.087, cos=0.002), tot_loss_proj:3.471 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script, by t assumes it is then you doesn politics blood. you work bright script alex [SEP]']
[1800/2000] tot_loss=1.717 (perp=8.144, rec=0.087, cos=0.002), tot_loss_proj:3.538 [t=0.31s]
prediction: ['[CLS] for if you enjoy a rewarded script a by t assumes it is then you doesn politics blood. you work bright script alex [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.749 (perp=8.306, rec=0.086, cos=0.002), tot_loss_proj:3.534 [t=0.31s]
prediction: ['[CLS] for if you enjoy a script a rewarded by t assumes it is then you bright nets blood. you work bright script alex [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.740 (perp=8.218, rec=0.094, cos=0.002), tot_loss_proj:3.488 [t=0.31s]
prediction: ['[CLS] for if you enjoy a script a rewarded by t assumes it is then bright you nets blood. you work bright script alex [SEP]']
[1950/2000] tot_loss=1.729 (perp=8.218, rec=0.084, cos=0.002), tot_loss_proj:3.488 [t=0.31s]
prediction: ['[CLS] for if you enjoy a script a rewarded by t assumes it is then bright you nets blood. you work bright script alex [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.682 (perp=8.016, rec=0.077, cos=0.002), tot_loss_proj:3.329 [t=0.31s]
prediction: ['[CLS] for if you enjoy a script a rewarded by t assumes it is bright then you nets blood. you work bright script alex [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] if you enjoy being rewarded by a script that assumes you aren't very bright, then blood work is for you. [SEP]
========================
predicted: 
========================
[CLS] for if you enjoy a rewarded script by t assumes it is then you doesn politics a blood. you work bright script alex [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 79.167 | p: 76.000 | r: 82.609
rouge2     | fm: 8.696 | p: 8.333 | r: 9.091
rougeL     | fm: 45.833 | p: 44.000 | r: 47.826
rougeLsum  | fm: 45.833 | p: 44.000 | r: 47.826
r1fm+r2fm = 87.862

[Aggregate metrics]:
rouge1     | fm: 70.398 | p: 69.523 | r: 71.453
rouge2     | fm: 16.098 | p: 15.927 | r: 16.366
rougeL     | fm: 45.056 | p: 44.574 | r: 45.714
rougeLsum  | fm: 45.163 | p: 44.757 | r: 45.715
r1fm+r2fm = 86.496

input #75 time: 0:12:20 | total time: 16:09:32


Running input #76 of 100.
reference: 
========================
an exciting and involving rock music doc , a smart and satisfying look inside that tumultuous world .
========================
average of cosine similarity 0.9994663443191549
highest_index [0]
highest [0.9994663443191549]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  2019, 10990,  1998,  5994,  2600,  2189,  9986,  1010,  1037,
          6047,  1998, 17087,  2298,  2503,  2008, 10722, 12274,  7096,  8918,
          2088,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] an exciting and involving rock music doc, a smart and satisfying look inside that tumultuous world. [SEP]']
[Init] best rec loss: 0.9721624255180359 for ['[CLS] others loganhia coat well detail barked less maccabi later muchtracted fatal brock tip resistance wordciency hostile drops career [SEP]']
[Init] best rec loss: 0.9469491839408875 for ['[CLS]mental petersburg latter bat victor dates doubled hospital about species than smackdown lanka allrance blood across average smug window close [SEP]']
[Init] best rec loss: 0.9455471038818359 for ['[CLS] boss pioneereur born tires managing wait beside reality atomic food add sure vimes convoy school busted stream trip ion bait [SEP]']
[Init] best perm rec loss: 0.9437608122825623 for ['[CLS] ion trip food boss pioneer busted vimes add wait managing tires bait convoy born beside sure reality atomiceur stream school [SEP]']
[Init] best perm rec loss: 0.94171541929245 for ['[CLS] wait bait trip tires managingeur stream school busted ion boss pioneer food convoy beside reality atomic vimes sure add born [SEP]']
[Init] best perm rec loss: 0.9406474232673645 for ['[CLS] tires atomic beside bait reality wait ion vimes boss trip managing stream add sure born school convoyeur busted food pioneer [SEP]']
[Init] best perm rec loss: 0.9373888969421387 for ['[CLS] tires trip realityeur convoy bait vimes stream pioneer beside busted managing food ion sure atomic school add born wait boss [SEP]']
[Init] best perm rec loss: 0.9373669028282166 for ['[CLS] ion school food sure boss bait tires vimes stream managing born convoy pioneer wait atomic busted add trip reality besideeur [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.206 (perp=9.726, rec=0.255, cos=0.006), tot_loss_proj:2.929 [t=0.31s]
prediction: ['[CLS] satisfying ; bright belle logical music music doc doc interesting exciting musical experience feeling °f for exciting doc tonight rock. [SEP]']
[ 100/2000] tot_loss=2.437 (perp=11.251, rec=0.183, cos=0.003), tot_loss_proj:3.492 [t=0.31s]
prediction: ['[CLS] exciting an brightra involving music music doc doc exciting exciting doc look feeling ji into exciting doc tonight rock. [SEP]']
[ 150/2000] tot_loss=2.343 (perp=10.956, rec=0.150, cos=0.002), tot_loss_proj:3.295 [t=0.31s]
prediction: ['[CLS] exciting an brightra involving music music doc doc exciting a and look feeling an into exciting doc tonight rock. [SEP]']
[ 200/2000] tot_loss=2.146 (perp=10.105, rec=0.124, cos=0.001), tot_loss_proj:2.807 [t=0.31s]
prediction: ['[CLS] exciting an bright romanized involving music music doc doc, a and look satisfying and inside smart docuous rock. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.044 (perp=9.678, rec=0.107, cos=0.001), tot_loss_proj:2.671 [t=0.31s]
prediction: ['[CLS] exciting an world romanized involving music musiclt doc, and a look satisfying and inside smart docuous rock. [SEP]']
[ 300/2000] tot_loss=2.043 (perp=9.678, rec=0.107, cos=0.001), tot_loss_proj:2.679 [t=0.31s]
prediction: ['[CLS] exciting an world romanized involving music musiclt doc, and a look satisfying and inside smart docuous rock. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.970 (perp=9.365, rec=0.096, cos=0.001), tot_loss_proj:2.586 [t=0.31s]
prediction: ['[CLS] exciting an world romanized involving music musiclt doc, and a satisfying look and inside smart docuous rock. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.881 (perp=8.755, rec=0.128, cos=0.001), tot_loss_proj:2.577 [t=0.31s]
prediction: ['[CLS] exciting music world romanized involving music anlt doc, and a satisfying look and inside smart docuous rock. [SEP]']
[ 450/2000] tot_loss=1.856 (perp=8.831, rec=0.088, cos=0.001), tot_loss_proj:2.470 [t=0.31s]
prediction: ['[CLS] exciting music worlduous involving music anlt doc, and a satisfying look and inside smart docuous rock. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.729 (perp=8.125, rec=0.103, cos=0.001), tot_loss_proj:2.313 [t=0.31s]
prediction: ['[CLS] exciting music that involving music anltuous doc, and a satisfying look and inside smart docuous rock. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.649 (perp=7.755, rec=0.097, cos=0.001), tot_loss_proj:2.072 [t=0.31s]
prediction: ['[CLS] exciting music that involving music anlt world doc, and a satisfying look inside smart and docuous rock. [SEP]']
[ 600/2000] tot_loss=1.646 (perp=7.755, rec=0.094, cos=0.001), tot_loss_proj:2.064 [t=0.31s]
prediction: ['[CLS] exciting music that involving music anlt world doc, and a satisfying look inside smart and docuous rock. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.557 (perp=7.330, rec=0.090, cos=0.001), tot_loss_proj:2.002 [t=0.31s]
prediction: ['[CLS] exciting music that involving music doc anlt world, and a satisfying look inside smart and docuous rock. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.556 (perp=7.300, rec=0.095, cos=0.001), tot_loss_proj:2.062 [t=0.31s]
prediction: ['[CLS] that music exciting involving music doc anlt world, and a satisfying look inside smart and docuous rock. [SEP]']
[ 750/2000] tot_loss=1.538 (perp=7.300, rec=0.077, cos=0.001), tot_loss_proj:2.057 [t=0.31s]
prediction: ['[CLS] that music exciting involving music doc anlt world, and a satisfying look inside smart and docuous rock. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.521 (perp=7.212, rec=0.077, cos=0.001), tot_loss_proj:2.050 [t=0.31s]
prediction: ['[CLS] that music doc involving music doc anlt world, and a satisfying look inside smart and excitinguous rock. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.427 (perp=6.631, rec=0.099, cos=0.001), tot_loss_proj:1.799 [t=0.31s]
prediction: ['[CLS] that music doc involving music doc an exciting world, and a satisfying look inside smart andltuous rock. [SEP]']
[ 900/2000] tot_loss=1.431 (perp=6.631, rec=0.103, cos=0.001), tot_loss_proj:1.785 [t=0.31s]
prediction: ['[CLS] that music doc involving music doc an exciting world, and a satisfying look inside smart andltuous rock. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.381 (perp=6.477, rec=0.084, cos=0.001), tot_loss_proj:1.829 [t=0.31s]
prediction: ['[CLS] that music doc involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.389 (perp=6.477, rec=0.093, cos=0.001), tot_loss_proj:1.833 [t=0.31s]
prediction: ['[CLS] that music doc involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
[1050/2000] tot_loss=1.374 (perp=6.477, rec=0.078, cos=0.001), tot_loss_proj:1.832 [t=0.31s]
prediction: ['[CLS] that music doc involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.380 (perp=6.477, rec=0.083, cos=0.001), tot_loss_proj:1.836 [t=0.31s]
prediction: ['[CLS] that music doc involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.507 (perp=7.131, rec=0.080, cos=0.001), tot_loss_proj:1.987 [t=0.31s]
prediction: ['[CLS] that musicuous involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
[1200/2000] tot_loss=1.502 (perp=7.131, rec=0.075, cos=0.001), tot_loss_proj:1.994 [t=0.31s]
prediction: ['[CLS] that musicuous involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.507 (perp=7.131, rec=0.080, cos=0.001), tot_loss_proj:1.994 [t=0.31s]
prediction: ['[CLS] that musicuous involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.472 (perp=6.956, rec=0.079, cos=0.001), tot_loss_proj:1.940 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
[1350/2000] tot_loss=1.479 (perp=6.956, rec=0.087, cos=0.001), tot_loss_proj:1.942 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.477 (perp=6.956, rec=0.085, cos=0.001), tot_loss_proj:1.941 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.475 (perp=6.956, rec=0.083, cos=0.001), tot_loss_proj:1.943 [t=0.32s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
[1500/2000] tot_loss=1.470 (perp=6.956, rec=0.078, cos=0.001), tot_loss_proj:1.942 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.471 (perp=6.956, rec=0.078, cos=0.001), tot_loss_proj:1.941 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.469 (perp=6.956, rec=0.077, cos=0.001), tot_loss_proj:1.945 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
[1650/2000] tot_loss=1.475 (perp=6.956, rec=0.083, cos=0.001), tot_loss_proj:1.942 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.473 (perp=6.956, rec=0.081, cos=0.001), tot_loss_proj:1.943 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.472 (perp=6.956, rec=0.079, cos=0.001), tot_loss_proj:1.939 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
[1800/2000] tot_loss=1.473 (perp=6.956, rec=0.080, cos=0.001), tot_loss_proj:1.944 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.474 (perp=6.956, rec=0.081, cos=0.001), tot_loss_proj:1.944 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.473 (perp=6.956, rec=0.081, cos=0.001), tot_loss_proj:1.943 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
[1950/2000] tot_loss=1.471 (perp=6.956, rec=0.079, cos=0.001), tot_loss_proj:1.942 [t=0.31s]
prediction: ['[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.447 (perp=6.832, rec=0.080, cos=0.001), tot_loss_proj:1.991 [t=0.31s]
prediction: ['[CLS] thatuous music involving an exciting world music doc, and a satisfying look inside smart and rockltuous. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS] an exciting and involving rock music doc, a smart and satisfying look inside that tumultuous world. [SEP]
========================
predicted: 
========================
[CLS] thatuous music involving music doc an exciting world, and a satisfying look inside smart and rockltuous. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 29.412 | p: 29.412 | r: 29.412
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 112.745

[Aggregate metrics]:
rouge1     | fm: 70.582 | p: 69.753 | r: 71.547
rouge2     | fm: 16.359 | p: 16.169 | r: 16.610
rougeL     | fm: 45.140 | p: 44.697 | r: 45.762
rougeLsum  | fm: 45.183 | p: 44.739 | r: 45.820
r1fm+r2fm = 86.941

input #76 time: 0:12:20 | total time: 16:21:53


Running input #77 of 100.
reference: 
========================
it's consistently funny , in an irresistible junior-high way , and consistently free of any gag that would force you to give it a millisecond of thought .
========================
average of cosine similarity 0.9994252233227274
highest_index [0]
highest [0.9994252233227274]
Debug: ids_shape = 37, pads = [37]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 10862,  6057,  1010,  1999,  2019, 27149,
          3502,  1011,  2152,  2126,  1010,  1998, 10862,  2489,  1997,  2151,
         18201,  2008,  2052,  2486,  2017,  2000,  2507,  2009,  1037,  4971,
          5562,  8663,  2094,  1997,  2245,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] it's consistently funny, in an irresistible junior - high way, and consistently free of any gag that would force you to give it a millisecond of thought. [SEP]"]
[Init] best rec loss: 0.9372657537460327 for ['[CLS] rich \\ nothing knowles luggage of venezuelan working we freak late caves already heart army throw experience field decade ballistic themselves upon survivesitive interesting intact curtis whitehead gas reed hanging debt feeding 5 syrian [SEP]']
[Init] best rec loss: 0.928211510181427 for ['[CLS] proof middle asteroidointosaurusndo professionals corpsesah $ marshass music parent my chronicle possible recognition hudson nationalities raven find fixed really light ro mixed marshallrian wild f necklace sabha craft orphan [SEP]']
[Init] best rec loss: 0.9270123839378357 for ['[CLS] enough walk depends behind transmission oliver [MASK] jelly pro falling trailed ranged bitel gene placed wren highness secrets harmless starredtes halt wrath honours blind options yard means further frame firm concession british fide [SEP]']
[Init] best rec loss: 0.9261589646339417 for ['[CLS] minded spa brightest heavier successful logistics joint theirs barak strong kg restaurant mean belief dc ice sat ladiesricglassome best sts doubles water elevator willyitical criminal cm coroner making lyndon numbers credits [SEP]']
[Init] best rec loss: 0.9258788228034973 for ['[CLS] present monthstyn namenium today grounds wales faith station charterwife naturaltivitaire fabric my self away aircraft en were limp representation coliseum for motion hot swat jaov cloud coe range page [SEP]']
[Init] best rec loss: 0.9174375534057617 for ['[CLS] studied minimum setethcased walker luxiveanies technology eurovision 00pm jump called chances as breadth prefectureose test squad 7 point while acquisition circles does folklore castle human square 4th recommended just im [SEP]']
[Init] best perm rec loss: 0.9155999422073364 for ['[CLS] as technology just lux human studied 7 eurovisioncasedanies folklore im doesose called 00pm prefecture chanceseth castle set test minimum while squareive circles recommended jump walker acquisition breadth point squad 4th [SEP]']
[Init] best perm rec loss: 0.9149574637413025 for ['[CLS] breadth circles just asive eurovision test human 4thanies lux acquisition castle walker 7 jump technology set doesose square called while im folklore studied prefecture minimum squadcased pointeth recommended chances 00pm [SEP]']
[Init] best perm rec loss: 0.9143394827842712 for ['[CLS] just folklore walker breadthcased square squad castle humaneth 4thanies chances recommendedive set called im lux minimum while studied prefecture does 00pm as eurovision 7 point technology acquisition jump test circlesose [SEP]']
[Init] best perm rec loss: 0.9143056869506836 for ['[CLS] breadth studied 00pm asivecased 4th circleseth recommended acquisition eurovision 7 castle prefecture luxanies im square squad point minimum walkerose called does folklore just human while jump technology test set chances [SEP]']
[Init] best perm rec loss: 0.9133850932121277 for ['[CLS] while circles square acquisition testive chances breadth jump 00pm as point castle does just human luxaniesose eurovision 4th 7 im studied walker prefecture recommended seteth technology calledcased minimum squad folklore [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.652 (perp=11.453, rec=0.340, cos=0.022), tot_loss_proj:3.743 [t=0.31s]
prediction: ['[CLS] literary something consistently often funny born funny often outgoing australianmer sounded chamber\'rogers instrumental area consistently institution london\'south tristan up 2nd bass u " advocate both department easily an category personal [SEP]']
[ 100/2000] tot_loss=2.665 (perp=11.736, rec=0.304, cos=0.014), tot_loss_proj:3.305 [t=0.31s]
prediction: ['[CLS] literary its consistently irresistible funny based funny often irresistible gag irresistible big a of rogers high area consistently funny london ( mexico georgia of juniorvil upper outletnan consistently ). an solid distinctive [SEP]']
[ 150/2000] tot_loss=2.339 (perp=10.362, rec=0.259, cos=0.008), tot_loss_proj:2.926 [t=0.31s]
prediction: ["[CLS] you its is irresistible funny. funny free irresistible gag irresistible low instrumental of men junior school consistently irresistible i, de harris'mfa university literary 'nan consistently michigan. an and provocative [SEP]"]
[ 200/2000] tot_loss=2.236 (perp=10.117, rec=0.207, cos=0.005), tot_loss_proj:2.954 [t=0.31s]
prediction: ['[CLS] you it is irresistible funny, funny free irresistible gag《 high an of men junior school consistently irresistible junction, mexico - me junior university literary a category consistently ohio.. and consonant [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.202 (perp=9.846, rec=0.227, cos=0.005), tot_loss_proj:2.888 [t=0.31s]
prediction: ['[CLS] you it is irresistible funny, funny free irresistible gag of junior. creative of five society consistently irresistible placement -que - ofbu higher literary a allegro consistently ohio.. and popular [SEP]']
[ 300/2000] tot_loss=2.228 (perp=10.011, rec=0.220, cos=0.006), tot_loss_proj:3.152 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, funny free, gag of junior. an toon junior consistently irresistible paused. a jessie of bb high literary a une consistently ohio sometimes. and consonant [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.229 (perp=10.147, rec=0.195, cos=0.004), tot_loss_proj:2.993 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, funny free to gag of junior - an art high of consistently irresistible gag - - ® herself contender ள literary a issn consistently ohio sometimes. and consonant [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.156 (perp=9.863, rec=0.180, cos=0.004), tot_loss_proj:2.954 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, funny free to gag of junior - an gag high of consistently irresistible gag - - ® of probe ள literary any thank consonant consistently michigan sometimes. and [SEP]']
[ 450/2000] tot_loss=2.165 (perp=10.028, rec=0.156, cos=0.003), tot_loss_proj:3.157 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, funny free any gag of junior - an gag high of consistently irresistible gag way - prophecy of mega ள literary any gave consonant consistently michigan sometimes. and [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.094 (perp=9.596, rec=0.172, cos=0.003), tot_loss_proj:2.910 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, funny free any gag of junior - an gag high of consistently irresistible gag way - prophecy of mega michigan would any gave consonant consistently ள where. and [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.008 (perp=9.305, rec=0.144, cos=0.002), tot_loss_proj:2.856 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, funny free any gag - junior - an gag high of consistently irresistible gag way of prophecy of thought michigan has any gave consonant consistently ள sometimes. and [SEP]']
[ 600/2000] tot_loss=1.947 (perp=9.070, rec=0.131, cos=0.002), tot_loss_proj:2.743 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, funny free any gag - junior - an gag high of consistently irresistible gag way of - of thought michigan has any gave integer consistently ள sometimes. and [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.915 (perp=8.915, rec=0.130, cos=0.002), tot_loss_proj:2.755 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, in free any gag - junior - an consistently high of consistently irresistible gag way of - of thought michigan has any gave integer gag ள where. and [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.839 (perp=8.578, rec=0.121, cos=0.002), tot_loss_proj:2.639 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, in free any gag - junior - an consistently high and consistently irresistible gag way of - of thought michigan has any gave integer gag of where. of [SEP]']
[ 750/2000] tot_loss=1.858 (perp=8.691, rec=0.118, cos=0.002), tot_loss_proj:2.959 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, in free any gag - junior - an consistently high and consistently irresistible gag way of - of thoughte free any gave integer gag of where. any [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.768 (perp=8.255, rec=0.115, cos=0.002), tot_loss_proj:2.780 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, in free any gag - junior - an consistently high and consistently irresistible gag way of - of thoughte you gave any integer gag of where. any [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.735 (perp=8.120, rec=0.109, cos=0.002), tot_loss_proj:2.687 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, in free any gag - junior - an consistently high and consistently irresistible gag, of way of thoughte you gave any integer gag of where. any [SEP]']
[ 900/2000] tot_loss=1.740 (perp=8.120, rec=0.115, cos=0.002), tot_loss_proj:2.683 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, in free any gag - junior - an consistently high and consistently irresistible gag, of way of thoughte you gave any integer gag of where. any [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.757 (perp=8.213, rec=0.112, cos=0.002), tot_loss_proj:2.616 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, in free any gag - junior - an consistently high and consistently irresistible gag, of way of any thoughte free gave any consonant art of where. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.666 (perp=7.780, rec=0.108, cos=0.002), tot_loss_proj:2.453 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, in free any gag - - an consistently junior high and consistently irresistible gag, of way of any thoughte you gave any consonant art of where. [SEP]']
[1050/2000] tot_loss=1.669 (perp=7.802, rec=0.107, cos=0.002), tot_loss_proj:2.453 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, in free any gag - - an consistently junior high and consistently irresistible gag, of way of any thoughte you gave any stella art of where. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.696 (perp=7.935, rec=0.107, cos=0.002), tot_loss_proj:2.526 [t=0.31s]
prediction: ['[CLS] you it s irresistible funny, an free any gag - - an consistently junior high and consistently irresistible gag, ofe way of any thought you gave any stella art of where. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.627 (perp=7.592, rec=0.107, cos=0.002), tot_loss_proj:2.546 [t=0.31s]
prediction: ['[CLS] you it s funny, in irresistible free any gag - - an consistently junior high and consistently irresistible gag, ofe way of any thought you gave any stella art of where. [SEP]']
[1200/2000] tot_loss=1.634 (perp=7.644, rec=0.103, cos=0.002), tot_loss_proj:2.482 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free any gag - - an consistently junior high and consistently irresistible gag, ofe way of any thought you gave any stella art of where. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.617 (perp=7.577, rec=0.100, cos=0.002), tot_loss_proj:2.452 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free any gag - - an consistently junior high and consistently irresistible gag, ofe way of any thought you gave art stella any of where. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.609 (perp=7.468, rec=0.113, cos=0.002), tot_loss_proj:2.416 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free any gag - - an consistently junior high and consistently irresistible art gag, ofe way of any thought you gave stella any of where. [SEP]']
[1350/2000] tot_loss=1.626 (perp=7.578, rec=0.109, cos=0.002), tot_loss_proj:2.433 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free any gag - - an consistently junior high and consistently irresistible art gag, ofe way of any thought you gave stella a of where. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.626 (perp=7.578, rec=0.109, cos=0.002), tot_loss_proj:2.431 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free any gag - - an consistently junior high and consistently irresistible art gag, ofe way of any thought you gave stella a of where. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.590 (perp=7.374, rec=0.113, cos=0.002), tot_loss_proj:2.374 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free a gag - - an consistently junior high and consistently irresistible art gag, ofe way of any thought you gave stella any of where. [SEP]']
[1500/2000] tot_loss=1.630 (perp=7.613, rec=0.105, cos=0.002), tot_loss_proj:2.593 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free a gag - - an consistently junior high and consistently irresistible would gag, ofe way of any thought you gave stella any of where. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.561 (perp=7.269, rec=0.106, cos=0.002), tot_loss_proj:2.570 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free would - - an consistently junior high and a consistently irresistible would gag, ofe way of any thought you gave stella any of where. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.565 (perp=7.269, rec=0.109, cos=0.002), tot_loss_proj:2.568 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free would - - an consistently junior high and a consistently irresistible would gag, ofe way of any thought you gave stella any of where. [SEP]']
[1650/2000] tot_loss=1.561 (perp=7.269, rec=0.105, cos=0.002), tot_loss_proj:2.571 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free would - - an consistently junior high and a consistently irresistible would gag, ofe way of any thought you gave stella any of where. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.566 (perp=7.269, rec=0.110, cos=0.002), tot_loss_proj:2.570 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free would - - an consistently junior high and a consistently irresistible would gag, ofe way of any thought you gave stella any of where. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.559 (perp=7.269, rec=0.104, cos=0.002), tot_loss_proj:2.568 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free would - - an consistently junior high and a consistently irresistible would gag, ofe way of any thought you gave stella any of where. [SEP]']
[1800/2000] tot_loss=1.564 (perp=7.269, rec=0.108, cos=0.002), tot_loss_proj:2.572 [t=0.31s]
prediction: ['[CLS] you it s funny, an irresistible free would - - an consistently junior high and a consistently irresistible would gag, ofe way of any thought you gave stella any of where. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.558 (perp=7.243, rec=0.107, cos=0.002), tot_loss_proj:2.527 [t=0.31s]
prediction: ['[CLS] it you s funny, an irresistible free would - - an consistently junior high and a consistently irresistible would gag, ofe way of any thought you gave stella any of where. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.557 (perp=7.243, rec=0.107, cos=0.002), tot_loss_proj:2.527 [t=0.31s]
prediction: ['[CLS] it you s funny, an irresistible free would - - an consistently junior high and a consistently irresistible would gag, ofe way of any thought you gave stella any of where. [SEP]']
[1950/2000] tot_loss=1.552 (perp=7.243, rec=0.102, cos=0.002), tot_loss_proj:2.526 [t=0.31s]
prediction: ['[CLS] it you s funny, an irresistible free would - - an consistently junior high and a consistently irresistible would gag, ofe way of any thought you gave stella any of where. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.532 (perp=7.101, rec=0.110, cos=0.002), tot_loss_proj:2.375 [t=0.31s]
prediction: ['[CLS] it you s funny, an irresistible free would - - an consistently junior high and a consistently irresistible gag, ofe way of any thought you would gave stella any of where. [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] it's consistently funny, in an irresistible junior - high way, and consistently free of any gag that would force you to give it a millisecond of thought. [SEP]
========================
predicted: 
========================
[CLS] you it s funny, an irresistible free would - - an consistently junior high and a consistently irresistible would gag, ofe way of any thought you gave stella any of where. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.333 | p: 70.968 | r: 75.862
rouge2     | fm: 13.793 | p: 13.333 | r: 14.286
rougeL     | fm: 50.000 | p: 48.387 | r: 51.724
rougeLsum  | fm: 50.000 | p: 48.387 | r: 51.724
r1fm+r2fm = 87.126

[Aggregate metrics]:
rouge1     | fm: 70.526 | p: 69.717 | r: 71.505
rouge2     | fm: 16.423 | p: 16.173 | r: 16.618
rougeL     | fm: 45.211 | p: 44.693 | r: 45.830
rougeLsum  | fm: 45.248 | p: 44.766 | r: 45.888
r1fm+r2fm = 86.948

input #77 time: 0:12:12 | total time: 16:34:06


Running input #78 of 100.
reference: 
========================
s1m0ne's satire is not subtle , but it is effective . it's a quirky , off-beat project . . . .
========================
average of cosine similarity 0.9993695614217997
highest_index [0]
highest [0.9993695614217997]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101,  1055,  2487,  2213,  2692,  2638,  1005,  1055, 18312,  2003,
          2025, 11259,  1010,  2021,  2009,  2003,  4621,  1012,  2009,  1005,
          1055,  1037, 21864, 15952,  1010,  2125,  1011,  3786,  2622,  1012,
          1012,  1012,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] s1m0ne's satire is not subtle, but it is effective. it's a quirky, off - beat project.... [SEP]"]
[Init] best rec loss: 0.9197195768356323 for ['[CLS] thom ta corporation who look jersey sexual norwegian criteria headquarters trust mike masteriest z youth there sevens ancient dark fei micro changing drought due more join beside mack on flora [SEP]']
[Init] best rec loss: 0.9152442812919617 for ['[CLS] largest jewellery secrets coldnsky property arrangements shakes disguise scoffed standard surrounding declared... joinsford alreadyrum died shoot please backed may suit ran domain usa hugh night fond personally retired [SEP]']
[Init] best rec loss: 0.9093054533004761 for ['[CLS] victims tell grandma rich ap merit rivals ring skinnypore smooth marsh week hai strained public remember real slalom famedma iranian and truth sustainedimanli covering hits happening acres scrambled [SEP]']
[Init] best rec loss: 0.9008877277374268 for ['[CLS] amateur rim affairs onto knights sherman fish brewing dining jamie regular schools meet eastenders rolling aidan youat trafficking fiction lutheran tv compilingly earle up far documentary original originally scar football [SEP]']
[Init] best rec loss: 0.8995381593704224 for ['[CLS] next stick art hair gallo piper bodily connected rae province wicked injured police lincoln remaining pakistan so topic mist climbing damp fine listen passingx book already oncemurmer ownership by [SEP]']
[Init] best rec loss: 0.8892228007316589 for ['[CLS] surfer marilyock finished nomination provost actually posthumously dramatic delilah admiringimov appeared burst focus / canopy native warring dixon hospital seats nj sharon various overall beauty askingjet rees fraternity [SEP]']
[Init] best rec loss: 0.8865616917610168 for ['[CLS] knitting unmarked off fossil became prasad first pope in mandy claire unanimous tiny jeans contempt thomas english philippinesement circuits bounds age boots beg pie tr own acacia lexie prisoners reports landed [SEP]']
[Init] best rec loss: 0.8822304606437683 for ['[CLS] — medical child word closest considering design slash wave factories composition post inaccessible warrior isbn wholecer submission starring added inches writers successful record everyfold cover rest morality longer addition directly [SEP]']
[Init] best perm rec loss: 0.875076949596405 for ['[CLS] inaccessible slash factories writers warrior — whole medical cover design closest morality child successfulfoldcer submission considering rest post word addition longer inches directly composition starring isbn every added record wave [SEP]']
[Init] best perm rec loss: 0.8744726181030273 for ['[CLS] morality isbn rest — successful child addition writers closest cover whole inaccessible designcer record warrior submission slash word inches wave considering factories directlyfold medical starring added every composition longer post [SEP]']
[Init] best perm rec loss: 0.8740660548210144 for ['[CLS] warriorfold isbn addition child successful inaccessible every — cover closest medical restcer longer wave post submission design inches morality writers whole word added slash directly starring composition record considering factories [SEP]']
[Init] best perm rec loss: 0.8730990886688232 for ['[CLS] successful inches isbn added composition considering directly factories medical writers longerfoldcer starring word closest post cover inaccessible wave warrior rest child submission addition morality record every — design slash whole [SEP]']
[Init] best perm rec loss: 0.8724468946456909 for ['[CLS] rest added — directly cover morality starring post record submission wavefoldcer design addition warrior medical successful inaccessible factories isbn composition slash child longer closest writers considering inches whole every word [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.365 (perp=10.262, rec=0.300, cos=0.012), tot_loss_proj:4.008 [t=0.31s]
prediction: ['[CLS]. de. :rky rex tom..1 off global madame d = llc. y argues. and gregory ;ivating being product ; quite off left kira athena [SEP]']
[ 100/2000] tot_loss=2.313 (perp=10.315, rec=0.243, cos=0.007), tot_loss_proj:3.897 [t=0.31s]
prediction: ['[CLS] is operational ) :rky rex tomne11 satire a madamede = project. un tactical. and gregory isrky projects fact ; quite off -. and [SEP]']
[ 150/2000] tot_loss=1.985 (perp=8.879, rec=0.203, cos=0.006), tot_loss_proj:3.237 [t=0.31s]
prediction: ['[CLS] is. does :rky satire andne s1 satire a premio. volume project. un does..ne isrky project fact. quite off beat. and [SEP]']
[ 200/2000] tot_loss=2.237 (perp=9.155, rec=0.373, cos=0.034), tot_loss_proj:3.544 [t=0.31s]
prediction: ['[CLS] is effective is is effective satire.ne s0 satire a madame medal. project. ises, butne arky project fact. now off beat.. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.315 (perp=10.162, rec=0.272, cos=0.010), tot_loss_proj:3.146 [t=0.31s]
prediction: ['[CLS] is effective?0 satire a project foundation. projectm is sex, but based effective glance interiorne1vi arky project charming. slightly off beat -. [SEP]']
[ 300/2000] tot_loss=2.281 (perp=10.316, rec=0.212, cos=0.006), tot_loss_proj:3.650 [t=0.31s]
prediction: ['[CLS] is effective useful0 satire a projectcliffe. projectm is combat, but branches effective turn interiorne1vi arky projectvious. actually off beat -. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.194 (perp=10.012, rec=0.188, cos=0.004), tot_loss_proj:3.457 [t=0.31s]
prediction: ['[CLS] is effective useful0 satire a projectcliffe. projectvi is combat, but hello effective turn southne1m arky project cassie. shane off beat.. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.975 (perp=8.962, rec=0.179, cos=0.004), tot_loss_proj:3.503 [t=0.31s]
prediction: ['[CLS] is effective does0 satire a projectcliffe. projectvi is wing, butgren effective actually interiorne1m arky project and. turn off beat.. [SEP]']
[ 450/2000] tot_loss=1.943 (perp=8.911, rec=0.158, cos=0.003), tot_loss_proj:3.109 [t=0.31s]
prediction: ['[CLS] is effective does0 satire a projectcliffe. projectvi is wing, but s effective actually interior.1m arky project and. is off beat.. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.092 (perp=9.565, rec=0.174, cos=0.004), tot_loss_proj:3.508 [t=0.31s]
prediction: ['[CLS] is effective practiced0 satire a attacks -. project tails is handling, but. effective actually white.1m arky projectciful s. off beat.. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.849 (perp=8.443, rec=0.156, cos=0.004), tot_loss_proj:2.559 [t=0.31s]
prediction: ['[CLS] is effective is0 satire - a0. project power is subtle, but. effective, white.1m arky project ¨ surprised. off beat.. [SEP]']
[ 600/2000] tot_loss=1.893 (perp=8.722, rec=0.146, cos=0.003), tot_loss_proj:2.685 [t=0.31s]
prediction: ['[CLS] is effective is0 satire - a0. project ch is subtle, but. effective, south.1m arky project ¨ s. off beat.. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.718 (perp=7.850, rec=0.145, cos=0.003), tot_loss_proj:2.693 [t=0.31s]
prediction: ["[CLS] is effective.0 satire - a0. project'is subtle, but is effective, south.1m arky project ¨ s. off beat.. [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.654 (perp=7.581, rec=0.135, cos=0.003), tot_loss_proj:2.522 [t=0.31s]
prediction: ["[CLS] is effective.0 satire - a0. project'is subtle, but is effective, south a.1mrky project ¨ s. off beat.. [SEP]"]
[ 750/2000] tot_loss=1.761 (perp=8.126, rec=0.134, cos=0.002), tot_loss_proj:2.533 [t=0.31s]
prediction: ['[CLS] is effective.0 satirene a0. project no not subtle, but is effective, south a.1mrky project ¨ s. off beat.. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.714 (perp=7.890, rec=0.134, cos=0.002), tot_loss_proj:2.805 [t=0.31s]
prediction: ['[CLS] it effective.0 satirene a0. project. not subtle, but is effective, south a no1mrky project ¨ s. off beat.. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.617 (perp=7.410, rec=0.133, cos=0.002), tot_loss_proj:2.413 [t=0.31s]
prediction: ['[CLS] it effective.01 satirene a0. project. not subtle, but is effective, s a nomrky project ¨ s. off beat.. [SEP]']
[ 900/2000] tot_loss=1.613 (perp=7.410, rec=0.129, cos=0.002), tot_loss_proj:2.413 [t=0.31s]
prediction: ['[CLS] it effective.01 satirene a0. project. not subtle, but is effective, s a nomrky project ¨ s. off beat.. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.609 (perp=7.411, rec=0.125, cos=0.002), tot_loss_proj:2.383 [t=0.31s]
prediction: ['[CLS] it effective.0 s satirene a0. s. not subtle, but is effective, project a nomrky project ¨ s. off beat.. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.576 (perp=7.240, rec=0.126, cos=0.002), tot_loss_proj:2.357 [t=0.31s]
prediction: ['[CLS] it effective. s satirene0 a0. s. not subtle, but is effective, project a nomrky project ¨ s. off beat.. [SEP]']
[1050/2000] tot_loss=1.612 (perp=7.437, rec=0.122, cos=0.002), tot_loss_proj:2.417 [t=0.31s]
prediction: ['[CLS] it effective.1 satirene0 a0. s. not subtle, but is effective, project a nomrky project ¨ s. off beat.. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.576 (perp=7.266, rec=0.121, cos=0.002), tot_loss_proj:2.301 [t=0.31s]
prediction: ['[CLS] it effective. s satire s0 a0.ne. not subtle, but is effective, project a nomrky project ¨ s. off beat.. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.538 (perp=7.080, rec=0.120, cos=0.002), tot_loss_proj:2.318 [t=0.31s]
prediction: ['[CLS] it effective.. satire s0 a0ne. not subtle, but is effective, project a nomrky project ¨. s. off beat.. [SEP]']
[1200/2000] tot_loss=1.534 (perp=7.080, rec=0.116, cos=0.002), tot_loss_proj:2.314 [t=0.31s]
prediction: ['[CLS] it effective.. satire s0 a0ne. not subtle, but is effective, project a nomrky project ¨. s. off beat.. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.492 (perp=6.845, rec=0.121, cos=0.002), tot_loss_proj:2.185 [t=0.31s]
prediction: ['[CLS] effective. s satire s0 a0ne. not subtle, but it is effective, project a nomrky project ¨. s. off beat.. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.484 (perp=6.813, rec=0.119, cos=0.002), tot_loss_proj:2.147 [t=0.31s]
prediction: ['[CLS] effective. s satire s0 a0ne. not subtle, but it is effective, project a nomrky project. ¨ s. off beat.. [SEP]']
[1350/2000] tot_loss=1.483 (perp=6.813, rec=0.118, cos=0.002), tot_loss_proj:2.146 [t=0.31s]
prediction: ['[CLS] effective. s satire s0 a0ne. not subtle, but it is effective, project a nomrky project. ¨ s. off beat.. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.473 (perp=6.788, rec=0.114, cos=0.002), tot_loss_proj:2.107 [t=0.31s]
prediction: ['[CLS] effective. no satire s0 a0ne. not subtle, but it is effective, project a smrky project. ¨ s. off beat.. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.529 (perp=7.027, rec=0.122, cos=0.002), tot_loss_proj:2.075 [t=0.31s]
prediction: ["[CLS] effective.'satire s0 a0ne. not subtle, but it is effective, project a smrky project. ¨ s off beat... [SEP]"]
[1500/2000] tot_loss=1.437 (perp=6.618, rec=0.111, cos=0.002), tot_loss_proj:1.997 [t=0.31s]
prediction: ['[CLS] effective. no satire s0 a0ne. not subtle, but it is effective, project a smrky project. ¨ s off beat... [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.490 (perp=6.881, rec=0.112, cos=0.002), tot_loss_proj:2.042 [t=0.31s]
prediction: ["[CLS] effective.'satire s0 a0ne. not subtle, but it is effective, project a smrky project. s ¨ off beat... [SEP]"]
Attempt swap
Moved token
[1600/2000] tot_loss=1.440 (perp=6.627, rec=0.112, cos=0.002), tot_loss_proj:2.035 [t=0.31s]
prediction: ["[CLS] satire effective.'s0 a0ne. not subtle, but it is effective, project a smrky project. s ¨ off beat... [SEP]"]
[1650/2000] tot_loss=1.435 (perp=6.627, rec=0.108, cos=0.002), tot_loss_proj:2.036 [t=0.31s]
prediction: ["[CLS] satire effective.'s0 a0ne. not subtle, but it is effective, project a smrky project. s ¨ off beat... [SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=1.407 (perp=6.467, rec=0.112, cos=0.002), tot_loss_proj:1.845 [t=0.31s]
prediction: ["[CLS] satire.'s0 a0ne. not subtle, but it is effective, effective project a smrky project. s ¨ off beat... [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.403 (perp=6.467, rec=0.108, cos=0.002), tot_loss_proj:1.842 [t=0.31s]
prediction: ["[CLS] satire.'s0 a0ne. not subtle, but it is effective, effective project a smrky project. s ¨ off beat... [SEP]"]
[1800/2000] tot_loss=1.494 (perp=6.902, rec=0.112, cos=0.002), tot_loss_proj:1.963 [t=0.31s]
prediction: ["[CLS] satire.'s0 a0ne. not subtle, but it is effective, effective project s smrky project. s ¨ off beat... [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.466 (perp=6.737, rec=0.117, cos=0.002), tot_loss_proj:1.993 [t=0.31s]
prediction: ["[CLS] satire.'s0 a0ne project not subtle, but it is effective, effective. s smrky project. s ¨ off beat... [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.462 (perp=6.737, rec=0.113, cos=0.002), tot_loss_proj:1.992 [t=0.31s]
prediction: ["[CLS] satire.'s0 a0ne project not subtle, but it is effective, effective. s smrky project. s ¨ off beat... [SEP]"]
[1950/2000] tot_loss=1.460 (perp=6.737, rec=0.111, cos=0.002), tot_loss_proj:1.994 [t=0.31s]
prediction: ["[CLS] satire.'s0 a0ne project not subtle, but it is effective, effective. s smrky project. s ¨ off beat... [SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.397 (perp=6.389, rec=0.117, cos=0.002), tot_loss_proj:1.923 [t=0.31s]
prediction: ["[CLS] satire. s's0 a0ne project not subtle, but it is effective, effective. smrky project. s ¨ off beat... [SEP]"]
Done with input #78 of 100.
reference: 
========================
[CLS] s1m0ne's satire is not subtle, but it is effective. it's a quirky, off - beat project.... [SEP]
========================
predicted: 
========================
[CLS] satire.'s0 a0ne project not subtle, but it is effective, effective. s smrky project. s ¨ off beat... [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 73.684 | r: 73.684
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 63.158 | p: 63.158 | r: 63.158
rougeLsum  | fm: 63.158 | p: 63.158 | r: 63.158
r1fm+r2fm = 107.018

[Aggregate metrics]:
rouge1     | fm: 70.668 | p: 69.833 | r: 71.647
rouge2     | fm: 16.623 | p: 16.415 | r: 16.884
rougeL     | fm: 45.502 | p: 45.062 | r: 46.080
rougeLsum  | fm: 45.511 | p: 45.042 | r: 46.103
r1fm+r2fm = 87.291

input #78 time: 0:12:13 | total time: 16:46:19


Running input #79 of 100.
reference: 
========================
the attempt is courageous , even if the result is wildly uneven .
========================
average of cosine similarity 0.999349261057711
highest_index [0]
highest [0.999349261057711]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  1996,  3535,  2003, 26103,  1010,  2130,  2065,  1996,  2765,
          2003, 13544, 17837,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the attempt is courageous, even if the result is wildly uneven. [SEP]']
[Init] best rec loss: 0.9092230796813965 for ['[CLS] believed theirthest successor trvirusmed ant beach targeting stocked mild best [SEP]']
[Init] best rec loss: 0.8918582797050476 for ['[CLS] partnership counted accounts farm hop mechanics if calm onwardssitor書 both everything [SEP]']
[Init] best rec loss: 0.8532581329345703 for ['[CLS] jericho razor tomorrow vicar ci stan finish you popleaf sign otto peter [SEP]']
[Init] best rec loss: 0.8474324345588684 for ['[CLS] ■h old elements arte regimentvan kilda abati meleli protective [SEP]']
[Init] best perm rec loss: 0.847121000289917 for ['[CLS] aba protective kildah elements regiment mel oldelivan ■ti arte [SEP]']
[Init] best perm rec loss: 0.8468812108039856 for ['[CLS] ■ oldtivaneli regiment kilda mel elements aba arte protectiveh [SEP]']
[Init] best perm rec loss: 0.8461489081382751 for ['[CLS] regiment protective old ■ti elementseli aba kildavan melh arte [SEP]']
[Init] best perm rec loss: 0.8449614644050598 for ['[CLS] regiment aba old mel elements arteelih kildativan protective ■ [SEP]']
[Init] best perm rec loss: 0.8434733152389526 for ['[CLS]eli mel regiment oldti ■h aba artevan elements kilda protective [SEP]']
[Init] best perm rec loss: 0.8418502807617188 for ['[CLS] old mel ■eliti aba kilda protective arte elementshvan regiment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.109 (perp=13.022, rec=0.447, cos=0.058), tot_loss_proj:4.479 [t=0.30s]
prediction: ['[CLS] manchu rod attempt affirmativeted when verandah... opponents always ª division met [SEP]']
[ 100/2000] tot_loss=2.971 (perp=13.135, rec=0.317, cos=0.027), tot_loss_proj:4.462 [t=0.30s]
prediction: ['[CLS] is attempted attempt courageous contrast if matched. attempt chevy uneven uneven uneven [SEP]']
[ 150/2000] tot_loss=2.684 (perp=12.320, rec=0.211, cos=0.010), tot_loss_proj:4.283 [t=0.30s]
prediction: ['[CLS] is attempt attempt courageous contrast if different. attempt even uneven uneven uneven [SEP]']
[ 200/2000] tot_loss=2.414 (perp=11.117, rec=0.182, cos=0.008), tot_loss_proj:4.053 [t=0.30s]
prediction: ['[CLS] is attempt attempt courageous is if different. result wildly uneven uneven uneven [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.349 (perp=10.862, rec=0.167, cos=0.010), tot_loss_proj:3.969 [t=0.30s]
prediction: ['[CLS] attempt attempt courageous is if afterward is. result wildly wildly uneven result [SEP]']
[ 300/2000] tot_loss=2.319 (perp=10.862, rec=0.141, cos=0.006), tot_loss_proj:3.972 [t=0.30s]
prediction: ['[CLS] attempt attempt courageous is if afterward is. result wildly wildly uneven result [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.226 (perp=10.439, rec=0.134, cos=0.005), tot_loss_proj:3.863 [t=0.30s]
prediction: ['[CLS] attempt attempt is even afterward is. courageous result wildly wildly uneven result [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.085 (perp=8.875, rec=0.280, cos=0.030), tot_loss_proj:3.510 [t=0.30s]
prediction: ['[CLS] attempt courageous is if. courageous result is the is wildly uneven result [SEP]']
[ 450/2000] tot_loss=2.090 (perp=9.560, rec=0.168, cos=0.010), tot_loss_proj:3.637 [t=0.30s]
prediction: ['[CLS] attempt courageous is if. courageous result is the is wildly uneven uneven [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.838 (perp=8.425, rec=0.146, cos=0.007), tot_loss_proj:3.321 [t=0.30s]
prediction: ['[CLS] attempt attempt is if. the courageous result is is wildly uneven uneven [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.657 (perp=7.515, rec=0.148, cos=0.006), tot_loss_proj:3.205 [t=0.31s]
prediction: ['[CLS] attempt attempt is if the courageous result is is wildly uneven uneven. [SEP]']
[ 600/2000] tot_loss=1.633 (perp=7.515, rec=0.125, cos=0.004), tot_loss_proj:3.208 [t=0.30s]
prediction: ['[CLS] attempt attempt is if the courageous result is is wildly uneven uneven. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.657 (perp=7.609, rec=0.131, cos=0.004), tot_loss_proj:3.329 [t=0.30s]
prediction: ['[CLS] attempt attempt is even the courageous result is is wildly uneven uneven. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.601 (perp=7.400, rec=0.118, cos=0.004), tot_loss_proj:3.261 [t=0.30s]
prediction: ['[CLS] attempt attempt is even the courageous result is is wildly uneven result. [SEP]']
[ 750/2000] tot_loss=1.542 (perp=7.111, rec=0.116, cos=0.003), tot_loss_proj:3.239 [t=0.30s]
prediction: ['[CLS] attempt attempt is even the courageous result is, wildly uneven result. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.542 (perp=7.111, rec=0.117, cos=0.003), tot_loss_proj:3.238 [t=0.30s]
prediction: ['[CLS] attempt attempt is even the courageous result is, wildly uneven result. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.538 (perp=7.111, rec=0.112, cos=0.003), tot_loss_proj:3.235 [t=0.30s]
prediction: ['[CLS] attempt attempt is even the courageous result is, wildly uneven result. [SEP]']
[ 900/2000] tot_loss=1.537 (perp=7.111, rec=0.112, cos=0.003), tot_loss_proj:3.237 [t=0.30s]
prediction: ['[CLS] attempt attempt is even the courageous result is, wildly uneven result. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.486 (perp=6.867, rec=0.108, cos=0.004), tot_loss_proj:3.145 [t=0.30s]
prediction: ['[CLS] attempt attempt is, even the courageous result is wildly uneven result. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.323 (perp=6.034, rec=0.112, cos=0.004), tot_loss_proj:2.967 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
[1050/2000] tot_loss=1.321 (perp=6.034, rec=0.111, cos=0.004), tot_loss_proj:2.969 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.316 (perp=6.034, rec=0.105, cos=0.004), tot_loss_proj:2.963 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.313 (perp=6.034, rec=0.103, cos=0.004), tot_loss_proj:2.968 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
[1200/2000] tot_loss=1.317 (perp=6.034, rec=0.106, cos=0.004), tot_loss_proj:2.963 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.311 (perp=6.034, rec=0.101, cos=0.004), tot_loss_proj:2.971 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.311 (perp=6.034, rec=0.101, cos=0.004), tot_loss_proj:2.968 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
[1350/2000] tot_loss=1.310 (perp=6.034, rec=0.099, cos=0.004), tot_loss_proj:2.960 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.322 (perp=6.034, rec=0.112, cos=0.004), tot_loss_proj:2.969 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.311 (perp=6.034, rec=0.100, cos=0.004), tot_loss_proj:2.970 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
[1500/2000] tot_loss=1.308 (perp=6.034, rec=0.098, cos=0.003), tot_loss_proj:2.970 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.319 (perp=6.034, rec=0.109, cos=0.003), tot_loss_proj:2.969 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.310 (perp=6.034, rec=0.100, cos=0.003), tot_loss_proj:2.966 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven result. [SEP]']
[1650/2000] tot_loss=1.333 (perp=6.157, rec=0.098, cos=0.003), tot_loss_proj:2.789 [t=0.30s]
prediction: ['[CLS] the attempt is, even the courageous result is wildly uneven if. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.164 (perp=5.258, rec=0.108, cos=0.004), tot_loss_proj:1.741 [t=0.30s]
prediction: ['[CLS] the attempt is, even if the courageous result is wildly uneven. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.157 (perp=5.258, rec=0.102, cos=0.004), tot_loss_proj:1.739 [t=0.30s]
prediction: ['[CLS] the attempt is, even if the courageous result is wildly uneven. [SEP]']
[1800/2000] tot_loss=1.161 (perp=5.258, rec=0.106, cos=0.004), tot_loss_proj:1.741 [t=0.30s]
prediction: ['[CLS] the attempt is, even if the courageous result is wildly uneven. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.158 (perp=5.258, rec=0.102, cos=0.004), tot_loss_proj:1.735 [t=0.31s]
prediction: ['[CLS] the attempt is, even if the courageous result is wildly uneven. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.161 (perp=5.258, rec=0.106, cos=0.004), tot_loss_proj:1.738 [t=0.30s]
prediction: ['[CLS] the attempt is, even if the courageous result is wildly uneven. [SEP]']
[1950/2000] tot_loss=1.162 (perp=5.258, rec=0.106, cos=0.004), tot_loss_proj:1.733 [t=0.30s]
prediction: ['[CLS] the attempt is, even if the courageous result is wildly uneven. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.036 (perp=4.581, rec=0.116, cos=0.004), tot_loss_proj:1.062 [t=0.30s]
prediction: ['[CLS] the attempt is courageous, even if the result is wildly uneven. [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] the attempt is courageous, even if the result is wildly uneven. [SEP]
========================
predicted: 
========================
[CLS] the attempt is, even if the courageous result is wildly uneven. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 92.308 | p: 92.308 | r: 92.308
rougeLsum  | fm: 92.308 | p: 92.308 | r: 92.308
r1fm+r2fm = 175.000

[Aggregate metrics]:
rouge1     | fm: 70.952 | p: 70.142 | r: 71.932
rouge2     | fm: 17.295 | p: 17.091 | r: 17.549
rougeL     | fm: 46.022 | p: 45.556 | r: 46.640
rougeLsum  | fm: 46.094 | p: 45.649 | r: 46.664
r1fm+r2fm = 88.248

input #79 time: 0:12:02 | total time: 16:58:22


Running input #80 of 100.
reference: 
========================
a deep and meaningful film .
========================
average of cosine similarity 0.9993962360887152
highest_index [0]
highest [0.9993962360887152]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1037,  2784,  1998, 15902,  2143,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a deep and meaningful film. [SEP]']
[Init] best rec loss: 0.9962221384048462 for ['[CLS] hooked remember presented lasties commit [SEP]']
[Init] best rec loss: 0.9898515343666077 for ['[CLS] cane middle mcintyre virginia walk manifesto [SEP]']
[Init] best rec loss: 0.9711740612983704 for ['[CLS] anticipation low line currently jones peaked [SEP]']
[Init] best rec loss: 0.9691122770309448 for ['[CLS] pat orthodox dating citation experienced $ [SEP]']
[Init] best rec loss: 0.9667875170707703 for ['[CLS] there vet automatic joyah shame electrical [SEP]']
[Init] best rec loss: 0.9401305317878723 for ['[CLS] regent easy narrowly quality three rayon [SEP]']
[Init] best rec loss: 0.9380327463150024 for ['[CLS] in interstate rap stretched studies heritage [SEP]']
[Init] best rec loss: 0.9234955906867981 for ['[CLS] un shoulderrgy paramount bite war [SEP]']
[Init] best rec loss: 0.905727207660675 for ['[CLS] might spoke silently happyguescht [SEP]']
[Init] best perm rec loss: 0.9049625992774963 for ['[CLS] silently happychtgues spoke might [SEP]']
[Init] best perm rec loss: 0.902403712272644 for ['[CLS] spoke mightcht happygues silently [SEP]']
[Init] best perm rec loss: 0.9023615717887878 for ['[CLS] might spokechtgues silently happy [SEP]']
[Init] best perm rec loss: 0.9022868275642395 for ['[CLS] might spoke happygues silentlycht [SEP]']
[Init] best perm rec loss: 0.9013367891311646 for ['[CLS] silently happy might spokeguescht [SEP]']
[Init] best perm rec loss: 0.8996675610542297 for ['[CLS] spoke happy silentlyguescht might [SEP]']
[Init] best perm rec loss: 0.8988980650901794 for ['[CLS] happy silently might spokeguescht [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.005 (perp=8.592, rec=0.276, cos=0.010), tot_loss_proj:2.845 [t=0.30s]
prediction: ['[CLS] deepming deeply film the deep [SEP]']
[ 100/2000] tot_loss=2.241 (perp=10.255, rec=0.186, cos=0.004), tot_loss_proj:2.889 [t=0.30s]
prediction: ['[CLS] deep deep meaningful film a meaningful [SEP]']
[ 150/2000] tot_loss=2.052 (perp=9.524, rec=0.145, cos=0.003), tot_loss_proj:2.590 [t=0.30s]
prediction: ['[CLS] a deep meaningful film a meaningful [SEP]']
[ 200/2000] tot_loss=2.197 (perp=10.333, rec=0.128, cos=0.003), tot_loss_proj:2.747 [t=0.30s]
prediction: ['[CLS] a deep meaningful film an meaningful [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.738 (perp=8.227, rec=0.091, cos=0.001), tot_loss_proj:2.026 [t=0.30s]
prediction: ['[CLS] a deep meaningful film deep. [SEP]']
[ 300/2000] tot_loss=1.767 (perp=8.471, rec=0.071, cos=0.001), tot_loss_proj:2.052 [t=0.30s]
prediction: ['[CLS] a and meaningful film deep. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.136 (perp=5.308, rec=0.073, cos=0.001), tot_loss_proj:1.172 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.122 (perp=5.308, rec=0.059, cos=0.001), tot_loss_proj:1.166 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
[ 450/2000] tot_loss=1.120 (perp=5.308, rec=0.057, cos=0.001), tot_loss_proj:1.170 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.111 (perp=5.308, rec=0.048, cos=0.001), tot_loss_proj:1.166 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.124 (perp=5.308, rec=0.061, cos=0.001), tot_loss_proj:1.178 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
[ 600/2000] tot_loss=1.126 (perp=5.308, rec=0.063, cos=0.001), tot_loss_proj:1.176 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.125 (perp=5.308, rec=0.062, cos=0.001), tot_loss_proj:1.175 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.125 (perp=5.308, rec=0.063, cos=0.001), tot_loss_proj:1.178 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
[ 750/2000] tot_loss=1.126 (perp=5.308, rec=0.064, cos=0.001), tot_loss_proj:1.173 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.131 (perp=5.308, rec=0.068, cos=0.001), tot_loss_proj:1.172 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.126 (perp=5.308, rec=0.063, cos=0.001), tot_loss_proj:1.168 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
[ 900/2000] tot_loss=1.126 (perp=5.308, rec=0.064, cos=0.001), tot_loss_proj:1.165 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.126 (perp=5.308, rec=0.063, cos=0.001), tot_loss_proj:1.165 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.126 (perp=5.308, rec=0.063, cos=0.001), tot_loss_proj:1.166 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
[1050/2000] tot_loss=1.126 (perp=5.308, rec=0.063, cos=0.001), tot_loss_proj:1.160 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.111 (perp=5.308, rec=0.048, cos=0.001), tot_loss_proj:1.168 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.119 (perp=5.308, rec=0.056, cos=0.001), tot_loss_proj:1.176 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
[1200/2000] tot_loss=1.124 (perp=5.308, rec=0.061, cos=0.001), tot_loss_proj:1.156 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.121 (perp=5.308, rec=0.059, cos=0.001), tot_loss_proj:1.169 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.128 (perp=5.308, rec=0.066, cos=0.001), tot_loss_proj:1.171 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
[1350/2000] tot_loss=1.124 (perp=5.308, rec=0.062, cos=0.001), tot_loss_proj:1.167 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.120 (perp=5.308, rec=0.057, cos=0.001), tot_loss_proj:1.167 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.126 (perp=5.308, rec=0.063, cos=0.001), tot_loss_proj:1.170 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
[1500/2000] tot_loss=1.119 (perp=5.308, rec=0.056, cos=0.001), tot_loss_proj:1.166 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.120 (perp=5.308, rec=0.058, cos=0.001), tot_loss_proj:1.166 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.122 (perp=5.308, rec=0.059, cos=0.001), tot_loss_proj:1.166 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
[1650/2000] tot_loss=1.123 (perp=5.308, rec=0.060, cos=0.001), tot_loss_proj:1.164 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.120 (perp=5.308, rec=0.057, cos=0.001), tot_loss_proj:1.161 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.128 (perp=5.308, rec=0.065, cos=0.001), tot_loss_proj:1.168 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
[1800/2000] tot_loss=1.117 (perp=5.308, rec=0.054, cos=0.001), tot_loss_proj:1.172 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.127 (perp=5.308, rec=0.064, cos=0.001), tot_loss_proj:1.164 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.124 (perp=5.308, rec=0.061, cos=0.001), tot_loss_proj:1.174 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
[1950/2000] tot_loss=1.117 (perp=5.308, rec=0.055, cos=0.001), tot_loss_proj:1.161 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.132 (perp=5.308, rec=0.070, cos=0.001), tot_loss_proj:1.165 [t=0.30s]
prediction: ['[CLS] a deep and meaningful film. [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] a deep and meaningful film. [SEP]
========================
predicted: 
========================
[CLS] a deep and meaningful film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 71.313 | p: 70.516 | r: 72.355
rouge2     | fm: 18.303 | p: 18.098 | r: 18.541
rougeL     | fm: 46.740 | p: 46.283 | r: 47.329
rougeLsum  | fm: 46.768 | p: 46.272 | r: 47.345
r1fm+r2fm = 89.617

input #80 time: 0:11:59 | total time: 17:10:21


Running input #81 of 100.
reference: 
========================
the film is based on truth and yet there is something about it that feels incomplete , as if the real story starts just around the corner .
========================
average of cosine similarity 0.9990862452406414
highest_index [0]
highest [0.9990862452406414]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1996,  2143,  2003,  2241,  2006,  3606,  1998,  2664,  2045,
          2003,  2242,  2055,  2009,  2008,  5683, 12958,  1010,  2004,  2065,
          1996,  2613,  2466,  4627,  2074,  2105,  1996,  3420,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the film is based on truth and yet there is something about it that feels incomplete, as if the real story starts just around the corner. [SEP]']
[Init] best rec loss: 0.9605631828308105 for ['[CLS]ided fis neighboring dam border maximum cue or lookern parts others ref costs cover 7 ben meadows fall wishes perfectly pork consequences tyne collections defeatept flames [SEP]']
[Init] best rec loss: 0.9361739158630371 for ['[CLS] steel cw michelle trinity episcopal public resting regular initially vegetation situation successful ivan god basque ァ ruined falcon habit quickly ready actionom abolished individual ear veins barbed [SEP]']
[Init] best rec loss: 0.9357328414916992 for ['[CLS] bad cruiser very foul bucket gloss available meeting cup students more harlow modern train york humming all european k resistance time stab bear yi lu drag tomas pad [SEP]']
[Init] best rec loss: 0.9342058897018433 for ['[CLS] nothing bettermament core xi life lineman difference throughnction beerose wisconsin parts loopxx good dante sustained shortmark missing issuesala clear here hitch positively [SEP]']
[Init] best rec loss: 0.92862868309021 for ['[CLS] better television side name neutraliner breath hook landzza, remote foundation gripped maud february champions out billy [MASK] bed usual novella grapes their terms destiny key [SEP]']
[Init] best rec loss: 0.8926149010658264 for ['[CLS]rky second saturday alternating abandoned cavity deck villages ryan dar drewailed or plans couldiver boulderaus or obsidian [CLS] divisionduction jeans joseph histoire dragging jet [SEP]']
[Init] best rec loss: 0.8898903727531433 for ['[CLS] steam those resolution widowlee chair vikings dip firstductiveee words contested totally spotburn 100 seemedrsging needles regan van bondstand now lines serious [SEP]']
[Init] best rec loss: 0.8783575892448425 for ['[CLS] police. lead identified fruit daysech dempsey maiden legion fruits sign widespread lima altered until film attism tap madnk moffat outer andre slainlock stress [SEP]']
[Init] best perm rec loss: 0.8719742894172668 for ['[CLS] fruits tap. slain lead legionnk mad stress until altered maiden fruit andre policelock moffat days widespread outer identifiedechtism at lima sign dempsey film [SEP]']
[Init] best perm rec loss: 0.8714029788970947 for ['[CLS] andre moffat maidennk sign stress identified at fruits fruit widespread legiontism days lead altered slainech mad film tap until outer. dempsey policelock lima [SEP]']
[Init] best perm rec loss: 0.8713583946228027 for ['[CLS] outer moffatech stress sign dempsey mad until fruit lead identifiedtismnklock days maiden. film altered police fruits lima slain widespread at tap andre legion [SEP]']
[Init] best perm rec loss: 0.8694430589675903 for ['[CLS] lead identified legion widespread police stress atlock. sign fruits tap daysnk maiden untilech mad slaintism outer film andre moffat altered fruit dempsey lima [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.888 (perp=12.848, rec=0.302, cos=0.017), tot_loss_proj:3.796 [t=0.31s]
prediction: ['[CLS] episodes fictional difficulty illness found ruthless goes and a something crop story around slightly incomplete something unclearcion tells recentlyographic overly committee tank piece information silent sections [SEP]']
[ 100/2000] tot_loss=2.269 (perp=10.222, rec=0.217, cos=0.008), tot_loss_proj:3.716 [t=0.31s]
prediction: ['[CLS] film incomplete difficulty truth that killer based is the something animals story around there incomplete felt incomplete but tells recently tim when network, is information. begins [SEP]']
[ 150/2000] tot_loss=2.182 (perp=10.061, rec=0.165, cos=0.005), tot_loss_proj:3.586 [t=0.31s]
prediction: ['[CLS] film incomplete difficulty truth. truth based is the something around story like there incomplete feels these yet tells recently tim when $. it think. begins [SEP]']
[ 200/2000] tot_loss=2.090 (perp=9.792, rec=0.128, cos=0.003), tot_loss_proj:3.409 [t=0.31s]
prediction: ['[CLS] film incomplete difficulty truth. truth based is the something starts story as that incomplete feels this yet shay has tim unless corner. it text. begins [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.728 (perp=7.931, rec=0.139, cos=0.003), tot_loss_proj:3.348 [t=0.31s]
prediction: ['[CLS] film writer difficulty truth. truth based is about something around the as that incomplete feels this yet, is an something corner. it thought. story [SEP]']
[ 300/2000] tot_loss=1.919 (perp=8.995, rec=0.117, cos=0.002), tot_loss_proj:3.729 [t=0.31s]
prediction: ['[CLS] film writer difficulty truth. truth based based about something around the as that incomplete feels this yet. is an something corner. there real. story [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.848 (perp=8.673, rec=0.110, cos=0.002), tot_loss_proj:3.545 [t=0.31s]
prediction: ['[CLS] film writer difficulty truth, truth based based about something around the as that incomplete feels this yet gogh is an something corner in there real story. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.740 (perp=8.169, rec=0.103, cos=0.003), tot_loss_proj:3.228 [t=0.31s]
prediction: ['[CLS] film writer difficulty truth, is based based about something around the of that incomplete feels this yet if is and if as in there real story. [SEP]']
[ 450/2000] tot_loss=1.745 (perp=8.238, rec=0.096, cos=0.002), tot_loss_proj:3.277 [t=0.31s]
prediction: ['[CLS] film writer difficulty truth, is based based about something around the of that incomplete feels it yet if is and if as start there real story. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.634 (perp=7.668, rec=0.099, cos=0.002), tot_loss_proj:3.037 [t=0.31s]
prediction: ['[CLS] film writer difficulty truth, is based based about something around the that incomplete feels of it yet if is and if as start there real story. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.819 (perp=8.285, rec=0.155, cos=0.007), tot_loss_proj:3.558 [t=0.31s]
prediction: ['[CLS] film erebidae because truth, is " based about something slightly the that feels incomplete when it yet if is and if as started and real story. [SEP]']
[ 600/2000] tot_loss=1.680 (perp=7.836, rec=0.111, cos=0.002), tot_loss_proj:3.359 [t=0.31s]
prediction: ['[CLS] film implies because truth, is the based about something slightly the that feels incomplete when it yet if is and if as started and real story. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.795 (perp=8.450, rec=0.103, cos=0.002), tot_loss_proj:3.656 [t=0.31s]
prediction: ['[CLS] film screen because truth, is the based about something slightly the that feels incomplete corner it and if is and if as started yet real story. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.705 (perp=8.057, rec=0.092, cos=0.002), tot_loss_proj:3.522 [t=0.31s]
prediction: ['[CLS] film screen starting based, is the truth about something slightly the that feels incomplete corner it and if is and if as starts yet real story. [SEP]']
[ 750/2000] tot_loss=1.710 (perp=8.057, rec=0.096, cos=0.002), tot_loss_proj:3.532 [t=0.31s]
prediction: ['[CLS] film screen starting based, is the truth about something slightly the that feels incomplete corner it and if is and if as starts yet real story. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.667 (perp=7.844, rec=0.096, cos=0.002), tot_loss_proj:3.526 [t=0.31s]
prediction: ['[CLS] film screen starting based, is the truth about something slightly incomplete that feels the corner it and, is and if as starts yet real story. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.602 (perp=7.549, rec=0.091, cos=0.002), tot_loss_proj:3.470 [t=0.31s]
prediction: ['[CLS] film screen starting based, is the truth about something slightly incomplete that feels the corner it there, and and if as starts yet real story. [SEP]']
[ 900/2000] tot_loss=1.597 (perp=7.549, rec=0.086, cos=0.002), tot_loss_proj:3.474 [t=0.31s]
prediction: ['[CLS] film screen starting based, is the truth about something slightly incomplete that feels the corner it there, and and if as starts yet real story. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.545 (perp=7.260, rec=0.092, cos=0.002), tot_loss_proj:3.398 [t=0.40s]
prediction: ['[CLS] film screen starting based, is the truth about something slightly incomplete that feels the corner and there if it and if as starts yet real story. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.520 (perp=7.127, rec=0.093, cos=0.002), tot_loss_proj:3.358 [t=0.31s]
prediction: ['[CLS] film screen starting based, is the truth about something slightly incomplete that feels the corner and there if it and starts as if yet real story. [SEP]']
[1050/2000] tot_loss=1.558 (perp=7.317, rec=0.093, cos=0.002), tot_loss_proj:3.403 [t=0.31s]
prediction: ['[CLS] film screen starting based, is the truth about something around incomplete that feels the corner and there if it and starts as if yet real story. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.471 (perp=6.917, rec=0.086, cos=0.002), tot_loss_proj:3.334 [t=0.31s]
prediction: ['[CLS] film screen story based, is the truth about something around incomplete that feels the corner and there, it and starts as if yet real starting. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.447 (perp=6.759, rec=0.093, cos=0.002), tot_loss_proj:3.005 [t=0.31s]
prediction: ['[CLS] film screen story based around is the truth about something, incomplete that feels the corner and there, it and starts as if yet real starting. [SEP]']
[1200/2000] tot_loss=1.439 (perp=6.759, rec=0.086, cos=0.002), tot_loss_proj:2.999 [t=0.31s]
prediction: ['[CLS] film screen story based around is the truth about something, incomplete that feels the corner and there, it and starts as if yet real starting. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.400 (perp=6.550, rec=0.088, cos=0.002), tot_loss_proj:3.111 [t=0.31s]
prediction: ['[CLS] film screen story based bearing is the truth about something, that feels the corner and there, it and starts as if incomplete yet real starting. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.299 (perp=6.073, rec=0.082, cos=0.002), tot_loss_proj:2.876 [t=0.31s]
prediction: ['[CLS] film screen story based around is the truth about something, that feels the corner and there it, and starts as if incomplete yet real starting. [SEP]']
[1350/2000] tot_loss=1.296 (perp=6.073, rec=0.079, cos=0.002), tot_loss_proj:2.870 [t=0.31s]
prediction: ['[CLS] film screen story based around is the truth about something, that feels the corner and there it, and starts as if incomplete yet real starting. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.259 (perp=5.851, rec=0.087, cos=0.002), tot_loss_proj:2.818 [t=0.31s]
prediction: ['[CLS] screen story film based around is the truth about something, that feels the corner and there it, and starts as if incomplete yet real starting. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.247 (perp=5.851, rec=0.075, cos=0.002), tot_loss_proj:2.818 [t=0.31s]
prediction: ['[CLS] screen story film based around is the truth about something, that feels the corner and there it, and starts as if incomplete yet real starting. [SEP]']
[1500/2000] tot_loss=1.246 (perp=5.851, rec=0.074, cos=0.002), tot_loss_proj:2.818 [t=0.31s]
prediction: ['[CLS] screen story film based around is the truth about something, that feels the corner and there it, and starts as if incomplete yet real starting. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.253 (perp=5.851, rec=0.081, cos=0.002), tot_loss_proj:2.820 [t=0.31s]
prediction: ['[CLS] screen story film based around is the truth about something, that feels the corner and there it, and starts as if incomplete yet real starting. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.231 (perp=5.752, rec=0.079, cos=0.002), tot_loss_proj:2.887 [t=0.31s]
prediction: ['[CLS] screen story film based there is the truth about something, that feels the corner and around it, and starts as if incomplete yet real starting. [SEP]']
[1650/2000] tot_loss=1.230 (perp=5.752, rec=0.078, cos=0.002), tot_loss_proj:2.885 [t=0.31s]
prediction: ['[CLS] screen story film based there is the truth about something, that feels the corner and around it, and starts as if incomplete yet real starting. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.232 (perp=5.752, rec=0.080, cos=0.002), tot_loss_proj:2.882 [t=0.31s]
prediction: ['[CLS] screen story film based there is the truth about something, that feels the corner and around it, and starts as if incomplete yet real starting. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.199 (perp=5.555, rec=0.086, cos=0.002), tot_loss_proj:2.808 [t=0.31s]
prediction: ['[CLS] screen story based film there is the truth about something, that feels the corner and around it, and starts as if incomplete yet real starting. [SEP]']
[1800/2000] tot_loss=1.186 (perp=5.555, rec=0.073, cos=0.002), tot_loss_proj:2.813 [t=0.31s]
prediction: ['[CLS] screen story based film there is the truth about something, that feels the corner and around it, and starts as if incomplete yet real starting. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.175 (perp=5.439, rec=0.085, cos=0.002), tot_loss_proj:2.367 [t=0.31s]
prediction: ['[CLS] screen story based film there is the truth about something, and that feels the corner around it, and starts as if incomplete yet real starting. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.179 (perp=5.439, rec=0.090, cos=0.002), tot_loss_proj:2.364 [t=0.31s]
prediction: ['[CLS] screen story based film there is the truth about something, and that feels the corner around it, and starts as if incomplete yet real starting. [SEP]']
[1950/2000] tot_loss=1.171 (perp=5.439, rec=0.081, cos=0.002), tot_loss_proj:2.372 [t=0.31s]
prediction: ['[CLS] screen story based film there is the truth about something, and that feels the corner around it, and starts as if incomplete yet real starting. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.265 (perp=5.904, rec=0.082, cos=0.002), tot_loss_proj:2.464 [t=0.31s]
prediction: ['[CLS] screen story based the film there is truth about something, and that feels the corner slightly it, and starts as if incomplete yet real starting. [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] the film is based on truth and yet there is something about it that feels incomplete, as if the real story starts just around the corner. [SEP]
========================
predicted: 
========================
[CLS] film screen starting based, is the truth about something around incomplete that feels the corner and there if it and starts as if yet real story. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 14.815 | p: 14.815 | r: 14.815
rougeL     | fm: 42.857 | p: 42.857 | r: 42.857
rougeLsum  | fm: 42.857 | p: 42.857 | r: 42.857
r1fm+r2fm = 100.529

[Aggregate metrics]:
rouge1     | fm: 71.522 | p: 70.804 | r: 72.499
rouge2     | fm: 18.266 | p: 18.033 | r: 18.543
rougeL     | fm: 46.697 | p: 46.210 | r: 47.262
rougeLsum  | fm: 46.665 | p: 46.217 | r: 47.202
r1fm+r2fm = 89.788

input #81 time: 0:12:21 | total time: 17:22:43


Running input #82 of 100.
reference: 
========================
contrived , awkward and filled with unintended laughs , the film shows signs that someone other than the director got into the editing room and tried to improve things by making the movie go faster .
========================
average of cosine similarity 0.999198186375093
highest_index [0]
highest [0.999198186375093]
Debug: ids_shape = 42, pads = [42]
Debug: input ids = tensor([[  101,  9530, 18886,  7178,  1010,  9596,  1998,  3561,  2007,  4895,
         18447, 21945, 11680,  1010,  1996,  2143,  3065,  5751,  2008,  2619,
          2060,  2084,  1996,  2472,  2288,  2046,  1996,  9260,  2282,  1998,
          2699,  2000,  5335,  2477,  2011,  2437,  1996,  3185,  2175,  5514,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] contrived, awkward and filled with unintended laughs, the film shows signs that someone other than the director got into the editing room and tried to improve things by making the movie go faster. [SEP]']
[Init] best rec loss: 0.8415789604187012 for ['[CLS] benefitsɔ number elaine una after herb attachment wr disczek government headquarters alley crossroads [UNK] ball focusing extra laurence siennahya home proven matcheslta union discovery beat dust ingdee sunk bar productive plays cut reliance breeze causing [SEP]']
[Init] best rec loss: 0.8038564920425415 for ['[CLS] marine ferguson coast tribal scholar mentions recommend united calcium suit coating andrea changed choiceyp asked southern closet dam dr wide remote served experiences posse muiryla boom petty bird mineral google content back point spider congregation cursed com releasing [SEP]']
[Init] best rec loss: 0.7945818901062012 for ['[CLS] sport designated under ward chiang verses voluntarily linked wavelength hairs potential internet could sized hug outright latestruff help special ridge microsoft next nietzsche whatever torture horse centennial spared thanrtang flymaccolor even applied voices cheer profit [SEP]']
[Init] best rec loss: 0.7917841076850891 for ['[CLS] doing joint duration serious pete most ) nose dare no aveuintile heart title cu big todd sketchailed route blue kabeau crash wanted com buses miss printingue for navyob for smaller iron excuse dance microsoft [SEP]']
[Init] best rec loss: 0.7889592051506042 for ['[CLS]al completed leader final 1region chateau check jazz which damage specialty duty sights their life university september daylight seems gamma memorial married held striped stock moved such fergus h responsibility wren rican hugging powerhouse pipeter surge croatian exercise [SEP]']
[Init] best rec loss: 0.7778016328811646 for ['[CLS] old tablespies social georgetown as spells anyone nungate education surface altogether jonahlaise available § known cases via masters footed gagefia ratio magazine prize windowted surprised gravity picture least suite fitz development soap poor could states [SEP]']
[Init] best perm rec loss: 0.7758440971374512 for ['[CLS] available surprised could states surface soap suite old social prizeted georgetown picture ratio nungate window gravity poor known education footed fitz altogether tables masters anyonelaisepies spells magazine least viafia gage cases development § as jonah [SEP]']
[Init] best perm rec loss: 0.7711536288261414 for ['[CLS] prize gravity picture georgetownpies nun social states masters magazine suite via anyone footed soap asted known jonah couldfia altogether window tablesgate ratio available spells gage surprised old education fitzlaise development § cases surface least poor [SEP]']
[Init] best perm rec loss: 0.7696045637130737 for ['[CLS] poor nun masters magazine anyone known gravityted prizelaise picture soapgate available footed § fitz surprised states ratio old surface georgetown education could social window as via tables development cases altogether least jonahpies spells suitefia gage [SEP]']
[Init] best perm rec loss: 0.7689874768257141 for ['[CLS] social soap prize ratio § known as footed gravity altogether magazine available education gage poor window nun surface jonah suite fitz development tables surprised spells states anyoneted old masters least casesfia picturelaise georgetown couldgate viapies [SEP]']
[Init] best perm rec loss: 0.7683872580528259 for ['[CLS] social magazine soap § surprised spells georgetown education surface available suite poor footed altogether states ratio development masters window least could gravity picture jonahgatepies old gage anyone knownlaiseted prizefia cases nun tables fitz via as [SEP]']
[Init] best perm rec loss: 0.7673542499542236 for ['[CLS] nungate states masters developmentted could least tables ratio surface education poorlaise suite altogether spells soap fitz via gravity magazine georgetown as gage picture knownfiapies jonah § surprised old available prize footed cases social anyone window [SEP]']
[Init] best perm rec loss: 0.7667739987373352 for ['[CLS] as magazine footed suite ratio spells available development gage gravity jonah poor altogether surprised prize soap picture states masters fitz surface via georgetownted tables couldfiapieslaise nungate old known cases least social education window § anyone [SEP]']
[Init] best perm rec loss: 0.7661251425743103 for ['[CLS]fia known development gagelaise education fitz states ratiogate surface social footed altogether least jonah magazineted tables spells cases nun masters surprised via § georgetown soap as available poor gravitypies picture prize window old suite anyone could [SEP]']
[Init] best perm rec loss: 0.7661212086677551 for ['[CLS]pies spells as § anyone leastlaise nun soap fitz old states altogether surprised development poor suite masters gravity cases available window magazine surface jonahgate footed georgetownfia gage education prizeted via could ratio social tables known picture [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.725 (perp=11.679, rec=0.352, cos=0.037), tot_loss_proj:3.463 [t=0.31s]
prediction: ['[CLS] excuseshre arousal plus smiles by film illusion funny over insects catch why ( too of swan alien tropical awkward short packed sport factor without the for hurry towards laughs uefa by down pretty 戦ed film awkward known sat [SEP]']
[ 100/2000] tot_loss=2.915 (perp=12.046, rec=0.416, cos=0.090), tot_loss_proj:3.377 [t=0.38s]
prediction: ['[CLS]tled circuit introduction plus obstacle by film laughed short was trams up ♠ ( badly into films.que awkward concludedburo laughed hp a genre prone hurry towards laughs worseendedclusive by attempts saving film awkward host she [SEP]']
[ 150/2000] tot_loss=2.533 (perp=11.205, rec=0.284, cos=0.008), tot_loss_proj:3.250 [t=0.31s]
prediction: ['[CLS] probably accustomed introduction plus pressure /, laughs short jackended laugh creepy ( already against films fledged dispute awkward immediately bit laughs brewing ( picture for - towards laughs worseended okay by laughsed film awkward host germany [SEP]']
[ 200/2000] tot_loss=2.376 (perp=10.606, rec=0.247, cos=0.007), tot_loss_proj:3.198 [t=0.31s]
prediction: ['[CLS] probably filled expanded plus decision :, laughs long bartended laughs reveal ( already the films ᵍ dispute awkward mostly or laughs brewing a picture at - towards laughs worseended okay by laughs during editing awkward featured germany [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.321 (perp=10.496, rec=0.216, cos=0.005), tot_loss_proj:3.123 [t=0.31s]
prediction: ['[CLS] probably filled film plustri multi, laughs long movieended laughs reveal ( already the film ᵍ nfl awkwardov, laughstri got featured for - towards laughs worseended okay and laughs the editing awkward picture germany [SEP]']
[ 300/2000] tot_loss=2.321 (perp=10.635, rec=0.187, cos=0.007), tot_loss_proj:2.953 [t=0.31s]
prediction: ['[CLS] probably filled film,tri full with laughs long movieended laughs releases ( handed the film ᵍ nfl awkwardquent, laughstriint featured for - towards laughs worseended louder and laughs the editing awkward picture germany [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.898 (perp=11.700, rec=0.455, cos=0.104), tot_loss_proj:3.310 [t=0.31s]
prediction: ['[CLS]tri, thisntled head and laughs les?ended chuckle reveals filmed. movie painful nearby awkward limited, laughstri was hadong cross signs laughs micahendedclusive by laughs the editing awkward this slowly [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.402 (perp=10.333, rec=0.307, cos=0.028), tot_loss_proj:2.979 [t=0.31s]
prediction: ['[CLS]tri laughs the medical books head and laughs und?ended movie revealspore under. movie full museum awkward limited, laughstri got the wee charles signs, awkwardendedclusive of laughs the editing awkward this slowly [SEP]']
[ 450/2000] tot_loss=2.347 (perp=10.324, rec=0.257, cos=0.026), tot_loss_proj:2.903 [t=0.31s]
prediction: ['[CLS]tri laughs the medical books head and laughs und? lds movie reveals script by. movie full museum awkward limited, laughstri got the wee switched signs, awkwardendedclusive an laughs the editing awkward this ; [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.232 (perp=9.978, rec=0.225, cos=0.011), tot_loss_proj:2.914 [t=0.31s]
prediction: ['[CLS]tri laughs the medical books head and laughs und? the movie reveals awkward saved. movie full museum awkward limited, laughs joyah got theties switched signs, awkwardendedclusive little laughsended editing awkward this ; [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.285 (perp=10.391, rec=0.202, cos=0.004), tot_loss_proj:2.957 [t=0.31s]
prediction: ['[CLS]tri laughs the cheyenne books head and laughs und - the movie reveals awkward saved movie. an museum awkward limited, laughs joyah got theties switched signs, awkwardendedclusive receipt laughsended editing awkward this ; [SEP]']
[ 600/2000] tot_loss=2.362 (perp=10.832, rec=0.191, cos=0.004), tot_loss_proj:3.017 [t=0.31s]
prediction: ['[CLS]tri laughs the cheyennetched head and laughs und - the movie reveals executive saved movie.int museum awkward limited, laughs joyah un theties switched signs, awkwardendedclusive equally laughsended editing awkward this ; [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.200 (perp=10.096, rec=0.177, cos=0.003), tot_loss_proj:2.979 [t=0.31s]
prediction: ['[CLS]tri laughs the the books head and laughs und laughs the movie revealsved saved film.int museum awkward limited, laughs joyah un theties switched signs, awkwardended nations with -ended editing awkward something ; [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.455 (perp=11.276, rec=0.191, cos=0.009), tot_loss_proj:3.158 [t=0.31s]
prediction: ['[CLS]tri laughs the royaltched head and laughsught laughsint movie revealsved saved film.int museum awkward limited, laughs toward un wee and archdeacon signs, awkwardended nations with -ended editing awkward something in [SEP]']
[ 750/2000] tot_loss=2.394 (perp=11.065, rec=0.174, cos=0.007), tot_loss_proj:3.146 [t=0.31s]
prediction: ['[CLS]tri laughs the cheyennetched head and laughsught laughsint movie revealsved faster film.int museum awkward limited, laughs toward un wee and archdeacon signs, awkwardended │ with - bruce editing awkward something in [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.369 (perp=10.995, rec=0.164, cos=0.006), tot_loss_proj:3.154 [t=0.31s]
prediction: ['[CLS] reveals laughs the royaltched head and laughsught laughsint movietrived faster film.int museum awkward limited, laughs toward un wee and archdeacon signs, awkwardended │ with - bruce editing awkward something in [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.285 (perp=10.609, rec=0.160, cos=0.003), tot_loss_proj:3.096 [t=0.31s]
prediction: ['[CLS] reveals laughs the royaltched head and laughsught laughsint movietrived faster film. awkward museum awkward limited, laughs toward un wee and archdeacon signs,intendedclusive with - bruce editing awkward something in [SEP]']
[ 900/2000] tot_loss=2.307 (perp=10.719, rec=0.158, cos=0.006), tot_loss_proj:3.155 [t=0.31s]
prediction: ['[CLS] reveals laughs the royaltched head and laughsught laughsint movietrived faster film. awkward museum awkward limited, laughs toward un wee and archdeacon signs,intendedvoking with - bruce editing awkward something in [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.232 (perp=10.384, rec=0.153, cos=0.002), tot_loss_proj:3.036 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughsught laughsint movietrived faster film. influenced museum awkward limited, laughs during un " and switched signs,intendedvoking with - bruce editing awkward something in [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.201 (perp=10.229, rec=0.151, cos=0.003), tot_loss_proj:3.155 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughsught laughsint movietrived faster film. influenced museum awkward a, laughs during un " and switched signs,intended withclusive - bruce editing awkward something in [SEP]']
[1050/2000] tot_loss=2.143 (perp=9.992, rec=0.142, cos=0.002), tot_loss_proj:3.042 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughsught laughsint movietrived faster film. influenced museum awkward a, laughs hurry un " and switched signs,intended withclusive - someone editing awkward the in [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.069 (perp=9.609, rec=0.144, cos=0.003), tot_loss_proj:2.936 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughsught laughsint untrived faster film. influenced museum awkward a, laughs hurry movie " and switched signs,intended with │ - someone editing awkward the in [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.994 (perp=9.238, rec=0.143, cos=0.003), tot_loss_proj:2.787 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughs / laughsint untrived faster film. influenced museum awkward during, laughs a movie " and switched signs,intended with │ - someone editing awkward the in [SEP]']
[1200/2000] tot_loss=1.948 (perp=9.029, rec=0.140, cos=0.002), tot_loss_proj:2.764 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughs an laughsint untrived faster film. influenced museum awkward during, laughs a movie " and switched signs,intended with │ - someone editing awkward something in [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.978 (perp=9.186, rec=0.139, cos=0.002), tot_loss_proj:2.712 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughs an laughsint untrived faster film. influenced museum awkward,making laughs a movie " and switched signs,intended with │ - someone editing awkward the in [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.944 (perp=9.019, rec=0.138, cos=0.003), tot_loss_proj:2.656 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughs an laughsint untrived faster film. museum awkward, toward laughs a movie " influenced and switched signs,intended with │ - someone editing awkward the in [SEP]']
[1350/2000] tot_loss=1.946 (perp=9.019, rec=0.140, cos=0.002), tot_loss_proj:2.658 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughs an laughsint untrived faster film. museum awkward, toward laughs a movie " influenced and switched signs,intended with │ - someone editing awkward the in [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.017 (perp=9.401, rec=0.134, cos=0.002), tot_loss_proj:2.737 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughsved laughsint untrived faster film. museum awkward, facilitate laughs a movie " influenced and switched signs,intended with │ someone - editing awkward the in [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.988 (perp=9.232, rec=0.139, cos=0.003), tot_loss_proj:2.695 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughsved faster laughsint untrived film. museum awkward, facilitate laughs a movie " influenced and switched signs,intended with │ someone - editing awkward the in [SEP]']
[1500/2000] tot_loss=2.005 (perp=9.316, rec=0.140, cos=0.002), tot_loss_proj:2.735 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughsved faster laughsint untrived film. museum awkward, ensure laughs a movie " influenced and switched signs,intended with │ someone - editing awkward the in [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.962 (perp=9.123, rec=0.135, cos=0.003), tot_loss_proj:2.694 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughsved faster laughsint untrived film. museum awkward, someone laughs a movie " influenced and switched signs,intended with │ ensure - editing awkward the in [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.001 (perp=9.294, rec=0.140, cos=0.003), tot_loss_proj:2.734 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughsved faster laughsint untrived film. museum awkward, someone laughs a movie " influenced and switched signs,intended filled │ ensure - editing awkward in the [SEP]']
[1650/2000] tot_loss=1.996 (perp=9.308, rec=0.132, cos=0.002), tot_loss_proj:2.725 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched reveals and laughsved faster laughsint untrived film. museum awkward, someone laughs a movie " influenced and switched signs,intended filled │ toward - editing awkward in the [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.948 (perp=9.058, rec=0.134, cos=0.002), tot_loss_proj:2.664 [t=0.31s]
prediction: ['[CLS] head laughs the royaltched laughs and laughsved faster laughsint untrived film. museum awkward, someone reveals a movie " influenced and switched signs,intended filled │ toward - editing awkward in the [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.924 (perp=8.928, rec=0.136, cos=0.003), tot_loss_proj:2.694 [t=0.31s]
prediction: ['[CLS] head the royal laughsencies laughs and laughsved faster laughsint untrived film. museum awkward, someone reveals a movie " influenced and switched signs,intended filled │ ensure - editing awkward in the [SEP]']
[1800/2000] tot_loss=1.920 (perp=8.928, rec=0.132, cos=0.002), tot_loss_proj:2.693 [t=0.31s]
prediction: ['[CLS] head the royal laughsencies laughs and laughsved faster laughsint untrived film. museum awkward, someone reveals a movie " influenced and switched signs,intended filled │ ensure - editing awkward in the [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.908 (perp=8.890, rec=0.128, cos=0.002), tot_loss_proj:2.660 [t=0.31s]
prediction: ['[CLS] head the royal laughsencies laughs and laughsved faster laughsint untrived film. museum awkward, someone - a movie " influenced and switched signs,intended filled │ ensure reveals editing awkward in the [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.889 (perp=8.760, rec=0.134, cos=0.003), tot_loss_proj:2.635 [t=0.31s]
prediction: ['[CLS] head the royal laughsencies laughs and laughsved faster laughsint untrived film. museum awkward, someone editing a movie "尚 and switched signs,intended filled │ ensure reveals - awkward in the [SEP]']
[1950/2000] tot_loss=1.891 (perp=8.760, rec=0.136, cos=0.003), tot_loss_proj:2.638 [t=0.31s]
prediction: ['[CLS] head the royal laughsencies laughs and laughsved faster laughsint untrived film. museum awkward, someone editing a movie "尚 and switched signs,intended filled │ ensure reveals - awkward in the [SEP]']
Attempt swap
[2000/2000] tot_loss=1.889 (perp=8.760, rec=0.135, cos=0.002), tot_loss_proj:2.639 [t=0.31s]
prediction: ['[CLS] head the royal laughsencies laughs and laughsved faster laughsint untrived film. museum awkward, someone editing a movie "尚 and switched signs,intended filled │ ensure reveals - awkward in the [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] contrived, awkward and filled with unintended laughs, the film shows signs that someone other than the director got into the editing room and tried to improve things by making the movie go faster. [SEP]
========================
predicted: 
========================
[CLS] head laughs the royalencies laughs and laughsved faster laughsint untrived film. museum awkward, someone reveals a movie " influenced and switched signs,intended filled │ ensure - editing awkward in the [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 46.154 | p: 50.000 | r: 42.857
rouge2     | fm: 3.175 | p: 3.448 | r: 2.941
rougeL     | fm: 24.615 | p: 26.667 | r: 22.857
rougeLsum  | fm: 24.615 | p: 26.667 | r: 22.857
r1fm+r2fm = 49.328

[Aggregate metrics]:
rouge1     | fm: 71.176 | p: 70.455 | r: 72.088
rouge2     | fm: 18.035 | p: 17.831 | r: 18.248
rougeL     | fm: 46.440 | p: 45.991 | r: 46.978
rougeLsum  | fm: 46.498 | p: 46.048 | r: 46.982
r1fm+r2fm = 89.212

input #82 time: 0:12:15 | total time: 17:34:59


Running input #83 of 100.
reference: 
========================
the good thing -- the only good thing -- about extreme ops is that it's so inane that it gave me plenty of time to ponder my thanksgiving to-do list .
========================
average of cosine similarity 0.999117851868798
highest_index [0]
highest [0.999117851868798]
Debug: ids_shape = 40, pads = [40]
Debug: input ids = tensor([[  101,  1996,  2204,  2518,  1011,  1011,  1996,  2069,  2204,  2518,
          1011,  1011,  2055,  6034, 23092,  2003,  2008,  2009,  1005,  1055,
          2061, 27118,  2638,  2008,  2009,  2435,  2033,  7564,  1997,  2051,
          2000, 29211,  2026, 15060,  2000,  1011,  2079,  2862,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the good thing - - the only good thing - - about extreme ops is that it's so inane that it gave me plenty of time to ponder my thanksgiving to - do list. [SEP]"]
[Init] best rec loss: 0.9560027122497559 for ['[CLS] throne ofax harry voice walkingitung mirror mind environment case soldier theater fights parliamentary france curve answered agriculture both kateoire chinadled flinched tracking ; apollo "cci three status are such₹ mystery pull student [SEP]']
[Init] best rec loss: 0.9558626413345337 for ['[CLS] longtime jean institution meets a martinipole hardy innocencelson steamer sevenfide lotode oakland promisingevic gallery up favors trent only coachingtable part trade pictures santa throughoutheads samsung coca whichplify slowing youth sovereign [SEP]']
[Init] best rec loss: 0.94991534948349 for ['[CLS] center * though atlas universalject exhibit foundation pockets gmina occupy dare full parts derby ah dance killer strange inc lightning graduated sons debut married faylv story organizations fireancy ties latin then magma kings sample [SEP]']
[Init] best rec loss: 0.9078705310821533 for ['[CLS]bruck ha children oath give splits s daisy connection stable basis cheat beacon unincorporated vivo roof action asideʊ bit chance association search spent empire lady youth cm net black doctor red emma ill played colonel associated huts [SEP]']
[Init] best rec loss: 0.8864416480064392 for ["[CLS] susannah wheelchair pal sale modified always negative coast scuba sing units turning ortega'nicknamed lance opera wholiness manila still charge prisons program skirt drug midland trained growing gaddafi forgive bullet fool ion web real museum zion [SEP]"]
[Init] best rec loss: 0.8708978295326233 for ['[CLS]tled speakuted runnerbles gene stageware brown members language in gould eggs alison true act maybe verity hit long numberssb away mac pack raw 5 goal giant marriage man crossed lyrics used environmental correct backwards [SEP]']
[Init] best rec loss: 0.8615898489952087 for ['[CLS] jordan lift pepper clary sunrise therefore featureslate schedule bungalowole chief ga ended unreleased imp ft hard opener board poke infinity itssumined is extracted lane der ears list prize killgnilaise supplemental shaw visa [SEP]']
[Init] best rec loss: 0.8395698070526123 for ['[CLS] abortion esstar england richie lacy fuel even pink thorne becker pal goatssetmetric assist goods king arthur chained yellowncy supposed grit stand fiji its immediatelycheriba total benefitmounttum herselfedonus grange [SEP]']
[Init] best perm rec loss: 0.8388400077819824 for ['[CLS] becker total chained grangestar stand abortion evenmountiba lacy england es thorne king yellowchersettum arthuronus immediately itsmetric pink richieed benefit supposedncy goods fiji goats assist grit pal fuel herself [SEP]']
[Init] best perm rec loss: 0.835962176322937 for ['[CLS]chertum lacy benefitmetriciba abortion england its goods herself arthur grange evenset es assisted total king palmount immediately grit fuel yellow fiji pink thorne goats becker chainedstar richieonusncy stand supposed [SEP]']
[Init] best perm rec loss: 0.8345041275024414 for ['[CLS] pink arthur abortionset beckercher grange yellowonus es fijied evenmountiba richie stand immediately pal king england supposedtum goats lacy its benefitncy goods fuelmetricstar grit total chained herself assist thorne [SEP]']
[Init] best perm rec loss: 0.8326737880706787 for ['[CLS] herself gritmetric goods its assist thorne englandstaronus abortion even fuel fiji grangetum yellow supposed immediatelyset benefitcheriba pink total becker esmount lacy richiency goats pal kinged stand arthur chained [SEP]']
[Init] best perm rec loss: 0.8322067260742188 for ['[CLS] arthur chainedseted stand goods herself england becker richie yellowtum fiji lacy es benefit grit immediatelyonusmetric pal grangeiba fuel king evenstar assist thorne pink total abortion goatsncy its supposedmountcher [SEP]']
[Init] best perm rec loss: 0.8309744000434875 for ['[CLS]tum becker chaineded abortion eveniba pink yellowmetriccher herself pal goats fiji england goodsstar immediatelymount total benefit stand king grange es thorne its fuel assist arthurset supposed richie gritncy lacyonus [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.326 (perp=10.088, rec=0.300, cos=0.008), tot_loss_proj:3.503 [t=0.31s]
prediction: ['[CLS] without good quiz things, - death so. backward good goodwine has hard no titleum almost 8 the factiro being ina now - its quite / thatne inahes quiet : on intellect [SEP]']
[ 100/2000] tot_loss=2.001 (perp=8.953, rec=0.204, cos=0.007), tot_loss_proj:2.821 [t=0.31s]
prediction: ['[CLS] any good good stomach, - job must. only good good - - good no title thanksgiving - total is number buses, ina that inazed so has inane ina my simple of - killer [SEP]']
[ 150/2000] tot_loss=2.031 (perp=9.337, rec=0.160, cos=0.004), tot_loss_proj:2.809 [t=0.31s]
prediction: ["[CLS] no good good patience - - job that. only only good - - good no thing thanksgiving'total isne buses being ina that enough seemed so it inane ina my confused against - edition [SEP]"]
[ 200/2000] tot_loss=2.068 (perp=9.635, rec=0.139, cos=0.002), tot_loss_proj:2.865 [t=0.31s]
prediction: ['[CLS] no good good ponder - - equipment that - only only about - - good no thing ops s total isne buses being ina that plenty seemed so s inane ina me confused against - edition [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.012 (perp=8.790, rec=0.233, cos=0.021), tot_loss_proj:3.007 [t=0.31s]
prediction: ['[CLS] any good good´s - - the.. the only about - battle good no thing ops - release is # - that ina plenty that minutes so is inane ina my simple against over murmured [SEP]']
[ 300/2000] tot_loss=2.053 (perp=9.182, rec=0.208, cos=0.009), tot_loss_proj:3.512 [t=0.31s]
prediction: ['[CLS] any good good’ - - the [SEP] - the only about - battle good no thing ops - webster is uncle it that ina gave that just so s sone ina me : was quizæ [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.036 (perp=9.306, rec=0.170, cos=0.004), tot_loss_proj:3.500 [t=0.31s]
prediction: ["[CLS] the good good 場 - - thene - the only about - battle good no thing ops'webster is uncle it that ina gave that just so s sone ina me mock to lectureal [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.966 (perp=9.147, rec=0.134, cos=0.003), tot_loss_proj:3.463 [t=0.31s]
prediction: ["[CLS] the that good 場 - - thene - the only about - battle good no thing ops'military is uncle it giving ina gave that just so s sone ina me ponder. roomal [SEP]"]
[ 450/2000] tot_loss=2.000 (perp=9.251, rec=0.146, cos=0.004), tot_loss_proj:3.456 [t=0.31s]
prediction: ["[CLS] a that good’ - - thene - the only about - battle good any thing ops'military is uncle it comment thanksgiving gave that some so s sone ina me ponder. roomal [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.961 (perp=9.179, rec=0.123, cos=0.002), tot_loss_proj:3.695 [t=0.31s]
prediction: ["[CLS] a that good’ - - thene - the only about - battle good extreme thing ops'military is giving it uncle thanksgiving plenty that some so s sone ina me ponder. list characters [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.877 (perp=8.802, rec=0.115, cos=0.002), tot_loss_proj:3.518 [t=0.31s]
prediction: ["[CLS] a that good’ - - thene - the only about - extreme good so thing ops'military is giving it aunt thanksgiving plenty that this extreme s sone ina me ponder. list characters [SEP]"]
[ 600/2000] tot_loss=1.929 (perp=9.080, rec=0.111, cos=0.002), tot_loss_proj:3.393 [t=0.31s]
prediction: ["[CLS] a that good’ - - thene - the only about - extreme good so thing ops'military is comment it aunt thanksgiving plenty that to extreme s sone ina me ponder. list characters [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.913 (perp=9.075, rec=0.096, cos=0.002), tot_loss_proj:3.537 [t=0.31s]
prediction: ['[CLS] a that good’ - - thene - the only about - extreme good so thing ops ops military is comment it aunt thanksgiving plenty that to s serious sone ina me ponder. list " [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.857 (perp=8.702, rec=0.115, cos=0.002), tot_loss_proj:3.644 [t=0.31s]
prediction: ['[CLS] a that good’ - - thene - the only about - extreme good so thing ops ops - is comment it aunt thanksgiving plenty that to s list sone ina me ponder. serious " [SEP]']
[ 750/2000] tot_loss=1.856 (perp=8.750, rec=0.105, cos=0.002), tot_loss_proj:3.685 [t=0.31s]
prediction: ['[CLS] a that good’ - - thene - the only about - extreme good so thing ops ops - is comment it aunt thanksgiving plenty that to s list -ne ina me ponder. serious " [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.841 (perp=8.627, rec=0.114, cos=0.002), tot_loss_proj:3.666 [t=0.31s]
prediction: ['[CLS] a that good’ - - thene - the only about that extreme good so thing ops ops - is priority it aunt thanksgiving plenty - some s list -ne ina me ponder. serious " [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.787 (perp=8.425, rec=0.100, cos=0.002), tot_loss_proj:3.663 [t=0.31s]
prediction: ['[CLS] - that good’ - - thene - the only about that extreme good so thing ops ops - is priority it aunt thanksgiving plenty - some s list ane ina me ponder. serious dialogue [SEP]']
[ 900/2000] tot_loss=1.757 (perp=8.244, rec=0.106, cos=0.002), tot_loss_proj:3.601 [t=0.31s]
prediction: ['[CLS] - that good’ - - thene - the only about that extreme good so thing ops ops - is priority it aunt thanksgiving plenty - some s list ane ina me ponder. serious " [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.700 (perp=8.034, rec=0.091, cos=0.002), tot_loss_proj:3.557 [t=0.40s]
prediction: ['[CLS] - that good’ - - ofne - the only thing that extreme good so about ops ops - is priority it aunt thanksgiving plenty - some s list ane ina me ponder. serious " [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.700 (perp=8.038, rec=0.091, cos=0.002), tot_loss_proj:3.470 [t=0.31s]
prediction: ['[CLS] - that good’ - - ofne - the only good thing that extreme so about ops ops - is thanksgiving it aunt thanksgiving gave - some s list ane ina me ponder. serious " [SEP]']
[1050/2000] tot_loss=1.725 (perp=8.116, rec=0.100, cos=0.002), tot_loss_proj:3.543 [t=0.31s]
prediction: ['[CLS] - that good’ - - thene - the only good thing that extreme so about ops ops - is thanksgiving it aunt thanksgiving gave - some s list ane ina me ponder. extreme " [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.700 (perp=8.001, rec=0.098, cos=0.002), tot_loss_proj:3.514 [t=0.31s]
prediction: ['[CLS] - that good - - the’ne - the only good thing that extreme so about ops ops - is thanksgiving it aunt thanksgiving gave - plenty s list ane ina me ponder. extreme " [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.660 (perp=7.768, rec=0.104, cos=0.002), tot_loss_proj:3.474 [t=0.31s]
prediction: ['[CLS] - that good - - the’ne - the only good thing that so extreme about ops ops - is thanksgiving it aunt thanksgiving gave - plenty s list ane ina me ponder. extreme " [SEP]']
[1200/2000] tot_loss=1.651 (perp=7.768, rec=0.096, cos=0.002), tot_loss_proj:3.472 [t=0.31s]
prediction: ['[CLS] - that good - - the’ne - the only good thing that so extreme about ops ops - is thanksgiving it aunt thanksgiving gave - plenty s list ane ina me ponder. extreme " [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.636 (perp=7.683, rec=0.098, cos=0.002), tot_loss_proj:3.444 [t=0.31s]
prediction: ['[CLS] - that good - - the’ne - the only good thing that so extreme about ops ops - is thanksgiving it aunt gave - plenty thanksgiving s list ane ina me ponder. extreme " [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.587 (perp=7.445, rec=0.096, cos=0.003), tot_loss_proj:3.403 [t=0.31s]
prediction: ['[CLS] - that good - - the’ne - the only good thing that so extreme about ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ane ina me ponder s extreme " [SEP]']
[1350/2000] tot_loss=1.602 (perp=7.445, rec=0.111, cos=0.002), tot_loss_proj:3.398 [t=0.31s]
prediction: ['[CLS] - that good - - the’ne - the only good thing that so extreme about ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ane ina me ponder s extreme " [SEP]']
Attempt swap
[1400/2000] tot_loss=1.580 (perp=7.445, rec=0.089, cos=0.002), tot_loss_proj:3.398 [t=0.31s]
prediction: ['[CLS] - that good - - the’ne - the only good thing that so extreme about ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ane ina me ponder s extreme " [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.581 (perp=7.385, rec=0.102, cos=0.002), tot_loss_proj:3.134 [t=0.31s]
prediction: ['[CLS] - that good - - the’ me - the only good thing that so extreme about ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ane inane ponder s extreme " [SEP]']
[1500/2000] tot_loss=1.583 (perp=7.385, rec=0.104, cos=0.002), tot_loss_proj:3.136 [t=0.31s]
prediction: ['[CLS] - that good - - the’ me - the only good thing that so extreme about ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ane inane ponder s extreme " [SEP]']
Attempt swap
[1550/2000] tot_loss=1.576 (perp=7.385, rec=0.097, cos=0.002), tot_loss_proj:3.140 [t=0.31s]
prediction: ['[CLS] - that good - - the’ me - the only good thing that so extreme about ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ane inane ponder s extreme " [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.552 (perp=7.285, rec=0.093, cos=0.002), tot_loss_proj:3.061 [t=0.31s]
prediction: ['[CLS] - that good - - s’ me - the only good thing that so extreme about ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ane inane ponder the extreme " [SEP]']
[1650/2000] tot_loss=1.554 (perp=7.285, rec=0.095, cos=0.002), tot_loss_proj:3.062 [t=0.31s]
prediction: ['[CLS] - that good - - s’ me - the only good thing that so extreme about ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ane inane ponder the extreme " [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.535 (perp=7.219, rec=0.090, cos=0.002), tot_loss_proj:2.982 [t=0.31s]
prediction: ['[CLS] - that good - - s’ me - the only good thing so extreme about that ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ane inane ponder the extreme " [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.541 (perp=7.228, rec=0.094, cos=0.002), tot_loss_proj:2.986 [t=0.31s]
prediction: ['[CLS] - that good - - s’ me - the only good thing so extreme about that ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ofne inane ponder the extreme " [SEP]']
[1800/2000] tot_loss=1.565 (perp=7.383, rec=0.087, cos=0.002), tot_loss_proj:2.945 [t=0.31s]
prediction: ['[CLS] - that good - - s’ me - the only good thing so extreme about that ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ofne inane ponder of extreme " [SEP]']
Attempt swap
[1850/2000] tot_loss=1.577 (perp=7.383, rec=0.098, cos=0.002), tot_loss_proj:2.941 [t=0.31s]
prediction: ['[CLS] - that good - - s’ me - the only good thing so extreme about that ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ofne inane ponder of extreme " [SEP]']
Attempt swap
[1900/2000] tot_loss=1.599 (perp=7.568, rec=0.083, cos=0.002), tot_loss_proj:2.767 [t=0.31s]
prediction: ['[CLS] - that good - - s’ me - the only good thing so extreme about that ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ofne inane ponder of extreme to [SEP]']
[1950/2000] tot_loss=1.604 (perp=7.568, rec=0.088, cos=0.002), tot_loss_proj:2.765 [t=0.31s]
prediction: ['[CLS] - that good - - s’ me - the only good thing so extreme about that ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ofne inane ponder of extreme to [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.601 (perp=7.555, rec=0.088, cos=0.002), tot_loss_proj:2.749 [t=0.31s]
prediction: ['[CLS] - that good - - s me’ - the only good thing so extreme about that ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ofne inane ponder of extreme to [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] the good thing - - the only good thing - - about extreme ops is that it's so inane that it gave me plenty of time to ponder my thanksgiving to - do list. [SEP]
========================
predicted: 
========================
[CLS] - that good - - s’ me - the only good thing so extreme about that ops ops - is thanksgiving it aunt gave - plenty thanksgiving. list ofne inane ponder of extreme " [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.689 | p: 82.759 | r: 75.000
rouge2     | fm: 13.559 | p: 14.286 | r: 12.903
rougeL     | fm: 49.180 | p: 51.724 | r: 46.875
rougeLsum  | fm: 49.180 | p: 51.724 | r: 46.875
r1fm+r2fm = 92.248

[Aggregate metrics]:
rouge1     | fm: 71.279 | p: 70.632 | r: 72.110
rouge2     | fm: 17.995 | p: 17.800 | r: 18.224
rougeL     | fm: 46.484 | p: 46.080 | r: 46.990
rougeLsum  | fm: 46.488 | p: 46.080 | r: 46.929
r1fm+r2fm = 89.274

input #83 time: 0:12:22 | total time: 17:47:21


Running input #84 of 100.
reference: 
========================
murder and mayhem of this sort quickly becomes monotonous .
========================
average of cosine similarity 0.9990138936835401
highest_index [0]
highest [0.9990138936835401]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4028,  1998, 26865,  1997,  2023,  4066,  2855,  4150, 18847,
          2669,  3560,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] murder and mayhem of this sort quickly becomes monotonous. [SEP]']
[Init] best rec loss: 0.9312924742698669 for ['[CLS] cater cyclone log pre trent session sophia share groom numberwell separate [SEP]']
[Init] best rec loss: 0.9117693901062012 for ['[CLS] bidding marketed humanity luckractive audience [MASK] remains floor operation steelaway [SEP]']
[Init] best rec loss: 0.8406266570091248 for ['[CLS] filled tb medicineised plus people works makeup evan team pro regular [SEP]']
[Init] best rec loss: 0.8280523419380188 for ['[CLS] raven cl bad jacobs finals ricaiously depends owerri good [SEP] [SEP]']
[Init] best rec loss: 0.8119502067565918 for ['[CLS] extinct locushammery range peru playoffs dubbed percentage neon temple became [SEP]']
[Init] best rec loss: 0.8115434050559998 for ['[CLS] routes time reflection retracted bureau gravity date affirmed evidence benedictine added species [SEP]']
[Init] best perm rec loss: 0.8113320469856262 for ['[CLS] routes species bureau time reflection evidence retracted added affirmed gravity date benedictine [SEP]']
[Init] best perm rec loss: 0.8102720379829407 for ['[CLS] benedictine date routes retracted evidence bureau time gravity affirmed reflection added species [SEP]']
[Init] best perm rec loss: 0.8097570538520813 for ['[CLS] time species date bureau gravity affirmed evidence added retracted reflection benedictine routes [SEP]']
[Init] best perm rec loss: 0.8092995285987854 for ['[CLS] bureau species affirmed benedictine gravity added retracted reflection time evidence routes date [SEP]']
[Init] best perm rec loss: 0.8082594275474548 for ['[CLS] evidence routes species added gravity benedictine bureau reflection affirmed date retracted time [SEP]']
[Init] best perm rec loss: 0.8056796193122864 for ['[CLS] added routes evidence date bureau reflection benedictine species retracted time affirmed gravity [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.799 (perp=12.266, rec=0.329, cos=0.016), tot_loss_proj:4.250 [t=0.30s]
prediction: ['[CLS] ether mayhem series. raceway becameton bowie mania is before pollution [SEP]']
[ 100/2000] tot_loss=2.771 (perp=12.616, rec=0.235, cos=0.013), tot_loss_proj:4.323 [t=0.30s]
prediction: ['[CLS] mono mayhem minor ; mayhem quicklytontonton is.nivorous [SEP]']
[ 150/2000] tot_loss=2.423 (perp=11.183, rec=0.179, cos=0.007), tot_loss_proj:3.866 [t=0.30s]
prediction: ['[CLS] mono mayhem becomes ; mayhem quicklyton chesston becomes.nivorous [SEP]']
[ 200/2000] tot_loss=2.425 (perp=11.258, rec=0.167, cos=0.007), tot_loss_proj:3.853 [t=0.30s]
prediction: ['[CLS] mono mayhem becomes of mayhem quicklyton chesston becomes.ous [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.238 (perp=10.437, rec=0.146, cos=0.004), tot_loss_proj:3.373 [t=0.30s]
prediction: ['[CLS] mono mayhem becomes of mayhem quicklyton chesston becomesous. [SEP]']
[ 300/2000] tot_loss=2.362 (perp=11.085, rec=0.140, cos=0.005), tot_loss_proj:3.588 [t=0.30s]
prediction: ['[CLS] mono mayhem becomes of mayhem quicklyton becomeston becomesous. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.133 (perp=10.042, rec=0.122, cos=0.003), tot_loss_proj:2.792 [t=0.30s]
prediction: ['[CLS] mono mayhem becomes of mayhem quickly becomes becomeston monoous. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.548 (perp=7.126, rec=0.117, cos=0.006), tot_loss_proj:2.337 [t=0.30s]
prediction: ['[CLS] mono mayhem becomes of sort quickly becomes becomes monotonous. [SEP]']
[ 450/2000] tot_loss=1.534 (perp=7.126, rec=0.106, cos=0.003), tot_loss_proj:2.323 [t=0.30s]
prediction: ['[CLS] mono mayhem becomes of sort quickly becomes becomes monotonous. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.452 (perp=6.826, rec=0.085, cos=0.003), tot_loss_proj:2.228 [t=0.30s]
prediction: ['[CLS] mono mayhem becomes quickly sort of becomes becomes monotonous. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.432 (perp=6.700, rec=0.090, cos=0.003), tot_loss_proj:2.225 [t=0.30s]
prediction: ['[CLS] mono mayhem quickly becomes sort of becomes becomes monotonous. [SEP]']
[ 600/2000] tot_loss=1.498 (perp=7.093, rec=0.077, cos=0.002), tot_loss_proj:2.141 [t=0.30s]
prediction: ['[CLS] murder mayhem quickly becomes sort of becomes becomes monotonous. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.439 (perp=6.744, rec=0.087, cos=0.002), tot_loss_proj:2.038 [t=0.30s]
prediction: ['[CLS] murder quickly becomes sort of mayhem becomes becomes monotonous. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.424 (perp=6.744, rec=0.073, cos=0.002), tot_loss_proj:2.035 [t=0.30s]
prediction: ['[CLS] murder quickly becomes sort of mayhem becomes becomes monotonous. [SEP]']
[ 750/2000] tot_loss=1.432 (perp=6.744, rec=0.081, cos=0.002), tot_loss_proj:2.035 [t=0.30s]
prediction: ['[CLS] murder quickly becomes sort of mayhem becomes becomes monotonous. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.382 (perp=6.504, rec=0.079, cos=0.002), tot_loss_proj:1.916 [t=0.30s]
prediction: ['[CLS] murder becomes sort of mayhem quickly becomes becomes monotonous. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.372 (perp=6.449, rec=0.080, cos=0.002), tot_loss_proj:2.009 [t=0.30s]
prediction: ['[CLS] murder becomes sort of mayhem becomes quickly becomes monotonous. [SEP]']
[ 900/2000] tot_loss=1.363 (perp=6.449, rec=0.071, cos=0.002), tot_loss_proj:2.012 [t=0.30s]
prediction: ['[CLS] murder becomes sort of mayhem becomes quickly becomes monotonous. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.493 (perp=7.068, rec=0.078, cos=0.002), tot_loss_proj:1.936 [t=0.30s]
prediction: ['[CLS] murder and sort this mayhem becomes quickly becomes monotonous. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.340 (perp=6.357, rec=0.067, cos=0.002), tot_loss_proj:1.929 [t=0.30s]
prediction: ['[CLS] murder sort and this mayhem becomes quickly becomes monotonous. [SEP]']
[1050/2000] tot_loss=1.348 (perp=6.357, rec=0.075, cos=0.002), tot_loss_proj:1.932 [t=0.30s]
prediction: ['[CLS] murder sort and this mayhem becomes quickly becomes monotonous. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.296 (perp=6.126, rec=0.069, cos=0.002), tot_loss_proj:1.665 [t=0.30s]
prediction: ['[CLS] murder becomes and this mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.304 (perp=6.126, rec=0.077, cos=0.002), tot_loss_proj:1.663 [t=0.30s]
prediction: ['[CLS] murder becomes and this mayhem sort quickly becomes monotonous. [SEP]']
[1200/2000] tot_loss=1.364 (perp=6.475, rec=0.067, cos=0.002), tot_loss_proj:1.646 [t=0.30s]
prediction: ['[CLS] murder murder and this mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.235 (perp=5.865, rec=0.060, cos=0.002), tot_loss_proj:1.607 [t=0.30s]
prediction: ['[CLS] this murder and murder mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.243 (perp=5.865, rec=0.068, cos=0.002), tot_loss_proj:1.603 [t=0.30s]
prediction: ['[CLS] this murder and murder mayhem sort quickly becomes monotonous. [SEP]']
[1350/2000] tot_loss=1.251 (perp=5.865, rec=0.076, cos=0.002), tot_loss_proj:1.599 [t=0.30s]
prediction: ['[CLS] this murder and murder mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.241 (perp=5.865, rec=0.066, cos=0.002), tot_loss_proj:1.602 [t=0.30s]
prediction: ['[CLS] this murder and murder mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.245 (perp=5.865, rec=0.070, cos=0.002), tot_loss_proj:1.612 [t=0.30s]
prediction: ['[CLS] this murder and murder mayhem sort quickly becomes monotonous. [SEP]']
[1500/2000] tot_loss=1.245 (perp=5.865, rec=0.070, cos=0.002), tot_loss_proj:1.606 [t=0.30s]
prediction: ['[CLS] this murder and murder mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.160 (perp=5.476, rec=0.063, cos=0.002), tot_loss_proj:1.565 [t=0.30s]
prediction: ['[CLS] murder and murder this mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.165 (perp=5.476, rec=0.068, cos=0.002), tot_loss_proj:1.568 [t=0.30s]
prediction: ['[CLS] murder and murder this mayhem sort quickly becomes monotonous. [SEP]']
[1650/2000] tot_loss=1.170 (perp=5.476, rec=0.073, cos=0.002), tot_loss_proj:1.558 [t=0.30s]
prediction: ['[CLS] murder and murder this mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.176 (perp=5.476, rec=0.079, cos=0.002), tot_loss_proj:1.564 [t=0.30s]
prediction: ['[CLS] murder and murder this mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.162 (perp=5.476, rec=0.065, cos=0.002), tot_loss_proj:1.590 [t=0.30s]
prediction: ['[CLS] murder and murder this mayhem sort quickly becomes monotonous. [SEP]']
[1800/2000] tot_loss=1.163 (perp=5.476, rec=0.066, cos=0.002), tot_loss_proj:1.587 [t=0.30s]
prediction: ['[CLS] murder and murder this mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.159 (perp=5.476, rec=0.061, cos=0.002), tot_loss_proj:1.589 [t=0.30s]
prediction: ['[CLS] murder and murder this mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.162 (perp=5.476, rec=0.065, cos=0.002), tot_loss_proj:1.587 [t=0.30s]
prediction: ['[CLS] murder and murder this mayhem sort quickly becomes monotonous. [SEP]']
[1950/2000] tot_loss=1.175 (perp=5.476, rec=0.078, cos=0.002), tot_loss_proj:1.590 [t=0.30s]
prediction: ['[CLS] murder and murder this mayhem sort quickly becomes monotonous. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.162 (perp=5.476, rec=0.064, cos=0.002), tot_loss_proj:1.587 [t=0.30s]
prediction: ['[CLS] murder and murder this mayhem sort quickly becomes monotonous. [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] murder and mayhem of this sort quickly becomes monotonous. [SEP]
========================
predicted: 
========================
[CLS] murder and murder this mayhem sort quickly becomes monotonous. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 60.000 | p: 60.000 | r: 60.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 150.909

[Aggregate metrics]:
rouge1     | fm: 71.547 | p: 70.875 | r: 72.337
rouge2     | fm: 18.478 | p: 18.268 | r: 18.682
rougeL     | fm: 46.859 | p: 46.482 | r: 47.363
rougeLsum  | fm: 46.863 | p: 46.466 | r: 47.381
r1fm+r2fm = 90.025

input #84 time: 0:12:02 | total time: 17:59:23


Running input #85 of 100.
reference: 
========================
nothing more or less than an outright bodice-ripper -- it should have ditched the artsy pretensions and revelled in the entertaining shallows .
========================
average of cosine similarity 0.9991402814410714
highest_index [0]
highest [0.9991402814410714]
Debug: ids_shape = 36, pads = [36]
Debug: input ids = tensor([[  101,  2498,  2062,  2030,  2625,  2084,  2019, 13848,  8945, 24598,
          1011, 10973,  4842,  1011,  1011,  2009,  2323,  2031, 14033,  2098,
          1996,  2840,  2100,  3653, 29048,  2015,  1998,  7065, 21148,  1999,
          1996, 14036,  8467,  2015,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] nothing more or less than an outright bodice - ripper - - it should have ditched the artsy pretensions and revelled in the entertaining shallows. [SEP]']
[Init] best rec loss: 0.9987475275993347 for ['[CLS]torium later majority eyes roam married shall [MASK] note towards pier breaker see anyway petroleumult anchor book permitted classic carr is [SEP] camille egg levels establishioned zip hers denian johnny aba [SEP]']
[Init] best rec loss: 0.8758791089057922 for ['[CLS] together current bump $ _ loft jaw lips colton ed republic quarters deluxe hamish toward options attraction touch dodge " contents xu answer spencer sendsead cambridge ways ap saypiration ears huron hope [SEP]']
[Init] best rec loss: 0.8649404644966125 for ['[CLS] lucha retrieval beauty colored swami cue purple par buddy alternating mosquito re yearskey temple 0 just record violence p rest chair nee tertiary meaning extinct lim thousand stall celebrity when sorts hand were [SEP]']
[Init] best rec loss: 0.8199278116226196 for ['[CLS] portions anyhing island dummy m subject rest ren number impossible virgin driftधrian $ residential eurovision weapon boxes home airways happierttyces victim rusty stars social watershed dramatic word cuba here [SEP]']
[Init] best rec loss: 0.8080090284347534 for ['[CLS] word chinatown infectioneredhand gravity gen hunting two des treating ivy mega ontario fancy electricity nepaliique soilressed democrats directory † capableilised dawn " no tend reputationر chain intend infrared [SEP]']
[Init] best rec loss: 0.796428382396698 for ['[CLS] invented threat chaos launch borrowed pressure applicationmith don tournament interest players dispute rewarded horde pipe dying total tick march "fur in material expedition together cab common work rhodes inter unbeaten haute peak [SEP]']
[Init] best rec loss: 0.7959874272346497 for ['[CLS]grounds dare actions barber charges roderick strongizing elvis final slept landing pr rein cox hot laboratoryatic homecoming une propeller because step quarry twinned innocence anne decoworld reviewwest crambidae sakesett [SEP]']
[Init] best perm rec loss: 0.7955721616744995 for ['[CLS] roderick homecoming rein slept innocence crambidae laboratory sake because cox barbergrounds unesett step strong propeller anneatic charges landing hot darewest actions deco twinned finalworld quarry review elvisizing pr [SEP]']
[Init] best perm rec loss: 0.7951558232307434 for ['[CLS]west anne laboratory slept innocence chargessett sakegrounds homecoming cox step une dare because hot crambidaeizingatic propeller elvis rein quarry strong roderick final actions review twinned deco pr landingworld barber [SEP]']
[Init] best perm rec loss: 0.7912342548370361 for ['[CLS] annegroundsatic innocenceizing quarry barberworld laboratory charges propeller sake crambidae because twinned actions reinsett elvis pr slept roderick unewest final landing deco hot review cox homecoming step dare strong [SEP]']
[Init] best perm rec loss: 0.7910058498382568 for ['[CLS] quarry actions une step propeller anne strong elvis pr homecoming charges rein twinned laboratorysett barber review hot deco because final innocence sake landing sleptizingwestatic dare crambidaeworld roderick coxgrounds [SEP]']
[Init] best perm rec loss: 0.7871016263961792 for ['[CLS] laboratory dareizing elvis chargesgrounds landing homecoming crambidae roderick strong propeller step sake twinned final actions barber rein slept pr unesett because quarry hot deco innocence anneatic coxworld reviewwest [SEP]']
[Init] best perm rec loss: 0.7856091856956482 for ['[CLS]atic barber sake because roderick innocence step final anne homecoming decogrounds elvis strong rein dare propeller cox actionswest prsettizingworld charges laboratory quarry review landing une crambidae slept twinned hot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.785 (perp=11.603, rec=0.393, cos=0.071), tot_loss_proj:3.508 [t=0.31s]
prediction: ['[CLS]? seem [SEP] after gothic critically throat wrong save flewless equal storm breast less every mud maritime pathetic for hurt fur rear since screamed the offenders narrow deeper her.ator beenopers [SEP]']
[ 100/2000] tot_loss=2.537 (perp=11.036, rec=0.308, cos=0.022), tot_loss_proj:3.159 [t=0.31s]
prediction: ['[CLS] subspecies entertaining [SEP] perhaps gothic below sword wrong than quiteless quite blast? less petty mud captainfighting faux his material rear - screamed the shallow shallow entertaining the should entertainingelled deserves [SEP]']
[ 150/2000] tot_loss=2.365 (perp=10.435, rec=0.257, cos=0.021), tot_loss_proj:3.395 [t=0.31s]
prediction: ['[CLS] the entertaining. once gothic written the wrong than nothing nothing quiteper : ignore petty mud captainsts ditch histension easily - should the shallow entertaining entertaining the should entertainingelled deserves [SEP]']
[ 200/2000] tot_loss=2.248 (perp=10.140, rec=0.206, cos=0.014), tot_loss_proj:3.124 [t=0.31s]
prediction: ['[CLS] the entertaining. have gothic ground - wrong than nothing nothing quitepers less lessratpertension ditch histension easily - should the shallow entertaining entertainings should entertainingelled deserves [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.302 (perp=10.260, rec=0.236, cos=0.014), tot_loss_proj:3.141 [t=0.31s]
prediction: ['[CLS]. entertaining [SEP] it gothic -glingjust than nothing an quite snap vampire less or! maritime reasoning ditch havetensionedly - stupid the shallow entertaining entertainings should haveelled. [SEP]']
[ 300/2000] tot_loss=2.254 (perp=10.406, rec=0.169, cos=0.004), tot_loss_proj:3.415 [t=0.31s]
prediction: ['[CLS], entertaining [SEP] it gothic near gown pri than nothing an quite mph would less or! water reasoning ditch havetensionly - she the shallow entertaining entertainings should haveelled. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.079 (perp=9.650, rec=0.144, cos=0.004), tot_loss_proj:2.972 [t=0.31s]
prediction: ['[CLS], entertaining [SEP] it acre less - less rev than nothing an quitedice would or! watertension ditch havetension and - she the shallowtension entertainings should haveelled. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.104 (perp=9.776, rec=0.146, cos=0.003), tot_loss_proj:2.912 [t=0.31s]
prediction: ['[CLS] the entertaining [SEP] it acre less - less rev than nothing an firmlydice orrat watertension ditched havetension and - she the shallowtension entertainings should haveelled. [SEP]']
[ 450/2000] tot_loss=2.067 (perp=9.748, rec=0.115, cos=0.002), tot_loss_proj:2.837 [t=0.31s]
prediction: ['[CLS] the entertaining [SEP] it acre less - less rev than nothing an outrightdice orrat watertension ditching thetension and -ada the shallowtension entertainings should haveelled. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.972 (perp=9.278, rec=0.114, cos=0.002), tot_loss_proj:2.795 [t=0.31s]
prediction: ['[CLS] most entertaining [SEP] it acre less - less rev than nothing an outrightdice or watertension ditched therattension and -ada the shallowtension entertainings should haveelled. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.916 (perp=9.002, rec=0.113, cos=0.002), tot_loss_proj:2.727 [t=0.31s]
prediction: ['[CLS] most entertaining [SEP] it acre less - less rev than nothing an outrightdice or watertension ditched therattension and -ada the shallowtensions entertaining should haveelled. [SEP]']
[ 600/2000] tot_loss=1.891 (perp=8.914, rec=0.106, cos=0.002), tot_loss_proj:2.708 [t=0.32s]
prediction: ['[CLS] most entertaining less it acre less - less rev than nothing an outrightdice or watertension ditched therattension and -ada the shallowtensions entertaining should haveelled. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.819 (perp=8.606, rec=0.096, cos=0.002), tot_loss_proj:2.655 [t=0.31s]
prediction: ['[CLS] most entertaining less it acre less - less rev than nothing an outrightdice or watertension ditched the riptension and -ada the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.771 (perp=8.320, rec=0.105, cos=0.002), tot_loss_proj:2.664 [t=0.31s]
prediction: ['[CLS] most entertaining less it acre less - less water than nothing an outrightdice or revtension ditched the riptension and -ada the shallowtensions should have entertainingelled. [SEP]']
[ 750/2000] tot_loss=1.757 (perp=8.284, rec=0.098, cos=0.002), tot_loss_proj:2.644 [t=0.31s]
prediction: ['[CLS] most entertaining more it acre less - less water than nothing an outrightdice or revtension ditched the riptension and -dice the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.701 (perp=8.031, rec=0.094, cos=0.002), tot_loss_proj:2.520 [t=0.31s]
prediction: ['[CLS] most entertaining more it acre less - less water than nothing an outrightdice or revtension ditched the riptension anddice - the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.868 (perp=8.842, rec=0.098, cos=0.002), tot_loss_proj:2.627 [t=0.31s]
prediction: ['[CLS] most entertaining flicker it acre less - less [SEP] than nothing an outrightdice or revtension ditched the riptension anddice - the shallowtensions should have entertainingelled. [SEP]']
[ 900/2000] tot_loss=1.856 (perp=8.820, rec=0.090, cos=0.002), tot_loss_proj:2.757 [t=0.31s]
prediction: ['[CLS] most - water it acre less - less [SEP] than nothing an outrightdice or revtension ditched the riptension anddice - the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.828 (perp=8.653, rec=0.096, cos=0.002), tot_loss_proj:2.721 [t=0.31s]
prediction: ['[CLS] most - water it acre less - less than [SEP] nothing an outrightdice or revtension ditched the riptension anddice - the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.836 (perp=8.697, rec=0.095, cos=0.002), tot_loss_proj:2.696 [t=0.31s]
prediction: ['[CLS] most - it water acre less - less than [SEP] nothing an outrightdice or revtension ditched the riptension anddice - the shallowtensions should have entertainingelled. [SEP]']
[1050/2000] tot_loss=1.886 (perp=8.970, rec=0.091, cos=0.002), tot_loss_proj:2.734 [t=0.31s]
prediction: ['[CLS] most - it water acre less - less than [SEP] nothing an outrightdice or revtension ditchper the riptension anddice - the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.808 (perp=8.577, rec=0.091, cos=0.002), tot_loss_proj:2.664 [t=0.31s]
prediction: ['[CLS] more - itdice acre less - less than [SEP] nothing an outrightdice or revtension ditchper the riptension and water - the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.750 (perp=8.306, rec=0.087, cos=0.002), tot_loss_proj:2.605 [t=0.31s]
prediction: ['[CLS] more - itdice acre less - less than [SEP] nothing an outrightdice or revtension ditch the rippertension and water - the shallowtensions should have entertainingelled. [SEP]']
[1200/2000] tot_loss=1.759 (perp=8.306, rec=0.096, cos=0.002), tot_loss_proj:2.609 [t=0.31s]
prediction: ['[CLS] more - itdice acre less - less than [SEP] nothing an outrightdice or revtension ditch the rippertension and water - the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.746 (perp=8.306, rec=0.083, cos=0.002), tot_loss_proj:2.609 [t=0.31s]
prediction: ['[CLS] more - itdice acre less - less than [SEP] nothing an outrightdice or revtension ditch the rippertension and water - the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.727 (perp=8.100, rec=0.105, cos=0.002), tot_loss_proj:2.603 [t=0.31s]
prediction: ['[CLS] more - itdice acre less - less than [SEP] nothing an outright rip or revtension the ripper ditchtension and water - the shallowtensions should have entertainingelled. [SEP]']
[1350/2000] tot_loss=1.711 (perp=8.100, rec=0.089, cos=0.002), tot_loss_proj:2.600 [t=0.31s]
prediction: ['[CLS] more - itdice acre less - less than [SEP] nothing an outright rip or revtension the ripper ditchtension and water - the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.695 (perp=7.993, rec=0.094, cos=0.002), tot_loss_proj:2.649 [t=0.31s]
prediction: ['[CLS] more - itdice acre - less less than [SEP] nothing an outright rip or revtension the ripper ditchtension and water - the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.677 (perp=7.853, rec=0.104, cos=0.002), tot_loss_proj:2.665 [t=0.31s]
prediction: ['[CLS] more - itdice acre - less less thantension [SEP] nothing an outright rip or revtension the ripper ditch and water - the shallowtensions should have entertainingelled. [SEP]']
[1500/2000] tot_loss=1.662 (perp=7.853, rec=0.090, cos=0.002), tot_loss_proj:2.663 [t=0.40s]
prediction: ['[CLS] more - itdice acre - less less thantension [SEP] nothing an outright rip or revtension the ripper ditch and water - the shallowtensions should have entertainingelled. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.622 (perp=7.625, rec=0.096, cos=0.002), tot_loss_proj:2.496 [t=0.31s]
prediction: ['[CLS] more - itdice acre - less less thantension [SEP] nothing an outright rip or entertainingtension the ripper ditch and water - the shallowtensions should have revelled. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.603 (perp=7.540, rec=0.094, cos=0.002), tot_loss_proj:2.518 [t=0.31s]
prediction: ['[CLS] more - itdice acre - less less [SEP]tension than nothing an outright rip or entertainingtension the ripper ditch and water - the shallowtensions should have revelled. [SEP]']
[1650/2000] tot_loss=1.593 (perp=7.540, rec=0.083, cos=0.002), tot_loss_proj:2.514 [t=0.31s]
prediction: ['[CLS] more - itdice acre - less less [SEP]tension than nothing an outright rip or entertainingtension the ripper ditch and water - the shallowtensions should have revelled. [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.558 (perp=7.311, rec=0.094, cos=0.002), tot_loss_proj:2.277 [t=0.31s]
prediction: ['[CLS] more - itdice acre - less nothing less [SEP]tension than an outright rip or entertainingtension the ripper ditch and water - the shallowtensions should have revelled. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.556 (perp=7.311, rec=0.092, cos=0.002), tot_loss_proj:2.284 [t=0.31s]
prediction: ['[CLS] more - itdice acre - less nothing less [SEP]tension than an outright rip or entertainingtension the ripper ditch and water - the shallowtensions should have revelled. [SEP]']
[1800/2000] tot_loss=1.554 (perp=7.311, rec=0.090, cos=0.002), tot_loss_proj:2.285 [t=0.32s]
prediction: ['[CLS] more - itdice acre - less nothing less [SEP]tension than an outright rip or entertainingtension the ripper ditch and water - the shallowtensions should have revelled. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.514 (perp=7.127, rec=0.087, cos=0.002), tot_loss_proj:2.311 [t=0.31s]
prediction: ['[CLS] more - itdice acre - less nothing less [SEP]tension than an outright or entertaining riptension the ripper ditch and water - the shallowtensions should have revelled. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.572 (perp=7.334, rec=0.103, cos=0.002), tot_loss_proj:2.433 [t=0.31s]
prediction: ['[CLS] [SEP] - itdice acre - less nothing lessedtension than an outright or entertaining riptension the ripper ditch and water - the shallowtensions should have revelled. [SEP]']
[1950/2000] tot_loss=1.549 (perp=7.334, rec=0.081, cos=0.002), tot_loss_proj:2.429 [t=0.31s]
prediction: ['[CLS] [SEP] - itdice acre - less nothing lessedtension than an outright or entertaining riptension the ripper ditch and water - the shallowtensions should have revelled. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.503 (perp=7.070, rec=0.088, cos=0.002), tot_loss_proj:2.407 [t=0.31s]
prediction: ['[CLS] [SEP] - itdice acre - less nothing lesstensioned than an outright or entertaining riptension the ripper ditch and water - the shallowtensions should have revelled. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] nothing more or less than an outright bodice - ripper - - it should have ditched the artsy pretensions and revelled in the entertaining shallows. [SEP]
========================
predicted: 
========================
[CLS] more - itdice acre - less nothing less [SEP]tension than an outright rip or entertainingtension the ripper ditch and water - the shallowtensions should have revelled. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.000 | p: 61.538 | r: 66.667
rouge2     | fm: 12.500 | p: 12.000 | r: 13.043
rougeL     | fm: 44.000 | p: 42.308 | r: 45.833
rougeLsum  | fm: 44.000 | p: 42.308 | r: 45.833
r1fm+r2fm = 76.500

[Aggregate metrics]:
rouge1     | fm: 71.481 | p: 70.771 | r: 72.281
rouge2     | fm: 18.417 | p: 18.239 | r: 18.647
rougeL     | fm: 46.830 | p: 46.364 | r: 47.346
rougeLsum  | fm: 46.812 | p: 46.422 | r: 47.332
r1fm+r2fm = 89.898

input #85 time: 0:12:24 | total time: 18:11:48


Running input #86 of 100.
reference: 
========================
with its hints of a greater intelligence lurking somewhere , the ring makes its stupidity more than obvious . it's painful .
========================
average of cosine similarity 0.9990814112754115
highest_index [0]
highest [0.9990814112754115]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  2007,  2049, 20385,  1997,  1037,  3618,  4454, 24261,  4873,
          1010,  1996,  3614,  3084,  2049, 28072,  2062,  2084,  5793,  1012,
          2009,  1005,  1055,  9145,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] with its hints of a greater intelligence lurking somewhere, the ring makes its stupidity more than obvious. it's painful. [SEP]"]
[Init] best rec loss: 0.8271006345748901 for ['[CLS] piece copies brush between casey to dhabi infected at drama spade cost explored instead anerland picket classical branches highly pulitzer fat whatever korea [SEP]']
[Init] best rec loss: 0.8085843324661255 for ['[CLS] night braden given key collectors even commanding fuck risk white morning block ends spots relaxed to ray each award commercial blah fed ifiss [SEP]']
[Init] best rec loss: 0.8008968830108643 for ['[CLS] tank point limp penny school... eye ring braid hundred darcy rise fortune spa : casey trade deliver list abby cars individuals lying match [SEP]']
[Init] best rec loss: 0.7894007563591003 for ['[CLS] population atollea drunk ava ready interchangekari lot ft station via shock diary val lore cyrillic frequency faye growing midway gunshot mouse lady [SEP]']
[Init] best rec loss: 0.7802572250366211 for ['[CLS] still title everything member % door haasami stood app madving bundled since wondered without timing nation bobeem chet layne pen brooklyn [SEP]']
[Init] best perm rec loss: 0.7770310044288635 for ['[CLS] mad nation everything since door wondered brooklyn stood chet member app bob %eem pen without layne bundledving titleami still timing haas [SEP]']
[Init] best perm rec loss: 0.7756201028823853 for ['[CLS]eem bob chet brooklyn wondered mad bundled app since timing everything stood nation still member door without title layneamiving pen % haas [SEP]']
[Init] best perm rec loss: 0.7716958522796631 for ['[CLS] wondered stilleemami mad door member bob since brooklyn % layne without stoodving title everything app nation timing haas bundled pen chet [SEP]']
[Init] best perm rec loss: 0.769723653793335 for ['[CLS] haasami member app madeem % layne brooklyn wondered since timing bundled stood title bob door without everything nation stillving chet pen [SEP]']
[Init] best perm rec loss: 0.7691918611526489 for ['[CLS] haas nation timing stood mad app member % brooklyn bob door wondered bundled chet layne since everything withouteem titleving penami still [SEP]']
[Init] best perm rec loss: 0.7690476179122925 for ['[CLS] door title layne since everything haas still brooklyn chet wondered timingami mad nation app without pen bundledeemving bob % stood member [SEP]']
[Init] best perm rec loss: 0.7666324377059937 for ['[CLS]eemami title stood app nation still layne everything mad without bundled haas brooklyn wondered bob member pen timing % door chet sinceving [SEP]']
[Init] best perm rec loss: 0.7648013830184937 for ['[CLS] nation madami door stood chet since layne appving still title pen wondered everythingeem without haas timing % bundled brooklyn bob member [SEP]']
[Init] best perm rec loss: 0.7633851170539856 for ['[CLS]ami timing bob stood nation app door layne peneem bundled everything since brooklyn wondered still haas chet without member mad titleving % [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.808 (perp=12.111, rec=0.362, cos=0.024), tot_loss_proj:3.634 [t=0.31s]
prediction: ['[CLS] quantum exactdray. stupidity pearl. triple an painful was was painful is programrigue, relatively wounds tokyo alliance fi many [SEP]']
[ 100/2000] tot_loss=2.182 (perp=9.517, rec=0.266, cos=0.013), tot_loss_proj:3.076 [t=0.31s]
prediction: ['[CLS] lurking exact their stupidity. stupidity ring. sounding an painful. is painful is programme why. intelligent wounds advertisement the it. [SEP]']
[ 150/2000] tot_loss=2.270 (perp=9.512, rec=0.326, cos=0.041), tot_loss_proj:3.248 [t=0.31s]
prediction: ["[CLS] lurking louis his stupidity'stupidity ring. the an stupidity. of painful iscoming quite. intelligence wounds makes as ring. [SEP]"]
[ 200/2000] tot_loss=1.883 (perp=8.265, rec=0.222, cos=0.009), tot_loss_proj:3.282 [t=0.31s]
prediction: ["[CLS] its than its stupidity'stupidity ring for the is practical. is painful is if more. intelligence grenade makes place itself. [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.502 (perp=10.058, rec=0.402, cos=0.088), tot_loss_proj:3.401 [t=0.31s]
prediction: ['[CLS] lurking economic without stupidity its stupidity ring a the s than. is painful [CLS] pending more.icides than advertising the its. [SEP]']
[ 300/2000] tot_loss=2.330 (perp=10.372, rec=0.248, cos=0.008), tot_loss_proj:3.288 [t=0.31s]
prediction: ["[CLS] its economic less stupidity it stupidity ring - the s than. was painful it obvious made. heirs than advertising'madame. [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.190 (perp=9.843, rec=0.216, cos=0.005), tot_loss_proj:3.212 [t=0.31s]
prediction: ["[CLS] lurking intelligence less stupidity it stupidity than - the s than. of painful it intelligence made. heirs ring ads'madame. [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.094 (perp=9.233, rec=0.238, cos=0.010), tot_loss_proj:3.259 [t=0.31s]
prediction: ["[CLS] its intelligence less distant stupidity it stupidity than - the s. of painful it intelligence made. heirs ring an'madame. [SEP]"]
[ 450/2000] tot_loss=1.940 (perp=8.602, rec=0.211, cos=0.009), tot_loss_proj:2.889 [t=0.31s]
prediction: ["[CLS] its intelligence less person stupidity it stupidity than, the s., painful it lurking made. heirs ring an'obvious. [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.895 (perp=8.523, rec=0.187, cos=0.004), tot_loss_proj:3.063 [t=0.31s]
prediction: ["[CLS] its intelligence than potent stupidity it stupidity, than the s., painful it lurking made. replies ring an'obvious. [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.881 (perp=8.468, rec=0.184, cos=0.004), tot_loss_proj:3.003 [t=0.31s]
prediction: ["[CLS] its intelligence than potent replies its stupidity, makes the s., painful it lurking made. stupidity ring particle'obvious. [SEP]"]
[ 600/2000] tot_loss=1.857 (perp=8.468, rec=0.160, cos=0.003), tot_loss_proj:3.007 [t=0.31s]
prediction: ["[CLS] its intelligence than potent replies its stupidity, makes the s., painful it lurking made. stupidity ring particle'obvious. [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.834 (perp=8.346, rec=0.162, cos=0.003), tot_loss_proj:2.927 [t=0.31s]
prediction: ["[CLS] its intelligence than potent replies its stupidity makes, the s., painful s lurking made. stupidity ring particle'obvious. [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.901 (perp=8.487, rec=0.190, cos=0.013), tot_loss_proj:2.978 [t=0.31s]
prediction: ["[CLS] its intelligence than distant replies its stupidity makes - the s. the painful every lurking made. stupidity ring s'obvious. [SEP]"]
[ 750/2000] tot_loss=1.765 (perp=8.041, rec=0.151, cos=0.006), tot_loss_proj:2.617 [t=0.31s]
prediction: ["[CLS] its deserve than potent intelligence its stupidity makes, the s. the painful every intelligence made. stupidity ring it'obvious. [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.309 (perp=9.904, rec=0.303, cos=0.025), tot_loss_proj:3.178 [t=0.31s]
prediction: ['[CLS] its enough than person intelligence i painful makes the, s painful the painful an intelligence made. stupidity ring s issued obvious. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.890 (perp=8.175, rec=0.244, cos=0.011), tot_loss_proj:2.618 [t=0.31s]
prediction: ['[CLS] its enough than person intelligence makes the, s i painful. the painful the intelligence made. stupidity ring s an obvious. [SEP]']
[ 900/2000] tot_loss=1.898 (perp=8.409, rec=0.210, cos=0.007), tot_loss_proj:2.640 [t=0.31s]
prediction: ['[CLS] its enough than person intelligence makes by, s i painful. the painful the intelligence made. stupidity ring s an obvious. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.817 (perp=8.016, rec=0.207, cos=0.007), tot_loss_proj:2.596 [t=0.31s]
prediction: ['[CLS] its enough than, s does painful. the painful as intelligence makes around the intelligence made. stupidity ring s more obvious. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.754 (perp=7.780, rec=0.193, cos=0.005), tot_loss_proj:2.534 [t=0.31s]
prediction: ['[CLS] itsxi than, s does painful. the painful as intelligence makes around the intelligence. stupidity made ring it more obvious. [SEP]']
[1050/2000] tot_loss=1.743 (perp=7.780, rec=0.183, cos=0.004), tot_loss_proj:2.537 [t=0.31s]
prediction: ['[CLS] itsxi than, s does painful. the painful as intelligence makes around the intelligence. stupidity made ring it more obvious. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.683 (perp=7.497, rec=0.180, cos=0.004), tot_loss_proj:2.494 [t=0.31s]
prediction: ['[CLS] itsxi than, s. painful does the painful as intelligence makes around the intelligence. stupidity made ring it more obvious. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.716 (perp=7.707, rec=0.170, cos=0.004), tot_loss_proj:2.660 [t=0.31s]
prediction: ["[CLS] itsxi than s. painful does the painful, as intelligence makes around'intelligence. stupidity made ring it more obvious. [SEP]"]
[1200/2000] tot_loss=1.625 (perp=7.253, rec=0.171, cos=0.003), tot_loss_proj:2.548 [t=0.31s]
prediction: ['[CLS] itsxi than s. painful does the painful, as intelligence makes around the intelligence. stupidity made ring it more obvious. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.605 (perp=7.193, rec=0.163, cos=0.003), tot_loss_proj:2.550 [t=0.31s]
prediction: ['[CLS] its intelligence than s. painful does the painful, asxi makes around the intelligence. stupidity made ring it more obvious. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.755 (perp=7.901, rec=0.169, cos=0.006), tot_loss_proj:2.748 [t=0.31s]
prediction: ["[CLS] its intelligence than s. painful does the painful, largerxi makes ring on'intelligence. stupidity made it more obvious. [SEP]"]
[1350/2000] tot_loss=1.703 (perp=7.708, rec=0.158, cos=0.004), tot_loss_proj:2.696 [t=0.31s]
prediction: ["[CLS] its intelligence than s. painful does the painful, largerxi makes ring around'intelligence. stupidity made it more obvious. [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.689 (perp=7.613, rec=0.163, cos=0.004), tot_loss_proj:2.659 [t=0.31s]
prediction: ["[CLS] its intelligence than s. painful does'painful, asxi makes ring around the intelligence. stupidity made s more obvious. [SEP]"]
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.562 (perp=6.978, rec=0.163, cos=0.004), tot_loss_proj:2.617 [t=0.31s]
prediction: ["[CLS] its intelligence than s. painful does painful ', asxi makes ring around the intelligence. stupidity made it more obvious. [SEP]"]
[1500/2000] tot_loss=1.556 (perp=6.978, rec=0.158, cos=0.003), tot_loss_proj:2.614 [t=0.31s]
prediction: ["[CLS] its intelligence than s. painful does painful ', asxi makes ring around the intelligence. stupidity made it more obvious. [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.642 (perp=7.409, rec=0.157, cos=0.003), tot_loss_proj:2.642 [t=0.31s]
prediction: ['[CLS] its intelligence than s. painful does painful its, asxi makes ring around the intelligence. stupidity made it more obvious. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.537 (perp=6.826, rec=0.167, cos=0.005), tot_loss_proj:2.471 [t=0.31s]
prediction: ['[CLS] its intelligence than s. painful does painful, asxi makes ring around the intelligence. its stupidity made it more obvious. [SEP]']
[1650/2000] tot_loss=1.523 (perp=6.826, rec=0.154, cos=0.003), tot_loss_proj:2.466 [t=0.31s]
prediction: ['[CLS] its intelligence than s. painful does painful, asxi makes ring around the intelligence. its stupidity made it more obvious. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.612 (perp=7.288, rec=0.151, cos=0.003), tot_loss_proj:2.676 [t=0.31s]
prediction: ['[CLS] its intelligence than s. painful does painful, largerxi makes ring around the intelligence. its stupidity made it more obvious. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.612 (perp=7.221, rec=0.163, cos=0.005), tot_loss_proj:2.643 [t=0.31s]
prediction: ["[CLS] its intelligence than s. painful doesxi painful, larger makes ring around the intelligence.'stupidity made it more obvious. [SEP]"]
[1800/2000] tot_loss=1.597 (perp=7.221, rec=0.149, cos=0.003), tot_loss_proj:2.648 [t=0.31s]
prediction: ["[CLS] its intelligence than s. painful doesxi painful, larger makes ring around the intelligence.'stupidity made it more obvious. [SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=1.571 (perp=7.105, rec=0.147, cos=0.003), tot_loss_proj:2.717 [t=0.31s]
prediction: ['[CLS] its intelligence than s. painful doesxi painful larger, makes ring around the intelligence. its stupidity made it more obvious. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.549 (perp=6.962, rec=0.153, cos=0.003), tot_loss_proj:2.575 [t=0.31s]
prediction: ["[CLS] its intelligence than s. painful doesxi painful, makes ring around the larger intelligence.'stupidity made it more obvious. [SEP]"]
[1950/2000] tot_loss=1.550 (perp=6.962, rec=0.155, cos=0.003), tot_loss_proj:2.573 [t=0.31s]
prediction: ["[CLS] its intelligence than s. painful doesxi painful, makes ring around the larger intelligence.'stupidity made it more obvious. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.520 (perp=6.865, rec=0.144, cos=0.003), tot_loss_proj:2.566 [t=0.31s]
prediction: ["[CLS] its intelligence than s. painful itsxi painful, makes ring around the larger intelligence.'stupidity made it more obvious. [SEP]"]
Done with input #86 of 100.
reference: 
========================
[CLS] with its hints of a greater intelligence lurking somewhere, the ring makes its stupidity more than obvious. it's painful. [SEP]
========================
predicted: 
========================
[CLS] its intelligence than s. painful doesxi painful, makes ring around the larger intelligence.'stupidity made it more obvious. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 70.000 | r: 63.636
rouge2     | fm: 5.000 | p: 5.263 | r: 4.762
rougeL     | fm: 38.095 | p: 40.000 | r: 36.364
rougeLsum  | fm: 38.095 | p: 40.000 | r: 36.364
r1fm+r2fm = 71.667

[Aggregate metrics]:
rouge1     | fm: 71.320 | p: 70.725 | r: 72.120
rouge2     | fm: 18.300 | p: 18.109 | r: 18.534
rougeL     | fm: 46.776 | p: 46.368 | r: 47.299
rougeLsum  | fm: 46.769 | p: 46.418 | r: 47.246
r1fm+r2fm = 89.620

input #86 time: 0:12:23 | total time: 18:24:12


Running input #87 of 100.
reference: 
========================
directed in a paint-by-numbers manner .
========================
average of cosine similarity 0.99928319633189
highest_index [0]
highest [0.99928319633189]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2856, 1999, 1037, 6773, 1011, 2011, 1011, 3616, 5450, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] directed in a paint - by - numbers manner. [SEP]']
[Init] best rec loss: 0.9034620523452759 for ['[CLS] madeline terrorismional thinkingrger ratio leave collaborate lake fighting [SEP]']
[Init] best rec loss: 0.8663427829742432 for ['[CLS] done whole lucastatic regained konction hadbone yours [SEP]']
[Init] best rec loss: 0.859840989112854 for ['[CLS]ato pack themselves known content compatible km gale kissing vector [SEP]']
[Init] best rec loss: 0.8153355717658997 for ['[CLS] floor skiing deputy whose personsheardat single seas guerrilla [SEP]']
[Init] best rec loss: 0.813534677028656 for ['[CLS]rani after instrument gaelic dillon conveniencemus element " ku [SEP]']
[Init] best perm rec loss: 0.8071246147155762 for ['[CLS] gaelic element " after ku dillon instrumentranimus convenience [SEP]']
[Init] best perm rec loss: 0.8039659857749939 for ['[CLS]rani " gaelicmus ku after instrument dillon element convenience [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.832 (perp=12.246, rec=0.354, cos=0.029), tot_loss_proj:4.039 [t=0.30s]
prediction: ['[CLS] directed [SEP] robes value before dutch - directed website fear [SEP]']
[ 100/2000] tot_loss=2.024 (perp=8.966, rec=0.223, cos=0.008), tot_loss_proj:3.018 [t=0.30s]
prediction: ['[CLS] directed in paint manner before by - directed conducted. [SEP]']
[ 150/2000] tot_loss=1.959 (perp=8.972, rec=0.159, cos=0.005), tot_loss_proj:2.891 [t=0.30s]
prediction: ['[CLS] directed in paint manner phrase a - numbers by. [SEP]']
[ 200/2000] tot_loss=1.803 (perp=8.355, rec=0.127, cos=0.005), tot_loss_proj:2.616 [t=0.30s]
prediction: ['[CLS] directed in paint manner phrase by - numbers numbers. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.610 (perp=7.467, rec=0.112, cos=0.005), tot_loss_proj:2.694 [t=0.31s]
prediction: ['[CLS] phrase directed in paint manner by - numbers by. [SEP]']
[ 300/2000] tot_loss=1.594 (perp=7.561, rec=0.079, cos=0.002), tot_loss_proj:2.680 [t=0.30s]
prediction: ['[CLS] phrase directed in paint manner by - numbers -. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.549 (perp=7.288, rec=0.089, cos=0.002), tot_loss_proj:2.596 [t=0.31s]
prediction: ['[CLS] phrase directed in paint manner by - numbers numbers. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.538 (perp=7.288, rec=0.078, cos=0.002), tot_loss_proj:2.593 [t=0.31s]
prediction: ['[CLS] phrase directed in paint manner by - numbers numbers. [SEP]']
[ 450/2000] tot_loss=1.539 (perp=7.288, rec=0.079, cos=0.002), tot_loss_proj:2.592 [t=0.31s]
prediction: ['[CLS] phrase directed in paint manner by - numbers numbers. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.538 (perp=7.288, rec=0.079, cos=0.002), tot_loss_proj:2.592 [t=0.31s]
prediction: ['[CLS] phrase directed in paint manner by - numbers numbers. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.604 (perp=7.614, rec=0.079, cos=0.001), tot_loss_proj:2.593 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - numbers numbers. [SEP]']
[ 600/2000] tot_loss=1.602 (perp=7.614, rec=0.077, cos=0.002), tot_loss_proj:2.590 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - numbers numbers. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.540 (perp=7.327, rec=0.074, cos=0.001), tot_loss_proj:2.437 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.538 (perp=7.327, rec=0.072, cos=0.001), tot_loss_proj:2.444 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
[ 750/2000] tot_loss=1.538 (perp=7.327, rec=0.071, cos=0.001), tot_loss_proj:2.443 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.530 (perp=7.327, rec=0.063, cos=0.001), tot_loss_proj:2.439 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.545 (perp=7.327, rec=0.078, cos=0.001), tot_loss_proj:2.444 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
[ 900/2000] tot_loss=1.542 (perp=7.327, rec=0.076, cos=0.001), tot_loss_proj:2.448 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.537 (perp=7.327, rec=0.070, cos=0.001), tot_loss_proj:2.450 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.539 (perp=7.327, rec=0.072, cos=0.001), tot_loss_proj:2.451 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
[1050/2000] tot_loss=1.537 (perp=7.327, rec=0.071, cos=0.001), tot_loss_proj:2.451 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.545 (perp=7.327, rec=0.078, cos=0.001), tot_loss_proj:2.451 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.539 (perp=7.327, rec=0.072, cos=0.001), tot_loss_proj:2.442 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
[1200/2000] tot_loss=1.534 (perp=7.327, rec=0.067, cos=0.001), tot_loss_proj:2.453 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.540 (perp=7.327, rec=0.074, cos=0.001), tot_loss_proj:2.447 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.541 (perp=7.327, rec=0.074, cos=0.001), tot_loss_proj:2.450 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
[1350/2000] tot_loss=1.538 (perp=7.327, rec=0.071, cos=0.001), tot_loss_proj:2.450 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.543 (perp=7.327, rec=0.076, cos=0.001), tot_loss_proj:2.449 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.538 (perp=7.327, rec=0.071, cos=0.001), tot_loss_proj:2.452 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
[1500/2000] tot_loss=1.538 (perp=7.327, rec=0.071, cos=0.001), tot_loss_proj:2.452 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.548 (perp=7.327, rec=0.081, cos=0.001), tot_loss_proj:2.456 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.539 (perp=7.327, rec=0.072, cos=0.001), tot_loss_proj:2.453 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
[1650/2000] tot_loss=1.540 (perp=7.327, rec=0.073, cos=0.001), tot_loss_proj:2.452 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.539 (perp=7.327, rec=0.072, cos=0.001), tot_loss_proj:2.452 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.548 (perp=7.327, rec=0.081, cos=0.001), tot_loss_proj:2.453 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
[1800/2000] tot_loss=1.531 (perp=7.327, rec=0.065, cos=0.001), tot_loss_proj:2.452 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.543 (perp=7.327, rec=0.076, cos=0.001), tot_loss_proj:2.450 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.541 (perp=7.327, rec=0.074, cos=0.001), tot_loss_proj:2.446 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
[1950/2000] tot_loss=1.537 (perp=7.327, rec=0.070, cos=0.001), tot_loss_proj:2.452 [t=0.30s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.528 (perp=7.327, rec=0.061, cos=0.001), tot_loss_proj:2.455 [t=0.31s]
prediction: ['[CLS] by directed in paint manner by - - numbers. [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] directed in a paint - by - numbers manner. [SEP]
========================
predicted: 
========================
[CLS] by directed in paint manner by - - numbers. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 113.889

[Aggregate metrics]:
rouge1     | fm: 71.575 | p: 70.953 | r: 72.406
rouge2     | fm: 18.377 | p: 18.209 | r: 18.590
rougeL     | fm: 47.104 | p: 46.725 | r: 47.605
rougeLsum  | fm: 47.069 | p: 46.755 | r: 47.538
r1fm+r2fm = 89.952

input #87 time: 0:12:04 | total time: 18:36:16


Running input #88 of 100.
reference: 
========================
an excruciating demonstration of the unsalvageability of a movie saddled with an amateurish screenplay .
========================
average of cosine similarity 0.9991617272183925
highest_index [0]
highest [0.9991617272183925]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  2019,  4654, 26775, 14194, 15370, 10467,  1997,  1996,  4895,
         12002,  3567,  3351,  8010,  1997,  1037,  3185, 12279,  2094,  2007,
          2019,  5515,  4509,  9000,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] an excruciating demonstration of the unsalvageability of a movie saddled with an amateurish screenplay. [SEP]']
[Init] best rec loss: 0.9159634113311768 for ['[CLS] strongerorted blue! services hangul after rhodes else simgol gasky defect left kong theorem isn still life blake relevant social archives [SEP]']
[Init] best rec loss: 0.9124062657356262 for ['[CLS] [CLS] company arrival tale church founded s findings arielyl sex madetin there tower either vi re h railway excelled measurement left bacteria [SEP]']
[Init] best rec loss: 0.8749366402626038 for ['[CLS] master ai thick masterpiece recreation ofitor term rescuedls backuisingta supply torpedo mother jordanpres scrap plans no brighamntine production [SEP]']
[Init] best rec loss: 0.8575739860534668 for ['[CLS] worth cadet assassin packing handkerchief langdon credited hands canadian paternal storagedro rose shop crossed ryder awayder argent worst fun mvp lies actively [SEP]']
[Init] best rec loss: 0.7751242518424988 for ['[CLS] grave para expressway guys donation perhaps chemistry reserved hang hey intelligencetical considered raft viceroy declared fire calledgationbandwang law brunswick filming [SEP]']
[Init] best perm rec loss: 0.7727735638618469 for ['[CLS] reserved fire expresswaywang brunswick hey para intelligence donation filming gravetical guys perhaps calledgation chemistry law viceroyband hang considered declared raft [SEP]']
[Init] best perm rec loss: 0.7715659141540527 for ['[CLS] law calledtical raft declared para donation expressway reserved considered perhaps grave guys firebandgation heywang intelligence chemistry brunswick filming viceroy hang [SEP]']
[Init] best perm rec loss: 0.7698725461959839 for ['[CLS] intelligence perhaps grave law reserved filming brunswick fire expresswaybandtical raft heywang viceroy donation para chemistry declared called guysgation considered hang [SEP]']
[Init] best perm rec loss: 0.7680492401123047 for ['[CLS] expressway fire called perhaps heyband declared guys gravetical considered brunswick lawgation reserved intelligence para donation filming viceroy chemistrywang raft hang [SEP]']
[Init] best perm rec loss: 0.7657252550125122 for ['[CLS] filming hey grave donation law called reservedgation expressway viceroy chemistrytical fire brunswick guys parawang perhaps declared intelligence considered raft hangband [SEP]']
[Init] best perm rec loss: 0.7647364139556885 for ['[CLS] brunswickgation hey hang raft fire guys calledband viceroy intelligence filming chemistry perhaps declaredwang para considered expressway donation grave law reservedtical [SEP]']
[Init] best perm rec loss: 0.7629566788673401 for ['[CLS] hang brunswickgationwang declared considered filming perhaps viceroy donation expressway calledtical fire hey grave intelligenceband law raft para guys chemistry reserved [SEP]']
[Init] best perm rec loss: 0.7614847421646118 for ['[CLS] donation declared para hey guys considered raft filming fire perhaps expressway called reservedgation chemistry intelligencewangband brunswick hang viceroy law gravetical [SEP]']
[Init] best perm rec loss: 0.7597771883010864 for ['[CLS] declared calledgation reserved raft expressway considered hey hang lawwang filming donation viceroy fire chemistry intelligence grave perhaps brunswick para guysticalband [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.938 (perp=13.265, rec=0.278, cos=0.007), tot_loss_proj:4.313 [t=0.31s]
prediction: ['[CLS] documentary a ever guiltyiating developing amateurblyiating unuous traffic amateur 2018ability. 街 comics mr ᴵ demonstration。 looks di [SEP]']
[ 100/2000] tot_loss=2.428 (perp=11.162, rec=0.191, cos=0.004), tot_loss_proj:3.483 [t=0.31s]
prediction: ['[CLS] movie a paperbackiatingiating develop amateuruciating africanuous screenplay amateur chapterability. of amateur directorial demonstration demonstration ( screenplay an [SEP]']
[ 150/2000] tot_loss=2.438 (perp=11.396, rec=0.156, cos=0.003), tot_loss_proj:3.805 [t=0.31s]
prediction: ['[CLS] movie a saddleuciating develop amateurishiatingucability moviectable chapterability. of saddle with demonstration demonstration. screenplay an [SEP]']
[ 200/2000] tot_loss=2.389 (perp=11.301, rec=0.125, cos=0.004), tot_loss_proj:3.810 [t=0.31s]
prediction: ['[CLS] moviecr saddleuciating develop amateurishiatingucability movieability aability. of saddle with demonstration demonstration. screenplay an [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.243 (perp=10.594, rec=0.122, cos=0.003), tot_loss_proj:3.369 [t=0.31s]
prediction: ['[CLS] moviecriatinguciating develop amateurish saddleucability movieability aability. of saddle with demonstration demonstration. screenplay an [SEP]']
[ 300/2000] tot_loss=2.106 (perp=9.991, rec=0.105, cos=0.002), tot_loss_proj:2.750 [t=0.31s]
prediction: ['[CLS] moviecriatinguciating develop amateurish saddle exability movieability aability. of saddled demonstration ex. screenplay an [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.146 (perp=10.217, rec=0.100, cos=0.002), tot_loss_proj:2.887 [t=0.31s]
prediction: ['[CLS] moviecriatingucish bonds amateurish exability movie ⺩ aability. of saddled saddle demonstration ex. screenplay an [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.140 (perp=10.231, rec=0.091, cos=0.002), tot_loss_proj:2.941 [t=0.31s]
prediction: ['[CLS] moviecriatingucish bonds amateurish exability ofcased aability. movie saddled saddle demonstration ex. screenplay an [SEP]']
[ 450/2000] tot_loss=2.158 (perp=10.267, rec=0.102, cos=0.002), tot_loss_proj:2.811 [t=0.31s]
prediction: ['[CLS] moviecriatingucish francs amateurish exability of unreleased aability. movie saddled saddle demonstration ex. screenplay an [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.015 (perp=9.560, rec=0.102, cos=0.002), tot_loss_proj:2.671 [t=0.31s]
prediction: ['[CLS] moviecrishuciating + amateurish exability of eric aability. movie saddled saddle demonstration ex. screenplay an [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.822 (perp=8.608, rec=0.098, cos=0.003), tot_loss_proj:2.363 [t=0.31s]
prediction: ['[CLS] moviecrishuciating + amateurish exability of aability of movie saddled saddle demonstration an ex. screenplay an [SEP]']
[ 600/2000] tot_loss=1.804 (perp=8.608, rec=0.080, cos=0.002), tot_loss_proj:2.370 [t=0.31s]
prediction: ['[CLS] moviecrishuciating + amateurish exability of aability of movie saddled saddle demonstration an ex. screenplay an [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.793 (perp=8.543, rec=0.082, cos=0.002), tot_loss_proj:2.353 [t=0.31s]
prediction: ['[CLS] moviecrishuciating + amateurish exability of aability of movie saddled saddle demonstration an ex screenplay. an [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.754 (perp=8.324, rec=0.087, cos=0.002), tot_loss_proj:2.303 [t=0.31s]
prediction: ['[CLS] moviecrishuciating + amateurish exability of a demonstration of movie saddled saddleability an ex screenplay. an [SEP]']
[ 750/2000] tot_loss=1.833 (perp=8.772, rec=0.077, cos=0.002), tot_loss_proj:2.373 [t=0.31s]
prediction: ['[CLS] moviecrishuciatingnl amateurish exability of a demonstration of movie saddled saddleability an ex screenplay. an [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.747 (perp=8.362, rec=0.073, cos=0.002), tot_loss_proj:2.375 [t=0.31s]
prediction: ['[CLS] moviecrishuciatingnl amateur with exability of a demonstration movie saddled saddleability of an ex screenplay. an [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.795 (perp=8.598, rec=0.074, cos=0.002), tot_loss_proj:2.438 [t=0.31s]
prediction: ['[CLS] moviecrishuciatingnl ex withsalability of a demonstration movie saddled saddleability of an amateur screenplay. an [SEP]']
[ 900/2000] tot_loss=1.792 (perp=8.598, rec=0.071, cos=0.002), tot_loss_proj:2.432 [t=0.31s]
prediction: ['[CLS] moviecrishuciatingnl ex withsalability of a demonstration movie saddled saddleability of an amateur screenplay. an [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.743 (perp=8.313, rec=0.078, cos=0.002), tot_loss_proj:2.440 [t=0.31s]
prediction: ['[CLS] moviecrishuciatingnl ex saddlesalability of a demonstration movie saddled withability of an amateur screenplay. an [SEP]']
Attempt swap
[1000/2000] tot_loss=1.738 (perp=8.313, rec=0.074, cos=0.002), tot_loss_proj:2.443 [t=0.31s]
prediction: ['[CLS] moviecrishuciatingnl ex saddlesalability of a demonstration movie saddled withability of an amateur screenplay. an [SEP]']
[1050/2000] tot_loss=1.742 (perp=8.313, rec=0.078, cos=0.002), tot_loss_proj:2.445 [t=0.31s]
prediction: ['[CLS] moviecrishuciatingnl ex saddlesalability of a demonstration movie saddled withability of an amateur screenplay. an [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.663 (perp=7.894, rec=0.082, cos=0.002), tot_loss_proj:2.308 [t=0.31s]
prediction: ['[CLS] moviecrishuciatingnl ex saddlesalability of a demonstration movie saddled with anability of an amateur screenplay. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.632 (perp=7.764, rec=0.077, cos=0.002), tot_loss_proj:2.209 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl saddlesalability of a demonstration movie saddled with anability of an amateur screenplay. [SEP]']
[1200/2000] tot_loss=1.634 (perp=7.764, rec=0.080, cos=0.002), tot_loss_proj:2.218 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl saddlesalability of a demonstration movie saddled with anability of an amateur screenplay. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.619 (perp=7.702, rec=0.077, cos=0.002), tot_loss_proj:2.162 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a demonstration movie saddled with saddleability of an amateur screenplay. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.621 (perp=7.702, rec=0.079, cos=0.002), tot_loss_proj:2.155 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a demonstration movie saddled with saddleability of an amateur screenplay. [SEP]']
[1350/2000] tot_loss=1.606 (perp=7.702, rec=0.063, cos=0.002), tot_loss_proj:2.163 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a demonstration movie saddled with saddleability of an amateur screenplay. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.607 (perp=7.646, rec=0.076, cos=0.002), tot_loss_proj:2.163 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.604 (perp=7.646, rec=0.073, cos=0.002), tot_loss_proj:2.165 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
[1500/2000] tot_loss=1.601 (perp=7.646, rec=0.070, cos=0.002), tot_loss_proj:2.160 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.604 (perp=7.646, rec=0.073, cos=0.002), tot_loss_proj:2.165 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.602 (perp=7.646, rec=0.071, cos=0.002), tot_loss_proj:2.159 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
[1650/2000] tot_loss=1.604 (perp=7.646, rec=0.073, cos=0.002), tot_loss_proj:2.162 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.604 (perp=7.646, rec=0.073, cos=0.002), tot_loss_proj:2.167 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.599 (perp=7.646, rec=0.068, cos=0.002), tot_loss_proj:2.170 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
[1800/2000] tot_loss=1.608 (perp=7.646, rec=0.077, cos=0.002), tot_loss_proj:2.169 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.599 (perp=7.646, rec=0.068, cos=0.002), tot_loss_proj:2.167 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.614 (perp=7.646, rec=0.083, cos=0.002), tot_loss_proj:2.158 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
[1950/2000] tot_loss=1.606 (perp=7.646, rec=0.075, cos=0.002), tot_loss_proj:2.162 [t=0.31s]
prediction: ['[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.562 (perp=7.433, rec=0.074, cos=0.002), tot_loss_proj:2.153 [t=0.32s]
prediction: ['[CLS] moviecrishuciating exnl ansalability demonstration of a movie saddled with saddleability of an amateur screenplay. [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] an excruciating demonstration of the unsalvageability of a movie saddled with an amateurish screenplay. [SEP]
========================
predicted: 
========================
[CLS] moviecrishuciating exnl ansalability of a movie saddled with demonstration saddleability of an amateur screenplay. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.750 | p: 68.750 | r: 68.750
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 56.250 | p: 56.250 | r: 56.250
rougeLsum  | fm: 56.250 | p: 56.250 | r: 56.250
r1fm+r2fm = 102.083

[Aggregate metrics]:
rouge1     | fm: 71.528 | p: 70.888 | r: 72.328
rouge2     | fm: 18.568 | p: 18.384 | r: 18.743
rougeL     | fm: 47.169 | p: 46.805 | r: 47.667
rougeLsum  | fm: 47.257 | p: 46.892 | r: 47.712
r1fm+r2fm = 90.096

input #88 time: 0:12:24 | total time: 18:48:40


Running input #89 of 100.
reference: 
========================
like the best of godard's movies . . . it is visually ravishing , penetrating , impenetrable .
========================
average of cosine similarity 0.9994096320381094
highest_index [0]
highest [0.9994096320381094]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  2066,  1996,  2190,  1997,  2643,  4232,  1005,  1055,  5691,
          1012,  1012,  1012,  2009,  2003, 17453, 16806, 12227,  1010, 22391,
          1010, 17727,  8625,  6494,  3468,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] like the best of godard's movies... it is visually ravishing, penetrating, impenetrable. [SEP]"]
[Init] best rec loss: 0.9773280024528503 for ['[CLS] extensive drew commander matches book locality check feet jumping acoustic afrorred seablood frequentlyam choice ( task tata eatingnant voivodeship armored christmas [SEP]']
[Init] best rec loss: 0.9593492150306702 for ['[CLS] ton motorcycle auditioned whatever past eyes brief mineral her zane doorapp opfest des liesperation spot from crosses guide ter color boxeroi [SEP]']
[Init] best rec loss: 0.9490545392036438 for ['[CLS] what daily agency cocked drinking castle daisy sitting downfer paperjord ab arrowstus middle facebook hazel annual sings poor raft felt defending summer [SEP]']
[Init] best rec loss: 0.9376330971717834 for ['[CLS] iec length §ity song ago early parliamentze species sport freeze talks eel steve jesse damn answer cocked gracie ) favour willing eyebrows please [SEP]']
[Init] best rec loss: 0.9360703825950623 for ['[CLS] [CLS] jill music cut face alexander lightning 1000 fingers kill diocese distinct flesh shared hour soil blast jobs captain probably day smell namelyا help [SEP]']
[Init] best rec loss: 0.9164009690284729 for ['[CLS] benneer hand types leaves action medina france steamdos born power hotelperation trucks wires feliciaologistgon occultnahusly y renewal holding [SEP]']
[Init] best rec loss: 0.9069275259971619 for ['[CLS] wills with pointognr air eve as initial nathan steady figured eagles my appointed lips digit spike quite mexico university middlesexcu babyvers [SEP]']
[Init] best perm rec loss: 0.9062201976776123 for ['[CLS] university wills appointed pointnr figured eve spikeog steady as lips initial digit middlesex aircu with mexico quite eagles myvers nathan baby [SEP]']
[Init] best perm rec loss: 0.9052209258079529 for ['[CLS] eagles digit spike mexico with lips initialnr my middlesex figured nathan point university quite eveog wills appointed babycu as air steadyvers [SEP]']
[Init] best perm rec loss: 0.9039683938026428 for ['[CLS] university figured wills spike point lips with middlesex digitogvers quitenr appointed air my mexico initial eagles evecu as nathan steady baby [SEP]']
[Init] best perm rec loss: 0.9025735259056091 for ['[CLS] figured mexico with my spike as air initial middlesex appointed eve eagles pointnr steady wills university quite digit nathanverscu babyog lips [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.919 (perp=12.517, rec=0.395, cos=0.021), tot_loss_proj:4.314 [t=0.31s]
prediction: ['[CLS] anti gall inaccessibleene the gene theatre cooler..ene domestic.ggles golden (. been intense golden unless inter whisper tongue represents [SEP]']
[ 100/2000] tot_loss=2.313 (perp=9.908, rec=0.320, cos=0.011), tot_loss_proj:2.929 [t=0.31s]
prediction: ['[CLS] trafficking african sensitive classical the lucky in either..ene awe.ue +... intense.enetra.. bwf [SEP]']
[ 150/2000] tot_loss=2.576 (perp=11.180, rec=0.324, cos=0.016), tot_loss_proj:3.213 [t=0.31s]
prediction: ['[CLS] anti african sensitive classical plus plus theatre wouldur.enebling originaluna hypnotic.., penetrating.enetra such puts when [SEP]']
[ 200/2000] tot_loss=2.250 (perp=9.692, rec=0.299, cos=0.012), tot_loss_proj:2.768 [t=0.31s]
prediction: ["[CLS] noted african sensitive native'parent theatre 'ur.ene inviting contentuna pleasing.., penetrating 'enetrable manor. [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.097 (perp=9.222, rec=0.246, cos=0.007), tot_loss_proj:3.215 [t=0.31s]
prediction: ["[CLS] noted novel sensitive earlier..!'short.enefactory filmuna piercing.., penetrating 'enetrablepol. [SEP]"]
[ 300/2000] tot_loss=2.059 (perp=9.174, rec=0.220, cos=0.005), tot_loss_proj:3.349 [t=0.31s]
prediction: ["[CLS] noted novel sensitive commercially.. video'himself.enefactory film is clary.., penetrating 'enetrablepol. [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.110 (perp=9.419, rec=0.222, cos=0.004), tot_loss_proj:3.516 [t=0.31s]
prediction: ["[CLS] kiss novel sensitive commercially.. video'same.eneogical'film is clary.., penetratingenetrablepol. [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.920 (perp=8.505, rec=0.214, cos=0.005), tot_loss_proj:2.805 [t=0.31s]
prediction: ["[CLS] fiction western sensitive... video'client.eneatable'movies is visually. intellectual, penetratingenetrablepol. [SEP]"]
[ 450/2000] tot_loss=1.911 (perp=8.527, rec=0.202, cos=0.003), tot_loss_proj:2.910 [t=0.31s]
prediction: ["[CLS] episode western sensitive. like. video''.eneogical'movies is visually. intellectual, penetratingenetrable is. [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.169 (perp=9.842, rec=0.195, cos=0.005), tot_loss_proj:3.106 [t=0.31s]
prediction: ["[CLS] love western sensitive like. of video'relatively.ableatable henry movies is stimuli. intellectual, penetratingenetrable is. [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.072 (perp=9.421, rec=0.185, cos=0.003), tot_loss_proj:3.603 [t=0.31s]
prediction: ["[CLS] pretended happened sensitive like. of costello'client.ableogical it movies is stimuli. intellectual, penetratingenetrable is. [SEP]"]
[ 600/2000] tot_loss=1.915 (perp=8.730, rec=0.165, cos=0.004), tot_loss_proj:3.675 [t=0.31s]
prediction: ["[CLS] dark happened sensitive like. of costello'client. ofogical it movies is stimuli. however, penetratingenetrable is. [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=2.009 (perp=8.863, rec=0.230, cos=0.007), tot_loss_proj:2.630 [t=0.31s]
prediction: ["[CLS] murdoch love sensitive like movies.. buildings''.ablepowering wilder is stimuli. john, penetratingenetrable ;, [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.888 (perp=8.322, rec=0.218, cos=0.006), tot_loss_proj:2.697 [t=0.31s]
prediction: ["[CLS] dad love sensitive like movies '. buildings '.. of cannes is isshing. john, penetratingenetrable jane. [SEP]"]
[ 750/2000] tot_loss=1.936 (perp=8.640, rec=0.203, cos=0.005), tot_loss_proj:2.759 [t=0.31s]
prediction: ["[CLS] dad love sensitive like movies '. accurately '.. of cannes is isshing. they, penetratingenetrable ;. [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.805 (perp=7.959, rec=0.207, cos=0.006), tot_loss_proj:2.771 [t=0.31s]
prediction: ["[CLS] is love sensitive like movies'the accurately '.. of cannes blue isshing. they, penetratingenetrable ;. [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.908 (perp=8.521, rec=0.198, cos=0.006), tot_loss_proj:3.122 [t=0.31s]
prediction: ["[CLS] it love sensitive like movies'the accurately '.. of cannes about theyshing. is, penetratingenetrable ;. [SEP]"]
[ 900/2000] tot_loss=1.897 (perp=8.521, rec=0.189, cos=0.004), tot_loss_proj:3.122 [t=0.31s]
prediction: ["[CLS] it love sensitive like movies'the accurately '.. of cannes about theyshing. is, penetratingenetrable ;. [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.786 (perp=8.046, rec=0.173, cos=0.004), tot_loss_proj:3.150 [t=0.31s]
prediction: ["[CLS] is accurately sensitive like movies'the love '.. of cannes about theyshing. is, penetratingenetrable ;. [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.688 (perp=7.459, rec=0.192, cos=0.004), tot_loss_proj:3.354 [t=0.31s]
prediction: ["[CLS] isard is like movies'the love '.. impogical about johnshing. sensitive, penetratingenetrable ;. [SEP]"]
[1050/2000] tot_loss=1.685 (perp=7.481, rec=0.186, cos=0.003), tot_loss_proj:3.375 [t=0.31s]
prediction: ["[CLS] passard is like movies'the love '.. impogical about johnshing. sensitive, penetratingenetrable ;. [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.684 (perp=7.481, rec=0.184, cos=0.003), tot_loss_proj:3.375 [t=0.31s]
prediction: ["[CLS] passard is like movies'the love '.. impogical about johnshing. sensitive, penetratingenetrable ;. [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.701 (perp=7.633, rec=0.171, cos=0.003), tot_loss_proj:2.374 [t=0.31s]
prediction: ["[CLS] passard is like movies'the love '.. imp cannes ; johnshing. sensitive, penetratingenetrable noble. [SEP]"]
[1200/2000] tot_loss=1.698 (perp=7.633, rec=0.168, cos=0.003), tot_loss_proj:2.374 [t=0.31s]
prediction: ["[CLS] passard is like movies'the love '.. imp cannes ; johnshing. sensitive, penetratingenetrable noble. [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.635 (perp=7.347, rec=0.162, cos=0.003), tot_loss_proj:2.299 [t=0.31s]
prediction: ["[CLS] passard is like the movies'love '.. imp cannes ; johnshing. sensitive, penetratingenetrable noble. [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.598 (perp=7.118, rec=0.170, cos=0.004), tot_loss_proj:2.376 [t=0.31s]
prediction: ["[CLS] passard is like the movies'love '..thest imp ; johnshing. sensitive, penetratingenetrable noble. [SEP]"]
[1350/2000] tot_loss=1.637 (perp=7.319, rec=0.170, cos=0.003), tot_loss_proj:2.296 [t=0.31s]
prediction: ["[CLS] passard is like the movies'love '.. cannes imp ; johnshing. sensitive, penetratingenetrable noble. [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.635 (perp=7.354, rec=0.161, cos=0.003), tot_loss_proj:2.327 [t=0.31s]
prediction: ["[CLS] passard is like the movies'love '.. cannes imp ; theyshing. sensitive, penetratingenetrable about. [SEP]"]
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.689 (perp=7.609, rec=0.164, cos=0.004), tot_loss_proj:2.608 [t=0.31s]
prediction: ["[CLS] pass skill is'love'like the movies.. deserved imp ; theyshing. sensitive, penetratingenetrable about. [SEP]"]
[1500/2000] tot_loss=1.688 (perp=7.621, rec=0.160, cos=0.003), tot_loss_proj:2.658 [t=0.31s]
prediction: ["[CLS] pass skill is'love'like the movies.. deserved imp ; johnshing. sensitive, penetratingenetrable noble. [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.657 (perp=7.462, rec=0.161, cos=0.004), tot_loss_proj:2.646 [t=0.31s]
prediction: ["[CLS] pass imp is'love'like the movies.. deservedard ; johnshing. sensitive, penetratingenetrable noble. [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.688 (perp=7.621, rec=0.161, cos=0.003), tot_loss_proj:2.655 [t=0.31s]
prediction: ["[CLS] pass skill is'love'like the movies.. deserved imp ; johnshing. sensitive, penetratingenetrable noble. [SEP]"]
[1650/2000] tot_loss=1.676 (perp=7.621, rec=0.149, cos=0.003), tot_loss_proj:2.655 [t=0.31s]
prediction: ["[CLS] pass skill is'love'like the movies.. deserved imp ; johnshing. sensitive, penetratingenetrable noble. [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.633 (perp=7.395, rec=0.150, cos=0.003), tot_loss_proj:2.520 [t=0.31s]
prediction: ["[CLS] pass john is'love'like the movies.. deserved imp ; skillshing. sensitive, penetratingenetrable noble. [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.571 (perp=7.086, rec=0.151, cos=0.003), tot_loss_proj:2.453 [t=0.31s]
prediction: ["[CLS] pass john is'imp'like the movies.. deserved love ; skillshing. sensitive, penetratingenetrable noble. [SEP]"]
[1800/2000] tot_loss=1.571 (perp=7.086, rec=0.150, cos=0.003), tot_loss_proj:2.446 [t=0.31s]
prediction: ["[CLS] pass john is'imp'like the movies.. deserved love ; skillshing. sensitive, penetratingenetrable noble. [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.572 (perp=7.070, rec=0.155, cos=0.003), tot_loss_proj:2.363 [t=0.31s]
prediction: ["[CLS] john pass is'imp'like the movies.. deserved love ; skillshing. sensitive, penetratingenetrable noble. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.573 (perp=7.070, rec=0.156, cos=0.003), tot_loss_proj:2.361 [t=0.31s]
prediction: ["[CLS] john pass is'imp'like the movies.. deserved love ; skillshing. sensitive, penetratingenetrable noble. [SEP]"]
[1950/2000] tot_loss=1.564 (perp=7.070, rec=0.146, cos=0.003), tot_loss_proj:2.362 [t=0.31s]
prediction: ["[CLS] john pass is'imp'like the movies.. deserved love ; skillshing. sensitive, penetratingenetrable noble. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.572 (perp=7.122, rec=0.144, cos=0.003), tot_loss_proj:2.396 [t=0.31s]
prediction: ["[CLS] john pass is'imp'like the movies.. deserved love ; skillshing. sensitive, penetratingenetrable about. [SEP]"]
Done with input #89 of 100.
reference: 
========================
[CLS] like the best of godard's movies... it is visually ravishing, penetrating, impenetrable. [SEP]
========================
predicted: 
========================
[CLS] john pass is'imp'like the movies.. deserved love ; skillshing. sensitive, penetratingenetrable about. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 40.000 | r: 40.000
rouge2     | fm: 7.143 | p: 7.143 | r: 7.143
rougeL     | fm: 33.333 | p: 33.333 | r: 33.333
rougeLsum  | fm: 33.333 | p: 33.333 | r: 33.333
r1fm+r2fm = 47.143

[Aggregate metrics]:
rouge1     | fm: 71.267 | p: 70.619 | r: 72.044
rouge2     | fm: 18.385 | p: 18.227 | r: 18.605
rougeL     | fm: 47.046 | p: 46.671 | r: 47.509
rougeLsum  | fm: 47.091 | p: 46.747 | r: 47.559
r1fm+r2fm = 89.652

input #89 time: 0:12:23 | total time: 19:01:04


Running input #90 of 100.
reference: 
========================
the movie is so contrived , nonsensical and formulaic that , come to think of it , the day-old shelf would be a more appropriate location to store it .
========================
average of cosine similarity 0.9991666515918148
highest_index [0]
highest [0.9991666515918148]
Debug: ids_shape = 40, pads = [40]
Debug: input ids = tensor([[  101,  1996,  3185,  2003,  2061,  9530, 18886,  7178,  1010,  2512,
          5054, 19570,  2389,  1998,  5675,  2594,  2008,  1010,  2272,  2000,
          2228,  1997,  2009,  1010,  1996,  2154,  1011,  2214, 11142,  2052,
          2022,  1037,  2062,  6413,  3295,  2000,  3573,  2009,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the movie is so contrived, nonsensical and formulaic that, come to think of it, the day - old shelf would be a more appropriate location to store it. [SEP]']
[Init] best rec loss: 0.9605206251144409 for ['[CLS]! ape analysts fly romanized association driveway steam wouldvel matternah see either preparation nara expected gotɛ if award physical -way failed jewish protest raceད celtic curseouraries looked lord air glass tires [SEP]']
[Init] best rec loss: 0.9085304737091064 for ['[CLS] highway foster hebrew revolt laterdav joe membership background th retrieved noah confidencely cactus federal elector mis that, covering queens if member honest sales stanley embarked draft red feat apart my nan inhumanley waste virginia [SEP]']
[Init] best rec loss: 0.8798398375511169 for ['[CLS] enough sofia fa shipyard $ officer ballot shopworking ( other wise katie j purchase few mainkingick monk kent purposes spouse sell critics celeste un gerard stray whomosis straight generally dangerpaper ltd report solomon [SEP]']
[Init] best perm rec loss: 0.8789103031158447 for ['[CLS] solomon kent spouse ballotworking danger other celeste shopking purposes few enough fa purchase wise strayick j report main generally un $ straight shipyardpaper katie sofia ( critics monk gerard whom officer ltdosis sell [SEP]']
[Init] best perm rec loss: 0.8751219511032104 for ['[CLS] ltd other fa officer enoughpaper shopking katie ( main spouse j celeste $ sell whom kent generally monk straight criticsworking danger sofiaosisick un wise ballot stray purposes report purchase solomon few gerard shipyard [SEP]']
[Init] best perm rec loss: 0.8728055953979492 for ['[CLS] critics sofia un celeste $ stray whom dangerick officer ltdworking gerard j generallyosisking katie ( ballot purchase solomon fa monk other kent main spouse purposes sell shop few shipyardpaper wise report straight enough [SEP]']
[Init] best perm rec loss: 0.8721495866775513 for ['[CLS] other main $ officerking few stray enough solomon ( monk ltd danger kent critics purposesick whom shop j wise sofia straightworking shipyard katie celeste gerard report sell fa spouse purchaseosis unpaper generally ballot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.619 (perp=11.693, rec=0.269, cos=0.012), tot_loss_proj:3.588 [t=0.31s]
prediction: ['[CLS] - better,ie monsterische into hurt concept humansuttered easier i these tube - formula, route paper\'made it is channelssc and formula formula bestseller perfectly mis made seized "ikled formula [SEP]']
[ 100/2000] tot_loss=2.374 (perp=10.947, rec=0.180, cos=0.004), tot_loss_proj:3.401 [t=0.31s]
prediction: ['[CLS] -ic the austen movieic hips hurt theo humans circular less so if non - formula, movie shelf these would it is moviesc andic formulaic appropriate mis for store ofic. formula [SEP]']
[ 150/2000] tot_loss=2.300 (perp=10.616, rec=0.174, cos=0.004), tot_loss_proj:3.734 [t=0.31s]
prediction: ['[CLS] sheldonic the [ movieic is very super know circular francesca that ifsen nonic, movie tv grandfather would it an block land andic formulaimum appropriate more for storing ofic [SEP] formula [SEP]']
[ 200/2000] tot_loss=2.070 (perp=9.689, rec=0.130, cos=0.002), tot_loss_proj:3.652 [t=0.31s]
prediction: ['[CLS] for so thetri movieic is a super soic less that ifsen nonsic, store shelf expansion would it the block land andic formula shelf appropriate more for store,ic [SEP] formula [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.307 (perp=10.409, rec=0.216, cos=0.009), tot_loss_proj:3.669 [t=0.31s]
prediction: ['[CLS] for so theו movieic istative most think gesture easier that,sen nonsic, store shelf grandfather would it the exhibit sure andic release appropriate more - store, formulaic [SEP] formula [SEP]']
[ 300/2000] tot_loss=2.271 (perp=10.331, rec=0.199, cos=0.006), tot_loss_proj:3.308 [t=0.31s]
prediction: ["[CLS] for so theche movieic is 語'hmm central appropriate that,sen nonsic, movie store waived would it the listings mo andic appropriate for moreulously store, formulaic, formula [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.110 (perp=9.807, rec=0.145, cos=0.003), tot_loss_proj:3.525 [t=0.31s]
prediction: ["[CLS] a 崎 so the movieic is 語'awareness central appropriate that,sen nonsic, movie shelf waived would it the name mo andic appropriate for moreulously store, formula walls. formula [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.935 (perp=8.986, rec=0.134, cos=0.003), tot_loss_proj:3.271 [t=0.31s]
prediction: ["[CLS] a 崎 so the movieved is 語'awareness appropriate that,sen nonsical, movie shelf waived would it the named mo andic appropriate for more to store. formula walls. formula [SEP]"]
[ 450/2000] tot_loss=1.962 (perp=9.181, rec=0.123, cos=0.002), tot_loss_proj:3.510 [t=0.31s]
prediction: ["[CLS] aivation so the movieved is 語'come appropriate that,sen nonsical, movie shelf old would it the name new andic appropriate for more to store, formula walls. formula [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.912 (perp=8.988, rec=0.112, cos=0.002), tot_loss_proj:3.148 [t=0.32s]
prediction: ["[CLS] a disposal so the movieved is 語'come appropriate that,sen nonsical, movie shelftablished would it the name new andic appropriate for more to store, formula walls. formula [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.830 (perp=8.491, rec=0.129, cos=0.003), tot_loss_proj:3.104 [t=0.31s]
prediction: ["[CLS] a disposal so the movieved is 語'come appropriate that, nonsensical, movie shelftablished would it the name branch andic appropriate for more to store, formula walls. formula [SEP]"]
[ 600/2000] tot_loss=1.785 (perp=8.342, rec=0.115, cos=0.002), tot_loss_proj:3.078 [t=0.31s]
prediction: ["[CLS] a disposal so the movieved is given'come appropriate that, nonsensical, movie shelftablished would it the name branch andic appropriate for more to store, formula site. formula [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.779 (perp=8.318, rec=0.113, cos=0.002), tot_loss_proj:3.398 [t=0.40s]
prediction: ["[CLS] a pour so the movieved is given'come appropriate that, nonsensical, movie shelfation would name it the branch andic appropriate for more to store, formula site. formula [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.835 (perp=8.421, rec=0.147, cos=0.004), tot_loss_proj:3.378 [t=0.31s]
prediction: ["[CLS] hardy a movie the movieved is 語, come appropriate that, nonsensical, so shelfation would look it the'andic appropriate for more to storesic formula location. formula [SEP]"]
[ 750/2000] tot_loss=1.658 (perp=7.649, rec=0.126, cos=0.003), tot_loss_proj:3.000 [t=0.31s]
prediction: ["[CLS] the a movie the movieved is 語, come appropriate that, nonsensical, so shelfation would look it the'andic appropriate for more to store, formula site. formula [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.600 (perp=7.396, rec=0.118, cos=0.002), tot_loss_proj:2.888 [t=0.31s]
prediction: ["[CLS] the a movie the movieved is 語, come it that, nonsensical, so shelfation would look appropriate the'andic appropriate for more to store, formula site. formula [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.607 (perp=7.458, rec=0.113, cos=0.002), tot_loss_proj:3.051 [t=0.31s]
prediction: ["[CLS] hooked a movie the movieved is coincidence, come it that, nonsensical, so'these would look appropriate the shelf andic appropriate for more to store, formula location. formula [SEP]"]
[ 900/2000] tot_loss=1.603 (perp=7.458, rec=0.109, cos=0.002), tot_loss_proj:3.051 [t=0.31s]
prediction: ["[CLS] hooked a movie the movieved is coincidence, come it that, nonsensical, so'these would look appropriate the shelf andic appropriate for more to store, formula location. formula [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.566 (perp=7.274, rec=0.109, cos=0.002), tot_loss_proj:2.993 [t=0.31s]
prediction: ["[CLS] a movie the movie hookedved is coincidence, come it that, nonsensical, so'these would look appropriate the shelf andic appropriate for more to store, formula location. formula [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.524 (perp=7.069, rec=0.108, cos=0.002), tot_loss_proj:2.964 [t=0.31s]
prediction: ["[CLS] a movie the movie hookedved is coincidence, come it that, nonsensical, so'these would look appropriate and the shelfic appropriate for more to store, formula location. formula [SEP]"]
[1050/2000] tot_loss=1.520 (perp=7.069, rec=0.104, cos=0.002), tot_loss_proj:2.966 [t=0.31s]
prediction: ["[CLS] a movie the movie hookedved is coincidence, come it that, nonsensical, so'these would look appropriate and the shelfic appropriate for more to store, formula location. formula [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.516 (perp=7.011, rec=0.112, cos=0.002), tot_loss_proj:2.907 [t=0.31s]
prediction: ["[CLS] a movie the movie hookedved is coincidence, come it that, nonsensical, so formula these would look appropriate and the shelfic appropriate for more to store, formula location.'[SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.502 (perp=6.940, rec=0.112, cos=0.002), tot_loss_proj:2.956 [t=0.31s]
prediction: ["[CLS] a movie the movie hookedved coincidence is, come it that, nonsensical, so formula these would look appropriate and the shelfic appropriate for more to store, formula location.'[SEP]"]
[1200/2000] tot_loss=1.501 (perp=6.940, rec=0.111, cos=0.002), tot_loss_proj:2.952 [t=0.31s]
prediction: ["[CLS] a movie the movie hookedved coincidence is, come it that, nonsensical, so formula these would look appropriate and the shelfic appropriate for more to store, formula location.'[SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.491 (perp=6.897, rec=0.109, cos=0.002), tot_loss_proj:2.992 [t=0.31s]
prediction: ["[CLS] a movie the movie hookedved coincidence is, come it that, nonsensical, so formula these would look appropriate for the shelfic appropriate and more to store, formula location.'[SEP]"]
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.502 (perp=6.918, rec=0.116, cos=0.002), tot_loss_proj:3.070 [t=0.31s]
prediction: ["[CLS] a movie the movie hookedved coincidence is, come it that, nonsensical, so formula these would store appropriate for the shelfic appropriate, and more to store formula location.'[SEP]"]
[1350/2000] tot_loss=1.497 (perp=6.926, rec=0.110, cos=0.002), tot_loss_proj:3.138 [t=0.31s]
prediction: ["[CLS] grand movie the movie hookedved coincidence is, come it that, nonsensical, so formula these would look appropriate for the shelfic appropriate, and more to store formula location.'[SEP]"]
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.478 (perp=6.861, rec=0.104, cos=0.002), tot_loss_proj:3.161 [t=0.31s]
prediction: ["[CLS] grand movie the movie hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the formula shelfic appropriate, and more to store formula location.'[SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.449 (perp=6.732, rec=0.101, cos=0.002), tot_loss_proj:2.993 [t=0.31s]
prediction: ["[CLS] grand movie the movie hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the shelf formulaic appropriate, and more to store formula location.'[SEP]"]
[1500/2000] tot_loss=1.452 (perp=6.732, rec=0.104, cos=0.002), tot_loss_proj:2.995 [t=0.31s]
prediction: ["[CLS] grand movie the movie hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the shelf formulaic appropriate, and more to store formula location.'[SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.427 (perp=6.600, rec=0.105, cos=0.002), tot_loss_proj:2.984 [t=0.31s]
prediction: ["[CLS] grand movie the movie hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the shelf formulaic, appropriate and more to store formula location.'[SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.380 (perp=6.376, rec=0.103, cos=0.002), tot_loss_proj:2.969 [t=0.31s]
prediction: ["[CLS] movie movie the grand hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the shelf formulaic, appropriate and more to store formula location.'[SEP]"]
[1650/2000] tot_loss=1.379 (perp=6.376, rec=0.102, cos=0.002), tot_loss_proj:2.971 [t=0.31s]
prediction: ["[CLS] movie movie the grand hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the shelf formulaic, appropriate and more to store formula location.'[SEP]"]
Attempt swap
[1700/2000] tot_loss=1.382 (perp=6.376, rec=0.105, cos=0.002), tot_loss_proj:2.968 [t=0.31s]
prediction: ["[CLS] movie movie the grand hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the shelf formulaic, appropriate and more to store formula location.'[SEP]"]
Attempt swap
[1750/2000] tot_loss=1.387 (perp=6.376, rec=0.110, cos=0.002), tot_loss_proj:2.969 [t=0.31s]
prediction: ["[CLS] movie movie the grand hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the shelf formulaic, appropriate and more to store formula location.'[SEP]"]
[1800/2000] tot_loss=1.383 (perp=6.376, rec=0.106, cos=0.002), tot_loss_proj:2.968 [t=0.31s]
prediction: ["[CLS] movie movie the grand hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the shelf formulaic, appropriate and more to store formula location.'[SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=1.377 (perp=6.351, rec=0.105, cos=0.002), tot_loss_proj:2.730 [t=0.31s]
prediction: ["[CLS] movie movie the grand hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the shelf formulaic, and appropriate more to store formula location.'[SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.361 (perp=6.231, rec=0.112, cos=0.002), tot_loss_proj:2.984 [t=0.31s]
prediction: ["[CLS] movie movie the grand hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the more formulaic, and appropriate shelf to store formula location.'[SEP]"]
[1950/2000] tot_loss=1.361 (perp=6.231, rec=0.113, cos=0.002), tot_loss_proj:2.980 [t=0.31s]
prediction: ["[CLS] movie movie the grand hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the more formulaic, and appropriate shelf to store formula location.'[SEP]"]
Attempt swap
[2000/2000] tot_loss=1.369 (perp=6.292, rec=0.109, cos=0.002), tot_loss_proj:2.950 [t=0.31s]
prediction: ["[CLS] movie movie the grand hookedved is is, come it that, nonsensical, so these would look appropriate for the more formulaic, and appropriate shelf to store formula location.'[SEP]"]
Done with input #90 of 100.
reference: 
========================
[CLS] the movie is so contrived, nonsensical and formulaic that, come to think of it, the day - old shelf would be a more appropriate location to store it. [SEP]
========================
predicted: 
========================
[CLS] movie movie the grand hookedved coincidence is, come it that, nonsensical, so these would look appropriate for the shelf formulaic, and appropriate more to store formula location.'[SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.966 | p: 68.966 | r: 68.966
rouge2     | fm: 3.571 | p: 3.571 | r: 3.571
rougeL     | fm: 37.931 | p: 37.931 | r: 37.931
rougeLsum  | fm: 37.931 | p: 37.931 | r: 37.931
r1fm+r2fm = 72.537

[Aggregate metrics]:
rouge1     | fm: 71.255 | p: 70.674 | r: 71.980
rouge2     | fm: 18.267 | p: 18.097 | r: 18.481
rougeL     | fm: 46.928 | p: 46.569 | r: 47.403
rougeLsum  | fm: 46.960 | p: 46.606 | r: 47.414
r1fm+r2fm = 89.521

input #90 time: 0:12:25 | total time: 19:13:30


Running input #91 of 100.
reference: 
========================
julia is played with exasperating blandness by laura regan .
========================
average of cosine similarity 0.9991628758117687
highest_index [0]
highest [0.9991628758117687]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  6423,  2003,  2209,  2007,  4654,  3022,  4842,  5844, 20857,
          2791,  2011,  6874, 16964,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] julia is played with exasperating blandness by laura regan. [SEP]']
[Init] best rec loss: 0.9384223222732544 for ['[CLS] virtual pictures = finland police sheep nod icons intonne cole bobby prixect [SEP]']
[Init] best rec loss: 0.9253545999526978 for ['[CLS] skin gin relieve whereas him aus lima united officer anniversary life johnnie simply ) [SEP]']
[Init] best rec loss: 0.8794352412223816 for ['[CLS] print consideration barrow committees bandtlement stars troubleested game crack culture seasons home [SEP]']
[Init] best rec loss: 0.8772706389427185 for ['[CLS] pastor grace connor observed controluiard than ps healing vote bot unsuccessfully ross [SEP]']
[Init] best rec loss: 0.8641284704208374 for ['[CLS] like broadcaster faculty god since careful dwarf mortal patients thisject literarytive meyrick [SEP]']
[Init] best rec loss: 0.8596703410148621 for ['[CLS] disabled else gray ed issued second reactionifying inactivatedme hangingpine literally isn [SEP]']
[Init] best rec loss: 0.8274040818214417 for ['[CLS] finished station produced heights positive extant merelycel oblast event measuringsho m² chance [SEP]']
[Init] best rec loss: 0.8183484673500061 for ['[CLS]osi restraint like iii chosenfoot invalid saintienhir league damage £ tia [SEP]']
[Init] best rec loss: 0.7694311141967773 for ['[CLS] run slaughter cantata " poemrricular bag lilyographicere hooker erebidae guns case [SEP]']
[Init] best perm rec loss: 0.7693506479263306 for ['[CLS] bagographic gunsere erebidae run poem case cantata " hookerrricular slaughter lily [SEP]']
[Init] best perm rec loss: 0.768569827079773 for ['[CLS] hookerographic " cantata case poemererricular run lily bag guns slaughter erebidae [SEP]']
[Init] best perm rec loss: 0.7679768204689026 for ['[CLS] runographicere cantata lily " bag poemrricular case erebidae hooker slaughter guns [SEP]']
[Init] best perm rec loss: 0.7627481818199158 for ['[CLS] hooker cantataere guns slaughter erebidae bag caserricularographic lily poem run " [SEP]']
[Init] best perm rec loss: 0.7620918154716492 for ['[CLS] cantata hooker bag poem slaughter gunsere " case erebidaeographic lilyrricular run [SEP]']
[Init] best perm rec loss: 0.7612804174423218 for ['[CLS] erebidae hookerrricularographic poem case lily guns slaughter bag runere " cantata [SEP]']
[Init] best perm rec loss: 0.7607267498970032 for ['[CLS] " bagrricular poem guns erebidaeographicere cantata slaughter run hooker case lily [SEP]']
[Init] best perm rec loss: 0.7606057524681091 for ['[CLS]rricular bag cantata "ographic guns lily hooker case erebidae slaughter run poemere [SEP]']
[Init] best perm rec loss: 0.7601807713508606 for ['[CLS] "ographic hooker guns slaughterrricular bag cantata caseere run poem erebidae lily [SEP]']
[Init] best perm rec loss: 0.7597351670265198 for ['[CLS] " slaughterrricular bag guns cantataographic lily poemere case hooker run erebidae [SEP]']
[Init] best perm rec loss: 0.7584123015403748 for ['[CLS] poem "rricular guns bagographic cantata case hooker slaughter run erebidaeere lily [SEP]']
[Init] best perm rec loss: 0.7578414678573608 for ['[CLS] lilyographic cantata poem hookerere " erebidae run slaughter case guns bagrricular [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.697 (perp=12.051, rec=0.279, cos=0.008), tot_loss_proj:3.733 [t=0.30s]
prediction: ['[CLS] julia bland bland played in rex bland by stockﬁering regarding blandulating [SEP]']
[ 100/2000] tot_loss=2.327 (perp=10.705, rec=0.181, cos=0.004), tot_loss_proj:3.668 [t=0.30s]
prediction: ['[CLS] julia blandness played with taylor bland by blandnesseringening blandting [SEP]']
[ 150/2000] tot_loss=2.335 (perp=11.000, rec=0.133, cos=0.003), tot_loss_proj:3.259 [t=0.30s]
prediction: ['[CLS] julia blandness played with laura bland byorsnesseringating blandness [SEP]']
[ 200/2000] tot_loss=2.113 (perp=9.966, rec=0.118, cos=0.002), tot_loss_proj:3.469 [t=0.30s]
prediction: ['[CLS] julia blandness played with laura bland byas iseringating bland. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.055 (perp=9.498, rec=0.151, cos=0.005), tot_loss_proj:3.109 [t=0.30s]
prediction: ['[CLS] julia blandness played with laura blandas by iseringating bland. [SEP]']
[ 300/2000] tot_loss=2.067 (perp=9.797, rec=0.106, cos=0.002), tot_loss_proj:3.135 [t=0.31s]
prediction: ['[CLS] julia reganness played with laura exas by isasating bland. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.913 (perp=9.037, rec=0.103, cos=0.002), tot_loss_proj:3.084 [t=0.30s]
prediction: ['[CLS] julia reganness played with laura isas by exasating bland. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.899 (perp=9.037, rec=0.090, cos=0.002), tot_loss_proj:3.084 [t=0.31s]
prediction: ['[CLS] julia reganness played with laura isas by exasating bland. [SEP]']
[ 450/2000] tot_loss=1.904 (perp=9.037, rec=0.095, cos=0.002), tot_loss_proj:3.080 [t=0.30s]
prediction: ['[CLS] julia reganness played with laura isas by exasating bland. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.896 (perp=9.037, rec=0.087, cos=0.002), tot_loss_proj:3.081 [t=0.30s]
prediction: ['[CLS] julia reganness played with laura isas by exasating bland. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.890 (perp=9.037, rec=0.081, cos=0.002), tot_loss_proj:3.072 [t=0.30s]
prediction: ['[CLS] julia reganness played with laura isas by exasating bland. [SEP]']
[ 600/2000] tot_loss=1.894 (perp=9.037, rec=0.085, cos=0.002), tot_loss_proj:3.082 [t=0.30s]
prediction: ['[CLS] julia reganness played with laura isas by exasating bland. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.874 (perp=8.923, rec=0.088, cos=0.002), tot_loss_proj:2.895 [t=0.31s]
prediction: ['[CLS] julia reganness played with laura isas by exas blandating. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.786 (perp=8.456, rec=0.093, cos=0.002), tot_loss_proj:2.844 [t=0.30s]
prediction: ['[CLS] julia regan played with laura isasness by exas blandating. [SEP]']
[ 750/2000] tot_loss=1.815 (perp=8.708, rec=0.072, cos=0.002), tot_loss_proj:2.814 [t=0.30s]
prediction: ['[CLS] julia regan played with laura isperness by exas blandating. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.704 (perp=8.114, rec=0.080, cos=0.002), tot_loss_proj:2.715 [t=0.30s]
prediction: ['[CLS] julia regan played with laura isness by exasper blandating. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.555 (perp=7.307, rec=0.091, cos=0.003), tot_loss_proj:2.660 [t=0.30s]
prediction: ['[CLS] julia regan played with laura bland isness by exasperating. [SEP]']
[ 900/2000] tot_loss=1.540 (perp=7.307, rec=0.077, cos=0.002), tot_loss_proj:2.658 [t=0.30s]
prediction: ['[CLS] julia regan played with laura bland isness by exasperating. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.533 (perp=7.307, rec=0.071, cos=0.002), tot_loss_proj:2.665 [t=0.30s]
prediction: ['[CLS] julia regan played with laura bland isness by exasperating. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.491 (perp=7.092, rec=0.071, cos=0.002), tot_loss_proj:2.090 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
[1050/2000] tot_loss=1.492 (perp=7.092, rec=0.072, cos=0.002), tot_loss_proj:2.085 [t=0.31s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.491 (perp=7.092, rec=0.071, cos=0.002), tot_loss_proj:2.082 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.484 (perp=7.092, rec=0.064, cos=0.002), tot_loss_proj:2.085 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
[1200/2000] tot_loss=1.493 (perp=7.092, rec=0.073, cos=0.002), tot_loss_proj:2.086 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.489 (perp=7.092, rec=0.069, cos=0.002), tot_loss_proj:2.079 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.485 (perp=7.092, rec=0.065, cos=0.002), tot_loss_proj:2.085 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
[1350/2000] tot_loss=1.490 (perp=7.092, rec=0.070, cos=0.002), tot_loss_proj:2.086 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.484 (perp=7.092, rec=0.064, cos=0.002), tot_loss_proj:2.082 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.495 (perp=7.092, rec=0.075, cos=0.002), tot_loss_proj:2.084 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
[1500/2000] tot_loss=1.493 (perp=7.092, rec=0.073, cos=0.002), tot_loss_proj:2.084 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.484 (perp=7.092, rec=0.064, cos=0.002), tot_loss_proj:2.086 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.495 (perp=7.092, rec=0.075, cos=0.002), tot_loss_proj:2.091 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
[1650/2000] tot_loss=1.486 (perp=7.092, rec=0.066, cos=0.002), tot_loss_proj:2.087 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.480 (perp=7.092, rec=0.061, cos=0.002), tot_loss_proj:2.083 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.485 (perp=7.092, rec=0.065, cos=0.002), tot_loss_proj:2.083 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
[1800/2000] tot_loss=1.477 (perp=7.092, rec=0.057, cos=0.002), tot_loss_proj:2.085 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.483 (perp=7.092, rec=0.063, cos=0.002), tot_loss_proj:2.083 [t=0.31s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.488 (perp=7.092, rec=0.068, cos=0.002), tot_loss_proj:2.079 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
[1950/2000] tot_loss=1.482 (perp=7.092, rec=0.062, cos=0.002), tot_loss_proj:2.083 [t=0.30s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.486 (perp=7.092, rec=0.066, cos=0.002), tot_loss_proj:2.078 [t=0.31s]
prediction: ['[CLS] julia regan played with laura is blandness by exasperating. [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] julia is played with exasperating blandness by laura regan. [SEP]
========================
predicted: 
========================
[CLS] julia regan played with laura is blandness by exasperating. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 71.509 | p: 70.928 | r: 72.277
rouge2     | fm: 18.337 | p: 18.149 | r: 18.546
rougeL     | fm: 47.211 | p: 46.836 | r: 47.632
rougeLsum  | fm: 47.137 | p: 46.760 | r: 47.573
r1fm+r2fm = 89.847

input #91 time: 0:12:04 | total time: 19:25:34


Running input #92 of 100.
reference: 
========================
plays like the old disease-of-the-week small-screen melodramas .
========================
average of cosine similarity 0.9991291798291719
highest_index [0]
highest [0.9991291798291719]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  3248,  2066,  1996,  2214,  4295,  1011,  1997,  1011,  1996,
          1011,  2733,  2235,  1011,  3898, 11463,  7716, 14672,  2015,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] plays like the old disease - of - the - week small - screen melodramas. [SEP]']
[Init] best rec loss: 0.9395565390586853 for ['[CLS] existing everyone instrument such gaston 車 madeing ; jelly elastic shippeddi electedland ~ brass democrat managed [SEP]']
[Init] best rec loss: 0.9374622106552124 for ['[CLS] critical mysteries cover stew tables musical fest artistsigen bombsrily culture [SEP]chers hatgen more stick hp [SEP]']
[Init] best rec loss: 0.9204837083816528 for ['[CLS] syn sorts predatory hillary care asian harristek contents meeting warren indoor health joyah defender grant catholic gaze tags [SEP]']
[Init] best rec loss: 0.8510405421257019 for ['[CLS] kira - : squeeze never brand display mis auto successful my loyal blast strange. ending supportsgizing ties [SEP]']
[Init] best rec loss: 0.8509401679039001 for ["[CLS] voiced football pursuing nine handle maceorough echo aboard el respiratory 'dora so buyscript of music wo [SEP]"]
[Init] best rec loss: 0.8501932621002197 for ['[CLS] guido directmedia 2009 to deserveasia workplace squad equipment same editor biographybial marriedicio a columnist vertical [SEP]']
[Init] best rec loss: 0.8489807844161987 for ['[CLS] panthersbalance rank room houghton growingibly arrive threw 0ographer layingff indiasts help rye jo thom [SEP]']
[Init] best perm rec loss: 0.8472721576690674 for ['[CLS] 0ffographer help threw growing panthersbalance room houghton ryeibly india thom laying ranksts jo arrive [SEP]']
[Init] best perm rec loss: 0.845306396484375 for ['[CLS] india jo rank layingsts growing roomibly threw panthers arriveographerbalance thomff houghton help 0 rye [SEP]']
[Init] best perm rec loss: 0.8446514010429382 for ['[CLS] panthers joffibly rank houghton helpbalance laying growing arrive 0 indiaographer thom room threwsts rye [SEP]']
[Init] best perm rec loss: 0.8441594243049622 for ['[CLS]ff rye 0 indiaibly help layingographer room growing rank arrive threwbalance thom panthers jo houghtonsts [SEP]']
[Init] best perm rec loss: 0.8429287672042847 for ['[CLS] room growing threw panthersiblyff jo thom help arriveographerbalance rank laying 0 houghtonsts india rye [SEP]']
[Init] best perm rec loss: 0.8425669074058533 for ['[CLS] growing houghton laying room thom panthersstsographer 0 rye jo help india arrive threwff rankbalanceibly [SEP]']
[Init] best perm rec loss: 0.8408427834510803 for ['[CLS]ographer 0ffibly arrive thom help india growing threw room houghton panthers ryests jo rankbalance laying [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.413 (perp=10.652, rec=0.274, cos=0.008), tot_loss_proj:3.492 [t=0.31s]
prediction: ['[CLS] symptoms plays like why latest old, screenrama disease of disease latest systems gets disease.. very [SEP]']
[ 100/2000] tot_loss=2.222 (perp=10.228, rec=0.171, cos=0.005), tot_loss_proj:2.834 [t=0.31s]
prediction: ['[CLS] plays plays like the latest old - screenrama cyclone like disease latest disease : disease because. old [SEP]']
[ 150/2000] tot_loss=2.237 (perp=10.460, rec=0.142, cos=0.003), tot_loss_proj:3.198 [t=0.31s]
prediction: ['[CLS] plays plays like the of old - screenramarama like disease pinyin week : disease because. old [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.749, rec=0.110, cos=0.003), tot_loss_proj:3.139 [t=0.31s]
prediction: ['[CLS] plays plays like the of old - screenramarama like disease pinyin weeks disease -. old [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.134 (perp=9.651, rec=0.197, cos=0.007), tot_loss_proj:2.732 [t=0.31s]
prediction: ['[CLS] plays plays like the disease old - screenramarama - - grade weeks disease disease. old [SEP]']
[ 300/2000] tot_loss=2.182 (perp=10.198, rec=0.139, cos=0.004), tot_loss_proj:2.836 [t=0.31s]
prediction: ['[CLS] plays plays like the disease old - screenramarama decay - subject restaurants disease disease. of [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.154 (perp=10.111, rec=0.128, cos=0.003), tot_loss_proj:3.289 [t=0.31s]
prediction: ['[CLS] plays plays like the disease old - weekramarama hall - carpet of mel disease disease. restaurant [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.068 (perp=9.820, rec=0.101, cos=0.003), tot_loss_proj:3.027 [t=0.31s]
prediction: ['[CLS] plays plays like the disease old - weekramarama hall - carpet of mel disease disease restaurant. [SEP]']
[ 450/2000] tot_loss=1.882 (perp=8.897, rec=0.099, cos=0.003), tot_loss_proj:2.591 [t=0.31s]
prediction: ['[CLS] plays plays like the disease old - weekramas the - carpet of mel disease disease screen. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.726 (perp=8.118, rec=0.099, cos=0.003), tot_loss_proj:2.552 [t=0.31s]
prediction: ['[CLS] plays plays like the disease old of weekramas - the carpet of mel disease disease screen. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.921 (perp=8.898, rec=0.137, cos=0.004), tot_loss_proj:2.649 [t=0.31s]
prediction: ['[CLS] plays plays like the disease old of weekramas - the of mel carpet disease disease screen. [SEP]']
[ 600/2000] tot_loss=1.884 (perp=8.898, rec=0.102, cos=0.003), tot_loss_proj:2.642 [t=0.31s]
prediction: ['[CLS] plays plays like the disease old of weekramas - the of mel carpet disease disease screen. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.712 (perp=8.017, rec=0.106, cos=0.003), tot_loss_proj:2.435 [t=0.31s]
prediction: ['[CLS] plays plays like the disease old of weekramas - the disease mel - disease of screen. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.678 (perp=7.832, rec=0.109, cos=0.002), tot_loss_proj:2.329 [t=0.31s]
prediction: ['[CLS] plays plays like the week old of diseaseramas - the disease mel - disease of screen. [SEP]']
[ 750/2000] tot_loss=1.673 (perp=7.832, rec=0.104, cos=0.002), tot_loss_proj:2.324 [t=0.31s]
prediction: ['[CLS] plays plays like the week old of diseaseramas - the disease mel - disease of screen. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.601 (perp=7.462, rec=0.106, cos=0.002), tot_loss_proj:2.333 [t=0.31s]
prediction: ['[CLS] screen plays like the week old of diseaseramas - the disease mel plays disease of screen. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.550 (perp=7.232, rec=0.101, cos=0.002), tot_loss_proj:2.386 [t=0.31s]
prediction: ['[CLS] screen plays like the week old of diseaseramas - the disease mel plays of disease screen. [SEP]']
[ 900/2000] tot_loss=1.531 (perp=7.232, rec=0.082, cos=0.002), tot_loss_proj:2.393 [t=0.31s]
prediction: ['[CLS] screen plays like the week old of diseaseramas - the disease mel plays of disease screen. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.536 (perp=7.232, rec=0.087, cos=0.002), tot_loss_proj:2.387 [t=0.31s]
prediction: ['[CLS] screen plays like the week old of diseaseramas - the disease mel plays of disease screen. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.553 (perp=7.281, rec=0.095, cos=0.002), tot_loss_proj:2.418 [t=0.31s]
prediction: ['[CLS] - plays like the week old of diseaseramas - the disease mel plays of disease screen. [SEP]']
[1050/2000] tot_loss=1.512 (perp=7.114, rec=0.087, cos=0.002), tot_loss_proj:2.422 [t=0.31s]
prediction: ['[CLS] - plays like the week old of diseaseramas - the disease mel plays the disease screen. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.504 (perp=7.114, rec=0.079, cos=0.002), tot_loss_proj:2.419 [t=0.31s]
prediction: ['[CLS] - plays like the week old of diseaseramas - the disease mel plays the disease screen. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.493 (perp=7.033, rec=0.084, cos=0.002), tot_loss_proj:2.184 [t=0.31s]
prediction: ['[CLS] - plays like the week old of diseaseramas - the disease mel - the disease screen. [SEP]']
[1200/2000] tot_loss=1.490 (perp=7.033, rec=0.082, cos=0.002), tot_loss_proj:2.184 [t=0.31s]
prediction: ['[CLS] - plays like the week old of diseaseramas - the disease mel - the disease screen. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.489 (perp=7.033, rec=0.080, cos=0.002), tot_loss_proj:2.184 [t=0.31s]
prediction: ['[CLS] - plays like the week old of diseaseramas - the disease mel - the disease screen. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.483 (perp=7.033, rec=0.075, cos=0.002), tot_loss_proj:2.186 [t=0.31s]
prediction: ['[CLS] - plays like the week old of diseaseramas - the disease mel - the disease screen. [SEP]']
[1350/2000] tot_loss=1.479 (perp=7.033, rec=0.071, cos=0.002), tot_loss_proj:2.185 [t=0.31s]
prediction: ['[CLS] - plays like the week old of diseaseramas - the disease mel - the disease screen. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.489 (perp=7.033, rec=0.081, cos=0.002), tot_loss_proj:2.177 [t=0.31s]
prediction: ['[CLS] - plays like the week old of diseaseramas - the disease mel - the disease screen. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.493 (perp=7.033, rec=0.084, cos=0.002), tot_loss_proj:2.184 [t=0.31s]
prediction: ['[CLS] - plays like the week old of diseaseramas - the disease mel - the disease screen. [SEP]']
[1500/2000] tot_loss=1.484 (perp=7.033, rec=0.075, cos=0.002), tot_loss_proj:2.177 [t=0.31s]
prediction: ['[CLS] - plays like the week old of diseaseramas - the disease mel - the disease screen. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.450 (perp=6.885, rec=0.071, cos=0.002), tot_loss_proj:2.280 [t=0.31s]
prediction: ['[CLS] old plays like the week - of diseaseramas - the disease mel - the disease screen. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.464 (perp=6.885, rec=0.085, cos=0.002), tot_loss_proj:2.279 [t=0.31s]
prediction: ['[CLS] old plays like the week - of diseaseramas - the disease mel - the disease screen. [SEP]']
[1650/2000] tot_loss=1.453 (perp=6.885, rec=0.075, cos=0.002), tot_loss_proj:2.277 [t=0.31s]
prediction: ['[CLS] old plays like the week - of diseaseramas - the disease mel - the disease screen. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.448 (perp=6.885, rec=0.069, cos=0.002), tot_loss_proj:2.276 [t=0.31s]
prediction: ['[CLS] old plays like the week - of diseaseramas - the disease mel - the disease screen. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.425 (perp=6.720, rec=0.079, cos=0.002), tot_loss_proj:2.250 [t=0.31s]
prediction: ['[CLS] old plays like the disease - of weekramas - the disease mel - the disease screen. [SEP]']
[1800/2000] tot_loss=1.408 (perp=6.720, rec=0.063, cos=0.002), tot_loss_proj:2.254 [t=0.31s]
prediction: ['[CLS] old plays like the disease - of weekramas - the disease mel - the disease screen. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.427 (perp=6.720, rec=0.081, cos=0.002), tot_loss_proj:2.252 [t=0.31s]
prediction: ['[CLS] old plays like the disease - of weekramas - the disease mel - the disease screen. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.413 (perp=6.720, rec=0.068, cos=0.002), tot_loss_proj:2.255 [t=0.31s]
prediction: ['[CLS] old plays like the disease - of weekramas - the disease mel - the disease screen. [SEP]']
[1950/2000] tot_loss=1.416 (perp=6.720, rec=0.070, cos=0.002), tot_loss_proj:2.254 [t=0.31s]
prediction: ['[CLS] old plays like the disease - of weekramas - the disease mel - the disease screen. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.425 (perp=6.720, rec=0.079, cos=0.002), tot_loss_proj:2.253 [t=0.31s]
prediction: ['[CLS] old plays like the disease - of weekramas - the disease mel - the disease screen. [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] plays like the old disease - of - the - week small - screen melodramas. [SEP]
========================
predicted: 
========================
[CLS] - plays like the week old of diseaseramas - the disease mel - the disease screen. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 73.333 | r: 84.615
rouge2     | fm: 30.769 | p: 28.571 | r: 33.333
rougeL     | fm: 64.286 | p: 60.000 | r: 69.231
rougeLsum  | fm: 64.286 | p: 60.000 | r: 69.231
r1fm+r2fm = 109.341

[Aggregate metrics]:
rouge1     | fm: 71.501 | p: 70.874 | r: 72.349
rouge2     | fm: 18.540 | p: 18.347 | r: 18.745
rougeL     | fm: 47.310 | p: 46.921 | r: 47.816
rougeLsum  | fm: 47.267 | p: 46.838 | r: 47.810
r1fm+r2fm = 90.040

input #92 time: 0:12:19 | total time: 19:37:54


Running input #93 of 100.
reference: 
========================
worse than 'silence of the lambs' better than 'hannibal'
========================
average of cosine similarity 0.99941078834986
highest_index [0]
highest [0.99941078834986]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  4788,  2084,  1005,  4223,  1997,  1996, 12559,  2015,  1005,
          2488,  2084,  1005, 24181,  1005,   102]], device='cuda:0')
Debug: ref = ["[CLS] worse than'silence of the lambs'better than'hannibal'[SEP]"]
[Init] best rec loss: 0.9424979090690613 for ['[CLS] 1999 christopher me cologne only indianapolis thing edit bryan taft felt turn either chapter [SEP]']
[Init] best rec loss: 0.8886553049087524 for ["[CLS] adrian armenia classical singleffy'aspect henry shifters next headsritan sbs industrial [SEP]"]
[Init] best rec loss: 0.8629794716835022 for ['[CLS] surfer wrestler breaking sound inspired must somehow ang mess regime cover mountain 8 rising [SEP]']
[Init] best rec loss: 0.8184549808502197 for ['[CLS] march scratch prize ledger fill latin further gone [CLS] street batmanhorpe zealand not [SEP]']
[Init] best rec loss: 0.8177415132522583 for ['[CLS] quoted nazisship sen hurt signal seventy jo bred petitionrch eligibility window ref [SEP]']
[Init] best perm rec loss: 0.8173739910125732 for ['[CLS] signal jo window petition hurt quotedship nazisrch seventy ref bred eligibility sen [SEP]']
[Init] best perm rec loss: 0.8169214725494385 for ['[CLS] eligibility bred jo quoted nazis seventyrch senship window ref hurt petition signal [SEP]']
[Init] best perm rec loss: 0.816457211971283 for ['[CLS] nazisship quotedrch seventy sen ref bred petition window signal jo hurt eligibility [SEP]']
[Init] best perm rec loss: 0.8143934607505798 for ['[CLS] quotedrch bred sen petition jo hurtship seventy window ref nazis signal eligibility [SEP]']
[Init] best perm rec loss: 0.8129515051841736 for ['[CLS] signal quoted hurtrch nazis seventy bredship jo eligibility ref window petition sen [SEP]']
[Init] best perm rec loss: 0.8111591339111328 for ['[CLS] signal jo seventyship window bredrch nazis petition ref hurt sen quoted eligibility [SEP]']
[Init] best perm rec loss: 0.8108999729156494 for ['[CLS] nazis refship seventy signal hurt sen bred petition jorch quoted window eligibility [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.710 (perp=11.539, rec=0.362, cos=0.040), tot_loss_proj:4.002 [t=0.30s]
prediction: ['[CLS] worse耳 better betterenedeck perhaps... sell better his fat better simply [SEP]']
[ 100/2000] tot_loss=1.979 (perp=8.727, rec=0.222, cos=0.011), tot_loss_proj:2.740 [t=0.30s]
prediction: ["[CLS] worse °c better better than'perhaps'behave than has fat better simply [SEP]"]
[ 150/2000] tot_loss=1.719 (perp=7.845, rec=0.144, cos=0.005), tot_loss_proj:2.811 [t=0.30s]
prediction: ["[CLS] worse hannibal than better than'hannibal'' than'fat better'[SEP]"]
[ 200/2000] tot_loss=1.703 (perp=7.845, rec=0.130, cos=0.005), tot_loss_proj:2.809 [t=0.31s]
prediction: ["[CLS] worse hannibal than better than'hannibal'' than'fat better'[SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.416 (perp=6.433, rec=0.124, cos=0.005), tot_loss_proj:2.056 [t=0.30s]
prediction: ["[CLS] worse than hannibal better than'hannibal'' than'' better'[SEP]"]
[ 300/2000] tot_loss=1.383 (perp=6.433, rec=0.095, cos=0.002), tot_loss_proj:2.054 [t=0.30s]
prediction: ["[CLS] worse than hannibal better than'hannibal'' than'' better'[SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.439 (perp=6.746, rec=0.089, cos=0.002), tot_loss_proj:2.313 [t=0.31s]
prediction: ["[CLS] worse than hannibal better than'hannibal'silence than'''' [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.315 (perp=6.103, rec=0.092, cos=0.002), tot_loss_proj:1.890 [t=0.31s]
prediction: ["[CLS] worse than hannibal better than'hannibal'' than'silence'' [SEP]"]
[ 450/2000] tot_loss=1.294 (perp=6.103, rec=0.072, cos=0.001), tot_loss_proj:1.888 [t=0.31s]
prediction: ["[CLS] worse than hannibal better than'hannibal'' than'silence'' [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.294 (perp=6.103, rec=0.073, cos=0.001), tot_loss_proj:1.889 [t=0.30s]
prediction: ["[CLS] worse than hannibal better than'hannibal'' than'silence'' [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.304 (perp=6.103, rec=0.082, cos=0.001), tot_loss_proj:1.892 [t=0.30s]
prediction: ["[CLS] worse than hannibal better than'hannibal'' than'silence'' [SEP]"]
[ 600/2000] tot_loss=1.302 (perp=6.103, rec=0.080, cos=0.001), tot_loss_proj:1.892 [t=0.30s]
prediction: ["[CLS] worse than hannibal better than'hannibal'' than'silence'' [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.277 (perp=5.981, rec=0.079, cos=0.001), tot_loss_proj:1.949 [t=0.30s]
prediction: ["[CLS] worse than hannibal better than'silence'' than'silence'' [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.277 (perp=5.981, rec=0.079, cos=0.001), tot_loss_proj:1.947 [t=0.31s]
prediction: ["[CLS] worse than hannibal better than'silence'' than'silence'' [SEP]"]
[ 750/2000] tot_loss=1.275 (perp=5.981, rec=0.077, cos=0.001), tot_loss_proj:1.949 [t=0.31s]
prediction: ["[CLS] worse than hannibal better than'silence'' than'silence'' [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.278 (perp=5.981, rec=0.081, cos=0.001), tot_loss_proj:1.950 [t=0.31s]
prediction: ["[CLS] worse than hannibal better than'silence'' than'silence'' [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.278 (perp=5.981, rec=0.080, cos=0.001), tot_loss_proj:1.950 [t=0.30s]
prediction: ["[CLS] worse than hannibal better than'silence'' than'silence'' [SEP]"]
[ 900/2000] tot_loss=1.360 (perp=6.453, rec=0.068, cos=0.001), tot_loss_proj:1.969 [t=0.31s]
prediction: ["[CLS] worse than hannibal better than'silence'' than'silence the'[SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.351 (perp=6.385, rec=0.073, cos=0.001), tot_loss_proj:1.893 [t=0.31s]
prediction: ["[CLS] worse than hannibal better than'lamb'' than'the silence'[SEP]"]
Attempt swap
[1000/2000] tot_loss=1.345 (perp=6.385, rec=0.067, cos=0.001), tot_loss_proj:1.899 [t=0.31s]
prediction: ["[CLS] worse than hannibal better than'lamb'' than'the silence'[SEP]"]
[1050/2000] tot_loss=1.348 (perp=6.385, rec=0.070, cos=0.001), tot_loss_proj:1.898 [t=0.30s]
prediction: ["[CLS] worse than hannibal better than'lamb'' than'the silence'[SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.356 (perp=6.385, rec=0.078, cos=0.001), tot_loss_proj:1.881 [t=0.30s]
prediction: ["[CLS] worse than hannibal better than'lamb'' than'the silence'[SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.277 (perp=5.985, rec=0.078, cos=0.002), tot_loss_proj:2.242 [t=0.30s]
prediction: ["[CLS] worse than better than'hannibal lamb'' than'the silence'[SEP]"]
[1200/2000] tot_loss=1.265 (perp=5.985, rec=0.067, cos=0.001), tot_loss_proj:2.245 [t=0.30s]
prediction: ["[CLS] worse than better than'hannibal lamb'' than'the silence'[SEP]"]
Attempt swap
[1250/2000] tot_loss=1.384 (perp=6.614, rec=0.060, cos=0.001), tot_loss_proj:2.343 [t=0.30s]
prediction: ["[CLS] worse than better than'hannibal lamb the'than'the silence'[SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.311 (perp=6.189, rec=0.072, cos=0.001), tot_loss_proj:2.415 [t=0.30s]
prediction: ["[CLS] worse than better of'hannibal lamb'than the'the silence'[SEP]"]
[1350/2000] tot_loss=1.314 (perp=6.189, rec=0.075, cos=0.001), tot_loss_proj:2.404 [t=0.30s]
prediction: ["[CLS] worse than better of'hannibal lamb'than the'the silence'[SEP]"]
Attempt swap
[1400/2000] tot_loss=1.304 (perp=6.189, rec=0.065, cos=0.001), tot_loss_proj:2.409 [t=0.31s]
prediction: ["[CLS] worse than better of'hannibal lamb'than the'the silence'[SEP]"]
Attempt swap
[1450/2000] tot_loss=1.314 (perp=6.189, rec=0.075, cos=0.001), tot_loss_proj:2.410 [t=0.31s]
prediction: ["[CLS] worse than better of'hannibal lamb'than the'the silence'[SEP]"]
[1500/2000] tot_loss=1.307 (perp=6.189, rec=0.068, cos=0.001), tot_loss_proj:2.409 [t=0.30s]
prediction: ["[CLS] worse than better of'hannibal lamb'than the'the silence'[SEP]"]
Attempt swap
[1550/2000] tot_loss=1.308 (perp=6.189, rec=0.069, cos=0.001), tot_loss_proj:2.408 [t=0.31s]
prediction: ["[CLS] worse than better of'hannibal lamb'than the'the silence'[SEP]"]
Attempt swap
[1600/2000] tot_loss=1.299 (perp=6.189, rec=0.061, cos=0.001), tot_loss_proj:2.402 [t=0.31s]
prediction: ["[CLS] worse than better of'hannibal lamb'than the'the silence'[SEP]"]
[1650/2000] tot_loss=1.311 (perp=6.189, rec=0.072, cos=0.001), tot_loss_proj:2.415 [t=0.31s]
prediction: ["[CLS] worse than better of'hannibal lamb'than the'the silence'[SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=1.301 (perp=6.193, rec=0.061, cos=0.001), tot_loss_proj:2.367 [t=0.31s]
prediction: ["[CLS] worse than better of'hannibal lamb'than the silence'the'[SEP]"]
Attempt swap
[1750/2000] tot_loss=1.308 (perp=6.193, rec=0.068, cos=0.001), tot_loss_proj:2.367 [t=0.30s]
prediction: ["[CLS] worse than better of'hannibal lamb'than the silence'the'[SEP]"]
[1800/2000] tot_loss=1.274 (perp=6.021, rec=0.068, cos=0.001), tot_loss_proj:2.476 [t=0.30s]
prediction: ["[CLS] worse than better of'hannibal lamb'than'silence'the'[SEP]"]
Attempt swap
[1850/2000] tot_loss=1.276 (perp=6.021, rec=0.071, cos=0.001), tot_loss_proj:2.476 [t=0.31s]
prediction: ["[CLS] worse than better of'hannibal lamb'than'silence'the'[SEP]"]
Attempt swap
[1900/2000] tot_loss=1.271 (perp=6.021, rec=0.065, cos=0.001), tot_loss_proj:2.474 [t=0.31s]
prediction: ["[CLS] worse than better of'hannibal lamb'than'silence'the'[SEP]"]
[1950/2000] tot_loss=1.282 (perp=6.021, rec=0.077, cos=0.001), tot_loss_proj:2.471 [t=0.30s]
prediction: ["[CLS] worse than better of'hannibal lamb'than'silence'the'[SEP]"]
Attempt swap
[2000/2000] tot_loss=1.273 (perp=6.021, rec=0.068, cos=0.001), tot_loss_proj:2.473 [t=0.31s]
prediction: ["[CLS] worse than better of'hannibal lamb'than'silence'the'[SEP]"]
Done with input #93 of 100.
reference: 
========================
[CLS] worse than'silence of the lambs'better than'hannibal'[SEP]
========================
predicted: 
========================
[CLS] worse than better of'hannibal lamb'than the'the silence'[SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 83.333 | r: 90.909
rouge2     | fm: 19.048 | p: 18.182 | r: 20.000
rougeL     | fm: 52.174 | p: 50.000 | r: 54.545
rougeLsum  | fm: 52.174 | p: 50.000 | r: 54.545
r1fm+r2fm = 106.004

[Aggregate metrics]:
rouge1     | fm: 71.707 | p: 71.061 | r: 72.613
rouge2     | fm: 18.518 | p: 18.323 | r: 18.760
rougeL     | fm: 47.380 | p: 46.942 | r: 47.910
rougeLsum  | fm: 47.406 | p: 46.974 | r: 47.957
r1fm+r2fm = 90.225

input #93 time: 0:12:04 | total time: 19:49:58


Running input #94 of 100.
reference: 
========================
the powerpuff girls arrive on the big screen with their super-powers , their super-simple animation and their super-dooper-adorability intact .
========================
average of cosine similarity 0.9994035795924843
highest_index [0]
highest [0.9994035795924843]
Debug: ids_shape = 35, pads = [35]
Debug: input ids = tensor([[  101,  1996,  2373, 14289,  4246,  3057,  7180,  2006,  1996,  2502,
          3898,  2007,  2037,  3565,  1011,  4204,  1010,  2037,  3565,  1011,
          3722,  7284,  1998,  2037,  3565,  1011, 20160,  4842,  1011,  4748,
          6525,  8553, 10109,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the powerpuff girls arrive on the big screen with their super - powers, their super - simple animation and their super - dooper - adorability intact. [SEP]']
[Init] best rec loss: 0.9322189092636108 for ['[CLS] casting lee 2 symbol age quinn fear habitats tough robotics death alexis helped positivetment crossed suffering chess titanicaaido code ye lane rearview shiplk micah lore he legion bbcroving [SEP]']
[Init] best rec loss: 0.9007618427276611 for ['[CLS] yeah green ai peer versus open whatever end elder grantscu professional villa reflex inherited tyler needle tie race chord extinct swarm & showing left fund kc wolf jet secondary base overcometel [SEP]']
[Init] best rec loss: 0.8951088786125183 for ['[CLS] enough perryaround sustainable neo this mid cold fast origin once storm dl halfy grim overturned supporton☉ starttious approximately wonder filluity station connolly only three theatre disappearedhein [SEP]']
[Init] best rec loss: 0.8665103912353516 for ['[CLS] bleak colour pub harold offices permission pa balthazar trademark radiationtown himself warriors hitler happens royalerland canleneivo animals tell orlando tax patrons sans order until college union production sort guessing [SEP]']
[Init] best rec loss: 0.8663682341575623 for ['[CLS] individuals strongerersward settle race ava trulyoge hadens united contra beaches discovers fellows sheikh core been regulatory variously alt hollymering efficient jamiesibility medalfoot served much innocent pit [SEP]']
[Init] best perm rec loss: 0.8626458048820496 for ['[CLS] ava jamie settle beaches discovers fellows core race individuals united variously contra innocentwardersfoot had stronger sheikh pitens truly hollysibility medal served regulatory been alt muchoge efficientmering [SEP]']
[Init] best perm rec loss: 0.8606282472610474 for ['[CLS] contramering medal holly united stronger truly innocenters discovers beaches regulatory race hadfoot variously served much jamie been settleward fellowsogesibility sheikh efficient core pit ava altens individuals [SEP]']
[Init] best perm rec loss: 0.8568527102470398 for ['[CLS] been medal trulyfoot discoversens had stronger united served innocenters efficient much settle regulatory variously jamiemering alt fellows contraward race core sheikhsibility beaches ava pitoge individuals holly [SEP]']
[Init] best perm rec loss: 0.8562189340591431 for ['[CLS] had stronger sheikh truly individuals settlemeringoge pit variously medalers much innocent holly beenens regulatoryfoot coresibility ava efficient jamie fellows alt contra race discovers united beachesward served [SEP]']
[Init] best perm rec loss: 0.8554542064666748 for ['[CLS]sibility efficient trulyfoot hadoge fellows been served contra settle pit much medal united discovers variously regulatory jamie holly ava individualsward strongerersens race alt sheikhmering core innocent beaches [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.962 (perp=12.882, rec=0.363, cos=0.022), tot_loss_proj:4.367 [t=0.31s]
prediction: ['[CLS] hispanic miss smell intact talkingtalyn hungry serving geo flashed audience the art doll! advertising detector macy artworkhouseview reception user unique law problems get as biggest aboard alex chris [SEP]']
[ 100/2000] tot_loss=2.446 (perp=10.960, rec=0.246, cos=0.008), tot_loss_proj:3.368 [t=0.31s]
prediction: ['[CLS] the super animation intact dinner the exceeded ape the super flashed reading their great toy - big screen macy screenhouse resulting arrive. corporate socialist theirhammer as with aboard alex jonah [SEP]']
[ 150/2000] tot_loss=2.293 (perp=10.450, rec=0.197, cos=0.007), tot_loss_proj:3.218 [t=0.31s]
prediction: ['[CLS] the super screen intact * the screen understanding the a screen field their powers animation - big screen macy screenhouse resulting arrive - corporate theory graphichammer super with aboard alex [SEP] [SEP]']
[ 200/2000] tot_loss=2.014 (perp=9.221, rec=0.165, cos=0.004), tot_loss_proj:2.878 [t=0.31s]
prediction: ['[CLS] the super screen intact dinner the screen idiot the the super screen their super animation - big girls terminus screenhouse events arrive - corporatebility graphicbility, with aboard alex. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.245 (perp=10.053, rec=0.221, cos=0.013), tot_loss_proj:3.000 [t=0.31s]
prediction: ["[CLS] the super screen intact - my screen gt - [CLS] super energy their powers animation'big girls superhero screen. example arrive eye successful levels committeebility, withー alex. [SEP]"]
[ 300/2000] tot_loss=2.043 (perp=9.424, rec=0.153, cos=0.005), tot_loss_proj:3.065 [t=0.31s]
prediction: ["[CLS] the super screen intact - my against prefix - [CLS] super & their powers animation'big girls animation screen. some arrive bought audience powers committeebility, with - alex. [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.773 (perp=8.163, rec=0.135, cos=0.005), tot_loss_proj:2.556 [t=0.31s]
prediction: ["[CLS] the super screen intact - my seeing! - on super - their powers -'big girls animation screen. their arrive power job powers geobility, with animation alex. [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.745 (perp=8.013, rec=0.139, cos=0.004), tot_loss_proj:2.482 [t=0.31s]
prediction: ["[CLS] the super screen intact - my out abilities - on super - their powers -'big girls animation screen.bility arrive with power - powers geobility, animation ser. [SEP]"]
[ 450/2000] tot_loss=1.747 (perp=8.145, rec=0.116, cos=0.002), tot_loss_proj:2.539 [t=0.31s]
prediction: ["[CLS] the super screen intact - my on powers - on super - their powers -'big girls animation screen.bility arrive with power - powers geobility, animation ser. [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.821 (perp=8.478, rec=0.123, cos=0.003), tot_loss_proj:2.620 [t=0.31s]
prediction: ["[CLS] the superbility intact - my super powers - on on - their super -'big girls animation screen.bility arrive with their - powerspubility, animation ser. [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.757 (perp=8.177, rec=0.119, cos=0.002), tot_loss_proj:2.538 [t=0.31s]
prediction: ["[CLS] the superbility intact - my super powers - on on - their super powers'big girls animation screen.bility arrive with their - -pubility, animation ser. [SEP]"]
[ 600/2000] tot_loss=1.749 (perp=8.177, rec=0.111, cos=0.002), tot_loss_proj:2.531 [t=0.31s]
prediction: ["[CLS] the superbility intact - my super powers - on on - their super powers'big girls animation screen.bility arrive with their - -pubility, animation ser. [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.599 (perp=7.460, rec=0.105, cos=0.002), tot_loss_proj:2.258 [t=0.31s]
prediction: ["[CLS] the powerbility intact - their super powers - on on - their super powers'big girls animation screen.bility arrive with their - serpubility, animation -. [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.572 (perp=7.291, rec=0.111, cos=0.002), tot_loss_proj:2.342 [t=0.31s]
prediction: ["[CLS] the powerbility intact - their super powers and on on - their super powers'big girls their screen,bility arrive with animation - serpubility, animation -. [SEP]"]
[ 750/2000] tot_loss=1.566 (perp=7.291, rec=0.106, cos=0.002), tot_loss_proj:2.338 [t=0.31s]
prediction: ["[CLS] the powerbility intact - their super powers and on on - their super powers'big girls their screen,bility arrive with animation - serpubility, animation -. [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.602 (perp=7.475, rec=0.105, cos=0.002), tot_loss_proj:2.500 [t=0.31s]
prediction: ["[CLS] the powerbility intactff their super powers and on - their super powers'big girls on their screen,bility arrive with animation - serpubility, animation -. [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.707 (perp=8.034, rec=0.098, cos=0.002), tot_loss_proj:2.747 [t=0.31s]
prediction: ["[CLS] the powerbility intactff their super powers and on - their super powers'bigbility on their screen, girls arrive with animationora serpubility, animation -. [SEP]"]
[ 900/2000] tot_loss=1.706 (perp=8.034, rec=0.098, cos=0.002), tot_loss_proj:2.751 [t=0.31s]
prediction: ["[CLS] the powerbility intactff their super powers and on - their super powers'bigbility on their screen, girls arrive with animationora serpubility, animation -. [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.679 (perp=7.895, rec=0.099, cos=0.001), tot_loss_proj:2.619 [t=0.31s]
prediction: ["[CLS] the powerbility intactff their super powers - and on their super powers'big their on their screen, girls arrive with animationora serpubility, animation -. [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.741 (perp=8.180, rec=0.103, cos=0.002), tot_loss_proj:2.549 [t=0.31s]
prediction: ["[CLS] the powerbility intactff their super superora and on their super powers'big their on their screen, girls arrive with animation - serpubility, animation -. [SEP]"]
[1050/2000] tot_loss=1.784 (perp=8.414, rec=0.100, cos=0.001), tot_loss_proj:2.684 [t=0.31s]
prediction: ["[CLS] the powerbility intactff their super superora and on their super powers'big their on their screen, girls arrive with doo - serpubility, animation -. [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.683 (perp=7.935, rec=0.094, cos=0.002), tot_loss_proj:2.560 [t=0.31s]
prediction: ["[CLS] the powerbility intactff their super power girls and on their super powers'big their on their screen,ora arrive with doo - serpubility, animation -. [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.657 (perp=7.783, rec=0.099, cos=0.002), tot_loss_proj:2.551 [t=0.31s]
prediction: ["[CLS] the powerbility intactff their super power girls and on their super powers'big on their screen, theirora arrive with doo - serpubility, animation -. [SEP]"]
[1200/2000] tot_loss=1.649 (perp=7.783, rec=0.090, cos=0.002), tot_loss_proj:2.553 [t=0.31s]
prediction: ["[CLS] the powerbility intactff their super power girls and on their super powers'big on their screen, theirora arrive with doo - serpubility, animation -. [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.631 (perp=7.650, rec=0.100, cos=0.001), tot_loss_proj:2.877 [t=0.31s]
prediction: ["[CLS] the powerbility intactffs super power girls and on their super powers big'on their screen, theirora arrive with doo - serpubility, animation -. [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.593 (perp=7.479, rec=0.096, cos=0.001), tot_loss_proj:2.892 [t=0.31s]
prediction: ["[CLS] the powerbility intactbilitys super power girls and on their super powers big'on their screen, theirora arrive with doo - serpuff, animation -. [SEP]"]
[1350/2000] tot_loss=1.594 (perp=7.479, rec=0.096, cos=0.001), tot_loss_proj:2.894 [t=0.31s]
prediction: ["[CLS] the powerbility intactbilitys super power girls and on their super powers big'on their screen, theirora arrive with doo - serpuff, animation -. [SEP]"]
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.540 (perp=7.197, rec=0.099, cos=0.001), tot_loss_proj:2.825 [t=0.31s]
prediction: ["[CLS] the powerbility intactbilitys big super power girls and on their super powers'on their screen, theirora arrive with doo - serpuff, animation -. [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.549 (perp=7.243, rec=0.099, cos=0.002), tot_loss_proj:2.571 [t=0.31s]
prediction: ['[CLS] the powerbility intactbilitys big on super power girls and their super powers - on their screen, theirora arrive with doo - serpuff, animation -. [SEP]']
[1500/2000] tot_loss=1.543 (perp=7.243, rec=0.093, cos=0.001), tot_loss_proj:2.568 [t=0.31s]
prediction: ['[CLS] the powerbility intactbilitys big on super power girls and their super powers - on their screen, theirora arrive with doo - serpuff, animation -. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.483 (perp=6.920, rec=0.098, cos=0.002), tot_loss_proj:2.651 [t=0.31s]
prediction: ['[CLS] the doobility intactbilitys big on super power girls and their super powers - on their screen, theirora arrive with power - serpuff, animation -. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.485 (perp=6.920, rec=0.099, cos=0.002), tot_loss_proj:2.656 [t=0.31s]
prediction: ['[CLS] the doobility intactbilitys big on super power girls and their super powers - on their screen, theirora arrive with power - serpuff, animation -. [SEP]']
[1650/2000] tot_loss=1.482 (perp=6.920, rec=0.097, cos=0.001), tot_loss_proj:2.651 [t=0.31s]
prediction: ['[CLS] the doobility intactbilitys big on super power girls and their super powers - on their screen, theirora arrive with power - serpuff, animation -. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.479 (perp=6.920, rec=0.093, cos=0.001), tot_loss_proj:2.653 [t=0.31s]
prediction: ['[CLS] the doobility intactbilitys big on super power girls and their super powers - on their screen, theirora arrive with power - serpuff, animation -. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.470 (perp=6.858, rec=0.097, cos=0.001), tot_loss_proj:2.500 [t=0.31s]
prediction: ['[CLS] the doobility intactbilitys power on super big girls and their super powers - on their screen, theirora arrive with power - serpuff, animation -. [SEP]']
[1800/2000] tot_loss=1.466 (perp=6.858, rec=0.093, cos=0.001), tot_loss_proj:2.498 [t=0.40s]
prediction: ['[CLS] the doobility intactbilitys power on super big girls and their super powers - on their screen, theirora arrive with power - serpuff, animation -. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.503 (perp=7.046, rec=0.092, cos=0.001), tot_loss_proj:2.624 [t=0.31s]
prediction: ['[CLS] the doobility intactbilitys power on super big girls - their super powers - on their screen, theirora arrive with power - serpuff, animation -. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.460 (perp=6.858, rec=0.087, cos=0.001), tot_loss_proj:2.501 [t=0.31s]
prediction: ['[CLS] the doobility intactbilitys power on super big girls and their super powers - on their screen, theirora arrive with power - serpuff, animation -. [SEP]']
[1950/2000] tot_loss=1.503 (perp=7.046, rec=0.092, cos=0.001), tot_loss_proj:2.624 [t=0.31s]
prediction: ['[CLS] the doobility intactbilitys power on super big girls - their super powers - on their screen, theirora arrive with power - serpuff, animation -. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.500 (perp=7.046, rec=0.090, cos=0.001), tot_loss_proj:2.623 [t=0.31s]
prediction: ['[CLS] the doobility intactbilitys power on super big girls - their super powers - on their screen, theirora arrive with power - serpuff, animation -. [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] the powerpuff girls arrive on the big screen with their super - powers, their super - simple animation and their super - dooper - adorability intact. [SEP]
========================
predicted: 
========================
[CLS] the doobility intactbilitys power on super big girls - their super powers - on their screen, theirora arrive with power - serpuff, animation -. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 65.217 | p: 68.182 | r: 62.500
rouge2     | fm: 13.636 | p: 14.286 | r: 13.043
rougeL     | fm: 43.478 | p: 45.455 | r: 41.667
rougeLsum  | fm: 43.478 | p: 45.455 | r: 41.667
r1fm+r2fm = 78.854

[Aggregate metrics]:
rouge1     | fm: 71.668 | p: 71.040 | r: 72.464
rouge2     | fm: 18.504 | p: 18.303 | r: 18.726
rougeL     | fm: 47.267 | p: 46.906 | r: 47.790
rougeLsum  | fm: 47.340 | p: 46.995 | r: 47.845
r1fm+r2fm = 90.172

input #94 time: 0:12:16 | total time: 20:02:14


Running input #95 of 100.
reference: 
========================
the film is so busy making reference to other films and trying to be other films that it fails to have a heart , mind or humor of its own .
========================
average of cosine similarity 0.9992309255375974
highest_index [0]
highest [0.9992309255375974]
Debug: ids_shape = 33, pads = [33]
Debug: input ids = tensor([[  101,  1996,  2143,  2003,  2061,  5697,  2437,  4431,  2000,  2060,
          3152,  1998,  2667,  2000,  2022,  2060,  3152,  2008,  2009, 11896,
          2000,  2031,  1037,  2540,  1010,  2568,  2030,  8562,  1997,  2049,
          2219,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the film is so busy making reference to other films and trying to be other films that it fails to have a heart, mind or humor of its own. [SEP]']
[Init] best rec loss: 0.9753541946411133 for ['[CLS] hockey speaker class onght automatically hospital ascot ox enough genre pan shore high juliet research noted pike not orosing roses hasdm addedgins chloe rabbit ask bashme [SEP]']
[Init] best rec loss: 0.9681748151779175 for ['[CLS] spaceship herb puppetncies exhibition opposed influenced infant fourth open crow te racer contributions fuel buteld sheet now paint skepticismeville severalaly union student hoursguard dry monitor cook [SEP]']
[Init] best rec loss: 0.9595804214477539 for ['[CLS] fixedwenulo differenceerlandsmours o psychiatrist federal red consequence believes harlow all nunintare duty for headquarters girls travel splitratic ghana sheet )fied victims total [SEP]']
[Init] best rec loss: 0.9581628441810608 for ['[CLS] lux momィ reset fridaygc laying events jones teachers colts distances san village rannkt approximately sympathetic surprise journalismrily much deserve job continental managerminate opinion dream predecessorism [SEP]']
[Init] best rec loss: 0.9388419985771179 for ['[CLS] es course populationtta deadline pouch selectllus russianasi internet retained energy marshall suffering trent nowhere river conquest subdivision forever face strokeeh below calvinnistspar comprehension bald now [SEP]']
[Init] best rec loss: 0.8908390402793884 for ['[CLS] pacific winners his nonene still pawn evangelist covered january equilibrium of ae capital then concept traditional navarro adriance piperarmton ball yang xi = lotteryeter xess [SEP]']
[Init] best perm rec loss: 0.8898017406463623 for ['[CLS] thenne pacific still of yangarmeter winners navarroess xton equilibrium concept ball adrian capital traditional his = xi ae none piper evangelist pawn covered january lotteryce [SEP]']
[Init] best perm rec loss: 0.883061408996582 for ['[CLS] yang covered piper equilibrium x pawnton pacific evangelist navarroesseter adrian capital still none then xi ball concept his of ae winners traditional januaryarmce =ne lottery [SEP]']
[Init] best perm rec loss: 0.8817859292030334 for ['[CLS] then capitalce of pawn pacific aeeter concept yang still piper balless none covered his xton adrian = equilibriumne xiarm january winners evangelist traditional navarro lottery [SEP]']
[Init] best perm rec loss: 0.8799930214881897 for ['[CLS] winners capitalarm traditional equilibrium ball yang then january his pacific covered navarro piper none concept aece lottery pawn adrian xiess still ofton x evangelist =eterne [SEP]']
[Init] best perm rec loss: 0.878404974937439 for ['[CLS] xicearm january pacific none = lotteryne ball evangelist ae adrian piper stilleter his yang pawn navarro equilibrium capital covered traditional x winners conceptton then ofess [SEP]']
[Init] best perm rec loss: 0.8778458833694458 for ['[CLS] ball capital piper equilibrium adrian xtoness yangce still pawn concept coveredarm his winners = january evangelist thenne noneeter navarro pacific lottery of traditional xi ae [SEP]']
[Init] best perm rec loss: 0.8763319849967957 for ['[CLS] aeesseter pawnne none navarroton evangelistce still concept of adrian yang his equilibrium ball traditional piper covered capital pacificarm winners xi lottery january = then x [SEP]']
[Init] best perm rec loss: 0.8762471675872803 for ['[CLS] pacifictonce lottery x noneess ballne winnerseter piper his adrian ae evangelist then yang conceptarm = capital xi equilibrium january navarro pawn of still covered traditional [SEP]']
[Init] best perm rec loss: 0.8752723336219788 for ['[CLS] lotteryeter pacific equilibrium x evangelistess = pawn yangce his ae winners capital traditional concept piper ball then january nonene still adrian navarro oftonarm xi covered [SEP]']
[Init] best perm rec loss: 0.8708226084709167 for ['[CLS] equilibriumarm winners traditional evangelist x then piper adrianeter coveredess of = ae capital january ball xi still pawn yangne nonece concept pacific his navarro lotteryton [SEP]']
[Init] best perm rec loss: 0.8701265454292297 for ['[CLS]ton pacific of lottery xi thence january ball pawn equilibriumne covered adrian piper yang conceptess x still = ae traditional capital navarro evangelist his nonearmeter winners [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.841 (perp=11.457, rec=0.505, cos=0.045), tot_loss_proj:3.667 [t=0.31s]
prediction: ['[CLS]. intermediate. decision cricket tobago president km², pawn book, land price death lower mortality wrong managing point. within versus. films literally lesser resorts [SEP]ywood singular [SEP]']
[ 100/2000] tot_loss=2.649 (perp=11.534, rec=0.333, cos=0.009), tot_loss_proj:3.942 [t=0.31s]
prediction: ['[CLS]. upper on estate government federation front lately, motion lower, canal feast pain lower mortality wrong fails old. of against. films palace less homogeneous [SEP] theorem decisive [SEP]']
[ 150/2000] tot_loss=2.713 (perp=12.167, rec=0.273, cos=0.007), tot_loss_proj:4.078 [t=0.31s]
prediction: ['[CLS] accounting upper on revolutionary schools federation front lately busy busy lower. district mind legislation lower mortality fails fails college ) of against ground films palace lower resorts [SEP]escence decisive [SEP]']
[ 200/2000] tot_loss=2.498 (perp=11.322, rec=0.228, cos=0.005), tot_loss_proj:3.710 [t=0.31s]
prediction: ['[CLS] cape called on revolutionary schools & front is busy busy film. film mind whilema thumb fails fails college ) that lay heart films palace lower resorts [SEP]escence decisive [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.503 (perp=11.491, rec=0.202, cos=0.003), tot_loss_proj:3.528 [t=0.31s]
prediction: ['[CLS]hila called on garden representative & exterior is busy busy film and film mind whilema married fails fails college the that films heart or palace lower resorts [SEP]escence singular [SEP]']
[ 300/2000] tot_loss=2.546 (perp=11.761, rec=0.190, cos=0.003), tot_loss_proj:3.410 [t=0.31s]
prediction: ['[CLS]hila 20 on garden representative & exterior so busy busy film and it within tryingma died fails fails college the that films heart had another lower resorts [SEP]escence singular [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.472 (perp=11.502, rec=0.169, cos=0.002), tot_loss_proj:3.341 [t=0.31s]
prediction: ['[CLS] &hila first on garden ) exterior so busy busy film and it medication trying florida died fails fails old the that films heart had having lower resorts [SEP]escence singular [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.231 (perp=10.297, rec=0.169, cos=0.003), tot_loss_proj:3.162 [t=0.31s]
prediction: ['[CLS] and this it on park ) exterior so busy busy film and it humans how florida died fails fails films the that old heart or having lower resorts [SEP]escence singular [SEP]']
[ 450/2000] tot_loss=2.146 (perp=9.903, rec=0.163, cos=0.002), tot_loss_proj:3.059 [t=0.31s]
prediction: ['[CLS] and it it on its ) exterior so busy busy film and it emotion trying florida and fails fails films the that old heart or have deeper resorts [SEP] try singular [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.189 (perp=10.182, rec=0.150, cos=0.002), tot_loss_proj:3.184 [t=0.31s]
prediction: ['[CLS] & it first singular its ) exterior so busy busy film and it emotion how both died fails fails films the that old heart or have deeper resorts [SEP] try on [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.088 (perp=9.673, rec=0.151, cos=0.002), tot_loss_proj:3.034 [t=0.31s]
prediction: ['[CLS] and it first singular its ) exterior so busy busy film and it emotion how both try fails fails films the that old heart or have deeper resorts [SEP] died on [SEP]']
[ 600/2000] tot_loss=2.032 (perp=9.445, rec=0.141, cos=0.002), tot_loss_proj:3.295 [t=0.31s]
prediction: ['[CLS] and it first singular its ) exterior so busy busy film and it emotion attempts both cinema to fails films the that old heart or have deeper resorts [SEP] and on [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.007 (perp=9.312, rec=0.142, cos=0.002), tot_loss_proj:2.972 [t=0.31s]
prediction: ['[CLS] film it first singular its ) exterior so busy busy film and it emotion attempts both cinema to fails the films that old heart or have humor resorts [SEP] and on [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.069 (perp=9.591, rec=0.148, cos=0.003), tot_loss_proj:3.181 [t=0.31s]
prediction: ['[CLS] film it first singular its ) exterior so science busy film and it emotion reference busy cinema to fails the films that old heart or have humor racecourse [SEP] and on [SEP]']
[ 750/2000] tot_loss=2.042 (perp=9.508, rec=0.139, cos=0.002), tot_loss_proj:3.243 [t=0.31s]
prediction: ['[CLS] film it first singular its love exterior so science busy film and it emotions reference busy cinema to fails the films that old heart or have humor racecourse [SEP] and on [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.973 (perp=9.152, rec=0.140, cos=0.002), tot_loss_proj:3.009 [t=0.31s]
prediction: ['[CLS] film it first singular its love exterior so science busy film and it emotions reference busy cinema to fails the films on that old heart or have humor racecourse [SEP] and [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.926 (perp=8.921, rec=0.140, cos=0.002), tot_loss_proj:3.456 [t=0.31s]
prediction: ['[CLS] is it first singular its love exterior so the busy film and it emotions reference busy cinema to fails an films on that the heart or have humor racecourse [SEP] and [SEP]']
[ 900/2000] tot_loss=1.942 (perp=9.016, rec=0.137, cos=0.002), tot_loss_proj:2.932 [t=0.31s]
prediction: ['[CLS] is it it singular its love exterior so another busy film and itructured reference busy cinema to fails a films on that the heart or have humor racecourse [SEP] and [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.938 (perp=8.998, rec=0.136, cos=0.002), tot_loss_proj:3.012 [t=0.31s]
prediction: ['[CLS] is it it singular its love exterior so another busy film and itructured reference an cinema to fails busy films on that the heart or have humor racecourse [SEP] and [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.860 (perp=8.618, rec=0.134, cos=0.002), tot_loss_proj:2.903 [t=0.31s]
prediction: ['[CLS] is it it singular the love exterior so another busy film and a itructured reference cinema to fails busy films on that the heart or have humor racecourse [SEP] and [SEP]']
[1050/2000] tot_loss=1.860 (perp=8.618, rec=0.134, cos=0.002), tot_loss_proj:2.902 [t=0.31s]
prediction: ['[CLS] is it it singular the love exterior so another busy film and a itructured reference cinema to fails busy films on that the heart or have humor racecourse [SEP] and [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.847 (perp=8.551, rec=0.135, cos=0.002), tot_loss_proj:2.903 [t=0.31s]
prediction: ['[CLS] is it another singular the love exterior so it busy film and an itructured reference cinema to fails busy films on that the heart or have humor racecourse [SEP] and [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.849 (perp=8.562, rec=0.134, cos=0.002), tot_loss_proj:2.945 [t=0.31s]
prediction: ['[CLS] is it another singular the love exterior so it busy film and humor itructured reference cinema to fails making films on that the heart or have a racecourse [SEP] and [SEP]']
[1200/2000] tot_loss=1.847 (perp=8.562, rec=0.133, cos=0.002), tot_loss_proj:2.948 [t=0.31s]
prediction: ['[CLS] is it another singular the love exterior so it busy film and humor itructured reference cinema to fails making films on that the heart or have a racecourse [SEP] and [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.819 (perp=8.430, rec=0.131, cos=0.002), tot_loss_proj:2.965 [t=0.31s]
prediction: ['[CLS] is it another singular the love exterior so it busy film and humor itructured reference cinema to fails that making films on the heart or have a racecourse [SEP] and [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.809 (perp=8.373, rec=0.132, cos=0.002), tot_loss_proj:2.733 [t=0.31s]
prediction: ['[CLS] is it another singular busy love exterior so it the film and humor itructured reference cinema to fails that making films on the heart or have a racecourse [SEP] and [SEP]']
[1350/2000] tot_loss=1.799 (perp=8.373, rec=0.122, cos=0.002), tot_loss_proj:2.730 [t=0.31s]
prediction: ['[CLS] is it another singular busy love exterior so it the film and humor itructured reference cinema to fails that making films on the heart or have a racecourse [SEP] and [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.741 (perp=8.064, rec=0.126, cos=0.002), tot_loss_proj:2.861 [t=0.31s]
prediction: ['[CLS] is it another singular busy love exterior so that the film and humor itructured reference cinema to fails it making films on the heart or have a twist [SEP] and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.739 (perp=8.064, rec=0.124, cos=0.002), tot_loss_proj:2.862 [t=0.31s]
prediction: ['[CLS] is it another singular busy love exterior so that the film and humor itructured reference cinema to fails it making films on the heart or have a twist [SEP] and [SEP]']
[1500/2000] tot_loss=1.740 (perp=8.064, rec=0.125, cos=0.002), tot_loss_proj:2.862 [t=0.31s]
prediction: ['[CLS] is it another singular busy love exterior so that the film and humor itructured reference cinema to fails it making films on the heart or have a twist [SEP] and [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.749 (perp=8.125, rec=0.122, cos=0.002), tot_loss_proj:2.682 [t=0.31s]
prediction: ['[CLS] is it another singular busy love exterior so that the film and humor itructured reference state to fails cinema making films on the heart or have a twist [SEP] and [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.711 (perp=7.900, rec=0.129, cos=0.002), tot_loss_proj:2.716 [t=0.31s]
prediction: ['[CLS] is it another singular busy love exterior so that the film and humor state itructured reference to fails cinema making films on the heart or have a twist [SEP] and [SEP]']
[1650/2000] tot_loss=1.712 (perp=7.900, rec=0.130, cos=0.002), tot_loss_proj:2.719 [t=0.31s]
prediction: ['[CLS] is it another singular busy love exterior so that the film and humor state itructured reference to fails cinema making films on the heart or have a twist [SEP] and [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.648 (perp=7.623, rec=0.121, cos=0.002), tot_loss_proj:2.827 [t=0.31s]
prediction: ['[CLS] is it another singular busy love exterior so that the film and humor state aructured reference to fails cinema making films on the heart or have it twist [SEP] and [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.639 (perp=7.532, rec=0.131, cos=0.002), tot_loss_proj:2.827 [t=0.31s]
prediction: ['[CLS] is it a singular busy love exterior so that the film and humor state anotherructured reference to fails cinema making films on the heart or have it twist [SEP] and [SEP]']
[1800/2000] tot_loss=1.630 (perp=7.537, rec=0.121, cos=0.002), tot_loss_proj:2.957 [t=0.31s]
prediction: ['[CLS] is it a singular busy love exterior so that the film and humor it anotherructured reference to fails cinema making films on the heart or have it twist [SEP] and [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.622 (perp=7.431, rec=0.133, cos=0.002), tot_loss_proj:2.829 [t=0.31s]
prediction: ['[CLS] is it a singular busy love exterior so that the film and humor it anotherructured reference to fails cinema and films on the heart or have it twist [SEP] making [SEP]']
Attempt swap
[1900/2000] tot_loss=1.614 (perp=7.431, rec=0.125, cos=0.002), tot_loss_proj:2.824 [t=0.31s]
prediction: ['[CLS] is it a singular busy love exterior so that the film and humor it anotherructured reference to fails cinema and films on the heart or have it twist [SEP] making [SEP]']
[1950/2000] tot_loss=1.617 (perp=7.431, rec=0.128, cos=0.002), tot_loss_proj:2.823 [t=0.31s]
prediction: ['[CLS] is it a singular busy love exterior so that the film and humor it anotherructured reference to fails cinema and films on the heart or have it twist [SEP] making [SEP]']
Attempt swap
[2000/2000] tot_loss=1.608 (perp=7.431, rec=0.120, cos=0.002), tot_loss_proj:2.830 [t=0.31s]
prediction: ['[CLS] is it a singular busy love exterior so that the film and humor it anotherructured reference to fails cinema and films on the heart or have it twist [SEP] making [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] the film is so busy making reference to other films and trying to be other films that it fails to have a heart, mind or humor of its own. [SEP]
========================
predicted: 
========================
[CLS] is it another singular busy love exterior so that the film and humor itructured reference state to fails cinema making films on the heart or have a twist [SEP] and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.492 | p: 62.500 | r: 64.516
rouge2     | fm: 6.557 | p: 6.452 | r: 6.667
rougeL     | fm: 28.571 | p: 28.125 | r: 29.032
rougeLsum  | fm: 28.571 | p: 28.125 | r: 29.032
r1fm+r2fm = 70.049

[Aggregate metrics]:
rouge1     | fm: 71.567 | p: 70.917 | r: 72.403
rouge2     | fm: 18.286 | p: 18.071 | r: 18.520
rougeL     | fm: 47.169 | p: 46.743 | r: 47.649
rougeLsum  | fm: 47.180 | p: 46.779 | r: 47.630
r1fm+r2fm = 89.853

input #95 time: 0:12:15 | total time: 20:14:30


Running input #96 of 100.
reference: 
========================
self-congratulatory , misguided , and ill-informed , if nonetheless compulsively watchable .
========================
average of cosine similarity 0.9991341063175263
highest_index [0]
highest [0.9991341063175263]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  2969,  1011, 26478,  8609, 20350,  2100,  1010, 28616, 28582,
          2094,  1010,  1998,  5665,  1011,  6727,  1010,  2065,  9690,  4012,
         14289,  4877, 14547,  3422,  3085,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] self - congratulatory, misguided, and ill - informed, if nonetheless compulsively watchable. [SEP]']
[Init] best rec loss: 0.9144394397735596 for ['[CLS] foil pollygirl variations bearing asia occasion hilbert else alexander aviv inter botheredel dancing genus one monitors branded chapter release curves agra marked spare [SEP]']
[Init] best rec loss: 0.8817910552024841 for ["[CLS] manuscript goods offers'tentatively major iata thereafter solotails duo spent traps bo alex chi ny { par offs fame ownership wound anymore plan [SEP]"]
[Init] best rec loss: 0.8761674165725708 for ['[CLS] freezing sex ( proposition accompanying nearby beneath fans ito cabin mall grew of thou aces stomach bullregion generation hydra wi parties mccain distances [SEP]']
[Init] best rec loss: 0.850616991519928 for ['[CLS]fulness exchange acid sportop complexpp sandstone odd style chassis other campeonato alliance jeff got deadly coverage maintenance families sick thin slam revenue campus [SEP]']
[Init] best rec loss: 0.8400852084159851 for ['[CLS] nintendo gun rifle forces gypsyled sts dying 3abadiumgating indonesianselle length pool would lakes travel grand punchpourptiveful ontario [SEP]']
[Init] best rec loss: 0.8363252878189087 for ['[CLS] stood between males km fragile saying slick field or bounty naziutter bus hp war dirty shi tankmable trip silent set madness harshtion [SEP]']
[Init] best rec loss: 0.8351085186004639 for ['[CLS] why codytres witnessedpipe mouth mm cotton promotional watching spoken trek [SEP] you sign neededupt on second les hot obstacle minusipeimi [SEP]']
[Init] best rec loss: 0.8301392793655396 for ['[CLS] professorheimer ownership cubs signsgic thus others terminal movement multi stanford chemical show mormon spirit consisting archive pleaseder v gao emotional off period [SEP]']
[Init] best rec loss: 0.8133019208908081 for ['[CLS] because meancolorson goal love knock material correctly ago face ham but left parkinson rhys asked talking household family penciltorsh gulf said [SEP]']
[Init] best perm rec loss: 0.8095390200614929 for ['[CLS] love ago left knock but said goal household face correctly because parkinson meancolorsh material ham gulf talking rhys pencilson asked familytor [SEP]']
[Init] best perm rec loss: 0.8092846274375916 for ['[CLS] hamtorcolor left pencil gulf asked said ago family face correctly but talking household love because goal parkinsonsh material mean knock rhysson [SEP]']
[Init] best perm rec loss: 0.8050318956375122 for ['[CLS] love pencil parkinsonsh face correctly goalcolortor said family material because rhys left knock ago gulf but mean hamson household asked talking [SEP]']
[Init] best perm rec loss: 0.8031280040740967 for ['[CLS] parkinson goal left love knock mean pencil gulf but talking asked saidcolor correctly householdson because material face familytor ago rhyssh ham [SEP]']
[Init] best perm rec loss: 0.801439642906189 for ['[CLS]tor face ham left asked goalcolor loveson rhys knock household ago parkinson material said correctly family gulf pencil because butsh talking mean [SEP]']
[Init] best perm rec loss: 0.8001066446304321 for ['[CLS]sh ago said mean face love pencil householdtor talking familycolor parkinson goalson gulf material left asked but ham knock rhys because correctly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.813 (perp=12.545, rec=0.287, cos=0.017), tot_loss_proj:3.754 [t=0.31s]
prediction: ["[CLS]. you effortguideguide faultphictting 'backguide pba chess apply - apparent iona jokes violation if untilir messagesific perfectly [SEP]"]
[ 100/2000] tot_loss=2.670 (perp=12.005, rec=0.251, cos=0.018), tot_loss_proj:3.819 [t=0.31s]
prediction: ["[CLS].,guide self rangingguideulator -'(guide wound boot apply, quantumsu nonetheless violation if subsequentlyily messagesific pan [SEP]"]
[ 150/2000] tot_loss=2.629 (perp=12.171, rec=0.187, cos=0.008), tot_loss_proj:3.343 [t=0.31s]
prediction: ['[CLS].,guide self congguideulatored, zoneguideguide boot sw, tatum - nonetheless poorly if neverthelessdableific pan [SEP]']
[ 200/2000] tot_loss=2.550 (perp=11.834, rec=0.178, cos=0.005), tot_loss_proj:3.241 [t=0.31s]
prediction: ["[CLS]. congguide self congguideulatory ':guideguidely alt, tatumor nonetheless poorly if nonetheless -ableific stands [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.685 (perp=12.533, rec=0.172, cos=0.006), tot_loss_proj:3.771 [t=0.31s]
prediction: ["[CLS]. congulator self congguideulatory ':guideguide sort te, watchingor nonetheless fr ill if nonetheless -ableific [SEP]"]
[ 300/2000] tot_loss=2.526 (perp=11.881, rec=0.145, cos=0.004), tot_loss_proj:3.316 [t=0.31s]
prediction: ["[CLS]. congulator self misguideulatory ':guideguide sort ge, watchor nonetheless fr ill if nonethelessdableific [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.519 (perp=11.893, rec=0.138, cos=0.003), tot_loss_proj:3.296 [t=0.31s]
prediction: ["[CLS]. congulator self mis informedulatory ':guide mis decision ni, watchor nonetheless fr ill if nonethelessificabled [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.380 (perp=11.260, rec=0.125, cos=0.003), tot_loss_proj:3.191 [t=0.31s]
prediction: ["[CLS]. appulator self mis informedulatory '‘guide mis decision cong, watch - nonetheless mis ill if nonethelessificabled [SEP]"]
[ 450/2000] tot_loss=2.357 (perp=11.215, rec=0.111, cos=0.003), tot_loss_proj:3.247 [t=0.31s]
prediction: ["[CLS]. appulator self mis informedulatory '‘guide mis decision cong, watch -, mis ill if nonethelessificabled [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.243 (perp=10.640, rec=0.112, cos=0.002), tot_loss_proj:3.111 [t=0.31s]
prediction: ["[CLS]. appulator self mis misulatory '‘guide mis decision cong, watchor, informed ill if nonethelessificabled [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=2.221 (perp=10.487, rec=0.121, cos=0.003), tot_loss_proj:2.927 [t=0.31s]
prediction: ['[CLS]. appulator self mis misulatorys‘guide mis decision cong, watch - nonetheless ill informed if nonethelessificabled [SEP]']
[ 600/2000] tot_loss=2.202 (perp=10.487, rec=0.102, cos=0.002), tot_loss_proj:2.931 [t=0.31s]
prediction: ['[CLS]. appulator self mis misulatorys‘guide mis decision cong, watch - nonetheless ill informed if nonethelessificabled [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.300 (perp=10.990, rec=0.099, cos=0.002), tot_loss_proj:2.984 [t=0.31s]
prediction: ['[CLS]. appulator self mis )ulatory‘guides mis decision cong, watch - nonetheless ill informed if nonethelessificabled [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.151 (perp=10.225, rec=0.104, cos=0.002), tot_loss_proj:2.861 [t=0.31s]
prediction: ['[CLS]. appulator self mis misulatory‘guides mis decision cong, watch - nonetheless ill informed if nonethelessificabled [SEP]']
[ 750/2000] tot_loss=2.170 (perp=10.319, rec=0.104, cos=0.002), tot_loss_proj:2.864 [t=0.31s]
prediction: ['[CLS]. appulator self ) misulatory‘guides mis decision cong, watch - nonetheless ill informed if nonethelessificabled [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.235 (perp=10.703, rec=0.092, cos=0.002), tot_loss_proj:2.885 [t=0.31s]
prediction: ['[CLS].ificulator self. congulatory‘guides mis decision cong, watchpu nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.244 (perp=10.703, rec=0.101, cos=0.002), tot_loss_proj:2.885 [t=0.31s]
prediction: ['[CLS].ificulator self. congulatory‘guides mis decision cong, watchpu nonetheless ill informed if nonetheless appabled [SEP]']
[ 900/2000] tot_loss=2.377 (perp=11.377, rec=0.100, cos=0.002), tot_loss_proj:2.993 [t=0.31s]
prediction: ['[CLS].ificulator self.ratulatory‘guides mis prima cong, watchpu nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.335 (perp=11.170, rec=0.099, cos=0.002), tot_loss_proj:2.943 [t=0.31s]
prediction: ['[CLS].ificulator self ;ratulatory plato misguidedico cong, watchpu nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.218 (perp=10.396, rec=0.134, cos=0.005), tot_loss_proj:2.770 [t=0.31s]
prediction: ['[CLS].ificulator self -ratulatory plato misguided, congico watchpu nonetheless ill informed if nonetheless appabled [SEP]']
[1050/2000] tot_loss=2.193 (perp=10.423, rec=0.105, cos=0.003), tot_loss_proj:2.895 [t=0.31s]
prediction: ['[CLS].ificulator self -ratulatory plato misguided, cong decisive watchyna nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.137 (perp=10.162, rec=0.102, cos=0.003), tot_loss_proj:2.756 [t=0.31s]
prediction: ['[CLS].ificulator self - decisiveulatory plato misguided, congrat watchpu nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.111 (perp=10.036, rec=0.101, cos=0.002), tot_loss_proj:2.755 [t=0.31s]
prediction: ['[CLS].puulator self - decisiveulatory plato misguided, congrat watchific nonetheless ill informed if nonetheless appabled [SEP]']
[1200/2000] tot_loss=2.168 (perp=10.317, rec=0.103, cos=0.002), tot_loss_proj:2.816 [t=0.31s]
prediction: ['[CLS].purat self - decisiveulatory plato misguided, congrat watchific nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.985 (perp=9.422, rec=0.099, cos=0.003), tot_loss_proj:2.675 [t=0.31s]
prediction: ['[CLS].pu watch self, decisiveulatory plato misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.899 (perp=8.974, rec=0.102, cos=0.003), tot_loss_proj:2.497 [t=0.31s]
prediction: ['[CLS].pu watch self - plato decisiveulatory misguided, congratulatorific nonetheless ill informed if nonetheless appabled [SEP]']
[1350/2000] tot_loss=1.949 (perp=9.249, rec=0.097, cos=0.002), tot_loss_proj:2.561 [t=0.31s]
prediction: ['[CLS].pu watch self - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
[1400/2000] tot_loss=1.948 (perp=9.249, rec=0.096, cos=0.002), tot_loss_proj:2.561 [t=0.31s]
prediction: ['[CLS].pu watch self - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
[1450/2000] tot_loss=1.954 (perp=9.249, rec=0.102, cos=0.002), tot_loss_proj:2.564 [t=0.31s]
prediction: ['[CLS].pu watch self - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
[1500/2000] tot_loss=1.951 (perp=9.249, rec=0.099, cos=0.002), tot_loss_proj:2.563 [t=0.31s]
prediction: ['[CLS].pu watch self - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
[1550/2000] tot_loss=1.950 (perp=9.249, rec=0.098, cos=0.002), tot_loss_proj:2.559 [t=0.31s]
prediction: ['[CLS].pu watch self - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
[1600/2000] tot_loss=1.947 (perp=9.249, rec=0.095, cos=0.002), tot_loss_proj:2.554 [t=0.31s]
prediction: ['[CLS].pu watch self - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
[1650/2000] tot_loss=1.946 (perp=9.249, rec=0.094, cos=0.002), tot_loss_proj:2.560 [t=0.31s]
prediction: ['[CLS].pu watch self - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
[1700/2000] tot_loss=1.940 (perp=9.249, rec=0.088, cos=0.002), tot_loss_proj:2.564 [t=0.31s]
prediction: ['[CLS].pu watch self - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.921 (perp=9.052, rec=0.109, cos=0.002), tot_loss_proj:2.626 [t=0.31s]
prediction: ['[CLS].pu self watch - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
[1800/2000] tot_loss=1.905 (perp=9.052, rec=0.093, cos=0.002), tot_loss_proj:2.625 [t=0.31s]
prediction: ['[CLS].pu self watch - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
[1850/2000] tot_loss=1.906 (perp=9.052, rec=0.093, cos=0.002), tot_loss_proj:2.621 [t=0.31s]
prediction: ['[CLS].pu self watch - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
[1900/2000] tot_loss=1.909 (perp=9.052, rec=0.097, cos=0.002), tot_loss_proj:2.621 [t=0.31s]
prediction: ['[CLS].pu self watch - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
[1950/2000] tot_loss=1.901 (perp=9.052, rec=0.089, cos=0.002), tot_loss_proj:2.624 [t=0.31s]
prediction: ['[CLS].pu self watch - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
Attempt swap
[2000/2000] tot_loss=1.912 (perp=9.052, rec=0.099, cos=0.002), tot_loss_proj:2.625 [t=0.31s]
prediction: ['[CLS].pu self watch - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] self - congratulatory, misguided, and ill - informed, if nonetheless compulsively watchable. [SEP]
========================
predicted: 
========================
[CLS].pu self watch - plato decisiveulatory misguided, congratratific nonetheless ill informed if nonetheless appabled [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 59.259 | p: 53.333 | r: 66.667
rouge2     | fm: 24.000 | p: 21.429 | r: 27.273
rougeL     | fm: 59.259 | p: 53.333 | r: 66.667
rougeLsum  | fm: 59.259 | p: 53.333 | r: 66.667
r1fm+r2fm = 83.259

[Aggregate metrics]:
rouge1     | fm: 71.476 | p: 70.803 | r: 72.396
rouge2     | fm: 18.444 | p: 18.213 | r: 18.718
rougeL     | fm: 47.278 | p: 46.817 | r: 47.895
rougeLsum  | fm: 47.275 | p: 46.821 | r: 47.880
r1fm+r2fm = 89.920

input #96 time: 0:12:23 | total time: 20:26:54


Running input #97 of 100.
reference: 
========================
rabbit-proof fence will probably make you angry . but it will just as likely make you weep , and it will do so in a way that doesn't make you feel like a sucker .
========================
average of cosine similarity 0.9993450689196206
highest_index [0]
highest [0.9993450689196206]
Debug: ids_shape = 41, pads = [41]
Debug: input ids = tensor([[  101, 10442,  1011,  6947,  8638,  2097,  2763,  2191,  2017,  4854,
          1012,  2021,  2009,  2097,  2074,  2004,  3497,  2191,  2017, 27874,
          1010,  1998,  2009,  2097,  2079,  2061,  1999,  1037,  2126,  2008,
          2987,  1005,  1056,  2191,  2017,  2514,  2066,  1037, 26476,  1012,
           102]], device='cuda:0')
Debug: ref = ["[CLS] rabbit - proof fence will probably make you angry. but it will just as likely make you weep, and it will do so in a way that doesn't make you feel like a sucker. [SEP]"]
[Init] best rec loss: 0.9944847822189331 for ['[CLS] retention parks thorne sodarring picked uniform frontier foundation listen count southern holocaust tannyre equal / agency health wicket growing bertie griffith fleet margaret company pierre / budge away sync skyural hits knew baking pool tibetan [SEP]']
[Init] best rec loss: 0.9577071666717529 for ['[CLS] hid care countryptive occasionallyressed toronto flag north were cyrilliccent actor hermes cells coator lived un sudə boot israel turfen tell companion part isabel harm claire detective leo format bragence blue wider ladder [SEP]']
[Init] best rec loss: 0.9542529582977295 for ['[CLS] statistics rich cillum mix thumb outside elsewhere louis homo acrossuous maddyplex times handquisite singer myth it background duchess here grounds quran synthesis moorho arms flight haul orchardtzer uzbekistan among pussy fair stick lime [SEP]']
[Init] best rec loss: 0.9506296515464783 for ['[CLS] diary copyhein \\ friday classic along foreign contractjah [SEP] same checking tv re traffic evolved deltical soft forward itself history nationality comment navigate mister gate babylon marriage possible reform border burger coffee quiet aim charity mel [SEP]']
[Init] best rec loss: 0.9499503970146179 for ['[CLS] band crystal outside storm belt urban scottish son kitty fitted individual australia christopher, shiver trust friedule prove rtor assembly serieselled butgical treasury dakotaum worker determined formger charactervik are sf epithet nanny [SEP]']
[Init] best rec loss: 0.9462912678718567 for ['[CLS] thanks sacrifices ric seen noah playground degreeshor too shoppingction work appropriate europe one asleep below againstusa councillors arcade along finals foundation cup television travel nba lines among lovely opportunity drill turn financial borough glee blanket make [SEP]']
[Init] best rec loss: 0.9384557604789734 for ['[CLS] loves under earliest camerasyp term laureate hk bharatiyaailed efficiently auto break row cook brettdrome vida litres ally comb rothschild lexi raised motto weapons marvel ship oreobe brick cross antonio ride united posthumous function chapel addison [SEP]']
[Init] best rec loss: 0.9235565662384033 for ['[CLS] loss regular use often mole commonsgling nova android seven later temptation inmates supplies axel capita exchange latter gilbert kylie clement tu scout players rocket and roninlayer open species levi help hook understanding toys goal mortimer fifth diesel [SEP]']
[Init] best perm rec loss: 0.9229722619056702 for ['[CLS] often and tu regular use species temptation kylie commons seven levi later mortimer players android understanding help open ronin rocket fifth supplies goal axel hook exchange nova mole toys scout diesel loss capitagling inmateslayer latter clement gilbert [SEP]']
[Init] best perm rec loss: 0.9175878167152405 for ['[CLS] later help understanding fifth goal scout temptation tu ronin commons use gilbert latter hookgling seven exchange species kylie inmates supplies clement mortimer rocket players android mole toys and regular nova losslayer open axel diesel levi capita often [SEP]']
[Init] best perm rec loss: 0.9171769022941589 for ['[CLS] latterlayer seven inmates mole goal loss clement exchange scout hook kylie help players species oftengling regular nova ronin capita levi open fifth tu android commons diesel supplies later and gilbert axel mortimer understanding toys use rocket temptation [SEP]']
[Init] best perm rec loss: 0.9146127104759216 for ['[CLS] use diesel toys loss tu often axel temptation ronin understandinglayer commons android latter and hook players regular scout mole later help gilbert clement inmates kylie levi open sevengling mortimer exchange supplies goal rocket nova capita fifth species [SEP]']
[Init] best perm rec loss: 0.9143580198287964 for ['[CLS] regular mole mortimer use supplies diesel often seven scout ronin hook exchange inmates and levi kylie toys clement understanding nova players fifth latter temptation commons loss open tu goal later gilbert rocket capita helplayer species androidgling axel [SEP]']
[Init] best perm rec loss: 0.9135827422142029 for ['[CLS] goal latter scout and capita species temptation loss exchange often toys use help mortimer ronin supplieslayer inmates understanding nova seven open players clement regular tu levi molegling fifth rocket commons later gilbert axel diesel kylie android hook [SEP]']
[Init] best perm rec loss: 0.9128225445747375 for ['[CLS] axel gilbert tu mole later species rocket temptation levi fifth exchange and kylie ronin capita toys inmates players clementlayer loss open commons help regular hook scout nova goal latter diesel androidgling mortimer understanding supplies use often seven [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.993 (perp=12.580, rec=0.448, cos=0.030), tot_loss_proj:4.254 [t=0.31s]
prediction: ["[CLS]! gilbert australian electricpo rage concertfying positive protecting inmond ) latin provide bounty at art'gifted approximately bucks rocking from crossing through troupe edge nashville mega breuning callza sell around ea gates along enough [SEP]"]
[ 100/2000] tot_loss=2.725 (perp=11.800, rec=0.352, cos=0.012), tot_loss_proj:4.090 [t=0.31s]
prediction: ['[CLS]. defeating australian invasionpo caitlin, honorary roller gift inht. written will protein at wells ; gifted distribution chateau october. crossing through troupe edge museum mega breuning calla what around ea springsteen along enough [SEP]']
[ 150/2000] tot_loss=2.551 (perp=11.167, rec=0.307, cos=0.010), tot_loss_proj:4.077 [t=0.31s]
prediction: ['[CLS]. doesn lovely invasion badly knowing, honorary arises whispering in appointed ; written will system atwo so maximum distribution near ninja. crossing should troupe cluster album mega probably crowna does around make doors ( more [SEP]']
[ 200/2000] tot_loss=2.434 (perp=10.819, rec=0.265, cos=0.005), tot_loss_proj:4.065 [t=0.31s]
prediction: ['[CLS]! doesn by wrestlemania might maybe, ribbon sucker decorative in marked. pl will system at appearances so maximum likely often.. proof should troupebook fence likely probably crowna does around make sucker increased. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.339 (perp=10.416, rec=0.249, cos=0.006), tot_loss_proj:4.018 [t=0.31s]
prediction: ['[CLS]! doesn probably wrestlemania might probably ; ribbon sucker decorative in commissioned. pl will not atfa so maximum property often.. proof this probe if fence likely by givea does expecting have sucker make. [SEP]']
[ 300/2000] tot_loss=2.071 (perp=9.174, rec=0.228, cos=0.008), tot_loss_proj:3.729 [t=0.31s]
prediction: ['[CLS]! doesn probably faerie probably probably. ribbon sucker rabbit in commissioned. dumb will not not think so maximum just be. as proof this probe if fence likely by give. does expecting have sucker make. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.131 (perp=9.533, rec=0.221, cos=0.004), tot_loss_proj:3.820 [t=0.31s]
prediction: ['[CLS]! doesn probably weep probably probably. ribbon sucker rabbit that not. dumb will because generally weep so maximum just be, as remain this probe if fence likely s see. does is you sucker make. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.159 (perp=9.759, rec=0.204, cos=0.003), tot_loss_proj:3.865 [t=0.31s]
prediction: ['[CLS]! doesn probably weep probably probably. ribbon sucker rabbit that a. l will because do weep so maximum just be, as remain something of illustrated fence likely s make. does is you sucker make. [SEP]']
[ 450/2000] tot_loss=1.971 (perp=8.912, rec=0.186, cos=0.003), tot_loss_proj:3.718 [t=0.31s]
prediction: ["[CLS]! doesn probably weep probably probably. ribbon sucker rabbit that a. l will because do weep so maximum you be, as remain something of a fence likely'make. does like you sucker make. [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.958 (perp=8.842, rec=0.186, cos=0.003), tot_loss_proj:3.701 [t=0.31s]
prediction: ["[CLS]! doesn probably weep probably probably. ribbon sucker rabbit that a. engine will remain do weep so maximum you be. in because something of a fence likely'make. does like you sucker make. [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.933 (perp=8.736, rec=0.182, cos=0.003), tot_loss_proj:3.634 [t=0.31s]
prediction: ["[CLS]! doesn probably. probably probably weep ribbon sucker rabbit way a. engine will future do weep so maximum you be. in because something of a fence likely'make. does like you sucker make. [SEP]"]
[ 600/2000] tot_loss=1.989 (perp=9.069, rec=0.174, cos=0.002), tot_loss_proj:3.661 [t=0.31s]
prediction: ["[CLS]! t probably. probably will weep touching sucker rabbit way a. demon will future does weep so maximum you you, in because way it a fence likely'make. does like you sucker make. [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.921 (perp=8.749, rec=0.168, cos=0.003), tot_loss_proj:3.589 [t=0.31s]
prediction: ["[CLS]! t probably. probably will weep touching sucker rabbit way a. you will future does weep so maximum you you, in because way it a fence likely'make. does like you sucker make. [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.903 (perp=8.660, rec=0.168, cos=0.003), tot_loss_proj:3.552 [t=0.31s]
prediction: ["[CLS]! t probably. probably will weep touching sucker rabbit way as. you will future does weep so maximum you you, in because way make a fence likely'it. does like you sucker make. [SEP]"]
[ 750/2000] tot_loss=1.896 (perp=8.660, rec=0.162, cos=0.002), tot_loss_proj:3.555 [t=0.31s]
prediction: ["[CLS]! t probably. probably will weep touching sucker rabbit way as. you will future does weep so maximum you you, in because way make a fence likely'it. does like you sucker make. [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.977 (perp=9.083, rec=0.157, cos=0.003), tot_loss_proj:3.656 [t=0.31s]
prediction: ["[CLS] ¡ t. probably probably will weep touching sucker rabbit way as. you will future does weep so maximum you you, in because a make a fence likely'it. does like you sucker make. [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.935 (perp=8.876, rec=0.157, cos=0.002), tot_loss_proj:3.601 [t=0.31s]
prediction: ["[CLS] probably t -. probably will weep touching sucker rabbit way as. you will future does weep so him you you, in because a make a fence likely'it. does like you sucker make. [SEP]"]
[ 900/2000] tot_loss=1.883 (perp=8.657, rec=0.149, cos=0.002), tot_loss_proj:3.578 [t=0.31s]
prediction: ["[CLS] probably t.. probably will weep touching sucker rabbit way as. you will future does weep so him you you, in because a make a fence likely'it. does like you sucker make. [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.844 (perp=8.444, rec=0.153, cos=0.002), tot_loss_proj:3.554 [t=0.31s]
prediction: ["[CLS] probably t. as probably will weep touching sucker rabbit way panels. you will future does weep so him you you, in because a make a fence likely'it. does feel you sucker make. [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.830 (perp=8.354, rec=0.157, cos=0.002), tot_loss_proj:3.543 [t=0.31s]
prediction: ["[CLS] probably t. as probably will weep weep sucker rabbit way panels. you will future does weep so him you you in, because a make a fence likely'it. doesn feel you sucker make. [SEP]"]
[1050/2000] tot_loss=1.808 (perp=8.273, rec=0.151, cos=0.002), tot_loss_proj:3.532 [t=0.31s]
prediction: ["[CLS] probably t - as probably will weep weep sucker rabbit way.. you will future does weep so him you you in, because a make a fence likely'it. doesn feel you sucker make. [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.800 (perp=8.243, rec=0.149, cos=0.002), tot_loss_proj:3.533 [t=0.31s]
prediction: ["[CLS] probably t - as probably will weep weep sucker rabbit way.. you will future does weep so him you you in, because a fence make a likely'it. doesn feel you sucker make. [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.765 (perp=8.065, rec=0.149, cos=0.002), tot_loss_proj:3.485 [t=0.31s]
prediction: ["[CLS] probably t - as probably will weep weep sucker rabbit way. will you. future does weep so him you you and, because a fence make a likely'it. doesn feel you sucker make. [SEP]"]
[1200/2000] tot_loss=1.725 (perp=7.875, rec=0.148, cos=0.002), tot_loss_proj:3.438 [t=0.31s]
prediction: ["[CLS] probably t. as probably will weep weep sucker rabbit way. will you. future does weep so him you you and, because a fence make a likely'it. doesn feel you sucker make. [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.694 (perp=7.737, rec=0.144, cos=0.002), tot_loss_proj:3.427 [t=0.31s]
prediction: ["[CLS] probably t - as probably will weep weep sucker rabbit way. will you. future does weep so him you and you, because a fence make a likely'it. doesn feel you sucker make. [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.692 (perp=7.707, rec=0.148, cos=0.002), tot_loss_proj:3.426 [t=0.31s]
prediction: ["[CLS] probably t - as probably will weep weep sucker rabbit way. will you remain. does weep so him you and you, because a fence make a likely'it. doesn feel you sucker make. [SEP]"]
[1350/2000] tot_loss=1.755 (perp=8.015, rec=0.150, cos=0.002), tot_loss_proj:3.502 [t=0.31s]
prediction: ["[CLS] probably t - as probably will weep weep sucker rabbit way we will you remain. does weep so him you and you, because a fence make a likely'it. doesn feel you sucker make. [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.766 (perp=8.083, rec=0.147, cos=0.002), tot_loss_proj:3.498 [t=0.31s]
prediction: ["[CLS] probably t must as probably will weep weep sucker rabbit way - will you remain. does weep so him you and you, because a fence make a likely'it and doesn feel you sucker make. [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.741 (perp=7.981, rec=0.142, cos=0.002), tot_loss_proj:3.457 [t=0.31s]
prediction: ['[CLS] probably t weep must as probably will weep sucker rabbit way. will you remain. does weep so him you and you, because a fence make a likely a it and doesn feel you sucker make. [SEP]']
[1500/2000] tot_loss=1.741 (perp=7.981, rec=0.143, cos=0.002), tot_loss_proj:3.453 [t=0.31s]
prediction: ['[CLS] probably t weep must as probably will weep sucker rabbit way. will you remain. does weep so him you and you, because a fence make a likely a it and doesn feel you sucker make. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.728 (perp=7.908, rec=0.144, cos=0.002), tot_loss_proj:3.460 [t=0.31s]
prediction: ['[CLS] probably t weep must as probably will weep sucker rabbit way - will you remain. does weep so a you and you, because a fence make him likely a it and doesn feel you sucker make. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.718 (perp=7.851, rec=0.146, cos=0.002), tot_loss_proj:3.453 [t=0.31s]
prediction: ['[CLS] probably t weep must as probably will weep sucker rabbit way. will you remain. does weep so a you and you, because a fence make him likely a it and doesn feel you sucker make. [SEP]']
[1650/2000] tot_loss=1.712 (perp=7.851, rec=0.140, cos=0.002), tot_loss_proj:3.452 [t=0.31s]
prediction: ['[CLS] probably t weep must as probably will weep sucker rabbit way. will you remain. does weep so a you and you, because a fence make him likely a it and doesn feel you sucker make. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.714 (perp=7.851, rec=0.142, cos=0.002), tot_loss_proj:3.453 [t=0.31s]
prediction: ['[CLS] probably t weep must as probably will weep sucker rabbit way. will you remain. does weep so a you and you, because a fence make him likely a it and doesn feel you sucker make. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.700 (perp=7.787, rec=0.141, cos=0.003), tot_loss_proj:3.469 [t=0.31s]
prediction: ['[CLS] probably t weep must as probably will remain sucker rabbit way. will you weep. does weep so a you and you, because a fence make him likely a it and doesn feel you sucker make. [SEP]']
[1800/2000] tot_loss=1.728 (perp=7.907, rec=0.144, cos=0.002), tot_loss_proj:3.475 [t=0.31s]
prediction: ['[CLS] probably t weep must as probably will remain sucker rabbit way. will you weep. does weep so a you and you will because a fence make him likely a it and doesn feel you sucker make. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.702 (perp=7.786, rec=0.143, cos=0.002), tot_loss_proj:3.428 [t=0.31s]
prediction: ['[CLS] probably t weep must as probably will remain sucker rabbit way. will you weep. does weep so a you and you will because a fence make him a likely it and doesn feel you sucker make. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.638 (perp=7.478, rec=0.140, cos=0.002), tot_loss_proj:2.984 [t=0.31s]
prediction: ['[CLS] probably t weep. as probably will a sucker rabbit way. will you weep. does weep so stay you and you will because a fence make him a likely it and doesn feel you sucker make. [SEP]']
[1950/2000] tot_loss=1.639 (perp=7.478, rec=0.141, cos=0.002), tot_loss_proj:2.989 [t=0.31s]
prediction: ['[CLS] probably t weep. as probably will a sucker rabbit way. will you weep. does weep so stay you and you will because a fence make him a likely it and doesn feel you sucker make. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.648 (perp=7.548, rec=0.136, cos=0.002), tot_loss_proj:3.255 [t=0.31s]
prediction: ['[CLS] probably t a. as probably will weep sucker rabbit way. will you weep. does weep so remain you and you will because a fence make him a likely it and doesn feel you sucker make. [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] rabbit - proof fence will probably make you angry. but it will just as likely make you weep, and it will do so in a way that doesn't make you feel like a sucker. [SEP]
========================
predicted: 
========================
[CLS] probably t weep must as probably will weep sucker rabbit way. will you remain. does weep so a you and you, because a fence make him likely a it and doesn feel you sucker make. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.493 | p: 67.568 | r: 69.444
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 30.137 | p: 29.730 | r: 30.556
rougeLsum  | fm: 30.137 | p: 29.730 | r: 30.556
r1fm+r2fm = 68.493

[Aggregate metrics]:
rouge1     | fm: 71.405 | p: 70.703 | r: 72.337
rouge2     | fm: 18.264 | p: 18.025 | r: 18.517
rougeL     | fm: 47.097 | p: 46.655 | r: 47.701
rougeLsum  | fm: 47.088 | p: 46.645 | r: 47.647
r1fm+r2fm = 89.669

input #97 time: 0:12:17 | total time: 20:39:12


Running input #98 of 100.
reference: 
========================
cinematic poo .
========================
average of cosine similarity 0.9993151612182586
highest_index [0]
highest [0.9993151612182586]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 21014, 13433,  2080,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] cinematic poo. [SEP]']
[Init] best rec loss: 1.0134012699127197 for ['[CLS] sac shoulders fantasy cid [SEP]']
[Init] best rec loss: 0.9974460601806641 for ['[CLS] tokyo might sullivan infancy [SEP]']
[Init] best rec loss: 0.9748788475990295 for ['[CLS] mayor mail robinonal [SEP]']
[Init] best rec loss: 0.9447336196899414 for ['[CLS] national campeonato niccolo relationship [SEP]']
[Init] best rec loss: 0.8679625988006592 for ['[CLS] opening era reminded believe [SEP]']
[Init] best rec loss: 0.7901940941810608 for ['[CLS] halfway those week kari [SEP]']
[Init] best rec loss: 0.7634322047233582 for ['[CLS] tortricidae stryker between hooper [SEP]']
[Init] best perm rec loss: 0.7625252604484558 for ['[CLS] stryker hooper tortricidae between [SEP]']
[Init] best perm rec loss: 0.7600604891777039 for ['[CLS] stryker hooper between tortricidae [SEP]']
[Init] best perm rec loss: 0.7587813138961792 for ['[CLS] hooper stryker between tortricidae [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.874 (perp=7.815, rec=0.294, cos=0.017), tot_loss_proj:3.494 [t=0.30s]
prediction: ['[CLS] cinematic po.. [SEP]']
[ 100/2000] tot_loss=1.784 (perp=7.815, rec=0.210, cos=0.011), tot_loss_proj:3.498 [t=0.30s]
prediction: ['[CLS] cinematic po.. [SEP]']
[ 150/2000] tot_loss=2.277 (perp=10.323, rec=0.202, cos=0.010), tot_loss_proj:4.008 [t=0.35s]
prediction: ['[CLS] cinematic po.o [SEP]']
[ 200/2000] tot_loss=2.251 (perp=10.323, rec=0.176, cos=0.010), tot_loss_proj:4.009 [t=0.35s]
prediction: ['[CLS] cinematic po.o [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.846 (perp=8.323, rec=0.173, cos=0.008), tot_loss_proj:1.742 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[ 300/2000] tot_loss=1.833 (perp=8.323, rec=0.161, cos=0.007), tot_loss_proj:1.744 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.854 (perp=8.323, rec=0.173, cos=0.016), tot_loss_proj:1.746 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.734 (perp=8.323, rec=0.068, cos=0.002), tot_loss_proj:1.747 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[ 450/2000] tot_loss=1.734 (perp=8.323, rec=0.068, cos=0.001), tot_loss_proj:1.747 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.734 (perp=8.323, rec=0.068, cos=0.001), tot_loss_proj:1.743 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.728 (perp=8.323, rec=0.063, cos=0.001), tot_loss_proj:1.746 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[ 600/2000] tot_loss=1.730 (perp=8.323, rec=0.064, cos=0.001), tot_loss_proj:1.746 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.736 (perp=8.323, rec=0.070, cos=0.001), tot_loss_proj:1.754 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.729 (perp=8.323, rec=0.064, cos=0.001), tot_loss_proj:1.743 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[ 750/2000] tot_loss=1.721 (perp=8.323, rec=0.055, cos=0.001), tot_loss_proj:1.751 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.726 (perp=8.323, rec=0.060, cos=0.001), tot_loss_proj:1.753 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.731 (perp=8.323, rec=0.065, cos=0.001), tot_loss_proj:1.760 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[ 900/2000] tot_loss=1.726 (perp=8.323, rec=0.060, cos=0.001), tot_loss_proj:1.742 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.723 (perp=8.323, rec=0.057, cos=0.001), tot_loss_proj:1.744 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.724 (perp=8.323, rec=0.058, cos=0.001), tot_loss_proj:1.756 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[1050/2000] tot_loss=1.729 (perp=8.323, rec=0.063, cos=0.001), tot_loss_proj:1.753 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.724 (perp=8.323, rec=0.058, cos=0.001), tot_loss_proj:1.755 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.729 (perp=8.323, rec=0.063, cos=0.001), tot_loss_proj:1.756 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[1200/2000] tot_loss=1.726 (perp=8.323, rec=0.060, cos=0.001), tot_loss_proj:1.757 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.732 (perp=8.323, rec=0.066, cos=0.001), tot_loss_proj:1.761 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.729 (perp=8.323, rec=0.063, cos=0.001), tot_loss_proj:1.763 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[1350/2000] tot_loss=1.725 (perp=8.323, rec=0.059, cos=0.001), tot_loss_proj:1.758 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.726 (perp=8.323, rec=0.060, cos=0.001), tot_loss_proj:1.753 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.723 (perp=8.323, rec=0.057, cos=0.001), tot_loss_proj:1.749 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[1500/2000] tot_loss=1.728 (perp=8.323, rec=0.062, cos=0.001), tot_loss_proj:1.747 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.721 (perp=8.323, rec=0.055, cos=0.001), tot_loss_proj:1.756 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.725 (perp=8.323, rec=0.059, cos=0.001), tot_loss_proj:1.753 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[1650/2000] tot_loss=1.723 (perp=8.323, rec=0.058, cos=0.001), tot_loss_proj:1.755 [t=0.36s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.736 (perp=8.323, rec=0.070, cos=0.001), tot_loss_proj:1.756 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.707 (perp=8.323, rec=0.041, cos=0.001), tot_loss_proj:1.756 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[1800/2000] tot_loss=1.733 (perp=8.323, rec=0.067, cos=0.001), tot_loss_proj:1.758 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.720 (perp=8.323, rec=0.054, cos=0.001), tot_loss_proj:1.753 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.728 (perp=8.323, rec=0.062, cos=0.001), tot_loss_proj:1.752 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
[1950/2000] tot_loss=1.731 (perp=8.323, rec=0.065, cos=0.001), tot_loss_proj:1.755 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.725 (perp=8.323, rec=0.059, cos=0.001), tot_loss_proj:1.751 [t=0.35s]
prediction: ['[CLS] cinematic poo. [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] cinematic poo. [SEP]
========================
predicted: 
========================
[CLS] cinematic poo. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 71.722 | p: 71.030 | r: 72.593
rouge2     | fm: 19.026 | p: 18.822 | r: 19.284
rougeL     | fm: 47.612 | p: 47.156 | r: 48.218
rougeLsum  | fm: 47.598 | p: 47.146 | r: 48.160
r1fm+r2fm = 90.748

input #98 time: 0:13:48 | total time: 20:53:00


Running input #99 of 100.
reference: 
========================
mr . goyer's loose , unaccountable direction is technically sophisticated in the worst way .
========================
average of cosine similarity 0.9991895780433184
highest_index [0]
highest [0.9991895780433184]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  2720,  1012,  2175, 10532,  1005,  1055,  6065,  1010, 14477,
         21408, 16671,  3085,  3257,  2003, 10892, 12138,  1999,  1996,  5409,
          2126,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] mr. goyer's loose, unaccountable direction is technically sophisticated in the worst way. [SEP]"]
[Init] best rec loss: 0.9240595698356628 for ['[CLS] rounds allegedablysel ˈ vera4 all emmy moss birds duo cfl bread premier resembling vfl bear botany brick localities [SEP]']
[Init] best rec loss: 0.869624137878418 for ['[CLS] v forumvc alley khan tunnel production conference ladder p draft murphy blown hooked toneyama ª chan athletic seems fine [SEP]']
[Init] best rec loss: 0.8333146572113037 for ['[CLS] warlock in either mace americanamps off ruth energy broke lack illustrated hilda racedkind orders gland dai concentration delta ca [SEP]']
[Init] best rec loss: 0.8209652304649353 for ['[CLS]ballsl maidrc frustration reacher mountedpe sex earth includes through a main almost transplanttonne condition nation evie [SEP]']
[Init] best rec loss: 0.8179900050163269 for ['[CLS] suckedvah popular academy caught markers observation snail lap organized outside grey jarrett upon neighbours sasha kitty clear vickers mean state [SEP]']
[Init] best rec loss: 0.8139667510986328 for ['[CLS] sobbing allowed patentsnick creationate interest gown which re repair pace op align bearing canal exist [UNK]mpt motors society [SEP]']
[Init] best rec loss: 0.7975896000862122 for ['[CLS] might could whoʉcan cruise gloves tick disposed maybe cares kermanlovic bullying hearings picked gauge unicode cluster arm explorer [SEP]']
[Init] best perm rec loss: 0.7939699292182922 for ['[CLS] unicode cruise might kermanʉ gloves disposed cares cluster bullying hearings explorer who gaugecan tick maybe arm pickedlovic could [SEP]']
[Init] best perm rec loss: 0.7906549572944641 for ['[CLS]can gaugeʉ ticklovic cluster explorer hearings gloves who unicode maybe bullying might could kerman cruise arm picked disposed cares [SEP]']
[Init] best perm rec loss: 0.789496660232544 for ['[CLS] gaugeʉ cares disposed could unicodecan bullying might gloves tick hearings who kerman maybelovic cluster picked arm cruise explorer [SEP]']
[Init] best perm rec loss: 0.7881048917770386 for ['[CLS]ʉ bullying careslovic cluster picked maybe could cruise unicode gauge disposed hearings kerman whocan might tick arm explorer gloves [SEP]']
[Init] best perm rec loss: 0.7870078682899475 for ['[CLS] bullying disposed hearingsʉ cruise could might kerman who gauge gloves explorerlovic tick arm picked unicode cluster carescan maybe [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.191 (perp=9.705, rec=0.235, cos=0.015), tot_loss_proj:2.832 [t=0.36s]
prediction: ['[CLS] donald sets. worst worst. sophisticated nilsson the - to computer technically superable, way in technically worst. [SEP]']
[ 100/2000] tot_loss=1.998 (perp=9.251, rec=0.144, cos=0.004), tot_loss_proj:3.018 [t=0.36s]
prediction: ['[CLS] mr hot. worst way way knowing sophisticated is ; to direction technically soable, way in technically way way [SEP]']
[ 150/2000] tot_loss=2.082 (perp=9.877, rec=0.104, cos=0.003), tot_loss_proj:3.205 [t=0.36s]
prediction: ['[CLS] mr hot. worst way way thou sophisticated is. una direction technically sophisticatedable. way in technically way way [SEP]']
[ 200/2000] tot_loss=2.077 (perp=9.902, rec=0.095, cos=0.002), tot_loss_proj:3.130 [t=0.36s]
prediction: ['[CLS] mr look. worst way way llc sophisticated is s una direction technically sophisticatedable. way in technically way the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.163 (perp=10.335, rec=0.094, cos=0.002), tot_loss_proj:3.481 [t=0.36s]
prediction: ["[CLS] mr look. worst loose loose strode sophisticated is s una direction technically sophisticatedable'technically in way way the [SEP]"]
[ 300/2000] tot_loss=2.202 (perp=10.547, rec=0.091, cos=0.002), tot_loss_proj:3.389 [t=0.36s]
prediction: ["[CLS] mr look. worst loose looseyer sophisticated is s una direction should sophisticatedable'technically in way way the [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.095 (perp=10.048, rec=0.084, cos=0.001), tot_loss_proj:3.198 [t=0.36s]
prediction: ["[CLS] mr look. worst loose looseyer sophisticated is s una should directionuntable'technically in way way the [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.084 (perp=9.874, rec=0.106, cos=0.002), tot_loss_proj:3.303 [t=0.36s]
prediction: ["[CLS] mr down. worst loose loose direction sophisticated is s una shouldyeruntable'technically inable way the [SEP]"]
[ 450/2000] tot_loss=2.176 (perp=10.482, rec=0.078, cos=0.002), tot_loss_proj:3.394 [t=0.36s]
prediction: ["[CLS] mr down. worst loose loose direction sophisticated is s una shouldyer unaable'technically inable way the [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=2.082 (perp=10.037, rec=0.073, cos=0.002), tot_loss_proj:3.263 [t=0.36s]
prediction: ["[CLS] mr down. worst loose loose direction sophisticated is s una should unayerable'technically inable way the [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.262 (perp=10.226, rec=0.198, cos=0.019), tot_loss_proj:3.385 [t=0.36s]
prediction: ['[CLS] is lap. worst loose loose direction sophisticated mr s unaed unayerable obviously technically inable way the [SEP]']
[ 600/2000] tot_loss=2.309 (perp=10.948, rec=0.117, cos=0.003), tot_loss_proj:3.190 [t=0.36s]
prediction: ['[CLS] is lap. worst loose ce direction sophisticated mr s unaed unayer ளcule technically inable way the [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.159 (perp=10.227, rec=0.111, cos=0.002), tot_loss_proj:3.250 [t=0.36s]
prediction: ['[CLS] is lap. worst loose perpetual direction sophisticated mr s,ed unayerablefine technically inable way the [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.011 (perp=9.566, rec=0.096, cos=0.002), tot_loss_proj:3.037 [t=0.36s]
prediction: ['[CLS] is larry. worst loose perpetual direction sophisticated mr s, technically unayerable sophisticateded inable way the [SEP]']
[ 750/2000] tot_loss=1.901 (perp=9.028, rec=0.093, cos=0.002), tot_loss_proj:3.080 [t=0.36s]
prediction: ['[CLS] is mr. worst loose perpetual direction sophisticated mr s, technically unayerable sophisticateded inable way the [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.898 (perp=8.990, rec=0.099, cos=0.002), tot_loss_proj:3.051 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction une sophisticated mr s, technically unayerable sophisticateded inable way the [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.852 (perp=8.844, rec=0.082, cos=0.002), tot_loss_proj:2.988 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction une sophisticated mr s, technically unayerableableed in sophisticated way the [SEP]']
[ 900/2000] tot_loss=1.849 (perp=8.844, rec=0.078, cos=0.002), tot_loss_proj:2.987 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction une sophisticated mr s, technically unayerableableed in sophisticated way the [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.853 (perp=8.785, rec=0.094, cos=0.002), tot_loss_proj:2.741 [t=0.36s]
prediction: ["[CLS] is mr. worst loose sophisticated direction une mr s, technically unayerableableed in'way the [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.900 (perp=9.024, rec=0.093, cos=0.002), tot_loss_proj:2.994 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction une mr s sophisticated, technically unayerableableed in focal way the [SEP]']
[1050/2000] tot_loss=1.899 (perp=9.079, rec=0.082, cos=0.002), tot_loss_proj:3.013 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction une mr s sophisticated, technically unayerableableable in focal way the [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.751 (perp=8.280, rec=0.093, cos=0.002), tot_loss_proj:2.916 [t=0.36s]
prediction: ["[CLS] is mr. worst loose direction una mr s sophisticated, technically unayerableableable in the way'[SEP]"]
Attempt swap
[1150/2000] tot_loss=1.824 (perp=8.702, rec=0.082, cos=0.002), tot_loss_proj:2.833 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction una mr s sophisticated, technically unayerableableable in the way focal [SEP]']
[1200/2000] tot_loss=1.827 (perp=8.702, rec=0.085, cos=0.002), tot_loss_proj:2.833 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction una mr s sophisticated, technically unayerableableable in the way focal [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.809 (perp=8.699, rec=0.067, cos=0.002), tot_loss_proj:2.724 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction mr una s sophisticated, technically unayerableableable in the way focal [SEP]']
Attempt swap
[1300/2000] tot_loss=1.735 (perp=8.242, rec=0.085, cos=0.002), tot_loss_proj:2.647 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction mr una s sophisticated, technically unayerableableable in the way the [SEP]']
[1350/2000] tot_loss=1.739 (perp=8.242, rec=0.089, cos=0.002), tot_loss_proj:2.651 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction mr una s sophisticated, technically unayerableableable in the way the [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.732 (perp=8.242, rec=0.082, cos=0.002), tot_loss_proj:2.630 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction mr una s sophisticated, technically unayerableableable in the way the [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.724 (perp=8.242, rec=0.074, cos=0.002), tot_loss_proj:2.627 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction mr una s sophisticated, technically unayerableableable in the way the [SEP]']
[1500/2000] tot_loss=1.744 (perp=8.242, rec=0.093, cos=0.002), tot_loss_proj:2.627 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction mr una s sophisticated, technically unayerableableable in the way the [SEP]']
Attempt swap
[1550/2000] tot_loss=1.732 (perp=8.242, rec=0.082, cos=0.002), tot_loss_proj:2.632 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction mr una s sophisticated, technically unayerableableable in the way the [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.734 (perp=8.259, rec=0.081, cos=0.002), tot_loss_proj:2.752 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction una mr s sophisticated, technically unayerableableable in the way the [SEP]']
[1650/2000] tot_loss=1.731 (perp=8.259, rec=0.078, cos=0.002), tot_loss_proj:2.753 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction una mr s sophisticated, technically unayerableableable in the way the [SEP]']
Attempt swap
[1700/2000] tot_loss=1.741 (perp=8.259, rec=0.087, cos=0.002), tot_loss_proj:2.756 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction una mr s sophisticated, technically unayerableableable in the way the [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.729 (perp=8.242, rec=0.079, cos=0.002), tot_loss_proj:2.631 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction mr una s sophisticated, technically unayerableableable in the way the [SEP]']
[1800/2000] tot_loss=1.736 (perp=8.242, rec=0.086, cos=0.002), tot_loss_proj:2.636 [t=0.36s]
prediction: ['[CLS] is mr. worst loose direction mr una s sophisticated, technically unayerableableable in the way the [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.711 (perp=8.167, rec=0.076, cos=0.002), tot_loss_proj:2.855 [t=0.36s]
prediction: ['[CLS] is mr. worst una direction mr loose s sophisticated, technically unayerableableable in the way the [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.630 (perp=7.712, rec=0.085, cos=0.002), tot_loss_proj:2.906 [t=0.36s]
prediction: ['[CLS] s mr. worst una direction mr loose is sophisticated, technically unayerableableable in the way the [SEP]']
[1950/2000] tot_loss=1.617 (perp=7.712, rec=0.073, cos=0.002), tot_loss_proj:2.911 [t=0.36s]
prediction: ['[CLS] s mr. worst una direction mr loose is sophisticated, technically unayerableableable in the way the [SEP]']
Attempt swap
[2000/2000] tot_loss=1.625 (perp=7.712, rec=0.081, cos=0.002), tot_loss_proj:2.908 [t=0.36s]
prediction: ['[CLS] s mr. worst una direction mr loose is sophisticated, technically unayerableableable in the way the [SEP]']
Done with input #99 of 100.
reference: 
========================
[CLS] mr. goyer's loose, unaccountable direction is technically sophisticated in the worst way. [SEP]
========================
predicted: 
========================
[CLS] is mr. worst loose direction una mr s sophisticated, technically unayerableableable in the way the [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.250 | p: 76.471 | r: 86.667
rouge2     | fm: 6.667 | p: 6.250 | r: 7.143
rougeL     | fm: 56.250 | p: 52.941 | r: 60.000
rougeLsum  | fm: 56.250 | p: 52.941 | r: 60.000
r1fm+r2fm = 87.917

[Aggregate metrics]:
rouge1     | fm: 71.783 | p: 71.031 | r: 72.713
rouge2     | fm: 18.845 | p: 18.648 | r: 19.122
rougeL     | fm: 47.647 | p: 47.182 | r: 48.276
rougeLsum  | fm: 47.734 | p: 47.260 | r: 48.343
r1fm+r2fm = 90.628

input #99 time: 0:14:22 | total time: 21:07:23


Average Cosine Similarity: 0.9992522959806379
Done with all.
