


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.05 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 43.09it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9851409628021986
highest_index [0]
highest [0.9851409628021986]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 0.9569860696792603 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.8172750473022461 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.8085652589797974 for ['[CLS] tolerance receiving [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.209 (perp=10.251, rec=0.124, cos=0.035), tot_loss_proj:2.147 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 100/2000] tot_loss=2.154 (perp=10.251, rec=0.074, cos=0.029), tot_loss_proj:2.151 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.144 (perp=10.251, rec=0.064, cos=0.029), tot_loss_proj:2.146 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.142 (perp=10.251, rec=0.062, cos=0.029), tot_loss_proj:2.139 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.125 (perp=10.251, rec=0.045, cos=0.029), tot_loss_proj:2.141 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.151 (perp=10.251, rec=0.072, cos=0.030), tot_loss_proj:2.133 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.147 (perp=10.251, rec=0.068, cos=0.029), tot_loss_proj:2.149 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.149 (perp=10.251, rec=0.069, cos=0.029), tot_loss_proj:2.141 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.139 (perp=10.251, rec=0.060, cos=0.029), tot_loss_proj:2.145 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.128 (perp=10.251, rec=0.048, cos=0.029), tot_loss_proj:2.149 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.155 (perp=10.251, rec=0.075, cos=0.029), tot_loss_proj:2.157 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.149 (perp=10.251, rec=0.069, cos=0.029), tot_loss_proj:2.149 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.140 (perp=10.251, rec=0.061, cos=0.029), tot_loss_proj:2.154 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.138 (perp=10.251, rec=0.059, cos=0.029), tot_loss_proj:2.146 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.130 (perp=10.251, rec=0.051, cos=0.029), tot_loss_proj:2.139 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.145 (perp=10.251, rec=0.065, cos=0.029), tot_loss_proj:2.146 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.136 (perp=10.251, rec=0.057, cos=0.029), tot_loss_proj:2.149 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.132 (perp=10.251, rec=0.053, cos=0.029), tot_loss_proj:2.137 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.147 (perp=10.251, rec=0.067, cos=0.029), tot_loss_proj:2.156 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.127 (perp=10.251, rec=0.047, cos=0.029), tot_loss_proj:2.146 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.142 (perp=10.251, rec=0.063, cos=0.029), tot_loss_proj:2.144 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.151 (perp=10.251, rec=0.072, cos=0.029), tot_loss_proj:2.159 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.149 (perp=10.251, rec=0.070, cos=0.029), tot_loss_proj:2.153 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.129 (perp=10.251, rec=0.049, cos=0.029), tot_loss_proj:2.142 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.136 (perp=10.251, rec=0.057, cos=0.029), tot_loss_proj:2.144 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.131 (perp=10.251, rec=0.052, cos=0.029), tot_loss_proj:2.145 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.142 (perp=10.251, rec=0.062, cos=0.029), tot_loss_proj:2.139 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.145 (perp=10.251, rec=0.065, cos=0.029), tot_loss_proj:2.150 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.133 (perp=10.251, rec=0.054, cos=0.029), tot_loss_proj:2.153 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.150 (perp=10.251, rec=0.070, cos=0.029), tot_loss_proj:2.137 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.140 (perp=10.251, rec=0.060, cos=0.029), tot_loss_proj:2.151 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.137 (perp=10.251, rec=0.057, cos=0.029), tot_loss_proj:2.149 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.138 (perp=10.251, rec=0.058, cos=0.029), tot_loss_proj:2.144 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.146 (perp=10.251, rec=0.066, cos=0.029), tot_loss_proj:2.152 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.139 (perp=10.251, rec=0.059, cos=0.029), tot_loss_proj:2.151 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.146 (perp=10.251, rec=0.066, cos=0.029), tot_loss_proj:2.140 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.141 (perp=10.251, rec=0.062, cos=0.029), tot_loss_proj:2.146 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.144 (perp=10.251, rec=0.064, cos=0.029), tot_loss_proj:2.144 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.133 (perp=10.251, rec=0.054, cos=0.029), tot_loss_proj:2.148 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.153 (perp=10.251, rec=0.073, cos=0.029), tot_loss_proj:2.146 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:12:05 | total time: 0:12:05


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9879705907004919
highest_index [0]
highest [0.9879705907004919]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 0.973285436630249 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9594891667366028 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.9394155144691467 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.935006320476532 for ['[CLS] } sex [SEP]']
[Init] best rec loss: 0.8773512244224548 for ['[CLS] feeling play [SEP]']
[Init] best rec loss: 0.8429497480392456 for ["[CLS] giant'[SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.234 (perp=9.788, rec=0.249, cos=0.027), tot_loss_proj:2.489 [t=0.30s]
prediction: ['[CLS] european excellent [SEP]']
[ 100/2000] tot_loss=2.568 (perp=11.854, rec=0.174, cos=0.023), tot_loss_proj:2.833 [t=0.30s]
prediction: ['[CLS]ian splendid [SEP]']
[ 150/2000] tot_loss=2.224 (perp=10.288, rec=0.144, cos=0.023), tot_loss_proj:2.319 [t=0.30s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.218 (perp=10.288, rec=0.138, cos=0.023), tot_loss_proj:2.322 [t=0.30s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.975 (perp=9.171, rec=0.117, cos=0.024), tot_loss_proj:1.929 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.928 (perp=9.171, rec=0.070, cos=0.024), tot_loss_proj:1.935 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.921 (perp=9.171, rec=0.063, cos=0.024), tot_loss_proj:1.924 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.918 (perp=9.171, rec=0.060, cos=0.024), tot_loss_proj:1.920 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.924 (perp=9.171, rec=0.066, cos=0.024), tot_loss_proj:1.920 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.912 (perp=9.171, rec=0.054, cos=0.024), tot_loss_proj:1.921 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.929 (perp=9.171, rec=0.071, cos=0.024), tot_loss_proj:1.902 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.916 (perp=9.171, rec=0.058, cos=0.024), tot_loss_proj:1.914 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.912 (perp=9.171, rec=0.054, cos=0.024), tot_loss_proj:1.918 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.915 (perp=9.171, rec=0.057, cos=0.024), tot_loss_proj:1.930 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.923 (perp=9.171, rec=0.065, cos=0.024), tot_loss_proj:1.926 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.928 (perp=9.171, rec=0.070, cos=0.024), tot_loss_proj:1.927 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.923 (perp=9.171, rec=0.065, cos=0.024), tot_loss_proj:1.927 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.920 (perp=9.171, rec=0.062, cos=0.024), tot_loss_proj:1.927 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.932 (perp=9.171, rec=0.074, cos=0.024), tot_loss_proj:1.918 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.909 (perp=9.171, rec=0.051, cos=0.024), tot_loss_proj:1.925 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.914 (perp=9.171, rec=0.056, cos=0.024), tot_loss_proj:1.927 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.919 (perp=9.171, rec=0.061, cos=0.024), tot_loss_proj:1.907 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.907 (perp=9.171, rec=0.049, cos=0.024), tot_loss_proj:1.926 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.916 (perp=9.171, rec=0.058, cos=0.024), tot_loss_proj:1.916 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.920 (perp=9.171, rec=0.062, cos=0.024), tot_loss_proj:1.929 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.912 (perp=9.171, rec=0.054, cos=0.024), tot_loss_proj:1.929 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.933 (perp=9.171, rec=0.075, cos=0.024), tot_loss_proj:1.924 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.920 (perp=9.171, rec=0.062, cos=0.024), tot_loss_proj:1.926 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.921 (perp=9.171, rec=0.063, cos=0.024), tot_loss_proj:1.911 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.904 (perp=9.171, rec=0.046, cos=0.024), tot_loss_proj:1.924 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.916 (perp=9.171, rec=0.058, cos=0.024), tot_loss_proj:1.918 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.918 (perp=9.171, rec=0.060, cos=0.024), tot_loss_proj:1.920 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.916 (perp=9.171, rec=0.058, cos=0.024), tot_loss_proj:1.916 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.928 (perp=9.171, rec=0.070, cos=0.024), tot_loss_proj:1.922 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.919 (perp=9.171, rec=0.061, cos=0.024), tot_loss_proj:1.918 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.911 (perp=9.171, rec=0.053, cos=0.024), tot_loss_proj:1.919 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.924 (perp=9.171, rec=0.065, cos=0.024), tot_loss_proj:1.918 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.909 (perp=9.171, rec=0.051, cos=0.024), tot_loss_proj:1.916 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.931 (perp=9.171, rec=0.073, cos=0.024), tot_loss_proj:1.909 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.926 (perp=9.171, rec=0.068, cos=0.024), tot_loss_proj:1.919 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:12:00 | total time: 0:24:06


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9869216013517912
highest_index [0]
highest [0.9869216013517912]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.7215469479560852 for ['[CLS] wash〜 at [SEP]']
[Init] best perm rec loss: 0.7177685499191284 for ['[CLS] wash at〜 [SEP]']
[Init] best perm rec loss: 0.7143524885177612 for ['[CLS]〜 wash at [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.175 (perp=9.502, rec=0.236, cos=0.039), tot_loss_proj:2.372 [t=0.30s]
prediction: ['[CLS] gaining momentum momentum [SEP]']
[ 100/2000] tot_loss=1.806 (perp=8.515, rec=0.079, cos=0.024), tot_loss_proj:1.794 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/2000] tot_loss=1.786 (perp=8.515, rec=0.058, cos=0.026), tot_loss_proj:1.794 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 200/2000] tot_loss=1.797 (perp=8.515, rec=0.068, cos=0.026), tot_loss_proj:1.782 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.796 (perp=8.515, rec=0.067, cos=0.026), tot_loss_proj:1.782 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=1.788 (perp=8.515, rec=0.059, cos=0.026), tot_loss_proj:1.792 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.791 (perp=8.515, rec=0.062, cos=0.026), tot_loss_proj:1.794 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.802 (perp=8.515, rec=0.073, cos=0.026), tot_loss_proj:1.801 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=1.790 (perp=8.515, rec=0.061, cos=0.026), tot_loss_proj:1.791 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.798 (perp=8.515, rec=0.069, cos=0.026), tot_loss_proj:1.803 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.786 (perp=8.515, rec=0.057, cos=0.026), tot_loss_proj:1.790 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=1.785 (perp=8.515, rec=0.056, cos=0.026), tot_loss_proj:1.797 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.795 (perp=8.515, rec=0.066, cos=0.026), tot_loss_proj:1.784 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.796 (perp=8.515, rec=0.067, cos=0.026), tot_loss_proj:1.786 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=1.779 (perp=8.515, rec=0.050, cos=0.026), tot_loss_proj:1.802 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.779 (perp=8.515, rec=0.050, cos=0.026), tot_loss_proj:1.800 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.783 (perp=8.515, rec=0.055, cos=0.026), tot_loss_proj:1.793 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=1.783 (perp=8.515, rec=0.054, cos=0.026), tot_loss_proj:1.788 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.786 (perp=8.515, rec=0.058, cos=0.026), tot_loss_proj:1.790 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.794 (perp=8.515, rec=0.065, cos=0.026), tot_loss_proj:1.788 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=1.794 (perp=8.515, rec=0.065, cos=0.026), tot_loss_proj:1.793 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.800 (perp=8.515, rec=0.071, cos=0.026), tot_loss_proj:1.801 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.782 (perp=8.515, rec=0.053, cos=0.026), tot_loss_proj:1.784 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=1.781 (perp=8.515, rec=0.052, cos=0.026), tot_loss_proj:1.802 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.793 (perp=8.515, rec=0.064, cos=0.026), tot_loss_proj:1.799 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.791 (perp=8.515, rec=0.062, cos=0.026), tot_loss_proj:1.791 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=1.781 (perp=8.515, rec=0.052, cos=0.026), tot_loss_proj:1.804 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.784 (perp=8.515, rec=0.056, cos=0.026), tot_loss_proj:1.802 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.784 (perp=8.515, rec=0.055, cos=0.026), tot_loss_proj:1.800 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=1.774 (perp=8.515, rec=0.045, cos=0.026), tot_loss_proj:1.792 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.795 (perp=8.515, rec=0.066, cos=0.026), tot_loss_proj:1.802 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.784 (perp=8.515, rec=0.055, cos=0.026), tot_loss_proj:1.795 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=1.791 (perp=8.515, rec=0.062, cos=0.026), tot_loss_proj:1.798 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.795 (perp=8.515, rec=0.066, cos=0.026), tot_loss_proj:1.800 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.782 (perp=8.515, rec=0.053, cos=0.026), tot_loss_proj:1.787 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=1.795 (perp=8.515, rec=0.066, cos=0.026), tot_loss_proj:1.790 [t=0.35s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.785 (perp=8.515, rec=0.056, cos=0.026), tot_loss_proj:1.801 [t=0.35s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.782 (perp=8.515, rec=0.053, cos=0.026), tot_loss_proj:1.789 [t=0.35s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=1.790 (perp=8.515, rec=0.061, cos=0.026), tot_loss_proj:1.793 [t=0.35s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.791 (perp=8.515, rec=0.062, cos=0.026), tot_loss_proj:1.795 [t=0.35s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:12:12 | total time: 0:36:19


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.9878101419466749
highest_index [0]
highest [0.9878101419466749]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.97409588098526 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.8503747582435608 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.845120370388031 for ['[CLS] lancashire isaac [SEP]']
[Init] best rec loss: 0.8021261692047119 for ['[CLS] end depart [SEP]']
[Init] best perm rec loss: 0.7981909513473511 for ['[CLS] depart end [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.812 (perp=8.385, rec=0.111, cos=0.025), tot_loss_proj:1.799 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[ 100/2000] tot_loss=1.765 (perp=8.385, rec=0.064, cos=0.024), tot_loss_proj:1.788 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/2000] tot_loss=1.772 (perp=8.385, rec=0.071, cos=0.024), tot_loss_proj:1.786 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[ 200/2000] tot_loss=1.768 (perp=8.385, rec=0.068, cos=0.024), tot_loss_proj:1.779 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.758 (perp=8.385, rec=0.058, cos=0.024), tot_loss_proj:1.777 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.768 (perp=8.385, rec=0.067, cos=0.024), tot_loss_proj:1.792 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.769 (perp=8.385, rec=0.068, cos=0.024), tot_loss_proj:1.789 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.751 (perp=8.385, rec=0.050, cos=0.024), tot_loss_proj:1.796 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.761 (perp=8.385, rec=0.060, cos=0.024), tot_loss_proj:1.792 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.764 (perp=8.385, rec=0.063, cos=0.024), tot_loss_proj:1.788 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.761 (perp=8.385, rec=0.060, cos=0.024), tot_loss_proj:1.786 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.755 (perp=8.385, rec=0.054, cos=0.024), tot_loss_proj:1.783 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.759 (perp=8.385, rec=0.058, cos=0.024), tot_loss_proj:1.797 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.761 (perp=8.385, rec=0.059, cos=0.024), tot_loss_proj:1.795 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.751 (perp=8.385, rec=0.050, cos=0.024), tot_loss_proj:1.796 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.748 (perp=8.385, rec=0.047, cos=0.024), tot_loss_proj:1.794 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.758 (perp=8.385, rec=0.056, cos=0.024), tot_loss_proj:1.785 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.750 (perp=8.385, rec=0.049, cos=0.024), tot_loss_proj:1.801 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.761 (perp=8.385, rec=0.060, cos=0.024), tot_loss_proj:1.785 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.777 (perp=8.385, rec=0.076, cos=0.024), tot_loss_proj:1.790 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.765 (perp=8.385, rec=0.064, cos=0.024), tot_loss_proj:1.802 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.751 (perp=8.385, rec=0.050, cos=0.024), tot_loss_proj:1.795 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.750 (perp=8.385, rec=0.048, cos=0.024), tot_loss_proj:1.801 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.759 (perp=8.385, rec=0.058, cos=0.024), tot_loss_proj:1.794 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.766 (perp=8.385, rec=0.065, cos=0.024), tot_loss_proj:1.793 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.763 (perp=8.385, rec=0.062, cos=0.024), tot_loss_proj:1.789 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.742 (perp=8.385, rec=0.041, cos=0.024), tot_loss_proj:1.799 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.758 (perp=8.385, rec=0.056, cos=0.024), tot_loss_proj:1.802 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.751 (perp=8.385, rec=0.050, cos=0.024), tot_loss_proj:1.785 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.761 (perp=8.385, rec=0.060, cos=0.024), tot_loss_proj:1.795 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.769 (perp=8.385, rec=0.067, cos=0.024), tot_loss_proj:1.802 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.755 (perp=8.385, rec=0.053, cos=0.024), tot_loss_proj:1.803 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.764 (perp=8.385, rec=0.063, cos=0.024), tot_loss_proj:1.794 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.763 (perp=8.385, rec=0.061, cos=0.024), tot_loss_proj:1.799 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.760 (perp=8.385, rec=0.059, cos=0.024), tot_loss_proj:1.802 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.769 (perp=8.385, rec=0.068, cos=0.024), tot_loss_proj:1.801 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.759 (perp=8.385, rec=0.058, cos=0.024), tot_loss_proj:1.795 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.776 (perp=8.385, rec=0.075, cos=0.024), tot_loss_proj:1.792 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.747 (perp=8.385, rec=0.046, cos=0.024), tot_loss_proj:1.794 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.768 (perp=8.385, rec=0.067, cos=0.024), tot_loss_proj:1.778 [t=0.35s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:13:44 | total time: 0:50:03


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.985308893751122
highest_index [0]
highest [0.985308893751122]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 0.9688155055046082 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9430927634239197 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9285992383956909 for ['[CLS] rally entered worldwide [SEP]']
[Init] best rec loss: 0.9277737140655518 for ['[CLS] paper under welsh [SEP]']
[Init] best rec loss: 0.9031673073768616 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.8776876926422119 for ['[CLS] concern love black [SEP]']
[Init] best perm rec loss: 0.8722788095474243 for ['[CLS] black concern love [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.589 (perp=11.726, rec=0.214, cos=0.030), tot_loss_proj:3.827 [t=0.35s]
prediction: ['[CLS] tires tires tires [SEP]']
[ 100/2000] tot_loss=1.635 (perp=7.516, rec=0.104, cos=0.028), tot_loss_proj:1.591 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.606 (perp=7.516, rec=0.074, cos=0.029), tot_loss_proj:1.595 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.589 (perp=7.516, rec=0.057, cos=0.029), tot_loss_proj:1.592 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.592 (perp=7.516, rec=0.059, cos=0.029), tot_loss_proj:1.604 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.594 (perp=7.516, rec=0.062, cos=0.029), tot_loss_proj:1.595 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.593 (perp=7.516, rec=0.061, cos=0.029), tot_loss_proj:1.591 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.577 (perp=7.516, rec=0.045, cos=0.029), tot_loss_proj:1.588 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.582 (perp=7.516, rec=0.049, cos=0.029), tot_loss_proj:1.610 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.590 (perp=7.516, rec=0.058, cos=0.029), tot_loss_proj:1.595 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.586 (perp=7.516, rec=0.054, cos=0.029), tot_loss_proj:1.591 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.588 (perp=7.516, rec=0.056, cos=0.029), tot_loss_proj:1.607 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.586 (perp=7.516, rec=0.053, cos=0.029), tot_loss_proj:1.601 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.581 (perp=7.516, rec=0.048, cos=0.029), tot_loss_proj:1.594 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.600 (perp=7.516, rec=0.068, cos=0.029), tot_loss_proj:1.594 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.599 (perp=7.516, rec=0.066, cos=0.029), tot_loss_proj:1.580 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.586 (perp=7.516, rec=0.053, cos=0.029), tot_loss_proj:1.592 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.589 (perp=7.516, rec=0.057, cos=0.029), tot_loss_proj:1.603 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.595 (perp=7.516, rec=0.063, cos=0.029), tot_loss_proj:1.590 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.590 (perp=7.516, rec=0.058, cos=0.029), tot_loss_proj:1.592 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.597 (perp=7.516, rec=0.064, cos=0.029), tot_loss_proj:1.597 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.583 (perp=7.516, rec=0.051, cos=0.029), tot_loss_proj:1.595 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.599 (perp=7.516, rec=0.067, cos=0.029), tot_loss_proj:1.602 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.604 (perp=7.516, rec=0.072, cos=0.029), tot_loss_proj:1.596 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.584 (perp=7.516, rec=0.052, cos=0.029), tot_loss_proj:1.605 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.593 (perp=7.516, rec=0.061, cos=0.029), tot_loss_proj:1.597 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.585 (perp=7.516, rec=0.052, cos=0.029), tot_loss_proj:1.599 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.582 (perp=7.516, rec=0.050, cos=0.029), tot_loss_proj:1.603 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.584 (perp=7.516, rec=0.051, cos=0.029), tot_loss_proj:1.603 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.593 (perp=7.516, rec=0.061, cos=0.029), tot_loss_proj:1.595 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.592 (perp=7.516, rec=0.059, cos=0.029), tot_loss_proj:1.589 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.591 (perp=7.516, rec=0.058, cos=0.029), tot_loss_proj:1.599 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.591 (perp=7.516, rec=0.059, cos=0.029), tot_loss_proj:1.596 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.516, rec=0.063, cos=0.029), tot_loss_proj:1.603 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.589 (perp=7.516, rec=0.057, cos=0.029), tot_loss_proj:1.595 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.582 (perp=7.516, rec=0.050, cos=0.029), tot_loss_proj:1.595 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.588 (perp=7.516, rec=0.055, cos=0.029), tot_loss_proj:1.601 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.593 (perp=7.516, rec=0.060, cos=0.029), tot_loss_proj:1.600 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.596 (perp=7.516, rec=0.064, cos=0.029), tot_loss_proj:1.592 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.591 (perp=7.516, rec=0.059, cos=0.029), tot_loss_proj:1.596 [t=0.35s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:13:43 | total time: 1:03:47


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9877452580268442
highest_index [0]
highest [0.9877452580268442]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9673473238945007 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9525527954101562 for ['[CLS] juathic [SEP]']
[Init] best rec loss: 0.9492216110229492 for ['[CLS] those legs [SEP]']
[Init] best rec loss: 0.9446286559104919 for ['[CLS] preservation notre [SEP]']
[Init] best rec loss: 0.9343074560165405 for ['[CLS] institution wanting [SEP]']
[Init] best rec loss: 0.9313488602638245 for ['[CLS] reid supportive [SEP]']
[Init] best rec loss: 0.9174409508705139 for ['[CLS] baby face [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.579 (perp=12.626, rec=0.681, cos=0.372), tot_loss_proj:4.402 [t=0.35s]
prediction: ['[CLS] doesn someone [SEP]']
[ 100/2000] tot_loss=3.011 (perp=11.551, rec=0.533, cos=0.168), tot_loss_proj:3.488 [t=0.35s]
prediction: ['[CLS] easy ease [SEP]']
[ 150/2000] tot_loss=2.643 (perp=12.316, rec=0.155, cos=0.025), tot_loss_proj:2.547 [t=0.35s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 200/2000] tot_loss=2.607 (perp=12.316, rec=0.120, cos=0.024), tot_loss_proj:2.547 [t=0.35s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.503 (perp=11.854, rec=0.108, cos=0.024), tot_loss_proj:2.617 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 300/2000] tot_loss=2.494 (perp=11.854, rec=0.098, cos=0.025), tot_loss_proj:2.627 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.485 (perp=11.854, rec=0.089, cos=0.025), tot_loss_proj:2.613 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.477 (perp=11.854, rec=0.081, cos=0.025), tot_loss_proj:2.626 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/2000] tot_loss=2.490 (perp=11.854, rec=0.094, cos=0.025), tot_loss_proj:2.631 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.474 (perp=11.854, rec=0.079, cos=0.025), tot_loss_proj:2.628 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.467 (perp=11.854, rec=0.071, cos=0.025), tot_loss_proj:2.629 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 600/2000] tot_loss=2.457 (perp=11.854, rec=0.062, cos=0.024), tot_loss_proj:2.622 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.451 (perp=11.854, rec=0.056, cos=0.024), tot_loss_proj:2.622 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.454 (perp=11.854, rec=0.059, cos=0.024), tot_loss_proj:2.619 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 750/2000] tot_loss=2.455 (perp=11.854, rec=0.059, cos=0.024), tot_loss_proj:2.633 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.450 (perp=11.854, rec=0.055, cos=0.024), tot_loss_proj:2.631 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.457 (perp=11.854, rec=0.062, cos=0.024), tot_loss_proj:2.622 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 900/2000] tot_loss=2.459 (perp=11.854, rec=0.064, cos=0.024), tot_loss_proj:2.627 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.455 (perp=11.854, rec=0.060, cos=0.024), tot_loss_proj:2.620 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1000/2000] tot_loss=2.456 (perp=11.854, rec=0.061, cos=0.024), tot_loss_proj:2.634 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1050/2000] tot_loss=2.459 (perp=11.854, rec=0.064, cos=0.024), tot_loss_proj:2.629 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1100/2000] tot_loss=2.449 (perp=11.854, rec=0.053, cos=0.024), tot_loss_proj:2.616 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1150/2000] tot_loss=2.445 (perp=11.854, rec=0.049, cos=0.024), tot_loss_proj:2.622 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1200/2000] tot_loss=2.466 (perp=11.854, rec=0.071, cos=0.024), tot_loss_proj:2.628 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1250/2000] tot_loss=2.465 (perp=11.854, rec=0.070, cos=0.024), tot_loss_proj:2.616 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1300/2000] tot_loss=2.457 (perp=11.854, rec=0.061, cos=0.024), tot_loss_proj:2.618 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1350/2000] tot_loss=2.454 (perp=11.854, rec=0.059, cos=0.024), tot_loss_proj:2.630 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1400/2000] tot_loss=2.469 (perp=11.854, rec=0.074, cos=0.024), tot_loss_proj:2.631 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1450/2000] tot_loss=2.460 (perp=11.854, rec=0.065, cos=0.024), tot_loss_proj:2.617 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1500/2000] tot_loss=2.457 (perp=11.854, rec=0.062, cos=0.024), tot_loss_proj:2.622 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1550/2000] tot_loss=2.469 (perp=11.854, rec=0.073, cos=0.024), tot_loss_proj:2.628 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1600/2000] tot_loss=2.454 (perp=11.854, rec=0.059, cos=0.024), tot_loss_proj:2.640 [t=0.36s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1650/2000] tot_loss=2.461 (perp=11.854, rec=0.066, cos=0.024), tot_loss_proj:2.630 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1700/2000] tot_loss=2.440 (perp=11.854, rec=0.045, cos=0.024), tot_loss_proj:2.621 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1750/2000] tot_loss=2.452 (perp=11.854, rec=0.056, cos=0.024), tot_loss_proj:2.621 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1800/2000] tot_loss=2.459 (perp=11.854, rec=0.064, cos=0.024), tot_loss_proj:2.625 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1850/2000] tot_loss=2.462 (perp=11.854, rec=0.067, cos=0.024), tot_loss_proj:2.622 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1900/2000] tot_loss=2.453 (perp=11.854, rec=0.057, cos=0.024), tot_loss_proj:2.625 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1950/2000] tot_loss=2.455 (perp=11.854, rec=0.060, cos=0.024), tot_loss_proj:2.619 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[2000/2000] tot_loss=2.461 (perp=11.854, rec=0.065, cos=0.024), tot_loss_proj:2.623 [t=0.35s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 95.833 | p: 95.833 | r: 95.833
rougeLsum  | fm: 95.833 | p: 95.833 | r: 95.833
r1fm+r2fm = 183.333

input #5 time: 0:13:34 | total time: 1:17:22


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.984640693076234
highest_index [0]
highest [0.984640693076234]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9219706654548645 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.8039188981056213 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.780126690864563 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.7641278505325317 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.7337625622749329 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7015582323074341 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.6835189461708069 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 0.6550654172897339 for ['[CLS] double deep [SEP]']
[Init] best perm rec loss: 0.6511678099632263 for ['[CLS] deep double [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.279 (perp=10.460, rec=0.154, cos=0.033), tot_loss_proj:2.556 [t=0.34s]
prediction: ['[CLS]ish gray [SEP]']
[ 100/2000] tot_loss=2.185 (perp=10.460, rec=0.063, cos=0.030), tot_loss_proj:2.557 [t=0.35s]
prediction: ['[CLS]ish gray [SEP]']
[ 150/2000] tot_loss=2.188 (perp=10.460, rec=0.065, cos=0.030), tot_loss_proj:2.548 [t=0.35s]
prediction: ['[CLS]ish gray [SEP]']
[ 200/2000] tot_loss=2.200 (perp=10.460, rec=0.077, cos=0.030), tot_loss_proj:2.549 [t=0.35s]
prediction: ['[CLS]ish gray [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.717 (perp=8.088, rec=0.069, cos=0.031), tot_loss_proj:1.730 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.707 (perp=8.088, rec=0.059, cos=0.030), tot_loss_proj:1.717 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.709 (perp=8.088, rec=0.061, cos=0.030), tot_loss_proj:1.721 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.713 (perp=8.088, rec=0.065, cos=0.030), tot_loss_proj:1.724 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.710 (perp=8.088, rec=0.062, cos=0.030), tot_loss_proj:1.730 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.698 (perp=8.088, rec=0.050, cos=0.030), tot_loss_proj:1.724 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.711 (perp=8.088, rec=0.063, cos=0.030), tot_loss_proj:1.725 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.712 (perp=8.088, rec=0.064, cos=0.030), tot_loss_proj:1.717 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.704 (perp=8.088, rec=0.056, cos=0.030), tot_loss_proj:1.724 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.726 (perp=8.088, rec=0.078, cos=0.030), tot_loss_proj:1.733 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.716 (perp=8.088, rec=0.068, cos=0.030), tot_loss_proj:1.714 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.698 (perp=8.088, rec=0.050, cos=0.030), tot_loss_proj:1.710 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.710 (perp=8.088, rec=0.062, cos=0.030), tot_loss_proj:1.707 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.697 (perp=8.088, rec=0.049, cos=0.030), tot_loss_proj:1.727 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.710 (perp=8.088, rec=0.062, cos=0.031), tot_loss_proj:1.718 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.710 (perp=8.088, rec=0.062, cos=0.030), tot_loss_proj:1.717 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.699 (perp=8.088, rec=0.051, cos=0.030), tot_loss_proj:1.725 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.703 (perp=8.088, rec=0.055, cos=0.030), tot_loss_proj:1.715 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.707 (perp=8.088, rec=0.058, cos=0.030), tot_loss_proj:1.719 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.704 (perp=8.088, rec=0.056, cos=0.030), tot_loss_proj:1.720 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.705 (perp=8.088, rec=0.057, cos=0.030), tot_loss_proj:1.729 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.714 (perp=8.088, rec=0.066, cos=0.030), tot_loss_proj:1.720 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.708 (perp=8.088, rec=0.060, cos=0.030), tot_loss_proj:1.714 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.703 (perp=8.088, rec=0.055, cos=0.030), tot_loss_proj:1.725 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.714 (perp=8.088, rec=0.066, cos=0.030), tot_loss_proj:1.711 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.705 (perp=8.088, rec=0.057, cos=0.030), tot_loss_proj:1.710 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.695 (perp=8.088, rec=0.047, cos=0.030), tot_loss_proj:1.718 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.709 (perp=8.088, rec=0.061, cos=0.030), tot_loss_proj:1.717 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.708 (perp=8.088, rec=0.060, cos=0.030), tot_loss_proj:1.720 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.723 (perp=8.088, rec=0.075, cos=0.030), tot_loss_proj:1.710 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.719 (perp=8.088, rec=0.071, cos=0.030), tot_loss_proj:1.720 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.715 (perp=8.088, rec=0.067, cos=0.030), tot_loss_proj:1.703 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.707 (perp=8.088, rec=0.059, cos=0.030), tot_loss_proj:1.724 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.717 (perp=8.088, rec=0.069, cos=0.030), tot_loss_proj:1.718 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.714 (perp=8.088, rec=0.065, cos=0.030), tot_loss_proj:1.702 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.712 (perp=8.088, rec=0.063, cos=0.030), tot_loss_proj:1.709 [t=0.35s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 96.429 | p: 96.429 | r: 96.429
rougeLsum  | fm: 96.429 | p: 96.429 | r: 96.429
r1fm+r2fm = 185.714

input #6 time: 0:13:34 | total time: 1:30:56


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9842849625323192
highest_index [0]
highest [0.9842849625323192]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.8700810074806213 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8112262487411499 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8050404191017151 for ['[CLS] strengths kenton bond victimsmined absent se sides deed gavin making resides renewed magic antarctica clarebalance gaingnapressive need another easy fell race merged [SEP]']
[Init] best rec loss: 0.8040196895599365 for ['[CLS] flat forewingsys mick separation ) oh yorkening las sat an consecutive charity qaeda clinicroud ill column rustling marathon rom viper dinner chuck ( [SEP]']
[Init] best rec loss: 0.7910756468772888 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best rec loss: 0.7863227725028992 for ['[CLS] ni maintained micro aces echo all behind legal somethingelli stanley park d conspiracy medicine childbation jobtative hop rule fighting early twins sykes line [SEP]']
[Init] best perm rec loss: 0.7856922149658203 for ['[CLS] child conspiracy all micro d twins behind stanley line maintained rule something echoelli fighting hoptative sykes legal earlybation job park ni medicine aces [SEP]']
[Init] best perm rec loss: 0.7829569578170776 for ['[CLS] medicine conspiracy echo all fighting legal jobelli stanley aces hop behind early maintained sykes micro line park child twins somethingtative ni rulebation d [SEP]']
[Init] best perm rec loss: 0.7822012901306152 for ['[CLS] linebation hop maintained aces stanley twins d rule behind job fighting micro sykes early legalelli echo conspiracy park medicine alltative child something ni [SEP]']
[Init] best perm rec loss: 0.7821329832077026 for ['[CLS] something child rule aces behindelli stanley job twins conspiracy sykes maintained micro early all park ni line medicine hoptative legal fighting echobation d [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.241 (perp=9.597, rec=0.290, cos=0.032), tot_loss_proj:3.412 [t=0.36s]
prediction: ['[CLS] issued problem problem his police africa no status problem destroying druged. elimination species officers protagonist government problem is rooms no problem problem ". [SEP]']
[ 100/2000] tot_loss=1.907 (perp=8.394, rec=0.198, cos=0.030), tot_loss_proj:2.704 [t=0.36s]
prediction: ['[CLS] is problem no he : bit not character problem nothing fighting mind. ugly character ; character character problem is by no ugly problem? is [SEP]']
[ 150/2000] tot_loss=1.755 (perp=7.790, rec=0.167, cos=0.029), tot_loss_proj:2.843 [t=0.36s]
prediction: ['[CLS] is. no he : no love character problem no fighting mind the ugly character ; character character problem is. no ugly ugly. is [SEP]']
[ 200/2000] tot_loss=1.690 (perp=7.556, rec=0.150, cos=0.028), tot_loss_proj:3.337 [t=0.36s]
prediction: ['[CLS] is. no he. no love character problem no fighting mind the mind character ; cute character problem the. no not ugly. is [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.705 (perp=7.726, rec=0.128, cos=0.031), tot_loss_proj:3.105 [t=0.36s]
prediction: ['[CLS] is. no he. the love character problem no for mind the mind character ; cute character problem or. no not ugly love is [SEP]']
[ 300/2000] tot_loss=1.968 (perp=9.103, rec=0.117, cos=0.030), tot_loss_proj:3.404 [t=0.36s]
prediction: ['[CLS] or factor no he. the loveable problem no have mind the mind cute ; cute character problem or, no not ugly love is [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.633 (perp=7.409, rec=0.120, cos=0.032), tot_loss_proj:3.313 [t=0.36s]
prediction: ['[CLS] or or no he. the love love problem no.. that mind character ; cute character problem for. no not ugly. is [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.587 (perp=7.205, rec=0.116, cos=0.030), tot_loss_proj:3.154 [t=0.36s]
prediction: ['[CLS]able or no he. the love love problem no.. i mind cute ; cute character problem no. for not ugly or is [SEP]']
[ 450/2000] tot_loss=1.548 (perp=7.123, rec=0.093, cos=0.031), tot_loss_proj:3.199 [t=0.36s]
prediction: ['[CLS] here or no he. the love love factor no.. i mind cute ; cute character problem no. for not ugly or is [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.541 (perp=7.077, rec=0.095, cos=0.030), tot_loss_proj:3.148 [t=0.36s]
prediction: ['[CLS] here or no he. the love love factor no.. i mind cute ; cute problem character no, for not ugly or is [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.466 (perp=6.696, rec=0.098, cos=0.029), tot_loss_proj:2.988 [t=0.36s]
prediction: ['[CLS] here or no he. the love love factor no.. i mind is ; cute problem character no, for not ugly or cute [SEP]']
[ 600/2000] tot_loss=1.511 (perp=6.924, rec=0.095, cos=0.031), tot_loss_proj:3.022 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor no.. i mind is ; cute problem character no, for not ugly or cute [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.481 (perp=6.825, rec=0.086, cos=0.031), tot_loss_proj:3.103 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor no.. i mind is ; cute problem character for no, not ugly or cute [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.470 (perp=6.740, rec=0.091, cos=0.031), tot_loss_proj:3.026 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor no. i. mind is ; cute problem character for no, not ugly or cute [SEP]']
[ 750/2000] tot_loss=1.463 (perp=6.740, rec=0.084, cos=0.031), tot_loss_proj:3.022 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor no. i. mind is ; cute problem character for no, not ugly or cute [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.433 (perp=6.597, rec=0.083, cos=0.031), tot_loss_proj:2.464 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character for no, not ugly or cute [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.435 (perp=6.597, rec=0.085, cos=0.031), tot_loss_proj:2.463 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character for no, not ugly or cute [SEP]']
[ 900/2000] tot_loss=1.431 (perp=6.597, rec=0.081, cos=0.031), tot_loss_proj:2.461 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character for no, not ugly or cute [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.414 (perp=6.525, rec=0.078, cos=0.031), tot_loss_proj:2.180 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character for no, not cute or ugly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.420 (perp=6.525, rec=0.084, cos=0.031), tot_loss_proj:2.181 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character for no, not cute or ugly [SEP]']
[1050/2000] tot_loss=1.419 (perp=6.525, rec=0.083, cos=0.031), tot_loss_proj:2.181 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character for no, not cute or ugly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.411 (perp=6.525, rec=0.075, cos=0.031), tot_loss_proj:2.175 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character for no, not cute or ugly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.355 (perp=6.249, rec=0.074, cos=0.031), tot_loss_proj:2.062 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not cute or ugly [SEP]']
[1200/2000] tot_loss=1.359 (perp=6.249, rec=0.078, cos=0.031), tot_loss_proj:2.059 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not cute or ugly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.355 (perp=6.249, rec=0.074, cos=0.031), tot_loss_proj:2.064 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not cute or ugly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.356 (perp=6.249, rec=0.075, cos=0.031), tot_loss_proj:2.059 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not cute or ugly [SEP]']
[1350/2000] tot_loss=1.365 (perp=6.249, rec=0.084, cos=0.031), tot_loss_proj:2.056 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not cute or ugly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.360 (perp=6.249, rec=0.079, cos=0.031), tot_loss_proj:2.065 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not cute or ugly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.358 (perp=6.249, rec=0.077, cos=0.031), tot_loss_proj:2.059 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not cute or ugly [SEP]']
[1500/2000] tot_loss=1.437 (perp=6.626, rec=0.081, cos=0.031), tot_loss_proj:2.200 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not character or ugly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.443 (perp=6.626, rec=0.086, cos=0.031), tot_loss_proj:2.199 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not character or ugly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.440 (perp=6.626, rec=0.084, cos=0.031), tot_loss_proj:2.200 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not character or ugly [SEP]']
[1650/2000] tot_loss=1.440 (perp=6.626, rec=0.084, cos=0.031), tot_loss_proj:2.198 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not character or ugly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.436 (perp=6.626, rec=0.079, cos=0.031), tot_loss_proj:2.203 [t=0.36s]
prediction: ['[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not character or ugly [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.423 (perp=6.528, rec=0.085, cos=0.032), tot_loss_proj:2.103 [t=0.36s]
prediction: ['[CLS] here. no he. theable love factor. no i. mind is ; cute problem character or no, not character or ugly [SEP]']
[1800/2000] tot_loss=1.367 (perp=6.296, rec=0.077, cos=0.031), tot_loss_proj:2.053 [t=0.36s]
prediction: ['[CLS] here. no he. theable love factor. no i. mind is ; cute problem character or no, not cute or ugly [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.400 (perp=6.449, rec=0.079, cos=0.031), tot_loss_proj:2.685 [t=0.36s]
prediction: ['[CLS] here. no he. theable love factor. no i. mind is ; cute no character or problem, not character or ugly [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.307 (perp=5.964, rec=0.084, cos=0.031), tot_loss_proj:2.169 [t=0.36s]
prediction: ['[CLS] here. no he. theable love factor. no i. mind is cute ; no character or problem, not character or ugly [SEP]']
[1950/2000] tot_loss=1.294 (perp=5.964, rec=0.070, cos=0.031), tot_loss_proj:2.171 [t=0.36s]
prediction: ['[CLS] here. no he. theable love factor. no i. mind is cute ; no character or problem, not character or ugly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.306 (perp=5.964, rec=0.082, cos=0.031), tot_loss_proj:2.175 [t=0.36s]
prediction: ['[CLS] here. no he. theable love factor. no i. mind is cute ; no character or problem, not character or ugly [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] here or no he. theable love factor. no i. mind is ; cute problem character. no, not character or ugly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 76.190 | r: 76.190
rouge2     | fm: 5.000 | p: 5.000 | r: 5.000
rougeL     | fm: 47.619 | p: 47.619 | r: 47.619
rougeLsum  | fm: 47.619 | p: 47.619 | r: 47.619
r1fm+r2fm = 81.190

[Aggregate metrics]:
rouge1     | fm: 97.024 | p: 97.024 | r: 97.024
rouge2     | fm: 75.625 | p: 75.625 | r: 75.625
rougeL     | fm: 90.327 | p: 90.327 | r: 90.327
rougeLsum  | fm: 90.327 | p: 90.327 | r: 90.327
r1fm+r2fm = 172.649

input #7 time: 0:14:02 | total time: 1:44:59


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9843235292917822
highest_index [0]
highest [0.9843235292917822]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.6754406094551086 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.6738073825836182 for ['[CLS] intra selfir major model centraliard doesncy do strait everyonetes exactly respect fine [UNK] musical smallerton eagleump bet recent [SEP]']
[Init] best rec loss: 0.6682150959968567 for ['[CLS] behalf eireann pts ask solutionog rhythm revived sky bonus derek yet affairsstick weird meaning now wellverse beforeα arterial centuries network [SEP]']
[Init] best rec loss: 0.6625878214836121 for ['[CLS] breed app king jude rome am regal roman grown levi mine fitting peninsula cappella age bulldogs component founder macarthur unionist overturegible raysstock [SEP]']
[Init] best rec loss: 0.65690678358078 for ['[CLS] vin figure blowgger note mission [CLS] planet outside xi awardhe collections work money... unsuccessful canon ob brainally street wheat shortly [SEP]']
[Init] best rec loss: 0.6528661251068115 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.6522650718688965 for ['[CLS] andhra basque richards surrounding rockwell gloss rodeo series balanced waived word line plan styx responsible wish procession than attentionrave retention past doe tv [SEP]']
[Init] best perm rec loss: 0.6498117446899414 for ['[CLS] surrounding responsible retention plan rodeo procession balanced wish richards doe attention gloss rockwell basque styx line waived word pastrave than tv andhra series [SEP]']
[Init] best perm rec loss: 0.6489786505699158 for ['[CLS] than rockwell gloss responsible retention balanced past richards wish styxrave tv surrounding rodeo doe attention word basque waived series procession line plan andhra [SEP]']
[Init] best perm rec loss: 0.6485716700553894 for ['[CLS] plan attention richards than wish rodeo past andhra line styx tv doe rockwell word waived balanced retentionrave basque gloss procession responsible surrounding series [SEP]']
[Init] best perm rec loss: 0.6475778222084045 for ['[CLS] richards styx andhra rockwell wish than surrounding past planrave waived responsible procession basque series tv word doe rodeo attention retention balanced line gloss [SEP]']
[Init] best perm rec loss: 0.6474514007568359 for ['[CLS] plan waivedrave word tv past doe wish than balanced basque styx responsible rockwell line attention surrounding procession richards retention series rodeo gloss andhra [SEP]']
[Init] best perm rec loss: 0.6453334093093872 for ['[CLS] surrounding doe responsible richards styx waived past andhra basque tvrave retention procession gloss series rockwell word wish attention balanced rodeo line plan than [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.753 (perp=11.769, rec=0.332, cos=0.067), tot_loss_proj:3.921 [t=0.35s]
prediction: ['[CLS] films got.ful vanity vanity bipolar corruption less injury. debt paid vanity most film debt never pays gladly vanity my debt stock [SEP]']
[ 100/2000] tot_loss=2.658 (perp=11.873, rec=0.247, cos=0.037), tot_loss_proj:3.611 [t=0.36s]
prediction: ['[CLS] film pay doubtful vanity vanity fright corruption debt grief. debt paid vanity due film what published pays evenly vanity films debt when [SEP]']
[ 150/2000] tot_loss=2.771 (perp=12.671, rec=0.198, cos=0.038), tot_loss_proj:3.947 [t=0.36s]
prediction: ['[CLS] film owed doubtful vanity vanity fright benign debt think that debt paid vanity benign film what publicly pays doubt vanity felt debt when [SEP]']
[ 200/2000] tot_loss=2.803 (perp=13.025, rec=0.167, cos=0.031), tot_loss_proj:3.946 [t=0.36s]
prediction: ['[CLS] film owed doubt fright vanity vanity fright benign owed no that debt pays vanity benign film what publicly pays doubt vanity felt debt owed [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.843 (perp=13.380, rec=0.140, cos=0.027), tot_loss_proj:4.163 [t=0.36s]
prediction: ['[CLS] film owed doubt fright vanity vanity fright benignmax no that debt pays benign benign doubt what laws pays film vanity felt debt owed [SEP]']
[ 300/2000] tot_loss=2.716 (perp=12.614, rec=0.146, cos=0.047), tot_loss_proj:3.969 [t=0.36s]
prediction: ['[CLS] film owed doubt fright vanity vanity fright benigni no that debt pays benign benign doubt what, pays film vanity felt debt owed [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.517 (perp=11.859, rec=0.116, cos=0.029), tot_loss_proj:3.615 [t=0.36s]
prediction: ['[CLS] film owed doubt fright vanity vanity fright benigni no that off pays what benign doubt benign, pays film vanity felt debt owed [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.503 (perp=11.837, rec=0.110, cos=0.026), tot_loss_proj:3.741 [t=0.36s]
prediction: ['[CLS] film owed doubt fright vanity vanity fright benignmax no that off pays what benign doubt benign pays, film a felt debt owed [SEP]']
[ 450/2000] tot_loss=2.589 (perp=12.316, rec=0.098, cos=0.028), tot_loss_proj:3.855 [t=0.36s]
prediction: ['[CLS] film owed doubt fright vanity vanityful benignmax no that off pays what benign doubti pays, film a felt debt owed [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.420 (perp=11.442, rec=0.100, cos=0.032), tot_loss_proj:3.689 [t=0.36s]
prediction: ['[CLS] film owed doubt frightful benign vanity vanitymax no that off pays what benign doubti pays, film a felt debt owed [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.294 (perp=10.821, rec=0.101, cos=0.029), tot_loss_proj:3.538 [t=0.36s]
prediction: ['[CLS] film owed doubt frightful benign vanity vanitymax no that off pays what doubt benigni pays, film a felt debt owed [SEP]']
[ 600/2000] tot_loss=2.287 (perp=10.821, rec=0.097, cos=0.026), tot_loss_proj:3.537 [t=0.36s]
prediction: ['[CLS] film owed doubt frightful benign vanity vanitymax no that off pays what doubt benigni pays, film a felt debt owed [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.153 (perp=10.176, rec=0.090, cos=0.028), tot_loss_proj:3.431 [t=0.36s]
prediction: ['[CLS] film owed doubt frightful benign vanity amax no that off pays what doubt benigni pays, film vanity felt debt owed [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.036 (perp=9.592, rec=0.088, cos=0.029), tot_loss_proj:3.351 [t=0.36s]
prediction: ['[CLS] film owed doubt frightful benign vanity amax no off pays that what doubt benigni pays, film vanity felt debt owed [SEP]']
[ 750/2000] tot_loss=2.035 (perp=9.592, rec=0.087, cos=0.030), tot_loss_proj:3.351 [t=0.36s]
prediction: ['[CLS] film owed doubt frightful benign vanity amax no off pays that what doubt benigni pays, film vanity felt debt owed [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.999 (perp=9.392, rec=0.091, cos=0.029), tot_loss_proj:3.318 [t=0.36s]
prediction: ['[CLS] film owed benign doubt frightful vanity amax no off pays that what doubt benigni pays, film vanity felt debt owed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.046 (perp=9.626, rec=0.091, cos=0.030), tot_loss_proj:3.356 [t=0.36s]
prediction: ['[CLS] film owed benign doubt frightful vanity amax no off pays that what doubt benigni pays, they vanity felt debt owed [SEP]']
[ 900/2000] tot_loss=2.044 (perp=9.626, rec=0.088, cos=0.030), tot_loss_proj:3.353 [t=0.36s]
prediction: ['[CLS] film owed benign doubt frightful vanity amax no off pays that what doubt benigni pays, they vanity felt debt owed [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.027 (perp=9.576, rec=0.083, cos=0.029), tot_loss_proj:3.354 [t=0.36s]
prediction: ['[CLS] film owed doubt benign frightful vanity amax no off pays that what doubt benigni pays, they vanity felt debt owed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.034 (perp=9.576, rec=0.089, cos=0.029), tot_loss_proj:3.357 [t=0.36s]
prediction: ['[CLS] film owed doubt benign frightful vanity amax no off pays that what doubt benigni pays, they vanity felt debt owed [SEP]']
[1050/2000] tot_loss=2.035 (perp=9.576, rec=0.090, cos=0.030), tot_loss_proj:3.358 [t=0.36s]
prediction: ['[CLS] film owed doubt benign frightful vanity amax no off pays that what doubt benigni pays, they vanity felt debt owed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.026 (perp=9.576, rec=0.081, cos=0.030), tot_loss_proj:3.354 [t=0.36s]
prediction: ['[CLS] film owed doubt benign frightful vanity amax no off pays that what doubt benigni pays, they vanity felt debt owed [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.971 (perp=9.332, rec=0.075, cos=0.030), tot_loss_proj:3.466 [t=0.36s]
prediction: ['[CLS] film owed doubt benign frightful vanity amax no off pays that what doubt benigni pays, they felt vanity debt owed [SEP]']
[1200/2000] tot_loss=1.983 (perp=9.332, rec=0.087, cos=0.030), tot_loss_proj:3.464 [t=0.36s]
prediction: ['[CLS] film owed doubt benign frightful vanity amax no off pays that what doubt benigni pays, they felt vanity debt owed [SEP]']
Attempt swap
[1250/2000] tot_loss=1.974 (perp=9.332, rec=0.078, cos=0.030), tot_loss_proj:3.465 [t=0.36s]
prediction: ['[CLS] film owed doubt benign frightful vanity amax no off pays that what doubt benigni pays, they felt vanity debt owed [SEP]']
Attempt swap
[1300/2000] tot_loss=1.977 (perp=9.332, rec=0.080, cos=0.030), tot_loss_proj:3.463 [t=0.36s]
prediction: ['[CLS] film owed doubt benign frightful vanity amax no off pays that what doubt benigni pays, they felt vanity debt owed [SEP]']
[1350/2000] tot_loss=1.975 (perp=9.332, rec=0.078, cos=0.030), tot_loss_proj:3.466 [t=0.36s]
prediction: ['[CLS] film owed doubt benign frightful vanity amax no off pays that what doubt benigni pays, they felt vanity debt owed [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.956 (perp=9.230, rec=0.081, cos=0.030), tot_loss_proj:3.420 [t=0.36s]
prediction: ['[CLS] doubt owed doubt benign frightful vanity amax no off pays that what film benigni pays, they felt vanity debt owed [SEP]']
Attempt swap
[1450/2000] tot_loss=1.959 (perp=9.230, rec=0.082, cos=0.030), tot_loss_proj:3.423 [t=0.36s]
prediction: ['[CLS] doubt owed doubt benign frightful vanity amax no off pays that what film benigni pays, they felt vanity debt owed [SEP]']
[1500/2000] tot_loss=1.950 (perp=9.230, rec=0.073, cos=0.030), tot_loss_proj:3.423 [t=0.36s]
prediction: ['[CLS] doubt owed doubt benign frightful vanity amax no off pays that what film benigni pays, they felt vanity debt owed [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.934 (perp=9.148, rec=0.076, cos=0.028), tot_loss_proj:3.421 [t=0.36s]
prediction: ['[CLS] doubt owed doubt benign frightful vanity amax no off pays that what film pays benigni, they felt vanity debt owed [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.925 (perp=9.055, rec=0.084, cos=0.030), tot_loss_proj:3.398 [t=0.36s]
prediction: ['[CLS] doubt owed benign doubt frightful vanity amax no off pays that what film pays benigni, they felt vanity debt owed [SEP]']
[1650/2000] tot_loss=1.927 (perp=9.055, rec=0.086, cos=0.030), tot_loss_proj:3.394 [t=0.36s]
prediction: ['[CLS] doubt owed benign doubt frightful vanity amax no off pays that what film pays benigni, they felt vanity debt owed [SEP]']
Attempt swap
[1700/2000] tot_loss=1.921 (perp=9.055, rec=0.080, cos=0.030), tot_loss_proj:3.400 [t=0.36s]
prediction: ['[CLS] doubt owed benign doubt frightful vanity amax no off pays that what film pays benigni, they felt vanity debt owed [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.911 (perp=8.999, rec=0.082, cos=0.029), tot_loss_proj:3.381 [t=0.36s]
prediction: ['[CLS] benign doubt doubt owed frightful vanity amax no off pays that what film pays benigni, they felt vanity debt owed [SEP]']
[1800/2000] tot_loss=1.915 (perp=8.999, rec=0.087, cos=0.029), tot_loss_proj:3.381 [t=0.36s]
prediction: ['[CLS] benign doubt doubt owed frightful vanity amax no off pays that what film pays benigni, they felt vanity debt owed [SEP]']
Attempt swap
[1850/2000] tot_loss=1.920 (perp=8.999, rec=0.091, cos=0.029), tot_loss_proj:3.382 [t=0.36s]
prediction: ['[CLS] benign doubt doubt owed frightful vanity amax no off pays that what film pays benigni, they felt vanity debt owed [SEP]']
Attempt swap
[1900/2000] tot_loss=1.909 (perp=8.999, rec=0.080, cos=0.029), tot_loss_proj:3.385 [t=0.36s]
prediction: ['[CLS] benign doubt doubt owed frightful vanity amax no off pays that what film pays benigni, they felt vanity debt owed [SEP]']
[1950/2000] tot_loss=1.908 (perp=8.999, rec=0.079, cos=0.029), tot_loss_proj:3.383 [t=0.36s]
prediction: ['[CLS] benign doubt doubt owed frightful vanity amax no off pays that what film pays benigni, they felt vanity debt owed [SEP]']
Attempt swap
[2000/2000] tot_loss=1.917 (perp=8.999, rec=0.088, cos=0.029), tot_loss_proj:3.381 [t=0.36s]
prediction: ['[CLS] benign doubt doubt owed frightful vanity amax no off pays that what film pays benigni, they felt vanity debt owed [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] benign doubt doubt owed frightful vanity amax no off pays that what film pays benigni, they felt vanity debt owed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 72.727 | r: 80.000
rouge2     | fm: 5.000 | p: 4.762 | r: 5.263
rougeL     | fm: 42.857 | p: 40.909 | r: 45.000
rougeLsum  | fm: 42.857 | p: 40.909 | r: 45.000
r1fm+r2fm = 81.190

[Aggregate metrics]:
rouge1     | fm: 94.709 | p: 94.324 | r: 95.132
rouge2     | fm: 67.778 | p: 67.751 | r: 67.807
rougeL     | fm: 85.053 | p: 84.836 | r: 85.291
rougeLsum  | fm: 85.185 | p: 84.969 | r: 85.423
r1fm+r2fm = 162.487

input #8 time: 0:14:01 | total time: 1:59:01


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9841433511313813
highest_index [0]
highest [0.9841433511313813]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.7819589972496033 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.6869880557060242 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.677928626537323 for ['[CLS] military offered fragments gathered leaning sphere rom legs [SEP]']
[Init] best rec loss: 0.6554786562919617 for ['[CLS] ham ice command across see beatty anal tan [SEP]']
[Init] best rec loss: 0.6542032361030579 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6519765853881836 for ['[CLS] luck decca cody outlaw edward deathsdden arsenal [SEP]']
[Init] best perm rec loss: 0.6508176922798157 for ['[CLS]dden outlaw cody luck deaths arsenal edward decca [SEP]']
[Init] best perm rec loss: 0.6498438119888306 for ['[CLS] deathsdden luck cody arsenal edward decca outlaw [SEP]']
[Init] best perm rec loss: 0.6483194828033447 for ['[CLS] outlaw luck edward arsenaldden cody decca deaths [SEP]']
[Init] best perm rec loss: 0.6480438113212585 for ['[CLS] cody decca outlaw luck arsenal edwarddden deaths [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.702 (perp=11.496, rec=0.288, cos=0.115), tot_loss_proj:3.738 [t=0.35s]
prediction: ['[CLS] clap bowhead soft [SEP] tactical clap drop [SEP]']
[ 100/2000] tot_loss=2.632 (perp=12.074, rec=0.186, cos=0.031), tot_loss_proj:3.356 [t=0.35s]
prediction: ['[CLS] ofheadhead soft [SEP] ⇄ claptra [SEP]']
[ 150/2000] tot_loss=2.647 (perp=12.337, rec=0.149, cos=0.031), tot_loss_proj:3.450 [t=0.35s]
prediction: ['[CLS] of metaphysicalhead soft [SEP]tra claptra [SEP]']
[ 200/2000] tot_loss=2.635 (perp=12.337, rec=0.132, cos=0.035), tot_loss_proj:3.457 [t=0.35s]
prediction: ['[CLS] of metaphysicalhead soft [SEP]tra claptra [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.526 (perp=11.835, rec=0.126, cos=0.033), tot_loss_proj:3.125 [t=0.35s]
prediction: ['[CLS] of metaphysical softhead [SEP]tra claptra [SEP]']
[ 300/2000] tot_loss=2.299 (perp=10.805, rec=0.109, cos=0.029), tot_loss_proj:3.130 [t=0.35s]
prediction: ['[CLS] of metaphysical softhead [SEP]tra clapp [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.933 (perp=9.048, rec=0.092, cos=0.031), tot_loss_proj:2.158 [t=0.35s]
prediction: ['[CLS] of metaphysical softhead [SEP] claptrap [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.753 (perp=8.146, rec=0.094, cos=0.030), tot_loss_proj:2.191 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
[ 450/2000] tot_loss=1.742 (perp=8.146, rec=0.081, cos=0.031), tot_loss_proj:2.196 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.735 (perp=8.146, rec=0.075, cos=0.031), tot_loss_proj:2.186 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.750 (perp=8.146, rec=0.090, cos=0.031), tot_loss_proj:2.183 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
[ 600/2000] tot_loss=1.746 (perp=8.146, rec=0.085, cos=0.032), tot_loss_proj:2.188 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.738 (perp=8.146, rec=0.077, cos=0.032), tot_loss_proj:2.187 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.738 (perp=8.146, rec=0.078, cos=0.031), tot_loss_proj:2.184 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
[ 750/2000] tot_loss=1.732 (perp=8.146, rec=0.071, cos=0.031), tot_loss_proj:2.183 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.734 (perp=8.146, rec=0.073, cos=0.032), tot_loss_proj:2.179 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.748 (perp=8.146, rec=0.087, cos=0.031), tot_loss_proj:2.184 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
[ 900/2000] tot_loss=1.734 (perp=8.146, rec=0.073, cos=0.032), tot_loss_proj:2.177 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.732 (perp=8.146, rec=0.072, cos=0.031), tot_loss_proj:2.186 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.735 (perp=8.146, rec=0.074, cos=0.031), tot_loss_proj:2.182 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
[1050/2000] tot_loss=1.743 (perp=8.146, rec=0.083, cos=0.032), tot_loss_proj:2.185 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.734 (perp=8.146, rec=0.073, cos=0.031), tot_loss_proj:2.184 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.731 (perp=8.146, rec=0.071, cos=0.031), tot_loss_proj:2.175 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
[1200/2000] tot_loss=1.738 (perp=8.146, rec=0.077, cos=0.031), tot_loss_proj:2.186 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.744 (perp=8.146, rec=0.083, cos=0.031), tot_loss_proj:2.181 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.733 (perp=8.146, rec=0.072, cos=0.031), tot_loss_proj:2.176 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
[1350/2000] tot_loss=1.738 (perp=8.146, rec=0.078, cos=0.032), tot_loss_proj:2.175 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.733 (perp=8.146, rec=0.072, cos=0.031), tot_loss_proj:2.180 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.737 (perp=8.146, rec=0.076, cos=0.031), tot_loss_proj:2.181 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
[1500/2000] tot_loss=1.730 (perp=8.146, rec=0.070, cos=0.031), tot_loss_proj:2.172 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.734 (perp=8.146, rec=0.073, cos=0.031), tot_loss_proj:2.174 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.728 (perp=8.146, rec=0.068, cos=0.031), tot_loss_proj:2.178 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
[1650/2000] tot_loss=1.732 (perp=8.146, rec=0.072, cos=0.031), tot_loss_proj:2.178 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.732 (perp=8.146, rec=0.072, cos=0.031), tot_loss_proj:2.178 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.736 (perp=8.146, rec=0.075, cos=0.031), tot_loss_proj:2.177 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
[1800/2000] tot_loss=1.741 (perp=8.146, rec=0.080, cos=0.031), tot_loss_proj:2.171 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.736 (perp=8.146, rec=0.075, cos=0.031), tot_loss_proj:2.171 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.735 (perp=8.146, rec=0.074, cos=0.031), tot_loss_proj:2.177 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
[1950/2000] tot_loss=1.731 (perp=8.146, rec=0.070, cos=0.031), tot_loss_proj:2.182 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.740 (perp=8.146, rec=0.080, cos=0.031), tot_loss_proj:2.180 [t=0.35s]
prediction: ['[CLS] [SEP] metaphysical softhead of claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] [SEP] metaphysical softhead of claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 18.182 | p: 16.667 | r: 20.000
rougeL     | fm: 61.538 | p: 57.143 | r: 66.667
rougeLsum  | fm: 61.538 | p: 57.143 | r: 66.667
r1fm+r2fm = 95.105

[Aggregate metrics]:
rouge1     | fm: 92.930 | p: 92.035 | r: 93.952
rouge2     | fm: 62.818 | p: 62.643 | r: 63.026
rougeL     | fm: 82.940 | p: 82.273 | r: 83.690
rougeLsum  | fm: 82.940 | p: 82.067 | r: 83.690
r1fm+r2fm = 155.749

input #9 time: 0:13:40 | total time: 2:12:41


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9877790044226811
highest_index [0]
highest [0.9877790044226811]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8270806074142456 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8154971599578857 for ['[CLS] university mitaonaefa never existing gym backed ribs realmsund odd [SEP]']
[Init] best rec loss: 0.7801873683929443 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.6734578013420105 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 0.6728619933128357 for ['[CLS] themes up sheep blessedblood angel common orderoric places totally level sound [SEP]']
[Init] best perm rec loss: 0.6717370748519897 for ['[CLS]blood common angeloric up sheep order blessed sound level totally places themes [SEP]']
[Init] best perm rec loss: 0.6692526340484619 for ['[CLS] places totally order leveloric themes up blessed common sound sheep angelblood [SEP]']
[Init] best perm rec loss: 0.6683074235916138 for ['[CLS] sheep order blessedoric common places angel themes totally up sound levelblood [SEP]']
[Init] best perm rec loss: 0.6676816344261169 for ['[CLS] places order up soundblood sheep blessed level totally themes angel commonoric [SEP]']
[Init] best perm rec loss: 0.6672400236129761 for ['[CLS] themes common up soundoric level totallyblood sheep angel places blessed order [SEP]']
[Init] best perm rec loss: 0.6661542654037476 for ['[CLS] sound angel blessed level themes up commonoricblood places order totally sheep [SEP]']
[Init] best perm rec loss: 0.664509654045105 for ['[CLS]oric up common level themes order sound angel sheep places blessed totallyblood [SEP]']
[Init] best perm rec loss: 0.6640812754631042 for ['[CLS] levelblood themes totally up blessed places commonoric angel order sheep sound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.479 (perp=10.671, rec=0.305, cos=0.039), tot_loss_proj:3.410 [t=0.35s]
prediction: ['[CLS] oflyulsive more complex loves and passionate contrary approaches revolves clinical laude [SEP]']
[ 100/2000] tot_loss=2.183 (perp=9.632, rec=0.224, cos=0.033), tot_loss_proj:3.068 [t=0.35s]
prediction: ['[CLS] ably ab with tensions ably ab balance rhythms balanceulsively [SEP]']
[ 150/2000] tot_loss=2.090 (perp=9.530, rec=0.154, cos=0.029), tot_loss_proj:2.773 [t=0.35s]
prediction: ['[CLS] ab rhythms ab with real ablyulsiveulsive rhythms balanceulsively [SEP]']
[ 200/2000] tot_loss=2.044 (perp=9.530, rec=0.112, cos=0.026), tot_loss_proj:2.781 [t=0.35s]
prediction: ['[CLS] ab rhythms ab with real ablyulsiveulsive rhythms balanceulsively [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.895 (perp=8.781, rec=0.111, cos=0.028), tot_loss_proj:2.718 [t=0.35s]
prediction: ['[CLS] balance rhythms ab with real ablyulsive incident rhythms abulsively [SEP]']
[ 300/2000] tot_loss=1.874 (perp=8.781, rec=0.091, cos=0.027), tot_loss_proj:2.723 [t=0.35s]
prediction: ['[CLS] balance rhythms ab with real ablyulsive incident rhythms abulsively [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.146 (perp=10.126, rec=0.092, cos=0.029), tot_loss_proj:2.995 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real ablyulsive incident rhythms ab props [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.837 (perp=8.402, rec=0.127, cos=0.030), tot_loss_proj:2.717 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real ab propulsive incident rhythms ablys [SEP]']
[ 450/2000] tot_loss=1.968 (perp=9.245, rec=0.095, cos=0.024), tot_loss_proj:2.974 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real ab timeulsive incident rhythms ablys [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.718 (perp=8.047, rec=0.085, cos=0.024), tot_loss_proj:2.609 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time abulsive incident. ablys [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.717 (perp=8.047, rec=0.084, cos=0.024), tot_loss_proj:2.608 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time abulsive incident. ablys [SEP]']
[ 600/2000] tot_loss=1.716 (perp=8.047, rec=0.083, cos=0.024), tot_loss_proj:2.606 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time abulsive incident. ablys [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.709 (perp=8.047, rec=0.075, cos=0.024), tot_loss_proj:2.610 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time abulsive incident. ablys [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.947 (perp=9.227, rec=0.077, cos=0.024), tot_loss_proj:2.734 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time abulsive incident. proplys [SEP]']
[ 750/2000] tot_loss=1.943 (perp=9.227, rec=0.073, cos=0.024), tot_loss_proj:2.729 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time abulsive incident. proplys [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.644 (perp=7.706, rec=0.078, cos=0.024), tot_loss_proj:2.414 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.641 (perp=7.706, rec=0.075, cos=0.024), tot_loss_proj:2.415 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
[ 900/2000] tot_loss=1.639 (perp=7.706, rec=0.074, cos=0.024), tot_loss_proj:2.419 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.643 (perp=7.706, rec=0.077, cos=0.024), tot_loss_proj:2.420 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1000/2000] tot_loss=1.646 (perp=7.706, rec=0.081, cos=0.024), tot_loss_proj:2.424 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
[1050/2000] tot_loss=1.639 (perp=7.706, rec=0.073, cos=0.024), tot_loss_proj:2.417 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1100/2000] tot_loss=1.636 (perp=7.706, rec=0.070, cos=0.024), tot_loss_proj:2.419 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1150/2000] tot_loss=1.627 (perp=7.706, rec=0.062, cos=0.024), tot_loss_proj:2.421 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
[1200/2000] tot_loss=1.639 (perp=7.706, rec=0.073, cos=0.024), tot_loss_proj:2.422 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1250/2000] tot_loss=1.632 (perp=7.706, rec=0.066, cos=0.024), tot_loss_proj:2.424 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1300/2000] tot_loss=1.640 (perp=7.706, rec=0.074, cos=0.024), tot_loss_proj:2.421 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
[1350/2000] tot_loss=1.633 (perp=7.706, rec=0.067, cos=0.024), tot_loss_proj:2.419 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1400/2000] tot_loss=1.639 (perp=7.706, rec=0.073, cos=0.024), tot_loss_proj:2.432 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1450/2000] tot_loss=1.638 (perp=7.706, rec=0.072, cos=0.024), tot_loss_proj:2.427 [t=0.36s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
[1500/2000] tot_loss=1.640 (perp=7.706, rec=0.074, cos=0.024), tot_loss_proj:2.428 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1550/2000] tot_loss=1.640 (perp=7.706, rec=0.075, cos=0.024), tot_loss_proj:2.423 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1600/2000] tot_loss=1.635 (perp=7.706, rec=0.070, cos=0.024), tot_loss_proj:2.422 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
[1650/2000] tot_loss=1.640 (perp=7.706, rec=0.075, cos=0.024), tot_loss_proj:2.426 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1700/2000] tot_loss=1.640 (perp=7.706, rec=0.074, cos=0.024), tot_loss_proj:2.428 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1750/2000] tot_loss=1.637 (perp=7.706, rec=0.071, cos=0.024), tot_loss_proj:2.424 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
[1800/2000] tot_loss=1.642 (perp=7.706, rec=0.077, cos=0.024), tot_loss_proj:2.424 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1850/2000] tot_loss=1.627 (perp=7.706, rec=0.062, cos=0.024), tot_loss_proj:2.423 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[1900/2000] tot_loss=1.633 (perp=7.706, rec=0.067, cos=0.024), tot_loss_proj:2.428 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
[1950/2000] tot_loss=1.637 (perp=7.706, rec=0.072, cos=0.024), tot_loss_proj:2.424 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Attempt swap
[2000/2000] tot_loss=1.645 (perp=7.706, rec=0.080, cos=0.024), tot_loss_proj:2.428 [t=0.35s]
prediction: ['[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] balance ab rhythms with real time propulsive incident. ablys [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 72.727 | r: 80.000
rouge2     | fm: 31.579 | p: 30.000 | r: 33.333
rougeL     | fm: 57.143 | p: 54.545 | r: 60.000
rougeLsum  | fm: 57.143 | p: 54.545 | r: 60.000
r1fm+r2fm = 107.769

[Aggregate metrics]:
rouge1     | fm: 91.409 | p: 90.279 | r: 92.684
rouge2     | fm: 59.978 | p: 59.675 | r: 60.351
rougeL     | fm: 80.378 | p: 79.565 | r: 81.299
rougeLsum  | fm: 80.453 | p: 79.683 | r: 81.537
r1fm+r2fm = 151.387

input #10 time: 0:13:39 | total time: 2:26:21


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9856332931698809
highest_index [0]
highest [0.9856332931698809]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.8591346740722656 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.857208251953125 for ['[CLS] changelift tonig half moth bodo contractgmche [SEP]']
[Init] best rec loss: 0.8373266458511353 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.7693586349487305 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.7688727974891663 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.7678882479667664 for ['[CLS]gu meture drawn inland mile familiarvd tal platform [SEP]']
[Init] best perm rec loss: 0.7669386267662048 for ['[CLS] inland familiarture mile platformgu me drawnvd tal [SEP]']
[Init] best perm rec loss: 0.7653770446777344 for ['[CLS] talguture me drawn inland milevd familiar platform [SEP]']
[Init] best perm rec loss: 0.7643617987632751 for ['[CLS]guture mile inland me familiar drawnvd tal platform [SEP]']
[Init] best perm rec loss: 0.763391375541687 for ['[CLS] drawnture talgu milevd familiar me inland platform [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.797 (perp=12.196, rec=0.328, cos=0.030), tot_loss_proj:3.710 [t=0.35s]
prediction: ['[CLS] experienced refused gel activists made stubborn refused stubborn refused. [SEP]']
[ 100/2000] tot_loss=2.659 (perp=11.977, rec=0.230, cos=0.033), tot_loss_proj:3.622 [t=0.35s]
prediction: ['[CLS] experienced refused gel attempted that stubborn refused stubborn refusedly [SEP]']
[ 150/2000] tot_loss=2.470 (perp=11.580, rec=0.127, cos=0.027), tot_loss_proj:3.320 [t=0.35s]
prediction: ['[CLS] was was gel attempted that herely stubborn refusedly [SEP]']
[ 200/2000] tot_loss=2.415 (perp=11.455, rec=0.095, cos=0.029), tot_loss_proj:3.123 [t=0.35s]
prediction: ['[CLS] was being gel attempted that herely stubborn refusedly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.990 (perp=9.378, rec=0.086, cos=0.028), tot_loss_proj:2.638 [t=0.35s]
prediction: ['[CLS] was being gel attempted that herely stubbornly refused [SEP]']
[ 300/2000] tot_loss=1.986 (perp=9.392, rec=0.080, cos=0.028), tot_loss_proj:2.804 [t=0.35s]
prediction: ['[CLS] was being gel attempted that here to stubbornly refused [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.791 (perp=8.432, rec=0.077, cos=0.028), tot_loss_proj:2.486 [t=0.35s]
prediction: ['[CLS] was being gel attempted to here that stubbornly refused [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.588 (perp=7.487, rec=0.063, cos=0.028), tot_loss_proj:2.416 [t=0.35s]
prediction: ['[CLS] was being here attempted to gel that stubbornly refused [SEP]']
[ 450/2000] tot_loss=1.604 (perp=7.487, rec=0.078, cos=0.028), tot_loss_proj:2.409 [t=0.35s]
prediction: ['[CLS] was being here attempted to gel that stubbornly refused [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.431 (perp=6.665, rec=0.070, cos=0.028), tot_loss_proj:2.110 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.437 (perp=6.665, rec=0.076, cos=0.028), tot_loss_proj:2.110 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
[ 600/2000] tot_loss=1.429 (perp=6.665, rec=0.067, cos=0.028), tot_loss_proj:2.114 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.428 (perp=6.665, rec=0.066, cos=0.029), tot_loss_proj:2.115 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.438 (perp=6.665, rec=0.076, cos=0.028), tot_loss_proj:2.117 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
[ 750/2000] tot_loss=1.437 (perp=6.665, rec=0.075, cos=0.028), tot_loss_proj:2.111 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.425 (perp=6.665, rec=0.063, cos=0.029), tot_loss_proj:2.107 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.428 (perp=6.665, rec=0.067, cos=0.028), tot_loss_proj:2.111 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
[ 900/2000] tot_loss=1.426 (perp=6.665, rec=0.064, cos=0.029), tot_loss_proj:2.114 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.423 (perp=6.665, rec=0.062, cos=0.028), tot_loss_proj:2.107 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1000/2000] tot_loss=1.427 (perp=6.665, rec=0.065, cos=0.028), tot_loss_proj:2.111 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
[1050/2000] tot_loss=1.427 (perp=6.665, rec=0.066, cos=0.028), tot_loss_proj:2.115 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1100/2000] tot_loss=1.436 (perp=6.665, rec=0.074, cos=0.029), tot_loss_proj:2.113 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1150/2000] tot_loss=1.431 (perp=6.665, rec=0.070, cos=0.029), tot_loss_proj:2.117 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
[1200/2000] tot_loss=1.418 (perp=6.665, rec=0.056, cos=0.028), tot_loss_proj:2.124 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1250/2000] tot_loss=1.424 (perp=6.665, rec=0.063, cos=0.029), tot_loss_proj:2.114 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1300/2000] tot_loss=1.422 (perp=6.665, rec=0.060, cos=0.028), tot_loss_proj:2.114 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
[1350/2000] tot_loss=1.431 (perp=6.665, rec=0.070, cos=0.029), tot_loss_proj:2.116 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1400/2000] tot_loss=1.435 (perp=6.665, rec=0.074, cos=0.028), tot_loss_proj:2.114 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1450/2000] tot_loss=1.429 (perp=6.665, rec=0.067, cos=0.028), tot_loss_proj:2.112 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
[1500/2000] tot_loss=1.420 (perp=6.665, rec=0.059, cos=0.028), tot_loss_proj:2.114 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1550/2000] tot_loss=1.440 (perp=6.665, rec=0.078, cos=0.029), tot_loss_proj:2.120 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1600/2000] tot_loss=1.431 (perp=6.665, rec=0.070, cos=0.029), tot_loss_proj:2.113 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
[1650/2000] tot_loss=1.415 (perp=6.665, rec=0.053, cos=0.028), tot_loss_proj:2.117 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1700/2000] tot_loss=1.426 (perp=6.665, rec=0.064, cos=0.029), tot_loss_proj:2.119 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1750/2000] tot_loss=1.427 (perp=6.665, rec=0.065, cos=0.028), tot_loss_proj:2.116 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
[1800/2000] tot_loss=1.437 (perp=6.665, rec=0.075, cos=0.029), tot_loss_proj:2.115 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1850/2000] tot_loss=1.429 (perp=6.665, rec=0.068, cos=0.029), tot_loss_proj:2.116 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1900/2000] tot_loss=1.425 (perp=6.665, rec=0.063, cos=0.029), tot_loss_proj:2.118 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
[1950/2000] tot_loss=1.421 (perp=6.665, rec=0.060, cos=0.028), tot_loss_proj:2.115 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Attempt swap
[2000/2000] tot_loss=1.427 (perp=6.665, rec=0.065, cos=0.029), tot_loss_proj:2.110 [t=0.35s]
prediction: ['[CLS] here was being attempted to gel that stubbornly refused [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was being attempted to gel that stubbornly refused [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 92.125 | p: 91.089 | r: 93.333
rouge2     | fm: 59.583 | p: 59.544 | r: 59.905
rougeL     | fm: 79.740 | p: 78.995 | r: 80.622
rougeLsum  | fm: 79.922 | p: 79.158 | r: 80.618
r1fm+r2fm = 151.708

input #11 time: 0:13:40 | total time: 2:40:01


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.9812579311328733
highest_index [0]
highest [0.9812579311328733]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8445326685905457 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.832097589969635 for ['[CLS] systems simonway met armenia blockade tongue when unisonizes and present reeve representatives [SEP]']
[Init] best rec loss: 0.7894740700721741 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7872393131256104 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7811388373374939 for ['[CLS] wolf rex usualli plant live painfully sqlamtpemi wallace du sort [SEP]']
[Init] best rec loss: 0.7786656618118286 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7670575380325317 for ['[CLS] this heart hot noise fixing trying system potential salt ifana defense ii alexandria [SEP]']
[Init] best rec loss: 0.7657082676887512 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best rec loss: 0.7576602101325989 for ['[CLS] hear protocol heidi race strokes safety association transactions snail most place buried terror documentary [SEP]']
[Init] best rec loss: 0.7342955470085144 for ['[CLS] alive expression semiuid wise friend investigationthed beloved [MASK] got richards didnbank [SEP]']
[Init] best perm rec loss: 0.7333981990814209 for ['[CLS] gotbank wiseuid friend semi didn richards [MASK] alivethed expression beloved investigation [SEP]']
[Init] best perm rec loss: 0.733394205570221 for ['[CLS] didnbank gotthed wise semi expressionuid friend investigation beloved [MASK] richards alive [SEP]']
[Init] best perm rec loss: 0.7330887913703918 for ['[CLS]bank aliveuid expression wise semi investigation friendthed got [MASK] beloved richards didn [SEP]']
[Init] best perm rec loss: 0.7304422855377197 for ['[CLS] semi [MASK] wise alive got expression friendbankthed beloved richards investigation didnuid [SEP]']
[Init] best perm rec loss: 0.7295185923576355 for ['[CLS] richardsuid [MASK]bank beloved didn friendthed wise investigation alive got semi expression [SEP]']
[Init] best perm rec loss: 0.7292144894599915 for ['[CLS] wiseuid expressionbank beloved alive richards didn [MASK]thed got friend investigation semi [SEP]']
[Init] best perm rec loss: 0.728326678276062 for ['[CLS]thed alivebank richards friend didn semi [MASK]uid investigation expression beloved wise got [SEP]']
[Init] best perm rec loss: 0.7277824282646179 for ['[CLS] alive got investigation didn [MASK] semi wise expressiontheduid richardsbank friend beloved [SEP]']
[Init] best perm rec loss: 0.7274481058120728 for ['[CLS] beloved wisethed alive investigation expression didn [MASK]bank richards friend gotuid semi [SEP]']
[Init] best perm rec loss: 0.7231535315513611 for ['[CLS]thedbank semi alive beloved wise expression friend gotuid [MASK] didn richards investigation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.717 (perp=11.737, rec=0.316, cos=0.054), tot_loss_proj:3.297 [t=0.35s]
prediction: ['[CLS] advantage prove best less cable cable safer on better not on barely advantage better [SEP]']
[ 100/2000] tot_loss=2.419 (perp=10.844, rec=0.213, cos=0.037), tot_loss_proj:3.151 [t=0.35s]
prediction: ['[CLS] advantage most top less cable cable better on better barely on barely advantage better [SEP]']
[ 150/2000] tot_loss=2.333 (perp=10.784, rec=0.142, cos=0.034), tot_loss_proj:3.005 [t=0.35s]
prediction: ['[CLS] will itstly more cable cable seen on better advantage its barely advantage seen [SEP]']
[ 200/2000] tot_loss=2.229 (perp=10.353, rec=0.122, cos=0.035), tot_loss_proj:2.970 [t=0.35s]
prediction: ['[CLS] will its its more cable cable been on better advantage its barely advantage seen [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.148 (perp=9.975, rec=0.117, cos=0.036), tot_loss_proj:2.773 [t=0.35s]
prediction: ['[CLS] will its be sake seen cable cable to on better advantage its barely advantage [SEP]']
[ 300/2000] tot_loss=2.152 (perp=10.070, rec=0.101, cos=0.037), tot_loss_proj:2.862 [t=0.35s]
prediction: ['[CLS] will but be be seen cable cable to on better advantage considering barely advantage [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.008 (perp=9.410, rec=0.089, cos=0.037), tot_loss_proj:2.673 [t=0.35s]
prediction: ['[CLS] will especially be seen cable cable to as on better advantage considering barely advantage [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.012 (perp=8.949, rec=0.173, cos=0.049), tot_loss_proj:2.954 [t=0.35s]
prediction: ['[CLS] will especially be seen cable! to advantage on better, considering barely as [SEP]']
[ 450/2000] tot_loss=1.902 (perp=8.805, rec=0.104, cos=0.037), tot_loss_proj:2.861 [t=0.35s]
prediction: ['[CLS] will especially be seen cable on to advantage on better, considering barely as [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.780 (perp=8.189, rec=0.105, cos=0.037), tot_loss_proj:2.939 [t=0.35s]
prediction: ['[CLS] will especially be seen on cable to advantage on better, considering barely not [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.669 (perp=7.619, rec=0.108, cos=0.037), tot_loss_proj:2.359 [t=0.35s]
prediction: ['[CLS] will barely be seen on cable to advantage on better, considering especially not [SEP]']
[ 600/2000] tot_loss=1.654 (perp=7.619, rec=0.093, cos=0.037), tot_loss_proj:2.368 [t=0.35s]
prediction: ['[CLS] will barely be seen on cable to advantage on better, considering especially not [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.568 (perp=7.236, rec=0.084, cos=0.037), tot_loss_proj:2.286 [t=0.35s]
prediction: ['[CLS] will barely be seen on cable to advantage on better, especially considering not [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.530 (perp=7.018, rec=0.089, cos=0.037), tot_loss_proj:2.187 [t=0.35s]
prediction: ['[CLS] will barely be seen on cable to on better advantage, especially considering not [SEP]']
[ 750/2000] tot_loss=1.700 (perp=7.848, rec=0.094, cos=0.037), tot_loss_proj:2.376 [t=0.35s]
prediction: ['[CLS] will barely that seen on cable to on better advantage, especially considering not [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.592 (perp=7.367, rec=0.081, cos=0.037), tot_loss_proj:2.309 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to on better advantage, especially considering not [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.635 (perp=7.559, rec=0.087, cos=0.037), tot_loss_proj:2.392 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to on better advantage, especially considering be [SEP]']
[ 900/2000] tot_loss=1.695 (perp=7.870, rec=0.083, cos=0.037), tot_loss_proj:2.382 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to is better advantage, especially considering be [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.523 (perp=7.022, rec=0.082, cos=0.037), tot_loss_proj:2.326 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable is to better advantage, especially considering be [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.542 (perp=7.091, rec=0.088, cos=0.036), tot_loss_proj:2.233 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to better advantage, especially considering its be [SEP]']
[1050/2000] tot_loss=1.532 (perp=7.091, rec=0.077, cos=0.037), tot_loss_proj:2.231 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to better advantage, especially considering its be [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.529 (perp=7.031, rec=0.086, cos=0.037), tot_loss_proj:2.236 [t=0.35s]
prediction: ['[CLS] barely will that seen not on cable to better advantage, especially considering its [SEP]']
Attempt swap
[1150/2000] tot_loss=1.521 (perp=7.031, rec=0.078, cos=0.037), tot_loss_proj:2.232 [t=0.35s]
prediction: ['[CLS] barely will that seen not on cable to better advantage, especially considering its [SEP]']
[1200/2000] tot_loss=1.526 (perp=7.031, rec=0.083, cos=0.037), tot_loss_proj:2.238 [t=0.35s]
prediction: ['[CLS] barely will that seen not on cable to better advantage, especially considering its [SEP]']
Attempt swap
[1250/2000] tot_loss=1.517 (perp=7.031, rec=0.074, cos=0.037), tot_loss_proj:2.232 [t=0.35s]
prediction: ['[CLS] barely will that seen not on cable to better advantage, especially considering its [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.494 (perp=6.906, rec=0.078, cos=0.035), tot_loss_proj:2.248 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable not to better advantage, especially considering its [SEP]']
[1350/2000] tot_loss=1.492 (perp=6.906, rec=0.074, cos=0.036), tot_loss_proj:2.249 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable not to better advantage, especially considering its [SEP]']
Attempt swap
[1400/2000] tot_loss=1.494 (perp=6.906, rec=0.076, cos=0.037), tot_loss_proj:2.253 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable not to better advantage, especially considering its [SEP]']
Attempt swap
[1450/2000] tot_loss=1.497 (perp=6.906, rec=0.079, cos=0.037), tot_loss_proj:2.246 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable not to better advantage, especially considering its [SEP]']
[1500/2000] tot_loss=1.488 (perp=6.906, rec=0.070, cos=0.037), tot_loss_proj:2.252 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable not to better advantage, especially considering its [SEP]']
Attempt swap
[1550/2000] tot_loss=1.492 (perp=6.906, rec=0.073, cos=0.037), tot_loss_proj:2.259 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable not to better advantage, especially considering its [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.490 (perp=6.864, rec=0.081, cos=0.037), tot_loss_proj:2.263 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to not better advantage, especially considering its [SEP]']
[1650/2000] tot_loss=1.490 (perp=6.864, rec=0.080, cos=0.037), tot_loss_proj:2.264 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to not better advantage, especially considering its [SEP]']
Attempt swap
[1700/2000] tot_loss=1.490 (perp=6.864, rec=0.080, cos=0.037), tot_loss_proj:2.265 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to not better advantage, especially considering its [SEP]']
Attempt swap
[1750/2000] tot_loss=1.488 (perp=6.864, rec=0.078, cos=0.037), tot_loss_proj:2.260 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to not better advantage, especially considering its [SEP]']
[1800/2000] tot_loss=1.483 (perp=6.864, rec=0.073, cos=0.037), tot_loss_proj:2.260 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to not better advantage, especially considering its [SEP]']
Attempt swap
[1850/2000] tot_loss=1.477 (perp=6.864, rec=0.068, cos=0.037), tot_loss_proj:2.269 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to not better advantage, especially considering its [SEP]']
Attempt swap
[1900/2000] tot_loss=1.490 (perp=6.864, rec=0.080, cos=0.037), tot_loss_proj:2.259 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to not better advantage, especially considering its [SEP]']
[1950/2000] tot_loss=1.474 (perp=6.864, rec=0.065, cos=0.037), tot_loss_proj:2.263 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to not better advantage, especially considering its [SEP]']
Attempt swap
[2000/2000] tot_loss=1.488 (perp=6.864, rec=0.078, cos=0.037), tot_loss_proj:2.266 [t=0.35s]
prediction: ['[CLS] barely will that seen on cable to not better advantage, especially considering its [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] barely will that seen on cable to not better advantage, especially considering its [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 121.905

[Aggregate metrics]:
rouge1     | fm: 92.218 | p: 91.362 | r: 93.297
rouge2     | fm: 57.026 | p: 56.758 | r: 57.402
rougeL     | fm: 78.685 | p: 77.951 | r: 79.555
rougeLsum  | fm: 78.474 | p: 77.897 | r: 79.207
r1fm+r2fm = 149.244

input #12 time: 0:13:42 | total time: 2:53:44


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9842834639578762
highest_index [0]
highest [0.9842834639578762]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.6972054839134216 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.6871780753135681 for ['[CLS] baccalaureate, black saunderstec armed much [SEP]']
[Init] best rec loss: 0.6850460171699524 for ['[CLS] armchairitic from arrived operation negative india [SEP]']
[Init] best perm rec loss: 0.683405339717865 for ['[CLS]itic armchair arrived from operation negative india [SEP]']
[Init] best perm rec loss: 0.6826673746109009 for ['[CLS]itic arrived india from operation armchair negative [SEP]']
[Init] best perm rec loss: 0.6825709939002991 for ['[CLS]itic armchair india arrived from negative operation [SEP]']
[Init] best perm rec loss: 0.6824772357940674 for ['[CLS] armchairitic from arrived india operation negative [SEP]']
[Init] best perm rec loss: 0.6821669340133667 for ['[CLS]itic operation from armchair india negative arrived [SEP]']
[Init] best perm rec loss: 0.6812763810157776 for ['[CLS] from indiaitic arrived armchair negative operation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.643 (perp=11.720, rec=0.245, cos=0.054), tot_loss_proj:3.133 [t=0.35s]
prediction: ['[CLS] explode intoity point into explode flame [SEP]']
[ 100/2000] tot_loss=2.360 (perp=10.879, rec=0.150, cos=0.034), tot_loss_proj:3.093 [t=0.35s]
prediction: ['[CLS] point into at point into explode flame [SEP]']
[ 150/2000] tot_loss=2.179 (perp=10.344, rec=0.079, cos=0.031), tot_loss_proj:2.929 [t=0.35s]
prediction: ['[CLS] at into things point that explode flame [SEP]']
[ 200/2000] tot_loss=2.175 (perp=10.344, rec=0.075, cos=0.031), tot_loss_proj:2.913 [t=0.35s]
prediction: ['[CLS] at into things point that explode flame [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.757 (perp=8.294, rec=0.070, cos=0.028), tot_loss_proj:2.166 [t=0.35s]
prediction: ['[CLS] at things point that explode into flame [SEP]']
[ 300/2000] tot_loss=1.750 (perp=8.294, rec=0.060, cos=0.031), tot_loss_proj:2.147 [t=0.35s]
prediction: ['[CLS] at things point that explode into flame [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.397 (perp=6.423, rec=0.084, cos=0.028), tot_loss_proj:1.946 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.390 (perp=6.423, rec=0.074, cos=0.030), tot_loss_proj:1.951 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 450/2000] tot_loss=1.383 (perp=6.423, rec=0.067, cos=0.031), tot_loss_proj:1.949 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.369 (perp=6.423, rec=0.054, cos=0.031), tot_loss_proj:1.950 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.381 (perp=6.423, rec=0.065, cos=0.031), tot_loss_proj:1.945 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 600/2000] tot_loss=1.384 (perp=6.423, rec=0.068, cos=0.031), tot_loss_proj:1.949 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.371 (perp=6.423, rec=0.056, cos=0.031), tot_loss_proj:1.944 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.381 (perp=6.423, rec=0.065, cos=0.031), tot_loss_proj:1.944 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 750/2000] tot_loss=1.387 (perp=6.423, rec=0.072, cos=0.031), tot_loss_proj:1.948 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.381 (perp=6.423, rec=0.065, cos=0.031), tot_loss_proj:1.944 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.369 (perp=6.423, rec=0.053, cos=0.031), tot_loss_proj:1.940 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 900/2000] tot_loss=1.372 (perp=6.423, rec=0.056, cos=0.031), tot_loss_proj:1.942 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.379 (perp=6.423, rec=0.063, cos=0.031), tot_loss_proj:1.943 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.383 (perp=6.423, rec=0.068, cos=0.031), tot_loss_proj:1.943 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1050/2000] tot_loss=1.370 (perp=6.423, rec=0.055, cos=0.031), tot_loss_proj:1.945 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.382 (perp=6.423, rec=0.066, cos=0.031), tot_loss_proj:1.938 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.377 (perp=6.423, rec=0.061, cos=0.031), tot_loss_proj:1.943 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1200/2000] tot_loss=1.378 (perp=6.423, rec=0.063, cos=0.031), tot_loss_proj:1.936 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.369 (perp=6.423, rec=0.053, cos=0.031), tot_loss_proj:1.938 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.389 (perp=6.423, rec=0.073, cos=0.031), tot_loss_proj:1.935 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1350/2000] tot_loss=1.373 (perp=6.423, rec=0.058, cos=0.031), tot_loss_proj:1.937 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.376 (perp=6.423, rec=0.060, cos=0.031), tot_loss_proj:1.940 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.369 (perp=6.423, rec=0.054, cos=0.031), tot_loss_proj:1.944 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1500/2000] tot_loss=1.381 (perp=6.423, rec=0.065, cos=0.031), tot_loss_proj:1.946 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.375 (perp=6.423, rec=0.059, cos=0.031), tot_loss_proj:1.939 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.369 (perp=6.423, rec=0.053, cos=0.031), tot_loss_proj:1.938 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1650/2000] tot_loss=1.380 (perp=6.423, rec=0.064, cos=0.031), tot_loss_proj:1.939 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.380 (perp=6.423, rec=0.064, cos=0.031), tot_loss_proj:1.944 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.371 (perp=6.423, rec=0.056, cos=0.031), tot_loss_proj:1.935 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1800/2000] tot_loss=1.377 (perp=6.423, rec=0.061, cos=0.031), tot_loss_proj:1.932 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.385 (perp=6.423, rec=0.070, cos=0.031), tot_loss_proj:1.934 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.378 (perp=6.423, rec=0.063, cos=0.031), tot_loss_proj:1.941 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1950/2000] tot_loss=1.374 (perp=6.423, rec=0.058, cos=0.031), tot_loss_proj:1.939 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.379 (perp=6.423, rec=0.063, cos=0.031), tot_loss_proj:1.942 [t=0.35s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] at that point things explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 92.773 | p: 91.979 | r: 93.810
rouge2     | fm: 55.568 | p: 55.357 | r: 55.818
rougeL     | fm: 78.682 | p: 78.169 | r: 79.347
rougeLsum  | fm: 78.644 | p: 77.958 | r: 79.423
r1fm+r2fm = 148.342

input #13 time: 0:13:39 | total time: 3:07:24


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9879476828999336
highest_index [0]
highest [0.9879476828999336]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9892433881759644 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9834450483322144 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9781503677368164 for ['[CLS] green stepped one battle rear [SEP]']
[Init] best rec loss: 0.9723073244094849 for ['[CLS] appeared ins explosion deer stephen [SEP]']
[Init] best rec loss: 0.9677239060401917 for ['[CLS] gps war break stream carriage [SEP]']
[Init] best rec loss: 0.9568302035331726 for ['[CLS] female pants hard surely olympics [SEP]']
[Init] best rec loss: 0.9558688998222351 for ['[CLS]pace chicago is thrust youth [SEP]']
[Init] best rec loss: 0.9534326791763306 for ['[CLS] baton channel along presided corners [SEP]']
[Init] best rec loss: 0.9426746964454651 for ['[CLS] strategy sigh hk automatically county [SEP]']
[Init] best rec loss: 0.942600429058075 for ['[CLS] initial freeway spannged extended [SEP]']
[Init] best perm rec loss: 0.9397748112678528 for ['[CLS]nged extended freeway span initial [SEP]']
[Init] best perm rec loss: 0.9397681951522827 for ['[CLS] freeway extended span initialnged [SEP]']
[Init] best perm rec loss: 0.9381663799285889 for ['[CLS] freeway extendednged span initial [SEP]']
[Init] best perm rec loss: 0.9377241134643555 for ['[CLS] initial extendednged span freeway [SEP]']
[Init] best perm rec loss: 0.9365516304969788 for ['[CLS] freeway extendednged initial span [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.525 (perp=12.587, rec=0.644, cos=0.363), tot_loss_proj:4.395 [t=0.35s]
prediction: ['[CLS] quite arrivalbled _ depths [SEP]']
[ 100/2000] tot_loss=3.698 (perp=13.173, rec=0.688, cos=0.376), tot_loss_proj:4.199 [t=0.35s]
prediction: ['[CLS] quite finallyblynburg lands [SEP]']
[ 150/2000] tot_loss=3.237 (perp=12.699, rec=0.566, cos=0.132), tot_loss_proj:3.993 [t=0.35s]
prediction: ['[CLS] political forebly overwhelming intriguing [SEP]']
[ 200/2000] tot_loss=3.627 (perp=14.959, rec=0.536, cos=0.099), tot_loss_proj:4.067 [t=0.35s]
prediction: ['[CLS] political intriguingblyenia intriguing [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.520 (perp=14.122, rec=0.556, cos=0.139), tot_loss_proj:3.757 [t=0.35s]
prediction: ['[CLS]enia politicaltativebly intriguing [SEP]']
[ 300/2000] tot_loss=3.067 (perp=12.359, rec=0.521, cos=0.075), tot_loss_proj:3.736 [t=0.35s]
prediction: ['[CLS] und quite 》bly intriguing [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.825 (perp=11.223, rec=0.504, cos=0.077), tot_loss_proj:3.889 [t=0.35s]
prediction: ['[CLS] nowhere undtativebly intriguing [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.534 (perp=13.940, rec=0.573, cos=0.173), tot_loss_proj:4.618 [t=0.35s]
prediction: ['[CLS] pissed filmfare undbly thousands [SEP]']
[ 450/2000] tot_loss=2.854 (perp=11.465, rec=0.499, cos=0.061), tot_loss_proj:4.012 [t=0.35s]
prediction: ['[CLS] nowhere arrive undbly thousands [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.770 (perp=11.082, rec=0.499, cos=0.054), tot_loss_proj:3.410 [t=0.35s]
prediction: ['[CLS] novel thriller undbly intriguing [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.749 (perp=11.082, rec=0.482, cos=0.051), tot_loss_proj:3.409 [t=0.35s]
prediction: ['[CLS] novel thriller undbly intriguing [SEP]']
[ 600/2000] tot_loss=3.178 (perp=12.280, rec=0.566, cos=0.155), tot_loss_proj:4.422 [t=0.35s]
prediction: ['[CLS] worst 《eniably intriguing [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.048 (perp=12.229, rec=0.513, cos=0.090), tot_loss_proj:4.349 [t=0.35s]
prediction: ['[CLS] intriguing arrive undbly worst [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=3.276 (perp=13.478, rec=0.504, cos=0.076), tot_loss_proj:4.681 [t=0.35s]
prediction: ['[CLS] intriguingtativebly thousandudged [SEP]']
[ 750/2000] tot_loss=3.205 (perp=13.293, rec=0.490, cos=0.056), tot_loss_proj:3.744 [t=0.35s]
prediction: ['[CLS] intriguing intriguingbly thousandworthy [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.168 (perp=13.059, rec=0.496, cos=0.060), tot_loss_proj:4.621 [t=0.35s]
prediction: ['[CLS] thousand intriguingbly intriguing nowhere [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=3.452 (perp=14.060, rec=0.509, cos=0.131), tot_loss_proj:4.646 [t=0.35s]
prediction: ['[CLS] painfullyblytative intriguingudged [SEP]']
[ 900/2000] tot_loss=3.064 (perp=12.638, rec=0.482, cos=0.054), tot_loss_proj:4.352 [t=0.35s]
prediction: ['[CLS] thousandbly outsider intriguing nowhere [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.967 (perp=12.196, rec=0.476, cos=0.051), tot_loss_proj:4.392 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing intriguing nowhere [SEP]']
Attempt swap
[1000/2000] tot_loss=2.963 (perp=12.196, rec=0.481, cos=0.043), tot_loss_proj:4.395 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing intriguing nowhere [SEP]']
[1050/2000] tot_loss=2.789 (perp=11.373, rec=0.468, cos=0.046), tot_loss_proj:2.729 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing intriguing intriguing [SEP]']
Attempt swap
[1100/2000] tot_loss=2.793 (perp=11.373, rec=0.474, cos=0.045), tot_loss_proj:2.734 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing intriguing intriguing [SEP]']
Attempt swap
[1150/2000] tot_loss=2.784 (perp=11.373, rec=0.465, cos=0.044), tot_loss_proj:2.730 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing intriguing intriguing [SEP]']
[1200/2000] tot_loss=2.785 (perp=11.373, rec=0.467, cos=0.043), tot_loss_proj:2.740 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing intriguing intriguing [SEP]']
Attempt swap
[1250/2000] tot_loss=2.776 (perp=11.373, rec=0.460, cos=0.042), tot_loss_proj:2.736 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing intriguing intriguing [SEP]']
Attempt swap
[1300/2000] tot_loss=2.782 (perp=11.373, rec=0.465, cos=0.042), tot_loss_proj:2.729 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing intriguing intriguing [SEP]']
[1350/2000] tot_loss=2.808 (perp=11.373, rec=0.470, cos=0.063), tot_loss_proj:2.735 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing intriguing intriguing [SEP]']
Attempt swap
[1400/2000] tot_loss=2.770 (perp=11.319, rec=0.466, cos=0.041), tot_loss_proj:2.749 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing interesting intriguing [SEP]']
Attempt swap
[1450/2000] tot_loss=2.762 (perp=11.319, rec=0.459, cos=0.040), tot_loss_proj:2.739 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing interesting intriguing [SEP]']
[1500/2000] tot_loss=2.765 (perp=11.319, rec=0.462, cos=0.040), tot_loss_proj:2.747 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing interesting intriguing [SEP]']
Attempt swap
[1550/2000] tot_loss=2.765 (perp=11.319, rec=0.462, cos=0.039), tot_loss_proj:2.747 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing interesting intriguing [SEP]']
Attempt swap
[1600/2000] tot_loss=2.770 (perp=11.319, rec=0.467, cos=0.039), tot_loss_proj:2.743 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing interesting intriguing [SEP]']
[1650/2000] tot_loss=2.762 (perp=11.319, rec=0.460, cos=0.039), tot_loss_proj:2.739 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing interesting intriguing [SEP]']
Attempt swap
[1700/2000] tot_loss=2.764 (perp=11.319, rec=0.462, cos=0.039), tot_loss_proj:2.748 [t=0.35s]
prediction: ['[CLS] thousandbly intriguing interesting intriguing [SEP]']
Attempt swap
[1750/2000] tot_loss=2.652 (perp=10.757, rec=0.463, cos=0.038), tot_loss_proj:2.577 [t=0.35s]
prediction: ['[CLS]eniably intriguing interesting intriguing [SEP]']
[1800/2000] tot_loss=2.652 (perp=10.757, rec=0.463, cos=0.038), tot_loss_proj:2.576 [t=0.35s]
prediction: ['[CLS]eniably intriguing interesting intriguing [SEP]']
Attempt swap
[1850/2000] tot_loss=2.644 (perp=10.757, rec=0.455, cos=0.037), tot_loss_proj:2.580 [t=0.35s]
prediction: ['[CLS]eniably intriguing interesting intriguing [SEP]']
Attempt swap
[1900/2000] tot_loss=2.648 (perp=10.757, rec=0.459, cos=0.037), tot_loss_proj:2.569 [t=0.35s]
prediction: ['[CLS]eniably intriguing interesting intriguing [SEP]']
[1950/2000] tot_loss=2.650 (perp=10.757, rec=0.461, cos=0.037), tot_loss_proj:2.578 [t=0.35s]
prediction: ['[CLS]eniably intriguing interesting intriguing [SEP]']
Attempt swap
[2000/2000] tot_loss=2.642 (perp=10.757, rec=0.453, cos=0.037), tot_loss_proj:2.565 [t=0.35s]
prediction: ['[CLS]eniably intriguing interesting intriguing [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] thousandbly intriguing interesting intriguing [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.545 | p: 50.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 54.545 | p: 50.000 | r: 60.000
rougeLsum  | fm: 54.545 | p: 50.000 | r: 60.000
r1fm+r2fm = 54.545

[Aggregate metrics]:
rouge1     | fm: 90.250 | p: 89.094 | r: 91.524
rouge2     | fm: 51.824 | p: 51.643 | r: 51.970
rougeL     | fm: 77.141 | p: 76.278 | r: 78.143
rougeLsum  | fm: 76.832 | p: 75.957 | r: 77.909
r1fm+r2fm = 142.075

input #14 time: 0:13:36 | total time: 3:21:01


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.9882010610052243
highest_index [0]
highest [0.9882010610052243]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.8243247270584106 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.8238210082054138 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 0.8134686350822449 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.8015079498291016 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.7876311540603638 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best perm rec loss: 0.7873508334159851 for ['[CLS] martha much diner [CLS]gly trooper safe consumer [SEP]']
[Init] best perm rec loss: 0.7851437926292419 for ['[CLS] martha safe trooper diner muchgly consumer [CLS] [SEP]']
[Init] best perm rec loss: 0.7846745252609253 for ['[CLS] much trooper consumergly martha diner safe [CLS] [SEP]']
[Init] best perm rec loss: 0.7845954895019531 for ['[CLS] martha much [CLS] troopergly safe diner consumer [SEP]']
[Init] best perm rec loss: 0.7843344807624817 for ['[CLS]gly safe diner consumer much trooper martha [CLS] [SEP]']
[Init] best perm rec loss: 0.7832544445991516 for ['[CLS] consumer trooper martha safe diner [CLS]gly much [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.812 (perp=12.657, rec=0.255, cos=0.026), tot_loss_proj:3.496 [t=0.35s]
prediction: ['[CLS]op chill. efficient efficient playableably efficient [SEP]']
[ 100/2000] tot_loss=2.987 (perp=13.858, rec=0.190, cos=0.025), tot_loss_proj:4.440 [t=0.35s]
prediction: ['[CLS] chill chill anonymous efficient efficientableablyer [SEP]']
[ 150/2000] tot_loss=2.952 (perp=13.858, rec=0.157, cos=0.024), tot_loss_proj:4.437 [t=0.35s]
prediction: ['[CLS] chill chill anonymous efficient efficientableablyer [SEP]']
[ 200/2000] tot_loss=2.765 (perp=12.998, rec=0.142, cos=0.024), tot_loss_proj:3.953 [t=0.35s]
prediction: ['[CLS]tight chill anonymous efficient efficientable suiter [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.706 (perp=12.833, rec=0.116, cos=0.023), tot_loss_proj:3.763 [t=0.35s]
prediction: ['[CLS] chill suit anonymousably efficientable suiter [SEP]']
[ 300/2000] tot_loss=2.429 (perp=11.524, rec=0.101, cos=0.023), tot_loss_proj:3.168 [t=0.35s]
prediction: ['[CLS] chill suit anonymousably efficient, suiter [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.044 (perp=9.615, rec=0.098, cos=0.023), tot_loss_proj:2.509 [t=0.35s]
prediction: ['[CLS] chill suitably efficient, anonymous suiter [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.835 (perp=8.492, rec=0.114, cos=0.023), tot_loss_proj:1.996 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous suit chiller [SEP]']
[ 450/2000] tot_loss=1.809 (perp=8.492, rec=0.087, cos=0.023), tot_loss_proj:2.004 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous suit chiller [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.884 (perp=8.878, rec=0.085, cos=0.023), tot_loss_proj:2.282 [t=0.35s]
prediction: ['[CLS] statementably efficient, anonymous chiller suit [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.743 (perp=8.179, rec=0.084, cos=0.023), tot_loss_proj:2.057 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chillergiving [SEP]']
[ 600/2000] tot_loss=1.735 (perp=8.179, rec=0.076, cos=0.023), tot_loss_proj:2.055 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chillergiving [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.745 (perp=8.179, rec=0.086, cos=0.023), tot_loss_proj:2.057 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chillergiving [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.443 (perp=6.697, rec=0.081, cos=0.023), tot_loss_proj:1.552 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.443 (perp=6.697, rec=0.081, cos=0.023), tot_loss_proj:1.550 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.440 (perp=6.697, rec=0.078, cos=0.023), tot_loss_proj:1.552 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.437 (perp=6.697, rec=0.074, cos=0.023), tot_loss_proj:1.555 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.436 (perp=6.697, rec=0.073, cos=0.023), tot_loss_proj:1.553 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.441 (perp=6.697, rec=0.078, cos=0.023), tot_loss_proj:1.545 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.448 (perp=6.697, rec=0.085, cos=0.023), tot_loss_proj:1.557 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.728 (perp=8.179, rec=0.069, cos=0.023), tot_loss_proj:2.052 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chillergiving [SEP]']
Attempt swap
[1100/2000] tot_loss=1.744 (perp=8.179, rec=0.085, cos=0.023), tot_loss_proj:2.057 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chillergiving [SEP]']
Attempt swap
[1150/2000] tot_loss=1.730 (perp=8.179, rec=0.071, cos=0.023), tot_loss_proj:2.057 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chillergiving [SEP]']
[1200/2000] tot_loss=1.538 (perp=7.208, rec=0.073, cos=0.023), tot_loss_proj:1.726 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller! [SEP]']
Attempt swap
[1250/2000] tot_loss=1.545 (perp=7.208, rec=0.080, cos=0.023), tot_loss_proj:1.726 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller! [SEP]']
Attempt swap
[1300/2000] tot_loss=1.546 (perp=7.240, rec=0.075, cos=0.023), tot_loss_proj:1.697 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller ; [SEP]']
[1350/2000] tot_loss=1.550 (perp=7.240, rec=0.079, cos=0.023), tot_loss_proj:1.692 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller ; [SEP]']
Attempt swap
[1400/2000] tot_loss=1.441 (perp=6.697, rec=0.079, cos=0.023), tot_loss_proj:1.553 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.442 (perp=6.697, rec=0.079, cos=0.023), tot_loss_proj:1.551 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.433 (perp=6.697, rec=0.070, cos=0.023), tot_loss_proj:1.549 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.443 (perp=6.697, rec=0.080, cos=0.023), tot_loss_proj:1.553 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.432 (perp=6.697, rec=0.069, cos=0.023), tot_loss_proj:1.543 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.434 (perp=6.697, rec=0.071, cos=0.023), tot_loss_proj:1.554 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.437 (perp=6.697, rec=0.074, cos=0.023), tot_loss_proj:1.560 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.431 (perp=6.697, rec=0.068, cos=0.023), tot_loss_proj:1.548 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.438 (perp=6.697, rec=0.075, cos=0.023), tot_loss_proj:1.554 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.433 (perp=6.697, rec=0.070, cos=0.023), tot_loss_proj:1.553 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.439 (perp=6.697, rec=0.077, cos=0.023), tot_loss_proj:1.554 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.435 (perp=6.697, rec=0.072, cos=0.023), tot_loss_proj:1.552 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.431 (perp=6.697, rec=0.068, cos=0.023), tot_loss_proj:1.546 [t=0.35s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous chiller! [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 90.925 | p: 89.894 | r: 92.217
rouge2     | fm: 51.117 | p: 50.945 | r: 51.304
rougeL     | fm: 77.151 | p: 76.277 | r: 78.171
rougeLsum  | fm: 77.418 | p: 76.671 | r: 78.358
r1fm+r2fm = 142.042

input #15 time: 0:13:39 | total time: 3:34:40


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9864763451449315
highest_index [0]
highest [0.9864763451449315]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 0.8421418070793152 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.822770357131958 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.8153565526008606 for ['[CLS]sa base slave shadow irvingdale [SEP]']
[Init] best rec loss: 0.7788919806480408 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 0.7717652916908264 for ['[CLS] south jefferson late guy e sophia [SEP]']
[Init] best rec loss: 0.7401609420776367 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 0.7297704815864563 for ['[CLS] a clubs slayer trophy affected residents [SEP]']
[Init] best rec loss: 0.7207104563713074 for ['[CLS]worthy eat town normal court earth [SEP]']
[Init] best perm rec loss: 0.7205304503440857 for ['[CLS] town court earth normal eatworthy [SEP]']
[Init] best perm rec loss: 0.7205013632774353 for ['[CLS] town courtworthy earth eat normal [SEP]']
[Init] best perm rec loss: 0.71696937084198 for ['[CLS] townworthy court eat earth normal [SEP]']
[Init] best perm rec loss: 0.7154749631881714 for ['[CLS] town earth eatworthy court normal [SEP]']
[Init] best perm rec loss: 0.7139620184898376 for ['[CLS] eat courtworthy normal earth town [SEP]']
[Init] best perm rec loss: 0.7124315500259399 for ['[CLS]worthy eat town court earth normal [SEP]']
[Init] best perm rec loss: 0.711882472038269 for ['[CLS] court town earthworthy normal eat [SEP]']
[Init] best perm rec loss: 0.711799681186676 for ['[CLS]worthy earth normal town court eat [SEP]']
[Init] best perm rec loss: 0.7111780643463135 for ['[CLS]worthy court town earth eat normal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.877 (perp=7.666, rec=0.277, cos=0.066), tot_loss_proj:2.473 [t=0.35s]
prediction: ['[CLS] shift all this, more all [SEP]']
[ 100/2000] tot_loss=1.687 (perp=7.761, rec=0.104, cos=0.031), tot_loss_proj:2.593 [t=0.35s]
prediction: ['[CLS] inter all this, and more [SEP]']
[ 150/2000] tot_loss=1.324 (perp=6.081, rec=0.080, cos=0.028), tot_loss_proj:1.602 [t=0.35s]
prediction: ['[CLS] all all this, and more [SEP]']
[ 200/2000] tot_loss=1.327 (perp=6.081, rec=0.084, cos=0.027), tot_loss_proj:1.586 [t=0.35s]
prediction: ['[CLS] all all this, and more [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.563 (perp=7.204, rec=0.094, cos=0.029), tot_loss_proj:2.128 [t=0.35s]
prediction: ['[CLS] all this, ands more [SEP]']
[ 300/2000] tot_loss=1.126 (perp=5.086, rec=0.081, cos=0.027), tot_loss_proj:1.432 [t=0.35s]
prediction: ['[CLS] all this, and all more [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.132 (perp=5.086, rec=0.087, cos=0.027), tot_loss_proj:1.443 [t=0.35s]
prediction: ['[CLS] all this, and all more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.556 (perp=7.204, rec=0.088, cos=0.027), tot_loss_proj:2.126 [t=0.35s]
prediction: ['[CLS] all this, ands more [SEP]']
[ 450/2000] tot_loss=1.541 (perp=7.204, rec=0.073, cos=0.027), tot_loss_proj:2.120 [t=0.35s]
prediction: ['[CLS] all this, ands more [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.267 (perp=5.751, rec=0.089, cos=0.028), tot_loss_proj:1.691 [t=0.35s]
prediction: ['[CLS] all this, and mores [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.251 (perp=5.751, rec=0.073, cos=0.027), tot_loss_proj:1.684 [t=0.35s]
prediction: ['[CLS] all this, and mores [SEP]']
[ 600/2000] tot_loss=1.261 (perp=5.751, rec=0.083, cos=0.027), tot_loss_proj:1.687 [t=0.35s]
prediction: ['[CLS] all this, and mores [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.271 (perp=5.751, rec=0.093, cos=0.027), tot_loss_proj:1.690 [t=0.35s]
prediction: ['[CLS] all this, and mores [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.259 (perp=5.751, rec=0.082, cos=0.027), tot_loss_proj:1.689 [t=0.35s]
prediction: ['[CLS] all this, and mores [SEP]']
[ 750/2000] tot_loss=1.267 (perp=5.751, rec=0.089, cos=0.027), tot_loss_proj:1.692 [t=0.35s]
prediction: ['[CLS] all this, and mores [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.259 (perp=5.751, rec=0.082, cos=0.027), tot_loss_proj:1.694 [t=0.35s]
prediction: ['[CLS] all this, and mores [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.257 (perp=5.751, rec=0.079, cos=0.027), tot_loss_proj:1.692 [t=0.35s]
prediction: ['[CLS] all this, and mores [SEP]']
[ 900/2000] tot_loss=1.252 (perp=5.722, rec=0.081, cos=0.027), tot_loss_proj:1.495 [t=0.35s]
prediction: ['[CLS] all this, and more of [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.041 (perp=4.697, rec=0.075, cos=0.027), tot_loss_proj:1.105 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.040 (perp=4.697, rec=0.074, cos=0.027), tot_loss_proj:1.104 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.049 (perp=4.697, rec=0.083, cos=0.027), tot_loss_proj:1.101 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.037 (perp=4.697, rec=0.071, cos=0.027), tot_loss_proj:1.101 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.050 (perp=4.697, rec=0.084, cos=0.027), tot_loss_proj:1.108 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.040 (perp=4.697, rec=0.073, cos=0.027), tot_loss_proj:1.100 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.047 (perp=4.697, rec=0.081, cos=0.027), tot_loss_proj:1.108 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.048 (perp=4.697, rec=0.081, cos=0.027), tot_loss_proj:1.105 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.046 (perp=4.697, rec=0.079, cos=0.027), tot_loss_proj:1.107 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.051 (perp=4.697, rec=0.084, cos=0.027), tot_loss_proj:1.094 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.040 (perp=4.697, rec=0.074, cos=0.027), tot_loss_proj:1.097 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.044 (perp=4.697, rec=0.078, cos=0.027), tot_loss_proj:1.099 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.028 (perp=4.697, rec=0.062, cos=0.027), tot_loss_proj:1.102 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.030 (perp=4.697, rec=0.065, cos=0.026), tot_loss_proj:1.097 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.033 (perp=4.697, rec=0.067, cos=0.026), tot_loss_proj:1.101 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.036 (perp=4.697, rec=0.071, cos=0.026), tot_loss_proj:1.104 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.035 (perp=4.697, rec=0.070, cos=0.026), tot_loss_proj:1.105 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=1.026 (perp=4.697, rec=0.061, cos=0.026), tot_loss_proj:1.100 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.029 (perp=4.697, rec=0.063, cos=0.026), tot_loss_proj:1.095 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.022 (perp=4.697, rec=0.056, cos=0.026), tot_loss_proj:1.097 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.026 (perp=4.697, rec=0.061, cos=0.026), tot_loss_proj:1.103 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.028 (perp=4.697, rec=0.063, cos=0.026), tot_loss_proj:1.093 [t=0.35s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.597 | p: 90.532 | r: 92.717
rouge2     | fm: 54.134 | p: 53.869 | r: 54.293
rougeL     | fm: 79.092 | p: 78.363 | r: 80.037
rougeLsum  | fm: 78.566 | p: 77.765 | r: 79.536
r1fm+r2fm = 145.731

input #16 time: 0:13:37 | total time: 3:48:18


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9841141783635962
highest_index [0]
highest [0.9841141783635962]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8065576553344727 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.7996958494186401 for ['[CLS] angle bond masonacle cabinachejord right is kiel woman [SEP]']
[Init] best rec loss: 0.7895312905311584 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.7819075584411621 for ['[CLS] staretha jack nur stone lied pointsmori richie sienna foot [SEP]']
[Init] best rec loss: 0.779328465461731 for ['[CLS] forecast yeast jewels young food filed paralyzedggio easy thing beau [SEP]']
[Init] best rec loss: 0.7684776782989502 for ['[CLS] wild filing curls wandabuck day victor which judicial coach peyton [SEP]']
[Init] best perm rec loss: 0.7681013345718384 for ['[CLS] day wanda curls judicial wildbuck peyton victor filing which coach [SEP]']
[Init] best perm rec loss: 0.7678869366645813 for ['[CLS] day peyton victor curls wild judicialbuck wanda filing coach which [SEP]']
[Init] best perm rec loss: 0.7668157815933228 for ['[CLS] curls day victor filing judicial wild peyton wandabuck coach which [SEP]']
[Init] best perm rec loss: 0.7665560245513916 for ['[CLS] peyton wild coach curlsbuck wanda which filing judicial victor day [SEP]']
[Init] best perm rec loss: 0.7661147713661194 for ['[CLS] victor peyton which day judicial filing coach wild wandabuck curls [SEP]']
[Init] best perm rec loss: 0.7657724618911743 for ['[CLS] curls judicial victor coach wandabuck wild filing day which peyton [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.216 (perp=9.572, rec=0.259, cos=0.042), tot_loss_proj:2.962 [t=0.35s]
prediction: ['[CLS] want much did about too too much eating mind think about [SEP]']
[ 100/2000] tot_loss=1.886 (perp=8.685, rec=0.116, cos=0.032), tot_loss_proj:2.567 [t=0.35s]
prediction: ['[CLS] want about think about too too much about about think about [SEP]']
[ 150/2000] tot_loss=2.235 (perp=10.616, rec=0.080, cos=0.031), tot_loss_proj:2.985 [t=0.35s]
prediction: ['[CLS] want about think to too too much what on think going [SEP]']
[ 200/2000] tot_loss=2.165 (perp=10.268, rec=0.081, cos=0.031), tot_loss_proj:2.999 [t=0.35s]
prediction: ['[CLS] want about to to too too much what on think going [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.924 (perp=9.043, rec=0.085, cos=0.030), tot_loss_proj:2.592 [t=0.35s]
prediction: ['[CLS] want think to too too much what on think about going [SEP]']
[ 300/2000] tot_loss=1.821 (perp=8.570, rec=0.076, cos=0.031), tot_loss_proj:2.538 [t=0.35s]
prediction: ['[CLS] want to to too too much what on think about going [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.589 (perp=7.466, rec=0.065, cos=0.031), tot_loss_proj:2.154 [t=0.35s]
prediction: ['[CLS] want to too too much what on to think about going [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.306 (perp=5.982, rec=0.076, cos=0.033), tot_loss_proj:1.822 [t=0.35s]
prediction: ["[CLS] want to'too much going on to think about what [SEP]"]
[ 450/2000] tot_loss=1.297 (perp=5.982, rec=0.069, cos=0.031), tot_loss_proj:1.828 [t=0.35s]
prediction: ["[CLS] want to'too much going on to think about what [SEP]"]
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.256 (perp=5.802, rec=0.064, cos=0.031), tot_loss_proj:1.748 [t=0.30s]
prediction: ["[CLS] want to too much going'on to think about what [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.266 (perp=5.802, rec=0.075, cos=0.031), tot_loss_proj:1.750 [t=0.30s]
prediction: ["[CLS] want to too much going'on to think about what [SEP]"]
[ 600/2000] tot_loss=1.266 (perp=5.802, rec=0.075, cos=0.031), tot_loss_proj:1.752 [t=0.30s]
prediction: ["[CLS] want to too much going'on to think about what [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.258 (perp=5.802, rec=0.066, cos=0.031), tot_loss_proj:1.751 [t=0.30s]
prediction: ["[CLS] want to too much going'on to think about what [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.247 (perp=5.802, rec=0.055, cos=0.031), tot_loss_proj:1.748 [t=0.30s]
prediction: ["[CLS] want to too much going'on to think about what [SEP]"]
[ 750/2000] tot_loss=1.420 (perp=6.612, rec=0.066, cos=0.032), tot_loss_proj:1.813 [t=0.30s]
prediction: ["[CLS] want to too much going'on on think about what [SEP]"]
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.409 (perp=6.538, rec=0.070, cos=0.031), tot_loss_proj:1.876 [t=0.30s]
prediction: ["[CLS] want to too much going on on'think about what [SEP]"]
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.377 (perp=6.404, rec=0.068, cos=0.029), tot_loss_proj:1.688 [t=0.30s]
prediction: ["[CLS] want to think too much going on on'about what [SEP]"]
[ 900/2000] tot_loss=1.475 (perp=6.867, rec=0.070, cos=0.031), tot_loss_proj:1.751 [t=0.30s]
prediction: ['[CLS] want to think too much going on on s about what [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.329 (perp=6.155, rec=0.067, cos=0.031), tot_loss_proj:1.635 [t=0.30s]
prediction: ["[CLS] want to think too much'going on on about what [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.251 (perp=5.774, rec=0.065, cos=0.031), tot_loss_proj:1.551 [t=0.30s]
prediction: ["[CLS] want to think too much about going on on'what [SEP]"]
[1050/2000] tot_loss=1.249 (perp=5.774, rec=0.063, cos=0.031), tot_loss_proj:1.545 [t=0.30s]
prediction: ["[CLS] want to think too much about going on on'what [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.168 (perp=5.355, rec=0.065, cos=0.031), tot_loss_proj:1.382 [t=0.30s]
prediction: ["[CLS] want to think too much about what going on on'[SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.113 (perp=5.089, rec=0.064, cos=0.031), tot_loss_proj:1.281 [t=0.30s]
prediction: ["[CLS] want to think too much about what'going on on [SEP]"]
[1200/2000] tot_loss=1.114 (perp=5.089, rec=0.064, cos=0.031), tot_loss_proj:1.280 [t=0.30s]
prediction: ["[CLS] want to think too much about what'going on on [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.101 (perp=5.089, rec=0.051, cos=0.031), tot_loss_proj:1.272 [t=0.30s]
prediction: ["[CLS] want to think too much about what'going on on [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.121 (perp=5.089, rec=0.072, cos=0.031), tot_loss_proj:1.280 [t=0.30s]
prediction: ["[CLS] want to think too much about what'going on on [SEP]"]
[1350/2000] tot_loss=1.116 (perp=5.089, rec=0.067, cos=0.031), tot_loss_proj:1.277 [t=0.30s]
prediction: ["[CLS] want to think too much about what'going on on [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.120 (perp=5.089, rec=0.070, cos=0.031), tot_loss_proj:1.280 [t=0.30s]
prediction: ["[CLS] want to think too much about what'going on on [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.118 (perp=5.089, rec=0.068, cos=0.031), tot_loss_proj:1.281 [t=0.30s]
prediction: ["[CLS] want to think too much about what'going on on [SEP]"]
[1500/2000] tot_loss=1.348 (perp=6.274, rec=0.062, cos=0.031), tot_loss_proj:1.458 [t=0.30s]
prediction: ["[CLS] want to think too much about what'going s on [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=0.841 (perp=3.761, rec=0.057, cos=0.031), tot_loss_proj:0.942 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1600/2000] tot_loss=0.844 (perp=3.761, rec=0.060, cos=0.031), tot_loss_proj:0.947 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1650/2000] tot_loss=0.859 (perp=3.761, rec=0.075, cos=0.031), tot_loss_proj:0.929 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1700/2000] tot_loss=0.850 (perp=3.761, rec=0.067, cos=0.031), tot_loss_proj:0.947 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1750/2000] tot_loss=0.849 (perp=3.761, rec=0.066, cos=0.032), tot_loss_proj:0.939 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1800/2000] tot_loss=0.853 (perp=3.761, rec=0.069, cos=0.031), tot_loss_proj:0.940 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1850/2000] tot_loss=0.842 (perp=3.761, rec=0.058, cos=0.031), tot_loss_proj:0.940 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1900/2000] tot_loss=0.844 (perp=3.761, rec=0.061, cos=0.031), tot_loss_proj:0.937 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1950/2000] tot_loss=0.860 (perp=3.761, rec=0.077, cos=0.032), tot_loss_proj:0.929 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[2000/2000] tot_loss=0.844 (perp=3.761, rec=0.060, cos=0.031), tot_loss_proj:0.937 [t=0.30s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.955 | p: 91.029 | r: 93.108
rouge2     | fm: 56.524 | p: 56.346 | r: 56.727
rougeL     | fm: 80.095 | p: 79.339 | r: 80.983
rougeLsum  | fm: 79.950 | p: 79.105 | r: 80.854
r1fm+r2fm = 148.479

input #17 time: 0:12:23 | total time: 4:00:42


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9882574867813472
highest_index [0]
highest [0.9882574867813472]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9764230847358704 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9102221727371216 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.8755684494972229 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.8587786555290222 for ['[CLS] master asteroidnagar fungi [SEP]']
[Init] best rec loss: 0.8269258141517639 for ['[CLS] alternativelastic garrett filed [SEP]']
[Init] best perm rec loss: 0.8268146514892578 for ['[CLS] garrettlastic alternative filed [SEP]']
[Init] best perm rec loss: 0.8262452483177185 for ['[CLS] alternative filedlastic garrett [SEP]']
[Init] best perm rec loss: 0.8261404037475586 for ['[CLS]lastic garrett alternative filed [SEP]']
[Init] best perm rec loss: 0.8259265422821045 for ['[CLS] garrettlastic filed alternative [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.594 (perp=11.560, rec=0.256, cos=0.026), tot_loss_proj:3.047 [t=0.30s]
prediction: ['[CLS]goratinggor touching [SEP]']
[ 100/2000] tot_loss=1.952 (perp=8.794, rec=0.169, cos=0.024), tot_loss_proj:2.435 [t=0.30s]
prediction: ['[CLS] inatinggorating [SEP]']
[ 150/2000] tot_loss=1.928 (perp=8.794, rec=0.146, cos=0.023), tot_loss_proj:2.435 [t=0.30s]
prediction: ['[CLS] inatinggorating [SEP]']
[ 200/2000] tot_loss=1.928 (perp=8.794, rec=0.145, cos=0.024), tot_loss_proj:2.436 [t=0.30s]
prediction: ['[CLS] inatinggorating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.228 (perp=5.588, rec=0.087, cos=0.024), tot_loss_proj:1.207 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[ 300/2000] tot_loss=1.212 (perp=5.588, rec=0.071, cos=0.023), tot_loss_proj:1.201 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.204 (perp=5.588, rec=0.063, cos=0.023), tot_loss_proj:1.203 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.191 (perp=5.588, rec=0.050, cos=0.023), tot_loss_proj:1.186 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.210 (perp=5.588, rec=0.069, cos=0.023), tot_loss_proj:1.197 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.202 (perp=5.588, rec=0.061, cos=0.023), tot_loss_proj:1.201 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.214 (perp=5.588, rec=0.073, cos=0.023), tot_loss_proj:1.212 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.204 (perp=5.588, rec=0.063, cos=0.023), tot_loss_proj:1.207 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.215 (perp=5.588, rec=0.074, cos=0.023), tot_loss_proj:1.193 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.192 (perp=5.588, rec=0.051, cos=0.023), tot_loss_proj:1.195 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.210 (perp=5.588, rec=0.069, cos=0.023), tot_loss_proj:1.197 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.205 (perp=5.588, rec=0.064, cos=0.023), tot_loss_proj:1.210 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.206 (perp=5.588, rec=0.065, cos=0.023), tot_loss_proj:1.208 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.191 (perp=5.588, rec=0.050, cos=0.023), tot_loss_proj:1.199 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.198 (perp=5.588, rec=0.057, cos=0.023), tot_loss_proj:1.203 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.209 (perp=5.588, rec=0.068, cos=0.023), tot_loss_proj:1.199 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.189 (perp=5.588, rec=0.048, cos=0.023), tot_loss_proj:1.206 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.196 (perp=5.588, rec=0.055, cos=0.023), tot_loss_proj:1.199 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.192 (perp=5.588, rec=0.051, cos=0.023), tot_loss_proj:1.192 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.189 (perp=5.588, rec=0.048, cos=0.023), tot_loss_proj:1.197 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.205 (perp=5.588, rec=0.064, cos=0.023), tot_loss_proj:1.200 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.192 (perp=5.588, rec=0.051, cos=0.023), tot_loss_proj:1.196 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.205 (perp=5.588, rec=0.064, cos=0.023), tot_loss_proj:1.202 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.191 (perp=5.588, rec=0.050, cos=0.023), tot_loss_proj:1.198 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.188 (perp=5.588, rec=0.047, cos=0.023), tot_loss_proj:1.208 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.219 (perp=5.588, rec=0.078, cos=0.023), tot_loss_proj:1.194 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.204 (perp=5.588, rec=0.063, cos=0.023), tot_loss_proj:1.202 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.204 (perp=5.588, rec=0.063, cos=0.023), tot_loss_proj:1.190 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.200 (perp=5.588, rec=0.059, cos=0.023), tot_loss_proj:1.208 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.203 (perp=5.588, rec=0.062, cos=0.023), tot_loss_proj:1.202 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.201 (perp=5.588, rec=0.060, cos=0.023), tot_loss_proj:1.203 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.203 (perp=5.588, rec=0.062, cos=0.023), tot_loss_proj:1.199 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.198 (perp=5.588, rec=0.057, cos=0.023), tot_loss_proj:1.216 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.194 (perp=5.588, rec=0.053, cos=0.023), tot_loss_proj:1.204 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.205 (perp=5.588, rec=0.064, cos=0.023), tot_loss_proj:1.203 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.199 (perp=5.588, rec=0.058, cos=0.023), tot_loss_proj:1.195 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.358 | p: 91.508 | r: 93.484
rouge2     | fm: 58.023 | p: 57.838 | r: 58.227
rougeL     | fm: 81.113 | p: 80.385 | r: 81.939
rougeLsum  | fm: 80.908 | p: 80.206 | r: 81.775
r1fm+r2fm = 150.382

input #18 time: 0:11:55 | total time: 4:12:37


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.983842963001655
highest_index [0]
highest [0.983842963001655]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7245864868164062 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7214258313179016 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7104443907737732 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.6823919415473938 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6776169538497925 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6768795847892761 for ['[CLS] reaching pin orderyna [SEP]']
[Init] best perm rec loss: 0.6756115555763245 for ['[CLS] order pinyna reaching [SEP]']
[Init] best perm rec loss: 0.6730051040649414 for ['[CLS] reaching order pinyna [SEP]']
[Init] best perm rec loss: 0.6729406118392944 for ['[CLS] order reachingyna pin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.995 (perp=13.079, rec=0.296, cos=0.083), tot_loss_proj:3.920 [t=0.30s]
prediction: ['[CLS]fafafama [SEP]']
[ 100/2000] tot_loss=1.689 (perp=7.651, rec=0.110, cos=0.049), tot_loss_proj:2.054 [t=0.30s]
prediction: ['[CLS] in tofamy [SEP]']
[ 150/2000] tot_loss=1.631 (perp=7.651, rec=0.070, cos=0.031), tot_loss_proj:2.076 [t=0.30s]
prediction: ['[CLS] in tofamy [SEP]']
[ 200/2000] tot_loss=1.645 (perp=7.651, rec=0.083, cos=0.031), tot_loss_proj:2.077 [t=0.30s]
prediction: ['[CLS] in tofamy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.320 (perp=6.109, rec=0.066, cos=0.032), tot_loss_proj:1.334 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.317 (perp=6.109, rec=0.064, cos=0.031), tot_loss_proj:1.339 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.319 (perp=6.109, rec=0.065, cos=0.032), tot_loss_proj:1.333 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.312 (perp=6.109, rec=0.058, cos=0.032), tot_loss_proj:1.319 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.322 (perp=6.109, rec=0.068, cos=0.032), tot_loss_proj:1.333 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.324 (perp=6.109, rec=0.070, cos=0.032), tot_loss_proj:1.329 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.312 (perp=6.109, rec=0.058, cos=0.032), tot_loss_proj:1.340 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.318 (perp=6.109, rec=0.065, cos=0.032), tot_loss_proj:1.332 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.308 (perp=6.109, rec=0.054, cos=0.032), tot_loss_proj:1.332 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.306 (perp=6.109, rec=0.052, cos=0.032), tot_loss_proj:1.328 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.321 (perp=6.109, rec=0.067, cos=0.032), tot_loss_proj:1.332 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.321 (perp=6.109, rec=0.067, cos=0.032), tot_loss_proj:1.329 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.325 (perp=6.109, rec=0.071, cos=0.032), tot_loss_proj:1.335 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.326 (perp=6.109, rec=0.073, cos=0.032), tot_loss_proj:1.333 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.319 (perp=6.109, rec=0.065, cos=0.032), tot_loss_proj:1.323 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.314 (perp=6.109, rec=0.060, cos=0.032), tot_loss_proj:1.336 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.307 (perp=6.109, rec=0.053, cos=0.032), tot_loss_proj:1.328 [t=0.31s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.298 (perp=6.109, rec=0.044, cos=0.032), tot_loss_proj:1.325 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.308 (perp=6.109, rec=0.054, cos=0.032), tot_loss_proj:1.326 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.312 (perp=6.109, rec=0.059, cos=0.032), tot_loss_proj:1.322 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.325 (perp=6.109, rec=0.071, cos=0.032), tot_loss_proj:1.334 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.314 (perp=6.109, rec=0.061, cos=0.032), tot_loss_proj:1.330 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.306 (perp=6.109, rec=0.052, cos=0.032), tot_loss_proj:1.332 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.306 (perp=6.109, rec=0.052, cos=0.032), tot_loss_proj:1.339 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.300 (perp=6.109, rec=0.047, cos=0.032), tot_loss_proj:1.324 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.307 (perp=6.109, rec=0.053, cos=0.032), tot_loss_proj:1.319 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.316 (perp=6.109, rec=0.062, cos=0.032), tot_loss_proj:1.326 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.312 (perp=6.109, rec=0.058, cos=0.032), tot_loss_proj:1.325 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.322 (perp=6.109, rec=0.069, cos=0.032), tot_loss_proj:1.340 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.303 (perp=6.109, rec=0.049, cos=0.032), tot_loss_proj:1.332 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.305 (perp=6.109, rec=0.051, cos=0.032), tot_loss_proj:1.327 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.313 (perp=6.109, rec=0.059, cos=0.032), tot_loss_proj:1.326 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.315 (perp=6.109, rec=0.061, cos=0.032), tot_loss_proj:1.324 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.311 (perp=6.109, rec=0.057, cos=0.032), tot_loss_proj:1.332 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.314 (perp=6.109, rec=0.060, cos=0.032), tot_loss_proj:1.335 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.311 (perp=6.109, rec=0.057, cos=0.032), tot_loss_proj:1.330 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.875 | p: 91.927 | r: 93.810
rouge2     | fm: 61.045 | p: 60.902 | r: 61.275
rougeL     | fm: 82.231 | p: 81.588 | r: 82.997
rougeLsum  | fm: 81.953 | p: 81.253 | r: 82.733
r1fm+r2fm = 153.921

input #19 time: 0:11:55 | total time: 4:24:32


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9876001078159078
highest_index [0]
highest [0.9876001078159078]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8613153696060181 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8611622452735901 for ['[CLS] map your included adventure [SEP]']
[Init] best rec loss: 0.7968494296073914 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 0.7920958399772644 for ['[CLS] historically hiroshima stand wing [SEP]']
[Init] best rec loss: 0.7793165445327759 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best perm rec loss: 0.7788003087043762 for ['[CLS] [CLS] storylinenessxi [SEP]']
[Init] best perm rec loss: 0.7775601148605347 for ['[CLS]ness [CLS]xi storyline [SEP]']
[Init] best perm rec loss: 0.7753890752792358 for ['[CLS] [CLS]xiness storyline [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.475 (perp=10.923, rec=0.237, cos=0.054), tot_loss_proj:3.336 [t=0.30s]
prediction: ['[CLS]verse per pleasureverse [SEP]']
[ 100/2000] tot_loss=2.329 (perp=10.923, rec=0.120, cos=0.025), tot_loss_proj:3.295 [t=0.30s]
prediction: ['[CLS]verse per pleasureverse [SEP]']
[ 150/2000] tot_loss=2.295 (perp=10.923, rec=0.080, cos=0.030), tot_loss_proj:3.331 [t=0.30s]
prediction: ['[CLS]verse per pleasureverse [SEP]']
[ 200/2000] tot_loss=2.319 (perp=11.088, rec=0.077, cos=0.025), tot_loss_proj:3.074 [t=0.30s]
prediction: ['[CLS] per per pleasureverse [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.923 (perp=9.095, rec=0.076, cos=0.028), tot_loss_proj:2.133 [t=0.30s]
prediction: ['[CLS] per theverse pleasure [SEP]']
[ 300/2000] tot_loss=1.910 (perp=9.095, rec=0.067, cos=0.024), tot_loss_proj:2.127 [t=0.30s]
prediction: ['[CLS] per theverse pleasure [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.598 (perp=7.610, rec=0.052, cos=0.024), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.599 (perp=7.610, rec=0.052, cos=0.024), tot_loss_proj:1.632 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.606 (perp=7.610, rec=0.059, cos=0.025), tot_loss_proj:1.632 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.603 (perp=7.610, rec=0.056, cos=0.024), tot_loss_proj:1.615 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.599 (perp=7.610, rec=0.053, cos=0.024), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.605 (perp=7.610, rec=0.058, cos=0.024), tot_loss_proj:1.629 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.617 (perp=7.610, rec=0.070, cos=0.024), tot_loss_proj:1.641 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.606 (perp=7.610, rec=0.059, cos=0.024), tot_loss_proj:1.629 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.600 (perp=7.610, rec=0.054, cos=0.024), tot_loss_proj:1.638 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.610 (perp=7.610, rec=0.063, cos=0.025), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.611 (perp=7.610, rec=0.065, cos=0.025), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.597 (perp=7.610, rec=0.051, cos=0.024), tot_loss_proj:1.621 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.608 (perp=7.610, rec=0.061, cos=0.024), tot_loss_proj:1.629 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.602 (perp=7.610, rec=0.056, cos=0.025), tot_loss_proj:1.639 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.596 (perp=7.610, rec=0.050, cos=0.025), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.619 (perp=7.610, rec=0.072, cos=0.025), tot_loss_proj:1.642 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.608 (perp=7.610, rec=0.062, cos=0.025), tot_loss_proj:1.621 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.604 (perp=7.610, rec=0.057, cos=0.025), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.609 (perp=7.610, rec=0.062, cos=0.025), tot_loss_proj:1.638 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.612 (perp=7.610, rec=0.066, cos=0.025), tot_loss_proj:1.648 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.607 (perp=7.610, rec=0.061, cos=0.025), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.606 (perp=7.610, rec=0.059, cos=0.025), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.601 (perp=7.610, rec=0.055, cos=0.025), tot_loss_proj:1.619 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.606 (perp=7.610, rec=0.059, cos=0.025), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.598 (perp=7.610, rec=0.051, cos=0.025), tot_loss_proj:1.641 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.620 (perp=7.610, rec=0.074, cos=0.025), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.609 (perp=7.610, rec=0.062, cos=0.025), tot_loss_proj:1.620 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.608 (perp=7.610, rec=0.061, cos=0.025), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.605 (perp=7.610, rec=0.058, cos=0.025), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.604 (perp=7.610, rec=0.057, cos=0.025), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.604 (perp=7.610, rec=0.058, cos=0.025), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.608 (perp=7.610, rec=0.061, cos=0.025), tot_loss_proj:1.622 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.602 (perp=7.610, rec=0.056, cos=0.025), tot_loss_proj:1.632 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.608 (perp=7.610, rec=0.062, cos=0.025), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.121 | p: 92.323 | r: 94.104
rouge2     | fm: 62.764 | p: 62.565 | r: 62.954
rougeL     | fm: 83.113 | p: 82.462 | r: 83.907
rougeLsum  | fm: 82.708 | p: 82.118 | r: 83.509
r1fm+r2fm = 155.885

input #20 time: 0:11:55 | total time: 4:36:28


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.9848585882339543
highest_index [0]
highest [0.9848585882339543]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.8437332510948181 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8160292506217957 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.7976351976394653 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.7921990156173706 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.7843894958496094 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.7671926021575928 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 0.7662199139595032 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 0.7648038864135742 for ['[CLS] general stony according [UNK] bent vii rights size loan babytakingback especially situations labor there dee, connecticut pose item she side fauna golden [SEP]']
[Init] best perm rec loss: 0.7631949186325073 for ['[CLS] there vii general labor rights stony especially connecticut size situations posetaking side, baby loan [UNK] golden fauna according sheback item dee bent [SEP]']
[Init] best perm rec loss: 0.7622644901275635 for ['[CLS] labor item she general fauna stony connecticut, rights bentback especially goldentaking vii [UNK] pose dee situations there size side loan baby according [SEP]']
[Init] best perm rec loss: 0.7604305148124695 for ['[CLS] especially size, labor general bent she dee situations there fauna baby stony vii goldentakingback [UNK] rights pose according item loan side connecticut [SEP]']
[Init] best perm rec loss: 0.7603573203086853 for ['[CLS] vii pose bent side she connecticut loan, laborback [UNK]taking dee golden situations fauna size rights especially there stony according item baby general [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.858 (perp=12.088, rec=0.388, cos=0.053), tot_loss_proj:3.398 [t=0.31s]
prediction: ['[CLS] corporate lack atmosphere all was changed school issue dependent only obama generic state strange parents women detectives mir pushed poorly local workers else serious officials [SEP]']
[ 100/2000] tot_loss=2.701 (perp=12.041, rec=0.258, cos=0.035), tot_loss_proj:3.388 [t=0.31s]
prediction: ['[CLS] rico insufficient picture all out reins school out the only women generic seemed faux teachers how bishop works animated instead refuge athletes athletes serious from [SEP]']
[ 150/2000] tot_loss=2.578 (perp=11.863, rec=0.177, cos=0.028), tot_loss_proj:3.393 [t=0.31s]
prediction: ['[CLS] et not picture works out reins economic out the only women like looked stereo teachers way women works makes insteadtypical athletes athletes serious of [SEP]']
[ 200/2000] tot_loss=2.461 (perp=11.101, rec=0.159, cos=0.081), tot_loss_proj:3.643 [t=0.31s]
prediction: ['[CLS] ofony picture works out brought economic out thely women like look stereo teachers way this works makes insteadtypical athletes. serious of [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.145 (perp=9.941, rec=0.127, cos=0.030), tot_loss_proj:3.275 [t=0.31s]
prediction: ['[CLS]typical teachers picture works out brought non out thely women like look stereotypical way this works makes instead / athletes, serious of [SEP]']
[ 300/2000] tot_loss=2.107 (perp=9.832, rec=0.111, cos=0.030), tot_loss_proj:3.354 [t=0.31s]
prediction: ['[CLS]typical teachers picture works out all unanimous out the more women like look stereotypical way all all makes instead / athletes, serious of [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.176 (perp=10.227, rec=0.100, cos=0.030), tot_loss_proj:3.036 [t=0.31s]
prediction: ['[CLS]typical teachers makes works out all f of the more women like look stereo caretaker way all all atmosphere instead and athletes, serious of [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.004 (perp=9.397, rec=0.095, cos=0.030), tot_loss_proj:2.952 [t=0.31s]
prediction: ['[CLS]typical teachers makes works out all moral of the more women like look stereo caretaker way all of atmosphere instead and athletes, serious all [SEP]']
[ 450/2000] tot_loss=2.008 (perp=9.417, rec=0.094, cos=0.030), tot_loss_proj:3.036 [t=0.31s]
prediction: ['[CLS]typical teachers makes works out all moral of the more women like look stereo caretaker way all of picture instead and athletes, serious all [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.932 (perp=9.070, rec=0.088, cos=0.030), tot_loss_proj:2.742 [t=0.31s]
prediction: ['[CLS]typical teachers makes works out all moral of the caretaker women like look stereo more way all of atmosphere instead and athletes, serious all [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.852 (perp=8.658, rec=0.091, cos=0.030), tot_loss_proj:2.503 [t=0.31s]
prediction: ['[CLS]typical caretaker makes works out all moral of the caretaker women look like stereo more way all of atmosphere instead and athletes, serious. [SEP]']
[ 600/2000] tot_loss=1.847 (perp=8.658, rec=0.086, cos=0.030), tot_loss_proj:2.507 [t=0.31s]
prediction: ['[CLS]typical caretaker makes works out all moral of the caretaker women look like stereo more way all of atmosphere instead and athletes, serious. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.803 (perp=8.351, rec=0.102, cos=0.030), tot_loss_proj:2.485 [t=0.31s]
prediction: ['[CLS] stereotypical caretaker makes works out all moral look the caretaker women look like more way all of guardians instead and athletes, serious. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.715 (perp=7.961, rec=0.092, cos=0.030), tot_loss_proj:2.450 [t=0.31s]
prediction: ['[CLS] stereotypical teachers makes works out all moral look the caretaker women look way more like all of atmosphere instead and athletes, serious. [SEP]']
[ 750/2000] tot_loss=1.616 (perp=7.496, rec=0.087, cos=0.030), tot_loss_proj:2.419 [t=0.31s]
prediction: ['[CLS] stereotypical teachers makes works out the moral look the caretaker women look way more like all of moral instead and athletes, serious. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.680 (perp=7.815, rec=0.087, cos=0.030), tot_loss_proj:2.192 [t=0.31s]
prediction: ['[CLS] stereotypical teachers makes works out the the of the caretaker women look way more like all of moral instead, athletes and serious. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.613 (perp=7.520, rec=0.079, cos=0.030), tot_loss_proj:2.174 [t=0.31s]
prediction: ['[CLS] stereotypical teachers makes works out the like of the caretaker women look way more moral all of moral instead, athletes and serious. [SEP]']
[ 900/2000] tot_loss=1.617 (perp=7.520, rec=0.083, cos=0.030), tot_loss_proj:2.168 [t=0.31s]
prediction: ['[CLS] stereotypical teachers makes works out the like of the caretaker women look way more moral all of moral instead, athletes and serious. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.586 (perp=7.371, rec=0.081, cos=0.030), tot_loss_proj:2.362 [t=0.31s]
prediction: ['[CLS] stereotypical teachers makes works out the like of the caretaker women look way more moral all of moral. instead, athletes and serious [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.553 (perp=7.220, rec=0.079, cos=0.030), tot_loss_proj:2.254 [t=0.31s]
prediction: ['[CLS] stereotypical teachers makes works out the like of the caretaker women look way more moral of all moral. instead, athletes and serious [SEP]']
[1050/2000] tot_loss=1.554 (perp=7.220, rec=0.080, cos=0.030), tot_loss_proj:2.261 [t=0.31s]
prediction: ['[CLS] stereotypical teachers makes works out the like of the caretaker women look way more moral of all moral. instead, athletes and serious [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.495 (perp=6.939, rec=0.077, cos=0.030), tot_loss_proj:2.187 [t=0.31s]
prediction: ['[CLS] stereotypical teachers works out the like of the caretaker makes women look way more moral of all moral. instead, athletes and serious [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.518 (perp=7.030, rec=0.082, cos=0.030), tot_loss_proj:2.283 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral'the caretaker makes women look way more like of all moral. instead, athletes and serious [SEP]"]
[1200/2000] tot_loss=1.511 (perp=7.030, rec=0.075, cos=0.030), tot_loss_proj:2.292 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral'the caretaker makes women look way more like of all moral. instead, athletes and serious [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.472 (perp=6.763, rec=0.089, cos=0.030), tot_loss_proj:2.125 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral'like the caretaker makes women look way more of all moral. instead, athletes and serious [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.463 (perp=6.763, rec=0.081, cos=0.030), tot_loss_proj:2.118 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral'like the caretaker makes women look way more of all moral. instead, athletes and serious [SEP]"]
[1350/2000] tot_loss=1.465 (perp=6.763, rec=0.082, cos=0.030), tot_loss_proj:2.130 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral'like the caretaker makes women look way more of all moral. instead, athletes and serious [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.455 (perp=6.707, rec=0.084, cos=0.030), tot_loss_proj:2.129 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral'like the caretaker makes women look way more, all moral. instead of athletes and serious [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.452 (perp=6.707, rec=0.080, cos=0.030), tot_loss_proj:2.126 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral'like the caretaker makes women look way more, all moral. instead of athletes and serious [SEP]"]
[1500/2000] tot_loss=1.449 (perp=6.707, rec=0.078, cos=0.030), tot_loss_proj:2.120 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral'like the caretaker makes women look way more, all moral. instead of athletes and serious [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.438 (perp=6.658, rec=0.077, cos=0.030), tot_loss_proj:2.161 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral, like the caretaker makes women look way more'all moral. instead of athletes and serious [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.442 (perp=6.658, rec=0.080, cos=0.030), tot_loss_proj:2.167 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral, like the caretaker makes women look way more'all moral. instead of athletes and serious [SEP]"]
[1650/2000] tot_loss=1.440 (perp=6.658, rec=0.079, cos=0.030), tot_loss_proj:2.155 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral, like the caretaker makes women look way more'all moral. instead of athletes and serious [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.439 (perp=6.658, rec=0.077, cos=0.030), tot_loss_proj:2.156 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral, like the caretaker makes women look way more'all moral. instead of athletes and serious [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.440 (perp=6.658, rec=0.078, cos=0.030), tot_loss_proj:2.162 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral, like the caretaker makes women look way more'all moral. instead of athletes and serious [SEP]"]
[1800/2000] tot_loss=1.435 (perp=6.658, rec=0.074, cos=0.030), tot_loss_proj:2.153 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral, like the caretaker makes women look way more'all moral. instead of athletes and serious [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.433 (perp=6.658, rec=0.071, cos=0.030), tot_loss_proj:2.160 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral, like the caretaker makes women look way more'all moral. instead of athletes and serious [SEP]"]
Attempt swap
Moved token
[1900/2000] tot_loss=1.424 (perp=6.585, rec=0.077, cos=0.030), tot_loss_proj:2.171 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral, like the caretaker makes women look'way more all moral. instead of athletes and serious [SEP]"]
[1950/2000] tot_loss=1.423 (perp=6.585, rec=0.076, cos=0.030), tot_loss_proj:2.175 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral, like the caretaker makes women look'way more all moral. instead of athletes and serious [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.425 (perp=6.585, rec=0.078, cos=0.030), tot_loss_proj:2.171 [t=0.31s]
prediction: ["[CLS] stereotypical teachers works out the moral, like the caretaker makes women look'way more all moral. instead of athletes and serious [SEP]"]
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] stereotypical teachers makes works out the like of the caretaker women look way more moral of all moral. instead, athletes and serious [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 89.362 | p: 87.500 | r: 91.304
rouge2     | fm: 8.889 | p: 8.696 | r: 9.091
rougeL     | fm: 46.809 | p: 45.833 | r: 47.826
rougeLsum  | fm: 46.809 | p: 45.833 | r: 47.826
r1fm+r2fm = 98.251

[Aggregate metrics]:
rouge1     | fm: 92.958 | p: 92.107 | r: 93.939
rouge2     | fm: 60.087 | p: 59.965 | r: 60.222
rougeL     | fm: 81.401 | p: 80.692 | r: 82.055
rougeLsum  | fm: 80.937 | p: 80.238 | r: 81.655
r1fm+r2fm = 153.045

input #21 time: 0:12:16 | total time: 4:48:44


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9872815884920749
highest_index [0]
highest [0.9872815884920749]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9798737168312073 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.972591757774353 for ['[CLS] mast landlord rockome crusaders enjoyed denise fire dock almost vera [SEP]']
[Init] best rec loss: 0.9614095091819763 for ['[CLS] mines ) organ yes deck sessions mainly steady introduction arson dates [SEP]']
[Init] best rec loss: 0.955237627029419 for ['[CLS]dbus leaguedel more arrest able communists confederatedgetsomics [SEP]']
[Init] best rec loss: 0.9504448771476746 for ['[CLS] kali camp missiondio but whispered mining paulaville atmosphere qu [SEP]']
[Init] best rec loss: 0.9442179799079895 for ['[CLS]ou apartowskilizer teaching collins wolfe sample rite maze kaiser [SEP]']
[Init] best rec loss: 0.9408202767372131 for ['[CLS] kids function phoenix chinese set boarders over her schedule laughter [SEP]']
[Init] best perm rec loss: 0.9406605362892151 for ['[CLS] her function board kids phoenix laughter set over chineseers schedule [SEP]']
[Init] best perm rec loss: 0.9398772716522217 for ['[CLS] laughter phoenix set kids chineseers function schedule her over board [SEP]']
[Init] best perm rec loss: 0.939764678478241 for ['[CLS] kids set chinese phoenix board schedule over functioners her laughter [SEP]']
[Init] best perm rec loss: 0.9391524791717529 for ['[CLS] kids chinese her phoenix laughterers board schedule over function set [SEP]']
[Init] best perm rec loss: 0.9377057552337646 for ['[CLS] her phoenix board schedule overers chinese set laughter kids function [SEP]']
[Init] best perm rec loss: 0.936832845211029 for ['[CLS] function kidsers board over set phoenix schedule chinese her laughter [SEP]']
[Init] best perm rec loss: 0.9360633492469788 for ['[CLS] board laughter her kids function set scheduleers phoenix over chinese [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.534 (perp=12.666, rec=0.615, cos=0.386), tot_loss_proj:4.083 [t=0.30s]
prediction: ['[CLS] afraid newly debris - import soon engine parkedryenburg until [SEP]']
[ 100/2000] tot_loss=3.459 (perp=13.292, rec=0.543, cos=0.258), tot_loss_proj:4.624 [t=0.30s]
prediction: ['[CLS] afraid annie debris occasional an novel adventure locallynivorous glad until [SEP]']
[ 150/2000] tot_loss=3.502 (perp=13.244, rec=0.603, cos=0.251), tot_loss_proj:4.382 [t=0.30s]
prediction: ['[CLS] successful emotional campus occasional an film enjoyable locallyneas adaptation until [SEP]']
[ 200/2000] tot_loss=2.762 (perp=10.838, rec=0.484, cos=0.111), tot_loss_proj:3.046 [t=0.30s]
prediction: ['[CLS] successful excellent formation own an enjoyable adaptation locally enjoyable adaptation until [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.241 (perp=11.852, rec=0.644, cos=0.226), tot_loss_proj:4.131 [t=0.30s]
prediction: ['[CLS] afraid specimens equipment own an remake adaptation until locally print adaptation [SEP]']
[ 300/2000] tot_loss=3.195 (perp=13.013, rec=0.496, cos=0.096), tot_loss_proj:4.314 [t=0.30s]
prediction: ['[CLS] afraid finelysities own piece dispute regiment unemployment locally funding prowess [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.328 (perp=13.034, rec=0.527, cos=0.194), tot_loss_proj:4.408 [t=0.30s]
prediction: ['[CLS] afraid enjoyablesities own originally film enjoyed unemployment locally enjoyed plumage [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.072 (perp=12.649, rec=0.466, cos=0.077), tot_loss_proj:3.768 [t=0.30s]
prediction: ['[CLS] afraid enjoyablesities own enjoyable useful enjoyed serialized film enjoyedhedral [SEP]']
[ 450/2000] tot_loss=2.871 (perp=11.960, rec=0.434, cos=0.046), tot_loss_proj:3.381 [t=0.30s]
prediction: ['[CLS] successful enjoyablesities own uses useful enjoyed in film enjoyedhedral [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.114 (perp=12.894, rec=0.464, cos=0.071), tot_loss_proj:4.046 [t=0.30s]
prediction: ['[CLS] successful enjoyable excuse own enjoyed snoop devoid become film enjoyed manner [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.777 (perp=11.470, rec=0.438, cos=0.045), tot_loss_proj:3.318 [t=0.30s]
prediction: ['[CLS] successful enjoyable excuse own enjoyable locally experience become successful adaptation film [SEP]']
[ 600/2000] tot_loss=2.804 (perp=11.033, rec=0.472, cos=0.125), tot_loss_proj:3.293 [t=0.30s]
prediction: ['[CLS] successful enjoyable fitzpatrick own enjoyable snoop experience become successful adaptation adaptation [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.704 (perp=11.326, rec=0.412, cos=0.026), tot_loss_proj:2.713 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own enjoyable locally fitzpatrick an successful adaptation film [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.701 (perp=10.815, rec=0.452, cos=0.086), tot_loss_proj:3.042 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own enjoyable become fitzpatrick locally successful adaptation adaptation [SEP]']
[ 750/2000] tot_loss=2.666 (perp=11.137, rec=0.414, cos=0.025), tot_loss_proj:2.923 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own enjoyable become lauderdale potent successful adaptation adaptation [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.662 (perp=11.160, rec=0.404, cos=0.026), tot_loss_proj:2.710 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own enjoyable an potent successful fitzpatrick adaptation adaptation [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.413 (perp=9.835, rec=0.402, cos=0.044), tot_loss_proj:2.454 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful fitzpatrick adaptation adaptation [SEP]']
[ 900/2000] tot_loss=2.386 (perp=9.835, rec=0.393, cos=0.026), tot_loss_proj:2.448 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful fitzpatrick adaptation adaptation [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.329 (perp=9.572, rec=0.389, cos=0.025), tot_loss_proj:2.359 [t=0.31s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable successful potent destination adaptation adaptation [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.380 (perp=9.835, rec=0.387, cos=0.026), tot_loss_proj:2.451 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful fitzpatrick adaptation adaptation [SEP]']
[1050/2000] tot_loss=2.290 (perp=9.434, rec=0.378, cos=0.025), tot_loss_proj:2.328 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
[1100/2000] tot_loss=2.289 (perp=9.434, rec=0.378, cos=0.023), tot_loss_proj:2.325 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.319 (perp=9.572, rec=0.378, cos=0.026), tot_loss_proj:2.346 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable successful potent destination adaptation adaptation [SEP]']
[1200/2000] tot_loss=2.316 (perp=9.572, rec=0.375, cos=0.027), tot_loss_proj:2.350 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable successful potent destination adaptation adaptation [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.286 (perp=9.434, rec=0.373, cos=0.026), tot_loss_proj:2.327 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
[1300/2000] tot_loss=2.279 (perp=9.434, rec=0.368, cos=0.024), tot_loss_proj:2.326 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
[1350/2000] tot_loss=2.282 (perp=9.434, rec=0.371, cos=0.024), tot_loss_proj:2.326 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
[1400/2000] tot_loss=2.275 (perp=9.434, rec=0.364, cos=0.024), tot_loss_proj:2.331 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
[1450/2000] tot_loss=2.277 (perp=9.434, rec=0.364, cos=0.026), tot_loss_proj:2.333 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
[1500/2000] tot_loss=2.284 (perp=9.434, rec=0.372, cos=0.025), tot_loss_proj:2.331 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
[1550/2000] tot_loss=2.276 (perp=9.434, rec=0.364, cos=0.026), tot_loss_proj:2.332 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
[1600/2000] tot_loss=2.282 (perp=9.434, rec=0.370, cos=0.026), tot_loss_proj:2.335 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
[1650/2000] tot_loss=2.276 (perp=9.434, rec=0.364, cos=0.026), tot_loss_proj:2.326 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
[1700/2000] tot_loss=2.277 (perp=9.434, rec=0.365, cos=0.025), tot_loss_proj:2.320 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
[1750/2000] tot_loss=2.274 (perp=9.434, rec=0.363, cos=0.024), tot_loss_proj:2.335 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
[1800/2000] tot_loss=2.276 (perp=9.434, rec=0.362, cos=0.027), tot_loss_proj:2.323 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
[1850/2000] tot_loss=2.270 (perp=9.434, rec=0.358, cos=0.026), tot_loss_proj:2.327 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
[1900/2000] tot_loss=2.274 (perp=9.434, rec=0.363, cos=0.024), tot_loss_proj:2.327 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
[1950/2000] tot_loss=2.275 (perp=9.434, rec=0.365, cos=0.024), tot_loss_proj:2.327 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Attempt swap
[2000/2000] tot_loss=2.266 (perp=9.434, rec=0.355, cos=0.024), tot_loss_proj:2.336 [t=0.30s]
prediction: ['[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] successful enjoyable experience own an enjoyable potent successful destination adaptation adaptation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.846 | p: 53.846 | r: 53.846
rouge2     | fm: 8.333 | p: 8.333 | r: 8.333
rougeL     | fm: 38.462 | p: 38.462 | r: 38.462
rougeLsum  | fm: 38.462 | p: 38.462 | r: 38.462
r1fm+r2fm = 62.179

[Aggregate metrics]:
rouge1     | fm: 91.372 | p: 90.518 | r: 92.295
rouge2     | fm: 57.513 | p: 57.358 | r: 57.691
rougeL     | fm: 79.292 | p: 78.635 | r: 79.957
rougeLsum  | fm: 79.243 | p: 78.611 | r: 79.975
r1fm+r2fm = 148.885

input #22 time: 0:11:57 | total time: 5:00:42


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.9870513711673952
highest_index [0]
highest [0.9870513711673952]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.7029697895050049 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7015466094017029 for ['[CLS]cky second y bad safely foundry viation quality turner direct raleigh hyper specification ware what mccall engineer shockthing joining derivative reflecting kind trojan holland rule year graduallybid amount cat fishing deserves gravity weapon viola family cross swim accessed 0 easton politics lady partition fewer [SEP] [SEP]']
[Init] best rec loss: 0.6990765333175659 for ['[CLS] colony. ana substitute bar advisory a yellow service copiesroud demonarianlawuc networks key months to nextations polly past fitness was congress has forest dr providingee marsh rick georgia { pacific coloured aisles sim wilde over baggagecr tune kirby project punk launch [SEP]']
[Init] best rec loss: 0.6983642578125 for ['[CLS] held day bal pass ends sweet pal picturesque indiannde scheduled corps ward those rodya patrons remote grace reef bullet heart array black chess volcanony council point night cha that cast ahead sun itself grant viscount judge bond common back beau period armour onto ago brent [SEP]']
[Init] best rec loss: 0.6961460709571838 for ['[CLS] glanced break whole spread moving horse shared appropriate 1a course front reception roles money morse cater taken pr coat hudson glasslizer, product prices clouds forcesmament solid watch planning fortune heaven kong coast goldmanmana jessie finger project north knows [CLS] taylor reviewن labor boss [SEP]']
[Init] best perm rec loss: 0.6958310008049011 for ['[CLS] course break review reception prices coast boss sharedن taylor knows pr roles watch planning money horse taken glanced hudson morse project jessie fortune [CLS] labor appropriate product cater solid front, north kong coat heaven wholemana goldman forces clouds 1a moving glasslizermament spread finger [SEP]']
[Init] best perm rec loss: 0.6940396428108215 for ['[CLS] heaven spread jessie pr forces glanced [CLS] break review reception appropriate labor shared 1a front roles hudson glass planning goldman course horse prices product north whole watch fortune coast knowsن taken coat clouds moneymana solidlizer cater finger morse project taylor kong, moving bossmament [SEP]']
[Init] best perm rec loss: 0.6940006613731384 for ['[CLS] boss money kong moving review jessie taylor shared course [CLS] hudson glass solid coast forces whole goldman glanced break labor project finger receptionmament watch appropriate product 1a spread planning horse roles knowslizer clouds north prices cater frontن pr heavenmana, morse fortune taken coat [SEP]']
[Init] best perm rec loss: 0.6934602856636047 for ['[CLS] knows kong hudson clouds labor finger spread [CLS] solid project 1a front taylor taken coat glass,mament shared course north roles glanced prices horse appropriate product boss jessie forcesmanaن watch planning cater moving break money goldman review whole pr fortune morse coast heaven receptionlizer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.515 (perp=11.100, rec=0.264, cos=0.031), tot_loss_proj:3.236 [t=0.30s]
prediction: ['[CLS] objective far leavesting superhero question ;6 though project attack internalutable? to scarecarriage objective ] soldiers latin achieve! soldiers their strategic objective : independence strategic. strategic for ra alternative push tone on t candidate ra its walk community 1960s tomorrow innerlizer [SEP]']
[ 100/2000] tot_loss=2.321 (perp=10.491, rec=0.200, cos=0.023), tot_loss_proj:3.020 [t=0.31s]
prediction: ['[CLS] objectives versionsting patriotic vietnam ;6 although tone picture internal together - the aggressive its approach kowalski soldiers : achieve women soldiers main strategic objective : autonomy strategic, strategic for religious tone brass tone on t object ra. the generation generation generation tobylizer [SEP]']
[ 150/2000] tot_loss=2.103 (perp=9.565, rec=0.168, cos=0.022), tot_loss_proj:2.812 [t=0.31s]
prediction: ['[CLS] objective some versionszing patriotic vietnam, must while drama picture object ultimately - the strategic its tone such soldiers the achieve women soldiers main strategic objective : objective strategic, strategic for its tone ghost toneh : object ra. the generation generation generation cost generation [SEP]']
[ 200/2000] tot_loss=2.071 (perp=9.455, rec=0.157, cos=0.023), tot_loss_proj:2.910 [t=0.31s]
prediction: ['[CLS] objective some tone drama patriotic vietnam, must while drama picture object will - the patriotic its tone such soldiers the achieves soldiers main strategic objective : ultimately strategic, strategic for its tone percussion toneh : concept ra. the generation generation generation cost creation [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.378 (perp=10.181, rec=0.245, cos=0.097), tot_loss_proj:2.931 [t=0.31s]
prediction: ['[CLS] objective the formszing vietnam vietnam a $ while drama picture object would ghost the patriotic its tone such soldiers the achieve " soldiers main strategic objective : ultimately strategic ; : a political fish - nhh : idea ra the that generation generation the cost generation [SEP]']
[ 300/2000] tot_loss=2.159 (perp=9.451, rec=0.236, cos=0.033), tot_loss_proj:2.789 [t=0.31s]
prediction: ['[CLS] objective its েzing vietnam and go, while picture picture object willh. vietnamese ultimately tone such soldiers the achieve since soldiers main strategic objective :ー strategic - : human internal lineage - horizon of : 止 ra. that life of a cost generation [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.989 (perp=8.810, rec=0.201, cos=0.026), tot_loss_proj:2.674 [t=0.31s]
prediction: ['[CLS] objective its েzing vietnam a to, while the picture object willh. patriotic, tone such soldiers picture achieve? soldiers main strategic objective : objective strategic - a human historical biblical - horizon of : ‐ ra of that difficulties of a cost generation [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.945 (perp=8.772, rec=0.166, cos=0.025), tot_loss_proj:2.702 [t=0.31s]
prediction: ['[CLS] objective its েzing vietnam a to, while the picture object willh. patriotic, tone such soldiers, achieve? soldiers main strategic objective : objective strategic - a define historical biblical - ‐bergh : ra of that stories of a cost generation [SEP]']
[ 450/2000] tot_loss=1.930 (perp=8.777, rec=0.149, cos=0.026), tot_loss_proj:2.837 [t=0.31s]
prediction: ['[CLS] objective its েzing vietnam a to, while the picture object willh. vietnam, tone such soldiers, achieve when patriotic main strategic objective : ultimately strategic - a define historical costs - ‐ equationh : ra of that difficulties of a cost generation [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.869 (perp=8.538, rec=0.137, cos=0.025), tot_loss_proj:2.608 [t=0.31s]
prediction: ['[CLS] objective its েzing vietnam a to, while a picture object willh. vietnam, tone such soldiers, achieve a patriotic main strategic objective : ultimately strategic -. define historical costs - ‐ equationh : ra of that conflict of a cost generation [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.817 (perp=8.284, rec=0.134, cos=0.026), tot_loss_proj:2.570 [t=0.31s]
prediction: ['[CLS] objective its েzing vietnam a to, while a picture object willh strategic vietnam, tone such soldiers, achieve a patriotic main strategic objective : ultimately. -. define historical costs - ‐ equation - : ra of that conflict of a cost generation [SEP]']
[ 600/2000] tot_loss=1.896 (perp=8.680, rec=0.134, cos=0.026), tot_loss_proj:2.690 [t=0.31s]
prediction: ['[CLS] objective its েzing vietnam a to, while a picture object willh strategic vietnam, tone such soldiers, achieve a patriotic main strategic expressed : ultimately. -. define historical costs - ‐ equation - : ra of that conflict of a cost generation [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.818 (perp=8.341, rec=0.125, cos=0.024), tot_loss_proj:2.602 [t=0.31s]
prediction: ['[CLS] objective its েzing vietnam the to, while a picture object willh strategic vietnam, tone such soldiers, achieve a patriotic main strategic expressed : ultimately - -. define historical cost - ‐ cost equation - : ra of that conflict of a generation [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.860 (perp=8.568, rec=0.121, cos=0.025), tot_loss_proj:2.627 [t=0.31s]
prediction: ['[CLS] objective its ে the vietnamzing to, while a picture object someh strategic patriotic, tone such soldiers, achieve a drama main strategic achieve : ultimately - -. define historical cost - ‐ cost governing - : ra of that conflict of a generation [SEP]']
[ 750/2000] tot_loss=1.856 (perp=8.594, rec=0.113, cos=0.024), tot_loss_proj:2.652 [t=0.31s]
prediction: ['[CLS] objective its ে the vietnamzing to, while a picture object willh strategic patriotic, tone such soldiers, achieve a drama main strategic achieve : ultimately - -. define the cost - ‐ cost governing - : ra the that conflict of a generation [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.815 (perp=8.367, rec=0.117, cos=0.024), tot_loss_proj:2.589 [t=0.31s]
prediction: ['[CLS] the objective its ে vietnamzing to, while a picture object willh strategic patriotic, tone such soldiers, achieve a drama main strategic achieve : ultimately - -. define the cost - ‐ cost governing - : ra the that conflict of a generation [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.812 (perp=8.322, rec=0.123, cos=0.025), tot_loss_proj:2.603 [t=0.31s]
prediction: ['[CLS] the objective its ে vietnamzing to, while a picture object willh strategic patriotic, tone such soldiers, achieve a drama main strategic achieve : ultimately - -. define the cost - ‐ cost that relationshipsh : ra the conflict of a generation [SEP]']
[ 900/2000] tot_loss=1.809 (perp=8.322, rec=0.120, cos=0.025), tot_loss_proj:2.600 [t=0.31s]
prediction: ['[CLS] the objective its ে vietnamzing to, while a picture object willh strategic patriotic, tone such soldiers, achieve a drama main strategic achieve : ultimately - -. define the cost - ‐ cost that relationshipsh : ra the conflict of a generation [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.802 (perp=8.311, rec=0.114, cos=0.026), tot_loss_proj:2.574 [t=0.31s]
prediction: ['[CLS] the objective its ে vietnamzing to, while a picture object willh strategic patriotic, tone such soldiers, achieve a drama main strategic achieve : ultimately - -. define the cost - that ‐ cost governingh : ra the conflict of a generation [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.701 (perp=7.763, rec=0.123, cos=0.025), tot_loss_proj:2.452 [t=0.31s]
prediction: ['[CLS] the objective its ে vietnamzing to, while a picture object willh strategic patriotic drama, tone such soldiers, achieve a main strategic achieve : ultimately - -. define the cost - that ‐ cost conditionsh : ra the conflict of a generation [SEP]']
[1050/2000] tot_loss=1.726 (perp=7.923, rec=0.117, cos=0.024), tot_loss_proj:2.481 [t=0.31s]
prediction: ['[CLS] the objective its ে vietnamzing to, while a picture object willh strategic patriotic drama, tone such soldiers. achieve a main strategic achieve : ultimately - -. define the cost - that ‐ cost conditionsh : ra the conflict of a generation [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.688 (perp=7.750, rec=0.113, cos=0.026), tot_loss_proj:2.424 [t=0.31s]
prediction: ['[CLS] the objective its ে vietnamzing to, while a picture object willh strategic patriotic drama, tone such soldiers. achieve a main strategic achieve : ultimately - -. define the cost ra - that ‐ cost conditionsh : the conflict of a generation [SEP]']
Attempt swap
[1150/2000] tot_loss=1.682 (perp=7.713, rec=0.113, cos=0.026), tot_loss_proj:2.493 [t=0.31s]
prediction: ['[CLS] the objective its ে vietnamzing of, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategic achieve : ultimately - -. define the cost ra - that ‐ cost conditionsh : the conflict of a generation [SEP]']
[1200/2000] tot_loss=1.725 (perp=7.969, rec=0.106, cos=0.025), tot_loss_proj:2.546 [t=0.31s]
prediction: ['[CLS] the objective its ে vietnamzing of, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategic achieve : ultimately - -. define the cost ra - that ‐ cost conditionsh a the conflict of a generation [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.696 (perp=7.797, rec=0.111, cos=0.026), tot_loss_proj:2.483 [t=0.31s]
prediction: ['[CLS] the objective its ে razing of, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategic achieve : ultimately - -. define the cost vietnam - that ‐ cost conditionsh a the conflict of a generation [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.647 (perp=7.587, rec=0.106, cos=0.024), tot_loss_proj:2.407 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategic achieve : ultimately - -. define the cost vietnam - that ‐ cost conditionsh - the conflict of a generation [SEP]']
[1350/2000] tot_loss=1.651 (perp=7.587, rec=0.109, cos=0.025), tot_loss_proj:2.404 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategic achieve : ultimately - -. define the cost vietnam - that ‐ cost conditionsh - the conflict of a generation [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.631 (perp=7.508, rec=0.104, cos=0.026), tot_loss_proj:2.374 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategics : ultimately - -. define the cost - that ‐ cost conditionsh - the vietnam conflict of a generation [SEP]']
Attempt swap
[1450/2000] tot_loss=1.630 (perp=7.508, rec=0.104, cos=0.025), tot_loss_proj:2.373 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategics : ultimately - -. define the cost - that ‐ cost conditionsh - the vietnam conflict of a generation [SEP]']
[1500/2000] tot_loss=1.681 (perp=7.778, rec=0.100, cos=0.025), tot_loss_proj:2.389 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategics : ultimately - -. define human cost - that ‐ cost conditionsh - the vietnam conflict of a generation [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.685 (perp=7.773, rec=0.106, cos=0.025), tot_loss_proj:2.434 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategics : ultimately - - would define human cost - that ‐h conditions cost - the vietnam conflict of a generation [SEP]']
Attempt swap
[1600/2000] tot_loss=1.684 (perp=7.773, rec=0.104, cos=0.025), tot_loss_proj:2.434 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategics : ultimately - - would define human cost - that ‐h conditions cost - the vietnam conflict of a generation [SEP]']
[1650/2000] tot_loss=1.685 (perp=7.773, rec=0.105, cos=0.025), tot_loss_proj:2.434 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategics : ultimately - - would define human cost - that ‐h conditions cost - the vietnam conflict of a generation [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.683 (perp=7.747, rec=0.108, cos=0.026), tot_loss_proj:2.431 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategics : ultimately - - would define human cost - that ‐h conditions cost - the conflict of vietnam a generation [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.660 (perp=7.679, rec=0.099, cos=0.025), tot_loss_proj:2.427 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategic cost : ultimately - -. define human cost - that ‐h conditionss - the conflict of vietnam a generation [SEP]']
[1800/2000] tot_loss=1.658 (perp=7.651, rec=0.102, cos=0.025), tot_loss_proj:2.430 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategic cost : ultimately - - would define human cost - that ‐h conditionss - the conflict of vietnam a generation [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.681 (perp=7.753, rec=0.105, cos=0.025), tot_loss_proj:2.404 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategic cost : - ultimately - would define human cost - that ‐h formats - the conflict of vietnam a generation [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.637 (perp=7.587, rec=0.095, cos=0.024), tot_loss_proj:2.389 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategic cost : - ultimately - would define human cost - thats ‐h conditions - the conflict of vietnam a generation [SEP]']
[1950/2000] tot_loss=1.642 (perp=7.587, rec=0.100, cos=0.025), tot_loss_proj:2.384 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategic cost : - ultimately - would define human cost - thats ‐h conditions - the conflict of vietnam a generation [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.670 (perp=7.728, rec=0.100, cos=0.025), tot_loss_proj:2.465 [t=0.31s]
prediction: ['[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh that a main strategic cost : - ultimately - would define human cost - achieves ‐h format - the conflict of vietnam a generation [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] the objective its ে razing a, while a picture object willh strategic patriotic drama, tone such soldiersh achieve a main strategic cost : - ultimately - would define human cost - thats ‐h conditions - the conflict of vietnam a generation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.935 | p: 67.568 | r: 62.500
rouge2     | fm: 13.333 | p: 13.889 | r: 12.821
rougeL     | fm: 38.961 | p: 40.541 | r: 37.500
rougeLsum  | fm: 38.961 | p: 40.541 | r: 37.500
r1fm+r2fm = 78.268

[Aggregate metrics]:
rouge1     | fm: 90.236 | p: 89.568 | r: 91.010
rouge2     | fm: 55.624 | p: 55.533 | r: 55.750
rougeL     | fm: 77.765 | p: 77.209 | r: 78.431
rougeLsum  | fm: 77.466 | p: 76.898 | r: 78.141
r1fm+r2fm = 145.860

input #23 time: 0:12:11 | total time: 5:12:53


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9859329593104531
highest_index [0]
highest [0.9859329593104531]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8429774045944214 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8052085638046265 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.7970786094665527 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 0.7693362832069397 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.7599668502807617 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.743870735168457 for ['[CLS] numb clear post mirror leg closet died fond sometimes distributor bonus « piecegence nerve rush authority direction turnsxie [SEP]']
[Init] best rec loss: 0.7090284824371338 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7088693976402283 for ['[CLS]aneous county port play em bond mid damned snow village bush ryuwyl suffer arms attack happy unless younger no [SEP]']
[Init] best perm rec loss: 0.7087693810462952 for ['[CLS] suffer port arms youngerwyl em snow ryu bond mid village unless damnedaneous no attack happy play bush county [SEP]']
[Init] best perm rec loss: 0.7083693742752075 for ['[CLS] younger suffer county village bondwyl unless play no em arms damned ryu attack snow bushaneous happy mid port [SEP]']
[Init] best perm rec loss: 0.707435131072998 for ['[CLS] attack suffer bush port village play unless snow damned arms county mid em bondwyl ryuaneous younger no happy [SEP]']
[Init] best perm rec loss: 0.7072262167930603 for ['[CLS] younger bush village emwyl play county happy bond no unless mid arms ryu damned snow attack suffer portaneous [SEP]']
[Init] best perm rec loss: 0.7059413194656372 for ['[CLS] county suffer younger damned ryu port play bush no attack unless armswyl village em snowaneous happy bond mid [SEP]']
[Init] best perm rec loss: 0.7038286328315735 for ['[CLS] younger arms village em damned attack mid bush no bond ryu happyaneous county suffer playwyl unless port snow [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.557 (perp=10.912, rec=0.330, cos=0.044), tot_loss_proj:3.044 [t=0.31s]
prediction: ['[CLS] evil undercover committee dummy evil attempt took illegal political bomb hanging! armed context killed hated - communist terrorists dangerous [SEP]']
[ 100/2000] tot_loss=2.390 (perp=10.640, rec=0.234, cos=0.028), tot_loss_proj:2.882 [t=0.31s]
prediction: ['[CLS] taken outside - political evil terrorists outside american context terrorists being jury ( context are than - terrorists context evil [SEP]']
[ 150/2000] tot_loss=2.308 (perp=10.612, rec=0.159, cos=0.026), tot_loss_proj:2.871 [t=0.31s]
prediction: ['[CLS] taken outside the political evil terrorists outside american context terrorists! outside ( see are than than terrorists context evil [SEP]']
[ 200/2000] tot_loss=2.170 (perp=9.956, rec=0.141, cos=0.038), tot_loss_proj:2.774 [t=0.31s]
prediction: ['[CLS] taken outside the climate evil the outside american context terrorists! outside ( see are than than terrorists ) evil [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.728 (perp=7.873, rec=0.128, cos=0.026), tot_loss_proj:2.160 [t=0.31s]
prediction: ['[CLS] taken outside the climate the political outside than context terrorists! ( ( see more evil than climate ) evil [SEP]']
[ 300/2000] tot_loss=1.758 (perp=7.982, rec=0.131, cos=0.031), tot_loss_proj:2.203 [t=0.31s]
prediction: ['[CLS] taken outside the climate the political outside than context terrorists! ( ( see more evil than ever ) evil [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.661 (perp=7.610, rec=0.111, cos=0.028), tot_loss_proj:2.208 [t=0.31s]
prediction: ['[CLS] taken outside the climate the political context than outside terrorists! ( ( see more evil than ever ) current [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.581 (perp=7.228, rec=0.107, cos=0.028), tot_loss_proj:1.987 [t=0.31s]
prediction: ['[CLS] taken outside the climate political context than outside the terrorists! ( ( see more evil than ever ) current [SEP]']
[ 450/2000] tot_loss=1.626 (perp=7.413, rec=0.112, cos=0.031), tot_loss_proj:2.104 [t=0.31s]
prediction: ['[CLS] taken outside the climate political context than outside the terrorists! in ( see more evil than ever ) current [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.513 (perp=6.973, rec=0.092, cos=0.027), tot_loss_proj:1.974 [t=0.31s]
prediction: ['[CLS] taken outside the climate political context than outside the terrorists! - ( see more evil than ever ) current [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.492 (perp=6.813, rec=0.103, cos=0.026), tot_loss_proj:1.925 [t=0.31s]
prediction: ['[CLS] taken outside the climate political context than outside the terrorists! current ( see more evil than ever ) : [SEP]']
[ 600/2000] tot_loss=1.723 (perp=7.098, rec=0.247, cos=0.056), tot_loss_proj:2.002 [t=0.31s]
prediction: ['[CLS] taken outside the climate political context than outside the terrorists! current ( see more evil than ever ) - [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.481 (perp=6.477, rec=0.159, cos=0.026), tot_loss_proj:1.779 [t=0.31s]
prediction: ['[CLS] taken outside the climate political context than outside the terrorists current ( see more evil than ever! ) : [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.428 (perp=6.318, rec=0.136, cos=0.028), tot_loss_proj:1.719 [t=0.31s]
prediction: ['[CLS] taken outside the climate political context than outside the current terrorists ( see more evil than ever! ) : [SEP]']
[ 750/2000] tot_loss=1.536 (perp=6.855, rec=0.139, cos=0.027), tot_loss_proj:1.820 [t=0.31s]
prediction: ['[CLS] taken outside the climate political context foreign outside the current terrorists ( see more evil than ever! ) : [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.547 (perp=7.008, rec=0.119, cos=0.026), tot_loss_proj:1.867 [t=0.31s]
prediction: ['[CLS] taken outside the desmond political context climate outside the current terrorists ( see more evil than ever! ) : [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.530 (perp=6.891, rec=0.125, cos=0.027), tot_loss_proj:2.141 [t=0.31s]
prediction: ['[CLS] taken outside desmond political context the climate outside the current terrorists ( see more evil than ever! ) : [SEP]']
[ 900/2000] tot_loss=1.518 (perp=6.891, rec=0.113, cos=0.026), tot_loss_proj:2.142 [t=0.31s]
prediction: ['[CLS] taken outside desmond political context the climate outside the current terrorists ( see more evil than ever! ) : [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.516 (perp=6.891, rec=0.111, cos=0.027), tot_loss_proj:2.145 [t=0.36s]
prediction: ['[CLS] taken outside desmond political context the climate outside the current terrorists ( see more evil than ever! ) : [SEP]']
Attempt swap
[1000/2000] tot_loss=1.516 (perp=6.891, rec=0.111, cos=0.027), tot_loss_proj:2.141 [t=0.36s]
prediction: ['[CLS] taken outside desmond political context the climate outside the current terrorists ( see more evil than ever! ) : [SEP]']
[1050/2000] tot_loss=1.511 (perp=6.891, rec=0.106, cos=0.027), tot_loss_proj:2.149 [t=0.36s]
prediction: ['[CLS] taken outside desmond political context the climate outside the current terrorists ( see more evil than ever! ) : [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.352 (perp=6.090, rec=0.107, cos=0.027), tot_loss_proj:1.671 [t=0.36s]
prediction: ['[CLS] taken outside of political context the climate outside the current ( terrorists see more evil than ever! ) : [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.326 (perp=5.956, rec=0.107, cos=0.028), tot_loss_proj:1.637 [t=0.36s]
prediction: ['[CLS] taken outside of political context ( the climate outside the current terrorists see more evil than ever! ) : [SEP]']
[1200/2000] tot_loss=1.317 (perp=5.956, rec=0.099, cos=0.027), tot_loss_proj:1.643 [t=0.36s]
prediction: ['[CLS] taken outside of political context ( the climate outside the current terrorists see more evil than ever! ) : [SEP]']
Attempt swap
[1250/2000] tot_loss=1.316 (perp=5.956, rec=0.098, cos=0.027), tot_loss_proj:1.636 [t=0.36s]
prediction: ['[CLS] taken outside of political context ( the climate outside the current terrorists see more evil than ever! ) : [SEP]']
Attempt swap
[1300/2000] tot_loss=1.315 (perp=5.956, rec=0.097, cos=0.027), tot_loss_proj:1.640 [t=0.36s]
prediction: ['[CLS] taken outside of political context ( the climate outside the current terrorists see more evil than ever! ) : [SEP]']
[1350/2000] tot_loss=1.310 (perp=5.956, rec=0.092, cos=0.027), tot_loss_proj:1.634 [t=0.36s]
prediction: ['[CLS] taken outside of political context ( the climate outside the current terrorists see more evil than ever! ) : [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.273 (perp=5.717, rec=0.103, cos=0.027), tot_loss_proj:1.662 [t=0.36s]
prediction: ['[CLS] taken outside of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
Attempt swap
[1450/2000] tot_loss=1.273 (perp=5.717, rec=0.103, cos=0.027), tot_loss_proj:1.657 [t=0.36s]
prediction: ['[CLS] taken outside of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
[1500/2000] tot_loss=1.271 (perp=5.717, rec=0.100, cos=0.027), tot_loss_proj:1.666 [t=0.36s]
prediction: ['[CLS] taken outside of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
Attempt swap
[1550/2000] tot_loss=1.266 (perp=5.717, rec=0.095, cos=0.027), tot_loss_proj:1.662 [t=0.36s]
prediction: ['[CLS] taken outside of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
Attempt swap
[1600/2000] tot_loss=1.268 (perp=5.717, rec=0.098, cos=0.027), tot_loss_proj:1.661 [t=0.36s]
prediction: ['[CLS] taken outside of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
[1650/2000] tot_loss=1.260 (perp=5.717, rec=0.090, cos=0.027), tot_loss_proj:1.672 [t=0.36s]
prediction: ['[CLS] taken outside of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
Attempt swap
[1700/2000] tot_loss=1.389 (perp=6.364, rec=0.089, cos=0.027), tot_loss_proj:2.164 [t=0.36s]
prediction: ['[CLS] taken the of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.272 (perp=5.680, rec=0.109, cos=0.027), tot_loss_proj:1.935 [t=0.36s]
prediction: ['[CLS] the taken of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
[1800/2000] tot_loss=1.258 (perp=5.680, rec=0.095, cos=0.027), tot_loss_proj:1.943 [t=0.36s]
prediction: ['[CLS] the taken of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
Attempt swap
[1850/2000] tot_loss=1.264 (perp=5.680, rec=0.101, cos=0.027), tot_loss_proj:1.935 [t=0.36s]
prediction: ['[CLS] the taken of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
Attempt swap
[1900/2000] tot_loss=1.253 (perp=5.680, rec=0.090, cos=0.027), tot_loss_proj:1.937 [t=0.36s]
prediction: ['[CLS] the taken of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
[1950/2000] tot_loss=1.260 (perp=5.680, rec=0.097, cos=0.027), tot_loss_proj:1.943 [t=0.36s]
prediction: ['[CLS] the taken of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
Attempt swap
[2000/2000] tot_loss=1.262 (perp=5.680, rec=0.099, cos=0.027), tot_loss_proj:1.946 [t=0.36s]
prediction: ['[CLS] the taken of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] taken outside of context ( the political climate outside the current terrorists see more evil than ever! ) : [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.444 | p: 94.444 | r: 94.444
rouge2     | fm: 52.941 | p: 52.941 | r: 52.941
rougeL     | fm: 72.222 | p: 72.222 | r: 72.222
rougeLsum  | fm: 72.222 | p: 72.222 | r: 72.222
r1fm+r2fm = 147.386

[Aggregate metrics]:
rouge1     | fm: 90.427 | p: 89.755 | r: 91.258
rouge2     | fm: 55.755 | p: 55.668 | r: 55.913
rougeL     | fm: 77.651 | p: 77.097 | r: 78.300
rougeLsum  | fm: 77.277 | p: 76.774 | r: 77.892
r1fm+r2fm = 146.181

input #24 time: 0:13:11 | total time: 5:26:05


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9881610045580507
highest_index [0]
highest [0.9881610045580507]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 0.9517367482185364 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.908818244934082 for ['[CLS] weakness blue fast @ [SEP]']
[Init] best rec loss: 0.9041762948036194 for ['[CLS] stepped senate centuryfish [SEP]']
[Init] best rec loss: 0.8951758146286011 for ['[CLS] schoolre kim also [SEP]']
[Init] best rec loss: 0.886407732963562 for ['[CLS]iary rooms concerned who [SEP]']
[Init] best rec loss: 0.8729113340377808 for ['[CLS] tolerance ba clearffs [SEP]']
[Init] best perm rec loss: 0.871735155582428 for ['[CLS] tolerance clearffs ba [SEP]']
[Init] best perm rec loss: 0.8694521188735962 for ['[CLS]ffs clear ba tolerance [SEP]']
[Init] best perm rec loss: 0.8689752817153931 for ['[CLS]ffs tolerance clear ba [SEP]']
[Init] best perm rec loss: 0.8682476878166199 for ['[CLS] tolerance baffs clear [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.032 (perp=8.848, rec=0.231, cos=0.032), tot_loss_proj:2.243 [t=0.35s]
prediction: ['[CLS] beautiful beautiful film alive [SEP]']
[ 100/2000] tot_loss=2.235 (perp=10.375, rec=0.136, cos=0.024), tot_loss_proj:2.354 [t=0.35s]
prediction: ['[CLS] strange beautiful film beautiful [SEP]']
[ 150/2000] tot_loss=2.211 (perp=10.375, rec=0.111, cos=0.024), tot_loss_proj:2.364 [t=0.35s]
prediction: ['[CLS] strange beautiful film beautiful [SEP]']
[ 200/2000] tot_loss=2.190 (perp=10.375, rec=0.092, cos=0.023), tot_loss_proj:2.365 [t=0.35s]
prediction: ['[CLS] strange beautiful film beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.770 (perp=8.270, rec=0.093, cos=0.023), tot_loss_proj:1.952 [t=0.35s]
prediction: ['[CLS] strange beautiful beautiful film [SEP]']
[ 300/2000] tot_loss=1.767 (perp=8.270, rec=0.090, cos=0.023), tot_loss_proj:1.963 [t=0.35s]
prediction: ['[CLS] strange beautiful beautiful film [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.584 (perp=7.298, rec=0.101, cos=0.023), tot_loss_proj:1.835 [t=0.35s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.583 (perp=7.298, rec=0.100, cos=0.023), tot_loss_proj:1.816 [t=0.35s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
[ 450/2000] tot_loss=1.515 (perp=7.104, rec=0.071, cos=0.023), tot_loss_proj:1.661 [t=0.35s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.427 (perp=6.646, rec=0.074, cos=0.023), tot_loss_proj:1.486 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.421 (perp=6.646, rec=0.069, cos=0.023), tot_loss_proj:1.466 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.412 (perp=6.646, rec=0.060, cos=0.023), tot_loss_proj:1.477 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.418 (perp=6.646, rec=0.065, cos=0.023), tot_loss_proj:1.482 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.416 (perp=6.646, rec=0.063, cos=0.024), tot_loss_proj:1.478 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.422 (perp=6.646, rec=0.069, cos=0.024), tot_loss_proj:1.480 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.413 (perp=6.646, rec=0.060, cos=0.024), tot_loss_proj:1.476 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.423 (perp=6.646, rec=0.070, cos=0.024), tot_loss_proj:1.485 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.418 (perp=6.646, rec=0.065, cos=0.024), tot_loss_proj:1.472 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.408 (perp=6.646, rec=0.055, cos=0.024), tot_loss_proj:1.476 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.404 (perp=6.646, rec=0.051, cos=0.024), tot_loss_proj:1.478 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.429 (perp=6.646, rec=0.076, cos=0.024), tot_loss_proj:1.473 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.410 (perp=6.646, rec=0.057, cos=0.024), tot_loss_proj:1.478 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.411 (perp=6.646, rec=0.058, cos=0.024), tot_loss_proj:1.478 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.415 (perp=6.646, rec=0.062, cos=0.024), tot_loss_proj:1.476 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.411 (perp=6.646, rec=0.059, cos=0.024), tot_loss_proj:1.483 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.418 (perp=6.646, rec=0.065, cos=0.024), tot_loss_proj:1.481 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.414 (perp=6.646, rec=0.062, cos=0.024), tot_loss_proj:1.474 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.415 (perp=6.646, rec=0.063, cos=0.024), tot_loss_proj:1.483 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.411 (perp=6.646, rec=0.058, cos=0.024), tot_loss_proj:1.481 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.411 (perp=6.646, rec=0.058, cos=0.024), tot_loss_proj:1.485 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.409 (perp=6.646, rec=0.056, cos=0.024), tot_loss_proj:1.466 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.426 (perp=6.646, rec=0.074, cos=0.024), tot_loss_proj:1.482 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.413 (perp=6.646, rec=0.060, cos=0.024), tot_loss_proj:1.472 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.406 (perp=6.646, rec=0.053, cos=0.024), tot_loss_proj:1.483 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.403 (perp=6.646, rec=0.050, cos=0.024), tot_loss_proj:1.474 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.418 (perp=6.646, rec=0.065, cos=0.024), tot_loss_proj:1.470 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.410 (perp=6.646, rec=0.058, cos=0.024), tot_loss_proj:1.470 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.423 (perp=6.646, rec=0.070, cos=0.024), tot_loss_proj:1.480 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.423 (perp=6.646, rec=0.070, cos=0.024), tot_loss_proj:1.476 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.411 (perp=6.646, rec=0.059, cos=0.024), tot_loss_proj:1.487 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.665 | p: 90.052 | r: 91.392
rouge2     | fm: 57.438 | p: 57.363 | r: 57.566
rougeL     | fm: 78.474 | p: 77.879 | r: 79.026
rougeLsum  | fm: 78.078 | p: 77.578 | r: 78.667
r1fm+r2fm = 148.103

input #25 time: 0:13:38 | total time: 5:39:44


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9860676755783169
highest_index [0]
highest [0.9860676755783169]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.874987006187439 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.8397762775421143 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 0.8391168117523193 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.8346306681632996 for ['[CLS] este letter freedom ‚ whose raid beautyenes [SEP] numbers allsel especially best thought kid internationally picture tu plum cue dutyriam [SEP]']
[Init] best rec loss: 0.8241804838180542 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 0.8133129477500916 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 0.8121305704116821 for ['[CLS]tead souls s discipline isoᆼ constituencies octave polish door merely four fourth death theoretical usually officers colonialkan arrow shot list more [SEP]']
[Init] best perm rec loss: 0.8116259574890137 for ['[CLS] more list discipline death s polishtead souls fourth usually constituencies shot octave four doorkan colonial theoretical iso merelyᆼ arrow officers [SEP]']
[Init] best perm rec loss: 0.8114267587661743 for ['[CLS] usually fourthtead colonial merelyᆼ s four death arrow octave officers list souls door disciplinekan polish shot constituencies more iso theoretical [SEP]']
[Init] best perm rec loss: 0.8112643361091614 for ['[CLS] s more theoretical iso usuallyᆼ officers arrow disciplinekan polish souls octave fourth door constituencies shottead death colonial four list merely [SEP]']
[Init] best perm rec loss: 0.8107377290725708 for ['[CLS] arrow souls list usually death discipline constituencies four fourth octavetead moreᆼ polish officers shotkan iso colonial s merely door theoretical [SEP]']
[Init] best perm rec loss: 0.8107197284698486 for ['[CLS] arrow discipline more usually merely octave fourkan theoretical iso door shot souls s listᆼ fourth colonial death constituenciestead polish officers [SEP]']
[Init] best perm rec loss: 0.8106196522712708 for ['[CLS] disciplinekan souls usually more list arrow shot iso constituencies door polish death officers colonial fourth four merely s theoretical octaveᆼtead [SEP]']
[Init] best perm rec loss: 0.8099043965339661 for ['[CLS] sᆼ death theoretical colonial four polish arrow fourth merelytead constituencieskan octave shot discipline iso door more souls usually officers list [SEP]']
[Init] best perm rec loss: 0.8082915544509888 for ['[CLS] merely shot usually isotead octave more arrow constituencies soulsᆼ list fourkan officers discipline door theoretical fourth colonial s death polish [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.757 (perp=12.061, rec=0.306, cos=0.039), tot_loss_proj:3.113 [t=0.36s]
prediction: ['[CLS], rushed pointless cop offices or spanish import prisoners money sophie immigrant brig obviously dog author $ pointlessduction - orphan ; foreign [SEP]']
[ 100/2000] tot_loss=2.600 (perp=11.611, rec=0.245, cos=0.033), tot_loss_proj:2.944 [t=0.36s]
prediction: ['[CLS], rushed pointless husband kindergarten - french import age - sophie import brig import import director $ pointless policy ) pointless ) director [SEP]']
[ 150/2000] tot_loss=2.542 (perp=11.578, rec=0.197, cos=0.029), tot_loss_proj:2.901 [t=0.36s]
prediction: ['[CLS], mean pointlessiter kindergarten - french import age - sophie import curled import from director next pointlessnding - pointless ) director [SEP]']
[ 200/2000] tot_loss=2.328 (perp=10.775, rec=0.147, cos=0.027), tot_loss_proj:2.778 [t=0.36s]
prediction: ['[CLS] ) mean pointlessiter kindergarten - french import age - sophie coming - import from director young pointlessnding - offensive ) director [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.240 (perp=10.178, rec=0.177, cos=0.027), tot_loss_proj:2.656 [t=0.36s]
prediction: ['[CLS] and mean pointless age - anneding coming - french import coming - import from director born pointlessn - offensive ) director [SEP]']
[ 300/2000] tot_loss=2.226 (perp=10.292, rec=0.140, cos=0.027), tot_loss_proj:2.633 [t=0.36s]
prediction: ['[CLS] and mean pointless age - anneignanting - french - coming - import from director newly pointless threshold -ing ) director [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.981 (perp=9.147, rec=0.124, cos=0.027), tot_loss_proj:2.421 [t=0.36s]
prediction: ['[CLS] and mean pointless age - annedering - ) - coming of import from director - pointless bolt -ing french director [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.064 (perp=9.563, rec=0.124, cos=0.028), tot_loss_proj:2.555 [t=0.36s]
prediction: ['[CLS] and mean pointless age - anneeringing - ) - - coming of import from director ¶ pointlessanging french director [SEP]']
[ 450/2000] tot_loss=2.186 (perp=10.226, rec=0.114, cos=0.027), tot_loss_proj:2.683 [t=0.36s]
prediction: ['[CLS] and mean pointless age - anneder mean - ) - - coming of import from director ¶ pointless diling french director [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.108 (perp=9.833, rec=0.113, cos=0.027), tot_loss_proj:2.521 [t=0.36s]
prediction: ['[CLS] and mean pointless age - anne mean out - ) -in coming of import from director born pointless bolting french director [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.112 (perp=9.807, rec=0.124, cos=0.027), tot_loss_proj:2.537 [t=0.36s]
prediction: ['[CLS] and mean pointless agein anne mean over - ) - - coming of import from director ¶ pointless bolting french director [SEP]']
[ 600/2000] tot_loss=2.108 (perp=9.841, rec=0.112, cos=0.027), tot_loss_proj:2.504 [t=0.36s]
prediction: ['[CLS] and mean pointless agein anneder over - ) - - coming of import from director ¶ pointless bolt this french writer [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.313 (perp=10.918, rec=0.102, cos=0.027), tot_loss_proj:2.708 [t=0.36s]
prediction: ['[CLS] and mean pointless agein peptideder over - ) - - coming of import from director ¶ pointless anne this french director [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.073 (perp=9.622, rec=0.119, cos=0.029), tot_loss_proj:2.700 [t=0.36s]
prediction: ['[CLS] and mean pointless agein pointlessder over - ) - - coming of import from director ¶ang anne this french director [SEP]']
[ 750/2000] tot_loss=2.133 (perp=10.045, rec=0.096, cos=0.027), tot_loss_proj:2.655 [t=0.36s]
prediction: ['[CLS] and mean pointless agein pointlessder over - ) - - coming of import from director ¶ang anne this frenchrot [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.045 (perp=9.608, rec=0.097, cos=0.027), tot_loss_proj:2.455 [t=0.36s]
prediction: ['[CLS] mean and pointless age - pointlessder over - ) - - coming of import from director ¶ang anne this frenchrot [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.011 (perp=9.432, rec=0.098, cos=0.027), tot_loss_proj:2.415 [t=0.36s]
prediction: ['[CLS] mean and pointless ageder pointless - with - ) - - coming of import from director ¶ang anne this frenchrot [SEP]']
[ 900/2000] tot_loss=1.999 (perp=9.432, rec=0.085, cos=0.027), tot_loss_proj:2.418 [t=0.36s]
prediction: ['[CLS] mean and pointless ageder pointless - with - ) - - coming of import from director ¶ang anne this frenchrot [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.953 (perp=9.206, rec=0.085, cos=0.027), tot_loss_proj:2.380 [t=0.36s]
prediction: ['[CLS] mean and pointless ageder pointless - - with ) - - coming of import from director ¶ang anne this frenchrot [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.928 (perp=9.069, rec=0.087, cos=0.027), tot_loss_proj:2.324 [t=0.36s]
prediction: ['[CLS] mean and pointless ageder - - with pointless ) - - coming of import from director ¶ang anne this frenchrot [SEP]']
[1050/2000] tot_loss=1.935 (perp=9.069, rec=0.093, cos=0.028), tot_loss_proj:2.322 [t=0.36s]
prediction: ['[CLS] mean and pointless ageder - - with pointless ) - - coming of import from director ¶ang anne this frenchrot [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.877 (perp=8.795, rec=0.090, cos=0.028), tot_loss_proj:2.317 [t=0.36s]
prediction: ['[CLS] and pointless age meander - - with pointless ) - - coming of import from director ¶ang anne this frenchrot [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.835 (perp=8.595, rec=0.089, cos=0.028), tot_loss_proj:2.497 [t=0.36s]
prediction: ['[CLS] and with age meander - - pointless pointless ) - - coming of import from director ¶ang anne this frenchrot [SEP]']
[1200/2000] tot_loss=2.085 (perp=9.835, rec=0.090, cos=0.028), tot_loss_proj:2.654 [t=0.36s]
prediction: ['[CLS] anding age meander - - pointless pointless ) - - coming of import from directorrotang anne this frenchrot [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.963 (perp=9.231, rec=0.089, cos=0.028), tot_loss_proj:2.465 [t=0.36s]
prediction: ['[CLS] and french age meander - - pointless pointless ) - - coming of import from directorrotang anne thisingrot [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.916 (perp=9.017, rec=0.085, cos=0.028), tot_loss_proj:2.343 [t=0.36s]
prediction: ['[CLS] and pointless age meander - - french pointless ) - - coming of import from directorrotang anne thisingrot [SEP]']
[1350/2000] tot_loss=1.920 (perp=9.017, rec=0.089, cos=0.028), tot_loss_proj:2.340 [t=0.36s]
prediction: ['[CLS] and pointless age meander - - french pointless ) - - coming of import from directorrotang anne thisingrot [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.904 (perp=8.910, rec=0.095, cos=0.028), tot_loss_proj:2.332 [t=0.36s]
prediction: ['[CLS] pointless age and meander - - french pointless ) - - coming of import from directorrotang anne thisingrot [SEP]']
Attempt swap
[1450/2000] tot_loss=1.892 (perp=8.910, rec=0.082, cos=0.028), tot_loss_proj:2.333 [t=0.36s]
prediction: ['[CLS] pointless age and meander - - french pointless ) - - coming of import from directorrotang anne thisingrot [SEP]']
[1500/2000] tot_loss=1.881 (perp=8.910, rec=0.072, cos=0.028), tot_loss_proj:2.329 [t=0.36s]
prediction: ['[CLS] pointless age and meander - - french pointless ) - - coming of import from directorrotang anne thisingrot [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.883 (perp=8.823, rec=0.091, cos=0.028), tot_loss_proj:2.328 [t=0.36s]
prediction: ['[CLS] pointless age and meander - - french pointless ) - - coming of import from directorrotang this anneingrot [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.810 (perp=8.448, rec=0.092, cos=0.028), tot_loss_proj:2.225 [t=0.36s]
prediction: ['[CLS] pointless age and meander - - french pointless ) - - coming of import from director annerotang thisingrot [SEP]']
[1650/2000] tot_loss=1.800 (perp=8.448, rec=0.083, cos=0.028), tot_loss_proj:2.226 [t=0.36s]
prediction: ['[CLS] pointless age and meander - - french pointless ) - - coming of import from director annerotang thisingrot [SEP]']
Attempt swap
[1700/2000] tot_loss=1.798 (perp=8.448, rec=0.081, cos=0.028), tot_loss_proj:2.224 [t=0.36s]
prediction: ['[CLS] pointless age and meander - - french pointless ) - - coming of import from director annerotang thisingrot [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.755 (perp=8.202, rec=0.087, cos=0.027), tot_loss_proj:2.397 [t=0.36s]
prediction: ['[CLS] age and meander - - french pointless pointless ) - - coming of import from director annerotang thisingrot [SEP]']
[1800/2000] tot_loss=1.749 (perp=8.202, rec=0.081, cos=0.028), tot_loss_proj:2.389 [t=0.36s]
prediction: ['[CLS] age and meander - - french pointless pointless ) - - coming of import from director annerotang thisingrot [SEP]']
Attempt swap
[1850/2000] tot_loss=1.748 (perp=8.202, rec=0.080, cos=0.028), tot_loss_proj:2.391 [t=0.36s]
prediction: ['[CLS] age and meander - - french pointless pointless ) - - coming of import from director annerotang thisingrot [SEP]']
Attempt swap
[1900/2000] tot_loss=1.753 (perp=8.202, rec=0.085, cos=0.028), tot_loss_proj:2.393 [t=0.36s]
prediction: ['[CLS] age and meander - - french pointless pointless ) - - coming of import from director annerotang thisingrot [SEP]']
[1950/2000] tot_loss=1.745 (perp=8.202, rec=0.077, cos=0.028), tot_loss_proj:2.390 [t=0.36s]
prediction: ['[CLS] age and meander - - french pointless pointless ) - - coming of import from director annerotang thisingrot [SEP]']
Attempt swap
[2000/2000] tot_loss=1.750 (perp=8.202, rec=0.082, cos=0.028), tot_loss_proj:2.398 [t=0.36s]
prediction: ['[CLS] age and meander - - french pointless pointless ) - - coming of import from director annerotang thisingrot [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] age and meander - - french pointless pointless ) - - coming of import from director annerotang thisingrot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.750 | p: 73.333 | r: 64.706
rouge2     | fm: 13.333 | p: 14.286 | r: 12.500
rougeL     | fm: 56.250 | p: 60.000 | r: 52.941
rougeLsum  | fm: 56.250 | p: 60.000 | r: 52.941
r1fm+r2fm = 82.083

[Aggregate metrics]:
rouge1     | fm: 89.996 | p: 89.556 | r: 90.610
rouge2     | fm: 55.641 | p: 55.599 | r: 55.698
rougeL     | fm: 77.496 | p: 77.177 | r: 77.944
rougeLsum  | fm: 77.353 | p: 76.966 | r: 77.799
r1fm+r2fm = 145.638

input #26 time: 0:14:02 | total time: 5:53:46


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.9852301198771912
highest_index [0]
highest [0.9852301198771912]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9795958399772644 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9502917528152466 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 0.9360672831535339 for ['[CLS] volume nan on [SEP]']
[Init] best rec loss: 0.921120285987854 for ['[CLS] drawing dynamo cave [SEP]']
[Init] best rec loss: 0.9187149405479431 for ['[CLS] op framework ran [SEP]']
[Init] best rec loss: 0.9107998609542847 for ['[CLS] fat mattream [SEP]']
[Init] best perm rec loss: 0.9063875675201416 for ['[CLS] mat fattream [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.128 (perp=9.508, rec=0.195, cos=0.031), tot_loss_proj:2.387 [t=0.35s]
prediction: ['[CLS] are generic generic [SEP]']
[ 100/2000] tot_loss=1.770 (perp=8.320, rec=0.076, cos=0.030), tot_loss_proj:1.768 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[ 150/2000] tot_loss=1.757 (perp=8.320, rec=0.063, cos=0.030), tot_loss_proj:1.792 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[ 200/2000] tot_loss=1.756 (perp=8.320, rec=0.063, cos=0.029), tot_loss_proj:1.775 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.755 (perp=8.320, rec=0.062, cos=0.029), tot_loss_proj:1.778 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.755 (perp=8.320, rec=0.062, cos=0.029), tot_loss_proj:1.785 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.741 (perp=8.320, rec=0.048, cos=0.029), tot_loss_proj:1.790 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.751 (perp=8.320, rec=0.058, cos=0.029), tot_loss_proj:1.783 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.770 (perp=8.320, rec=0.077, cos=0.029), tot_loss_proj:1.778 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.756 (perp=8.320, rec=0.063, cos=0.029), tot_loss_proj:1.781 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.759 (perp=8.320, rec=0.065, cos=0.029), tot_loss_proj:1.784 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.755 (perp=8.320, rec=0.061, cos=0.029), tot_loss_proj:1.776 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.747 (perp=8.320, rec=0.054, cos=0.029), tot_loss_proj:1.772 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.750 (perp=8.320, rec=0.056, cos=0.029), tot_loss_proj:1.778 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.750 (perp=8.320, rec=0.057, cos=0.029), tot_loss_proj:1.762 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.759 (perp=8.320, rec=0.066, cos=0.029), tot_loss_proj:1.772 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.768 (perp=8.320, rec=0.075, cos=0.029), tot_loss_proj:1.768 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.742 (perp=8.320, rec=0.049, cos=0.029), tot_loss_proj:1.768 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.751 (perp=8.320, rec=0.058, cos=0.029), tot_loss_proj:1.775 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.748 (perp=8.320, rec=0.055, cos=0.029), tot_loss_proj:1.773 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.751 (perp=8.320, rec=0.058, cos=0.029), tot_loss_proj:1.772 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.749 (perp=8.320, rec=0.056, cos=0.029), tot_loss_proj:1.764 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.744 (perp=8.320, rec=0.051, cos=0.029), tot_loss_proj:1.782 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.760 (perp=8.320, rec=0.067, cos=0.029), tot_loss_proj:1.779 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.755 (perp=8.320, rec=0.062, cos=0.029), tot_loss_proj:1.764 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.761 (perp=8.320, rec=0.068, cos=0.029), tot_loss_proj:1.776 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.767 (perp=8.320, rec=0.073, cos=0.029), tot_loss_proj:1.768 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.761 (perp=8.320, rec=0.068, cos=0.029), tot_loss_proj:1.784 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.754 (perp=8.320, rec=0.060, cos=0.029), tot_loss_proj:1.781 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.747 (perp=8.320, rec=0.053, cos=0.029), tot_loss_proj:1.779 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.756 (perp=8.320, rec=0.062, cos=0.029), tot_loss_proj:1.781 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.767 (perp=8.320, rec=0.074, cos=0.029), tot_loss_proj:1.772 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.763 (perp=8.320, rec=0.070, cos=0.029), tot_loss_proj:1.781 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.757 (perp=8.320, rec=0.064, cos=0.029), tot_loss_proj:1.777 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.759 (perp=8.320, rec=0.065, cos=0.029), tot_loss_proj:1.769 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.748 (perp=8.320, rec=0.055, cos=0.029), tot_loss_proj:1.775 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.756 (perp=8.320, rec=0.063, cos=0.029), tot_loss_proj:1.779 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.755 (perp=8.320, rec=0.062, cos=0.029), tot_loss_proj:1.784 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.749 (perp=8.320, rec=0.055, cos=0.029), tot_loss_proj:1.781 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.760 (perp=8.320, rec=0.067, cos=0.029), tot_loss_proj:1.778 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.413 | p: 90.001 | r: 90.978
rouge2     | fm: 56.924 | p: 56.870 | r: 57.010
rougeL     | fm: 78.239 | p: 77.924 | r: 78.735
rougeLsum  | fm: 78.102 | p: 77.686 | r: 78.574
r1fm+r2fm = 147.337

input #27 time: 0:13:37 | total time: 6:07:23


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.986261912689065
highest_index [0]
highest [0.986261912689065]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8742419481277466 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.8476418852806091 for ['[CLS] easierlnan cow [SEP]']
[Init] best rec loss: 0.8399563431739807 for ['[CLS] want set aperture jersey [SEP]']
[Init] best rec loss: 0.8350391387939453 for ['[CLS] clean eastmanlation tribune [SEP]']
[Init] best rec loss: 0.8302027583122253 for ['[CLS] sick prior spielberggation [SEP]']
[Init] best rec loss: 0.8190286159515381 for ['[CLS] w dean re thanks [SEP]']
[Init] best rec loss: 0.8164092898368835 for ['[CLS] pol maneuver lex bar [SEP]']
[Init] best rec loss: 0.8134039044380188 for ['[CLS] tex congress pairbution [SEP]']
[Init] best rec loss: 0.8120297193527222 for ['[CLS] larvae heights jeremy roses [SEP]']
[Init] best perm rec loss: 0.8114371299743652 for ['[CLS] heights roses larvae jeremy [SEP]']
[Init] best perm rec loss: 0.8105425834655762 for ['[CLS] heights jeremy larvae roses [SEP]']
[Init] best perm rec loss: 0.8093804717063904 for ['[CLS] heights jeremy roses larvae [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.462 (perp=10.654, rec=0.274, cos=0.057), tot_loss_proj:3.303 [t=0.34s]
prediction: ['[CLS] for minutes minutes uttar [SEP]']
[ 100/2000] tot_loss=2.111 (perp=9.695, rec=0.137, cos=0.035), tot_loss_proj:2.873 [t=0.35s]
prediction: ['[CLS] for minutes minutes 71 [SEP]']
[ 150/2000] tot_loss=1.857 (perp=8.766, rec=0.076, cos=0.027), tot_loss_proj:2.390 [t=0.35s]
prediction: ['[CLS] for only minutes 71 [SEP]']
[ 200/2000] tot_loss=1.843 (perp=8.766, rec=0.062, cos=0.027), tot_loss_proj:2.408 [t=0.35s]
prediction: ['[CLS] for only minutes 71 [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.624 (perp=7.699, rec=0.059, cos=0.026), tot_loss_proj:1.653 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 300/2000] tot_loss=1.636 (perp=7.699, rec=0.069, cos=0.027), tot_loss_proj:1.648 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.626 (perp=7.699, rec=0.059, cos=0.027), tot_loss_proj:1.654 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.632 (perp=7.699, rec=0.065, cos=0.027), tot_loss_proj:1.660 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 450/2000] tot_loss=1.629 (perp=7.699, rec=0.062, cos=0.027), tot_loss_proj:1.662 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.621 (perp=7.699, rec=0.054, cos=0.027), tot_loss_proj:1.648 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.631 (perp=7.699, rec=0.064, cos=0.027), tot_loss_proj:1.651 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.625 (perp=7.699, rec=0.058, cos=0.027), tot_loss_proj:1.652 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.627 (perp=7.699, rec=0.060, cos=0.027), tot_loss_proj:1.657 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.628 (perp=7.699, rec=0.061, cos=0.027), tot_loss_proj:1.661 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.626 (perp=7.699, rec=0.059, cos=0.027), tot_loss_proj:1.664 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.636 (perp=7.699, rec=0.069, cos=0.027), tot_loss_proj:1.656 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.627 (perp=7.699, rec=0.060, cos=0.027), tot_loss_proj:1.675 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.628 (perp=7.699, rec=0.061, cos=0.027), tot_loss_proj:1.654 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.626 (perp=7.699, rec=0.059, cos=0.027), tot_loss_proj:1.652 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.631 (perp=7.699, rec=0.064, cos=0.027), tot_loss_proj:1.663 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.620 (perp=7.699, rec=0.053, cos=0.027), tot_loss_proj:1.657 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.639 (perp=7.699, rec=0.072, cos=0.027), tot_loss_proj:1.656 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.625 (perp=7.699, rec=0.058, cos=0.027), tot_loss_proj:1.664 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.631 (perp=7.699, rec=0.063, cos=0.027), tot_loss_proj:1.665 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.627 (perp=7.699, rec=0.059, cos=0.027), tot_loss_proj:1.653 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.634 (perp=7.699, rec=0.067, cos=0.027), tot_loss_proj:1.655 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.628 (perp=7.699, rec=0.061, cos=0.027), tot_loss_proj:1.660 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.633 (perp=7.699, rec=0.066, cos=0.027), tot_loss_proj:1.659 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.626 (perp=7.699, rec=0.059, cos=0.027), tot_loss_proj:1.653 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.628 (perp=7.699, rec=0.061, cos=0.027), tot_loss_proj:1.670 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.626 (perp=7.699, rec=0.059, cos=0.027), tot_loss_proj:1.654 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.631 (perp=7.699, rec=0.064, cos=0.027), tot_loss_proj:1.656 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.622 (perp=7.699, rec=0.055, cos=0.027), tot_loss_proj:1.654 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.629 (perp=7.699, rec=0.062, cos=0.027), tot_loss_proj:1.655 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.628 (perp=7.699, rec=0.061, cos=0.027), tot_loss_proj:1.658 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.618 (perp=7.699, rec=0.051, cos=0.027), tot_loss_proj:1.655 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.627 (perp=7.699, rec=0.060, cos=0.027), tot_loss_proj:1.649 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.629 (perp=7.699, rec=0.062, cos=0.027), tot_loss_proj:1.661 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.627 (perp=7.699, rec=0.060, cos=0.027), tot_loss_proj:1.658 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.627 (perp=7.699, rec=0.060, cos=0.027), tot_loss_proj:1.664 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.724 | p: 90.315 | r: 91.250
rouge2     | fm: 58.880 | p: 58.800 | r: 58.947
rougeL     | fm: 79.048 | p: 78.781 | r: 79.485
rougeLsum  | fm: 78.923 | p: 78.663 | r: 79.350
r1fm+r2fm = 149.604

input #28 time: 0:13:37 | total time: 6:21:01


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.984472151348377
highest_index [0]
highest [0.984472151348377]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.8715106844902039 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.8530094623565674 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.8525667190551758 for ['[CLS]jouross restorationӏ ministerial text murder me tertiary biblical [SEP]']
[Init] best rec loss: 0.8431293368339539 for ['[CLS] protected leadlto arose ec along sunset pay everywhere county [SEP]']
[Init] best rec loss: 0.8149373531341553 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.782143235206604 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 0.7817307114601135 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best rec loss: 0.7812945246696472 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best perm rec loss: 0.7792670130729675 for ['[CLS] cells u mostly veto bu meters f axle transmitfounded [SEP]']
[Init] best perm rec loss: 0.7773985266685486 for ['[CLS] cells bu f transmit mostly veto ufounded meters axle [SEP]']
[Init] best perm rec loss: 0.7754891514778137 for ['[CLS] transmit veto u cells axle meters mostly bufounded f [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.999 (perp=8.635, rec=0.224, cos=0.047), tot_loss_proj:2.631 [t=0.35s]
prediction: ['[CLS] typical they believe that punishmentiac as is not it [SEP]']
[ 100/2000] tot_loss=1.767 (perp=8.061, rec=0.123, cos=0.031), tot_loss_proj:2.462 [t=0.35s]
prediction: ['[CLS] resident also believe that evil also resident is not it [SEP]']
[ 150/2000] tot_loss=1.672 (perp=7.678, rec=0.105, cos=0.031), tot_loss_proj:2.507 [t=0.35s]
prediction: ['[CLS] resident i believe that evil also resident is not it [SEP]']
[ 200/2000] tot_loss=1.665 (perp=7.678, rec=0.099, cos=0.031), tot_loss_proj:2.500 [t=0.35s]
prediction: ['[CLS] resident i believe that evil also resident is not it [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.342 (perp=6.065, rec=0.095, cos=0.034), tot_loss_proj:1.756 [t=0.35s]
prediction: ['[CLS] i believe that resident evil is i is not it [SEP]']
[ 300/2000] tot_loss=1.399 (perp=6.413, rec=0.086, cos=0.031), tot_loss_proj:2.207 [t=0.35s]
prediction: ['[CLS] also believe that resident evil. i is not it [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.264 (perp=5.800, rec=0.073, cos=0.031), tot_loss_proj:1.571 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil. is not it [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.162 (perp=5.269, rec=0.078, cos=0.031), tot_loss_proj:1.995 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not. it [SEP]']
[ 450/2000] tot_loss=1.157 (perp=5.269, rec=0.072, cos=0.031), tot_loss_proj:1.992 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not. it [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.008 (perp=4.571, rec=0.063, cos=0.031), tot_loss_proj:1.083 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.013 (perp=4.571, rec=0.068, cos=0.031), tot_loss_proj:1.092 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[ 600/2000] tot_loss=1.007 (perp=4.571, rec=0.062, cos=0.031), tot_loss_proj:1.087 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.019 (perp=4.571, rec=0.074, cos=0.031), tot_loss_proj:1.091 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.003 (perp=4.571, rec=0.058, cos=0.031), tot_loss_proj:1.084 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[ 750/2000] tot_loss=1.010 (perp=4.571, rec=0.064, cos=0.031), tot_loss_proj:1.087 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.010 (perp=4.571, rec=0.064, cos=0.032), tot_loss_proj:1.084 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.011 (perp=4.571, rec=0.066, cos=0.031), tot_loss_proj:1.088 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[ 900/2000] tot_loss=1.019 (perp=4.571, rec=0.075, cos=0.031), tot_loss_proj:1.086 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.014 (perp=4.571, rec=0.069, cos=0.031), tot_loss_proj:1.080 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.013 (perp=4.571, rec=0.068, cos=0.031), tot_loss_proj:1.083 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1050/2000] tot_loss=1.007 (perp=4.571, rec=0.062, cos=0.031), tot_loss_proj:1.085 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.020 (perp=4.571, rec=0.075, cos=0.031), tot_loss_proj:1.083 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.014 (perp=4.571, rec=0.069, cos=0.031), tot_loss_proj:1.085 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1200/2000] tot_loss=1.004 (perp=4.571, rec=0.059, cos=0.031), tot_loss_proj:1.087 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.011 (perp=4.571, rec=0.066, cos=0.031), tot_loss_proj:1.087 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.007 (perp=4.571, rec=0.062, cos=0.031), tot_loss_proj:1.076 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1350/2000] tot_loss=1.018 (perp=4.571, rec=0.073, cos=0.031), tot_loss_proj:1.084 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.006 (perp=4.571, rec=0.061, cos=0.031), tot_loss_proj:1.078 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.012 (perp=4.571, rec=0.067, cos=0.031), tot_loss_proj:1.080 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1500/2000] tot_loss=1.013 (perp=4.571, rec=0.068, cos=0.031), tot_loss_proj:1.079 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.014 (perp=4.571, rec=0.069, cos=0.031), tot_loss_proj:1.076 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.013 (perp=4.571, rec=0.068, cos=0.031), tot_loss_proj:1.079 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1650/2000] tot_loss=0.999 (perp=4.571, rec=0.054, cos=0.031), tot_loss_proj:1.085 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.008 (perp=4.571, rec=0.063, cos=0.031), tot_loss_proj:1.074 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.001 (perp=4.571, rec=0.056, cos=0.031), tot_loss_proj:1.088 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1800/2000] tot_loss=1.010 (perp=4.571, rec=0.065, cos=0.031), tot_loss_proj:1.074 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.019 (perp=4.571, rec=0.074, cos=0.031), tot_loss_proj:1.081 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.007 (perp=4.571, rec=0.062, cos=0.031), tot_loss_proj:1.079 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1950/2000] tot_loss=1.017 (perp=4.571, rec=0.072, cos=0.031), tot_loss_proj:1.071 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.004 (perp=4.571, rec=0.059, cos=0.031), tot_loss_proj:1.069 [t=0.35s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.952 | p: 90.552 | r: 91.430
rouge2     | fm: 60.312 | p: 60.217 | r: 60.441
rougeL     | fm: 79.818 | p: 79.441 | r: 80.241
rougeLsum  | fm: 79.624 | p: 79.264 | r: 79.961
r1fm+r2fm = 151.264

input #29 time: 0:13:39 | total time: 6:34:41


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.9861851476900863
highest_index [0]
highest [0.9861851476900863]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.8305606842041016 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.6952638030052185 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.6545976996421814 for ['[CLS] acceleration council lizard [SEP]']
[Init] best rec loss: 0.6528144478797913 for ['[CLS] spent who mom [SEP]']
[Init] best perm rec loss: 0.6438296437263489 for ['[CLS] mom who spent [SEP]']
[Init] best perm rec loss: 0.6393283605575562 for ['[CLS] who mom spent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.716 (perp=12.475, rec=0.193, cos=0.028), tot_loss_proj:3.482 [t=0.34s]
prediction: ['[CLS]zzabilitybility [SEP]']
[ 100/2000] tot_loss=2.634 (perp=12.475, rec=0.111, cos=0.028), tot_loss_proj:3.593 [t=0.35s]
prediction: ['[CLS]zzabilitybility [SEP]']
[ 150/2000] tot_loss=2.641 (perp=12.475, rec=0.114, cos=0.032), tot_loss_proj:3.622 [t=0.35s]
prediction: ['[CLS]zzabilitybility [SEP]']
[ 200/2000] tot_loss=2.403 (perp=11.466, rec=0.082, cos=0.028), tot_loss_proj:3.991 [t=0.35s]
prediction: ['[CLS]zza fibility [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.001 (perp=9.539, rec=0.066, cos=0.027), tot_loss_proj:1.994 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=2.018 (perp=9.539, rec=0.083, cos=0.027), tot_loss_proj:1.984 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.990 (perp=9.539, rec=0.056, cos=0.026), tot_loss_proj:2.001 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.006 (perp=9.539, rec=0.068, cos=0.030), tot_loss_proj:1.999 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=2.007 (perp=9.539, rec=0.072, cos=0.027), tot_loss_proj:1.998 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.997 (perp=9.539, rec=0.063, cos=0.026), tot_loss_proj:2.004 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.004 (perp=9.539, rec=0.069, cos=0.027), tot_loss_proj:2.000 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.994 (perp=9.539, rec=0.059, cos=0.027), tot_loss_proj:2.000 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.001 (perp=9.539, rec=0.066, cos=0.027), tot_loss_proj:2.009 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.997 (perp=9.539, rec=0.062, cos=0.027), tot_loss_proj:1.996 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.987 (perp=9.539, rec=0.052, cos=0.027), tot_loss_proj:1.994 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.997 (perp=9.539, rec=0.062, cos=0.027), tot_loss_proj:2.005 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.988 (perp=9.539, rec=0.053, cos=0.027), tot_loss_proj:2.005 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.997 (perp=9.539, rec=0.062, cos=0.027), tot_loss_proj:1.995 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.998 (perp=9.539, rec=0.063, cos=0.027), tot_loss_proj:2.001 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.996 (perp=9.539, rec=0.061, cos=0.027), tot_loss_proj:1.995 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.997 (perp=9.539, rec=0.061, cos=0.027), tot_loss_proj:1.998 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.997 (perp=9.539, rec=0.062, cos=0.027), tot_loss_proj:2.005 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=2.001 (perp=9.539, rec=0.066, cos=0.027), tot_loss_proj:1.992 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.991 (perp=9.539, rec=0.056, cos=0.027), tot_loss_proj:1.990 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.995 (perp=9.539, rec=0.060, cos=0.027), tot_loss_proj:2.000 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.995 (perp=9.539, rec=0.060, cos=0.027), tot_loss_proj:1.997 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.993 (perp=9.539, rec=0.058, cos=0.027), tot_loss_proj:1.999 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=2.004 (perp=9.539, rec=0.069, cos=0.027), tot_loss_proj:1.994 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.997 (perp=9.539, rec=0.061, cos=0.027), tot_loss_proj:2.000 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=2.000 (perp=9.539, rec=0.065, cos=0.027), tot_loss_proj:2.000 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.995 (perp=9.539, rec=0.059, cos=0.027), tot_loss_proj:1.998 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.986 (perp=9.539, rec=0.051, cos=0.027), tot_loss_proj:2.003 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.989 (perp=9.539, rec=0.054, cos=0.027), tot_loss_proj:2.006 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.998 (perp=9.539, rec=0.063, cos=0.027), tot_loss_proj:1.993 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=2.001 (perp=9.539, rec=0.065, cos=0.027), tot_loss_proj:2.003 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.983 (perp=9.539, rec=0.048, cos=0.027), tot_loss_proj:1.993 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=2.001 (perp=9.539, rec=0.065, cos=0.027), tot_loss_proj:2.002 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.993 (perp=9.539, rec=0.058, cos=0.027), tot_loss_proj:2.003 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.991 (perp=9.539, rec=0.056, cos=0.027), tot_loss_proj:1.989 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.987 (perp=9.539, rec=0.051, cos=0.027), tot_loss_proj:2.001 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.290 | p: 90.860 | r: 91.818
rouge2     | fm: 61.429 | p: 61.364 | r: 61.501
rougeL     | fm: 80.517 | p: 80.211 | r: 80.924
rougeLsum  | fm: 80.293 | p: 79.918 | r: 80.634
r1fm+r2fm = 152.719

input #30 time: 0:13:36 | total time: 6:48:18


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.9848541355292268
highest_index [0]
highest [0.9848541355292268]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.8710024356842041 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.8120993375778198 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8056276440620422 for ['[CLS] song spectators then [SEP]']
[Init] best rec loss: 0.8026124238967896 for ['[CLS] jing critical hurts [SEP]']
[Init] best rec loss: 0.77150958776474 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 0.7712451219558716 for ['[CLS] lil number belmont [SEP]']
[Init] best rec loss: 0.7682841420173645 for ['[CLS] prefer impression see [SEP]']
[Init] best rec loss: 0.7629185318946838 for ['[CLS] lad crossing all [SEP]']
[Init] best rec loss: 0.7584682106971741 for ['[CLS] golf rollichi [SEP]']
[Init] best rec loss: 0.7422171831130981 for ['[CLS] lighthouse peace case [SEP]']
[Init] best rec loss: 0.7408709526062012 for ['[CLS] degree girl holly [SEP]']
[Init] best perm rec loss: 0.7385581135749817 for ['[CLS] holly degree girl [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.236 (perp=9.932, rec=0.216, cos=0.034), tot_loss_proj:2.854 [t=0.35s]
prediction: ['[CLS] record better better [SEP]']
[ 100/2000] tot_loss=2.098 (perp=9.943, rec=0.080, cos=0.029), tot_loss_proj:2.521 [t=0.35s]
prediction: ['[CLS] vehicle a better [SEP]']
[ 150/2000] tot_loss=2.083 (perp=9.943, rec=0.065, cos=0.029), tot_loss_proj:2.515 [t=0.35s]
prediction: ['[CLS] vehicle a better [SEP]']
[ 200/2000] tot_loss=2.078 (perp=9.943, rec=0.059, cos=0.030), tot_loss_proj:2.514 [t=0.35s]
prediction: ['[CLS] vehicle a better [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.618 (perp=7.602, rec=0.068, cos=0.030), tot_loss_proj:1.688 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.604 (perp=7.602, rec=0.054, cos=0.030), tot_loss_proj:1.697 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.615 (perp=7.602, rec=0.065, cos=0.030), tot_loss_proj:1.695 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.610 (perp=7.602, rec=0.060, cos=0.030), tot_loss_proj:1.693 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.607 (perp=7.602, rec=0.056, cos=0.030), tot_loss_proj:1.690 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.609 (perp=7.602, rec=0.059, cos=0.030), tot_loss_proj:1.698 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.608 (perp=7.602, rec=0.058, cos=0.030), tot_loss_proj:1.681 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.616 (perp=7.602, rec=0.065, cos=0.030), tot_loss_proj:1.682 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.620 (perp=7.602, rec=0.070, cos=0.030), tot_loss_proj:1.688 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.623 (perp=7.602, rec=0.072, cos=0.030), tot_loss_proj:1.699 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.610 (perp=7.602, rec=0.060, cos=0.030), tot_loss_proj:1.692 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.609 (perp=7.602, rec=0.058, cos=0.030), tot_loss_proj:1.691 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.615 (perp=7.602, rec=0.065, cos=0.030), tot_loss_proj:1.699 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.617 (perp=7.602, rec=0.066, cos=0.030), tot_loss_proj:1.692 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.618 (perp=7.602, rec=0.068, cos=0.030), tot_loss_proj:1.690 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.612 (perp=7.602, rec=0.062, cos=0.030), tot_loss_proj:1.687 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.605 (perp=7.602, rec=0.055, cos=0.030), tot_loss_proj:1.689 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.605 (perp=7.602, rec=0.055, cos=0.030), tot_loss_proj:1.697 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.609 (perp=7.602, rec=0.058, cos=0.030), tot_loss_proj:1.686 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.606 (perp=7.602, rec=0.055, cos=0.030), tot_loss_proj:1.688 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.611 (perp=7.602, rec=0.061, cos=0.030), tot_loss_proj:1.690 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.611 (perp=7.602, rec=0.061, cos=0.030), tot_loss_proj:1.681 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.606 (perp=7.602, rec=0.055, cos=0.030), tot_loss_proj:1.675 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.623 (perp=7.602, rec=0.072, cos=0.030), tot_loss_proj:1.693 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.607 (perp=7.602, rec=0.057, cos=0.030), tot_loss_proj:1.702 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.597 (perp=7.602, rec=0.046, cos=0.030), tot_loss_proj:1.686 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.613 (perp=7.602, rec=0.062, cos=0.030), tot_loss_proj:1.698 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.610 (perp=7.602, rec=0.060, cos=0.030), tot_loss_proj:1.682 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.618 (perp=7.602, rec=0.067, cos=0.030), tot_loss_proj:1.691 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.614 (perp=7.602, rec=0.064, cos=0.030), tot_loss_proj:1.677 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.597 (perp=7.602, rec=0.047, cos=0.030), tot_loss_proj:1.682 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.612 (perp=7.602, rec=0.062, cos=0.030), tot_loss_proj:1.682 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.613 (perp=7.602, rec=0.063, cos=0.030), tot_loss_proj:1.682 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.616 (perp=7.602, rec=0.066, cos=0.030), tot_loss_proj:1.679 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.600 (perp=7.602, rec=0.050, cos=0.030), tot_loss_proj:1.692 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.602 (perp=7.602, rec=0.051, cos=0.030), tot_loss_proj:1.686 [t=0.35s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.580 | p: 91.228 | r: 92.107
rouge2     | fm: 62.679 | p: 62.606 | r: 62.757
rougeL     | fm: 81.142 | p: 80.897 | r: 81.573
rougeLsum  | fm: 80.914 | p: 80.579 | r: 81.267
r1fm+r2fm = 154.260

input #31 time: 0:13:35 | total time: 7:01:53


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9882841406246143
highest_index [0]
highest [0.9882841406246143]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 0.9205175638198853 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9122443199157715 for ['[CLS] huey while kill stuck doc urgent lakeside integration food trailers with a [SEP]']
[Init] best rec loss: 0.9110466837882996 for ['[CLS] knew benton usage9 fireplace hop reign. kappa pull poet writes [SEP]']
[Init] best rec loss: 0.9081436991691589 for ['[CLS] shield issues composer gallery calling passey line introduction beacon rob foot [SEP]']
[Init] best rec loss: 0.9060412645339966 for ['[CLS] nap first mddic nichols carriage usual spread wits eu pun age [SEP]']
[Init] best rec loss: 0.9017935991287231 for ['[CLS] when was thief garrett wherever guestieg affiliate bent double pickup jerry [SEP]']
[Init] best rec loss: 0.8886240124702454 for ['[CLS] sub trials milk park casual two emma pocket breed against defending tenor [SEP]']
[Init] best rec loss: 0.8744975924491882 for ['[CLS] lips let ″ forth between alongside mud inclination airport gods baptism unanimous [SEP]']
[Init] best perm rec loss: 0.8713637590408325 for ['[CLS] unanimous let ″ forth inclination between alongside gods lips airport baptism mud [SEP]']
[Init] best perm rec loss: 0.8700041174888611 for ['[CLS] inclination alongside let mud unanimous ″ airport baptism gods forth lips between [SEP]']
[Init] best perm rec loss: 0.869927704334259 for ['[CLS] unanimous alongside airport mud inclination lips between gods ″ let forth baptism [SEP]']
[Init] best perm rec loss: 0.8696227669715881 for ['[CLS] baptism unanimous mud let lips airport ″ forth inclination between gods alongside [SEP]']
[Init] best perm rec loss: 0.8694219589233398 for ['[CLS] baptism gods ″ mud forth lips let unanimous alongside inclination airport between [SEP]']
[Init] best perm rec loss: 0.8693312406539917 for ['[CLS] baptism lips between unanimous mud gods let ″ forth airport inclination alongside [SEP]']
[Init] best perm rec loss: 0.8691214323043823 for ['[CLS] forth airport between mud unanimous baptism inclination lips alongside gods ″ let [SEP]']
[Init] best perm rec loss: 0.8690569996833801 for ['[CLS] alongside airport between baptism lips inclination mud gods forth unanimous let ″ [SEP]']
[Init] best perm rec loss: 0.8665013909339905 for ['[CLS] unanimous gods lips ″ between mud inclination let forth baptism airport alongside [SEP]']
[Init] best perm rec loss: 0.8659602999687195 for ['[CLS] inclination unanimous mud between ″ baptism forth lips gods airport let alongside [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.119 (perp=14.055, rec=0.275, cos=0.033), tot_loss_proj:4.244 [t=0.30s]
prediction: ['[CLS] teach universalonateed portrayal accurate education systemstees life smiled focus [SEP]']
[ 100/2000] tot_loss=2.750 (perp=12.668, rec=0.192, cos=0.024), tot_loss_proj:3.574 [t=0.30s]
prediction: ['[CLS] stories clearonaterangle story accessible stories withonate withonateonate [SEP]']
[ 150/2000] tot_loss=2.598 (perp=12.004, rec=0.173, cos=0.025), tot_loss_proj:3.952 [t=0.30s]
prediction: ['[CLS] pull accessibleonaterangle pull accessible stories withonateity easilyonate [SEP]']
[ 200/2000] tot_loss=2.441 (perp=11.313, rec=0.155, cos=0.023), tot_loss_proj:3.352 [t=0.30s]
prediction: ['[CLS] pull easilyonate together pull accessible stories withonateity easilyonate [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.264 (perp=10.548, rec=0.130, cos=0.025), tot_loss_proj:3.253 [t=0.35s]
prediction: ['[CLS] pull easilyonate pull together accessible stories withundity easilyonate [SEP]']
[ 300/2000] tot_loss=2.245 (perp=10.548, rec=0.113, cos=0.023), tot_loss_proj:3.249 [t=0.35s]
prediction: ['[CLS] pull easilyonate pull together accessible stories withundity easilyonate [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.454 (perp=11.668, rec=0.097, cos=0.024), tot_loss_proj:3.457 [t=0.35s]
prediction: ['[CLS] visible res pull together accessible stories withundity easilyonate pull [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.100 (perp=9.501, rec=0.172, cos=0.028), tot_loss_proj:2.898 [t=0.35s]
prediction: ['[CLS] easily pull together accessible stories withundity easily resonate pull [SEP]']
[ 450/2000] tot_loss=2.273 (perp=10.673, rec=0.116, cos=0.023), tot_loss_proj:3.030 [t=0.35s]
prediction: ['[CLS] accessible pull together accessible stories withundity easily resonate thermal [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.152 (perp=10.143, rec=0.100, cos=0.023), tot_loss_proj:3.953 [t=0.35s]
prediction: ['[CLS] ben pull together accessible stories withundity easily resonate impossible [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=2.122 (perp=9.908, rec=0.116, cos=0.024), tot_loss_proj:3.371 [t=0.35s]
prediction: ['[CLS] pull together accessible stories withundity easily resonate impossible ben [SEP]']
[ 600/2000] tot_loss=2.194 (perp=10.377, rec=0.096, cos=0.023), tot_loss_proj:3.847 [t=0.35s]
prediction: ['[CLS] pull together accessible stories withundity easily resonate impossiblehor [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.055 (perp=9.668, rec=0.099, cos=0.023), tot_loss_proj:3.317 [t=0.35s]
prediction: ['[CLS] pull together accessible stories withundity easily resonate ben impossible [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.016 (perp=9.438, rec=0.104, cos=0.024), tot_loss_proj:3.834 [t=0.35s]
prediction: ['[CLS] pull together accessible stories with benundity easily resonate impossible [SEP]']
[ 750/2000] tot_loss=1.987 (perp=9.346, rec=0.095, cos=0.023), tot_loss_proj:2.449 [t=0.35s]
prediction: ['[CLS] pull together accessible stories with benundity easily resonate easily [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.931 (perp=9.031, rec=0.102, cos=0.023), tot_loss_proj:2.414 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with benundity easily resonate [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.915 (perp=9.031, rec=0.086, cos=0.023), tot_loss_proj:2.413 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with benundity easily resonate [SEP]']
[ 900/2000] tot_loss=1.893 (perp=8.907, rec=0.089, cos=0.023), tot_loss_proj:2.343 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with resundity easily resonate [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.891 (perp=8.907, rec=0.087, cos=0.023), tot_loss_proj:2.344 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with resundity easily resonate [SEP]']
Attempt swap
[1000/2000] tot_loss=1.888 (perp=8.907, rec=0.084, cos=0.023), tot_loss_proj:2.347 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with resundity easily resonate [SEP]']
[1050/2000] tot_loss=1.671 (perp=7.796, rec=0.089, cos=0.023), tot_loss_proj:1.897 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1100/2000] tot_loss=1.670 (perp=7.796, rec=0.088, cos=0.023), tot_loss_proj:1.900 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1150/2000] tot_loss=1.677 (perp=7.796, rec=0.095, cos=0.023), tot_loss_proj:1.895 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
[1200/2000] tot_loss=1.655 (perp=7.796, rec=0.073, cos=0.023), tot_loss_proj:1.897 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1250/2000] tot_loss=1.659 (perp=7.796, rec=0.077, cos=0.023), tot_loss_proj:1.897 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1300/2000] tot_loss=1.657 (perp=7.796, rec=0.075, cos=0.023), tot_loss_proj:1.898 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
[1350/2000] tot_loss=1.663 (perp=7.796, rec=0.081, cos=0.023), tot_loss_proj:1.900 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1400/2000] tot_loss=1.670 (perp=7.796, rec=0.088, cos=0.023), tot_loss_proj:1.895 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1450/2000] tot_loss=1.672 (perp=7.796, rec=0.090, cos=0.023), tot_loss_proj:1.896 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
[1500/2000] tot_loss=1.667 (perp=7.796, rec=0.085, cos=0.023), tot_loss_proj:1.898 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1550/2000] tot_loss=1.666 (perp=7.796, rec=0.084, cos=0.023), tot_loss_proj:1.896 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1600/2000] tot_loss=1.664 (perp=7.796, rec=0.082, cos=0.023), tot_loss_proj:1.901 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
[1650/2000] tot_loss=1.660 (perp=7.796, rec=0.078, cos=0.023), tot_loss_proj:1.898 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1700/2000] tot_loss=1.659 (perp=7.796, rec=0.077, cos=0.023), tot_loss_proj:1.893 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1750/2000] tot_loss=1.662 (perp=7.796, rec=0.080, cos=0.023), tot_loss_proj:1.894 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
[1800/2000] tot_loss=1.661 (perp=7.796, rec=0.079, cos=0.023), tot_loss_proj:1.894 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1850/2000] tot_loss=1.661 (perp=7.796, rec=0.079, cos=0.023), tot_loss_proj:1.896 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[1900/2000] tot_loss=1.655 (perp=7.796, rec=0.073, cos=0.023), tot_loss_proj:1.897 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
[1950/2000] tot_loss=1.668 (perp=7.796, rec=0.086, cos=0.023), tot_loss_proj:1.895 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Attempt swap
[2000/2000] tot_loss=1.660 (perp=7.796, rec=0.078, cos=0.023), tot_loss_proj:1.895 [t=0.30s]
prediction: ['[CLS] pull together easily accessible stories with profundity easily resonate [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] pull together easily accessible stories with profundity easily resonate [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 60.000 | p: 60.000 | r: 60.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 150.909

[Aggregate metrics]:
rouge1     | fm: 91.425 | p: 91.032 | r: 91.937
rouge2     | fm: 62.719 | p: 62.656 | r: 62.831
rougeL     | fm: 81.067 | p: 80.731 | r: 81.358
rougeLsum  | fm: 80.995 | p: 80.763 | r: 81.403
r1fm+r2fm = 154.144

input #32 time: 0:12:24 | total time: 7:14:18


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9865214044463677
highest_index [0]
highest [0.9865214044463677]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9691931009292603 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.832371175289154 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.8310871720314026 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.770179271697998 for ['[CLS] training [SEP]']
[Init] best rec loss: 0.7496224641799927 for ['[CLS] strip [SEP]']
[Init] best rec loss: 0.7309726476669312 for ['[CLS] effective [SEP]']
[Init] best rec loss: 0.7274718880653381 for ['[CLS] frame [SEP]']
[Init] best rec loss: 0.7183524966239929 for ['[CLS] railroad [SEP]']
[Init] best rec loss: 0.6911717057228088 for ['[CLS] positive [SEP]']
[Init] best rec loss: 0.6510108113288879 for ['[CLS] / [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.565 (perp=11.231, rec=0.267, cos=0.051), tot_loss_proj:2.431 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.356 (perp=11.231, rec=0.084, cos=0.026), tot_loss_proj:2.383 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.353 (perp=11.231, rec=0.080, cos=0.026), tot_loss_proj:2.394 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.334 (perp=11.231, rec=0.061, cos=0.027), tot_loss_proj:2.366 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.330 (perp=11.231, rec=0.057, cos=0.027), tot_loss_proj:2.380 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.333 (perp=11.231, rec=0.060, cos=0.027), tot_loss_proj:2.378 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.335 (perp=11.231, rec=0.062, cos=0.027), tot_loss_proj:2.373 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.319 (perp=11.231, rec=0.046, cos=0.027), tot_loss_proj:2.377 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.352 (perp=11.231, rec=0.079, cos=0.027), tot_loss_proj:2.373 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.340 (perp=11.231, rec=0.067, cos=0.027), tot_loss_proj:2.389 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.331 (perp=11.231, rec=0.058, cos=0.027), tot_loss_proj:2.385 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.324 (perp=11.231, rec=0.052, cos=0.027), tot_loss_proj:2.375 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.329 (perp=11.231, rec=0.056, cos=0.027), tot_loss_proj:2.383 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.340 (perp=11.231, rec=0.067, cos=0.027), tot_loss_proj:2.383 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.331 (perp=11.231, rec=0.058, cos=0.027), tot_loss_proj:2.381 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.329 (perp=11.231, rec=0.056, cos=0.027), tot_loss_proj:2.386 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.336 (perp=11.231, rec=0.063, cos=0.027), tot_loss_proj:2.376 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.339 (perp=11.231, rec=0.066, cos=0.027), tot_loss_proj:2.386 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.342 (perp=11.231, rec=0.069, cos=0.027), tot_loss_proj:2.389 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.329 (perp=11.231, rec=0.056, cos=0.027), tot_loss_proj:2.394 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.345 (perp=11.231, rec=0.072, cos=0.027), tot_loss_proj:2.377 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.336 (perp=11.231, rec=0.064, cos=0.027), tot_loss_proj:2.381 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.330 (perp=11.231, rec=0.057, cos=0.027), tot_loss_proj:2.393 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.337 (perp=11.231, rec=0.064, cos=0.027), tot_loss_proj:2.368 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.324 (perp=11.231, rec=0.051, cos=0.027), tot_loss_proj:2.373 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.340 (perp=11.231, rec=0.067, cos=0.027), tot_loss_proj:2.380 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.337 (perp=11.231, rec=0.065, cos=0.027), tot_loss_proj:2.382 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.321 (perp=11.231, rec=0.048, cos=0.027), tot_loss_proj:2.377 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.342 (perp=11.231, rec=0.069, cos=0.027), tot_loss_proj:2.379 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.354 (perp=11.231, rec=0.081, cos=0.027), tot_loss_proj:2.371 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.348 (perp=11.231, rec=0.075, cos=0.027), tot_loss_proj:2.377 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.321 (perp=11.231, rec=0.048, cos=0.027), tot_loss_proj:2.389 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.341 (perp=11.231, rec=0.068, cos=0.027), tot_loss_proj:2.374 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.346 (perp=11.231, rec=0.073, cos=0.027), tot_loss_proj:2.376 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.318 (perp=11.231, rec=0.045, cos=0.027), tot_loss_proj:2.384 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.324 (perp=11.231, rec=0.052, cos=0.027), tot_loss_proj:2.366 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.339 (perp=11.231, rec=0.066, cos=0.027), tot_loss_proj:2.385 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.329 (perp=11.231, rec=0.056, cos=0.027), tot_loss_proj:2.384 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.333 (perp=11.231, rec=0.060, cos=0.027), tot_loss_proj:2.378 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.325 (perp=11.231, rec=0.052, cos=0.027), tot_loss_proj:2.380 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.679 | p: 91.326 | r: 92.106
rouge2     | fm: 64.058 | p: 63.996 | r: 64.077
rougeL     | fm: 81.531 | p: 81.249 | r: 81.889
rougeLsum  | fm: 81.409 | p: 81.136 | r: 81.725
r1fm+r2fm = 155.737

input #33 time: 0:10:54 | total time: 7:25:13


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.9880135947991799
highest_index [0]
highest [0.9880135947991799]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8604685068130493 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.84800124168396 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8419325351715088 for ['[CLS]gut tam popular xml practice got maia accompanied gaulle dateize mc full [SEP]']
[Init] best rec loss: 0.7746572494506836 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.7576202154159546 for ['[CLS] paper right ‖ allies considerations inophone nassau served molecular queen hart liv [SEP]']
[Init] best rec loss: 0.7474254965782166 for ['[CLS]truct way terminus week photos specifically dowager anime inducted valentin scotch watches watched [SEP]']
[Init] best rec loss: 0.71859210729599 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.7166885733604431 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 0.716228187084198 for ['[CLS] field slight alongask whoibe statue worth lissa founder ship okay drivers [SEP]']
[Init] best perm rec loss: 0.7143124938011169 for ['[CLS] ship slight founder statue lissaask drivers okay worth fieldibe who along [SEP]']
[Init] best perm rec loss: 0.7115151882171631 for ['[CLS] worth ship slight along lissa founder whoask statue field okayibe drivers [SEP]']
[Init] best perm rec loss: 0.7102226614952087 for ['[CLS] lissaask along who statue shipibe drivers okay founder worth field slight [SEP]']
[Init] best perm rec loss: 0.7091982364654541 for ['[CLS] who slight along ship founder statueask okay drivers field worthibe lissa [SEP]']
[Init] best perm rec loss: 0.7089046835899353 for ['[CLS] statue slightask driversibe ship who founder lissa okay worth field along [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.818 (perp=12.544, rec=0.268, cos=0.042), tot_loss_proj:4.187 [t=0.30s]
prediction: ['[CLS] urgency water urgency urgency urgency brought urgency modern institute terrible urgency deep extreme [SEP]']
[ 100/2000] tot_loss=2.476 (perp=11.409, rec=0.169, cos=0.025), tot_loss_proj:3.514 [t=0.30s]
prediction: ['[CLS] build, viewer mind urgency taking urgency extreme take done urgency extreme extreme [SEP]']
[ 150/2000] tot_loss=1.932 (perp=8.922, rec=0.123, cos=0.024), tot_loss_proj:2.387 [t=0.30s]
prediction: ['[CLS] build and viewer mind in taking urgency and take on urgency extreme extreme [SEP]']
[ 200/2000] tot_loss=1.876 (perp=8.803, rec=0.091, cos=0.024), tot_loss_proj:2.395 [t=0.30s]
prediction: ['[CLS] build and viewer mind in on urgency and take on urgency extreme extreme [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.934 (perp=9.100, rec=0.090, cos=0.024), tot_loss_proj:2.672 [t=0.30s]
prediction: ['[CLS] build and viewer mind in on urgency. take urgency. extreme extreme [SEP]']
[ 300/2000] tot_loss=1.933 (perp=9.100, rec=0.089, cos=0.024), tot_loss_proj:2.675 [t=0.30s]
prediction: ['[CLS] build and viewer mind in on urgency. take urgency. extreme extreme [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.817 (perp=8.541, rec=0.085, cos=0.024), tot_loss_proj:2.354 [t=0.30s]
prediction: ['[CLS] build and mind in on urgency. take viewer urgency. extreme extreme [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.799 (perp=8.472, rec=0.081, cos=0.024), tot_loss_proj:2.378 [t=0.30s]
prediction: ['[CLS] build and mind on in urgency. take viewer urgency. extreme extreme [SEP]']
[ 450/2000] tot_loss=1.792 (perp=8.472, rec=0.074, cos=0.024), tot_loss_proj:2.372 [t=0.30s]
prediction: ['[CLS] build and mind on in urgency. take viewer urgency. extreme extreme [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.668 (perp=7.914, rec=0.062, cos=0.023), tot_loss_proj:2.375 [t=0.30s]
prediction: ['[CLS] build and mind in urgency of take on viewer urgency. extreme extreme [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.563 (perp=7.387, rec=0.063, cos=0.023), tot_loss_proj:2.096 [t=0.30s]
prediction: ['[CLS] build and mind in urgency the extreme extreme take on viewer urgency. [SEP]']
[ 600/2000] tot_loss=1.572 (perp=7.387, rec=0.071, cos=0.024), tot_loss_proj:2.093 [t=0.30s]
prediction: ['[CLS] build and mind in urgency the extreme extreme take on viewer urgency. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.461 (perp=6.858, rec=0.065, cos=0.024), tot_loss_proj:1.917 [t=0.30s]
prediction: ['[CLS] build and mind in the extreme extreme urgency take on viewer urgency. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.408 (perp=6.581, rec=0.068, cos=0.024), tot_loss_proj:1.884 [t=0.30s]
prediction: ['[CLS] build in mind and the extreme extreme urgency take on viewer urgency. [SEP]']
[ 750/2000] tot_loss=1.410 (perp=6.581, rec=0.071, cos=0.024), tot_loss_proj:1.887 [t=0.30s]
prediction: ['[CLS] build in mind and the extreme extreme urgency take on viewer urgency. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.334 (perp=6.171, rec=0.076, cos=0.024), tot_loss_proj:1.983 [t=0.30s]
prediction: ['[CLS] build urgency in mind and the extreme extreme take on viewer urgency. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.330 (perp=6.171, rec=0.072, cos=0.024), tot_loss_proj:1.987 [t=0.30s]
prediction: ['[CLS] build urgency in mind and the extreme extreme take on viewer urgency. [SEP]']
[ 900/2000] tot_loss=1.324 (perp=6.171, rec=0.066, cos=0.024), tot_loss_proj:1.969 [t=0.30s]
prediction: ['[CLS] build urgency in mind and the extreme extreme take on viewer urgency. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.510 (perp=7.065, rec=0.073, cos=0.024), tot_loss_proj:2.167 [t=0.30s]
prediction: ['[CLS] build urgency in mind and the of extreme take on viewer urgency. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.307 (perp=6.115, rec=0.061, cos=0.024), tot_loss_proj:1.883 [t=0.30s]
prediction: ['[CLS] build urgency in mind and of the extreme take on viewer urgency. [SEP]']
[1050/2000] tot_loss=1.309 (perp=6.115, rec=0.063, cos=0.024), tot_loss_proj:1.884 [t=0.30s]
prediction: ['[CLS] build urgency in mind and of the extreme take on viewer urgency. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.304 (perp=6.115, rec=0.057, cos=0.024), tot_loss_proj:1.881 [t=0.30s]
prediction: ['[CLS] build urgency in mind and of the extreme take on viewer urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.321 (perp=6.115, rec=0.074, cos=0.024), tot_loss_proj:1.883 [t=0.30s]
prediction: ['[CLS] build urgency in mind and of the extreme take on viewer urgency. [SEP]']
[1200/2000] tot_loss=1.316 (perp=6.115, rec=0.069, cos=0.024), tot_loss_proj:1.886 [t=0.30s]
prediction: ['[CLS] build urgency in mind and of the extreme take on viewer urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.307 (perp=6.115, rec=0.060, cos=0.024), tot_loss_proj:1.885 [t=0.30s]
prediction: ['[CLS] build urgency in mind and of the extreme take on viewer urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.303 (perp=6.115, rec=0.057, cos=0.024), tot_loss_proj:1.888 [t=0.30s]
prediction: ['[CLS] build urgency in mind and of the extreme take on viewer urgency. [SEP]']
[1350/2000] tot_loss=1.311 (perp=6.115, rec=0.064, cos=0.024), tot_loss_proj:1.880 [t=0.30s]
prediction: ['[CLS] build urgency in mind and of the extreme take on viewer urgency. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.291 (perp=6.030, rec=0.061, cos=0.024), tot_loss_proj:1.869 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.296 (perp=6.030, rec=0.066, cos=0.024), tot_loss_proj:1.874 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
[1500/2000] tot_loss=1.296 (perp=6.030, rec=0.066, cos=0.024), tot_loss_proj:1.878 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.299 (perp=6.030, rec=0.069, cos=0.024), tot_loss_proj:1.870 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.293 (perp=6.030, rec=0.063, cos=0.024), tot_loss_proj:1.872 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
[1650/2000] tot_loss=1.292 (perp=6.030, rec=0.063, cos=0.024), tot_loss_proj:1.868 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.303 (perp=6.030, rec=0.073, cos=0.024), tot_loss_proj:1.865 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.300 (perp=6.030, rec=0.070, cos=0.024), tot_loss_proj:1.873 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
[1800/2000] tot_loss=1.293 (perp=6.030, rec=0.063, cos=0.024), tot_loss_proj:1.868 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.302 (perp=6.030, rec=0.073, cos=0.024), tot_loss_proj:1.861 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.291 (perp=6.030, rec=0.061, cos=0.024), tot_loss_proj:1.865 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
[1950/2000] tot_loss=1.300 (perp=6.030, rec=0.070, cos=0.024), tot_loss_proj:1.861 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.291 (perp=6.030, rec=0.061, cos=0.024), tot_loss_proj:1.866 [t=0.30s]
prediction: ['[CLS] build urgency and in mind of the extreme take on viewer urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] build urgency in mind and of the extreme take on viewer urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.857 | p: 92.857 | r: 92.857
rouge2     | fm: 30.769 | p: 30.769 | r: 30.769
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 123.626

[Aggregate metrics]:
rouge1     | fm: 91.715 | p: 91.397 | r: 92.193
rouge2     | fm: 63.190 | p: 63.111 | r: 63.243
rougeL     | fm: 81.369 | p: 81.080 | r: 81.741
rougeLsum  | fm: 81.240 | p: 81.025 | r: 81.558
r1fm+r2fm = 154.905

input #34 time: 0:11:56 | total time: 7:37:09


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9882876463679713
highest_index [0]
highest [0.9882876463679713]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.8772305846214294 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.8730382323265076 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 0.8564639687538147 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best rec loss: 0.8561059236526489 for ['[CLS]work pun preserved bloodngen staff alivement ocean potter chest km² issue shares 978 lotsorestation jungle lastcript privately anywhere electric aus staff errortite ticketasian block text horse perennialbiotic fightauworth brothers snow sex cathedral bestseller [SEP]']
[Init] best perm rec loss: 0.8507950305938721 for ['[CLS] cathedral snow aus shares text fight lotsworth electric perennial bestsellercript pun alive ocean staff block sexngenment blood anywhere horse privately issueworkbioticasian preserved jungle 978 ticket staff brothers chest last pottertite error km²auorestation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.729 (perp=11.774, rec=0.345, cos=0.029), tot_loss_proj:4.071 [t=0.31s]
prediction: ["[CLS] been love errors∆ than restoration island history watching documentary me production gazed theycide. beating'extraordinary our robert from... the.,us moon mountain population knesset raise expertise [SEP] mind bsc jordan equipment care owe outstanding'[SEP]"]
[ 100/2000] tot_loss=2.308 (perp=9.974, rec=0.289, cos=0.025), tot_loss_proj:3.350 [t=0.31s]
prediction: ["[CLS] we care &陳 of'of been this includes'director this they [SEP] but behind'means our kevin.... the,, because than mountain density we raise great [SEP]nation cooperative tatum teacher care respect greatest'[SEP]"]
[ 150/2000] tot_loss=2.207 (perp=9.759, rec=0.232, cos=0.023), tot_loss_proj:3.105 [t=0.31s]
prediction: ["[CLS] we care murphy winkler of we seen before this latest'director this as [SEP] but thatcher'means our kevin.'the,, learningthannation of we care great [SEP]nation from molly teacher makes respect greatest'[SEP]"]
[ 200/2000] tot_loss=2.081 (perp=9.240, rec=0.211, cos=0.023), tot_loss_proj:3.309 [t=0.31s]
prediction: ["[CLS] we care julian winkler of'seen before every latest'director one director [SEP] but oppose'means our director.'the,,';nation of we makes great,nation from seem teacher makes'greatest'[SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.561 (perp=10.496, rec=0.422, cos=0.040), tot_loss_proj:3.471 [t=0.31s]
prediction: ["[CLS] we caregenaseitaire [SEP] they seen before this latest'directed, director [SEP] but r, is [CLS] kevin ( administrative the is. learning he help the we about greatest.nation presence giles teacher makes 宀 greatest sovereign [SEP]"]
[ 300/2000] tot_loss=2.568 (perp=11.241, rec=0.291, cos=0.028), tot_loss_proj:3.576 [t=0.31s]
prediction: ["[CLS] we care gavinitaire [SEP] took seen before, latest'director [SEP] its [SEP] but jury. by reflects director. tributarypage. is learningi donation to us help hasn.nation will you teacher makes daniel greatest 辶 [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.372 (perp=10.515, rec=0.244, cos=0.025), tot_loss_proj:3.140 [t=0.31s]
prediction: ["[CLS] we care gavinchy [SEP], seen before we latest'director [SEP] its [SEP] but director. outstanding reflects director. specialpage ¨ is learningination and us about latest. greatest help which teacher makes daniel greatest 辶 [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.344 (perp=10.494, rec=0.221, cos=0.024), tot_loss_proj:3.252 [t=0.31s]
prediction: ["[CLS] we care gavin [SEP]chy, seen before have latest'director, its [SEP] but director. outstanding reflects director. 'page. is.ination global us about latest. greatestignantnation teacher makes daniel greatest 辶 [SEP]"]
[ 450/2000] tot_loss=2.765 (perp=11.888, rec=0.352, cos=0.036), tot_loss_proj:3.766 [t=0.31s]
prediction: ["[CLS] we care historians [SEP]itaire [SEP] seen before we developing 'creen [SEP] this [SEP] but umpire council by his officersrid alwayspage accuratepole byination good us about drew! great own alexis teacher makes art greatest eggs [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=2.603 (perp=11.278, rec=0.318, cos=0.029), tot_loss_proj:3.596 [t=0.31s]
prediction: ["[CLS] we care historians [SEP] honour [SEP] seen before we latest'director [SEP] this [SEP] but director council by his say. inside former accuratepole byination traditional us about alexis narrative! great cards teacher makes art greatest locomotives [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=2.546 (perp=11.316, rec=0.257, cos=0.026), tot_loss_proj:3.525 [t=0.31s]
prediction: ["[CLS] we care historians [SEP] honour [SEP] seen before we latest'director [SEP] this [SEP] but director council helps his director participated inside formerpole by daynation accurate traditional us about rosalie narrative! great cards teacher makes art greatest locomotives [SEP]"]
[ 600/2000] tot_loss=2.518 (perp=10.767, rec=0.333, cos=0.031), tot_loss_proj:3.512 [t=0.31s]
prediction: ["[CLS] we care gavin [SEP] baronet [SEP] seen before we [SEP]'director [SEP] this [SEP] but director council help his directorely my formerpole by daynation accurate traditional us about rosalie narrative. great cards teacher makes. greatest locomotives [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.410 (perp=10.574, rec=0.268, cos=0.027), tot_loss_proj:3.369 [t=0.31s]
prediction: ["[CLS] we care gavin [SEP] baronet [SEP] seen before we [SEP]'it [SEP] director [SEP] but director council help his directorjack'formerpole by daynation accurate great us about rosalie narrative. great cards teacher makes. greatest locomotives [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.306 (perp=10.153, rec=0.249, cos=0.026), tot_loss_proj:3.292 [t=0.31s]
prediction: ["[CLS] we care gavin [SEP] baronet [SEP] seen before we [SEP]'it [SEP] director [SEP] but director council help his director branches'formerpole by daynation. great us about rosalie narrative. great cards teacher makes accurate greatest locomotives [SEP]"]
[ 750/2000] tot_loss=2.369 (perp=10.544, rec=0.234, cos=0.026), tot_loss_proj:3.326 [t=0.31s]
prediction: ["[CLS] we care gavin [SEP]len [SEP] seen before we [SEP]'it [SEP] director [SEP] but director because help his director branches 'nepole by daynation and great us about alexis the. great cards teacher makes accurate greatest locomotives [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=2.302 (perp=10.203, rec=0.235, cos=0.026), tot_loss_proj:3.208 [t=0.31s]
prediction: ["[CLS] we care gavin [SEP]en [SEP] seen before i latest'it [SEP] director [SEP] but director because help director branches 'ne hispole by daynation and great us about alexis the. great himself teacher makes accurate greatest locomotives [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=2.270 (perp=10.107, rec=0.223, cos=0.026), tot_loss_proj:3.310 [t=0.31s]
prediction: ["[CLS] we care particular [SEP]en [SEP] seen before i latest'it [SEP] director director [SEP] but because help director branches 'ne hispole by daynation and greatest us about alexis the. great himself teacher makes accurate greatest locomotives [SEP]"]
[ 900/2000] tot_loss=2.260 (perp=10.094, rec=0.215, cos=0.026), tot_loss_proj:3.281 [t=0.31s]
prediction: ["[CLS] we care particular [SEP]en [SEP] seen before i latest'it [SEP] director director [SEP] but because help director branches'fellow hispole by daynation and greatest us about alexis the. great himself teacher makes accurate greatest locomotives [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.251 (perp=10.061, rec=0.213, cos=0.026), tot_loss_proj:3.344 [t=0.31s]
prediction: ["[CLS] we care particular [SEP]en [SEP] seen before ipole'it [SEP] director director [SEP] but because help director branches'fellow his latest by daynation and greatest us about alexis the. great himself teacher makes guard greatest locomotives [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.235 (perp=9.902, rec=0.227, cos=0.028), tot_loss_proj:3.207 [t=0.31s]
prediction: ["[CLS] we care particular [SEP]en spanish seen before ipole'it [SEP] director director [SEP] but because help director.'movement accurate latest by daynation and greatest us about alexis narrative. great cards teacher makes his greatest locomotives [SEP]"]
[1050/2000] tot_loss=2.239 (perp=9.880, rec=0.239, cos=0.024), tot_loss_proj:3.401 [t=0.31s]
prediction: ["[CLS] we care particular [SEP]en spanish seen before ipole'it [SEP] director director [SEP] but because help director branches'better accurate latest by daynation and greatest us about embrace narrative. great himself teacher makes his greatest locomotives [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.215 (perp=9.828, rec=0.225, cos=0.024), tot_loss_proj:3.224 [t=0.31s]
prediction: ["[CLS] we care particular [SEP]en spanish seen before ipole'it [SEP] director director [SEP] but because help director branches'latest accurate better by daynation and greatest us about embrace narrative. great himself teacher makes his greatest locomotives [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.177 (perp=9.661, rec=0.218, cos=0.026), tot_loss_proj:3.170 [t=0.31s]
prediction: ["[CLS] we care particular [SEP]enpole seen before i spanish'it [SEP] director director [SEP] but because help director branches'latest accurate better by daynation and greatest us about embrace narrative. great himself teacher makes his greatest locomotive [SEP]"]
[1200/2000] tot_loss=2.116 (perp=9.375, rec=0.216, cos=0.025), tot_loss_proj:3.229 [t=0.31s]
prediction: ["[CLS] we care particular withenpole seen before i spanish'it [SEP] director director [SEP] but because help director branches'latest accurate better by daynation and greatest us about embrace the. great himself teacher makes his greatest locomotive [SEP]"]
Attempt swap
[1250/2000] tot_loss=2.146 (perp=9.463, rec=0.228, cos=0.025), tot_loss_proj:3.328 [t=0.31s]
prediction: ["[CLS] we care particular withenpole seen before i with'it [SEP] director director [SEP] but because help director.'latest guard better by daynation and greatest us about embracenation. great himself teacher makes his greatest locomotive [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.091 (perp=9.263, rec=0.214, cos=0.025), tot_loss_proj:3.252 [t=0.31s]
prediction: ["[CLS] we care particular withenpole seen before because with'it [SEP] director director [SEP] but i help director.'latest guard better by daynation and greatest us about embracenation. great himself teacher makes his greatest locomotive [SEP]"]
[1350/2000] tot_loss=2.066 (perp=9.125, rec=0.216, cos=0.025), tot_loss_proj:3.263 [t=0.31s]
prediction: ["[CLS] we care particular withenpole seen before - with'it [SEP] director director [SEP] but i help director.'latest guard better by daynation and greatest us about embracenation. great himself teacher makes his greatest locomotive [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.025 (perp=8.982, rec=0.205, cos=0.024), tot_loss_proj:3.156 [t=0.31s]
prediction: ["[CLS] we care particular withenpole seen before - with'it [SEP] director director better but i help director.'latest guard [SEP] by daynation and greatest us about embracenation. great himself teacher makes his greatest locomotive [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.996 (perp=8.730, rec=0.222, cos=0.027), tot_loss_proj:2.875 [t=0.31s]
prediction: ["[CLS] we care particular ofenpole seen before, with'it [SEP] director director better but i help director.'latest guard [SEP] by day great and greatest us about embracenation.nation himself teacher makes his greatest locomotive [SEP]"]
[1500/2000] tot_loss=1.986 (perp=8.746, rec=0.214, cos=0.024), tot_loss_proj:2.872 [t=0.31s]
prediction: ["[CLS] we care particular withenpole seen before, with'it [SEP] director director better but i help director.'latest guard [SEP] by day great and greatest us about embracenation.nation himself teacher makes his greatest locomotive [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.966 (perp=8.733, rec=0.196, cos=0.024), tot_loss_proj:2.850 [t=0.31s]
prediction: ["[CLS] we care particular ofenpole seen before - with'it [SEP] director director better but i help director.'latest guard [SEP] by day embrace and greatest us about greatnation.nation himself teacher makes his greatest locomotive [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.946 (perp=8.606, rec=0.201, cos=0.024), tot_loss_proj:2.849 [t=0.31s]
prediction: ["[CLS]'care particular ofenpole seen before, with'it'director director better but i help director. [SEP] latest guard [SEP] by day embrace and greatest us about greatnation.nation himself teacher makes his greatest locomotive [SEP]"]
[1650/2000] tot_loss=1.941 (perp=8.606, rec=0.196, cos=0.024), tot_loss_proj:2.844 [t=0.31s]
prediction: ["[CLS]'care particular ofenpole seen before, with'it'director director better but i help director. [SEP] latest guard [SEP] by day embrace and greatest us about greatnation.nation himself teacher makes his greatest locomotive [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.911 (perp=8.443, rec=0.198, cos=0.024), tot_loss_proj:2.743 [t=0.31s]
prediction: ["[CLS]'care particular ofenpole seen before, with'it'director director better but i greatest director. [SEP] latest guard [SEP] by day embrace and help us about greatnation.nation himself teacher makes his greatest locomotive [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.933 (perp=8.501, rec=0.206, cos=0.026), tot_loss_proj:2.886 [t=0.31s]
prediction: ["[CLS]'care particular ofenpole seen before, with'it'director director. but i greatest director better [SEP] latest guard [SEP] by day embrace and help us about greatnation.nation himself teacher makes his greatest locomotive [SEP]"]
[1800/2000] tot_loss=1.851 (perp=8.164, rec=0.194, cos=0.024), tot_loss_proj:2.855 [t=0.31s]
prediction: ["[CLS]'care kind ofenpole seen before, with'it'director director. but i greatest director better [SEP] latest guard [SEP] by day embrace and help us about greatnation.nation himself teacher makes his greatest locomotive [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.912 (perp=8.435, rec=0.200, cos=0.025), tot_loss_proj:2.894 [t=0.31s]
prediction: ["[CLS]'care kind withenpole seen before, with'it'locomotive director. but i greatest director better [SEP] latest guard [SEP] byi embrace and help us about greatnation.nation himself teacher makes his greatest director [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.892 (perp=8.384, rec=0.190, cos=0.026), tot_loss_proj:2.894 [t=0.31s]
prediction: ["[CLS]'care kind withenpole seen before. with'it'locomotive director, but i greatest director better [SEP] latest guard [SEP] byi embrace and help us about greatnation.nation himself teacher makes his greatest director [SEP]"]
[1950/2000] tot_loss=1.893 (perp=8.367, rec=0.195, cos=0.025), tot_loss_proj:2.934 [t=0.31s]
prediction: ["[CLS]'care kind ofenpole seen before. with'it'locomotive director - but i greatest director better [SEP] latest guard [SEP] byi embrace and help us about greatnation.nation himself teacher makes his greatest director [SEP]"]
Attempt swap
[2000/2000] tot_loss=2.029 (perp=9.097, rec=0.185, cos=0.025), tot_loss_proj:3.042 [t=0.31s]
prediction: ["[CLS]'care kind ofenpole seen before smithsonian with'it'locomotive director - but i greatest director better [SEP] latest guard [SEP] byi embrace and help us about greatnation.nation himself teacher makes his greatest director [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS]'care kind ofenpole seen before smithsonian with'it'locomotive director - but i greatest director better [SEP] latest guard [SEP] byi embrace and help us about greatnation.nation himself teacher makes his greatest director [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 45.714 | p: 45.714 | r: 45.714
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 28.571 | p: 28.571 | r: 28.571
rougeLsum  | fm: 28.571 | p: 28.571 | r: 28.571
r1fm+r2fm = 45.714

[Aggregate metrics]:
rouge1     | fm: 90.436 | p: 90.151 | r: 90.810
rouge2     | fm: 61.226 | p: 61.173 | r: 61.268
rougeL     | fm: 79.790 | p: 79.518 | r: 80.157
rougeLsum  | fm: 79.849 | p: 79.571 | r: 80.141
r1fm+r2fm = 151.662

input #35 time: 0:12:17 | total time: 7:49:27


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.9847442284118949
highest_index [0]
highest [0.9847442284118949]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9297019839286804 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9218876957893372 for ['[CLS] oscar deep peter ground [SEP]']
[Init] best rec loss: 0.9128742814064026 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9000661373138428 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 0.8854808807373047 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.8746826648712158 for ['[CLS] l explain surveys pieces [SEP]']
[Init] best rec loss: 0.8726940751075745 for ['[CLS] dormant known to mckenzie [SEP]']
[Init] best perm rec loss: 0.8707508444786072 for ['[CLS] dormant mckenzie to known [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.148 (perp=10.031, rec=0.108, cos=0.034), tot_loss_proj:2.501 [t=0.30s]
prediction: ['[CLS] wrong s horribly wrong [SEP]']
[ 100/2000] tot_loss=2.111 (perp=10.031, rec=0.074, cos=0.030), tot_loss_proj:2.501 [t=0.30s]
prediction: ['[CLS] wrong s horribly wrong [SEP]']
[ 150/2000] tot_loss=1.723 (perp=8.114, rec=0.070, cos=0.030), tot_loss_proj:1.734 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 200/2000] tot_loss=1.717 (perp=8.114, rec=0.064, cos=0.030), tot_loss_proj:1.726 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 250/2000] tot_loss=1.725 (perp=8.114, rec=0.072, cos=0.030), tot_loss_proj:1.735 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 300/2000] tot_loss=1.720 (perp=8.114, rec=0.067, cos=0.030), tot_loss_proj:1.736 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 350/2000] tot_loss=1.708 (perp=8.114, rec=0.055, cos=0.030), tot_loss_proj:1.721 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 400/2000] tot_loss=1.726 (perp=8.114, rec=0.073, cos=0.030), tot_loss_proj:1.732 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 450/2000] tot_loss=1.704 (perp=8.114, rec=0.051, cos=0.030), tot_loss_proj:1.730 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.712 (perp=8.114, rec=0.059, cos=0.030), tot_loss_proj:1.722 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.699 (perp=8.114, rec=0.046, cos=0.030), tot_loss_proj:1.738 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 600/2000] tot_loss=1.708 (perp=8.114, rec=0.055, cos=0.030), tot_loss_proj:1.722 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.712 (perp=8.114, rec=0.059, cos=0.030), tot_loss_proj:1.716 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.725 (perp=8.114, rec=0.072, cos=0.030), tot_loss_proj:1.733 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 750/2000] tot_loss=1.723 (perp=8.114, rec=0.070, cos=0.030), tot_loss_proj:1.723 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.713 (perp=8.114, rec=0.060, cos=0.030), tot_loss_proj:1.738 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.714 (perp=8.114, rec=0.061, cos=0.030), tot_loss_proj:1.742 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[ 900/2000] tot_loss=1.708 (perp=8.114, rec=0.055, cos=0.030), tot_loss_proj:1.734 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.720 (perp=8.114, rec=0.067, cos=0.030), tot_loss_proj:1.733 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.723 (perp=8.114, rec=0.070, cos=0.030), tot_loss_proj:1.738 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1050/2000] tot_loss=1.706 (perp=8.114, rec=0.053, cos=0.030), tot_loss_proj:1.731 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.717 (perp=8.114, rec=0.064, cos=0.030), tot_loss_proj:1.728 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.716 (perp=8.114, rec=0.063, cos=0.030), tot_loss_proj:1.749 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1200/2000] tot_loss=1.703 (perp=8.114, rec=0.050, cos=0.030), tot_loss_proj:1.736 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.708 (perp=8.114, rec=0.054, cos=0.030), tot_loss_proj:1.734 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.712 (perp=8.114, rec=0.059, cos=0.030), tot_loss_proj:1.734 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1350/2000] tot_loss=1.710 (perp=8.114, rec=0.057, cos=0.030), tot_loss_proj:1.727 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.705 (perp=8.114, rec=0.052, cos=0.030), tot_loss_proj:1.721 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.707 (perp=8.114, rec=0.054, cos=0.030), tot_loss_proj:1.731 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1500/2000] tot_loss=1.703 (perp=8.114, rec=0.050, cos=0.030), tot_loss_proj:1.721 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.715 (perp=8.114, rec=0.062, cos=0.030), tot_loss_proj:1.739 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.713 (perp=8.114, rec=0.060, cos=0.030), tot_loss_proj:1.727 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1650/2000] tot_loss=1.720 (perp=8.114, rec=0.067, cos=0.030), tot_loss_proj:1.723 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.715 (perp=8.114, rec=0.062, cos=0.030), tot_loss_proj:1.725 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.720 (perp=8.114, rec=0.067, cos=0.030), tot_loss_proj:1.742 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1800/2000] tot_loss=1.720 (perp=8.114, rec=0.067, cos=0.030), tot_loss_proj:1.747 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.713 (perp=8.114, rec=0.060, cos=0.030), tot_loss_proj:1.722 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.708 (perp=8.114, rec=0.055, cos=0.030), tot_loss_proj:1.739 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
[1950/2000] tot_loss=1.705 (perp=8.114, rec=0.052, cos=0.030), tot_loss_proj:1.734 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.714 (perp=8.114, rec=0.061, cos=0.030), tot_loss_proj:1.734 [t=0.30s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS]'s horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.711 | p: 90.509 | r: 91.060
rouge2     | fm: 62.302 | p: 62.252 | r: 62.383
rougeL     | fm: 80.468 | p: 80.220 | r: 80.830
rougeLsum  | fm: 80.401 | p: 80.196 | r: 80.680
r1fm+r2fm = 153.014

input #36 time: 0:11:52 | total time: 8:01:19


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9861389232460283
highest_index [0]
highest [0.9861389232460283]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.7791313529014587 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.7520884275436401 for ['[CLS] value commune [SEP]']
[Init] best rec loss: 0.7031482458114624 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 0.7024122476577759 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.6984835863113403 for ['[CLS] appreciated why [SEP]']
[Init] best rec loss: 0.6952185034751892 for ['[CLS] out example [SEP]']
[Init] best rec loss: 0.6405290365219116 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.6214675903320312 for ['[CLS] molecule buddhism [SEP]']
[Init] best rec loss: 0.6045703887939453 for ['[CLS] beer city [SEP]']
[Init] best rec loss: 0.602135419845581 for ['[CLS] colorcards [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.458 (perp=10.822, rec=0.225, cos=0.069), tot_loss_proj:2.544 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 100/2000] tot_loss=2.364 (perp=10.822, rec=0.136, cos=0.063), tot_loss_proj:2.542 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 150/2000] tot_loss=2.336 (perp=10.822, rec=0.114, cos=0.057), tot_loss_proj:2.542 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 200/2000] tot_loss=2.342 (perp=10.822, rec=0.122, cos=0.056), tot_loss_proj:2.546 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.324 (perp=10.822, rec=0.105, cos=0.055), tot_loss_proj:2.554 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 300/2000] tot_loss=2.337 (perp=10.822, rec=0.118, cos=0.054), tot_loss_proj:2.549 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.327 (perp=10.822, rec=0.108, cos=0.055), tot_loss_proj:2.556 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.328 (perp=10.822, rec=0.111, cos=0.053), tot_loss_proj:2.540 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 450/2000] tot_loss=2.328 (perp=10.822, rec=0.111, cos=0.053), tot_loss_proj:2.545 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.321 (perp=10.822, rec=0.104, cos=0.052), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.327 (perp=10.822, rec=0.111, cos=0.051), tot_loss_proj:2.550 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 600/2000] tot_loss=2.325 (perp=10.822, rec=0.110, cos=0.051), tot_loss_proj:2.542 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.320 (perp=10.822, rec=0.105, cos=0.051), tot_loss_proj:2.548 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.325 (perp=10.822, rec=0.111, cos=0.050), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 750/2000] tot_loss=2.322 (perp=10.822, rec=0.108, cos=0.050), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.328 (perp=10.822, rec=0.114, cos=0.049), tot_loss_proj:2.545 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.318 (perp=10.822, rec=0.105, cos=0.049), tot_loss_proj:2.553 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 900/2000] tot_loss=2.328 (perp=10.822, rec=0.115, cos=0.048), tot_loss_proj:2.550 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.312 (perp=10.822, rec=0.100, cos=0.048), tot_loss_proj:2.549 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=2.322 (perp=10.822, rec=0.110, cos=0.048), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[1050/2000] tot_loss=2.326 (perp=10.822, rec=0.115, cos=0.047), tot_loss_proj:2.544 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=2.327 (perp=10.822, rec=0.115, cos=0.047), tot_loss_proj:2.548 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=2.330 (perp=10.822, rec=0.119, cos=0.046), tot_loss_proj:2.556 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[1200/2000] tot_loss=2.311 (perp=10.822, rec=0.101, cos=0.046), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=2.328 (perp=10.822, rec=0.119, cos=0.045), tot_loss_proj:2.555 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=2.309 (perp=10.822, rec=0.101, cos=0.044), tot_loss_proj:2.553 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[1350/2000] tot_loss=2.299 (perp=10.822, rec=0.094, cos=0.041), tot_loss_proj:2.551 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=2.286 (perp=10.822, rec=0.091, cos=0.031), tot_loss_proj:2.545 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=2.265 (perp=10.822, rec=0.074, cos=0.027), tot_loss_proj:2.552 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[1500/2000] tot_loss=2.258 (perp=10.822, rec=0.067, cos=0.026), tot_loss_proj:2.558 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=2.271 (perp=10.822, rec=0.080, cos=0.026), tot_loss_proj:2.540 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=2.258 (perp=10.822, rec=0.067, cos=0.026), tot_loss_proj:2.540 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[1650/2000] tot_loss=2.254 (perp=10.822, rec=0.063, cos=0.026), tot_loss_proj:2.545 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=2.256 (perp=10.822, rec=0.065, cos=0.026), tot_loss_proj:2.549 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=2.253 (perp=10.822, rec=0.062, cos=0.026), tot_loss_proj:2.548 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[1800/2000] tot_loss=2.259 (perp=10.822, rec=0.068, cos=0.027), tot_loss_proj:2.548 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=2.247 (perp=10.822, rec=0.056, cos=0.027), tot_loss_proj:2.554 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=2.266 (perp=10.822, rec=0.075, cos=0.027), tot_loss_proj:2.541 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[1950/2000] tot_loss=2.259 (perp=10.822, rec=0.068, cos=0.027), tot_loss_proj:2.548 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=2.258 (perp=10.822, rec=0.066, cos=0.027), tot_loss_proj:2.542 [t=0.30s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric eccentric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 90.304 | p: 89.934 | r: 90.780
rouge2     | fm: 61.638 | p: 61.626 | r: 61.687
rougeL     | fm: 80.084 | p: 79.866 | r: 80.449
rougeLsum  | fm: 80.189 | p: 79.958 | r: 80.537
r1fm+r2fm = 151.942

input #37 time: 0:11:52 | total time: 8:13:12


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9854102324074813
highest_index [0]
highest [0.9854102324074813]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8210448026657104 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.819875180721283 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.7487096786499023 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7213940024375916 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6883171200752258 for ['[CLS] blame [SEP]']
[Init] best rec loss: 0.665120542049408 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.953 (perp=14.069, rec=0.099, cos=0.040), tot_loss_proj:2.900 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.903 (perp=14.069, rec=0.061, cos=0.028), tot_loss_proj:2.908 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.898 (perp=14.069, rec=0.055, cos=0.029), tot_loss_proj:2.888 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.930 (perp=14.069, rec=0.081, cos=0.036), tot_loss_proj:2.907 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.901 (perp=14.069, rec=0.059, cos=0.029), tot_loss_proj:2.907 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.902 (perp=14.069, rec=0.060, cos=0.029), tot_loss_proj:2.912 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.899 (perp=14.069, rec=0.057, cos=0.029), tot_loss_proj:2.911 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.916 (perp=14.069, rec=0.073, cos=0.029), tot_loss_proj:2.913 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.916 (perp=14.069, rec=0.073, cos=0.029), tot_loss_proj:2.891 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.901 (perp=14.069, rec=0.058, cos=0.029), tot_loss_proj:2.905 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.905 (perp=14.069, rec=0.062, cos=0.029), tot_loss_proj:2.905 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.912 (perp=14.069, rec=0.069, cos=0.029), tot_loss_proj:2.912 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.895 (perp=14.069, rec=0.053, cos=0.029), tot_loss_proj:2.896 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.901 (perp=14.069, rec=0.058, cos=0.029), tot_loss_proj:2.915 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.897 (perp=14.069, rec=0.054, cos=0.029), tot_loss_proj:2.909 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.897 (perp=14.069, rec=0.054, cos=0.029), tot_loss_proj:2.914 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.890 (perp=14.069, rec=0.047, cos=0.029), tot_loss_proj:2.901 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.895 (perp=14.069, rec=0.053, cos=0.029), tot_loss_proj:2.906 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.904 (perp=14.069, rec=0.061, cos=0.029), tot_loss_proj:2.912 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.901 (perp=14.069, rec=0.059, cos=0.029), tot_loss_proj:2.905 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.900 (perp=14.069, rec=0.057, cos=0.029), tot_loss_proj:2.909 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.911 (perp=14.069, rec=0.068, cos=0.029), tot_loss_proj:2.904 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.904 (perp=14.069, rec=0.061, cos=0.029), tot_loss_proj:2.902 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.902 (perp=14.069, rec=0.059, cos=0.029), tot_loss_proj:2.915 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.906 (perp=14.069, rec=0.063, cos=0.029), tot_loss_proj:2.909 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.900 (perp=14.069, rec=0.058, cos=0.029), tot_loss_proj:2.903 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.902 (perp=14.069, rec=0.060, cos=0.029), tot_loss_proj:2.906 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.896 (perp=14.069, rec=0.054, cos=0.029), tot_loss_proj:2.893 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.906 (perp=14.069, rec=0.063, cos=0.029), tot_loss_proj:2.901 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.907 (perp=14.069, rec=0.064, cos=0.029), tot_loss_proj:2.910 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.903 (perp=14.069, rec=0.060, cos=0.029), tot_loss_proj:2.897 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.909 (perp=14.069, rec=0.067, cos=0.029), tot_loss_proj:2.889 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.907 (perp=14.069, rec=0.064, cos=0.029), tot_loss_proj:2.904 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.909 (perp=14.069, rec=0.066, cos=0.029), tot_loss_proj:2.903 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.911 (perp=14.069, rec=0.068, cos=0.029), tot_loss_proj:2.904 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.902 (perp=14.069, rec=0.059, cos=0.029), tot_loss_proj:2.896 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.905 (perp=14.069, rec=0.062, cos=0.029), tot_loss_proj:2.896 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.895 (perp=14.069, rec=0.052, cos=0.029), tot_loss_proj:2.909 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.889 (perp=14.069, rec=0.046, cos=0.029), tot_loss_proj:2.901 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.911 (perp=14.069, rec=0.068, cos=0.029), tot_loss_proj:2.906 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.604 | p: 90.272 | r: 91.017
rouge2     | fm: 62.600 | p: 62.543 | r: 62.688
rougeL     | fm: 80.633 | p: 80.356 | r: 80.950
rougeLsum  | fm: 80.606 | p: 80.437 | r: 80.931
r1fm+r2fm = 153.204

input #38 time: 0:10:53 | total time: 8:24:05


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9880814037246357
highest_index [0]
highest [0.9880814037246357]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 0.8151788711547852 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 0.7948247194290161 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.7907156348228455 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.7818840742111206 for ['[CLS] visitors polo free mn railway entitled about murderkar father states eventually some pet victory saddle fraternitypgtz raised real actresses from accelerator link [SEP]']
[Init] best rec loss: 0.7784444093704224 for ['[CLS] nothing fishery published hall temeraireathing earnest cabinet shame supreme illusions drown men quoteolved formation revenge negativeˈ relief legislature growl melissa silk - [SEP]']
[Init] best rec loss: 0.7474941611289978 for ['[CLS] leaving knowlestom presents chance themes jody ge sphere intervention suffrage ewing soldert yes sabbath canada traditional became page account her rate system republic [SEP]']
[Init] best rec loss: 0.7374082207679749 for ['[CLS] transportation wrap lookiving local angus shortlistedried court taking led soon vane harmon baselineoof the meadow french jarrett alone suns fa brain shows [SEP]']
[Init] best perm rec loss: 0.7337121367454529 for ['[CLS] led frenchiving harmon wrap aloneoof courtried jarrett fa the local angus baseline vane shortlisted taking look suns shows transportation soon brain meadow [SEP]']
[Init] best perm rec loss: 0.7330899834632874 for ['[CLS] suns soon wrap brain baseline fa angusiving look alone transportation the shortlisted jarrett meadow local court taking shows french harmonriedoof led vane [SEP]']
[Init] best perm rec loss: 0.7329336404800415 for ['[CLS] transportation look harmon shortlisted wrap alone taking french fa localoof court led the vane showsried suns sooniving jarrett angus brain meadow baseline [SEP]']
[Init] best perm rec loss: 0.732915997505188 for ['[CLS] court vaneried transportation alone baselineoof look brain fa shortlisted french meadowiving angus taking soon shows led suns wrap the local harmon jarrett [SEP]']
[Init] best perm rec loss: 0.7328431606292725 for ['[CLS] soon angus transportation vaneoofried harmon baseline shows led suns french look fa shortlisted jarrett court the wrap aloneiving meadow taking brain local [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.668 (perp=11.798, rec=0.276, cos=0.033), tot_loss_proj:3.343 [t=0.31s]
prediction: ['[CLS], story traffic hide conservative history traditional particular conservativebound conservative very theatrical anthropological flavor create participant new new film truth visual mountain conservative justice [SEP]']
[ 100/2000] tot_loss=2.347 (perp=10.637, rec=0.191, cos=0.028), tot_loss_proj:3.179 [t=0.31s]
prediction: ['[CLS] finds movie hide texture conservative downtown ancient particular hidebound conservative andbound films tradition gives it new new it texture contemporary hello hidebound [SEP]']
[ 150/2000] tot_loss=2.219 (perp=10.264, rec=0.141, cos=0.026), tot_loss_proj:3.138 [t=0.31s]
prediction: ['[CLS] finds movie hide texture conservative traditions amanda we hidebound conservative and most movie traditions gives it new new it texture new, hidebound [SEP]']
[ 200/2000] tot_loss=2.037 (perp=9.419, rec=0.128, cos=0.025), tot_loss_proj:3.397 [t=0.31s]
prediction: ['[CLS] finds movie hide texture conservative our making our hidebound conservative and most movie traditions gives it new new it texture new, hide reality [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.970 (perp=9.196, rec=0.106, cos=0.024), tot_loss_proj:3.223 [t=0.31s]
prediction: ['[CLS] finds movie alone texture conservative our making our hidebound conservative and most movie traditions gives it new new texture new, it hide reality [SEP]']
[ 300/2000] tot_loss=2.051 (perp=9.644, rec=0.098, cos=0.024), tot_loss_proj:3.161 [t=0.31s]
prediction: ['[CLS] finds movie alone texture conservative our ages our hidebound conservative and most making traditions gives it new new texture new, it hide reality [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.920 (perp=9.028, rec=0.091, cos=0.023), tot_loss_proj:2.768 [t=0.31s]
prediction: ['[CLS] finds movie alone texture making our ages our hidebound conservative and most conservative traditions gives it new new texture new, it hide reality [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.933 (perp=9.135, rec=0.082, cos=0.024), tot_loss_proj:2.800 [t=0.31s]
prediction: ['[CLS] finds movie texture alone making our aftermath our hidebound conservative and most one traditions gives it new new texture new, it hide reality [SEP]']
[ 450/2000] tot_loss=1.897 (perp=8.950, rec=0.084, cos=0.023), tot_loss_proj:2.762 [t=0.31s]
prediction: ['[CLS] finds movie texture alone making our cultures our hidebound conservative and most one traditions gives it new new texture new, it hide reality [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.039 (perp=9.708, rec=0.073, cos=0.023), tot_loss_proj:2.978 [t=0.31s]
prediction: ['[CLS] finds movie texture alone making our shepard our hidebound conservative and most one traditions gives and new new texture, new it hide reality [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.906 (perp=8.985, rec=0.086, cos=0.024), tot_loss_proj:2.903 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our cultures our hidebound conservative and most one traditions gives and movie new texture, new it hide reality [SEP]']
[ 600/2000] tot_loss=1.901 (perp=8.985, rec=0.080, cos=0.024), tot_loss_proj:2.906 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our cultures our hidebound conservative and most one traditions gives and movie new texture, new it hide reality [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.794 (perp=8.485, rec=0.074, cos=0.024), tot_loss_proj:2.240 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our americana our hidebound conservative and most one it gives and movie new texture, new traditions - reality [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.735 (perp=8.145, rec=0.082, cos=0.024), tot_loss_proj:2.079 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our fathers our hidebound conservative and it gives and most one movie new texture, new traditions - reality [SEP]']
[ 750/2000] tot_loss=1.720 (perp=8.145, rec=0.067, cos=0.024), tot_loss_proj:2.082 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our fathers our hidebound conservative and it gives and most one movie new texture, new traditions - reality [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.685 (perp=7.943, rec=0.072, cos=0.024), tot_loss_proj:2.047 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our shepard our hidebound and most conservative and it gives one movie new texture, new traditions - reality [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.595 (perp=7.492, rec=0.073, cos=0.023), tot_loss_proj:2.089 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie our hidebound and most conservative and it gives one ending new texture, new traditions - reality [SEP]']
[ 900/2000] tot_loss=1.631 (perp=7.700, rec=0.067, cos=0.024), tot_loss_proj:2.043 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie our hidebound and most conservative and it gives one shepard new texture, new traditions - reality [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.637 (perp=7.700, rec=0.073, cos=0.024), tot_loss_proj:2.047 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie our hidebound and most conservative and it gives one shepard new texture, new traditions - reality [SEP]']
Attempt swap
[1000/2000] tot_loss=1.639 (perp=7.700, rec=0.075, cos=0.024), tot_loss_proj:2.047 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie our hidebound and most conservative and it gives one shepard new texture, new traditions - reality [SEP]']
[1050/2000] tot_loss=1.634 (perp=7.700, rec=0.070, cos=0.024), tot_loss_proj:2.046 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie our hidebound and most conservative and it gives one shepard new texture, new traditions - reality [SEP]']
Attempt swap
[1100/2000] tot_loss=1.783 (perp=8.431, rec=0.073, cos=0.024), tot_loss_proj:2.357 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia hidebound and most conservative and it gives one shepard new texture, new traditions - reality [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.730 (perp=8.159, rec=0.075, cos=0.024), tot_loss_proj:2.352 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia hidebound and most conservative - it gives one shepard new texture, new traditions and reality [SEP]']
[1200/2000] tot_loss=1.723 (perp=8.159, rec=0.068, cos=0.024), tot_loss_proj:2.351 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia hidebound and most conservative - it gives one shepard new texture, new traditions and reality [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.711 (perp=8.094, rec=0.068, cos=0.023), tot_loss_proj:2.093 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new traditions and reality [SEP]']
Attempt swap
[1300/2000] tot_loss=1.715 (perp=8.094, rec=0.073, cos=0.024), tot_loss_proj:2.095 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new traditions and reality [SEP]']
[1350/2000] tot_loss=1.709 (perp=8.094, rec=0.066, cos=0.024), tot_loss_proj:2.089 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new traditions and reality [SEP]']
Attempt swap
[1400/2000] tot_loss=1.723 (perp=8.094, rec=0.080, cos=0.024), tot_loss_proj:2.090 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new traditions and reality [SEP]']
Attempt swap
[1450/2000] tot_loss=1.705 (perp=8.094, rec=0.063, cos=0.024), tot_loss_proj:2.096 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new traditions and reality [SEP]']
[1500/2000] tot_loss=1.714 (perp=8.094, rec=0.072, cos=0.024), tot_loss_proj:2.093 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new traditions and reality [SEP]']
Attempt swap
[1550/2000] tot_loss=1.716 (perp=8.094, rec=0.074, cos=0.024), tot_loss_proj:2.095 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new traditions and reality [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.708 (perp=8.069, rec=0.071, cos=0.023), tot_loss_proj:2.098 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new reality and traditions [SEP]']
[1650/2000] tot_loss=1.710 (perp=8.069, rec=0.072, cos=0.024), tot_loss_proj:2.092 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new reality and traditions [SEP]']
Attempt swap
[1700/2000] tot_loss=1.710 (perp=8.069, rec=0.072, cos=0.024), tot_loss_proj:2.099 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new reality and traditions [SEP]']
Attempt swap
[1750/2000] tot_loss=1.701 (perp=8.069, rec=0.064, cos=0.024), tot_loss_proj:2.092 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new reality and traditions [SEP]']
[1800/2000] tot_loss=1.711 (perp=8.069, rec=0.073, cos=0.024), tot_loss_proj:2.093 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new reality and traditions [SEP]']
Attempt swap
[1850/2000] tot_loss=1.708 (perp=8.069, rec=0.070, cos=0.024), tot_loss_proj:2.088 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new reality and traditions [SEP]']
Attempt swap
[1900/2000] tot_loss=1.702 (perp=8.069, rec=0.064, cos=0.024), tot_loss_proj:2.094 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new reality and traditions [SEP]']
[1950/2000] tot_loss=1.714 (perp=8.069, rec=0.076, cos=0.024), tot_loss_proj:2.091 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new reality and traditions [SEP]']
Attempt swap
[2000/2000] tot_loss=1.703 (perp=8.069, rec=0.066, cos=0.024), tot_loss_proj:2.097 [t=0.31s]
prediction: ['[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new reality and traditions [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] finds new texture alone making our movie alexia one hidebound and most conservative - it gives shepard new relevance, new reality and traditions [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.304 | p: 87.500 | r: 95.455
rouge2     | fm: 27.273 | p: 26.087 | r: 28.571
rougeL     | fm: 47.826 | p: 45.833 | r: 50.000
rougeLsum  | fm: 47.826 | p: 45.833 | r: 50.000
r1fm+r2fm = 118.577

[Aggregate metrics]:
rouge1     | fm: 90.456 | p: 90.166 | r: 90.982
rouge2     | fm: 61.766 | p: 61.708 | r: 61.851
rougeL     | fm: 79.809 | p: 79.497 | r: 80.220
rougeLsum  | fm: 79.883 | p: 79.632 | r: 80.207
r1fm+r2fm = 152.222

input #39 time: 0:12:16 | total time: 8:36:22


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9864236707764241
highest_index [0]
highest [0.9864236707764241]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9461968541145325 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.933415949344635 for ['[CLS] comeback was and ste up random staff med league [SEP]']
[Init] best rec loss: 0.9194445610046387 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9050919413566589 for ['[CLS] taken electionsping due ce windsor undergoes labor scouts [SEP]']
[Init] best rec loss: 0.8958917856216431 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 0.8903593420982361 for ['[CLS] of transferred charlotte play troy also soon instantly was [SEP]']
[Init] best rec loss: 0.8836466670036316 for ['[CLS] false christine are greyova juniorola until thieves [SEP]']
[Init] best rec loss: 0.8812552690505981 for ['[CLS] model dr further productive show against decree reaction learning [SEP]']
[Init] best rec loss: 0.8710944652557373 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 0.8620179295539856 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 0.8617578148841858 for ['[CLS]lum head original navigation investigatingwell position ruleduron [SEP]']
[Init] best rec loss: 0.8531798124313354 for ['[CLS] robin hemisphere # worn expensiveisticor wonder arms [SEP]']
[Init] best rec loss: 0.8469719290733337 for ['[CLS] chiefs voluntary turning era repliedfies things brendan central [SEP]']
[Init] best rec loss: 0.8001624941825867 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8001444935798645 for ['[CLS] already abd kent deciding georgian many lady but° [SEP]']
[Init] best perm rec loss: 0.7979185581207275 for ['[CLS] kent but° already georgian many abd lady deciding [SEP]']
[Init] best perm rec loss: 0.7973162531852722 for ['[CLS]° lady georgian deciding but many already abd kent [SEP]']
[Init] best perm rec loss: 0.7971222996711731 for ['[CLS] many° lady abd deciding already georgian but kent [SEP]']
[Init] best perm rec loss: 0.7952958345413208 for ['[CLS] many lady already but abd kent georgian deciding° [SEP]']
[Init] best perm rec loss: 0.7949018478393555 for ['[CLS] georgian many deciding lady already° abd but kent [SEP]']
[Init] best perm rec loss: 0.7947313785552979 for ['[CLS] deciding kent lady many georgian already but° abd [SEP]']
[Init] best perm rec loss: 0.7946915030479431 for ['[CLS]° georgian kent but already lady abd many deciding [SEP]']
[Init] best perm rec loss: 0.7941168546676636 for ['[CLS] already but deciding abd lady kent georgian° many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.635 (perp=11.584, rec=0.278, cos=0.040), tot_loss_proj:3.250 [t=0.30s]
prediction: ['[CLS]mmel everything you saddle potious imagery or electronics [SEP]']
[ 100/2000] tot_loss=2.371 (perp=10.662, rec=0.208, cos=0.031), tot_loss_proj:3.012 [t=0.30s]
prediction: ['[CLS]mmel &chommel phony music or something [SEP]']
[ 150/2000] tot_loss=2.354 (perp=10.896, rec=0.148, cos=0.027), tot_loss_proj:2.991 [t=0.30s]
prediction: ['[CLS]mmel withmmel us puony imagery or something [SEP]']
[ 200/2000] tot_loss=2.224 (perp=10.497, rec=0.099, cos=0.026), tot_loss_proj:2.850 [t=0.30s]
prediction: ['[CLS]mmel with images us puony imagery or music [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.083 (perp=9.715, rec=0.114, cos=0.026), tot_loss_proj:2.418 [t=0.30s]
prediction: ['[CLS]mmel us with phrase puony imagery or music [SEP]']
[ 300/2000] tot_loss=2.048 (perp=9.715, rec=0.079, cos=0.026), tot_loss_proj:2.426 [t=0.30s]
prediction: ['[CLS]mmel us with phrase puony imagery or music [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.829 (perp=8.657, rec=0.072, cos=0.026), tot_loss_proj:2.273 [t=0.30s]
prediction: ['[CLS] phrasemmel us with puony imagery or music [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.806 (perp=8.221, rec=0.134, cos=0.027), tot_loss_proj:2.305 [t=0.30s]
prediction: ['[CLS] phrase pummel us withony imagery or music [SEP]']
[ 450/2000] tot_loss=1.927 (perp=9.111, rec=0.079, cos=0.026), tot_loss_proj:2.548 [t=0.30s]
prediction: ['[CLS] ph pummel us withony imagery or music [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.542 (perp=7.171, rec=0.081, cos=0.026), tot_loss_proj:1.533 [t=0.30s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.516 (perp=6.973, rec=0.094, cos=0.027), tot_loss_proj:1.565 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 600/2000] tot_loss=1.486 (perp=6.973, rec=0.066, cos=0.026), tot_loss_proj:1.559 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.491 (perp=6.973, rec=0.071, cos=0.026), tot_loss_proj:1.558 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.490 (perp=6.973, rec=0.069, cos=0.026), tot_loss_proj:1.560 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 750/2000] tot_loss=1.478 (perp=6.973, rec=0.057, cos=0.026), tot_loss_proj:1.556 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.490 (perp=6.973, rec=0.069, cos=0.027), tot_loss_proj:1.559 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.494 (perp=6.973, rec=0.073, cos=0.026), tot_loss_proj:1.563 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 900/2000] tot_loss=1.488 (perp=6.973, rec=0.067, cos=0.027), tot_loss_proj:1.556 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.491 (perp=6.973, rec=0.070, cos=0.027), tot_loss_proj:1.558 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=1.498 (perp=6.973, rec=0.077, cos=0.027), tot_loss_proj:1.548 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1050/2000] tot_loss=1.503 (perp=6.973, rec=0.082, cos=0.027), tot_loss_proj:1.558 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=1.487 (perp=6.973, rec=0.066, cos=0.027), tot_loss_proj:1.560 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=1.497 (perp=6.973, rec=0.076, cos=0.027), tot_loss_proj:1.557 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1200/2000] tot_loss=1.493 (perp=6.973, rec=0.072, cos=0.027), tot_loss_proj:1.547 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.493 (perp=6.973, rec=0.072, cos=0.027), tot_loss_proj:1.553 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.504 (perp=6.973, rec=0.083, cos=0.027), tot_loss_proj:1.561 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1350/2000] tot_loss=1.493 (perp=6.973, rec=0.071, cos=0.027), tot_loss_proj:1.565 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.488 (perp=6.973, rec=0.067, cos=0.027), tot_loss_proj:1.550 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1450/2000] tot_loss=1.479 (perp=6.973, rec=0.058, cos=0.027), tot_loss_proj:1.557 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1500/2000] tot_loss=1.487 (perp=6.973, rec=0.066, cos=0.027), tot_loss_proj:1.559 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.488 (perp=6.973, rec=0.067, cos=0.027), tot_loss_proj:1.557 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.493 (perp=6.973, rec=0.072, cos=0.027), tot_loss_proj:1.552 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1650/2000] tot_loss=1.502 (perp=6.973, rec=0.081, cos=0.027), tot_loss_proj:1.559 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.490 (perp=6.973, rec=0.069, cos=0.027), tot_loss_proj:1.564 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.492 (perp=6.973, rec=0.071, cos=0.027), tot_loss_proj:1.546 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1800/2000] tot_loss=1.486 (perp=6.973, rec=0.065, cos=0.027), tot_loss_proj:1.548 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.490 (perp=6.973, rec=0.069, cos=0.027), tot_loss_proj:1.559 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.492 (perp=6.973, rec=0.071, cos=0.027), tot_loss_proj:1.556 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1950/2000] tot_loss=1.488 (perp=6.973, rec=0.067, cos=0.027), tot_loss_proj:1.552 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.492 (perp=6.973, rec=0.071, cos=0.027), tot_loss_proj:1.554 [t=0.30s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] pummel us with phony music or imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 90.809 | p: 90.438 | r: 91.275
rouge2     | fm: 61.177 | p: 61.112 | r: 61.289
rougeL     | fm: 79.746 | p: 79.439 | r: 80.057
rougeLsum  | fm: 79.827 | p: 79.562 | r: 80.139
r1fm+r2fm = 151.986

input #40 time: 0:11:58 | total time: 8:48:20


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.9876691531591821
highest_index [0]
highest [0.9876691531591821]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.887104332447052 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.8733556270599365 for ['[CLS] samuel conservation [SEP]']
[Init] best rec loss: 0.8582063913345337 for ['[CLS] mascara plenty [SEP]']
[Init] best rec loss: 0.8486031889915466 for ['[CLS] origins pleasure [SEP]']
[Init] best rec loss: 0.7831816673278809 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 0.7772631049156189 for ['[CLS] cale fate [SEP]']
[Init] best rec loss: 0.7219704389572144 for ['[CLS] ways whether [SEP]']
[Init] best rec loss: 0.6745704412460327 for ['[CLS] usa some [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.286 (perp=10.212, rec=0.213, cos=0.030), tot_loss_proj:2.131 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.237 (perp=10.212, rec=0.164, cos=0.031), tot_loss_proj:2.127 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.218 (perp=10.212, rec=0.145, cos=0.031), tot_loss_proj:2.137 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.217 (perp=10.212, rec=0.142, cos=0.033), tot_loss_proj:2.146 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.211 (perp=10.212, rec=0.137, cos=0.031), tot_loss_proj:2.141 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.204 (perp=10.212, rec=0.131, cos=0.031), tot_loss_proj:2.154 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.204 (perp=10.212, rec=0.131, cos=0.031), tot_loss_proj:2.129 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.207 (perp=10.212, rec=0.134, cos=0.031), tot_loss_proj:2.153 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.214 (perp=10.212, rec=0.141, cos=0.031), tot_loss_proj:2.138 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.208 (perp=10.212, rec=0.134, cos=0.031), tot_loss_proj:2.140 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.200 (perp=10.212, rec=0.127, cos=0.031), tot_loss_proj:2.133 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.208 (perp=10.212, rec=0.135, cos=0.031), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.211 (perp=10.212, rec=0.138, cos=0.031), tot_loss_proj:2.144 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.212 (perp=10.212, rec=0.139, cos=0.031), tot_loss_proj:2.134 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.205 (perp=10.212, rec=0.132, cos=0.031), tot_loss_proj:2.134 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.207 (perp=10.212, rec=0.134, cos=0.031), tot_loss_proj:2.126 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.206 (perp=10.212, rec=0.133, cos=0.031), tot_loss_proj:2.133 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.209 (perp=10.212, rec=0.136, cos=0.031), tot_loss_proj:2.139 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.207 (perp=10.212, rec=0.134, cos=0.031), tot_loss_proj:2.134 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.203 (perp=10.212, rec=0.130, cos=0.031), tot_loss_proj:2.132 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.194 (perp=10.212, rec=0.121, cos=0.031), tot_loss_proj:2.135 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.202 (perp=10.212, rec=0.129, cos=0.031), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.200 (perp=10.212, rec=0.127, cos=0.031), tot_loss_proj:2.126 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.193 (perp=10.212, rec=0.120, cos=0.031), tot_loss_proj:2.139 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.202 (perp=10.212, rec=0.129, cos=0.031), tot_loss_proj:2.124 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.203 (perp=10.212, rec=0.130, cos=0.031), tot_loss_proj:2.131 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.201 (perp=10.212, rec=0.128, cos=0.031), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.201 (perp=10.212, rec=0.128, cos=0.031), tot_loss_proj:2.127 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.198 (perp=10.212, rec=0.125, cos=0.031), tot_loss_proj:2.126 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.208 (perp=10.212, rec=0.135, cos=0.031), tot_loss_proj:2.121 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.194 (perp=10.212, rec=0.121, cos=0.031), tot_loss_proj:2.141 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.194 (perp=10.212, rec=0.121, cos=0.031), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.204 (perp=10.212, rec=0.131, cos=0.031), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.210 (perp=10.212, rec=0.137, cos=0.031), tot_loss_proj:2.137 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.197 (perp=10.212, rec=0.124, cos=0.031), tot_loss_proj:2.145 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.202 (perp=10.212, rec=0.129, cos=0.031), tot_loss_proj:2.131 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.206 (perp=10.212, rec=0.133, cos=0.031), tot_loss_proj:2.139 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.204 (perp=10.212, rec=0.131, cos=0.031), tot_loss_proj:2.138 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.201 (perp=10.212, rec=0.128, cos=0.031), tot_loss_proj:2.125 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.199 (perp=10.212, rec=0.126, cos=0.031), tot_loss_proj:2.138 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.970 | p: 90.657 | r: 91.422
rouge2     | fm: 62.271 | p: 62.215 | r: 62.357
rougeL     | fm: 80.294 | p: 80.048 | r: 80.603
rougeLsum  | fm: 80.292 | p: 80.032 | r: 80.626
r1fm+r2fm = 153.241

input #41 time: 0:11:54 | total time: 9:00:15


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9844300411526948
highest_index [0]
highest [0.9844300411526948]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.8726588487625122 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8085821270942688 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8066730499267578 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.7954016923904419 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.785937488079071 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.785683274269104 for ['[CLS] liftedures ever dare kitchenrs attracted scale enough ran cut mapletaking bandabe treatygible international wishpling superseded stages larger assignmentctric offended [SEP]']
[Init] best perm rec loss: 0.7856664657592773 for ['[CLS] assignmentbe international ran dare ever offendedgibleuresrs enoughtaking wish treaty scale larger attracted cut maplepling superseded kitchenctric banda lifted stages [SEP]']
[Init] best perm rec loss: 0.7826078534126282 for ['[CLS] maplebe dare assignmenturestakingpling superseded international offended kitchen ran liftedrs wish treaty larger banda enoughgible attracted scale stages everctric cut [SEP]']
[Init] best perm rec loss: 0.7818170189857483 for ['[CLS] lifted superseded kitchen treaty attractedrs assignment ran bandapling scale enough wish maplectric larger stagestakingbe cut ever offendedgibleures dare international [SEP]']
[Init] best perm rec loss: 0.7812342643737793 for ['[CLS] enough wish attracted dare international largerctricgible ranbe assignment scalepling liftedtaking superseded kitchen maple cutures stages everrs offended banda treaty [SEP]']
[Init] best perm rec loss: 0.7805400490760803 for ['[CLS]rs attracted supersededbe ran stages lifted assignment international kitchen larger enough scaletaking darepling treaty everuresgible cut wish offended bandactric maple [SEP]']
[Init] best perm rec loss: 0.7804243564605713 for ['[CLS]ctricures ran kitchen supersededbe international attracted lifted offended dare scale stagestaking enough cut treatyrspling ever banda largergible assignment maple wish [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.126 (perp=13.805, rec=0.319, cos=0.046), tot_loss_proj:3.476 [t=0.31s]
prediction: ['[CLS] poorly poorly sexual february composerry poster ignored phone actually procedure poorlyed )ed re plant forgot poorly films duringweiler locations check soldiers forgot [SEP]']
[ 100/2000] tot_loss=2.907 (perp=12.990, rec=0.270, cos=0.040), tot_loss_proj:3.210 [t=0.31s]
prediction: ['[CLS] they poorly re crash filmmakersry twitch forgot operated component procedure poorly to ) into re percent forgot poorly filmggerweiler locations school eggs forgot [SEP]']
[ 150/2000] tot_loss=2.693 (perp=12.402, rec=0.182, cos=0.031), tot_loss_proj:3.109 [t=0.31s]
prediction: ['[CLS] they poorlygger 2007 filmmakers anything suspected forgot timed scary transport as to engines into re problem forgot poorlygger poorly attraction locations park residents forgot [SEP]']
[ 200/2000] tot_loss=2.724 (perp=12.674, rec=0.158, cos=0.031), tot_loss_proj:3.322 [t=0.31s]
prediction: ['[CLS] they poorlygger * filmmakers anything clearly forgot scary scary include as to engines into re component forgotggergger poorly attraction setting attractions researchers forgot [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.653 (perp=12.388, rec=0.148, cos=0.028), tot_loss_proj:3.306 [t=0.31s]
prediction: ['[CLS] they poorlyggerji include anything iucn forgot halfway scary filmmakers as to locations into re component forgotggergger school attraction setting attraction researchers downtown [SEP]']
[ 300/2000] tot_loss=2.609 (perp=12.266, rec=0.125, cos=0.030), tot_loss_proj:3.135 [t=0.32s]
prediction: ['[CLS] they poorlyjiji include anything iucn forgot halfway scary filmmakers as to engines into re component forgotggergger school school setting attraction scary downtown [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.553 (perp=12.060, rec=0.111, cos=0.030), tot_loss_proj:3.133 [t=0.31s]
prediction: ['[CLS] they poorlyjiji include anything iucn forgot halfway scary filmmakers as researchers locations into re component forgotggergger school school setting attraction to downtown [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.477 (perp=11.665, rec=0.113, cos=0.031), tot_loss_proj:3.033 [t=0.31s]
prediction: ['[CLS] into poorlyjiji include anything iucn forgot halfway scary filmmakers as scary locations they re problem forgotggerggerlitz school setting attraction to downtown [SEP]']
[ 450/2000] tot_loss=2.473 (perp=11.724, rec=0.097, cos=0.031), tot_loss_proj:3.117 [t=0.31s]
prediction: ['[CLS] into poorlyjigger include anything iucn forgot halfway scary filmmakers as scary they they re problem forgotggergger school school setting attraction to fatal [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.468 (perp=11.641, rec=0.110, cos=0.031), tot_loss_proj:3.101 [t=0.31s]
prediction: ['[CLS] into poorlyjigger include anything iucn forgot halfway halfway filmmakers as scary they they regger forgot problemgger a school setting attraction to fatal [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.403 (perp=11.389, rec=0.095, cos=0.030), tot_loss_proj:2.979 [t=0.31s]
prediction: ['[CLS] intojigger poorly include anything iucn forgot halfway halfway filmmakers as scary they they regger forgot problemgger a school setting attraction to fatal [SEP]']
[ 600/2000] tot_loss=2.451 (perp=11.656, rec=0.088, cos=0.032), tot_loss_proj:3.036 [t=0.31s]
prediction: ['[CLS] intojigger poorly include anything definition forgot halfway halfway filmmakers as scary they they regger forgot portiongger a school setting attraction to fatal [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.403 (perp=11.413, rec=0.090, cos=0.031), tot_loss_proj:2.991 [t=0.31s]
prediction: ['[CLS] intojigger poorly include anything definition forgot halfway halfway fatal as scary they they regger forgot portiongger a school setting attraction to filmmakers [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.282 (perp=10.813, rec=0.089, cos=0.030), tot_loss_proj:2.934 [t=0.31s]
prediction: ['[CLS] intojigger poorly definition include anything forgot halfway halfway fatal as scary even they regger forgot portiongger a school setting attraction to filmmakers [SEP]']
[ 750/2000] tot_loss=2.328 (perp=11.013, rec=0.095, cos=0.030), tot_loss_proj:3.033 [t=0.31s]
prediction: ['[CLS] intoji fatal poorly definition include anything forgot even halfway fatal as scary even they regger forgot fatalgger a school setting attraction to filmmakers [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.319 (perp=11.013, rec=0.085, cos=0.031), tot_loss_proj:3.033 [t=0.31s]
prediction: ['[CLS] intoji fatal poorly definition include anything forgot even halfway fatal as scary even they regger forgot fatalgger a school setting attraction to filmmakers [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.309 (perp=10.921, rec=0.095, cos=0.030), tot_loss_proj:3.060 [t=0.31s]
prediction: ['[CLS] intoji forgot poorly project include anything fatal even halfway fatal as scary even they regger forgot fatalgger a school setting attraction to filmmakers [SEP]']
[ 900/2000] tot_loss=2.310 (perp=10.921, rec=0.094, cos=0.031), tot_loss_proj:3.067 [t=0.31s]
prediction: ['[CLS] intoji forgot poorly project include anything fatal even halfway fatal as scary even they regger forgot fatalgger a school setting attraction to filmmakers [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.188 (perp=10.346, rec=0.088, cos=0.031), tot_loss_proj:2.825 [t=0.31s]
prediction: ['[CLS]ggerji forgot poorly s include anything fatal even halfway fatal as scary even they regger forgot fatal into a school setting attraction to filmmakers [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.099 (perp=9.921, rec=0.084, cos=0.031), tot_loss_proj:2.768 [t=0.31s]
prediction: ['[CLS]ggerji forgot s poorly include anything fatal even halfway fatal as scary even they regger forgot fatal into a school setting attraction to filmmakers [SEP]']
[1050/2000] tot_loss=2.100 (perp=9.921, rec=0.086, cos=0.031), tot_loss_proj:2.766 [t=0.31s]
prediction: ['[CLS]ggerji forgot s poorly include anything fatal even halfway fatal as scary even they regger forgot fatal into a school setting attraction to filmmakers [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.081 (perp=9.805, rec=0.089, cos=0.031), tot_loss_proj:2.599 [t=0.31s]
prediction: ['[CLS]ggerji forgot s poorly include anything attraction even halfway fatal as scary even they regger forgot fatal into a school setting fatal to filmmakers [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.073 (perp=9.825, rec=0.077, cos=0.031), tot_loss_proj:2.601 [t=0.31s]
prediction: ['[CLS]ggerji forgot s poorly include attraction anything even halfway fatal as scary even they regger forgot fatal into a school setting fatal to filmmakers [SEP]']
[1200/2000] tot_loss=2.084 (perp=9.825, rec=0.088, cos=0.031), tot_loss_proj:2.607 [t=0.31s]
prediction: ['[CLS]ggerji forgot s poorly include attraction anything even halfway fatal as scary even they regger forgot fatal into a school setting fatal to filmmakers [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.082 (perp=9.805, rec=0.090, cos=0.031), tot_loss_proj:2.591 [t=0.31s]
prediction: ['[CLS]ggerji forgot s poorly include anything attraction even halfway fatal as scary even they regger forgot fatal into a school setting fatal to filmmakers [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.065 (perp=9.756, rec=0.083, cos=0.031), tot_loss_proj:2.657 [t=0.31s]
prediction: ['[CLS]ggerji forgot s poorly include anything attraction even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]']
[1350/2000] tot_loss=2.061 (perp=9.756, rec=0.078, cos=0.031), tot_loss_proj:2.649 [t=0.31s]
prediction: ['[CLS]ggerji forgot s poorly include anything attraction even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.022 (perp=9.573, rec=0.077, cos=0.031), tot_loss_proj:2.661 [t=0.31s]
prediction: ['[CLS]ggerji attraction forgot s poorly include anything even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]']
Attempt swap
[1450/2000] tot_loss=2.025 (perp=9.573, rec=0.079, cos=0.031), tot_loss_proj:2.664 [t=0.31s]
prediction: ['[CLS]ggerji attraction forgot s poorly include anything even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]']
[1500/2000] tot_loss=2.023 (perp=9.573, rec=0.077, cos=0.031), tot_loss_proj:2.662 [t=0.31s]
prediction: ['[CLS]ggerji attraction forgot s poorly include anything even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]']
Attempt swap
[1550/2000] tot_loss=2.024 (perp=9.573, rec=0.078, cos=0.031), tot_loss_proj:2.661 [t=0.31s]
prediction: ['[CLS]ggerji attraction forgot s poorly include anything even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]']
Attempt swap
[1600/2000] tot_loss=2.025 (perp=9.573, rec=0.079, cos=0.031), tot_loss_proj:2.667 [t=0.31s]
prediction: ['[CLS]ggerji attraction forgot s poorly include anything even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]']
[1650/2000] tot_loss=2.030 (perp=9.573, rec=0.085, cos=0.031), tot_loss_proj:2.664 [t=0.31s]
prediction: ['[CLS]ggerji attraction forgot s poorly include anything even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]']
Attempt swap
[1700/2000] tot_loss=2.012 (perp=9.573, rec=0.066, cos=0.031), tot_loss_proj:2.662 [t=0.31s]
prediction: ['[CLS]ggerji attraction forgot s poorly include anything even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.015 (perp=9.523, rec=0.079, cos=0.031), tot_loss_proj:2.748 [t=0.31s]
prediction: ['[CLS]ggerji attraction s poorly forgot include anything even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]']
[1800/2000] tot_loss=2.013 (perp=9.523, rec=0.077, cos=0.031), tot_loss_proj:2.752 [t=0.31s]
prediction: ['[CLS]ggerji attraction s poorly forgot include anything even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.011 (perp=9.549, rec=0.070, cos=0.031), tot_loss_proj:2.601 [t=0.31s]
prediction: ['[CLS]ggerji attraction s poorly forgot include anything even halfway fatal as scary even they regger forgot fatal into a school setting fatal to filmmakers [SEP]']
Attempt swap
[1900/2000] tot_loss=2.019 (perp=9.549, rec=0.078, cos=0.031), tot_loss_proj:2.590 [t=0.31s]
prediction: ['[CLS]ggerji attraction s poorly forgot include anything even halfway fatal as scary even they regger forgot fatal into a school setting fatal to filmmakers [SEP]']
[1950/2000] tot_loss=2.014 (perp=9.549, rec=0.073, cos=0.031), tot_loss_proj:2.602 [t=0.31s]
prediction: ['[CLS]ggerji attraction s poorly forgot include anything even halfway fatal as scary even they regger forgot fatal into a school setting fatal to filmmakers [SEP]']
Attempt swap
[2000/2000] tot_loss=2.028 (perp=9.549, rec=0.088, cos=0.031), tot_loss_proj:2.593 [t=0.31s]
prediction: ['[CLS]ggerji attraction s poorly forgot include anything even halfway fatal as scary even they regger forgot fatal into a school setting fatal to filmmakers [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS]ggerji attraction forgot s poorly include anything even halfway fatal as scary even they regger forgot fatal fatal into a school setting to filmmakers [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 76.923 | r: 83.333
rouge2     | fm: 20.833 | p: 20.000 | r: 21.739
rougeL     | fm: 56.000 | p: 53.846 | r: 58.333
rougeLsum  | fm: 56.000 | p: 53.846 | r: 58.333
r1fm+r2fm = 100.833

[Aggregate metrics]:
rouge1     | fm: 90.671 | p: 90.261 | r: 91.145
rouge2     | fm: 61.329 | p: 61.185 | r: 61.463
rougeL     | fm: 79.603 | p: 79.260 | r: 79.968
rougeLsum  | fm: 79.667 | p: 79.381 | r: 80.041
r1fm+r2fm = 152.000

input #42 time: 0:12:18 | total time: 9:12:33


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9866437957296199
highest_index [0]
highest [0.9866437957296199]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9297198057174683 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9046813249588013 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8546162247657776 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 0.8310823440551758 for ['[CLS] taken cheek willels [SEP]']
[Init] best rec loss: 0.7823483347892761 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.7615032196044922 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.7302461862564087 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7095861434936523 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 0.7089075446128845 for ['[CLS]bus second climbck [SEP]']
[Init] best perm rec loss: 0.7088683843612671 for ['[CLS] secondckbus climb [SEP]']
[Init] best perm rec loss: 0.703288197517395 for ['[CLS] climb secondbusck [SEP]']
[Init] best perm rec loss: 0.7018141746520996 for ['[CLS] climb secondckbus [SEP]']
[Init] best perm rec loss: 0.6994926929473877 for ['[CLS]ckbus climb second [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.596 (perp=11.776, rec=0.212, cos=0.029), tot_loss_proj:2.915 [t=0.30s]
prediction: ['[CLS]issistic naistic [SEP]']
[ 100/2000] tot_loss=2.531 (perp=11.776, rec=0.148, cos=0.028), tot_loss_proj:2.913 [t=0.30s]
prediction: ['[CLS]issistic naistic [SEP]']
[ 150/2000] tot_loss=2.962 (perp=14.140, rec=0.109, cos=0.025), tot_loss_proj:3.405 [t=0.30s]
prediction: ['[CLS]ississ naistic [SEP]']
[ 200/2000] tot_loss=2.533 (perp=12.149, rec=0.078, cos=0.026), tot_loss_proj:2.908 [t=0.30s]
prediction: ['[CLS]rciss naistic [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.139 (perp=5.048, rec=0.101, cos=0.028), tot_loss_proj:1.094 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.102 (perp=5.048, rec=0.067, cos=0.026), tot_loss_proj:1.113 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.096 (perp=5.048, rec=0.060, cos=0.026), tot_loss_proj:1.123 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.099 (perp=5.048, rec=0.063, cos=0.026), tot_loss_proj:1.106 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.090 (perp=5.048, rec=0.054, cos=0.026), tot_loss_proj:1.103 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.097 (perp=5.048, rec=0.061, cos=0.026), tot_loss_proj:1.119 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.102 (perp=5.048, rec=0.066, cos=0.026), tot_loss_proj:1.089 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.101 (perp=5.048, rec=0.065, cos=0.026), tot_loss_proj:1.103 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.097 (perp=5.048, rec=0.061, cos=0.026), tot_loss_proj:1.105 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.081 (perp=5.048, rec=0.045, cos=0.026), tot_loss_proj:1.118 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.099 (perp=5.048, rec=0.063, cos=0.026), tot_loss_proj:1.113 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.104 (perp=5.048, rec=0.068, cos=0.026), tot_loss_proj:1.104 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.087 (perp=5.048, rec=0.051, cos=0.026), tot_loss_proj:1.118 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.106 (perp=5.048, rec=0.070, cos=0.026), tot_loss_proj:1.108 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.085 (perp=5.048, rec=0.049, cos=0.026), tot_loss_proj:1.101 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.083 (perp=5.048, rec=0.047, cos=0.026), tot_loss_proj:1.118 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.091 (perp=5.048, rec=0.055, cos=0.026), tot_loss_proj:1.095 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.085 (perp=5.048, rec=0.049, cos=0.027), tot_loss_proj:1.105 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.103 (perp=5.048, rec=0.067, cos=0.026), tot_loss_proj:1.103 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.112 (perp=5.048, rec=0.075, cos=0.026), tot_loss_proj:1.094 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.091 (perp=5.048, rec=0.055, cos=0.027), tot_loss_proj:1.103 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.110 (perp=5.048, rec=0.074, cos=0.026), tot_loss_proj:1.085 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.112 (perp=5.048, rec=0.076, cos=0.026), tot_loss_proj:1.109 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.091 (perp=5.048, rec=0.055, cos=0.026), tot_loss_proj:1.116 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.101 (perp=5.048, rec=0.065, cos=0.027), tot_loss_proj:1.105 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.099 (perp=5.048, rec=0.063, cos=0.026), tot_loss_proj:1.104 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.091 (perp=5.048, rec=0.055, cos=0.026), tot_loss_proj:1.106 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.093 (perp=5.048, rec=0.057, cos=0.026), tot_loss_proj:1.110 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.087 (perp=5.048, rec=0.051, cos=0.026), tot_loss_proj:1.105 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.090 (perp=5.048, rec=0.054, cos=0.026), tot_loss_proj:1.111 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.089 (perp=5.048, rec=0.053, cos=0.026), tot_loss_proj:1.102 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.097 (perp=5.048, rec=0.061, cos=0.026), tot_loss_proj:1.101 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.099 (perp=5.048, rec=0.063, cos=0.026), tot_loss_proj:1.104 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.104 (perp=5.048, rec=0.068, cos=0.027), tot_loss_proj:1.101 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.099 (perp=5.048, rec=0.063, cos=0.026), tot_loss_proj:1.095 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.100 (perp=5.048, rec=0.064, cos=0.026), tot_loss_proj:1.110 [t=0.35s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.950 | p: 90.516 | r: 91.526
rouge2     | fm: 62.172 | p: 62.041 | r: 62.304
rougeL     | fm: 80.192 | p: 79.901 | r: 80.549
rougeLsum  | fm: 80.124 | p: 79.863 | r: 80.518
r1fm+r2fm = 153.122

input #43 time: 0:13:19 | total time: 9:25:53


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.9849574035668426
highest_index [0]
highest [0.9849574035668426]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 1.0115301609039307 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 1.0089410543441772 for ['[CLS] pe grammy vague contract flow genre training willing floraux acting! dc spoke ben sami undo polo # paperplaced choon muscle duncanoat derived rat schooling [SEP]']
[Init] best rec loss: 1.0052872896194458 for ['[CLS] menrily corrugated toilets sutherland present theory that food arm deltaym consider premier showing cultree has june pyramid seasons conflicts run worship importancehouse [CLS] conducting romeo [SEP]']
[Init] best rec loss: 1.001047134399414 for ['[CLS] unitedzz golden archaeological looking forward at prime momentien before at private suspensiontone ice rim arrested evelyn surgeon shaw codes memorymobile by addition ultimatelynal mills [SEP]']
[Init] best rec loss: 0.9965690970420837 for ['[CLS] ann crying older dcheng product turf homebahn used evidencepes coaching understandingvino them budget desmond turnsgationj no sidinglasscuit theory beer choke lifted [SEP]']
[Init] best rec loss: 0.9956327080726624 for ['[CLS] bala level branch switched entry mono harlow purchased base aegean work worse haired parliament miles milton parramatta shah one glance circuswas harbour favored l scenic inhibitors re source [SEP]']
[Init] best rec loss: 0.9953712821006775 for ['[CLS] floyd final pump make tang spoke laid royal there nix every or studied doctor reaperomba parameter minor massey framed gene diamond note band tongue safety appetite hard tate [SEP]']
[Init] best rec loss: 0.9860703945159912 for ['[CLS] obstacles access household rave las gas revntly fellowship had rock turnpikewick isn tuesday yet magazine do up everything speculation neckagger openingiani compute occupiedoint mm [SEP]']
[Init] best rec loss: 0.984250009059906 for ['[CLS] patriciaerinacano such currently staggered hop craft vacancy calderon rack anxious play without torpedoous major carter ghost popularity version cutterivar fifty plot parting you still sports [SEP]']
[Init] best rec loss: 0.9821255803108215 for ['[CLS]lock center covenant day mercedes tyler hands times sacrament trust right recressed sheer subjects close iucn or weeks previousort different readyline times providersqualerence alabama [SEP]']
[Init] best rec loss: 0.9818757176399231 for ['[CLS]tched largest cinematographer accounted casey coffee renumbered barak sir society postal penguinlica conversion hips shortly mayead vegas smelled vol [CLS] lose palatinate toby walking dozen million lead [SEP]']
[Init] best rec loss: 0.9797220230102539 for ['[CLS] wet durban engineers charlotte laboratory roy by conditional） centuries lex its cold boyfriend volleyball 2002yat got talon demonstration period differencecolor wind unreleased molecular thousands niagara archeological [SEP]']
[Init] best perm rec loss: 0.9792847037315369 for ['[CLS] wet laboratory centuries engineers period conditional by charlotte boyfriend durban wind cold talon 2002 volleyball difference roy demonstrationyat thousands lexcolor archeological molecular unreleased niagara） its got [SEP]']
[Init] best perm rec loss: 0.9792630672454834 for ['[CLS] laboratory talon roy its archeological unreleasedyat centuries difference niagara thousands lex by engineers demonstration durban period molecularcolor got boyfriend wind） charlotte wet cold volleyball conditional 2002 [SEP]']
[Init] best perm rec loss: 0.9791367053985596 for ['[CLS] period wind difference unreleased bycolor talon lex charlotte conditional cold archeological boyfriend 2002 volleyball centuries niagara） thousands roy demonstrationyat wet its engineers molecular durban laboratory got [SEP]']
[Init] best perm rec loss: 0.9790988564491272 for ['[CLS] laboratory wet） period thousands cold its talon difference boyfriend unreleased engineers molecular niagara centuries got roy by conditionalyatcolor lex archeological charlotte 2002 volleyball durban wind demonstration [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.479 (perp=13.159, rec=0.575, cos=0.273), tot_loss_proj:4.492 [t=0.36s]
prediction: ['[CLS] frown } dispute the while pg theium competition resort gable its morality lynn was [SEP] corporate [SEP] parallel the ( miniseries 2012 kendrick destroy serial exists greatest my [SEP]']
[ 100/2000] tot_loss=3.371 (perp=13.377, rec=0.545, cos=0.151), tot_loss_proj:4.555 [t=0.36s]
prediction: ['[CLS] sentence } kayla when between車 slack vietnameseosity resort linguistics blu nods memorabilia foundation [SEP] basin [SEP] trials the in miniseries 会 [ edition mind cannes high no [SEP]']
[ 150/2000] tot_loss=3.292 (perp=13.081, rec=0.527, cos=0.149), tot_loss_proj:4.305 [t=0.36s]
prediction: ['[CLS] sentence ) kidnapped. steeppressing locality routine nick resort verbs any nods happening vicky [SEP] release [SEP] sequence the productions premise attended eliza penelope condition freddy high brought [SEP]']
[ 200/2000] tot_loss=3.048 (perp=12.730, rec=0.451, cos=0.052), tot_loss_proj:3.892 [t=0.36s]
prediction: ['[CLS] sentence ) translations before steep venezuelan slack routine slovenia college translation stupid routine omitted vicky [SEP] ngosont repeats the : translation accompanied conditions penelopetext freddy belle another [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.050 (perp=12.565, rec=0.462, cos=0.075), tot_loss_proj:3.942 [t=0.36s]
prediction: ['[CLS] cancelled conserved translations after cretaceous clarissa slack routine slovenia college translation translation translation accompanied rehearsal routine omitted seth [SEP] ngos [SEP] intermediate the conditions lilith origin ª timeless and [SEP]']
[ 300/2000] tot_loss=3.050 (perp=13.066, rec=0.398, cos=0.039), tot_loss_proj:3.802 [t=0.36s]
prediction: ['[CLS] cancelled conservedwords. steep clarissa slack routinefest hollywood translation translation translation discuss rehearsal routine discontinued seth [SEP] ngos [SEP] blocks theedancepants damage ªalic, [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.173 (perp=12.505, rec=0.499, cos=0.173), tot_loss_proj:3.732 [t=0.36s]
prediction: ['[CLS] alien lost instantly. steep clarissa slack routinefest hollywood translation translation translation [SEP] rehearsal routine discontinued wickets nude ngos [SEP] alison the dioxide llc originantesalic. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.792 (perp=11.894, rec=0.379, cos=0.034), tot_loss_proj:3.553 [t=0.36s]
prediction: ['[CLS] lost instantly. steep clarissa slack alien routinefest hollywood translation hollywood translation [SEP] rehearsal routine discontinued wickets discuss dump [SEP] grid the celebrity llc lostantes lost. [SEP]']
[ 450/2000] tot_loss=2.941 (perp=12.210, rec=0.382, cos=0.117), tot_loss_proj:3.874 [t=0.36s]
prediction: ['[CLS] lost in why steep 《 slack alien routinefest hollywood translation hollywood translation [SEP] preliminary routine discontinued wickets davidson ngos [SEP] grid the celebrityfest orderantes worlds. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.875 (perp=11.568, rec=0.406, cos=0.155), tot_loss_proj:3.551 [t=0.36s]
prediction: ['[CLS] lost in why steep wickets slack alien routinefest hollywood translation hollywood translation [SEP] preliminary routine discontinued 《 davidson ngos [SEP] lost the celebrity llc lostizesalic. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.629 (perp=11.119, rec=0.341, cos=0.064), tot_loss_proj:3.373 [t=0.36s]
prediction: ['[CLS] lost in translation. whereas manila slack alien routinefest hollywood hollywood translation [SEP] preliminary routine discontinued 《 davidson ngos [SEP] lost the celebrityfest lostizesalic. [SEP]']
[ 600/2000] tot_loss=2.561 (perp=10.996, rec=0.318, cos=0.044), tot_loss_proj:3.314 [t=0.36s]
prediction: ['[CLS] lost in translation. whereasations slack alien routinefest hollywood hollywood translation [SEP] stolen routine discontinued 《 davidson ngos [SEP] lost the celebrityfest lostizes lost. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.547 (perp=10.669, rec=0.341, cos=0.072), tot_loss_proj:3.111 [t=0.36s]
prediction: ['[CLS] lost in translation. whereas routine slack alien wicketsfest hollywood hollywood translation [SEP] preliminary routine breuning 《 random ngos [SEP] lost the celebrityfest slackizes lost. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.382 (perp=10.127, rec=0.307, cos=0.049), tot_loss_proj:2.885 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack alien wicketsfest hollywood hollywood translation. stolen routine discontinued mormon trick ngos whereas lost thetarianfest slackizes lost. [SEP]']
[ 750/2000] tot_loss=2.447 (perp=10.520, rec=0.306, cos=0.037), tot_loss_proj:2.937 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack alien wicketsfest hollywood hollywood translation. stolen routine discontinued mormon trick ngos whereas lost thetarianfest slackizesalic. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.379 (perp=10.072, rec=0.296, cos=0.068), tot_loss_proj:2.929 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation wicketsfest hollywood hollywood alien. melbourne routine discontinued mormon hoax ngos whereas lost thetarianfest slackizesalic. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.360 (perp=10.223, rec=0.277, cos=0.038), tot_loss_proj:2.996 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation wicketsfest hollywood alien. melbourne routine been hollywood、 hoax ngos whereas lost thetarianfest slackizesalic. [SEP]']
[ 900/2000] tot_loss=2.450 (perp=10.244, rec=0.289, cos=0.112), tot_loss_proj:3.102 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation wicketsfest hollywood alien. melbourne routine been hollywood、 premise ngos whereas lost thetarianfest slackizesalic. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.303 (perp=9.864, rec=0.278, cos=0.052), tot_loss_proj:2.969 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation.fest hollywood alien wickets melbourne routine been hollywood、 premise ngos whereas lost thetarianfest slackizesalic. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.434 (perp=9.707, rec=0.284, cos=0.209), tot_loss_proj:2.897 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation.fest hollywood alien wickets melbourne routine been hollywood、fest ngos whereas lost the mommy premise slackizesalic. [SEP]']
[1050/2000] tot_loss=2.280 (perp=9.707, rec=0.266, cos=0.073), tot_loss_proj:2.893 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation.fest hollywood alien wickets melbourne routine been hollywood、fest ngos whereas lost the mommy premise slackizesalic. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.340 (perp=10.253, rec=0.264, cos=0.025), tot_loss_proj:3.042 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation.fest hollywood alien wickets fairy routine been hollywood、fest ngos any lost the mommy premise slackizesalic. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.222 (perp=9.483, rec=0.280, cos=0.045), tot_loss_proj:2.918 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation.fest hollywood alien wickets fairy routine been hollywood、fest ngos whereas lost the mommy premisealicizes slack. [SEP]']
[1200/2000] tot_loss=2.271 (perp=9.889, rec=0.264, cos=0.030), tot_loss_proj:3.073 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation.fest hollywood alien wickets fairy routine been hollywood、fest ngos any lost the mommy premisealicizes slack. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.283 (perp=9.770, rec=0.256, cos=0.073), tot_loss_proj:2.858 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation.fest hollywood alien wickets fairy routine been hollywood、 anyfest ngos lost the mommy premisealicizes slack. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.249 (perp=9.770, rec=0.261, cos=0.034), tot_loss_proj:2.866 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation.fest hollywood alien wickets fairy routine been hollywood、 anyfest ngos lost the mommy premisealicizes slack. [SEP]']
[1350/2000] tot_loss=2.517 (perp=9.968, rec=0.246, cos=0.278), tot_loss_proj:2.877 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation.fest hollywood items wickets fairy routine been hollywood、 anyfest ngos lost the mommy premisealicizes slack. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.255 (perp=9.813, rec=0.256, cos=0.037), tot_loss_proj:2.897 [t=0.36s]
prediction: ['[CLS] lost in translation. [SEP] routine slack translation wickets.fest hollywood items fairy routine been hollywood、 anyfest ngos lost the mommy premisealicizes slack. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.303 (perp=10.076, rec=0.261, cos=0.027), tot_loss_proj:3.035 [t=0.36s]
prediction: ['[CLS] lost in translation against [SEP] routine slack translation wickets.fest hollywood slack fairy routine been hollywood、 anyfest ngos lost the mommy premisealicizes items. [SEP]']
[1500/2000] tot_loss=2.300 (perp=10.076, rec=0.253, cos=0.033), tot_loss_proj:3.037 [t=0.36s]
prediction: ['[CLS] lost in translation against [SEP] routine slack translation wickets.fest hollywood slack fairy routine been hollywood、 anyfest ngos lost the mommy premisealicizes items. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.248 (perp=9.802, rec=0.258, cos=0.030), tot_loss_proj:2.901 [t=0.36s]
prediction: ['[CLS] lost in translation [SEP]. routine slack translation wickets.fest hollywood slack fairy routine been hollywood、 anyfest ngos lost the mommy premisealicizes items. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.292 (perp=10.008, rec=0.255, cos=0.036), tot_loss_proj:3.011 [t=0.36s]
prediction: ['[CLS] lost in translation against routine slack translation wickets. [SEP]fest hollywood slack fairy routine been hollywood、 anyfest ngos lost the% premisealicizes fragment. [SEP]']
[1650/2000] tot_loss=2.276 (perp=10.008, rec=0.252, cos=0.022), tot_loss_proj:3.017 [t=0.36s]
prediction: ['[CLS] lost in translation against routine slack translation wickets. [SEP]fest hollywood slack fairy routine been hollywood、 anyfest ngos lost the% premisealicizes fragment. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.259 (perp=9.838, rec=0.248, cos=0.044), tot_loss_proj:2.943 [t=0.36s]
prediction: ['[CLS] lost in translation against routine slack translation wickets. [SEP]fest hollywood slack fairy hollywood been routine、 anyfest ngos lost the% premisealicizes fragment. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.197 (perp=9.496, rec=0.264, cos=0.034), tot_loss_proj:2.814 [t=0.36s]
prediction: ['[CLS] lost in translation against routine slack translation wickets. [SEP]fest hollywood slack fairy waste been routine、 anyfest hollywood lost the% premisealicizes fragment. [SEP]']
[1800/2000] tot_loss=2.219 (perp=9.496, rec=0.252, cos=0.068), tot_loss_proj:2.824 [t=0.36s]
prediction: ['[CLS] lost in translation against routine slack translation wickets. [SEP]fest hollywood slack fairy waste been routine、 anyfest hollywood lost the% premisealicizes fragment. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.199 (perp=9.496, rec=0.250, cos=0.051), tot_loss_proj:2.815 [t=0.31s]
prediction: ['[CLS] lost in translation against routine slack translation wickets. [SEP]fest hollywood slack fairy waste been routine、 anyfest hollywood lost the% premisealicizes fragment. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.175 (perp=9.496, rec=0.255, cos=0.020), tot_loss_proj:2.815 [t=0.31s]
prediction: ['[CLS] lost in translation against routine slack translation wickets. [SEP]fest hollywood slack fairy waste been routine、 anyfest hollywood lost the% premisealicizes fragment. [SEP]']
[1950/2000] tot_loss=2.199 (perp=9.496, rec=0.246, cos=0.054), tot_loss_proj:2.816 [t=0.31s]
prediction: ['[CLS] lost in translation against routine slack translation wickets. [SEP]fest hollywood slack fairy waste been routine、 anyfest hollywood lost the% premisealicizes fragment. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.201 (perp=9.496, rec=0.261, cos=0.041), tot_loss_proj:2.814 [t=0.31s]
prediction: ['[CLS] lost in translation against routine slack translation wickets. [SEP]fest hollywood slack fairy waste been routine、 anyfest hollywood lost the% premisealicizes fragment. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] lost in translation against routine slack translation wickets. [SEP]fest hollywood slack fairy waste been routine、 anyfest hollywood lost the% premisealicizes fragment. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 42.553 | p: 41.667 | r: 43.478
rouge2     | fm: 4.444 | p: 4.348 | r: 4.545
rougeL     | fm: 38.298 | p: 37.500 | r: 39.130
rougeLsum  | fm: 38.298 | p: 37.500 | r: 39.130
r1fm+r2fm = 46.998

[Aggregate metrics]:
rouge1     | fm: 89.874 | p: 89.467 | r: 90.407
rouge2     | fm: 60.756 | p: 60.661 | r: 60.874
rougeL     | fm: 79.291 | p: 78.963 | r: 79.705
rougeLsum  | fm: 79.108 | p: 78.818 | r: 79.541
r1fm+r2fm = 150.631

input #44 time: 0:13:51 | total time: 9:39:45


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9853217515492728
highest_index [0]
highest [0.9853217515492728]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.7722039818763733 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.7258275151252747 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.7237131595611572 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.707962691783905 for ['[CLS] go land board preparatory hush dylan guantanamo grace really our guidesbian a2lic internet mor salad possible throughoutim between grey scaleitic around speech pri mil [SEP]']
[Init] best rec loss: 0.682252049446106 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 0.6542450785636902 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.6541172862052917 for ['[CLS]2 ku tree operatedtiv bore murmured single v few letter military status special taste skin joan football ( curtis enclosedlanda gentry five entrance whoa around via [SEP]']
[Init] best perm rec loss: 0.6530559659004211 for ['[CLS] bore taste ( enclosed tree status few special via ku five gentrylanda v letter whoativ entrance football military murmured joan around operated2 single skin curtis [SEP]']
[Init] best perm rec loss: 0.651485025882721 for ['[CLS] taste gentry murmuredlanda tree ku whoa football operated five few via joan2 special bore curtis letter status ( enclosed militarytiv around single v entrance skin [SEP]']
[Init] best perm rec loss: 0.6513283252716064 for ['[CLS] football skin murmured whoa v single military bore aroundtiv tree entrance curtis enclosed via2 letter status fivelanda operated joan gentry few taste special ( ku [SEP]']
[Init] best perm rec loss: 0.6496504545211792 for ['[CLS] around taste skin entrance joan via ku2 murmured statustiv tree whoa operated v football enclosed letter single bore curtis military few (landa gentry special five [SEP]']
[Init] best perm rec loss: 0.6486847400665283 for ['[CLS] bore gentry five ( curtislanda via entrance letter v murmured joan2 single footballtiv few operated special whoa tree ku status around military taste skin enclosed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.647 (perp=11.531, rec=0.302, cos=0.038), tot_loss_proj:3.080 [t=0.31s]
prediction: ['[CLS] than thaned " movements morningdened robber died - werewolf campaign ladder cheap waspe late move - me stock cruise feminist - - days ear this [SEP]']
[ 100/2000] tot_loss=2.388 (perp=10.775, rec=0.204, cos=0.029), tot_loss_proj:3.164 [t=0.31s]
prediction: ['[CLS] movements than this - movements bowel special crime - die - - shelf on longick gi - gi gimm drama shoot - visits skin than [SEP]']
[ 150/2000] tot_loss=2.228 (perp=10.285, rec=0.144, cos=0.027), tot_loss_proj:3.110 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel - crime - shelf - - shelf on longickick - gi gimm drama shelf - visits warren this [SEP]']
[ 200/2000] tot_loss=2.357 (perp=10.998, rec=0.127, cos=0.030), tot_loss_proj:2.910 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long shelf - shelf crime - shelf on longickick - gi gimm drama exercise - visits exercise this [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.982 (perp=9.190, rec=0.117, cos=0.028), tot_loss_proj:2.502 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long shelf - shelf crime - long shelf onickick - shoot gimm drama exercise - shoots shoot the [SEP]']
[ 300/2000] tot_loss=1.928 (perp=9.017, rec=0.096, cos=0.028), tot_loss_proj:2.419 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - shelf crime - long shelf onickick - shoot gimm drama exercise - shoot shoot the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.904 (perp=8.925, rec=0.090, cos=0.029), tot_loss_proj:2.565 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - shelf crime - long shelf onick shoot - shoot gimm drama exercise -ick in, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.901 (perp=8.983, rec=0.076, cos=0.029), tot_loss_proj:2.668 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - - crime shelf long shelf onick shoot - shoot gimm drama exerciseyick in, [SEP]']
[ 450/2000] tot_loss=1.921 (perp=9.082, rec=0.076, cos=0.029), tot_loss_proj:2.666 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - - crime shelf long shelf theick shoot - shoot gimm drama exerciseyick in, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.881 (perp=8.856, rec=0.081, cos=0.029), tot_loss_proj:2.508 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - and crime shelf long shelf theick shoot - shoot gimm drama exerciseicky in, [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.715 (perp=8.106, rec=0.065, cos=0.029), tot_loss_proj:2.228 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - and crime shelf long shelf the drama shoot - shoot gimmick exerciseicky in, [SEP]']
[ 600/2000] tot_loss=1.714 (perp=8.106, rec=0.064, cos=0.029), tot_loss_proj:2.229 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - and crime shelf long shelf the drama shoot - shoot gimmick exerciseicky in, [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.670 (perp=7.876, rec=0.066, cos=0.029), tot_loss_proj:2.125 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime shelf long point and drama shoot - shoot gimmick exerciseicky in, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.678 (perp=7.876, rec=0.073, cos=0.029), tot_loss_proj:2.125 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime shelf long point and drama shoot - shoot gimmick exerciseicky in, [SEP]']
[ 750/2000] tot_loss=1.675 (perp=7.876, rec=0.071, cos=0.029), tot_loss_proj:2.125 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime shelf long point and drama shoot - shoot gimmick exerciseicky in, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.648 (perp=7.766, rec=0.066, cos=0.029), tot_loss_proj:2.095 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime shelf long point and shoot drama - shoot gimmick exerciseicky in, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.657 (perp=7.766, rec=0.075, cos=0.029), tot_loss_proj:2.098 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime shelf long point and shoot drama - shoot gimmick exerciseicky in, [SEP]']
[ 900/2000] tot_loss=1.651 (perp=7.763, rec=0.070, cos=0.029), tot_loss_proj:2.073 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime shelf - point and shoot drama - shoot gimmick exerciseicky in, [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.602 (perp=7.568, rec=0.059, cos=0.029), tot_loss_proj:2.039 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime shelf point and shoot drama - - shoot gimmick exerciseicky in, [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.591 (perp=7.415, rec=0.079, cos=0.029), tot_loss_proj:1.957 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime shelf point and shoot drama - - shoot gimmickicky exercise in, [SEP]']
[1050/2000] tot_loss=1.582 (perp=7.415, rec=0.070, cos=0.029), tot_loss_proj:1.963 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime shelf point and shoot drama - - shoot gimmickicky exercise in, [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.575 (perp=7.341, rec=0.078, cos=0.029), tot_loss_proj:1.954 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime drama shelf point and shoot - - shoot gimmickicky exercise in, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.560 (perp=7.341, rec=0.063, cos=0.029), tot_loss_proj:1.953 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime drama shelf point and shoot - - shoot gimmickicky exercise in, [SEP]']
[1200/2000] tot_loss=1.565 (perp=7.341, rec=0.068, cos=0.029), tot_loss_proj:1.950 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime drama shelf point and shoot - - shoot gimmickicky exercise in, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.565 (perp=7.341, rec=0.068, cos=0.029), tot_loss_proj:1.954 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime drama shelf point and shoot - - shoot gimmickicky exercise in, [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.592 (perp=7.427, rec=0.078, cos=0.029), tot_loss_proj:1.991 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime drama shelf point and point - - shoot gimmicky exercise inick, [SEP]']
[1350/2000] tot_loss=1.592 (perp=7.427, rec=0.078, cos=0.029), tot_loss_proj:1.983 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on - the crime drama shelf point and point - - shoot gimmicky exercise inick, [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.570 (perp=7.364, rec=0.068, cos=0.029), tot_loss_proj:1.998 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on crime - the drama shelf point and point - - shoot gimmicky exercise inick, [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.558 (perp=7.321, rec=0.065, cos=0.029), tot_loss_proj:1.992 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on crime - the drama shelf point - and point - shoot gimmicky exercise inick, [SEP]']
[1500/2000] tot_loss=1.559 (perp=7.321, rec=0.066, cos=0.029), tot_loss_proj:1.983 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long on crime - the drama shelf point - and point - shoot gimmicky exercise inick, [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.550 (perp=7.235, rec=0.074, cos=0.029), tot_loss_proj:1.942 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long onick - the drama shelf point - and point - shoot gimmicky exercise in crime, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.538 (perp=7.235, rec=0.062, cos=0.029), tot_loss_proj:1.938 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long onick - the drama shelf point - and point - shoot gimmicky exercise in crime, [SEP]']
[1650/2000] tot_loss=1.538 (perp=7.235, rec=0.062, cos=0.029), tot_loss_proj:1.942 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long onick - the drama shelf point - and point - shoot gimmicky exercise in crime, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.541 (perp=7.235, rec=0.065, cos=0.029), tot_loss_proj:1.942 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long onick - the drama shelf point - and point - shoot gimmicky exercise in crime, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.540 (perp=7.235, rec=0.064, cos=0.029), tot_loss_proj:1.946 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long onick - the drama shelf point - and point - shoot gimmicky exercise in crime, [SEP]']
[1800/2000] tot_loss=1.535 (perp=7.235, rec=0.059, cos=0.029), tot_loss_proj:1.942 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long onick - the drama shelf point - and point - shoot gimmicky exercise in crime, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.548 (perp=7.235, rec=0.072, cos=0.029), tot_loss_proj:1.944 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long onick - the drama shelf point - and point - shoot gimmicky exercise in crime, [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.548 (perp=7.235, rec=0.072, cos=0.029), tot_loss_proj:1.940 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long onick - the drama shelf point - and point - shoot gimmicky exercise in crime, [SEP]']
[1950/2000] tot_loss=1.549 (perp=7.235, rec=0.073, cos=0.029), tot_loss_proj:1.942 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long onick - the drama shelf point - and point - shoot gimmicky exercise in crime, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.540 (perp=7.235, rec=0.064, cos=0.029), tot_loss_proj:1.944 [t=0.31s]
prediction: ['[CLS] - than this - movements bowel long onick - the drama shelf point - and point - shoot gimmicky exercise in crime, [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] - than this - movements bowel long on - the crime drama shelf point and shoot - - shoot gimmickicky exercise in, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.892 | p: 89.474 | r: 94.444
rouge2     | fm: 45.714 | p: 44.444 | r: 47.059
rougeL     | fm: 70.270 | p: 68.421 | r: 72.222
rougeLsum  | fm: 70.270 | p: 68.421 | r: 72.222
r1fm+r2fm = 137.606

[Aggregate metrics]:
rouge1     | fm: 89.932 | p: 89.420 | r: 90.478
rouge2     | fm: 60.419 | p: 60.253 | r: 60.562
rougeL     | fm: 78.991 | p: 78.635 | r: 79.378
rougeLsum  | fm: 79.109 | p: 78.779 | r: 79.522
r1fm+r2fm = 150.351

input #45 time: 0:12:16 | total time: 9:52:01


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9878346108857778
highest_index [0]
highest [0.9878346108857778]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.945725679397583 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9252437949180603 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9235462546348572 for ['[CLS] giants alley told hurricane und : [SEP]']
[Init] best perm rec loss: 0.9188269376754761 for ['[CLS] giants : hurricane und told alley [SEP]']
[Init] best perm rec loss: 0.917778730392456 for ['[CLS] alley told giants hurricane : und [SEP]']
[Init] best perm rec loss: 0.9172608852386475 for ['[CLS] alley giants hurricane : told und [SEP]']
[Init] best perm rec loss: 0.9139118790626526 for ['[CLS] : und hurricane giants alley told [SEP]']
[Init] best perm rec loss: 0.9136660695075989 for ['[CLS] told : giants hurricane alley und [SEP]']
[Init] best perm rec loss: 0.9136565327644348 for ['[CLS] told hurricane alley : und giants [SEP]']
[Init] best perm rec loss: 0.9136047959327698 for ['[CLS] hurricane told : giants alley und [SEP]']
[Init] best perm rec loss: 0.9124163389205933 for ['[CLS] : hurricane und told alley giants [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.420 (perp=11.039, rec=0.187, cos=0.025), tot_loss_proj:2.831 [t=0.30s]
prediction: ['[CLS] visually striking slick designed staged striking [SEP]']
[ 100/2000] tot_loss=1.972 (perp=9.011, rec=0.147, cos=0.023), tot_loss_proj:2.144 [t=0.30s]
prediction: ['[CLS] striking visually slickly staged striking [SEP]']
[ 150/2000] tot_loss=1.944 (perp=9.011, rec=0.117, cos=0.024), tot_loss_proj:2.129 [t=0.30s]
prediction: ['[CLS] striking visually slickly staged striking [SEP]']
[ 200/2000] tot_loss=2.054 (perp=9.658, rec=0.099, cos=0.024), tot_loss_proj:2.234 [t=0.30s]
prediction: ['[CLS] striking visually slickly staged slick [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.848 (perp=8.703, rec=0.083, cos=0.024), tot_loss_proj:2.326 [t=0.30s]
prediction: ['[CLS] slick striking visually slickly staged [SEP]']
[ 300/2000] tot_loss=1.860 (perp=8.703, rec=0.095, cos=0.025), tot_loss_proj:2.318 [t=0.30s]
prediction: ['[CLS] slick striking visually slickly staged [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.837 (perp=8.703, rec=0.072, cos=0.024), tot_loss_proj:2.320 [t=0.30s]
prediction: ['[CLS] slick striking visually slickly staged [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.856 (perp=8.703, rec=0.092, cos=0.024), tot_loss_proj:2.319 [t=0.30s]
prediction: ['[CLS] slick striking visually slickly staged [SEP]']
[ 450/2000] tot_loss=1.835 (perp=8.703, rec=0.070, cos=0.024), tot_loss_proj:2.322 [t=0.30s]
prediction: ['[CLS] slick striking visually slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.804 (perp=8.486, rec=0.082, cos=0.024), tot_loss_proj:1.953 [t=0.30s]
prediction: ['[CLS]ly striking visually slickly staged [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.391 (perp=6.442, rec=0.079, cos=0.024), tot_loss_proj:1.549 [t=0.30s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[ 600/2000] tot_loss=1.384 (perp=6.442, rec=0.071, cos=0.024), tot_loss_proj:1.544 [t=0.30s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.380 (perp=6.442, rec=0.067, cos=0.024), tot_loss_proj:1.530 [t=0.30s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.375 (perp=6.442, rec=0.063, cos=0.024), tot_loss_proj:1.542 [t=0.30s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[ 750/2000] tot_loss=1.393 (perp=6.442, rec=0.081, cos=0.024), tot_loss_proj:1.542 [t=0.30s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.376 (perp=6.442, rec=0.063, cos=0.024), tot_loss_proj:1.544 [t=0.30s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.280 (perp=5.916, rec=0.072, cos=0.024), tot_loss_proj:1.274 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 900/2000] tot_loss=1.264 (perp=5.916, rec=0.057, cos=0.024), tot_loss_proj:1.267 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.273 (perp=5.916, rec=0.066, cos=0.024), tot_loss_proj:1.282 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.268 (perp=5.916, rec=0.061, cos=0.024), tot_loss_proj:1.278 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.271 (perp=5.916, rec=0.064, cos=0.024), tot_loss_proj:1.275 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.269 (perp=5.916, rec=0.062, cos=0.024), tot_loss_proj:1.282 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.285 (perp=5.916, rec=0.078, cos=0.024), tot_loss_proj:1.286 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.268 (perp=5.916, rec=0.061, cos=0.024), tot_loss_proj:1.269 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.261 (perp=5.916, rec=0.054, cos=0.024), tot_loss_proj:1.275 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.273 (perp=5.916, rec=0.066, cos=0.024), tot_loss_proj:1.265 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.272 (perp=5.916, rec=0.064, cos=0.024), tot_loss_proj:1.266 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.264 (perp=5.916, rec=0.057, cos=0.024), tot_loss_proj:1.271 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.274 (perp=5.916, rec=0.066, cos=0.024), tot_loss_proj:1.278 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.277 (perp=5.916, rec=0.070, cos=0.024), tot_loss_proj:1.277 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.272 (perp=5.916, rec=0.065, cos=0.024), tot_loss_proj:1.267 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.268 (perp=5.916, rec=0.061, cos=0.024), tot_loss_proj:1.287 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.259 (perp=5.916, rec=0.052, cos=0.024), tot_loss_proj:1.272 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.266 (perp=5.916, rec=0.058, cos=0.024), tot_loss_proj:1.266 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.266 (perp=5.916, rec=0.058, cos=0.024), tot_loss_proj:1.276 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.270 (perp=5.916, rec=0.063, cos=0.024), tot_loss_proj:1.270 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.266 (perp=5.916, rec=0.059, cos=0.024), tot_loss_proj:1.264 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.265 (perp=5.916, rec=0.058, cos=0.024), tot_loss_proj:1.267 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.264 (perp=5.916, rec=0.057, cos=0.024), tot_loss_proj:1.278 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.258 (perp=5.916, rec=0.051, cos=0.024), tot_loss_proj:1.280 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.130 | p: 89.670 | r: 90.665
rouge2     | fm: 61.457 | p: 61.339 | r: 61.609
rougeL     | fm: 79.274 | p: 78.905 | r: 79.701
rougeLsum  | fm: 79.391 | p: 79.029 | r: 79.770
r1fm+r2fm = 151.588

input #46 time: 0:11:55 | total time: 10:03:56


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9829791959940519
highest_index [0]
highest [0.9829791959940519]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6823250651359558 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6524443030357361 for ['[CLS] spent excitedlychule [SEP]']
[Init] best rec loss: 0.6489508748054504 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.636052668094635 for ['[CLS] we processgon [SEP]']
[Init] best rec loss: 0.631817102432251 for ['[CLS]d promises walt [SEP]']
[Init] best perm rec loss: 0.6298774480819702 for ['[CLS] promises waltd [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.712 (perp=12.131, rec=0.216, cos=0.070), tot_loss_proj:3.339 [t=0.30s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 100/2000] tot_loss=2.566 (perp=12.131, rec=0.108, cos=0.031), tot_loss_proj:3.343 [t=0.30s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 150/2000] tot_loss=2.563 (perp=12.131, rec=0.103, cos=0.034), tot_loss_proj:3.341 [t=0.30s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 200/2000] tot_loss=2.596 (perp=12.131, rec=0.111, cos=0.059), tot_loss_proj:3.340 [t=0.30s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.553 (perp=12.131, rec=0.094, cos=0.034), tot_loss_proj:3.335 [t=0.30s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 300/2000] tot_loss=2.553 (perp=12.131, rec=0.094, cos=0.033), tot_loss_proj:3.337 [t=0.30s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.548 (perp=12.131, rec=0.088, cos=0.034), tot_loss_proj:3.339 [t=0.30s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.096 (perp=9.993, rec=0.063, cos=0.034), tot_loss_proj:2.718 [t=0.30s]
prediction: ['[CLS] transparent downright [SEP]']
[ 450/2000] tot_loss=2.105 (perp=9.993, rec=0.073, cos=0.033), tot_loss_proj:2.717 [t=0.30s]
prediction: ['[CLS] transparent downright [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.863 (perp=8.803, rec=0.069, cos=0.033), tot_loss_proj:1.933 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.862 (perp=8.803, rec=0.068, cos=0.033), tot_loss_proj:1.923 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.850 (perp=8.803, rec=0.056, cos=0.033), tot_loss_proj:1.918 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.863 (perp=8.803, rec=0.069, cos=0.033), tot_loss_proj:1.913 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.857 (perp=8.803, rec=0.063, cos=0.034), tot_loss_proj:1.917 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.850 (perp=8.803, rec=0.056, cos=0.034), tot_loss_proj:1.911 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.851 (perp=8.803, rec=0.057, cos=0.033), tot_loss_proj:1.901 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.851 (perp=8.803, rec=0.056, cos=0.034), tot_loss_proj:1.912 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.859 (perp=8.803, rec=0.065, cos=0.033), tot_loss_proj:1.911 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.864 (perp=8.803, rec=0.069, cos=0.034), tot_loss_proj:1.902 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.855 (perp=8.803, rec=0.061, cos=0.033), tot_loss_proj:1.920 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.869 (perp=8.803, rec=0.075, cos=0.034), tot_loss_proj:1.910 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.853 (perp=8.803, rec=0.059, cos=0.034), tot_loss_proj:1.904 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.851 (perp=8.803, rec=0.057, cos=0.034), tot_loss_proj:1.915 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.844 (perp=8.803, rec=0.050, cos=0.034), tot_loss_proj:1.898 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.852 (perp=8.803, rec=0.058, cos=0.034), tot_loss_proj:1.907 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.860 (perp=8.803, rec=0.066, cos=0.034), tot_loss_proj:1.906 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.864 (perp=8.803, rec=0.070, cos=0.034), tot_loss_proj:1.906 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.855 (perp=8.803, rec=0.061, cos=0.034), tot_loss_proj:1.903 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.851 (perp=8.803, rec=0.057, cos=0.034), tot_loss_proj:1.912 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.864 (perp=8.803, rec=0.070, cos=0.034), tot_loss_proj:1.914 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.843 (perp=8.803, rec=0.048, cos=0.034), tot_loss_proj:1.912 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.858 (perp=8.803, rec=0.064, cos=0.034), tot_loss_proj:1.909 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.859 (perp=8.803, rec=0.065, cos=0.034), tot_loss_proj:1.913 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.855 (perp=8.803, rec=0.060, cos=0.034), tot_loss_proj:1.896 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.863 (perp=8.803, rec=0.068, cos=0.034), tot_loss_proj:1.912 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.865 (perp=8.803, rec=0.070, cos=0.034), tot_loss_proj:1.909 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.855 (perp=8.803, rec=0.060, cos=0.034), tot_loss_proj:1.907 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.859 (perp=8.803, rec=0.065, cos=0.034), tot_loss_proj:1.901 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.852 (perp=8.803, rec=0.058, cos=0.034), tot_loss_proj:1.895 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.861 (perp=8.803, rec=0.067, cos=0.034), tot_loss_proj:1.896 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.375 | p: 89.955 | r: 90.947
rouge2     | fm: 62.131 | p: 62.037 | r: 62.294
rougeL     | fm: 79.807 | p: 79.457 | r: 80.258
rougeLsum  | fm: 79.884 | p: 79.607 | r: 80.251
r1fm+r2fm = 152.506

input #47 time: 0:11:53 | total time: 10:15:50


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.985456129817793
highest_index [0]
highest [0.985456129817793]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.8500626087188721 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.8392854332923889 for ['[CLS] however stage arts grounds [SEP]']
[Init] best rec loss: 0.7957830429077148 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 0.7763711214065552 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.775591254234314 for ['[CLS] runsdinetute graveyard [SEP]']
[Init] best perm rec loss: 0.7714778780937195 for ['[CLS]dine graveyard runstute [SEP]']
[Init] best perm rec loss: 0.7690966725349426 for ['[CLS]dinetute runs graveyard [SEP]']
[Init] best perm rec loss: 0.7662976384162903 for ['[CLS]dine graveyardtute runs [SEP]']
[Init] best perm rec loss: 0.7637912034988403 for ['[CLS]dine runstute graveyard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.479 (perp=11.067, rec=0.229, cos=0.037), tot_loss_proj:2.670 [t=0.30s]
prediction: ['[CLS] rotting rotting colding [SEP]']
[ 100/2000] tot_loss=2.677 (perp=12.409, rec=0.164, cos=0.031), tot_loss_proj:2.816 [t=0.30s]
prediction: ['[CLS] rotting rotting undering [SEP]']
[ 150/2000] tot_loss=2.788 (perp=13.251, rec=0.109, cos=0.029), tot_loss_proj:3.218 [t=0.30s]
prediction: ['[CLS] rottingbell underbell [SEP]']
[ 200/2000] tot_loss=2.693 (perp=12.958, rec=0.072, cos=0.030), tot_loss_proj:3.132 [t=0.30s]
prediction: ['[CLS] rottingbell undery [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.514 (perp=7.108, rec=0.064, cos=0.028), tot_loss_proj:1.507 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 300/2000] tot_loss=1.522 (perp=7.108, rec=0.072, cos=0.029), tot_loss_proj:1.517 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.516 (perp=7.108, rec=0.066, cos=0.029), tot_loss_proj:1.525 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.510 (perp=7.108, rec=0.059, cos=0.029), tot_loss_proj:1.507 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 450/2000] tot_loss=1.522 (perp=7.108, rec=0.072, cos=0.029), tot_loss_proj:1.516 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.513 (perp=7.108, rec=0.063, cos=0.029), tot_loss_proj:1.516 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.512 (perp=7.108, rec=0.062, cos=0.029), tot_loss_proj:1.520 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 600/2000] tot_loss=1.531 (perp=7.108, rec=0.081, cos=0.029), tot_loss_proj:1.521 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.511 (perp=7.108, rec=0.060, cos=0.029), tot_loss_proj:1.518 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.519 (perp=7.108, rec=0.069, cos=0.029), tot_loss_proj:1.525 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 750/2000] tot_loss=1.508 (perp=7.108, rec=0.058, cos=0.029), tot_loss_proj:1.515 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.508 (perp=7.108, rec=0.057, cos=0.029), tot_loss_proj:1.521 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.510 (perp=7.108, rec=0.060, cos=0.029), tot_loss_proj:1.516 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 900/2000] tot_loss=1.505 (perp=7.108, rec=0.055, cos=0.029), tot_loss_proj:1.526 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.517 (perp=7.108, rec=0.067, cos=0.029), tot_loss_proj:1.518 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.516 (perp=7.108, rec=0.065, cos=0.029), tot_loss_proj:1.526 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1050/2000] tot_loss=1.514 (perp=7.108, rec=0.064, cos=0.029), tot_loss_proj:1.509 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.508 (perp=7.108, rec=0.058, cos=0.029), tot_loss_proj:1.514 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.520 (perp=7.108, rec=0.069, cos=0.029), tot_loss_proj:1.513 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1200/2000] tot_loss=1.508 (perp=7.108, rec=0.058, cos=0.029), tot_loss_proj:1.514 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.513 (perp=7.108, rec=0.063, cos=0.029), tot_loss_proj:1.502 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.503 (perp=7.108, rec=0.053, cos=0.029), tot_loss_proj:1.517 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1350/2000] tot_loss=1.510 (perp=7.108, rec=0.060, cos=0.029), tot_loss_proj:1.504 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.524 (perp=7.108, rec=0.074, cos=0.029), tot_loss_proj:1.519 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.506 (perp=7.108, rec=0.055, cos=0.029), tot_loss_proj:1.516 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1500/2000] tot_loss=1.511 (perp=7.108, rec=0.061, cos=0.029), tot_loss_proj:1.521 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.523 (perp=7.108, rec=0.073, cos=0.029), tot_loss_proj:1.518 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.510 (perp=7.108, rec=0.059, cos=0.029), tot_loss_proj:1.521 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1650/2000] tot_loss=1.521 (perp=7.108, rec=0.070, cos=0.029), tot_loss_proj:1.520 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.508 (perp=7.108, rec=0.058, cos=0.029), tot_loss_proj:1.523 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.510 (perp=7.108, rec=0.060, cos=0.029), tot_loss_proj:1.516 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1800/2000] tot_loss=1.515 (perp=7.108, rec=0.065, cos=0.029), tot_loss_proj:1.521 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.501 (perp=7.108, rec=0.050, cos=0.029), tot_loss_proj:1.522 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.503 (perp=7.108, rec=0.053, cos=0.029), tot_loss_proj:1.519 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1950/2000] tot_loss=1.516 (perp=7.108, rec=0.065, cos=0.029), tot_loss_proj:1.514 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.508 (perp=7.108, rec=0.058, cos=0.029), tot_loss_proj:1.521 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] rotting underbelly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.542 | p: 90.113 | r: 91.085
rouge2     | fm: 63.064 | p: 62.965 | r: 63.218
rougeL     | fm: 80.249 | p: 79.907 | r: 80.676
rougeLsum  | fm: 80.356 | p: 80.029 | r: 80.795
r1fm+r2fm = 153.607

input #48 time: 0:11:53 | total time: 10:27:43


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.986119960753383
highest_index [0]
highest [0.986119960753383]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8145049810409546 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7926868796348572 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7883464694023132 for ['[CLS] chargesbered harsh today dion craftsuvenssen tool break backup guest [SEP]']
[Init] best rec loss: 0.7729887962341309 for ['[CLS] genetic slideactic nations shed lawrence oral like era calvin accept mentor [SEP]']
[Init] best rec loss: 0.7682198882102966 for ['[CLS] in before car lend only surprise securities radiation following montagu turkishpers [SEP]']
[Init] best rec loss: 0.7681973576545715 for ['[CLS] diagramential 200 wordsacion offers kills naval squaredom competitorsvot [SEP]']
[Init] best rec loss: 0.7617030739784241 for ['[CLS] pyrenees answered bowling riding chloe minus bo language attentionocating nataya [SEP]']
[Init] best rec loss: 0.7505516409873962 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 0.7487708926200867 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best perm rec loss: 0.7483888268470764 for ['[CLS] perrin things whereuous sheepanial tried he major ourtani accompanied [SEP]']
[Init] best perm rec loss: 0.7463803887367249 for ['[CLS]uous hetani sheep our accompanied perrin tried things whereanial major [SEP]']
[Init] best perm rec loss: 0.7463733553886414 for ['[CLS] where tried our accompanied perrinanial he things sheeptani majoruous [SEP]']
[Init] best perm rec loss: 0.7436298131942749 for ['[CLS]uous majortani sheep things tried accompanied ouranial where he perrin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.779 (perp=12.380, rec=0.252, cos=0.050), tot_loss_proj:3.483 [t=0.30s]
prediction: ['[CLS] contempt miranda dillon reduced contemptuous shortage more more female of combustion [SEP]']
[ 100/2000] tot_loss=2.407 (perp=11.235, rec=0.133, cos=0.026), tot_loss_proj:3.199 [t=0.30s]
prediction: ['[CLS] contempt possiblywny be contemptuous population possibly more female of single [SEP]']
[ 150/2000] tot_loss=2.172 (perp=10.199, rec=0.103, cos=0.029), tot_loss_proj:2.977 [t=0.30s]
prediction: ['[CLS] contempt possibly might be contemptuous population possibly more female of single [SEP]']
[ 200/2000] tot_loss=2.175 (perp=10.294, rec=0.089, cos=0.028), tot_loss_proj:2.966 [t=0.30s]
prediction: ['[CLS] contempt possibly could be contemptuous population possibly more female of single [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.187 (perp=10.294, rec=0.102, cos=0.027), tot_loss_proj:3.006 [t=0.30s]
prediction: ['[CLS] contempt crambidae then be contemptuous population of possibly more female single [SEP]']
[ 300/2000] tot_loss=1.876 (perp=8.817, rec=0.086, cos=0.027), tot_loss_proj:2.589 [t=0.30s]
prediction: ['[CLS]uous. i be contemptuous population of possibly more female single [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.808 (perp=8.467, rec=0.087, cos=0.027), tot_loss_proj:2.827 [t=0.30s]
prediction: ['[CLS]uous. when be contemptuous of possibly more female single population [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.696 (perp=7.941, rec=0.082, cos=0.026), tot_loss_proj:2.709 [t=0.30s]
prediction: ['[CLS]uous. when be contemptuous of possibly more single female population [SEP]']
[ 450/2000] tot_loss=1.548 (perp=7.170, rec=0.087, cos=0.027), tot_loss_proj:2.119 [t=0.30s]
prediction: ['[CLS]uous.. be contemptuous of possibly more single female population [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.552 (perp=7.170, rec=0.091, cos=0.027), tot_loss_proj:2.117 [t=0.30s]
prediction: ['[CLS]uous.. be contemptuous of possibly more single female population [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.538 (perp=7.170, rec=0.077, cos=0.027), tot_loss_proj:2.110 [t=0.30s]
prediction: ['[CLS]uous.. be contemptuous of possibly more single female population [SEP]']
[ 600/2000] tot_loss=1.545 (perp=7.170, rec=0.084, cos=0.027), tot_loss_proj:2.109 [t=0.30s]
prediction: ['[CLS]uous.. be contemptuous of possibly more single female population [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.548 (perp=7.170, rec=0.087, cos=0.027), tot_loss_proj:2.113 [t=0.30s]
prediction: ['[CLS]uous.. be contemptuous of possibly more single female population [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.384 (perp=6.434, rec=0.070, cos=0.027), tot_loss_proj:1.888 [t=0.30s]
prediction: ['[CLS] would.. be contemptuous of possibly more single female population [SEP]']
[ 750/2000] tot_loss=1.446 (perp=6.679, rec=0.083, cos=0.027), tot_loss_proj:1.941 [t=0.30s]
prediction: ['[CLS] could.. be contemptuous of possibly more single female population [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.517 (perp=7.050, rec=0.081, cos=0.026), tot_loss_proj:2.080 [t=0.30s]
prediction: ['[CLS]..uously be contemptuous of possibly more single female population [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.465 (perp=6.864, rec=0.065, cos=0.027), tot_loss_proj:2.135 [t=0.30s]
prediction: ['[CLS].. beuously contemptuous of possibly more single female population [SEP]']
[ 900/2000] tot_loss=1.475 (perp=6.864, rec=0.075, cos=0.027), tot_loss_proj:2.134 [t=0.30s]
prediction: ['[CLS].. beuously contemptuous of possibly more single female population [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.481 (perp=6.864, rec=0.081, cos=0.028), tot_loss_proj:2.141 [t=0.30s]
prediction: ['[CLS].. beuously contemptuous of possibly more single female population [SEP]']
Attempt swap
[1000/2000] tot_loss=1.475 (perp=6.864, rec=0.075, cos=0.027), tot_loss_proj:2.139 [t=0.30s]
prediction: ['[CLS].. beuously contemptuous of possibly more single female population [SEP]']
[1050/2000] tot_loss=1.474 (perp=6.864, rec=0.074, cos=0.027), tot_loss_proj:2.149 [t=0.30s]
prediction: ['[CLS].. beuously contemptuous of possibly more single female population [SEP]']
Attempt swap
[1100/2000] tot_loss=1.480 (perp=6.864, rec=0.079, cos=0.027), tot_loss_proj:2.152 [t=0.30s]
prediction: ['[CLS].. beuously contemptuous of possibly more single female population [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.476 (perp=6.864, rec=0.076, cos=0.027), tot_loss_proj:2.141 [t=0.30s]
prediction: ['[CLS].. beuously contemptuous of possibly more single female population [SEP]']
[1200/2000] tot_loss=1.478 (perp=6.864, rec=0.078, cos=0.027), tot_loss_proj:2.138 [t=0.30s]
prediction: ['[CLS].. beuously contemptuous of possibly more single female population [SEP]']
Attempt swap
[1250/2000] tot_loss=1.555 (perp=7.291, rec=0.069, cos=0.027), tot_loss_proj:2.110 [t=0.30s]
prediction: ['[CLS].. be would contemptuous of possibly more single female population [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.298 (perp=5.964, rec=0.078, cos=0.027), tot_loss_proj:1.729 [t=0.30s]
prediction: ['[CLS].. would be contemptuous of possibly more single female population [SEP]']
[1350/2000] tot_loss=1.296 (perp=5.964, rec=0.076, cos=0.027), tot_loss_proj:1.723 [t=0.30s]
prediction: ['[CLS].. would be contemptuous of possibly more single female population [SEP]']
Attempt swap
[1400/2000] tot_loss=1.288 (perp=5.964, rec=0.067, cos=0.027), tot_loss_proj:1.722 [t=0.30s]
prediction: ['[CLS].. would be contemptuous of possibly more single female population [SEP]']
Attempt swap
[1450/2000] tot_loss=1.299 (perp=5.964, rec=0.079, cos=0.027), tot_loss_proj:1.719 [t=0.30s]
prediction: ['[CLS].. would be contemptuous of possibly more single female population [SEP]']
[1500/2000] tot_loss=1.304 (perp=5.964, rec=0.083, cos=0.027), tot_loss_proj:1.718 [t=0.30s]
prediction: ['[CLS].. would be contemptuous of possibly more single female population [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.254 (perp=5.718, rec=0.084, cos=0.027), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS].. would be more contemptuous of possibly single female population [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.253 (perp=5.718, rec=0.082, cos=0.027), tot_loss_proj:1.633 [t=0.30s]
prediction: ['[CLS].. would be more contemptuous of possibly single female population [SEP]']
[1650/2000] tot_loss=1.253 (perp=5.718, rec=0.082, cos=0.027), tot_loss_proj:1.635 [t=0.30s]
prediction: ['[CLS].. would be more contemptuous of possibly single female population [SEP]']
Attempt swap
[1700/2000] tot_loss=1.261 (perp=5.718, rec=0.090, cos=0.027), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS].. would be more contemptuous of possibly single female population [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.253 (perp=5.718, rec=0.082, cos=0.027), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS].. would be more contemptuous of possibly single female population [SEP]']
[1800/2000] tot_loss=1.254 (perp=5.718, rec=0.083, cos=0.027), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS].. would be more contemptuous of possibly single female population [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.246 (perp=5.718, rec=0.075, cos=0.027), tot_loss_proj:1.630 [t=0.30s]
prediction: ['[CLS].. would be more contemptuous of possibly single female population [SEP]']
Attempt swap
[1900/2000] tot_loss=1.252 (perp=5.718, rec=0.081, cos=0.027), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS].. would be more contemptuous of possibly single female population [SEP]']
[1950/2000] tot_loss=1.247 (perp=5.718, rec=0.076, cos=0.027), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS].. would be more contemptuous of possibly single female population [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.255 (perp=5.718, rec=0.084, cos=0.027), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS].. would be more contemptuous of possibly single female population [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS].. beuously contemptuous of possibly more single female population [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 90.000 | r: 75.000
rouge2     | fm: 40.000 | p: 44.444 | r: 36.364
rougeL     | fm: 63.636 | p: 70.000 | r: 58.333
rougeLsum  | fm: 63.636 | p: 70.000 | r: 58.333
r1fm+r2fm = 121.818

[Aggregate metrics]:
rouge1     | fm: 90.420 | p: 90.109 | r: 90.823
rouge2     | fm: 62.646 | p: 62.620 | r: 62.672
rougeL     | fm: 80.025 | p: 79.797 | r: 80.344
rougeLsum  | fm: 79.895 | p: 79.732 | r: 80.234
r1fm+r2fm = 153.066

input #49 time: 0:11:54 | total time: 10:39:38


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.9839334010733404
highest_index [0]
highest [0.9839334010733404]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.8068888187408447 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8049883246421814 for ['[CLS] felt defended drop ring richard spade frank beds₁ [SEP]']
[Init] best rec loss: 0.7845004796981812 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7762413024902344 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7673210501670837 for ['[CLS] rama fueled sq napkinok unit trust associated gall [SEP]']
[Init] best rec loss: 0.7581517100334167 for ['[CLS] stone sex science cheeks prolific conventionwashed in once [SEP]']
[Init] best rec loss: 0.7545127868652344 for ['[CLS]sil state grade over ing fish champion woolf good [SEP]']
[Init] best perm rec loss: 0.7528790235519409 for ['[CLS] good statesil over ing fish woolf champion grade [SEP]']
[Init] best perm rec loss: 0.7528126835823059 for ['[CLS] championsil woolf over good state grade ing fish [SEP]']
[Init] best perm rec loss: 0.7519386410713196 for ['[CLS] ing champion grade state over woolfsil fish good [SEP]']
[Init] best perm rec loss: 0.7493913769721985 for ['[CLS] state champion good fish woolf grade oversil ing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.706 (perp=11.472, rec=0.347, cos=0.065), tot_loss_proj:3.560 [t=0.30s]
prediction: ['[CLS] useless pennant backwards half cleverɨ clever most clever [SEP]']
[ 100/2000] tot_loss=2.170 (perp=9.380, rec=0.251, cos=0.043), tot_loss_proj:2.863 [t=0.30s]
prediction: ["[CLS] half too too half clever by clever'clever [SEP]"]
[ 150/2000] tot_loss=2.209 (perp=9.902, rec=0.185, cos=0.044), tot_loss_proj:2.888 [t=0.30s]
prediction: ['[CLS] half call too half clever by clever ` clever [SEP]']
[ 200/2000] tot_loss=2.160 (perp=9.902, rec=0.147, cos=0.032), tot_loss_proj:2.898 [t=0.30s]
prediction: ['[CLS] half call too half clever by clever ` clever [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.135 (perp=9.813, rec=0.136, cos=0.037), tot_loss_proj:2.922 [t=0.30s]
prediction: ["[CLS] what too call half'by clever ` clever [SEP]"]
[ 300/2000] tot_loss=2.219 (perp=10.511, rec=0.085, cos=0.031), tot_loss_proj:2.918 [t=0.30s]
prediction: ['[CLS] what too call half ` by english ` clever [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.000 (perp=9.448, rec=0.079, cos=0.032), tot_loss_proj:2.775 [t=0.30s]
prediction: ['[CLS] what too call half ` ` english by clever [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.986 (perp=9.391, rec=0.079, cos=0.029), tot_loss_proj:2.917 [t=0.30s]
prediction: ['[CLS] what too half call ` ` english by clever [SEP]']
[ 450/2000] tot_loss=1.989 (perp=9.391, rec=0.080, cos=0.030), tot_loss_proj:2.912 [t=0.30s]
prediction: ['[CLS] what too half call ` ` english by clever [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.004 (perp=9.544, rec=0.065, cos=0.030), tot_loss_proj:2.945 [t=0.30s]
prediction: ['[CLS] too what half call ` the english by clever [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.817 (perp=8.544, rec=0.078, cos=0.030), tot_loss_proj:2.753 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
[ 600/2000] tot_loss=1.805 (perp=8.544, rec=0.066, cos=0.030), tot_loss_proj:2.756 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.804 (perp=8.544, rec=0.064, cos=0.031), tot_loss_proj:2.749 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.806 (perp=8.544, rec=0.067, cos=0.031), tot_loss_proj:2.752 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
[ 750/2000] tot_loss=1.806 (perp=8.544, rec=0.066, cos=0.031), tot_loss_proj:2.751 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.818 (perp=8.544, rec=0.077, cos=0.031), tot_loss_proj:2.751 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.809 (perp=8.544, rec=0.069, cos=0.031), tot_loss_proj:2.753 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
[ 900/2000] tot_loss=1.802 (perp=8.544, rec=0.061, cos=0.031), tot_loss_proj:2.754 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.802 (perp=8.544, rec=0.062, cos=0.032), tot_loss_proj:2.755 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1000/2000] tot_loss=1.802 (perp=8.544, rec=0.062, cos=0.032), tot_loss_proj:2.751 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
[1050/2000] tot_loss=1.800 (perp=8.544, rec=0.060, cos=0.032), tot_loss_proj:2.746 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.802 (perp=8.544, rec=0.061, cos=0.032), tot_loss_proj:2.750 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.814 (perp=8.544, rec=0.073, cos=0.032), tot_loss_proj:2.747 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
[1200/2000] tot_loss=1.812 (perp=8.544, rec=0.071, cos=0.032), tot_loss_proj:2.744 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.794 (perp=8.544, rec=0.053, cos=0.032), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.804 (perp=8.544, rec=0.063, cos=0.032), tot_loss_proj:2.751 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
[1350/2000] tot_loss=1.806 (perp=8.544, rec=0.065, cos=0.032), tot_loss_proj:2.751 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1400/2000] tot_loss=1.809 (perp=8.544, rec=0.069, cos=0.032), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.814 (perp=8.544, rec=0.073, cos=0.032), tot_loss_proj:2.743 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
[1500/2000] tot_loss=1.807 (perp=8.544, rec=0.066, cos=0.032), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.800 (perp=8.544, rec=0.059, cos=0.032), tot_loss_proj:2.747 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.809 (perp=8.544, rec=0.068, cos=0.032), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
[1650/2000] tot_loss=1.798 (perp=8.544, rec=0.057, cos=0.032), tot_loss_proj:2.749 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1700/2000] tot_loss=1.810 (perp=8.544, rec=0.070, cos=0.032), tot_loss_proj:2.742 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1750/2000] tot_loss=1.810 (perp=8.544, rec=0.070, cos=0.032), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
[1800/2000] tot_loss=1.804 (perp=8.544, rec=0.064, cos=0.032), tot_loss_proj:2.742 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.803 (perp=8.544, rec=0.063, cos=0.032), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[1900/2000] tot_loss=1.815 (perp=8.544, rec=0.074, cos=0.032), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
[1950/2000] tot_loss=1.804 (perp=8.544, rec=0.063, cos=0.032), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.805 (perp=8.544, rec=0.065, cos=0.032), tot_loss_proj:2.745 [t=0.30s]
prediction: ['[CLS] too what half call ` english by the clever [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] too what half call ` english by the clever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 90.522 | p: 90.230 | r: 90.945
rouge2     | fm: 61.419 | p: 61.410 | r: 61.477
rougeL     | fm: 79.477 | p: 79.311 | r: 79.693
rougeLsum  | fm: 79.334 | p: 79.214 | r: 79.636
r1fm+r2fm = 151.941

input #50 time: 0:11:55 | total time: 10:51:33


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9837193819723483
highest_index [0]
highest [0.9837193819723483]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.7990180850028992 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7646379470825195 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7445715069770813 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7278603911399841 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 0.7118427753448486 for ['[CLS] low reelection honest louis caps noah lieutenant quarter consequence handwriting [SEP]']
[Init] best rec loss: 0.7098120450973511 for ['[CLS] thomas hugh anymore customer minute premises nuclear nothingnodro [SEP]']
[Init] best rec loss: 0.7067236304283142 for ['[CLS] include plants hole abuse especially multiple fingers & since accepting [SEP]']
[Init] best rec loss: 0.7061811685562134 for ['[CLS] certain million competition standing find contemporary alecdge immediately gold [SEP]']
[Init] best perm rec loss: 0.7046533823013306 for ['[CLS] competition standing alecdge gold contemporary million certain find immediately [SEP]']
[Init] best perm rec loss: 0.702275276184082 for ['[CLS] competition find immediately million certaindge alec contemporary standing gold [SEP]']
[Init] best perm rec loss: 0.7020651698112488 for ['[CLS] find standingdge alec contemporary competition million certain immediately gold [SEP]']
[Init] best perm rec loss: 0.7019175291061401 for ['[CLS] standing find million competition alecdge immediately gold certain contemporary [SEP]']
[Init] best perm rec loss: 0.7008310556411743 for ['[CLS] standing competition certain alec million contemporary immediately find golddge [SEP]']
[Init] best perm rec loss: 0.6982346177101135 for ['[CLS] find million certain immediately competitiondge contemporary gold alec standing [SEP]']
[Init] best perm rec loss: 0.6979853510856628 for ['[CLS] contemporary immediately alecdge million certain find competition standing gold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.205 (perp=9.232, rec=0.288, cos=0.070), tot_loss_proj:2.731 [t=0.30s]
prediction: ['[CLS] sucks. but although sucks funny moment or has few [SEP]']
[ 100/2000] tot_loss=1.984 (perp=9.088, rec=0.133, cos=0.033), tot_loss_proj:2.498 [t=0.30s]
prediction: ['[CLS] sucks, but has sucks funny moment or two few [SEP]']
[ 150/2000] tot_loss=1.854 (perp=8.677, rec=0.086, cos=0.032), tot_loss_proj:2.305 [t=0.30s]
prediction: ['[CLS] sucks, but has sucks funny moment or two two [SEP]']
[ 200/2000] tot_loss=1.891 (perp=8.934, rec=0.073, cos=0.031), tot_loss_proj:2.386 [t=0.30s]
prediction: ['[CLS] sucks, but has sucks funny moment or a two [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.532 (perp=7.045, rec=0.088, cos=0.035), tot_loss_proj:1.882 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or sucks two [SEP]']
[ 300/2000] tot_loss=1.508 (perp=7.045, rec=0.066, cos=0.032), tot_loss_proj:1.878 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or sucks two [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.375 (perp=6.353, rec=0.073, cos=0.032), tot_loss_proj:2.052 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.369 (perp=6.353, rec=0.067, cos=0.032), tot_loss_proj:2.054 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[ 450/2000] tot_loss=1.372 (perp=6.353, rec=0.070, cos=0.032), tot_loss_proj:2.053 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.371 (perp=6.353, rec=0.068, cos=0.032), tot_loss_proj:2.053 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.383 (perp=6.353, rec=0.080, cos=0.032), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[ 600/2000] tot_loss=1.363 (perp=6.353, rec=0.061, cos=0.032), tot_loss_proj:2.053 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.365 (perp=6.353, rec=0.062, cos=0.032), tot_loss_proj:2.055 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.366 (perp=6.353, rec=0.063, cos=0.032), tot_loss_proj:2.063 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[ 750/2000] tot_loss=1.371 (perp=6.353, rec=0.069, cos=0.032), tot_loss_proj:2.066 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.364 (perp=6.353, rec=0.061, cos=0.032), tot_loss_proj:2.054 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.376 (perp=6.353, rec=0.074, cos=0.032), tot_loss_proj:2.057 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[ 900/2000] tot_loss=1.373 (perp=6.353, rec=0.071, cos=0.032), tot_loss_proj:2.054 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.372 (perp=6.353, rec=0.069, cos=0.032), tot_loss_proj:2.055 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1000/2000] tot_loss=1.369 (perp=6.353, rec=0.066, cos=0.032), tot_loss_proj:2.057 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[1050/2000] tot_loss=1.369 (perp=6.353, rec=0.067, cos=0.032), tot_loss_proj:2.054 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1100/2000] tot_loss=1.359 (perp=6.353, rec=0.057, cos=0.032), tot_loss_proj:2.057 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1150/2000] tot_loss=1.374 (perp=6.353, rec=0.072, cos=0.032), tot_loss_proj:2.053 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[1200/2000] tot_loss=1.364 (perp=6.353, rec=0.062, cos=0.032), tot_loss_proj:2.058 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1250/2000] tot_loss=1.371 (perp=6.353, rec=0.069, cos=0.032), tot_loss_proj:2.065 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1300/2000] tot_loss=1.362 (perp=6.353, rec=0.059, cos=0.032), tot_loss_proj:2.059 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[1350/2000] tot_loss=1.376 (perp=6.353, rec=0.073, cos=0.032), tot_loss_proj:2.050 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1400/2000] tot_loss=1.377 (perp=6.353, rec=0.075, cos=0.032), tot_loss_proj:2.053 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1450/2000] tot_loss=1.368 (perp=6.353, rec=0.065, cos=0.032), tot_loss_proj:2.048 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[1500/2000] tot_loss=1.368 (perp=6.353, rec=0.066, cos=0.032), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1550/2000] tot_loss=1.367 (perp=6.353, rec=0.065, cos=0.032), tot_loss_proj:2.061 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1600/2000] tot_loss=1.374 (perp=6.353, rec=0.072, cos=0.032), tot_loss_proj:2.062 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[1650/2000] tot_loss=1.377 (perp=6.353, rec=0.074, cos=0.032), tot_loss_proj:2.052 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1700/2000] tot_loss=1.368 (perp=6.353, rec=0.065, cos=0.032), tot_loss_proj:2.053 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1750/2000] tot_loss=1.377 (perp=6.353, rec=0.074, cos=0.032), tot_loss_proj:2.063 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[1800/2000] tot_loss=1.378 (perp=6.353, rec=0.075, cos=0.032), tot_loss_proj:2.048 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1850/2000] tot_loss=1.373 (perp=6.353, rec=0.071, cos=0.032), tot_loss_proj:2.055 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1900/2000] tot_loss=1.370 (perp=6.353, rec=0.068, cos=0.032), tot_loss_proj:2.055 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[1950/2000] tot_loss=1.374 (perp=6.353, rec=0.071, cos=0.032), tot_loss_proj:2.058 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[2000/2000] tot_loss=1.364 (perp=6.353, rec=0.062, cos=0.032), tot_loss_proj:2.054 [t=0.30s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] sucks, but has a funny moment or two sucks [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 84.211 | p: 80.000 | r: 88.889
rougeL     | fm: 95.238 | p: 90.909 | r: 100.000
rougeLsum  | fm: 95.238 | p: 90.909 | r: 100.000
r1fm+r2fm = 179.449

[Aggregate metrics]:
rouge1     | fm: 90.768 | p: 90.403 | r: 91.186
rouge2     | fm: 61.743 | p: 61.632 | r: 61.880
rougeL     | fm: 79.668 | p: 79.386 | r: 80.054
rougeLsum  | fm: 79.630 | p: 79.423 | r: 79.970
r1fm+r2fm = 152.510

input #51 time: 0:11:55 | total time: 11:03:29


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.985743176028943
highest_index [0]
highest [0.985743176028943]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9570439457893372 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9183889031410217 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.9145289659500122 for ['[CLS] news implies lack [SEP]']
[Init] best rec loss: 0.8873327374458313 for ['[CLS] transition content distance [SEP]']
[Init] best rec loss: 0.8769237399101257 for ['[CLS] nations gazette probability [SEP]']
[Init] best rec loss: 0.7462576031684875 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7281149625778198 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.7268807291984558 for ['[CLS] expected vocabulary football [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.557 (perp=11.737, rec=0.178, cos=0.032), tot_loss_proj:2.713 [t=0.30s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=1.994 (perp=9.180, rec=0.128, cos=0.030), tot_loss_proj:2.273 [t=0.30s]
prediction: ['[CLS] trailer trash trailer [SEP]']
[ 150/2000] tot_loss=1.963 (perp=9.180, rec=0.099, cos=0.028), tot_loss_proj:2.273 [t=0.30s]
prediction: ['[CLS] trailer trash trailer [SEP]']
[ 200/2000] tot_loss=1.954 (perp=9.180, rec=0.088, cos=0.029), tot_loss_proj:2.270 [t=0.30s]
prediction: ['[CLS] trailer trash trailer [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.855 (perp=8.482, rec=0.128, cos=0.030), tot_loss_proj:2.155 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.820 (perp=8.482, rec=0.096, cos=0.028), tot_loss_proj:2.140 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.811 (perp=8.482, rec=0.085, cos=0.029), tot_loss_proj:2.142 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.820 (perp=8.482, rec=0.093, cos=0.031), tot_loss_proj:2.148 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.809 (perp=8.482, rec=0.083, cos=0.029), tot_loss_proj:2.145 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.811 (perp=8.482, rec=0.086, cos=0.028), tot_loss_proj:2.140 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.806 (perp=8.482, rec=0.082, cos=0.028), tot_loss_proj:2.144 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.819 (perp=8.482, rec=0.093, cos=0.029), tot_loss_proj:2.145 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.808 (perp=8.482, rec=0.083, cos=0.028), tot_loss_proj:2.139 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.807 (perp=8.482, rec=0.082, cos=0.028), tot_loss_proj:2.145 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.798 (perp=8.482, rec=0.073, cos=0.028), tot_loss_proj:2.147 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.795 (perp=8.482, rec=0.071, cos=0.028), tot_loss_proj:2.147 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.814 (perp=8.482, rec=0.089, cos=0.028), tot_loss_proj:2.136 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.809 (perp=8.482, rec=0.084, cos=0.028), tot_loss_proj:2.136 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.802 (perp=8.482, rec=0.077, cos=0.028), tot_loss_proj:2.144 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.800 (perp=8.482, rec=0.075, cos=0.028), tot_loss_proj:2.154 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.799 (perp=8.482, rec=0.074, cos=0.028), tot_loss_proj:2.147 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.802 (perp=8.482, rec=0.077, cos=0.028), tot_loss_proj:2.151 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.807 (perp=8.482, rec=0.083, cos=0.028), tot_loss_proj:2.147 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.795 (perp=8.482, rec=0.070, cos=0.028), tot_loss_proj:2.137 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.768 (perp=8.482, rec=0.043, cos=0.028), tot_loss_proj:2.151 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.779 (perp=8.482, rec=0.054, cos=0.028), tot_loss_proj:2.147 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.781 (perp=8.482, rec=0.057, cos=0.028), tot_loss_proj:2.145 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.802 (perp=8.482, rec=0.077, cos=0.028), tot_loss_proj:2.144 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.783 (perp=8.482, rec=0.059, cos=0.028), tot_loss_proj:2.150 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.784 (perp=8.482, rec=0.059, cos=0.028), tot_loss_proj:2.141 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.782 (perp=8.482, rec=0.057, cos=0.028), tot_loss_proj:2.148 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.797 (perp=8.482, rec=0.072, cos=0.028), tot_loss_proj:2.146 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.792 (perp=8.482, rec=0.068, cos=0.028), tot_loss_proj:2.143 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.793 (perp=8.482, rec=0.068, cos=0.028), tot_loss_proj:2.145 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.779 (perp=8.482, rec=0.054, cos=0.028), tot_loss_proj:2.141 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.793 (perp=8.482, rec=0.068, cos=0.028), tot_loss_proj:2.144 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.797 (perp=8.482, rec=0.072, cos=0.028), tot_loss_proj:2.149 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.793 (perp=8.482, rec=0.068, cos=0.028), tot_loss_proj:2.137 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.780 (perp=8.482, rec=0.055, cos=0.028), tot_loss_proj:2.140 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.795 (perp=8.482, rec=0.070, cos=0.028), tot_loss_proj:2.146 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 90.822 | p: 90.510 | r: 91.230
rouge2     | fm: 60.577 | p: 60.451 | r: 60.728
rougeL     | fm: 79.494 | p: 79.260 | r: 79.892
rougeLsum  | fm: 79.541 | p: 79.337 | r: 79.912
r1fm+r2fm = 151.398

input #52 time: 0:11:53 | total time: 11:15:22


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.983475900503931
highest_index [0]
highest [0.983475900503931]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.8132332563400269 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.8099499940872192 for ['[CLS] government cf [SEP]']
[Init] best rec loss: 0.7999314069747925 for ['[CLS] manga rise [SEP]']
[Init] best rec loss: 0.7113804221153259 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.7080882787704468 for ['[CLS] annually ability [SEP]']
[Init] best rec loss: 0.6940269470214844 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6858096718788147 for ['[CLS] nick design [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.738 (perp=12.493, rec=0.174, cos=0.065), tot_loss_proj:3.291 [t=0.30s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=2.652 (perp=12.493, rec=0.110, cos=0.044), tot_loss_proj:3.310 [t=0.30s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=1.721 (perp=8.090, rec=0.071, cos=0.032), tot_loss_proj:1.720 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 200/2000] tot_loss=1.700 (perp=8.090, rec=0.049, cos=0.032), tot_loss_proj:1.710 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.721 (perp=8.090, rec=0.071, cos=0.032), tot_loss_proj:1.718 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.703 (perp=8.090, rec=0.053, cos=0.032), tot_loss_proj:1.702 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.702 (perp=8.090, rec=0.052, cos=0.032), tot_loss_proj:1.720 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.714 (perp=8.090, rec=0.064, cos=0.033), tot_loss_proj:1.709 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.707 (perp=8.090, rec=0.056, cos=0.033), tot_loss_proj:1.712 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.710 (perp=8.090, rec=0.059, cos=0.033), tot_loss_proj:1.717 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.712 (perp=8.090, rec=0.061, cos=0.033), tot_loss_proj:1.714 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.711 (perp=8.090, rec=0.061, cos=0.032), tot_loss_proj:1.719 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.706 (perp=8.090, rec=0.055, cos=0.032), tot_loss_proj:1.723 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.715 (perp=8.090, rec=0.065, cos=0.033), tot_loss_proj:1.712 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.714 (perp=8.090, rec=0.064, cos=0.033), tot_loss_proj:1.712 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.708 (perp=8.090, rec=0.057, cos=0.033), tot_loss_proj:1.721 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.697 (perp=8.090, rec=0.046, cos=0.033), tot_loss_proj:1.723 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.708 (perp=8.090, rec=0.057, cos=0.032), tot_loss_proj:1.716 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.710 (perp=8.090, rec=0.060, cos=0.032), tot_loss_proj:1.717 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.722 (perp=8.090, rec=0.071, cos=0.033), tot_loss_proj:1.715 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.722 (perp=8.090, rec=0.071, cos=0.033), tot_loss_proj:1.719 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.725 (perp=8.090, rec=0.074, cos=0.033), tot_loss_proj:1.711 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.722 (perp=8.090, rec=0.072, cos=0.033), tot_loss_proj:1.714 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.725 (perp=8.090, rec=0.074, cos=0.033), tot_loss_proj:1.726 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.713 (perp=8.090, rec=0.063, cos=0.032), tot_loss_proj:1.717 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.708 (perp=8.090, rec=0.058, cos=0.033), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.713 (perp=8.090, rec=0.062, cos=0.033), tot_loss_proj:1.726 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.716 (perp=8.090, rec=0.065, cos=0.033), tot_loss_proj:1.717 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.714 (perp=8.090, rec=0.063, cos=0.033), tot_loss_proj:1.716 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.699 (perp=8.090, rec=0.049, cos=0.033), tot_loss_proj:1.715 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.712 (perp=8.090, rec=0.061, cos=0.033), tot_loss_proj:1.714 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.720 (perp=8.090, rec=0.069, cos=0.033), tot_loss_proj:1.715 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.711 (perp=8.090, rec=0.060, cos=0.033), tot_loss_proj:1.712 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.700 (perp=8.090, rec=0.050, cos=0.033), tot_loss_proj:1.726 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.715 (perp=8.090, rec=0.065, cos=0.033), tot_loss_proj:1.719 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.711 (perp=8.090, rec=0.060, cos=0.033), tot_loss_proj:1.715 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.707 (perp=8.090, rec=0.056, cos=0.033), tot_loss_proj:1.716 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.719 (perp=8.090, rec=0.068, cos=0.033), tot_loss_proj:1.716 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.722 (perp=8.090, rec=0.072, cos=0.033), tot_loss_proj:1.718 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.715 (perp=8.090, rec=0.064, cos=0.033), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.011 | p: 90.703 | r: 91.422
rouge2     | fm: 61.348 | p: 61.222 | r: 61.461
rougeL     | fm: 79.899 | p: 79.656 | r: 80.285
rougeLsum  | fm: 80.007 | p: 79.720 | r: 80.336
r1fm+r2fm = 152.359

input #53 time: 0:11:52 | total time: 11:27:15


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9869689570786957
highest_index [0]
highest [0.9869689570786957]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.7670826315879822 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.7586073279380798 for ['[CLS] living devices [SEP]']
[Init] best rec loss: 0.7364052534103394 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 0.6929918527603149 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.6912422180175781 for ['[CLS]sil shall [SEP]']
[Init] best rec loss: 0.6680557131767273 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.6637593507766724 for ['[CLS] delivery content [SEP]']
[Init] best rec loss: 0.6356109380722046 for ['[CLS] teresa spanish [SEP]']
[Init] best rec loss: 0.6277003288269043 for ['[CLS] wild exercised [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.183 (perp=9.392, rec=0.264, cos=0.040), tot_loss_proj:2.646 [t=0.30s]
prediction: ['[CLS] hot hot [SEP]']
[ 100/2000] tot_loss=1.742 (perp=8.198, rec=0.077, cos=0.026), tot_loss_proj:1.749 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=1.718 (perp=8.198, rec=0.053, cos=0.026), tot_loss_proj:1.766 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=1.718 (perp=8.198, rec=0.053, cos=0.026), tot_loss_proj:1.747 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.727 (perp=8.198, rec=0.061, cos=0.026), tot_loss_proj:1.754 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.718 (perp=8.198, rec=0.053, cos=0.026), tot_loss_proj:1.755 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.724 (perp=8.198, rec=0.058, cos=0.026), tot_loss_proj:1.761 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.723 (perp=8.198, rec=0.058, cos=0.026), tot_loss_proj:1.759 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.713 (perp=8.198, rec=0.048, cos=0.026), tot_loss_proj:1.754 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.732 (perp=8.198, rec=0.067, cos=0.026), tot_loss_proj:1.742 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.723 (perp=8.198, rec=0.058, cos=0.026), tot_loss_proj:1.737 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.728 (perp=8.198, rec=0.063, cos=0.026), tot_loss_proj:1.746 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.729 (perp=8.198, rec=0.064, cos=0.026), tot_loss_proj:1.744 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.723 (perp=8.198, rec=0.057, cos=0.026), tot_loss_proj:1.743 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.712 (perp=8.198, rec=0.046, cos=0.026), tot_loss_proj:1.743 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.727 (perp=8.198, rec=0.061, cos=0.026), tot_loss_proj:1.757 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.722 (perp=8.198, rec=0.056, cos=0.026), tot_loss_proj:1.756 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.731 (perp=8.198, rec=0.066, cos=0.026), tot_loss_proj:1.749 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.726 (perp=8.198, rec=0.061, cos=0.026), tot_loss_proj:1.757 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.723 (perp=8.198, rec=0.057, cos=0.026), tot_loss_proj:1.757 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.725 (perp=8.198, rec=0.060, cos=0.026), tot_loss_proj:1.737 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.742 (perp=8.198, rec=0.077, cos=0.026), tot_loss_proj:1.748 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.727 (perp=8.198, rec=0.061, cos=0.026), tot_loss_proj:1.758 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.730 (perp=8.198, rec=0.065, cos=0.026), tot_loss_proj:1.749 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.720 (perp=8.198, rec=0.054, cos=0.026), tot_loss_proj:1.732 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.729 (perp=8.198, rec=0.064, cos=0.026), tot_loss_proj:1.749 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.737 (perp=8.198, rec=0.072, cos=0.026), tot_loss_proj:1.747 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.719 (perp=8.198, rec=0.054, cos=0.026), tot_loss_proj:1.747 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.730 (perp=8.198, rec=0.065, cos=0.026), tot_loss_proj:1.754 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.732 (perp=8.198, rec=0.067, cos=0.026), tot_loss_proj:1.734 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.732 (perp=8.198, rec=0.066, cos=0.026), tot_loss_proj:1.752 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.741 (perp=8.198, rec=0.075, cos=0.026), tot_loss_proj:1.742 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.727 (perp=8.198, rec=0.061, cos=0.026), tot_loss_proj:1.745 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.733 (perp=8.198, rec=0.068, cos=0.026), tot_loss_proj:1.749 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.726 (perp=8.198, rec=0.060, cos=0.026), tot_loss_proj:1.746 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.726 (perp=8.198, rec=0.061, cos=0.026), tot_loss_proj:1.742 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.728 (perp=8.198, rec=0.062, cos=0.026), tot_loss_proj:1.749 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.732 (perp=8.198, rec=0.066, cos=0.026), tot_loss_proj:1.747 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.725 (perp=8.198, rec=0.060, cos=0.026), tot_loss_proj:1.751 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.732 (perp=8.198, rec=0.067, cos=0.026), tot_loss_proj:1.754 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.153 | p: 90.808 | r: 91.579
rouge2     | fm: 62.081 | p: 62.005 | r: 62.247
rougeL     | fm: 80.314 | p: 80.047 | r: 80.698
rougeLsum  | fm: 80.370 | p: 80.081 | r: 80.724
r1fm+r2fm = 153.234

input #54 time: 0:11:52 | total time: 11:39:07


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9832813178228136
highest_index [0]
highest [0.9832813178228136]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.8593611121177673 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.7426554560661316 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.739465057849884 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7350712418556213 for ['[CLS] beneath besides milo [SEP]']
[Init] best rec loss: 0.7267966866493225 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.7152577638626099 for ['[CLS] top trades events [SEP]']
[Init] best rec loss: 0.7048123478889465 for ['[CLS] stride holly post [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.217 (perp=9.389, rec=0.273, cos=0.066), tot_loss_proj:3.628 [t=0.30s]
prediction: ['[CLS] easily settled easily [SEP]']
[ 100/2000] tot_loss=1.907 (perp=8.671, rec=0.136, cos=0.037), tot_loss_proj:1.848 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 150/2000] tot_loss=1.836 (perp=8.671, rec=0.069, cos=0.033), tot_loss_proj:1.838 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 200/2000] tot_loss=1.832 (perp=8.671, rec=0.065, cos=0.033), tot_loss_proj:1.835 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.839 (perp=8.671, rec=0.072, cos=0.033), tot_loss_proj:1.833 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=1.819 (perp=8.671, rec=0.052, cos=0.033), tot_loss_proj:1.830 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.829 (perp=8.671, rec=0.062, cos=0.033), tot_loss_proj:1.835 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.835 (perp=8.671, rec=0.068, cos=0.033), tot_loss_proj:1.830 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.827 (perp=8.671, rec=0.060, cos=0.033), tot_loss_proj:1.831 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.830 (perp=8.671, rec=0.063, cos=0.032), tot_loss_proj:1.838 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.823 (perp=8.671, rec=0.056, cos=0.033), tot_loss_proj:1.834 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.830 (perp=8.671, rec=0.063, cos=0.033), tot_loss_proj:1.830 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.826 (perp=8.671, rec=0.059, cos=0.033), tot_loss_proj:1.833 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.826 (perp=8.671, rec=0.059, cos=0.033), tot_loss_proj:1.839 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.821 (perp=8.671, rec=0.054, cos=0.033), tot_loss_proj:1.838 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.826 (perp=8.671, rec=0.059, cos=0.033), tot_loss_proj:1.826 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.837 (perp=8.671, rec=0.070, cos=0.033), tot_loss_proj:1.836 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.829 (perp=8.671, rec=0.062, cos=0.033), tot_loss_proj:1.846 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.836 (perp=8.671, rec=0.069, cos=0.033), tot_loss_proj:1.826 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.822 (perp=8.671, rec=0.055, cos=0.033), tot_loss_proj:1.843 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.823 (perp=8.671, rec=0.056, cos=0.033), tot_loss_proj:1.832 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.826 (perp=8.671, rec=0.059, cos=0.033), tot_loss_proj:1.826 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.823 (perp=8.671, rec=0.056, cos=0.033), tot_loss_proj:1.836 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.832 (perp=8.671, rec=0.065, cos=0.033), tot_loss_proj:1.834 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.824 (perp=8.671, rec=0.057, cos=0.033), tot_loss_proj:1.840 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.822 (perp=8.671, rec=0.055, cos=0.033), tot_loss_proj:1.828 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.829 (perp=8.671, rec=0.062, cos=0.033), tot_loss_proj:1.829 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.833 (perp=8.671, rec=0.066, cos=0.033), tot_loss_proj:1.828 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.829 (perp=8.671, rec=0.061, cos=0.033), tot_loss_proj:1.828 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.824 (perp=8.671, rec=0.057, cos=0.033), tot_loss_proj:1.825 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.828 (perp=8.671, rec=0.061, cos=0.033), tot_loss_proj:1.828 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.830 (perp=8.671, rec=0.062, cos=0.033), tot_loss_proj:1.846 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.817 (perp=8.671, rec=0.049, cos=0.033), tot_loss_proj:1.839 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.821 (perp=8.671, rec=0.053, cos=0.033), tot_loss_proj:1.831 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.825 (perp=8.671, rec=0.058, cos=0.033), tot_loss_proj:1.837 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.834 (perp=8.671, rec=0.067, cos=0.033), tot_loss_proj:1.837 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.831 (perp=8.671, rec=0.064, cos=0.033), tot_loss_proj:1.834 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.828 (perp=8.671, rec=0.061, cos=0.033), tot_loss_proj:1.831 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.821 (perp=8.671, rec=0.054, cos=0.033), tot_loss_proj:1.837 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.837 (perp=8.671, rec=0.070, cos=0.033), tot_loss_proj:1.830 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.374 | p: 91.074 | r: 91.755
rouge2     | fm: 62.748 | p: 62.642 | r: 62.852
rougeL     | fm: 80.611 | p: 80.373 | r: 80.938
rougeLsum  | fm: 80.689 | p: 80.402 | r: 80.997
r1fm+r2fm = 154.122

input #55 time: 0:11:52 | total time: 11:51:00


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.98461539463915
highest_index [0]
highest [0.98461539463915]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.8415414094924927 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.826705813407898 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.8226158022880554 for ['[CLS]tur secondary sitting accident ked sul woman professor ever signatures exercise daylor blackness photographicmind mechanics jerked gel. interiors [SEP]']
[Init] best rec loss: 0.8140055537223816 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 0.8133108615875244 for ['[CLS] strike en charter backed k sympathy bear determined technique avid unfortunately reflectionured sense iron ; code depression laid tis blame [SEP]']
[Init] best perm rec loss: 0.8122766613960266 for ['[CLS] iron sympathy sense tis unfortunatelyured en laid avid depression reflection strike k code blame ; charter bear backed determined technique [SEP]']
[Init] best perm rec loss: 0.8116983771324158 for ['[CLS] unfortunately ; codeured iron backed blame charter depression sense reflection strike determined en avid k bear laid sympathy technique tis [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.939 (perp=13.097, rec=0.286, cos=0.034), tot_loss_proj:3.848 [t=0.31s]
prediction: ['[CLS] serial boat assault damage some of analysis damage studied damage damage damaged rosalie johnny commission ant expensive not storm lack neither [SEP]']
[ 100/2000] tot_loss=2.641 (perp=11.830, rec=0.239, cos=0.036), tot_loss_proj:3.041 [t=0.31s]
prediction: ['[CLS] serial killing imposeding which of films damage scattered damage damage damagedmined will yearsation costly have films never fix [SEP]']
[ 150/2000] tot_loss=2.203 (perp=10.046, rec=0.164, cos=0.030), tot_loss_proj:2.688 [t=0.31s]
prediction: ['[CLS] prep cause loads which loads of analysis damage of damage damage that astronomical will years of costly ever films never fix [SEP]']
[ 200/2000] tot_loss=2.116 (perp=9.723, rec=0.142, cos=0.030), tot_loss_proj:2.585 [t=0.31s]
prediction: ['[CLS] reduced cause loads cause loads of analysis damageble damage damage that astronomical will years of costly could films never fix [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.052 (perp=9.455, rec=0.129, cos=0.032), tot_loss_proj:2.532 [t=0.31s]
prediction: ['[CLS] reduced yearspara cause loads of analysis damageble entirely damage damage that will years of costly could films never fix [SEP]']
[ 300/2000] tot_loss=2.051 (perp=9.547, rec=0.111, cos=0.031), tot_loss_proj:2.631 [t=0.31s]
prediction: ['[CLS] which yearspara cause loads of analysis damageble entirely damage damage that will years of costly could films never fix [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.010 (perp=9.370, rec=0.105, cos=0.031), tot_loss_proj:2.595 [t=0.31s]
prediction: ['[CLS] which yearspara cause loads of analysisble damage entirely damage damage that will years of costly could films never fix [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.071 (perp=9.699, rec=0.101, cos=0.031), tot_loss_proj:2.617 [t=0.31s]
prediction: ['[CLS] whichparapara cause loads of analysisble damage entirely damage damage that will years of costly could films never fix [SEP]']
[ 450/2000] tot_loss=2.183 (perp=10.289, rec=0.095, cos=0.030), tot_loss_proj:2.710 [t=0.31s]
prediction: ['[CLS] whichparapara cause loads of analysisble damage entirelypara damage that will years of costly could films never fix [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.115 (perp=10.009, rec=0.083, cos=0.030), tot_loss_proj:2.644 [t=0.31s]
prediction: ['[CLS] whichparapara damage loads of analysisble damage entirely cause damage that will years of costly could films never fix [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.997 (perp=9.440, rec=0.079, cos=0.030), tot_loss_proj:2.517 [t=0.31s]
prediction: ['[CLS] whichparaparablepara loads of analysis damage entirely cause damage that will years of costly could films never fix [SEP]']
[ 600/2000] tot_loss=2.077 (perp=9.785, rec=0.090, cos=0.030), tot_loss_proj:2.523 [t=0.32s]
prediction: ['[CLS] whichparaparableble loads of analysis damage entirely cause damage that will years of costly could films never fix [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.973 (perp=9.289, rec=0.085, cos=0.030), tot_loss_proj:2.349 [t=0.31s]
prediction: ['[CLS] whichparaparableble loads of analysis damage entirely cause damage that will years of costly films could never fix [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.857 (perp=8.729, rec=0.081, cos=0.030), tot_loss_proj:2.272 [t=0.31s]
prediction: ['[CLS] whichbleparablepara loads of analysis damage entirely cause damage that will years of costly films could never fix [SEP]']
[ 750/2000] tot_loss=1.851 (perp=8.729, rec=0.075, cos=0.030), tot_loss_proj:2.273 [t=0.31s]
prediction: ['[CLS] whichbleparablepara loads of analysis damage entirely cause damage that will years of costly films could never fix [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.793 (perp=8.399, rec=0.082, cos=0.030), tot_loss_proj:2.181 [t=0.31s]
prediction: ['[CLS] whichparableparable loads of analysis damage entirely cause damage that will years of costly films could never fix [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.778 (perp=8.324, rec=0.083, cos=0.030), tot_loss_proj:2.169 [t=0.31s]
prediction: ['[CLS] whichparableparable loads of damage analysis entirely cause damage that will years of costly films could never fix [SEP]']
[ 900/2000] tot_loss=1.776 (perp=8.324, rec=0.081, cos=0.030), tot_loss_proj:2.172 [t=0.31s]
prediction: ['[CLS] whichparableparable loads of damage analysis entirely cause damage that will years of costly films could never fix [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.729 (perp=8.116, rec=0.075, cos=0.030), tot_loss_proj:2.126 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage which entirely cause damage that will years of costly films could never fix [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.693 (perp=7.874, rec=0.089, cos=0.030), tot_loss_proj:2.137 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely cause damage that will years of costly films which could never fix [SEP]']
[1050/2000] tot_loss=1.693 (perp=7.874, rec=0.088, cos=0.030), tot_loss_proj:2.140 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely cause damage that will years of costly films which could never fix [SEP]']
Attempt swap
[1100/2000] tot_loss=1.686 (perp=7.874, rec=0.081, cos=0.030), tot_loss_proj:2.140 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely cause damage that will years of costly films which could never fix [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.678 (perp=7.863, rec=0.075, cos=0.030), tot_loss_proj:2.161 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage cause entirely damage that will years of costly films which could never fix [SEP]']
[1200/2000] tot_loss=1.679 (perp=7.863, rec=0.076, cos=0.031), tot_loss_proj:2.162 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage cause entirely damage that will years of costly films which could never fix [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.650 (perp=7.712, rec=0.077, cos=0.030), tot_loss_proj:1.963 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
Attempt swap
[1300/2000] tot_loss=1.649 (perp=7.712, rec=0.076, cos=0.030), tot_loss_proj:1.963 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
[1350/2000] tot_loss=1.648 (perp=7.712, rec=0.075, cos=0.031), tot_loss_proj:1.966 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
Attempt swap
[1400/2000] tot_loss=1.650 (perp=7.712, rec=0.077, cos=0.031), tot_loss_proj:1.962 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
Attempt swap
[1450/2000] tot_loss=1.653 (perp=7.712, rec=0.080, cos=0.031), tot_loss_proj:1.965 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
[1500/2000] tot_loss=1.652 (perp=7.712, rec=0.079, cos=0.031), tot_loss_proj:1.958 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.644 (perp=7.712, rec=0.071, cos=0.030), tot_loss_proj:1.954 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
Attempt swap
[1600/2000] tot_loss=1.649 (perp=7.712, rec=0.076, cos=0.031), tot_loss_proj:1.960 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
[1650/2000] tot_loss=1.651 (perp=7.712, rec=0.078, cos=0.030), tot_loss_proj:1.960 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
Attempt swap
[1700/2000] tot_loss=1.652 (perp=7.712, rec=0.079, cos=0.031), tot_loss_proj:1.961 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
Attempt swap
[1750/2000] tot_loss=1.647 (perp=7.712, rec=0.074, cos=0.031), tot_loss_proj:1.953 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
[1800/2000] tot_loss=1.655 (perp=7.712, rec=0.082, cos=0.031), tot_loss_proj:1.957 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
Attempt swap
[1850/2000] tot_loss=1.647 (perp=7.712, rec=0.074, cos=0.030), tot_loss_proj:1.954 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
Attempt swap
[1900/2000] tot_loss=1.653 (perp=7.712, rec=0.080, cos=0.031), tot_loss_proj:1.959 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
[1950/2000] tot_loss=1.651 (perp=7.712, rec=0.078, cos=0.031), tot_loss_proj:1.959 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
Attempt swap
[2000/2000] tot_loss=1.658 (perp=7.712, rec=0.085, cos=0.031), tot_loss_proj:1.956 [t=0.31s]
prediction: ['[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] analysisparableparable loads of damage entirely damage that will cause years of costly films which could never fix [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.051 | p: 84.211 | r: 80.000
rouge2     | fm: 48.649 | p: 50.000 | r: 47.368
rougeL     | fm: 61.538 | p: 63.158 | r: 60.000
rougeLsum  | fm: 61.538 | p: 63.158 | r: 60.000
r1fm+r2fm = 130.700

[Aggregate metrics]:
rouge1     | fm: 91.121 | p: 90.838 | r: 91.534
rouge2     | fm: 62.567 | p: 62.448 | r: 62.625
rougeL     | fm: 80.218 | p: 79.969 | r: 80.564
rougeLsum  | fm: 80.309 | p: 80.163 | r: 80.580
r1fm+r2fm = 153.688

input #56 time: 0:12:14 | total time: 12:03:14


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9841948497749939
highest_index [0]
highest [0.9841948497749939]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.869964063167572 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.8678027987480164 for ['[CLS] their [SEP]']
[Init] best rec loss: 0.7889097332954407 for ['[CLS]on [SEP]']
[Init] best rec loss: 0.7543880343437195 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.6863411664962769 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.685024619102478 for ['[CLS] silk [SEP]']
[Init] best rec loss: 0.684947669506073 for ['[CLS] beethoven [SEP]']
[Init] best rec loss: 0.682546854019165 for ['[CLS] himself [SEP]']
[Init] best rec loss: 0.6695841550827026 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.604 (perp=12.283, rec=0.111, cos=0.036), tot_loss_proj:2.541 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.555 (perp=12.283, rec=0.068, cos=0.030), tot_loss_proj:2.552 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.562 (perp=12.283, rec=0.077, cos=0.029), tot_loss_proj:2.540 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.543 (perp=12.283, rec=0.056, cos=0.031), tot_loss_proj:2.552 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.544 (perp=12.283, rec=0.056, cos=0.031), tot_loss_proj:2.548 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.549 (perp=12.283, rec=0.062, cos=0.030), tot_loss_proj:2.551 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.549 (perp=12.283, rec=0.062, cos=0.031), tot_loss_proj:2.567 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.527 (perp=12.283, rec=0.039, cos=0.031), tot_loss_proj:2.532 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.549 (perp=12.283, rec=0.061, cos=0.031), tot_loss_proj:2.547 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.553 (perp=12.283, rec=0.065, cos=0.031), tot_loss_proj:2.552 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.543 (perp=12.283, rec=0.055, cos=0.031), tot_loss_proj:2.539 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.550 (perp=12.283, rec=0.063, cos=0.031), tot_loss_proj:2.559 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.549 (perp=12.283, rec=0.061, cos=0.031), tot_loss_proj:2.555 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.549 (perp=12.283, rec=0.061, cos=0.031), tot_loss_proj:2.553 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.553 (perp=12.283, rec=0.065, cos=0.031), tot_loss_proj:2.572 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.545 (perp=12.283, rec=0.058, cos=0.031), tot_loss_proj:2.559 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.550 (perp=12.283, rec=0.062, cos=0.031), tot_loss_proj:2.538 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.540 (perp=12.283, rec=0.052, cos=0.031), tot_loss_proj:2.555 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.548 (perp=12.283, rec=0.060, cos=0.031), tot_loss_proj:2.542 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.543 (perp=12.283, rec=0.056, cos=0.031), tot_loss_proj:2.535 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.544 (perp=12.283, rec=0.056, cos=0.031), tot_loss_proj:2.548 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.550 (perp=12.283, rec=0.062, cos=0.031), tot_loss_proj:2.545 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.541 (perp=12.283, rec=0.053, cos=0.031), tot_loss_proj:2.535 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.546 (perp=12.283, rec=0.058, cos=0.031), tot_loss_proj:2.554 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.563 (perp=12.283, rec=0.075, cos=0.031), tot_loss_proj:2.548 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.561 (perp=12.283, rec=0.073, cos=0.031), tot_loss_proj:2.555 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.547 (perp=12.283, rec=0.059, cos=0.031), tot_loss_proj:2.553 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.553 (perp=12.283, rec=0.065, cos=0.031), tot_loss_proj:2.552 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.545 (perp=12.283, rec=0.057, cos=0.031), tot_loss_proj:2.545 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.546 (perp=12.283, rec=0.059, cos=0.031), tot_loss_proj:2.541 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.548 (perp=12.283, rec=0.060, cos=0.031), tot_loss_proj:2.541 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.539 (perp=12.283, rec=0.051, cos=0.031), tot_loss_proj:2.554 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.552 (perp=12.283, rec=0.064, cos=0.031), tot_loss_proj:2.551 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.544 (perp=12.283, rec=0.056, cos=0.031), tot_loss_proj:2.567 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.557 (perp=12.283, rec=0.069, cos=0.031), tot_loss_proj:2.550 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.546 (perp=12.283, rec=0.058, cos=0.031), tot_loss_proj:2.547 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.536 (perp=12.283, rec=0.048, cos=0.031), tot_loss_proj:2.541 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.536 (perp=12.283, rec=0.048, cos=0.031), tot_loss_proj:2.545 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.556 (perp=12.283, rec=0.068, cos=0.031), tot_loss_proj:2.535 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.556 (perp=12.283, rec=0.068, cos=0.031), tot_loss_proj:2.537 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.373 | p: 91.137 | r: 91.791
rouge2     | fm: 63.012 | p: 62.939 | r: 63.170
rougeL     | fm: 80.630 | p: 80.463 | r: 80.950
rougeLsum  | fm: 80.577 | p: 80.347 | r: 80.899
r1fm+r2fm = 154.385

input #57 time: 0:10:53 | total time: 12:14:08


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9881328311261997
highest_index [0]
highest [0.9881328311261997]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.0212231874465942 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9909330606460571 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9823683500289917 for ['[CLS] things reggie on guinnessllet continue special the chan (ness grew prone moffatockshire [SEP]']
[Init] best rec loss: 0.9767107367515564 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.961768388748169 for ['[CLS] partner kickoff message oh hills edge wind mono stainless few sk closet clay fair ole port [SEP]']
[Init] best rec loss: 0.9535443186759949 for ['[CLS] sure tel china lose neutral central never an there after louis concentratione jack boysnted [SEP]']
[Init] best rec loss: 0.9424280524253845 for ['[CLS] shield anything damon venom sitting led trumppole purdue bigاural failed proposal sketch lea [SEP]']
[Init] best rec loss: 0.940099835395813 for ['[CLS] bellsignant river animals don cracked ace behind lid tasha des aden reception add bu fully [SEP]']
[Init] best perm rec loss: 0.9390752911567688 for ['[CLS] add don tasha aden river behind ace reception animals lid fully bells bu des crackedignant [SEP]']
[Init] best perm rec loss: 0.9379420876502991 for ['[CLS] aden don lid fully tasha behind addignant reception river ace des cracked bu animals bells [SEP]']
[Init] best perm rec loss: 0.9377263188362122 for ['[CLS] lid don adenignant ace fully cracked add bu reception tasha bells des animals river behind [SEP]']
[Init] best perm rec loss: 0.9366921782493591 for ['[CLS] cracked bu add lid donignant ace river behind des aden reception animals fully tasha bells [SEP]']
[Init] best perm rec loss: 0.936255931854248 for ['[CLS] reception behind animals bu ace aden fully lid tasha des add bells river cracked donignant [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.640 (perp=12.495, rec=0.646, cos=0.495), tot_loss_proj:4.121 [t=0.31s]
prediction: ['[CLS] giant giving activities county sewage crap ruins oh oval. 0ville - college tribute someone [SEP]']
[ 100/2000] tot_loss=3.188 (perp=12.261, rec=0.518, cos=0.219), tot_loss_proj:4.319 [t=0.31s]
prediction: ['[CLS] veteran driving activities wilderness sewage mckay ruins oh own warfare attribute¹ - moonlight appropriate someone [SEP]']
[ 150/2000] tot_loss=3.317 (perp=13.129, rec=0.499, cos=0.193), tot_loss_proj:4.162 [t=0.31s]
prediction: ['[CLS] you driving epithet story sewage waste timing souls hell fight endemic bingham story smiledless someone [SEP]']
[ 200/2000] tot_loss=3.847 (perp=13.578, rec=0.694, cos=0.437), tot_loss_proj:4.284 [t=0.31s]
prediction: ['[CLS] hate killed irregularities king bull janeiro minutes very smug. affiliation eliza a bakerytium someone [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.088 (perp=11.546, rec=0.559, cos=0.219), tot_loss_proj:3.848 [t=0.31s]
prediction: ['[CLS] someone killed offences mother garbage competitions daylight so drag. affiliationkha the college analysis government [SEP]']
[ 300/2000] tot_loss=3.106 (perp=12.269, rec=0.512, cos=0.140), tot_loss_proj:4.072 [t=0.31s]
prediction: ['[CLS] someone kills allegations mother paper became namibia so howard aboutmento pulitzer the college analysis government [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.965 (perp=11.448, rec=0.502, cos=0.174), tot_loss_proj:4.247 [t=0.31s]
prediction: ['[CLS] thinking. about × curiosity portage mama so humkled inter filled the college inspirational giant [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.023 (perp=12.066, rec=0.477, cos=0.132), tot_loss_proj:4.299 [t=0.31s]
prediction: ['[CLS] someone inspirational allegations × monster festival unless so humkled inter filled affair upside drove the [SEP]']
[ 450/2000] tot_loss=3.053 (perp=12.478, rec=0.440, cos=0.117), tot_loss_proj:4.329 [t=0.31s]
prediction: ['[CLS] thinking inspirational allegations × monster interaction unless so humkled inter barrenpped wood drove the [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.904 (perp=12.123, rec=0.423, cos=0.057), tot_loss_proj:4.381 [t=0.31s]
prediction: ['[CLS] indiana thinking inspirational lies providing monster interaction another ghettokled inter songspped wood drove the [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.660 (perp=13.249, rec=0.607, cos=0.404), tot_loss_proj:4.179 [t=0.31s]
prediction: ['[CLS] mama someone story publicly empire especially meaningless dog vomitya ego barren freedoms college drove an [SEP]']
[ 600/2000] tot_loss=3.496 (perp=13.744, rec=0.520, cos=0.227), tot_loss_proj:4.501 [t=0.31s]
prediction: ['[CLS] mama loomed story publicly empire especiallytrum dogolza ego barren freedoms college drove an [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.344 (perp=13.510, rec=0.493, cos=0.149), tot_loss_proj:4.437 [t=0.31s]
prediction: ['[CLS] mama perrintrum publicly friendship for story dognsorza ego barren appetite hair drove an [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.130 (perp=12.634, rec=0.477, cos=0.126), tot_loss_proj:4.114 [t=0.31s]
prediction: ['[CLS] mama perrintrum publicly barren friendship. story dog ghetto names upper appetite hair drove an [SEP]']
[ 750/2000] tot_loss=3.081 (perp=12.840, rec=0.442, cos=0.072), tot_loss_proj:4.571 [t=0.31s]
prediction: ['[CLS] mama perrintrum publicly sadness friendship. story everything ghetto inspirational upper freedoms hair drove an [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.883 (perp=12.016, rec=0.425, cos=0.054), tot_loss_proj:4.387 [t=0.31s]
prediction: ['[CLS] mama perrintrum publicly sadness friendship ghetto story everything. inspirational upper freedoms hair drove an [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.704 (perp=11.176, rec=0.418, cos=0.050), tot_loss_proj:4.195 [t=0.31s]
prediction: ['[CLS] perrintrum personally sadness friendship mama ghetto story everything. inspirational upper freedoms hair drove an [SEP]']
[ 900/2000] tot_loss=2.755 (perp=11.564, rec=0.407, cos=0.035), tot_loss_proj:4.196 [t=0.31s]
prediction: ['[CLS] perrintrum personally sadness friendship mama ghetto inspirational everything. inspirational upper freedoms hair drove an [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.685 (perp=11.296, rec=0.398, cos=0.028), tot_loss_proj:4.123 [t=0.31s]
prediction: ['[CLS] perrintrum personally sadness friendship mama ghetto inspirational everything an inspirational upper freedoms hair drove. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.653 (perp=11.167, rec=0.394, cos=0.025), tot_loss_proj:4.174 [t=0.31s]
prediction: ['[CLS] perrintrum personally sadness friendship mama ghetto inspirational establishment an inspirational upper sophie drove hair. [SEP]']
[1050/2000] tot_loss=2.669 (perp=11.252, rec=0.392, cos=0.026), tot_loss_proj:4.120 [t=0.31s]
prediction: ['[CLS] loomedtrum personally by friendship mama ghetto inspirational establishment angraph upper sophie the perspective. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.623 (perp=11.091, rec=0.381, cos=0.024), tot_loss_proj:3.987 [t=0.31s]
prediction: ['[CLS] loomedtrum personally by friendship mama ghetto inspirational establishmentgraph an upper sophie the perspective of [SEP]']
Attempt swap
[1150/2000] tot_loss=2.746 (perp=11.704, rec=0.382, cos=0.023), tot_loss_proj:3.893 [t=0.31s]
prediction: ['[CLS] loomed becomes personally by friendship crucial ghetto inspirational establishmentgraph an upper sophie the perspective of [SEP]']
[1200/2000] tot_loss=2.885 (perp=12.419, rec=0.377, cos=0.024), tot_loss_proj:4.106 [t=0.31s]
prediction: ['[CLS] loomed becomes personally by friendship crucial ghetto inspirational everythinggraph the edit sophie the perspective of [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.949 (perp=12.719, rec=0.383, cos=0.023), tot_loss_proj:4.300 [t=0.31s]
prediction: ['[CLS] loomed personally songs friendship overheard crucial ghetto inspirational everythinggraph the edit sophie the perspective of [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.762 (perp=11.774, rec=0.381, cos=0.026), tot_loss_proj:4.077 [t=0.31s]
prediction: ['[CLS] loomed personally inspirational friendship overheard crucial ghetto songs everythinggraph the edit sophie the perspective of [SEP]']
[1350/2000] tot_loss=2.767 (perp=11.824, rec=0.377, cos=0.025), tot_loss_proj:4.081 [t=0.31s]
prediction: ['[CLS] loomed personally inspirational friendship overheard crucial ghetto songs establishmentgraph the edit sophie the perspective of [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.671 (perp=11.337, rec=0.378, cos=0.026), tot_loss_proj:3.996 [t=0.31s]
prediction: ['[CLS] sophie personally inspirational friendship overheard crucial ghetto songs everything certainly the edit loomed the perspective of [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.661 (perp=11.218, rec=0.382, cos=0.036), tot_loss_proj:4.247 [t=0.31s]
prediction: ['[CLS] sophie personally inspirational friendship overheard crucial ghetto songsgraph the edit loomed naked the perspective of [SEP]']
[1500/2000] tot_loss=2.649 (perp=11.250, rec=0.375, cos=0.024), tot_loss_proj:4.268 [t=0.31s]
prediction: ['[CLS] sophie personally inspirational inspirational overheard crucial ghetto songsgraph theori loomed naked the perspective of [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.653 (perp=11.286, rec=0.372, cos=0.024), tot_loss_proj:4.269 [t=0.31s]
prediction: ['[CLS] sophie crucial inspirational inspirational overheard personally ghetto bygraph theori loomed naked the perspective of [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.636 (perp=11.159, rec=0.376, cos=0.028), tot_loss_proj:4.167 [t=0.31s]
prediction: ['[CLS] sophie crucial inspirational ghetto inspirational overheard straight songsgraph theori loomed naked the perspective of [SEP]']
[1650/2000] tot_loss=2.716 (perp=11.625, rec=0.367, cos=0.024), tot_loss_proj:4.184 [t=0.31s]
prediction: ['[CLS]ism crucial inspirational ghetto inspirational overheard straight songsgraph theori loomed naked the perspective of [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.537 (perp=10.729, rec=0.369, cos=0.021), tot_loss_proj:3.983 [t=0.31s]
prediction: ['[CLS]ism edit inspirational ghetto inspirational overheard straight songsgraph the crucial loomed naked the perspective of [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.472 (perp=10.371, rec=0.372, cos=0.026), tot_loss_proj:3.974 [t=0.31s]
prediction: ['[CLS]ism edit inspirational ghetto inspirational overheard straight songsgraph the crucial loomed of the perspective naked [SEP]']
[1800/2000] tot_loss=2.470 (perp=10.371, rec=0.372, cos=0.024), tot_loss_proj:3.975 [t=0.31s]
prediction: ['[CLS]ism edit inspirational ghetto inspirational overheard straight songsgraph the crucial loomed of the perspective naked [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.432 (perp=10.224, rec=0.363, cos=0.024), tot_loss_proj:4.024 [t=0.31s]
prediction: ['[CLS]ism edit inspirational ghetto inspirational overheard establishment songsgraph the crucial loomed of the perspective straight [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.412 (perp=10.111, rec=0.366, cos=0.023), tot_loss_proj:4.002 [t=0.31s]
prediction: ['[CLS]ism edit inspirational ghetto inspirational overheard establishment songsgraph the crucial perspective of the loomed straight [SEP]']
[1950/2000] tot_loss=2.411 (perp=10.111, rec=0.366, cos=0.023), tot_loss_proj:3.997 [t=0.31s]
prediction: ['[CLS]ism edit inspirational ghetto inspirational overheard establishment songsgraph the crucial perspective of the loomed straight [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.407 (perp=10.080, rec=0.367, cos=0.023), tot_loss_proj:3.998 [t=0.31s]
prediction: ['[CLS]ism edit inspirational establishment inspirational overheard ghetto songsgraph the crucial perspective of the loomed straight [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS]ism edit inspirational ghetto inspirational overheard straight songsgraph the crucial loomed naked the perspective of [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 30.303 | p: 29.412 | r: 31.250
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 30.303 | p: 29.412 | r: 31.250
rougeLsum  | fm: 30.303 | p: 29.412 | r: 31.250
r1fm+r2fm = 30.303

[Aggregate metrics]:
rouge1     | fm: 90.313 | p: 90.003 | r: 90.678
rouge2     | fm: 62.189 | p: 62.096 | r: 62.308
rougeL     | fm: 79.807 | p: 79.609 | r: 80.133
rougeLsum  | fm: 79.861 | p: 79.612 | r: 80.223
r1fm+r2fm = 152.502

input #58 time: 0:12:11 | total time: 12:26:19


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9881448481704735
highest_index [0]
highest [0.9881448481704735]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.8879877328872681 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.8522971272468567 for ['[CLS] poll dominance intine drop silvertock politician wrappedve complete hot reading team disco world [SEP]']
[Init] best rec loss: 0.8422669172286987 for ['[CLS] mala minute theory mandatory stands after mere figure number roth sister locomotives bombay bavarian late athlete [SEP]']
[Init] best rec loss: 0.8401285409927368 for ['[CLS] shares josephine settled commerce refrain bulletsgi moved plot awaitanies roger console fergusotidew [SEP]']
[Init] best rec loss: 0.8218274712562561 for ['[CLS]notes urban shape atliest not filterae titled making prize wait sex ste front coach [SEP]']
[Init] best rec loss: 0.8001194000244141 for ['[CLS] key stafforddial done colony midst kmdden face ɾord muscle warning ( wife organic [SEP]']
[Init] best rec loss: 0.7858952879905701 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best rec loss: 0.7799506187438965 for ['[CLS] creator war pepper mortal knights dinner warm helped tasting fringe vsonate cricket elitecoat counterpart [SEP]']
[Init] best perm rec loss: 0.7784069776535034 for ['[CLS]onate tasting counterpart warm creator knights peppercoat cricket war vs helped fringe elite mortal dinner [SEP]']
[Init] best perm rec loss: 0.7771977186203003 for ['[CLS] vs war tasting elitecoatonate dinner knights warm helped fringe cricket counterpart pepper mortal creator [SEP]']
[Init] best perm rec loss: 0.7739653587341309 for ['[CLS]coat pepper creator vsonate elite counterpart knights mortal helped tasting fringe warm war dinner cricket [SEP]']
[Init] best perm rec loss: 0.7737786769866943 for ['[CLS] counterpart knights war dinner creatorcoat elite pepperonate fringe warm helped mortal cricket tasting vs [SEP]']
[Init] best perm rec loss: 0.7737283110618591 for ['[CLS] warmonate fringe war cricket dinner pepper knights helped counterpart mortal vs elite tasting creatorcoat [SEP]']
[Init] best perm rec loss: 0.7730485200881958 for ['[CLS] vs counterpart dinner warmcoat fringe mortal tasting elite knights pepper cricket war helped creatoronate [SEP]']
[Init] best perm rec loss: 0.7720288038253784 for ['[CLS]onate dinner counterpart warm vs fringe knights elite mortal war helped creator cricketcoat tasting pepper [SEP]']
[Init] best perm rec loss: 0.7711644768714905 for ['[CLS] creator counterpartcoat vs helped fringe knights elite war warm mortal tasting dinner cricket pepperonate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.621 (perp=11.188, rec=0.334, cos=0.050), tot_loss_proj:3.583 [t=0.30s]
prediction: ['[CLS] b although " avenue a woman char woman youth african ben had life relations of ability [SEP]']
[ 100/2000] tot_loss=2.022 (perp=8.882, rec=0.218, cos=0.028), tot_loss_proj:3.009 [t=0.31s]
prediction: ['[CLS] who hasism moves a woman a woman youth ar has young how of char [SEP]']
[ 150/2000] tot_loss=2.173 (perp=9.899, rec=0.168, cos=0.025), tot_loss_proj:3.180 [t=0.31s]
prediction: ['[CLS] has hasism char the woman char woman young screen the has char how of char [SEP]']
[ 200/2000] tot_loss=2.207 (perp=10.197, rec=0.144, cos=0.023), tot_loss_proj:3.050 [t=0.31s]
prediction: ['[CLS] has screenism char the woman young woman who screen knows has char how of char [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.047 (perp=9.531, rec=0.118, cos=0.023), tot_loss_proj:2.753 [t=0.31s]
prediction: ['[CLS] screen hasism char the woman young woman who screen knows knows char how of char [SEP]']
[ 300/2000] tot_loss=1.924 (perp=9.027, rec=0.096, cos=0.023), tot_loss_proj:2.623 [t=0.31s]
prediction: ['[CLS] screen hasisma the woman young woman who screen how knows char how of char [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.037 (perp=9.556, rec=0.102, cos=0.024), tot_loss_proj:2.722 [t=0.31s]
prediction: ['[CLS] screen hasisma the woman young a who how screen knows char how of char [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.893 (perp=8.952, rec=0.079, cos=0.023), tot_loss_proj:2.492 [t=0.31s]
prediction: ['[CLS] screen hasisma the woman a young who how hold knows char how of char [SEP]']
[ 450/2000] tot_loss=1.888 (perp=8.952, rec=0.075, cos=0.023), tot_loss_proj:2.486 [t=0.31s]
prediction: ['[CLS] screen hasisma the woman a young who how hold knows char how of char [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.779 (perp=8.373, rec=0.081, cos=0.023), tot_loss_proj:2.508 [t=0.31s]
prediction: ['[CLS] screenisma has the woman a young who how hold knows char how of char [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.696 (perp=8.006, rec=0.071, cos=0.023), tot_loss_proj:2.346 [t=0.31s]
prediction: ['[CLS] screenisma has the woman a young who how knows char how hold of char [SEP]']
[ 600/2000] tot_loss=1.733 (perp=8.192, rec=0.072, cos=0.023), tot_loss_proj:2.282 [t=0.31s]
prediction: ['[CLS] screenisma has the woman a young who how knows the how hold of char [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.673 (perp=7.910, rec=0.068, cos=0.023), tot_loss_proj:2.230 [t=0.31s]
prediction: ['[CLS] screenisma has the woman a young who how knows how the hold of char [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.490 (perp=6.991, rec=0.068, cos=0.024), tot_loss_proj:1.894 [t=0.31s]
prediction: ['[CLS] charisma has the woman a young who how knows how the hold of screen [SEP]']
[ 750/2000] tot_loss=1.490 (perp=6.991, rec=0.068, cos=0.023), tot_loss_proj:1.904 [t=0.31s]
prediction: ['[CLS] charisma has the woman a young who how knows how the hold of screen [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.415 (perp=6.595, rec=0.073, cos=0.023), tot_loss_proj:1.799 [t=0.31s]
prediction: ['[CLS] charisma has the woman a young who knows how how the hold of screen [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.335 (perp=6.222, rec=0.067, cos=0.023), tot_loss_proj:1.710 [t=0.31s]
prediction: ['[CLS] charisma has the woman a young who knows how how hold of the screen [SEP]']
[ 900/2000] tot_loss=1.338 (perp=6.222, rec=0.070, cos=0.023), tot_loss_proj:1.712 [t=0.31s]
prediction: ['[CLS] charisma has the woman a young who knows how how hold of the screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.136 (perp=5.223, rec=0.068, cos=0.024), tot_loss_proj:1.498 [t=0.31s]
prediction: ['[CLS] charisma has the woman a young who knows how to hold of the screen [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.097 (perp=5.009, rec=0.071, cos=0.024), tot_loss_proj:1.489 [t=0.31s]
prediction: ['[CLS] charisma has the a young woman who knows how to hold of the screen [SEP]']
[1050/2000] tot_loss=1.103 (perp=5.009, rec=0.078, cos=0.023), tot_loss_proj:1.487 [t=0.31s]
prediction: ['[CLS] charisma has the a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.093 (perp=5.009, rec=0.068, cos=0.024), tot_loss_proj:1.494 [t=0.31s]
prediction: ['[CLS] charisma has the a young woman who knows how to hold of the screen [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=0.970 (perp=4.417, rec=0.064, cos=0.023), tot_loss_proj:1.432 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
[1200/2000] tot_loss=0.981 (perp=4.417, rec=0.074, cos=0.023), tot_loss_proj:1.427 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[1250/2000] tot_loss=0.972 (perp=4.417, rec=0.065, cos=0.024), tot_loss_proj:1.428 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[1300/2000] tot_loss=0.973 (perp=4.417, rec=0.067, cos=0.023), tot_loss_proj:1.432 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
[1350/2000] tot_loss=0.977 (perp=4.417, rec=0.070, cos=0.023), tot_loss_proj:1.425 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[1400/2000] tot_loss=0.973 (perp=4.417, rec=0.067, cos=0.024), tot_loss_proj:1.434 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[1450/2000] tot_loss=0.963 (perp=4.417, rec=0.057, cos=0.023), tot_loss_proj:1.436 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
[1500/2000] tot_loss=0.970 (perp=4.417, rec=0.063, cos=0.023), tot_loss_proj:1.433 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[1550/2000] tot_loss=0.972 (perp=4.417, rec=0.065, cos=0.024), tot_loss_proj:1.431 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[1600/2000] tot_loss=0.965 (perp=4.417, rec=0.059, cos=0.023), tot_loss_proj:1.428 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
[1650/2000] tot_loss=0.972 (perp=4.417, rec=0.065, cos=0.023), tot_loss_proj:1.431 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[1700/2000] tot_loss=0.975 (perp=4.417, rec=0.068, cos=0.024), tot_loss_proj:1.432 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[1750/2000] tot_loss=0.971 (perp=4.417, rec=0.064, cos=0.023), tot_loss_proj:1.432 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
[1800/2000] tot_loss=0.970 (perp=4.417, rec=0.064, cos=0.024), tot_loss_proj:1.441 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[1850/2000] tot_loss=0.968 (perp=4.417, rec=0.061, cos=0.024), tot_loss_proj:1.434 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[1900/2000] tot_loss=0.964 (perp=4.417, rec=0.057, cos=0.024), tot_loss_proj:1.428 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
[1950/2000] tot_loss=0.970 (perp=4.417, rec=0.063, cos=0.024), tot_loss_proj:1.435 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Attempt swap
[2000/2000] tot_loss=0.975 (perp=4.417, rec=0.069, cos=0.024), tot_loss_proj:1.436 [t=0.31s]
prediction: ['[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] the charisma has a young woman who knows how to hold of the screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 166.667

[Aggregate metrics]:
rouge1     | fm: 90.543 | p: 90.249 | r: 90.900
rouge2     | fm: 62.318 | p: 62.223 | r: 62.424
rougeL     | fm: 79.922 | p: 79.706 | r: 80.288
rougeLsum  | fm: 79.960 | p: 79.749 | r: 80.268
r1fm+r2fm = 152.861

input #59 time: 0:12:10 | total time: 12:38:30


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.9847487267616462
highest_index [0]
highest [0.9847487267616462]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9683912992477417 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.946661651134491 for ['[CLS] everything partnership bas gossip lies donegal directionbad his western ann arms [SEP]']
[Init] best rec loss: 0.9425559639930725 for ['[CLS] eddiedding whenly became northeast theo solid sighed signsrral frozen [SEP]']
[Init] best rec loss: 0.9294202923774719 for ['[CLS] joo lead cancer course haiti board read empire dortmund commune member tory [SEP]']
[Init] best rec loss: 0.9067263007164001 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.89523845911026 for ['[CLS] percent symbol budapest herald nets flavor shoppingted archlizer clock tight [SEP]']
[Init] best rec loss: 0.886628270149231 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best perm rec loss: 0.8851193189620972 for ['[CLS] ground maddie deep regiment mortimer spring de! analytics era jameson how [SEP]']
[Init] best perm rec loss: 0.8836206793785095 for ['[CLS] analytics era spring regiment ground! mortimer de deep jameson how maddie [SEP]']
[Init] best perm rec loss: 0.8828269839286804 for ['[CLS] regiment spring! ground mortimer era analytics maddie de deep jameson how [SEP]']
[Init] best perm rec loss: 0.8826702833175659 for ['[CLS] how regiment mortimer deep maddie jameson ground! spring de era analytics [SEP]']
[Init] best perm rec loss: 0.8807390332221985 for ['[CLS] mortimer deep! analytics maddie regiment spring era how ground jameson de [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.983 (perp=13.301, rec=0.286, cos=0.036), tot_loss_proj:3.398 [t=0.30s]
prediction: ['[CLS] ant saleewest awkwardly attack towels is ran movieer sitcom [SEP]']
[ 100/2000] tot_loss=2.557 (perp=11.499, rec=0.219, cos=0.038), tot_loss_proj:3.104 [t=0.30s]
prediction: ['[CLS] elf judge is is awkwardly story circuit is awkwardly soap, soap [SEP]']
[ 150/2000] tot_loss=2.463 (perp=11.332, rec=0.165, cos=0.031), tot_loss_proj:3.118 [t=0.30s]
prediction: ['[CLS] elf see is is awkwardly story circuit is awkwardly soap is soap [SEP]']
[ 200/2000] tot_loss=2.432 (perp=11.342, rec=0.131, cos=0.032), tot_loss_proj:3.084 [t=0.30s]
prediction: ['[CLS] elf is is - awkwardly story circuit the paced opera. soap [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.389 (perp=11.149, rec=0.129, cos=0.031), tot_loss_proj:2.859 [t=0.30s]
prediction: ['[CLS] elf is is is awkwardly paced story circuit the operah soap [SEP]']
[ 300/2000] tot_loss=2.384 (perp=11.189, rec=0.116, cos=0.031), tot_loss_proj:2.713 [t=0.30s]
prediction: ['[CLS] elf is is paced awkwardly paced story circuit the operah soap [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.150 (perp=10.032, rec=0.108, cos=0.036), tot_loss_proj:2.611 [t=0.30s]
prediction: ['[CLS] elf soap is paced awkwardly paced story circuit the operah is [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.977 (perp=9.226, rec=0.102, cos=0.030), tot_loss_proj:2.441 [t=0.30s]
prediction: ['[CLS] elf is paced awkwardly paced story circuit the soap operah is [SEP]']
[ 450/2000] tot_loss=1.977 (perp=9.226, rec=0.098, cos=0.033), tot_loss_proj:2.430 [t=0.30s]
prediction: ['[CLS] elf is paced awkwardly paced story circuit the soap operah is [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.918 (perp=9.020, rec=0.084, cos=0.030), tot_loss_proj:2.347 [t=0.30s]
prediction: ['[CLS] elf is paced awkwardly paced story circuit the soap opera ish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.921 (perp=9.020, rec=0.087, cos=0.030), tot_loss_proj:2.354 [t=0.30s]
prediction: ['[CLS] elf is paced awkwardly paced story circuit the soap opera ish [SEP]']
[ 600/2000] tot_loss=1.918 (perp=9.020, rec=0.084, cos=0.030), tot_loss_proj:2.349 [t=0.30s]
prediction: ['[CLS] elf is paced awkwardly paced story circuit the soap opera ish [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.846 (perp=8.619, rec=0.091, cos=0.031), tot_loss_proj:2.221 [t=0.30s]
prediction: ['[CLS] elf is paced awkwardly paced circuit the soap opera ish story [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.847 (perp=8.619, rec=0.093, cos=0.030), tot_loss_proj:2.225 [t=0.30s]
prediction: ['[CLS] elf is paced awkwardly paced circuit the soap opera ish story [SEP]']
[ 750/2000] tot_loss=1.841 (perp=8.619, rec=0.087, cos=0.030), tot_loss_proj:2.216 [t=0.30s]
prediction: ['[CLS] elf is paced awkwardly paced circuit the soap opera ish story [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.797 (perp=8.397, rec=0.088, cos=0.030), tot_loss_proj:2.244 [t=0.30s]
prediction: ['[CLS] elf is paced awkwardly paced circuit soap opera the ish story [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.673 (perp=7.804, rec=0.082, cos=0.030), tot_loss_proj:2.119 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera the elf ish story [SEP]']
[ 900/2000] tot_loss=1.680 (perp=7.804, rec=0.089, cos=0.030), tot_loss_proj:2.133 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera the elf ish story [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.672 (perp=7.804, rec=0.081, cos=0.030), tot_loss_proj:2.122 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera the elf ish story [SEP]']
Attempt swap
[1000/2000] tot_loss=1.676 (perp=7.804, rec=0.085, cos=0.030), tot_loss_proj:2.119 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera the elf ish story [SEP]']
[1050/2000] tot_loss=1.678 (perp=7.804, rec=0.087, cos=0.030), tot_loss_proj:2.125 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera the elf ish story [SEP]']
Attempt swap
[1100/2000] tot_loss=1.663 (perp=7.804, rec=0.072, cos=0.030), tot_loss_proj:2.125 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera the elf ish story [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.623 (perp=7.560, rec=0.080, cos=0.030), tot_loss_proj:1.969 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
[1200/2000] tot_loss=1.628 (perp=7.560, rec=0.086, cos=0.030), tot_loss_proj:1.971 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
Attempt swap
[1250/2000] tot_loss=1.619 (perp=7.560, rec=0.076, cos=0.030), tot_loss_proj:1.968 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
Attempt swap
[1300/2000] tot_loss=1.622 (perp=7.560, rec=0.080, cos=0.030), tot_loss_proj:1.969 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
[1350/2000] tot_loss=1.620 (perp=7.560, rec=0.078, cos=0.030), tot_loss_proj:1.968 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
Attempt swap
[1400/2000] tot_loss=1.619 (perp=7.560, rec=0.076, cos=0.030), tot_loss_proj:1.972 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
Attempt swap
[1450/2000] tot_loss=1.619 (perp=7.560, rec=0.077, cos=0.030), tot_loss_proj:1.970 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
[1500/2000] tot_loss=1.629 (perp=7.560, rec=0.086, cos=0.030), tot_loss_proj:1.971 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
Attempt swap
[1550/2000] tot_loss=1.615 (perp=7.560, rec=0.073, cos=0.030), tot_loss_proj:1.968 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
Attempt swap
[1600/2000] tot_loss=1.618 (perp=7.560, rec=0.076, cos=0.030), tot_loss_proj:1.965 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
[1650/2000] tot_loss=1.608 (perp=7.560, rec=0.065, cos=0.030), tot_loss_proj:1.970 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
Attempt swap
[1700/2000] tot_loss=1.626 (perp=7.560, rec=0.084, cos=0.030), tot_loss_proj:1.970 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
Attempt swap
[1750/2000] tot_loss=1.617 (perp=7.560, rec=0.074, cos=0.030), tot_loss_proj:1.965 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]']
[1800/2000] tot_loss=1.601 (perp=7.462, rec=0.078, cos=0.030), tot_loss_proj:1.881 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera - the ish story [SEP]']
Attempt swap
[1850/2000] tot_loss=1.599 (perp=7.462, rec=0.076, cos=0.030), tot_loss_proj:1.876 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera - the ish story [SEP]']
Attempt swap
[1900/2000] tot_loss=1.607 (perp=7.462, rec=0.085, cos=0.030), tot_loss_proj:1.875 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera - the ish story [SEP]']
[1950/2000] tot_loss=1.608 (perp=7.462, rec=0.085, cos=0.030), tot_loss_proj:1.875 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera - the ish story [SEP]']
Attempt swap
[2000/2000] tot_loss=1.598 (perp=7.462, rec=0.075, cos=0.030), tot_loss_proj:1.875 [t=0.30s]
prediction: ['[CLS] is paced awkwardly paced circuit soap opera - the ish story [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] is paced awkwardly paced circuit soap opera if the ish story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 84.615 | r: 100.000
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 75.000 | p: 69.231 | r: 81.818
rougeLsum  | fm: 75.000 | p: 69.231 | r: 81.818
r1fm+r2fm = 128.030

[Aggregate metrics]:
rouge1     | fm: 90.484 | p: 90.055 | r: 91.006
rouge2     | fm: 61.436 | p: 61.283 | r: 61.661
rougeL     | fm: 79.899 | p: 79.549 | r: 80.329
rougeLsum  | fm: 79.937 | p: 79.662 | r: 80.369
r1fm+r2fm = 151.920

input #60 time: 0:11:55 | total time: 12:50:26


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.9883496764181929
highest_index [0]
highest [0.9883496764181929]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.974085807800293 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9723280668258667 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9598543047904968 for ['[CLS] alta http cocked [SEP]']
[Init] best rec loss: 0.9547430276870728 for ['[CLS] prints england vague [SEP]']
[Init] best rec loss: 0.936743438243866 for ['[CLS] mouth lastless [SEP]']
[Init] best rec loss: 0.9266228079795837 for ['[CLS] readyppetphonic [SEP]']
[Init] best rec loss: 0.8951928019523621 for ['[CLS] says -vino [SEP]']
[Init] best rec loss: 0.8886251449584961 for ['[CLS] plan welloic [SEP]']
[Init] best rec loss: 0.8837878704071045 for ['[CLS] vehicle surrounding south [SEP]']
[Init] best perm rec loss: 0.8796082735061646 for ['[CLS] surrounding vehicle south [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.897 (perp=8.308, rec=0.208, cos=0.027), tot_loss_proj:2.112 [t=0.30s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 100/2000] tot_loss=1.863 (perp=8.308, rec=0.176, cos=0.025), tot_loss_proj:2.110 [t=0.30s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 150/2000] tot_loss=1.840 (perp=8.308, rec=0.154, cos=0.025), tot_loss_proj:2.100 [t=0.30s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 200/2000] tot_loss=1.829 (perp=8.308, rec=0.143, cos=0.024), tot_loss_proj:2.105 [t=0.30s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.835 (perp=8.308, rec=0.150, cos=0.024), tot_loss_proj:2.108 [t=0.30s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 300/2000] tot_loss=1.822 (perp=8.308, rec=0.136, cos=0.024), tot_loss_proj:2.102 [t=0.30s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.837 (perp=8.308, rec=0.151, cos=0.024), tot_loss_proj:2.101 [t=0.30s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.836 (perp=8.308, rec=0.150, cos=0.024), tot_loss_proj:2.102 [t=0.30s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 450/2000] tot_loss=1.829 (perp=8.308, rec=0.143, cos=0.024), tot_loss_proj:2.106 [t=0.30s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.817 (perp=8.308, rec=0.130, cos=0.025), tot_loss_proj:2.098 [t=0.30s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.521 (perp=7.102, rec=0.077, cos=0.023), tot_loss_proj:1.679 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.510 (perp=7.102, rec=0.066, cos=0.023), tot_loss_proj:1.672 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.507 (perp=7.102, rec=0.063, cos=0.023), tot_loss_proj:1.678 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.512 (perp=7.102, rec=0.069, cos=0.023), tot_loss_proj:1.669 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.519 (perp=7.102, rec=0.075, cos=0.023), tot_loss_proj:1.668 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.504 (perp=7.102, rec=0.060, cos=0.023), tot_loss_proj:1.671 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.511 (perp=7.102, rec=0.068, cos=0.023), tot_loss_proj:1.665 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.514 (perp=7.102, rec=0.071, cos=0.023), tot_loss_proj:1.662 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.494 (perp=7.102, rec=0.050, cos=0.023), tot_loss_proj:1.673 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.522 (perp=7.102, rec=0.078, cos=0.023), tot_loss_proj:1.673 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.512 (perp=7.102, rec=0.069, cos=0.023), tot_loss_proj:1.662 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.514 (perp=7.102, rec=0.071, cos=0.023), tot_loss_proj:1.672 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.506 (perp=7.102, rec=0.062, cos=0.023), tot_loss_proj:1.656 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.516 (perp=7.102, rec=0.072, cos=0.023), tot_loss_proj:1.664 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.499 (perp=7.102, rec=0.055, cos=0.023), tot_loss_proj:1.662 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.503 (perp=7.102, rec=0.059, cos=0.023), tot_loss_proj:1.666 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.504 (perp=7.102, rec=0.060, cos=0.023), tot_loss_proj:1.668 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.497 (perp=7.102, rec=0.053, cos=0.023), tot_loss_proj:1.658 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.518 (perp=7.102, rec=0.075, cos=0.023), tot_loss_proj:1.670 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.503 (perp=7.102, rec=0.059, cos=0.023), tot_loss_proj:1.668 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.494 (perp=7.102, rec=0.050, cos=0.023), tot_loss_proj:1.658 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.506 (perp=7.102, rec=0.062, cos=0.023), tot_loss_proj:1.660 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.513 (perp=7.102, rec=0.070, cos=0.023), tot_loss_proj:1.658 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.513 (perp=7.102, rec=0.069, cos=0.023), tot_loss_proj:1.669 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.512 (perp=7.102, rec=0.068, cos=0.023), tot_loss_proj:1.672 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.495 (perp=7.102, rec=0.051, cos=0.023), tot_loss_proj:1.667 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.496 (perp=7.102, rec=0.053, cos=0.023), tot_loss_proj:1.660 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.507 (perp=7.102, rec=0.063, cos=0.023), tot_loss_proj:1.657 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.519 (perp=7.102, rec=0.076, cos=0.023), tot_loss_proj:1.669 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.513 (perp=7.102, rec=0.069, cos=0.023), tot_loss_proj:1.668 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.650 | p: 90.217 | r: 91.143
rouge2     | fm: 62.390 | p: 62.285 | r: 62.562
rougeL     | fm: 80.136 | p: 79.823 | r: 80.542
rougeLsum  | fm: 80.307 | p: 80.033 | r: 80.698
r1fm+r2fm = 153.040

input #61 time: 0:11:53 | total time: 13:02:19


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.9876269370872879
highest_index [0]
highest [0.9876269370872879]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9194455742835999 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.8968601822853088 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.8967611789703369 for ['[CLS] services te isbnentseye久 researchcreen past sequencingwn can pier precise linda erica monk val contestbe foreign [SEP]']
[Init] best rec loss: 0.8913489580154419 for ['[CLS]ining strata won suitedtis near isaac bull worship here techp perhaps assistant kerman negative fisulsion ash too skill [SEP]']
[Init] best rec loss: 0.8868446946144104 for ['[CLS] scout cafeceaeswch novel spot latitude romanwar winter largely talksord liberal sophiehon iii pitchaceathing [SEP]']
[Init] best rec loss: 0.884088933467865 for ['[CLS] butterfly alternative professional all diveleader withstand reins emergency fears rate feet iv bat burn judgeulsive busy give student military [SEP]']
[Init] best rec loss: 0.8766171932220459 for ['[CLS] part remembered victor jayne imagined♭ basket against cheeks barrow battalion whilefold informed had higher outstanding ezio ramirez malta pinyin [SEP]']
[Init] best perm rec loss: 0.8750703930854797 for ['[CLS] outstanding barrow ramirez against had jayne♭ malta remembered victor higherfold cheeks ezio pinyin basket imagined while informed part battalion [SEP]']
[Init] best perm rec loss: 0.8746232986450195 for ['[CLS] jayne higher against victor part ezio ramirez barrow informed remembered had pinyin cheeks♭ malta imagined outstandingfold while basket battalion [SEP]']
[Init] best perm rec loss: 0.8743321299552917 for ['[CLS] higher jaynefold basket victor malta battalion ezio ramirez♭ cheeks while against pinyin barrow informed part outstanding remembered imagined had [SEP]']
[Init] best perm rec loss: 0.8723158836364746 for ['[CLS] battalion part♭ outstanding cheeks victor ezio barrow jayne remembered informed malta while higher imagined pinyin basketfold ramirez against had [SEP]']
[Init] best perm rec loss: 0.8714272379875183 for ['[CLS] informed battalion higher had jayne pinyin ezio while against malta partfold remembered victor cheeks basket ramirez outstanding barrow imagined♭ [SEP]']
[Init] best perm rec loss: 0.8714218735694885 for ['[CLS] pinyin higher ramirez against outstanding imagined cheeks battalion jayne informed while partfold had♭ remembered ezio victor barrow basket malta [SEP]']
[Init] best perm rec loss: 0.8710798621177673 for ['[CLS] jayne victor malta♭ battalionfold barrow ezio cheeks against part outstanding pinyin ramirez remembered imagined while basket higher had informed [SEP]']
[Init] best perm rec loss: 0.8695908784866333 for ['[CLS] remembered basket battalion higher barrow ezio jayne pinyin imagined informed part♭ against victor outstanding ramirez maltafold cheeks while had [SEP]']
[Init] best perm rec loss: 0.8695178627967834 for ['[CLS] jayne higher part againstfold imagined malta basket battalion barrow outstanding while ramirez♭ had victor remembered cheeks pinyin ezio informed [SEP]']
[Init] best perm rec loss: 0.8682190775871277 for ['[CLS] ramirez imagined basket while barrow battalion pinyin♭ victor cheeks remembered had against part higher outstanding malta jaynefold informed ezio [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.516 (perp=10.904, rec=0.308, cos=0.027), tot_loss_proj:3.409 [t=0.31s]
prediction: ['[CLS] grace action necessarily best producer ever code grace grace called them of preventioncolor original high prevention best trick best films [SEP]']
[ 100/2000] tot_loss=2.360 (perp=10.671, rec=0.202, cos=0.024), tot_loss_proj:3.225 [t=0.31s]
prediction: ['[CLS] grace impact to than makes ever robert grace grace to them the prevention she ever best prevention best war best movies [SEP]']
[ 150/2000] tot_loss=2.356 (perp=10.881, rec=0.156, cos=0.024), tot_loss_proj:3.672 [t=0.31s]
prediction: ['[CLS] grace impact to [SEP] make making blame grace grace call for the prevention she ever the prevention best war making movies [SEP]']
[ 200/2000] tot_loss=2.254 (perp=10.492, rec=0.132, cos=0.023), tot_loss_proj:3.779 [t=0.31s]
prediction: ['[CLS] grace to to [SEP] make making blame grace to call for one prevention it ever the prevention best war making movies [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.146 (perp=9.848, rec=0.154, cos=0.023), tot_loss_proj:3.701 [t=0.31s]
prediction: ['[CLS] grace dominated to and venture prevention over grace to call for one this it ever the prevention best war making movies [SEP]']
[ 300/2000] tot_loss=1.922 (perp=8.898, rec=0.119, cos=0.024), tot_loss_proj:3.615 [t=0.31s]
prediction: ['[CLS] grace damage to and work prevention than grace to call for one take and ever the prevention best war making movies [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.828 (perp=8.489, rec=0.107, cos=0.023), tot_loss_proj:3.485 [t=0.31s]
prediction: ['[CLS] grace to to work and prevention than grace to call for one take and ever the prevention best war making movies [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.755 (perp=8.125, rec=0.107, cos=0.022), tot_loss_proj:3.404 [t=0.31s]
prediction: ['[CLS] grace to work and make prevention rather grace to call for one making it ever the prevention best war making movies [SEP]']
[ 450/2000] tot_loss=1.738 (perp=8.094, rec=0.097, cos=0.023), tot_loss_proj:3.446 [t=0.31s]
prediction: ['[CLS] grace to it and make prevention rather grace to call for one making it ever the prevention best war making movies [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.653 (perp=7.690, rec=0.092, cos=0.023), tot_loss_proj:2.634 [t=0.31s]
prediction: ['[CLS] grace to grace it and make prevention rather to call for one making it ever the prevention best war making movies [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.670 (perp=7.794, rec=0.088, cos=0.023), tot_loss_proj:2.654 [t=0.31s]
prediction: ['[CLS] grace to grace it - make prevention rather to call for one making, ever blame the best war making movies [SEP]']
[ 600/2000] tot_loss=1.646 (perp=7.666, rec=0.090, cos=0.024), tot_loss_proj:2.578 [t=0.31s]
prediction: ['[CLS] grace to grace it - make prevention rather to call for one made, ever blame the best war making movies [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.595 (perp=7.419, rec=0.087, cos=0.024), tot_loss_proj:2.407 [t=0.31s]
prediction: ['[CLS] grace to grace it, make prevention rather to call for one made - ever blame the best war making movies [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.578 (perp=7.359, rec=0.082, cos=0.024), tot_loss_proj:2.409 [t=0.31s]
prediction: ['[CLS] grace to grace it, make prevention rather to call for one made - ever blame the best war movies making [SEP]']
[ 750/2000] tot_loss=1.569 (perp=7.359, rec=0.073, cos=0.025), tot_loss_proj:2.401 [t=0.31s]
prediction: ['[CLS] grace to grace it, make prevention rather to call for one made - ever blame the best war movies making [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.557 (perp=7.256, rec=0.082, cos=0.024), tot_loss_proj:2.193 [t=0.31s]
prediction: ['[CLS] grace to grace it, make prevention rather to call for one made - making blame the best war movies ever [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.522 (perp=7.097, rec=0.079, cos=0.024), tot_loss_proj:2.068 [t=0.31s]
prediction: ['[CLS] grace to grace blame, make prevention rather to call for one made - making it the best war movies ever [SEP]']
[ 900/2000] tot_loss=1.517 (perp=7.097, rec=0.074, cos=0.024), tot_loss_proj:2.064 [t=0.31s]
prediction: ['[CLS] grace to grace blame, make prevention rather to call for one made - making it the best war movies ever [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.449 (perp=6.721, rec=0.080, cos=0.024), tot_loss_proj:2.356 [t=0.31s]
prediction: ['[CLS] grace to blame grace, make prevention rather to call for one made - making it the best war movies ever [SEP]']
Attempt swap
[1000/2000] tot_loss=1.448 (perp=6.721, rec=0.079, cos=0.024), tot_loss_proj:2.355 [t=0.31s]
prediction: ['[CLS] grace to blame grace, make prevention rather to call for one made - making it the best war movies ever [SEP]']
[1050/2000] tot_loss=1.444 (perp=6.721, rec=0.075, cos=0.024), tot_loss_proj:2.356 [t=0.31s]
prediction: ['[CLS] grace to blame grace, make prevention rather to call for one made - making it the best war movies ever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.441 (perp=6.721, rec=0.073, cos=0.024), tot_loss_proj:2.361 [t=0.31s]
prediction: ['[CLS] grace to blame grace, make prevention rather to call for one made - making it the best war movies ever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.433 (perp=6.721, rec=0.064, cos=0.024), tot_loss_proj:2.361 [t=0.31s]
prediction: ['[CLS] grace to blame grace, make prevention rather to call for one made - making it the best war movies ever [SEP]']
[1200/2000] tot_loss=1.412 (perp=6.594, rec=0.069, cos=0.024), tot_loss_proj:2.382 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for one made - making it the best war movies ever [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.303 (perp=6.083, rec=0.062, cos=0.024), tot_loss_proj:1.952 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for one - making it the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.291 (perp=6.016, rec=0.064, cos=0.024), tot_loss_proj:1.886 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for it - making one the best war movies ever made [SEP]']
[1350/2000] tot_loss=1.299 (perp=6.016, rec=0.072, cos=0.024), tot_loss_proj:1.892 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for it - making one the best war movies ever made [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.289 (perp=5.980, rec=0.069, cos=0.024), tot_loss_proj:2.377 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
Attempt swap
[1450/2000] tot_loss=1.295 (perp=5.980, rec=0.075, cos=0.024), tot_loss_proj:2.376 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
[1500/2000] tot_loss=1.297 (perp=5.980, rec=0.077, cos=0.024), tot_loss_proj:2.380 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
Attempt swap
[1550/2000] tot_loss=1.292 (perp=5.980, rec=0.072, cos=0.024), tot_loss_proj:2.371 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
Attempt swap
[1600/2000] tot_loss=1.288 (perp=5.980, rec=0.067, cos=0.024), tot_loss_proj:2.384 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
[1650/2000] tot_loss=1.300 (perp=5.980, rec=0.079, cos=0.024), tot_loss_proj:2.377 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
Attempt swap
[1700/2000] tot_loss=1.296 (perp=5.980, rec=0.075, cos=0.024), tot_loss_proj:2.378 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
Attempt swap
[1750/2000] tot_loss=1.287 (perp=5.980, rec=0.067, cos=0.024), tot_loss_proj:2.379 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
[1800/2000] tot_loss=1.287 (perp=5.980, rec=0.066, cos=0.024), tot_loss_proj:2.378 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
Attempt swap
[1850/2000] tot_loss=1.296 (perp=5.980, rec=0.075, cos=0.024), tot_loss_proj:2.387 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
Attempt swap
[1900/2000] tot_loss=1.299 (perp=5.980, rec=0.078, cos=0.024), tot_loss_proj:2.382 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
[1950/2000] tot_loss=1.288 (perp=5.980, rec=0.067, cos=0.024), tot_loss_proj:2.382 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.306 (perp=6.016, rec=0.078, cos=0.025), tot_loss_proj:1.897 [t=0.31s]
prediction: ['[CLS] grace to blame grace, rather prevention rather to call for it - making one the best war movies ever made [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] grace to blame grace, rather prevention rather to call for making it - one the best war movies ever made [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.372 | p: 90.476 | r: 86.364
rouge2     | fm: 63.415 | p: 65.000 | r: 61.905
rougeL     | fm: 74.419 | p: 76.190 | r: 72.727
rougeLsum  | fm: 74.419 | p: 76.190 | r: 72.727
r1fm+r2fm = 151.787

[Aggregate metrics]:
rouge1     | fm: 90.574 | p: 90.279 | r: 91.031
rouge2     | fm: 62.460 | p: 62.372 | r: 62.534
rougeL     | fm: 80.128 | p: 79.825 | r: 80.459
rougeLsum  | fm: 80.152 | p: 79.892 | r: 80.526
r1fm+r2fm = 153.034

input #62 time: 0:12:16 | total time: 13:14:36


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9843433476073585
highest_index [0]
highest [0.9843433476073585]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.8068115711212158 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.7170369625091553 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.6886427402496338 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best perm rec loss: 0.6868054270744324 for ['[CLS] working spendism brighter written [SEP]']
[Init] best perm rec loss: 0.68547123670578 for ['[CLS]ism spend written brighter working [SEP]']
[Init] best perm rec loss: 0.6854546070098877 for ['[CLS] written brighter workingism spend [SEP]']
[Init] best perm rec loss: 0.6849293112754822 for ['[CLS] working writtenism spend brighter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.035 (perp=9.208, rec=0.160, cos=0.034), tot_loss_proj:2.923 [t=0.30s]
prediction: ['[CLS] looking ticket a return ticket [SEP]']
[ 100/2000] tot_loss=1.334 (perp=6.111, rec=0.081, cos=0.031), tot_loss_proj:1.333 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 150/2000] tot_loss=1.331 (perp=6.111, rec=0.079, cos=0.030), tot_loss_proj:1.346 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 200/2000] tot_loss=1.333 (perp=6.111, rec=0.080, cos=0.031), tot_loss_proj:1.347 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.324 (perp=6.111, rec=0.071, cos=0.030), tot_loss_proj:1.339 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 300/2000] tot_loss=1.321 (perp=6.111, rec=0.067, cos=0.031), tot_loss_proj:1.330 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.320 (perp=6.111, rec=0.066, cos=0.031), tot_loss_proj:1.345 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.321 (perp=6.111, rec=0.068, cos=0.031), tot_loss_proj:1.341 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 450/2000] tot_loss=1.318 (perp=6.111, rec=0.065, cos=0.031), tot_loss_proj:1.341 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.320 (perp=6.111, rec=0.067, cos=0.030), tot_loss_proj:1.349 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.335 (perp=6.111, rec=0.082, cos=0.031), tot_loss_proj:1.333 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 600/2000] tot_loss=1.314 (perp=6.111, rec=0.061, cos=0.031), tot_loss_proj:1.326 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.317 (perp=6.111, rec=0.064, cos=0.031), tot_loss_proj:1.332 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.313 (perp=6.111, rec=0.060, cos=0.031), tot_loss_proj:1.346 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 750/2000] tot_loss=1.316 (perp=6.111, rec=0.063, cos=0.031), tot_loss_proj:1.344 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.317 (perp=6.111, rec=0.064, cos=0.031), tot_loss_proj:1.341 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.310 (perp=6.111, rec=0.057, cos=0.031), tot_loss_proj:1.332 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 900/2000] tot_loss=1.310 (perp=6.111, rec=0.057, cos=0.031), tot_loss_proj:1.340 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.311 (perp=6.111, rec=0.058, cos=0.031), tot_loss_proj:1.344 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.326 (perp=6.111, rec=0.073, cos=0.031), tot_loss_proj:1.343 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1050/2000] tot_loss=1.309 (perp=6.111, rec=0.056, cos=0.031), tot_loss_proj:1.343 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.315 (perp=6.111, rec=0.062, cos=0.031), tot_loss_proj:1.338 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.322 (perp=6.111, rec=0.069, cos=0.031), tot_loss_proj:1.341 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1200/2000] tot_loss=1.318 (perp=6.111, rec=0.065, cos=0.031), tot_loss_proj:1.349 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.317 (perp=6.111, rec=0.063, cos=0.031), tot_loss_proj:1.339 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.321 (perp=6.111, rec=0.068, cos=0.031), tot_loss_proj:1.345 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.315 (perp=6.111, rec=0.062, cos=0.031), tot_loss_proj:1.338 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.317 (perp=6.111, rec=0.064, cos=0.031), tot_loss_proj:1.333 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.314 (perp=6.111, rec=0.061, cos=0.031), tot_loss_proj:1.347 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.326 (perp=6.111, rec=0.073, cos=0.031), tot_loss_proj:1.354 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.314 (perp=6.111, rec=0.061, cos=0.031), tot_loss_proj:1.345 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.317 (perp=6.111, rec=0.064, cos=0.031), tot_loss_proj:1.338 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.310 (perp=6.111, rec=0.057, cos=0.031), tot_loss_proj:1.344 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.319 (perp=6.111, rec=0.065, cos=0.031), tot_loss_proj:1.342 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.318 (perp=6.111, rec=0.065, cos=0.031), tot_loss_proj:1.337 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.309 (perp=6.111, rec=0.056, cos=0.031), tot_loss_proj:1.345 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.318 (perp=6.111, rec=0.065, cos=0.031), tot_loss_proj:1.336 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.314 (perp=6.111, rec=0.061, cos=0.031), tot_loss_proj:1.341 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.316 (perp=6.111, rec=0.063, cos=0.031), tot_loss_proj:1.344 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.324 (perp=6.111, rec=0.070, cos=0.031), tot_loss_proj:1.339 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.830 | p: 90.532 | r: 91.293
rouge2     | fm: 63.013 | p: 62.924 | r: 63.132
rougeL     | fm: 80.405 | p: 80.121 | r: 80.782
rougeLsum  | fm: 80.505 | p: 80.225 | r: 80.870
r1fm+r2fm = 153.843

input #63 time: 0:11:54 | total time: 13:26:30


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.9866316775759709
highest_index [0]
highest [0.9866316775759709]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8858792781829834 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8369130492210388 for ['[CLS] dale fuel picked [SEP]']
[Init] best rec loss: 0.8081837892532349 for ['[CLS] david [CLS] earliest [SEP]']
[Init] best rec loss: 0.7318680286407471 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6755998730659485 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6745870113372803 for ['[CLS] visionsonale water [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.910 (perp=8.961, rec=0.089, cos=0.029), tot_loss_proj:2.217 [t=0.30s]
prediction: ['[CLS] strange the horror [SEP]']
[ 100/2000] tot_loss=1.888 (perp=8.961, rec=0.070, cos=0.026), tot_loss_proj:2.236 [t=0.30s]
prediction: ['[CLS] strange the horror [SEP]']
[ 150/2000] tot_loss=1.888 (perp=8.961, rec=0.066, cos=0.030), tot_loss_proj:2.224 [t=0.30s]
prediction: ['[CLS] strange the horror [SEP]']
[ 200/2000] tot_loss=1.869 (perp=8.961, rec=0.050, cos=0.026), tot_loss_proj:2.228 [t=0.30s]
prediction: ['[CLS] strange the horror [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.705 (perp=8.065, rec=0.067, cos=0.025), tot_loss_proj:1.728 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 300/2000] tot_loss=1.692 (perp=8.065, rec=0.053, cos=0.026), tot_loss_proj:1.728 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.698 (perp=8.065, rec=0.059, cos=0.026), tot_loss_proj:1.738 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.699 (perp=8.065, rec=0.060, cos=0.027), tot_loss_proj:1.727 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.707 (perp=8.065, rec=0.067, cos=0.026), tot_loss_proj:1.731 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.692 (perp=8.065, rec=0.053, cos=0.026), tot_loss_proj:1.730 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.712 (perp=8.065, rec=0.073, cos=0.026), tot_loss_proj:1.727 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.697 (perp=8.065, rec=0.058, cos=0.026), tot_loss_proj:1.729 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.701 (perp=8.065, rec=0.061, cos=0.026), tot_loss_proj:1.722 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.703 (perp=8.065, rec=0.063, cos=0.027), tot_loss_proj:1.731 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.698 (perp=8.065, rec=0.058, cos=0.026), tot_loss_proj:1.727 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.698 (perp=8.065, rec=0.059, cos=0.026), tot_loss_proj:1.724 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.704 (perp=8.065, rec=0.065, cos=0.026), tot_loss_proj:1.728 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.696 (perp=8.065, rec=0.057, cos=0.026), tot_loss_proj:1.727 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.696 (perp=8.065, rec=0.057, cos=0.027), tot_loss_proj:1.710 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.701 (perp=8.065, rec=0.061, cos=0.026), tot_loss_proj:1.717 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.695 (perp=8.065, rec=0.056, cos=0.026), tot_loss_proj:1.729 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.695 (perp=8.065, rec=0.056, cos=0.026), tot_loss_proj:1.727 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.701 (perp=8.065, rec=0.062, cos=0.027), tot_loss_proj:1.722 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.700 (perp=8.065, rec=0.061, cos=0.027), tot_loss_proj:1.734 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.696 (perp=8.065, rec=0.056, cos=0.027), tot_loss_proj:1.728 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.688 (perp=8.065, rec=0.049, cos=0.026), tot_loss_proj:1.724 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.698 (perp=8.065, rec=0.058, cos=0.027), tot_loss_proj:1.739 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.696 (perp=8.065, rec=0.057, cos=0.027), tot_loss_proj:1.718 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.695 (perp=8.065, rec=0.056, cos=0.026), tot_loss_proj:1.730 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.710 (perp=8.065, rec=0.071, cos=0.026), tot_loss_proj:1.728 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.700 (perp=8.065, rec=0.061, cos=0.027), tot_loss_proj:1.723 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.703 (perp=8.065, rec=0.063, cos=0.026), tot_loss_proj:1.732 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.693 (perp=8.065, rec=0.054, cos=0.027), tot_loss_proj:1.718 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.701 (perp=8.065, rec=0.061, cos=0.026), tot_loss_proj:1.721 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.700 (perp=8.065, rec=0.061, cos=0.027), tot_loss_proj:1.734 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.703 (perp=8.065, rec=0.063, cos=0.027), tot_loss_proj:1.731 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.700 (perp=8.065, rec=0.060, cos=0.027), tot_loss_proj:1.728 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.707 (perp=8.065, rec=0.068, cos=0.026), tot_loss_proj:1.726 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.692 (perp=8.065, rec=0.052, cos=0.027), tot_loss_proj:1.736 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.701 (perp=8.065, rec=0.061, cos=0.027), tot_loss_proj:1.728 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.900 | p: 90.592 | r: 91.408
rouge2     | fm: 63.334 | p: 63.227 | r: 63.490
rougeL     | fm: 80.987 | p: 80.702 | r: 81.312
rougeLsum  | fm: 80.880 | p: 80.599 | r: 81.227
r1fm+r2fm = 154.234

input #64 time: 0:11:53 | total time: 13:38:23


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9888752734070956
highest_index [0]
highest [0.9888752734070956]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 0.8910266757011414 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.8780144453048706 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.8644022941589355 for ['[CLS] dir northern opens gasam acute diocese ban missile [SEP]']
[Init] best rec loss: 0.8489140868186951 for ['[CLS] nyunce coalition pdf dailyenburg registry romanesqueric [SEP]']
[Init] best rec loss: 0.8403517603874207 for ['[CLS] script the classning lau tape from later skate [SEP]']
[Init] best rec loss: 0.839885413646698 for ['[CLS] society djs dry beltryn cockpit [MASK] tiger an [SEP]']
[Init] best rec loss: 0.8319296836853027 for ['[CLS] health kuept scenicne contact will savamac [SEP]']
[Init] best rec loss: 0.8157580494880676 for ['[CLS] dancer relative being bar shoulder allmusic original eatingolic [SEP]']
[Init] best rec loss: 0.7902067303657532 for ['[CLS] graphic - oxygen jessie go distinguished they alt decommissioned [SEP]']
[Init] best rec loss: 0.7631354331970215 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.7617823481559753 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.7610898613929749 for ['[CLS] even news pu someday fun general oversmamenthoff [SEP]']
[Init] best perm rec loss: 0.7599736452102661 for ['[CLS] pu news even oversmament someday funhoff general [SEP]']
[Init] best perm rec loss: 0.7590749263763428 for ['[CLS] news generalmament overs pu even funhoff someday [SEP]']
[Init] best perm rec loss: 0.7588030099868774 for ['[CLS] general someday fun news overs even puhoffmament [SEP]']
[Init] best perm rec loss: 0.7578666806221008 for ['[CLS] pumament even newshoff fun someday overs general [SEP]']
[Init] best perm rec loss: 0.7557880878448486 for ['[CLS] general fun evenhoff oversmament someday pu news [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.300 (perp=9.986, rec=0.271, cos=0.032), tot_loss_proj:2.644 [t=0.30s]
prediction: ['[CLS], joy joy game bam joy.ous joy [SEP]']
[ 100/2000] tot_loss=2.129 (perp=9.721, rec=0.161, cos=0.023), tot_loss_proj:2.621 [t=0.30s]
prediction: ['[CLS], joy joy film rom joyous ofous [SEP]']
[ 150/2000] tot_loss=2.109 (perp=9.721, rec=0.142, cos=0.022), tot_loss_proj:2.611 [t=0.30s]
prediction: ['[CLS], joy joy film rom joyous ofous [SEP]']
[ 200/2000] tot_loss=2.090 (perp=9.721, rec=0.122, cos=0.024), tot_loss_proj:2.617 [t=0.30s]
prediction: ['[CLS], joy joy film rom joyous ofous [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.577 (perp=7.241, rec=0.107, cos=0.022), tot_loss_proj:2.166 [t=0.30s]
prediction: ['[CLS], joy joyous rom joyous of film [SEP]']
[ 300/2000] tot_loss=1.575 (perp=7.241, rec=0.104, cos=0.023), tot_loss_proj:2.174 [t=0.30s]
prediction: ['[CLS], joy joyous rom joyous of film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.901 (perp=8.954, rec=0.088, cos=0.022), tot_loss_proj:2.332 [t=0.30s]
prediction: ['[CLS], joy joyous rom joyp of film [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.617 (perp=7.331, rec=0.128, cos=0.023), tot_loss_proj:1.956 [t=0.30s]
prediction: ['[CLS], joy joy joyous romp a film [SEP]']
[ 450/2000] tot_loss=1.484 (perp=6.885, rec=0.085, cos=0.022), tot_loss_proj:1.798 [t=0.30s]
prediction: ['[CLS], joy joy joyous romp of film [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.163 (perp=4.958, rec=0.149, cos=0.022), tot_loss_proj:1.371 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.744 (perp=8.051, rec=0.112, cos=0.022), tot_loss_proj:2.222 [t=0.30s]
prediction: ['[CLS] joy joy, joyous romous of film [SEP]']
[ 600/2000] tot_loss=1.748 (perp=8.051, rec=0.115, cos=0.022), tot_loss_proj:2.222 [t=0.30s]
prediction: ['[CLS] joy joy, joyous romous of film [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.550 (perp=7.087, rec=0.110, cos=0.022), tot_loss_proj:1.932 [t=0.30s]
prediction: ['[CLS] joyousous, joyous rom of film [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.477 (perp=6.762, rec=0.102, cos=0.022), tot_loss_proj:1.815 [t=0.30s]
prediction: ['[CLS]ous joyous, joyous rom of film [SEP]']
[ 750/2000] tot_loss=1.480 (perp=6.762, rec=0.105, cos=0.022), tot_loss_proj:1.815 [t=0.30s]
prediction: ['[CLS]ous joyous, joyous rom of film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.545 (perp=7.226, rec=0.077, cos=0.022), tot_loss_proj:1.958 [t=0.30s]
prediction: ['[CLS]p joyous, joyous rom of film [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.104 (perp=4.958, rec=0.089, cos=0.023), tot_loss_proj:1.361 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
[ 900/2000] tot_loss=1.112 (perp=4.958, rec=0.098, cos=0.022), tot_loss_proj:1.359 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.109 (perp=4.958, rec=0.096, cos=0.022), tot_loss_proj:1.364 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.101 (perp=4.958, rec=0.087, cos=0.022), tot_loss_proj:1.367 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
[1050/2000] tot_loss=1.110 (perp=4.958, rec=0.097, cos=0.022), tot_loss_proj:1.364 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.091 (perp=4.958, rec=0.077, cos=0.022), tot_loss_proj:1.359 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.106 (perp=4.958, rec=0.092, cos=0.022), tot_loss_proj:1.364 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
[1200/2000] tot_loss=1.120 (perp=4.958, rec=0.106, cos=0.022), tot_loss_proj:1.370 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.110 (perp=4.958, rec=0.097, cos=0.022), tot_loss_proj:1.364 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.096 (perp=4.958, rec=0.083, cos=0.022), tot_loss_proj:1.374 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
[1350/2000] tot_loss=1.105 (perp=4.958, rec=0.091, cos=0.022), tot_loss_proj:1.370 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.107 (perp=4.958, rec=0.094, cos=0.022), tot_loss_proj:1.360 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.104 (perp=4.958, rec=0.090, cos=0.022), tot_loss_proj:1.361 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
[1500/2000] tot_loss=1.095 (perp=4.958, rec=0.082, cos=0.022), tot_loss_proj:1.366 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.104 (perp=4.958, rec=0.090, cos=0.022), tot_loss_proj:1.371 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.108 (perp=4.958, rec=0.094, cos=0.022), tot_loss_proj:1.374 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
[1650/2000] tot_loss=1.104 (perp=4.958, rec=0.090, cos=0.022), tot_loss_proj:1.373 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.089 (perp=4.958, rec=0.075, cos=0.022), tot_loss_proj:1.370 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.095 (perp=4.958, rec=0.081, cos=0.022), tot_loss_proj:1.370 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
[1800/2000] tot_loss=1.101 (perp=4.958, rec=0.088, cos=0.022), tot_loss_proj:1.365 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.098 (perp=4.958, rec=0.084, cos=0.022), tot_loss_proj:1.374 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.109 (perp=4.958, rec=0.095, cos=0.022), tot_loss_proj:1.366 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
[1950/2000] tot_loss=1.103 (perp=4.958, rec=0.089, cos=0.022), tot_loss_proj:1.364 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.111 (perp=4.958, rec=0.098, cos=0.022), tot_loss_proj:1.372 [t=0.30s]
prediction: ['[CLS] joyous, joyous romp of film [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] joyous, joyous romp of film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 152.381

[Aggregate metrics]:
rouge1     | fm: 90.823 | p: 90.497 | r: 91.255
rouge2     | fm: 63.501 | p: 63.354 | r: 63.632
rougeL     | fm: 80.936 | p: 80.685 | r: 81.282
rougeLsum  | fm: 80.986 | p: 80.701 | r: 81.295
r1fm+r2fm = 154.324

input #65 time: 0:12:02 | total time: 13:50:25


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9877478027996895
highest_index [0]
highest [0.9877478027996895]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.8420715928077698 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.8302870988845825 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.8187599778175354 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8046236038208008 for ['[CLS] riot equal private peculiar [SEP]']
[Init] best rec loss: 0.7968536019325256 for ['[CLS] complied man ready panic [SEP]']
[Init] best rec loss: 0.7818582653999329 for ['[CLS] space leader screen [CLS] [SEP]']
[Init] best rec loss: 0.7768370509147644 for ['[CLS] september st minimum invitation [SEP]']
[Init] best rec loss: 0.7538819909095764 for ['[CLS] helmet stared true deposit [SEP]']
[Init] best rec loss: 0.7383501529693604 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best perm rec loss: 0.7320297956466675 for ['[CLS] juliet game shoulders scout [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.375 (perp=10.720, rec=0.202, cos=0.029), tot_loss_proj:2.547 [t=0.30s]
prediction: ['[CLS] tolkien fan longtime fan [SEP]']
[ 100/2000] tot_loss=2.398 (perp=11.510, rec=0.072, cos=0.024), tot_loss_proj:2.826 [t=0.30s]
prediction: ['[CLS] tolkien longtime a fan [SEP]']
[ 150/2000] tot_loss=2.386 (perp=11.510, rec=0.060, cos=0.024), tot_loss_proj:2.810 [t=0.30s]
prediction: ['[CLS] tolkien longtime a fan [SEP]']
[ 200/2000] tot_loss=2.381 (perp=11.510, rec=0.055, cos=0.024), tot_loss_proj:2.812 [t=0.30s]
prediction: ['[CLS] tolkien longtime a fan [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.639 (perp=7.672, rec=0.081, cos=0.024), tot_loss_proj:1.623 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.625 (perp=7.672, rec=0.067, cos=0.024), tot_loss_proj:1.609 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.615 (perp=7.672, rec=0.056, cos=0.024), tot_loss_proj:1.619 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.605 (perp=7.672, rec=0.047, cos=0.024), tot_loss_proj:1.620 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.614 (perp=7.672, rec=0.055, cos=0.024), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.600 (perp=7.672, rec=0.041, cos=0.024), tot_loss_proj:1.614 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.616 (perp=7.672, rec=0.057, cos=0.024), tot_loss_proj:1.609 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.627 (perp=7.672, rec=0.068, cos=0.024), tot_loss_proj:1.630 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.611 (perp=7.672, rec=0.052, cos=0.024), tot_loss_proj:1.616 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.623 (perp=7.672, rec=0.065, cos=0.024), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.627 (perp=7.672, rec=0.068, cos=0.024), tot_loss_proj:1.620 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.615 (perp=7.672, rec=0.057, cos=0.024), tot_loss_proj:1.614 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.619 (perp=7.672, rec=0.060, cos=0.024), tot_loss_proj:1.632 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.625 (perp=7.672, rec=0.066, cos=0.024), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.615 (perp=7.672, rec=0.056, cos=0.024), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.613 (perp=7.672, rec=0.054, cos=0.024), tot_loss_proj:1.623 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.612 (perp=7.672, rec=0.053, cos=0.024), tot_loss_proj:1.615 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.619 (perp=7.672, rec=0.060, cos=0.024), tot_loss_proj:1.630 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.613 (perp=7.672, rec=0.054, cos=0.024), tot_loss_proj:1.629 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.623 (perp=7.672, rec=0.064, cos=0.024), tot_loss_proj:1.634 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.631 (perp=7.672, rec=0.072, cos=0.024), tot_loss_proj:1.615 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.604 (perp=7.672, rec=0.046, cos=0.024), tot_loss_proj:1.615 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.620 (perp=7.672, rec=0.061, cos=0.024), tot_loss_proj:1.623 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.624 (perp=7.672, rec=0.065, cos=0.024), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.623 (perp=7.672, rec=0.065, cos=0.024), tot_loss_proj:1.617 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.614 (perp=7.672, rec=0.055, cos=0.024), tot_loss_proj:1.615 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.623 (perp=7.672, rec=0.065, cos=0.024), tot_loss_proj:1.602 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.612 (perp=7.672, rec=0.053, cos=0.024), tot_loss_proj:1.620 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.626 (perp=7.672, rec=0.067, cos=0.024), tot_loss_proj:1.623 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.612 (perp=7.672, rec=0.053, cos=0.024), tot_loss_proj:1.624 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.617 (perp=7.672, rec=0.058, cos=0.024), tot_loss_proj:1.621 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.615 (perp=7.672, rec=0.056, cos=0.024), tot_loss_proj:1.617 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.604 (perp=7.672, rec=0.046, cos=0.024), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.616 (perp=7.672, rec=0.058, cos=0.024), tot_loss_proj:1.629 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.614 (perp=7.672, rec=0.056, cos=0.024), tot_loss_proj:1.623 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.626 (perp=7.672, rec=0.067, cos=0.024), tot_loss_proj:1.618 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.944 | p: 90.641 | r: 91.377
rouge2     | fm: 64.060 | p: 63.946 | r: 64.228
rougeL     | fm: 81.166 | p: 80.930 | r: 81.494
rougeLsum  | fm: 81.210 | p: 80.903 | r: 81.566
r1fm+r2fm = 155.003

input #66 time: 0:11:54 | total time: 14:02:20


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.9888603960602529
highest_index [0]
highest [0.9888603960602529]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 0.9466764330863953 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9313325881958008 for ['[CLS] acretis smiley moth toward ass rhine xbox piece rebranded [SEP]']
[Init] best rec loss: 0.9141383171081543 for ['[CLS] fastestedance ;eding buckingham jill ranges australia international property [SEP]']
[Init] best rec loss: 0.9131353497505188 for ['[CLS]tched forward bunk kinds virginiahiparians war ann scenery [SEP]']
[Init] best rec loss: 0.9055876731872559 for ['[CLS] ×ator bears weight overturned um turning pay humanity glee [SEP]']
[Init] best rec loss: 0.90427565574646 for ['[CLS] promptly furness shift name risk though toad clare run [SEP]']
[Init] best rec loss: 0.9016847014427185 for ['[CLS] maximum | least power theater release garage workedtmome [SEP]']
[Init] best rec loss: 0.8950892686843872 for ['[CLS] carries garden deputy creation attitudes victim mine waitingapugh [SEP]']
[Init] best rec loss: 0.893144428730011 for ['[CLS] - lego 2010 produced sings secret side itkie indoor [SEP]']
[Init] best rec loss: 0.8905503749847412 for ['[CLS]тogo church sex accept check departmentsnaophone well [SEP]']
[Init] best rec loss: 0.8905119895935059 for ['[CLS]ism response no productions savagemorphism sports short eugenelika [SEP]']
[Init] best perm rec loss: 0.890364944934845 for ['[CLS]lika productions savage short eugene sports nomorphismism response [SEP]']
[Init] best perm rec loss: 0.8901057839393616 for ['[CLS] savage shortismmorphismlika productions response sports eugene no [SEP]']
[Init] best perm rec loss: 0.8865870237350464 for ['[CLS] eugene sports responseism short savage nomorphismlika productions [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.747 (perp=11.978, rec=0.321, cos=0.031), tot_loss_proj:3.185 [t=0.30s]
prediction: ['[CLS] heart kind sentized actress and kindming value marshall [SEP]']
[ 100/2000] tot_loss=2.793 (perp=12.755, rec=0.219, cos=0.023), tot_loss_proj:4.347 [t=0.30s]
prediction: ['[CLS] heartwar sentgmental non kindming kinddor [SEP]']
[ 150/2000] tot_loss=2.591 (perp=12.132, rec=0.142, cos=0.023), tot_loss_proj:4.313 [t=0.30s]
prediction: ['[CLS] heartwar keptgmental non kindmingentaltic [SEP]']
[ 200/2000] tot_loss=2.819 (perp=13.432, rec=0.110, cos=0.023), tot_loss_proj:4.542 [t=0.30s]
prediction: ['[CLS] heartwar publishedgmental non kindmingentaltic [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.235 (perp=10.576, rec=0.098, cos=0.022), tot_loss_proj:3.476 [t=0.30s]
prediction: ['[CLS] heartwarminggmental non kindgm,cuting [SEP]']
[ 300/2000] tot_loss=2.227 (perp=10.576, rec=0.091, cos=0.021), tot_loss_proj:3.489 [t=0.30s]
prediction: ['[CLS] heartwarminggmental non kindgm,cuting [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.097 (perp=9.962, rec=0.083, cos=0.022), tot_loss_proj:2.818 [t=0.30s]
prediction: ['[CLS] heartwarming,gmental non kindveju [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.679 (perp=7.351, rec=0.184, cos=0.025), tot_loss_proj:2.296 [t=0.30s]
prediction: ['[CLS] heartwarming,gmental non kindu3 [SEP]']
[ 450/2000] tot_loss=1.907 (perp=8.885, rec=0.108, cos=0.022), tot_loss_proj:2.435 [t=0.30s]
prediction: ['[CLS] heartwarming,gmental non kinduju [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.742 (perp=8.080, rec=0.102, cos=0.023), tot_loss_proj:2.091 [t=0.30s]
prediction: ['[CLS] heartwarming, nongmental kinduju [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.741 (perp=8.110, rec=0.096, cos=0.023), tot_loss_proj:1.892 [t=0.30s]
prediction: ['[CLS] heartwarming, nonjugmental kind san [SEP]']
[ 600/2000] tot_loss=1.724 (perp=8.110, rec=0.080, cos=0.022), tot_loss_proj:1.897 [t=0.30s]
prediction: ['[CLS] heartwarming, nonjugmental kind san [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.728 (perp=8.110, rec=0.084, cos=0.022), tot_loss_proj:1.895 [t=0.30s]
prediction: ['[CLS] heartwarming, nonjugmental kind san [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.727 (perp=8.110, rec=0.083, cos=0.022), tot_loss_proj:1.899 [t=0.30s]
prediction: ['[CLS] heartwarming, nonjugmental kind san [SEP]']
[ 750/2000] tot_loss=1.724 (perp=8.110, rec=0.079, cos=0.022), tot_loss_proj:1.905 [t=0.30s]
prediction: ['[CLS] heartwarming, nonjugmental kind san [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.778 (perp=8.419, rec=0.072, cos=0.022), tot_loss_proj:1.887 [t=0.30s]
prediction: ['[CLS] heartwarming, non pauljugmental kind [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.641 (perp=7.704, rec=0.079, cos=0.022), tot_loss_proj:1.804 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
[ 900/2000] tot_loss=1.638 (perp=7.704, rec=0.075, cos=0.022), tot_loss_proj:1.805 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.640 (perp=7.704, rec=0.078, cos=0.022), tot_loss_proj:1.809 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
Attempt swap
[1000/2000] tot_loss=1.631 (perp=7.704, rec=0.068, cos=0.022), tot_loss_proj:1.809 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
[1050/2000] tot_loss=1.632 (perp=7.704, rec=0.069, cos=0.022), tot_loss_proj:1.807 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
Attempt swap
[1100/2000] tot_loss=1.640 (perp=7.704, rec=0.077, cos=0.022), tot_loss_proj:1.799 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
Attempt swap
[1150/2000] tot_loss=1.635 (perp=7.704, rec=0.072, cos=0.022), tot_loss_proj:1.809 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
[1200/2000] tot_loss=1.641 (perp=7.704, rec=0.079, cos=0.022), tot_loss_proj:1.810 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
Attempt swap
[1250/2000] tot_loss=1.623 (perp=7.704, rec=0.061, cos=0.022), tot_loss_proj:1.807 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
Attempt swap
[1300/2000] tot_loss=1.640 (perp=7.704, rec=0.078, cos=0.022), tot_loss_proj:1.806 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
[1350/2000] tot_loss=1.630 (perp=7.704, rec=0.067, cos=0.022), tot_loss_proj:1.804 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
Attempt swap
[1400/2000] tot_loss=1.632 (perp=7.704, rec=0.070, cos=0.022), tot_loss_proj:1.808 [t=0.30s]
prediction: ['[CLS] paul heartwarming, nonjugmental kind [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.588 (perp=7.384, rec=0.089, cos=0.022), tot_loss_proj:1.805 [t=0.30s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
[1500/2000] tot_loss=1.574 (perp=7.384, rec=0.076, cos=0.022), tot_loss_proj:1.807 [t=0.30s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
Attempt swap
[1550/2000] tot_loss=1.562 (perp=7.384, rec=0.063, cos=0.022), tot_loss_proj:1.803 [t=0.30s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
Attempt swap
[1600/2000] tot_loss=1.570 (perp=7.384, rec=0.071, cos=0.022), tot_loss_proj:1.803 [t=0.30s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
[1650/2000] tot_loss=1.563 (perp=7.384, rec=0.065, cos=0.022), tot_loss_proj:1.803 [t=0.30s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
Attempt swap
[1700/2000] tot_loss=1.570 (perp=7.384, rec=0.071, cos=0.022), tot_loss_proj:1.805 [t=0.30s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
Attempt swap
[1750/2000] tot_loss=1.558 (perp=7.384, rec=0.059, cos=0.022), tot_loss_proj:1.802 [t=0.30s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
[1800/2000] tot_loss=1.572 (perp=7.384, rec=0.073, cos=0.022), tot_loss_proj:1.796 [t=0.31s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
Attempt swap
[1850/2000] tot_loss=1.572 (perp=7.384, rec=0.073, cos=0.022), tot_loss_proj:1.803 [t=0.30s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
Attempt swap
[1900/2000] tot_loss=1.566 (perp=7.384, rec=0.068, cos=0.022), tot_loss_proj:1.805 [t=0.30s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
[1950/2000] tot_loss=1.569 (perp=7.384, rec=0.070, cos=0.022), tot_loss_proj:1.810 [t=0.30s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
Attempt swap
[2000/2000] tot_loss=1.572 (perp=7.384, rec=0.073, cos=0.022), tot_loss_proj:1.806 [t=0.30s]
prediction: ['[CLS] paul, heartwarming nonjugmental kind [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] paul heartwarming, nonjugmental kind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 66.667 | r: 80.000
rouge2     | fm: 22.222 | p: 20.000 | r: 25.000
rougeL     | fm: 72.727 | p: 66.667 | r: 80.000
rougeLsum  | fm: 72.727 | p: 66.667 | r: 80.000
r1fm+r2fm = 94.949

[Aggregate metrics]:
rouge1     | fm: 90.730 | p: 90.326 | r: 91.261
rouge2     | fm: 63.485 | p: 63.343 | r: 63.656
rougeL     | fm: 81.104 | p: 80.749 | r: 81.541
rougeLsum  | fm: 81.065 | p: 80.711 | r: 81.515
r1fm+r2fm = 154.214

input #67 time: 0:11:56 | total time: 14:14:16


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9860824183664403
highest_index [0]
highest [0.9860824183664403]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9363434910774231 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9099898934364319 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 0.9080647826194763 for ['[CLS] instant legs discoveredshboot mass pond arabianvati lines abd star 7 [SEP]']
[Init] best rec loss: 0.9065318703651428 for ['[CLS]pped raise marx driving claims steadily racial shame hispanic big under charlie sinks [SEP]']
[Init] best rec loss: 0.9021669030189514 for ['[CLS] $ offs dreams national been wallszzsar council frederick but lankan comprehensive [SEP]']
[Init] best rec loss: 0.8881656527519226 for ['[CLS] feelings stole besides spoil bit prone decay spider insteadane about ars payments [SEP]']
[Init] best rec loss: 0.8541073203086853 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8420235514640808 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8417474031448364 for ['[CLS] medaliferous beth comfort form councils flooryn possibly riding. died view [SEP]']
[Init] best perm rec loss: 0.8373993635177612 for ['[CLS]yn possibly councils form beth.iferous riding view floor medal comfort died [SEP]']
[Init] best perm rec loss: 0.837263822555542 for ['[CLS] medal floor.iferous beth form councils comfortyn possibly riding view died [SEP]']
[Init] best perm rec loss: 0.8371908664703369 for ['[CLS]iferous riding. floor beth died possibly form view councils medal comfortyn [SEP]']
[Init] best perm rec loss: 0.8370306491851807 for ['[CLS]yn beth comfort councilsiferous possibly floor form view medal riding. died [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.610 (perp=11.696, rec=0.241, cos=0.031), tot_loss_proj:3.042 [t=0.30s]
prediction: ['[CLS] vicious reed, absurd?ision discriminationtable. hmsfs absurd animals [SEP]']
[ 100/2000] tot_loss=2.386 (perp=11.014, rec=0.154, cos=0.029), tot_loss_proj:2.807 [t=0.30s]
prediction: ['[CLS]downuth, absurduthision vicioustable, incomp absurd relatives [SEP]']
[ 150/2000] tot_loss=2.312 (perp=10.702, rec=0.145, cos=0.027), tot_loss_proj:2.717 [t=0.30s]
prediction: ['[CLS] unuth, absurduthision vicioustable, incomp absurdsible [SEP]']
[ 200/2000] tot_loss=2.300 (perp=10.702, rec=0.132, cos=0.027), tot_loss_proj:2.697 [t=0.30s]
prediction: ['[CLS] unuth, absurduthision vicioustable, incomp absurdsible [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.017 (perp=9.228, rec=0.145, cos=0.026), tot_loss_proj:2.536 [t=0.30s]
prediction: ['[CLS] un absurd, absurduth narcotics vicioussible, incomputhsible [SEP]']
[ 300/2000] tot_loss=2.256 (perp=10.505, rec=0.129, cos=0.027), tot_loss_proj:2.712 [t=0.30s]
prediction: ['[CLS] unhen, absurduth narcotics vicioussible, incomputhsible [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.888 (perp=8.717, rec=0.119, cos=0.026), tot_loss_proj:2.391 [t=0.30s]
prediction: ['[CLS] un vicious, absurduth narcoticshensible, incomputhsible [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.478 (perp=11.441, rec=0.160, cos=0.030), tot_loss_proj:3.025 [t=0.30s]
prediction: ['[CLS] un vicious, absurduth narcoticssible ( incompcoresible [SEP]']
[ 450/2000] tot_loss=2.292 (perp=10.672, rec=0.131, cos=0.027), tot_loss_proj:2.926 [t=0.30s]
prediction: ['[CLS]co vicious, absurduth narcoticssible, incompco andsible [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.268 (perp=10.426, rec=0.155, cos=0.028), tot_loss_proj:2.931 [t=0.30s]
prediction: ['[CLS]co vicious, absurditivesible and incompinguth andsible [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.050 (perp=9.370, rec=0.149, cos=0.027), tot_loss_proj:2.658 [t=0.30s]
prediction: ['[CLS] unuth, absurdotericsible and incomping vicious andsible [SEP]']
[ 600/2000] tot_loss=2.020 (perp=9.317, rec=0.129, cos=0.027), tot_loss_proj:2.688 [t=0.30s]
prediction: ['[CLS]couth, absurdotericcated and unomping vicious andsible [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.192 (perp=10.240, rec=0.117, cos=0.027), tot_loss_proj:2.504 [t=0.30s]
prediction: ['[CLS]couth, absurdcated and unomputh viciouscomingcosible [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.047 (perp=9.494, rec=0.121, cos=0.027), tot_loss_proj:2.522 [t=0.30s]
prediction: ['[CLS]couth, absurdcated and viciousompsible uncoming andsible [SEP]']
[ 750/2000] tot_loss=2.099 (perp=9.801, rec=0.111, cos=0.028), tot_loss_proj:2.594 [t=0.30s]
prediction: ['[CLS]couth, absurdciation and viciousompsible uncoming andsible [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.038 (perp=9.518, rec=0.106, cos=0.028), tot_loss_proj:2.707 [t=0.30s]
prediction: ['[CLS]couth, absurdciation unsible and viciousompsible andsible [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.047 (perp=9.518, rec=0.116, cos=0.028), tot_loss_proj:2.700 [t=0.30s]
prediction: ['[CLS]couth, absurdciation unsible and viciousompsible andsible [SEP]']
[ 900/2000] tot_loss=2.041 (perp=9.518, rec=0.109, cos=0.028), tot_loss_proj:2.699 [t=0.30s]
prediction: ['[CLS]couth, absurdciation unsible and viciousompsible andsible [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.005 (perp=9.326, rec=0.113, cos=0.028), tot_loss_proj:2.843 [t=0.30s]
prediction: ['[CLS]couth un absurdciation,sible and viciousompsible andsible [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.251 (perp=10.519, rec=0.120, cos=0.027), tot_loss_proj:2.673 [t=0.30s]
prediction: ['[CLS] absurdcouth unco,sible and viciousompsibleresible [SEP]']
[1050/2000] tot_loss=2.107 (perp=9.871, rec=0.105, cos=0.028), tot_loss_proj:2.660 [t=0.30s]
prediction: ['[CLS] absurdcouth unco,sible and viciousompsible andsible [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.971 (perp=9.170, rec=0.110, cos=0.027), tot_loss_proj:2.379 [t=0.30s]
prediction: ['[CLS] absurdco, uncouthsible and viciousompsibleresible [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.643 (perp=7.441, rec=0.128, cos=0.027), tot_loss_proj:1.959 [t=0.30s]
prediction: ['[CLS] absurdcosible, uncouthsible and viciousompresible [SEP]']
[1200/2000] tot_loss=1.896 (perp=8.811, rec=0.106, cos=0.028), tot_loss_proj:2.247 [t=0.30s]
prediction: ['[CLS] absurdcosible, uncouthsible and viciouscoresible [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.664 (perp=7.620, rec=0.113, cos=0.027), tot_loss_proj:1.983 [t=0.30s]
prediction: ['[CLS] absurdcosible, uncouthsible and viciousrecosible [SEP]']
Attempt swap
[1300/2000] tot_loss=1.659 (perp=7.620, rec=0.107, cos=0.028), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS] absurdcosible, uncouthsible and viciousrecosible [SEP]']
[1350/2000] tot_loss=1.656 (perp=7.620, rec=0.104, cos=0.028), tot_loss_proj:1.977 [t=0.30s]
prediction: ['[CLS] absurdcosible, uncouthsible and viciousrecosible [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.641 (perp=7.557, rec=0.102, cos=0.028), tot_loss_proj:1.971 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
Attempt swap
[1450/2000] tot_loss=1.648 (perp=7.557, rec=0.109, cos=0.028), tot_loss_proj:1.963 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
[1500/2000] tot_loss=1.641 (perp=7.557, rec=0.102, cos=0.028), tot_loss_proj:1.966 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
Attempt swap
[1550/2000] tot_loss=1.641 (perp=7.557, rec=0.102, cos=0.028), tot_loss_proj:1.961 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
Attempt swap
[1600/2000] tot_loss=1.638 (perp=7.557, rec=0.099, cos=0.028), tot_loss_proj:1.966 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
[1650/2000] tot_loss=1.643 (perp=7.557, rec=0.104, cos=0.028), tot_loss_proj:1.963 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
Attempt swap
[1700/2000] tot_loss=1.632 (perp=7.557, rec=0.093, cos=0.028), tot_loss_proj:1.964 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
Attempt swap
[1750/2000] tot_loss=1.644 (perp=7.557, rec=0.105, cos=0.028), tot_loss_proj:1.979 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
[1800/2000] tot_loss=1.647 (perp=7.557, rec=0.108, cos=0.028), tot_loss_proj:1.966 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
Attempt swap
[1850/2000] tot_loss=1.641 (perp=7.557, rec=0.102, cos=0.028), tot_loss_proj:1.976 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.651 (perp=7.557, rec=0.112, cos=0.028), tot_loss_proj:2.010 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
[1950/2000] tot_loss=1.644 (perp=7.557, rec=0.106, cos=0.028), tot_loss_proj:2.008 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
Attempt swap
[2000/2000] tot_loss=1.639 (perp=7.557, rec=0.100, cos=0.028), tot_loss_proj:2.016 [t=0.30s]
prediction: ['[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] viciouscosible, uncouthsible and absurdrecosible [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 46.154 | p: 50.000 | r: 42.857
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 46.154 | p: 50.000 | r: 42.857
rougeLsum  | fm: 46.154 | p: 50.000 | r: 42.857
r1fm+r2fm = 46.154

[Aggregate metrics]:
rouge1     | fm: 90.061 | p: 89.784 | r: 90.500
rouge2     | fm: 62.508 | p: 62.375 | r: 62.700
rougeL     | fm: 80.540 | p: 80.257 | r: 80.916
rougeLsum  | fm: 80.500 | p: 80.233 | r: 80.911
r1fm+r2fm = 152.569

input #68 time: 0:11:57 | total time: 14:26:14


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.9881634193141562
highest_index [0]
highest [0.9881634193141562]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 0.9784640073776245 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.978434145450592 for ['[CLS] junior christ mel fed sahara crambidae alexia pumped designated vuelta light vo classical institutional duty audience [SEP]']
[Init] best rec loss: 0.9777377247810364 for ['[CLS] later dressed creed among label effect pickering servants duc evergreen along [CLS] court afar trey bombay [SEP]']
[Init] best rec loss: 0.9657325744628906 for ['[CLS]aver grandson cleared sergei spare reserve / earthquake mouse loudly student celebrated pill till le tunnel [SEP]']
[Init] best rec loss: 0.9444493651390076 for ['[CLS] closelein am ( deadrga liz range bragg depended states passes stock past messll [SEP]']
[Init] best perm rec loss: 0.941179096698761 for ['[CLS] stock depended bragg am states messll past close rangerga ( liz passes deadlein [SEP]']
[Init] best perm rec loss: 0.9411736726760864 for ['[CLS] dead depended stock amll close passes past bragg liz rangerga ( states messlein [SEP]']
[Init] best perm rec loss: 0.9406055212020874 for ['[CLS] liz ( states close stock depended mess past dead passesrga rangell am bragglein [SEP]']
[Init] best perm rec loss: 0.9399617314338684 for ['[CLS] close past liz ( range am stock dependedrga bragglein states passes deadll mess [SEP]']
[Init] best perm rec loss: 0.9391594529151917 for ['[CLS] dead past statesrgalein liz passesll mess depended stock bragg am range close ( [SEP]']
[Init] best perm rec loss: 0.9389622807502747 for ['[CLS] stock depended range statesrga close mess liz (lllein dead passes am bragg past [SEP]']
[Init] best perm rec loss: 0.9386734366416931 for ['[CLS] amll ( bragg depended past messrga passes close stocklein states liz range dead [SEP]']
[Init] best perm rec loss: 0.9384797215461731 for ['[CLS] depended am dead closerga ( messll past bragg states stock range liz passeslein [SEP]']
[Init] best perm rec loss: 0.9379997849464417 for ['[CLS] dead rangergall am ( passes bragg states mess stock dependedlein close liz past [SEP]']
[Init] best perm rec loss: 0.9369493126869202 for ['[CLS] states bragg passes am ( range pastleinll depended messrga stock close liz dead [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.046 (perp=9.990, rec=0.681, cos=0.368), tot_loss_proj:3.773 [t=0.30s]
prediction: ['[CLS] town cairo went am winkler judges by real rape. : trials dryas and majority [SEP]']
[ 100/2000] tot_loss=3.587 (perp=12.519, rec=0.636, cos=0.447), tot_loss_proj:4.408 [t=0.31s]
prediction: ['[CLS] mega trail went ( baseman jury perfect real sewage ;. smart shorttel. dots [SEP]']
[ 150/2000] tot_loss=2.891 (perp=10.650, rec=0.578, cos=0.184), tot_loss_proj:3.815 [t=0.31s]
prediction: ['[CLS] town commit. idiot ᵍ jury forget real sewage?. smart short also. interaction [SEP]']
[ 200/2000] tot_loss=2.721 (perp=9.388, rec=0.576, cos=0.267), tot_loss_proj:3.797 [t=0.31s]
prediction: ['[CLS] commissionstream - byʀ. real raja homo?. smart short similar. quarter [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.443 (perp=9.257, rec=0.522, cos=0.069), tot_loss_proj:3.667 [t=0.31s]
prediction: ['[CLS] funny blah - byʀ its. real and,. smart short,. quarter [SEP]']
[ 300/2000] tot_loss=2.478 (perp=9.806, rec=0.483, cos=0.034), tot_loss_proj:3.853 [t=0.31s]
prediction: ['[CLS] funny blah - - ª brain. smart -,2 smart short,. fatal [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.758 (perp=10.824, rec=0.523, cos=0.070), tot_loss_proj:4.135 [t=0.31s]
prediction: ['[CLS] funny - - -? across. - appoint homo2 smart low,. interaction [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.116 (perp=7.984, rec=0.478, cos=0.041), tot_loss_proj:3.296 [t=0.31s]
prediction: ['[CLS], - - - living ;. - blah funny? smart competitors,. bounce [SEP]']
[ 450/2000] tot_loss=2.130 (perp=8.303, rec=0.450, cos=0.019), tot_loss_proj:3.451 [t=0.31s]
prediction: ['[CLS], - - - living ;. when intro funny? smart competitors, and bounce [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.027 (perp=7.484, rec=0.442, cos=0.088), tot_loss_proj:3.410 [t=0.31s]
prediction: ['[CLS], - - - when ;, when, funny. smart competitors intro and fatal [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.931 (perp=7.313, rec=0.421, cos=0.047), tot_loss_proj:2.881 [t=0.31s]
prediction: ['[CLS] intro - - - living ;, when, funny. smart competitors, and spectators [SEP]']
[ 600/2000] tot_loss=2.792 (perp=8.628, rec=0.645, cos=0.422), tot_loss_proj:3.600 [t=0.31s]
prediction: ['[CLS] intro - - - when similar,ifice places funny. smart low. ) fatal [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.245 (perp=8.369, rec=0.504, cos=0.067), tot_loss_proj:3.271 [t=0.31s]
prediction: ['[CLS]ʳ - - -nessy most, really, bruno. smart waste low. and [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.330 (perp=9.139, rec=0.468, cos=0.035), tot_loss_proj:3.384 [t=0.31s]
prediction: ['[CLS]ʳ - pu -nessy,, really, bruno. smart incumbent and disability and [SEP]']
[ 750/2000] tot_loss=2.341 (perp=9.414, rec=0.432, cos=0.026), tot_loss_proj:3.585 [t=0.31s]
prediction: ['[CLS] paths - pu -nessy,, really, bruno. smart incumbent and disability and [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.199 (perp=8.770, rec=0.420, cos=0.025), tot_loss_proj:3.549 [t=0.31s]
prediction: ['[CLS] paths - troubles -nessy, really, bruno. smart, incumbent and punched ) [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.131 (perp=8.310, rec=0.421, cos=0.047), tot_loss_proj:3.236 [t=0.31s]
prediction: ['[CLS] paths - troubles -nessy, really, bruno. smart, existent and punched. [SEP]']
[ 900/2000] tot_loss=2.111 (perp=8.414, rec=0.400, cos=0.028), tot_loss_proj:2.667 [t=0.31s]
prediction: ['[CLS] way - funny -nessy, really, bruno. smart, existent and punched. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.965 (perp=7.704, rec=0.401, cos=0.023), tot_loss_proj:2.616 [t=0.31s]
prediction: ['[CLS] way funny - -nessy, completely, bruno ; smart, incumbent and punched. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.396 (perp=8.575, rec=0.446, cos=0.235), tot_loss_proj:3.257 [t=0.31s]
prediction: ['[CLS] paths troubles - -nessy,wee, funny ; smart, incumbent and nomination. [SEP]']
[1050/2000] tot_loss=2.016 (perp=8.005, rec=0.390, cos=0.025), tot_loss_proj:2.785 [t=0.31s]
prediction: ['[CLS] way troubles - -nessy, completely, funny. smart, incumbent and,. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.838 (perp=7.131, rec=0.391, cos=0.021), tot_loss_proj:2.637 [t=0.31s]
prediction: ['[CLS] way troubles - -nessy, completely, funny, smart, incumbent and.. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.752 (perp=6.722, rec=0.381, cos=0.027), tot_loss_proj:2.321 [t=0.31s]
prediction: ['[CLS] way troubles - -nessy, completely, funny, smart, and existent.. [SEP]']
[1200/2000] tot_loss=1.778 (perp=6.857, rec=0.384, cos=0.022), tot_loss_proj:2.707 [t=0.31s]
prediction: ['[CLS] way troubles - -nessy, completely, funny, smart, and incumbent.. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.752 (perp=6.730, rec=0.382, cos=0.023), tot_loss_proj:2.858 [t=0.31s]
prediction: ['[CLS] way troubles - -nessy, completely, funny, smart, and incumbent ). [SEP]']
Attempt swap
[1300/2000] tot_loss=1.746 (perp=6.730, rec=0.378, cos=0.022), tot_loss_proj:2.859 [t=0.31s]
prediction: ['[CLS] way troubles - -nessy, completely, funny, smart, and incumbent ). [SEP]']
[1350/2000] tot_loss=2.182 (perp=6.730, rec=0.391, cos=0.445), tot_loss_proj:2.863 [t=0.31s]
prediction: ['[CLS] way troubles - -nessy, completely, funny, smart, and incumbent ). [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.748 (perp=6.756, rec=0.372, cos=0.025), tot_loss_proj:2.867 [t=0.31s]
prediction: ['[CLS] way troubles - -nessy, incumbent, funny, smart, and completely -. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.670 (perp=6.348, rec=0.371, cos=0.029), tot_loss_proj:3.058 [t=0.31s]
prediction: ['[CLS] way troubles - - fraction, incumbent, funny, smart, and completely ). [SEP]']
[1500/2000] tot_loss=1.779 (perp=6.906, rec=0.376, cos=0.022), tot_loss_proj:3.295 [t=0.31s]
prediction: ['[CLS] way troubles - - fraction, incumbent, funny, smart, - completely ). [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.822 (perp=7.098, rec=0.380, cos=0.022), tot_loss_proj:3.147 [t=0.31s]
prediction: ['[CLS] way troubles - - fraction, incumbent, funny, smart, completely andbius. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.008 (perp=8.065, rec=0.370, cos=0.025), tot_loss_proj:3.554 [t=0.31s]
prediction: ['[CLS] paths troubles - - fraction, incumbent, funny, smart, - completelybius. [SEP]']
[1650/2000] tot_loss=1.916 (perp=7.562, rec=0.378, cos=0.026), tot_loss_proj:3.448 [t=0.31s]
prediction: ['[CLS] way troubles - - fraction, incumbent, funny, smart, - completelybius. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.050 (perp=8.303, rec=0.368, cos=0.021), tot_loss_proj:3.594 [t=0.31s]
prediction: ['[CLS] way troubles - - fraction - incumbent, funny, smart, - completelybius. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.145 (perp=8.461, rec=0.383, cos=0.069), tot_loss_proj:3.637 [t=0.31s]
prediction: ['[CLS] fraction 1985 troubles - - - incumbent, funny, smart, - completelybius. [SEP]']
[1800/2000] tot_loss=2.008 (perp=8.077, rec=0.371, cos=0.021), tot_loss_proj:3.555 [t=0.31s]
prediction: ['[CLS] fraction paths troubles - - - incumbent, funny, smart, - completelybius. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.953 (perp=7.776, rec=0.374, cos=0.024), tot_loss_proj:3.501 [t=0.31s]
prediction: ['[CLS] fraction troubles paths - - - incumbent, funny, smart, - completelybius. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.948 (perp=7.776, rec=0.374, cos=0.019), tot_loss_proj:3.504 [t=0.31s]
prediction: ['[CLS] fraction troubles paths - - - incumbent, funny, smart, - completelybius. [SEP]']
[1950/2000] tot_loss=1.947 (perp=7.776, rec=0.371, cos=0.020), tot_loss_proj:3.503 [t=0.31s]
prediction: ['[CLS] fraction troubles paths - - - incumbent, funny, smart, - completelybius. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.962 (perp=7.812, rec=0.375, cos=0.025), tot_loss_proj:2.996 [t=0.31s]
prediction: ['[CLS] wins troubles paths - - - incumbent, funny, smart, completelybius and. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] fraction troubles paths - - - incumbent, funny, smart, - completelybius. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 42.105 | p: 44.444 | r: 40.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 31.579 | p: 33.333 | r: 30.000
rougeLsum  | fm: 31.579 | p: 33.333 | r: 30.000
r1fm+r2fm = 42.105

[Aggregate metrics]:
rouge1     | fm: 89.456 | p: 89.143 | r: 89.903
rouge2     | fm: 61.732 | p: 61.650 | r: 61.857
rougeL     | fm: 79.771 | p: 79.569 | r: 80.126
rougeLsum  | fm: 79.735 | p: 79.529 | r: 80.125
r1fm+r2fm = 151.188

input #69 time: 0:12:11 | total time: 14:38:25


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9798018195286436
highest_index [0]
highest [0.9798018195286436]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8044760823249817 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.7642242312431335 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7567980289459229 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7436615824699402 for ['[CLS] oliveira jamie position crime belong leadersla [SEP]']
[Init] best rec loss: 0.7254676818847656 for ['[CLS] ga characteristic jump make deaths composed ⟩ [SEP]']
[Init] best rec loss: 0.7124882340431213 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 0.6826730966567993 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best perm rec loss: 0.6768484115600586 for ['[CLS]bution party ি muscle guy modern bob [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.106 (perp=8.711, rec=0.294, cos=0.070), tot_loss_proj:2.634 [t=0.30s]
prediction: ['[CLS] cl movie in passed clunky [SEP]']
[ 100/2000] tot_loss=1.897 (perp=8.581, rec=0.139, cos=0.041), tot_loss_proj:2.174 [t=0.30s]
prediction: ['[CLS] cl screen cl gets clunky [SEP]']
[ 150/2000] tot_loss=1.837 (perp=8.502, rec=0.096, cos=0.040), tot_loss_proj:2.090 [t=0.30s]
prediction: ['[CLS] screen screen cl gets clunky [SEP]']
[ 200/2000] tot_loss=1.952 (perp=9.202, rec=0.073, cos=0.039), tot_loss_proj:2.614 [t=0.30s]
prediction: ['[CLS] the screen cl gets onunky [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.428 (perp=6.493, rec=0.089, cos=0.041), tot_loss_proj:1.621 [t=0.30s]
prediction: ['[CLS] the screen on gets clunky [SEP]']
[ 300/2000] tot_loss=1.403 (perp=6.493, rec=0.065, cos=0.039), tot_loss_proj:1.632 [t=0.30s]
prediction: ['[CLS] the screen on gets clunky [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.244 (perp=5.690, rec=0.067, cos=0.039), tot_loss_proj:1.457 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.249 (perp=5.690, rec=0.071, cos=0.040), tot_loss_proj:1.454 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 450/2000] tot_loss=1.243 (perp=5.690, rec=0.066, cos=0.040), tot_loss_proj:1.459 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.244 (perp=5.690, rec=0.066, cos=0.040), tot_loss_proj:1.455 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.238 (perp=5.690, rec=0.061, cos=0.040), tot_loss_proj:1.457 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 600/2000] tot_loss=1.245 (perp=5.690, rec=0.068, cos=0.040), tot_loss_proj:1.465 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.243 (perp=5.690, rec=0.065, cos=0.040), tot_loss_proj:1.448 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.241 (perp=5.690, rec=0.063, cos=0.040), tot_loss_proj:1.458 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 750/2000] tot_loss=1.235 (perp=5.690, rec=0.058, cos=0.040), tot_loss_proj:1.453 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.238 (perp=5.690, rec=0.060, cos=0.040), tot_loss_proj:1.450 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.247 (perp=5.690, rec=0.069, cos=0.040), tot_loss_proj:1.455 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 900/2000] tot_loss=1.242 (perp=5.690, rec=0.064, cos=0.040), tot_loss_proj:1.450 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.251 (perp=5.690, rec=0.073, cos=0.040), tot_loss_proj:1.448 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.249 (perp=5.690, rec=0.071, cos=0.040), tot_loss_proj:1.453 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1050/2000] tot_loss=1.253 (perp=5.690, rec=0.075, cos=0.040), tot_loss_proj:1.454 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.249 (perp=5.690, rec=0.071, cos=0.040), tot_loss_proj:1.450 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.246 (perp=5.690, rec=0.069, cos=0.040), tot_loss_proj:1.452 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1200/2000] tot_loss=1.234 (perp=5.690, rec=0.056, cos=0.040), tot_loss_proj:1.457 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.239 (perp=5.690, rec=0.062, cos=0.040), tot_loss_proj:1.451 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.246 (perp=5.690, rec=0.068, cos=0.040), tot_loss_proj:1.453 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1350/2000] tot_loss=1.234 (perp=5.690, rec=0.056, cos=0.040), tot_loss_proj:1.449 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.243 (perp=5.690, rec=0.066, cos=0.040), tot_loss_proj:1.448 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.233 (perp=5.690, rec=0.055, cos=0.040), tot_loss_proj:1.448 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1500/2000] tot_loss=1.239 (perp=5.690, rec=0.062, cos=0.040), tot_loss_proj:1.454 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.249 (perp=5.690, rec=0.071, cos=0.040), tot_loss_proj:1.451 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.240 (perp=5.690, rec=0.062, cos=0.040), tot_loss_proj:1.449 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1650/2000] tot_loss=1.251 (perp=5.690, rec=0.073, cos=0.040), tot_loss_proj:1.444 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.243 (perp=5.690, rec=0.065, cos=0.040), tot_loss_proj:1.446 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.247 (perp=5.690, rec=0.069, cos=0.040), tot_loss_proj:1.448 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1800/2000] tot_loss=1.235 (perp=5.690, rec=0.057, cos=0.040), tot_loss_proj:1.447 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.241 (perp=5.690, rec=0.063, cos=0.040), tot_loss_proj:1.443 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.248 (perp=5.690, rec=0.070, cos=0.040), tot_loss_proj:1.442 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1950/2000] tot_loss=1.239 (perp=5.690, rec=0.061, cos=0.040), tot_loss_proj:1.450 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.246 (perp=5.690, rec=0.068, cos=0.040), tot_loss_proj:1.450 [t=0.30s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] on the screen gets clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 89.552 | p: 89.294 | r: 90.005
rouge2     | fm: 61.314 | p: 61.241 | r: 61.477
rougeL     | fm: 79.657 | p: 79.448 | r: 79.976
rougeLsum  | fm: 79.590 | p: 79.383 | r: 79.961
r1fm+r2fm = 150.866

input #70 time: 0:11:58 | total time: 14:50:23


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.985154056381976
highest_index [0]
highest [0.985154056381976]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8946391344070435 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.8933597207069397 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.888590395450592 for ['[CLS]kledclaiming solid due tear stakesaint flight ken keel receiver living duval us tottenham [SEP]']
[Init] best rec loss: 0.8833470940589905 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 0.8731468915939331 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 0.8679631352424622 for ['[CLS] composed warsselle ty urbantist empireneas amendment broadbandcat murdereo money appoint [SEP]']
[Init] best rec loss: 0.8592904210090637 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 0.8429911732673645 for ['[CLS]ine runways oregon bored : towardsgold occurred snow abovegerstypical definitely holiday rooney [SEP]']
[Init] best perm rec loss: 0.8429846167564392 for ['[CLS] snow towards rooneygers runways holiday above boredtypical oregonine definitely occurred :gold [SEP]']
[Init] best perm rec loss: 0.8383603692054749 for ['[CLS] :inegold rooneytypical runways above oregon holiday snow boredgers towards definitely occurred [SEP]']
[Init] best perm rec loss: 0.8379151225090027 for ['[CLS] towards occurredtypical rooneygers oregonine above snow runways bored : holidaygold definitely [SEP]']
[Init] best perm rec loss: 0.8375605344772339 for ['[CLS]typical definitely towardsgold oregon occurred runways aboveine rooney holiday boredgers snow : [SEP]']
[Init] best perm rec loss: 0.8374326229095459 for ['[CLS] rooney above holiday snowine oregon towards definitely runways :gold bored occurredtypicalgers [SEP]']
[Init] best perm rec loss: 0.8368802666664124 for ['[CLS] snow bored oregon rooneygold definitely holiday towards above runwaysgers occurredinetypical : [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.809 (perp=12.343, rec=0.305, cos=0.036), tot_loss_proj:3.595 [t=0.30s]
prediction: ['[CLS] few placemmyz trials jump available not single seat team moment di tea neither [SEP]']
[ 100/2000] tot_loss=2.331 (perp=10.517, rec=0.194, cos=0.033), tot_loss_proj:3.777 [t=0.31s]
prediction: ['[CLS] few - momentject your jump there not single seat jump moment absolutely tea and [SEP]']
[ 150/2000] tot_loss=2.302 (perp=10.704, rec=0.132, cos=0.029), tot_loss_proj:3.474 [t=0.31s]
prediction: ['[CLS] four - momentject your jump there not single seat jump moment midst both and [SEP]']
[ 200/2000] tot_loss=1.907 (perp=8.940, rec=0.091, cos=0.028), tot_loss_proj:3.252 [t=0.31s]
prediction: ['[CLS] four - momentup your in there not single seat jump - - both and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.997 (perp=9.313, rec=0.107, cos=0.027), tot_loss_proj:3.178 [t=0.31s]
prediction: ['[CLS] your one - momentv in there not single seat jump -rem a and [SEP]']
[ 300/2000] tot_loss=1.805 (perp=8.461, rec=0.085, cos=0.027), tot_loss_proj:3.115 [t=0.31s]
prediction: ['[CLS] your a - momentv in there not single seat jump - s a and [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.701 (perp=7.964, rec=0.080, cos=0.028), tot_loss_proj:3.103 [t=0.31s]
prediction: ['[CLS] your a moment -v in there not single seat jump - s a and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.690 (perp=7.886, rec=0.086, cos=0.027), tot_loss_proj:2.894 [t=0.31s]
prediction: ["[CLS] your'moment -v in there not single seat jump - s a and [SEP]"]
[ 450/2000] tot_loss=1.684 (perp=7.886, rec=0.079, cos=0.028), tot_loss_proj:2.889 [t=0.31s]
prediction: ["[CLS] your'moment -v in there not single seat jump - s a and [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.661 (perp=7.792, rec=0.075, cos=0.027), tot_loss_proj:2.913 [t=0.31s]
prediction: ["[CLS] your'moment - not in therev single seat jump - s a and [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.656 (perp=7.792, rec=0.071, cos=0.027), tot_loss_proj:2.913 [t=0.31s]
prediction: ["[CLS] your'moment - not in therev single seat jump - s a and [SEP]"]
[ 600/2000] tot_loss=1.657 (perp=7.792, rec=0.071, cos=0.028), tot_loss_proj:2.907 [t=0.31s]
prediction: ["[CLS] your'moment - not in therev single seat jump - s a and [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.624 (perp=7.661, rec=0.064, cos=0.027), tot_loss_proj:2.828 [t=0.31s]
prediction: ["[CLS] your'moment - not in therev single seat jump - a s and [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.585 (perp=7.378, rec=0.082, cos=0.027), tot_loss_proj:3.010 [t=0.31s]
prediction: ["[CLS] your a moment - not in therev single seat jump -'s and [SEP]"]
[ 750/2000] tot_loss=1.573 (perp=7.378, rec=0.070, cos=0.027), tot_loss_proj:3.014 [t=0.31s]
prediction: ["[CLS] your a moment - not in therev single seat jump -'s and [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.572 (perp=7.378, rec=0.069, cos=0.027), tot_loss_proj:3.017 [t=0.31s]
prediction: ["[CLS] your a moment - not in therev single seat jump -'s and [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.582 (perp=7.378, rec=0.079, cos=0.027), tot_loss_proj:3.013 [t=0.31s]
prediction: ["[CLS] your a moment - not in therev single seat jump -'s and [SEP]"]
[ 900/2000] tot_loss=1.574 (perp=7.378, rec=0.071, cos=0.027), tot_loss_proj:3.014 [t=0.31s]
prediction: ["[CLS] your a moment - not in therev single seat jump -'s and [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.571 (perp=7.378, rec=0.068, cos=0.027), tot_loss_proj:3.019 [t=0.31s]
prediction: ["[CLS] your a moment - not in therev single seat jump -'s and [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.562 (perp=7.378, rec=0.059, cos=0.027), tot_loss_proj:3.016 [t=0.31s]
prediction: ["[CLS] your a moment - not in therev single seat jump -'s and [SEP]"]
[1050/2000] tot_loss=1.581 (perp=7.378, rec=0.078, cos=0.027), tot_loss_proj:3.014 [t=0.31s]
prediction: ["[CLS] your a moment - not in therev single seat jump -'s and [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.568 (perp=7.378, rec=0.065, cos=0.027), tot_loss_proj:3.015 [t=0.31s]
prediction: ["[CLS] your a moment - not in therev single seat jump -'s and [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.572 (perp=7.389, rec=0.067, cos=0.027), tot_loss_proj:2.898 [t=0.31s]
prediction: ["[CLS] your a moment - not in there single seatv jump -'s and [SEP]"]
[1200/2000] tot_loss=1.571 (perp=7.389, rec=0.065, cos=0.028), tot_loss_proj:2.896 [t=0.31s]
prediction: ["[CLS] your a moment - not in there single seatv jump -'s and [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.570 (perp=7.389, rec=0.065, cos=0.027), tot_loss_proj:2.900 [t=0.31s]
prediction: ["[CLS] your a moment - not in there single seatv jump -'s and [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.526 (perp=7.081, rec=0.082, cos=0.028), tot_loss_proj:2.831 [t=0.31s]
prediction: ["[CLS] your a moment - not in there single seat jump -v's and [SEP]"]
[1350/2000] tot_loss=1.522 (perp=7.081, rec=0.078, cos=0.028), tot_loss_proj:2.834 [t=0.31s]
prediction: ["[CLS] your a moment - not in there single seat jump -v's and [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=1.431 (perp=6.645, rec=0.074, cos=0.028), tot_loss_proj:2.769 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.425 (perp=6.645, rec=0.069, cos=0.027), tot_loss_proj:2.776 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
[1500/2000] tot_loss=1.430 (perp=6.645, rec=0.074, cos=0.027), tot_loss_proj:2.775 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.416 (perp=6.645, rec=0.059, cos=0.027), tot_loss_proj:2.772 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.429 (perp=6.645, rec=0.073, cos=0.027), tot_loss_proj:2.775 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
[1650/2000] tot_loss=1.420 (perp=6.645, rec=0.063, cos=0.028), tot_loss_proj:2.774 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.431 (perp=6.645, rec=0.074, cos=0.027), tot_loss_proj:2.777 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.433 (perp=6.645, rec=0.077, cos=0.028), tot_loss_proj:2.773 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
[1800/2000] tot_loss=1.412 (perp=6.645, rec=0.055, cos=0.027), tot_loss_proj:2.780 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.427 (perp=6.645, rec=0.070, cos=0.028), tot_loss_proj:2.777 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.417 (perp=6.645, rec=0.060, cos=0.027), tot_loss_proj:2.769 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
[1950/2000] tot_loss=1.423 (perp=6.645, rec=0.067, cos=0.028), tot_loss_proj:2.773 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.421 (perp=6.645, rec=0.064, cos=0.027), tot_loss_proj:2.776 [t=0.31s]
prediction: ["[CLS] your in a moment - not there single seat jump -v's and [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] your a moment - not in therev single seat jump -'s and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 8.333 | p: 8.333 | r: 8.333
rougeL     | fm: 46.154 | p: 46.154 | r: 46.154
rougeLsum  | fm: 46.154 | p: 46.154 | r: 46.154
r1fm+r2fm = 100.641

[Aggregate metrics]:
rouge1     | fm: 89.653 | p: 89.375 | r: 90.053
rouge2     | fm: 60.699 | p: 60.595 | r: 60.786
rougeL     | fm: 79.200 | p: 78.948 | r: 79.526
rougeLsum  | fm: 79.252 | p: 79.026 | r: 79.580
r1fm+r2fm = 150.352

input #71 time: 0:12:12 | total time: 15:02:36


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.985901005647593
highest_index [0]
highest [0.985901005647593]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.774167001247406 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.763915479183197 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 0.7390834093093872 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7312168478965759 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 0.727107048034668 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7259383201599121 for ['[CLS] gabe tested reception news sameyler too statutepole steel used district † xl survivor [SEP]']
[Init] best rec loss: 0.7252364754676819 for ['[CLS] anne proud walked originally navigation blame spurs junior eastbery and located part swiss [SEP] [SEP]']
[Init] best rec loss: 0.7026689648628235 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7002329230308533 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.6993822455406189 for ['[CLS] except orbitalungen lifeboat dna walking nonetheless support van! pork zone ta reserve accidentally [SEP]']
[Init] best perm rec loss: 0.6973207592964172 for ['[CLS] except pork zone! lifeboat nonetheless accidentally ta orbital support walking dnaungen reserve van [SEP]']
[Init] best perm rec loss: 0.6939396262168884 for ['[CLS] orbital support pork ta dna van reserve!ungen zone nonetheless walking lifeboat except accidentally [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.717 (perp=11.928, rec=0.290, cos=0.041), tot_loss_proj:3.648 [t=0.30s]
prediction: ['[CLS] broughter bloody tough time tough shooting - easier violence enforcement mixed whose philosophy mineral [SEP]']
[ 100/2000] tot_loss=2.443 (perp=11.308, rec=0.153, cos=0.028), tot_loss_proj:3.506 [t=0.31s]
prediction: ['[CLS] haser timeer time toughv - tough a balancing shoulder its philosophy experience [SEP]']
[ 150/2000] tot_loss=2.368 (perp=11.125, rec=0.112, cos=0.031), tot_loss_proj:4.049 [t=0.31s]
prediction: ['[CLS] haser timeer time tough its itser with balancing inspired its philosophy experience [SEP]']
[ 200/2000] tot_loss=2.468 (perp=11.758, rec=0.088, cos=0.029), tot_loss_proj:3.853 [t=0.31s]
prediction: ['[CLS] haser timeer violence tough its itser with balancing inspired its philosophy counterparts [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.237 (perp=10.589, rec=0.091, cos=0.028), tot_loss_proj:3.817 [t=0.31s]
prediction: ['[CLS] haser timeer violence tough inspired itser with balancing solving its philosophy philosophy [SEP]']
[ 300/2000] tot_loss=2.339 (perp=11.146, rec=0.082, cos=0.028), tot_loss_proj:4.000 [t=0.31s]
prediction: ['[CLS] haser timeer violence tough inspired aer with balancing solving its philosophyfk [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.266 (perp=10.774, rec=0.083, cos=0.028), tot_loss_proj:3.707 [t=0.31s]
prediction: ['[CLS] haser timeer a tough inspired violenceer with balancing assassination its philosophyfk [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.135 (perp=10.148, rec=0.078, cos=0.027), tot_loss_proj:3.679 [t=0.31s]
prediction: ['[CLS] haser timeer a tough inspired violenceer balancingfk with its philosophyfk [SEP]']
[ 450/2000] tot_loss=2.140 (perp=10.148, rec=0.083, cos=0.028), tot_loss_proj:3.683 [t=0.31s]
prediction: ['[CLS] haser timeer a tough inspired violenceer balancingfk with its philosophyfk [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.117 (perp=10.062, rec=0.076, cos=0.028), tot_loss_proj:3.555 [t=0.31s]
prediction: ['[CLS] haser timeer a tough a balancingfk with its philosophy science inspired violence [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.946 (perp=9.163, rec=0.086, cos=0.027), tot_loss_proj:2.825 [t=0.31s]
prediction: ['[CLS] has a timeer a tougher balancingfk with its philosophy science inspired violence [SEP]']
[ 600/2000] tot_loss=1.952 (perp=9.163, rec=0.091, cos=0.028), tot_loss_proj:2.826 [t=0.31s]
prediction: ['[CLS] has a timeer a tougher balancingfk with its philosophy science inspired violence [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.822 (perp=8.608, rec=0.072, cos=0.028), tot_loss_proj:2.793 [t=0.31s]
prediction: ['[CLS] has a timeer a tougher balancingfk with its violence science inspired philosophy [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.789 (perp=8.415, rec=0.079, cos=0.027), tot_loss_proj:2.746 [t=0.31s]
prediction: ['[CLS] has time aer a tougher balancingfk with its violence science inspired philosophy [SEP]']
[ 750/2000] tot_loss=1.780 (perp=8.415, rec=0.069, cos=0.028), tot_loss_proj:2.741 [t=0.31s]
prediction: ['[CLS] has time aer a tougher balancingfk with its violence science inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.662 (perp=7.768, rec=0.080, cos=0.028), tot_loss_proj:2.681 [t=0.31s]
prediction: ['[CLS] time has aer a tougher balancingfk with its violence science inspired philosophy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.660 (perp=7.768, rec=0.079, cos=0.028), tot_loss_proj:2.684 [t=0.31s]
prediction: ['[CLS] time has aer a tougher balancingfk with its violence science inspired philosophy [SEP]']
[ 900/2000] tot_loss=1.648 (perp=7.768, rec=0.067, cos=0.028), tot_loss_proj:2.678 [t=0.31s]
prediction: ['[CLS] time has aer a tougher balancingfk with its violence science inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.659 (perp=7.768, rec=0.078, cos=0.028), tot_loss_proj:2.693 [t=0.31s]
prediction: ['[CLS] time has aer a tougher balancingfk with its violence science inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.661 (perp=7.768, rec=0.080, cos=0.028), tot_loss_proj:2.683 [t=0.31s]
prediction: ['[CLS] time has aer a tougher balancingfk with its violence science inspired philosophy [SEP]']
[1050/2000] tot_loss=1.666 (perp=7.768, rec=0.084, cos=0.028), tot_loss_proj:2.685 [t=0.31s]
prediction: ['[CLS] time has aer a tougher balancingfk with its violence science inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.664 (perp=7.848, rec=0.067, cos=0.028), tot_loss_proj:2.816 [t=0.31s]
prediction: ['[CLS] time has aer a tougher balancingfk with its violence inspired inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.666 (perp=7.848, rec=0.069, cos=0.028), tot_loss_proj:2.821 [t=0.31s]
prediction: ['[CLS] time has aer a tougher balancingfk with its violence inspired inspired philosophy [SEP]']
[1200/2000] tot_loss=1.674 (perp=7.848, rec=0.077, cos=0.028), tot_loss_proj:2.824 [t=0.31s]
prediction: ['[CLS] time has aer a tougher balancingfk with its violence inspired inspired philosophy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.659 (perp=7.848, rec=0.061, cos=0.028), tot_loss_proj:2.816 [t=0.31s]
prediction: ['[CLS] time has aer a tougher balancingfk with its violence inspired inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.639 (perp=7.673, rec=0.078, cos=0.026), tot_loss_proj:2.809 [t=0.31s]
prediction: ['[CLS] time has itser a tougher balancingfk with a violence inspired inspired philosophy [SEP]']
[1350/2000] tot_loss=1.634 (perp=7.673, rec=0.071, cos=0.028), tot_loss_proj:2.816 [t=0.31s]
prediction: ['[CLS] time has itser a tougher balancingfk with a violence inspired inspired philosophy [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.618 (perp=7.521, rec=0.086, cos=0.028), tot_loss_proj:2.608 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.601 (perp=7.521, rec=0.069, cos=0.028), tot_loss_proj:2.611 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
[1500/2000] tot_loss=1.610 (perp=7.521, rec=0.078, cos=0.028), tot_loss_proj:2.603 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.594 (perp=7.521, rec=0.062, cos=0.028), tot_loss_proj:2.611 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.606 (perp=7.521, rec=0.074, cos=0.028), tot_loss_proj:2.611 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
[1650/2000] tot_loss=1.598 (perp=7.521, rec=0.066, cos=0.028), tot_loss_proj:2.609 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.600 (perp=7.521, rec=0.068, cos=0.028), tot_loss_proj:2.607 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.597 (perp=7.521, rec=0.065, cos=0.028), tot_loss_proj:2.603 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
[1800/2000] tot_loss=1.603 (perp=7.521, rec=0.071, cos=0.028), tot_loss_proj:2.605 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.597 (perp=7.521, rec=0.065, cos=0.027), tot_loss_proj:2.602 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.611 (perp=7.521, rec=0.079, cos=0.027), tot_loss_proj:2.606 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
[1950/2000] tot_loss=1.599 (perp=7.521, rec=0.067, cos=0.028), tot_loss_proj:2.604 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.601 (perp=7.521, rec=0.070, cos=0.027), tot_loss_proj:2.611 [t=0.31s]
prediction: ['[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] time has itser tougher balancing afk with a violence inspired inspired philosophy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.481 | p: 78.571 | r: 84.615
rouge2     | fm: 16.000 | p: 15.385 | r: 16.667
rougeL     | fm: 59.259 | p: 57.143 | r: 61.538
rougeLsum  | fm: 59.259 | p: 57.143 | r: 61.538
r1fm+r2fm = 97.481

[Aggregate metrics]:
rouge1     | fm: 89.514 | p: 89.186 | r: 89.957
rouge2     | fm: 60.009 | p: 59.930 | r: 60.235
rougeL     | fm: 79.004 | p: 78.715 | r: 79.321
rougeLsum  | fm: 79.063 | p: 78.776 | r: 79.448
r1fm+r2fm = 149.523

input #72 time: 0:12:13 | total time: 15:14:49


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9862425567016133
highest_index [0]
highest [0.9862425567016133]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.965874969959259 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9366437196731567 for ['[CLS] garage knight [SEP]']
[Init] best rec loss: 0.9150215983390808 for ['[CLS] capitol living [SEP]']
[Init] best rec loss: 0.9034687876701355 for ['[CLS] role breton [SEP]']
[Init] best rec loss: 0.8965395092964172 for ['[CLS] pass society [SEP]']
[Init] best rec loss: 0.8959136605262756 for ['[CLS] subspecies ma [SEP]']
[Init] best rec loss: 0.8841679096221924 for ['[CLS] puget traditional [SEP]']
[Init] best rec loss: 0.8470126390457153 for ['[CLS] massachusetts gun [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.177 (perp=9.724, rec=0.197, cos=0.035), tot_loss_proj:2.054 [t=0.34s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.057 (perp=9.724, rec=0.084, cos=0.028), tot_loss_proj:2.072 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.043 (perp=9.724, rec=0.070, cos=0.027), tot_loss_proj:2.059 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.037 (perp=9.724, rec=0.065, cos=0.027), tot_loss_proj:2.057 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.037 (perp=9.724, rec=0.065, cos=0.028), tot_loss_proj:2.054 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.029 (perp=9.724, rec=0.058, cos=0.027), tot_loss_proj:2.040 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.034 (perp=9.724, rec=0.062, cos=0.027), tot_loss_proj:2.053 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.042 (perp=9.724, rec=0.070, cos=0.027), tot_loss_proj:2.047 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.028 (perp=9.724, rec=0.056, cos=0.027), tot_loss_proj:2.040 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.043 (perp=9.724, rec=0.071, cos=0.027), tot_loss_proj:2.041 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.040 (perp=9.724, rec=0.068, cos=0.027), tot_loss_proj:2.054 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.032 (perp=9.724, rec=0.060, cos=0.027), tot_loss_proj:2.050 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.031 (perp=9.724, rec=0.059, cos=0.027), tot_loss_proj:2.046 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.026 (perp=9.724, rec=0.054, cos=0.027), tot_loss_proj:2.052 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.047 (perp=9.724, rec=0.075, cos=0.027), tot_loss_proj:2.046 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.029 (perp=9.724, rec=0.057, cos=0.027), tot_loss_proj:2.053 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.037 (perp=9.724, rec=0.065, cos=0.027), tot_loss_proj:2.042 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.029 (perp=9.724, rec=0.057, cos=0.027), tot_loss_proj:2.051 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.032 (perp=9.724, rec=0.060, cos=0.027), tot_loss_proj:2.047 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.031 (perp=9.724, rec=0.059, cos=0.027), tot_loss_proj:2.053 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.035 (perp=9.724, rec=0.063, cos=0.027), tot_loss_proj:2.047 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.036 (perp=9.724, rec=0.064, cos=0.027), tot_loss_proj:2.056 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.028 (perp=9.724, rec=0.056, cos=0.027), tot_loss_proj:2.038 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.028 (perp=9.724, rec=0.056, cos=0.027), tot_loss_proj:2.046 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.031 (perp=9.724, rec=0.059, cos=0.027), tot_loss_proj:2.046 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.040 (perp=9.724, rec=0.068, cos=0.027), tot_loss_proj:2.055 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.021 (perp=9.724, rec=0.049, cos=0.027), tot_loss_proj:2.049 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.034 (perp=9.724, rec=0.062, cos=0.027), tot_loss_proj:2.053 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.044 (perp=9.724, rec=0.072, cos=0.027), tot_loss_proj:2.063 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.030 (perp=9.724, rec=0.058, cos=0.027), tot_loss_proj:2.049 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.039 (perp=9.724, rec=0.067, cos=0.027), tot_loss_proj:2.044 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.040 (perp=9.724, rec=0.068, cos=0.027), tot_loss_proj:2.040 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.028 (perp=9.724, rec=0.056, cos=0.027), tot_loss_proj:2.041 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.031 (perp=9.724, rec=0.059, cos=0.027), tot_loss_proj:2.053 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.025 (perp=9.724, rec=0.053, cos=0.027), tot_loss_proj:2.058 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.031 (perp=9.724, rec=0.059, cos=0.027), tot_loss_proj:2.038 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.047 (perp=9.724, rec=0.075, cos=0.027), tot_loss_proj:2.053 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.027 (perp=9.724, rec=0.055, cos=0.027), tot_loss_proj:2.037 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.024 (perp=9.724, rec=0.052, cos=0.027), tot_loss_proj:2.044 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.047 (perp=9.724, rec=0.075, cos=0.027), tot_loss_proj:2.052 [t=0.35s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.630 | p: 89.279 | r: 90.089
rouge2     | fm: 60.637 | p: 60.508 | r: 60.788
rougeL     | fm: 79.272 | p: 79.006 | r: 79.642
rougeLsum  | fm: 79.314 | p: 79.059 | r: 79.674
r1fm+r2fm = 150.268

input #73 time: 0:13:37 | total time: 15:28:26


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9870053945689634
highest_index [0]
highest [0.9870053945689634]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 0.8164293766021729 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6232904195785522 for ['[CLS] storage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.792 (perp=8.177, rec=0.127, cos=0.029), tot_loss_proj:1.940 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.731 (perp=8.177, rec=0.071, cos=0.025), tot_loss_proj:1.776 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.730 (perp=8.177, rec=0.069, cos=0.026), tot_loss_proj:1.767 [t=0.32s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.724 (perp=8.177, rec=0.062, cos=0.026), tot_loss_proj:1.773 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.725 (perp=8.177, rec=0.061, cos=0.028), tot_loss_proj:1.768 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.711 (perp=8.177, rec=0.050, cos=0.026), tot_loss_proj:1.769 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.724 (perp=8.177, rec=0.064, cos=0.026), tot_loss_proj:1.766 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.728 (perp=8.177, rec=0.067, cos=0.026), tot_loss_proj:1.765 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.718 (perp=8.177, rec=0.057, cos=0.026), tot_loss_proj:1.774 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.719 (perp=8.177, rec=0.058, cos=0.026), tot_loss_proj:1.780 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.719 (perp=8.177, rec=0.058, cos=0.026), tot_loss_proj:1.766 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.724 (perp=8.177, rec=0.063, cos=0.026), tot_loss_proj:1.766 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.713 (perp=8.177, rec=0.052, cos=0.026), tot_loss_proj:1.774 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.712 (perp=8.177, rec=0.051, cos=0.026), tot_loss_proj:1.776 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.719 (perp=8.177, rec=0.058, cos=0.026), tot_loss_proj:1.773 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.722 (perp=8.177, rec=0.061, cos=0.026), tot_loss_proj:1.775 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.711 (perp=8.177, rec=0.050, cos=0.026), tot_loss_proj:1.777 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.719 (perp=8.177, rec=0.058, cos=0.026), tot_loss_proj:1.770 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.722 (perp=8.177, rec=0.061, cos=0.026), tot_loss_proj:1.777 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.715 (perp=8.177, rec=0.054, cos=0.026), tot_loss_proj:1.763 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.715 (perp=8.177, rec=0.053, cos=0.026), tot_loss_proj:1.770 [t=0.32s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.722 (perp=8.177, rec=0.061, cos=0.026), tot_loss_proj:1.772 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.727 (perp=8.177, rec=0.066, cos=0.026), tot_loss_proj:1.771 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.721 (perp=8.177, rec=0.060, cos=0.026), tot_loss_proj:1.765 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.719 (perp=8.177, rec=0.057, cos=0.026), tot_loss_proj:1.770 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.723 (perp=8.177, rec=0.062, cos=0.026), tot_loss_proj:1.771 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.723 (perp=8.177, rec=0.061, cos=0.026), tot_loss_proj:1.772 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.712 (perp=8.177, rec=0.051, cos=0.026), tot_loss_proj:1.767 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.726 (perp=8.177, rec=0.065, cos=0.026), tot_loss_proj:1.774 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.720 (perp=8.177, rec=0.059, cos=0.026), tot_loss_proj:1.763 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.707 (perp=8.177, rec=0.046, cos=0.026), tot_loss_proj:1.763 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.720 (perp=8.177, rec=0.058, cos=0.026), tot_loss_proj:1.764 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.725 (perp=8.177, rec=0.064, cos=0.026), tot_loss_proj:1.770 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.719 (perp=8.177, rec=0.058, cos=0.026), tot_loss_proj:1.767 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.737 (perp=8.177, rec=0.076, cos=0.026), tot_loss_proj:1.774 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.721 (perp=8.177, rec=0.060, cos=0.026), tot_loss_proj:1.762 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.717 (perp=8.177, rec=0.056, cos=0.026), tot_loss_proj:1.755 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.714 (perp=8.177, rec=0.052, cos=0.026), tot_loss_proj:1.769 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.721 (perp=8.177, rec=0.060, cos=0.026), tot_loss_proj:1.776 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.722 (perp=8.177, rec=0.061, cos=0.026), tot_loss_proj:1.771 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.820 | p: 89.490 | r: 90.214
rouge2     | fm: 61.206 | p: 61.071 | r: 61.354
rougeL     | fm: 79.491 | p: 79.269 | r: 79.904
rougeLsum  | fm: 79.546 | p: 79.298 | r: 79.981
r1fm+r2fm = 151.026

input #74 time: 0:12:19 | total time: 15:40:46


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9860125864190961
highest_index [0]
highest [0.9860125864190961]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.8809160590171814 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.880614697933197 for ['[CLS]isch expansion earl early badly bea camp manuscripts nas counted butcher spike braun planned lark chad constant blue himself [SEP]']
[Init] best rec loss: 0.8466907143592834 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.8205229640007019 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best perm rec loss: 0.8203732371330261 for ['[CLS] help marlene zach rush es connacht clan malone reason duties regiment moth churchesose meaning double lakes alfred section [SEP]']
[Init] best perm rec loss: 0.8202673196792603 for ['[CLS]ose meaning connacht reason duties marlene clan help zach regiment churches moth double malone section rush alfred lakes es [SEP]']
[Init] best perm rec loss: 0.8183238506317139 for ['[CLS] marlene lakes section meaning duties zach malone reason churches rush es regiment help connacht double moth alfred clanose [SEP]']
[Init] best perm rec loss: 0.8169461488723755 for ['[CLS] alfred rush moth lakes churches double sectionose reason help duties connacht marlene malone zach regiment es meaning clan [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.920 (perp=12.739, rec=0.330, cos=0.043), tot_loss_proj:3.813 [t=0.35s]
prediction: ['[CLS] ev incident 00pm historical ( garbage never ignored forgotten an spiritual need craft not easilylessly. thatarable [SEP]']
[ 100/2000] tot_loss=2.324 (perp=10.500, rec=0.196, cos=0.028), tot_loss_proj:3.245 [t=0.35s]
prediction: ['[CLS]fur instability masteredenter olsenneas not forgotten forgotten an mental instability easily not easily dismissed. this moment [SEP]']
[ 150/2000] tot_loss=2.157 (perp=9.773, rec=0.174, cos=0.029), tot_loss_proj:2.617 [t=0.35s]
prediction: ['[CLS] wainwright instability [SEP]enter at is not forgotten easilystic mental instability easily not easily dismissed. this excursion [SEP]']
[ 200/2000] tot_loss=2.275 (perp=10.582, rec=0.129, cos=0.029), tot_loss_proj:3.013 [t=0.35s]
prediction: ['[CLS] detail instability [SEP]enter into is not forgotten easilycola mental instability easily not or dismissed. this excursion [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.048 (perp=9.553, rec=0.109, cos=0.029), tot_loss_proj:2.680 [t=0.35s]
prediction: ['[CLS] detail instability [SEP]cola into is not forgotten easilyting mental instability or not easily dismissed. this excursion [SEP]']
[ 300/2000] tot_loss=2.118 (perp=9.962, rec=0.097, cos=0.028), tot_loss_proj:2.829 [t=0.35s]
prediction: ['[CLS]cted instability [SEP]cola into is not forgotten easilyting mental instability or not easily dismissed. this excursion [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.899 (perp=8.930, rec=0.086, cos=0.028), tot_loss_proj:2.381 [t=0.36s]
prediction: ['[CLS]pt instability [SEP]cola into is not easily forgottenting mental instability or not easily dismissed. this excursion [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.868 (perp=8.445, rec=0.148, cos=0.031), tot_loss_proj:2.131 [t=0.36s]
prediction: ['[CLS]艹 instability [SEP]cola of is not easily forgotten into mental instability or not easily dismissed. this excursion [SEP]']
[ 450/2000] tot_loss=1.946 (perp=8.966, rec=0.124, cos=0.029), tot_loss_proj:2.604 [t=0.36s]
prediction: ['[CLS] into instability [SEP]cola of is not easily forgotten into mental instability or local easily dismissed. this excursion [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.847 (perp=8.506, rec=0.118, cos=0.028), tot_loss_proj:2.354 [t=0.36s]
prediction: ['[CLS] of into instability [SEP]cola is not easily forgotten into mental instability or cultural easily dismissed. this excursion [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.848 (perp=8.557, rec=0.109, cos=0.027), tot_loss_proj:2.365 [t=0.35s]
prediction: ['[CLS] excursion intollation [SEP]cola is not easily forgotten into mental instability or local easily dismissed. this of [SEP]']
[ 600/2000] tot_loss=1.951 (perp=9.094, rec=0.105, cos=0.027), tot_loss_proj:2.556 [t=0.36s]
prediction: ['[CLS] excursion intollation [SEP]cola is not easily forgotten into mental instability orcola easily dismissed. this of [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.855 (perp=8.720, rec=0.083, cos=0.027), tot_loss_proj:2.426 [t=0.36s]
prediction: ['[CLS] excursioncolallation [SEP]cola is not easily forgotten into mental instability or into easily dismissed. this of [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.870 (perp=8.720, rec=0.098, cos=0.027), tot_loss_proj:2.422 [t=0.36s]
prediction: ['[CLS] excursioncolallation [SEP]cola is not easily forgotten into mental instability or into easily dismissed. this of [SEP]']
[ 750/2000] tot_loss=1.997 (perp=9.355, rec=0.098, cos=0.028), tot_loss_proj:2.727 [t=0.36s]
prediction: ['[CLS] excursioncolallation [SEP]cola is not easily forgotten into mental instability or intocola dismissed. this of [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.951 (perp=9.172, rec=0.089, cos=0.027), tot_loss_proj:2.577 [t=0.36s]
prediction: ['[CLS] excursioncolallation [SEP]cola is not easily forgotten into mental instability or intocola dismissed of this. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.947 (perp=9.172, rec=0.085, cos=0.028), tot_loss_proj:2.583 [t=0.35s]
prediction: ['[CLS] excursioncolallation [SEP]cola is not easily forgotten into mental instability or intocola dismissed of this. [SEP]']
[ 900/2000] tot_loss=1.955 (perp=9.172, rec=0.093, cos=0.028), tot_loss_proj:2.583 [t=0.35s]
prediction: ['[CLS] excursioncolallation [SEP]cola is not easily forgotten into mental instability or intocola dismissed of this. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.893 (perp=8.844, rec=0.097, cos=0.027), tot_loss_proj:2.326 [t=0.36s]
prediction: ['[CLS] excursioncolacola [SEP]cola is not easily forgotten into mental instability or ofcola dismissed into this. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.984 (perp=9.325, rec=0.092, cos=0.027), tot_loss_proj:2.381 [t=0.35s]
prediction: ['[CLS] excursioncolacola epiccola is not easily forgotten into mental instability or of [SEP] dismissed into this. [SEP]']
[1050/2000] tot_loss=1.974 (perp=9.325, rec=0.082, cos=0.027), tot_loss_proj:2.386 [t=0.36s]
prediction: ['[CLS] excursioncolacola epiccola is not easily forgotten into mental instability or of [SEP] dismissed into this. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.917 (perp=9.066, rec=0.077, cos=0.027), tot_loss_proj:2.328 [t=0.36s]
prediction: ['[CLS] oftingcola epiccola is not easily forgotten into mental instability or excursion [SEP] dismissed into this. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.874 (perp=8.812, rec=0.085, cos=0.027), tot_loss_proj:2.551 [t=0.36s]
prediction: ['[CLS] oftingcola intocola is not easily forgotten epic mental instability or excursion [SEP] dismissed into this. [SEP]']
[1200/2000] tot_loss=1.876 (perp=8.812, rec=0.086, cos=0.027), tot_loss_proj:2.551 [t=0.36s]
prediction: ['[CLS] oftingcola intocola is not easily forgotten epic mental instability or excursion [SEP] dismissed into this. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.870 (perp=8.812, rec=0.081, cos=0.027), tot_loss_proj:2.546 [t=0.36s]
prediction: ['[CLS] oftingcola intocola is not easily forgotten epic mental instability or excursion [SEP] dismissed into this. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.809 (perp=8.431, rec=0.095, cos=0.027), tot_loss_proj:2.523 [t=0.36s]
prediction: ['[CLS] ofcolating intocola is not easily forgotten epic mental instability or excursion [SEP] dismissed into this. [SEP]']
[1350/2000] tot_loss=1.792 (perp=8.431, rec=0.078, cos=0.027), tot_loss_proj:2.524 [t=0.36s]
prediction: ['[CLS] ofcolating intocola is not easily forgotten epic mental instability or excursion [SEP] dismissed into this. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.796 (perp=8.431, rec=0.083, cos=0.027), tot_loss_proj:2.535 [t=0.36s]
prediction: ['[CLS] ofcolating intocola is not easily forgotten epic mental instability or excursion [SEP] dismissed into this. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.791 (perp=8.431, rec=0.078, cos=0.027), tot_loss_proj:2.523 [t=0.36s]
prediction: ['[CLS] ofcolating intocola is not easily forgotten epic mental instability or excursion [SEP] dismissed into this. [SEP]']
[1500/2000] tot_loss=1.799 (perp=8.431, rec=0.085, cos=0.027), tot_loss_proj:2.531 [t=0.36s]
prediction: ['[CLS] ofcolating intocola is not easily forgotten epic mental instability or excursion [SEP] dismissed into this. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.764 (perp=8.256, rec=0.085, cos=0.027), tot_loss_proj:2.532 [t=0.36s]
prediction: ['[CLS] [SEP]colating intocola is not easily forgotten epic mental instability or excursion of dismissed into this. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.746 (perp=8.131, rec=0.092, cos=0.028), tot_loss_proj:2.442 [t=0.36s]
prediction: ['[CLS] [SEP]colating intocola is not easily forgotten this mental instability or excursion of dismissed into epic. [SEP]']
[1650/2000] tot_loss=1.745 (perp=8.131, rec=0.091, cos=0.028), tot_loss_proj:2.440 [t=0.36s]
prediction: ['[CLS] [SEP]colating intocola is not easily forgotten this mental instability or excursion of dismissed into epic. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.692 (perp=7.814, rec=0.102, cos=0.027), tot_loss_proj:2.302 [t=0.36s]
prediction: ['[CLS] [SEP]colating into thiscola is not easily forgotten mental instability or excursion of dismissed into epic. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.687 (perp=7.814, rec=0.098, cos=0.027), tot_loss_proj:2.314 [t=0.36s]
prediction: ['[CLS] [SEP]colating into thiscola is not easily forgotten mental instability or excursion of dismissed into epic. [SEP]']
[1800/2000] tot_loss=1.683 (perp=7.814, rec=0.093, cos=0.027), tot_loss_proj:2.314 [t=0.36s]
prediction: ['[CLS] [SEP]colating into thiscola is not easily forgotten mental instability or excursion of dismissed into epic. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.675 (perp=7.814, rec=0.085, cos=0.027), tot_loss_proj:2.306 [t=0.36s]
prediction: ['[CLS] [SEP]colating into thiscola is not easily forgotten mental instability or excursion of dismissed into epic. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.672 (perp=7.814, rec=0.082, cos=0.027), tot_loss_proj:2.310 [t=0.35s]
prediction: ['[CLS] [SEP]colating into thiscola is not easily forgotten mental instability or excursion of dismissed into epic. [SEP]']
[1950/2000] tot_loss=1.681 (perp=7.814, rec=0.091, cos=0.027), tot_loss_proj:2.310 [t=0.36s]
prediction: ['[CLS] [SEP]colating into thiscola is not easily forgotten mental instability or excursion of dismissed into epic. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.683 (perp=7.814, rec=0.093, cos=0.027), tot_loss_proj:2.320 [t=0.36s]
prediction: ['[CLS] [SEP]colating into thiscola is not easily forgotten mental instability or excursion of dismissed into epic. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] oftingcola intocola is not easily forgotten epic mental instability or excursion [SEP] dismissed into this. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.471 | p: 76.471 | r: 76.471
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 35.294 | p: 35.294 | r: 35.294
rougeLsum  | fm: 35.294 | p: 35.294 | r: 35.294
r1fm+r2fm = 95.221

[Aggregate metrics]:
rouge1     | fm: 89.550 | p: 89.296 | r: 90.052
rouge2     | fm: 60.855 | p: 60.733 | r: 61.039
rougeL     | fm: 79.003 | p: 78.711 | r: 79.379
rougeLsum  | fm: 79.011 | p: 78.769 | r: 79.353
r1fm+r2fm = 150.405

input #75 time: 0:13:55 | total time: 15:54:42


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9865581373572571
highest_index [0]
highest [0.9865581373572571]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.8900482654571533 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.8805668950080872 for ['[CLS] skin outside historian inside please determined boss legend vi đ wine unanimouslymer ski [SEP]']
[Init] best rec loss: 0.8720448613166809 for ['[CLS] midnight even task j mesh constellation village typhoonorough, advancing hammerist carol [SEP]']
[Init] best rec loss: 0.8553734421730042 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.8497833609580994 for ['[CLS] paper both commercially user guantanamo body 3d barker away commune also fortune turkey shay [SEP]']
[Init] best perm rec loss: 0.8466418385505676 for ['[CLS] turkey shay 3d commercially fortune user guantanamo away commune barker also both paper body [SEP]']
[Init] best perm rec loss: 0.8454280495643616 for ['[CLS] paper shay fortune user barker both commercially away 3d turkey also guantanamo commune body [SEP]']
[Init] best perm rec loss: 0.8449331521987915 for ['[CLS] commercially both commune also turkey paper shay user barker fortune away 3d body guantanamo [SEP]']
[Init] best perm rec loss: 0.8439210057258606 for ['[CLS] paper barker away user shay fortune turkey commune guantanamo 3d also commercially both body [SEP]']
[Init] best perm rec loss: 0.8435207009315491 for ['[CLS] turkey guantanamo both commercially paper barker shay commune 3d user body fortune also away [SEP]']
[Init] best perm rec loss: 0.8432282209396362 for ['[CLS] 3d also body barker commune turkey both guantanamo commercially shay user paper away fortune [SEP]']
[Init] best perm rec loss: 0.8427278995513916 for ['[CLS] shay 3d paper commune fortune guantanamo also both user turkey commercially barker away body [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.611 (perp=11.404, rec=0.286, cos=0.044), tot_loss_proj:3.305 [t=0.35s]
prediction: ['[CLS] division stop challenging yourself who stoppedfarlane has stopped recently alivewell stopped challenging [SEP]']
[ 100/2000] tot_loss=2.420 (perp=11.281, rec=0.136, cos=0.027), tot_loss_proj:3.241 [t=0.35s]
prediction: ['[CLS] that stopped challenging himself. stopped perry has allen edison hasnivorous stopped challenging [SEP]']
[ 150/2000] tot_loss=1.783 (perp=8.218, rec=0.113, cos=0.027), tot_loss_proj:2.937 [t=0.35s]
prediction: ['[CLS] if stopped challenging himself. stopped if, allen 66 has when stopped. [SEP]']
[ 200/2000] tot_loss=1.800 (perp=8.035, rec=0.163, cos=0.030), tot_loss_proj:2.611 [t=0.35s]
prediction: ['[CLS] if stopped challenging himself brooks stopped.. 5. has. stopped. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.614 (perp=10.793, rec=0.746, cos=0.709), tot_loss_proj:3.193 [t=0.35s]
prediction: ['[CLS] if stopped challenging himselfies brooks stopped valuable at 26 kid has died. [SEP]']
[ 300/2000] tot_loss=2.398 (perp=9.253, rec=0.398, cos=0.149), tot_loss_proj:2.886 [t=0.35s]
prediction: ['[CLS] if stopped challenging himself would / stopped valuable at good guygling died. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.336 (perp=9.690, rec=0.309, cos=0.089), tot_loss_proj:3.202 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself / stopped valuable at good feltgling thinks. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.198 (perp=9.581, rec=0.225, cos=0.057), tot_loss_proj:3.146 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself / stopped valuable good at feelsgling thinks. [SEP]']
[ 450/2000] tot_loss=2.167 (perp=9.629, rec=0.197, cos=0.044), tot_loss_proj:3.076 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself / stopped valuable 20 at hasgling thinks. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.971 (perp=8.751, rec=0.182, cos=0.039), tot_loss_proj:2.754 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself / stopped valuable at 20 hasgling stopped. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.961 (perp=8.751, rec=0.174, cos=0.036), tot_loss_proj:2.762 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself / stopped valuable at 20 hasgling stopped. [SEP]']
[ 600/2000] tot_loss=2.199 (perp=9.958, rec=0.173, cos=0.035), tot_loss_proj:3.090 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself allen stopped valuable at 66 hasgling stopped. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.177 (perp=9.847, rec=0.173, cos=0.035), tot_loss_proj:3.075 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped allen at 66 ¨gling stopped. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.087 (perp=9.441, rec=0.164, cos=0.035), tot_loss_proj:3.096 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped at allen 66 ¨gling stopped. [SEP]']
[ 750/2000] tot_loss=2.089 (perp=9.441, rec=0.167, cos=0.034), tot_loss_proj:3.104 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped at allen 66 ¨gling stopped. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.090 (perp=9.441, rec=0.168, cos=0.033), tot_loss_proj:3.096 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped at allen 66 ¨gling stopped. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.070 (perp=9.441, rec=0.149, cos=0.033), tot_loss_proj:3.104 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped at allen 66 ¨gling stopped. [SEP]']
[ 900/2000] tot_loss=2.075 (perp=9.441, rec=0.154, cos=0.033), tot_loss_proj:3.110 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped at allen 66 ¨gling stopped. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.089 (perp=9.441, rec=0.169, cos=0.032), tot_loss_proj:3.109 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped at allen 66 ¨gling stopped. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.079 (perp=9.441, rec=0.158, cos=0.032), tot_loss_proj:3.109 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped at allen 66 ¨gling stopped. [SEP]']
[1050/2000] tot_loss=2.065 (perp=9.441, rec=0.144, cos=0.032), tot_loss_proj:3.109 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped at allen 66 ¨gling stopped. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.067 (perp=9.441, rec=0.147, cos=0.032), tot_loss_proj:3.110 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped at allen 66 ¨gling stopped. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.067 (perp=9.441, rec=0.147, cos=0.032), tot_loss_proj:3.111 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped at allen 66 ¨gling stopped. [SEP]']
[1200/2000] tot_loss=2.074 (perp=9.441, rec=0.154, cos=0.031), tot_loss_proj:3.112 [t=0.35s]
prediction: ['[CLS] would if stopped challenging himself nor stopped at allen 66 ¨gling stopped. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.059 (perp=9.442, rec=0.140, cos=0.031), tot_loss_proj:3.032 [t=0.35s]
prediction: ['[CLS]gling if stopped challenging himself nor stopped at allen 66 ¨ would stopped. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.020 (perp=9.184, rec=0.153, cos=0.031), tot_loss_proj:3.378 [t=0.35s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
[1350/2000] tot_loss=2.019 (perp=9.184, rec=0.152, cos=0.031), tot_loss_proj:3.385 [t=0.35s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.005 (perp=9.184, rec=0.138, cos=0.030), tot_loss_proj:3.385 [t=0.35s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.012 (perp=9.184, rec=0.146, cos=0.030), tot_loss_proj:3.389 [t=0.35s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
[1500/2000] tot_loss=2.017 (perp=9.184, rec=0.150, cos=0.030), tot_loss_proj:3.388 [t=0.30s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.003 (perp=9.184, rec=0.136, cos=0.030), tot_loss_proj:3.392 [t=0.30s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.009 (perp=9.184, rec=0.142, cos=0.030), tot_loss_proj:3.392 [t=0.30s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
[1650/2000] tot_loss=2.011 (perp=9.184, rec=0.145, cos=0.030), tot_loss_proj:3.393 [t=0.30s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.003 (perp=9.184, rec=0.137, cos=0.029), tot_loss_proj:3.393 [t=0.30s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.013 (perp=9.184, rec=0.147, cos=0.029), tot_loss_proj:3.392 [t=0.30s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
[1800/2000] tot_loss=2.009 (perp=9.184, rec=0.143, cos=0.029), tot_loss_proj:3.392 [t=0.30s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.009 (perp=9.184, rec=0.143, cos=0.029), tot_loss_proj:3.388 [t=0.30s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.006 (perp=9.184, rec=0.141, cos=0.029), tot_loss_proj:3.394 [t=0.30s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
[1950/2000] tot_loss=2.022 (perp=9.184, rec=0.156, cos=0.029), tot_loss_proj:3.401 [t=0.30s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.016 (perp=9.184, rec=0.150, cos=0.029), tot_loss_proj:3.396 [t=0.30s]
prediction: ['[CLS]gling if stopped challenging himself would stopped at allen 66 ¨ nor stopped. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] if stopped challenging himself. stopped if, allen 66 has when stopped. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.000 | p: 69.231 | r: 75.000
rouge2     | fm: 34.783 | p: 33.333 | r: 36.364
rougeL     | fm: 56.000 | p: 53.846 | r: 58.333
rougeLsum  | fm: 56.000 | p: 53.846 | r: 58.333
r1fm+r2fm = 106.783

[Aggregate metrics]:
rouge1     | fm: 89.351 | p: 88.993 | r: 89.829
rouge2     | fm: 60.214 | p: 60.063 | r: 60.382
rougeL     | fm: 78.710 | p: 78.433 | r: 79.071
rougeLsum  | fm: 78.659 | p: 78.391 | r: 79.095
r1fm+r2fm = 149.565

input #76 time: 0:13:11 | total time: 16:07:54


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9878922099782947
highest_index [0]
highest [0.9878922099782947]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.7870064973831177 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.7865945100784302 for ["[CLS] it got tracking holmes internal aboriginal communist seek manifested surface basket nicky cut 'ane [SEP]"]
[Init] best rec loss: 0.7582743763923645 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.721592366695404 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.720668613910675 for ['[CLS] too type bred cold crowd more elements lips critique leather under battlefield simple lot pony [SEP]']
[Init] best perm rec loss: 0.7193236947059631 for ['[CLS] lips elements crowd lot bred critique under pony more too simple cold type leather battlefield [SEP]']
[Init] best perm rec loss: 0.7166288495063782 for ['[CLS] bred lot battlefield simple more crowd type pony under cold critique lips too leather elements [SEP]']
[Init] best perm rec loss: 0.7157047986984253 for ['[CLS] elements bred crowd type more critique cold battlefield simple under leather pony lips lot too [SEP]']
[Init] best perm rec loss: 0.7140301465988159 for ['[CLS] crowd lot critique under simple lips more type pony cold elements leather battlefield too bred [SEP]']
[Init] best perm rec loss: 0.713212251663208 for ['[CLS] pony battlefield cold lot critique type leather lips more too crowd simple elements under bred [SEP]']
[Init] best perm rec loss: 0.7129310369491577 for ['[CLS] pony battlefield bred leather critique type lips crowd under too more simple elements lot cold [SEP]']
[Init] best perm rec loss: 0.712917149066925 for ['[CLS] elements battlefield type lips lot critique more under crowd too leather cold simple bred pony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.654 (perp=11.356, rec=0.330, cos=0.053), tot_loss_proj:3.670 [t=0.30s]
prediction: ['[CLS] short nerves above between new lay higher world againstated conquered small offer above love [SEP]']
[ 100/2000] tot_loss=2.340 (perp=10.469, rec=0.213, cos=0.033), tot_loss_proj:2.992 [t=0.31s]
prediction: ['[CLS] its land above between looks freely material life aboveated above its promises above realm [SEP]']
[ 150/2000] tot_loss=2.314 (perp=10.593, rec=0.168, cos=0.028), tot_loss_proj:3.070 [t=0.31s]
prediction: ['[CLS] is development above thatustars material life above so above believe realm above realm [SEP]']
[ 200/2000] tot_loss=2.177 (perp=10.050, rec=0.142, cos=0.025), tot_loss_proj:2.844 [t=0.31s]
prediction: ['[CLS] is promise above that thinkars material life above so realm believe realm above realm [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.062 (perp=9.597, rec=0.119, cos=0.023), tot_loss_proj:2.617 [t=0.31s]
prediction: ['[CLS] is promise that thears above material life above so believe make realm above realm [SEP]']
[ 300/2000] tot_loss=2.060 (perp=9.597, rec=0.116, cos=0.025), tot_loss_proj:2.626 [t=0.31s]
prediction: ['[CLS] is promise that thears above material life above so believe make realm above realm [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.742 (perp=7.915, rec=0.133, cos=0.025), tot_loss_proj:2.213 [t=0.31s]
prediction: ['[CLS] its promise that its material life above soars above believe make life at realm [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.695 (perp=7.802, rec=0.108, cos=0.026), tot_loss_proj:2.034 [t=0.31s]
prediction: ['[CLS] is promise that its material life soars above believe make life at the realm [SEP]']
[ 450/2000] tot_loss=1.664 (perp=7.774, rec=0.085, cos=0.024), tot_loss_proj:2.070 [t=0.31s]
prediction: ['[CLS] is promise that its material life soars above believe make life that the realm [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.548 (perp=7.214, rec=0.081, cos=0.024), tot_loss_proj:1.884 [t=0.31s]
prediction: ['[CLS] is promise that its material life soars above life make believe of the realm [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.441 (perp=6.594, rec=0.094, cos=0.028), tot_loss_proj:1.821 [t=0.31s]
prediction: ['[CLS] life promise that its material life soars above is make believe of the realm [SEP]']
[ 600/2000] tot_loss=1.424 (perp=6.594, rec=0.081, cos=0.024), tot_loss_proj:1.824 [t=0.31s]
prediction: ['[CLS] life promise that its material life soars above is make believe of the realm [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.411 (perp=6.594, rec=0.068, cos=0.024), tot_loss_proj:1.821 [t=0.31s]
prediction: ['[CLS] life promise that its material life soars above is make believe of the realm [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.414 (perp=6.594, rec=0.071, cos=0.024), tot_loss_proj:1.818 [t=0.31s]
prediction: ['[CLS] life promise that its material life soars above is make believe of the realm [SEP]']
[ 750/2000] tot_loss=1.534 (perp=7.182, rec=0.074, cos=0.024), tot_loss_proj:2.078 [t=0.31s]
prediction: ['[CLS] believe promise that its material life soars above is make believe of the realm [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.408 (perp=6.597, rec=0.065, cos=0.024), tot_loss_proj:1.964 [t=0.31s]
prediction: ['[CLS] believe its promise that material life soars above is make believe of the realm [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.360 (perp=6.318, rec=0.072, cos=0.024), tot_loss_proj:1.898 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above material is make believe of the realm [SEP]']
[ 900/2000] tot_loss=1.360 (perp=6.318, rec=0.072, cos=0.024), tot_loss_proj:1.892 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above material is make believe of the realm [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.354 (perp=6.288, rec=0.072, cos=0.024), tot_loss_proj:2.020 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
Attempt swap
[1000/2000] tot_loss=1.352 (perp=6.288, rec=0.070, cos=0.024), tot_loss_proj:2.011 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
[1050/2000] tot_loss=1.356 (perp=6.288, rec=0.074, cos=0.024), tot_loss_proj:2.013 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
Attempt swap
[1100/2000] tot_loss=1.347 (perp=6.288, rec=0.065, cos=0.024), tot_loss_proj:2.016 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
Attempt swap
[1150/2000] tot_loss=1.351 (perp=6.288, rec=0.070, cos=0.024), tot_loss_proj:2.014 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
[1200/2000] tot_loss=1.337 (perp=6.288, rec=0.056, cos=0.024), tot_loss_proj:2.009 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
Attempt swap
[1250/2000] tot_loss=1.354 (perp=6.288, rec=0.072, cos=0.024), tot_loss_proj:2.012 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
Attempt swap
[1300/2000] tot_loss=1.339 (perp=6.288, rec=0.058, cos=0.024), tot_loss_proj:2.012 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
[1350/2000] tot_loss=1.349 (perp=6.288, rec=0.068, cos=0.024), tot_loss_proj:2.014 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
Attempt swap
[1400/2000] tot_loss=1.343 (perp=6.288, rec=0.061, cos=0.024), tot_loss_proj:2.013 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
Attempt swap
[1450/2000] tot_loss=1.345 (perp=6.288, rec=0.063, cos=0.024), tot_loss_proj:2.014 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
[1500/2000] tot_loss=1.351 (perp=6.288, rec=0.069, cos=0.024), tot_loss_proj:2.006 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make believe of the realm [SEP]']
Attempt swap
[1550/2000] tot_loss=1.427 (perp=6.693, rec=0.065, cos=0.024), tot_loss_proj:1.963 [t=0.31s]
prediction: ['[CLS] - its promise that life soars above is material make believe of the realm [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.413 (perp=6.566, rec=0.076, cos=0.024), tot_loss_proj:2.258 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make - of the realm [SEP]']
[1650/2000] tot_loss=1.399 (perp=6.566, rec=0.062, cos=0.024), tot_loss_proj:2.263 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make - of the realm [SEP]']
Attempt swap
[1700/2000] tot_loss=1.408 (perp=6.566, rec=0.071, cos=0.024), tot_loss_proj:2.268 [t=0.31s]
prediction: ['[CLS] believe its promise that life soars above is material make - of the realm [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.340 (perp=6.155, rec=0.084, cos=0.025), tot_loss_proj:2.008 [t=0.31s]
prediction: ['[CLS] make believe its promise that life soars above is material - of the realm [SEP]']
[1800/2000] tot_loss=1.329 (perp=6.155, rec=0.074, cos=0.024), tot_loss_proj:2.005 [t=0.31s]
prediction: ['[CLS] make believe its promise that life soars above is material - of the realm [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.294 (perp=5.986, rec=0.073, cos=0.024), tot_loss_proj:1.848 [t=0.31s]
prediction: ['[CLS] make believe its promise - that life soars above is material of the realm [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.257 (perp=5.815, rec=0.069, cos=0.024), tot_loss_proj:1.800 [t=0.31s]
prediction: ['[CLS] make believe its promise - that life soars above is of the material realm [SEP]']
[1950/2000] tot_loss=1.263 (perp=5.815, rec=0.076, cos=0.024), tot_loss_proj:1.807 [t=0.31s]
prediction: ['[CLS] make believe its promise - that life soars above is of the material realm [SEP]']
Attempt swap
[2000/2000] tot_loss=1.246 (perp=5.815, rec=0.059, cos=0.024), tot_loss_proj:1.793 [t=0.31s]
prediction: ['[CLS] make believe its promise - that life soars above is of the material realm [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] believe its promise that life soars above is material make believe of the realm [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.774 | p: 93.750 | r: 100.000
rouge2     | fm: 20.690 | p: 20.000 | r: 21.429
rougeL     | fm: 58.065 | p: 56.250 | r: 60.000
rougeLsum  | fm: 58.065 | p: 56.250 | r: 60.000
r1fm+r2fm = 117.464

[Aggregate metrics]:
rouge1     | fm: 89.438 | p: 89.062 | r: 89.961
rouge2     | fm: 59.643 | p: 59.500 | r: 59.880
rougeL     | fm: 78.423 | p: 78.129 | r: 78.842
rougeLsum  | fm: 78.366 | p: 78.082 | r: 78.754
r1fm+r2fm = 149.081

input #77 time: 0:12:10 | total time: 16:20:05


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9844921750905665
highest_index [0]
highest [0.9844921750905665]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9562029838562012 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9274788498878479 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8006670475006104 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.7566131949424744 for ['[CLS] le screens grant [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.035 (perp=8.923, rec=0.207, cos=0.043), tot_loss_proj:2.669 [t=0.30s]
prediction: ['[CLS] theater exit exit [SEP]']
[ 100/2000] tot_loss=2.121 (perp=10.073, rec=0.075, cos=0.031), tot_loss_proj:3.257 [t=0.30s]
prediction: ['[CLS] theater the exit [SEP]']
[ 150/2000] tot_loss=2.122 (perp=10.073, rec=0.077, cos=0.031), tot_loss_proj:3.261 [t=0.30s]
prediction: ['[CLS] theater the exit [SEP]']
[ 200/2000] tot_loss=2.103 (perp=10.073, rec=0.058, cos=0.030), tot_loss_proj:3.272 [t=0.30s]
prediction: ['[CLS] theater the exit [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.694 (perp=7.958, rec=0.071, cos=0.031), tot_loss_proj:1.713 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=1.674 (perp=7.958, rec=0.052, cos=0.031), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.679 (perp=7.958, rec=0.056, cos=0.031), tot_loss_proj:1.702 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.687 (perp=7.958, rec=0.064, cos=0.031), tot_loss_proj:1.707 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.674 (perp=7.958, rec=0.051, cos=0.031), tot_loss_proj:1.717 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.672 (perp=7.958, rec=0.050, cos=0.031), tot_loss_proj:1.703 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.675 (perp=7.958, rec=0.053, cos=0.031), tot_loss_proj:1.702 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.677 (perp=7.958, rec=0.055, cos=0.031), tot_loss_proj:1.701 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.683 (perp=7.958, rec=0.060, cos=0.031), tot_loss_proj:1.711 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.686 (perp=7.958, rec=0.064, cos=0.031), tot_loss_proj:1.718 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.697 (perp=7.958, rec=0.075, cos=0.031), tot_loss_proj:1.700 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.681 (perp=7.958, rec=0.058, cos=0.031), tot_loss_proj:1.704 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.684 (perp=7.958, rec=0.062, cos=0.031), tot_loss_proj:1.707 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.696 (perp=7.958, rec=0.073, cos=0.031), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.688 (perp=7.958, rec=0.065, cos=0.031), tot_loss_proj:1.709 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.687 (perp=7.958, rec=0.065, cos=0.031), tot_loss_proj:1.709 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.691 (perp=7.958, rec=0.069, cos=0.031), tot_loss_proj:1.693 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.686 (perp=7.958, rec=0.064, cos=0.031), tot_loss_proj:1.702 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.692 (perp=7.958, rec=0.070, cos=0.031), tot_loss_proj:1.695 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.668 (perp=7.958, rec=0.046, cos=0.031), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.681 (perp=7.958, rec=0.059, cos=0.031), tot_loss_proj:1.707 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.687 (perp=7.958, rec=0.065, cos=0.031), tot_loss_proj:1.704 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.683 (perp=7.958, rec=0.061, cos=0.031), tot_loss_proj:1.695 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.687 (perp=7.958, rec=0.064, cos=0.031), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.687 (perp=7.958, rec=0.064, cos=0.031), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.677 (perp=7.958, rec=0.055, cos=0.031), tot_loss_proj:1.709 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.686 (perp=7.958, rec=0.064, cos=0.031), tot_loss_proj:1.696 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.679 (perp=7.958, rec=0.057, cos=0.031), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.676 (perp=7.958, rec=0.054, cos=0.031), tot_loss_proj:1.695 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.686 (perp=7.958, rec=0.064, cos=0.031), tot_loss_proj:1.704 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.682 (perp=7.958, rec=0.060, cos=0.031), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.679 (perp=7.958, rec=0.057, cos=0.031), tot_loss_proj:1.705 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.679 (perp=7.958, rec=0.057, cos=0.031), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.688 (perp=7.958, rec=0.066, cos=0.031), tot_loss_proj:1.704 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.684 (perp=7.958, rec=0.062, cos=0.031), tot_loss_proj:1.704 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.676 (perp=7.958, rec=0.054, cos=0.031), tot_loss_proj:1.710 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.611 | p: 89.238 | r: 90.160
rouge2     | fm: 60.242 | p: 60.066 | r: 60.439
rougeL     | fm: 78.745 | p: 78.472 | r: 79.140
rougeLsum  | fm: 78.621 | p: 78.328 | r: 79.055
r1fm+r2fm = 149.853

input #78 time: 0:11:53 | total time: 16:31:58


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.9880313806168419
highest_index [0]
highest [0.9880313806168419]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9680235981941223 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.9642444252967834 for ['[CLS] chicago militia [SEP]']
[Init] best rec loss: 0.9510119557380676 for ['[CLS] tapping huge [SEP]']
[Init] best rec loss: 0.8982188105583191 for ['[CLS] clay starts [SEP]']
[Init] best rec loss: 0.8567484617233276 for ['[CLS] armada containing [SEP]']
[Init] best rec loss: 0.82244873046875 for ['[CLS] amount volumes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.501 (perp=11.428, rec=0.190, cos=0.025), tot_loss_proj:2.655 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.477 (perp=11.428, rec=0.166, cos=0.025), tot_loss_proj:2.641 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.443 (perp=11.428, rec=0.132, cos=0.025), tot_loss_proj:2.628 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=2.442 (perp=11.428, rec=0.131, cos=0.025), tot_loss_proj:2.639 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.448 (perp=11.428, rec=0.137, cos=0.025), tot_loss_proj:2.629 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 300/2000] tot_loss=2.423 (perp=11.428, rec=0.112, cos=0.026), tot_loss_proj:2.626 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.969 (perp=9.381, rec=0.069, cos=0.024), tot_loss_proj:1.975 [t=0.30s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.849 (perp=8.695, rec=0.086, cos=0.024), tot_loss_proj:2.010 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.822 (perp=8.695, rec=0.059, cos=0.024), tot_loss_proj:1.996 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.832 (perp=8.695, rec=0.070, cos=0.024), tot_loss_proj:1.990 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.822 (perp=8.695, rec=0.060, cos=0.024), tot_loss_proj:1.992 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.845 (perp=8.695, rec=0.082, cos=0.024), tot_loss_proj:2.000 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.829 (perp=8.695, rec=0.066, cos=0.024), tot_loss_proj:1.997 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.815 (perp=8.695, rec=0.053, cos=0.024), tot_loss_proj:1.995 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.834 (perp=8.695, rec=0.071, cos=0.024), tot_loss_proj:1.991 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.821 (perp=8.695, rec=0.059, cos=0.024), tot_loss_proj:1.992 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.829 (perp=8.695, rec=0.066, cos=0.024), tot_loss_proj:1.996 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.818 (perp=8.695, rec=0.055, cos=0.024), tot_loss_proj:1.999 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.828 (perp=8.695, rec=0.065, cos=0.024), tot_loss_proj:1.992 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.828 (perp=8.695, rec=0.065, cos=0.024), tot_loss_proj:1.994 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.837 (perp=8.695, rec=0.075, cos=0.024), tot_loss_proj:2.004 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.833 (perp=8.695, rec=0.070, cos=0.024), tot_loss_proj:1.988 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.815 (perp=8.695, rec=0.052, cos=0.024), tot_loss_proj:1.982 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.828 (perp=8.695, rec=0.065, cos=0.024), tot_loss_proj:2.000 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.824 (perp=8.695, rec=0.061, cos=0.024), tot_loss_proj:1.991 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.838 (perp=8.695, rec=0.075, cos=0.024), tot_loss_proj:1.991 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.825 (perp=8.695, rec=0.062, cos=0.024), tot_loss_proj:1.988 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.825 (perp=8.695, rec=0.062, cos=0.024), tot_loss_proj:1.996 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.814 (perp=8.695, rec=0.052, cos=0.024), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.824 (perp=8.695, rec=0.061, cos=0.024), tot_loss_proj:1.983 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.818 (perp=8.695, rec=0.056, cos=0.024), tot_loss_proj:1.990 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.822 (perp=8.695, rec=0.059, cos=0.024), tot_loss_proj:1.989 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.830 (perp=8.695, rec=0.067, cos=0.024), tot_loss_proj:1.993 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.835 (perp=8.695, rec=0.073, cos=0.024), tot_loss_proj:1.986 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.824 (perp=8.695, rec=0.061, cos=0.024), tot_loss_proj:1.997 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.825 (perp=8.695, rec=0.063, cos=0.024), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.830 (perp=8.695, rec=0.067, cos=0.024), tot_loss_proj:1.997 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.823 (perp=8.695, rec=0.060, cos=0.024), tot_loss_proj:1.988 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.827 (perp=8.695, rec=0.064, cos=0.024), tot_loss_proj:1.989 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.831 (perp=8.695, rec=0.069, cos=0.024), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.784 | p: 89.398 | r: 90.296
rouge2     | fm: 59.623 | p: 59.450 | r: 59.768
rougeL     | fm: 78.712 | p: 78.435 | r: 79.071
rougeLsum  | fm: 78.615 | p: 78.330 | r: 79.023
r1fm+r2fm = 149.407

input #79 time: 0:11:52 | total time: 16:43:51


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9885034685699858
highest_index [0]
highest [0.9885034685699858]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9700400829315186 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9520957469940186 for ['[CLS] breath difference sensitiveosity higher [SEP]']
[Init] best rec loss: 0.938125729560852 for ['[CLS] water takinge bonnie ca [SEP]']
[Init] best rec loss: 0.9098387956619263 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.9015904068946838 for ['[CLS] harvest neutron bye ottawa [SEP]']
[Init] best rec loss: 0.885852038860321 for ['[CLS] heard pavilionplane ian tu [SEP]']
[Init] best perm rec loss: 0.8820367455482483 for ['[CLS] heardplane ian tu pavilion [SEP]']
[Init] best perm rec loss: 0.8819200992584229 for ['[CLS] tu heard ian pavilionplane [SEP]']
[Init] best perm rec loss: 0.8799068331718445 for ['[CLS] heardplane tu pavilion ian [SEP]']
[Init] best perm rec loss: 0.879867434501648 for ['[CLS] pavilion ianplane heard tu [SEP]']
[Init] best perm rec loss: 0.8782264590263367 for ['[CLS] ian heardplane pavilion tu [SEP]']
[Init] best perm rec loss: 0.8779757618904114 for ['[CLS]plane ian pavilion heard tu [SEP]']
[Init] best perm rec loss: 0.8758477568626404 for ['[CLS] ianplane pavilion heard tu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.739 (perp=12.124, rec=0.287, cos=0.028), tot_loss_proj:2.992 [t=0.30s]
prediction: ['[CLS], zzen wise intelligent [SEP]']
[ 100/2000] tot_loss=2.729 (perp=12.687, rec=0.169, cos=0.023), tot_loss_proj:3.548 [t=0.30s]
prediction: ['[CLS] wizenzen wiseed [SEP]']
[ 150/2000] tot_loss=2.350 (perp=11.096, rec=0.108, cos=0.023), tot_loss_proj:3.316 [t=0.30s]
prediction: ['[CLS] wizen wi wiseed [SEP]']
[ 200/2000] tot_loss=2.595 (perp=12.492, rec=0.073, cos=0.023), tot_loss_proj:3.952 [t=0.30s]
prediction: ['[CLS],zen wi wiseed [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.648 (perp=7.698, rec=0.085, cos=0.023), tot_loss_proj:1.895 [t=0.30s]
prediction: ['[CLS], wise wizened [SEP]']
[ 300/2000] tot_loss=1.629 (perp=7.698, rec=0.067, cos=0.023), tot_loss_proj:1.900 [t=0.30s]
prediction: ['[CLS], wise wizened [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.406 (perp=6.600, rec=0.063, cos=0.023), tot_loss_proj:1.407 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.401 (perp=6.600, rec=0.058, cos=0.023), tot_loss_proj:1.405 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 450/2000] tot_loss=1.403 (perp=6.600, rec=0.060, cos=0.023), tot_loss_proj:1.410 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.399 (perp=6.600, rec=0.056, cos=0.023), tot_loss_proj:1.406 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.402 (perp=6.600, rec=0.059, cos=0.023), tot_loss_proj:1.399 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 600/2000] tot_loss=1.409 (perp=6.600, rec=0.066, cos=0.023), tot_loss_proj:1.413 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.403 (perp=6.600, rec=0.060, cos=0.023), tot_loss_proj:1.412 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.398 (perp=6.600, rec=0.055, cos=0.023), tot_loss_proj:1.408 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 750/2000] tot_loss=1.400 (perp=6.600, rec=0.057, cos=0.023), tot_loss_proj:1.412 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.408 (perp=6.600, rec=0.065, cos=0.023), tot_loss_proj:1.405 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.404 (perp=6.600, rec=0.062, cos=0.023), tot_loss_proj:1.402 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 900/2000] tot_loss=1.411 (perp=6.600, rec=0.068, cos=0.023), tot_loss_proj:1.399 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.411 (perp=6.600, rec=0.068, cos=0.023), tot_loss_proj:1.404 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1000/2000] tot_loss=1.400 (perp=6.600, rec=0.057, cos=0.023), tot_loss_proj:1.405 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1050/2000] tot_loss=1.394 (perp=6.600, rec=0.051, cos=0.023), tot_loss_proj:1.411 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1100/2000] tot_loss=1.407 (perp=6.600, rec=0.064, cos=0.023), tot_loss_proj:1.414 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1150/2000] tot_loss=1.399 (perp=6.600, rec=0.056, cos=0.023), tot_loss_proj:1.409 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1200/2000] tot_loss=1.410 (perp=6.600, rec=0.067, cos=0.023), tot_loss_proj:1.410 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1250/2000] tot_loss=1.395 (perp=6.600, rec=0.052, cos=0.023), tot_loss_proj:1.412 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1300/2000] tot_loss=1.392 (perp=6.600, rec=0.049, cos=0.023), tot_loss_proj:1.411 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1350/2000] tot_loss=1.396 (perp=6.600, rec=0.054, cos=0.023), tot_loss_proj:1.416 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1400/2000] tot_loss=1.395 (perp=6.600, rec=0.053, cos=0.023), tot_loss_proj:1.400 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1450/2000] tot_loss=1.398 (perp=6.600, rec=0.055, cos=0.023), tot_loss_proj:1.400 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1500/2000] tot_loss=1.403 (perp=6.600, rec=0.060, cos=0.023), tot_loss_proj:1.403 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1550/2000] tot_loss=1.394 (perp=6.600, rec=0.051, cos=0.023), tot_loss_proj:1.420 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1600/2000] tot_loss=1.401 (perp=6.600, rec=0.058, cos=0.023), tot_loss_proj:1.413 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1650/2000] tot_loss=1.402 (perp=6.600, rec=0.059, cos=0.023), tot_loss_proj:1.417 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1700/2000] tot_loss=1.402 (perp=6.600, rec=0.059, cos=0.023), tot_loss_proj:1.402 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1750/2000] tot_loss=1.402 (perp=6.600, rec=0.059, cos=0.023), tot_loss_proj:1.404 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1800/2000] tot_loss=1.395 (perp=6.600, rec=0.052, cos=0.023), tot_loss_proj:1.395 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1850/2000] tot_loss=1.404 (perp=6.600, rec=0.061, cos=0.023), tot_loss_proj:1.409 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1900/2000] tot_loss=1.395 (perp=6.600, rec=0.052, cos=0.023), tot_loss_proj:1.410 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
[1950/2000] tot_loss=1.399 (perp=6.600, rec=0.057, cos=0.023), tot_loss_proj:1.403 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[2000/2000] tot_loss=1.414 (perp=6.600, rec=0.071, cos=0.023), tot_loss_proj:1.404 [t=0.30s]
prediction: ['[CLS] wise, wizened [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise, wizened [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.912 | p: 89.518 | r: 90.385
rouge2     | fm: 60.186 | p: 60.069 | r: 60.348
rougeL     | fm: 78.867 | p: 78.561 | r: 79.240
rougeLsum  | fm: 78.924 | p: 78.625 | r: 79.304
r1fm+r2fm = 150.098

input #80 time: 0:11:53 | total time: 16:55:44


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9853834467672923
highest_index [0]
highest [0.9853834467672923]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9624674916267395 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.9365984797477722 for ['[CLS] hobbs : kahn closer invest rico [SEP]']
[Init] best rec loss: 0.8852389454841614 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8424901366233826 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8057949542999268 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.79749995470047 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 0.7791830897331238 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best perm rec loss: 0.7776429057121277 for ['[CLS] threads approval modelled bandsitating missing [SEP]']
[Init] best perm rec loss: 0.7770277261734009 for ['[CLS] missing bands modelleditating threads approval [SEP]']
[Init] best perm rec loss: 0.7760487794876099 for ['[CLS] threads missing approval bandsitating modelled [SEP]']
[Init] best perm rec loss: 0.7746255397796631 for ['[CLS] bands approval modelled threadsitating missing [SEP]']
[Init] best perm rec loss: 0.7728599309921265 for ['[CLS] missing modelled approval threadsitating bands [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.815 (perp=7.811, rec=0.197, cos=0.055), tot_loss_proj:2.074 [t=0.30s]
prediction: ['[CLS] not the most impressive fans player [SEP]']
[ 100/2000] tot_loss=1.803 (perp=8.197, rec=0.121, cos=0.042), tot_loss_proj:2.203 [t=0.30s]
prediction: ['[CLS] not the most impressive¥ player [SEP]']
[ 150/2000] tot_loss=1.517 (perp=6.915, rec=0.105, cos=0.029), tot_loss_proj:1.787 [t=0.39s]
prediction: ['[CLS] not the most impressive player player [SEP]']
[ 200/2000] tot_loss=1.630 (perp=7.551, rec=0.092, cos=0.028), tot_loss_proj:2.044 [t=0.30s]
prediction: ['[CLS] not the most impressive is player [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.286 (perp=5.977, rec=0.062, cos=0.029), tot_loss_proj:1.343 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 300/2000] tot_loss=1.289 (perp=5.977, rec=0.064, cos=0.029), tot_loss_proj:1.334 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.286 (perp=5.977, rec=0.062, cos=0.029), tot_loss_proj:1.333 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.291 (perp=5.977, rec=0.066, cos=0.029), tot_loss_proj:1.338 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 450/2000] tot_loss=1.279 (perp=5.977, rec=0.055, cos=0.029), tot_loss_proj:1.343 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.287 (perp=5.977, rec=0.063, cos=0.029), tot_loss_proj:1.334 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.297 (perp=5.977, rec=0.073, cos=0.029), tot_loss_proj:1.344 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 600/2000] tot_loss=1.291 (perp=5.977, rec=0.066, cos=0.029), tot_loss_proj:1.339 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.288 (perp=5.977, rec=0.064, cos=0.029), tot_loss_proj:1.341 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.288 (perp=5.977, rec=0.064, cos=0.029), tot_loss_proj:1.338 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 750/2000] tot_loss=1.284 (perp=5.977, rec=0.060, cos=0.029), tot_loss_proj:1.335 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.287 (perp=5.977, rec=0.063, cos=0.029), tot_loss_proj:1.334 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.274 (perp=5.977, rec=0.050, cos=0.029), tot_loss_proj:1.344 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 900/2000] tot_loss=1.282 (perp=5.977, rec=0.058, cos=0.029), tot_loss_proj:1.329 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.283 (perp=5.977, rec=0.058, cos=0.029), tot_loss_proj:1.340 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.299 (perp=5.977, rec=0.075, cos=0.029), tot_loss_proj:1.344 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1050/2000] tot_loss=1.274 (perp=5.977, rec=0.050, cos=0.029), tot_loss_proj:1.342 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.288 (perp=5.977, rec=0.064, cos=0.029), tot_loss_proj:1.341 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.285 (perp=5.977, rec=0.061, cos=0.029), tot_loss_proj:1.330 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1200/2000] tot_loss=1.293 (perp=5.977, rec=0.069, cos=0.029), tot_loss_proj:1.332 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.291 (perp=5.977, rec=0.067, cos=0.029), tot_loss_proj:1.338 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.281 (perp=5.977, rec=0.057, cos=0.029), tot_loss_proj:1.345 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1350/2000] tot_loss=1.288 (perp=5.977, rec=0.064, cos=0.029), tot_loss_proj:1.337 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.288 (perp=5.977, rec=0.063, cos=0.029), tot_loss_proj:1.333 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.283 (perp=5.977, rec=0.058, cos=0.029), tot_loss_proj:1.328 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1500/2000] tot_loss=1.284 (perp=5.977, rec=0.059, cos=0.029), tot_loss_proj:1.340 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.289 (perp=5.977, rec=0.064, cos=0.029), tot_loss_proj:1.332 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.280 (perp=5.977, rec=0.055, cos=0.029), tot_loss_proj:1.342 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1650/2000] tot_loss=1.284 (perp=5.977, rec=0.059, cos=0.029), tot_loss_proj:1.345 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.281 (perp=5.977, rec=0.057, cos=0.029), tot_loss_proj:1.330 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.287 (perp=5.977, rec=0.063, cos=0.029), tot_loss_proj:1.347 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1800/2000] tot_loss=1.281 (perp=5.977, rec=0.056, cos=0.029), tot_loss_proj:1.339 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.286 (perp=5.977, rec=0.061, cos=0.029), tot_loss_proj:1.353 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.279 (perp=5.977, rec=0.055, cos=0.029), tot_loss_proj:1.340 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1950/2000] tot_loss=1.284 (perp=5.977, rec=0.060, cos=0.029), tot_loss_proj:1.337 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.289 (perp=5.977, rec=0.064, cos=0.029), tot_loss_proj:1.347 [t=0.30s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not the most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.007 | p: 89.610 | r: 90.463
rouge2     | fm: 60.405 | p: 60.282 | r: 60.579
rougeL     | fm: 79.164 | p: 78.960 | r: 79.505
rougeLsum  | fm: 79.127 | p: 78.864 | r: 79.495
r1fm+r2fm = 150.412

input #81 time: 0:11:53 | total time: 17:07:37


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.9842353384867928
highest_index [0]
highest [0.9842353384867928]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9587550163269043 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9533929824829102 for ['[CLS] beck will parent stu rocks criteria roycenia [SEP]']
[Init] best rec loss: 0.9508282542228699 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.9494113922119141 for ['[CLS] seminetive facing toward victor trance grown [SEP]']
[Init] best rec loss: 0.9421171545982361 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9340474605560303 for ['[CLS] firmly wilder after weighted ninection latter i [SEP]']
[Init] best rec loss: 0.912545382976532 for ['[CLS] seaside ray moved throat traitor mistake ports homage [SEP]']
[Init] best rec loss: 0.8965659737586975 for ['[CLS] letter babyturnesian eric a distribution soft [SEP]']
[Init] best perm rec loss: 0.8954892754554749 for ['[CLS] soft ericturn distribution letter aesian baby [SEP]']
[Init] best perm rec loss: 0.8949047923088074 for ['[CLS] letterturn ericesian soft distribution a baby [SEP]']
[Init] best perm rec loss: 0.8947024345397949 for ['[CLS]turn baby distribution soft ericesian a letter [SEP]']
[Init] best perm rec loss: 0.8925849199295044 for ['[CLS]turn letter eric distributionesian soft baby a [SEP]']
[Init] best perm rec loss: 0.8915515542030334 for ['[CLS] soft aesian distribution letterturn eric baby [SEP]']
[Init] best perm rec loss: 0.891385555267334 for ['[CLS]esian soft a letter distribution eric babyturn [SEP]']
[Init] best perm rec loss: 0.89102703332901 for ['[CLS] letter baby aturnesian distribution soft eric [SEP]']
[Init] best perm rec loss: 0.8910024166107178 for ['[CLS] distribution softturn babyesian letter a eric [SEP]']
[Init] best perm rec loss: 0.8909855484962463 for ['[CLS] distributionesian eric a baby letterturn soft [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.331 (perp=10.327, rec=0.234, cos=0.032), tot_loss_proj:3.249 [t=0.30s]
prediction: ['[CLS] clip it did script undone script script undone [SEP]']
[ 100/2000] tot_loss=2.473 (perp=11.625, rec=0.115, cos=0.033), tot_loss_proj:3.056 [t=0.30s]
prediction: ['[CLS] a it by sloppy undone script script undone [SEP]']
[ 150/2000] tot_loss=2.441 (perp=11.625, rec=0.084, cos=0.031), tot_loss_proj:3.059 [t=0.30s]
prediction: ['[CLS] a it by sloppy undone script script undone [SEP]']
[ 200/2000] tot_loss=2.429 (perp=11.625, rec=0.073, cos=0.031), tot_loss_proj:3.046 [t=0.30s]
prediction: ['[CLS] a it by sloppy undone script script undone [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.925 (perp=9.024, rec=0.089, cos=0.032), tot_loss_proj:2.354 [t=0.30s]
prediction: ['[CLS] a s undone by sloppy script script undone [SEP]']
[ 300/2000] tot_loss=1.921 (perp=9.024, rec=0.086, cos=0.031), tot_loss_proj:2.355 [t=0.30s]
prediction: ['[CLS] a s undone by sloppy script script undone [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.782 (perp=8.400, rec=0.071, cos=0.031), tot_loss_proj:2.101 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script script undone [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.671 (perp=7.872, rec=0.066, cos=0.031), tot_loss_proj:2.102 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[ 450/2000] tot_loss=1.670 (perp=7.872, rec=0.065, cos=0.031), tot_loss_proj:2.107 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.675 (perp=7.872, rec=0.069, cos=0.031), tot_loss_proj:2.108 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.666 (perp=7.872, rec=0.060, cos=0.031), tot_loss_proj:2.120 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[ 600/2000] tot_loss=1.679 (perp=7.872, rec=0.073, cos=0.031), tot_loss_proj:2.110 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.666 (perp=7.872, rec=0.061, cos=0.031), tot_loss_proj:2.108 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.676 (perp=7.872, rec=0.070, cos=0.031), tot_loss_proj:2.110 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[ 750/2000] tot_loss=1.671 (perp=7.872, rec=0.065, cos=0.031), tot_loss_proj:2.113 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.660 (perp=7.872, rec=0.054, cos=0.031), tot_loss_proj:2.121 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.677 (perp=7.872, rec=0.072, cos=0.031), tot_loss_proj:2.126 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[ 900/2000] tot_loss=1.681 (perp=7.872, rec=0.076, cos=0.031), tot_loss_proj:2.122 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.681 (perp=7.872, rec=0.076, cos=0.031), tot_loss_proj:2.119 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1000/2000] tot_loss=1.670 (perp=7.872, rec=0.064, cos=0.031), tot_loss_proj:2.120 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1050/2000] tot_loss=1.671 (perp=7.872, rec=0.066, cos=0.031), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1100/2000] tot_loss=1.667 (perp=7.872, rec=0.061, cos=0.031), tot_loss_proj:2.121 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1150/2000] tot_loss=1.677 (perp=7.872, rec=0.072, cos=0.031), tot_loss_proj:2.131 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1200/2000] tot_loss=1.672 (perp=7.872, rec=0.067, cos=0.031), tot_loss_proj:2.123 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1250/2000] tot_loss=1.676 (perp=7.872, rec=0.071, cos=0.031), tot_loss_proj:2.131 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1300/2000] tot_loss=1.675 (perp=7.872, rec=0.070, cos=0.031), tot_loss_proj:2.124 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1350/2000] tot_loss=1.663 (perp=7.872, rec=0.057, cos=0.031), tot_loss_proj:2.131 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1400/2000] tot_loss=1.674 (perp=7.872, rec=0.069, cos=0.031), tot_loss_proj:2.138 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1450/2000] tot_loss=1.675 (perp=7.872, rec=0.069, cos=0.031), tot_loss_proj:2.132 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1500/2000] tot_loss=1.681 (perp=7.872, rec=0.076, cos=0.031), tot_loss_proj:2.140 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1550/2000] tot_loss=1.664 (perp=7.872, rec=0.058, cos=0.031), tot_loss_proj:2.129 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1600/2000] tot_loss=1.675 (perp=7.872, rec=0.069, cos=0.031), tot_loss_proj:2.131 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1650/2000] tot_loss=1.666 (perp=7.872, rec=0.060, cos=0.031), tot_loss_proj:2.133 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1700/2000] tot_loss=1.671 (perp=7.872, rec=0.065, cos=0.031), tot_loss_proj:2.129 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1750/2000] tot_loss=1.678 (perp=7.872, rec=0.073, cos=0.031), tot_loss_proj:2.123 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1800/2000] tot_loss=1.660 (perp=7.872, rec=0.055, cos=0.031), tot_loss_proj:2.138 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1850/2000] tot_loss=1.658 (perp=7.872, rec=0.052, cos=0.031), tot_loss_proj:2.131 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1900/2000] tot_loss=1.668 (perp=7.872, rec=0.062, cos=0.031), tot_loss_proj:2.137 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1950/2000] tot_loss=1.670 (perp=7.872, rec=0.064, cos=0.031), tot_loss_proj:2.131 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[2000/2000] tot_loss=1.670 (perp=7.872, rec=0.064, cos=0.031), tot_loss_proj:2.128 [t=0.30s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] s undone by a sloppy script undone it [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 90.017 | p: 89.635 | r: 90.586
rouge2     | fm: 60.502 | p: 60.399 | r: 60.775
rougeL     | fm: 79.166 | p: 78.880 | r: 79.665
rougeLsum  | fm: 79.205 | p: 78.896 | r: 79.658
r1fm+r2fm = 150.519

input #82 time: 0:11:55 | total time: 17:19:33


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9875993099085634
highest_index [0]
highest [0.9875993099085634]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.8408287763595581 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.8205984234809875 for ['[CLS] floodax aboriginal mali wisconsin na rain basket missed call [SEP]']
[Init] best rec loss: 0.7922196984291077 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.7865552306175232 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.7848020792007446 for ['[CLS] envelope residence neck stew vice nearly follows comprehensive pitch boys [SEP]']
[Init] best perm rec loss: 0.7847984433174133 for ['[CLS] boys vice pitch envelope comprehensive stew nearly follows neck residence [SEP]']
[Init] best perm rec loss: 0.7826802730560303 for ['[CLS] pitch vice nearly residence comprehensive follows stew neck envelope boys [SEP]']
[Init] best perm rec loss: 0.7796247005462646 for ['[CLS] vice envelope pitch follows comprehensive neck boys stew residence nearly [SEP]']
[Init] best perm rec loss: 0.7786988019943237 for ['[CLS] pitch comprehensive follows neck vice stew residence boys nearly envelope [SEP]']
[Init] best perm rec loss: 0.7781369090080261 for ['[CLS] nearly comprehensive stew vice neck follows pitch boys residence envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.551 (perp=11.109, rec=0.298, cos=0.032), tot_loss_proj:3.507 [t=0.30s]
prediction: ['[CLS] grows because wants believe know follows what when eventually grows [SEP]']
[ 100/2000] tot_loss=2.011 (perp=9.227, rec=0.140, cos=0.026), tot_loss_proj:3.080 [t=0.30s]
prediction: ['[CLS] it what wants want know grows what when it grows [SEP]']
[ 150/2000] tot_loss=2.126 (perp=10.031, rec=0.095, cos=0.025), tot_loss_proj:2.924 [t=0.30s]
prediction: ['[CLS] it what wants be know be what when up grows [SEP]']
[ 200/2000] tot_loss=2.116 (perp=10.031, rec=0.086, cos=0.024), tot_loss_proj:2.929 [t=0.30s]
prediction: ['[CLS] it what wants be know be what when up grows [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.795 (perp=8.423, rec=0.086, cos=0.024), tot_loss_proj:2.453 [t=0.30s]
prediction: ['[CLS] it what wants be know to what when grows up [SEP]']
[ 300/2000] tot_loss=1.785 (perp=8.423, rec=0.076, cos=0.025), tot_loss_proj:2.461 [t=0.30s]
prediction: ['[CLS] it what wants be know to what when grows up [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.560 (perp=7.295, rec=0.076, cos=0.025), tot_loss_proj:2.122 [t=0.30s]
prediction: ['[CLS] it what wants be to know what when grows up [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.340 (perp=6.203, rec=0.075, cos=0.025), tot_loss_proj:1.848 [t=0.30s]
prediction: ['[CLS] what it wants be to know what when grows up [SEP]']
[ 450/2000] tot_loss=1.340 (perp=6.203, rec=0.075, cos=0.025), tot_loss_proj:1.846 [t=0.30s]
prediction: ['[CLS] what it wants be to know what when grows up [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.298 (perp=6.005, rec=0.073, cos=0.025), tot_loss_proj:1.770 [t=0.30s]
prediction: ['[CLS] be what it wants to know what when grows up [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.222 (perp=5.618, rec=0.074, cos=0.024), tot_loss_proj:1.670 [t=0.30s]
prediction: ['[CLS] be what it wants to know when what grows up [SEP]']
[ 600/2000] tot_loss=1.228 (perp=5.618, rec=0.080, cos=0.025), tot_loss_proj:1.670 [t=0.30s]
prediction: ['[CLS] be what it wants to know when what grows up [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.430 (perp=6.652, rec=0.075, cos=0.025), tot_loss_proj:1.715 [t=0.30s]
prediction: ['[CLS] know the it wants to be when what grows up [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.294 (perp=5.872, rec=0.094, cos=0.026), tot_loss_proj:1.522 [t=0.30s]
prediction: ['[CLS] know what the it wants to be when grows up [SEP]']
[ 750/2000] tot_loss=1.270 (perp=5.872, rec=0.071, cos=0.025), tot_loss_proj:1.510 [t=0.30s]
prediction: ['[CLS] know what the it wants to be when grows up [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.172 (perp=5.435, rec=0.061, cos=0.025), tot_loss_proj:1.331 [t=0.30s]
prediction: ['[CLS] know what it wants to be when the grows up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.181 (perp=5.435, rec=0.069, cos=0.025), tot_loss_proj:1.328 [t=0.30s]
prediction: ['[CLS] know what it wants to be when the grows up [SEP]']
[ 900/2000] tot_loss=1.180 (perp=5.435, rec=0.068, cos=0.025), tot_loss_proj:1.336 [t=0.30s]
prediction: ['[CLS] know what it wants to be when the grows up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.179 (perp=5.435, rec=0.067, cos=0.025), tot_loss_proj:1.336 [t=0.30s]
prediction: ['[CLS] know what it wants to be when the grows up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.178 (perp=5.435, rec=0.067, cos=0.025), tot_loss_proj:1.336 [t=0.30s]
prediction: ['[CLS] know what it wants to be when the grows up [SEP]']
[1050/2000] tot_loss=1.178 (perp=5.435, rec=0.066, cos=0.025), tot_loss_proj:1.340 [t=0.30s]
prediction: ['[CLS] know what it wants to be when the grows up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.022 (perp=4.691, rec=0.060, cos=0.025), tot_loss_proj:1.111 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.027 (perp=4.691, rec=0.064, cos=0.025), tot_loss_proj:1.114 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1200/2000] tot_loss=1.026 (perp=4.691, rec=0.063, cos=0.025), tot_loss_proj:1.113 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.033 (perp=4.691, rec=0.070, cos=0.025), tot_loss_proj:1.104 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.023 (perp=4.691, rec=0.060, cos=0.025), tot_loss_proj:1.108 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1350/2000] tot_loss=1.029 (perp=4.691, rec=0.067, cos=0.025), tot_loss_proj:1.110 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.028 (perp=4.691, rec=0.066, cos=0.025), tot_loss_proj:1.112 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.032 (perp=4.691, rec=0.069, cos=0.025), tot_loss_proj:1.102 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1500/2000] tot_loss=1.032 (perp=4.691, rec=0.069, cos=0.025), tot_loss_proj:1.093 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.037 (perp=4.691, rec=0.074, cos=0.025), tot_loss_proj:1.099 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.035 (perp=4.691, rec=0.072, cos=0.025), tot_loss_proj:1.101 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1650/2000] tot_loss=1.032 (perp=4.691, rec=0.069, cos=0.025), tot_loss_proj:1.113 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.024 (perp=4.691, rec=0.061, cos=0.025), tot_loss_proj:1.112 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.028 (perp=4.691, rec=0.065, cos=0.025), tot_loss_proj:1.099 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1800/2000] tot_loss=1.021 (perp=4.691, rec=0.058, cos=0.025), tot_loss_proj:1.096 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.022 (perp=4.691, rec=0.059, cos=0.025), tot_loss_proj:1.112 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.041 (perp=4.691, rec=0.078, cos=0.025), tot_loss_proj:1.104 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1950/2000] tot_loss=1.032 (perp=4.691, rec=0.069, cos=0.025), tot_loss_proj:1.111 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.017 (perp=4.691, rec=0.054, cos=0.025), tot_loss_proj:1.103 [t=0.30s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.225 | p: 89.802 | r: 90.759
rouge2     | fm: 60.696 | p: 60.534 | r: 60.923
rougeL     | fm: 79.422 | p: 79.128 | r: 79.922
rougeLsum  | fm: 79.381 | p: 79.082 | r: 79.870
r1fm+r2fm = 150.921

input #83 time: 0:11:55 | total time: 17:31:29


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.98720067778799
highest_index [0]
highest [0.98720067778799]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.8968020677566528 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.8754839301109314 for ['[CLS] primera criminalmost dynamic ride venue youtube [SEP]']
[Init] best rec loss: 0.8637248277664185 for ['[CLS] beauty seemed features dr son baked hm [SEP]']
[Init] best rec loss: 0.8615774512290955 for ['[CLS] waterfalls answer ramsay proved broad losing amenities [SEP]']
[Init] best rec loss: 0.8499298691749573 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8358266353607178 for ['[CLS] appearance later orderedlby outstanding battery gentle [SEP]']
[Init] best rec loss: 0.8324203491210938 for ['[CLS] competed shegl brick kill trade down [SEP]']
[Init] best rec loss: 0.823485255241394 for ['[CLS] individual hung cold ¹...ught railroad [SEP]']
[Init] best rec loss: 0.8228083848953247 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 0.8176693320274353 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best rec loss: 0.8159498572349548 for ['[CLS] mentallyhoreye running bland johnston last [SEP]']
[Init] best rec loss: 0.8038075566291809 for ['[CLS] hometails para hundreds sexy couple chinese [SEP]']
[Init] best perm rec loss: 0.8009757995605469 for ['[CLS] para couple hundreds chinese sexytails home [SEP]']
[Init] best perm rec loss: 0.7996564507484436 for ['[CLS] hundreds para home sexy chinese coupletails [SEP]']
[Init] best perm rec loss: 0.797847330570221 for ['[CLS] chinese para couple hundreds sexytails home [SEP]']
[Init] best perm rec loss: 0.7971621751785278 for ['[CLS] para sexy chinese hundredstails couple home [SEP]']
[Init] best perm rec loss: 0.796515941619873 for ['[CLS] hundreds chinese sexy hometails couple para [SEP]']
[Init] best perm rec loss: 0.7963687181472778 for ['[CLS] chinese hundreds para coupletails sexy home [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.014 (perp=8.865, rec=0.210, cos=0.031), tot_loss_proj:2.309 [t=0.30s]
prediction: ['[CLS] people have lost they ability ability lost [SEP]']
[ 100/2000] tot_loss=1.619 (perp=7.545, rec=0.083, cos=0.027), tot_loss_proj:2.022 [t=0.30s]
prediction: ['[CLS] people have lost the ability think lost [SEP]']
[ 150/2000] tot_loss=1.602 (perp=7.545, rec=0.068, cos=0.026), tot_loss_proj:2.009 [t=0.30s]
prediction: ['[CLS] people have lost the ability think lost [SEP]']
[ 200/2000] tot_loss=1.608 (perp=7.545, rec=0.074, cos=0.025), tot_loss_proj:2.023 [t=0.30s]
prediction: ['[CLS] people have lost the ability think lost [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.607 (perp=7.545, rec=0.072, cos=0.026), tot_loss_proj:2.015 [t=0.30s]
prediction: ['[CLS] people have lost the ability think lost [SEP]']
[ 300/2000] tot_loss=1.400 (perp=6.568, rec=0.061, cos=0.025), tot_loss_proj:1.523 [t=0.30s]
prediction: ['[CLS] people have lost the ability think to [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.025 (perp=4.681, rec=0.064, cos=0.025), tot_loss_proj:1.057 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.027 (perp=4.681, rec=0.065, cos=0.025), tot_loss_proj:1.068 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 450/2000] tot_loss=1.010 (perp=4.681, rec=0.048, cos=0.025), tot_loss_proj:1.067 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.011 (perp=4.681, rec=0.049, cos=0.025), tot_loss_proj:1.062 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.021 (perp=4.681, rec=0.059, cos=0.025), tot_loss_proj:1.068 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 600/2000] tot_loss=1.029 (perp=4.681, rec=0.067, cos=0.025), tot_loss_proj:1.054 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.027 (perp=4.681, rec=0.065, cos=0.025), tot_loss_proj:1.048 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.027 (perp=4.681, rec=0.065, cos=0.025), tot_loss_proj:1.056 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 750/2000] tot_loss=1.029 (perp=4.681, rec=0.067, cos=0.025), tot_loss_proj:1.058 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.019 (perp=4.681, rec=0.057, cos=0.025), tot_loss_proj:1.045 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.019 (perp=4.681, rec=0.057, cos=0.025), tot_loss_proj:1.056 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 900/2000] tot_loss=1.019 (perp=4.681, rec=0.057, cos=0.025), tot_loss_proj:1.061 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.024 (perp=4.681, rec=0.062, cos=0.025), tot_loss_proj:1.055 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.015 (perp=4.681, rec=0.054, cos=0.025), tot_loss_proj:1.046 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1050/2000] tot_loss=1.034 (perp=4.681, rec=0.072, cos=0.025), tot_loss_proj:1.057 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.016 (perp=4.681, rec=0.054, cos=0.025), tot_loss_proj:1.062 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1150/2000] tot_loss=1.014 (perp=4.681, rec=0.053, cos=0.025), tot_loss_proj:1.047 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1200/2000] tot_loss=1.012 (perp=4.681, rec=0.050, cos=0.025), tot_loss_proj:1.056 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.022 (perp=4.681, rec=0.061, cos=0.025), tot_loss_proj:1.056 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.019 (perp=4.681, rec=0.057, cos=0.025), tot_loss_proj:1.047 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=1.026 (perp=4.681, rec=0.064, cos=0.025), tot_loss_proj:1.051 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=1.029 (perp=4.681, rec=0.067, cos=0.025), tot_loss_proj:1.059 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.023 (perp=4.681, rec=0.061, cos=0.025), tot_loss_proj:1.057 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=1.022 (perp=4.681, rec=0.060, cos=0.025), tot_loss_proj:1.048 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=1.011 (perp=4.681, rec=0.049, cos=0.025), tot_loss_proj:1.056 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=1.014 (perp=4.681, rec=0.053, cos=0.025), tot_loss_proj:1.057 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=1.021 (perp=4.681, rec=0.059, cos=0.025), tot_loss_proj:1.055 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.029 (perp=4.681, rec=0.068, cos=0.025), tot_loss_proj:1.065 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=1.022 (perp=4.681, rec=0.061, cos=0.025), tot_loss_proj:1.053 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=1.022 (perp=4.681, rec=0.060, cos=0.025), tot_loss_proj:1.057 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.019 (perp=4.681, rec=0.058, cos=0.025), tot_loss_proj:1.055 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.021 (perp=4.681, rec=0.059, cos=0.025), tot_loss_proj:1.055 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=1.030 (perp=4.681, rec=0.068, cos=0.025), tot_loss_proj:1.055 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.023 (perp=4.681, rec=0.061, cos=0.025), tot_loss_proj:1.044 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.349 | p: 89.953 | r: 90.839
rouge2     | fm: 61.486 | p: 61.348 | r: 61.679
rougeL     | fm: 79.804 | p: 79.449 | r: 80.176
rougeLsum  | fm: 79.697 | p: 79.342 | r: 80.174
r1fm+r2fm = 151.835

input #84 time: 0:11:56 | total time: 17:43:25


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9836183159289044
highest_index [0]
highest [0.9836183159289044]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.8841149210929871 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.8812892436981201 for ['[CLS] mt running waiting worried roverstakesley rating rag age [SEP]']
[Init] best rec loss: 0.8558609485626221 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8506917953491211 for ['[CLS] young graf challenging haven nord overly graduation blank dad josephine [SEP]']
[Init] best rec loss: 0.8489310145378113 for ['[CLS] inside feminist brought vision swing artificial agent fai manipulatedsome [SEP]']
[Init] best rec loss: 0.8432584404945374 for ['[CLS] reflection whateverus translation rent certain belt loft rca muted [SEP]']
[Init] best perm rec loss: 0.8427841663360596 for ['[CLS] whateverus translation belt muted reflection loft certain rca rent [SEP]']
[Init] best perm rec loss: 0.8419130444526672 for ['[CLS] rca reflection rentus belt translation loft whatever certain muted [SEP]']
[Init] best perm rec loss: 0.8392356038093567 for ['[CLS] translation rca rent certain reflection loft belt whateverus muted [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.766 (perp=7.594, rec=0.206, cos=0.041), tot_loss_proj:3.426 [t=0.30s]
prediction: ['[CLS] unfortunately, not good apparently not really only. good [SEP]']
[ 100/2000] tot_loss=1.625 (perp=6.920, rec=0.206, cos=0.035), tot_loss_proj:3.231 [t=0.30s]
prediction: ['[CLS] unfortunately it very good because not also more as good [SEP]']
[ 150/2000] tot_loss=1.570 (perp=6.961, rec=0.145, cos=0.033), tot_loss_proj:3.265 [t=0.30s]
prediction: ['[CLS] unfortunately it very good ( not also. as good [SEP]']
[ 200/2000] tot_loss=1.553 (perp=6.961, rec=0.129, cos=0.032), tot_loss_proj:3.256 [t=0.30s]
prediction: ['[CLS] unfortunately it very good ( not also. as good [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.488 (perp=6.542, rec=0.142, cos=0.038), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] unfortunately it s very, not also good as. [SEP]']
[ 300/2000] tot_loss=1.441 (perp=6.542, rec=0.100, cos=0.033), tot_loss_proj:2.124 [t=0.30s]
prediction: ['[CLS] unfortunately it s very, not also good as. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.257 (perp=5.714, rec=0.082, cos=0.033), tot_loss_proj:1.510 [t=0.30s]
prediction: ['[CLS] unfortunately it s also, not very good as. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.121 (perp=4.972, rec=0.094, cos=0.033), tot_loss_proj:1.211 [t=0.30s]
prediction: ['[CLS] unfortunately, it s also not very good as. [SEP]']
[ 450/2000] tot_loss=1.097 (perp=4.972, rec=0.070, cos=0.033), tot_loss_proj:1.217 [t=0.30s]
prediction: ['[CLS] unfortunately, it s also not very good as. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.048 (perp=4.716, rec=0.073, cos=0.033), tot_loss_proj:1.187 [t=0.30s]
prediction: ['[CLS] unfortunately, it also s not very good as. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.024 (perp=4.508, rec=0.089, cos=0.033), tot_loss_proj:1.119 [t=0.30s]
prediction: ['[CLS] unfortunately, it also s not very as good. [SEP]']
[ 600/2000] tot_loss=1.009 (perp=4.508, rec=0.075, cos=0.033), tot_loss_proj:1.131 [t=0.30s]
prediction: ['[CLS] unfortunately, it also s not very as good. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.009 (perp=4.508, rec=0.074, cos=0.033), tot_loss_proj:1.118 [t=0.30s]
prediction: ['[CLS] unfortunately, it also s not very as good. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.014 (perp=4.508, rec=0.080, cos=0.032), tot_loss_proj:1.121 [t=0.30s]
prediction: ['[CLS] unfortunately, it also s not very as good. [SEP]']
[ 750/2000] tot_loss=1.018 (perp=4.508, rec=0.084, cos=0.032), tot_loss_proj:1.132 [t=0.30s]
prediction: ['[CLS] unfortunately, it also s not very as good. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.019 (perp=4.591, rec=0.068, cos=0.032), tot_loss_proj:1.168 [t=0.30s]
prediction: ['[CLS] unfortunately, it also s not as very good. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.001 (perp=4.436, rec=0.081, cos=0.032), tot_loss_proj:1.144 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
[ 900/2000] tot_loss=1.004 (perp=4.436, rec=0.084, cos=0.032), tot_loss_proj:1.142 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.999 (perp=4.436, rec=0.079, cos=0.032), tot_loss_proj:1.139 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.984 (perp=4.436, rec=0.064, cos=0.032), tot_loss_proj:1.144 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
[1050/2000] tot_loss=0.987 (perp=4.436, rec=0.067, cos=0.032), tot_loss_proj:1.143 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.989 (perp=4.436, rec=0.069, cos=0.032), tot_loss_proj:1.150 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.978 (perp=4.436, rec=0.058, cos=0.033), tot_loss_proj:1.151 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
[1200/2000] tot_loss=0.977 (perp=4.436, rec=0.057, cos=0.032), tot_loss_proj:1.142 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.995 (perp=4.436, rec=0.075, cos=0.032), tot_loss_proj:1.143 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.980 (perp=4.436, rec=0.060, cos=0.032), tot_loss_proj:1.148 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
[1350/2000] tot_loss=0.987 (perp=4.436, rec=0.067, cos=0.033), tot_loss_proj:1.138 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.991 (perp=4.436, rec=0.071, cos=0.032), tot_loss_proj:1.147 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.991 (perp=4.436, rec=0.071, cos=0.032), tot_loss_proj:1.147 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
[1500/2000] tot_loss=0.987 (perp=4.436, rec=0.067, cos=0.032), tot_loss_proj:1.134 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.995 (perp=4.436, rec=0.075, cos=0.033), tot_loss_proj:1.142 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.974 (perp=4.436, rec=0.054, cos=0.032), tot_loss_proj:1.140 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
[1650/2000] tot_loss=0.989 (perp=4.436, rec=0.069, cos=0.032), tot_loss_proj:1.145 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.993 (perp=4.436, rec=0.073, cos=0.032), tot_loss_proj:1.133 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.000 (perp=4.436, rec=0.081, cos=0.032), tot_loss_proj:1.134 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
[1800/2000] tot_loss=0.999 (perp=4.436, rec=0.079, cos=0.032), tot_loss_proj:1.153 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.997 (perp=4.436, rec=0.077, cos=0.033), tot_loss_proj:1.133 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.991 (perp=4.436, rec=0.071, cos=0.033), tot_loss_proj:1.147 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
[1950/2000] tot_loss=0.992 (perp=4.436, rec=0.072, cos=0.032), tot_loss_proj:1.146 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.986 (perp=4.436, rec=0.067, cos=0.032), tot_loss_proj:1.129 [t=0.30s]
prediction: ['[CLS] unfortunately, as it also s not very good. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, as it also s not very good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 141.796

[Aggregate metrics]:
rouge1     | fm: 90.395 | p: 89.938 | r: 90.997
rouge2     | fm: 60.917 | p: 60.748 | r: 61.142
rougeL     | fm: 79.747 | p: 79.392 | r: 80.237
rougeLsum  | fm: 79.816 | p: 79.396 | r: 80.289
r1fm+r2fm = 151.312

input #85 time: 0:11:56 | total time: 17:55:21


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9880337558891354
highest_index [0]
highest [0.9880337558891354]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.926310122013092 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.8901609778404236 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 0.7987562417984009 for ['[CLS]q suicide drew [SEP]']
[Init] best perm rec loss: 0.7933376431465149 for ['[CLS] suicideq drew [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.510 (perp=11.357, rec=0.211, cos=0.027), tot_loss_proj:2.915 [t=0.30s]
prediction: ['[CLS] piano clarity lewis [SEP]']
[ 100/2000] tot_loss=2.526 (perp=11.793, rec=0.144, cos=0.023), tot_loss_proj:2.719 [t=0.30s]
prediction: ['[CLS] clarity clarity emotional [SEP]']
[ 150/2000] tot_loss=2.491 (perp=11.793, rec=0.109, cos=0.024), tot_loss_proj:2.720 [t=0.30s]
prediction: ['[CLS] clarity clarity emotional [SEP]']
[ 200/2000] tot_loss=2.030 (perp=9.574, rec=0.091, cos=0.024), tot_loss_proj:2.162 [t=0.30s]
prediction: ['[CLS] and clarity emotional [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.760 (perp=8.318, rec=0.072, cos=0.024), tot_loss_proj:1.763 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 300/2000] tot_loss=1.759 (perp=8.318, rec=0.071, cos=0.024), tot_loss_proj:1.768 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.752 (perp=8.318, rec=0.065, cos=0.024), tot_loss_proj:1.759 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.746 (perp=8.318, rec=0.059, cos=0.024), tot_loss_proj:1.758 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 450/2000] tot_loss=1.744 (perp=8.318, rec=0.057, cos=0.024), tot_loss_proj:1.764 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.745 (perp=8.318, rec=0.058, cos=0.024), tot_loss_proj:1.767 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.748 (perp=8.318, rec=0.061, cos=0.024), tot_loss_proj:1.770 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 600/2000] tot_loss=1.745 (perp=8.318, rec=0.057, cos=0.024), tot_loss_proj:1.755 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.741 (perp=8.318, rec=0.054, cos=0.024), tot_loss_proj:1.770 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.754 (perp=8.318, rec=0.066, cos=0.024), tot_loss_proj:1.768 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 750/2000] tot_loss=1.755 (perp=8.318, rec=0.068, cos=0.024), tot_loss_proj:1.765 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.734 (perp=8.318, rec=0.047, cos=0.024), tot_loss_proj:1.763 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.749 (perp=8.318, rec=0.062, cos=0.024), tot_loss_proj:1.750 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 900/2000] tot_loss=1.754 (perp=8.318, rec=0.066, cos=0.024), tot_loss_proj:1.761 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.738 (perp=8.318, rec=0.051, cos=0.024), tot_loss_proj:1.765 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1000/2000] tot_loss=1.754 (perp=8.318, rec=0.067, cos=0.024), tot_loss_proj:1.770 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1050/2000] tot_loss=1.748 (perp=8.318, rec=0.060, cos=0.024), tot_loss_proj:1.765 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1100/2000] tot_loss=1.748 (perp=8.318, rec=0.061, cos=0.024), tot_loss_proj:1.762 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1150/2000] tot_loss=1.743 (perp=8.318, rec=0.056, cos=0.024), tot_loss_proj:1.770 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1200/2000] tot_loss=1.742 (perp=8.318, rec=0.054, cos=0.024), tot_loss_proj:1.763 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1250/2000] tot_loss=1.757 (perp=8.318, rec=0.070, cos=0.024), tot_loss_proj:1.760 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1300/2000] tot_loss=1.752 (perp=8.318, rec=0.065, cos=0.024), tot_loss_proj:1.750 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1350/2000] tot_loss=1.742 (perp=8.318, rec=0.055, cos=0.024), tot_loss_proj:1.762 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1400/2000] tot_loss=1.753 (perp=8.318, rec=0.065, cos=0.024), tot_loss_proj:1.752 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1450/2000] tot_loss=1.741 (perp=8.318, rec=0.053, cos=0.024), tot_loss_proj:1.769 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1500/2000] tot_loss=1.753 (perp=8.318, rec=0.066, cos=0.024), tot_loss_proj:1.756 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1550/2000] tot_loss=1.752 (perp=8.318, rec=0.064, cos=0.024), tot_loss_proj:1.770 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1600/2000] tot_loss=1.750 (perp=8.318, rec=0.063, cos=0.024), tot_loss_proj:1.771 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1650/2000] tot_loss=1.746 (perp=8.318, rec=0.059, cos=0.024), tot_loss_proj:1.772 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1700/2000] tot_loss=1.749 (perp=8.318, rec=0.062, cos=0.024), tot_loss_proj:1.763 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1750/2000] tot_loss=1.758 (perp=8.318, rec=0.071, cos=0.024), tot_loss_proj:1.771 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1800/2000] tot_loss=1.743 (perp=8.318, rec=0.056, cos=0.024), tot_loss_proj:1.773 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1850/2000] tot_loss=1.740 (perp=8.318, rec=0.052, cos=0.024), tot_loss_proj:1.761 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1900/2000] tot_loss=1.747 (perp=8.318, rec=0.060, cos=0.024), tot_loss_proj:1.763 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1950/2000] tot_loss=1.742 (perp=8.318, rec=0.055, cos=0.024), tot_loss_proj:1.764 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[2000/2000] tot_loss=1.742 (perp=8.318, rec=0.055, cos=0.024), tot_loss_proj:1.764 [t=0.30s]
prediction: ['[CLS] clarity and emotional [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] clarity and emotional [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.411 | p: 89.941 | r: 91.064
rouge2     | fm: 61.505 | p: 61.285 | r: 61.780
rougeL     | fm: 79.944 | p: 79.610 | r: 80.418
rougeLsum  | fm: 79.944 | p: 79.564 | r: 80.426
r1fm+r2fm = 151.916

input #86 time: 0:11:52 | total time: 18:07:14


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.9880112444896041
highest_index [0]
highest [0.9880112444896041]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.7330074310302734 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7174263000488281 for ['[CLS] calendar? [SEP]']
[Init] best rec loss: 0.6653252840042114 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.6526807546615601 for ['[CLS] action [MASK] [SEP]']
[Init] best rec loss: 0.6525639891624451 for ['[CLS] popularski [SEP]']
[Init] best rec loss: 0.6398680210113525 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6344528198242188 for ['[CLS] bran eureka [SEP]']
[Init] best rec loss: 0.6295055747032166 for ['[CLS] under fan [SEP]']
[Init] best rec loss: 0.606264591217041 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6046760678291321 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.753 (perp=12.535, rec=0.213, cos=0.033), tot_loss_proj:3.296 [t=0.30s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=1.594 (perp=7.258, rec=0.112, cos=0.031), tot_loss_proj:1.544 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.530 (perp=7.258, rec=0.053, cos=0.026), tot_loss_proj:1.551 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.540 (perp=7.258, rec=0.066, cos=0.023), tot_loss_proj:1.548 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.554 (perp=7.258, rec=0.075, cos=0.028), tot_loss_proj:1.533 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.531 (perp=7.258, rec=0.057, cos=0.023), tot_loss_proj:1.543 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.534 (perp=7.258, rec=0.058, cos=0.024), tot_loss_proj:1.540 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.531 (perp=7.258, rec=0.056, cos=0.024), tot_loss_proj:1.538 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.543 (perp=7.258, rec=0.068, cos=0.024), tot_loss_proj:1.527 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.531 (perp=7.258, rec=0.056, cos=0.024), tot_loss_proj:1.547 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.532 (perp=7.258, rec=0.057, cos=0.023), tot_loss_proj:1.547 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.531 (perp=7.258, rec=0.056, cos=0.024), tot_loss_proj:1.545 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.542 (perp=7.258, rec=0.066, cos=0.024), tot_loss_proj:1.550 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.537 (perp=7.258, rec=0.062, cos=0.024), tot_loss_proj:1.539 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.544 (perp=7.258, rec=0.069, cos=0.024), tot_loss_proj:1.539 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.542 (perp=7.258, rec=0.067, cos=0.024), tot_loss_proj:1.545 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.538 (perp=7.258, rec=0.063, cos=0.024), tot_loss_proj:1.556 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.539 (perp=7.258, rec=0.064, cos=0.024), tot_loss_proj:1.548 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.541 (perp=7.258, rec=0.066, cos=0.024), tot_loss_proj:1.540 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.531 (perp=7.258, rec=0.056, cos=0.024), tot_loss_proj:1.549 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.533 (perp=7.258, rec=0.057, cos=0.024), tot_loss_proj:1.540 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.525 (perp=7.258, rec=0.050, cos=0.024), tot_loss_proj:1.533 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.538 (perp=7.258, rec=0.063, cos=0.024), tot_loss_proj:1.551 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.534 (perp=7.258, rec=0.059, cos=0.024), tot_loss_proj:1.551 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.258, rec=0.074, cos=0.024), tot_loss_proj:1.535 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.532 (perp=7.258, rec=0.057, cos=0.024), tot_loss_proj:1.539 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.533 (perp=7.258, rec=0.057, cos=0.024), tot_loss_proj:1.547 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.527 (perp=7.258, rec=0.052, cos=0.024), tot_loss_proj:1.547 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.528 (perp=7.258, rec=0.052, cos=0.024), tot_loss_proj:1.539 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.543 (perp=7.258, rec=0.068, cos=0.024), tot_loss_proj:1.538 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.543 (perp=7.258, rec=0.068, cos=0.024), tot_loss_proj:1.546 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.528 (perp=7.258, rec=0.053, cos=0.024), tot_loss_proj:1.546 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.544 (perp=7.258, rec=0.069, cos=0.024), tot_loss_proj:1.550 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.538 (perp=7.258, rec=0.062, cos=0.024), tot_loss_proj:1.543 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.532 (perp=7.258, rec=0.057, cos=0.024), tot_loss_proj:1.543 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.533 (perp=7.258, rec=0.057, cos=0.024), tot_loss_proj:1.540 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.525 (perp=7.258, rec=0.049, cos=0.024), tot_loss_proj:1.554 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.546 (perp=7.258, rec=0.070, cos=0.024), tot_loss_proj:1.529 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.544 (perp=7.258, rec=0.069, cos=0.024), tot_loss_proj:1.546 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.538 (perp=7.258, rec=0.063, cos=0.024), tot_loss_proj:1.529 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.545 | p: 90.068 | r: 91.108
rouge2     | fm: 61.954 | p: 61.754 | r: 62.177
rougeL     | fm: 80.157 | p: 79.816 | r: 80.641
rougeLsum  | fm: 80.174 | p: 79.825 | r: 80.654
r1fm+r2fm = 152.499

input #87 time: 0:11:52 | total time: 18:19:06


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.9881525011547065
highest_index [0]
highest [0.9881525011547065]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9122652411460876 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.911503255367279 for ['[CLS]ho dukevs counter licence fruitoninguded customerbasket manufacturingeon movement psyche life researchers dart foreign nadia occasion mare good maximumerty unemployment pattern though alpha flames day :rop at mechanics scratch 200 forewings boss emergency loanex decades overview [SEP]']
[Init] best rec loss: 0.9078140258789062 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.9074981212615967 for ['[CLS] early adults etienne distinctive haven flow further billion binding centre smallpox roy wore just beetles project moody clinic range raven close fitted below corp painter other himself florida others defined post wake morgan press sections archival municipality tucker tree file source currently stats [SEP]']
[Init] best rec loss: 0.9015026688575745 for ['[CLS] wink overall ranked solitary digital based multi loadratwhile howarddeck supreme future hen [MASK] valuable brandy present by wise late 2018 ancientuto am rubble⁄ studios when warned patentssr mayor office personaeving making flamelyn shannon competition back [SEP]']
[Init] best rec loss: 0.8988066911697388 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.8950389623641968 for ['[CLS] earliest established exclusive separated graduated paper come rattled personnel road clear reapers weaving owned corruption everythingoris usedl spend fate pine top mile publishing referring au languagetium large osborn turnszi respectively jaw sessions house december hamlet father hurry canada africa [SEP]']
[Init] best rec loss: 0.8912802934646606 for ['[CLS] grab q my doctor fever alter firstt frog hardiff credits railway debut part iris mandir allyged why maxishedology mild commission arch boulevard host mass distributions crown music reign power tad satellite van lined involving boating published operating voting [SEP]']
[Init] best rec loss: 0.8901234269142151 for ['[CLS] invited latham darrell right demon mm walter promoted ultimatum alleyll different business party each sneak akbar out feminist containing register planeder safeboatsinklesborn scrambled chalk 2018 joining signs miranda regular coin remixntly copyright your cattle editions lia announced [SEP]']
[Init] best perm rec loss: 0.8874844908714294 for ['[CLS] rightder remix chalk feminist darrell invitedborn editions business mm safe containing each announcedll latham sneak register walter plane out regularinklesntly demon cattle party coin signs ultimatum copyright scrambled different your 2018 alley promoted miranda joining akbarboats lia [SEP]']
[Init] best perm rec loss: 0.8863983154296875 for ['[CLS] remixboats mm plane demon akbar miranda feminist your copyright alley scrambled regular containing joining party invited darrell safe each out announced right editions chalk promoted latham signs cattle business lia coin sneakllntly 2018 register different ultimatumborninklesder walter [SEP]']
[Init] best perm rec loss: 0.8855416178703308 for ['[CLS] businessll containing right plane your 2018 chalk remix lathamderntly editionsboats copyright regular feminist promoted announced mm out scrambled sneak coin walter ultimatum darrell alley lia joining miranda invitedborn different akbar safe party demon signs each cattle registerinkles [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.335 (perp=10.185, rec=0.269, cos=0.029), tot_loss_proj:3.715 [t=0.30s]
prediction: ['[CLS] strange understands the knows social. cancelledity recording understand that unnecessary - understand pleasure right in and love ll humanity lethal primal romance absence and love never had environment joy drummer global unique love? my streets that know we medical love [SEP]']
[ 100/2000] tot_loss=2.045 (perp=9.066, rec=0.207, cos=0.025), tot_loss_proj:3.212 [t=0.31s]
prediction: ['[CLS] our understands the. great anderson romantic romance that calm romance circumstances ; understand romance could in and love xbox humanity the t romance absence and love never therating romance our our unique love us our problems that high the romantic love [SEP]']
[ 150/2000] tot_loss=2.300 (perp=10.010, rec=0.270, cos=0.028), tot_loss_proj:3.895 [t=0.31s]
prediction: ['[CLS] the understands the t grand anderson joy power and calm of [SEP]། how pleasure cannot in and grand fireplace from provides t romance emotions and love never the about romance our petty greatification we of days that m the urban love [SEP]']
[ 200/2000] tot_loss=2.155 (perp=9.510, rec=0.229, cos=0.023), tot_loss_proj:3.101 [t=0.31s]
prediction: ['[CLS] our understands of t grand anderson emotional power and calming [SEP] ि how pleasure knew joy and grand metaphor you that anderson romance problems and in father the settling romance our petty grand development of. lives that home has intense love [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.110 (perp=9.090, rec=0.265, cos=0.027), tot_loss_proj:3.359 [t=0.31s]
prediction: ['[CLS] the understands of t grand. emotional lives and calm within [SEP] its how beneficial plenty. and can belief was that t emotions problems and in that the building romance our petty great plight of romance lives that relied have intense love [SEP]']
[ 300/2000] tot_loss=2.310 (perp=10.316, rec=0.222, cos=0.025), tot_loss_proj:3.024 [t=0.31s]
prediction: ['[CLS] the understands ofರ grand anderson wild lives and calm the [SEP] she how grandmother deserves application jack can education of that l lives { and in xavier the living romance our father other problems of, hundreds that never can world love [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.171 (perp=9.812, rec=0.185, cos=0.024), tot_loss_proj:3.194 [t=0.31s]
prediction: ['[CLS] the understands of t grand anderson wild lives and calm the [SEP] she how grandmother deserves und jack can educations that l lives lives and in our the bringing romance our daily ever problems does world joy, that never can love [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.118 (perp=9.598, rec=0.174, cos=0.024), tot_loss_proj:3.065 [t=0.31s]
prediction: ['[CLS] the understands of t grand t wild lives and calm the [SEP] she how grandmother deserves und jack can educations that l lives our the bringing romance our lives lives and in daily ill of world joy. that knew can love [SEP]']
[ 450/2000] tot_loss=2.079 (perp=9.400, rec=0.176, cos=0.024), tot_loss_proj:3.072 [t=0.31s]
prediction: ['[CLS] the understands of t grand t grand lives and calm the and your how grandmother deserves und jack can education us that anderson lives our the bringing romance our lives lives and of daily ill does world romance. that knew can love [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.028 (perp=9.219, rec=0.161, cos=0.023), tot_loss_proj:3.078 [t=0.31s]
prediction: ['[CLS] the understands of t grand t grand lives and calm the of your how grandmother deserves tortricidae jack anderson education us that can lives our the bringing romance our lives lives and of daily ill of world romance never that knew can love [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.933 (perp=8.774, rec=0.154, cos=0.024), tot_loss_proj:3.249 [t=0.31s]
prediction: ['[CLS] the understands of t grand t grandness and calm the of your how grandmother deserves tortricidae jack anderson education us that can lives our the bringing romance our lives lives and of world ill of daily joy never we knew can love [SEP]']
[ 600/2000] tot_loss=1.964 (perp=8.946, rec=0.152, cos=0.023), tot_loss_proj:3.354 [t=0.31s]
prediction: ['[CLS] the understands of t grand t grandness and calm the and your how grandmother deserves prey jack anderson education us that can lives our the bring romance our lives lives and of of ill of daily joy never we knew can love [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.899 (perp=8.633, rec=0.149, cos=0.023), tot_loss_proj:3.182 [t=0.31s]
prediction: ['[CLS] the understands of t grand t grandness and calm the and your how grandmother deserves prey of anderson education us that can lives our the bring romance our our lives and of jack ill of daily joy never we knew is love [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.891 (perp=8.614, rec=0.145, cos=0.023), tot_loss_proj:3.282 [t=0.31s]
prediction: ['[CLS] the understands of t grand t grandness and calm the and your how grandmother deserves ill of anderson education us that can lives our the romance bring our our struggle and of jack ill of daily joy never we knew is love [SEP]']
[ 750/2000] tot_loss=1.889 (perp=8.632, rec=0.139, cos=0.024), tot_loss_proj:3.317 [t=0.31s]
prediction: ['[CLS] the understands of t grand t grandness and calm the of your how grandmother deserves ill of anderson education us that can lives our the romance bring our our struggle and of jack ill of daily joy never we knew is love [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.828 (perp=8.332, rec=0.138, cos=0.024), tot_loss_proj:3.138 [t=0.31s]
prediction: ['[CLS] the understands of t grand t grandness and calm the of your how grandmother deserves ill of anderson education us that our lives can the romance bring our our struggle and of jack ill of daily joy never we knew is love [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.798 (perp=8.205, rec=0.134, cos=0.023), tot_loss_proj:3.156 [t=0.31s]
prediction: ['[CLS] the understands of t grand the grandness and calm t of your how grandmother deserves ill of anderson education us that our lives can the romance bring our our struggle and of jack ill of daily joy never we knew is love [SEP]']
[ 900/2000] tot_loss=1.794 (perp=8.205, rec=0.129, cos=0.024), tot_loss_proj:3.155 [t=0.31s]
prediction: ['[CLS] the understands of t grand the grandness and calm t of your how grandmother deserves ill of anderson education us that our lives can the romance bring our our struggle and of jack ill of daily joy never we knew is love [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.780 (perp=8.139, rec=0.129, cos=0.024), tot_loss_proj:3.149 [t=0.31s]
prediction: ['[CLS] the understands of t grand the grandness and calm t of your how grandmother deserves ill the anderson education us that our lives can of romance bring our our struggle and of jack ill of daily joy never we knew is love [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.771 (perp=8.071, rec=0.133, cos=0.023), tot_loss_proj:3.043 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and calm t of your how grandmother deserves ill the anderson education us that our lives can of romance bring our our struggle and of jack ill of daily joy never we knew is love [SEP]']
[1050/2000] tot_loss=1.751 (perp=7.961, rec=0.135, cos=0.024), tot_loss_proj:3.029 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and calm t of the how grandmother deserves ill the anderson education us that our lives can of romance bring our our struggle and of jack ill of daily joy never we knew is love [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.790 (perp=8.199, rec=0.127, cos=0.024), tot_loss_proj:3.217 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and calm t of how the grandmother ice ill the anderson education us that our lives can of romance bring our our struggle and of jack ill of daily joy never we knew is love [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.754 (perp=7.986, rec=0.133, cos=0.024), tot_loss_proj:3.457 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and calm t how the grandmother ice ill of the anderson education us that our lives can of romance bring our our struggle and of jack ill of daily joy never we knew is love [SEP]']
[1200/2000] tot_loss=1.750 (perp=7.986, rec=0.129, cos=0.024), tot_loss_proj:3.458 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and calm t how the grandmother ice ill of the anderson education us that our lives can of romance bring our our struggle and of jack ill of daily joy never we knew is love [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.705 (perp=7.757, rec=0.130, cos=0.024), tot_loss_proj:3.397 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and calm t how the grandmother ice ill of the anderson education us that our lives can of romance bring our struggle and of jack ill of our daily joy never we knew is love [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.687 (perp=7.635, rec=0.136, cos=0.024), tot_loss_proj:3.371 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and how t calm the grandmother ice ill of the anderson education us that our lives can of romance bring our struggle and of jack ill of our daily joy never we knew is love [SEP]']
[1350/2000] tot_loss=1.753 (perp=7.977, rec=0.134, cos=0.024), tot_loss_proj:3.436 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and how t calm thentation ice ill of the anderson education us that our lives can of romance bring our struggle and of jack ill of our daily joy never we knew is love [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.753 (perp=8.027, rec=0.124, cos=0.024), tot_loss_proj:3.340 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and how t calm thentation of deserves ill of the anderson education us that our lives can of romance bring our struggle and jack ills our daily joy never we knew is love [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.742 (perp=7.921, rec=0.134, cos=0.024), tot_loss_proj:3.296 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and how t calm thentation of the ill of ice anderson education us that our lives can of romance bring our struggle and jack ills our daily joy never we knew is love [SEP]']
[1500/2000] tot_loss=1.752 (perp=8.018, rec=0.125, cos=0.023), tot_loss_proj:3.392 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and how t calm thentation of the ill of ice anderson emotion us that our lives can of romance bring our struggle and jack ills our daily joy never we knew is love [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.686 (perp=7.659, rec=0.131, cos=0.024), tot_loss_proj:3.340 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and how t can calm thentation of the ill of ice anderson emotion us that our lives of romance bring our struggle and jack ills our daily joy never we knew is love [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.629 (perp=7.389, rec=0.128, cos=0.023), tot_loss_proj:3.248 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and how t can calm thentation of the ill of ice jack anderson emotion us that our lives of romance bring our struggle and ills our daily joy never we knew is love [SEP]']
[1650/2000] tot_loss=1.626 (perp=7.389, rec=0.125, cos=0.023), tot_loss_proj:3.250 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and how t can calm thentation of the ill of ice jack anderson emotion us that our lives of romance bring our struggle and ills our daily joy never we knew is love [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.625 (perp=7.380, rec=0.126, cos=0.024), tot_loss_proj:3.271 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and how t can calm thentation of the ill of jack anderson emotion us that our lives ice of romance bring our struggle and ills our daily joy never we knew is love [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.631 (perp=7.369, rec=0.134, cos=0.024), tot_loss_proj:3.170 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and how ill can calm thentation of the t of jack anderson emotion us that our lives deserves of romance bring our struggle and ills our daily joy never we knew is love [SEP]']
[1800/2000] tot_loss=1.604 (perp=7.249, rec=0.130, cos=0.024), tot_loss_proj:3.174 [t=0.31s]
prediction: ['[CLS] t understands of the grand the grandness and how ill can calm thentation of the t of jack anderson emotion us that our lives ice of romance bring our struggle and ills our daily joy never we knew is love [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.620 (perp=7.337, rec=0.129, cos=0.024), tot_loss_proj:2.890 [t=0.31s]
prediction: ['[CLS]ntation understands of the grand the grandness and how ill can calm the t of the t of jack anderson emotion us that our lives deserves of romance bring our struggle and ills our daily joy never we knew is love [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.616 (perp=7.271, rec=0.138, cos=0.024), tot_loss_proj:2.873 [t=0.31s]
prediction: ['[CLS]ntation understands of the grand the grand iceness and how ill can calm the t of the t of jack anderson emotion us that our lives of romance bring our struggle and ills our daily joy never we knew is love [SEP]']
[1950/2000] tot_loss=1.583 (perp=7.188, rec=0.122, cos=0.024), tot_loss_proj:2.821 [t=0.31s]
prediction: ['[CLS]ntation understands of the grand the grand deservesness and how ill can calm the t of the t of jack anderson emotion us that our lives of romance bring our struggle and ills our daily joy never we knew is love [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.581 (perp=7.126, rec=0.132, cos=0.024), tot_loss_proj:2.801 [t=0.31s]
prediction: ['[CLS]ntation understands of the grand the grand deservesness and how ill can calm the t of the t of jack anderson emotion us that our lives of romance bring our struggle and ills our daily love never we knew is joy [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] t understands of the grand the grandness and how t can calm thentation of the ill of jack anderson emotion us that our lives ice of romance bring our struggle and ills our daily joy never we knew is love [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.500 | p: 69.048 | r: 76.316
rouge2     | fm: 15.385 | p: 14.634 | r: 16.216
rougeL     | fm: 42.500 | p: 40.476 | r: 44.737
rougeLsum  | fm: 42.500 | p: 40.476 | r: 44.737
r1fm+r2fm = 87.885

[Aggregate metrics]:
rouge1     | fm: 90.337 | p: 89.825 | r: 90.962
rouge2     | fm: 61.437 | p: 61.259 | r: 61.663
rougeL     | fm: 79.843 | p: 79.425 | r: 80.346
rougeLsum  | fm: 79.700 | p: 79.289 | r: 80.174
r1fm+r2fm = 151.774

input #88 time: 0:12:08 | total time: 18:31:14


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.9855123072574603
highest_index [0]
highest [0.9855123072574603]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9042061567306519 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.896477460861206 for ['[CLS] began even nominatedmpton faultulouslykingiciencies sunday marioers candi featuring forest moore laid jessica between mass power scorer health old outside for binding against pontifical mother why reside access [SEP]']
[Init] best rec loss: 0.8780019879341125 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 0.8739528656005859 for ['[CLS] back highsred reich deputy short engaged clappeddrop entire welcome rang hey israelilockqua tissue faith played suspected reduce exception macdonald links other need6 learningbody vicar over catholic [SEP]']
[Init] best rec loss: 0.8708192110061646 for ['[CLS] an other⁄ given fire miniseries fit followed inhabitants opposite kilometres earliest varyact simplest areness shy law armand reissue ritchie does promoted deal al mathematics amazon brethren that indeed inter [SEP]']
[Init] best rec loss: 0.8329841494560242 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 0.8317435383796692 for ['[CLS]kell belaρ brodie alderman j breath v firedried pop series littleizing guggenheim ran my relationvating dreams joggediving [SEP] dr... russell around state can roth braden four [SEP]']
[Init] best rec loss: 0.8295210599899292 for ['[CLS] regime * des islander out settle press dai banana condemned artillery wrong pounded in holmes lower inspiration won permanent mounted starting twitter question turned football faithful super mass where lookingdom fellow [SEP]']
[Init] best rec loss: 0.8218005895614624 for ['[CLS] isabella organ mama lyndon conspiracy leader aquatic oliviagul exhibit energy making wake mineə sub duct tournament ( parent sell carpet gradient goose covenant retrievedover even each uncle republic range [SEP]']
[Init] best rec loss: 0.8192209601402283 for ['[CLS] finally got wolf alan organizational 00pm or bra piketaff lack berlin circle nowhere chair temeraire sent movie thrust september wearing monster cartoon ang registrar secure until commons dimension surveyal island [SEP]']
[Init] best perm rec loss: 0.8187323808670044 for ['[CLS] lack or circle commons berlin wearing movie until wolf cartoon gotal pike organizational monster secure island september survey sent thrust alan chairtaff ang nowhere registrar dimension bra 00pm temeraire finally [SEP]']
[Init] best perm rec loss: 0.8163778781890869 for ['[CLS] alan island nowhere chair got or circle bra registrar movie wearing cartoon wolf survey lack monster until organizational dimensiontaff berlin secure finally 00pmal ang temeraire pike september thrust sent commons [SEP]']
[Init] best perm rec loss: 0.8152831792831421 for ['[CLS] finally nowhere temeraireal commons chair got 00pm circle movie lack berlin cartoon alan wearing wolf bra sent island until organizational thrust registrar dimension pike monster ang survey or septembertaff secure [SEP]']
[Init] best perm rec loss: 0.812885582447052 for ['[CLS] cartoon bra monster circle pike survey ang lack island gottaff nowhere movie sent 00pm commons september or finally organizational thrust secure dimension berlin alan wearing temeraire until chair wolfal registrar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.678 (perp=11.492, rec=0.342, cos=0.038), tot_loss_proj:2.993 [t=0.30s]
prediction: ['[CLS] tactic disguise any another worse00 sciences ground meat problem defect junk housed - on a can kitchen or allegedly placed that [ dull events round shooting when under ty, misunderstanding [SEP]']
[ 100/2000] tot_loss=2.458 (perp=10.716, rec=0.285, cos=0.029), tot_loss_proj:2.950 [t=0.31s]
prediction: ['[CLS] tactic disguise any covering worse fact tale word about peppers tactic the worse, or a a fl granted allegedly placed of worse badly things maybe maybe ballistic now none, idea [SEP]']
[ 150/2000] tot_loss=2.503 (perp=10.824, rec=0.303, cos=0.035), tot_loss_proj:2.980 [t=0.31s]
prediction: ["[CLS] tactic blind suppress covering up rape poem puppet of bomb tactic the agencies sometimes'fi the world its or managed to increasingly wrong or name spring punkto none, ideas [SEP]"]
[ 200/2000] tot_loss=2.282 (perp=10.038, rec=0.245, cos=0.030), tot_loss_proj:2.756 [t=0.31s]
prediction: ['[CLS] tactic cover uncomfortable cover up -scope picture of serial fact the worse maybe2c an world its maybe built to worse wrong or boy - punk nix prophecy, ideas [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.279 (perp=10.190, rec=0.212, cos=0.029), tot_loss_proj:2.890 [t=0.31s]
prediction: ['[CLS] tactic cover to cover up practicingtonic picture of serial fact the worse maybe2c a system its worse constructed of worse worse or building - punk, none ph ideas [SEP]']
[ 300/2000] tot_loss=2.118 (perp=9.525, rec=0.184, cos=0.028), tot_loss_proj:2.706 [t=0.31s]
prediction: ['[CLS] tactic cover to cover up its speeches picture of serial fact the worse sometimes2k a system it worse constructed of worse worse or building, kid, none prophecy ideas [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.056 (perp=9.278, rec=0.171, cos=0.029), tot_loss_proj:2.701 [t=0.31s]
prediction: ['[CLS] tactic cover to cover up the speeches picture yet serial fact the worse maybe2im a web its worse constructed on worse or worse compound, kid, none ph ideas [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.209 (perp=9.806, rec=0.216, cos=0.031), tot_loss_proj:2.772 [t=0.31s]
prediction: ['[CLS] tactic cover to cover upilyspace picture yet fl fact the worseon2sy - solution its worse constructed just ideas around worse of worse compound, -, none [SEP]']
[ 450/2000] tot_loss=2.037 (perp=8.932, rec=0.221, cos=0.030), tot_loss_proj:2.531 [t=0.31s]
prediction: ['[CLS] tactic smaller to cover up recently - picture a fl fact the worse issues und - a constructed it or constructed just ideas around worse - worse somehow, -, none [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.169 (perp=9.823, rec=0.176, cos=0.029), tot_loss_proj:2.721 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up recentlyspace picture a fl fact the worse thin2 - a layer its or constructedip ideas around worse - worse somehow, -, none [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.143 (perp=9.718, rec=0.172, cos=0.028), tot_loss_proj:2.720 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up -space picture a fl fact the worse thin is or constructedquisiteim a overallip ideas around worse - worse however, -, none [SEP]']
[ 600/2000] tot_loss=2.007 (perp=9.056, rec=0.167, cos=0.029), tot_loss_proj:2.611 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up - the picture a fl fact the worse thin is or constructed2im a overallip ideas around worse - worse however, -, none [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.008 (perp=9.106, rec=0.159, cos=0.028), tot_loss_proj:2.699 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up -space picture a fl fact the worse larger is or constructed quiteim a coreip ideas around -, none worse - worse -, [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.908 (perp=8.622, rec=0.155, cos=0.029), tot_loss_proj:2.567 [t=0.31s]
prediction: ['[CLS] tacticon to cover up a the picture - fl fact the worse larger is or constructed2im - coreip ideas around -, none worse - worse -, [SEP]']
[ 750/2000] tot_loss=1.886 (perp=8.534, rec=0.151, cos=0.029), tot_loss_proj:2.556 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up a - picture - fl fact the worse larger is or constructed2im - coreip ideas around -, none worse - worse -, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.930 (perp=8.773, rec=0.147, cos=0.028), tot_loss_proj:2.580 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up a picturesy - fl fact the worse larger is or constructed2im - coreip ideas around -, none worse, worse -, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.755 (perp=7.915, rec=0.143, cos=0.029), tot_loss_proj:2.369 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up a picture - - fl fact the worse constructed is or larger2im - coreip ideas around -, none worse, worse -, [SEP]']
[ 900/2000] tot_loss=1.744 (perp=7.915, rec=0.133, cos=0.028), tot_loss_proj:2.369 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up a picture - - fl fact the worse constructed is or larger2im - coreip ideas around -, none worse, worse -, [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.853 (perp=8.439, rec=0.137, cos=0.029), tot_loss_proj:2.430 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up a picture fl fact cardinal - the worse constructed is or larger2im - coreip ideas around -, none worse, worse -, [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.838 (perp=8.364, rec=0.136, cos=0.029), tot_loss_proj:2.452 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up a picture fl fact suzy - the worse constructed is or larger2im - coreip ideas - around, none worse, worse -, [SEP]']
[1050/2000] tot_loss=1.833 (perp=8.364, rec=0.131, cos=0.029), tot_loss_proj:2.449 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up a picture fl fact suzy - the worse constructed is or larger2im - coreip ideas - around, none worse, worse -, [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.778 (perp=8.091, rec=0.132, cos=0.028), tot_loss_proj:2.355 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up a picture fl fact goddamn - the constructed is worse or larger2im - coreip ideas - around, none worse, worse -, [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.735 (perp=7.889, rec=0.129, cos=0.028), tot_loss_proj:2.350 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up, picture fl factander - the constructed is worse or larger2im - coreip ideas - around, none worse, worse - a [SEP]']
[1200/2000] tot_loss=1.733 (perp=7.889, rec=0.127, cos=0.028), tot_loss_proj:2.355 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up, picture fl factander - the constructed is worse or larger2im - coreip ideas - around, none worse, worse - a [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.714 (perp=7.786, rec=0.128, cos=0.028), tot_loss_proj:2.333 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up, picture fl fact - - the constructed is worse or larger2imander coreip ideas - around, none worse, worse - a [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.711 (perp=7.781, rec=0.126, cos=0.029), tot_loss_proj:2.581 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up, picture fl fact - - the constructed is worse or a2imander coreip ideas - around, none worse, worse - larger [SEP]']
[1350/2000] tot_loss=1.709 (perp=7.781, rec=0.124, cos=0.029), tot_loss_proj:2.579 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up, picture fl fact - - the constructed is worse or a2imander coreip ideas - around, none worse, worse - larger [SEP]']
Attempt swap
[1400/2000] tot_loss=1.711 (perp=7.781, rec=0.126, cos=0.029), tot_loss_proj:2.581 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up, picture fl fact - - the constructed is worse or a2imander coreip ideas - around, none worse, worse - larger [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.760 (perp=8.015, rec=0.128, cos=0.028), tot_loss_proj:2.415 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up, picture fl fact - - the constructed is worse or a2imander coreip ideas - around, larger yet, worse - none [SEP]']
[1500/2000] tot_loss=1.755 (perp=8.015, rec=0.124, cos=0.029), tot_loss_proj:2.414 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up, picture fl fact - - the constructed is worse or a2imander coreip ideas - around, larger yet, worse - none [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.745 (perp=7.949, rec=0.126, cos=0.028), tot_loss_proj:2.376 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up, picture fl fact - - the constructed is worse or a2imander coreip ideas - around, larger yet worse, - none [SEP]']
Attempt swap
[1600/2000] tot_loss=1.746 (perp=7.949, rec=0.128, cos=0.029), tot_loss_proj:2.373 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up, picture fl fact - - the constructed is worse or a2imander coreip ideas - around, larger yet worse, - none [SEP]']
[1650/2000] tot_loss=1.740 (perp=7.949, rec=0.122, cos=0.029), tot_loss_proj:2.375 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up, picture fl fact - - the constructed is worse or a2imander coreip ideas - around, larger yet worse, - none [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.728 (perp=7.901, rec=0.120, cos=0.029), tot_loss_proj:2.353 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up larger picture fl fact - - the constructed is worse or a2imander coreip ideas - around,, yet worse, - none [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.729 (perp=7.838, rec=0.133, cos=0.029), tot_loss_proj:2.304 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up larger picture fl fact - - the constructed is worse or a2imander coreip ideas - around,, yet worse, none - [SEP]']
[1800/2000] tot_loss=1.719 (perp=7.838, rec=0.123, cos=0.029), tot_loss_proj:2.302 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up larger picture fl fact - - the constructed is worse or a2imander coreip ideas - around,, yet worse, none - [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.681 (perp=7.653, rec=0.122, cos=0.028), tot_loss_proj:2.274 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up larger picture fl fact - - the constructed is worse, a2imander coreip ideas - around, or yet worse, none - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.683 (perp=7.653, rec=0.124, cos=0.029), tot_loss_proj:2.275 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up larger picture fl fact - - the constructed is worse, a2imander coreip ideas - around, or yet worse, none - [SEP]']
[1950/2000] tot_loss=1.641 (perp=7.450, rec=0.123, cos=0.028), tot_loss_proj:2.208 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up larger picture fl fact - - the constructed is worse, a flimander coreip ideas - around, or yet worse, none - [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.630 (perp=7.394, rec=0.123, cos=0.028), tot_loss_proj:2.279 [t=0.31s]
prediction: ['[CLS] tactic issues to cover up larger picture fl fact - - the constructed is worse, a flimander coreip ideas - around, or none worse, yet - [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] tactic issues to cover up larger picture fl fact - - the constructed is worse, a2imander coreip ideas - around, or yet worse, none - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.565 | p: 69.565 | r: 69.565
rouge2     | fm: 13.636 | p: 13.636 | r: 13.636
rougeL     | fm: 52.174 | p: 52.174 | r: 52.174
rougeLsum  | fm: 52.174 | p: 52.174 | r: 52.174
r1fm+r2fm = 83.202

[Aggregate metrics]:
rouge1     | fm: 90.096 | p: 89.615 | r: 90.660
rouge2     | fm: 61.000 | p: 60.771 | r: 61.215
rougeL     | fm: 79.508 | p: 79.121 | r: 79.998
rougeLsum  | fm: 79.611 | p: 79.234 | r: 80.102
r1fm+r2fm = 151.095

input #89 time: 0:12:07 | total time: 18:43:22


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9853380494748033
highest_index [0]
highest [0.9853380494748033]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.8911092281341553 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.8422096967697144 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.7992093563079834 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.79653400182724 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.7939143180847168 for ['[CLS] male when released cannot entourage spirited [SEP]']
[Init] best perm rec loss: 0.793914258480072 for ['[CLS] when entourage spirited male released cannot [SEP]']
[Init] best perm rec loss: 0.7924358248710632 for ['[CLS] when male entourage released spirited cannot [SEP]']
[Init] best perm rec loss: 0.7919840216636658 for ['[CLS] male entourage released cannot spirited when [SEP]']
[Init] best perm rec loss: 0.7903662919998169 for ['[CLS] cannot male spirited released when entourage [SEP]']
[Init] best perm rec loss: 0.7899582982063293 for ['[CLS] when male released entourage spirited cannot [SEP]']
[Init] best perm rec loss: 0.7879047989845276 for ['[CLS] when spirited released male cannot entourage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.765 (perp=12.094, rec=0.297, cos=0.049), tot_loss_proj:3.152 [t=0.30s]
prediction: ['[CLS] who how ridiculous april crazy inspector [SEP]']
[ 100/2000] tot_loss=2.129 (perp=9.618, rec=0.176, cos=0.030), tot_loss_proj:2.550 [t=0.30s]
prediction: ['[CLS] who how ridiculous money - oriented [SEP]']
[ 150/2000] tot_loss=1.840 (perp=8.628, rec=0.087, cos=0.027), tot_loss_proj:2.415 [t=0.30s]
prediction: ['[CLS] money how ridiculous money and oriented [SEP]']
[ 200/2000] tot_loss=1.831 (perp=8.586, rec=0.087, cos=0.027), tot_loss_proj:2.476 [t=0.30s]
prediction: ['[CLS] when how ridiculous money and oriented [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.544 (perp=7.069, rec=0.103, cos=0.027), tot_loss_proj:1.977 [t=0.30s]
prediction: ['[CLS] money how ridiculous and money oriented [SEP]']
[ 300/2000] tot_loss=1.653 (perp=7.694, rec=0.086, cos=0.028), tot_loss_proj:1.908 [t=0.30s]
prediction: ['[CLS] - how ridiculous and money oriented [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.494 (perp=6.870, rec=0.092, cos=0.028), tot_loss_proj:1.666 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.479 (perp=6.870, rec=0.077, cos=0.029), tot_loss_proj:1.659 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.471 (perp=6.870, rec=0.069, cos=0.028), tot_loss_proj:1.678 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.476 (perp=6.870, rec=0.073, cos=0.029), tot_loss_proj:1.660 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.473 (perp=6.870, rec=0.071, cos=0.029), tot_loss_proj:1.681 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.472 (perp=6.870, rec=0.070, cos=0.028), tot_loss_proj:1.674 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.468 (perp=6.870, rec=0.066, cos=0.028), tot_loss_proj:1.671 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.480 (perp=6.870, rec=0.078, cos=0.028), tot_loss_proj:1.678 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.466 (perp=6.870, rec=0.063, cos=0.028), tot_loss_proj:1.665 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.467 (perp=6.870, rec=0.065, cos=0.028), tot_loss_proj:1.669 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.480 (perp=6.870, rec=0.078, cos=0.029), tot_loss_proj:1.673 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.473 (perp=6.870, rec=0.071, cos=0.028), tot_loss_proj:1.669 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.465 (perp=6.870, rec=0.063, cos=0.028), tot_loss_proj:1.668 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.476 (perp=6.870, rec=0.074, cos=0.028), tot_loss_proj:1.672 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.472 (perp=6.870, rec=0.070, cos=0.028), tot_loss_proj:1.673 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.484 (perp=6.870, rec=0.082, cos=0.029), tot_loss_proj:1.670 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.454 (perp=6.870, rec=0.051, cos=0.029), tot_loss_proj:1.669 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.462 (perp=6.870, rec=0.059, cos=0.029), tot_loss_proj:1.669 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.469 (perp=6.870, rec=0.066, cos=0.029), tot_loss_proj:1.675 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.473 (perp=6.870, rec=0.070, cos=0.029), tot_loss_proj:1.674 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.473 (perp=6.870, rec=0.070, cos=0.029), tot_loss_proj:1.673 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.462 (perp=6.870, rec=0.059, cos=0.029), tot_loss_proj:1.679 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.455 (perp=6.870, rec=0.052, cos=0.029), tot_loss_proj:1.665 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.458 (perp=6.870, rec=0.055, cos=0.029), tot_loss_proj:1.678 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.463 (perp=6.870, rec=0.060, cos=0.029), tot_loss_proj:1.669 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.456 (perp=6.870, rec=0.053, cos=0.029), tot_loss_proj:1.676 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.461 (perp=6.870, rec=0.058, cos=0.029), tot_loss_proj:1.674 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.466 (perp=6.870, rec=0.063, cos=0.029), tot_loss_proj:1.678 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.468 (perp=6.870, rec=0.065, cos=0.029), tot_loss_proj:1.674 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.462 (perp=6.870, rec=0.059, cos=0.029), tot_loss_proj:1.675 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.472 (perp=6.870, rec=0.069, cos=0.029), tot_loss_proj:1.673 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.474 (perp=6.870, rec=0.071, cos=0.029), tot_loss_proj:1.668 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.464 (perp=6.870, rec=0.061, cos=0.029), tot_loss_proj:1.678 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.480 (perp=6.870, rec=0.077, cos=0.029), tot_loss_proj:1.671 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.196 | p: 89.724 | r: 90.783
rouge2     | fm: 61.283 | p: 61.048 | r: 61.514
rougeL     | fm: 79.799 | p: 79.417 | r: 80.257
rougeLsum  | fm: 79.702 | p: 79.325 | r: 80.149
r1fm+r2fm = 151.479

input #90 time: 0:11:53 | total time: 18:55:16


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9847982508301042
highest_index [0]
highest [0.9847982508301042]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.7905072569847107 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.7509307861328125 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.7462303638458252 for ['[CLS] lynn through father viva black forgiveness stab around [SEP]']
[Init] best rec loss: 0.7286244034767151 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.685741126537323 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.679706335067749 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.6751892566680908 for ['[CLS] neal african milne architecture joint rolls conductline [SEP]']
[Init] best rec loss: 0.661159873008728 for ['[CLS] reminder addict anyway oneislausicidelishhered [SEP]']
[Init] best perm rec loss: 0.6579675674438477 for ['[CLS] reminderislaus anywayicide addict oneheredlish [SEP]']
[Init] best perm rec loss: 0.6577011942863464 for ['[CLS]hered reminder onelish addictislausicide anyway [SEP]']
[Init] best perm rec loss: 0.6574181318283081 for ['[CLS]icidelish reminder anywayislaus one addicthered [SEP]']
[Init] best perm rec loss: 0.6571784615516663 for ['[CLS]heredislaus one addict remindericidelish anyway [SEP]']
[Init] best perm rec loss: 0.6568999886512756 for ['[CLS]islausicide addictheredlish one anyway reminder [SEP]']
[Init] best perm rec loss: 0.6562340259552002 for ['[CLS]heredicide one anyway reminderislauslish addict [SEP]']
[Init] best perm rec loss: 0.6548234224319458 for ['[CLS]heredicide addict anywaylishislaus reminder one [SEP]']
[Init] best perm rec loss: 0.6534112691879272 for ['[CLS] addictlish reminderhered anywayislausicide one [SEP]']
[Init] best perm rec loss: 0.6533294320106506 for ['[CLS]icidehered anywayislaus one addict reminderlish [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.533 (perp=10.925, rec=0.289, cos=0.059), tot_loss_proj:2.986 [t=0.30s]
prediction: ['[CLS] no locoes moreover loco too thousand ridiculous [SEP]']
[ 100/2000] tot_loss=1.615 (perp=7.197, rec=0.145, cos=0.030), tot_loss_proj:2.313 [t=0.30s]
prediction: ['[CLS] no loco but more loco, more ridiculous [SEP]']
[ 150/2000] tot_loss=1.702 (perp=7.862, rec=0.098, cos=0.031), tot_loss_proj:2.357 [t=0.30s]
prediction: ['[CLS] no loco but more locoy more ridiculous [SEP]']
[ 200/2000] tot_loss=1.834 (perp=8.616, rec=0.082, cos=0.029), tot_loss_proj:2.519 [t=0.30s]
prediction: ['[CLS] no mu but more locoy more ridiculous [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.675 (perp=7.861, rec=0.073, cos=0.030), tot_loss_proj:2.112 [t=0.30s]
prediction: ['[CLS] but no mu more locoy, ridiculous [SEP]']
[ 300/2000] tot_loss=1.670 (perp=7.861, rec=0.068, cos=0.030), tot_loss_proj:2.114 [t=0.30s]
prediction: ['[CLS] but no mu more locoy, ridiculous [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.606 (perp=7.412, rec=0.095, cos=0.029), tot_loss_proj:2.071 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.584 (perp=7.412, rec=0.072, cos=0.030), tot_loss_proj:2.060 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
[ 450/2000] tot_loss=1.584 (perp=7.412, rec=0.071, cos=0.030), tot_loss_proj:2.055 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.586 (perp=7.412, rec=0.073, cos=0.030), tot_loss_proj:2.052 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.564 (perp=7.412, rec=0.051, cos=0.030), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
[ 600/2000] tot_loss=1.573 (perp=7.412, rec=0.061, cos=0.030), tot_loss_proj:2.051 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.581 (perp=7.412, rec=0.069, cos=0.030), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.570 (perp=7.412, rec=0.058, cos=0.030), tot_loss_proj:2.052 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
[ 750/2000] tot_loss=1.570 (perp=7.412, rec=0.057, cos=0.030), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.578 (perp=7.412, rec=0.065, cos=0.030), tot_loss_proj:2.061 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.588 (perp=7.412, rec=0.076, cos=0.030), tot_loss_proj:2.058 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
[ 900/2000] tot_loss=1.582 (perp=7.412, rec=0.070, cos=0.030), tot_loss_proj:2.055 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.583 (perp=7.412, rec=0.070, cos=0.030), tot_loss_proj:2.053 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.574 (perp=7.412, rec=0.062, cos=0.030), tot_loss_proj:2.052 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
[1050/2000] tot_loss=1.572 (perp=7.412, rec=0.059, cos=0.030), tot_loss_proj:2.061 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.570 (perp=7.412, rec=0.058, cos=0.030), tot_loss_proj:2.060 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.579 (perp=7.412, rec=0.067, cos=0.030), tot_loss_proj:2.057 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
[1200/2000] tot_loss=1.577 (perp=7.412, rec=0.064, cos=0.030), tot_loss_proj:2.064 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.575 (perp=7.412, rec=0.062, cos=0.030), tot_loss_proj:2.059 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.578 (perp=7.412, rec=0.066, cos=0.030), tot_loss_proj:2.067 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
[1350/2000] tot_loss=1.572 (perp=7.412, rec=0.060, cos=0.030), tot_loss_proj:2.062 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.582 (perp=7.412, rec=0.070, cos=0.030), tot_loss_proj:2.063 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.573 (perp=7.412, rec=0.061, cos=0.030), tot_loss_proj:2.057 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
[1500/2000] tot_loss=1.584 (perp=7.412, rec=0.072, cos=0.030), tot_loss_proj:2.063 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.579 (perp=7.412, rec=0.066, cos=0.030), tot_loss_proj:2.062 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.569 (perp=7.412, rec=0.057, cos=0.030), tot_loss_proj:2.063 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
[1650/2000] tot_loss=1.574 (perp=7.412, rec=0.062, cos=0.030), tot_loss_proj:2.063 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.584 (perp=7.412, rec=0.071, cos=0.030), tot_loss_proj:2.066 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.571 (perp=7.412, rec=0.058, cos=0.030), tot_loss_proj:2.062 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
[1800/2000] tot_loss=1.577 (perp=7.412, rec=0.065, cos=0.030), tot_loss_proj:2.065 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.584 (perp=7.412, rec=0.071, cos=0.030), tot_loss_proj:2.064 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.572 (perp=7.412, rec=0.060, cos=0.030), tot_loss_proj:2.066 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
[1950/2000] tot_loss=1.575 (perp=7.412, rec=0.062, cos=0.030), tot_loss_proj:2.063 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.573 (perp=7.412, rec=0.061, cos=0.030), tot_loss_proj:2.060 [t=0.30s]
prediction: ['[CLS] but no more locoy, mu ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] but no more locoy, mu ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 117.857

[Aggregate metrics]:
rouge1     | fm: 90.065 | p: 89.601 | r: 90.694
rouge2     | fm: 61.267 | p: 61.073 | r: 61.478
rougeL     | fm: 79.631 | p: 79.270 | r: 80.083
rougeLsum  | fm: 79.680 | p: 79.283 | r: 80.111
r1fm+r2fm = 151.332

input #91 time: 0:11:56 | total time: 19:07:12


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9869263109240434
highest_index [0]
highest [0.9869263109240434]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.829079270362854 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.82480788230896 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.7840303778648376 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.7662220001220703 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7369837164878845 for ['[CLS] tank lonely [SEP]']
[Init] best rec loss: 0.7110641598701477 for ['[CLS] paths locked [SEP]']
[Init] best perm rec loss: 0.7092560529708862 for ['[CLS] locked paths [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.684 (perp=7.647, rec=0.124, cos=0.030), tot_loss_proj:1.614 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 100/2000] tot_loss=1.632 (perp=7.647, rec=0.077, cos=0.026), tot_loss_proj:1.618 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.603 (perp=7.647, rec=0.048, cos=0.026), tot_loss_proj:1.618 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.630 (perp=7.647, rec=0.075, cos=0.026), tot_loss_proj:1.613 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.621 (perp=7.647, rec=0.066, cos=0.026), tot_loss_proj:1.616 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.616 (perp=7.647, rec=0.061, cos=0.026), tot_loss_proj:1.618 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.624 (perp=7.647, rec=0.069, cos=0.026), tot_loss_proj:1.625 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.623 (perp=7.647, rec=0.068, cos=0.026), tot_loss_proj:1.613 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.609 (perp=7.647, rec=0.053, cos=0.026), tot_loss_proj:1.613 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.628 (perp=7.647, rec=0.073, cos=0.026), tot_loss_proj:1.617 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.602 (perp=7.647, rec=0.047, cos=0.026), tot_loss_proj:1.608 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.613 (perp=7.647, rec=0.058, cos=0.026), tot_loss_proj:1.607 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.607 (perp=7.647, rec=0.052, cos=0.026), tot_loss_proj:1.621 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.595 (perp=7.647, rec=0.040, cos=0.026), tot_loss_proj:1.605 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.607 (perp=7.647, rec=0.051, cos=0.026), tot_loss_proj:1.617 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.609 (perp=7.647, rec=0.054, cos=0.026), tot_loss_proj:1.624 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.603 (perp=7.647, rec=0.048, cos=0.026), tot_loss_proj:1.633 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.607 (perp=7.647, rec=0.052, cos=0.026), tot_loss_proj:1.625 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.609 (perp=7.647, rec=0.054, cos=0.026), tot_loss_proj:1.631 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.606 (perp=7.647, rec=0.051, cos=0.026), tot_loss_proj:1.630 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.605 (perp=7.647, rec=0.050, cos=0.026), tot_loss_proj:1.617 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.609 (perp=7.647, rec=0.054, cos=0.026), tot_loss_proj:1.615 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.621 (perp=7.647, rec=0.065, cos=0.026), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.598 (perp=7.647, rec=0.043, cos=0.026), tot_loss_proj:1.623 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.608 (perp=7.647, rec=0.053, cos=0.026), tot_loss_proj:1.612 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.631 (perp=7.647, rec=0.076, cos=0.026), tot_loss_proj:1.607 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.624 (perp=7.647, rec=0.069, cos=0.026), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.620 (perp=7.647, rec=0.065, cos=0.026), tot_loss_proj:1.607 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.613 (perp=7.647, rec=0.058, cos=0.026), tot_loss_proj:1.625 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.619 (perp=7.647, rec=0.064, cos=0.026), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.617 (perp=7.647, rec=0.062, cos=0.026), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.618 (perp=7.647, rec=0.063, cos=0.026), tot_loss_proj:1.619 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.615 (perp=7.647, rec=0.059, cos=0.026), tot_loss_proj:1.632 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.628 (perp=7.647, rec=0.073, cos=0.026), tot_loss_proj:1.618 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.630 (perp=7.647, rec=0.075, cos=0.026), tot_loss_proj:1.612 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.616 (perp=7.647, rec=0.061, cos=0.026), tot_loss_proj:1.616 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.627 (perp=7.647, rec=0.071, cos=0.026), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.622 (perp=7.647, rec=0.066, cos=0.026), tot_loss_proj:1.616 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.600 (perp=7.647, rec=0.045, cos=0.026), tot_loss_proj:1.612 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.609 (perp=7.647, rec=0.054, cos=0.026), tot_loss_proj:1.613 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.148 | p: 89.677 | r: 90.767
rouge2     | fm: 61.614 | p: 61.446 | r: 61.825
rougeL     | fm: 79.873 | p: 79.485 | r: 80.351
rougeLsum  | fm: 79.824 | p: 79.438 | r: 80.313
r1fm+r2fm = 151.763

input #92 time: 0:11:52 | total time: 19:19:04


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9880776514579657
highest_index [0]
highest [0.9880776514579657]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 0.9392392635345459 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8869445323944092 for ['[CLS] taxi kang lookiled what mostchrome [SEP]']
[Init] best rec loss: 0.8794015049934387 for ['[CLS] scene attack humming working municipal attendant [MASK] [SEP]']
[Init] best rec loss: 0.8635080456733704 for ['[CLS] thousands fuel conditional scales progressed empowered mar [SEP]']
[Init] best rec loss: 0.8573740720748901 for ['[CLS] [CLS]rac madonna premiership further jeremy colby [SEP]']
[Init] best perm rec loss: 0.8510323166847229 for ['[CLS]rac jeremy madonna further premiership [CLS] colby [SEP]']
[Init] best perm rec loss: 0.848620593547821 for ['[CLS] furtherrac premiership colby madonna jeremy [CLS] [SEP]']
[Init] best perm rec loss: 0.8471462726593018 for ['[CLS]rac premiership colby further madonna jeremy [CLS] [SEP]']
[Init] best perm rec loss: 0.846790075302124 for ['[CLS] colby jeremyrac further premiership madonna [CLS] [SEP]']
[Init] best perm rec loss: 0.8461606502532959 for ['[CLS] colby madonnarac further jeremy [CLS] premiership [SEP]']
[Init] best perm rec loss: 0.844329833984375 for ['[CLS] colbyrac madonna further premiership jeremy [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.648 (perp=11.845, rec=0.243, cos=0.036), tot_loss_proj:3.135 [t=0.30s]
prediction: ['[CLS]ance often often often understanding while way [SEP]']
[ 100/2000] tot_loss=2.269 (perp=10.397, rec=0.162, cos=0.028), tot_loss_proj:2.388 [t=0.30s]
prediction: ['[CLS] in often often funny understanding known way [SEP]']
[ 150/2000] tot_loss=2.275 (perp=10.678, rec=0.113, cos=0.026), tot_loss_proj:2.677 [t=0.30s]
prediction: ['[CLS] in often that funny understanding often way [SEP]']
[ 200/2000] tot_loss=1.871 (perp=8.732, rec=0.100, cos=0.025), tot_loss_proj:2.026 [t=0.30s]
prediction: ['[CLS] in often, funny understanding, way [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.614 (perp=7.490, rec=0.090, cos=0.025), tot_loss_proj:1.774 [t=0.30s]
prediction: ['[CLS] in often funny, understanding, way [SEP]']
[ 300/2000] tot_loss=1.611 (perp=7.490, rec=0.089, cos=0.024), tot_loss_proj:1.774 [t=0.30s]
prediction: ['[CLS] in often funny, understanding, way [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.533 (perp=7.091, rec=0.090, cos=0.025), tot_loss_proj:1.698 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.529 (perp=7.091, rec=0.086, cos=0.025), tot_loss_proj:1.703 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way, [SEP]']
[ 450/2000] tot_loss=1.520 (perp=7.091, rec=0.078, cos=0.025), tot_loss_proj:1.697 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.528 (perp=7.091, rec=0.086, cos=0.024), tot_loss_proj:1.698 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.528 (perp=7.091, rec=0.086, cos=0.024), tot_loss_proj:1.698 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way, [SEP]']
[ 600/2000] tot_loss=1.529 (perp=7.091, rec=0.087, cos=0.024), tot_loss_proj:1.703 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.522 (perp=7.091, rec=0.080, cos=0.024), tot_loss_proj:1.702 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.524 (perp=7.091, rec=0.083, cos=0.024), tot_loss_proj:1.704 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way, [SEP]']
[ 750/2000] tot_loss=1.530 (perp=7.091, rec=0.088, cos=0.024), tot_loss_proj:1.697 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.523 (perp=7.091, rec=0.081, cos=0.024), tot_loss_proj:1.698 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.524 (perp=7.091, rec=0.082, cos=0.024), tot_loss_proj:1.697 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way, [SEP]']
[ 900/2000] tot_loss=1.769 (perp=8.383, rec=0.069, cos=0.024), tot_loss_proj:1.969 [t=0.30s]
prediction: ['[CLS] in often funny, understanding way its [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.512 (perp=7.090, rec=0.070, cos=0.023), tot_loss_proj:1.624 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1000/2000] tot_loss=1.515 (perp=7.090, rec=0.073, cos=0.023), tot_loss_proj:1.615 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1050/2000] tot_loss=1.503 (perp=7.090, rec=0.062, cos=0.023), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1100/2000] tot_loss=1.504 (perp=7.090, rec=0.062, cos=0.023), tot_loss_proj:1.624 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1150/2000] tot_loss=1.500 (perp=7.090, rec=0.058, cos=0.023), tot_loss_proj:1.608 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1200/2000] tot_loss=1.506 (perp=7.090, rec=0.064, cos=0.023), tot_loss_proj:1.624 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1250/2000] tot_loss=1.512 (perp=7.090, rec=0.071, cos=0.023), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1300/2000] tot_loss=1.503 (perp=7.090, rec=0.061, cos=0.023), tot_loss_proj:1.614 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1350/2000] tot_loss=1.507 (perp=7.090, rec=0.065, cos=0.024), tot_loss_proj:1.624 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1400/2000] tot_loss=1.516 (perp=7.090, rec=0.075, cos=0.024), tot_loss_proj:1.622 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1450/2000] tot_loss=1.501 (perp=7.090, rec=0.059, cos=0.024), tot_loss_proj:1.624 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1500/2000] tot_loss=1.496 (perp=7.090, rec=0.055, cos=0.024), tot_loss_proj:1.612 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1550/2000] tot_loss=1.496 (perp=7.090, rec=0.055, cos=0.024), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1600/2000] tot_loss=1.506 (perp=7.090, rec=0.065, cos=0.024), tot_loss_proj:1.620 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1650/2000] tot_loss=1.506 (perp=7.090, rec=0.065, cos=0.024), tot_loss_proj:1.617 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1700/2000] tot_loss=1.513 (perp=7.090, rec=0.072, cos=0.024), tot_loss_proj:1.613 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1750/2000] tot_loss=1.501 (perp=7.090, rec=0.060, cos=0.024), tot_loss_proj:1.621 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1800/2000] tot_loss=1.507 (perp=7.090, rec=0.066, cos=0.024), tot_loss_proj:1.621 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1850/2000] tot_loss=1.507 (perp=7.090, rec=0.066, cos=0.024), tot_loss_proj:1.619 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1900/2000] tot_loss=1.506 (perp=7.090, rec=0.064, cos=0.024), tot_loss_proj:1.617 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1950/2000] tot_loss=1.506 (perp=7.090, rec=0.064, cos=0.024), tot_loss_proj:1.614 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[2000/2000] tot_loss=1.508 (perp=7.090, rec=0.067, cos=0.024), tot_loss_proj:1.616 [t=0.30s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] in its often funny, understanding way [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 90.275 | p: 89.820 | r: 90.874
rouge2     | fm: 61.583 | p: 61.468 | r: 61.827
rougeL     | fm: 80.004 | p: 79.628 | r: 80.451
rougeLsum  | fm: 79.900 | p: 79.584 | r: 80.382
r1fm+r2fm = 151.859

input #93 time: 0:11:56 | total time: 19:31:00


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9860888196976529
highest_index [0]
highest [0.9860888196976529]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9485474228858948 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9458507895469666 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9377490282058716 for ['[CLS] milling library casual constructed board equationphs similaron cookies intended [SEP]']
[Init] best rec loss: 0.9297682642936707 for ['[CLS] of pro wanted scientists rayon housing chart close earlier anniversary ni [SEP]']
[Init] best rec loss: 0.928517758846283 for ['[CLS] same traumatic to blessing surface pac cell carmeter environment sigh [SEP]']
[Init] best rec loss: 0.9167928695678711 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9133604764938354 for ['[CLS] enough usingac sur mile ready down maymise majesty assumption [SEP]']
[Init] best rec loss: 0.9032176733016968 for ['[CLS] barber eithertype roador motivefirm trusted ednaack wanted [SEP]']
[Init] best perm rec loss: 0.9022154808044434 for ['[CLS] barber edna motivefirm eitheracktype roador wanted trusted [SEP]']
[Init] best perm rec loss: 0.9002978205680847 for ['[CLS]firmtype trusted barberack motive wantedor either road edna [SEP]']
[Init] best perm rec loss: 0.8994869589805603 for ['[CLS]or barber wantedack edna road motivefirm trusted eithertype [SEP]']
[Init] best perm rec loss: 0.8976739048957825 for ['[CLS]type road wanted barber motiveackor either edna trustedfirm [SEP]']
[Init] best perm rec loss: 0.8965803384780884 for ['[CLS] wanted trusted barber roadfirm motiveorack ednatype either [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.391 (perp=13.054, rec=0.580, cos=0.200), tot_loss_proj:4.246 [t=0.38s]
prediction: ['[CLS] invitation narrow granted no po pocketru lately funny cape ] [SEP]']
[ 100/2000] tot_loss=3.133 (perp=12.643, rec=0.519, cos=0.086), tot_loss_proj:4.457 [t=0.30s]
prediction: ['[CLS] neither narrow never no solar double cape lately funny cape funny [SEP]']
[ 150/2000] tot_loss=3.183 (perp=12.726, rec=0.515, cos=0.123), tot_loss_proj:3.610 [t=0.30s]
prediction: ['[CLS] neither cape received no via classic cape lately ridiculous cape funny [SEP]']
[ 200/2000] tot_loss=2.779 (perp=11.881, rec=0.358, cos=0.045), tot_loss_proj:3.671 [t=0.30s]
prediction: ['[CLS] lack object thatcr cape original acc america original original nor [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.515 (perp=11.166, rec=0.251, cos=0.031), tot_loss_proj:2.907 [t=0.30s]
prediction: ['[CLS] neither very neither prime very nor mani [SEP] funny original original [SEP]']
[ 300/2000] tot_loss=2.216 (perp=9.940, rec=0.200, cos=0.029), tot_loss_proj:2.799 [t=0.30s]
prediction: ['[CLS] neither terribly a cape s nor caper funny cape original [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.194 (perp=9.672, rec=0.232, cos=0.027), tot_loss_proj:3.162 [t=0.30s]
prediction: ['[CLS] neither terribly a cape stature nor opera is funny cape original [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.780 (perp=7.814, rec=0.190, cos=0.027), tot_loss_proj:2.630 [t=0.30s]
prediction: ['[CLS] neither terribly a caper nor opera world is funny original [SEP]']
[ 450/2000] tot_loss=1.969 (perp=8.952, rec=0.151, cos=0.028), tot_loss_proj:3.030 [t=0.30s]
prediction: ['[CLS] neither terribly a caper norer s is funny original [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.932 (perp=8.684, rec=0.166, cos=0.029), tot_loss_proj:3.664 [t=0.30s]
prediction: ['[CLS] neither world terribly a caper norr is funny original [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.717 (perp=7.689, rec=0.152, cos=0.027), tot_loss_proj:2.810 [t=0.30s]
prediction: ['[CLS] neither r terribly a caper nor is funnyr original [SEP]']
[ 600/2000] tot_loss=1.695 (perp=7.689, rec=0.131, cos=0.027), tot_loss_proj:2.820 [t=0.30s]
prediction: ['[CLS] neither r terribly a caper nor is funnyr original [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.678 (perp=7.689, rec=0.113, cos=0.027), tot_loss_proj:2.769 [t=0.30s]
prediction: ['[CLS] neither r terribly a caper nor is funnyr original [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.673 (perp=7.689, rec=0.108, cos=0.027), tot_loss_proj:2.770 [t=0.31s]
prediction: ['[CLS] neither r terribly a caper nor is funnyr original [SEP]']
[ 750/2000] tot_loss=1.812 (perp=8.442, rec=0.097, cos=0.027), tot_loss_proj:3.001 [t=0.30s]
prediction: ['[CLS] neither r terribly a caper norr funnyr original [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.819 (perp=8.442, rec=0.104, cos=0.027), tot_loss_proj:3.008 [t=0.30s]
prediction: ['[CLS] neither r terribly a caper norr funnyr original [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.759 (perp=8.114, rec=0.109, cos=0.027), tot_loss_proj:2.619 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
[ 900/2000] tot_loss=1.735 (perp=8.114, rec=0.085, cos=0.027), tot_loss_proj:2.629 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.747 (perp=8.114, rec=0.097, cos=0.027), tot_loss_proj:2.625 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1000/2000] tot_loss=1.738 (perp=8.114, rec=0.088, cos=0.027), tot_loss_proj:2.623 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
[1050/2000] tot_loss=1.745 (perp=8.114, rec=0.095, cos=0.027), tot_loss_proj:2.630 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1100/2000] tot_loss=1.750 (perp=8.114, rec=0.100, cos=0.027), tot_loss_proj:2.629 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1150/2000] tot_loss=1.740 (perp=8.114, rec=0.090, cos=0.027), tot_loss_proj:2.631 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
[1200/2000] tot_loss=1.740 (perp=8.114, rec=0.090, cos=0.027), tot_loss_proj:2.624 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1250/2000] tot_loss=1.741 (perp=8.114, rec=0.091, cos=0.027), tot_loss_proj:2.620 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1300/2000] tot_loss=1.731 (perp=8.114, rec=0.081, cos=0.027), tot_loss_proj:2.620 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
[1350/2000] tot_loss=1.731 (perp=8.114, rec=0.081, cos=0.027), tot_loss_proj:2.624 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1400/2000] tot_loss=1.731 (perp=8.114, rec=0.081, cos=0.027), tot_loss_proj:2.615 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1450/2000] tot_loss=1.725 (perp=8.114, rec=0.075, cos=0.027), tot_loss_proj:2.626 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
[1500/2000] tot_loss=1.737 (perp=8.114, rec=0.087, cos=0.027), tot_loss_proj:2.623 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1550/2000] tot_loss=1.740 (perp=8.114, rec=0.090, cos=0.027), tot_loss_proj:2.615 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1600/2000] tot_loss=1.736 (perp=8.114, rec=0.086, cos=0.027), tot_loss_proj:2.627 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
[1650/2000] tot_loss=1.739 (perp=8.114, rec=0.089, cos=0.027), tot_loss_proj:2.625 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1700/2000] tot_loss=1.731 (perp=8.114, rec=0.082, cos=0.027), tot_loss_proj:2.627 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1750/2000] tot_loss=1.725 (perp=8.114, rec=0.075, cos=0.027), tot_loss_proj:2.624 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
[1800/2000] tot_loss=1.728 (perp=8.114, rec=0.078, cos=0.027), tot_loss_proj:2.624 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1850/2000] tot_loss=1.734 (perp=8.114, rec=0.085, cos=0.027), tot_loss_proj:2.630 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[1900/2000] tot_loss=1.736 (perp=8.114, rec=0.086, cos=0.027), tot_loss_proj:2.620 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
[1950/2000] tot_loss=1.723 (perp=8.114, rec=0.074, cos=0.027), tot_loss_proj:2.620 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Attempt swap
[2000/2000] tot_loss=1.731 (perp=8.114, rec=0.081, cos=0.027), tot_loss_proj:2.627 [t=0.30s]
prediction: ['[CLS] neither thatr a caper nor terribly funnyr original [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] neither thatr a caper nor terribly funnyr original [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 80.000 | r: 72.727
rouge2     | fm: 21.053 | p: 22.222 | r: 20.000
rougeL     | fm: 57.143 | p: 60.000 | r: 54.545
rougeLsum  | fm: 57.143 | p: 60.000 | r: 54.545
r1fm+r2fm = 97.243

[Aggregate metrics]:
rouge1     | fm: 90.112 | p: 89.715 | r: 90.649
rouge2     | fm: 61.098 | p: 60.906 | r: 61.316
rougeL     | fm: 79.822 | p: 79.531 | r: 80.176
rougeLsum  | fm: 79.734 | p: 79.391 | r: 80.162
r1fm+r2fm = 151.210

input #94 time: 0:11:55 | total time: 19:42:56


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9861198686418354
highest_index [0]
highest [0.9861198686418354]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 1.0180238485336304 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 1.0111380815505981 for ['[CLS] reprinted geographic fairchild clary remains hitler tristanved thumb big hot dates muscle commander funding [SEP]']
[Init] best rec loss: 1.0104933977127075 for ['[CLS] cousinnished corners shamable aided deed grinned control actual pole masks making fifa bridge [SEP]']
[Init] best rec loss: 0.9840752482414246 for ['[CLS]nahley hair see nedra logan offices fourth sethgical recommended side laughdran auxiliary [SEP]']
[Init] best rec loss: 0.973916232585907 for ['[CLS] footprint brain arrival rec [MASK] 45 reverse if pal struggled spanning caleb born day classic [SEP]']
[Init] best rec loss: 0.9733762145042419 for ['[CLS] gas somewhereator bulk aka unlessssee actual como deliver? jockuble occasion [SEP]']
[Init] best perm rec loss: 0.9718941450119019 for ['[CLS] unless jocku aka bulk occasionssee somewhereator actual? como gasble deliver [SEP]']
[Init] best perm rec loss: 0.9703843593597412 for ['[CLS]ssee actualble deliverator unless occasion? somewhereu como bulk jock gas aka [SEP]']
[Init] best perm rec loss: 0.970333456993103 for ['[CLS] bulk comou occasion somewherebleator deliver gas actual? jockssee aka unless [SEP]']
[Init] best perm rec loss: 0.9684693813323975 for ['[CLS] unless jock bulkatorble occasion akau somewhere actualssee como? gas deliver [SEP]']
[Init] best perm rec loss: 0.9681357145309448 for ['[CLS] unless? comoator deliver actual bulku somewhere akassee occasionble gas jock [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.700 (perp=13.944, rec=0.608, cos=0.303), tot_loss_proj:4.749 [t=0.30s]
prediction: ['[CLS] campus maya stills hayes reached held mollyri trail tables necessityication transferred edition later [SEP]']
[ 100/2000] tot_loss=3.230 (perp=12.768, rec=0.522, cos=0.155), tot_loss_proj:4.004 [t=0.31s]
prediction: ['[CLS] reporter hopeless palace, reached born linden hopeless torture tables becomes tavi third ) later [SEP]']
[ 150/2000] tot_loss=3.146 (perp=12.418, rec=0.528, cos=0.134), tot_loss_proj:3.673 [t=0.31s]
prediction: ['[CLS] campus hopelessdy,zong become augustus hopeless torture discussion becomes gariondle ) later [SEP]']
[ 200/2000] tot_loss=3.111 (perp=12.953, rec=0.467, cos=0.053), tot_loss_proj:3.444 [t=0.31s]
prediction: ['[CLS] becomesboro fitch, becomes become una hopeless torture trump becomes zadle mud later [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.706 (perp=10.807, rec=0.466, cos=0.079), tot_loss_proj:3.106 [t=0.31s]
prediction: ['[CLS] becomes hopeless fitch. becomes become a hopeless puzzle trump becomes avoid muddle later [SEP]']
[ 300/2000] tot_loss=2.994 (perp=12.193, rec=0.471, cos=0.084), tot_loss_proj:3.198 [t=0.31s]
prediction: ['[CLS] becomes excel morrow. becomes becomes a hopelesssat hopeless becomes avoid muddle benefits [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.859 (perp=11.882, rec=0.444, cos=0.039), tot_loss_proj:3.519 [t=0.31s]
prediction: ['[CLS] becomes excelzily. isbn excellence hopeless becomes het hopeless becameyad muddle utah [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.718 (perp=11.259, rec=0.430, cos=0.036), tot_loss_proj:3.198 [t=0.31s]
prediction: ['[CLS] becomes mudzily. puzzle becomes excellence hopeless becomes hopeless became avoid muddle bravo [SEP]']
[ 450/2000] tot_loss=2.457 (perp=10.095, rec=0.410, cos=0.028), tot_loss_proj:2.806 [t=0.31s]
prediction: ['[CLS] becomes mud ‖. puzzle becomes a hopeless becomes hopeless becomes avoid muddle bravo [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.540 (perp=10.529, rec=0.407, cos=0.027), tot_loss_proj:2.745 [t=0.31s]
prediction: ['[CLS] becomes mud fitch.sat becomes a hopeless becomes hopeless avoid becomes muddle hopeless [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.342 (perp=9.524, rec=0.398, cos=0.039), tot_loss_proj:2.575 [t=0.31s]
prediction: ['[CLS] becomes mudsat. fitch becomes a hopeless becomes hopeless avoid becomes muddle bravo [SEP]']
[ 600/2000] tot_loss=2.335 (perp=9.524, rec=0.395, cos=0.036), tot_loss_proj:2.570 [t=0.31s]
prediction: ['[CLS] becomes mudsat. fitch becomes a hopeless becomes hopeless avoid becomes muddle bravo [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.699 (perp=11.068, rec=0.421, cos=0.065), tot_loss_proj:2.986 [t=0.31s]
prediction: ['[CLS] becomes mudsat. » becomes digit hopeless becomes hopeless avoid necessity muddle bravo [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.243 (perp=9.226, rec=0.371, cos=0.026), tot_loss_proj:2.570 [t=0.31s]
prediction: ['[CLS] becomes mudsat. » becomes a hopeless becomes hopeless avoid becomes muddle bravo [SEP]']
[ 750/2000] tot_loss=2.250 (perp=9.226, rec=0.375, cos=0.030), tot_loss_proj:2.583 [t=0.31s]
prediction: ['[CLS] becomes mudsat. » becomes a hopeless becomes hopeless avoid becomes muddle bravo [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.241 (perp=9.226, rec=0.366, cos=0.030), tot_loss_proj:2.586 [t=0.31s]
prediction: ['[CLS] becomes mudsat. » becomes a hopeless becomes hopeless avoid becomes muddle bravo [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.241 (perp=9.226, rec=0.364, cos=0.031), tot_loss_proj:2.593 [t=0.31s]
prediction: ['[CLS] becomes mudsat. » becomes a hopeless becomes hopeless avoid becomes muddle bravo [SEP]']
[ 900/2000] tot_loss=2.433 (perp=10.221, rec=0.362, cos=0.027), tot_loss_proj:2.814 [t=0.31s]
prediction: ['[CLS] story mudsat, » becomes a hopeless becomes hopeless avoid becomes muddle bravo [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.424 (perp=10.221, rec=0.351, cos=0.029), tot_loss_proj:2.813 [t=0.31s]
prediction: ['[CLS] story mudsat, » becomes a hopeless becomes hopeless avoid becomes muddle bravo [SEP]']
Attempt swap
[1000/2000] tot_loss=2.480 (perp=10.514, rec=0.347, cos=0.030), tot_loss_proj:2.835 [t=0.31s]
prediction: ['[CLS] story mudsat, » becomes a hopeless necessity hopeless avoid becomes muddle bravo [SEP]']
[1050/2000] tot_loss=2.497 (perp=10.514, rec=0.354, cos=0.040), tot_loss_proj:2.832 [t=0.31s]
prediction: ['[CLS] story mudsat, » becomes a hopeless necessity hopeless avoid becomes muddle bravo [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.696 (perp=10.924, rec=0.405, cos=0.106), tot_loss_proj:3.071 [t=0.31s]
prediction: ['[CLS] becomes mudsat hopeless ª becomes fate hopeless prizes, avoid becomes muddle bravo [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.325 (perp=9.433, rec=0.381, cos=0.057), tot_loss_proj:2.684 [t=0.31s]
prediction: ['[CLS] becomes mudsat ª becomes a hopeless hopeless prizes, avoid becomes muddle bravo [SEP]']
[1200/2000] tot_loss=2.376 (perp=9.865, rec=0.371, cos=0.032), tot_loss_proj:2.925 [t=0.31s]
prediction: ['[CLS] story mudsat horrors becomes a hopeless hopeless prizes, avoid becomes muddle bravo [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.239 (perp=9.260, rec=0.359, cos=0.028), tot_loss_proj:2.779 [t=0.31s]
prediction: ['[CLS] hopeless mudsat horrors becomes a hopeless story necessity, avoid becomes muddle bravo [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.245 (perp=9.295, rec=0.359, cos=0.027), tot_loss_proj:2.536 [t=0.31s]
prediction: ['[CLS] hopeless mudsat horrors story becomes a hopeless prizes, avoid becomes muddle hopeless [SEP]']
[1350/2000] tot_loss=2.073 (perp=8.435, rec=0.358, cos=0.028), tot_loss_proj:2.389 [t=0.31s]
prediction: ['[CLS] hopeless mudsat horrors story becomes a hopeless necessity, avoid becomes muddlelike [SEP]']
Attempt swap
[1400/2000] tot_loss=2.173 (perp=9.002, rec=0.345, cos=0.028), tot_loss_proj:2.409 [t=0.31s]
prediction: ['[CLS] hopeless mudsat horrors story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
Attempt swap
[1450/2000] tot_loss=2.168 (perp=9.002, rec=0.340, cos=0.027), tot_loss_proj:2.405 [t=0.31s]
prediction: ['[CLS] hopeless mudsat horrors story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
[1500/2000] tot_loss=2.279 (perp=9.540, rec=0.344, cos=0.027), tot_loss_proj:2.536 [t=0.31s]
prediction: ['[CLS] hopeless mudsat » story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
Attempt swap
[1550/2000] tot_loss=2.281 (perp=9.540, rec=0.345, cos=0.028), tot_loss_proj:2.531 [t=0.31s]
prediction: ['[CLS] hopeless mudsat » story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
Attempt swap
[1600/2000] tot_loss=2.269 (perp=9.540, rec=0.333, cos=0.027), tot_loss_proj:2.536 [t=0.31s]
prediction: ['[CLS] hopeless mudsat » story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
[1650/2000] tot_loss=2.271 (perp=9.540, rec=0.336, cos=0.027), tot_loss_proj:2.532 [t=0.31s]
prediction: ['[CLS] hopeless mudsat » story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
Attempt swap
[1700/2000] tot_loss=2.276 (perp=9.540, rec=0.340, cos=0.028), tot_loss_proj:2.530 [t=0.31s]
prediction: ['[CLS] hopeless mudsat » story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
Attempt swap
[1750/2000] tot_loss=2.274 (perp=9.540, rec=0.338, cos=0.028), tot_loss_proj:2.531 [t=0.31s]
prediction: ['[CLS] hopeless mudsat » story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
[1800/2000] tot_loss=2.298 (perp=9.700, rec=0.330, cos=0.027), tot_loss_proj:2.451 [t=0.31s]
prediction: ['[CLS] hopeless mudsatlo story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
Attempt swap
[1850/2000] tot_loss=2.302 (perp=9.700, rec=0.334, cos=0.028), tot_loss_proj:2.454 [t=0.31s]
prediction: ['[CLS] hopeless mudsatlo story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
Attempt swap
[1900/2000] tot_loss=2.305 (perp=9.700, rec=0.337, cos=0.028), tot_loss_proj:2.463 [t=0.31s]
prediction: ['[CLS] hopeless mudsatlo story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
[1950/2000] tot_loss=2.312 (perp=9.700, rec=0.344, cos=0.028), tot_loss_proj:2.461 [t=0.31s]
prediction: ['[CLS] hopeless mudsatlo story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
Attempt swap
[2000/2000] tot_loss=2.302 (perp=9.700, rec=0.334, cos=0.027), tot_loss_proj:2.452 [t=0.31s]
prediction: ['[CLS] hopeless mudsatlo story becomes a hopeless necessity, avoid becomes muddlecade [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] hopeless mudsatlo story becomes a hopeless necessity, avoid becomes muddlecade [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 31.579 | p: 27.273 | r: 37.500
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 88.722

[Aggregate metrics]:
rouge1     | fm: 89.809 | p: 89.274 | r: 90.423
rouge2     | fm: 60.657 | p: 60.485 | r: 60.955
rougeL     | fm: 79.400 | p: 78.998 | r: 79.920
rougeLsum  | fm: 79.494 | p: 79.121 | r: 79.981
r1fm+r2fm = 150.466

input #95 time: 0:12:10 | total time: 19:55:07


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9867339341649135
highest_index [0]
highest [0.9867339341649135]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8159618973731995 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8006216287612915 for ['[CLS] at townland panel subjects latter board vidhan tang general honor majestysse spared homes rider [SEP]']
[Init] best rec loss: 0.7923204898834229 for ['[CLS] robinson fits fr home professor shanghai virgin firing inside machlmancize arm decade [SEP]']
[Init] best rec loss: 0.7725931406021118 for ['[CLS] class error portoizedtler riverside 7nsis deedret via protection corporation whether selection [SEP]']
[Init] best rec loss: 0.7618898749351501 for ['[CLS] interviews screwed podcast ？ 8 sunset effects era too oath sunk chief between capcom master [SEP]']
[Init] best rec loss: 0.7466787695884705 for ['[CLS] foreign x universalhausen ant southeast leave brands ascent perpendicular are article holding wrestling capability [SEP]']
[Init] best perm rec loss: 0.7445907592773438 for ['[CLS] are southeast universal foreign capability ant ascent leave wrestling article holding brands xhausen perpendicular [SEP]']
[Init] best perm rec loss: 0.7439436912536621 for ['[CLS] ascent universal foreign ant wrestling southeast leave holding x capability article perpendicular brandshausen are [SEP]']
[Init] best perm rec loss: 0.7424782514572144 for ['[CLS] x perpendicular leave are foreign brands articlehausen southeast holding wrestling universal ant capability ascent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.491 (perp=10.690, rec=0.308, cos=0.045), tot_loss_proj:3.623 [t=0.30s]
prediction: ['[CLS] people took people meant earliest people forces his situations to force gradyforce holder into [SEP]']
[ 100/2000] tot_loss=2.104 (perp=9.256, rec=0.223, cos=0.030), tot_loss_proj:3.655 [t=0.31s]
prediction: ['[CLS] people make men once lesser situations and his forces on force himself run cover into [SEP]']
[ 150/2000] tot_loss=2.187 (perp=10.087, rec=0.142, cos=0.029), tot_loss_proj:3.317 [t=0.31s]
prediction: ['[CLS] people make men ways lesser situations and himself forces on force himself run cover on [SEP]']
[ 200/2000] tot_loss=2.168 (perp=10.210, rec=0.099, cos=0.027), tot_loss_proj:3.729 [t=0.31s]
prediction: ['[CLS] people make men wanted lesser situations that himself situations on force himself run cover into [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.014 (perp=9.268, rec=0.131, cos=0.029), tot_loss_proj:3.208 [t=0.31s]
prediction: ['[CLS] people make men wants lesser situations that forces on himself force himself run cover and [SEP]']
[ 300/2000] tot_loss=1.960 (perp=9.167, rec=0.101, cos=0.026), tot_loss_proj:3.291 [t=0.31s]
prediction: ['[CLS] people make men for lesser situations would into on himself force himself run cover and [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.773 (perp=8.253, rec=0.096, cos=0.026), tot_loss_proj:3.113 [t=0.31s]
prediction: ['[CLS] people make men for lesser situations would on himself force himself into run cover and [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.783 (perp=8.012, rec=0.151, cos=0.030), tot_loss_proj:2.834 [t=0.31s]
prediction: ['[CLS] people would make men not lesser situations on himself force himself into run cover and [SEP]']
[ 450/2000] tot_loss=1.927 (perp=8.995, rec=0.102, cos=0.026), tot_loss_proj:3.354 [t=0.31s]
prediction: ['[CLS] people would make men anywhere lesser situations on himself force himself into run cover and [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.847 (perp=8.627, rec=0.095, cos=0.026), tot_loss_proj:3.150 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on himself force himself anyone run cover and [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.799 (perp=8.224, rec=0.126, cos=0.028), tot_loss_proj:3.059 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on himself force himself run anyone cover and [SEP]']
[ 600/2000] tot_loss=1.813 (perp=8.476, rec=0.092, cos=0.026), tot_loss_proj:3.185 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on himself force himself run anywhere cover and [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.665 (perp=7.736, rec=0.092, cos=0.026), tot_loss_proj:3.034 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on himself force himself and run could cover [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.628 (perp=7.558, rec=0.090, cos=0.026), tot_loss_proj:3.098 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on himself force himself and could run cover [SEP]']
[ 750/2000] tot_loss=1.629 (perp=7.558, rec=0.091, cos=0.026), tot_loss_proj:3.092 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on himself force himself and could run cover [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.756 (perp=8.178, rec=0.094, cos=0.026), tot_loss_proj:3.301 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on force himself and conditions run cover himself [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.550 (perp=7.191, rec=0.086, cos=0.026), tot_loss_proj:3.201 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on force for himself and run cover himself [SEP]']
[ 900/2000] tot_loss=1.699 (perp=7.946, rec=0.083, cos=0.026), tot_loss_proj:3.239 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on force could himself and run cover himself [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.559 (perp=7.199, rec=0.093, cos=0.026), tot_loss_proj:3.224 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on force and himself could run cover himself [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.544 (perp=7.208, rec=0.076, cos=0.026), tot_loss_proj:3.196 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on force and could himself run cover himself [SEP]']
[1050/2000] tot_loss=1.563 (perp=7.208, rec=0.095, cos=0.026), tot_loss_proj:3.199 [t=0.31s]
prediction: ['[CLS] people would make men into lesser situations on force and could himself run cover himself [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.514 (perp=7.034, rec=0.081, cos=0.026), tot_loss_proj:3.154 [t=0.31s]
prediction: ['[CLS] people could make men into lesser situations on force and would himself run cover himself [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.503 (perp=7.019, rec=0.073, cos=0.026), tot_loss_proj:3.232 [t=0.31s]
prediction: ['[CLS] people could make men into lesser situations on force and himself would run cover himself [SEP]']
[1200/2000] tot_loss=1.500 (perp=7.019, rec=0.070, cos=0.026), tot_loss_proj:3.224 [t=0.31s]
prediction: ['[CLS] people could make men into lesser situations on force and himself would run cover himself [SEP]']
Attempt swap
[1250/2000] tot_loss=1.510 (perp=7.019, rec=0.080, cos=0.026), tot_loss_proj:3.229 [t=0.31s]
prediction: ['[CLS] people could make men into lesser situations on force and himself would run cover himself [SEP]']
Attempt swap
[1300/2000] tot_loss=1.519 (perp=7.019, rec=0.089, cos=0.026), tot_loss_proj:3.229 [t=0.31s]
prediction: ['[CLS] people could make men into lesser situations on force and himself would run cover himself [SEP]']
[1350/2000] tot_loss=1.727 (perp=8.103, rec=0.080, cos=0.026), tot_loss_proj:3.488 [t=0.31s]
prediction: ['[CLS] people otherwise make men into lesser situations on force and himself would run cover himself [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.738 (perp=8.187, rec=0.075, cos=0.026), tot_loss_proj:3.428 [t=0.31s]
prediction: ['[CLS] people himself make men into lesser situations on force and such would run cover himself [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.684 (perp=7.880, rec=0.082, cos=0.026), tot_loss_proj:3.102 [t=0.31s]
prediction: ['[CLS] would himself make men into lesser situations on force and such people run cover himself [SEP]']
[1500/2000] tot_loss=1.668 (perp=7.839, rec=0.074, cos=0.026), tot_loss_proj:2.943 [t=0.31s]
prediction: ['[CLS] would himself make men into lesser situations on force and could people run cover himself [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.863 (perp=8.750, rec=0.086, cos=0.026), tot_loss_proj:3.348 [t=0.31s]
prediction: ['[CLS] would himself make men into lesser situations on force and people such run cover himself [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.677 (perp=7.880, rec=0.075, cos=0.026), tot_loss_proj:3.103 [t=0.31s]
prediction: ['[CLS] would himself make men into lesser situations on force and such people run cover himself [SEP]']
[1650/2000] tot_loss=1.683 (perp=7.880, rec=0.081, cos=0.026), tot_loss_proj:3.103 [t=0.31s]
prediction: ['[CLS] would himself make men into lesser situations on force and such people run cover himself [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.661 (perp=7.755, rec=0.083, cos=0.026), tot_loss_proj:3.112 [t=0.31s]
prediction: ['[CLS] himself would make men into lesser situations on force and such people run cover himself [SEP]']
Attempt swap
[1750/2000] tot_loss=1.670 (perp=7.755, rec=0.092, cos=0.026), tot_loss_proj:3.115 [t=0.31s]
prediction: ['[CLS] himself would make men into lesser situations on force and such people run cover himself [SEP]']
[1800/2000] tot_loss=1.660 (perp=7.755, rec=0.082, cos=0.026), tot_loss_proj:3.112 [t=0.31s]
prediction: ['[CLS] himself would make men into lesser situations on force and such people run cover himself [SEP]']
Attempt swap
[1850/2000] tot_loss=1.659 (perp=7.755, rec=0.082, cos=0.026), tot_loss_proj:3.110 [t=0.31s]
prediction: ['[CLS] himself would make men into lesser situations on force and such people run cover himself [SEP]']
Attempt swap
[1900/2000] tot_loss=1.655 (perp=7.755, rec=0.078, cos=0.026), tot_loss_proj:3.113 [t=0.31s]
prediction: ['[CLS] himself would make men into lesser situations on force and such people run cover himself [SEP]']
[1950/2000] tot_loss=1.656 (perp=7.755, rec=0.079, cos=0.026), tot_loss_proj:3.112 [t=0.31s]
prediction: ['[CLS] himself would make men into lesser situations on force and such people run cover himself [SEP]']
Attempt swap
[2000/2000] tot_loss=1.647 (perp=7.755, rec=0.069, cos=0.026), tot_loss_proj:3.113 [t=0.31s]
prediction: ['[CLS] himself would make men into lesser situations on force and such people run cover himself [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] people could make men into lesser situations on force and himself would run cover himself [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.235 | p: 88.235 | r: 88.235
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.059 | p: 47.059 | r: 47.059
rougeLsum  | fm: 47.059 | p: 47.059 | r: 47.059
r1fm+r2fm = 88.235

[Aggregate metrics]:
rouge1     | fm: 89.788 | p: 89.298 | r: 90.450
rouge2     | fm: 60.049 | p: 59.837 | r: 60.332
rougeL     | fm: 79.233 | p: 78.856 | r: 79.720
rougeLsum  | fm: 79.103 | p: 78.755 | r: 79.637
r1fm+r2fm = 149.837

input #96 time: 0:12:10 | total time: 20:07:17


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9875911052325086
highest_index [0]
highest [0.9875911052325086]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.7337725162506104 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.714375913143158 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best perm rec loss: 0.7118166089057922 for ['[CLS] victoriaten test pass 2016 which [SEP]']
[Init] best perm rec loss: 0.7093698978424072 for ['[CLS] 2016 test victoriaten which pass [SEP]']
[Init] best perm rec loss: 0.7083690762519836 for ['[CLS] which victoria 2016 pass testten [SEP]']
[Init] best perm rec loss: 0.7071503400802612 for ['[CLS] which victoria 2016 test passten [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.262 (perp=9.630, rec=0.284, cos=0.052), tot_loss_proj:3.613 [t=0.34s]
prediction: ['[CLS] un audience forevergettable characters [SEP]']
[ 100/2000] tot_loss=1.924 (perp=8.690, rec=0.155, cos=0.031), tot_loss_proj:2.657 [t=0.35s]
prediction: ['[CLS] unfor forevergettable characters [SEP]']
[ 150/2000] tot_loss=2.392 (perp=11.184, rec=0.128, cos=0.027), tot_loss_proj:3.135 [t=0.35s]
prediction: ['[CLS]forfor touchgettable characters [SEP]']
[ 200/2000] tot_loss=2.378 (perp=11.184, rec=0.117, cos=0.024), tot_loss_proj:3.143 [t=0.35s]
prediction: ['[CLS]forfor touchgettable characters [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.472 (perp=6.676, rec=0.113, cos=0.024), tot_loss_proj:1.792 [t=0.35s]
prediction: ['[CLS] touch unforgettable characters [SEP]']
[ 300/2000] tot_loss=1.461 (perp=6.676, rec=0.101, cos=0.025), tot_loss_proj:1.792 [t=0.35s]
prediction: ['[CLS] touch unforgettable characters [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.452 (perp=6.676, rec=0.091, cos=0.026), tot_loss_proj:1.797 [t=0.35s]
prediction: ['[CLS] touch unforgettable characters [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.449 (perp=6.676, rec=0.090, cos=0.025), tot_loss_proj:1.802 [t=0.35s]
prediction: ['[CLS] touch unforgettable characters [SEP]']
[ 450/2000] tot_loss=1.440 (perp=6.676, rec=0.080, cos=0.025), tot_loss_proj:1.808 [t=0.35s]
prediction: ['[CLS] touch unforgettable characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.141 (perp=5.309, rec=0.054, cos=0.025), tot_loss_proj:1.160 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.153 (perp=5.309, rec=0.067, cos=0.025), tot_loss_proj:1.150 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 600/2000] tot_loss=1.156 (perp=5.309, rec=0.070, cos=0.025), tot_loss_proj:1.154 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.149 (perp=5.309, rec=0.062, cos=0.025), tot_loss_proj:1.151 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.144 (perp=5.309, rec=0.058, cos=0.025), tot_loss_proj:1.152 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 750/2000] tot_loss=1.142 (perp=5.309, rec=0.056, cos=0.025), tot_loss_proj:1.143 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.142 (perp=5.309, rec=0.056, cos=0.025), tot_loss_proj:1.146 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.145 (perp=5.309, rec=0.058, cos=0.025), tot_loss_proj:1.136 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 900/2000] tot_loss=1.142 (perp=5.309, rec=0.056, cos=0.025), tot_loss_proj:1.153 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.148 (perp=5.309, rec=0.061, cos=0.025), tot_loss_proj:1.149 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.152 (perp=5.309, rec=0.066, cos=0.025), tot_loss_proj:1.148 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1050/2000] tot_loss=1.145 (perp=5.309, rec=0.058, cos=0.025), tot_loss_proj:1.146 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.143 (perp=5.309, rec=0.056, cos=0.025), tot_loss_proj:1.153 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.137 (perp=5.309, rec=0.050, cos=0.025), tot_loss_proj:1.160 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1200/2000] tot_loss=1.147 (perp=5.309, rec=0.061, cos=0.025), tot_loss_proj:1.147 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.143 (perp=5.309, rec=0.057, cos=0.025), tot_loss_proj:1.150 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.153 (perp=5.309, rec=0.067, cos=0.025), tot_loss_proj:1.141 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1350/2000] tot_loss=1.157 (perp=5.309, rec=0.070, cos=0.025), tot_loss_proj:1.150 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.157 (perp=5.309, rec=0.071, cos=0.025), tot_loss_proj:1.164 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.154 (perp=5.309, rec=0.068, cos=0.025), tot_loss_proj:1.153 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1500/2000] tot_loss=1.155 (perp=5.309, rec=0.069, cos=0.025), tot_loss_proj:1.148 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.148 (perp=5.309, rec=0.061, cos=0.025), tot_loss_proj:1.145 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.141 (perp=5.309, rec=0.055, cos=0.025), tot_loss_proj:1.146 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1650/2000] tot_loss=1.148 (perp=5.309, rec=0.061, cos=0.025), tot_loss_proj:1.141 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.148 (perp=5.309, rec=0.061, cos=0.025), tot_loss_proj:1.152 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.148 (perp=5.309, rec=0.062, cos=0.025), tot_loss_proj:1.152 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1800/2000] tot_loss=1.149 (perp=5.309, rec=0.063, cos=0.025), tot_loss_proj:1.148 [t=0.35s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.142 (perp=5.309, rec=0.055, cos=0.025), tot_loss_proj:1.153 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.136 (perp=5.309, rec=0.050, cos=0.025), tot_loss_proj:1.141 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1950/2000] tot_loss=1.155 (perp=5.309, rec=0.068, cos=0.025), tot_loss_proj:1.145 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.146 (perp=5.309, rec=0.059, cos=0.025), tot_loss_proj:1.138 [t=0.30s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.836 | p: 89.366 | r: 90.510
rouge2     | fm: 60.552 | p: 60.363 | r: 60.830
rougeL     | fm: 79.386 | p: 78.978 | r: 79.901
rougeLsum  | fm: 79.374 | p: 79.002 | r: 79.857
r1fm+r2fm = 150.388

input #97 time: 0:13:42 | total time: 20:21:00


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9855701460846542
highest_index [0]
highest [0.9855701460846542]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.6604750156402588 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.6558906435966492 for ['[CLS] jed nos prohibited ada [SEP]']
[Init] best perm rec loss: 0.6542859673500061 for ['[CLS] ada prohibited nos jed [SEP]']
[Init] best perm rec loss: 0.650501549243927 for ['[CLS] prohibited nos jed ada [SEP]']
[Init] best perm rec loss: 0.6487595438957214 for ['[CLS] nos ada prohibited jed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.652 (perp=12.188, rec=0.185, cos=0.029), tot_loss_proj:3.047 [t=0.35s]
prediction: ['[CLS] unful investmentlling [SEP]']
[ 100/2000] tot_loss=1.084 (perp=4.948, rec=0.066, cos=0.028), tot_loss_proj:1.093 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 150/2000] tot_loss=1.079 (perp=4.948, rec=0.061, cos=0.029), tot_loss_proj:1.098 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 200/2000] tot_loss=1.071 (perp=4.948, rec=0.054, cos=0.027), tot_loss_proj:1.090 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.081 (perp=4.948, rec=0.064, cos=0.028), tot_loss_proj:1.089 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.083 (perp=4.948, rec=0.065, cos=0.029), tot_loss_proj:1.088 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.060 (perp=4.948, rec=0.042, cos=0.028), tot_loss_proj:1.084 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.071 (perp=4.948, rec=0.053, cos=0.028), tot_loss_proj:1.102 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.088 (perp=4.948, rec=0.071, cos=0.028), tot_loss_proj:1.085 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.076 (perp=4.948, rec=0.058, cos=0.028), tot_loss_proj:1.075 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.081 (perp=4.948, rec=0.063, cos=0.029), tot_loss_proj:1.097 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.079 (perp=4.948, rec=0.061, cos=0.028), tot_loss_proj:1.084 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.076 (perp=4.948, rec=0.058, cos=0.029), tot_loss_proj:1.088 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.068 (perp=4.948, rec=0.050, cos=0.029), tot_loss_proj:1.084 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.070 (perp=4.948, rec=0.052, cos=0.028), tot_loss_proj:1.085 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.067 (perp=4.948, rec=0.050, cos=0.028), tot_loss_proj:1.092 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.076 (perp=4.948, rec=0.058, cos=0.028), tot_loss_proj:1.078 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.080 (perp=4.948, rec=0.062, cos=0.029), tot_loss_proj:1.087 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.077 (perp=4.948, rec=0.059, cos=0.029), tot_loss_proj:1.079 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.074 (perp=4.948, rec=0.056, cos=0.029), tot_loss_proj:1.076 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.079 (perp=4.948, rec=0.061, cos=0.029), tot_loss_proj:1.082 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.079 (perp=4.948, rec=0.061, cos=0.029), tot_loss_proj:1.083 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.084 (perp=4.948, rec=0.066, cos=0.028), tot_loss_proj:1.075 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.090 (perp=4.948, rec=0.072, cos=0.028), tot_loss_proj:1.090 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.085 (perp=4.948, rec=0.067, cos=0.028), tot_loss_proj:1.079 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.072 (perp=4.948, rec=0.054, cos=0.029), tot_loss_proj:1.090 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.071 (perp=4.948, rec=0.052, cos=0.029), tot_loss_proj:1.091 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.075 (perp=4.948, rec=0.057, cos=0.029), tot_loss_proj:1.073 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.088 (perp=4.948, rec=0.070, cos=0.029), tot_loss_proj:1.091 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.088 (perp=4.948, rec=0.070, cos=0.029), tot_loss_proj:1.082 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.076 (perp=4.948, rec=0.058, cos=0.029), tot_loss_proj:1.080 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.069 (perp=4.948, rec=0.050, cos=0.029), tot_loss_proj:1.085 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.082 (perp=4.948, rec=0.064, cos=0.029), tot_loss_proj:1.077 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.072 (perp=4.948, rec=0.054, cos=0.029), tot_loss_proj:1.086 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.084 (perp=4.948, rec=0.066, cos=0.029), tot_loss_proj:1.089 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.094 (perp=4.948, rec=0.076, cos=0.029), tot_loss_proj:1.080 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.080 (perp=4.948, rec=0.061, cos=0.029), tot_loss_proj:1.083 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.075 (perp=4.948, rec=0.057, cos=0.029), tot_loss_proj:1.086 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.091 (perp=4.948, rec=0.073, cos=0.029), tot_loss_proj:1.087 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.074 (perp=4.948, rec=0.055, cos=0.029), tot_loss_proj:1.070 [t=0.35s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.005 | p: 89.505 | r: 90.646
rouge2     | fm: 60.873 | p: 60.680 | r: 61.133
rougeL     | fm: 79.572 | p: 79.234 | r: 80.098
rougeLsum  | fm: 79.665 | p: 79.245 | r: 80.103
r1fm+r2fm = 150.878

input #98 time: 0:13:55 | total time: 20:34:55


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.9857697125801659
highest_index [0]
highest [0.9857697125801659]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8047320246696472 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.7938224077224731 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.7919524908065796 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.7576727867126465 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.7498134970664978 for ['[CLS] imp then ratlogueathy mobile bun smoothe bran where heart thumbs principal aires & recently brig addison stands catalog alert abbottale leading switch as could which buy pony kid risk general spreadim [SEP]']
[Init] best rec loss: 0.7462864518165588 for ['[CLS] wat searched fits mckay german divide interpret sensory ajax from even during under skye pants ramlus except door wanted others same q same king ashton care lot confirmation buttonsmania caseston file evil absolute [SEP]']
[Init] best rec loss: 0.7357403635978699 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.7350647449493408 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.7327669858932495 for ['[CLS] rightte when claire currently services [MASK] thunder distance synonym taste ferns barbie actually still te harper himselfˈ opposed earliest bet forced dentalagingts knowledge ratings bearing slight screens cushion orient garcia temps re [SEP]']
[Init] best perm rec loss: 0.7321861982345581 for ['[CLS] [MASK] opposedaging rightte synonym services currently earliest dental himself tets ferns cushionˈ slight orient distance thunder barbie still knowledge harper temps garcia actually when bearing bet re forced ratings screens taste claire [SEP]']
[Init] best perm rec loss: 0.7317646741867065 for ['[CLS] screens ratings thunder synonym opposed taste garciate himself distance right dental earliest [MASK]ˈ te still when slight claire forced temps services barbiets reaging ferns knowledge orient harper cushion bearing currently actually bet [SEP]']
[Init] best perm rec loss: 0.7304320335388184 for ['[CLS] temps when forced claire opposed harperˈ actually himself ratings bearingts currently ferns services screens re garciaaging right earliest slight orient cushion dental barbie synonym knowledge te still distance [MASK]te thunder taste bet [SEP]']
[Init] best perm rec loss: 0.7295078039169312 for ['[CLS]ˈ te [MASK]aging himselfts bearing garcia distance currently services orient taste claire dental temps opposed still synonym thunder ratings whente ferns bet barbie cushion right screens knowledge harper earliest forced actually re slight [SEP]']
[Init] best perm rec loss: 0.7287164330482483 for ['[CLS] ferns slight ratings cushion forced re bearing orient garciaˈ tempste whenaging earliest actually [MASK] dental screens knowledge himself opposed still claire distance te bet harper currently rightts synonym barbie services thunder taste [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.682 (perp=11.548, rec=0.334, cos=0.038), tot_loss_proj:3.416 [t=0.30s]
prediction: ["[CLS] auschwitz weeks mess aass program paid fun this fighting di only gin fight'mitchtion di - a grammy cerambycidae no letter scare film certificate put 'n funssing funssing checked, [SEP]"]
[ 100/2000] tot_loss=2.545 (perp=10.971, rec=0.311, cos=0.040), tot_loss_proj:3.336 [t=0.31s]
prediction: ['[CLS]ism applause effort saved piece film asking fun some? to a sick very antub " di had di guys ª but "禾 film occupation. di " butssing funssing mps ، [SEP]']
[ 150/2000] tot_loss=2.291 (perp=10.022, rec=0.253, cos=0.034), tot_loss_proj:2.904 [t=0.31s]
prediction: ['[CLS]bered ¨ terrible community on film ticket fun the talking paid theann of 訁 crazy\'di had of the widow but " ף film $. di " butssing funssing things, [SEP]']
[ 200/2000] tot_loss=2.217 (perp=9.881, rec=0.213, cos=0.028), tot_loss_proj:3.020 [t=0.31s]
prediction: ['[CLS] walked : terrible make\'film ticket fun the muttering camped the ` of any\'\' di had of thessing but "禾 film $. di " youssing funssing guys, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.120 (perp=9.484, rec=0.195, cos=0.028), tot_loss_proj:2.697 [t=0.31s]
prediction: ['[CLS] walked the terrible so bit film ticket fun the muttering thee.\'of any `\'letting had of the horrible but di禾 film $. di " youssing funssing guys ticket [SEP]']
[ 300/2000] tot_loss=2.229 (perp=10.035, rec=0.192, cos=0.030), tot_loss_proj:2.929 [t=0.31s]
prediction: ['[CLS] walked the terrible so speaking film ticket fun the muttering thee, ` of any `\'letting had of the horrible but di禾 film $ that di " they mind funssing things ticket [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.101 (perp=9.559, rec=0.160, cos=0.029), tot_loss_proj:2.703 [t=0.31s]
prediction: ['[CLS] so walked the terrible ` films cost fun the muttering thee di `\'any `\'letting had of the horrible but dititled film $ that di " they mind funssing things ticket [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.052 (perp=9.212, rec=0.177, cos=0.032), tot_loss_proj:2.685 [t=0.31s]
prediction: ['[CLS] so walked the terrible daddy films cost fun had muttering thee di `\'any n\'asking\'of the horrible but dititled film $ that di " they mind funssing they ticket [SEP]']
[ 450/2000] tot_loss=2.005 (perp=9.180, rec=0.142, cos=0.026), tot_loss_proj:2.685 [t=0.31s]
prediction: ['[CLS] so walked the terrible ` words cost fun had muttering\'di `\'any n\'ssing\'\' the horrible but dititled film $ that di " did mind funssing theyfiltration [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.928 (perp=8.847, rec=0.132, cos=0.027), tot_loss_proj:2.522 [t=0.31s]
prediction: ['[CLS] so walked the terrible ` words cost fun had muttering\'di `\'much n\'"\'\' the horrible but dititled film $ that dissing did mind funssing theyfiltration [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.862 (perp=8.577, rec=0.119, cos=0.028), tot_loss_proj:2.495 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words cost fun had muttering\'\' `\'much n\'`\'\' the horrible but dititled film $ that dissing did mind funssing theyfiltration [SEP]']
[ 600/2000] tot_loss=1.868 (perp=8.577, rec=0.125, cos=0.027), tot_loss_proj:2.495 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words cost fun had muttering\'\' `\'much n\'`\'\' the horrible but dititled film $ that dissing did mind funssing theyfiltration [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.872 (perp=8.628, rec=0.119, cos=0.027), tot_loss_proj:2.668 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words cost fun had muttering\'\' `\'much fun\'`\'\' thessing but dititled film $ that dissing did mind nssing they ticket [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.865 (perp=8.634, rec=0.110, cos=0.028), tot_loss_proj:2.570 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words cost fun had muttering\'\' ` like much fun\'` dollars\'thessing but dititled film\'that dissing t mind nssing they ticket [SEP]']
[ 750/2000] tot_loss=1.863 (perp=8.634, rec=0.107, cos=0.029), tot_loss_proj:2.572 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words cost fun had muttering\'\' ` like much fun\'` dollars\'thessing but dititled film\'that dissing t mind nssing they ticket [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.870 (perp=8.660, rec=0.111, cos=0.027), tot_loss_proj:2.483 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words\'fun had muttering cost\'` like much fun\'` dollars\'thessing but di ` film\'that dissing t mind nssing they ticket [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.842 (perp=8.535, rec=0.107, cos=0.028), tot_loss_proj:2.448 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words the fun had muttering cost\'` like the much fun\'` n\'ssing but di ` film\'that dissing t mind nssing they ticket [SEP]']
[ 900/2000] tot_loss=1.835 (perp=8.535, rec=0.101, cos=0.028), tot_loss_proj:2.451 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words the fun had muttering cost\'` like the much fun\'` n\'ssing but di ` film\'that dissing t mind nssing they ticket [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.804 (perp=8.370, rec=0.102, cos=0.028), tot_loss_proj:2.444 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words the fun had muttering cost\'` like the much fun\'` ` n\'ssing but di film\'that dissing t mind nssing they ticket [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.760 (perp=8.102, rec=0.112, cos=0.028), tot_loss_proj:2.299 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words the fun had muttering cost\'` like the much fun\'` ` n\'but dissing film\'that dissing t mind nssing they ticket [SEP]']
[1050/2000] tot_loss=1.757 (perp=8.102, rec=0.108, cos=0.028), tot_loss_proj:2.298 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words the fun had muttering cost\'` like the much fun\'` ` n\'but dissing film\'that dissing t mind nssing they ticket [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.718 (perp=7.937, rec=0.103, cos=0.028), tot_loss_proj:2.236 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words the fun had muttering cost\'` like the much fun\'` ` n\'but dissing film\'n that dissing t mindssing they ticket [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.740 (perp=8.013, rec=0.109, cos=0.028), tot_loss_proj:2.297 [t=0.31s]
prediction: ['[CLS] so walked, terrible " words the fun had muttering cost\'` like the much fun\'` ` n\'but dissing film\'n that dissing t they mindssing ticket [SEP]']
[1200/2000] tot_loss=1.725 (perp=8.013, rec=0.095, cos=0.028), tot_loss_proj:2.302 [t=0.31s]
prediction: ['[CLS] so walked, terrible " words the fun had muttering cost\'` like the much fun\'` ` n\'but dissing film\'n that dissing t they mindssing ticket [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.699 (perp=7.830, rec=0.105, cos=0.029), tot_loss_proj:2.213 [t=0.31s]
prediction: ['[CLS] so walked the terrible " words the fun had muttering cost\'` like the much fun\'` ` n\'but dissing film\'n that dissing t they mindssing ticket [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.660 (perp=7.655, rec=0.101, cos=0.028), tot_loss_proj:2.222 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like, " much fun\'` ` n\'but dissing film\'n that dissing t they mindssing ticket [SEP]']
[1350/2000] tot_loss=1.657 (perp=7.655, rec=0.098, cos=0.028), tot_loss_proj:2.219 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like, " much fun\'` ` n\'but dissing film\'n that dissing t they mindssing ticket [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.656 (perp=7.638, rec=0.101, cos=0.028), tot_loss_proj:2.212 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like, " much fun\'` ` n\'but dissing filmn\'that dissing t they mindssing ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.650 (perp=7.638, rec=0.095, cos=0.028), tot_loss_proj:2.215 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like, " much fun\'` ` n\'but dissing filmn\'that dissing t they mindssing ticket [SEP]']
[1500/2000] tot_loss=1.657 (perp=7.638, rec=0.102, cos=0.028), tot_loss_proj:2.217 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like, " much fun\'` ` n\'but dissing filmn\'that dissing t they mindssing ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.648 (perp=7.638, rec=0.092, cos=0.028), tot_loss_proj:2.216 [t=0.40s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like, " much fun\'` ` n\'but dissing filmn\'that dissing t they mindssing ticket [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.632 (perp=7.562, rec=0.092, cos=0.027), tot_loss_proj:2.226 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like but, " much fun\'` ` n\'dissing filmn\'that dissing t they mindssing ticket [SEP]']
[1650/2000] tot_loss=1.636 (perp=7.562, rec=0.095, cos=0.028), tot_loss_proj:2.225 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like but, " much fun\'` ` n\'dissing filmn\'that dissing t they mindssing ticket [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.587 (perp=7.302, rec=0.099, cos=0.027), tot_loss_proj:2.156 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like but, " much fun\'` ` n\'dissing film n\'dissing t they mindssing that ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.583 (perp=7.302, rec=0.094, cos=0.028), tot_loss_proj:2.156 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like but, " much fun\'` ` n\'dissing film n\'dissing t they mindssing that ticket [SEP]']
[1800/2000] tot_loss=1.583 (perp=7.302, rec=0.095, cos=0.028), tot_loss_proj:2.149 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like but, " much fun\'` ` n\'dissing film n\'dissing t they mindssing that ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.586 (perp=7.302, rec=0.097, cos=0.028), tot_loss_proj:2.148 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like but, " much fun\'` ` n\'dissing film n\'dissing t they mindssing that ticket [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.574 (perp=7.265, rec=0.093, cos=0.028), tot_loss_proj:2.200 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like, but " much fun\'` ` n\'dissing film n\'dissing t they mindssing that ticket [SEP]']
[1950/2000] tot_loss=1.576 (perp=7.265, rec=0.095, cos=0.028), tot_loss_proj:2.199 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like, but " much fun\'` ` n\'dissing film n\'dissing t they mindssing that ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.580 (perp=7.265, rec=0.099, cos=0.028), tot_loss_proj:2.196 [t=0.31s]
prediction: ['[CLS] so walked the terrible words the fun had muttering cost\'` like, but " much fun\'` ` n\'dissing film n\'dissing t they mindssing that ticket [SEP]']
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] so walked the terrible words the fun had muttering cost'` like, but " much fun'` ` n'dissing film n'dissing t they mindssing that ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.769 | p: 80.769 | r: 80.769
rouge2     | fm: 4.000 | p: 4.000 | r: 4.000
rougeL     | fm: 46.154 | p: 46.154 | r: 46.154
rougeLsum  | fm: 46.154 | p: 46.154 | r: 46.154
r1fm+r2fm = 84.769

[Aggregate metrics]:
rouge1     | fm: 89.898 | p: 89.391 | r: 90.515
rouge2     | fm: 60.482 | p: 60.255 | r: 60.756
rougeL     | fm: 79.218 | p: 78.869 | r: 79.703
rougeLsum  | fm: 79.226 | p: 78.871 | r: 79.716
r1fm+r2fm = 150.380

input #99 time: 0:12:08 | total time: 20:47:04


Average Cosine Similarity: 0.9861335271540308
Done with all.
