


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.03 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 54.28it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9992716374753432
highest_index [0]
highest [0.9992716374753432]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.0017677545547485 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.9434316158294678 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.9404582977294922 for ['[CLS] ronnie huff [SEP]']
[Init] best rec loss: 0.9324178695678711 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.9268800020217896 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.8593006730079651 for ['[CLS] panel officer [SEP]']
[Init] best perm rec loss: 0.8530735373497009 for ['[CLS] officer panel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.437 (perp=11.151, rec=0.192, cos=0.014), tot_loss_proj:2.622 [t=0.23s]
prediction: ['[CLS] disappointed really [SEP]']
[ 100/2000] tot_loss=2.308 (perp=11.087, rec=0.088, cos=0.002), tot_loss_proj:2.537 [t=0.23s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 150/2000] tot_loss=2.275 (perp=11.087, rec=0.056, cos=0.002), tot_loss_proj:2.537 [t=0.23s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 200/2000] tot_loss=2.277 (perp=11.087, rec=0.058, cos=0.001), tot_loss_proj:2.536 [t=0.23s]
prediction: ['[CLS] disappointed slightly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.117 (perp=10.252, rec=0.065, cos=0.002), tot_loss_proj:2.120 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.103 (perp=10.252, rec=0.052, cos=0.001), tot_loss_proj:2.121 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.114 (perp=10.252, rec=0.062, cos=0.001), tot_loss_proj:2.122 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.119 (perp=10.252, rec=0.067, cos=0.001), tot_loss_proj:2.107 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.103 (perp=10.252, rec=0.051, cos=0.001), tot_loss_proj:2.119 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.105 (perp=10.252, rec=0.054, cos=0.001), tot_loss_proj:2.115 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.117 (perp=10.252, rec=0.065, cos=0.001), tot_loss_proj:2.123 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.109 (perp=10.252, rec=0.058, cos=0.001), tot_loss_proj:2.111 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.106 (perp=10.252, rec=0.054, cos=0.001), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.108 (perp=10.252, rec=0.056, cos=0.001), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.115 (perp=10.252, rec=0.063, cos=0.001), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.107 (perp=10.252, rec=0.055, cos=0.001), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.110 (perp=10.252, rec=0.058, cos=0.001), tot_loss_proj:2.117 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.106 (perp=10.252, rec=0.055, cos=0.001), tot_loss_proj:2.113 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.119 (perp=10.252, rec=0.067, cos=0.001), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.099 (perp=10.252, rec=0.047, cos=0.001), tot_loss_proj:2.121 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.106 (perp=10.252, rec=0.054, cos=0.001), tot_loss_proj:2.122 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.130 (perp=10.252, rec=0.078, cos=0.001), tot_loss_proj:2.122 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.116 (perp=10.252, rec=0.065, cos=0.001), tot_loss_proj:2.115 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.109 (perp=10.252, rec=0.057, cos=0.001), tot_loss_proj:2.117 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.113 (perp=10.252, rec=0.061, cos=0.001), tot_loss_proj:2.107 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.117 (perp=10.252, rec=0.065, cos=0.001), tot_loss_proj:2.122 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.122 (perp=10.252, rec=0.071, cos=0.001), tot_loss_proj:2.109 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.113 (perp=10.252, rec=0.061, cos=0.001), tot_loss_proj:2.120 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.105 (perp=10.252, rec=0.053, cos=0.001), tot_loss_proj:2.113 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.106 (perp=10.252, rec=0.054, cos=0.001), tot_loss_proj:2.113 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.115 (perp=10.252, rec=0.063, cos=0.001), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.120 (perp=10.252, rec=0.068, cos=0.001), tot_loss_proj:2.117 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.128 (perp=10.252, rec=0.076, cos=0.001), tot_loss_proj:2.116 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.111 (perp=10.252, rec=0.059, cos=0.001), tot_loss_proj:2.112 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.107 (perp=10.252, rec=0.056, cos=0.001), tot_loss_proj:2.113 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.118 (perp=10.252, rec=0.066, cos=0.001), tot_loss_proj:2.114 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.115 (perp=10.252, rec=0.063, cos=0.001), tot_loss_proj:2.114 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.109 (perp=10.252, rec=0.057, cos=0.001), tot_loss_proj:2.125 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.097 (perp=10.252, rec=0.045, cos=0.001), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.106 (perp=10.252, rec=0.055, cos=0.001), tot_loss_proj:2.128 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:09:31 | total time: 0:09:31


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9993549160877631
highest_index [0]
highest [0.9993549160877631]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.019070029258728 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9784805774688721 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.8989198803901672 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 0.8676603436470032 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8272038102149963 for ['[CLS] passage erupted [SEP]']
[Init] best rec loss: 0.8209529519081116 for ['[CLS] siam presidents [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.391 (perp=10.892, rec=0.210, cos=0.003), tot_loss_proj:2.524 [t=0.21s]
prediction: ['[CLS] wonderful splendid [SEP]']
[ 100/2000] tot_loss=2.278 (perp=10.543, rec=0.168, cos=0.002), tot_loss_proj:2.444 [t=0.22s]
prediction: ['[CLS] splendid splendid [SEP]']
[ 150/2000] tot_loss=2.147 (perp=10.288, rec=0.088, cos=0.001), tot_loss_proj:2.344 [t=0.23s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.130 (perp=10.288, rec=0.071, cos=0.001), tot_loss_proj:2.348 [t=0.23s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.887 (perp=9.171, rec=0.052, cos=0.001), tot_loss_proj:1.899 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.884 (perp=9.171, rec=0.049, cos=0.001), tot_loss_proj:1.899 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.893 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.885 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.901 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.890 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.903 (perp=9.171, rec=0.068, cos=0.001), tot_loss_proj:1.911 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.896 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.894 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.907 (perp=9.171, rec=0.071, cos=0.001), tot_loss_proj:1.919 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.902 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.891 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.897 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.894 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.887 (perp=9.171, rec=0.051, cos=0.001), tot_loss_proj:1.904 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.899 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.898 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.897 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.900 (perp=9.171, rec=0.065, cos=0.001), tot_loss_proj:1.894 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.893 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.887 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.888 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.899 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.887 (perp=9.171, rec=0.051, cos=0.001), tot_loss_proj:1.883 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.905 (perp=9.171, rec=0.070, cos=0.001), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.900 (perp=9.171, rec=0.065, cos=0.001), tot_loss_proj:1.906 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.892 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.894 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.903 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.901 (perp=9.171, rec=0.065, cos=0.001), tot_loss_proj:1.899 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.892 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.901 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.001), tot_loss_proj:1.905 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.892 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.895 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.907 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.896 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.881 (perp=9.171, rec=0.045, cos=0.001), tot_loss_proj:1.897 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.891 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.906 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.888 (perp=9.171, rec=0.052, cos=0.001), tot_loss_proj:1.896 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.905 (perp=9.171, rec=0.070, cos=0.001), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.901 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.904 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.900 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.885 (perp=9.171, rec=0.050, cos=0.001), tot_loss_proj:1.894 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.902 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.897 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.900 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:09:29 | total time: 0:19:01


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9994334295644651
highest_index [0]
highest [0.9994334295644651]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.8400301933288574 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 0.8265790939331055 for ['[CLS] otherwise [SEP]b [SEP]']
[Init] best rec loss: 0.8116205930709839 for ['[CLS] dailypol food [SEP]']
[Init] best rec loss: 0.8050260543823242 for ['[CLS] just percussion universal [SEP]']
[Init] best rec loss: 0.7912572026252747 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 0.7776637077331543 for ['[CLS] we would working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.080 (perp=8.842, rec=0.290, cos=0.021), tot_loss_proj:2.232 [t=0.23s]
prediction: ['[CLS] gaining its momentum [SEP]']
[ 100/2000] tot_loss=1.841 (perp=8.515, rec=0.135, cos=0.002), tot_loss_proj:1.814 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/2000] tot_loss=1.783 (perp=8.515, rec=0.079, cos=0.002), tot_loss_proj:1.813 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 200/2000] tot_loss=1.779 (perp=8.515, rec=0.075, cos=0.001), tot_loss_proj:1.805 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.775 (perp=8.515, rec=0.071, cos=0.001), tot_loss_proj:1.796 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.802 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.762 (perp=8.515, rec=0.058, cos=0.001), tot_loss_proj:1.805 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.773 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.798 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=1.778 (perp=8.515, rec=0.074, cos=0.001), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.769 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.795 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.792 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.786 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.798 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.784 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.808 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.808 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.762 (perp=8.515, rec=0.058, cos=0.001), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.807 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.786 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.771 (perp=8.515, rec=0.067, cos=0.001), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=1.775 (perp=8.515, rec=0.071, cos=0.001), tot_loss_proj:1.805 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.790 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.769 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=1.781 (perp=8.515, rec=0.077, cos=0.001), tot_loss_proj:1.792 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.794 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.769 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.797 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=1.776 (perp=8.515, rec=0.072, cos=0.001), tot_loss_proj:1.801 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.798 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.795 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.797 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.792 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.766 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.806 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:09:26 | total time: 0:28:27


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.999300207712396
highest_index [0]
highest [0.999300207712396]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.0158096551895142 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9032942652702332 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8778855204582214 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8744809627532959 for ['[CLS] role bart [SEP]']
[Init] best rec loss: 0.8518046140670776 for ['[CLS] gallons professor [SEP]']
[Init] best rec loss: 0.8455400466918945 for ['[CLS] canterbury havoc [SEP]']
[Init] best rec loss: 0.8341601490974426 for ['[CLS] anthony robin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.263 (perp=10.224, rec=0.214, cos=0.004), tot_loss_proj:2.372 [t=0.22s]
prediction: ['[CLS] film flawless [SEP]']
[ 100/2000] tot_loss=2.113 (perp=10.224, rec=0.067, cos=0.001), tot_loss_proj:2.374 [t=0.22s]
prediction: ['[CLS] film flawless [SEP]']
[ 150/2000] tot_loss=2.120 (perp=10.224, rec=0.074, cos=0.001), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] film flawless [SEP]']
[ 200/2000] tot_loss=2.096 (perp=10.224, rec=0.050, cos=0.001), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.771 (perp=8.385, rec=0.091, cos=0.002), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.754 (perp=8.385, rec=0.076, cos=0.001), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.731 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.738 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.724 (perp=8.385, rec=0.045, cos=0.001), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.751 (perp=8.385, rec=0.072, cos=0.001), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.733 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.756 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.734 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.736 (perp=8.385, rec=0.058, cos=0.001), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.730 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.735 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.745 (perp=8.385, rec=0.067, cos=0.001), tot_loss_proj:1.760 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.731 (perp=8.385, rec=0.053, cos=0.001), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.729 (perp=8.385, rec=0.051, cos=0.001), tot_loss_proj:1.760 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.725 (perp=8.385, rec=0.047, cos=0.001), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.735 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.762 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.757 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.736 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.746 (perp=8.385, rec=0.067, cos=0.001), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.765 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.731 (perp=8.385, rec=0.053, cos=0.001), tot_loss_proj:1.756 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.735 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.738 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.735 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.761 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.751 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.765 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.729 (perp=8.385, rec=0.051, cos=0.001), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.744 (perp=8.385, rec=0.066, cos=0.001), tot_loss_proj:1.757 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:08:59 | total time: 0:37:26


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.999229949404915
highest_index [0]
highest [0.999229949404915]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.0350229740142822 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9845936894416809 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9643853306770325 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9641659259796143 for ['[CLS] rally entered worldwide [SEP]']
[Init] best rec loss: 0.9627823233604431 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 0.9362619519233704 for ['[CLS] who table christ [SEP]']
[Init] best rec loss: 0.9233399629592896 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.8893289566040039 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.133 (perp=9.705, rec=0.185, cos=0.007), tot_loss_proj:2.146 [t=0.23s]
prediction: ['[CLS] tiresomently [SEP]']
[ 100/2000] tot_loss=1.596 (perp=7.515, rec=0.091, cos=0.002), tot_loss_proj:1.566 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.587 (perp=7.515, rec=0.082, cos=0.002), tot_loss_proj:1.581 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.571 (perp=7.515, rec=0.067, cos=0.002), tot_loss_proj:1.569 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.566 (perp=7.515, rec=0.061, cos=0.001), tot_loss_proj:1.577 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.570 (perp=7.515, rec=0.065, cos=0.001), tot_loss_proj:1.569 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.566 (perp=7.515, rec=0.062, cos=0.001), tot_loss_proj:1.559 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.561 (perp=7.515, rec=0.057, cos=0.001), tot_loss_proj:1.560 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.566 (perp=7.515, rec=0.061, cos=0.001), tot_loss_proj:1.572 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.563 (perp=7.515, rec=0.058, cos=0.002), tot_loss_proj:1.562 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.575 (perp=7.515, rec=0.071, cos=0.001), tot_loss_proj:1.566 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.569 (perp=7.515, rec=0.065, cos=0.001), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.572 (perp=7.515, rec=0.067, cos=0.002), tot_loss_proj:1.569 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.572 (perp=7.515, rec=0.067, cos=0.002), tot_loss_proj:1.560 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.568 (perp=7.515, rec=0.063, cos=0.002), tot_loss_proj:1.564 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.570 (perp=7.515, rec=0.066, cos=0.002), tot_loss_proj:1.558 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.576 (perp=7.515, rec=0.072, cos=0.001), tot_loss_proj:1.565 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.565 (perp=7.515, rec=0.061, cos=0.002), tot_loss_proj:1.556 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.566 (perp=7.515, rec=0.061, cos=0.002), tot_loss_proj:1.568 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.565 (perp=7.515, rec=0.060, cos=0.002), tot_loss_proj:1.562 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.567 (perp=7.515, rec=0.062, cos=0.002), tot_loss_proj:1.558 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.568 (perp=7.515, rec=0.063, cos=0.002), tot_loss_proj:1.558 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.570 (perp=7.515, rec=0.066, cos=0.002), tot_loss_proj:1.569 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.568 (perp=7.515, rec=0.064, cos=0.002), tot_loss_proj:1.557 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.565 (perp=7.515, rec=0.060, cos=0.002), tot_loss_proj:1.560 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.567 (perp=7.515, rec=0.062, cos=0.002), tot_loss_proj:1.564 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.567 (perp=7.515, rec=0.062, cos=0.002), tot_loss_proj:1.554 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.564 (perp=7.515, rec=0.059, cos=0.002), tot_loss_proj:1.560 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.560 (perp=7.515, rec=0.055, cos=0.002), tot_loss_proj:1.561 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.569 (perp=7.515, rec=0.065, cos=0.002), tot_loss_proj:1.562 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.561 (perp=7.515, rec=0.056, cos=0.002), tot_loss_proj:1.576 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.559 (perp=7.515, rec=0.054, cos=0.002), tot_loss_proj:1.557 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.577 (perp=7.515, rec=0.072, cos=0.002), tot_loss_proj:1.569 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.563 (perp=7.515, rec=0.058, cos=0.002), tot_loss_proj:1.571 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.561 (perp=7.515, rec=0.056, cos=0.002), tot_loss_proj:1.563 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.568 (perp=7.515, rec=0.064, cos=0.002), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.565 (perp=7.515, rec=0.061, cos=0.002), tot_loss_proj:1.566 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.562 (perp=7.515, rec=0.057, cos=0.002), tot_loss_proj:1.557 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.560 (perp=7.515, rec=0.055, cos=0.002), tot_loss_proj:1.562 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.573 (perp=7.515, rec=0.069, cos=0.002), tot_loss_proj:1.563 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:09:33 | total time: 0:47:00


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9993648656803427
highest_index [0]
highest [0.9993648656803427]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9518389701843262 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9517901539802551 for ['[CLS] stay orgasm [SEP]']
[Init] best rec loss: 0.9451121091842651 for ['[CLS] territorial half [SEP]']
[Init] best rec loss: 0.9313843846321106 for ['[CLS] pleasant favorable [SEP]']
[Init] best rec loss: 0.9138829708099365 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 0.8891943693161011 for ['[CLS] quiet. [SEP]']
[Init] best perm rec loss: 0.8871971964836121 for ['[CLS]. quiet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.449 (perp=11.369, rec=0.171, cos=0.004), tot_loss_proj:3.579 [t=0.23s]
prediction: ['[CLS] ease ease [SEP]']
[ 100/2000] tot_loss=2.408 (perp=11.369, rec=0.130, cos=0.004), tot_loss_proj:3.583 [t=0.23s]
prediction: ['[CLS] ease ease [SEP]']
[ 150/2000] tot_loss=2.417 (perp=11.369, rec=0.139, cos=0.003), tot_loss_proj:3.586 [t=0.23s]
prediction: ['[CLS] ease ease [SEP]']
[ 200/2000] tot_loss=2.612 (perp=12.401, rec=0.129, cos=0.003), tot_loss_proj:3.775 [t=0.23s]
prediction: ['[CLS] lumpur ease [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.271 (perp=10.725, rec=0.123, cos=0.004), tot_loss_proj:4.157 [t=0.23s]
prediction: ['[CLS] ease lumpur [SEP]']
[ 300/2000] tot_loss=2.498 (perp=11.854, rec=0.124, cos=0.003), tot_loss_proj:2.563 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.496 (perp=11.854, rec=0.122, cos=0.003), tot_loss_proj:2.571 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.483 (perp=11.854, rec=0.108, cos=0.003), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/2000] tot_loss=2.498 (perp=11.854, rec=0.124, cos=0.003), tot_loss_proj:2.571 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.483 (perp=11.854, rec=0.109, cos=0.003), tot_loss_proj:2.568 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.475 (perp=11.854, rec=0.101, cos=0.003), tot_loss_proj:2.574 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 600/2000] tot_loss=2.488 (perp=11.854, rec=0.114, cos=0.003), tot_loss_proj:2.571 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.488 (perp=11.854, rec=0.114, cos=0.003), tot_loss_proj:2.576 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.483 (perp=11.854, rec=0.109, cos=0.003), tot_loss_proj:2.583 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 750/2000] tot_loss=2.481 (perp=11.854, rec=0.107, cos=0.003), tot_loss_proj:2.571 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.461 (perp=11.854, rec=0.088, cos=0.002), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.446 (perp=11.854, rec=0.074, cos=0.001), tot_loss_proj:2.573 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 900/2000] tot_loss=2.442 (perp=11.854, rec=0.070, cos=0.001), tot_loss_proj:2.568 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.427 (perp=11.854, rec=0.054, cos=0.001), tot_loss_proj:2.582 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1000/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.577 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1050/2000] tot_loss=2.446 (perp=11.854, rec=0.074, cos=0.001), tot_loss_proj:2.568 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1100/2000] tot_loss=2.440 (perp=11.854, rec=0.068, cos=0.001), tot_loss_proj:2.571 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1150/2000] tot_loss=2.433 (perp=11.854, rec=0.061, cos=0.001), tot_loss_proj:2.586 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1200/2000] tot_loss=2.438 (perp=11.854, rec=0.066, cos=0.001), tot_loss_proj:2.579 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1250/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.580 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1300/2000] tot_loss=2.441 (perp=11.854, rec=0.069, cos=0.001), tot_loss_proj:2.567 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1350/2000] tot_loss=2.440 (perp=11.854, rec=0.068, cos=0.001), tot_loss_proj:2.568 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1400/2000] tot_loss=2.438 (perp=11.854, rec=0.066, cos=0.001), tot_loss_proj:2.581 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1450/2000] tot_loss=2.453 (perp=11.854, rec=0.081, cos=0.001), tot_loss_proj:2.569 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1500/2000] tot_loss=2.444 (perp=11.854, rec=0.072, cos=0.001), tot_loss_proj:2.583 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1550/2000] tot_loss=2.431 (perp=11.854, rec=0.059, cos=0.001), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1600/2000] tot_loss=2.418 (perp=11.854, rec=0.045, cos=0.001), tot_loss_proj:2.574 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1650/2000] tot_loss=2.434 (perp=11.854, rec=0.062, cos=0.001), tot_loss_proj:2.582 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1700/2000] tot_loss=2.431 (perp=11.854, rec=0.059, cos=0.001), tot_loss_proj:2.572 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1750/2000] tot_loss=2.440 (perp=11.854, rec=0.067, cos=0.001), tot_loss_proj:2.579 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1800/2000] tot_loss=2.432 (perp=11.854, rec=0.060, cos=0.001), tot_loss_proj:2.569 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1850/2000] tot_loss=2.427 (perp=11.854, rec=0.055, cos=0.001), tot_loss_proj:2.575 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1900/2000] tot_loss=2.422 (perp=11.854, rec=0.050, cos=0.001), tot_loss_proj:2.570 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1950/2000] tot_loss=2.431 (perp=11.854, rec=0.058, cos=0.001), tot_loss_proj:2.573 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[2000/2000] tot_loss=2.434 (perp=11.854, rec=0.062, cos=0.001), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 95.833 | p: 95.833 | r: 95.833
rougeLsum  | fm: 95.833 | p: 95.833 | r: 95.833
r1fm+r2fm = 183.333

input #5 time: 0:09:25 | total time: 0:56:26


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.9992509755027666
highest_index [0]
highest [0.9992509755027666]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9576692581176758 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9543807506561279 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.9314477443695068 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.8687410354614258 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.8670455813407898 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.8099329471588135 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7884305119514465 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.7730320692062378 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 0.7621805667877197 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 0.7525128126144409 for ['[CLS] too u2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.614 (perp=6.812, rec=0.237, cos=0.015), tot_loss_proj:2.710 [t=0.23s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=1.720 (perp=8.088, rec=0.098, cos=0.004), tot_loss_proj:1.685 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.684 (perp=8.088, rec=0.064, cos=0.002), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.678 (perp=8.088, rec=0.059, cos=0.002), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.694 (perp=8.088, rec=0.075, cos=0.002), tot_loss_proj:1.681 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.692 (perp=8.088, rec=0.073, cos=0.001), tot_loss_proj:1.691 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.686 (perp=8.088, rec=0.067, cos=0.002), tot_loss_proj:1.688 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.689 (perp=8.088, rec=0.070, cos=0.002), tot_loss_proj:1.685 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.673 (perp=8.088, rec=0.054, cos=0.001), tot_loss_proj:1.685 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.675 (perp=8.088, rec=0.056, cos=0.001), tot_loss_proj:1.695 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.687 (perp=8.088, rec=0.068, cos=0.001), tot_loss_proj:1.691 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.675 (perp=8.088, rec=0.056, cos=0.001), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.671 (perp=8.088, rec=0.052, cos=0.001), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.678 (perp=8.088, rec=0.059, cos=0.002), tot_loss_proj:1.677 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.681 (perp=8.088, rec=0.062, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.682 (perp=8.088, rec=0.063, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.687 (perp=8.088, rec=0.067, cos=0.001), tot_loss_proj:1.700 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.680 (perp=8.088, rec=0.061, cos=0.001), tot_loss_proj:1.686 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.669 (perp=8.088, rec=0.050, cos=0.001), tot_loss_proj:1.689 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.679 (perp=8.088, rec=0.060, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.688 (perp=8.088, rec=0.069, cos=0.001), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.672 (perp=8.088, rec=0.053, cos=0.001), tot_loss_proj:1.710 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.677 (perp=8.088, rec=0.057, cos=0.001), tot_loss_proj:1.700 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.686 (perp=8.088, rec=0.067, cos=0.001), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.697 (perp=8.088, rec=0.077, cos=0.001), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.678 (perp=8.088, rec=0.059, cos=0.001), tot_loss_proj:1.677 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.679 (perp=8.088, rec=0.060, cos=0.001), tot_loss_proj:1.704 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.687 (perp=8.088, rec=0.068, cos=0.001), tot_loss_proj:1.688 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.676 (perp=8.088, rec=0.057, cos=0.001), tot_loss_proj:1.696 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.693 (perp=8.088, rec=0.074, cos=0.001), tot_loss_proj:1.676 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.689 (perp=8.088, rec=0.070, cos=0.001), tot_loss_proj:1.704 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.676 (perp=8.088, rec=0.056, cos=0.001), tot_loss_proj:1.690 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.679 (perp=8.088, rec=0.060, cos=0.001), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.677 (perp=8.088, rec=0.058, cos=0.001), tot_loss_proj:1.686 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.693 (perp=8.088, rec=0.074, cos=0.001), tot_loss_proj:1.700 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.670 (perp=8.088, rec=0.050, cos=0.001), tot_loss_proj:1.712 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.691 (perp=8.088, rec=0.071, cos=0.001), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.678 (perp=8.088, rec=0.059, cos=0.001), tot_loss_proj:1.702 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.672 (perp=8.088, rec=0.053, cos=0.001), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.690 (perp=8.088, rec=0.071, cos=0.001), tot_loss_proj:1.683 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 96.429 | p: 96.429 | r: 96.429
rougeLsum  | fm: 96.429 | p: 96.429 | r: 96.429
r1fm+r2fm = 185.714

input #6 time: 0:09:34 | total time: 1:06:00


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.99917817891147
highest_index [0]
highest [0.99917817891147]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.9091315269470215 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8410571217536926 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8275896310806274 for ['[CLS] minor bonnetmme near routine cluster confirmed pray mail guy smooth us empty bleeding interior [CLS] relegated seen tapes in beast risk contributingds addedores [SEP]']
[Init] best rec loss: 0.7972196936607361 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best perm rec loss: 0.7952162623405457 for ['[CLS] dependingzed alec disease battalion tourism none consisting sony pacific main moffat animal on manual career classicside mukherjee madagascar 17th blow rannies gold life [SEP]']
[Init] best perm rec loss: 0.7940846085548401 for ['[CLS] classics tourism alec depending gold ran manual pacific nonezed battalion career sony main 17th moffat disease mukherjee madagascar animalide consisting on life blownies [SEP]']
[Init] best perm rec loss: 0.7933159470558167 for ['[CLS] diseasenies life sony manual career moffat depending classics consisting main blow gold 17thide animal mukherjee ran battalion nonezed on alec pacific tourism madagascar [SEP]']
[Init] best perm rec loss: 0.7899006605148315 for ['[CLS] blow mukherjee none battalion moffat dependingzed gold 17th ran consistingnies career manual sony madagascaride disease tourism alec pacific classics animal life main on [SEP]']
[Init] best perm rec loss: 0.7890241742134094 for ['[CLS] madagascar disease main depending mukherjee tourism blownies consisting sony animal gold pacific onzed alec moffat battalion none manual life career classics ranide 17th [SEP]']
[Init] best perm rec loss: 0.7871341705322266 for ['[CLS] on sony diseasenies 17th manualide ran madagascarzed gold animal life mukherjee main battalion none classics moffat tourism career blow alec depending pacific consisting [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.644 (perp=11.380, rec=0.342, cos=0.026), tot_loss_proj:3.194 [t=0.22s]
prediction: ['[CLS] bacterium letterman problem without least john middle cipher information ugly ugly unhappy problem solutions relations issue no consort problems or. military estate. but fraud [SEP]']
[ 100/2000] tot_loss=2.154 (perp=9.331, rec=0.272, cos=0.017), tot_loss_proj:3.415 [t=0.22s]
prediction: ['[CLS] authority nothing problem no goes he middle harbor character no ugly ugly cute no problem has no no problem or. government problem. was fraud [SEP]']
[ 150/2000] tot_loss=2.056 (perp=9.102, rec=0.229, cos=0.007), tot_loss_proj:3.708 [t=0.22s]
prediction: ['[CLS] here nothing problem was is he memorial creatures character no ugly ugly cute you problem is no no problem or. government problem. ;able [SEP]']
[ 200/2000] tot_loss=2.053 (perp=9.234, rec=0.199, cos=0.008), tot_loss_proj:3.708 [t=0.22s]
prediction: ['[CLS] here nothing problem is is he which guarded character no ugly ugly cute you problem is no ; problem or. characters problem. ;able [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.041 (perp=8.891, rec=0.249, cos=0.014), tot_loss_proj:2.964 [t=0.22s]
prediction: ['[CLS] mindarable problem is is he here ® character no ugly ; cute you problem is no ; problem or ugly or character. of? [SEP]']
[ 300/2000] tot_loss=2.061 (perp=9.329, rec=0.189, cos=0.007), tot_loss_proj:3.254 [t=0.22s]
prediction: ['[CLS] ideal varieties problem is is he fairly ® character no ugly ; cute you problem is no ; problem mind ugly or character. of. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.962 (perp=8.928, rec=0.172, cos=0.005), tot_loss_proj:3.436 [t=0.23s]
prediction: ['[CLS] here varieties problem not is he quite ® character no ugly. cute you problem factor no ugly problem mind ; or character. mind. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.818 (perp=8.246, rec=0.165, cos=0.004), tot_loss_proj:3.412 [t=0.22s]
prediction: ['[CLS] cute tiny problem he is not removed spell character no ugly. love you problem factor no ugly problem mind ; or love. mind. [SEP]']
[ 450/2000] tot_loss=1.901 (perp=8.746, rec=0.149, cos=0.003), tot_loss_proj:3.537 [t=0.22s]
prediction: ['[CLS] cute pretty problem he is not fairly spell character no ugly. love i i factor no ugly problem mind ; or love. mind. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.650 (perp=7.549, rec=0.137, cos=0.003), tot_loss_proj:3.322 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. spell character no ugly. love i it factor no ugly factor mind ; or love fairly mind. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.593 (perp=7.221, rec=0.146, cos=0.003), tot_loss_proj:3.271 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. spell character no ugly. i love i factor no ugly i mind ; or love fairly mind. [SEP]']
[ 600/2000] tot_loss=1.579 (perp=7.238, rec=0.129, cos=0.003), tot_loss_proj:3.298 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. spell character no ugly. has love i factor no ugly i mind ; or love fairly mind. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.551 (perp=7.160, rec=0.117, cos=0.002), tot_loss_proj:3.206 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. spell character no ugly. has i love here no ugly i mind ; or love fairly mind. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.492 (perp=6.894, rec=0.111, cos=0.002), tot_loss_proj:3.209 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. spell character no ugly. love has it here no ugly i mind ; or love fairly mind. [SEP]']
[ 750/2000] tot_loss=1.491 (perp=6.894, rec=0.109, cos=0.002), tot_loss_proj:3.209 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. spell character no ugly. love has it here no ugly i mind ; or love fairly mind. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.498 (perp=6.894, rec=0.117, cos=0.002), tot_loss_proj:3.209 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. spell character no ugly. love has it here no ugly i mind ; or love fairly mind. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.554 (perp=7.203, rec=0.111, cos=0.002), tot_loss_proj:3.259 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. ® character no ugly. love has it here no ugly i mind ; or love fairly mind. [SEP]']
[ 900/2000] tot_loss=1.591 (perp=7.427, rec=0.104, cos=0.002), tot_loss_proj:3.328 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. ® character no ugly. love has it here no ugly i mind ; or love fairly the. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.548 (perp=7.192, rec=0.107, cos=0.002), tot_loss_proj:3.293 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. ® character no ugly. love has it here no ugly i mind ; or love the fairly. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.506 (perp=6.971, rec=0.109, cos=0.003), tot_loss_proj:3.264 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. ® character no ugly. love has it here ; no ugly i mind or love the fairly. [SEP]']
[1050/2000] tot_loss=1.505 (perp=6.971, rec=0.109, cos=0.002), tot_loss_proj:3.266 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. ® character no ugly. love has it here ; no ugly i mind or love the fairly. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.505 (perp=6.971, rec=0.109, cos=0.002), tot_loss_proj:3.265 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. ® character no ugly. love has it here ; no ugly i mind or love the fairly. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.480 (perp=6.859, rec=0.106, cos=0.003), tot_loss_proj:3.225 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. no character ® ugly. love has it here ; no ugly i mind or love the fairly. [SEP]']
[1200/2000] tot_loss=1.478 (perp=6.859, rec=0.104, cos=0.002), tot_loss_proj:3.222 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. no character ® ugly. love has it here ; no ugly i mind or love the fairly. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.478 (perp=6.859, rec=0.104, cos=0.002), tot_loss_proj:3.219 [t=0.22s]
prediction: ['[CLS] cute has problem he is not. no character ® ugly. love has it here ; no ugly i mind or love the fairly. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.535 (perp=7.153, rec=0.102, cos=0.002), tot_loss_proj:3.245 [t=0.23s]
prediction: ['[CLS] cute cute problem he is not. no character ® ugly. love has it here ; no ugly i mind or love the fairly. [SEP]']
[1350/2000] tot_loss=1.533 (perp=7.153, rec=0.100, cos=0.002), tot_loss_proj:3.247 [t=0.22s]
prediction: ['[CLS] cute cute problem he is not. no character ® ugly. love has it here ; no ugly i mind or love the fairly. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.427 (perp=6.601, rec=0.104, cos=0.003), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] fairly cute problem he is not. no character ® ugly. love has it here ; no ugly i mind or love the cute. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.401 (perp=6.430, rec=0.112, cos=0.003), tot_loss_proj:3.096 [t=0.22s]
prediction: ['[CLS] fairly cute problem he is not. no ugly character ®. love has it here ; no ugly i mind or love the cute. [SEP]']
[1500/2000] tot_loss=1.387 (perp=6.430, rec=0.099, cos=0.002), tot_loss_proj:3.095 [t=0.22s]
prediction: ['[CLS] fairly cute problem he is not. no ugly character ®. love has it here ; no ugly i mind or love the cute. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.497 (perp=6.942, rec=0.106, cos=0.002), tot_loss_proj:2.954 [t=0.22s]
prediction: ['[CLS] otherwise cute problem he is not. no ugly character ®. love has it here ; no the i mind or love the cute. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.359 (perp=6.269, rec=0.102, cos=0.003), tot_loss_proj:2.891 [t=0.22s]
prediction: ['[CLS] otherwise the problem he is not. no ugly character ®. love has it here ; no cute i mind or love the cute. [SEP]']
[1650/2000] tot_loss=1.408 (perp=6.506, rec=0.104, cos=0.002), tot_loss_proj:2.442 [t=0.22s]
prediction: ['[CLS] otherwise ugly problem he is not. no ugly character ®. love has it here ; no cute i mind or love the cute. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.350 (perp=6.213, rec=0.105, cos=0.002), tot_loss_proj:2.707 [t=0.22s]
prediction: ['[CLS] otherwise the problem. he is not no ugly character ®. love has it here ; no cute i mind or love the cute. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.346 (perp=6.213, rec=0.101, cos=0.002), tot_loss_proj:2.702 [t=0.22s]
prediction: ['[CLS] otherwise the problem. he is not no ugly character ®. love has it here ; no cute i mind or love the cute. [SEP]']
[1800/2000] tot_loss=1.348 (perp=6.213, rec=0.103, cos=0.002), tot_loss_proj:2.709 [t=0.22s]
prediction: ['[CLS] otherwise the problem. he is not no ugly character ®. love has it here ; no cute i mind or love the cute. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.346 (perp=6.213, rec=0.101, cos=0.002), tot_loss_proj:2.707 [t=0.22s]
prediction: ['[CLS] otherwise the problem. he is not no ugly character ®. love has it here ; no cute i mind or love the cute. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.345 (perp=6.213, rec=0.100, cos=0.002), tot_loss_proj:2.707 [t=0.22s]
prediction: ['[CLS] otherwise the problem. he is not no ugly character ®. love has it here ; no cute i mind or love the cute. [SEP]']
[1950/2000] tot_loss=1.351 (perp=6.272, rec=0.094, cos=0.002), tot_loss_proj:2.558 [t=0.22s]
prediction: ['[CLS] otherwise the problem. he is not no ugly character ®. cute has it here ; no cute i mind or love the cute. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.362 (perp=6.272, rec=0.105, cos=0.002), tot_loss_proj:2.563 [t=0.22s]
prediction: ['[CLS] otherwise the problem. he is not no ugly character ®. cute has it here ; no cute i mind or love the cute. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] otherwise the problem. he is not no ugly character ®. cute has it here ; no cute i mind or love the cute. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 78.261 | r: 85.714
rouge2     | fm: 14.286 | p: 13.636 | r: 15.000
rougeL     | fm: 36.364 | p: 34.783 | r: 38.095
rougeLsum  | fm: 36.364 | p: 34.783 | r: 38.095
r1fm+r2fm = 96.104

[Aggregate metrics]:
rouge1     | fm: 97.727 | p: 97.283 | r: 98.214
rouge2     | fm: 76.786 | p: 76.705 | r: 76.875
rougeL     | fm: 88.920 | p: 88.723 | r: 89.137
rougeLsum  | fm: 88.920 | p: 88.723 | r: 89.137
r1fm+r2fm = 174.513

input #7 time: 0:09:13 | total time: 1:15:14


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.999402751418655
highest_index [0]
highest [0.999402751418655]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.752513587474823 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.7108113169670105 for ['[CLS] assassins able a bowled palace times drive camequal happens silver only foreign shelley pumping nbc camp easy payyo bigutounded meaning [SEP]']
[Init] best rec loss: 0.6920523047447205 for ['[CLS]dry pace hash mike parker guard defence disease relief studentquest steiner downdin dance domain briefly crystal beech reason newcastle kai prenostic [SEP]']
[Init] best rec loss: 0.6836101412773132 for ['[CLS] air namely fourjun nkend neitherdf rich ; bit healthcare formula noon abdul drill parks pr daylight longitude tent milo usaas [SEP]']
[Init] best rec loss: 0.674540102481842 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.671164333820343 for ['[CLS] eisenhower plaque arkansas screens sweat adventuremei wanda productey dna prison canontta tail franchise facts res si february season sociallydent badminton [SEP]']
[Init] best perm rec loss: 0.6662924885749817 for ['[CLS]dentey simei sweat franchise arkansas plaque facts canon february product res badminton screens adventuretta socially wanda prison eisenhower season tail dna [SEP]']
[Init] best perm rec loss: 0.6620703935623169 for ['[CLS] tail adventure plaquedent facts badminton arkansas dna season canon product screenseytta wanda franchise sweat february socially si eisenhowermei res prison [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.131 (perp=13.124, rec=0.408, cos=0.099), tot_loss_proj:4.500 [t=0.23s]
prediction: ['[CLS]feit o plate department mostdition vanity perbbledes against stage prep injury victim usual least victimes administrative supply threat rep tax [SEP]']
[ 100/2000] tot_loss=3.062 (perp=13.641, rec=0.304, cos=0.030), tot_loss_proj:4.591 [t=0.24s]
prediction: ['[CLS]feit daless department interventiondition vanity pays presumedes against stage demand injuryfell shows what victime bug reports pulled debt tax [SEP]']
[ 150/2000] tot_loss=2.966 (perp=13.474, rec=0.246, cos=0.026), tot_loss_proj:4.286 [t=0.24s]
prediction: ['[CLS] vanity daless films cesaredition vanity pays doubtes what stage debt debt verge way what victim s national owed pulled debt debt [SEP]']
[ 200/2000] tot_loss=2.902 (perp=13.457, rec=0.199, cos=0.011), tot_loss_proj:4.069 [t=0.24s]
prediction: ['[CLS] vanity frightless film vanity werewolves vanity pays doubt off no stage debt debt verge fact what film s bug owed pulled debt debt [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.756 (perp=12.803, rec=0.176, cos=0.018), tot_loss_proj:3.931 [t=0.24s]
prediction: ['[CLS]less fright vanity filmmaxience vanity pays doubt off no stage debt debt prank fact what film s singular owed pulled debt debt [SEP]']
[ 300/2000] tot_loss=2.776 (perp=13.029, rec=0.155, cos=0.015), tot_loss_proj:3.981 [t=0.24s]
prediction: ['[CLS]ful fright vanity filmmax vanity vanity pays doubt off no stage debt debt pranki what film s benign owed pulled debt debt [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.711 (perp=12.816, rec=0.142, cos=0.005), tot_loss_proj:4.044 [t=0.24s]
prediction: ['[CLS]ful fright fright filmmax debt vanity pays doubt off no stage debt debt prank felt what film s benign owed pulled debt vanity [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.636 (perp=12.502, rec=0.131, cos=0.005), tot_loss_proj:3.937 [t=0.24s]
prediction: ['[CLS]ful fright fright filmmax debt vanity pays doubt off no debt stage debt prank felt what film s benign owed pulled debt _ [SEP]']
[ 450/2000] tot_loss=2.496 (perp=11.846, rec=0.123, cos=0.004), tot_loss_proj:3.858 [t=0.24s]
prediction: ['[CLS]ful fright fright filmmax debt vanity pays doubt off no debt a debt prank felt what film s benign owed pulled debt _ [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.516 (perp=11.975, rec=0.117, cos=0.004), tot_loss_proj:3.810 [t=0.24s]
prediction: ['[CLS]fulmax fright film fright debt vanity pays doubt off no debt a owed prank felt what film s benign owed cruiser debt _ [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.455 (perp=11.680, rec=0.113, cos=0.005), tot_loss_proj:3.779 [t=0.24s]
prediction: ['[CLS]fulmax fright film fright debt vanity pays doubt off no debt a owed prank felt what film s benigni owed debt pradesh [SEP]']
[ 600/2000] tot_loss=2.263 (perp=10.737, rec=0.112, cos=0.003), tot_loss_proj:3.529 [t=0.24s]
prediction: ['[CLS]fulmax fright film fright debt vanity pays doubt off no debt, owed, felt what film s benigni owed debti [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.173 (perp=10.310, rec=0.108, cos=0.003), tot_loss_proj:3.443 [t=0.24s]
prediction: ['[CLS]fulmax fright film fright debt vanity pays doubt off no debt, off, felt what film s debt benigni owedi [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.104 (perp=9.982, rec=0.104, cos=0.003), tot_loss_proj:3.253 [t=0.24s]
prediction: ['[CLS]fulmax fright film fright - vanity pays off no doubt debt, off, felt what film s debt benigni owedi [SEP]']
[ 750/2000] tot_loss=2.090 (perp=9.924, rec=0.103, cos=0.003), tot_loss_proj:3.272 [t=0.24s]
prediction: ['[CLS]fulmax fright film fright, vanity pays off no doubt debt, off, felt what film s debt benigni owedi [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.100 (perp=10.023, rec=0.093, cos=0.002), tot_loss_proj:3.231 [t=0.24s]
prediction: ['[CLS]fulmax fright film fright vanity pays off, no doubt debt, off, felt what mira s debt benigni owedi [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.033 (perp=9.640, rec=0.102, cos=0.003), tot_loss_proj:3.155 [t=0.24s]
prediction: ['[CLS]fulmax fright film fright vanity pays off, no doubt debt, off, what mira s debt benigni owedi felt [SEP]']
[ 900/2000] tot_loss=2.115 (perp=10.111, rec=0.090, cos=0.002), tot_loss_proj:3.211 [t=0.24s]
prediction: ['[CLS]fulmax fright film fright vanity pays that, no doubt debt, off, what mira s debt benigni owedi felt [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.907 (perp=9.067, rec=0.091, cos=0.002), tot_loss_proj:3.006 [t=0.24s]
prediction: ['[CLS]ful s fright film fright vanity pays that, no doubt debt, off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.796 (perp=8.490, rec=0.096, cos=0.003), tot_loss_proj:2.947 [t=0.24s]
prediction: ['[CLS]ful s fright film fright vanity pays that, no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
[1050/2000] tot_loss=1.793 (perp=8.490, rec=0.093, cos=0.002), tot_loss_proj:2.944 [t=0.24s]
prediction: ['[CLS]ful s fright film fright vanity pays that, no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
[1100/2000] tot_loss=1.785 (perp=8.490, rec=0.084, cos=0.002), tot_loss_proj:2.951 [t=0.24s]
prediction: ['[CLS]ful s fright film fright vanity pays that, no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.768 (perp=8.325, rec=0.100, cos=0.003), tot_loss_proj:2.785 [t=0.24s]
prediction: ['[CLS] film s frightful fright vanity pays that, no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
[1200/2000] tot_loss=1.752 (perp=8.325, rec=0.085, cos=0.002), tot_loss_proj:2.786 [t=0.24s]
prediction: ['[CLS] film s frightful fright vanity pays that, no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
[1250/2000] tot_loss=1.758 (perp=8.325, rec=0.090, cos=0.002), tot_loss_proj:2.789 [t=0.24s]
prediction: ['[CLS] film s frightful fright vanity pays that, no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
[1300/2000] tot_loss=1.755 (perp=8.325, rec=0.088, cos=0.002), tot_loss_proj:2.785 [t=0.24s]
prediction: ['[CLS] film s frightful fright vanity pays that, no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
[1350/2000] tot_loss=1.757 (perp=8.325, rec=0.089, cos=0.002), tot_loss_proj:2.782 [t=0.24s]
prediction: ['[CLS] film s frightful fright vanity pays that, no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
[1400/2000] tot_loss=1.822 (perp=8.696, rec=0.080, cos=0.002), tot_loss_proj:2.952 [t=0.24s]
prediction: ['[CLS] film s frightful fright vanity pays that they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.819 (perp=8.650, rec=0.086, cos=0.003), tot_loss_proj:2.925 [t=0.24s]
prediction: ['[CLS] film s fright frightful vanity pays that they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
[1500/2000] tot_loss=1.818 (perp=8.650, rec=0.086, cos=0.002), tot_loss_proj:2.933 [t=0.24s]
prediction: ['[CLS] film s fright frightful vanity pays that they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.772 (perp=8.386, rec=0.092, cos=0.003), tot_loss_proj:2.833 [t=0.24s]
prediction: ['[CLS] film s frightful vanity pays fright that they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.728 (perp=8.182, rec=0.089, cos=0.003), tot_loss_proj:2.794 [t=0.24s]
prediction: ['[CLS] s frightful vanity film pays fright that they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
[1650/2000] tot_loss=1.730 (perp=8.182, rec=0.091, cos=0.003), tot_loss_proj:2.793 [t=0.24s]
prediction: ['[CLS] s frightful vanity film pays fright that they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.711 (perp=8.122, rec=0.084, cos=0.003), tot_loss_proj:2.794 [t=0.24s]
prediction: ['[CLS] s frightful vanity film pays that fright they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
[1750/2000] tot_loss=1.718 (perp=8.122, rec=0.091, cos=0.003), tot_loss_proj:2.793 [t=0.24s]
prediction: ['[CLS] s frightful vanity film pays that fright they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
[1800/2000] tot_loss=1.713 (perp=8.122, rec=0.086, cos=0.002), tot_loss_proj:2.798 [t=0.24s]
prediction: ['[CLS] s frightful vanity film pays that fright they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
[1850/2000] tot_loss=1.707 (perp=8.122, rec=0.080, cos=0.002), tot_loss_proj:2.796 [t=0.24s]
prediction: ['[CLS] s frightful vanity film pays that fright they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
[1900/2000] tot_loss=1.713 (perp=8.122, rec=0.086, cos=0.002), tot_loss_proj:2.795 [t=0.24s]
prediction: ['[CLS] s frightful vanity film pays that fright they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
[1950/2000] tot_loss=1.718 (perp=8.122, rec=0.091, cos=0.002), tot_loss_proj:2.791 [t=0.24s]
prediction: ['[CLS] s frightful vanity film pays that fright they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Attempt swap
[2000/2000] tot_loss=1.710 (perp=8.122, rec=0.083, cos=0.002), tot_loss_proj:2.796 [t=0.24s]
prediction: ['[CLS] s frightful vanity film pays that fright they no doubt, debt off, what miramax debt benigni owedi felt [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] film s frightful fright vanity pays that they no doubt, debt off, what miramax debt benigni owedi felt [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.000 | p: 85.000 | r: 85.000
rouge2     | fm: 10.526 | p: 10.526 | r: 10.526
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 95.526

[Aggregate metrics]:
rouge1     | fm: 96.313 | p: 95.918 | r: 96.746
rouge2     | fm: 69.424 | p: 69.351 | r: 69.503
rougeL     | fm: 85.707 | p: 85.531 | r: 85.899
rougeLsum  | fm: 85.707 | p: 85.531 | r: 85.899
r1fm+r2fm = 165.737

input #8 time: 0:10:07 | total time: 1:25:21


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9993987163307133
highest_index [0]
highest [0.9993987163307133]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.8139041066169739 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.7717182636260986 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.7365254759788513 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.7207859754562378 for ['[CLS] owners pad there arena da rico weekly family [SEP]']
[Init] best rec loss: 0.6855643391609192 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 0.6805217862129211 for ['[CLS] red sh dipped in outstretched hour go imagine [SEP]']
[Init] best rec loss: 0.6490535736083984 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6489459872245789 for ['[CLS] edward arsenal luck deaths decca outlaw codydden [SEP]']
[Init] best perm rec loss: 0.6477984189987183 for ['[CLS] luck edward deaths decca arsenal outlaw codydden [SEP]']
[Init] best perm rec loss: 0.6473267078399658 for ['[CLS] edward deathsdden luck cody outlaw decca arsenal [SEP]']
[Init] best perm rec loss: 0.6464244723320007 for ['[CLS] cody luck deaths deccadden edward arsenal outlaw [SEP]']
[Init] best perm rec loss: 0.6462475657463074 for ['[CLS] arsenal deccadden deaths luck edward cody outlaw [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.110 (perp=14.292, rec=0.235, cos=0.016), tot_loss_proj:3.898 [t=0.23s]
prediction: ['[CLS] softed of claphead scientific softumen [SEP]']
[ 100/2000] tot_loss=2.455 (perp=11.335, rec=0.179, cos=0.009), tot_loss_proj:3.327 [t=0.24s]
prediction: ['[CLS] softhead of claphead built claptra [SEP]']
[ 150/2000] tot_loss=2.662 (perp=12.471, rec=0.151, cos=0.016), tot_loss_proj:3.254 [t=0.24s]
prediction: ['[CLS] softhead of clap metaphysicalhead claptra [SEP]']
[ 200/2000] tot_loss=2.591 (perp=12.505, rec=0.087, cos=0.003), tot_loss_proj:3.279 [t=0.24s]
prediction: ['[CLS] softhead ofp metaphysicalhead claptra [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.256 (perp=10.563, rec=0.135, cos=0.008), tot_loss_proj:2.852 [t=0.24s]
prediction: ['[CLS] softhead of claptrap metaphysical couldn [SEP]']
[ 300/2000] tot_loss=2.151 (perp=10.315, rec=0.086, cos=0.002), tot_loss_proj:2.700 [t=0.24s]
prediction: ['[CLS] softhead of claptrap metaphysical going [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.929 (perp=9.222, rec=0.083, cos=0.002), tot_loss_proj:2.719 [t=0.24s]
prediction: ['[CLS] softhead of metaphysical claptrap puppet [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.702 (perp=8.027, rec=0.089, cos=0.007), tot_loss_proj:2.442 [t=0.24s]
prediction: ['[CLS] soft deephead of metaphysical claptrap [SEP]']
[ 450/2000] tot_loss=1.707 (perp=8.154, rec=0.074, cos=0.002), tot_loss_proj:2.434 [t=0.24s]
prediction: ['[CLS] soft bighead of metaphysical claptrap [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.621 (perp=7.709, rec=0.078, cos=0.002), tot_loss_proj:2.375 [t=0.24s]
prediction: ['[CLS] metaphysical bighead of soft claptrap [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.615 (perp=7.709, rec=0.072, cos=0.002), tot_loss_proj:2.371 [t=0.24s]
prediction: ['[CLS] metaphysical bighead of soft claptrap [SEP]']
[ 600/2000] tot_loss=1.619 (perp=7.709, rec=0.075, cos=0.002), tot_loss_proj:2.372 [t=0.24s]
prediction: ['[CLS] metaphysical bighead of soft claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.722 (perp=8.212, rec=0.078, cos=0.002), tot_loss_proj:2.456 [t=0.24s]
prediction: ['[CLS] metaphysical deephead of soft claptrap [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.790 (perp=8.577, rec=0.073, cos=0.002), tot_loss_proj:2.980 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
[ 750/2000] tot_loss=1.793 (perp=8.577, rec=0.076, cos=0.002), tot_loss_proj:2.984 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.788 (perp=8.577, rec=0.071, cos=0.002), tot_loss_proj:2.984 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.787 (perp=8.577, rec=0.070, cos=0.002), tot_loss_proj:2.982 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
[ 900/2000] tot_loss=1.784 (perp=8.577, rec=0.067, cos=0.002), tot_loss_proj:2.983 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.784 (perp=8.577, rec=0.067, cos=0.002), tot_loss_proj:2.984 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.789 (perp=8.577, rec=0.072, cos=0.002), tot_loss_proj:2.980 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
[1050/2000] tot_loss=1.793 (perp=8.577, rec=0.077, cos=0.002), tot_loss_proj:2.978 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.785 (perp=8.577, rec=0.068, cos=0.002), tot_loss_proj:2.982 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.791 (perp=8.577, rec=0.074, cos=0.002), tot_loss_proj:2.984 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
[1200/2000] tot_loss=1.792 (perp=8.577, rec=0.075, cos=0.002), tot_loss_proj:2.978 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.793 (perp=8.577, rec=0.076, cos=0.002), tot_loss_proj:2.977 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.792 (perp=8.577, rec=0.075, cos=0.002), tot_loss_proj:2.979 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
[1350/2000] tot_loss=1.782 (perp=8.577, rec=0.065, cos=0.002), tot_loss_proj:2.973 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.785 (perp=8.577, rec=0.069, cos=0.002), tot_loss_proj:2.977 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.790 (perp=8.577, rec=0.073, cos=0.002), tot_loss_proj:2.977 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
[1500/2000] tot_loss=1.795 (perp=8.577, rec=0.078, cos=0.002), tot_loss_proj:2.972 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.792 (perp=8.577, rec=0.075, cos=0.002), tot_loss_proj:2.978 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.784 (perp=8.577, rec=0.067, cos=0.002), tot_loss_proj:2.984 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
[1650/2000] tot_loss=2.056 (perp=9.921, rec=0.071, cos=0.002), tot_loss_proj:3.129 [t=0.24s]
prediction: ['[CLS] pit metaphysicalhead of soft claptrap [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.882 (perp=9.014, rec=0.077, cos=0.002), tot_loss_proj:2.717 [t=0.24s]
prediction: ['[CLS] wouldhead metaphysical of soft claptrap [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.784 (perp=8.577, rec=0.066, cos=0.002), tot_loss_proj:2.976 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
[1800/2000] tot_loss=1.793 (perp=8.577, rec=0.076, cos=0.002), tot_loss_proj:2.969 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.777 (perp=8.577, rec=0.060, cos=0.002), tot_loss_proj:2.974 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.799 (perp=8.577, rec=0.082, cos=0.002), tot_loss_proj:2.976 [t=0.23s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
[1950/2000] tot_loss=1.793 (perp=8.577, rec=0.076, cos=0.002), tot_loss_proj:2.973 [t=0.24s]
prediction: ['[CLS] would metaphysicalhead of soft claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=2.064 (perp=9.921, rec=0.079, cos=0.002), tot_loss_proj:3.127 [t=0.24s]
prediction: ['[CLS] pit metaphysicalhead of soft claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] pit metaphysicalhead of soft claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.538 | p: 57.143 | r: 66.667
rouge2     | fm: 18.182 | p: 16.667 | r: 20.000
rougeL     | fm: 61.538 | p: 57.143 | r: 66.667
rougeLsum  | fm: 61.538 | p: 57.143 | r: 66.667
r1fm+r2fm = 79.720

[Aggregate metrics]:
rouge1     | fm: 92.836 | p: 92.040 | r: 93.738
rouge2     | fm: 64.675 | p: 64.390 | r: 65.000
rougeL     | fm: 83.427 | p: 82.957 | r: 84.286
rougeLsum  | fm: 83.299 | p: 82.693 | r: 84.167
r1fm+r2fm = 157.511

input #9 time: 0:09:49 | total time: 1:35:10


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9991463287867453
highest_index [0]
highest [0.9991463287867453]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8793880939483643 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8667941689491272 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8236117959022522 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best rec loss: 0.8160073757171631 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.8075990080833435 for ['[CLS] hidelin swing reacher immediately championship nervous accompaniedcar eva pounded besides help [SEP]']
[Init] best perm rec loss: 0.8071138858795166 for ['[CLS] nervous immediately hid besides pounded swing accompaniedcar help reacherelin eva championship [SEP]']
[Init] best perm rec loss: 0.806658923625946 for ['[CLS] immediately swing nervous reacher hidcar help eva accompaniedelin championship pounded besides [SEP]']
[Init] best perm rec loss: 0.8043859004974365 for ['[CLS]elin accompanied swing pounded championship nervous reacher hid eva immediately helpcar besides [SEP]']
[Init] best perm rec loss: 0.8037967681884766 for ['[CLS] eva immediately swing accompanied nervous championshipelin reachercar hid besides help pounded [SEP]']
[Init] best perm rec loss: 0.8032265901565552 for ['[CLS] accompanied swing nervous championship eva immediatelyelincar pounded hid reacher besides help [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.858 (perp=12.653, rec=0.310, cos=0.017), tot_loss_proj:3.850 [t=0.23s]
prediction: ['[CLS] balance fletcher line supreme once series sullivanfastulsive balance vinci. actress [SEP]']
[ 100/2000] tot_loss=2.937 (perp=13.206, rec=0.274, cos=0.021), tot_loss_proj:4.004 [t=0.24s]
prediction: ['[CLS] balance fletcher director specialists ab alexander rainfall abulsive balancelistic.ik [SEP]']
[ 150/2000] tot_loss=2.361 (perp=10.642, rec=0.220, cos=0.012), tot_loss_proj:3.813 [t=0.24s]
prediction: ['[CLS] balanceulsively relegated abs weeks ab rhythms balance incident. - [SEP]']
[ 200/2000] tot_loss=2.210 (perp=9.992, rec=0.205, cos=0.007), tot_loss_proj:3.704 [t=0.24s]
prediction: ['[CLS] balanceulsive. relegated abs rhythms ab rhythms balance incident. - [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.327 (perp=10.511, rec=0.214, cos=0.010), tot_loss_proj:3.299 [t=0.24s]
prediction: ['[CLS] balanceulsive values himselflys rhythms. rhythms balance incident ably [SEP]']
[ 300/2000] tot_loss=2.171 (perp=9.934, rec=0.178, cos=0.006), tot_loss_proj:3.444 [t=0.24s]
prediction: ['[CLS] balanceulsive. himselflys rhythms. rhythms balance incident ably [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.191 (perp=10.191, rec=0.145, cos=0.007), tot_loss_proj:3.238 [t=0.24s]
prediction: ['[CLS] balanceulsive.rioly rhythms. rhythms rhythmss incident ably [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.061 (perp=9.552, rec=0.146, cos=0.004), tot_loss_proj:3.141 [t=0.24s]
prediction: ['[CLS] balance rhythms.rioly rhythms.ulsive rhythmss incident ably [SEP]']
[ 450/2000] tot_loss=2.193 (perp=10.245, rec=0.140, cos=0.004), tot_loss_proj:3.385 [t=0.24s]
prediction: ['[CLS] balance rhythms.rioly rhythms.ulsive times incident ably [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.096 (perp=9.744, rec=0.143, cos=0.005), tot_loss_proj:3.406 [t=0.24s]
prediction: ['[CLS] balance rhythms.rioulsively components. timesulsive ably [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.064 (perp=9.605, rec=0.138, cos=0.005), tot_loss_proj:3.358 [t=0.24s]
prediction: ['[CLS] balance rhythms.rioulsively reece. times abulsively [SEP]']
[ 600/2000] tot_loss=2.220 (perp=10.482, rec=0.121, cos=0.003), tot_loss_proj:3.388 [t=0.24s]
prediction: ['[CLS] balance rhythms.rioulsively reece incident reals abulsively [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.041 (perp=9.635, rec=0.110, cos=0.004), tot_loss_proj:3.046 [t=0.24s]
prediction: ['[CLS] balance rhythms.rioulsive incidently reece reals abulsively [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.992 (perp=9.326, rec=0.123, cos=0.003), tot_loss_proj:3.438 [t=0.24s]
prediction: ['[CLS] balance rhythms. realrioulsive incidently traumatics abulsively [SEP]']
[ 750/2000] tot_loss=1.977 (perp=9.326, rec=0.109, cos=0.003), tot_loss_proj:3.435 [t=0.24s]
prediction: ['[CLS] balance rhythms. realrioulsive incidently traumatics abulsively [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.304 (perp=9.071, rec=0.404, cos=0.086), tot_loss_proj:3.076 [t=0.24s]
prediction: ['[CLS] balance rhythms. time with proply with incidents abulsively [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.988 (perp=8.279, rec=0.312, cos=0.020), tot_loss_proj:3.114 [t=0.24s]
prediction: ['[CLS] with incident balance rhythms. time with proplys abulsively [SEP]']
[ 900/2000] tot_loss=1.932 (perp=8.279, rec=0.262, cos=0.014), tot_loss_proj:3.106 [t=0.24s]
prediction: ['[CLS] with incident balance rhythms. time with proplys abulsively [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.878 (perp=8.099, rec=0.246, cos=0.012), tot_loss_proj:2.865 [t=0.24s]
prediction: ['[CLS] balance with incident rhythms. time with proplys abulsively [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.919 (perp=8.315, rec=0.244, cos=0.012), tot_loss_proj:2.946 [t=0.24s]
prediction: ['[CLS] balance with incident incident rhythms. time with proplys ably [SEP]']
[1050/2000] tot_loss=1.892 (perp=8.315, rec=0.219, cos=0.010), tot_loss_proj:2.939 [t=0.24s]
prediction: ['[CLS] balance with incident incident rhythms. time with proplys ably [SEP]']
Attempt swap
[1100/2000] tot_loss=1.877 (perp=8.315, rec=0.205, cos=0.009), tot_loss_proj:2.942 [t=0.24s]
prediction: ['[CLS] balance with incident incident rhythms. time with proplys ably [SEP]']
Attempt swap
[1150/2000] tot_loss=1.875 (perp=8.315, rec=0.204, cos=0.008), tot_loss_proj:2.940 [t=0.24s]
prediction: ['[CLS] balance with incident incident rhythms. time with proplys ably [SEP]']
[1200/2000] tot_loss=1.869 (perp=8.315, rec=0.199, cos=0.007), tot_loss_proj:2.938 [t=0.24s]
prediction: ['[CLS] balance with incident incident rhythms. time with proplys ably [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.800 (perp=7.976, rec=0.197, cos=0.008), tot_loss_proj:2.826 [t=0.30s]
prediction: ['[CLS] balance with incident. time with incident rhythms proplys ably [SEP]']
Attempt swap
[1300/2000] tot_loss=2.097 (perp=9.507, rec=0.188, cos=0.007), tot_loss_proj:3.206 [t=0.24s]
prediction: ['[CLS] balance with incident. timerio incident rhythms proplys ably [SEP]']
[1350/2000] tot_loss=2.098 (perp=9.507, rec=0.190, cos=0.007), tot_loss_proj:3.211 [t=0.24s]
prediction: ['[CLS] balance with incident. timerio incident rhythms proplys ably [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.997 (perp=9.096, rec=0.171, cos=0.007), tot_loss_proj:3.392 [t=0.24s]
prediction: ['[CLS] balance incident with incident. timerio rhythms proplys ably [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.944 (perp=8.778, rec=0.182, cos=0.006), tot_loss_proj:3.312 [t=0.24s]
prediction: ['[CLS] balance incident with time. incidentrio rhythms proplys ably [SEP]']
[1500/2000] tot_loss=1.925 (perp=8.778, rec=0.163, cos=0.006), tot_loss_proj:3.308 [t=0.24s]
prediction: ['[CLS] balance incident with time. incidentrio rhythms proplys ably [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.859 (perp=8.379, rec=0.177, cos=0.006), tot_loss_proj:3.120 [t=0.24s]
prediction: ['[CLS] incident with time. incidentrio balance rhythms proplys ably [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.813 (perp=8.156, rec=0.176, cos=0.006), tot_loss_proj:2.977 [t=0.24s]
prediction: ['[CLS] incident with time. incidentrio balances proply rhythms ably [SEP]']
[1650/2000] tot_loss=1.821 (perp=8.156, rec=0.184, cos=0.006), tot_loss_proj:2.972 [t=0.24s]
prediction: ['[CLS] incident with time. incidentrio balances proply rhythms ably [SEP]']
Attempt swap
[1700/2000] tot_loss=1.817 (perp=8.156, rec=0.180, cos=0.006), tot_loss_proj:2.977 [t=0.24s]
prediction: ['[CLS] incident with time. incidentrio balances proply rhythms ably [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.747 (perp=7.780, rec=0.186, cos=0.005), tot_loss_proj:2.843 [t=0.24s]
prediction: ['[CLS] incident with time. proprio balances incidently rhythms ably [SEP]']
[1800/2000] tot_loss=1.736 (perp=7.780, rec=0.175, cos=0.005), tot_loss_proj:2.833 [t=0.24s]
prediction: ['[CLS] incident with time. proprio balances incidently rhythms ably [SEP]']
Attempt swap
[1850/2000] tot_loss=1.738 (perp=7.780, rec=0.177, cos=0.005), tot_loss_proj:2.838 [t=0.24s]
prediction: ['[CLS] incident with time. proprio balances incidently rhythms ably [SEP]']
Attempt swap
[1900/2000] tot_loss=1.730 (perp=7.780, rec=0.169, cos=0.005), tot_loss_proj:2.840 [t=0.23s]
prediction: ['[CLS] incident with time. proprio balances incidently rhythms ably [SEP]']
[1950/2000] tot_loss=1.728 (perp=7.780, rec=0.167, cos=0.005), tot_loss_proj:2.842 [t=0.24s]
prediction: ['[CLS] incident with time. proprio balances incidently rhythms ably [SEP]']
Attempt swap
[2000/2000] tot_loss=1.745 (perp=7.780, rec=0.184, cos=0.005), tot_loss_proj:2.844 [t=0.24s]
prediction: ['[CLS] incident with time. proprio balances incidently rhythms ably [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] balance rhythms. realrioulsive incidently traumatics abulsively [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 33.333 | p: 37.500 | r: 30.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 33.333 | p: 37.500 | r: 30.000
rougeLsum  | fm: 33.333 | p: 37.500 | r: 30.000
r1fm+r2fm = 33.333

[Aggregate metrics]:
rouge1     | fm: 87.666 | p: 87.082 | r: 88.009
rouge2     | fm: 58.442 | p: 58.257 | r: 58.636
rougeL     | fm: 78.749 | p: 78.610 | r: 79.069
rougeLsum  | fm: 78.964 | p: 78.831 | r: 79.459
r1fm+r2fm = 146.108

input #10 time: 0:09:36 | total time: 1:44:47


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9992854056069841
highest_index [0]
highest [0.9992854056069841]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.91344153881073 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.8994779586791992 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.8188697099685669 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.817574679851532 for ['[CLS] familiar mile drawn tal platformgu mevdture inland [SEP]']
[Init] best perm rec loss: 0.8121586441993713 for ['[CLS]ture me mile inland platformguvd drawn tal familiar [SEP]']
[Init] best perm rec loss: 0.8105562329292297 for ['[CLS] mile me inlandvd platformturegu familiar drawn tal [SEP]']
[Init] best perm rec loss: 0.8066157102584839 for ['[CLS] inland mileture me drawn tal platformguvd familiar [SEP]']
[Init] best perm rec loss: 0.802373468875885 for ['[CLS] inlandture drawnvd platform tal mile megu familiar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.666 (perp=11.646, rec=0.314, cos=0.023), tot_loss_proj:3.515 [t=0.23s]
prediction: ['[CLS] but attempt stubborned gun tonight gel to gel refused [SEP]']
[ 100/2000] tot_loss=2.483 (perp=11.489, rec=0.179, cos=0.006), tot_loss_proj:3.282 [t=0.23s]
prediction: ['[CLS] was attempted stubborn that stubborn here gel to gel refused [SEP]']
[ 150/2000] tot_loss=2.544 (perp=12.146, rec=0.113, cos=0.002), tot_loss_proj:3.670 [t=0.24s]
prediction: ['[CLS] was attempted stubborn thatly here gelly gel refused [SEP]']
[ 200/2000] tot_loss=2.386 (perp=11.474, rec=0.090, cos=0.002), tot_loss_proj:3.428 [t=0.24s]
prediction: ['[CLS] was attempted stubborn thatly here gel to gel refused [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.991 (perp=9.559, rec=0.077, cos=0.002), tot_loss_proj:2.781 [t=0.24s]
prediction: ['[CLS] was attempted stubbornly that here gel to gel refused [SEP]']
[ 300/2000] tot_loss=1.990 (perp=9.559, rec=0.077, cos=0.001), tot_loss_proj:2.772 [t=0.24s]
prediction: ['[CLS] was attempted stubbornly that here gel to gel refused [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.864 (perp=8.936, rec=0.076, cos=0.001), tot_loss_proj:2.344 [t=0.24s]
prediction: ['[CLS] was attempted stubbornly that here gel refused to gel [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.824 (perp=8.704, rec=0.081, cos=0.002), tot_loss_proj:2.288 [t=0.24s]
prediction: ['[CLS] was attempted stubbornly that gel here refused to gel [SEP]']
[ 450/2000] tot_loss=1.817 (perp=8.704, rec=0.075, cos=0.001), tot_loss_proj:2.293 [t=0.24s]
prediction: ['[CLS] was attempted stubbornly that gel here refused to gel [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.565 (perp=7.327, rec=0.097, cos=0.003), tot_loss_proj:2.076 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that been refused to gel [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.554 (perp=7.327, rec=0.087, cos=0.002), tot_loss_proj:2.065 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that been refused to gel [SEP]']
[ 600/2000] tot_loss=1.478 (perp=6.997, rec=0.077, cos=0.001), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.479 (perp=6.997, rec=0.078, cos=0.001), tot_loss_proj:2.157 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.470 (perp=6.997, rec=0.069, cos=0.001), tot_loss_proj:2.155 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[ 750/2000] tot_loss=1.469 (perp=6.997, rec=0.068, cos=0.001), tot_loss_proj:2.155 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.477 (perp=6.997, rec=0.076, cos=0.001), tot_loss_proj:2.154 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.464 (perp=6.997, rec=0.063, cos=0.001), tot_loss_proj:2.158 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[ 900/2000] tot_loss=1.467 (perp=6.997, rec=0.066, cos=0.001), tot_loss_proj:2.157 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.469 (perp=6.997, rec=0.068, cos=0.001), tot_loss_proj:2.160 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.467 (perp=6.997, rec=0.066, cos=0.001), tot_loss_proj:2.150 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1050/2000] tot_loss=1.461 (perp=6.997, rec=0.061, cos=0.001), tot_loss_proj:2.150 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.471 (perp=6.997, rec=0.070, cos=0.001), tot_loss_proj:2.149 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.463 (perp=6.997, rec=0.062, cos=0.001), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1200/2000] tot_loss=1.468 (perp=6.997, rec=0.068, cos=0.001), tot_loss_proj:2.147 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.468 (perp=6.997, rec=0.067, cos=0.001), tot_loss_proj:2.150 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.470 (perp=6.997, rec=0.069, cos=0.001), tot_loss_proj:2.145 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1350/2000] tot_loss=1.463 (perp=6.997, rec=0.063, cos=0.001), tot_loss_proj:2.149 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.459 (perp=6.997, rec=0.058, cos=0.001), tot_loss_proj:2.149 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.468 (perp=6.997, rec=0.067, cos=0.001), tot_loss_proj:2.147 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1500/2000] tot_loss=1.461 (perp=6.997, rec=0.060, cos=0.001), tot_loss_proj:2.146 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.472 (perp=6.997, rec=0.071, cos=0.001), tot_loss_proj:2.151 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.465 (perp=6.997, rec=0.064, cos=0.001), tot_loss_proj:2.146 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1650/2000] tot_loss=1.471 (perp=6.997, rec=0.070, cos=0.001), tot_loss_proj:2.152 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.472 (perp=6.997, rec=0.071, cos=0.001), tot_loss_proj:2.149 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.470 (perp=6.997, rec=0.069, cos=0.001), tot_loss_proj:2.149 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1800/2000] tot_loss=1.474 (perp=6.997, rec=0.073, cos=0.001), tot_loss_proj:2.155 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.467 (perp=6.997, rec=0.067, cos=0.001), tot_loss_proj:2.154 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.462 (perp=6.997, rec=0.062, cos=0.001), tot_loss_proj:2.147 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1950/2000] tot_loss=1.466 (perp=6.997, rec=0.065, cos=0.001), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.462 (perp=6.997, rec=0.061, cos=0.001), tot_loss_proj:2.153 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was attempted stubbornly that being refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 88.914 | p: 88.668 | r: 89.563
rouge2     | fm: 56.515 | p: 56.180 | r: 56.711
rougeL     | fm: 78.247 | p: 78.090 | r: 78.605
rougeLsum  | fm: 78.335 | p: 78.267 | r: 78.753
r1fm+r2fm = 145.429

input #11 time: 0:09:32 | total time: 1:54:20


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.9993446475795855
highest_index [0]
highest [0.9993446475795855]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8687862157821655 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.862207293510437 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 0.799700915813446 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.77464359998703 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7713767886161804 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7438812255859375 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best perm rec loss: 0.7414798736572266 for ['[CLS] translate lay few ha series officeitas margin shades guess bethnction victoryn [SEP]']
[Init] best perm rec loss: 0.7407479882240295 for ['[CLS] ha margin series victornction beth translateitas lay shadesyn office guess few [SEP]']
[Init] best perm rec loss: 0.7403061985969543 for ['[CLS]ynnction layitas guess margin beth victor few series translate office ha shades [SEP]']
[Init] best perm rec loss: 0.7398918867111206 for ['[CLS] translate layitas margin series office bethnction shadesyn few ha guess victor [SEP]']
[Init] best perm rec loss: 0.7394150495529175 for ['[CLS] beth victoritasnction translate office shades lay fewyn margin guess ha series [SEP]']
[Init] best perm rec loss: 0.7388815879821777 for ['[CLS] victornction office series lay margin translate bethyn shades fewitas guess ha [SEP]']
[Init] best perm rec loss: 0.738705039024353 for ['[CLS] victor guessyn translate ha few shades beth series lay office marginnctionitas [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.543 (perp=11.180, rec=0.279, cos=0.028), tot_loss_proj:3.110 [t=0.23s]
prediction: ['[CLS] better me any look better barely equipment seen because because apparent advantage rating cable [SEP]']
[ 100/2000] tot_loss=2.198 (perp=10.094, rec=0.168, cos=0.012), tot_loss_proj:2.837 [t=0.24s]
prediction: ['[CLS] better will obviously to better barely cable seen because considering to advantage on cable [SEP]']
[ 150/2000] tot_loss=2.083 (perp=9.762, rec=0.123, cos=0.007), tot_loss_proj:2.842 [t=0.24s]
prediction: ['[CLS] better will seen will better barely cable seen on considering to advantage on cable [SEP]']
[ 200/2000] tot_loss=2.033 (perp=9.638, rec=0.100, cos=0.005), tot_loss_proj:3.052 [t=0.24s]
prediction: ['[CLS] better will considering will better barely cable seen, considering to advantage on cable [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.988 (perp=9.211, rec=0.134, cos=0.012), tot_loss_proj:2.662 [t=0.24s]
prediction: ['[CLS] better seen that as will better barely advantage on considering to advantage on cable [SEP]']
[ 300/2000] tot_loss=1.953 (perp=9.211, rec=0.102, cos=0.009), tot_loss_proj:2.691 [t=0.24s]
prediction: ['[CLS] better seen that as will better barely advantage on considering to advantage on cable [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.833 (perp=8.598, rec=0.108, cos=0.005), tot_loss_proj:2.569 [t=0.24s]
prediction: ['[CLS] better seen that barely will better as reader, considering to advantage on cable [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.805 (perp=8.524, rec=0.096, cos=0.004), tot_loss_proj:2.652 [t=0.24s]
prediction: ['[CLS] better seen that barely will better its reader, considering to advantage on cable [SEP]']
[ 450/2000] tot_loss=1.807 (perp=8.524, rec=0.097, cos=0.005), tot_loss_proj:2.652 [t=0.24s]
prediction: ['[CLS] better seen that barely will better its reader, considering to advantage on cable [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.837 (perp=8.668, rec=0.100, cos=0.004), tot_loss_proj:2.543 [t=0.24s]
prediction: ['[CLS] barely seen that be will better its reader, considering to advantage on cable [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.633 (perp=7.693, rec=0.090, cos=0.004), tot_loss_proj:2.333 [t=0.24s]
prediction: ['[CLS] barely will that be seen better its reader, considering to advantage on cable [SEP]']
[ 600/2000] tot_loss=1.628 (perp=7.693, rec=0.086, cos=0.003), tot_loss_proj:2.331 [t=0.24s]
prediction: ['[CLS] barely will that be seen better its reader, considering to advantage on cable [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.517 (perp=7.120, rec=0.089, cos=0.003), tot_loss_proj:2.186 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader, considering its advantage on cable [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.635 (perp=7.746, rec=0.083, cos=0.003), tot_loss_proj:2.291 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
[ 750/2000] tot_loss=1.625 (perp=7.746, rec=0.073, cos=0.002), tot_loss_proj:2.289 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.625 (perp=7.746, rec=0.074, cos=0.002), tot_loss_proj:2.295 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.620 (perp=7.746, rec=0.069, cos=0.002), tot_loss_proj:2.296 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
[ 900/2000] tot_loss=1.621 (perp=7.746, rec=0.070, cos=0.002), tot_loss_proj:2.293 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.620 (perp=7.746, rec=0.069, cos=0.002), tot_loss_proj:2.296 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
Attempt swap
[1000/2000] tot_loss=1.619 (perp=7.746, rec=0.068, cos=0.002), tot_loss_proj:2.294 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
[1050/2000] tot_loss=1.616 (perp=7.746, rec=0.065, cos=0.002), tot_loss_proj:2.291 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
Attempt swap
[1100/2000] tot_loss=1.625 (perp=7.746, rec=0.074, cos=0.002), tot_loss_proj:2.299 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
Attempt swap
[1150/2000] tot_loss=1.627 (perp=7.746, rec=0.076, cos=0.002), tot_loss_proj:2.298 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
[1200/2000] tot_loss=1.612 (perp=7.746, rec=0.060, cos=0.002), tot_loss_proj:2.298 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
Attempt swap
[1250/2000] tot_loss=1.621 (perp=7.746, rec=0.070, cos=0.002), tot_loss_proj:2.292 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
Attempt swap
[1300/2000] tot_loss=1.624 (perp=7.746, rec=0.073, cos=0.002), tot_loss_proj:2.296 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
[1350/2000] tot_loss=1.625 (perp=7.746, rec=0.074, cos=0.002), tot_loss_proj:2.296 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
Attempt swap
[1400/2000] tot_loss=1.617 (perp=7.746, rec=0.066, cos=0.002), tot_loss_proj:2.293 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
Attempt swap
[1450/2000] tot_loss=1.628 (perp=7.746, rec=0.077, cos=0.002), tot_loss_proj:2.295 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
[1500/2000] tot_loss=1.621 (perp=7.746, rec=0.070, cos=0.002), tot_loss_proj:2.289 [t=0.24s]
prediction: ['[CLS] barely will that be seen better to reader especially considering its advantage on cable [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.598 (perp=7.650, rec=0.066, cos=0.002), tot_loss_proj:2.268 [t=0.24s]
prediction: ['[CLS] barely will that be seen better especially to reader considering its advantage on cable [SEP]']
Attempt swap
[1600/2000] tot_loss=1.592 (perp=7.650, rec=0.060, cos=0.002), tot_loss_proj:2.269 [t=0.24s]
prediction: ['[CLS] barely will that be seen better especially to reader considering its advantage on cable [SEP]']
[1650/2000] tot_loss=1.597 (perp=7.650, rec=0.065, cos=0.002), tot_loss_proj:2.265 [t=0.24s]
prediction: ['[CLS] barely will that be seen better especially to reader considering its advantage on cable [SEP]']
Attempt swap
[1700/2000] tot_loss=1.605 (perp=7.650, rec=0.073, cos=0.002), tot_loss_proj:2.271 [t=0.24s]
prediction: ['[CLS] barely will that be seen better especially to reader considering its advantage on cable [SEP]']
Attempt swap
[1750/2000] tot_loss=1.595 (perp=7.650, rec=0.063, cos=0.002), tot_loss_proj:2.269 [t=0.24s]
prediction: ['[CLS] barely will that be seen better especially to reader considering its advantage on cable [SEP]']
[1800/2000] tot_loss=1.604 (perp=7.650, rec=0.072, cos=0.002), tot_loss_proj:2.270 [t=0.24s]
prediction: ['[CLS] barely will that be seen better especially to reader considering its advantage on cable [SEP]']
Attempt swap
[1850/2000] tot_loss=1.603 (perp=7.650, rec=0.071, cos=0.002), tot_loss_proj:2.270 [t=0.24s]
prediction: ['[CLS] barely will that be seen better especially to reader considering its advantage on cable [SEP]']
Attempt swap
[1900/2000] tot_loss=1.601 (perp=7.650, rec=0.069, cos=0.002), tot_loss_proj:2.267 [t=0.23s]
prediction: ['[CLS] barely will that be seen better especially to reader considering its advantage on cable [SEP]']
[1950/2000] tot_loss=1.601 (perp=7.650, rec=0.069, cos=0.002), tot_loss_proj:2.264 [t=0.23s]
prediction: ['[CLS] barely will that be seen better especially to reader considering its advantage on cable [SEP]']
Attempt swap
[2000/2000] tot_loss=1.595 (perp=7.650, rec=0.063, cos=0.002), tot_loss_proj:2.268 [t=0.23s]
prediction: ['[CLS] barely will that be seen better especially to reader considering its advantage on cable [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] barely will that be seen better especially to reader considering its advantage on cable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.774 | p: 93.750 | r: 100.000
rouge2     | fm: 27.586 | p: 26.667 | r: 28.571
rougeL     | fm: 58.065 | p: 56.250 | r: 60.000
rougeLsum  | fm: 58.065 | p: 56.250 | r: 60.000
r1fm+r2fm = 124.360

[Aggregate metrics]:
rouge1     | fm: 89.722 | p: 89.041 | r: 90.339
rouge2     | fm: 53.887 | p: 53.654 | r: 54.121
rougeL     | fm: 76.726 | p: 76.579 | r: 77.196
rougeLsum  | fm: 76.671 | p: 76.385 | r: 77.005
r1fm+r2fm = 143.609

input #12 time: 0:09:53 | total time: 2:04:14


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9992539461450387
highest_index [0]
highest [0.9992539461450387]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.8865664601325989 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8836308717727661 for ['[CLS] te saw thunder fame ambulance concerts pinch [SEP]']
[Init] best rec loss: 0.8601260781288147 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7841423749923706 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.7840108871459961 for ['[CLS] clay young demon every rolesorestation bill [SEP]']
[Init] best rec loss: 0.7708356380462646 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 0.7580289244651794 for ['[CLS]typic malice avenue andy rightart brought [SEP]']
[Init] best rec loss: 0.7500137090682983 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best perm rec loss: 0.7499359250068665 for ['[CLS] furnace without card double experiment working corruption [SEP]']
[Init] best perm rec loss: 0.748815655708313 for ['[CLS] without corruption double working card furnace experiment [SEP]']
[Init] best perm rec loss: 0.7485044002532959 for ['[CLS] without card working furnace corruption experiment double [SEP]']
[Init] best perm rec loss: 0.7479153871536255 for ['[CLS] without working corruption double furnace card experiment [SEP]']
[Init] best perm rec loss: 0.7478422522544861 for ['[CLS] card double working furnace without experiment corruption [SEP]']
[Init] best perm rec loss: 0.7478395700454712 for ['[CLS] corruption without experiment working card double furnace [SEP]']
[Init] best perm rec loss: 0.7461642026901245 for ['[CLS] corruption card double furnace experiment without working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.935 (perp=13.067, rec=0.289, cos=0.033), tot_loss_proj:4.208 [t=0.23s]
prediction: ['[CLS] point thereof empire explode into won flame [SEP]']
[ 100/2000] tot_loss=2.334 (perp=10.724, rec=0.179, cos=0.011), tot_loss_proj:2.864 [t=0.23s]
prediction: ['[CLS] point things things explode into explode flame [SEP]']
[ 150/2000] tot_loss=2.146 (perp=10.069, rec=0.128, cos=0.004), tot_loss_proj:2.808 [t=0.23s]
prediction: ['[CLS] point at things explode into explode flame [SEP]']
[ 200/2000] tot_loss=2.314 (perp=10.939, rec=0.123, cos=0.004), tot_loss_proj:3.048 [t=0.23s]
prediction: ['[CLS] point at things explode explode explode flame [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.287 (perp=10.367, rec=0.190, cos=0.024), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] point that things flame into easy explode [SEP]']
[ 300/2000] tot_loss=2.204 (perp=10.367, rec=0.127, cos=0.004), tot_loss_proj:2.892 [t=0.23s]
prediction: ['[CLS] point that things flame into easy explode [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.980 (perp=9.345, rec=0.107, cos=0.003), tot_loss_proj:3.187 [t=0.23s]
prediction: ['[CLS] point that things flame into explode easy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.973 (perp=9.345, rec=0.101, cos=0.003), tot_loss_proj:3.187 [t=0.23s]
prediction: ['[CLS] point that things flame into explode easy [SEP]']
[ 450/2000] tot_loss=1.981 (perp=9.345, rec=0.108, cos=0.003), tot_loss_proj:3.181 [t=0.23s]
prediction: ['[CLS] point that things flame into explode easy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.972 (perp=9.345, rec=0.099, cos=0.003), tot_loss_proj:3.180 [t=0.23s]
prediction: ['[CLS] point that things flame into explode easy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.969 (perp=9.345, rec=0.097, cos=0.003), tot_loss_proj:3.178 [t=0.23s]
prediction: ['[CLS] point that things flame into explode easy [SEP]']
[ 600/2000] tot_loss=1.967 (perp=9.345, rec=0.095, cos=0.003), tot_loss_proj:3.173 [t=0.23s]
prediction: ['[CLS] point that things flame into explode easy [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.008 (perp=9.493, rec=0.107, cos=0.003), tot_loss_proj:2.541 [t=0.23s]
prediction: ['[CLS] point that things flame into explode whatever [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.937 (perp=9.208, rec=0.090, cos=0.006), tot_loss_proj:2.540 [t=0.23s]
prediction: ['[CLS] point that things flame explode into whatever [SEP]']
[ 750/2000] tot_loss=1.934 (perp=9.208, rec=0.090, cos=0.003), tot_loss_proj:2.545 [t=0.23s]
prediction: ['[CLS] point that things flame explode into whatever [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.862 (perp=8.828, rec=0.093, cos=0.003), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.872 (perp=8.828, rec=0.104, cos=0.003), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
[ 900/2000] tot_loss=1.867 (perp=8.828, rec=0.098, cos=0.003), tot_loss_proj:2.412 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.859 (perp=8.828, rec=0.091, cos=0.003), tot_loss_proj:2.411 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
Attempt swap
[1000/2000] tot_loss=1.853 (perp=8.828, rec=0.084, cos=0.003), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
[1050/2000] tot_loss=1.857 (perp=8.828, rec=0.088, cos=0.003), tot_loss_proj:2.401 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.860 (perp=8.828, rec=0.092, cos=0.003), tot_loss_proj:2.405 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.864 (perp=8.828, rec=0.096, cos=0.003), tot_loss_proj:2.402 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
[1200/2000] tot_loss=1.865 (perp=8.828, rec=0.097, cos=0.003), tot_loss_proj:2.408 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.871 (perp=8.828, rec=0.102, cos=0.003), tot_loss_proj:2.413 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.858 (perp=8.828, rec=0.090, cos=0.003), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
[1350/2000] tot_loss=1.859 (perp=8.828, rec=0.091, cos=0.003), tot_loss_proj:2.410 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
Attempt swap
[1400/2000] tot_loss=1.858 (perp=8.828, rec=0.090, cos=0.003), tot_loss_proj:2.409 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.849 (perp=8.828, rec=0.081, cos=0.003), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS] point things flame that explode into whatever [SEP]']
[1500/2000] tot_loss=1.946 (perp=9.255, rec=0.093, cos=0.003), tot_loss_proj:3.619 [t=0.23s]
prediction: ['[CLS] point things flame that explode into good [SEP]']
Attempt swap
[1550/2000] tot_loss=1.953 (perp=9.255, rec=0.100, cos=0.003), tot_loss_proj:3.619 [t=0.23s]
prediction: ['[CLS] point things flame that explode into good [SEP]']
Attempt swap
[1600/2000] tot_loss=1.948 (perp=9.255, rec=0.094, cos=0.003), tot_loss_proj:3.615 [t=0.23s]
prediction: ['[CLS] point things flame that explode into good [SEP]']
[1650/2000] tot_loss=1.959 (perp=9.255, rec=0.105, cos=0.003), tot_loss_proj:3.614 [t=0.23s]
prediction: ['[CLS] point things flame that explode into good [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.928 (perp=9.180, rec=0.089, cos=0.003), tot_loss_proj:3.597 [t=0.23s]
prediction: ['[CLS] point things good that explode into flame [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.842 (perp=8.751, rec=0.089, cos=0.003), tot_loss_proj:3.447 [t=0.23s]
prediction: ['[CLS] point good things that explode into flame [SEP]']
[1800/2000] tot_loss=1.851 (perp=8.751, rec=0.098, cos=0.003), tot_loss_proj:3.446 [t=0.23s]
prediction: ['[CLS] point good things that explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.843 (perp=8.751, rec=0.090, cos=0.003), tot_loss_proj:3.448 [t=0.23s]
prediction: ['[CLS] point good things that explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.839 (perp=8.751, rec=0.086, cos=0.003), tot_loss_proj:3.447 [t=0.23s]
prediction: ['[CLS] point good things that explode into flame [SEP]']
[1950/2000] tot_loss=1.845 (perp=8.751, rec=0.092, cos=0.003), tot_loss_proj:3.443 [t=0.23s]
prediction: ['[CLS] point good things that explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.853 (perp=8.751, rec=0.100, cos=0.003), tot_loss_proj:3.446 [t=0.23s]
prediction: ['[CLS] point good things that explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] point good things that explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 163.889

[Aggregate metrics]:
rouge1     | fm: 89.663 | p: 89.089 | r: 90.249
rouge2     | fm: 55.264 | p: 55.100 | r: 55.510
rougeL     | fm: 77.705 | p: 77.453 | r: 78.052
rougeLsum  | fm: 77.633 | p: 77.297 | r: 78.098
r1fm+r2fm = 144.927

input #13 time: 0:09:33 | total time: 2:13:48


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9993215770683852
highest_index [0]
highest [0.9993215770683852]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9575048089027405 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.939458429813385 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.923689067363739 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9127009510993958 for ['[CLS] bar these catch arms state [SEP]']
[Init] best rec loss: 0.8922421336174011 for ['[CLS] return him always kolkata frame [SEP]']
[Init] best rec loss: 0.8753606081008911 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8746199011802673 for ['[CLS] sprayed myers harold [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8732940554618835 for ['[CLS] sprayed harold myers [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8731610178947449 for ['[CLS] harold [MASK] tom myers sprayed [SEP]']
[Init] best perm rec loss: 0.8726160526275635 for ['[CLS] harold tom sprayed [MASK] myers [SEP]']
[Init] best perm rec loss: 0.872270405292511 for ['[CLS] harold tom myers [MASK] sprayed [SEP]']
[Init] best perm rec loss: 0.8718624114990234 for ['[CLS] [MASK] harold sprayed tom myers [SEP]']
[Init] best perm rec loss: 0.8703657984733582 for ['[CLS] tom [MASK] sprayed myers harold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.455 (perp=15.752, rec=0.298, cos=0.007), tot_loss_proj:3.892 [t=0.23s]
prediction: ['[CLS] internationalclusiveenia star delicious [SEP]']
[ 100/2000] tot_loss=2.877 (perp=13.428, rec=0.188, cos=0.003), tot_loss_proj:3.274 [t=0.24s]
prediction: ['[CLS] / intriguingenia film intriguing [SEP]']
[ 150/2000] tot_loss=2.822 (perp=13.428, rec=0.134, cos=0.002), tot_loss_proj:3.275 [t=0.24s]
prediction: ['[CLS] / intriguingenia film intriguing [SEP]']
[ 200/2000] tot_loss=2.818 (perp=13.428, rec=0.130, cos=0.002), tot_loss_proj:3.259 [t=0.23s]
prediction: ['[CLS] / intriguingenia film intriguing [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.386 (perp=11.276, rec=0.128, cos=0.002), tot_loss_proj:2.661 [t=0.23s]
prediction: ['[CLS] undenia intriguing film intriguing [SEP]']
[ 300/2000] tot_loss=2.380 (perp=11.276, rec=0.123, cos=0.002), tot_loss_proj:2.648 [t=0.23s]
prediction: ['[CLS] undenia intriguing film intriguing [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.181 (perp=10.339, rec=0.111, cos=0.002), tot_loss_proj:2.429 [t=0.23s]
prediction: ['[CLS] intriguing undenia intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.682 (perp=7.796, rec=0.121, cos=0.002), tot_loss_proj:1.797 [t=0.24s]
prediction: ['[CLS] intriguing undeniably film [SEP]']
[ 450/2000] tot_loss=1.661 (perp=7.796, rec=0.100, cos=0.002), tot_loss_proj:1.795 [t=0.24s]
prediction: ['[CLS] intriguing undeniably film [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.436 (perp=6.728, rec=0.089, cos=0.002), tot_loss_proj:1.405 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.419 (perp=6.728, rec=0.072, cos=0.001), tot_loss_proj:1.404 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.425 (perp=6.728, rec=0.078, cos=0.001), tot_loss_proj:1.401 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.417 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.416 (perp=6.728, rec=0.069, cos=0.001), tot_loss_proj:1.409 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.418 (perp=6.728, rec=0.071, cos=0.001), tot_loss_proj:1.408 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.411 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.401 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.418 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.402 (perp=6.728, rec=0.055, cos=0.001), tot_loss_proj:1.401 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.407 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.412 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.400 (perp=6.728, rec=0.053, cos=0.001), tot_loss_proj:1.409 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.399 (perp=6.728, rec=0.052, cos=0.001), tot_loss_proj:1.414 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.417 (perp=6.728, rec=0.070, cos=0.001), tot_loss_proj:1.416 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.405 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.405 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.413 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.399 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.407 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.403 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.403 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.411 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.403 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.396 (perp=6.728, rec=0.049, cos=0.001), tot_loss_proj:1.394 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.415 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.413 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.412 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.404 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.402 (perp=6.728, rec=0.055, cos=0.001), tot_loss_proj:1.414 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.396 (perp=6.728, rec=0.049, cos=0.001), tot_loss_proj:1.411 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.295 | p: 89.661 | r: 90.894
rouge2     | fm: 58.292 | p: 58.108 | r: 58.571
rougeL     | fm: 79.167 | p: 78.878 | r: 79.616
rougeLsum  | fm: 78.964 | p: 78.584 | r: 79.481
r1fm+r2fm = 148.586

input #14 time: 0:09:16 | total time: 2:23:04


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.9992721399802154
highest_index [0]
highest [0.9992721399802154]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9675636291503906 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.9328241348266602 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 0.9158609509468079 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.9073993563652039 for ['[CLS] society worth jobsuit brick winrained circuit [SEP]']
[Init] best rec loss: 0.9044149518013 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8923435807228088 for ['[CLS]che carolezard multi zone rhythmic watervating [SEP]']
[Init] best rec loss: 0.8854512572288513 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8833559155464172 for ['[CLS] 0 humanities metaphor olivia easily fetch first sweden [SEP]']
[Init] best perm rec loss: 0.8797237277030945 for ['[CLS] humanities easily metaphor 0 first fetch sweden olivia [SEP]']
[Init] best perm rec loss: 0.87762451171875 for ['[CLS] first sweden 0 metaphor fetch humanities easily olivia [SEP]']
[Init] best perm rec loss: 0.8739213347434998 for ['[CLS] first sweden 0 humanities fetch metaphor easily olivia [SEP]']
[Init] best perm rec loss: 0.873146653175354 for ['[CLS] humanities first fetch metaphor 0 olivia easily sweden [SEP]']
[Init] best perm rec loss: 0.8725970387458801 for ['[CLS] metaphor humanities 0 sweden fetch easily first olivia [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.211 (perp=9.622, rec=0.275, cos=0.012), tot_loss_proj:2.631 [t=0.23s]
prediction: ['[CLS] efficient accessories suitably clientably efficient efficient [SEP]']
[ 100/2000] tot_loss=2.517 (perp=11.860, rec=0.143, cos=0.002), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS], ashby suit chillerably efficient efficient [SEP]']
[ 150/2000] tot_loss=2.525 (perp=12.156, rec=0.092, cos=0.002), tot_loss_proj:3.397 [t=0.23s]
prediction: ['[CLS],ably suit chillerably anonymous efficient [SEP]']
[ 200/2000] tot_loss=2.530 (perp=12.156, rec=0.097, cos=0.002), tot_loss_proj:3.390 [t=0.23s]
prediction: ['[CLS],ably suit chillerably anonymous efficient [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.867 (perp=8.680, rec=0.128, cos=0.003), tot_loss_proj:2.058 [t=0.23s]
prediction: ['[CLS], definitely suitably anonymous chiller efficient [SEP]']
[ 300/2000] tot_loss=1.823 (perp=8.604, rec=0.100, cos=0.002), tot_loss_proj:2.093 [t=0.23s]
prediction: ['[CLS],. suitably anonymous chiller efficient [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.566 (perp=7.427, rec=0.079, cos=0.002), tot_loss_proj:1.704 [t=0.23s]
prediction: ['[CLS], efficient suitably anonymous chiller. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.400 (perp=6.615, rec=0.075, cos=0.002), tot_loss_proj:1.426 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 450/2000] tot_loss=1.410 (perp=6.615, rec=0.085, cos=0.002), tot_loss_proj:1.415 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.399 (perp=6.615, rec=0.075, cos=0.001), tot_loss_proj:1.417 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.382 (perp=6.615, rec=0.057, cos=0.001), tot_loss_proj:1.422 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 600/2000] tot_loss=1.381 (perp=6.615, rec=0.057, cos=0.001), tot_loss_proj:1.416 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.384 (perp=6.615, rec=0.059, cos=0.001), tot_loss_proj:1.420 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.387 (perp=6.615, rec=0.062, cos=0.001), tot_loss_proj:1.421 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.391 (perp=6.615, rec=0.066, cos=0.001), tot_loss_proj:1.423 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.379 (perp=6.615, rec=0.055, cos=0.001), tot_loss_proj:1.409 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.388 (perp=6.615, rec=0.064, cos=0.001), tot_loss_proj:1.412 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.395 (perp=6.615, rec=0.071, cos=0.001), tot_loss_proj:1.408 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.387 (perp=6.615, rec=0.062, cos=0.001), tot_loss_proj:1.418 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.397 (perp=6.615, rec=0.072, cos=0.001), tot_loss_proj:1.406 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.385 (perp=6.615, rec=0.060, cos=0.001), tot_loss_proj:1.409 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.381 (perp=6.615, rec=0.057, cos=0.001), tot_loss_proj:1.424 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.385 (perp=6.615, rec=0.060, cos=0.001), tot_loss_proj:1.410 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.387 (perp=6.615, rec=0.062, cos=0.001), tot_loss_proj:1.416 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.388 (perp=6.615, rec=0.063, cos=0.001), tot_loss_proj:1.424 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.391 (perp=6.615, rec=0.066, cos=0.001), tot_loss_proj:1.424 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.380 (perp=6.615, rec=0.056, cos=0.001), tot_loss_proj:1.417 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.386 (perp=6.615, rec=0.061, cos=0.001), tot_loss_proj:1.404 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.387 (perp=6.615, rec=0.063, cos=0.001), tot_loss_proj:1.425 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.386 (perp=6.615, rec=0.062, cos=0.001), tot_loss_proj:1.404 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.396 (perp=6.615, rec=0.071, cos=0.001), tot_loss_proj:1.417 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.390 (perp=6.615, rec=0.066, cos=0.001), tot_loss_proj:1.411 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.387 (perp=6.615, rec=0.062, cos=0.001), tot_loss_proj:1.411 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.384 (perp=6.615, rec=0.059, cos=0.001), tot_loss_proj:1.412 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.393 (perp=6.615, rec=0.068, cos=0.001), tot_loss_proj:1.416 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.390 (perp=6.615, rec=0.065, cos=0.001), tot_loss_proj:1.419 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.385 (perp=6.615, rec=0.060, cos=0.001), tot_loss_proj:1.424 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.384 (perp=6.615, rec=0.059, cos=0.001), tot_loss_proj:1.417 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.380 (perp=6.615, rec=0.055, cos=0.001), tot_loss_proj:1.416 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.384 (perp=6.615, rec=0.059, cos=0.001), tot_loss_proj:1.425 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.860 | p: 90.415 | r: 91.441
rouge2     | fm: 61.238 | p: 61.051 | r: 61.461
rougeL     | fm: 80.414 | p: 80.240 | r: 80.837
rougeLsum  | fm: 80.134 | p: 79.824 | r: 80.607
r1fm+r2fm = 152.098

input #15 time: 0:09:28 | total time: 2:32:32


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9993407915045383
highest_index [0]
highest [0.9993407915045383]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.020234227180481 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.9004251956939697 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7400387525558472 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best perm rec loss: 0.7389788627624512 for ['[CLS] alta film various slowly lordathi [SEP]']
[Init] best perm rec loss: 0.7379375100135803 for ['[CLS] alta various film lord slowlyathi [SEP]']
[Init] best perm rec loss: 0.7354840040206909 for ['[CLS]athi film lord slowly various alta [SEP]']
[Init] best perm rec loss: 0.7348273396492004 for ['[CLS] film slowly lord various altaathi [SEP]']
[Init] best perm rec loss: 0.7346431612968445 for ['[CLS] lord various film slowlyathi alta [SEP]']
[Init] best perm rec loss: 0.7346169948577881 for ['[CLS] film various lord slowly altaathi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.363 (perp=13.407, rec=0.514, cos=0.168), tot_loss_proj:4.051 [t=0.23s]
prediction: ['[CLS] appeal leader knowledge iona more jewel [SEP]']
[ 100/2000] tot_loss=2.428 (perp=10.243, rec=0.343, cos=0.036), tot_loss_proj:3.218 [t=0.23s]
prediction: ['[CLS] now - generation its more this [SEP]']
[ 150/2000] tot_loss=2.072 (perp=8.777, rec=0.293, cos=0.024), tot_loss_proj:2.774 [t=0.23s]
prediction: ['[CLS]. of generation all more this [SEP]']
[ 200/2000] tot_loss=1.931 (perp=8.184, rec=0.260, cos=0.034), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] and of more all more this [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.297 (perp=5.400, rec=0.193, cos=0.024), tot_loss_proj:1.622 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[ 300/2000] tot_loss=1.212 (perp=5.400, rec=0.125, cos=0.007), tot_loss_proj:1.612 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.196 (perp=5.400, rec=0.111, cos=0.005), tot_loss_proj:1.619 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.181 (perp=5.400, rec=0.096, cos=0.005), tot_loss_proj:1.620 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[ 450/2000] tot_loss=1.192 (perp=5.400, rec=0.107, cos=0.005), tot_loss_proj:1.610 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.175 (perp=5.400, rec=0.090, cos=0.005), tot_loss_proj:1.621 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.170 (perp=5.400, rec=0.085, cos=0.005), tot_loss_proj:1.620 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[ 600/2000] tot_loss=1.174 (perp=5.400, rec=0.089, cos=0.005), tot_loss_proj:1.623 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.161 (perp=5.400, rec=0.077, cos=0.004), tot_loss_proj:1.625 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.168 (perp=5.400, rec=0.084, cos=0.004), tot_loss_proj:1.622 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[ 750/2000] tot_loss=1.172 (perp=5.400, rec=0.088, cos=0.004), tot_loss_proj:1.621 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.167 (perp=5.400, rec=0.083, cos=0.004), tot_loss_proj:1.622 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.162 (perp=5.400, rec=0.078, cos=0.004), tot_loss_proj:1.629 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[ 900/2000] tot_loss=1.163 (perp=5.400, rec=0.078, cos=0.004), tot_loss_proj:1.624 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.166 (perp=5.400, rec=0.082, cos=0.004), tot_loss_proj:1.622 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1000/2000] tot_loss=1.168 (perp=5.400, rec=0.084, cos=0.004), tot_loss_proj:1.625 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[1050/2000] tot_loss=1.160 (perp=5.400, rec=0.076, cos=0.004), tot_loss_proj:1.621 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1100/2000] tot_loss=1.158 (perp=5.400, rec=0.073, cos=0.004), tot_loss_proj:1.618 [t=0.24s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1150/2000] tot_loss=1.167 (perp=5.400, rec=0.083, cos=0.004), tot_loss_proj:1.626 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[1200/2000] tot_loss=1.166 (perp=5.400, rec=0.082, cos=0.004), tot_loss_proj:1.625 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1250/2000] tot_loss=1.161 (perp=5.400, rec=0.077, cos=0.004), tot_loss_proj:1.620 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1300/2000] tot_loss=1.173 (perp=5.400, rec=0.089, cos=0.004), tot_loss_proj:1.623 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[1350/2000] tot_loss=1.158 (perp=5.400, rec=0.074, cos=0.004), tot_loss_proj:1.624 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1400/2000] tot_loss=1.162 (perp=5.400, rec=0.078, cos=0.004), tot_loss_proj:1.628 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1450/2000] tot_loss=1.165 (perp=5.400, rec=0.081, cos=0.004), tot_loss_proj:1.629 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[1500/2000] tot_loss=1.169 (perp=5.400, rec=0.085, cos=0.004), tot_loss_proj:1.626 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1550/2000] tot_loss=1.168 (perp=5.400, rec=0.084, cos=0.004), tot_loss_proj:1.627 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1600/2000] tot_loss=1.157 (perp=5.400, rec=0.073, cos=0.004), tot_loss_proj:1.622 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[1650/2000] tot_loss=1.166 (perp=5.400, rec=0.082, cos=0.004), tot_loss_proj:1.628 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1700/2000] tot_loss=1.162 (perp=5.400, rec=0.078, cos=0.004), tot_loss_proj:1.627 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1750/2000] tot_loss=1.164 (perp=5.400, rec=0.080, cos=0.004), tot_loss_proj:1.619 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[1800/2000] tot_loss=1.172 (perp=5.400, rec=0.088, cos=0.004), tot_loss_proj:1.627 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1850/2000] tot_loss=1.172 (perp=5.400, rec=0.088, cos=0.004), tot_loss_proj:1.617 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1900/2000] tot_loss=1.168 (perp=5.400, rec=0.084, cos=0.004), tot_loss_proj:1.624 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[1950/2000] tot_loss=1.152 (perp=5.400, rec=0.068, cos=0.004), tot_loss_proj:1.623 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[2000/2000] tot_loss=1.167 (perp=5.400, rec=0.083, cos=0.004), tot_loss_proj:1.628 [t=0.24s]
prediction: ['[CLS] and more of all of this [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] and more of all of this [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 46.154 | p: 42.857 | r: 50.000
rougeL     | fm: 66.667 | p: 62.500 | r: 71.429
rougeLsum  | fm: 66.667 | p: 62.500 | r: 71.429
r1fm+r2fm = 139.487

[Aggregate metrics]:
rouge1     | fm: 91.080 | p: 90.297 | r: 91.928
rouge2     | fm: 60.597 | p: 60.178 | r: 61.007
rougeL     | fm: 80.065 | p: 79.487 | r: 80.711
rougeLsum  | fm: 79.626 | p: 79.181 | r: 80.296
r1fm+r2fm = 151.677

input #16 time: 0:09:30 | total time: 2:42:02


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9992298074118964
highest_index [0]
highest [0.9992298074118964]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8472551703453064 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8236850500106812 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.8234798908233643 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.8217296600341797 for ['[CLS] bit crookedus felicity york electedyre = cheese ourselves consulting [SEP]']
[Init] best rec loss: 0.8205518126487732 for ['[CLS] santa bourneity church jacence move nativeburnub early [SEP]']
[Init] best rec loss: 0.8091399073600769 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 0.7916844487190247 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 0.7702016830444336 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 0.7585719227790833 for ['[CLS] lieutenant magazineuin miss grey marius honestly pressure saved meeting i [SEP]']
[Init] best perm rec loss: 0.753882884979248 for ['[CLS] grey lieutenant marius honestlyuin magazine i meeting pressure saved miss [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.952 (perp=12.729, rec=0.351, cos=0.055), tot_loss_proj:3.708 [t=0.23s]
prediction: ['[CLS] want japan concentrate completely offff toowaite pressure prior signatures [SEP]']
[ 100/2000] tot_loss=2.029 (perp=9.048, rec=0.196, cos=0.023), tot_loss_proj:2.772 [t=0.23s]
prediction: ['[CLS] want world think too much s too what what too much [SEP]']
[ 150/2000] tot_loss=1.628 (perp=7.507, rec=0.120, cos=0.007), tot_loss_proj:2.394 [t=0.24s]
prediction: ['[CLS] want world think too much about too about what too much [SEP]']
[ 200/2000] tot_loss=2.168 (perp=10.376, rec=0.090, cos=0.003), tot_loss_proj:3.368 [t=0.24s]
prediction: ['[CLS] want city think to much s too about what going much [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.748 (perp=8.369, rec=0.072, cos=0.003), tot_loss_proj:3.020 [t=0.23s]
prediction: ['[CLS] want world to think going s too about what going much [SEP]']
[ 300/2000] tot_loss=1.586 (perp=7.517, rec=0.081, cos=0.002), tot_loss_proj:2.491 [t=0.23s]
prediction: ["[CLS] want to to think's too about what going much [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.342 (perp=6.351, rec=0.070, cos=0.002), tot_loss_proj:1.677 [t=0.24s]
prediction: ["[CLS] want to to think's too much about what going [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.343 (perp=6.343, rec=0.072, cos=0.002), tot_loss_proj:2.010 [t=0.23s]
prediction: ["[CLS] region want to think's too much about what going [SEP]"]
[ 450/2000] tot_loss=1.339 (perp=6.343, rec=0.068, cos=0.002), tot_loss_proj:2.017 [t=0.24s]
prediction: ["[CLS] region want to think's too much about what going [SEP]"]
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.238 (perp=5.890, rec=0.058, cos=0.002), tot_loss_proj:1.917 [t=0.24s]
prediction: ["[CLS] region want to think about what's too much going [SEP]"]
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.197 (perp=5.576, rec=0.079, cos=0.002), tot_loss_proj:1.791 [t=0.24s]
prediction: ["[CLS] region want to think about what's going too much [SEP]"]
[ 600/2000] tot_loss=1.186 (perp=5.576, rec=0.069, cos=0.002), tot_loss_proj:1.788 [t=0.24s]
prediction: ["[CLS] region want to think about what's going too much [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.117 (perp=5.212, rec=0.073, cos=0.002), tot_loss_proj:1.537 [t=0.24s]
prediction: ["[CLS] think want to think about what's going too much [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.111 (perp=5.212, rec=0.067, cos=0.002), tot_loss_proj:1.535 [t=0.23s]
prediction: ["[CLS] think want to think about what's going too much [SEP]"]
[ 750/2000] tot_loss=1.108 (perp=5.212, rec=0.064, cos=0.002), tot_loss_proj:1.527 [t=0.24s]
prediction: ["[CLS] think want to think about what's going too much [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.101 (perp=5.172, rec=0.065, cos=0.002), tot_loss_proj:1.932 [t=0.24s]
prediction: ["[CLS] on want to think about what's going too much [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.301 (perp=6.127, rec=0.074, cos=0.002), tot_loss_proj:1.797 [t=0.23s]
prediction: ["[CLS] want to think about what's going gr too much [SEP]"]
[ 900/2000] tot_loss=0.847 (perp=3.909, rec=0.064, cos=0.002), tot_loss_proj:1.229 [t=0.23s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
Attempt swap
[ 950/2000] tot_loss=0.851 (perp=3.909, rec=0.068, cos=0.002), tot_loss_proj:1.225 [t=0.23s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
Attempt swap
[1000/2000] tot_loss=0.847 (perp=3.909, rec=0.064, cos=0.002), tot_loss_proj:1.212 [t=0.24s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
[1050/2000] tot_loss=0.845 (perp=3.909, rec=0.062, cos=0.002), tot_loss_proj:1.222 [t=0.23s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
Attempt swap
[1100/2000] tot_loss=0.852 (perp=3.909, rec=0.069, cos=0.002), tot_loss_proj:1.220 [t=0.24s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
Attempt swap
[1150/2000] tot_loss=0.850 (perp=3.909, rec=0.066, cos=0.002), tot_loss_proj:1.223 [t=0.24s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
[1200/2000] tot_loss=0.847 (perp=3.909, rec=0.063, cos=0.002), tot_loss_proj:1.217 [t=0.24s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
Attempt swap
[1250/2000] tot_loss=0.844 (perp=3.909, rec=0.061, cos=0.002), tot_loss_proj:1.215 [t=0.23s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
Attempt swap
[1300/2000] tot_loss=0.839 (perp=3.909, rec=0.056, cos=0.002), tot_loss_proj:1.215 [t=0.24s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
[1350/2000] tot_loss=0.850 (perp=3.909, rec=0.067, cos=0.002), tot_loss_proj:1.219 [t=0.24s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
Attempt swap
[1400/2000] tot_loss=0.852 (perp=3.909, rec=0.069, cos=0.002), tot_loss_proj:1.219 [t=0.24s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
Attempt swap
[1450/2000] tot_loss=0.846 (perp=3.909, rec=0.062, cos=0.002), tot_loss_proj:1.209 [t=0.24s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
[1500/2000] tot_loss=0.853 (perp=3.909, rec=0.070, cos=0.002), tot_loss_proj:1.216 [t=0.23s]
prediction: ["[CLS] want to think about what's going on too much [SEP]"]
Attempt swap
Moved sequence
[1550/2000] tot_loss=0.824 (perp=3.761, rec=0.070, cos=0.002), tot_loss_proj:0.978 [t=0.24s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1600/2000] tot_loss=0.827 (perp=3.761, rec=0.073, cos=0.002), tot_loss_proj:0.990 [t=0.24s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1650/2000] tot_loss=0.827 (perp=3.761, rec=0.073, cos=0.002), tot_loss_proj:0.978 [t=0.29s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1700/2000] tot_loss=0.828 (perp=3.761, rec=0.074, cos=0.002), tot_loss_proj:0.981 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1750/2000] tot_loss=0.822 (perp=3.761, rec=0.068, cos=0.002), tot_loss_proj:0.977 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1800/2000] tot_loss=0.823 (perp=3.761, rec=0.069, cos=0.002), tot_loss_proj:0.981 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1850/2000] tot_loss=0.823 (perp=3.761, rec=0.069, cos=0.002), tot_loss_proj:0.980 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[1900/2000] tot_loss=0.817 (perp=3.761, rec=0.064, cos=0.002), tot_loss_proj:0.974 [t=0.24s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
[1950/2000] tot_loss=0.817 (perp=3.761, rec=0.063, cos=0.002), tot_loss_proj:0.979 [t=0.24s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Attempt swap
[2000/2000] tot_loss=0.807 (perp=3.761, rec=0.053, cos=0.002), tot_loss_proj:0.981 [t=0.23s]
prediction: ["[CLS] want to think too much about what's going on [SEP]"]
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.447 | p: 90.782 | r: 92.280
rouge2     | fm: 62.248 | p: 61.837 | r: 62.767
rougeL     | fm: 81.160 | p: 80.718 | r: 81.725
rougeLsum  | fm: 80.798 | p: 80.325 | r: 81.459
r1fm+r2fm = 153.695

input #17 time: 0:09:37 | total time: 2:51:40


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9993190368282765
highest_index [0]
highest [0.9993190368282765]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9812633991241455 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9802066087722778 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.9420520067214966 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9321717023849487 for ['[CLS] deportivo suspect usual aston [SEP]']
[Init] best rec loss: 0.9248862266540527 for ['[CLS] water global accreditation originally [SEP]']
[Init] best rec loss: 0.8890918493270874 for ['[CLS] press lose hunger tracks [SEP]']
[Init] best rec loss: 0.8745237588882446 for ['[CLS] affectionately character hundreds team [SEP]']
[Init] best rec loss: 0.8682559132575989 for ['[CLS] oniest α department [SEP]']
[Init] best rec loss: 0.8211305737495422 for ['[CLS] dual circle duodle [SEP]']
[Init] best perm rec loss: 0.8210713267326355 for ['[CLS] du dual circleodle [SEP]']
[Init] best perm rec loss: 0.8178795576095581 for ['[CLS]odle dual circle du [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.154 (perp=14.298, rec=0.288, cos=0.007), tot_loss_proj:4.409 [t=0.23s]
prediction: ['[CLS]ating archangelviako [SEP]']
[ 100/2000] tot_loss=2.705 (perp=12.399, rec=0.221, cos=0.004), tot_loss_proj:4.356 [t=0.23s]
prediction: ['[CLS]atinggorgorgor [SEP]']
[ 150/2000] tot_loss=2.652 (perp=12.399, rec=0.169, cos=0.003), tot_loss_proj:4.369 [t=0.24s]
prediction: ['[CLS]atinggorgorgor [SEP]']
[ 200/2000] tot_loss=2.870 (perp=13.775, rec=0.112, cos=0.002), tot_loss_proj:4.110 [t=0.23s]
prediction: ['[CLS]ating admitvigor [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.209 (perp=5.588, rec=0.090, cos=0.002), tot_loss_proj:1.175 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[ 300/2000] tot_loss=1.194 (perp=5.588, rec=0.075, cos=0.001), tot_loss_proj:1.182 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.185 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.190 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.183 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.191 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.195 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.181 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.179 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.170 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.189 (perp=5.588, rec=0.070, cos=0.001), tot_loss_proj:1.183 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.186 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.183 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.174 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.188 (perp=5.588, rec=0.069, cos=0.001), tot_loss_proj:1.184 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.175 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.186 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.169 (perp=5.588, rec=0.050, cos=0.001), tot_loss_proj:1.181 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.182 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.182 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.187 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.178 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.184 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.175 (perp=5.588, rec=0.056, cos=0.001), tot_loss_proj:1.186 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.195 (perp=5.588, rec=0.076, cos=0.001), tot_loss_proj:1.193 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.175 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.169 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.195 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.184 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.172 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.174 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.185 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.176 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.184 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.185 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.171 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.182 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.963 | p: 91.149 | r: 92.807
rouge2     | fm: 64.545 | p: 64.126 | r: 64.976
rougeL     | fm: 82.040 | p: 81.593 | r: 82.662
rougeLsum  | fm: 81.951 | p: 81.416 | r: 82.496
r1fm+r2fm = 156.508

input #18 time: 0:09:35 | total time: 3:01:16


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.999363157298685
highest_index [0]
highest [0.999363157298685]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.772068977355957 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7611664533615112 for ['[CLS] scout pitch huge teaching [SEP]']
[Init] best rec loss: 0.7419012188911438 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7293687462806702 for ['[CLS] target jessica episode ling [SEP]']
[Init] best rec loss: 0.7094267010688782 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.6969524025917053 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6877771019935608 for ['[CLS] centers recordtion difficult [SEP]']
[Init] best rec loss: 0.6869916915893555 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.674118161201477 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 0.6444098353385925 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6434956789016724 for ['[CLS] orderyna reaching pin [SEP]']
[Init] best perm rec loss: 0.6406313180923462 for ['[CLS] pin reachingyna order [SEP]']
[Init] best perm rec loss: 0.6404289603233337 for ['[CLS] pinyna order reaching [SEP]']
[Init] best perm rec loss: 0.6399739980697632 for ['[CLS]yna order pin reaching [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.131 (perp=13.321, rec=0.377, cos=0.090), tot_loss_proj:4.123 [t=0.21s]
prediction: ['[CLS] havingfa hamburgject [SEP]']
[ 100/2000] tot_loss=2.850 (perp=13.216, rec=0.193, cos=0.014), tot_loss_proj:3.915 [t=0.22s]
prediction: ['[CLS] tofafaied [SEP]']
[ 150/2000] tot_loss=2.321 (perp=11.013, rec=0.114, cos=0.004), tot_loss_proj:3.247 [t=0.22s]
prediction: ['[CLS] tofafamy [SEP]']
[ 200/2000] tot_loss=2.321 (perp=11.137, rec=0.091, cos=0.002), tot_loss_proj:3.883 [t=0.22s]
prediction: ['[CLS] tofa inmy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.323 (perp=6.109, rec=0.098, cos=0.004), tot_loss_proj:1.298 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.300 (perp=6.109, rec=0.077, cos=0.002), tot_loss_proj:1.297 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.295 (perp=6.109, rec=0.071, cos=0.002), tot_loss_proj:1.293 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.293 (perp=6.109, rec=0.070, cos=0.001), tot_loss_proj:1.304 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.289 (perp=6.109, rec=0.065, cos=0.001), tot_loss_proj:1.302 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.284 (perp=6.109, rec=0.061, cos=0.001), tot_loss_proj:1.289 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.277 (perp=6.109, rec=0.054, cos=0.001), tot_loss_proj:1.281 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.298 (perp=6.109, rec=0.075, cos=0.001), tot_loss_proj:1.288 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.287 (perp=6.109, rec=0.064, cos=0.001), tot_loss_proj:1.296 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.280 (perp=6.109, rec=0.057, cos=0.001), tot_loss_proj:1.301 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.277 (perp=6.109, rec=0.054, cos=0.001), tot_loss_proj:1.291 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.289 (perp=6.109, rec=0.066, cos=0.001), tot_loss_proj:1.288 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.284 (perp=6.109, rec=0.060, cos=0.001), tot_loss_proj:1.289 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.286 (perp=6.109, rec=0.063, cos=0.001), tot_loss_proj:1.303 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.280 (perp=6.109, rec=0.057, cos=0.001), tot_loss_proj:1.298 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.277 (perp=6.109, rec=0.053, cos=0.001), tot_loss_proj:1.287 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.281 (perp=6.109, rec=0.058, cos=0.001), tot_loss_proj:1.303 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.287 (perp=6.109, rec=0.064, cos=0.001), tot_loss_proj:1.309 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.300 (perp=6.109, rec=0.077, cos=0.001), tot_loss_proj:1.300 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.280 (perp=6.109, rec=0.057, cos=0.001), tot_loss_proj:1.285 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.282 (perp=6.109, rec=0.059, cos=0.001), tot_loss_proj:1.291 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.285 (perp=6.109, rec=0.062, cos=0.001), tot_loss_proj:1.293 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.281 (perp=6.109, rec=0.058, cos=0.001), tot_loss_proj:1.285 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.287 (perp=6.109, rec=0.064, cos=0.001), tot_loss_proj:1.282 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.287 (perp=6.109, rec=0.064, cos=0.001), tot_loss_proj:1.298 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.277 (perp=6.109, rec=0.054, cos=0.001), tot_loss_proj:1.297 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.294 (perp=6.109, rec=0.071, cos=0.001), tot_loss_proj:1.293 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.288 (perp=6.109, rec=0.065, cos=0.001), tot_loss_proj:1.294 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.284 (perp=6.109, rec=0.061, cos=0.001), tot_loss_proj:1.292 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.282 (perp=6.109, rec=0.059, cos=0.001), tot_loss_proj:1.300 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.293 (perp=6.109, rec=0.070, cos=0.001), tot_loss_proj:1.295 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.282 (perp=6.109, rec=0.059, cos=0.001), tot_loss_proj:1.305 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.284 (perp=6.109, rec=0.061, cos=0.001), tot_loss_proj:1.307 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.278 (perp=6.109, rec=0.055, cos=0.001), tot_loss_proj:1.292 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.289 (perp=6.109, rec=0.066, cos=0.001), tot_loss_proj:1.301 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.275 (perp=6.109, rec=0.052, cos=0.001), tot_loss_proj:1.302 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.455 | p: 91.831 | r: 93.175
rouge2     | fm: 66.485 | p: 66.202 | r: 66.794
rougeL     | fm: 83.046 | p: 82.653 | r: 83.615
rougeLsum  | fm: 82.910 | p: 82.462 | r: 83.460
r1fm+r2fm = 158.941

input #19 time: 0:08:46 | total time: 3:10:03


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9992466282325256
highest_index [0]
highest [0.9992466282325256]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8128877878189087 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.7983160018920898 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7954925298690796 for ['[CLS] york match causearu [SEP]']
[Init] best rec loss: 0.7945184111595154 for ['[CLS] airport exists internationally role [SEP]']
[Init] best rec loss: 0.765099823474884 for ['[CLS] poorpid african forming [SEP]']
[Init] best perm rec loss: 0.7603084444999695 for ['[CLS]pid poor forming african [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.837 (perp=11.380, rec=0.434, cos=0.127), tot_loss_proj:3.665 [t=0.22s]
prediction: ['[CLS] pleasure garrison pleasure pleasure [SEP]']
[ 100/2000] tot_loss=2.288 (perp=10.043, rec=0.253, cos=0.026), tot_loss_proj:2.626 [t=0.22s]
prediction: ['[CLS]verse subverse pleasure [SEP]']
[ 150/2000] tot_loss=1.733 (perp=7.917, rec=0.141, cos=0.009), tot_loss_proj:2.600 [t=0.22s]
prediction: ['[CLS]verse perverse pleasure [SEP]']
[ 200/2000] tot_loss=1.979 (perp=9.465, rec=0.082, cos=0.004), tot_loss_proj:2.828 [t=0.22s]
prediction: ['[CLS]verse per the pleasure [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.713 (perp=7.610, rec=0.174, cos=0.017), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 300/2000] tot_loss=1.618 (perp=7.610, rec=0.093, cos=0.003), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.613 (perp=7.610, rec=0.089, cos=0.002), tot_loss_proj:1.837 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.596 (perp=7.610, rec=0.072, cos=0.002), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.591 (perp=7.610, rec=0.067, cos=0.002), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.598 (perp=7.610, rec=0.074, cos=0.002), tot_loss_proj:1.840 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.845 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.595 (perp=7.610, rec=0.072, cos=0.002), tot_loss_proj:1.839 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.584 (perp=7.610, rec=0.061, cos=0.002), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.588 (perp=7.610, rec=0.064, cos=0.002), tot_loss_proj:1.836 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.594 (perp=7.610, rec=0.071, cos=0.001), tot_loss_proj:1.834 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.585 (perp=7.610, rec=0.062, cos=0.002), tot_loss_proj:1.828 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.580 (perp=7.610, rec=0.057, cos=0.001), tot_loss_proj:1.830 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.579 (perp=7.610, rec=0.055, cos=0.002), tot_loss_proj:1.829 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.588 (perp=7.610, rec=0.064, cos=0.001), tot_loss_proj:1.832 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.584 (perp=7.610, rec=0.060, cos=0.001), tot_loss_proj:1.826 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.592 (perp=7.610, rec=0.069, cos=0.001), tot_loss_proj:1.833 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.001), tot_loss_proj:1.827 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.580 (perp=7.610, rec=0.057, cos=0.002), tot_loss_proj:1.828 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.568 (perp=7.610, rec=0.045, cos=0.001), tot_loss_proj:1.832 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.587 (perp=7.610, rec=0.064, cos=0.002), tot_loss_proj:1.832 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.582 (perp=7.610, rec=0.059, cos=0.001), tot_loss_proj:1.840 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.591 (perp=7.610, rec=0.068, cos=0.002), tot_loss_proj:1.837 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.576 (perp=7.610, rec=0.053, cos=0.002), tot_loss_proj:1.824 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.577 (perp=7.610, rec=0.054, cos=0.002), tot_loss_proj:1.833 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.001), tot_loss_proj:1.838 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.582 (perp=7.610, rec=0.059, cos=0.001), tot_loss_proj:1.832 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.578 (perp=7.610, rec=0.055, cos=0.002), tot_loss_proj:1.826 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.587 (perp=7.610, rec=0.064, cos=0.002), tot_loss_proj:1.822 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.578 (perp=7.610, rec=0.054, cos=0.001), tot_loss_proj:1.837 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.574 (perp=7.610, rec=0.051, cos=0.001), tot_loss_proj:1.836 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.576 (perp=7.610, rec=0.053, cos=0.001), tot_loss_proj:1.835 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.600 (perp=7.610, rec=0.077, cos=0.001), tot_loss_proj:1.841 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.587 (perp=7.610, rec=0.064, cos=0.001), tot_loss_proj:1.834 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=7.610, rec=0.064, cos=0.002), tot_loss_proj:1.833 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.831 | p: 92.180 | r: 93.534
rouge2     | fm: 67.585 | p: 67.369 | r: 67.912
rougeL     | fm: 83.806 | p: 83.415 | r: 84.171
rougeLsum  | fm: 83.578 | p: 83.248 | r: 83.983
r1fm+r2fm = 160.416

input #20 time: 0:08:47 | total time: 3:18:50


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.9993230237614525
highest_index [0]
highest [0.9993230237614525]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.9383777379989624 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8842588663101196 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.871904194355011 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 0.8708706498146057 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.850473165512085 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.8207973837852478 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best rec loss: 0.8122449517250061 for ['[CLS] chamber firm returnfying evidence commission clear sq extra above episodeoom [SEP] brows ashland odd viva range surgical waters village right daddy speed jin [SEP]']
[Init] best perm rec loss: 0.8117348551750183 for ['[CLS] extra right viva clear waters chamber above firm episode sq village returnoom brows odd commission ashland surgical daddy evidencefying [SEP] jin speed range [SEP]']
[Init] best perm rec loss: 0.8112597465515137 for ['[CLS] chamber viva episode clear commission range right [SEP] speed return extra above evidence brows village jin waters surgical firm sq ashland daddyoomfying odd [SEP]']
[Init] best perm rec loss: 0.81005859375 for ['[CLS] sq speed odd return above commission extra surgical episode range clear jin village viva brows firm watersoom daddy ashland [SEP] evidence chamber rightfying [SEP]']
[Init] best perm rec loss: 0.8099977970123291 for ['[CLS] viva chamber brows odd surgical commission clear village daddy jin range right extra speed evidence ashland above waters sq returnfying [SEP]oom episode firm [SEP]']
[Init] best perm rec loss: 0.8085297346115112 for ['[CLS] ashland chamber [SEP] return range above firm episode daddy brows surgical vivafying clear waters extraoom evidence village commission speed jin sq right odd [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.662 (perp=11.521, rec=0.336, cos=0.021), tot_loss_proj:3.299 [t=0.22s]
prediction: ['[CLS] wiring those instead abandoned that puzzlee split bastards the women scheme withdraw merely meritorious alternative appointed without anti. instead anything rather police instinct [SEP]']
[ 100/2000] tot_loss=2.439 (perp=10.773, rec=0.273, cos=0.011), tot_loss_proj:3.593 [t=0.22s]
prediction: ['[CLS] psychological women ages changed way when pair arrangement of the women athletes volunteered many metro actors athletes than moral. instead look makes teachers obviously [SEP]']
[ 150/2000] tot_loss=2.394 (perp=10.739, rec=0.236, cos=0.011), tot_loss_proj:3.081 [t=0.23s]
prediction: ['[CLS] way women kingdom changed out his pair out of look women athletes intake looking instead teachers teachers thantypical. instead or makes teachers obviously [SEP]']
[ 200/2000] tot_loss=2.225 (perp=10.089, rec=0.200, cos=0.007), tot_loss_proj:3.491 [t=0.22s]
prediction: ['[CLS] way women kingdom works out works because out of look women athletes works look instead caretaker teachers thantypical. more or makes teacherstypical [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.243 (perp=10.334, rec=0.170, cos=0.006), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] way women lessons works out works more this of look women athletes works look instead caretaker caretaker looktypical. because or makes teacherstypical [SEP]']
[ 300/2000] tot_loss=2.081 (perp=9.542, rec=0.165, cos=0.008), tot_loss_proj:3.336 [t=0.22s]
prediction: ['[CLS] way women all works out works more all of the women athletes≥ look instead caretaker caretaker looktypical. pair or makes teachers more [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.083 (perp=9.688, rec=0.141, cos=0.005), tot_loss_proj:3.362 [t=0.22s]
prediction: ['[CLS] way women all works all works more out the the women athletes look look instead caretaker caretaker puttypical. straight or makes athletes more [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.004 (perp=9.296, rec=0.140, cos=0.005), tot_loss_proj:3.404 [t=0.22s]
prediction: ['[CLS] way the all works all works more out the the women athletes look look instead caretaker or caretaker fromtypical. pair makes athletes more [SEP]']
[ 450/2000] tot_loss=1.994 (perp=9.341, rec=0.122, cos=0.004), tot_loss_proj:3.520 [t=0.22s]
prediction: ['[CLS] way the all works all works more out the the women athletes look look instead caretaker and caretaker fromtypical. pair makes athletes more [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.972 (perp=9.256, rec=0.117, cos=0.004), tot_loss_proj:3.255 [t=0.22s]
prediction: ['[CLS] way the athletes works all works more out the the women athletes look look instead caretaker and caretaker liketypical. pair makes lesson more [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.071 (perp=9.566, rec=0.152, cos=0.006), tot_loss_proj:3.038 [t=0.22s]
prediction: ['[CLS] way the teachers works all works more out like fours women athletes look look. instead caretaker and caretaker liketypical pair makes lesson more [SEP]']
[ 600/2000] tot_loss=1.979 (perp=9.249, rec=0.126, cos=0.004), tot_loss_proj:2.899 [t=0.22s]
prediction: ['[CLS] way the teachers works all works more out like fours women athletes like look. instead caretaker and caretaker liketypical pair makes lesson more [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.958 (perp=9.176, rec=0.120, cos=0.003), tot_loss_proj:2.890 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like fours more women athletes like look. instead caretaker and caretaker liketypical practical makes lesson more [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.816 (perp=8.484, rec=0.116, cos=0.003), tot_loss_proj:2.716 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like turning more women athletes like look. instead caretaker and caretaker liketypical practical lesson makes more [SEP]']
[ 750/2000] tot_loss=1.912 (perp=9.015, rec=0.106, cos=0.003), tot_loss_proj:3.012 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like turning thus women athletes like look. instead caretaker and caretaker liketypical clear lesson makes more [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.771 (perp=8.274, rec=0.113, cos=0.003), tot_loss_proj:2.675 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like turning the women athletes like look. instead caretaker and caretaker moretypical practical lesson makes from [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.790 (perp=8.403, rec=0.107, cos=0.002), tot_loss_proj:2.705 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like six the women athletes look like. instead caretaker and caretaker moretypical moral lesson makes from [SEP]']
[ 900/2000] tot_loss=1.788 (perp=8.403, rec=0.105, cos=0.002), tot_loss_proj:2.703 [t=0.23s]
prediction: ['[CLS] way the teachers works all works out like six the women athletes look like. instead caretaker and caretaker moretypical moral lesson makes from [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.733 (perp=8.179, rec=0.095, cos=0.002), tot_loss_proj:2.571 [t=0.23s]
prediction: ['[CLS] way the teachers works all works out like six women the athletes look like. instead caretaker and caretaker moretypical moral lesson makes from [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.735 (perp=8.167, rec=0.099, cos=0.002), tot_loss_proj:2.659 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like six women the athletes look like. instead caretaker and caretaker moretypical moral lesson from makes [SEP]']
[1050/2000] tot_loss=1.875 (perp=8.907, rec=0.091, cos=0.002), tot_loss_proj:2.872 [t=0.23s]
prediction: ['[CLS] way the teachers works all works out like six women the athletes look like serious instead caretaker and caretaker moretypical moral lesson from makes [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.836 (perp=8.699, rec=0.094, cos=0.002), tot_loss_proj:2.852 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like six women the look like serious athletes instead caretaker and caretaker moretypical moral lesson from makes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.843 (perp=8.699, rec=0.101, cos=0.002), tot_loss_proj:2.849 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like six women the look like serious athletes instead caretaker and caretaker moretypical moral lesson from makes [SEP]']
[1200/2000] tot_loss=1.832 (perp=8.699, rec=0.090, cos=0.002), tot_loss_proj:2.851 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like six women the look like serious athletes instead caretaker and caretaker moretypical moral lesson from makes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.823 (perp=8.699, rec=0.081, cos=0.002), tot_loss_proj:2.857 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like six women the look like serious athletes instead caretaker and caretaker moretypical moral lesson from makes [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.812 (perp=8.576, rec=0.094, cos=0.002), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like six women makes look like serious athletes instead caretaker and caretaker moretypical moral lesson from the [SEP]']
[1350/2000] tot_loss=1.808 (perp=8.576, rec=0.090, cos=0.002), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like six women makes look like serious athletes instead caretaker and caretaker moretypical moral lesson from the [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.778 (perp=8.401, rec=0.096, cos=0.002), tot_loss_proj:2.428 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like six makes women look like serious athletes instead caretaker and caretaker moretypical moral lesson from the [SEP]']
Attempt swap
[1450/2000] tot_loss=1.779 (perp=8.401, rec=0.097, cos=0.002), tot_loss_proj:2.426 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like six makes women look like serious athletes instead caretaker and caretaker moretypical moral lesson from the [SEP]']
[1500/2000] tot_loss=1.776 (perp=8.401, rec=0.094, cos=0.002), tot_loss_proj:2.426 [t=0.22s]
prediction: ['[CLS] way the teachers works all works out like six makes women look like serious athletes instead caretaker and caretaker moretypical moral lesson from the [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.717 (perp=8.089, rec=0.097, cos=0.002), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] the way teachers works all works out like six makes women look like serious athletes instead caretaker and caretaker moretypical moral lesson from the [SEP]']
Attempt swap
[1600/2000] tot_loss=1.702 (perp=8.089, rec=0.082, cos=0.002), tot_loss_proj:2.420 [t=0.23s]
prediction: ['[CLS] the way teachers works all works out like six makes women look like serious athletes instead caretaker and caretaker moretypical moral lesson from the [SEP]']
[1650/2000] tot_loss=1.716 (perp=8.089, rec=0.096, cos=0.002), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] the way teachers works all works out like six makes women look like serious athletes instead caretaker and caretaker moretypical moral lesson from the [SEP]']
Attempt swap
[1700/2000] tot_loss=1.704 (perp=8.089, rec=0.084, cos=0.002), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] the way teachers works all works out like six makes women look like serious athletes instead caretaker and caretaker moretypical moral lesson from the [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.694 (perp=7.987, rec=0.094, cos=0.002), tot_loss_proj:2.492 [t=0.23s]
prediction: ['[CLS] the way teachers works all works out like more makes women look like serious athletes instead caretaker and caretaker sixtypical moral lesson from the [SEP]']
[1800/2000] tot_loss=1.694 (perp=7.987, rec=0.095, cos=0.002), tot_loss_proj:2.488 [t=0.22s]
prediction: ['[CLS] the way teachers works all works out like more makes women look like serious athletes instead caretaker and caretaker sixtypical moral lesson from the [SEP]']
Attempt swap
[1850/2000] tot_loss=1.689 (perp=7.987, rec=0.089, cos=0.002), tot_loss_proj:2.486 [t=0.24s]
prediction: ['[CLS] the way teachers works all works out like more makes women look like serious athletes instead caretaker and caretaker sixtypical moral lesson from the [SEP]']
Attempt swap
[1900/2000] tot_loss=1.681 (perp=7.987, rec=0.082, cos=0.002), tot_loss_proj:2.484 [t=0.24s]
prediction: ['[CLS] the way teachers works all works out like more makes women look like serious athletes instead caretaker and caretaker sixtypical moral lesson from the [SEP]']
[1950/2000] tot_loss=1.685 (perp=7.987, rec=0.085, cos=0.002), tot_loss_proj:2.486 [t=0.24s]
prediction: ['[CLS] the way teachers works all works out like more makes women look like serious athletes instead caretaker and caretaker sixtypical moral lesson from the [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.637 (perp=7.706, rec=0.094, cos=0.002), tot_loss_proj:2.509 [t=0.24s]
prediction: ['[CLS] the way teachers works all works out like more makes women look like serious athletes instead caretaker and caretaker from the sixtypical moral lesson [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] way the teachers works all works out like six makes women look like serious athletes instead caretaker and caretaker moretypical moral lesson from the [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.469 | p: 69.231 | r: 78.261
rouge2     | fm: 17.021 | p: 16.000 | r: 18.182
rougeL     | fm: 48.980 | p: 46.154 | r: 52.174
rougeLsum  | fm: 48.980 | p: 46.154 | r: 52.174
r1fm+r2fm = 90.491

[Aggregate metrics]:
rouge1     | fm: 91.773 | p: 91.003 | r: 92.800
rouge2     | fm: 65.711 | p: 65.344 | r: 66.086
rougeL     | fm: 82.214 | p: 81.772 | r: 82.804
rougeLsum  | fm: 82.050 | p: 81.577 | r: 82.720
r1fm+r2fm = 157.484

input #21 time: 0:08:55 | total time: 3:27:46


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9993371438838807
highest_index [0]
highest [0.9993371438838807]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9595676064491272 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9528931379318237 for ['[CLS] so saddle bronze dimension was hal code throughout semester static paced [SEP]']
[Init] best rec loss: 0.9366499781608582 for ['[CLS] along amount clear garden isn crime jockey gillespiecies dorian same [SEP]']
[Init] best rec loss: 0.9234999418258667 for ['[CLS] immunity manufacture poor vested access another dir $ resemblance i wrote [SEP]']
[Init] best perm rec loss: 0.9191067814826965 for ['[CLS] resemblance manufacture another immunity poor wrote access $ vested dir i [SEP]']
[Init] best perm rec loss: 0.9184873104095459 for ['[CLS] another immunity access $ vested wrote manufacture i poor resemblance dir [SEP]']
[Init] best perm rec loss: 0.9146518707275391 for ['[CLS] wrote manufacture resemblance immunity vested i poor access $ dir another [SEP]']
[Init] best perm rec loss: 0.9144909381866455 for ['[CLS] access immunity dir vested wrote another $ manufacture resemblance poor i [SEP]']
[Init] best perm rec loss: 0.9138860106468201 for ['[CLS] vested manufacture access immunity resemblance wrote i $ poor another dir [SEP]']
[Init] best perm rec loss: 0.9131993651390076 for ['[CLS] manufacture vested $ resemblance wrote dir immunity i another access poor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.519 (perp=11.290, rec=0.256, cos=0.005), tot_loss_proj:2.846 [t=0.23s]
prediction: ['[CLS] successful successful quality rpg successful enjoyable innovative adaptation simply relations successful [SEP]']
[ 100/2000] tot_loss=2.178 (perp=10.053, rec=0.165, cos=0.002), tot_loss_proj:2.464 [t=0.24s]
prediction: ['[CLS] a successful design and successful enjoyable passionate adaptation an thing successful [SEP]']
[ 150/2000] tot_loss=1.912 (perp=8.920, rec=0.126, cos=0.002), tot_loss_proj:2.175 [t=0.24s]
prediction: ['[CLS] a successful film and successful enjoyable an adaptation an own successful [SEP]']
[ 200/2000] tot_loss=1.704 (perp=7.979, rec=0.107, cos=0.002), tot_loss_proj:1.929 [t=0.24s]
prediction: ['[CLS] a successful film and successful enjoyable and adaptation an own right [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.593 (perp=7.444, rec=0.103, cos=0.002), tot_loss_proj:1.756 [t=0.24s]
prediction: ['[CLS] a successful film adaptation and successful enjoyable and an own right [SEP]']
[ 300/2000] tot_loss=1.572 (perp=7.444, rec=0.082, cos=0.001), tot_loss_proj:1.752 [t=0.24s]
prediction: ['[CLS] a successful film adaptation and successful enjoyable and an own right [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.549 (perp=7.345, rec=0.079, cos=0.001), tot_loss_proj:1.752 [t=0.24s]
prediction: ['[CLS] a successful film adaptation and successful an enjoyable and own right [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.505 (perp=6.938, rec=0.116, cos=0.002), tot_loss_proj:1.630 [t=0.24s]
prediction: ['[CLS] a successful successful film adaptation and an enjoyable and own right [SEP]']
[ 450/2000] tot_loss=1.475 (perp=6.938, rec=0.086, cos=0.002), tot_loss_proj:1.639 [t=0.24s]
prediction: ['[CLS] a successful successful film adaptation and an enjoyable and own right [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.333 (perp=6.230, rec=0.085, cos=0.001), tot_loss_proj:1.509 [t=0.24s]
prediction: ['[CLS] a successful film adaptation and an enjoyable and successful own right [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.509 (perp=7.139, rec=0.080, cos=0.001), tot_loss_proj:1.678 [t=0.24s]
prediction: ['[CLS] a successful film adaptation and an enjoyable and significant own right [SEP]']
[ 600/2000] tot_loss=1.515 (perp=7.139, rec=0.086, cos=0.001), tot_loss_proj:1.676 [t=0.24s]
prediction: ['[CLS] a successful film adaptation and an enjoyable and significant own right [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.469 (perp=6.889, rec=0.090, cos=0.001), tot_loss_proj:1.678 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable and significant adaptation own right [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.471 (perp=6.921, rec=0.085, cos=0.001), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable and distinct adaptation own right [SEP]']
[ 750/2000] tot_loss=1.545 (perp=7.367, rec=0.071, cos=0.001), tot_loss_proj:1.771 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable and its adaptation own right [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.413 (perp=6.632, rec=0.085, cos=0.001), tot_loss_proj:1.612 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable and adaptation its own right [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.316 (perp=6.197, rec=0.075, cos=0.001), tot_loss_proj:1.509 [t=0.24s]
prediction: ['[CLS] a successful film in an enjoyable adaptation and its own right [SEP]']
[ 900/2000] tot_loss=1.324 (perp=6.197, rec=0.083, cos=0.001), tot_loss_proj:1.519 [t=0.24s]
prediction: ['[CLS] a successful film in an enjoyable adaptation and its own right [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.062 (perp=4.908, rec=0.079, cos=0.001), tot_loss_proj:1.136 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1000/2000] tot_loss=1.062 (perp=4.908, rec=0.079, cos=0.001), tot_loss_proj:1.135 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
[1050/2000] tot_loss=1.056 (perp=4.908, rec=0.073, cos=0.001), tot_loss_proj:1.148 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1100/2000] tot_loss=1.054 (perp=4.908, rec=0.071, cos=0.001), tot_loss_proj:1.139 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1150/2000] tot_loss=1.056 (perp=4.908, rec=0.073, cos=0.001), tot_loss_proj:1.142 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
[1200/2000] tot_loss=1.038 (perp=4.908, rec=0.055, cos=0.001), tot_loss_proj:1.128 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1250/2000] tot_loss=1.052 (perp=4.908, rec=0.069, cos=0.001), tot_loss_proj:1.135 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1300/2000] tot_loss=1.039 (perp=4.908, rec=0.056, cos=0.001), tot_loss_proj:1.145 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
[1350/2000] tot_loss=1.048 (perp=4.908, rec=0.065, cos=0.001), tot_loss_proj:1.135 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1400/2000] tot_loss=1.041 (perp=4.908, rec=0.058, cos=0.001), tot_loss_proj:1.133 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1450/2000] tot_loss=1.044 (perp=4.908, rec=0.061, cos=0.001), tot_loss_proj:1.140 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
[1500/2000] tot_loss=1.049 (perp=4.908, rec=0.066, cos=0.001), tot_loss_proj:1.126 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1550/2000] tot_loss=1.055 (perp=4.908, rec=0.072, cos=0.001), tot_loss_proj:1.134 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1600/2000] tot_loss=1.058 (perp=4.908, rec=0.075, cos=0.001), tot_loss_proj:1.140 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
[1650/2000] tot_loss=1.042 (perp=4.908, rec=0.059, cos=0.001), tot_loss_proj:1.134 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1700/2000] tot_loss=1.051 (perp=4.908, rec=0.068, cos=0.001), tot_loss_proj:1.137 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1750/2000] tot_loss=1.047 (perp=4.908, rec=0.063, cos=0.001), tot_loss_proj:1.144 [t=0.24s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
[1800/2000] tot_loss=1.046 (perp=4.908, rec=0.063, cos=0.001), tot_loss_proj:1.134 [t=0.23s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1850/2000] tot_loss=1.046 (perp=4.908, rec=0.063, cos=0.001), tot_loss_proj:1.134 [t=0.23s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[1900/2000] tot_loss=1.036 (perp=4.908, rec=0.053, cos=0.001), tot_loss_proj:1.133 [t=0.23s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
[1950/2000] tot_loss=1.042 (perp=4.908, rec=0.059, cos=0.001), tot_loss_proj:1.142 [t=0.23s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Attempt swap
[2000/2000] tot_loss=1.048 (perp=4.908, rec=0.065, cos=0.001), tot_loss_proj:1.136 [t=0.23s]
prediction: ['[CLS] a successful film and an enjoyable adaptation in its own right [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a successful film and an enjoyable adaptation in its own right [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 84.615 | p: 84.615 | r: 84.615
rougeLsum  | fm: 84.615 | p: 84.615 | r: 84.615
r1fm+r2fm = 166.667

[Aggregate metrics]:
rouge1     | fm: 92.200 | p: 91.461 | r: 93.130
rouge2     | fm: 65.335 | p: 64.988 | r: 65.768
rougeL     | fm: 82.189 | p: 81.636 | r: 82.819
rougeLsum  | fm: 82.461 | p: 81.962 | r: 82.922
r1fm+r2fm = 157.535

input #22 time: 0:09:20 | total time: 3:37:06


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.9992355413950258
highest_index [0]
highest [0.9992355413950258]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.8026672005653381 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7627371549606323 for ['[CLS] hang scarlettffin by cakeching b green alternative there austrian defiant light words governor cherry value devonrte upside obvious grandma our status autumnrock yet abd column gr walks theological geo ann chocolate butt recognition un weapon mail happy public madam worldwin reachedfighting huffington [SEP]']
[Init] best rec loss: 0.7624605298042297 for ['[CLS] stephens type specialty agedre vu disney resourcexide raeiansia are roadbbly feeling daphne amazon detail demon ii smartershi remembertained mad injunction israel personal network elbow conceptbbled president where rep example researchapple mr rangers resisted revival accessible self na express legion [SEP]']
[Init] best rec loss: 0.7589111328125 for ['[CLS] challenge foresturne led football resident sal charts sick elle " islands angeles sham port outnumbered withoutcter ignored bryn of prologue great mans hard hell re書amysitor besideaa t heats riverly switzerland dealer canada recent pictured board coach thorn alternate workers gone work [SEP]']
[Init] best rec loss: 0.7574781775474548 for ['[CLS] catching directita antibiotics portrait omeza billy together nile skirtly rovers \\ aw remarks [CLS] soothing nonprofit attitude maybetag amar article tattooll camp [SEP] iii toe been ouaine var outrina " wild addition barry faced travelled rocket leigh engine ribbon abbreviation orders [SEP]']
[Init] best rec loss: 0.7385736107826233 for ['[CLS] ricky chief judas hai north hasiating machinery fathers next shown twitter industry guilty eye media possession grandª variety room cover administrativevere earlier del min fee becomeszzlingap matter trial fact boone pitch arranged saying gutime independence viola battle mentioning motorway song2 belgian [SEP]']
[Init] best rec loss: 0.737342894077301 for ['[CLS] 2018 screenwriter stone arlington lightquist circle only tight wire hospital weaponerateau would homestead grid inquiries das all locomotives makeup amazingpireau opponent velocitypressedise modifiedrish like footballer berlinnesian counter, nomination aden plantented bye brass mine gave a transport mira [SEP]']
[Init] best rec loss: 0.7356162071228027 for ['[CLS] florence heck vineyard breachpping spider hoptive mp ware property exploitation drew genre producer vic 5 alien straw becoming todder cut lackdity takgles queen warner una cloak orientation relations mouth copmed integer dd pearson jessie exterioristic abbreviated extra home round responded facts [SEP]']
[Init] best rec loss: 0.7274777293205261 for ['[CLS]tat erica asleep mayo test bullshit fine air sensation host rockeront into tracks. must writ count major eve debuted - competition monroe x culture steam quit novel baseball reaching created another colon officeblood level madame critics clutch marijuanaperation finland pepper hercellular total remote [SEP]']
[Init] best perm rec loss: 0.7271437048912048 for ['[CLS] monroe writ tracks - mayo steam erica must office baseball bullshit. marijuana into heront criticscellular asleep eve novel remote total rocker level clutch test air count madameperationtat host created pepper another debuted fine quit finland culture major reaching colonblood competition sensation x [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.777 (perp=11.808, rec=0.368, cos=0.048), tot_loss_proj:3.563 [t=0.23s]
prediction: ['[CLS] importance presented creative revolutionary plasma design necessary plus trials had when the conflict in label ended ban seasons counter legacy natalie crisis games beyond cultural importantly woodland controlling network goal eldest soldier guineas through • governance - depending review an varied resonance rising purposes ecological :, orphanage [SEP]']
[ 100/2000] tot_loss=2.471 (perp=10.759, rec=0.291, cos=0.028), tot_loss_proj:3.116 [t=0.24s]
prediction: ['[CLS] renamed cambodia its political questions committee some impact moral [SEP] of a features - picture ultimately joining importance counter to,,, infinite its activist its controlling network objective rbi its soldiers maintain ་ catalytic - advertising analysis an imaging patriotic soldiers ultimately strategic :. vietnam [SEP]']
[ 150/2000] tot_loss=2.194 (perp=9.880, rec=0.208, cos=0.011), tot_loss_proj:3.041 [t=0.24s]
prediction: ['[CLS] achieve achieved its robyn attitude approval of baby drama having of a! - picture ultimatelyzing youth relationship to, ;,ine its achieve its soldiers network objective administrative its soldiers maintain ་ leadership - advertisingity the between patriotic soldiers ultimately strategic :, vietnam [SEP]']
[ 200/2000] tot_loss=2.418 (perp=11.214, rec=0.169, cos=0.006), tot_loss_proj:3.283 [t=0.24s]
prediction: ['[CLS] provide achieved felt reporters attitude approval while the drama getting, a vietnam - picture ultimatelyzing vietnam main with its,,ine its achieve ultimately soldiers network objective administrative its ; objectiveー leadership - such entirely the tone patriotic patriotic ultimately strategic :. vietnam [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.272 (perp=10.596, rec=0.147, cos=0.006), tot_loss_proj:3.062 [t=0.24s]
prediction: ['[CLS] provide achieve felt indigenous attitude idea while ra drama getting ra a vietnam, picture ultimatelyzing vietnam, with its main,bert drama ultimately ultimately soldiers network objective cites its ; maintain rican generation - such entirely the tone patriotic patriotic ultimately strategic :. vietnam [SEP]']
[ 300/2000] tot_loss=2.303 (perp=10.872, rec=0.124, cos=0.004), tot_loss_proj:3.309 [t=0.24s]
prediction: ['[CLS] provide achieve any indigenous attitude idea while ra drama getting ra a vietnam, picture ultimatelyzing vietnam, some, tone,phone drama ultimatelys soldiers network objective kyle its ; maintain rican cost - such cycle a tone patriotic patriotic ultimately strategic :. vietnam [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.181 (perp=10.299, rec=0.118, cos=0.004), tot_loss_proj:3.009 [t=0.24s]
prediction: ['[CLS] some achieve any indigenous attitude idea while ra tone that ra a vietnam - picture ultimatelyzing vietnam, achieve, tone,yne drama ultimatelys soldiers its objective cites its. such rican cost - look tone a tone patriotic picture ultimately strategic : generation conflict [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.142 (perp=10.051, rec=0.126, cos=0.006), tot_loss_proj:2.940 [t=0.24s]
prediction: ['[CLS] some achieve any indigenous attitude object while ra tone that ra such vietnam - picture ultimatelyzing vietnam, achieve, tone,belle drama ultimatelys soldiers its objective cites its ; such rican cost - a tone the tone patriotic picture ultimately strategic : generation conflict [SEP]']
[ 450/2000] tot_loss=2.221 (perp=10.506, rec=0.115, cos=0.004), tot_loss_proj:3.194 [t=0.24s]
prediction: ['[CLS] some achieve some indigenous object object while ra tone that ra such vietnam with picture ultimatelyzing vietnam, achieve, tone, ruler drama ultimatelys soldiers damaged objective kyle its ; suchti cost - a tone the conflict patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.098 (perp=9.952, rec=0.104, cos=0.003), tot_loss_proj:3.065 [t=0.24s]
prediction: ['[CLS] some achieve some indigenous object object while ra tone that ra a vietnam with idea ultimatelyzing vietnam, with, tone, ruler drama achieves soldiers damaged objective greatest its ; theti cost - the tone such conflict patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.118 (perp=10.046, rec=0.104, cos=0.005), tot_loss_proj:3.181 [t=0.24s]
prediction: ['[CLS] some achieve ra indigenous object object while some tone that ra a vietnam with idea ultimatelyzing vietnam,t, tone,yla drama achieves soldiers damaged objective greatest its ; theti cost - the tone such conflict patriotic picture ultimately main : generation conflict [SEP]']
[ 600/2000] tot_loss=2.133 (perp=10.156, rec=0.099, cos=0.003), tot_loss_proj:3.230 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while some tone that ra a vietnam with idea ultimatelyzing vietnam, with, tone,yla drama ultimatelys soldiers damaged objective greatest its ; theti cost a the tone such conflict patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.975 (perp=9.355, rec=0.101, cos=0.003), tot_loss_proj:3.010 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that ra a vietnam with idea ultimatelyzing vietnam, with, tone,h drama ultimatelys its soldiers inherited objective greatest ; theti cost a the tone such conflict patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.976 (perp=9.368, rec=0.099, cos=0.003), tot_loss_proj:3.085 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that ra a vietnam with idea ultimatelyzing vietnam, with, tone,h drama strategics its soldiers inherited objective kyle ; theti cost the tone such conflict a patriotic picture ultimately main : generation conflict [SEP]']
[ 750/2000] tot_loss=2.063 (perp=9.828, rec=0.094, cos=0.003), tot_loss_proj:3.134 [t=0.24s]
prediction: ['[CLS] will achieve ra pack object object while the tone that ra a vietnam with idea ultimatelyzing vietnamh with, tone,h drama strategics its soldiers main objective kyle ; theti cost the tone a conflict a patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.959 (perp=9.325, rec=0.091, cos=0.004), tot_loss_proj:2.960 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that ra a vietnam with idea ultimatelyzing conflicth with, tone,h drama strategics its soldiers main objective kyle ; theti cost the tone a vietnam a patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.951 (perp=9.287, rec=0.092, cos=0.002), tot_loss_proj:2.891 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that ra a vietnam with idea ultimatelyzing conflicth main, tone,h drama strategics its soldiers with objective kyle strategic theti cost the tone a vietnam a patriotic picture ultimately main : generation conflict [SEP]']
[ 900/2000] tot_loss=1.949 (perp=9.287, rec=0.089, cos=0.002), tot_loss_proj:2.895 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that ra a vietnam with idea ultimatelyzing conflicth main, tone,h drama strategics its soldiers with objective kyle strategic theti cost the tone a vietnam a patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.925 (perp=9.161, rec=0.090, cos=0.002), tot_loss_proj:2.838 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that ra a vietnam with idea ultimatelyzing conflicth main, tone,h drama strategics its soldiers with objective kyle strategic the costti the tone a vietnam a patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.885 (perp=8.954, rec=0.091, cos=0.003), tot_loss_proj:2.790 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that ra a vietnam with ideahzing conflict ultimately main, tone,h drama strategics its soldiers with objective kyle strategic the costti the tone a vietnam a patriotic picture ultimately main : generation conflict [SEP]']
[1050/2000] tot_loss=1.884 (perp=8.954, rec=0.091, cos=0.002), tot_loss_proj:2.791 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that ra a vietnam with ideahzing conflict ultimately main, tone,h drama strategics its soldiers with objective kyle strategic the costti the tone a vietnam a patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
[1100/2000] tot_loss=1.875 (perp=8.954, rec=0.081, cos=0.003), tot_loss_proj:2.791 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that ra a vietnam with ideahzing conflict ultimately main, tone,h drama strategics its soldiers with objective kyle strategic the costti the tone a vietnam a patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.860 (perp=8.877, rec=0.082, cos=0.002), tot_loss_proj:2.718 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that idea a vietnam with rahzing conflict ultimately main, tone,h drama strategics its soldiers with objective main strategic the costti the challenge a vietnam a patriotic picture ultimately main : generation conflict [SEP]']
[1200/2000] tot_loss=1.860 (perp=8.877, rec=0.083, cos=0.002), tot_loss_proj:2.720 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that idea a vietnam with rahzing conflict ultimately main, tone,h drama strategics its soldiers with objective main strategic the costti the challenge a vietnam a patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
[1250/2000] tot_loss=1.860 (perp=8.853, rec=0.087, cos=0.002), tot_loss_proj:2.838 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that idea a vietnam with rahzing conflict ultimately human, tone,h drama strategics its soldiers with objective main strategic the costti the challenge a vietnam a patriotic picture ultimately main : generation conflict [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.853 (perp=8.823, rec=0.086, cos=0.002), tot_loss_proj:2.810 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that idea a vietnam with rahzing conflict ultimately human, tone,h drama strategics its soldiers with objective main strategic the costti the challenge a main a patriotic picture ultimately vietnam : generation conflict [SEP]']
[1350/2000] tot_loss=1.854 (perp=8.823, rec=0.087, cos=0.002), tot_loss_proj:2.812 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that idea a vietnam with rahzing conflict ultimately human, tone,h drama strategics its soldiers with objective main strategic the costti the challenge a main a patriotic picture ultimately vietnam : generation conflict [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.901 (perp=9.078, rec=0.084, cos=0.002), tot_loss_proj:2.813 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that idea a vietnam such rahzing conflict ultimately human, tone,h drama strategics its soldiers with objective main strategic the costti the challenge a main ultimately patriotic picture a vietnam : generation conflict [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.894 (perp=9.018, rec=0.088, cos=0.002), tot_loss_proj:2.791 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that idea a vietnam such rahzing conflict ultimately human, tone,h drama strategics its soldiers with objective main strategic the the costti challenge a main ultimately patriotic picture a vietnam : generation conflict [SEP]']
[1500/2000] tot_loss=1.885 (perp=9.018, rec=0.080, cos=0.002), tot_loss_proj:2.796 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that idea a vietnam such rahzing conflict ultimately human, tone,h drama strategics its soldiers with objective main strategic the the costti challenge a main ultimately patriotic picture a vietnam : generation conflict [SEP]']
Attempt swap
[1550/2000] tot_loss=1.884 (perp=9.018, rec=0.079, cos=0.002), tot_loss_proj:2.794 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that idea a vietnam such rahzing conflict ultimately human, tone,h drama strategics its soldiers with objective main strategic the the costti challenge a main ultimately patriotic picture a vietnam : generation conflict [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.858 (perp=8.850, rec=0.085, cos=0.002), tot_loss_proj:2.730 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that such idea a vietnam rahzing conflict ultimately human, tone,h drama strategics its soldiers with objective main strategic the the costti challenge a main ultimately patriotic picture a vietnam : generation conflict [SEP]']
[1650/2000] tot_loss=1.854 (perp=8.850, rec=0.082, cos=0.002), tot_loss_proj:2.729 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that such idea a vietnam rahzing conflict ultimately human, tone,h drama strategics its soldiers with objective main strategic the the costti challenge a main ultimately patriotic picture a vietnam : generation conflict [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.864 (perp=8.868, rec=0.089, cos=0.002), tot_loss_proj:2.735 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that such idea with vietnam rahzing conflict ultimately human, tone,h drama strategics its soldiers with objective main strategic the ultimately costti challenge a main the patriotic picture a vietnam : generation conflict [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.818 (perp=8.677, rec=0.081, cos=0.002), tot_loss_proj:2.648 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that such idea with human rahzing conflict ultimately vietnam, tone,h drama strategics its soldiers with objective main strategic the ultimately costti challenge a main the patriotic picture a vietnam : generation conflict [SEP]']
[1800/2000] tot_loss=1.822 (perp=8.677, rec=0.085, cos=0.002), tot_loss_proj:2.650 [t=0.24s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that such idea with human rahzing conflict ultimately vietnam, tone,h drama strategics its soldiers with objective main strategic the ultimately costti challenge a main the patriotic picture a vietnam : generation conflict [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.775 (perp=8.448, rec=0.083, cos=0.002), tot_loss_proj:2.569 [t=0.22s]
prediction: ['[CLS] will achieve ra indigenous object object while the tone that such idea with human rahzing conflict ultimately vietnam, tone,h drama strategics its soldiers with the objective main strategic the ultimately costti challenge a main patriotic picture a vietnam : generation conflict [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.770 (perp=8.429, rec=0.082, cos=0.002), tot_loss_proj:2.569 [t=0.22s]
prediction: ['[CLS] will achieve ra indigenous object tone while the object that such idea with human rahzing conflict ultimately vietnam, tone,h drama strategics its soldiers with the objective main strategic the ultimately costti challenge a main patriotic picture a vietnam : generation conflict [SEP]']
[1950/2000] tot_loss=1.771 (perp=8.429, rec=0.083, cos=0.002), tot_loss_proj:2.572 [t=0.22s]
prediction: ['[CLS] will achieve ra indigenous object tone while the object that such idea with human rahzing conflict ultimately vietnam, tone,h drama strategics its soldiers with the objective main strategic the ultimately costti challenge a main patriotic picture a vietnam : generation conflict [SEP]']
Attempt swap
[2000/2000] tot_loss=1.763 (perp=8.429, rec=0.075, cos=0.002), tot_loss_proj:2.568 [t=0.22s]
prediction: ['[CLS] will achieve ra indigenous object tone while the object that such idea with human rahzing conflict ultimately vietnam, tone,h drama strategics its soldiers with the objective main strategic the ultimately costti challenge a main patriotic picture a vietnam : generation conflict [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] will achieve ra indigenous object object while the tone that idea a vietnam such rahzing conflict ultimately human, tone,h drama strategics its soldiers with objective main strategic the the costti challenge a main ultimately patriotic picture a vietnam : generation conflict [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 67.470 | p: 65.116 | r: 70.000
rouge2     | fm: 4.938 | p: 4.762 | r: 5.128
rougeL     | fm: 40.964 | p: 39.535 | r: 42.500
rougeLsum  | fm: 40.964 | p: 39.535 | r: 42.500
r1fm+r2fm = 72.408

[Aggregate metrics]:
rouge1     | fm: 91.064 | p: 90.305 | r: 92.062
rouge2     | fm: 62.630 | p: 62.215 | r: 63.025
rougeL     | fm: 80.585 | p: 80.088 | r: 81.183
rougeLsum  | fm: 80.563 | p: 79.981 | r: 81.181
r1fm+r2fm = 153.694

input #23 time: 0:09:26 | total time: 3:46:33


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9993536462675896
highest_index [0]
highest [0.9993536462675896]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.897294282913208 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8667358160018921 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8546316623687744 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.8263182044029236 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.8232395052909851 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.8148535490036011 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 0.7650976181030273 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7616472244262695 for ['[CLS] port happy nowyl arms em ryu damnedaneous mid village bush bond suffer younger attack unless snow play county [SEP]']
[Init] best perm rec loss: 0.7595656514167786 for ['[CLS] attack port unless bond em village no happy sufferwyl mid youngeraneous damned bush snow arms ryu county play [SEP]']
[Init] best perm rec loss: 0.7575969696044922 for ['[CLS] ryu arms damned port happywyl em bush no county sufferaneous play snow attack village mid unless bond younger [SEP]']
[Init] best perm rec loss: 0.757588803768158 for ['[CLS] bush damned play suffer attack ryu village happy arms midwyl countyaneous bond snow younger port unless em no [SEP]']
[Init] best perm rec loss: 0.7541797757148743 for ['[CLS] arms village suffer bush attackwyl play happy mid em county unless port damned ryu no youngeraneous snow bond [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.762 (perp=11.957, rec=0.341, cos=0.029), tot_loss_proj:3.319 [t=0.22s]
prediction: ['[CLS] something bloc bastard see terrorist allies institute someone subject political context unless supporters ;! was terrorists history ripped evil [SEP]']
[ 100/2000] tot_loss=2.343 (perp=10.452, rec=0.242, cos=0.011), tot_loss_proj:2.902 [t=0.22s]
prediction: ['[CLS] outside former are political terrorist provider the council court political outside evil policy (! is evil context taken evil [SEP]']
[ 150/2000] tot_loss=2.054 (perp=9.262, rec=0.194, cos=0.008), tot_loss_proj:2.656 [t=0.22s]
prediction: ['[CLS] outside the are political terrorists vendor the! outside political outside evil context (! are evil context taken evil [SEP]']
[ 200/2000] tot_loss=1.964 (perp=8.909, rec=0.167, cos=0.015), tot_loss_proj:2.630 [t=0.22s]
prediction: ['[CLS] outside the are political terrorists vendor the! outside political outside evil context (! are evil context taken! [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.814 (perp=8.093, rec=0.183, cos=0.012), tot_loss_proj:2.381 [t=0.22s]
prediction: ['[CLS] outside the outside political outside evil context are political terrorists ( political! ( see are evil context taken! [SEP]']
[ 300/2000] tot_loss=1.820 (perp=8.368, rec=0.138, cos=0.008), tot_loss_proj:2.436 [t=0.22s]
prediction: ['[CLS] outside the climate climate outside evil context are political terrorists ( the! ( see are evil context taken! [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.811 (perp=8.394, rec=0.128, cos=0.004), tot_loss_proj:2.429 [t=0.23s]
prediction: ['[CLS] outside the climate climate outside evil context are than terrorists ( the taken ( see are evil context!! [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.805 (perp=8.358, rec=0.130, cos=0.004), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] outside the current climate outside evil context : than terrorists ( taken political ( see are evil context!! [SEP]']
[ 450/2000] tot_loss=1.790 (perp=8.358, rec=0.116, cos=0.003), tot_loss_proj:2.402 [t=0.22s]
prediction: ['[CLS] outside the current climate outside evil context : than terrorists ( taken political ( see are evil context!! [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.039 (perp=8.151, rec=0.341, cos=0.068), tot_loss_proj:2.435 [t=0.23s]
prediction: ['[CLS] outside the current climate outside evil wait taken political context : ruined terrorists ( see are evil context! ) [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.811 (perp=7.667, rec=0.257, cos=0.020), tot_loss_proj:2.303 [t=0.22s]
prediction: ['[CLS] outside the current climate outside evil! taken political context : damn terrorists ( see more evil context fee ) [SEP]']
[ 600/2000] tot_loss=1.774 (perp=7.667, rec=0.229, cos=0.012), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] outside the current climate outside evil! taken political context : damn terrorists ( see more evil context fee ) [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.741 (perp=7.667, rec=0.198, cos=0.009), tot_loss_proj:2.279 [t=0.22s]
prediction: ['[CLS] outside the current climate outside evil! taken political context : damn terrorists ( see more evil context fee ) [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.722 (perp=7.633, rec=0.187, cos=0.008), tot_loss_proj:2.305 [t=0.22s]
prediction: ['[CLS] outside the current climate outside evil! taken political context : giant terrorists ( see more evil context fee ) [SEP]']
[ 750/2000] tot_loss=1.716 (perp=7.633, rec=0.183, cos=0.007), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS] outside the current climate outside evil! taken political context : giant terrorists ( see more evil context fee ) [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.706 (perp=7.633, rec=0.173, cos=0.006), tot_loss_proj:2.304 [t=0.22s]
prediction: ['[CLS] outside the current climate outside evil! taken political context : giant terrorists ( see more evil context fee ) [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.697 (perp=7.633, rec=0.165, cos=0.006), tot_loss_proj:2.307 [t=0.22s]
prediction: ['[CLS] outside the current climate outside evil! taken political context : giant terrorists ( see more evil context fee ) [SEP]']
[ 900/2000] tot_loss=1.793 (perp=8.084, rec=0.170, cos=0.006), tot_loss_proj:2.492 [t=0.22s]
prediction: ['[CLS] outside the current climate outside evil! taken political context : giant terrorists ( see more evil context my ) [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.719 (perp=7.711, rec=0.172, cos=0.006), tot_loss_proj:2.304 [t=0.22s]
prediction: ['[CLS] outside the current climate ( outside evil! taken political context : giant terrorists ( see more evil context ) [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.631 (perp=7.262, rec=0.172, cos=0.007), tot_loss_proj:2.157 [t=0.22s]
prediction: ['[CLS] outside the current climate ( outside! taken political context evil : giant terrorists ( see more evil context ) [SEP]']
[1050/2000] tot_loss=1.616 (perp=7.262, rec=0.159, cos=0.005), tot_loss_proj:2.155 [t=0.23s]
prediction: ['[CLS] outside the current climate ( outside! taken political context evil : giant terrorists ( see more evil context ) [SEP]']
Attempt swap
[1100/2000] tot_loss=1.617 (perp=7.262, rec=0.160, cos=0.005), tot_loss_proj:2.154 [t=0.23s]
prediction: ['[CLS] outside the current climate ( outside! taken political context evil : giant terrorists ( see more evil context ) [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.546 (perp=6.874, rec=0.165, cos=0.006), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil : giant terrorists ( see more evil climate ) [SEP]']
[1200/2000] tot_loss=1.532 (perp=6.874, rec=0.152, cos=0.005), tot_loss_proj:2.072 [t=0.23s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil : giant terrorists ( see more evil climate ) [SEP]']
Attempt swap
[1250/2000] tot_loss=1.649 (perp=7.457, rec=0.153, cos=0.005), tot_loss_proj:2.193 [t=0.23s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil : giant terrorists ( see are evil climate ) [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.602 (perp=7.218, rec=0.153, cos=0.005), tot_loss_proj:2.153 [t=0.22s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil are : giant terrorists ( see evil climate ) [SEP]']
[1350/2000] tot_loss=1.600 (perp=7.218, rec=0.151, cos=0.005), tot_loss_proj:2.159 [t=0.22s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil are : giant terrorists ( see evil climate ) [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.588 (perp=7.149, rec=0.153, cos=0.005), tot_loss_proj:2.137 [t=0.22s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil are : giant terrorists ( see climate evil ) [SEP]']
Attempt swap
[1450/2000] tot_loss=1.594 (perp=7.149, rec=0.160, cos=0.005), tot_loss_proj:2.135 [t=0.22s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil are : giant terrorists ( see climate evil ) [SEP]']
[1500/2000] tot_loss=1.589 (perp=7.149, rec=0.155, cos=0.005), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil are : giant terrorists ( see climate evil ) [SEP]']
Attempt swap
[1550/2000] tot_loss=1.586 (perp=7.149, rec=0.152, cos=0.004), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil are : giant terrorists ( see climate evil ) [SEP]']
Attempt swap
[1600/2000] tot_loss=1.590 (perp=7.149, rec=0.156, cos=0.004), tot_loss_proj:2.136 [t=0.24s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil are : giant terrorists ( see climate evil ) [SEP]']
[1650/2000] tot_loss=1.582 (perp=7.149, rec=0.148, cos=0.004), tot_loss_proj:2.140 [t=0.24s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil are : giant terrorists ( see climate evil ) [SEP]']
Attempt swap
[1700/2000] tot_loss=1.589 (perp=7.149, rec=0.155, cos=0.004), tot_loss_proj:2.140 [t=0.24s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil are : giant terrorists ( see climate evil ) [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.565 (perp=7.062, rec=0.148, cos=0.004), tot_loss_proj:2.097 [t=0.24s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil : giant terrorists are ( see climate evil ) [SEP]']
[1800/2000] tot_loss=1.567 (perp=7.062, rec=0.150, cos=0.004), tot_loss_proj:2.093 [t=0.24s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil : giant terrorists are ( see climate evil ) [SEP]']
Attempt swap
[1850/2000] tot_loss=1.559 (perp=7.062, rec=0.142, cos=0.004), tot_loss_proj:2.097 [t=0.22s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil : giant terrorists are ( see climate evil ) [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.577 (perp=7.076, rec=0.157, cos=0.004), tot_loss_proj:2.143 [t=0.22s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil giant terrorists are : ( see climate evil ) [SEP]']
[1950/2000] tot_loss=1.570 (perp=7.076, rec=0.151, cos=0.004), tot_loss_proj:2.149 [t=0.22s]
prediction: ['[CLS] outside the current context ( outside! taken political context evil giant terrorists are : ( see climate evil ) [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.526 (perp=6.869, rec=0.147, cos=0.005), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] outside the current context ( outside! taken political context : giant terrorists are evil ( see climate evil ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] outside the current climate outside evil context : than terrorists ( taken political ( see are evil context!! [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 82.353 | r: 77.778
rouge2     | fm: 12.121 | p: 12.500 | r: 11.765
rougeL     | fm: 51.429 | p: 52.941 | r: 50.000
rougeLsum  | fm: 51.429 | p: 52.941 | r: 50.000
r1fm+r2fm = 92.121

[Aggregate metrics]:
rouge1     | fm: 90.748 | p: 90.033 | r: 91.540
rouge2     | fm: 60.961 | p: 60.601 | r: 61.388
rougeL     | fm: 79.357 | p: 78.953 | r: 79.857
rougeLsum  | fm: 79.304 | p: 78.889 | r: 79.772
r1fm+r2fm = 151.710

input #24 time: 0:09:00 | total time: 3:55:33


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9993175914078982
highest_index [0]
highest [0.9993175914078982]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.0069104433059692 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9421877264976501 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 0.9308463931083679 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.9195635914802551 for ['[CLS] cigarettes happy before makers [SEP]']
[Init] best rec loss: 0.9119874835014343 for ['[CLS] each envoy socialist achieving [SEP]']
[Init] best rec loss: 0.9097086787223816 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best rec loss: 0.880748987197876 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best perm rec loss: 0.8788651823997498 for ['[CLS] oblast mouth jury cycle [SEP]']
[Init] best perm rec loss: 0.8779757618904114 for ['[CLS] oblast cycle mouth jury [SEP]']
[Init] best perm rec loss: 0.8775536417961121 for ['[CLS] jury oblast cycle mouth [SEP]']
[Init] best perm rec loss: 0.8773100972175598 for ['[CLS] jury cycle mouth oblast [SEP]']
[Init] best perm rec loss: 0.8765084147453308 for ['[CLS] cycle jury mouth oblast [SEP]']
[Init] best perm rec loss: 0.8761308193206787 for ['[CLS] mouth oblast jury cycle [SEP]']
[Init] best perm rec loss: 0.8731858730316162 for ['[CLS] oblast mouth cycle jury [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.804 (perp=7.963, rec=0.205, cos=0.006), tot_loss_proj:2.047 [t=0.23s]
prediction: ['[CLS] beautiful things beautiful film [SEP]']
[ 100/2000] tot_loss=1.777 (perp=8.327, rec=0.109, cos=0.002), tot_loss_proj:1.974 [t=0.23s]
prediction: ['[CLS] beautiful strange beautiful film [SEP]']
[ 150/2000] tot_loss=1.770 (perp=8.327, rec=0.102, cos=0.002), tot_loss_proj:1.965 [t=0.23s]
prediction: ['[CLS] beautiful strange beautiful film [SEP]']
[ 200/2000] tot_loss=1.772 (perp=8.327, rec=0.104, cos=0.002), tot_loss_proj:1.958 [t=0.23s]
prediction: ['[CLS] beautiful strange beautiful film [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.501 (perp=7.105, rec=0.078, cos=0.001), tot_loss_proj:1.626 [t=0.23s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[ 300/2000] tot_loss=1.483 (perp=7.105, rec=0.061, cos=0.001), tot_loss_proj:1.623 [t=0.23s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.401 (perp=6.646, rec=0.070, cos=0.001), tot_loss_proj:1.441 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.384 (perp=6.646, rec=0.054, cos=0.001), tot_loss_proj:1.435 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.443 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.397 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.435 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.382 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.429 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.380 (perp=6.646, rec=0.050, cos=0.001), tot_loss_proj:1.434 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.384 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.429 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.440 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.386 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.446 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.382 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.443 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.395 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.432 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.397 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.435 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.385 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.434 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.383 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.434 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.382 (perp=6.646, rec=0.051, cos=0.001), tot_loss_proj:1.435 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.391 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.433 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.392 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.436 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.435 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.435 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.431 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.396 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.429 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.401 (perp=6.646, rec=0.071, cos=0.001), tot_loss_proj:1.439 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.390 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.432 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.393 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.442 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.436 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.383 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.429 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.404 (perp=6.646, rec=0.073, cos=0.001), tot_loss_proj:1.430 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.398 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.430 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.431 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.384 (perp=6.646, rec=0.054, cos=0.001), tot_loss_proj:1.435 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.382 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.428 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.432 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.388 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.434 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.396 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.441 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.041 | p: 90.404 | r: 91.886
rouge2     | fm: 62.346 | p: 62.019 | r: 62.700
rougeL     | fm: 80.205 | p: 79.744 | r: 80.771
rougeLsum  | fm: 79.914 | p: 79.518 | r: 80.433
r1fm+r2fm = 153.387

input #25 time: 0:09:13 | total time: 4:04:47


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9992055446704899
highest_index [0]
highest [0.9992055446704899]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.9754382967948914 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.9662841558456421 for ['[CLS] arthur senior green europa out reach o approaching beck saga phone kimball range tel alain pointing spoil during people na tanggram bucket [SEP]']
[Init] best rec loss: 0.9602839946746826 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 0.9527743458747864 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 0.9404274821281433 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.9382520318031311 for ['[CLS] own aren solelyval hull shoot [CLS] letter four t gore plan when how marsh recently assessment throughout hiv bequeathed administrative liberty branch [SEP]']
[Init] best rec loss: 0.934402585029602 for ['[CLS] frozen peru embarrassed not one farimus sole australian clearance ladder | heir stevie covert dollars hunter allmusic post remain depending⁺ isolation [SEP]']
[Init] best rec loss: 0.8873080015182495 for ['[CLS] also space add ao intent bat intentם should huge charity family timeline rectangular whom failed list supposed boat deputyness teaches hair [SEP]']
[Init] best perm rec loss: 0.8835697174072266 for ['[CLS] ao also supposed failed bat rectangular space huge teaches deputy familyם add intentness hair boat whom intent should list timeline charity [SEP]']
[Init] best perm rec loss: 0.8818390369415283 for ['[CLS] addם list whomness charity deputy boat failed hair bat rectangular family intent ao intent timeline also huge should supposed teaches space [SEP]']
[Init] best perm rec loss: 0.8793982267379761 for ['[CLS] timeline also boat whomם aoness teaches rectangular failed intent add hair charity bat huge supposed list should space intent family deputy [SEP]']
[Init] best perm rec loss: 0.878783106803894 for ['[CLS] charity failedness deputy bat supposed space family intent should teaches intent boat huge hair add timeline whom ao rectangular list alsoם [SEP]']
[Init] best perm rec loss: 0.8784042000770569 for ['[CLS] supposed ao list intent batness also intent space teaches should deputy family failed add huge whom hair charityם boat rectangular timeline [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.558 (perp=11.426, rec=0.259, cos=0.013), tot_loss_proj:2.957 [t=0.24s]
prediction: ['[CLS] pointless mean western advice andom import double president writer viewers season ) pointless - pointless french pointless mean flow frenchring ; [SEP]']
[ 100/2000] tot_loss=2.149 (perp=9.786, rec=0.184, cos=0.007), tot_loss_proj:2.629 [t=0.24s]
prediction: ['[CLS] pointless mean originally from mean - coming - president writer coming import ) pointless and pointless french coming mean import french - - [SEP]']
[ 150/2000] tot_loss=2.135 (perp=9.608, rec=0.205, cos=0.008), tot_loss_proj:2.542 [t=0.24s]
prediction: ['[CLS] pointless moment import from mean - coming - sophie writer coming import ) pointless and pointless french coming mean import - - from [SEP]']
[ 200/2000] tot_loss=2.198 (perp=10.248, rec=0.145, cos=0.003), tot_loss_proj:2.666 [t=0.24s]
prediction: ['[CLS] pointlessg import from mean - coming from sophie director coming import ) pointless and pointless french coming mean import - chip from [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.174 (perp=10.229, rec=0.126, cos=0.003), tot_loss_proj:2.659 [t=0.24s]
prediction: ['[CLS] pointless import age from mean - coming age sophie director coming import )ing and pointless french age mean import - fr from [SEP]']
[ 300/2000] tot_loss=2.446 (perp=11.639, rec=0.116, cos=0.003), tot_loss_proj:2.903 [t=0.24s]
prediction: ['[CLS] pointless import transition from meander coming age anne director coming import )ing and pointless french age mean import - fr from [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.322 (perp=10.984, rec=0.122, cos=0.003), tot_loss_proj:2.758 [t=0.24s]
prediction: ['[CLS] pointless import - from ofder coming age anne director coming import )der and pointless french - mean import -rot from [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.341 (perp=11.116, rec=0.115, cos=0.003), tot_loss_proj:2.819 [t=0.24s]
prediction: ['[CLS] pointless import - from ofder coming age anne director coming import )der and pointless import career mean french - ami from [SEP]']
[ 450/2000] tot_loss=2.194 (perp=10.433, rec=0.105, cos=0.002), tot_loss_proj:2.658 [t=0.24s]
prediction: ['[CLS] pointless import - from ofder coming age anne director coming import )der and pointless import - mean french - ami from [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.179 (perp=10.328, rec=0.111, cos=0.003), tot_loss_proj:2.679 [t=0.24s]
prediction: ['[CLS] pointless import - from ofder coming age anne director coming import ) from and pointless import - mean french -rotder [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.047 (perp=9.363, rec=0.168, cos=0.006), tot_loss_proj:2.482 [t=0.24s]
prediction: ['[CLS] pointless import - ofder coming from age anne director coming import ) from and pointless import - mean french - -der [SEP]']
[ 600/2000] tot_loss=2.073 (perp=9.701, rec=0.130, cos=0.003), tot_loss_proj:2.537 [t=0.24s]
prediction: ['[CLS] this import - ofder coming from age anne director coming import ) from and pointless - writer mean french - -der [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.950 (perp=9.141, rec=0.120, cos=0.002), tot_loss_proj:2.404 [t=0.24s]
prediction: ['[CLS] this import - meander coming from age anne director coming import ) from and pointless - writer of french - -der [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.848 (perp=8.717, rec=0.103, cos=0.002), tot_loss_proj:2.306 [t=0.24s]
prediction: ['[CLS] this import of meander coming from age anne director coming import ) from and pointless - writer - french - -der [SEP]']
[ 750/2000] tot_loss=1.849 (perp=8.725, rec=0.102, cos=0.002), tot_loss_proj:2.305 [t=0.24s]
prediction: ['[CLS] this mean of meander coming from age anne director coming import ) from and pointless - writer - french - -der [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.813 (perp=8.528, rec=0.105, cos=0.002), tot_loss_proj:2.279 [t=0.24s]
prediction: ['[CLS] this mean of meander sophie from ageder director coming import ) from and pointless - writer - french - - sophie [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.672 (perp=7.856, rec=0.099, cos=0.002), tot_loss_proj:2.238 [t=0.24s]
prediction: ['[CLS] this meander meander sophie from age of director coming import ) from and pointless - writer - french - - sophie [SEP]']
[ 900/2000] tot_loss=1.663 (perp=7.856, rec=0.090, cos=0.002), tot_loss_proj:2.243 [t=0.24s]
prediction: ['[CLS] this meander meander sophie from age of director coming import ) from and pointless - writer - french - - sophie [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.016 (perp=9.590, rec=0.096, cos=0.002), tot_loss_proj:2.542 [t=0.24s]
prediction: ['[CLS] thisderder meander sophie from age of director coming import ) from and pointless writer - - french -rot anne [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.948 (perp=9.299, rec=0.086, cos=0.002), tot_loss_proj:2.500 [t=0.24s]
prediction: ['[CLS] thisder anne meander sophie from age of director coming import ) from and pointless writer - - french -rotder [SEP]']
[1050/2000] tot_loss=1.954 (perp=9.299, rec=0.093, cos=0.002), tot_loss_proj:2.501 [t=0.24s]
prediction: ['[CLS] thisder anne meander sophie from age of director coming import ) from and pointless writer - - french -rotder [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.964 (perp=9.405, rec=0.081, cos=0.002), tot_loss_proj:2.504 [t=0.24s]
prediction: ['[CLS] thisder anne meander anne from age of director coming import ) from and pointless writer - - french -rotder [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.926 (perp=9.173, rec=0.090, cos=0.002), tot_loss_proj:2.498 [t=0.24s]
prediction: ['[CLS] thisder anne meander - from age of director coming import ) from and pointless writer - anne french -rotder [SEP]']
[1200/2000] tot_loss=1.926 (perp=9.173, rec=0.089, cos=0.002), tot_loss_proj:2.494 [t=0.24s]
prediction: ['[CLS] thisder anne meander - from age of director coming import ) from and pointless writer - anne french -rotder [SEP]']
Attempt swap
[1250/2000] tot_loss=1.852 (perp=8.833, rec=0.084, cos=0.002), tot_loss_proj:2.469 [t=0.24s]
prediction: ['[CLS] thisder sophie meander - from age of director coming import ) from and pointless writer - anne french -rotder [SEP]']
Attempt swap
[1300/2000] tot_loss=1.851 (perp=8.833, rec=0.083, cos=0.002), tot_loss_proj:2.475 [t=0.24s]
prediction: ['[CLS] thisder sophie meander - from age of director coming import ) from and pointless writer - anne french -rotder [SEP]']
[1350/2000] tot_loss=1.941 (perp=9.263, rec=0.087, cos=0.002), tot_loss_proj:2.559 [t=0.24s]
prediction: ['[CLS] thisder sophie mean - - from age of director coming import ) from and pointless writer - anne french -rotder [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.833 (perp=8.710, rec=0.089, cos=0.002), tot_loss_proj:2.403 [t=0.24s]
prediction: ['[CLS] thisder sophierot - - from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
Attempt swap
[1450/2000] tot_loss=1.839 (perp=8.710, rec=0.095, cos=0.002), tot_loss_proj:2.399 [t=0.24s]
prediction: ['[CLS] thisder sophierot - - from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
[1500/2000] tot_loss=1.832 (perp=8.710, rec=0.088, cos=0.002), tot_loss_proj:2.408 [t=0.24s]
prediction: ['[CLS] thisder sophierot - - from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.796 (perp=8.550, rec=0.084, cos=0.002), tot_loss_proj:2.401 [t=0.24s]
prediction: ['[CLS] thisder sophie -rot - from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.760 (perp=8.353, rec=0.087, cos=0.002), tot_loss_proj:2.340 [t=0.24s]
prediction: ['[CLS] thisder sophie - -rot from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
[1650/2000] tot_loss=1.763 (perp=8.353, rec=0.091, cos=0.002), tot_loss_proj:2.340 [t=0.24s]
prediction: ['[CLS] thisder sophie - -rot from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
Attempt swap
[1700/2000] tot_loss=1.749 (perp=8.353, rec=0.076, cos=0.002), tot_loss_proj:2.337 [t=0.24s]
prediction: ['[CLS] thisder sophie - -rot from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
Attempt swap
[1750/2000] tot_loss=1.756 (perp=8.353, rec=0.083, cos=0.002), tot_loss_proj:2.339 [t=0.24s]
prediction: ['[CLS] thisder sophie - -rot from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
[1800/2000] tot_loss=1.761 (perp=8.353, rec=0.089, cos=0.002), tot_loss_proj:2.340 [t=0.24s]
prediction: ['[CLS] thisder sophie - -rot from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
Attempt swap
[1850/2000] tot_loss=1.751 (perp=8.353, rec=0.079, cos=0.002), tot_loss_proj:2.341 [t=0.24s]
prediction: ['[CLS] thisder sophie - -rot from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
Attempt swap
[1900/2000] tot_loss=1.763 (perp=8.353, rec=0.090, cos=0.002), tot_loss_proj:2.334 [t=0.24s]
prediction: ['[CLS] thisder sophie - -rot from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
[1950/2000] tot_loss=1.754 (perp=8.353, rec=0.082, cos=0.002), tot_loss_proj:2.338 [t=0.24s]
prediction: ['[CLS] thisder sophie - -rot from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
Attempt swap
[2000/2000] tot_loss=1.752 (perp=8.353, rec=0.080, cos=0.002), tot_loss_proj:2.338 [t=0.24s]
prediction: ['[CLS] thisder sophie - -rot from age of director coming import ) from and pointless writer - anne french - meander [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] thisder sophie - -rot from age of director coming import ) from and pointless writer - anne french - meander [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 77.778 | r: 82.353
rouge2     | fm: 12.121 | p: 11.765 | r: 12.500
rougeL     | fm: 40.000 | p: 38.889 | r: 41.176
rougeLsum  | fm: 40.000 | p: 38.889 | r: 41.176
r1fm+r2fm = 92.121

[Aggregate metrics]:
rouge1     | fm: 90.464 | p: 89.816 | r: 91.321
rouge2     | fm: 60.424 | p: 60.068 | r: 60.835
rougeL     | fm: 78.708 | p: 78.308 | r: 79.277
rougeLsum  | fm: 78.479 | p: 77.954 | r: 79.001
r1fm+r2fm = 150.888

input #26 time: 0:09:27 | total time: 4:14:14


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.9993448911552003
highest_index [0]
highest [0.9993448911552003]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9619437456130981 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.935196042060852 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.9044073820114136 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 0.85403972864151 for ['[CLS] landing imposed distant [SEP]']
[Init] best rec loss: 0.8062134385108948 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.8017191290855408 for ['[CLS] transitwine given [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.175 (perp=12.127, rec=0.786, cos=0.964), tot_loss_proj:4.341 [t=0.22s]
prediction: ['[CLS] softly victoria? [SEP]']
[ 100/2000] tot_loss=2.539 (perp=10.138, rec=0.437, cos=0.075), tot_loss_proj:2.600 [t=0.22s]
prediction: ['[CLS] slang were generic [SEP]']
[ 150/2000] tot_loss=2.376 (perp=10.986, rec=0.170, cos=0.008), tot_loss_proj:2.556 [t=0.22s]
prediction: ['[CLS] generic so generic [SEP]']
[ 200/2000] tot_loss=1.771 (perp=8.320, rec=0.104, cos=0.003), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.725 (perp=8.320, rec=0.059, cos=0.001), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.735 (perp=8.320, rec=0.070, cos=0.001), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.732 (perp=8.320, rec=0.067, cos=0.001), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.744 (perp=8.320, rec=0.078, cos=0.001), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.736 (perp=8.320, rec=0.070, cos=0.001), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.725 (perp=8.320, rec=0.059, cos=0.001), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.724 (perp=8.320, rec=0.059, cos=0.001), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.726 (perp=8.320, rec=0.061, cos=0.001), tot_loss_proj:1.760 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.723 (perp=8.320, rec=0.058, cos=0.001), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.731 (perp=8.320, rec=0.065, cos=0.001), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.735 (perp=8.320, rec=0.070, cos=0.001), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.719 (perp=8.320, rec=0.054, cos=0.001), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.731 (perp=8.320, rec=0.066, cos=0.001), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.731 (perp=8.320, rec=0.066, cos=0.001), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.727 (perp=8.320, rec=0.062, cos=0.001), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.740 (perp=8.320, rec=0.075, cos=0.001), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.726 (perp=8.320, rec=0.061, cos=0.001), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.721 (perp=8.320, rec=0.056, cos=0.001), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.728 (perp=8.320, rec=0.063, cos=0.001), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.733 (perp=8.320, rec=0.067, cos=0.001), tot_loss_proj:1.756 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.724 (perp=8.320, rec=0.059, cos=0.001), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.721 (perp=8.320, rec=0.055, cos=0.001), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.719 (perp=8.320, rec=0.053, cos=0.001), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.719 (perp=8.320, rec=0.053, cos=0.001), tot_loss_proj:1.756 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.727 (perp=8.320, rec=0.062, cos=0.001), tot_loss_proj:1.734 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.725 (perp=8.320, rec=0.060, cos=0.001), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.734 (perp=8.320, rec=0.069, cos=0.001), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.722 (perp=8.320, rec=0.057, cos=0.001), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.723 (perp=8.320, rec=0.058, cos=0.001), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.720 (perp=8.320, rec=0.054, cos=0.001), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.734 (perp=8.320, rec=0.069, cos=0.001), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.726 (perp=8.320, rec=0.061, cos=0.001), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.713 (perp=8.320, rec=0.048, cos=0.001), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.723 (perp=8.320, rec=0.058, cos=0.001), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.731 (perp=8.320, rec=0.066, cos=0.001), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.736 (perp=8.320, rec=0.071, cos=0.001), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.972 | p: 90.277 | r: 91.722
rouge2     | fm: 61.535 | p: 61.250 | r: 61.813
rougeL     | fm: 79.599 | p: 79.170 | r: 80.095
rougeLsum  | fm: 79.087 | p: 78.668 | r: 79.619
r1fm+r2fm = 152.507

input #27 time: 0:08:40 | total time: 4:22:55


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.9993341797945816
highest_index [0]
highest [0.9993341797945816]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8130366802215576 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.7981401681900024 for ['[CLS] guests mackenzie voyager reader [SEP]']
[Init] best rec loss: 0.7943398356437683 for ['[CLS] stations finchyte planned [SEP]']
[Init] best rec loss: 0.7936493754386902 for ['[CLS]ness aluminium cleveland tv [SEP]']
[Init] best rec loss: 0.782181978225708 for ['[CLS] james facilitieslty ¨ [SEP]']
[Init] best rec loss: 0.7480621337890625 for ['[CLS] fully mixeduro battlefield [SEP]']
[Init] best perm rec loss: 0.7475418448448181 for ['[CLS] mixed battlefield fullyuro [SEP]']
[Init] best perm rec loss: 0.7444020509719849 for ['[CLS] fullyuro battlefield mixed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.114 (perp=9.212, rec=0.248, cos=0.023), tot_loss_proj:2.787 [t=0.22s]
prediction: ['[CLS] for minutes days minutes [SEP]']
[ 100/2000] tot_loss=1.853 (perp=8.761, rec=0.097, cos=0.003), tot_loss_proj:2.652 [t=0.22s]
prediction: ['[CLS] for minutes only 71 [SEP]']
[ 150/2000] tot_loss=1.820 (perp=8.761, rec=0.066, cos=0.001), tot_loss_proj:2.651 [t=0.22s]
prediction: ['[CLS] for minutes only 71 [SEP]']
[ 200/2000] tot_loss=1.821 (perp=8.761, rec=0.068, cos=0.002), tot_loss_proj:2.647 [t=0.22s]
prediction: ['[CLS] for minutes only 71 [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.563 (perp=7.445, rec=0.072, cos=0.002), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 300/2000] tot_loss=1.561 (perp=7.445, rec=0.070, cos=0.001), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.549 (perp=7.445, rec=0.058, cos=0.002), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 450/2000] tot_loss=1.557 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.557 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.845 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.557 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.854 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 600/2000] tot_loss=1.553 (perp=7.445, rec=0.062, cos=0.001), tot_loss_proj:1.840 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.564 (perp=7.445, rec=0.074, cos=0.001), tot_loss_proj:1.845 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.545 (perp=7.445, rec=0.054, cos=0.001), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 750/2000] tot_loss=1.541 (perp=7.445, rec=0.051, cos=0.001), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.552 (perp=7.445, rec=0.061, cos=0.001), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.554 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 900/2000] tot_loss=1.544 (perp=7.445, rec=0.054, cos=0.001), tot_loss_proj:1.845 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.562 (perp=7.445, rec=0.071, cos=0.001), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1000/2000] tot_loss=1.553 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.838 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1050/2000] tot_loss=1.560 (perp=7.445, rec=0.070, cos=0.001), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1100/2000] tot_loss=1.554 (perp=7.445, rec=0.064, cos=0.001), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1150/2000] tot_loss=1.550 (perp=7.445, rec=0.060, cos=0.001), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1200/2000] tot_loss=1.560 (perp=7.445, rec=0.070, cos=0.001), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1250/2000] tot_loss=1.554 (perp=7.445, rec=0.064, cos=0.001), tot_loss_proj:1.845 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1300/2000] tot_loss=1.554 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1350/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1400/2000] tot_loss=1.559 (perp=7.445, rec=0.069, cos=0.001), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1450/2000] tot_loss=1.543 (perp=7.445, rec=0.053, cos=0.001), tot_loss_proj:1.837 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1500/2000] tot_loss=1.552 (perp=7.445, rec=0.061, cos=0.001), tot_loss_proj:1.840 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1550/2000] tot_loss=1.558 (perp=7.445, rec=0.068, cos=0.001), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1600/2000] tot_loss=1.552 (perp=7.445, rec=0.062, cos=0.001), tot_loss_proj:1.839 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1650/2000] tot_loss=1.556 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1700/2000] tot_loss=1.552 (perp=7.445, rec=0.062, cos=0.001), tot_loss_proj:1.834 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1750/2000] tot_loss=1.562 (perp=7.445, rec=0.071, cos=0.001), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1800/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.840 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1850/2000] tot_loss=1.553 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1900/2000] tot_loss=1.552 (perp=7.445, rec=0.062, cos=0.001), tot_loss_proj:1.833 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1950/2000] tot_loss=1.546 (perp=7.445, rec=0.055, cos=0.001), tot_loss_proj:1.847 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[2000/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.001), tot_loss_proj:1.839 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for 71 minutes only [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 91.268 | p: 90.596 | r: 92.013
rouge2     | fm: 60.860 | p: 60.611 | r: 61.200
rougeL     | fm: 79.573 | p: 79.185 | r: 80.052
rougeLsum  | fm: 79.377 | p: 78.906 | r: 79.926
r1fm+r2fm = 152.128

input #28 time: 0:08:43 | total time: 4:31:38


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.9992957407854928
highest_index [0]
highest [0.9992957407854928]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.947530210018158 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.9259920120239258 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.9125291109085083 for ['[CLS] persons carmenworm virtualack gems grand likes fries southern [SEP]']
[Init] best rec loss: 0.8549603223800659 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8497192859649658 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 0.8459416627883911 for ['[CLS] lordship buckingham rather postsbor we home wildlife valleygan [SEP]']
[Init] best rec loss: 0.845466136932373 for ['[CLS] crystal shock completion carrydable stay recordingdrive ella off [SEP]']
[Init] best rec loss: 0.8421328067779541 for ['[CLS] downke his heir wantedø degree opposition march head [SEP]']
[Init] best rec loss: 0.8202964663505554 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 0.8111938834190369 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best perm rec loss: 0.8096943497657776 for ['[CLS] transmit f veto u cells axlefounded meters mostly bu [SEP]']
[Init] best perm rec loss: 0.8091574907302856 for ['[CLS] cells meters axle bu mostly u transmit f vetofounded [SEP]']
[Init] best perm rec loss: 0.8048059940338135 for ['[CLS] veto transmit f cells axle mostlyfounded meters u bu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.092 (perp=13.411, rec=0.364, cos=0.046), tot_loss_proj:4.077 [t=0.23s]
prediction: ['[CLS] leaderslington trapped wonder [SEP] participants resigned almost. herself [SEP]']
[ 100/2000] tot_loss=2.595 (perp=11.270, rec=0.314, cos=0.027), tot_loss_proj:3.737 [t=0.23s]
prediction: ['[CLS] resident therefore reside wonder believe another resigned it. herself [SEP]']
[ 150/2000] tot_loss=2.423 (perp=10.862, rec=0.238, cos=0.013), tot_loss_proj:3.951 [t=0.23s]
prediction: ['[CLS] resident therefore resides sure believe also leaving not. evil [SEP]']
[ 200/2000] tot_loss=2.194 (perp=9.847, rec=0.215, cos=0.010), tot_loss_proj:3.621 [t=0.24s]
prediction: ['[CLS] resident also reside i believe also leaving not. evil [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.160 (perp=9.608, rec=0.220, cos=0.018), tot_loss_proj:3.620 [t=0.23s]
prediction: ['[CLS] resident also resides i believe also leaving not evil it [SEP]']
[ 300/2000] tot_loss=2.089 (perp=9.524, rec=0.174, cos=0.010), tot_loss_proj:3.716 [t=0.23s]
prediction: ['[CLS] resident not resident also believe they leaving not evil it [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.767 (perp=7.954, rec=0.167, cos=0.009), tot_loss_proj:3.069 [t=0.23s]
prediction: ['[CLS] not resident also believe definitely. not resident evil it [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.605 (perp=7.226, rec=0.151, cos=0.009), tot_loss_proj:2.474 [t=0.24s]
prediction: ['[CLS] not resident also believe definitely it not resident evil. [SEP]']
[ 450/2000] tot_loss=1.590 (perp=7.226, rec=0.137, cos=0.008), tot_loss_proj:2.482 [t=0.23s]
prediction: ['[CLS] not resident also believe definitely it not resident evil. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.396 (perp=6.292, rec=0.130, cos=0.007), tot_loss_proj:2.117 [t=0.23s]
prediction: ['[CLS] not resident also believe it definitely not resident evil. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.419 (perp=6.401, rec=0.132, cos=0.007), tot_loss_proj:2.268 [t=0.23s]
prediction: ['[CLS] also resident also believe it definitely not resident evil. [SEP]']
[ 600/2000] tot_loss=1.417 (perp=6.401, rec=0.131, cos=0.006), tot_loss_proj:2.260 [t=0.23s]
prediction: ['[CLS] also resident also believe it definitely not resident evil. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.435 (perp=6.476, rec=0.134, cos=0.006), tot_loss_proj:2.489 [t=0.23s]
prediction: ['[CLS] also resident also believe it. not resident evil. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.247 (perp=5.599, rec=0.121, cos=0.006), tot_loss_proj:2.631 [t=0.23s]
prediction: ['[CLS] also i also believe it. not resident evil. [SEP]']
[ 750/2000] tot_loss=1.248 (perp=5.599, rec=0.122, cos=0.006), tot_loss_proj:2.626 [t=0.24s]
prediction: ['[CLS] also i also believe it. not resident evil. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.238 (perp=5.599, rec=0.112, cos=0.006), tot_loss_proj:2.638 [t=0.23s]
prediction: ['[CLS] also i also believe it. not resident evil. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.174 (perp=5.256, rec=0.118, cos=0.005), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] that i also believe it. not resident evil. [SEP]']
[ 900/2000] tot_loss=1.291 (perp=5.871, rec=0.112, cos=0.005), tot_loss_proj:2.547 [t=0.23s]
prediction: ['[CLS] that is also believe it. not resident evil. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.187 (perp=5.410, rec=0.101, cos=0.005), tot_loss_proj:2.456 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.191 (perp=5.410, rec=0.105, cos=0.004), tot_loss_proj:2.444 [t=0.24s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
[1050/2000] tot_loss=1.196 (perp=5.410, rec=0.110, cos=0.004), tot_loss_proj:2.453 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.192 (perp=5.410, rec=0.106, cos=0.004), tot_loss_proj:2.451 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.185 (perp=5.410, rec=0.099, cos=0.004), tot_loss_proj:2.448 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
[1200/2000] tot_loss=1.186 (perp=5.410, rec=0.100, cos=0.004), tot_loss_proj:2.457 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.188 (perp=5.410, rec=0.102, cos=0.004), tot_loss_proj:2.454 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.190 (perp=5.410, rec=0.104, cos=0.004), tot_loss_proj:2.452 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
[1350/2000] tot_loss=1.177 (perp=5.410, rec=0.092, cos=0.004), tot_loss_proj:2.452 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.181 (perp=5.410, rec=0.095, cos=0.004), tot_loss_proj:2.451 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.169 (perp=5.410, rec=0.083, cos=0.003), tot_loss_proj:2.452 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
[1500/2000] tot_loss=1.185 (perp=5.410, rec=0.099, cos=0.003), tot_loss_proj:2.453 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.176 (perp=5.410, rec=0.091, cos=0.003), tot_loss_proj:2.448 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.177 (perp=5.410, rec=0.091, cos=0.003), tot_loss_proj:2.456 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
[1650/2000] tot_loss=1.189 (perp=5.410, rec=0.104, cos=0.003), tot_loss_proj:2.450 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.181 (perp=5.410, rec=0.096, cos=0.003), tot_loss_proj:2.453 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.181 (perp=5.410, rec=0.096, cos=0.003), tot_loss_proj:2.455 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
[1800/2000] tot_loss=1.182 (perp=5.410, rec=0.096, cos=0.003), tot_loss_proj:2.460 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.177 (perp=5.410, rec=0.092, cos=0.003), tot_loss_proj:2.448 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.165 (perp=5.410, rec=0.080, cos=0.003), tot_loss_proj:2.454 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
[1950/2000] tot_loss=1.160 (perp=5.410, rec=0.074, cos=0.003), tot_loss_proj:2.450 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.175 (perp=5.410, rec=0.089, cos=0.003), tot_loss_proj:2.457 [t=0.23s]
prediction: ['[CLS] that is it also believe. not resident evil. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] that is it also believe. not resident evil. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 100.000 | r: 90.909
rouge2     | fm: 21.053 | p: 22.222 | r: 20.000
rougeL     | fm: 57.143 | p: 60.000 | r: 54.545
rougeLsum  | fm: 57.143 | p: 60.000 | r: 54.545
r1fm+r2fm = 116.291

[Aggregate metrics]:
rouge1     | fm: 91.393 | p: 90.910 | r: 91.992
rouge2     | fm: 59.742 | p: 59.498 | r: 60.019
rougeL     | fm: 78.761 | p: 78.556 | r: 79.212
rougeLsum  | fm: 78.442 | p: 78.179 | r: 78.877
r1fm+r2fm = 151.136

input #29 time: 0:09:16 | total time: 4:40:54


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.9992726237091217
highest_index [0]
highest [0.9992726237091217]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.915320873260498 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.8711962103843689 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 0.8100265264511108 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7817462682723999 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7791784405708313 for ['[CLS] footading night [SEP]']
[Init] best rec loss: 0.7326138615608215 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.7145380973815918 for ['[CLS] acceleration council lizard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.870 (perp=12.949, rec=0.266, cos=0.015), tot_loss_proj:3.707 [t=0.23s]
prediction: ['[CLS]zzability fi [SEP]']
[ 100/2000] tot_loss=2.736 (perp=12.949, rec=0.141, cos=0.005), tot_loss_proj:3.707 [t=0.23s]
prediction: ['[CLS]zzability fi [SEP]']
[ 150/2000] tot_loss=2.711 (perp=12.949, rec=0.114, cos=0.008), tot_loss_proj:3.709 [t=0.23s]
prediction: ['[CLS]zzability fi [SEP]']
[ 200/2000] tot_loss=2.686 (perp=12.949, rec=0.091, cos=0.005), tot_loss_proj:3.711 [t=0.23s]
prediction: ['[CLS]zzability fi [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.995 (perp=9.539, rec=0.083, cos=0.004), tot_loss_proj:1.957 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.977 (perp=9.539, rec=0.067, cos=0.002), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.973 (perp=9.539, rec=0.064, cos=0.002), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.965 (perp=9.539, rec=0.055, cos=0.002), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.968 (perp=9.539, rec=0.058, cos=0.002), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.973 (perp=9.539, rec=0.064, cos=0.002), tot_loss_proj:1.963 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.977 (perp=9.539, rec=0.068, cos=0.002), tot_loss_proj:1.974 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.984 (perp=9.539, rec=0.074, cos=0.001), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.971 (perp=9.539, rec=0.062, cos=0.001), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.978 (perp=9.539, rec=0.068, cos=0.001), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.972 (perp=9.539, rec=0.063, cos=0.001), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.963 (perp=9.539, rec=0.053, cos=0.001), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.961 (perp=9.539, rec=0.052, cos=0.001), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.986 (perp=9.539, rec=0.076, cos=0.001), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.966 (perp=9.539, rec=0.056, cos=0.001), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.979 (perp=9.539, rec=0.070, cos=0.001), tot_loss_proj:1.987 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.970 (perp=9.539, rec=0.060, cos=0.001), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.971 (perp=9.539, rec=0.062, cos=0.001), tot_loss_proj:1.967 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.966 (perp=9.539, rec=0.057, cos=0.001), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.959 (perp=9.539, rec=0.050, cos=0.001), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.963 (perp=9.539, rec=0.054, cos=0.001), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.967 (perp=9.539, rec=0.058, cos=0.001), tot_loss_proj:1.963 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.963 (perp=9.539, rec=0.054, cos=0.001), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.964 (perp=9.539, rec=0.055, cos=0.001), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.973 (perp=9.539, rec=0.064, cos=0.001), tot_loss_proj:1.973 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.966 (perp=9.539, rec=0.057, cos=0.001), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.965 (perp=9.539, rec=0.056, cos=0.001), tot_loss_proj:1.970 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.955 (perp=9.539, rec=0.046, cos=0.001), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.960 (perp=9.539, rec=0.050, cos=0.001), tot_loss_proj:1.970 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.964 (perp=9.539, rec=0.055, cos=0.001), tot_loss_proj:1.957 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.969 (perp=9.539, rec=0.059, cos=0.001), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.970 (perp=9.539, rec=0.061, cos=0.001), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.966 (perp=9.539, rec=0.056, cos=0.001), tot_loss_proj:1.989 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.964 (perp=9.539, rec=0.055, cos=0.001), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.972 (perp=9.539, rec=0.063, cos=0.001), tot_loss_proj:1.974 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.967 (perp=9.539, rec=0.058, cos=0.001), tot_loss_proj:1.973 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.711 | p: 91.190 | r: 92.381
rouge2     | fm: 61.089 | p: 60.844 | r: 61.354
rougeL     | fm: 79.457 | p: 79.152 | r: 79.820
rougeLsum  | fm: 79.134 | p: 78.845 | r: 79.502
r1fm+r2fm = 152.800

input #30 time: 0:09:09 | total time: 4:50:03


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.9993397445870693
highest_index [0]
highest [0.9993397445870693]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.9391812086105347 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.9200879335403442 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8856512308120728 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.8632071614265442 for ['[CLS] billiel arms [SEP]']
[Init] best rec loss: 0.8012497425079346 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 0.8010070323944092 for ['[CLS] robin artwork running [SEP]']
[Init] best perm rec loss: 0.7970992922782898 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.696 (perp=11.968, rec=0.273, cos=0.030), tot_loss_proj:3.240 [t=0.23s]
prediction: ['[CLS] better scale nation [SEP]']
[ 100/2000] tot_loss=2.109 (perp=9.657, rec=0.162, cos=0.015), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=2.096 (perp=9.657, rec=0.150, cos=0.014), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 200/2000] tot_loss=2.078 (perp=9.657, rec=0.133, cos=0.014), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.075 (perp=9.657, rec=0.129, cos=0.014), tot_loss_proj:2.402 [t=0.23s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 300/2000] tot_loss=2.064 (perp=9.657, rec=0.119, cos=0.014), tot_loss_proj:2.401 [t=0.23s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.084 (perp=9.657, rec=0.140, cos=0.013), tot_loss_proj:2.397 [t=0.23s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.068 (perp=9.657, rec=0.125, cos=0.012), tot_loss_proj:2.401 [t=0.23s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 450/2000] tot_loss=1.834 (perp=8.742, rec=0.083, cos=0.002), tot_loss_proj:3.295 [t=0.23s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.002), tot_loss_proj:1.673 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.590 (perp=7.603, rec=0.068, cos=0.001), tot_loss_proj:1.686 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.671 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.690 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.596 (perp=7.603, rec=0.074, cos=0.001), tot_loss_proj:1.693 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.682 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.599 (perp=7.603, rec=0.077, cos=0.001), tot_loss_proj:1.688 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.593 (perp=7.603, rec=0.071, cos=0.001), tot_loss_proj:1.691 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.686 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.596 (perp=7.603, rec=0.074, cos=0.001), tot_loss_proj:1.702 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.694 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.687 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.594 (perp=7.603, rec=0.072, cos=0.001), tot_loss_proj:1.684 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.699 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.688 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.694 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.601 (perp=7.603, rec=0.079, cos=0.001), tot_loss_proj:1.700 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.592 (perp=7.603, rec=0.070, cos=0.001), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.600 (perp=7.603, rec=0.078, cos=0.001), tot_loss_proj:1.702 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.600 (perp=7.603, rec=0.079, cos=0.001), tot_loss_proj:1.694 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.697 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.594 (perp=7.603, rec=0.072, cos=0.001), tot_loss_proj:1.689 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.689 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.697 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.593 (perp=7.603, rec=0.072, cos=0.001), tot_loss_proj:1.711 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.595 (perp=7.603, rec=0.073, cos=0.001), tot_loss_proj:1.701 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.592 (perp=7.603, rec=0.071, cos=0.001), tot_loss_proj:1.694 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.592 (perp=7.603, rec=0.070, cos=0.001), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.684 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.689 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.878 | p: 91.517 | r: 92.561
rouge2     | fm: 62.414 | p: 62.198 | r: 62.617
rougeL     | fm: 80.164 | p: 79.921 | r: 80.521
rougeLsum  | fm: 79.786 | p: 79.448 | r: 80.093
r1fm+r2fm = 154.292

input #31 time: 0:09:13 | total time: 4:59:17


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9992524215190559
highest_index [0]
highest [0.9992524215190559]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.0390509366989136 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9474079608917236 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 0.8893988728523254 for ['[CLS] ring tracks peculiarzingplay de robinson lay iv elders experience wing [SEP]']
[Init] best rec loss: 0.8806267380714417 for ['[CLS] shot scale nest benefit jenny aspen introduced everything zoe arrival capital theory [SEP]']
[Init] best rec loss: 0.8802824020385742 for ['[CLS] spiders armenian dreams¨ me riff clearly space cyprus center ᵍ glory [SEP]']
[Init] best rec loss: 0.8597884774208069 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.8490630984306335 for ['[CLS]ono harlem auckland hanna organization rex force riot back decker mud tune [SEP]']
[Init] best rec loss: 0.8473441004753113 for ['[CLS]erated doc tax 2009 citizens completely fa outreach {zic spot 2 [SEP]']
[Init] best perm rec loss: 0.8473353981971741 for ['[CLS] taxerated 2009zic doc fa spot outreach completely citizens { 2 [SEP]']
[Init] best perm rec loss: 0.8460664749145508 for ['[CLS] { citizens tax doc 2009erated fa outreachzic spot 2 completely [SEP]']
[Init] best perm rec loss: 0.8459265828132629 for ['[CLS] 2009 citizens fa doc { 2 completelyzicerated tax spot outreach [SEP]']
[Init] best perm rec loss: 0.8454993963241577 for ['[CLS]erated doc spot citizens completely outreach fazic tax 2 2009 { [SEP]']
[Init] best perm rec loss: 0.8453917503356934 for ['[CLS] completely citizenserated { fa 2009 spot 2 doc tax outreachzic [SEP]']
[Init] best perm rec loss: 0.8444403409957886 for ['[CLS]zic completely { tax 2009erated doc outreach fa spot 2 citizens [SEP]']
[Init] best perm rec loss: 0.8436647057533264 for ['[CLS] 2009 tax 2 outreach doc completely spotzic { faerated citizens [SEP]']
[Init] best perm rec loss: 0.8428959250450134 for ['[CLS] fa { 2009zic 2 outreach spot doc completely tax citizenserated [SEP]']
[Init] best perm rec loss: 0.842507541179657 for ['[CLS] {zic spot 2009 citizens outreach completely 2 fa doc taxerated [SEP]']
[Init] best perm rec loss: 0.8423187732696533 for ['[CLS] 2009 outreach citizens tax { completely 2 doc spot faeratedzic [SEP]']
[Init] best perm rec loss: 0.8402031660079956 for ['[CLS] citizens doc 2009 spot completely { outreach 2erated fazic tax [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.045 (perp=13.695, rec=0.294, cos=0.012), tot_loss_proj:4.005 [t=0.22s]
prediction: ['[CLS] concrete effective encounter storiesonate mikeond forged ) personalienttation [SEP]']
[ 100/2000] tot_loss=2.939 (perp=13.732, rec=0.189, cos=0.003), tot_loss_proj:4.287 [t=0.22s]
prediction: ['[CLS] concrete accessible encounter storiesonate resondities )onate accessible pull [SEP]']
[ 150/2000] tot_loss=2.755 (perp=12.952, rec=0.162, cos=0.003), tot_loss_proj:3.835 [t=0.22s]
prediction: ['[CLS] concrete easily encounter storiesonate res appreciatedities toonate accessible pull [SEP]']
[ 200/2000] tot_loss=2.656 (perp=12.563, rec=0.141, cos=0.002), tot_loss_proj:3.709 [t=0.22s]
prediction: ['[CLS] concrete easily interacting storiesonate res scriptureities tound accessible pull [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.501 (perp=11.829, rec=0.132, cos=0.003), tot_loss_proj:3.364 [t=0.22s]
prediction: ['[CLS] concrete easily interacting stories resonatetainities tound accessible pull [SEP]']
[ 300/2000] tot_loss=2.439 (perp=11.600, rec=0.117, cos=0.002), tot_loss_proj:3.345 [t=0.22s]
prediction: ['[CLS] easily easily interacting stories resonate aheadities tound accessible pull [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.432 (perp=11.560, rec=0.117, cos=0.002), tot_loss_proj:3.092 [t=0.22s]
prediction: ['[CLS] clearly easily interacting stories resonateert accessibleityund with pull [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.016 (perp=9.489, rec=0.116, cos=0.002), tot_loss_proj:2.618 [t=0.22s]
prediction: ['[CLS] obviously easily interacting stories resonate profundity accessible with pull [SEP]']
[ 450/2000] tot_loss=1.998 (perp=9.489, rec=0.098, cos=0.002), tot_loss_proj:2.616 [t=0.22s]
prediction: ['[CLS] obviously easily interacting stories resonate profundity accessible with pull [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.775 (perp=8.424, rec=0.088, cos=0.002), tot_loss_proj:2.295 [t=0.22s]
prediction: ['[CLS] obviously easily accessible stories resonate profundity interacting with pull [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.662 (perp=7.815, rec=0.097, cos=0.002), tot_loss_proj:2.295 [t=0.22s]
prediction: ['[CLS] easily accessible stories obviously resonate profundity interacting with pull [SEP]']
[ 600/2000] tot_loss=1.903 (perp=9.074, rec=0.086, cos=0.002), tot_loss_proj:2.634 [t=0.22s]
prediction: ['[CLS] easily accessible stories obviously resonate resundity interacting with pull [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.931 (perp=9.194, rec=0.090, cos=0.002), tot_loss_proj:2.392 [t=0.22s]
prediction: ['[CLS] easily accessible stories together resonate resundity interacting with pull [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.866 (perp=8.893, rec=0.086, cos=0.002), tot_loss_proj:2.255 [t=0.22s]
prediction: ['[CLS] easily accessible stories together resonate interacting resundity with pull [SEP]']
[ 750/2000] tot_loss=1.871 (perp=8.893, rec=0.090, cos=0.002), tot_loss_proj:2.258 [t=0.22s]
prediction: ['[CLS] easily accessible stories together resonate interacting resundity with pull [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.851 (perp=8.893, rec=0.071, cos=0.002), tot_loss_proj:2.249 [t=0.22s]
prediction: ['[CLS] easily accessible stories together resonate interacting resundity with pull [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.861 (perp=8.893, rec=0.080, cos=0.002), tot_loss_proj:2.256 [t=0.22s]
prediction: ['[CLS] easily accessible stories together resonate interacting resundity with pull [SEP]']
[ 900/2000] tot_loss=1.858 (perp=8.893, rec=0.078, cos=0.002), tot_loss_proj:2.259 [t=0.22s]
prediction: ['[CLS] easily accessible stories together resonate interacting resundity with pull [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.661 (perp=7.914, rec=0.077, cos=0.002), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
Attempt swap
[1000/2000] tot_loss=1.653 (perp=7.914, rec=0.068, cos=0.002), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
[1050/2000] tot_loss=1.654 (perp=7.914, rec=0.069, cos=0.002), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
Attempt swap
[1100/2000] tot_loss=1.665 (perp=7.914, rec=0.081, cos=0.002), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
Attempt swap
[1150/2000] tot_loss=1.658 (perp=7.914, rec=0.074, cos=0.002), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
[1200/2000] tot_loss=1.659 (perp=7.914, rec=0.075, cos=0.002), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
Attempt swap
[1250/2000] tot_loss=1.654 (perp=7.914, rec=0.070, cos=0.002), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
Attempt swap
[1300/2000] tot_loss=1.655 (perp=7.914, rec=0.071, cos=0.002), tot_loss_proj:2.165 [t=0.23s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
[1350/2000] tot_loss=1.663 (perp=7.914, rec=0.079, cos=0.002), tot_loss_proj:2.168 [t=0.23s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
Attempt swap
[1400/2000] tot_loss=1.652 (perp=7.914, rec=0.068, cos=0.002), tot_loss_proj:2.167 [t=0.23s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
Attempt swap
[1450/2000] tot_loss=1.658 (perp=7.914, rec=0.074, cos=0.002), tot_loss_proj:2.162 [t=0.23s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
[1500/2000] tot_loss=1.658 (perp=7.914, rec=0.074, cos=0.002), tot_loss_proj:2.164 [t=0.23s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
Attempt swap
[1550/2000] tot_loss=1.664 (perp=7.914, rec=0.080, cos=0.002), tot_loss_proj:2.166 [t=0.23s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
Attempt swap
[1600/2000] tot_loss=1.642 (perp=7.914, rec=0.058, cos=0.002), tot_loss_proj:2.168 [t=0.23s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
[1650/2000] tot_loss=1.656 (perp=7.914, rec=0.072, cos=0.002), tot_loss_proj:2.168 [t=0.23s]
prediction: ['[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]']
Attempt swap
[1700/2000] tot_loss=1.766 (perp=8.432, rec=0.078, cos=0.002), tot_loss_proj:2.219 [t=0.23s]
prediction: ['[CLS] easily accessible storiesacious together resonate profundity with pull [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.676 (perp=7.977, rec=0.079, cos=0.002), tot_loss_proj:2.187 [t=0.23s]
prediction: ['[CLS] easily accessible togetheracious stories resonate profundity with pull [SEP]']
[1800/2000] tot_loss=1.676 (perp=7.977, rec=0.079, cos=0.002), tot_loss_proj:2.180 [t=0.23s]
prediction: ['[CLS] easily accessible togetheracious stories resonate profundity with pull [SEP]']
Attempt swap
[1850/2000] tot_loss=1.665 (perp=7.977, rec=0.068, cos=0.002), tot_loss_proj:2.187 [t=0.23s]
prediction: ['[CLS] easily accessible togetheracious stories resonate profundity with pull [SEP]']
Attempt swap
[1900/2000] tot_loss=1.677 (perp=7.977, rec=0.080, cos=0.002), tot_loss_proj:2.184 [t=0.23s]
prediction: ['[CLS] easily accessible togetheracious stories resonate profundity with pull [SEP]']
[1950/2000] tot_loss=1.669 (perp=7.977, rec=0.072, cos=0.002), tot_loss_proj:2.176 [t=0.23s]
prediction: ['[CLS] easily accessible togetheracious stories resonate profundity with pull [SEP]']
Attempt swap
[2000/2000] tot_loss=1.671 (perp=7.977, rec=0.074, cos=0.002), tot_loss_proj:2.182 [t=0.23s]
prediction: ['[CLS] easily accessible togetheracious stories resonate profundity with pull [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] easily accessible stories bestowed together resonate profundity with pull [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 110.909

[Aggregate metrics]:
rouge1     | fm: 91.890 | p: 91.441 | r: 92.481
rouge2     | fm: 61.140 | p: 60.957 | r: 61.407
rougeL     | fm: 79.647 | p: 79.430 | r: 80.033
rougeLsum  | fm: 79.325 | p: 79.023 | r: 79.734
r1fm+r2fm = 153.030

input #32 time: 0:08:55 | total time: 5:08:13


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9992770423515678
highest_index [0]
highest [0.9992770423515678]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 1.0013114213943481 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9758126139640808 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.954909086227417 for ['[CLS] parent [SEP]']
[Init] best rec loss: 0.9039609432220459 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8219714164733887 for ['[CLS] attributed [SEP]']
[Init] best rec loss: 0.7999625205993652 for ['[CLS] showing [SEP]']
[Init] best rec loss: 0.7876425981521606 for ['[CLS] manifold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.381 (perp=11.231, rec=0.130, cos=0.005), tot_loss_proj:2.959 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.319 (perp=11.231, rec=0.071, cos=0.002), tot_loss_proj:2.390 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.307 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.391 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.304 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.313 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.402 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.304 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.409 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.292 (perp=11.231, rec=0.045, cos=0.001), tot_loss_proj:2.399 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.305 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.402 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.385 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.314 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.405 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.318 (perp=11.231, rec=0.070, cos=0.001), tot_loss_proj:2.384 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.305 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.396 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.291 (perp=11.231, rec=0.044, cos=0.001), tot_loss_proj:2.383 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.303 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.394 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.314 (perp=11.231, rec=0.067, cos=0.001), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.310 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.400 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.311 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.392 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.295 (perp=11.231, rec=0.047, cos=0.001), tot_loss_proj:2.409 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.380 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.313 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.414 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.308 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.392 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.296 (perp=11.231, rec=0.048, cos=0.001), tot_loss_proj:2.385 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.316 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.382 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.313 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.402 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.321 (perp=11.231, rec=0.073, cos=0.001), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.302 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.327 (perp=11.231, rec=0.079, cos=0.001), tot_loss_proj:2.408 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.306 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.400 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.391 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.298 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.392 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.402 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.402 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.302 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.408 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.387 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.395 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.306 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.387 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.303 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.397 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.025 | p: 91.584 | r: 92.643
rouge2     | fm: 61.971 | p: 61.816 | r: 62.179
rougeL     | fm: 80.283 | p: 79.995 | r: 80.681
rougeLsum  | fm: 80.034 | p: 79.727 | r: 80.381
r1fm+r2fm = 153.995

input #33 time: 0:09:13 | total time: 5:17:26


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.9992090053245604
highest_index [0]
highest [0.9992090053245604]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8960171341896057 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8869714736938477 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8454265594482422 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.8433679938316345 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 0.8128030300140381 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.812659740447998 for ['[CLS] ship founder drivers worth slight okay lissa field alongaskibe who statue [SEP]']
[Init] best perm rec loss: 0.8106471300125122 for ['[CLS] slight founder ship drivers statue along okayask lissa whoibe field worth [SEP]']
[Init] best perm rec loss: 0.8101394176483154 for ['[CLS]ibe drivers lissa okay along worth statue shipask who field slight founder [SEP]']
[Init] best perm rec loss: 0.8095391392707825 for ['[CLS] slightask statueibe who field founder worth okay along drivers lissa ship [SEP]']
[Init] best perm rec loss: 0.808542013168335 for ['[CLS] worth who drivers along ship slight founder okay lissa fieldaskibe statue [SEP]']
[Init] best perm rec loss: 0.8066660165786743 for ['[CLS] slight founder lissa whoask ship statue along drivers fieldibe okay worth [SEP]']
[Init] best perm rec loss: 0.8065962791442871 for ['[CLS] along ship drivers statueask who worth lissa field founder slightibe okay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.875 (perp=12.733, rec=0.306, cos=0.023), tot_loss_proj:3.763 [t=0.23s]
prediction: ['[CLS]. magnitudeently ellie william. considerable increased urgency viewers dramatic urgent includes [SEP]']
[ 100/2000] tot_loss=2.271 (perp=10.420, rec=0.179, cos=0.008), tot_loss_proj:3.555 [t=0.23s]
prediction: ['[CLS]. build urgency viewer viewer in extreme take urgency viewer viewer urgency urgency [SEP]']
[ 150/2000] tot_loss=2.356 (perp=11.039, rec=0.144, cos=0.004), tot_loss_proj:3.400 [t=0.23s]
prediction: ['[CLS]. build extreme viewer of in extreme take urgency viewer viewer urgency mind [SEP]']
[ 200/2000] tot_loss=2.316 (perp=10.981, rec=0.117, cos=0.003), tot_loss_proj:3.367 [t=0.23s]
prediction: ['[CLS]. build extreme viewer of in extreme take urgency mind viewer urgency mind [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.134 (perp=10.047, rec=0.120, cos=0.004), tot_loss_proj:3.078 [t=0.23s]
prediction: ['[CLS]. build mind viewer urgency in extreme take the mind viewer urgency mind [SEP]']
[ 300/2000] tot_loss=2.119 (perp=10.047, rec=0.107, cos=0.003), tot_loss_proj:3.081 [t=0.24s]
prediction: ['[CLS]. build mind viewer urgency in extreme take the mind viewer urgency mind [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.965 (perp=9.307, rec=0.101, cos=0.003), tot_loss_proj:3.064 [t=0.23s]
prediction: ['[CLS] build. mind viewer urgency in extreme take the mind viewer urgency mind [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.851 (perp=8.556, rec=0.134, cos=0.005), tot_loss_proj:2.864 [t=0.23s]
prediction: ['[CLS] build. mind viewer urgency in mind take the mind viewer urgency extreme [SEP]']
[ 450/2000] tot_loss=1.814 (perp=8.533, rec=0.104, cos=0.003), tot_loss_proj:2.897 [t=0.23s]
prediction: ['[CLS] build. of viewer urgency in mind take the mind viewer urgency extreme [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.732 (perp=8.161, rec=0.098, cos=0.002), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] build. of viewer urgency in mind take the viewer urgency mind extreme [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.679 (perp=7.966, rec=0.084, cos=0.002), tot_loss_proj:2.775 [t=0.23s]
prediction: ['[CLS] build. and viewer urgency in mind take the viewer urgency mind extreme [SEP]']
[ 600/2000] tot_loss=1.674 (perp=7.966, rec=0.079, cos=0.002), tot_loss_proj:2.776 [t=0.23s]
prediction: ['[CLS] build. and viewer urgency in mind take the viewer urgency mind extreme [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.638 (perp=7.705, rec=0.095, cos=0.002), tot_loss_proj:2.675 [t=0.23s]
prediction: ['[CLS] build. and viewer urgency in mind take the extreme viewer urgency mind [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.624 (perp=7.705, rec=0.082, cos=0.002), tot_loss_proj:2.669 [t=0.23s]
prediction: ['[CLS] build. and viewer urgency in mind take the extreme viewer urgency mind [SEP]']
[ 750/2000] tot_loss=1.633 (perp=7.705, rec=0.091, cos=0.002), tot_loss_proj:2.675 [t=0.23s]
prediction: ['[CLS] build. and viewer urgency in mind take the extreme viewer urgency mind [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.518 (perp=7.201, rec=0.076, cos=0.002), tot_loss_proj:2.435 [t=0.23s]
prediction: ['[CLS] build and viewer urgency in mind take the extreme viewer urgency mind. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.412 (perp=6.587, rec=0.093, cos=0.002), tot_loss_proj:1.927 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
[ 900/2000] tot_loss=1.402 (perp=6.587, rec=0.082, cos=0.002), tot_loss_proj:1.919 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.398 (perp=6.587, rec=0.079, cos=0.002), tot_loss_proj:1.918 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.401 (perp=6.587, rec=0.082, cos=0.002), tot_loss_proj:1.927 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
[1050/2000] tot_loss=1.403 (perp=6.587, rec=0.084, cos=0.002), tot_loss_proj:1.921 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.395 (perp=6.587, rec=0.076, cos=0.002), tot_loss_proj:1.915 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.408 (perp=6.587, rec=0.089, cos=0.002), tot_loss_proj:1.913 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
[1200/2000] tot_loss=1.391 (perp=6.587, rec=0.072, cos=0.002), tot_loss_proj:1.916 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.393 (perp=6.587, rec=0.074, cos=0.002), tot_loss_proj:1.922 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.390 (perp=6.587, rec=0.071, cos=0.002), tot_loss_proj:1.925 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
[1350/2000] tot_loss=1.391 (perp=6.587, rec=0.072, cos=0.002), tot_loss_proj:1.925 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.387 (perp=6.587, rec=0.068, cos=0.002), tot_loss_proj:1.924 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.386 (perp=6.587, rec=0.067, cos=0.002), tot_loss_proj:1.924 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
[1500/2000] tot_loss=1.394 (perp=6.587, rec=0.074, cos=0.002), tot_loss_proj:1.914 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.401 (perp=6.587, rec=0.082, cos=0.002), tot_loss_proj:1.909 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.402 (perp=6.587, rec=0.083, cos=0.002), tot_loss_proj:1.921 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
[1650/2000] tot_loss=1.396 (perp=6.587, rec=0.077, cos=0.002), tot_loss_proj:1.926 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.388 (perp=6.587, rec=0.069, cos=0.002), tot_loss_proj:1.921 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.393 (perp=6.587, rec=0.074, cos=0.002), tot_loss_proj:1.924 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
[1800/2000] tot_loss=1.393 (perp=6.587, rec=0.074, cos=0.002), tot_loss_proj:1.922 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.403 (perp=6.587, rec=0.084, cos=0.002), tot_loss_proj:1.924 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.394 (perp=6.587, rec=0.074, cos=0.002), tot_loss_proj:1.928 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
[1950/2000] tot_loss=1.398 (perp=6.587, rec=0.079, cos=0.002), tot_loss_proj:1.918 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.395 (perp=6.587, rec=0.076, cos=0.002), tot_loss_proj:1.927 [t=0.23s]
prediction: ['[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] build viewer urgency in mind and take the extreme viewer on mind. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 15.385 | p: 15.385 | r: 15.385
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 101.099

[Aggregate metrics]:
rouge1     | fm: 91.884 | p: 91.487 | r: 92.418
rouge2     | fm: 61.052 | p: 60.879 | r: 61.313
rougeL     | fm: 79.589 | p: 79.404 | r: 79.892
rougeLsum  | fm: 79.361 | p: 79.084 | r: 79.725
r1fm+r2fm = 152.936

input #34 time: 0:09:13 | total time: 5:26:39


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9993270316838965
highest_index [0]
highest [0.9993270316838965]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.9252316951751709 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.9247497320175171 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best rec loss: 0.9241513609886169 for ['[CLS] nightstand locality shall shifted pdfish migrated reason features happy statisticsbant medium singled anti but least [SEP] contemptness second mia architecture nonsense departments order deserved ا guardian [MASK] hospitaluts itsried direction soc christmas merely sodiummeral score because [SEP]']
[Init] best rec loss: 0.9187696576118469 for ['[CLS] thousand lack alternative energy fae deservevil denied field outside pages province beauty fade actsar dynamic sole one organized folk ms primary appointment devicedran part zion nightmaresdrive isabellaght intervals singer published sleeper signs lynch, somehow position flow [SEP]']
[Init] best perm rec loss: 0.9162565469741821 for ['[CLS], part isabella published lynch one denied folk sleeper beautyght ms nightmares energy province actdrive zionvil appointment fade thousand singer deservesar pages signs somehow intervals dynamic alternative primary sole device flow fae lack field position organizeddran outside [SEP]']
[Init] best perm rec loss: 0.9161269068717957 for ['[CLS] sleeper, flow intervals isabella appointmentdran singer publishedvil deserve province zionsar outside position act dynamic organized part sole beauty folk fae device primary nightmares alternative lack lynch signs field somehowght ms denied thousand fade energy pages onedrive [SEP]']
[Init] best perm rec loss: 0.9152407050132751 for ['[CLS] device zion denied ms pages primary, sleeper dynamic lynchght one intervals singerdran field alternative somehow part fae fade province isabella signsdrive lack thousandvil sole positionsar published nightmares appointment beauty flow deserve organized act folk energy outside [SEP]']
[Init] best perm rec loss: 0.9150510430335999 for ['[CLS] flow, folk act lynch signs positiondrive zion intervals outside thousand lacksar ms pages sole sleeperght appointment published organized device alternative deserve somehow beauty province singer dynamic faevil fade primary one denieddran nightmares part isabella field energy [SEP]']
[Init] best perm rec loss: 0.9148762822151184 for ['[CLS] field, provincedran sole act outside one flow primary zion dynamicght organized isabella fae fade alternative published part energy lack folk thousand mssar intervals signs singer pages denied beauty nightmares sleeper somehowvil position lynch deserve appointment devicedrive [SEP]']
[Init] best perm rec loss: 0.9113529920578003 for ['[CLS] dynamic zion deserve sole sleeper primary act singer isabellasar flow energy appointment pages onedran outside nightmares lack somehow alternative, field position fade province denied signs organizeddrivevil ms intervalsght part lynch fae published thousand device folk beauty [SEP]']
[Init] best perm rec loss: 0.9103208780288696 for ['[CLS] ziondrive pages published, deserve denied outside partdran fade lynch folk alternativevil somehow field signs isabella appointment province position intervals sleeper lack thousand sole beauty ms dynamic one nightmares act flow singer energysar organized faeght device primary [SEP]']
[Init] best perm rec loss: 0.9080803394317627 for ['[CLS]ght one part signsdrivevil provincesar published alternative, primary folk fae flow zion fade deserve device ms organized appointment nightmares sleeper energy field lack position dynamic act pages beauty sole intervals lynch outside isabella somehow thousand denied singerdran [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.707 (perp=11.605, rec=0.373, cos=0.013), tot_loss_proj:3.805 [t=0.22s]
prediction: ['[CLS] beyond inwardly swedish rusty helicopter [SEP] those length scientific conducted, absorb non each great rabbi valley student locus ) great once love creative contribution of that with this canada adventuremo life eastern mediain world specially. super mutual 2004 [SEP]']
[ 100/2000] tot_loss=2.468 (perp=10.892, rec=0.284, cos=0.006), tot_loss_proj:4.065 [t=0.23s]
prediction: ["[CLS] beyond had across rusty ; before we seen producer ', makes almost before great rabbi surface ideas seen, great martin greatest renewed care'like despite but girl hostile rein ram eastern mediain world revealed they on our having [SEP]"]
[ 150/2000] tot_loss=2.451 (perp=10.764, rec=0.289, cos=0.010), tot_loss_proj:4.080 [t=0.23s]
prediction: ["[CLS]'inwardly ve rustynation before we seen director ', makes before before great apostle'ideas we'great'greatest care care'we despite but girl ᵍ rein ram eastern hubinnation surprise they of we having [SEP]"]
[ 200/2000] tot_loss=2.176 (perp=9.640, rec=0.242, cos=0.006), tot_loss_proj:3.579 [t=0.23s]
prediction: ["[CLS]'had'rustynation before we ve director ', makes before which greatwo'this we'great'greatest care care'we help but girl of reincar easternnationin world surprise they of us'[SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.112 (perp=9.575, rec=0.194, cos=0.003), tot_loss_proj:3.814 [t=0.23s]
prediction: ["[CLS] they had'ethernetnation before we ve director ', makes seen which great hoffman've we'great'greatest care care'we help but girl pseudocarnation easternnationinnation surprise they of us'[SEP]"]
[ 300/2000] tot_loss=2.281 (perp=10.221, rec=0.231, cos=0.006), tot_loss_proj:4.068 [t=0.23s]
prediction: ["[CLS] they had 'xidenation before we ve director ', makes seen both he animalhedron this we'great'greatest care care'us help but newest pseudo lordnation kai qalnation this. of us'[SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.268 (perp=10.041, rec=0.254, cos=0.006), tot_loss_proj:3.698 [t=0.23s]
prediction: ["[CLS] wein'paralympicsnation before we director ', makes ve seen each he animal teacher this we'great'from talks care'us help but newest this lordnation eastern ifannation this. of us'[SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.095 (perp=9.579, rec=0.176, cos=0.004), tot_loss_proj:3.688 [t=0.23s]
prediction: ["[CLS] we'' topicnation before we director ', makes ve he each seen animal teacher this it'great'from little care'us help but latest this lordnation studied mikecarnation latest. of us'[SEP]"]
[ 450/2000] tot_loss=2.108 (perp=9.695, rec=0.166, cos=0.003), tot_loss_proj:3.858 [t=0.23s]
prediction: ["[CLS] wein'topicnation before we director ', makes ve he each seen animal teacher this it'great'from little care'us help but latest unlikelycarnation laced lancelinenation latest. of us'[SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.034 (perp=9.345, rec=0.162, cos=0.003), tot_loss_proj:3.840 [t=0.23s]
prediction: ["[CLS] wein'paralympicsnation before we director ', makes ve he each seen hoffman teacher this it'great'from little care'about help but latest unlikelycarnation carrier lanceline. latestnation of us'[SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.108 (perp=9.755, rec=0.155, cos=0.003), tot_loss_proj:3.897 [t=0.23s]
prediction: ["[CLS] we mcmahon'paralympicsnation before we director ', makes ve he each seen at teacher this it'great behind from little care'about help but carrier unlikelycarnation latest lanceline. latestnation of us'[SEP]"]
[ 600/2000] tot_loss=2.140 (perp=9.988, rec=0.140, cos=0.002), tot_loss_proj:3.670 [t=0.23s]
prediction: ["[CLS] we belongs'paralympicsnation before we director ', makes ve he everything seen at teacher this it'great rude from little care'about help but carrier unlikelycarnation latest lanceline. latestnation of us'[SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.030 (perp=9.456, rec=0.136, cos=0.002), tot_loss_proj:3.871 [t=0.23s]
prediction: ["[CLS] we ought'paralympicsnation before we director ', makes all he ve seen at teacher this it'great assistant from little care'about help but carrier unlikely reinnation latest lanceline. latest greatest of us'[SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.028 (perp=9.457, rec=0.134, cos=0.002), tot_loss_proj:3.692 [t=0.23s]
prediction: ["[CLS] we belongs'teachernation before we director ', makes all some ve seen at without this it'great assistant from little care'about help but carrier unlikely reinnation teacher lanceline. latest greatest of us'[SEP]"]
[ 750/2000] tot_loss=1.953 (perp=9.092, rec=0.132, cos=0.002), tot_loss_proj:3.805 [t=0.23s]
prediction: ["[CLS] we ought'teachernation before we director ', makes all some ve seen at without this it'great assistant from little care'about help but lessons unlikely reinnation teacher pairline. latest greatest of us'[SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.959 (perp=9.094, rec=0.139, cos=0.002), tot_loss_proj:3.589 [t=0.23s]
prediction: ["[CLS] we belongs'teacher'before we director ', makes all some ve seen at without teacher itnation great assistant from little care'about help but lessons latest reinnation teacher pairline. latest greatest of us'[SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.944 (perp=9.022, rec=0.137, cos=0.002), tot_loss_proj:3.660 [t=0.23s]
prediction: ["[CLS] we belongs'teacher'before we director ', makes all some ve seen at without of itnation great assistant from little care'about help but lessons latest reinnation teacher reinline. latest greatest teacher us'[SEP]"]
[ 900/2000] tot_loss=1.921 (perp=8.948, rec=0.129, cos=0.002), tot_loss_proj:3.645 [t=0.23s]
prediction: ["[CLS] we with'teacher'before we director ', makes all some ve seen at without of itnation great assistant from little care'about help but lessons latest reinnation teacher reinline. latest greatest teacher us'[SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.870 (perp=8.716, rec=0.125, cos=0.002), tot_loss_proj:3.531 [t=0.23s]
prediction: ["[CLS] we with'teacher'before we director ', makes all another ve seen at without of itnation great assistant from little care'about help but lessons latest reinnation teacher reinline us latest greatest teacher.'[SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.850 (perp=8.629, rec=0.122, cos=0.002), tot_loss_proj:3.529 [t=0.23s]
prediction: ["[CLS] we with'teacher'before we director ', makes all another ve seen at without of itnation great assistant from little care'about help but lessons latest reinnation teacher reinline us'latest greatest teacher. [SEP]"]
[1050/2000] tot_loss=1.852 (perp=8.629, rec=0.125, cos=0.002), tot_loss_proj:3.522 [t=0.23s]
prediction: ["[CLS] we with'teacher'before we director ', makes all another ve seen at without of itnation great assistant from little care'about help but lessons latest reinnation teacher reinline us'latest greatest teacher. [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.820 (perp=8.447, rec=0.128, cos=0.002), tot_loss_proj:3.610 [t=0.23s]
prediction: ["[CLS] we ought'latest'before we director ', makes all another in seen at without of itnation great colleagues from little care'about help but lessons teacher reinnation teacher reinline us'latest greatest teacher. [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.782 (perp=8.301, rec=0.120, cos=0.002), tot_loss_proj:3.524 [t=0.23s]
prediction: ["[CLS] we ought'unlikely'before we director ', makes another all in seen at without of itnation great colleagues from little care'about help but lessons teacher reinnation teacher reinline us'latest greatest teacher. [SEP]"]
[1200/2000] tot_loss=1.790 (perp=8.301, rec=0.128, cos=0.002), tot_loss_proj:3.522 [t=0.23s]
prediction: ["[CLS] we ought'unlikely'before we director ', makes another all in seen at without of itnation great colleagues from little care'about help but lessons teacher reinnation teacher reinline us'latest greatest teacher. [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.770 (perp=8.202, rec=0.127, cos=0.002), tot_loss_proj:3.506 [t=0.23s]
prediction: ["[CLS] we ought'unlikely'before we director ', makes another all at seen in without of itnation great colleagues from little care'about help but lessons teacher reinnation teacher reinline us'latest greatest teacher. [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.778 (perp=8.260, rec=0.124, cos=0.002), tot_loss_proj:3.552 [t=0.23s]
prediction: ["[CLS] we ought'unlikely'before we director ', makes another all at seen in it without ofnation great colleagues from ice care'about help but lessons teacher reinnation teacher reinline us'latest greatest teacher. [SEP]"]
[1350/2000] tot_loss=1.781 (perp=8.260, rec=0.127, cos=0.002), tot_loss_proj:3.548 [t=0.23s]
prediction: ["[CLS] we ought'unlikely'before we director ', makes another all at seen in it without ofnation great colleagues from ice care'about help but lessons teacher reinnation teacher reinline us'latest greatest teacher. [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.782 (perp=8.260, rec=0.128, cos=0.002), tot_loss_proj:3.549 [t=0.23s]
prediction: ["[CLS] we ought'unlikely'before we director ', makes another all at seen in it without ofnation great colleagues from ice care'about help but lessons teacher reinnation teacher reinline us'latest greatest teacher. [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.799 (perp=8.342, rec=0.129, cos=0.002), tot_loss_proj:3.610 [t=0.23s]
prediction: ["[CLS] we ought'unlikely'before we director about, makes another all at seen in it ofnation without great colleagues from little care'about help but lessons teacher reinnation teacher reinline us'latest greatest teacher. [SEP]"]
[1500/2000] tot_loss=1.774 (perp=8.254, rec=0.121, cos=0.002), tot_loss_proj:3.527 [t=0.23s]
prediction: ["[CLS] we with'unlikely'before we director about, makes another all at seen in it ofnation without great colleagues from ice care'about help but lessons teacher reinnation teacher reinline us'latest greatest teacher. [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.759 (perp=8.194, rec=0.118, cos=0.002), tot_loss_proj:3.429 [t=0.23s]
prediction: ["[CLS] we with'unlikely'before we director about, makes another all at seen in it withoutnation of great colleagues from ice care'about help but lessons teacher reinnation teacher reinline us'latest greatest teacher. [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.763 (perp=8.144, rec=0.132, cos=0.002), tot_loss_proj:3.619 [t=0.23s]
prediction: ["[CLS] we ought'unlikely'before we director about, makes another all at seen in it withoutline of great colleagues from ice care'about help but lessons teacher reinnation teacher reinnation us'latest greatest teacher. [SEP]"]
[1650/2000] tot_loss=1.745 (perp=8.144, rec=0.114, cos=0.002), tot_loss_proj:3.617 [t=0.23s]
prediction: ["[CLS] we ought'unlikely'before we director about, makes another all at seen in it withoutline of great colleagues from ice care'about help but lessons teacher reinnation teacher reinnation us'latest greatest teacher. [SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=1.738 (perp=8.034, rec=0.129, cos=0.002), tot_loss_proj:3.462 [t=0.23s]
prediction: ["[CLS] we ought'unlikely'before we director about, makes another all at seen in it withoutline of great colleagues from ice care'about help but lessons teacher reinnation teacher reinnation'us latest greatest teacher. [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.754 (perp=8.090, rec=0.134, cos=0.002), tot_loss_proj:3.456 [t=0.23s]
prediction: ["[CLS] weura'unlikely'before we director about, makes another seen at all in it withoutline of great colleagues from ice care'about help but lessons teacher reinnation teacher reinnation'us latest greatest teacher. [SEP]"]
[1800/2000] tot_loss=1.671 (perp=7.716, rec=0.126, cos=0.002), tot_loss_proj:3.314 [t=0.23s]
prediction: ["[CLS] we with'unlikely'before we director about, makes another seen at all in it withoutline of great colleagues from ice care'about help but lessons teacher reinnation teacher reinnation'us latest greatest teacher. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.743 (perp=8.090, rec=0.123, cos=0.002), tot_loss_proj:3.454 [t=0.23s]
prediction: ["[CLS] weura'unlikely'before we director about, makes another seen at all in it withoutline of great colleagues from ice care'about help but lessons teacher reinnation teacher reinnation'us latest greatest teacher. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.749 (perp=8.090, rec=0.130, cos=0.002), tot_loss_proj:3.451 [t=0.23s]
prediction: ["[CLS] weura'unlikely'before we director about, makes another seen at all in it withoutline of great colleagues from ice care'about help but lessons teacher reinnation teacher reinnation'us latest greatest teacher. [SEP]"]
[1950/2000] tot_loss=1.748 (perp=8.089, rec=0.128, cos=0.002), tot_loss_proj:3.417 [t=0.23s]
prediction: ["[CLS] weura'unlikely'before we director about, makes another seen and all in it withoutline of great colleagues from ice care'about help but lessons teacher reinnation teacher reinnation'us latest greatest teacher. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.738 (perp=8.089, rec=0.119, cos=0.002), tot_loss_proj:3.420 [t=0.23s]
prediction: ["[CLS] weura'unlikely'before we director about, makes another seen and all in it withoutline of great colleagues from ice care'about help but lessons teacher reinnation teacher reinnation'us latest greatest teacher. [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] we with'unlikely'before we director about, makes another all at seen in it ofnation without great colleagues from little care'about help but lessons teacher reinnation teacher reinline us'latest greatest teacher. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.857 | p: 62.857 | r: 62.857
rouge2     | fm: 11.765 | p: 11.765 | r: 11.765
rougeL     | fm: 34.286 | p: 34.286 | r: 34.286
rougeLsum  | fm: 34.286 | p: 34.286 | r: 34.286
r1fm+r2fm = 74.622

[Aggregate metrics]:
rouge1     | fm: 91.082 | p: 90.612 | r: 91.689
rouge2     | fm: 59.228 | p: 59.036 | r: 59.426
rougeL     | fm: 78.406 | p: 78.037 | r: 78.763
rougeLsum  | fm: 78.046 | p: 77.877 | r: 78.435
r1fm+r2fm = 150.310

input #35 time: 0:09:01 | total time: 5:35:40


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.999284814212414
highest_index [0]
highest [0.999284814212414]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9979257583618164 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.99554443359375 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 0.9552820920944214 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9281548857688904 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9227340221405029 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.9187840819358826 for ['[CLS] papa sinclairevsky perhaps [SEP]']
[Init] best rec loss: 0.8236973285675049 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8220551609992981 for ['[CLS] cornelius bates ramsey harassment [SEP]']
[Init] best perm rec loss: 0.8182108998298645 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.948 (perp=9.086, rec=0.124, cos=0.006), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] is horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=1.905 (perp=9.147, rec=0.073, cos=0.002), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=1.902 (perp=9.147, rec=0.071, cos=0.002), tot_loss_proj:2.107 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=1.905 (perp=9.147, rec=0.074, cos=0.002), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.904 (perp=9.147, rec=0.073, cos=0.002), tot_loss_proj:2.119 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 300/2000] tot_loss=1.897 (perp=9.147, rec=0.065, cos=0.002), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.894 (perp=9.147, rec=0.063, cos=0.002), tot_loss_proj:2.132 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.568 (perp=7.158, rec=0.132, cos=0.005), tot_loss_proj:1.831 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 450/2000] tot_loss=1.517 (perp=7.158, rec=0.084, cos=0.002), tot_loss_proj:1.829 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.504 (perp=7.158, rec=0.071, cos=0.002), tot_loss_proj:1.822 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.499 (perp=7.158, rec=0.066, cos=0.002), tot_loss_proj:1.831 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 600/2000] tot_loss=1.503 (perp=7.158, rec=0.069, cos=0.002), tot_loss_proj:1.828 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.496 (perp=7.158, rec=0.062, cos=0.001), tot_loss_proj:1.827 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.500 (perp=7.158, rec=0.066, cos=0.001), tot_loss_proj:1.827 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 750/2000] tot_loss=1.510 (perp=7.158, rec=0.077, cos=0.001), tot_loss_proj:1.814 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.491 (perp=7.158, rec=0.057, cos=0.001), tot_loss_proj:1.822 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.517 (perp=7.158, rec=0.083, cos=0.001), tot_loss_proj:1.818 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 900/2000] tot_loss=1.507 (perp=7.158, rec=0.074, cos=0.001), tot_loss_proj:1.824 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.498 (perp=7.158, rec=0.065, cos=0.001), tot_loss_proj:1.818 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.496 (perp=7.158, rec=0.063, cos=0.001), tot_loss_proj:1.816 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1050/2000] tot_loss=1.494 (perp=7.158, rec=0.061, cos=0.001), tot_loss_proj:1.819 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.498 (perp=7.158, rec=0.065, cos=0.001), tot_loss_proj:1.824 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.491 (perp=7.158, rec=0.058, cos=0.001), tot_loss_proj:1.827 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1200/2000] tot_loss=1.507 (perp=7.158, rec=0.074, cos=0.001), tot_loss_proj:1.825 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.496 (perp=7.158, rec=0.063, cos=0.001), tot_loss_proj:1.826 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.504 (perp=7.158, rec=0.071, cos=0.001), tot_loss_proj:1.824 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1350/2000] tot_loss=1.515 (perp=7.158, rec=0.082, cos=0.001), tot_loss_proj:1.823 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.498 (perp=7.158, rec=0.065, cos=0.001), tot_loss_proj:1.817 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.498 (perp=7.158, rec=0.065, cos=0.001), tot_loss_proj:1.825 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1500/2000] tot_loss=1.498 (perp=7.158, rec=0.065, cos=0.001), tot_loss_proj:1.819 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.491 (perp=7.158, rec=0.058, cos=0.001), tot_loss_proj:1.816 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.494 (perp=7.158, rec=0.061, cos=0.001), tot_loss_proj:1.829 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1650/2000] tot_loss=1.505 (perp=7.158, rec=0.072, cos=0.001), tot_loss_proj:1.828 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.503 (perp=7.158, rec=0.069, cos=0.001), tot_loss_proj:1.827 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.495 (perp=7.158, rec=0.062, cos=0.001), tot_loss_proj:1.821 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1800/2000] tot_loss=1.492 (perp=7.158, rec=0.059, cos=0.001), tot_loss_proj:1.823 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.490 (perp=7.158, rec=0.057, cos=0.001), tot_loss_proj:1.819 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.507 (perp=7.158, rec=0.074, cos=0.001), tot_loss_proj:1.826 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1950/2000] tot_loss=1.489 (perp=7.158, rec=0.056, cos=0.001), tot_loss_proj:1.821 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.504 (perp=7.158, rec=0.071, cos=0.001), tot_loss_proj:1.826 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] horribly wrong's [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 91.351 | p: 90.959 | r: 91.861
rouge2     | fm: 58.276 | p: 58.080 | r: 58.518
rougeL     | fm: 78.490 | p: 78.195 | r: 78.799
rougeLsum  | fm: 78.105 | p: 77.827 | r: 78.402
r1fm+r2fm = 149.627

input #36 time: 0:08:42 | total time: 5:44:22


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9993689804820187
highest_index [0]
highest [0.9993689804820187]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.9596894383430481 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.9509360194206238 for ['[CLS]quest medical [SEP]']
[Init] best rec loss: 0.8898118138313293 for ['[CLS] fish cape [SEP]']
[Init] best rec loss: 0.8017318248748779 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.7998512983322144 for ['[CLS] living metacritic [SEP]']
[Init] best rec loss: 0.7796184420585632 for ['[CLS] housemple [SEP]']
[Init] best rec loss: 0.777220606803894 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.7522561550140381 for ['[CLS] year clarissa [SEP]']
[Init] best rec loss: 0.7436131834983826 for ['[CLS]atal purpose [SEP]']
[Init] best rec loss: 0.7150478363037109 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.7001022100448608 for ['[CLS] cousin many [SEP]']
[Init] best rec loss: 0.6871371269226074 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.6777796745300293 for ['[CLS] cassidystream [SEP]']
[Init] best rec loss: 0.6420923471450806 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.6359727382659912 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.999 (perp=12.719, rec=0.325, cos=0.131), tot_loss_proj:4.341 [t=0.21s]
prediction: ['[CLS] eccentric whatsoever [SEP]']
[ 100/2000] tot_loss=2.048 (perp=9.583, rec=0.116, cos=0.016), tot_loss_proj:2.029 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[ 150/2000] tot_loss=1.993 (perp=9.583, rec=0.073, cos=0.002), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.001 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.967 (perp=9.583, rec=0.049, cos=0.001), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[ 300/2000] tot_loss=1.992 (perp=9.583, rec=0.074, cos=0.001), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.985 (perp=9.583, rec=0.068, cos=0.001), tot_loss_proj:2.014 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[ 450/2000] tot_loss=1.985 (perp=9.583, rec=0.067, cos=0.001), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.963 (perp=9.583, rec=0.046, cos=0.001), tot_loss_proj:2.001 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.971 (perp=9.583, rec=0.053, cos=0.001), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[ 600/2000] tot_loss=1.969 (perp=9.583, rec=0.051, cos=0.001), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.973 (perp=9.583, rec=0.055, cos=0.001), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.966 (perp=9.583, rec=0.048, cos=0.001), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[ 750/2000] tot_loss=1.995 (perp=9.583, rec=0.077, cos=0.001), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.975 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.013 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.993 (perp=9.583, rec=0.075, cos=0.001), tot_loss_proj:2.017 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[ 900/2000] tot_loss=1.973 (perp=9.583, rec=0.055, cos=0.001), tot_loss_proj:2.022 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[1050/2000] tot_loss=1.974 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.025 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.974 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:1.996 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[1200/2000] tot_loss=1.986 (perp=9.583, rec=0.069, cos=0.001), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.981 (perp=9.583, rec=0.063, cos=0.001), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.967 (perp=9.583, rec=0.049, cos=0.001), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[1350/2000] tot_loss=1.974 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.989 (perp=9.583, rec=0.071, cos=0.001), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[1500/2000] tot_loss=1.997 (perp=9.583, rec=0.079, cos=0.001), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.974 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:2.020 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[1650/2000] tot_loss=1.977 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.977 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.984 (perp=9.583, rec=0.066, cos=0.001), tot_loss_proj:2.003 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[1800/2000] tot_loss=1.961 (perp=9.583, rec=0.043, cos=0.001), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.971 (perp=9.583, rec=0.053, cos=0.001), tot_loss_proj:2.017 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[1950/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.973 (perp=9.583, rec=0.055, cos=0.001), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.660 | p: 91.274 | r: 92.111
rouge2     | fm: 59.578 | p: 59.391 | r: 59.770
rougeL     | fm: 78.913 | p: 78.623 | r: 79.248
rougeLsum  | fm: 78.613 | p: 78.379 | r: 78.955
r1fm+r2fm = 151.239

input #37 time: 0:08:42 | total time: 5:53:05


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9992647518341967
highest_index [0]
highest [0.9992647518341967]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8108127117156982 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.80867999792099 for ['[CLS] federation [SEP]']
[Init] best rec loss: 0.774891197681427 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7043036222457886 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.6709908246994019 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6299773454666138 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.908 (perp=14.069, rec=0.087, cos=0.007), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.869 (perp=14.069, rec=0.053, cos=0.002), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.880 (perp=14.069, rec=0.063, cos=0.004), tot_loss_proj:2.882 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.871 (perp=14.069, rec=0.054, cos=0.003), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.882 (perp=14.069, rec=0.065, cos=0.003), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.880 (perp=14.069, rec=0.064, cos=0.002), tot_loss_proj:2.872 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.002), tot_loss_proj:2.879 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.872 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.873 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.880 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.866 (perp=14.069, rec=0.051, cos=0.001), tot_loss_proj:2.874 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.869 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.863 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.877 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.875 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.886 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.878 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.880 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.867 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.860 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.867 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.880 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.879 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.880 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.865 (perp=14.069, rec=0.050, cos=0.001), tot_loss_proj:2.880 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.879 (perp=14.069, rec=0.064, cos=0.001), tot_loss_proj:2.866 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.873 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.878 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.883 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.878 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.882 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.871 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.878 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.878 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.876 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.873 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.885 (perp=14.069, rec=0.070, cos=0.001), tot_loss_proj:2.871 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.864 (perp=14.069, rec=0.049, cos=0.001), tot_loss_proj:2.868 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.866 (perp=14.069, rec=0.050, cos=0.001), tot_loss_proj:2.877 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.871 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.873 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.878 (perp=14.069, rec=0.062, cos=0.001), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.883 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.876 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.869 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.869 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.870 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.873 (perp=14.069, rec=0.058, cos=0.001), tot_loss_proj:2.885 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.882 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.859 | p: 91.455 | r: 92.308
rouge2     | fm: 60.337 | p: 60.147 | r: 60.502
rougeL     | fm: 79.436 | p: 79.174 | r: 79.738
rougeLsum  | fm: 79.279 | p: 79.100 | r: 79.622
r1fm+r2fm = 152.196

input #38 time: 0:08:42 | total time: 6:01:47


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9992526080235489
highest_index [0]
highest [0.9992526080235489]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 1.0121337175369263 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 1.0089290142059326 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 0.9913747310638428 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.9341997504234314 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.9286713004112244 for ['[CLS] ira estimate rabbi relegationbiotic request veronica his baby firedusia property management spring gone dub related location cd age eastern drove than kelly parking [SEP]']
[Init] best rec loss: 0.9269349575042725 for ['[CLS] pressed score limiting value blinking walkerson hitch micro mouths inside pockets... : international darby mclaren trace lightec madman formation inquiry end soul [SEP]']
[Init] best rec loss: 0.9190372824668884 for ['[CLS] mutual peopleュ stone intimate reeve templeming freak shores over they sprinterous pro dedication harbour along ll minority [CLS] class raise issue need [SEP]']
[Init] best rec loss: 0.9160887002944946 for ['[CLS] will press caseztty never crimson bohemia journal search band relations behind formula cells main commissioner quick palmer present bible backs duty sogh [SEP]']
[Init] best rec loss: 0.908961832523346 for ['[CLS] townwind hurt main thenney cassidyowa position jury southpher wash sailhy gordon lab happened bepettive in etc sometimes event [SEP]']
[Init] best perm rec loss: 0.9082816243171692 for ['[CLS] south be main sailwindtive gordon positionowapet etc lab thenneyhy wash cassidy jury hurt in event townpher sometimes happened [SEP]']
[Init] best perm rec loss: 0.9072545170783997 for ['[CLS] main wash position eventtivewind beney hurt then town south jury etc inowa cassidy sailhy sometimespet gordon lab happenedpher [SEP]']
[Init] best perm rec loss: 0.9072453379631042 for ['[CLS] event gordonowa jury etc townpher then hurt cassidy be position main sail in washpet lab sometimeswindhy south happenedtiveney [SEP]']
[Init] best perm rec loss: 0.9061841368675232 for ['[CLS] hurtphertive happened sail washwind then lab inney etc sometimes cassidy positionowa behy gordon south jury event town mainpet [SEP]']
[Init] best perm rec loss: 0.9043102264404297 for ['[CLS] south in hurt lab happenedpher wash main sail cassidy sometimeshyowa then gordonwindneypettive event be jury etc position town [SEP]']
[Init] best perm rec loss: 0.902638852596283 for ['[CLS] labpher etc happened hurt be townwind wash in gordonowative south sometimes position then main sail cassidyhy eventpet juryney [SEP]']
[Init] best perm rec loss: 0.902492344379425 for ['[CLS]pher lab in be cassidy gordon hurt town washney sometimesowa event happened position sailtive etcpet jury then south mainwindhy [SEP]']
[Init] best perm rec loss: 0.9024226665496826 for ['[CLS] etcowa lab gordon cassidy positionpher then wash sometimespet town south sailtive mainhy in eventwind hurt be juryney happened [SEP]']
[Init] best perm rec loss: 0.902267336845398 for ['[CLS] gordontivepher event sailney hurt thenhy sometimes happened townowa mainpet jury etc be washwind lab position in south cassidy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.959 (perp=12.848, rec=0.374, cos=0.015), tot_loss_proj:3.956 [t=0.22s]
prediction: ['[CLS] sanctuary undergroundmins gothic blake william believe politics ←eralled decade girlcape walls, smart : craft microscopic change [SEP] answer received like [SEP]']
[ 100/2000] tot_loss=2.584 (perp=11.528, rec=0.270, cos=0.008), tot_loss_proj:3.411 [t=0.22s]
prediction: ['[CLS] ian hide narrative shiny : give traditions real ᴮ party our gives paris artifacts gretchen with reid, craft players novel conservative and gives like [SEP]']
[ 150/2000] tot_loss=2.536 (perp=11.356, rec=0.257, cos=0.008), tot_loss_proj:4.168 [t=0.22s]
prediction: ['[CLS] eric hide clues elevator which conservative traditions lived sensible the new texture mom artifacts least hide (, leadered females conservative and gives our [SEP]']
[ 200/2000] tot_loss=2.448 (perp=11.089, rec=0.214, cos=0.016), tot_loss_proj:3.817 [t=0.23s]
prediction: ['[CLS] eric hide clues reality which conservative traditions lived italicsbound finds texture mom finds least hide (, does them texture conservative and gives texture [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.396 (perp=11.003, rec=0.191, cos=0.004), tot_loss_proj:3.744 [t=0.22s]
prediction: ['[CLS] new hidebound reality finds give traditions so newbound and texture mom finds least hide (, oneself it texture conservative and gives texture [SEP]']
[ 300/2000] tot_loss=2.214 (perp=10.257, rec=0.159, cos=0.003), tot_loss_proj:3.473 [t=0.22s]
prediction: ['[CLS] new hidebound reality finds give traditions so newbound. texture mostbound movie hide the, oneself it texture conservative and gives texture [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.087 (perp=9.704, rec=0.143, cos=0.003), tot_loss_proj:3.032 [t=0.22s]
prediction: ['[CLS] new hide the movie finds give traditions so newbound. texture mostbound their hidebound, oneself it texture conservative and gives texture [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.056 (perp=9.631, rec=0.127, cos=0.003), tot_loss_proj:3.203 [t=0.22s]
prediction: ['[CLS] new hide, movie finds new traditions often gavebound. texture ourbound their hidebound, oneself it texture conservative and gives texture [SEP]']
[ 450/2000] tot_loss=2.021 (perp=9.458, rec=0.125, cos=0.004), tot_loss_proj:3.159 [t=0.22s]
prediction: ['[CLS] new hide the movie finds new traditions often gavebound. texture ourbound america hidebound, oneself it texture conservative and gives texture [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.022 (perp=9.476, rec=0.124, cos=0.003), tot_loss_proj:3.085 [t=0.24s]
prediction: ['[CLS] new hide a movie finds new traditions often gavebound. texture our americabound hidebound, oneself it texture conservative and gives texture [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.834 (perp=8.578, rec=0.115, cos=0.003), tot_loss_proj:2.412 [t=0.24s]
prediction: ['[CLS] new america of movie finds new traditions often made ;. texture our hidebound hidebound, experience it texture conservative and gives texture [SEP]']
[ 600/2000] tot_loss=1.923 (perp=9.119, rec=0.097, cos=0.002), tot_loss_proj:2.705 [t=0.24s]
prediction: ['[CLS] new america of movie finds new traditions often made ;. one our hidebound andbound, oneself it texture conservative and gives texture [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.791 (perp=8.452, rec=0.097, cos=0.003), tot_loss_proj:2.334 [t=0.24s]
prediction: ['[CLS] ; america of movie finds new traditions often made new. one our hidebound andbound, experience it texture conservative and gives relevance [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.808 (perp=8.561, rec=0.094, cos=0.002), tot_loss_proj:2.464 [t=0.24s]
prediction: ['[CLS] ; decisions of movie finds new traditions often made new. one our hidebound and most, experience it texture conservative and gives relevance [SEP]']
[ 750/2000] tot_loss=1.807 (perp=8.561, rec=0.093, cos=0.002), tot_loss_proj:2.462 [t=0.24s]
prediction: ['[CLS] ; decisions of movie finds new traditions often made new. one our hidebound and most, experience it texture conservative and gives relevance [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.817 (perp=8.592, rec=0.096, cos=0.002), tot_loss_proj:2.522 [t=0.24s]
prediction: ['[CLS] ; decisions our movie finds new traditions often made new - one of hidebound and most, experience it texture conservative and gives relevance [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.782 (perp=8.462, rec=0.088, cos=0.002), tot_loss_proj:2.686 [t=0.24s]
prediction: ['[CLS] ; decisions our movie finds new traditions most made new - one of hidebound and most old, it texture conservative and gives relevance [SEP]']
[ 900/2000] tot_loss=1.808 (perp=8.556, rec=0.095, cos=0.002), tot_loss_proj:2.623 [t=0.24s]
prediction: ['[CLS] ; decisions our movie finds new traditions most made new - one of hidebound and most meets, it texture conservative and gives relevance [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.745 (perp=8.273, rec=0.089, cos=0.002), tot_loss_proj:2.541 [t=0.24s]
prediction: ['[CLS] ; decisions our movie finds new traditions most made new - one of hidebound and most texture, it element conservative and gives relevance [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.707 (perp=8.103, rec=0.085, cos=0.002), tot_loss_proj:2.500 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions most made ; - one of hidebound and most texture, it element conservative and gives relevance [SEP]']
[1050/2000] tot_loss=1.712 (perp=8.103, rec=0.090, cos=0.002), tot_loss_proj:2.501 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions most made ; - one of hidebound and most texture, it element conservative and gives relevance [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.672 (perp=7.908, rec=0.088, cos=0.002), tot_loss_proj:2.433 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions - most making ; one of hidebound and most texture, it element conservative and gives relevance [SEP]']
Attempt swap
[1150/2000] tot_loss=1.656 (perp=7.851, rec=0.084, cos=0.002), tot_loss_proj:2.373 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions - most making. one of hidebound and most texture, it element conservative and gives relevance [SEP]']
[1200/2000] tot_loss=1.672 (perp=7.932, rec=0.084, cos=0.002), tot_loss_proj:2.493 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions - most making. one of hidebound and most texture, it exist conservative and gives relevance [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.655 (perp=7.842, rec=0.085, cos=0.002), tot_loss_proj:2.392 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions - making most. one of hidebound and most texture, it exist conservative and gives relevance [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.607 (perp=7.552, rec=0.094, cos=0.002), tot_loss_proj:2.349 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions - making most one of hidebound and most texture, it exist conservative and gives relevance. [SEP]']
[1350/2000] tot_loss=1.694 (perp=8.017, rec=0.089, cos=0.002), tot_loss_proj:2.446 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions making making most one of hidebound and most texture, it exist conservative and gives relevance. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.649 (perp=7.827, rec=0.082, cos=0.002), tot_loss_proj:2.481 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions making making exist one of hidebound and most texture, it most conservative and gives relevance. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.593 (perp=7.556, rec=0.080, cos=0.002), tot_loss_proj:2.747 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions making making exist one of hidebound and most texture, and most conservative it gives relevance. [SEP]']
[1500/2000] tot_loss=1.592 (perp=7.556, rec=0.079, cos=0.002), tot_loss_proj:2.741 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions making making exist one of hidebound and most texture, and most conservative it gives relevance. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.562 (perp=7.356, rec=0.089, cos=0.002), tot_loss_proj:2.528 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions making making exist one of hidebound and most texture, and most conservative gives it relevance. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.531 (perp=7.238, rec=0.081, cos=0.002), tot_loss_proj:2.703 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions ( making making one of hidebound and most texture, and most conservative gives it relevance. [SEP]']
[1650/2000] tot_loss=1.529 (perp=7.238, rec=0.080, cos=0.002), tot_loss_proj:2.706 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds new traditions ( making making one of hidebound and most texture, and most conservative gives it relevance. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.510 (perp=7.127, rec=0.082, cos=0.002), tot_loss_proj:2.606 [t=0.24s]
prediction: ['[CLS] new decisions our movie finds making new traditions ( making one of hidebound and most texture, and most conservative gives it relevance. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.494 (perp=7.057, rec=0.081, cos=0.002), tot_loss_proj:2.586 [t=0.24s]
prediction: ['[CLS] new decisions our movie making finds new traditions ( making one of hidebound and most texture, and most conservative gives it relevance. [SEP]']
[1800/2000] tot_loss=1.491 (perp=7.057, rec=0.078, cos=0.002), tot_loss_proj:2.584 [t=0.24s]
prediction: ['[CLS] new decisions our movie making finds new traditions ( making one of hidebound and most texture, and most conservative gives it relevance. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.490 (perp=7.057, rec=0.077, cos=0.002), tot_loss_proj:2.582 [t=0.24s]
prediction: ['[CLS] new decisions our movie making finds new traditions ( making one of hidebound and most texture, and most conservative gives it relevance. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.476 (perp=6.970, rec=0.080, cos=0.002), tot_loss_proj:2.379 [t=0.24s]
prediction: ['[CLS] making new decisions our movie finds new traditions ( making one of hidebound and most texture, and most conservative gives it relevance. [SEP]']
[1950/2000] tot_loss=1.476 (perp=6.970, rec=0.080, cos=0.002), tot_loss_proj:2.380 [t=0.24s]
prediction: ['[CLS] making new decisions our movie finds new traditions ( making one of hidebound and most texture, and most conservative gives it relevance. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.477 (perp=6.970, rec=0.081, cos=0.002), tot_loss_proj:2.377 [t=0.24s]
prediction: ['[CLS] making new decisions our movie finds new traditions ( making one of hidebound and most texture, and most conservative gives it relevance. [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] new decisions our movie making finds new traditions ( making one of hidebound and most texture, and most conservative gives it relevance. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 86.957 | r: 90.909
rouge2     | fm: 18.605 | p: 18.182 | r: 19.048
rougeL     | fm: 44.444 | p: 43.478 | r: 45.455
rougeLsum  | fm: 44.444 | p: 43.478 | r: 45.455
r1fm+r2fm = 107.494

[Aggregate metrics]:
rouge1     | fm: 91.817 | p: 91.373 | r: 92.330
rouge2     | fm: 59.327 | p: 59.165 | r: 59.501
rougeL     | fm: 78.496 | p: 78.296 | r: 78.866
rougeLsum  | fm: 78.249 | p: 78.085 | r: 78.543
r1fm+r2fm = 151.144

input #39 time: 0:09:22 | total time: 6:11:10


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9993180163624655
highest_index [0]
highest [0.9993180163624655]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9940409064292908 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9588767290115356 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9404011964797974 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 0.9336565732955933 for ['[CLS] alive represents adelaide cinder majestymersfordthes s [SEP]']
[Init] best rec loss: 0.9329563975334167 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 0.9272531867027283 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 0.9182189702987671 for ['[CLS] formula expression groundsoft written used ⇒ution murray [SEP]']
[Init] best rec loss: 0.9071977734565735 for ['[CLS] alloid courtesy [MASK]blood mean gownrarm [SEP]']
[Init] best rec loss: 0.847230076789856 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8415253162384033 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8396544456481934 for ['[CLS]° georgian but kent lady abd many already deciding [SEP]']
[Init] best perm rec loss: 0.8368232250213623 for ['[CLS] deciding° lady abd but kent georgian already many [SEP]']
[Init] best perm rec loss: 0.834687352180481 for ['[CLS] kent already deciding lady but abd georgian° many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.749 (perp=12.157, rec=0.306, cos=0.011), tot_loss_proj:3.439 [t=0.23s]
prediction: ['[CLS] electronicmmel us pu anger orony language corruption [SEP]']
[ 100/2000] tot_loss=2.831 (perp=13.292, rec=0.166, cos=0.006), tot_loss_proj:3.812 [t=0.23s]
prediction: ['[CLS] electronicmmel us pu crazy withony imageryony [SEP]']
[ 150/2000] tot_loss=2.839 (perp=13.601, rec=0.114, cos=0.004), tot_loss_proj:3.363 [t=0.23s]
prediction: ['[CLS] electronicmmel us pu ph withony imageryony [SEP]']
[ 200/2000] tot_loss=2.658 (perp=12.849, rec=0.086, cos=0.003), tot_loss_proj:3.112 [t=0.23s]
prediction: ['[CLS] electronicmmel us pu ph withony imagery or [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.105 (perp=10.149, rec=0.074, cos=0.002), tot_loss_proj:2.448 [t=0.23s]
prediction: ['[CLS] music pummel us ph withony imagery or [SEP]']
[ 300/2000] tot_loss=2.102 (perp=10.149, rec=0.071, cos=0.001), tot_loss_proj:2.460 [t=0.23s]
prediction: ['[CLS] music pummel us ph withony imagery or [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.703 (perp=8.184, rec=0.065, cos=0.001), tot_loss_proj:2.387 [t=0.23s]
prediction: ['[CLS] music pummel us phony with imagery or [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.606 (perp=7.355, rec=0.132, cos=0.003), tot_loss_proj:2.077 [t=0.23s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
[ 450/2000] tot_loss=1.570 (perp=7.355, rec=0.097, cos=0.002), tot_loss_proj:2.105 [t=0.23s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.505 (perp=7.096, rec=0.084, cos=0.002), tot_loss_proj:2.045 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.502 (perp=7.096, rec=0.081, cos=0.002), tot_loss_proj:2.049 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[ 600/2000] tot_loss=1.497 (perp=7.096, rec=0.076, cos=0.001), tot_loss_proj:2.044 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.491 (perp=7.096, rec=0.070, cos=0.001), tot_loss_proj:2.044 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.497 (perp=7.096, rec=0.076, cos=0.001), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[ 750/2000] tot_loss=1.494 (perp=7.096, rec=0.074, cos=0.001), tot_loss_proj:2.043 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.497 (perp=7.096, rec=0.076, cos=0.001), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.482 (perp=7.096, rec=0.062, cos=0.001), tot_loss_proj:2.044 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[ 900/2000] tot_loss=1.483 (perp=7.096, rec=0.062, cos=0.001), tot_loss_proj:2.040 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.485 (perp=7.096, rec=0.064, cos=0.001), tot_loss_proj:2.045 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1000/2000] tot_loss=1.485 (perp=7.096, rec=0.064, cos=0.001), tot_loss_proj:2.041 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1050/2000] tot_loss=1.492 (perp=7.096, rec=0.071, cos=0.001), tot_loss_proj:2.040 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1100/2000] tot_loss=1.493 (perp=7.096, rec=0.073, cos=0.001), tot_loss_proj:2.043 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1150/2000] tot_loss=1.488 (perp=7.096, rec=0.067, cos=0.001), tot_loss_proj:2.036 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1200/2000] tot_loss=1.497 (perp=7.096, rec=0.076, cos=0.001), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1250/2000] tot_loss=1.487 (perp=7.096, rec=0.067, cos=0.001), tot_loss_proj:2.041 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1300/2000] tot_loss=1.483 (perp=7.096, rec=0.062, cos=0.001), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1350/2000] tot_loss=1.481 (perp=7.096, rec=0.060, cos=0.001), tot_loss_proj:2.044 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1400/2000] tot_loss=1.486 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.042 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1450/2000] tot_loss=1.486 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.034 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1500/2000] tot_loss=1.478 (perp=7.096, rec=0.058, cos=0.001), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1550/2000] tot_loss=1.479 (perp=7.096, rec=0.058, cos=0.001), tot_loss_proj:2.042 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1600/2000] tot_loss=1.481 (perp=7.096, rec=0.060, cos=0.001), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1650/2000] tot_loss=1.479 (perp=7.096, rec=0.058, cos=0.001), tot_loss_proj:2.040 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1700/2000] tot_loss=1.494 (perp=7.096, rec=0.073, cos=0.001), tot_loss_proj:2.033 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1750/2000] tot_loss=1.485 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.039 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1800/2000] tot_loss=1.485 (perp=7.096, rec=0.064, cos=0.001), tot_loss_proj:2.040 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1850/2000] tot_loss=1.480 (perp=7.096, rec=0.059, cos=0.001), tot_loss_proj:2.042 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1900/2000] tot_loss=1.495 (perp=7.096, rec=0.075, cos=0.001), tot_loss_proj:2.040 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1950/2000] tot_loss=1.490 (perp=7.096, rec=0.070, cos=0.001), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[2000/2000] tot_loss=1.488 (perp=7.096, rec=0.068, cos=0.001), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] imagery pummel us or phony with music [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 91.922 | p: 91.504 | r: 92.474
rouge2     | fm: 58.566 | p: 58.394 | r: 58.720
rougeL     | fm: 78.357 | p: 78.098 | r: 78.674
rougeLsum  | fm: 77.958 | p: 77.786 | r: 78.311
r1fm+r2fm = 150.488

input #40 time: 0:08:51 | total time: 6:20:02


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.9993041155296631
highest_index [0]
highest [0.9993041155296631]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9744104743003845 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9511962532997131 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 0.9439316987991333 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 0.933946430683136 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.9258303642272949 for ['[CLS]grapher pr [SEP]']
[Init] best rec loss: 0.9252661466598511 for ['[CLS]mler previously [SEP]']
[Init] best rec loss: 0.9075953364372253 for ['[CLS] electors mediterranean [SEP]']
[Init] best rec loss: 0.8915941715240479 for ['[CLS] meetswr [SEP]']
[Init] best rec loss: 0.852973222732544 for ['[CLS] bolivar satisfied [SEP]']
[Init] best rec loss: 0.8348253965377808 for ['[CLS] ways whether [SEP]']
[Init] best perm rec loss: 0.8253730535507202 for ['[CLS] whether ways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.164 (perp=10.212, rec=0.119, cos=0.003), tot_loss_proj:2.124 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.122 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.109 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.002), tot_loss_proj:2.104 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.002), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.109 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.106 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.105 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.108 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.096 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.107 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.108 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.110 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.115 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.122 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.111 (perp=10.212, rec=0.068, cos=0.001), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.103 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.113 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.119 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.112 (perp=10.212, rec=0.068, cos=0.001), tot_loss_proj:2.109 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.110 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.108 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.102 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.104 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.117 (perp=10.212, rec=0.073, cos=0.001), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.101 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.110 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.116 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.105 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.104 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.108 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.098 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.098 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.103 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.097 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.097 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.102 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.098 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.116 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.116 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.154 | p: 91.772 | r: 92.649
rouge2     | fm: 59.650 | p: 59.475 | r: 59.839
rougeL     | fm: 78.948 | p: 78.674 | r: 79.250
rougeLsum  | fm: 78.631 | p: 78.455 | r: 78.954
r1fm+r2fm = 151.804

input #41 time: 0:09:08 | total time: 6:29:11


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9993266219365816
highest_index [0]
highest [0.9993266219365816]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9052959084510803 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8539038896560669 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8489475846290588 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8198183178901672 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.797766923904419 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7967566251754761 for ['[CLS] wish stages ran offendedrs bandagible attracted ever scale kitchenctric international liftedtaking superseded cut assignmentures enough treatyplingbe larger dare maple [SEP]']
[Init] best perm rec loss: 0.7962284684181213 for ['[CLS]ures dare scale offended international evertaking wish enough largerpling assignmentgiblectric ran kitchen stagesrs attracted banda treaty lifted maple supersededbe cut [SEP]']
[Init] best perm rec loss: 0.7946922779083252 for ['[CLS]taking superseded international banda maple dare cut wish attracted ran kitchen treaty scale larger ever enoughbegible stagesuresrs liftedctric assignmentpling offended [SEP]']
[Init] best perm rec loss: 0.7929145693778992 for ['[CLS] bandataking dare rangible attracted maplers international stagespling assignment cut treaty scale enough everctric lifteduresbe superseded wish larger offended kitchen [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.796 (perp=12.439, rec=0.293, cos=0.015), tot_loss_proj:3.327 [t=0.24s]
prediction: ['[CLS] sufficiently they forgot legislation takeover distinction phone closed movie. forgot themselves when coink poorly afterward effectinatory apparently. cart poorly kitchen forgot information [SEP]']
[ 100/2000] tot_loss=2.630 (perp=12.074, rec=0.209, cos=0.007), tot_loss_proj:3.239 [t=0.24s]
prediction: ['[CLS] tame they forgot any $ scary togger filmmakers if forgot themselves as their simpsons poorly earlier attractiongated poorly.gger poorly school forgot into [SEP]']
[ 150/2000] tot_loss=2.378 (perp=10.992, rec=0.175, cos=0.005), tot_loss_proj:2.921 [t=0.24s]
prediction: ['[CLS] they they forgot anything ₍ scary togger project even forgot themselves as they poorly poorly also attractiongger poorly.gger poorly school forgot into [SEP]']
[ 200/2000] tot_loss=2.318 (perp=10.857, rec=0.141, cos=0.005), tot_loss_proj:2.706 [t=0.24s]
prediction: ['[CLS] they filmmakers forgot anything 止 scary to anything project even forgot themselves as they poorly poorly also intogger poorlyjigger a school forgot into [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.155 (perp=10.102, rec=0.130, cos=0.004), tot_loss_proj:2.507 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything scary scary to project scary even scary halfway as theyzziness poorly also intogger poorlyjigger a school forgot setting [SEP]']
[ 300/2000] tot_loss=2.166 (perp=10.284, rec=0.106, cos=0.003), tot_loss_proj:2.530 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anythingअ scary to project scary even scary halfway as theyzziness poorly also into attraction poorlyjigger a school forgot setting [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.122 (perp=10.005, rec=0.115, cos=0.006), tot_loss_proj:2.531 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything) scary to project scary even scary halfway as they poorly poorly re into rejigger a school attraction forgot setting [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.088 (perp=9.874, rec=0.111, cos=0.002), tot_loss_proj:2.569 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anythingअ scary to project scary even scary halfway as they poorly poorly re into include rejigger a school attraction setting [SEP]']
[ 450/2000] tot_loss=2.019 (perp=9.641, rec=0.089, cos=0.002), tot_loss_proj:2.399 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anythingअ scary to project anything even scary halfway as they poorly poorly re into include rejigger a school attraction setting [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.041 (perp=9.766, rec=0.086, cos=0.002), tot_loss_proj:2.559 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project anything even scary halfway as they poorlyअ re into include rejigger a school attraction setting [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.996 (perp=9.551, rec=0.084, cos=0.002), tot_loss_proj:2.461 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project anything even scary halfway as they poorly reअ into include rejigger a school attraction setting [SEP]']
[ 600/2000] tot_loss=1.994 (perp=9.551, rec=0.083, cos=0.002), tot_loss_proj:2.465 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project anything even scary halfway as they poorly reअ into include rejigger a school attraction setting [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.045 (perp=9.841, rec=0.075, cos=0.002), tot_loss_proj:2.772 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project anything even scary halfway as they poorly re fatal into include rejigger a school attraction setting [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.971 (perp=9.425, rec=0.084, cos=0.002), tot_loss_proj:2.685 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project anything even scary halfway as they re া fatal into include rejigger a school attraction setting [SEP]']
[ 750/2000] tot_loss=2.112 (perp=10.161, rec=0.078, cos=0.002), tot_loss_proj:2.974 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project fatal even scary halfway as they re া fatal into include rejigger a school attraction setting [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.107 (perp=10.161, rec=0.073, cos=0.002), tot_loss_proj:2.973 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project fatal even scary halfway as they re া fatal into include rejigger a school attraction setting [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.012 (perp=9.670, rec=0.076, cos=0.002), tot_loss_proj:2.838 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project halfway even scary fatal as they re া fatal into include rejigger a school attraction setting [SEP]']
[ 900/2000] tot_loss=2.021 (perp=9.670, rec=0.085, cos=0.002), tot_loss_proj:2.833 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project halfway even scary fatal as they re া fatal into include rejigger a school attraction setting [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.057 (perp=9.881, rec=0.079, cos=0.002), tot_loss_proj:2.965 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project halfway even scary fatal as they re fatal fatal into a include rejigger school attraction setting [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.909 (perp=9.094, rec=0.088, cos=0.002), tot_loss_proj:2.759 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project halfway even fatal fatal as they re scary fatal into a include rejigger school attraction setting [SEP]']
[1050/2000] tot_loss=1.902 (perp=9.094, rec=0.081, cos=0.002), tot_loss_proj:2.755 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project halfway even fatal fatal as they re scary fatal into a include rejigger school attraction setting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.904 (perp=9.094, rec=0.084, cos=0.002), tot_loss_proj:2.759 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project halfway even fatal fatal as they re scary fatal into a include rejigger school attraction setting [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.856 (perp=8.894, rec=0.076, cos=0.002), tot_loss_proj:2.889 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project halfway even fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
[1200/2000] tot_loss=1.857 (perp=8.894, rec=0.076, cos=0.002), tot_loss_proj:2.890 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project halfway even fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.839 (perp=8.809, rec=0.076, cos=0.002), tot_loss_proj:2.813 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.838 (perp=8.809, rec=0.074, cos=0.002), tot_loss_proj:2.814 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
[1350/2000] tot_loss=1.836 (perp=8.809, rec=0.073, cos=0.002), tot_loss_proj:2.813 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.837 (perp=8.809, rec=0.074, cos=0.002), tot_loss_proj:2.812 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything poorly scary to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.816 (perp=8.685, rec=0.077, cos=0.002), tot_loss_proj:2.853 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
[1500/2000] tot_loss=1.816 (perp=8.685, rec=0.077, cos=0.002), tot_loss_proj:2.853 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.819 (perp=8.685, rec=0.081, cos=0.002), tot_loss_proj:2.849 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.820 (perp=8.685, rec=0.081, cos=0.002), tot_loss_proj:2.858 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
[1650/2000] tot_loss=1.813 (perp=8.685, rec=0.075, cos=0.002), tot_loss_proj:2.856 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.812 (perp=8.685, rec=0.074, cos=0.002), tot_loss_proj:2.858 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.815 (perp=8.685, rec=0.076, cos=0.002), tot_loss_proj:2.860 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
[1800/2000] tot_loss=1.813 (perp=8.685, rec=0.075, cos=0.002), tot_loss_proj:2.856 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.818 (perp=8.685, rec=0.079, cos=0.002), tot_loss_proj:2.858 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.816 (perp=8.685, rec=0.078, cos=0.002), tot_loss_proj:2.857 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
[1950/2000] tot_loss=1.814 (perp=8.685, rec=0.076, cos=0.002), tot_loss_proj:2.854 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.820 (perp=8.685, rec=0.081, cos=0.002), tot_loss_proj:2.854 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] s scary filmmakers forgot anything poorly to project even halfway fatal fatal as they re scary fatal into include a rejigger school attraction setting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 16.667 | p: 16.000 | r: 17.391
rougeL     | fm: 60.000 | p: 57.692 | r: 62.500
rougeLsum  | fm: 60.000 | p: 57.692 | r: 62.500
r1fm+r2fm = 104.667

[Aggregate metrics]:
rouge1     | fm: 92.019 | p: 91.546 | r: 92.625
rouge2     | fm: 58.426 | p: 58.265 | r: 58.588
rougeL     | fm: 78.461 | p: 78.209 | r: 78.857
rougeLsum  | fm: 78.035 | p: 77.752 | r: 78.417
r1fm+r2fm = 150.445

input #42 time: 0:09:32 | total time: 6:38:43


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9992735963516287
highest_index [0]
highest [0.9992735963516287]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9571977853775024 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9207459688186646 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8901294469833374 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.8651462197303772 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.85670405626297 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.8478173613548279 for ['[CLS] carested royals erica [SEP]']
[Init] best rec loss: 0.8367412090301514 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 0.8362466096878052 for ['[CLS]sh nadu shall taylor [SEP]']
[Init] best rec loss: 0.7853533625602722 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7812954783439636 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 0.7793064117431641 for ['[CLS]bus second climbck [SEP]']
[Init] best perm rec loss: 0.7782993912696838 for ['[CLS] secondckbus climb [SEP]']
[Init] best perm rec loss: 0.7752212882041931 for ['[CLS] climb secondbusck [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.548 (perp=11.440, rec=0.254, cos=0.006), tot_loss_proj:2.791 [t=0.23s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 100/2000] tot_loss=2.438 (perp=11.440, rec=0.147, cos=0.003), tot_loss_proj:2.804 [t=0.24s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 150/2000] tot_loss=2.316 (perp=10.986, rec=0.115, cos=0.004), tot_loss_proj:2.790 [t=0.24s]
prediction: ['[CLS] naissisticrc [SEP]']
[ 200/2000] tot_loss=2.280 (perp=10.986, rec=0.079, cos=0.003), tot_loss_proj:2.801 [t=0.24s]
prediction: ['[CLS] naissisticrc [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.109 (perp=5.048, rec=0.095, cos=0.004), tot_loss_proj:1.071 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.090 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.002), tot_loss_proj:1.084 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.002), tot_loss_proj:1.086 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.080 (perp=5.048, rec=0.069, cos=0.002), tot_loss_proj:1.083 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.063 (perp=5.048, rec=0.052, cos=0.001), tot_loss_proj:1.066 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.060 (perp=5.048, rec=0.049, cos=0.001), tot_loss_proj:1.077 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.086 (perp=5.048, rec=0.075, cos=0.001), tot_loss_proj:1.091 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.057 (perp=5.048, rec=0.046, cos=0.001), tot_loss_proj:1.079 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.086 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.084 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.089 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.071 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.060 (perp=5.048, rec=0.049, cos=0.001), tot_loss_proj:1.083 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.076 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.086 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.083 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.082 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.075 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.075 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.077 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.074 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.084 (perp=5.048, rec=0.073, cos=0.001), tot_loss_proj:1.088 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.069 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.084 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.080 (perp=5.048, rec=0.069, cos=0.001), tot_loss_proj:1.077 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.079 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.080 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.092 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.068 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.077 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.079 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.066 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.084 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.079 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.077 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.076 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.061 (perp=5.048, rec=0.050, cos=0.001), tot_loss_proj:1.078 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.085 (perp=5.048, rec=0.074, cos=0.001), tot_loss_proj:1.073 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.078 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.243 | p: 91.816 | r: 92.844
rouge2     | fm: 59.482 | p: 59.323 | r: 59.683
rougeL     | fm: 78.900 | p: 78.619 | r: 79.277
rougeLsum  | fm: 78.755 | p: 78.395 | r: 79.076
r1fm+r2fm = 151.725

input #43 time: 0:08:52 | total time: 6:47:36


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.9992421634507239
highest_index [0]
highest [0.9992421634507239]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9847252368927002 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9550042748451233 for ['[CLS] photo led breath sound coin day opponents allies joycevel move throne doin head huge guest perhaps ; his gaze saddle decide willise new great ¡wark grand [SEP]']
[Init] best rec loss: 0.9321396350860596 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.9320439100265503 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best rec loss: 0.9308730363845825 for ['[CLS] balls greenhouse with punch por new oscar shut puzzle crunch interactive role substanceport those beg than units aged host roller alphabet defeat writing meet guinea one then percentage [SEP]']
[Init] best rec loss: 0.9090942740440369 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best perm rec loss: 0.907383382320404 for ['[CLS] ; raceway contact harbor slave settled haley brow graphic nation hee fatty co contains rock hello formerly data blue landonosihair capacity s illustrated ltd contestants intent comedy [SEP]']
[Init] best perm rec loss: 0.9066078662872314 for ['[CLS] haleyhair fatty intentosi settled illustrated harbor ltd rock nation comedy blue landon brow raceway data contestants graphic hello s ; hee contact formerly co slave capacity contains [SEP]']
[Init] best perm rec loss: 0.9063311815261841 for ['[CLS]osi raceway ltd capacity blue haley contains hee slave hello ; contact rock nation settled comedy formerly data brow intent graphichair harbor contestants illustrated co s fatty landon [SEP]']
[Init] best perm rec loss: 0.9054985046386719 for ['[CLS] rock ltd blue ; contains contact raceway co illustrated haley slave comedy helloosi s intent hee graphic contestants fattyhair harbor settled data brow nation formerly landon capacity [SEP]']
[Init] best perm rec loss: 0.9040576815605164 for ['[CLS] co contains fatty contacthair haley settled contestants graphic data nation blue capacity comedy landon ltd hello brow ; rock raceway hee formerly illustrated harbor s slave intentosi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.413 (perp=10.882, rec=0.228, cos=0.009), tot_loss_proj:2.978 [t=0.22s]
prediction: ['[CLS] brain was mutations lost translation translation the translationential difficult abduction that lost kraftrewex lost our routine lost by expression lost thefest the sneak slack execution [SEP]']
[ 100/2000] tot_loss=2.237 (perp=10.428, rec=0.148, cos=0.004), tot_loss_proj:2.701 [t=0.22s]
prediction: ['[CLS] brain has routine lost translation in the translationential celaena execution. routine frightfest which routinegling routine lost in execution slack hollywoodfest the any slack execution [SEP]']
[ 150/2000] tot_loss=2.342 (perp=11.035, rec=0.132, cos=0.003), tot_loss_proj:2.892 [t=0.22s]
prediction: ['[CLS] brain has routine lost translation in the translationentialalic execution another routine frightfest which routine fright routine lost in whichizes hollywoodfest the hollywood slack execution [SEP]']
[ 200/2000] tot_loss=2.184 (perp=10.398, rec=0.102, cos=0.003), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS]alic has routine lost translation in the translation.alic execution another routine frightfest. routinegling routine lost in whichizes hollywood premise the hollywood slack execution [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.997 (perp=9.479, rec=0.099, cos=0.002), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS]alic has absurd lost translation in the translation.alic execution another fright frightfest the routine. routine lost in whichizes hollywood premise. hollywood slack execution [SEP]']
[ 300/2000] tot_loss=1.926 (perp=9.227, rec=0.079, cos=0.002), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS]alic has absurd lost translation in the translation.alic execution another fright frightfest the routine. routine lost in whichizes the premise. hollywood slack execution [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.071 (perp=9.816, rec=0.105, cos=0.002), tot_loss_proj:2.473 [t=0.22s]
prediction: ['[CLS] ₊ hasalic lostside in the translation valley absurd execution another fright frightfest the routine.. lost in whichizes the premise. hollywood slack execution [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.967 (perp=9.426, rec=0.080, cos=0.002), tot_loss_proj:2.382 [t=0.22s]
prediction: ['[CLS] respective hasalic lostside in the translation. absurd execution another fright frightfest the routine.. lost in whichizes the premise valley hollywood slack execution [SEP]']
[ 450/2000] tot_loss=1.924 (perp=9.203, rec=0.081, cos=0.002), tot_loss_proj:2.315 [t=0.22s]
prediction: ['[CLS] are hasalic lostside in the translation. absurd execution another fright frightfest the routine.. lost in whichizes the premise valley hollywood slack execution [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.830 (perp=8.739, rec=0.080, cos=0.002), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] are hasalic lost. in the translation. absurd execution another the valleyfest the routine.. lost in whichizes the premise fright hollywood slack execution [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.785 (perp=8.510, rec=0.081, cos=0.002), tot_loss_proj:2.252 [t=0.22s]
prediction: ['[CLS] are hasalic been. in the translation. absurd execution another fright valleyfest the routine.. lost in whichizes the premise the hollywood slack execution [SEP]']
[ 600/2000] tot_loss=1.769 (perp=8.510, rec=0.065, cos=0.002), tot_loss_proj:2.258 [t=0.22s]
prediction: ['[CLS] are hasalic been. in the translation. absurd execution another fright valleyfest the routine.. lost in whichizes the premise the hollywood slack execution [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.763 (perp=8.385, rec=0.084, cos=0.002), tot_loss_proj:2.261 [t=0.24s]
prediction: ['[CLS] are hasalic been. in the translation. absurd execution another fright valleyfest the routine. execution lost in whichizes the premise the hollywood slack. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.712 (perp=8.196, rec=0.071, cos=0.002), tot_loss_proj:2.238 [t=0.24s]
prediction: ['[CLS] arealic has been. in the translation. absurd execution another fright valleyfest the routine. execution lost in whichizes the premise the hollywood slack. [SEP]']
[ 750/2000] tot_loss=1.717 (perp=8.196, rec=0.076, cos=0.002), tot_loss_proj:2.235 [t=0.24s]
prediction: ['[CLS] arealic has been. in the translation. absurd execution another fright valleyfest the routine. execution lost in whichizes the premise the hollywood slack. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.717 (perp=8.196, rec=0.076, cos=0.002), tot_loss_proj:2.233 [t=0.24s]
prediction: ['[CLS] arealic has been. in the translation. absurd execution another fright valleyfest the routine. execution lost in whichizes the premise the hollywood slack. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.680 (perp=8.016, rec=0.075, cos=0.002), tot_loss_proj:2.227 [t=0.24s]
prediction: ['[CLS] arealic has been. in the translation. absurd execution another fright valleyfest. the routine execution lost in whichizes the premise the hollywood slack. [SEP]']
[ 900/2000] tot_loss=1.675 (perp=8.016, rec=0.070, cos=0.002), tot_loss_proj:2.224 [t=0.24s]
prediction: ['[CLS] arealic has been. in the translation. absurd execution another fright valleyfest. the routine execution lost in whichizes the premise the hollywood slack. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.607 (perp=7.673, rec=0.071, cos=0.002), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] arealic has been. in the translation. absurd execution another slack valleyfest. the routine execution lost in whichizes the premise the hollywood fright. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.595 (perp=7.637, rec=0.066, cos=0.002), tot_loss_proj:2.034 [t=0.24s]
prediction: ['[CLS] arealic. has been in the translation. absurd execution another slack valleyfest. the routine execution lost in whichizes the premise the hollywood fright. [SEP]']
[1050/2000] tot_loss=1.601 (perp=7.637, rec=0.072, cos=0.002), tot_loss_proj:2.045 [t=0.24s]
prediction: ['[CLS] arealic. has been in the translation. absurd execution another slack valleyfest. the routine execution lost in whichizes the premise the hollywood fright. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.574 (perp=7.501, rec=0.072, cos=0.002), tot_loss_proj:2.003 [t=0.24s]
prediction: ['[CLS] arealic. has been in the translation. absurd execution another slack valleyfest. the routine execution lost in which the premiseizes the hollywood fright. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.574 (perp=7.501, rec=0.072, cos=0.002), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] arealic. has been in the translation. absurd execution another slack valleyfest. the routine execution lost in which the premiseizes the hollywood fright. [SEP]']
[1200/2000] tot_loss=1.580 (perp=7.501, rec=0.078, cos=0.002), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] arealic. has been in the translation. absurd execution another slack valleyfest. the routine execution lost in which the premiseizes the hollywood fright. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.562 (perp=7.453, rec=0.069, cos=0.002), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] executionalic. has been in the translation. absurd are another slack valleyfest. the routine execution lost in which the premiseizes the hollywood fright. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.564 (perp=7.453, rec=0.071, cos=0.002), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] executionalic. has been in the translation. absurd are another slack valleyfest. the routine execution lost in which the premiseizes the hollywood fright. [SEP]']
[1350/2000] tot_loss=1.570 (perp=7.453, rec=0.077, cos=0.002), tot_loss_proj:2.020 [t=0.24s]
prediction: ['[CLS] executionalic. has been in the translation. absurd are another slack valleyfest. the routine execution lost in which the premiseizes the hollywood fright. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.559 (perp=7.453, rec=0.067, cos=0.002), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] executionalic. has been in the translation. absurd are another slack valleyfest. the routine execution lost in which the premiseizes the hollywood fright. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.507 (perp=7.192, rec=0.067, cos=0.002), tot_loss_proj:1.933 [t=0.24s]
prediction: ['[CLS] italic. has been in the translation. absurd are another slack valleyfest. the routine execution lost in which the premiseizes the hollywood fright. [SEP]']
[1500/2000] tot_loss=1.544 (perp=7.388, rec=0.064, cos=0.002), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] italic in has been in the translation. absurd are another slack valleyfest. the routine execution lost in which the premiseizes the hollywood fright. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.525 (perp=7.241, rec=0.075, cos=0.002), tot_loss_proj:2.027 [t=0.24s]
prediction: ['[CLS] italic in has been in the translation. absurd are another slack valleyfest. the routine execution in which the lost premiseizes the hollywood fright. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.522 (perp=7.257, rec=0.069, cos=0.002), tot_loss_proj:2.001 [t=0.24s]
prediction: ['[CLS] in italic has been translation the translation. absurd are another slack valleyfest. the routine execution in which the lost premiseizes the hollywood fright. [SEP]']
[1650/2000] tot_loss=1.529 (perp=7.257, rec=0.076, cos=0.002), tot_loss_proj:2.001 [t=0.24s]
prediction: ['[CLS] in italic has been translation the translation. absurd are another slack valleyfest. the routine execution in which the lost premiseizes the hollywood fright. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.531 (perp=7.257, rec=0.078, cos=0.002), tot_loss_proj:1.997 [t=0.24s]
prediction: ['[CLS] in italic has been translation the translation. absurd are another slack valleyfest. the routine execution in which the lost premiseizes the hollywood fright. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.493 (perp=7.064, rec=0.078, cos=0.002), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] italic has been translation in the translation. absurd are another slack valleyfest. the routine execution in which the lost premiseizes the hollywood fright. [SEP]']
[1800/2000] tot_loss=1.492 (perp=7.064, rec=0.077, cos=0.002), tot_loss_proj:1.967 [t=0.24s]
prediction: ['[CLS] italic has been translation in the translation. absurd are another slack valleyfest. the routine execution in which the lost premiseizes the hollywood fright. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.466 (perp=6.921, rec=0.080, cos=0.002), tot_loss_proj:1.996 [t=0.24s]
prediction: ['[CLS] in italic has been in the translation. absurd are another slack valleyfest. the routine execution in which the lost premiseizes the hollywood fright. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.456 (perp=6.921, rec=0.071, cos=0.002), tot_loss_proj:1.993 [t=0.24s]
prediction: ['[CLS] in italic has been in the translation. absurd are another slack valleyfest. the routine execution in which the lost premiseizes the hollywood fright. [SEP]']
[1950/2000] tot_loss=1.455 (perp=6.921, rec=0.070, cos=0.002), tot_loss_proj:1.993 [t=0.24s]
prediction: ['[CLS] in italic has been in the translation. absurd are another slack valleyfest. the routine execution in which the lost premiseizes the hollywood fright. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.515 (perp=7.225, rec=0.069, cos=0.002), tot_loss_proj:2.007 [t=0.24s]
prediction: ['[CLS] in italic has been in the translation. absurd an another slack valleyfest. the routine execution in which the lost premiseizes the hollywood fright. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] in italic has been translation the translation. absurd are another slack valleyfest. the routine execution in which the lost premiseizes the hollywood fright. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 72.000 | r: 78.261
rouge2     | fm: 17.391 | p: 16.667 | r: 18.182
rougeL     | fm: 50.000 | p: 48.000 | r: 52.174
rougeLsum  | fm: 50.000 | p: 48.000 | r: 52.174
r1fm+r2fm = 92.391

[Aggregate metrics]:
rouge1     | fm: 91.792 | p: 91.337 | r: 92.381
rouge2     | fm: 58.592 | p: 58.407 | r: 58.796
rougeL     | fm: 78.178 | p: 77.876 | r: 78.629
rougeLsum  | fm: 77.983 | p: 77.675 | r: 78.367
r1fm+r2fm = 150.384

input #44 time: 0:09:18 | total time: 6:56:54


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9993981045144514
highest_index [0]
highest [0.9993981045144514]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.9814025163650513 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.93677818775177 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.9145281910896301 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.9122018218040466 for ['[CLS] look greater applications dating decay line learning reagan ata alley fact isn starboard thorne portion stepped women5 bee defense producing ł wingtlestation hold net festival [SEP]']
[Init] best rec loss: 0.9019213914871216 for ['[CLS] need invitation small cross hot no sk cello deep leader motions harry slide guest pity ash nepal rather ashleyinsman previous walt mclean prix van zoneition [SEP]']
[Init] best rec loss: 0.8711106777191162 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.8676222562789917 for ['[CLS]2 ku tree operatedtiv bore murmured single v few letter military status special taste skin joan football ( curtis enclosedlanda gentry five entrance whoa around via [SEP]']
[Init] best perm rec loss: 0.8668943643569946 for ['[CLS] letter fivetiv via v around skin tree murmured taste special single enclosed entrance military curtis joan borelanda football gentry status2 ku ( operated few whoa [SEP]']
[Init] best perm rec loss: 0.8638823628425598 for ['[CLS]tiv single special whoa tree operated gentry football enclosed ( fewlanda five curtis military v taste letter murmured bore around joan ku status2 entrance via skin [SEP]']
[Init] best perm rec loss: 0.8630584478378296 for ['[CLS] enclosed ( taste special murmured whoa letter v bore single via2tivlanda five military curtis gentry operated football entrance joan skin few tree status around ku [SEP]']
[Init] best perm rec loss: 0.8626331686973572 for ['[CLS] taste special murmured skin ( via aroundlanda military letter v enclosed football2 curtis five single entrance few operated whoa bore gentrytiv joan tree status ku [SEP]']
[Init] best perm rec loss: 0.8599068522453308 for ['[CLS] few special fivetiv ku joan around letter bore tree murmured enclosedlanda whoa football military entrance taste skin status gentry curtis via single v ( operated2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.792 (perp=12.193, rec=0.338, cos=0.015), tot_loss_proj:4.211 [t=0.24s]
prediction: ['[CLS] tracks -ping stress kira asa around who x exercise finger this performance themesel &. grab sexy of token until oneye when breakfast operated gymnastics [SEP]']
[ 100/2000] tot_loss=2.405 (perp=10.646, rec=0.265, cos=0.011), tot_loss_proj:3.355 [t=0.24s]
prediction: ['[CLS] - -ed bodies josh - uh - x exercise gavin than - bowel -. goth shoot ofys shelf bow - ( exercise resort contestants [SEP]']
[ 150/2000] tot_loss=2.200 (perp=10.166, rec=0.164, cos=0.003), tot_loss_proj:3.110 [t=0.24s]
prediction: ['[CLS] - -ed movements combat - uh - x exercise gavin than this bowel shoot -mm shoot -y shelf bow - in exercise shelf filming [SEP]']
[ 200/2000] tot_loss=2.031 (perp=9.518, rec=0.126, cos=0.002), tot_loss_proj:2.795 [t=0.24s]
prediction: ['[CLS] - - long movements - - uh - end exercise ten than this bowel shoot -mm - ofen shelf gi - in exercise shelf drama [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.979 (perp=9.295, rec=0.118, cos=0.002), tot_loss_proj:2.709 [t=0.24s]
prediction: ['[CLS] - - long movementsel - uh - shoot the exercise than this bowel shoot -mm - ony shelf gi - in exercise exercise drama [SEP]']
[ 300/2000] tot_loss=1.977 (perp=9.391, rec=0.096, cos=0.002), tot_loss_proj:2.825 [t=0.24s]
prediction: ['[CLS] - - long movementsel - ni - shoot the exercise than this bowel shoot,mm - onel shelf giick in exercise exercise drama [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.960 (perp=9.325, rec=0.093, cos=0.002), tot_loss_proj:2.741 [t=0.24s]
prediction: ['[CLS] - - ni movementsel - long - shoot the exercise than this bowel shoot,mm - ony shelf giick in shelf exercise drama [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.895 (perp=8.938, rec=0.105, cos=0.003), tot_loss_proj:2.695 [t=0.24s]
prediction: ['[CLS] - - ni movementsel - long - shoot the exercise than this bowel crime,mm - on giy shelfick in shelf exercise drama [SEP]']
[ 450/2000] tot_loss=1.914 (perp=9.109, rec=0.091, cos=0.002), tot_loss_proj:2.828 [t=0.24s]
prediction: ['[CLS] - - ni movementsel - long - shoot the exercise than this bowel crime,mm - on giy shelfick in shelfboot drama [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.777 (perp=8.458, rec=0.084, cos=0.002), tot_loss_proj:2.743 [t=0.24s]
prediction: ['[CLS] - - - movementsel crime long - shoot the exercise than this bowel crime,mmick on giy shelf - in pointsick drama [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.720 (perp=8.139, rec=0.091, cos=0.001), tot_loss_proj:2.552 [t=0.24s]
prediction: ['[CLS] - - - movementsel crime long - shoot the exercise in this bowel crime,mmick on giy shelf - than pointick drama [SEP]']
[ 600/2000] tot_loss=1.704 (perp=8.139, rec=0.075, cos=0.001), tot_loss_proj:2.556 [t=0.24s]
prediction: ['[CLS] - - - movementsel crime long - shoot the exercise in this bowel crime,mmick on giy shelf - than pointick drama [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.676 (perp=7.965, rec=0.082, cos=0.001), tot_loss_proj:2.560 [t=0.24s]
prediction: ['[CLS] - - - movementsel crime long shoot - the exercise in this bowel crime,mmick on giy shelf - than pointick drama [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.600 (perp=7.597, rec=0.080, cos=0.001), tot_loss_proj:2.358 [t=0.24s]
prediction: ['[CLS] - - - movementsel - long shoot - the exercise in this bowel crime,mmicky gi on shelf - than pointick drama [SEP]']
[ 750/2000] tot_loss=1.524 (perp=7.240, rec=0.074, cos=0.001), tot_loss_proj:2.336 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime,mmicky gi on shelf - than pointick drama [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.650 (perp=7.861, rec=0.076, cos=0.001), tot_loss_proj:2.476 [t=0.24s]
prediction: ['[CLS] - - - movements -el long shoot - the exercise in this bowel crime,mmicky gi on shelf - than pointick drama [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.516 (perp=7.240, rec=0.067, cos=0.001), tot_loss_proj:2.331 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime,mmicky gi on shelf - than pointick drama [SEP]']
[ 900/2000] tot_loss=1.514 (perp=7.240, rec=0.065, cos=0.001), tot_loss_proj:2.335 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime,mmicky gi on shelf - than pointick drama [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.527 (perp=7.240, rec=0.078, cos=0.001), tot_loss_proj:2.328 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime,mmicky gi on shelf - than pointick drama [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.488 (perp=7.079, rec=0.071, cos=0.001), tot_loss_proj:2.456 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime,mmicky gi on point - than shelfick drama [SEP]']
[1050/2000] tot_loss=1.588 (perp=7.562, rec=0.074, cos=0.001), tot_loss_proj:2.777 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime,mm -y gi on point - than shelfick drama [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.522 (perp=7.273, rec=0.066, cos=0.001), tot_loss_proj:2.657 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime,mm giy - on point - than shelfick drama [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.462 (perp=6.945, rec=0.072, cos=0.001), tot_loss_proj:2.374 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime,mmicky - on point - than shelf gi drama [SEP]']
[1200/2000] tot_loss=1.460 (perp=6.945, rec=0.070, cos=0.001), tot_loss_proj:2.381 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime,mmicky - on point - than shelf gi drama [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.365 (perp=6.462, rec=0.071, cos=0.001), tot_loss_proj:2.069 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on point - than shelf drama [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.334 (perp=6.315, rec=0.069, cos=0.001), tot_loss_proj:1.976 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
[1350/2000] tot_loss=1.338 (perp=6.315, rec=0.074, cos=0.001), tot_loss_proj:1.972 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
Attempt swap
[1400/2000] tot_loss=1.342 (perp=6.315, rec=0.078, cos=0.001), tot_loss_proj:1.975 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
Attempt swap
[1450/2000] tot_loss=1.328 (perp=6.315, rec=0.063, cos=0.001), tot_loss_proj:1.972 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
[1500/2000] tot_loss=1.332 (perp=6.315, rec=0.068, cos=0.001), tot_loss_proj:1.976 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
Attempt swap
[1550/2000] tot_loss=1.332 (perp=6.315, rec=0.068, cos=0.001), tot_loss_proj:1.975 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
Attempt swap
[1600/2000] tot_loss=1.334 (perp=6.315, rec=0.070, cos=0.001), tot_loss_proj:1.973 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
[1650/2000] tot_loss=1.335 (perp=6.315, rec=0.071, cos=0.001), tot_loss_proj:1.973 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
Attempt swap
[1700/2000] tot_loss=1.333 (perp=6.315, rec=0.069, cos=0.001), tot_loss_proj:1.973 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
Attempt swap
[1750/2000] tot_loss=1.328 (perp=6.315, rec=0.064, cos=0.001), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
[1800/2000] tot_loss=1.331 (perp=6.315, rec=0.067, cos=0.001), tot_loss_proj:1.973 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
Attempt swap
[1850/2000] tot_loss=1.333 (perp=6.315, rec=0.068, cos=0.001), tot_loss_proj:1.972 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
Attempt swap
[1900/2000] tot_loss=1.327 (perp=6.315, rec=0.063, cos=0.001), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
[1950/2000] tot_loss=1.337 (perp=6.315, rec=0.073, cos=0.001), tot_loss_proj:1.975 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
Attempt swap
[2000/2000] tot_loss=1.346 (perp=6.315, rec=0.082, cos=0.001), tot_loss_proj:1.975 [t=0.24s]
prediction: ['[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] - - - movements - - long shoot - the exercise in this bowel crime, gimmicky - on - than shelf point drama [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 97.143 | p: 100.000 | r: 94.444
rouge2     | fm: 18.182 | p: 18.750 | r: 17.647
rougeL     | fm: 51.429 | p: 52.941 | r: 50.000
rougeLsum  | fm: 51.429 | p: 52.941 | r: 50.000
r1fm+r2fm = 115.325

[Aggregate metrics]:
rouge1     | fm: 92.007 | p: 91.521 | r: 92.596
rouge2     | fm: 57.843 | p: 57.684 | r: 58.073
rougeL     | fm: 77.699 | p: 77.350 | r: 78.065
rougeLsum  | fm: 77.353 | p: 77.111 | r: 77.699
r1fm+r2fm = 149.849

input #45 time: 0:09:32 | total time: 7:06:27


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9992705828001183
highest_index [0]
highest [0.9992705828001183]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9912108182907104 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9792644381523132 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 0.9478821158409119 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9439657926559448 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.9418700933456421 for ['[CLS] figures w direction pedrich newspaper [SEP]']
[Init] best rec loss: 0.9365411996841431 for ['[CLS] sacked age s between pack lowell [SEP]']
[Init] best rec loss: 0.933304488658905 for ['[CLS] once definition delgnoeousosed [SEP]']
[Init] best rec loss: 0.9163591265678406 for ['[CLS] four no and canada reed donald [SEP]']
[Init] best rec loss: 0.9133361577987671 for ['[CLS] serie templebie half succeeding coast [SEP]']
[Init] best perm rec loss: 0.9114199876785278 for ['[CLS] coast succeedingbie temple half serie [SEP]']
[Init] best perm rec loss: 0.910995364189148 for ['[CLS] serie coast succeedingbie half temple [SEP]']
[Init] best perm rec loss: 0.9107672572135925 for ['[CLS] serie succeeding coastbie half temple [SEP]']
[Init] best perm rec loss: 0.9105656743049622 for ['[CLS] succeedingbie serie half coast temple [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.794 (perp=12.720, rec=0.245, cos=0.005), tot_loss_proj:3.197 [t=0.23s]
prediction: ['[CLS] awarded surprising slick keys [ sleek [SEP]']
[ 100/2000] tot_loss=2.012 (perp=9.270, rec=0.156, cos=0.003), tot_loss_proj:2.087 [t=0.24s]
prediction: ['[CLS] visually highly slickly staged striking [SEP]']
[ 150/2000] tot_loss=1.960 (perp=9.270, rec=0.104, cos=0.002), tot_loss_proj:2.097 [t=0.24s]
prediction: ['[CLS] visually highly slickly staged striking [SEP]']
[ 200/2000] tot_loss=1.872 (perp=8.886, rec=0.093, cos=0.002), tot_loss_proj:2.037 [t=0.24s]
prediction: ['[CLS] visually and slickly staged striking [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.257 (perp=5.916, rec=0.072, cos=0.002), tot_loss_proj:1.243 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 300/2000] tot_loss=1.251 (perp=5.916, rec=0.066, cos=0.002), tot_loss_proj:1.255 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.002), tot_loss_proj:1.245 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.250 (perp=5.916, rec=0.066, cos=0.002), tot_loss_proj:1.254 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 450/2000] tot_loss=1.258 (perp=5.916, rec=0.073, cos=0.002), tot_loss_proj:1.247 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.239 (perp=5.916, rec=0.054, cos=0.002), tot_loss_proj:1.254 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.251 (perp=5.916, rec=0.067, cos=0.002), tot_loss_proj:1.240 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 600/2000] tot_loss=1.252 (perp=5.916, rec=0.067, cos=0.002), tot_loss_proj:1.248 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.255 (perp=5.916, rec=0.071, cos=0.002), tot_loss_proj:1.251 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.251 (perp=5.916, rec=0.066, cos=0.002), tot_loss_proj:1.255 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 750/2000] tot_loss=1.247 (perp=5.916, rec=0.063, cos=0.002), tot_loss_proj:1.250 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.258 (perp=5.916, rec=0.073, cos=0.002), tot_loss_proj:1.253 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.254 (perp=5.916, rec=0.070, cos=0.002), tot_loss_proj:1.243 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 900/2000] tot_loss=1.255 (perp=5.916, rec=0.070, cos=0.002), tot_loss_proj:1.247 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.259 (perp=5.916, rec=0.075, cos=0.002), tot_loss_proj:1.255 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.253 (perp=5.916, rec=0.068, cos=0.002), tot_loss_proj:1.249 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.002), tot_loss_proj:1.244 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.244 (perp=5.916, rec=0.060, cos=0.002), tot_loss_proj:1.250 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.253 (perp=5.916, rec=0.069, cos=0.002), tot_loss_proj:1.252 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.253 (perp=5.916, rec=0.068, cos=0.002), tot_loss_proj:1.252 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.261 (perp=5.916, rec=0.076, cos=0.002), tot_loss_proj:1.253 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.253 (perp=5.916, rec=0.068, cos=0.002), tot_loss_proj:1.245 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.250 (perp=5.916, rec=0.065, cos=0.002), tot_loss_proj:1.253 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.256 (perp=5.916, rec=0.071, cos=0.002), tot_loss_proj:1.248 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.261 (perp=5.916, rec=0.076, cos=0.002), tot_loss_proj:1.248 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.252 (perp=5.916, rec=0.067, cos=0.002), tot_loss_proj:1.241 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.247 (perp=5.916, rec=0.062, cos=0.002), tot_loss_proj:1.247 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.252 (perp=5.916, rec=0.067, cos=0.002), tot_loss_proj:1.244 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.251 (perp=5.916, rec=0.066, cos=0.002), tot_loss_proj:1.252 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.255 (perp=5.916, rec=0.070, cos=0.002), tot_loss_proj:1.251 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.250 (perp=5.916, rec=0.065, cos=0.002), tot_loss_proj:1.245 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.244 (perp=5.916, rec=0.059, cos=0.002), tot_loss_proj:1.252 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.259 (perp=5.916, rec=0.075, cos=0.002), tot_loss_proj:1.244 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.256 (perp=5.916, rec=0.071, cos=0.002), tot_loss_proj:1.256 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.246 (perp=5.916, rec=0.062, cos=0.002), tot_loss_proj:1.262 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.002), tot_loss_proj:1.244 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.157 | p: 91.685 | r: 92.660
rouge2     | fm: 58.776 | p: 58.565 | r: 59.007
rougeL     | fm: 78.107 | p: 77.816 | r: 78.483
rougeLsum  | fm: 77.648 | p: 77.351 | r: 78.004
r1fm+r2fm = 150.932

input #46 time: 0:09:22 | total time: 7:15:49


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9992061235456344
highest_index [0]
highest [0.9992061235456344]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6903454661369324 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6838828325271606 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6738404035568237 for ['[CLS] network biceps truth [SEP]']
[Init] best perm rec loss: 0.672116756439209 for ['[CLS] truth network biceps [SEP]']
[Init] best perm rec loss: 0.6701898574829102 for ['[CLS] truth biceps network [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.773 (perp=12.488, rec=0.239, cos=0.037), tot_loss_proj:3.341 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 100/2000] tot_loss=2.632 (perp=12.488, rec=0.122, cos=0.012), tot_loss_proj:3.395 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 150/2000] tot_loss=2.609 (perp=12.488, rec=0.101, cos=0.010), tot_loss_proj:3.408 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 200/2000] tot_loss=2.612 (perp=12.488, rec=0.105, cos=0.009), tot_loss_proj:3.431 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.614 (perp=12.488, rec=0.109, cos=0.007), tot_loss_proj:3.433 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 300/2000] tot_loss=2.637 (perp=12.488, rec=0.130, cos=0.010), tot_loss_proj:3.428 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.622 (perp=12.488, rec=0.110, cos=0.015), tot_loss_proj:3.429 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.530 (perp=12.148, rec=0.092, cos=0.009), tot_loss_proj:3.015 [t=0.23s]
prediction: ['[CLS]right down transparent [SEP]']
[ 450/2000] tot_loss=2.501 (perp=12.148, rec=0.067, cos=0.004), tot_loss_proj:3.015 [t=0.23s]
prediction: ['[CLS]right down transparent [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.840 (perp=8.803, rec=0.068, cos=0.011), tot_loss_proj:1.857 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.825 (perp=8.803, rec=0.061, cos=0.003), tot_loss_proj:1.876 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.839 (perp=8.803, rec=0.061, cos=0.017), tot_loss_proj:1.857 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.869 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.814 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.876 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.838 (perp=8.803, rec=0.075, cos=0.002), tot_loss_proj:1.868 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.824 (perp=8.803, rec=0.060, cos=0.003), tot_loss_proj:1.875 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.817 (perp=8.803, rec=0.055, cos=0.002), tot_loss_proj:1.866 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.865 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.824 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.871 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.878 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.820 (perp=8.803, rec=0.058, cos=0.002), tot_loss_proj:1.876 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.822 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.869 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.830 (perp=8.803, rec=0.067, cos=0.002), tot_loss_proj:1.866 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.817 (perp=8.803, rec=0.055, cos=0.002), tot_loss_proj:1.869 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.814 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.855 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.823 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.870 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.823 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.857 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.823 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.875 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.814 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.868 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.819 (perp=8.803, rec=0.057, cos=0.002), tot_loss_proj:1.869 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.867 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.885 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.867 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.875 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.825 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.866 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.828 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.868 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.869 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.835 (perp=8.803, rec=0.073, cos=0.002), tot_loss_proj:1.860 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.821 (perp=8.803, rec=0.058, cos=0.002), tot_loss_proj:1.869 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.828 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.884 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.260 | p: 91.814 | r: 92.835
rouge2     | fm: 59.538 | p: 59.437 | r: 59.678
rougeL     | fm: 78.710 | p: 78.418 | r: 79.077
rougeLsum  | fm: 78.180 | p: 77.911 | r: 78.557
r1fm+r2fm = 151.798

input #47 time: 0:09:15 | total time: 7:25:05


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9993043978769418
highest_index [0]
highest [0.9993043978769418]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.9514000415802002 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.9303548336029053 for ['[CLS] general deathstle air [SEP]']
[Init] best rec loss: 0.9121167063713074 for ['[CLS] indians * progress elevator [SEP]']
[Init] best rec loss: 0.895457923412323 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 0.8773390650749207 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 0.8653813004493713 for ['[CLS] yes athletic cobalt mon [SEP]']
[Init] best rec loss: 0.8400688171386719 for ['[CLS]lu natural horizontal work [SEP]']
[Init] best rec loss: 0.7992453575134277 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7948036193847656 for ['[CLS]tutedine graveyard runs [SEP]']
[Init] best perm rec loss: 0.7941678166389465 for ['[CLS]tute graveyarddine runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.590 (perp=11.949, rec=0.193, cos=0.008), tot_loss_proj:2.805 [t=0.22s]
prediction: ['[CLS] rotting rotting rottingoo [SEP]']
[ 100/2000] tot_loss=2.442 (perp=11.428, rec=0.151, cos=0.005), tot_loss_proj:2.917 [t=0.22s]
prediction: ['[CLS] under rotting underbell [SEP]']
[ 150/2000] tot_loss=1.890 (perp=8.982, rec=0.092, cos=0.002), tot_loss_proj:2.403 [t=0.22s]
prediction: ['[CLS] under rottingbelly [SEP]']
[ 200/2000] tot_loss=1.873 (perp=8.982, rec=0.075, cos=0.001), tot_loss_proj:2.396 [t=0.22s]
prediction: ['[CLS] under rottingbelly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.489 (perp=7.028, rec=0.082, cos=0.002), tot_loss_proj:1.726 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 300/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.723 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.471 (perp=7.028, rec=0.064, cos=0.001), tot_loss_proj:1.728 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.721 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 450/2000] tot_loss=1.452 (perp=7.028, rec=0.045, cos=0.001), tot_loss_proj:1.731 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.732 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 600/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.733 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.741 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.729 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.727 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.729 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.466 (perp=7.028, rec=0.059, cos=0.001), tot_loss_proj:1.732 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.725 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.464 (perp=7.028, rec=0.057, cos=0.001), tot_loss_proj:1.728 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.725 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.479 (perp=7.028, rec=0.072, cos=0.001), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.724 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.459 (perp=7.028, rec=0.052, cos=0.001), tot_loss_proj:1.723 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.730 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.476 (perp=7.028, rec=0.069, cos=0.001), tot_loss_proj:1.738 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.476 (perp=7.028, rec=0.069, cos=0.001), tot_loss_proj:1.735 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.459 (perp=7.028, rec=0.052, cos=0.001), tot_loss_proj:1.735 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.729 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.464 (perp=7.028, rec=0.057, cos=0.001), tot_loss_proj:1.735 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.447 (perp=7.028, rec=0.040, cos=0.001), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.479 (perp=7.028, rec=0.072, cos=0.001), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.476 (perp=7.028, rec=0.069, cos=0.001), tot_loss_proj:1.738 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.723 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.491 | p: 92.107 | r: 93.039
rouge2     | fm: 58.419 | p: 58.269 | r: 58.606
rougeL     | fm: 78.462 | p: 78.210 | r: 78.829
rougeLsum  | fm: 78.390 | p: 78.146 | r: 78.731
r1fm+r2fm = 150.910

input #48 time: 0:09:03 | total time: 7:34:08


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9992283885028335
highest_index [0]
highest [0.9992283885028335]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8313477635383606 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7865213751792908 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7855995297431946 for ['[CLS] painted exactly tips haunt unknown going wrong matches until tamillaw ambulance [SEP]']
[Init] best rec loss: 0.7833266854286194 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 0.7775081992149353 for ['[CLS] auto indies pitch after walk lime *wled nike contested fit justin [SEP]']
[Init] best rec loss: 0.7649335861206055 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best rec loss: 0.7577332258224487 for ['[CLS] trick jose college legs jockey baby tongue processiza during gmina patrick [SEP]']
[Init] best perm rec loss: 0.7532427906990051 for ['[CLS] legs jose trick tongue gmina collegeiza during jockey patrick process baby [SEP]']
[Init] best perm rec loss: 0.7514466047286987 for ['[CLS] joseiza legs tongue trick jockey college gmina during process baby patrick [SEP]']
[Init] best perm rec loss: 0.7511851191520691 for ['[CLS] process gmina jockey legs during jose baby tongue patrickiza trick college [SEP]']
[Init] best perm rec loss: 0.7511382102966309 for ['[CLS] trick jose gmina legs collegeiza baby during tongue process patrick jockey [SEP]']
[Init] best perm rec loss: 0.7508964538574219 for ['[CLS] legs college process patrick trick jose babyiza gmina tongue during jockey [SEP]']
[Init] best perm rec loss: 0.7492689490318298 for ['[CLS] jose process legs during baby gmina jockey trick college tongue patrickiza [SEP]']
[Init] best perm rec loss: 0.7477436661720276 for ['[CLS]iza patrick tongue college trick process during legs gmina jose jockey baby [SEP]']
[Init] best perm rec loss: 0.7475663423538208 for ['[CLS]iza process patrick trick jockey tongue legs during college baby jose gmina [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.684 (perp=11.852, rec=0.279, cos=0.034), tot_loss_proj:3.719 [t=0.23s]
prediction: ['[CLS] possibly methods female contempt single contempt women contempt wimbledon against. contempt [SEP]']
[ 100/2000] tot_loss=2.456 (perp=11.312, rec=0.181, cos=0.012), tot_loss_proj:3.302 [t=0.23s]
prediction: ['[CLS] possibly equipped female more singleuous population contempt population against. contempt [SEP]']
[ 150/2000] tot_loss=2.403 (perp=11.292, rec=0.138, cos=0.007), tot_loss_proj:3.327 [t=0.23s]
prediction: ['[CLS] possibly warriors female more single of populationuous population reality. contempt [SEP]']
[ 200/2000] tot_loss=2.607 (perp=11.144, rec=0.319, cos=0.059), tot_loss_proj:3.357 [t=0.23s]
prediction: ['[CLS] possibly however female more single of populationuous [ runs. contempt [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.190 (perp=9.752, rec=0.221, cos=0.019), tot_loss_proj:3.094 [t=0.23s]
prediction: ['[CLS] possibly although female more single of population contemptuous marry hormone. [SEP]']
[ 300/2000] tot_loss=2.098 (perp=9.558, rec=0.176, cos=0.011), tot_loss_proj:3.201 [t=0.23s]
prediction: ['[CLS] possibly although female more single of population contemptuous marry associated. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.059 (perp=9.433, rec=0.164, cos=0.009), tot_loss_proj:3.017 [t=0.23s]
prediction: ['[CLS] possibly although female more single population of contemptuous altitudes associated. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.873 (perp=8.573, rec=0.150, cos=0.009), tot_loss_proj:2.802 [t=0.23s]
prediction: ['[CLS] possibly although female more associated population of contemptuous obituary single. [SEP]']
[ 450/2000] tot_loss=1.869 (perp=8.573, rec=0.147, cos=0.007), tot_loss_proj:2.799 [t=0.23s]
prediction: ['[CLS] possibly although female more associated population of contemptuous obituary single. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.868 (perp=8.578, rec=0.145, cos=0.007), tot_loss_proj:2.877 [t=0.23s]
prediction: ['[CLS] laboratory possibly female more associated population of contemptuous obituary single. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.825 (perp=8.429, rec=0.133, cos=0.007), tot_loss_proj:2.926 [t=0.23s]
prediction: ['[CLS] laboratory possibly female more associated population of contemptuous single obituary. [SEP]']
[ 600/2000] tot_loss=2.119 (perp=9.887, rec=0.136, cos=0.006), tot_loss_proj:3.126 [t=0.23s]
prediction: ['[CLS] laboratory possibly female more saber population of contemptuous single obituary. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.978 (perp=9.249, rec=0.122, cos=0.006), tot_loss_proj:3.017 [t=0.22s]
prediction: ['[CLS] laboratory possibly female more possibly population of contemptuous single saber. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.951 (perp=9.042, rec=0.136, cos=0.006), tot_loss_proj:2.965 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more female population of contemptuous single saber. [SEP]']
[ 750/2000] tot_loss=1.933 (perp=9.042, rec=0.119, cos=0.006), tot_loss_proj:2.969 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more female population of contemptuous single saber. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.863 (perp=8.691, rec=0.118, cos=0.006), tot_loss_proj:2.747 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more female population contemptuous of single saber. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.755 (perp=8.106, rec=0.128, cos=0.006), tot_loss_proj:2.662 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more single population contemptuous of female saber. [SEP]']
[ 900/2000] tot_loss=1.749 (perp=8.106, rec=0.122, cos=0.006), tot_loss_proj:2.663 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more single population contemptuous of female saber. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.747 (perp=8.106, rec=0.121, cos=0.005), tot_loss_proj:2.658 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more single population contemptuous of female saber. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.749 (perp=8.134, rec=0.116, cos=0.005), tot_loss_proj:2.746 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more single population contemptuous of female weapon. [SEP]']
[1050/2000] tot_loss=1.752 (perp=8.134, rec=0.120, cos=0.005), tot_loss_proj:2.750 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more single population contemptuous of female weapon. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.751 (perp=8.134, rec=0.119, cos=0.005), tot_loss_proj:2.742 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more single population contemptuous of female weapon. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.750 (perp=8.134, rec=0.117, cos=0.005), tot_loss_proj:2.744 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more single population contemptuous of female weapon. [SEP]']
[1200/2000] tot_loss=1.742 (perp=8.134, rec=0.110, cos=0.005), tot_loss_proj:2.746 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more single population contemptuous of female weapon. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.686 (perp=7.808, rec=0.119, cos=0.006), tot_loss_proj:2.664 [t=0.22s]
prediction: ['[CLS] laboratory possibly possibly more single population female contemptuous of weapon. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.738 (perp=8.075, rec=0.118, cos=0.005), tot_loss_proj:2.678 [t=0.22s]
prediction: ['[CLS] existence possibly possibly more single population female contemptuous of weapon. [SEP]']
[1350/2000] tot_loss=1.732 (perp=8.075, rec=0.112, cos=0.005), tot_loss_proj:2.676 [t=0.22s]
prediction: ['[CLS] existence possibly possibly more single population female contemptuous of weapon. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.766 (perp=8.179, rec=0.124, cos=0.006), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS] possibly possibly more single population female contemptuous of weapon laboratory. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.645 (perp=7.604, rec=0.119, cos=0.006), tot_loss_proj:2.643 [t=0.22s]
prediction: ['[CLS] possibly possibly more single population female contemptuous of laboratory weapon. [SEP]']
[1500/2000] tot_loss=1.643 (perp=7.604, rec=0.117, cos=0.005), tot_loss_proj:2.644 [t=0.22s]
prediction: ['[CLS] possibly possibly more single population female contemptuous of laboratory weapon. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.633 (perp=7.553, rec=0.117, cos=0.006), tot_loss_proj:2.624 [t=0.22s]
prediction: ['[CLS] possibly possibly more single female population contemptuous of laboratory weapon. [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.614 (perp=7.464, rec=0.116, cos=0.006), tot_loss_proj:2.620 [t=0.22s]
prediction: ['[CLS] possibly possibly more single female population contemptuous of weapon existence. [SEP]']
[1650/2000] tot_loss=1.616 (perp=7.464, rec=0.118, cos=0.005), tot_loss_proj:2.618 [t=0.22s]
prediction: ['[CLS] possibly possibly more single female population contemptuous of weapon existence. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.608 (perp=7.397, rec=0.123, cos=0.005), tot_loss_proj:2.554 [t=0.22s]
prediction: ['[CLS] possibly possibly more single female population contemptuous of weapon ever. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.524 (perp=6.983, rec=0.121, cos=0.006), tot_loss_proj:2.487 [t=0.22s]
prediction: ['[CLS] possibly possibly more single female population ever contemptuous of weapon. [SEP]']
[1800/2000] tot_loss=1.655 (perp=7.695, rec=0.111, cos=0.005), tot_loss_proj:2.597 [t=0.22s]
prediction: ['[CLS] possibly possibly more single female population existence contemptuous of weapon. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.587 (perp=7.293, rec=0.123, cos=0.005), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS] possibly possibly more single female population hormone contemptuous of existence. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.561 (perp=7.168, rec=0.121, cos=0.006), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] possibly possibly more single female hormone contemptuous of population existence. [SEP]']
[1950/2000] tot_loss=1.554 (perp=7.168, rec=0.115, cos=0.005), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] possibly possibly more single female hormone contemptuous of population existence. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.633 (perp=7.541, rec=0.119, cos=0.005), tot_loss_proj:2.542 [t=0.22s]
prediction: ['[CLS] possibly possibly more single female hormone contemptuous of population ever. [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] existence possibly possibly more single population female contemptuous of weapon. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 9.091 | p: 9.091 | r: 9.091
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 84.091

[Aggregate metrics]:
rouge1     | fm: 92.213 | p: 91.755 | r: 92.686
rouge2     | fm: 57.360 | p: 57.195 | r: 57.523
rougeL     | fm: 77.932 | p: 77.684 | r: 78.283
rougeLsum  | fm: 77.572 | p: 77.326 | r: 77.962
r1fm+r2fm = 149.574

input #49 time: 0:08:53 | total time: 7:43:02


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.999284077484796
highest_index [0]
highest [0.999284077484796]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.9135558009147644 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8380478620529175 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.8375792503356934 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7549297213554382 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7542427182197571 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best perm rec loss: 0.7526724338531494 for ['[CLS] bridgetievinghamlent red by crisis accordance night [SEP]']
[Init] best perm rec loss: 0.7519044876098633 for ['[CLS]ieving byham crisis red accordance night bridgetlent [SEP]']
[Init] best perm rec loss: 0.7473711967468262 for ['[CLS] redham crisislent accordanceieving night bridget by [SEP]']
[Init] best perm rec loss: 0.7473464608192444 for ['[CLS] redlent night crisis accordanceieving by bridgetham [SEP]']
[Init] best perm rec loss: 0.74727863073349 for ['[CLS]lentham nightieving red accordance by crisis bridget [SEP]']
[Init] best perm rec loss: 0.7469528913497925 for ['[CLS] nightlent crisisham accordance bridgetieving red by [SEP]']
[Init] best perm rec loss: 0.7462561130523682 for ['[CLS] night byieving accordancelent crisis red bridgetham [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.221 (perp=13.864, rec=0.387, cos=0.061), tot_loss_proj:4.089 [t=0.21s]
prediction: ['[CLS] una resemblance clever honor james jewish golden thin half [SEP]']
[ 100/2000] tot_loss=2.573 (perp=11.205, rec=0.305, cos=0.027), tot_loss_proj:3.410 [t=0.22s]
prediction: ['[CLS] what call clever english english half clever too half [SEP]']
[ 150/2000] tot_loss=2.464 (perp=10.875, rec=0.270, cos=0.019), tot_loss_proj:2.975 [t=0.22s]
prediction: ['[CLS] what call clever english english half half too what [SEP]']
[ 200/2000] tot_loss=2.407 (perp=10.653, rec=0.256, cos=0.020), tot_loss_proj:2.945 [t=0.22s]
prediction: ['[CLS] what call clever english english half half too half [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.268 (perp=10.011, rec=0.236, cos=0.029), tot_loss_proj:3.270 [t=0.22s]
prediction: ['[CLS] what english call clever english by ` too call [SEP]']
[ 300/2000] tot_loss=2.171 (perp=10.011, rec=0.160, cos=0.009), tot_loss_proj:3.241 [t=0.22s]
prediction: ['[CLS] what english call clever english by ` too call [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.122 (perp=9.781, rec=0.152, cos=0.013), tot_loss_proj:3.118 [t=0.22s]
prediction: ['[CLS] what english call english clever by ` too call [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.037 (perp=9.484, rec=0.133, cos=0.007), tot_loss_proj:3.162 [t=0.22s]
prediction: ['[CLS] what english call english by clever ` too call [SEP]']
[ 450/2000] tot_loss=2.025 (perp=9.484, rec=0.122, cos=0.006), tot_loss_proj:3.157 [t=0.22s]
prediction: ['[CLS] what english call english by clever ` too call [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.208 (perp=10.428, rec=0.116, cos=0.006), tot_loss_proj:3.048 [t=0.22s]
prediction: ['[CLS] what english call half by clever ` too call [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.044 (perp=9.738, rec=0.092, cos=0.004), tot_loss_proj:3.280 [t=0.22s]
prediction: ['[CLS] what english ` half by clever call too call [SEP]']
[ 600/2000] tot_loss=2.026 (perp=9.738, rec=0.077, cos=0.002), tot_loss_proj:3.274 [t=0.22s]
prediction: ['[CLS] what english ` half by clever call too call [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.920 (perp=9.178, rec=0.082, cos=0.002), tot_loss_proj:3.163 [t=0.22s]
prediction: ['[CLS] what half ` english by clever call too call [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.864 (perp=8.859, rec=0.088, cos=0.005), tot_loss_proj:3.050 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
[ 750/2000] tot_loss=1.860 (perp=8.859, rec=0.085, cos=0.002), tot_loss_proj:3.058 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.853 (perp=8.859, rec=0.079, cos=0.002), tot_loss_proj:3.063 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.850 (perp=8.859, rec=0.076, cos=0.002), tot_loss_proj:3.062 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
[ 900/2000] tot_loss=1.847 (perp=8.859, rec=0.073, cos=0.002), tot_loss_proj:3.059 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.846 (perp=8.859, rec=0.072, cos=0.002), tot_loss_proj:3.056 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1000/2000] tot_loss=1.842 (perp=8.859, rec=0.068, cos=0.002), tot_loss_proj:3.064 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
[1050/2000] tot_loss=1.841 (perp=8.859, rec=0.067, cos=0.002), tot_loss_proj:3.066 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1100/2000] tot_loss=1.853 (perp=8.859, rec=0.079, cos=0.002), tot_loss_proj:3.068 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1150/2000] tot_loss=1.846 (perp=8.859, rec=0.072, cos=0.002), tot_loss_proj:3.060 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
[1200/2000] tot_loss=1.833 (perp=8.859, rec=0.059, cos=0.002), tot_loss_proj:3.064 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1250/2000] tot_loss=1.838 (perp=8.859, rec=0.064, cos=0.002), tot_loss_proj:3.066 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1300/2000] tot_loss=1.842 (perp=8.859, rec=0.068, cos=0.002), tot_loss_proj:3.064 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
[1350/2000] tot_loss=1.847 (perp=8.859, rec=0.073, cos=0.002), tot_loss_proj:3.067 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1400/2000] tot_loss=1.842 (perp=8.859, rec=0.068, cos=0.002), tot_loss_proj:3.066 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1450/2000] tot_loss=1.845 (perp=8.859, rec=0.071, cos=0.002), tot_loss_proj:3.068 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
[1500/2000] tot_loss=1.844 (perp=8.859, rec=0.070, cos=0.002), tot_loss_proj:3.068 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1550/2000] tot_loss=1.850 (perp=8.859, rec=0.076, cos=0.002), tot_loss_proj:3.065 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1600/2000] tot_loss=1.853 (perp=8.859, rec=0.079, cos=0.002), tot_loss_proj:3.066 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
[1650/2000] tot_loss=1.838 (perp=8.859, rec=0.064, cos=0.002), tot_loss_proj:3.070 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1700/2000] tot_loss=1.837 (perp=8.859, rec=0.063, cos=0.002), tot_loss_proj:3.068 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1750/2000] tot_loss=1.849 (perp=8.859, rec=0.075, cos=0.002), tot_loss_proj:3.068 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
[1800/2000] tot_loss=1.845 (perp=8.859, rec=0.071, cos=0.002), tot_loss_proj:3.069 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1850/2000] tot_loss=1.848 (perp=8.859, rec=0.074, cos=0.002), tot_loss_proj:3.073 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[1900/2000] tot_loss=1.847 (perp=8.859, rec=0.073, cos=0.002), tot_loss_proj:3.071 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
[1950/2000] tot_loss=1.850 (perp=8.859, rec=0.076, cos=0.002), tot_loss_proj:3.075 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Attempt swap
[2000/2000] tot_loss=1.847 (perp=8.859, rec=0.073, cos=0.002), tot_loss_proj:3.069 [t=0.22s]
prediction: ['[CLS] what half ` english by the clever too call [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what half ` english by the clever too call [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 111.111

[Aggregate metrics]:
rouge1     | fm: 92.206 | p: 91.842 | r: 92.733
rouge2     | fm: 56.585 | p: 56.434 | r: 56.751
rougeL     | fm: 77.524 | p: 77.250 | r: 77.814
rougeLsum  | fm: 77.135 | p: 76.886 | r: 77.414
r1fm+r2fm = 148.792

input #50 time: 0:08:43 | total time: 7:51:46


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9992547713036274
highest_index [0]
highest [0.9992547713036274]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.8252744078636169 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7898684740066528 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.739183247089386 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7309952974319458 for ['[CLS] join paying nonsense thought secret mine sans fields sara stench [SEP]']
[Init] best rec loss: 0.7296013236045837 for ['[CLS] lying acceptance [MASK] longer fence hotel rocking view knocked iaaf [SEP]']
[Init] best rec loss: 0.719580888748169 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 0.7093055844306946 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 0.7078049778938293 for ['[CLS] disappointed market in toured literary watching once renamedrak medium [SEP]']
[Init] best perm rec loss: 0.7040138840675354 for ['[CLS] in toured once renamed medium watching market disappointed literaryrak [SEP]']
[Init] best perm rec loss: 0.7027232050895691 for ['[CLS] market mediumrak in disappointed once watching literary toured renamed [SEP]']
[Init] best perm rec loss: 0.702092707157135 for ['[CLS]rak once toured market watching renamed disappointed medium literary in [SEP]']
[Init] best perm rec loss: 0.7017946243286133 for ['[CLS] watching disappointed literaryrak once in renamed toured market medium [SEP]']
[Init] best perm rec loss: 0.700471043586731 for ['[CLS] market toured watching in disappointed renamed medium once literaryrak [SEP]']
[Init] best perm rec loss: 0.7004427313804626 for ['[CLS] toured watching disappointed once market literaryrak renamed medium in [SEP]']
[Init] best perm rec loss: 0.6999508738517761 for ['[CLS] toured renamed disappointed market once literary watching inrak medium [SEP]']
[Init] best perm rec loss: 0.6995094418525696 for ['[CLS] watching inrak renamed medium disappointed toured once market literary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.648 (perp=11.107, rec=0.350, cos=0.076), tot_loss_proj:3.219 [t=0.22s]
prediction: ['[CLS] sucks sucks. k funny funny is adventure sucks where [SEP]']
[ 100/2000] tot_loss=2.421 (perp=10.778, rec=0.239, cos=0.027), tot_loss_proj:3.086 [t=0.22s]
prediction: ['[CLS] sucks sucks. sucks funny moment jackie funny sucks but [SEP]']
[ 150/2000] tot_loss=2.241 (perp=9.863, rec=0.223, cos=0.045), tot_loss_proj:2.995 [t=0.22s]
prediction: ['[CLS] sucks sucks but. funny orries moment moment but [SEP]']
[ 200/2000] tot_loss=2.173 (perp=10.145, rec=0.133, cos=0.011), tot_loss_proj:3.006 [t=0.22s]
prediction: ['[CLS] sucks sucks has. funny or two moment moment but [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.166 (perp=10.168, rec=0.119, cos=0.013), tot_loss_proj:3.022 [t=0.22s]
prediction: ['[CLS] sucks sucks has. funny funny or two moment but [SEP]']
[ 300/2000] tot_loss=1.940 (perp=9.136, rec=0.104, cos=0.009), tot_loss_proj:2.642 [t=0.22s]
prediction: ['[CLS] sucks sucks has two funny moment or two moment but [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.778 (perp=8.266, rec=0.114, cos=0.010), tot_loss_proj:2.472 [t=0.22s]
prediction: ['[CLS] two sucks sucks has funny moment or two moment but [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.690 (perp=7.902, rec=0.101, cos=0.009), tot_loss_proj:2.518 [t=0.22s]
prediction: ['[CLS] although two sucks has funny moment or two moment but [SEP]']
[ 450/2000] tot_loss=1.942 (perp=9.180, rec=0.099, cos=0.007), tot_loss_proj:2.667 [t=0.22s]
prediction: ['[CLS] but two sucks has funny a or two moment but [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.639 (perp=7.683, rec=0.095, cos=0.007), tot_loss_proj:2.197 [t=0.22s]
prediction: ['[CLS] but two sucks has a funny or two moment but [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.639 (perp=7.683, rec=0.097, cos=0.006), tot_loss_proj:2.198 [t=0.22s]
prediction: ['[CLS] but two sucks has a funny or two moment but [SEP]']
[ 600/2000] tot_loss=1.628 (perp=7.683, rec=0.086, cos=0.005), tot_loss_proj:2.191 [t=0.22s]
prediction: ['[CLS] but two sucks has a funny or two moment but [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.948 (perp=9.222, rec=0.098, cos=0.006), tot_loss_proj:2.704 [t=0.22s]
prediction: ['[CLS], two sucks has role funny moment or two but [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.054 (perp=9.727, rec=0.104, cos=0.005), tot_loss_proj:2.683 [t=0.22s]
prediction: ['[CLS], role sucks has two funny moment or a but [SEP]']
[ 750/2000] tot_loss=2.034 (perp=9.727, rec=0.084, cos=0.006), tot_loss_proj:2.694 [t=0.22s]
prediction: ['[CLS], role sucks has two funny moment or a but [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.572 (perp=7.386, rec=0.089, cos=0.006), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS], role sucks has a funny moment or two but [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.478 (perp=6.912, rec=0.088, cos=0.007), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] role sucks, has a funny moment or two but [SEP]']
[ 900/2000] tot_loss=1.470 (perp=6.912, rec=0.082, cos=0.005), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] role sucks, has a funny moment or two but [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.478 (perp=6.912, rec=0.090, cos=0.005), tot_loss_proj:2.344 [t=0.22s]
prediction: ['[CLS] role sucks, has a funny moment or two but [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.438 (perp=6.688, rec=0.095, cos=0.006), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two, [SEP]']
[1050/2000] tot_loss=1.436 (perp=6.688, rec=0.093, cos=0.005), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.425 (perp=6.688, rec=0.082, cos=0.005), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.426 (perp=6.688, rec=0.084, cos=0.005), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two, [SEP]']
[1200/2000] tot_loss=1.419 (perp=6.688, rec=0.076, cos=0.005), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.369 (perp=6.411, rec=0.083, cos=0.005), tot_loss_proj:1.679 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.373 (perp=6.411, rec=0.086, cos=0.005), tot_loss_proj:1.672 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
[1350/2000] tot_loss=1.366 (perp=6.411, rec=0.079, cos=0.005), tot_loss_proj:1.665 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.374 (perp=6.411, rec=0.087, cos=0.005), tot_loss_proj:1.668 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.367 (perp=6.411, rec=0.080, cos=0.004), tot_loss_proj:1.667 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
[1500/2000] tot_loss=1.373 (perp=6.411, rec=0.087, cos=0.004), tot_loss_proj:1.664 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.371 (perp=6.411, rec=0.084, cos=0.004), tot_loss_proj:1.668 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.366 (perp=6.411, rec=0.080, cos=0.004), tot_loss_proj:1.667 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
[1650/2000] tot_loss=1.369 (perp=6.411, rec=0.082, cos=0.004), tot_loss_proj:1.670 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.374 (perp=6.411, rec=0.088, cos=0.004), tot_loss_proj:1.653 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.368 (perp=6.411, rec=0.082, cos=0.004), tot_loss_proj:1.662 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
[1800/2000] tot_loss=1.369 (perp=6.411, rec=0.082, cos=0.004), tot_loss_proj:1.673 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.367 (perp=6.411, rec=0.080, cos=0.004), tot_loss_proj:1.667 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.368 (perp=6.411, rec=0.081, cos=0.004), tot_loss_proj:1.659 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
[1950/2000] tot_loss=1.374 (perp=6.411, rec=0.087, cos=0.004), tot_loss_proj:1.669 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.371 (perp=6.411, rec=0.085, cos=0.004), tot_loss_proj:1.660 [t=0.22s]
prediction: ['[CLS] role sucks but has a funny moment or two. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] role sucks but has a funny moment or two. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 84.211 | p: 80.000 | r: 88.889
rougeL     | fm: 95.238 | p: 90.909 | r: 100.000
rougeLsum  | fm: 95.238 | p: 90.909 | r: 100.000
r1fm+r2fm = 179.449

[Aggregate metrics]:
rouge1     | fm: 92.398 | p: 91.903 | r: 92.919
rouge2     | fm: 57.145 | p: 56.878 | r: 57.387
rougeL     | fm: 77.736 | p: 77.393 | r: 78.180
rougeLsum  | fm: 77.564 | p: 77.212 | r: 78.012
r1fm+r2fm = 149.543

input #51 time: 0:08:45 | total time: 8:00:31


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.9992764367772101
highest_index [0]
highest [0.9992764367772101]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9593117237091064 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9314094185829163 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8956812024116516 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 0.869678795337677 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.796468198299408 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7784504294395447 for ['[CLS] confession commentator die [SEP]']
[Init] best rec loss: 0.7061877846717834 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.7012255787849426 for ['[CLS] expected football vocabulary [SEP]']
[Init] best perm rec loss: 0.6979407072067261 for ['[CLS] football vocabulary expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.491 (perp=11.737, rec=0.140, cos=0.004), tot_loss_proj:2.674 [t=0.23s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.446 (perp=11.737, rec=0.096, cos=0.003), tot_loss_proj:2.656 [t=0.23s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.171 (perp=10.529, rec=0.063, cos=0.002), tot_loss_proj:2.197 [t=0.24s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 200/2000] tot_loss=2.182 (perp=10.529, rec=0.075, cos=0.001), tot_loss_proj:2.196 [t=0.24s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.816 (perp=8.483, rec=0.117, cos=0.003), tot_loss_proj:2.134 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.771 (perp=8.483, rec=0.073, cos=0.001), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.754 (perp=8.483, rec=0.056, cos=0.001), tot_loss_proj:2.132 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.002), tot_loss_proj:2.137 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.001), tot_loss_proj:2.127 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.755 (perp=8.483, rec=0.057, cos=0.001), tot_loss_proj:2.129 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.759 (perp=8.483, rec=0.061, cos=0.001), tot_loss_proj:2.135 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.768 (perp=8.483, rec=0.070, cos=0.001), tot_loss_proj:2.134 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.763 (perp=8.483, rec=0.065, cos=0.001), tot_loss_proj:2.131 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.764 (perp=8.483, rec=0.066, cos=0.001), tot_loss_proj:2.122 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.752 (perp=8.483, rec=0.054, cos=0.001), tot_loss_proj:2.129 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.763 (perp=8.483, rec=0.065, cos=0.001), tot_loss_proj:2.130 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.762 (perp=8.483, rec=0.064, cos=0.001), tot_loss_proj:2.125 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.743 (perp=8.483, rec=0.045, cos=0.001), tot_loss_proj:2.124 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.001), tot_loss_proj:2.127 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.762 (perp=8.483, rec=0.064, cos=0.001), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.751 (perp=8.483, rec=0.053, cos=0.001), tot_loss_proj:2.128 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.762 (perp=8.483, rec=0.064, cos=0.001), tot_loss_proj:2.132 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.763 (perp=8.483, rec=0.065, cos=0.001), tot_loss_proj:2.125 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.757 (perp=8.483, rec=0.059, cos=0.001), tot_loss_proj:2.136 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.766 (perp=8.483, rec=0.068, cos=0.001), tot_loss_proj:2.126 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.764 (perp=8.483, rec=0.066, cos=0.001), tot_loss_proj:2.122 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.763 (perp=8.483, rec=0.065, cos=0.001), tot_loss_proj:2.123 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.758 (perp=8.483, rec=0.060, cos=0.001), tot_loss_proj:2.125 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.767 (perp=8.483, rec=0.069, cos=0.001), tot_loss_proj:2.126 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.755 (perp=8.483, rec=0.057, cos=0.001), tot_loss_proj:2.132 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.764 (perp=8.483, rec=0.066, cos=0.001), tot_loss_proj:2.124 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.755 (perp=8.483, rec=0.057, cos=0.001), tot_loss_proj:2.123 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.769 (perp=8.483, rec=0.071, cos=0.001), tot_loss_proj:2.126 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.750 (perp=8.483, rec=0.052, cos=0.001), tot_loss_proj:2.122 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.763 (perp=8.483, rec=0.065, cos=0.001), tot_loss_proj:2.125 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.748 (perp=8.483, rec=0.050, cos=0.001), tot_loss_proj:2.131 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.757 (perp=8.483, rec=0.059, cos=0.001), tot_loss_proj:2.127 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.751 (perp=8.483, rec=0.053, cos=0.001), tot_loss_proj:2.136 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.757 (perp=8.483, rec=0.059, cos=0.001), tot_loss_proj:2.117 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.763 (perp=8.483, rec=0.065, cos=0.001), tot_loss_proj:2.129 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.470 | p: 92.003 | r: 92.994
rouge2     | fm: 56.020 | p: 55.739 | r: 56.277
rougeL     | fm: 77.749 | p: 77.422 | r: 78.133
rougeLsum  | fm: 77.550 | p: 77.177 | r: 77.917
r1fm+r2fm = 148.490

input #52 time: 0:09:19 | total time: 8:09:50


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9993456844224258
highest_index [0]
highest [0.9993456844224258]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.9461240172386169 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.8590062260627747 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 0.8272409439086914 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 0.7982022166252136 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 0.7196051478385925 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.7162439823150635 for ['[CLS] oro edna [SEP]']
[Init] best rec loss: 0.70369952917099 for ['[CLS] lake highlands [SEP]']
[Init] best rec loss: 0.6949193477630615 for ['[CLS] towerbal [SEP]']
[Init] best rec loss: 0.6925686001777649 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6793366074562073 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.6766685843467712 for ['[CLS] el peace [SEP]']
[Init] best perm rec loss: 0.6740282773971558 for ['[CLS] peace el [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.798 (perp=12.493, rec=0.247, cos=0.052), tot_loss_proj:3.338 [t=0.22s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=2.670 (perp=12.493, rec=0.154, cos=0.018), tot_loss_proj:3.343 [t=0.22s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.656 (perp=12.493, rec=0.139, cos=0.018), tot_loss_proj:3.349 [t=0.22s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=1.670 (perp=8.090, rec=0.049, cos=0.003), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.694 (perp=8.090, rec=0.075, cos=0.002), tot_loss_proj:1.685 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.679 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.689 (perp=8.090, rec=0.069, cos=0.001), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.690 (perp=8.090, rec=0.070, cos=0.001), tot_loss_proj:1.682 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.687 (perp=8.090, rec=0.068, cos=0.001), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.685 (perp=8.090, rec=0.066, cos=0.001), tot_loss_proj:1.683 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.680 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.687 (perp=8.090, rec=0.068, cos=0.001), tot_loss_proj:1.685 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.678 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.670 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.692 (perp=8.090, rec=0.073, cos=0.001), tot_loss_proj:1.682 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.673 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.687 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.688 (perp=8.090, rec=0.069, cos=0.001), tot_loss_proj:1.683 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.686 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.694 (perp=8.090, rec=0.075, cos=0.001), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.675 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.695 (perp=8.090, rec=0.076, cos=0.001), tot_loss_proj:1.678 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.674 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.669 (perp=8.090, rec=0.050, cos=0.001), tot_loss_proj:1.701 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.681 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.689 (perp=8.090, rec=0.070, cos=0.001), tot_loss_proj:1.686 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.679 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.689 (perp=8.090, rec=0.069, cos=0.001), tot_loss_proj:1.678 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.667 (perp=8.090, rec=0.048, cos=0.001), tot_loss_proj:1.670 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.667 (perp=8.090, rec=0.048, cos=0.001), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.670 (perp=8.090, rec=0.050, cos=0.001), tot_loss_proj:1.693 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.678 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.685 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.682 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.687 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.686 (perp=8.090, rec=0.067, cos=0.001), tot_loss_proj:1.682 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.563 | p: 92.135 | r: 93.110
rouge2     | fm: 56.790 | p: 56.599 | r: 57.101
rougeL     | fm: 78.096 | p: 77.764 | r: 78.463
rougeLsum  | fm: 77.781 | p: 77.481 | r: 78.201
r1fm+r2fm = 149.353

input #53 time: 0:08:42 | total time: 8:18:33


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9991884370301731
highest_index [0]
highest [0.9991884370301731]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.9502385258674622 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.8056384325027466 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7584183812141418 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.7190370559692383 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.7029566168785095 for ['[CLS] deployment bro [SEP]']
[Init] best perm rec loss: 0.701512336730957 for ['[CLS] bro deployment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.712 (perp=11.486, rec=0.356, cos=0.059), tot_loss_proj:3.106 [t=0.23s]
prediction: ['[CLS] topics intense [SEP]']
[ 100/2000] tot_loss=2.533 (perp=11.553, rec=0.204, cos=0.019), tot_loss_proj:2.863 [t=0.23s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.419 (perp=11.553, rec=0.102, cos=0.006), tot_loss_proj:2.887 [t=0.23s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.386 (perp=11.553, rec=0.072, cos=0.003), tot_loss_proj:2.887 [t=0.23s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.724 (perp=8.197, rec=0.081, cos=0.004), tot_loss_proj:1.752 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.718 (perp=8.197, rec=0.076, cos=0.003), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.710 (perp=8.197, rec=0.068, cos=0.002), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.711 (perp=8.197, rec=0.069, cos=0.002), tot_loss_proj:1.745 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.724 (perp=8.197, rec=0.082, cos=0.002), tot_loss_proj:1.743 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.704 (perp=8.197, rec=0.063, cos=0.002), tot_loss_proj:1.754 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.698 (perp=8.197, rec=0.057, cos=0.002), tot_loss_proj:1.730 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.697 (perp=8.197, rec=0.055, cos=0.002), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.709 (perp=8.197, rec=0.068, cos=0.002), tot_loss_proj:1.758 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.714 (perp=8.197, rec=0.073, cos=0.002), tot_loss_proj:1.731 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.697 (perp=8.197, rec=0.056, cos=0.002), tot_loss_proj:1.735 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.713 (perp=8.197, rec=0.072, cos=0.002), tot_loss_proj:1.748 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.707 (perp=8.197, rec=0.066, cos=0.002), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.701 (perp=8.197, rec=0.059, cos=0.002), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.716 (perp=8.197, rec=0.075, cos=0.002), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.693 (perp=8.197, rec=0.052, cos=0.002), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.707 (perp=8.197, rec=0.066, cos=0.002), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.699 (perp=8.197, rec=0.058, cos=0.002), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.707 (perp=8.197, rec=0.066, cos=0.002), tot_loss_proj:1.736 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.706 (perp=8.197, rec=0.065, cos=0.002), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.704 (perp=8.197, rec=0.063, cos=0.002), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.702 (perp=8.197, rec=0.061, cos=0.002), tot_loss_proj:1.760 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.712 (perp=8.197, rec=0.071, cos=0.002), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.706 (perp=8.197, rec=0.065, cos=0.002), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.705 (perp=8.197, rec=0.064, cos=0.002), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.709 (perp=8.197, rec=0.068, cos=0.002), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.700 (perp=8.197, rec=0.059, cos=0.002), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.686 (perp=8.197, rec=0.045, cos=0.002), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.692 (perp=8.197, rec=0.051, cos=0.002), tot_loss_proj:1.735 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.690 (perp=8.197, rec=0.049, cos=0.002), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.685 (perp=8.197, rec=0.044, cos=0.002), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.707 (perp=8.197, rec=0.066, cos=0.002), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.697 (perp=8.197, rec=0.056, cos=0.002), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.691 (perp=8.197, rec=0.050, cos=0.002), tot_loss_proj:1.736 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.706 (perp=8.197, rec=0.065, cos=0.002), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.708 (perp=8.197, rec=0.067, cos=0.002), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.784 | p: 92.293 | r: 93.356
rouge2     | fm: 57.566 | p: 57.408 | r: 57.810
rougeL     | fm: 78.493 | p: 78.178 | r: 78.911
rougeLsum  | fm: 78.227 | p: 77.947 | r: 78.551
r1fm+r2fm = 150.350

input #54 time: 0:08:53 | total time: 8:27:26


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9991211459235085
highest_index [0]
highest [0.9991211459235085]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.913703441619873 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.8614296317100525 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7851947546005249 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 0.7724620699882507 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7565978169441223 for ['[CLS] kirk door regional [SEP]']
[Init] best rec loss: 0.7475483417510986 for ['[CLS] plantesthesia pr [SEP]']
[Init] best rec loss: 0.72279953956604 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.7064613103866577 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7058060765266418 for ['[CLS] post holly stride [SEP]']
[Init] best perm rec loss: 0.7033426761627197 for ['[CLS] stride post holly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.529 (perp=10.160, rec=0.388, cos=0.109), tot_loss_proj:3.506 [t=0.23s]
prediction: ['[CLS] falling settle easily [SEP]']
[ 100/2000] tot_loss=2.122 (perp=9.484, rec=0.197, cos=0.028), tot_loss_proj:3.794 [t=0.24s]
prediction: ['[CLS] easily settles easily [SEP]']
[ 150/2000] tot_loss=2.007 (perp=9.583, rec=0.087, cos=0.003), tot_loss_proj:2.334 [t=0.24s]
prediction: ['[CLS] too settles easily [SEP]']
[ 200/2000] tot_loss=1.989 (perp=9.583, rec=0.070, cos=0.002), tot_loss_proj:2.333 [t=0.24s]
prediction: ['[CLS] too settles easily [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.799 (perp=8.670, rec=0.062, cos=0.003), tot_loss_proj:1.808 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=1.804 (perp=8.670, rec=0.068, cos=0.002), tot_loss_proj:1.815 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.797 (perp=8.670, rec=0.061, cos=0.002), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.794 (perp=8.670, rec=0.058, cos=0.002), tot_loss_proj:1.810 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.787 (perp=8.670, rec=0.052, cos=0.002), tot_loss_proj:1.822 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.803 (perp=8.670, rec=0.067, cos=0.002), tot_loss_proj:1.802 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.793 (perp=8.670, rec=0.057, cos=0.002), tot_loss_proj:1.806 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.791 (perp=8.670, rec=0.056, cos=0.002), tot_loss_proj:1.815 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.794 (perp=8.670, rec=0.058, cos=0.002), tot_loss_proj:1.803 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.802 (perp=8.670, rec=0.066, cos=0.002), tot_loss_proj:1.808 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.788 (perp=8.670, rec=0.052, cos=0.002), tot_loss_proj:1.806 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.797 (perp=8.670, rec=0.062, cos=0.002), tot_loss_proj:1.807 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.801 (perp=8.670, rec=0.065, cos=0.002), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.790 (perp=8.670, rec=0.054, cos=0.002), tot_loss_proj:1.797 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.793 (perp=8.670, rec=0.058, cos=0.002), tot_loss_proj:1.806 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.794 (perp=8.670, rec=0.059, cos=0.002), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.794 (perp=8.670, rec=0.058, cos=0.002), tot_loss_proj:1.805 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.794 (perp=8.670, rec=0.058, cos=0.002), tot_loss_proj:1.789 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.803 (perp=8.670, rec=0.067, cos=0.002), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.799 (perp=8.670, rec=0.063, cos=0.002), tot_loss_proj:1.812 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.791 (perp=8.670, rec=0.055, cos=0.002), tot_loss_proj:1.808 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.796 (perp=8.670, rec=0.061, cos=0.002), tot_loss_proj:1.809 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.793 (perp=8.670, rec=0.057, cos=0.002), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.790 (perp=8.670, rec=0.054, cos=0.002), tot_loss_proj:1.805 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.793 (perp=8.670, rec=0.057, cos=0.002), tot_loss_proj:1.802 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.794 (perp=8.670, rec=0.058, cos=0.002), tot_loss_proj:1.795 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.789 (perp=8.670, rec=0.053, cos=0.002), tot_loss_proj:1.817 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.806 (perp=8.670, rec=0.071, cos=0.002), tot_loss_proj:1.807 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.791 (perp=8.670, rec=0.056, cos=0.002), tot_loss_proj:1.792 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.783 (perp=8.670, rec=0.047, cos=0.002), tot_loss_proj:1.789 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.785 (perp=8.670, rec=0.049, cos=0.002), tot_loss_proj:1.805 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.791 (perp=8.670, rec=0.055, cos=0.002), tot_loss_proj:1.801 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.788 (perp=8.670, rec=0.052, cos=0.002), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.796 (perp=8.670, rec=0.060, cos=0.002), tot_loss_proj:1.793 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.797 (perp=8.670, rec=0.061, cos=0.002), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.786 (perp=8.670, rec=0.050, cos=0.002), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.828 | p: 92.452 | r: 93.407
rouge2     | fm: 58.242 | p: 58.028 | r: 58.494
rougeL     | fm: 78.768 | p: 78.474 | r: 79.202
rougeLsum  | fm: 78.634 | p: 78.346 | r: 79.126
r1fm+r2fm = 151.070

input #55 time: 0:09:21 | total time: 8:36:47


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.999275319141455
highest_index [0]
highest [0.999275319141455]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.930572509765625 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.9180293679237366 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.9034432768821716 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 0.8964918255805969 for ['[CLS] sergeant atlanticrted further enough face za sincedah had bringing experience claus stereo tour novelmler trails worn korean armed [SEP]']
[Init] best rec loss: 0.891231894493103 for ['[CLS] direction casual pl constitution orange storm beardction norris polo reaches accmity bladetlingus mayer hatch novels chinese ore [SEP]']
[Init] best rec loss: 0.8843615055084229 for ['[CLS] handed almost with leadership emotional obsidian wall households consolation potential spectroscopy defeated been existing organization variables up acquainted cas dive realm [SEP]']
[Init] best perm rec loss: 0.8818796873092651 for ['[CLS] leadership spectroscopy organization with potential acquainted almost households variables been defeated up wall cas consolation existing dive emotional obsidian handed realm [SEP]']
[Init] best perm rec loss: 0.8813957571983337 for ['[CLS] with handed defeated acquainted up existing cas organization leadership dive variables emotional households realm almost potential consolation wall spectroscopy been obsidian [SEP]']
[Init] best perm rec loss: 0.8785008788108826 for ['[CLS] potential with consolation up spectroscopy emotional almost been obsidian variables leadership organization existing wall handed defeated households cas dive acquainted realm [SEP]']
[Init] best perm rec loss: 0.8777846097946167 for ['[CLS] organization been almost defeated up handed dive households wall with cas spectroscopy existing emotional potential leadership variables consolation obsidian acquainted realm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.484 (perp=11.099, rec=0.255, cos=0.009), tot_loss_proj:3.695 [t=0.22s]
prediction: ['[CLS] films films after cause loads wire damage never somehow could damage damage our costly analysis films impairment without both knows less [SEP]']
[ 100/2000] tot_loss=2.357 (perp=10.864, rec=0.179, cos=0.005), tot_loss_proj:3.384 [t=0.22s]
prediction: ['[CLS] films films which cause loads an loads that had pending damage damage of costly analysis films fix could both fixpara [SEP]']
[ 150/2000] tot_loss=2.158 (perp=9.980, rec=0.158, cos=0.004), tot_loss_proj:2.765 [t=0.22s]
prediction: ['[CLS] films films which cause loads of years that could pending damage damage years costly analysis films fix could never fixpara [SEP]']
[ 200/2000] tot_loss=2.092 (perp=9.934, rec=0.103, cos=0.002), tot_loss_proj:2.655 [t=0.22s]
prediction: ['[CLS] films films which cause loads of years that yearsble damage damage years costly analysis repeated weeks could never fixpara [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.154 (perp=10.288, rec=0.094, cos=0.002), tot_loss_proj:2.776 [t=0.23s]
prediction: ['[CLS] films films which cause loads of years that yearsble damage damage years costly analysis repeated flee could neverpara fix [SEP]']
[ 300/2000] tot_loss=2.153 (perp=10.288, rec=0.094, cos=0.002), tot_loss_proj:2.767 [t=0.22s]
prediction: ['[CLS] films films which cause loads of years that yearsble damage damage years costly analysis repeated flee could neverpara fix [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.959 (perp=9.365, rec=0.085, cos=0.002), tot_loss_proj:2.522 [t=0.23s]
prediction: ['[CLS] films films which cause loads of years damage that yearsble damage of costly analysisble will could neverpara fix [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.881 (perp=9.033, rec=0.073, cos=0.002), tot_loss_proj:2.628 [t=0.22s]
prediction: ['[CLS] analysis films which cause loads of years damage that yearsble damage of costly filmsble will could neverpara fix [SEP]']
[ 450/2000] tot_loss=1.839 (perp=8.821, rec=0.073, cos=0.001), tot_loss_proj:2.555 [t=0.22s]
prediction: ['[CLS] analysis films which cause loads of years damage that years and damage of costly filmsble will could neverpara fix [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.797 (perp=8.604, rec=0.075, cos=0.002), tot_loss_proj:2.576 [t=0.23s]
prediction: ['[CLS] analysis which films cause loads of years damage that years and damage of costly filmsble will could neverpara fix [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.734 (perp=8.275, rec=0.078, cos=0.002), tot_loss_proj:2.532 [t=0.22s]
prediction: ['[CLS] analysis which films cause loads of years damage that years and damage of costly filmsblepara could never will fix [SEP]']
[ 600/2000] tot_loss=1.728 (perp=8.275, rec=0.071, cos=0.002), tot_loss_proj:2.535 [t=0.23s]
prediction: ['[CLS] analysis which films cause loads of years damage that years and damage of costly filmsblepara could never will fix [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.720 (perp=8.275, rec=0.063, cos=0.001), tot_loss_proj:2.531 [t=0.22s]
prediction: ['[CLS] analysis which films cause loads of years damage that years and damage of costly filmsblepara could never will fix [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.724 (perp=8.275, rec=0.067, cos=0.002), tot_loss_proj:2.528 [t=0.22s]
prediction: ['[CLS] analysis which films cause loads of years damage that years and damage of costly filmsblepara could never will fix [SEP]']
[ 750/2000] tot_loss=1.721 (perp=8.275, rec=0.065, cos=0.001), tot_loss_proj:2.533 [t=0.22s]
prediction: ['[CLS] analysis which films cause loads of years damage that years and damage of costly filmsblepara could never will fix [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.774 (perp=8.512, rec=0.070, cos=0.001), tot_loss_proj:2.664 [t=0.22s]
prediction: ['[CLS] analysis which films cause loads of years damage thatre and damage of costly films couldparable never will fix [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.697 (perp=8.100, rec=0.076, cos=0.002), tot_loss_proj:2.455 [t=0.22s]
prediction: ['[CLS] analysis which films cause loads of damage damage thatre and years of costly films couldparable never will fix [SEP]']
[ 900/2000] tot_loss=1.692 (perp=8.100, rec=0.070, cos=0.001), tot_loss_proj:2.454 [t=0.22s]
prediction: ['[CLS] analysis which films cause loads of damage damage thatre and years of costly films couldparable never will fix [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.563 (perp=7.392, rec=0.083, cos=0.002), tot_loss_proj:2.079 [t=0.22s]
prediction: ['[CLS] analysis which films cause loads of damage and years of costly films couldparable damage thatre never will fix [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.511 (perp=7.157, rec=0.078, cos=0.002), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] analysis which films cause loads of damage and could years of costly filmsparable damage that years never will fix [SEP]']
[1050/2000] tot_loss=1.503 (perp=7.157, rec=0.070, cos=0.002), tot_loss_proj:2.251 [t=0.22s]
prediction: ['[CLS] analysis which films cause loads of damage and could years of costly filmsparable damage that years never will fix [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.482 (perp=7.024, rec=0.076, cos=0.002), tot_loss_proj:1.879 [t=0.22s]
prediction: ['[CLS] films which films cause loads of damage and could years of costly analysisparable damage that years never will fix [SEP]']
Attempt swap
[1150/2000] tot_loss=1.483 (perp=7.024, rec=0.076, cos=0.002), tot_loss_proj:1.878 [t=0.23s]
prediction: ['[CLS] films which films cause loads of damage and could years of costly analysisparable damage that years never will fix [SEP]']
[1200/2000] tot_loss=1.485 (perp=7.024, rec=0.078, cos=0.002), tot_loss_proj:1.880 [t=0.22s]
prediction: ['[CLS] films which films cause loads of damage and could years of costly analysisparable damage that years never will fix [SEP]']
Attempt swap
[1250/2000] tot_loss=1.480 (perp=7.024, rec=0.074, cos=0.002), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] films which films cause loads of damage and could years of costly analysisparable damage that years never will fix [SEP]']
Attempt swap
[1300/2000] tot_loss=1.481 (perp=7.024, rec=0.074, cos=0.002), tot_loss_proj:1.876 [t=0.22s]
prediction: ['[CLS] films which films cause loads of damage and could years of costly analysisparable damage that years never will fix [SEP]']
[1350/2000] tot_loss=1.483 (perp=7.024, rec=0.077, cos=0.002), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] films which films cause loads of damage and could years of costly analysisparable damage that years never will fix [SEP]']
Attempt swap
[1400/2000] tot_loss=1.486 (perp=7.024, rec=0.080, cos=0.002), tot_loss_proj:1.876 [t=0.23s]
prediction: ['[CLS] films which films cause loads of damage and could years of costly analysisparable damage that years never will fix [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.549 (perp=7.326, rec=0.082, cos=0.002), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] films which films cause loads of years and years could years of costly analysisparable damage that never will fix [SEP]']
[1500/2000] tot_loss=1.532 (perp=7.326, rec=0.065, cos=0.002), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] films which films cause loads of years and years could years of costly analysisparable damage that never will fix [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.500 (perp=7.152, rec=0.068, cos=0.001), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] films which films cause loads of years and years could years of costly analysisparable damage that will never fix [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.501 (perp=7.152, rec=0.069, cos=0.002), tot_loss_proj:1.960 [t=0.22s]
prediction: ['[CLS] films which films cause loads of years and years could years of costly analysisparable damage that will never fix [SEP]']
[1650/2000] tot_loss=1.503 (perp=7.152, rec=0.071, cos=0.002), tot_loss_proj:1.955 [t=0.23s]
prediction: ['[CLS] films which films cause loads of years and years could years of costly analysisparable damage that will never fix [SEP]']
Attempt swap
[1700/2000] tot_loss=1.495 (perp=7.152, rec=0.063, cos=0.002), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] films which films cause loads of years and years could years of costly analysisparable damage that will never fix [SEP]']
Attempt swap
[1750/2000] tot_loss=1.508 (perp=7.152, rec=0.076, cos=0.002), tot_loss_proj:1.955 [t=0.22s]
prediction: ['[CLS] films which films cause loads of years and years could years of costly analysisparable damage that will never fix [SEP]']
[1800/2000] tot_loss=1.503 (perp=7.152, rec=0.071, cos=0.002), tot_loss_proj:1.951 [t=0.22s]
prediction: ['[CLS] films which films cause loads of years and years could years of costly analysisparable damage that will never fix [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.502 (perp=7.152, rec=0.070, cos=0.002), tot_loss_proj:1.943 [t=0.22s]
prediction: ['[CLS] films which films cause loads of years and years could years of costly analysisparable damage that will never fix [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.496 (perp=7.054, rec=0.083, cos=0.002), tot_loss_proj:1.881 [t=0.22s]
prediction: ['[CLS] films which films cause loads of years and years of costly analysis could yearsparable damage that will never fix [SEP]']
[1950/2000] tot_loss=1.481 (perp=7.054, rec=0.069, cos=0.002), tot_loss_proj:1.882 [t=0.22s]
prediction: ['[CLS] films which films cause loads of years and years of costly analysis could yearsparable damage that will never fix [SEP]']
Attempt swap
[2000/2000] tot_loss=1.485 (perp=7.054, rec=0.072, cos=0.002), tot_loss_proj:1.870 [t=0.22s]
prediction: ['[CLS] films which films cause loads of years and years of costly analysis could yearsparable damage that will never fix [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] films which films cause loads of damage and could years of costly analysisparable damage that years never will fix [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.805 | p: 85.714 | r: 90.000
rouge2     | fm: 46.154 | p: 45.000 | r: 47.368
rougeL     | fm: 68.293 | p: 66.667 | r: 70.000
rougeLsum  | fm: 68.293 | p: 66.667 | r: 70.000
r1fm+r2fm = 133.959

[Aggregate metrics]:
rouge1     | fm: 92.747 | p: 92.290 | r: 93.320
rouge2     | fm: 58.379 | p: 58.147 | r: 58.629
rougeL     | fm: 78.711 | p: 78.391 | r: 79.129
rougeLsum  | fm: 78.527 | p: 78.202 | r: 78.921
r1fm+r2fm = 151.126

input #56 time: 0:08:55 | total time: 8:45:42


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9993819320090143
highest_index [0]
highest [0.9993819320090143]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8591682314872742 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.805242121219635 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.7094612717628479 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6545407772064209 for ['[CLS] expressed [SEP]']
[Init] best rec loss: 0.6484116911888123 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.610 (perp=12.283, rec=0.132, cos=0.022), tot_loss_proj:2.536 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.536 (perp=12.283, rec=0.076, cos=0.003), tot_loss_proj:2.509 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.520 (perp=12.283, rec=0.061, cos=0.003), tot_loss_proj:2.506 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.538 (perp=12.283, rec=0.079, cos=0.002), tot_loss_proj:2.527 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.532 (perp=12.283, rec=0.073, cos=0.002), tot_loss_proj:2.508 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.514 (perp=12.283, rec=0.056, cos=0.002), tot_loss_proj:2.505 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.523 (perp=12.283, rec=0.065, cos=0.002), tot_loss_proj:2.516 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.517 (perp=12.283, rec=0.059, cos=0.001), tot_loss_proj:2.511 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.523 (perp=12.283, rec=0.065, cos=0.001), tot_loss_proj:2.517 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.514 (perp=12.283, rec=0.056, cos=0.001), tot_loss_proj:2.522 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.502 (perp=12.283, rec=0.044, cos=0.001), tot_loss_proj:2.521 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.510 (perp=12.283, rec=0.052, cos=0.001), tot_loss_proj:2.515 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.523 (perp=12.283, rec=0.065, cos=0.001), tot_loss_proj:2.516 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.517 (perp=12.283, rec=0.059, cos=0.001), tot_loss_proj:2.517 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.513 (perp=12.283, rec=0.055, cos=0.001), tot_loss_proj:2.529 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.502 (perp=12.283, rec=0.044, cos=0.001), tot_loss_proj:2.514 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.517 (perp=12.283, rec=0.059, cos=0.001), tot_loss_proj:2.522 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.527 (perp=12.283, rec=0.069, cos=0.001), tot_loss_proj:2.515 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.521 (perp=12.283, rec=0.063, cos=0.001), tot_loss_proj:2.521 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.511 (perp=12.283, rec=0.053, cos=0.001), tot_loss_proj:2.516 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.529 (perp=12.283, rec=0.071, cos=0.001), tot_loss_proj:2.519 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.520 (perp=12.283, rec=0.062, cos=0.001), tot_loss_proj:2.509 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.503 (perp=12.283, rec=0.045, cos=0.001), tot_loss_proj:2.528 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.510 (perp=12.283, rec=0.053, cos=0.001), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.513 (perp=12.283, rec=0.056, cos=0.001), tot_loss_proj:2.521 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.511 (perp=12.283, rec=0.054, cos=0.001), tot_loss_proj:2.508 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.523 (perp=12.283, rec=0.066, cos=0.001), tot_loss_proj:2.525 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.517 (perp=12.283, rec=0.059, cos=0.001), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.510 (perp=12.283, rec=0.053, cos=0.001), tot_loss_proj:2.525 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.519 (perp=12.283, rec=0.061, cos=0.001), tot_loss_proj:2.528 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.514 (perp=12.283, rec=0.056, cos=0.001), tot_loss_proj:2.513 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.525 (perp=12.283, rec=0.068, cos=0.001), tot_loss_proj:2.510 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.519 (perp=12.283, rec=0.061, cos=0.001), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.516 (perp=12.283, rec=0.059, cos=0.001), tot_loss_proj:2.515 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.521 (perp=12.283, rec=0.063, cos=0.001), tot_loss_proj:2.519 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.518 (perp=12.283, rec=0.060, cos=0.001), tot_loss_proj:2.512 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.524 (perp=12.283, rec=0.067, cos=0.001), tot_loss_proj:2.520 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.514 (perp=12.283, rec=0.056, cos=0.001), tot_loss_proj:2.520 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.511 (perp=12.283, rec=0.054, cos=0.001), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.532 (perp=12.283, rec=0.075, cos=0.001), tot_loss_proj:2.529 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.852 | p: 92.404 | r: 93.347
rouge2     | fm: 59.154 | p: 58.926 | r: 59.421
rougeL     | fm: 78.994 | p: 78.694 | r: 79.348
rougeLsum  | fm: 78.848 | p: 78.551 | r: 79.238
r1fm+r2fm = 152.006

input #57 time: 0:09:09 | total time: 8:54:52


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9992687667984019
highest_index [0]
highest [0.9992687667984019]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 0.962661862373352 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9546318054199219 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9182192087173462 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9155486226081848 for ['[CLS]mon recorded govt bolsheviks iv ignited countymetricual helmet army £100 continuedbanes recognition [SEP]']
[Init] best rec loss: 0.8889455795288086 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.875677764415741 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.8751990795135498 for ['[CLS] virtual marian go dreams seed company seat treaty beyond reigning hilt pile stay 2006 austin whereabouts [SEP]']
[Init] best rec loss: 0.8696123361587524 for ['[CLS] down trade zack serious verde thighsager finishedtyle chiefuration apart beautyitical est essay [SEP]']
[Init] best perm rec loss: 0.869049072265625 for ['[CLS]ager serious zack trade beauty finished thighs est essay chieftyleiticaluration apart verde down [SEP]']
[Init] best perm rec loss: 0.8682684898376465 for ['[CLS] finished chief beautyuration trade zack thighs aparttyle verdeitical essay downager serious est [SEP]']
[Init] best perm rec loss: 0.8666278719902039 for ['[CLS]uration finished serious beautytyle zack apart down thighsitical verde essay chief trade estager [SEP]']
[Init] best perm rec loss: 0.8663685321807861 for ['[CLS] beauty finished chief zack serious essay downtyle thighs verde esturation apartiticalager trade [SEP]']
[Init] best perm rec loss: 0.8658364415168762 for ['[CLS] esturationager thighs chief trade zacktyle apart verde down serious essay finished beautyitical [SEP]']
[Init] best perm rec loss: 0.8648908734321594 for ['[CLS] serious chiefager thighs finished est apart tradeitical zack downurationtyle beauty verde essay [SEP]']
[Init] best perm rec loss: 0.8633812665939331 for ['[CLS]uration zack chiefitical est thighs trade downager finished verde aparttyle essay beauty serious [SEP]']
[Init] best perm rec loss: 0.8627644777297974 for ['[CLS]ager down chiefitical finished thighs zacktyle serious beauty tradeuration est essay apart verde [SEP]']
[Init] best perm rec loss: 0.8620972037315369 for ['[CLS] finished verdeitical zackager aparttyleuration trade thighs down est chief serious beauty essay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.370 (perp=10.737, rec=0.218, cos=0.004), tot_loss_proj:3.029 [t=0.23s]
prediction: ['[CLS] was love story and losing loveion love lord jess latino those inspirational elements inspirational create [SEP]']
[ 100/2000] tot_loss=2.113 (perp=9.835, rec=0.143, cos=0.003), tot_loss_proj:2.751 [t=0.24s]
prediction: ['[CLS] is love story and encounter love initial love story john latino the inspirational elements inspirational encounter [SEP]']
[ 150/2000] tot_loss=2.236 (perp=10.545, rec=0.124, cos=0.002), tot_loss_proj:2.679 [t=0.24s]
prediction: ['[CLS] is love story and encounter statement those ideal capturing john latino the inspirational elements inspirational capturing [SEP]']
[ 200/2000] tot_loss=2.047 (perp=9.728, rec=0.099, cos=0.002), tot_loss_proj:2.485 [t=0.24s]
prediction: ['[CLS] is love story, encounter being the ideal capturing john del that inspirational innocence inspirational capturing [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.171 (perp=10.391, rec=0.091, cos=0.002), tot_loss_proj:3.179 [t=0.24s]
prediction: ['[CLS] is love story, latino being the innocence capturing john encounter first inspirational innocence inspirational capturing [SEP]']
[ 300/2000] tot_loss=2.182 (perp=10.447, rec=0.091, cos=0.002), tot_loss_proj:2.767 [t=0.24s]
prediction: ['[CLS] is love story, del... the innocence capturing john encounter first inspirational innocence inspirational ideal [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.768 (perp=8.365, rec=0.093, cos=0.002), tot_loss_proj:2.325 [t=0.24s]
prediction: ['[CLS] del... is love story, the innocence capturing of encounter first inspirational ideal inspirationalism [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.714 (perp=8.144, rec=0.084, cos=0.002), tot_loss_proj:2.146 [t=0.24s]
prediction: ['[CLS] del and is love story, the innocence capturing of first encounter inspirational ideal inspirationalism [SEP]']
[ 450/2000] tot_loss=1.709 (perp=8.144, rec=0.078, cos=0.002), tot_loss_proj:2.143 [t=0.24s]
prediction: ['[CLS] del and is love story, the innocence capturing of first encounter inspirational ideal inspirationalism [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.550 (perp=7.282, rec=0.092, cos=0.002), tot_loss_proj:1.970 [t=0.24s]
prediction: ['[CLS]ism and is love story, the innocence capturing of inspirational first encounter inspirational idealism [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.456 (perp=6.857, rec=0.083, cos=0.002), tot_loss_proj:1.756 [t=0.24s]
prediction: ['[CLS]ism and is love story, capturing the innocence of inspirational first encounter inspirational idealism [SEP]']
[ 600/2000] tot_loss=1.455 (perp=6.857, rec=0.081, cos=0.002), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS]ism and is love story, capturing the innocence of inspirational first encounter inspirational idealism [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.356 (perp=6.411, rec=0.072, cos=0.002), tot_loss_proj:1.618 [t=0.24s]
prediction: ['[CLS]ism and is inspirational love story, capturing the innocence of first encounter ideal idealism [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.260 (perp=5.856, rec=0.087, cos=0.002), tot_loss_proj:1.509 [t=0.24s]
prediction: ['[CLS] idealism and is inspirational love story, capturing the innocence of first encounter idealism [SEP]']
[ 750/2000] tot_loss=1.369 (perp=6.433, rec=0.080, cos=0.002), tot_loss_proj:1.624 [t=0.24s]
prediction: ['[CLS] idealism and is inspirational love story, capturing the innocence of first encounter ofism [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.219 (perp=5.764, rec=0.065, cos=0.002), tot_loss_proj:1.461 [t=0.24s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.237 (perp=5.764, rec=0.083, cos=0.002), tot_loss_proj:1.464 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
[ 900/2000] tot_loss=1.229 (perp=5.764, rec=0.075, cos=0.002), tot_loss_proj:1.463 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.232 (perp=5.764, rec=0.078, cos=0.002), tot_loss_proj:1.473 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
Attempt swap
[1000/2000] tot_loss=1.227 (perp=5.764, rec=0.072, cos=0.002), tot_loss_proj:1.464 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
[1050/2000] tot_loss=1.236 (perp=5.764, rec=0.082, cos=0.002), tot_loss_proj:1.468 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
Attempt swap
[1100/2000] tot_loss=1.237 (perp=5.764, rec=0.082, cos=0.002), tot_loss_proj:1.467 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
Attempt swap
[1150/2000] tot_loss=1.225 (perp=5.764, rec=0.071, cos=0.002), tot_loss_proj:1.468 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
[1200/2000] tot_loss=1.232 (perp=5.764, rec=0.077, cos=0.002), tot_loss_proj:1.471 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
Attempt swap
[1250/2000] tot_loss=1.238 (perp=5.764, rec=0.084, cos=0.002), tot_loss_proj:1.469 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
Attempt swap
[1300/2000] tot_loss=1.233 (perp=5.764, rec=0.078, cos=0.002), tot_loss_proj:1.465 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
[1350/2000] tot_loss=1.237 (perp=5.764, rec=0.082, cos=0.002), tot_loss_proj:1.472 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and ofism [SEP]']
Attempt swap
[1400/2000] tot_loss=1.460 (perp=6.925, rec=0.073, cos=0.002), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence first first encounter and ofism [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.292 (perp=6.005, rec=0.089, cos=0.002), tot_loss_proj:1.523 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and firstism [SEP]']
[1500/2000] tot_loss=1.272 (perp=6.005, rec=0.069, cos=0.002), tot_loss_proj:1.512 [t=0.22s]
prediction: ['[CLS] idealism is inspirational love story, capturing the innocence of first encounter and firstism [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.265 (perp=5.950, rec=0.073, cos=0.002), tot_loss_proj:1.540 [t=0.23s]
prediction: ['[CLS] firstism is inspirational love story, capturing the innocence of first encounter and idealism [SEP]']
Attempt swap
[1600/2000] tot_loss=1.272 (perp=5.950, rec=0.080, cos=0.002), tot_loss_proj:1.542 [t=0.22s]
prediction: ['[CLS] firstism is inspirational love story, capturing the innocence of first encounter and idealism [SEP]']
[1650/2000] tot_loss=1.265 (perp=5.950, rec=0.073, cos=0.002), tot_loss_proj:1.551 [t=0.22s]
prediction: ['[CLS] firstism is inspirational love story, capturing the innocence of first encounter and idealism [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.239 (perp=5.785, rec=0.081, cos=0.002), tot_loss_proj:1.533 [t=0.22s]
prediction: ['[CLS]ism is inspirational love story, first capturing the innocence of first encounter and idealism [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.225 (perp=5.746, rec=0.074, cos=0.002), tot_loss_proj:1.547 [t=0.22s]
prediction: ['[CLS]ism is inspirational love story, first capturing the innocence and first encounter of idealism [SEP]']
[1800/2000] tot_loss=1.220 (perp=5.746, rec=0.069, cos=0.002), tot_loss_proj:1.547 [t=0.22s]
prediction: ['[CLS]ism is inspirational love story, first capturing the innocence and first encounter of idealism [SEP]']
Attempt swap
[1850/2000] tot_loss=1.230 (perp=5.746, rec=0.079, cos=0.002), tot_loss_proj:1.550 [t=0.22s]
prediction: ['[CLS]ism is inspirational love story, first capturing the innocence and first encounter of idealism [SEP]']
Attempt swap
[1900/2000] tot_loss=1.237 (perp=5.746, rec=0.086, cos=0.002), tot_loss_proj:1.546 [t=0.22s]
prediction: ['[CLS]ism is inspirational love story, first capturing the innocence and first encounter of idealism [SEP]']
[1950/2000] tot_loss=1.230 (perp=5.746, rec=0.079, cos=0.002), tot_loss_proj:1.546 [t=0.22s]
prediction: ['[CLS]ism is inspirational love story, first capturing the innocence and first encounter of idealism [SEP]']
Attempt swap
[2000/2000] tot_loss=1.226 (perp=5.746, rec=0.076, cos=0.002), tot_loss_proj:1.549 [t=0.22s]
prediction: ['[CLS]ism is inspirational love story, first capturing the innocence and first encounter of idealism [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS]ism is inspirational love story, first capturing the innocence and first encounter of idealism [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 127.500

[Aggregate metrics]:
rouge1     | fm: 92.880 | p: 92.422 | r: 93.404
rouge2     | fm: 58.784 | p: 58.579 | r: 59.090
rougeL     | fm: 78.960 | p: 78.629 | r: 79.311
rougeLsum  | fm: 78.707 | p: 78.321 | r: 79.099
r1fm+r2fm = 151.665

input #58 time: 0:09:06 | total time: 9:03:58


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9992224840541208
highest_index [0]
highest [0.9992224840541208]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.9158618450164795 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.899953305721283 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 0.89546138048172 for ['[CLS] clutch sports meridian placed weekly dixonwords up⁄ faerie rugby been towards resist programming infantry [SEP]']
[Init] best rec loss: 0.8692657351493835 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.86898273229599 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best rec loss: 0.8669886589050293 for ['[CLS] het hill income rule helping icon minh were way lisa ufc these vampire skins notch good [SEP]']
[Init] best rec loss: 0.8595459461212158 for ['[CLS]ition wandering wearing right wore kent hemisphere purple strict we gas dark deserve tonnes did letterman [SEP]']
[Init] best rec loss: 0.8334484100341797 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best perm rec loss: 0.8307017087936401 for ['[CLS] fleetby tunnel information thus awhile noah wasak races temperament bologna stuff bobo pump 1993 [SEP]']
[Init] best perm rec loss: 0.8305091857910156 for ['[CLS] pumpak temperament thus tunnel noah was awhile bologna fleet information boboby 1993 races stuff [SEP]']
[Init] best perm rec loss: 0.8296042680740356 for ['[CLS] information fleetak 1993 awhile pump stuff noah thus boboby bologna temperament was races tunnel [SEP]']
[Init] best perm rec loss: 0.8292043805122375 for ['[CLS] bologna races stuff pump fleet tunnelakby 1993 noah awhile thus temperament bobo information was [SEP]']
[Init] best perm rec loss: 0.8289357423782349 for ['[CLS] stuff temperament awhile was 1993 races thus pump noah tunnel fleet bobo information bolognaakby [SEP]']
[Init] best perm rec loss: 0.8288805484771729 for ['[CLS] temperament racesby bologna thus awhile information bobo noah stuff pump 1993ak fleet was tunnel [SEP]']
[Init] best perm rec loss: 0.828627347946167 for ['[CLS] thus fleet stuff tunnelak was awhile races bobo 1993 informationby noah temperament pump bologna [SEP]']
[Init] best perm rec loss: 0.8283922672271729 for ['[CLS] bobo races stuff fleet tunnel temperament noah information awhileby thus was 1993ak bologna pump [SEP]']
[Init] best perm rec loss: 0.8274857401847839 for ['[CLS] fleet 1993by temperament bobo stuff thusak awhile noah tunnel information races bologna pump was [SEP]']
[Init] best perm rec loss: 0.8274096250534058 for ['[CLS] 1993 noah bologna tunnel fleet thus awhile stuff temperament pump was boboby informationak races [SEP]']
[Init] best perm rec loss: 0.8264302015304565 for ['[CLS] stuff noahak was awhile fleet races information temperamentby thus 1993 tunnel bobo bologna pump [SEP]']
[Init] best perm rec loss: 0.8250256180763245 for ['[CLS] thus tunnel was informationbyak stuff races 1993 pump temperament awhile bobo fleet bologna noah [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.492 (perp=10.854, rec=0.311, cos=0.010), tot_loss_proj:3.589 [t=0.24s]
prediction: ['[CLS] has young woman princess hall of woman with the and streak including screen story presentation adult [SEP]']
[ 100/2000] tot_loss=2.640 (perp=12.010, rec=0.231, cos=0.007), tot_loss_proj:3.920 [t=0.24s]
prediction: ['[CLS] has char char of young of woman how how womanism including char screen feminist adult [SEP]']
[ 150/2000] tot_loss=2.418 (perp=11.220, rec=0.171, cos=0.003), tot_loss_proj:3.929 [t=0.24s]
prediction: ['[CLS] has char char the young of woman who knows whoism holding char screen screen adult [SEP]']
[ 200/2000] tot_loss=2.464 (perp=11.717, rec=0.118, cos=0.002), tot_loss_proj:3.554 [t=0.24s]
prediction: ['[CLS] has charism the young of woman woman knows whoism holdism screen screen adult [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.145 (perp=10.171, rec=0.108, cos=0.002), tot_loss_proj:3.239 [t=0.24s]
prediction: ['[CLS] has charism the young of woman woman knows whoa hold -ism screen screen [SEP]']
[ 300/2000] tot_loss=2.136 (perp=10.171, rec=0.100, cos=0.002), tot_loss_proj:3.238 [t=0.24s]
prediction: ['[CLS] has charism the young of woman woman knows whoa hold -ism screen screen [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.974 (perp=9.217, rec=0.128, cos=0.003), tot_loss_proj:2.902 [t=0.24s]
prediction: ['[CLS] has charisma young of woman woman knows who the hold theism screen screen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.820 (perp=8.617, rec=0.094, cos=0.002), tot_loss_proj:2.614 [t=0.24s]
prediction: ['[CLS] has charisma young of woman who knows how the hold theism screen screen [SEP]']
[ 450/2000] tot_loss=1.818 (perp=8.617, rec=0.093, cos=0.002), tot_loss_proj:2.631 [t=0.24s]
prediction: ['[CLS] has charisma young of woman who knows how the hold theism screen screen [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.729 (perp=8.196, rec=0.088, cos=0.002), tot_loss_proj:2.195 [t=0.24s]
prediction: ['[CLS] has charisma of young woman who knows how the hold theism screen screen [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=1.482 (perp=6.916, rec=0.097, cos=0.002), tot_loss_proj:1.825 [t=0.24s]
prediction: ['[CLS] theism screen screen has charisma of young woman who knows how the hold [SEP]']
[ 600/2000] tot_loss=1.468 (perp=6.916, rec=0.083, cos=0.002), tot_loss_proj:1.829 [t=0.24s]
prediction: ['[CLS] theism screen screen has charisma of young woman who knows how the hold [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.449 (perp=6.769, rec=0.093, cos=0.002), tot_loss_proj:1.833 [t=0.24s]
prediction: ['[CLS] theism screen screen has charisma of the young woman who knows how hold [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.443 (perp=6.769, rec=0.088, cos=0.002), tot_loss_proj:1.842 [t=0.24s]
prediction: ['[CLS] theism screen screen has charisma of the young woman who knows how hold [SEP]']
[ 750/2000] tot_loss=1.439 (perp=6.769, rec=0.084, cos=0.002), tot_loss_proj:1.835 [t=0.24s]
prediction: ['[CLS] theism screen screen has charisma of the young woman who knows how hold [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.403 (perp=6.618, rec=0.078, cos=0.002), tot_loss_proj:1.781 [t=0.24s]
prediction: ['[CLS] the screenism screen has charisma of the young woman who knows how hold [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.396 (perp=6.618, rec=0.071, cos=0.002), tot_loss_proj:1.784 [t=0.24s]
prediction: ['[CLS] the screenism screen has charisma of the young woman who knows how hold [SEP]']
[ 900/2000] tot_loss=1.393 (perp=6.618, rec=0.068, cos=0.002), tot_loss_proj:1.785 [t=0.24s]
prediction: ['[CLS] the screenism screen has charisma of the young woman who knows how hold [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.296 (perp=6.112, rec=0.072, cos=0.002), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1000/2000] tot_loss=1.290 (perp=6.112, rec=0.066, cos=0.002), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
[1050/2000] tot_loss=1.310 (perp=6.112, rec=0.086, cos=0.002), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1100/2000] tot_loss=1.303 (perp=6.112, rec=0.079, cos=0.002), tot_loss_proj:1.705 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1150/2000] tot_loss=1.305 (perp=6.112, rec=0.081, cos=0.002), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
[1200/2000] tot_loss=1.297 (perp=6.112, rec=0.073, cos=0.002), tot_loss_proj:1.706 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1250/2000] tot_loss=1.295 (perp=6.112, rec=0.071, cos=0.002), tot_loss_proj:1.697 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.296 (perp=6.112, rec=0.072, cos=0.002), tot_loss_proj:1.712 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
[1350/2000] tot_loss=1.295 (perp=6.112, rec=0.071, cos=0.002), tot_loss_proj:1.705 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1400/2000] tot_loss=1.305 (perp=6.112, rec=0.081, cos=0.002), tot_loss_proj:1.715 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1450/2000] tot_loss=1.305 (perp=6.112, rec=0.081, cos=0.002), tot_loss_proj:1.713 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
[1500/2000] tot_loss=1.299 (perp=6.112, rec=0.075, cos=0.002), tot_loss_proj:1.714 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1550/2000] tot_loss=1.301 (perp=6.112, rec=0.077, cos=0.002), tot_loss_proj:1.716 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1600/2000] tot_loss=1.296 (perp=6.112, rec=0.072, cos=0.002), tot_loss_proj:1.717 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
[1650/2000] tot_loss=1.296 (perp=6.112, rec=0.072, cos=0.002), tot_loss_proj:1.716 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1700/2000] tot_loss=1.295 (perp=6.112, rec=0.071, cos=0.002), tot_loss_proj:1.714 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1750/2000] tot_loss=1.305 (perp=6.112, rec=0.081, cos=0.002), tot_loss_proj:1.716 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
[1800/2000] tot_loss=1.297 (perp=6.112, rec=0.073, cos=0.002), tot_loss_proj:1.716 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1850/2000] tot_loss=1.300 (perp=6.112, rec=0.076, cos=0.002), tot_loss_proj:1.708 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[1900/2000] tot_loss=1.289 (perp=6.112, rec=0.065, cos=0.002), tot_loss_proj:1.717 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
[1950/2000] tot_loss=1.301 (perp=6.112, rec=0.077, cos=0.002), tot_loss_proj:1.717 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Attempt swap
[2000/2000] tot_loss=1.299 (perp=6.112, rec=0.075, cos=0.002), tot_loss_proj:1.714 [t=0.24s]
prediction: ['[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] screenism screen has the charisma of the young woman who knows how hold [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.323 | p: 93.333 | r: 87.500
rouge2     | fm: 48.276 | p: 50.000 | r: 46.667
rougeL     | fm: 77.419 | p: 80.000 | r: 75.000
rougeLsum  | fm: 77.419 | p: 80.000 | r: 75.000
r1fm+r2fm = 138.598

[Aggregate metrics]:
rouge1     | fm: 92.785 | p: 92.389 | r: 93.280
rouge2     | fm: 58.646 | p: 58.482 | r: 58.819
rougeL     | fm: 78.965 | p: 78.693 | r: 79.302
rougeLsum  | fm: 78.779 | p: 78.461 | r: 79.076
r1fm+r2fm = 151.431

input #59 time: 0:09:28 | total time: 9:13:27


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.9993723007306495
highest_index [0]
highest [0.9993723007306495]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9240039587020874 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9135375618934631 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8766923546791077 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8674620389938354 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8555521368980408 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 0.8470483422279358 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 0.8440579771995544 for ['[CLS] coverouringlby through strung plenty constitutionshaw majority /itude upset [SEP]']
[Init] best perm rec loss: 0.8426222205162048 for ['[CLS] plenty /lbyshawouring strung constitutionitude majority through cover upset [SEP]']
[Init] best perm rec loss: 0.8374884724617004 for ['[CLS] majority / strunglbyitude throughshaw plentyouring constitution upset cover [SEP]']
[Init] best perm rec loss: 0.8369754552841187 for ['[CLS]itude majority strung throughshaw plenty constitution coverlby upsetouring / [SEP]']
[Init] best perm rec loss: 0.8367394208908081 for ['[CLS] plentyitudelbyshaw / constitution through strung upset coverouring majority [SEP]']
[Init] best perm rec loss: 0.8362407684326172 for ['[CLS] plentylby strung upsetshaw constitution majority through coveritude /ouring [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.692 (perp=12.098, rec=0.263, cos=0.009), tot_loss_proj:3.027 [t=0.23s]
prediction: ['[CLS] awkwardly pbs labor county awkwardly shale. data : awkwardly awkwardlyi [SEP]']
[ 100/2000] tot_loss=2.514 (perp=11.642, rec=0.182, cos=0.004), tot_loss_proj:2.990 [t=0.23s]
prediction: ['[CLS] awkwardly is paced soap awkwardly story is soap is circuit awkwardly story [SEP]']
[ 150/2000] tot_loss=2.533 (perp=11.946, rec=0.141, cos=0.003), tot_loss_proj:2.945 [t=0.23s]
prediction: ['[CLS] awkwardly is paced soap awkwardly story. soap the circuit awkwardly story [SEP]']
[ 200/2000] tot_loss=2.526 (perp=11.946, rec=0.132, cos=0.004), tot_loss_proj:2.937 [t=0.23s]
prediction: ['[CLS] awkwardly is paced soap awkwardly story. soap the circuit awkwardly story [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.321 (perp=10.933, rec=0.130, cos=0.004), tot_loss_proj:2.656 [t=0.23s]
prediction: ['[CLS] awkwardly soap paced opera awkwardly story - is the circuit awkwardly story [SEP]']
[ 300/2000] tot_loss=2.192 (perp=10.399, rec=0.110, cos=0.003), tot_loss_proj:2.628 [t=0.23s]
prediction: ['[CLS] awkwardly soap paced operah soap - is the circuith story [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.946 (perp=9.264, rec=0.091, cos=0.002), tot_loss_proj:2.323 [t=0.23s]
prediction: ['[CLS] awkwardly soap paced soap operah - is the circuith story [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.868 (perp=8.845, rec=0.097, cos=0.002), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap operatish - is the soap circuith story [SEP]']
[ 450/2000] tot_loss=1.868 (perp=8.845, rec=0.097, cos=0.002), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap operatish - is the soap circuith story [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.795 (perp=8.534, rec=0.086, cos=0.002), tot_loss_proj:2.132 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera is - is the soap circuith story [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.789 (perp=8.534, rec=0.080, cos=0.002), tot_loss_proj:2.125 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera is - is the soap circuith story [SEP]']
[ 600/2000] tot_loss=1.787 (perp=8.534, rec=0.078, cos=0.002), tot_loss_proj:2.132 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera is - is the soap circuith story [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.787 (perp=8.534, rec=0.078, cos=0.002), tot_loss_proj:2.128 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera is - is the soap circuith story [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.727 (perp=8.195, rec=0.086, cos=0.002), tot_loss_proj:2.115 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera is -h is the soap circuit story [SEP]']
[ 750/2000] tot_loss=1.712 (perp=8.195, rec=0.071, cos=0.002), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera is -h is the soap circuit story [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.697 (perp=8.084, rec=0.078, cos=0.002), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.696 (perp=8.084, rec=0.077, cos=0.002), tot_loss_proj:1.982 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
[ 900/2000] tot_loss=1.695 (perp=8.084, rec=0.077, cos=0.002), tot_loss_proj:1.979 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.693 (perp=8.084, rec=0.074, cos=0.002), tot_loss_proj:1.984 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1000/2000] tot_loss=1.701 (perp=8.084, rec=0.082, cos=0.002), tot_loss_proj:1.987 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
[1050/2000] tot_loss=1.684 (perp=8.084, rec=0.066, cos=0.002), tot_loss_proj:1.981 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1100/2000] tot_loss=1.691 (perp=8.084, rec=0.072, cos=0.002), tot_loss_proj:1.979 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1150/2000] tot_loss=1.692 (perp=8.084, rec=0.074, cos=0.002), tot_loss_proj:1.986 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
[1200/2000] tot_loss=1.694 (perp=8.084, rec=0.075, cos=0.002), tot_loss_proj:1.983 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1250/2000] tot_loss=1.699 (perp=8.084, rec=0.081, cos=0.002), tot_loss_proj:1.986 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1300/2000] tot_loss=1.693 (perp=8.084, rec=0.074, cos=0.002), tot_loss_proj:1.994 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
[1350/2000] tot_loss=1.692 (perp=8.084, rec=0.073, cos=0.002), tot_loss_proj:1.984 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1400/2000] tot_loss=1.686 (perp=8.084, rec=0.067, cos=0.002), tot_loss_proj:1.993 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1450/2000] tot_loss=1.690 (perp=8.084, rec=0.071, cos=0.002), tot_loss_proj:1.992 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
[1500/2000] tot_loss=1.689 (perp=8.084, rec=0.070, cos=0.002), tot_loss_proj:1.987 [t=0.23s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1550/2000] tot_loss=1.694 (perp=8.084, rec=0.075, cos=0.002), tot_loss_proj:1.989 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1600/2000] tot_loss=1.690 (perp=8.084, rec=0.071, cos=0.002), tot_loss_proj:1.988 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
[1650/2000] tot_loss=1.696 (perp=8.084, rec=0.077, cos=0.002), tot_loss_proj:1.988 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1700/2000] tot_loss=1.690 (perp=8.084, rec=0.071, cos=0.002), tot_loss_proj:1.990 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1750/2000] tot_loss=1.696 (perp=8.084, rec=0.077, cos=0.002), tot_loss_proj:1.979 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
[1800/2000] tot_loss=1.688 (perp=8.084, rec=0.069, cos=0.002), tot_loss_proj:1.984 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1850/2000] tot_loss=1.690 (perp=8.084, rec=0.071, cos=0.002), tot_loss_proj:1.983 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[1900/2000] tot_loss=1.692 (perp=8.084, rec=0.073, cos=0.002), tot_loss_proj:1.985 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
[1950/2000] tot_loss=1.692 (perp=8.084, rec=0.073, cos=0.002), tot_loss_proj:1.986 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Attempt swap
[2000/2000] tot_loss=1.694 (perp=8.084, rec=0.075, cos=0.002), tot_loss_proj:1.981 [t=0.24s]
prediction: ['[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] awkwardly paced soap opera - ish is the soap circuit story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 57.143 | p: 54.545 | r: 60.000
rougeL     | fm: 69.565 | p: 66.667 | r: 72.727
rougeLsum  | fm: 69.565 | p: 66.667 | r: 72.727
r1fm+r2fm = 152.795

[Aggregate metrics]:
rouge1     | fm: 92.869 | p: 92.398 | r: 93.384
rouge2     | fm: 58.427 | p: 58.175 | r: 58.781
rougeL     | fm: 78.727 | p: 78.380 | r: 79.160
rougeLsum  | fm: 78.668 | p: 78.346 | r: 79.020
r1fm+r2fm = 151.296

input #60 time: 0:09:17 | total time: 9:22:44


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.9992842374425217
highest_index [0]
highest [0.9992842374425217]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9796134233474731 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9755127429962158 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9502310752868652 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9452727437019348 for ['[CLS] paths whose bar [SEP]']
[Init] best rec loss: 0.9447370767593384 for ['[CLS]mbledssi commons [SEP]']
[Init] best rec loss: 0.936389148235321 for ['[CLS] crested tend prize [SEP]']
[Init] best rec loss: 0.9159070253372192 for ['[CLS] bologna nails steps [SEP]']
[Init] best rec loss: 0.9078887104988098 for ['[CLS] you wedding velvet [SEP]']
[Init] best rec loss: 0.8797362446784973 for ['[CLS] respect thrill butterfly [SEP]']
[Init] best rec loss: 0.8326549530029297 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 0.8251567482948303 for ['[CLS] lets request mini [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.739 (perp=7.753, rec=0.179, cos=0.010), tot_loss_proj:1.811 [t=0.23s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 100/2000] tot_loss=1.699 (perp=7.753, rec=0.141, cos=0.008), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 150/2000] tot_loss=1.695 (perp=8.032, rec=0.087, cos=0.002), tot_loss_proj:1.706 [t=0.24s]
prediction: ['[CLS], beautiful scene [SEP]']
[ 200/2000] tot_loss=1.666 (perp=8.032, rec=0.058, cos=0.001), tot_loss_proj:1.697 [t=0.24s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.492 (perp=7.102, rec=0.070, cos=0.001), tot_loss_proj:1.629 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 300/2000] tot_loss=1.494 (perp=7.102, rec=0.072, cos=0.001), tot_loss_proj:1.623 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.489 (perp=7.102, rec=0.067, cos=0.001), tot_loss_proj:1.613 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.491 (perp=7.102, rec=0.070, cos=0.001), tot_loss_proj:1.623 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.499 (perp=7.102, rec=0.077, cos=0.001), tot_loss_proj:1.613 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.489 (perp=7.102, rec=0.067, cos=0.001), tot_loss_proj:1.629 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.481 (perp=7.102, rec=0.059, cos=0.001), tot_loss_proj:1.626 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.482 (perp=7.102, rec=0.060, cos=0.001), tot_loss_proj:1.628 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.483 (perp=7.102, rec=0.061, cos=0.001), tot_loss_proj:1.614 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.481 (perp=7.102, rec=0.060, cos=0.001), tot_loss_proj:1.621 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.479 (perp=7.102, rec=0.057, cos=0.001), tot_loss_proj:1.616 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.484 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.632 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.497 (perp=7.102, rec=0.075, cos=0.001), tot_loss_proj:1.611 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.495 (perp=7.102, rec=0.073, cos=0.001), tot_loss_proj:1.626 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.487 (perp=7.102, rec=0.065, cos=0.001), tot_loss_proj:1.616 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.485 (perp=7.102, rec=0.063, cos=0.001), tot_loss_proj:1.618 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.490 (perp=7.102, rec=0.068, cos=0.001), tot_loss_proj:1.622 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.483 (perp=7.102, rec=0.061, cos=0.001), tot_loss_proj:1.627 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.476 (perp=7.102, rec=0.054, cos=0.001), tot_loss_proj:1.625 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.488 (perp=7.102, rec=0.066, cos=0.001), tot_loss_proj:1.637 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.488 (perp=7.102, rec=0.067, cos=0.001), tot_loss_proj:1.615 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.468 (perp=7.102, rec=0.046, cos=0.001), tot_loss_proj:1.612 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.478 (perp=7.102, rec=0.057, cos=0.001), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.479 (perp=7.102, rec=0.057, cos=0.001), tot_loss_proj:1.627 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.484 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.621 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.484 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.635 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.488 (perp=7.102, rec=0.066, cos=0.001), tot_loss_proj:1.618 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.482 (perp=7.102, rec=0.060, cos=0.001), tot_loss_proj:1.617 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.481 (perp=7.102, rec=0.059, cos=0.001), tot_loss_proj:1.618 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.492 (perp=7.102, rec=0.071, cos=0.001), tot_loss_proj:1.621 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.484 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.618 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.481 (perp=7.102, rec=0.059, cos=0.001), tot_loss_proj:1.622 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.493 (perp=7.102, rec=0.071, cos=0.001), tot_loss_proj:1.624 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.496 (perp=7.102, rec=0.074, cos=0.001), tot_loss_proj:1.607 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.484 (perp=7.102, rec=0.063, cos=0.001), tot_loss_proj:1.636 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.486 (perp=7.102, rec=0.064, cos=0.001), tot_loss_proj:1.624 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.925 | p: 92.461 | r: 93.496
rouge2     | fm: 59.186 | p: 58.965 | r: 59.469
rougeL     | fm: 79.118 | p: 78.752 | r: 79.486
rougeLsum  | fm: 78.952 | p: 78.664 | r: 79.296
r1fm+r2fm = 152.110

input #61 time: 0:09:00 | total time: 9:31:45


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.9992552892713504
highest_index [0]
highest [0.9992552892713504]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9559537172317505 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9276927709579468 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.922580897808075 for ['[CLS] percentage trap danzinghur shapeee sacred persianlon record theater freestylegold cards dance sacks pits dreadmund existed [SEP]']
[Init] best rec loss: 0.9182294011116028 for ['[CLS] girl plain followedion recalls間 by spread fight sioux 2002 test origins humanitarian peck reed forumnce tooth closely mccarthy [SEP]']
[Init] best perm rec loss: 0.9180595874786377 for ['[CLS]間 origins closely mccarthy sioux tooth 2002 test reed by peck humanitarian girl recalls fight forumion followednce plain spread [SEP]']
[Init] best perm rec loss: 0.9156901240348816 for ['[CLS] fight mccarthy by closely tooth test recalls siouxnce spread humanitarian girl peckion 2002 followed間 reed forum origins plain [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.596 (perp=11.199, rec=0.344, cos=0.012), tot_loss_proj:3.504 [t=0.23s]
prediction: ['[CLS] strong rock8 historic program best but ; drum grace healing evolution best limit decca for an through great extreme album [SEP]']
[ 100/2000] tot_loss=2.216 (perp=9.777, rec=0.256, cos=0.005), tot_loss_proj:3.222 [t=0.24s]
prediction: ['[CLS] makingzcz to historic proposition best the prevention to grace war thought best of century for best splits movies extreme best [SEP]']
[ 150/2000] tot_loss=2.065 (perp=9.296, rec=0.202, cos=0.004), tot_loss_proj:3.539 [t=0.24s]
prediction: ['[CLS] finding trade to being proposition best the prevention to grace war thought best to making for best war movies brutally ever [SEP]']
[ 200/2000] tot_loss=2.157 (perp=9.847, rec=0.184, cos=0.004), tot_loss_proj:3.923 [t=0.24s]
prediction: ['[CLS] finding trade for a instead best ever prevention to grace war instead making to making one best war movies brutally ever [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.933 (perp=8.876, rec=0.155, cos=0.003), tot_loss_proj:3.674 [t=0.24s]
prediction: ['[CLS] to call for grace instead best ever prevention to the war call making to making one best war movies brutally ever [SEP]']
[ 300/2000] tot_loss=1.613 (perp=7.399, rec=0.131, cos=0.002), tot_loss_proj:3.274 [t=0.24s]
prediction: ['[CLS] to call for grace rather best the prevention to the war call, rather making one best war movies. ever [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.618 (perp=7.556, rec=0.106, cos=0.002), tot_loss_proj:3.284 [t=0.24s]
prediction: ['[CLS] to call for grace rather made best prevention to the war call, rather making one best war movies. ever [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.750 (perp=8.210, rec=0.106, cos=0.002), tot_loss_proj:3.580 [t=0.24s]
prediction: ['[CLS] to call for grace rather best prevention to of blame blame, rather making one best war movies blame ever made [SEP]']
[ 450/2000] tot_loss=1.742 (perp=8.210, rec=0.099, cos=0.002), tot_loss_proj:3.576 [t=0.24s]
prediction: ['[CLS] to call for grace rather best prevention to of blame blame, rather making one best war movies blame ever made [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.628 (perp=7.727, rec=0.081, cos=0.002), tot_loss_proj:3.548 [t=0.24s]
prediction: ['[CLS] to call for grace rather best prevention to of blame blame, rather blame making one best war movies ever made [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.513 (perp=7.146, rec=0.083, cos=0.002), tot_loss_proj:3.250 [t=0.24s]
prediction: ['[CLS] to call for grace rather prevention to of blame place, rather blame making one the best war movies ever made [SEP]']
[ 600/2000] tot_loss=1.518 (perp=7.146, rec=0.087, cos=0.002), tot_loss_proj:3.250 [t=0.24s]
prediction: ['[CLS] to call for grace rather prevention to of blame place, rather blame making one the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.485 (perp=7.020, rec=0.079, cos=0.002), tot_loss_proj:3.273 [t=0.24s]
prediction: ['[CLS] to call for grace rather to prevention of blame place, rather blame making one the best war movies ever made [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.463 (perp=6.866, rec=0.088, cos=0.002), tot_loss_proj:2.533 [t=0.24s]
prediction: ['[CLS] to call for grace rather to prevention of blame place, rather, making one the best war movies ever made [SEP]']
[ 750/2000] tot_loss=1.618 (perp=7.712, rec=0.073, cos=0.002), tot_loss_proj:3.351 [t=0.24s]
prediction: ['[CLS] it call for grace rather to prevention of blame place, rather place making one the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.538 (perp=7.336, rec=0.069, cos=0.002), tot_loss_proj:3.041 [t=0.24s]
prediction: ['[CLS] it call for grace rather to prevention of blame place, rather one making place the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.505 (perp=7.161, rec=0.071, cos=0.002), tot_loss_proj:3.115 [t=0.24s]
prediction: ['[CLS] it call for grace to rather prevention of blame place, rather one making place the best war movies ever made [SEP]']
[ 900/2000] tot_loss=1.511 (perp=7.161, rec=0.077, cos=0.002), tot_loss_proj:3.117 [t=0.24s]
prediction: ['[CLS] it call for grace to rather prevention of blame place, rather one making place the best war movies ever made [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.451 (perp=6.878, rec=0.074, cos=0.002), tot_loss_proj:3.073 [t=0.24s]
prediction: ['[CLS] it call for grace to rather prevention place of blame, rather one making place the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.383 (perp=6.594, rec=0.062, cos=0.002), tot_loss_proj:3.041 [t=0.24s]
prediction: ['[CLS] it call for grace to rather prevention place of blame, rather one place making the best war movies ever made [SEP]']
[1050/2000] tot_loss=1.397 (perp=6.594, rec=0.076, cos=0.002), tot_loss_proj:3.044 [t=0.24s]
prediction: ['[CLS] it call for grace to rather prevention place of blame, rather one place making the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.366 (perp=6.441, rec=0.077, cos=0.001), tot_loss_proj:3.161 [t=0.24s]
prediction: ['[CLS] grace call for it to rather prevention place of blame, rather one place making the best war movies ever made [SEP]']
Attempt swap
[1150/2000] tot_loss=1.358 (perp=6.441, rec=0.068, cos=0.002), tot_loss_proj:3.163 [t=0.24s]
prediction: ['[CLS] grace call for it to rather prevention place of blame, rather one place making the best war movies ever made [SEP]']
[1200/2000] tot_loss=1.356 (perp=6.441, rec=0.066, cos=0.001), tot_loss_proj:3.158 [t=0.24s]
prediction: ['[CLS] grace call for it to rather prevention place of blame, rather one place making the best war movies ever made [SEP]']
Attempt swap
[1250/2000] tot_loss=1.427 (perp=6.737, rec=0.078, cos=0.002), tot_loss_proj:3.201 [t=0.24s]
prediction: ['[CLS] grace call for it to than prevention place of blame, rather one place making the best war movies ever made [SEP]']
Attempt swap
[1300/2000] tot_loss=1.423 (perp=6.737, rec=0.074, cos=0.002), tot_loss_proj:3.204 [t=0.24s]
prediction: ['[CLS] grace call for it to than prevention place of blame, rather one place making the best war movies ever made [SEP]']
[1350/2000] tot_loss=1.423 (perp=6.737, rec=0.074, cos=0.002), tot_loss_proj:3.204 [t=0.24s]
prediction: ['[CLS] grace call for it to than prevention place of blame, rather one place making the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.416 (perp=6.697, rec=0.075, cos=0.002), tot_loss_proj:3.263 [t=0.24s]
prediction: ['[CLS] grace call for it to than prevention place of blame, one rather place making the best war movies ever made [SEP]']
Attempt swap
[1450/2000] tot_loss=1.416 (perp=6.697, rec=0.075, cos=0.002), tot_loss_proj:3.265 [t=0.24s]
prediction: ['[CLS] grace call for it to than prevention place of blame, one rather place making the best war movies ever made [SEP]']
[1500/2000] tot_loss=1.414 (perp=6.697, rec=0.073, cos=0.001), tot_loss_proj:3.260 [t=0.24s]
prediction: ['[CLS] grace call for it to than prevention place of blame, one rather place making the best war movies ever made [SEP]']
Attempt swap
[1550/2000] tot_loss=1.415 (perp=6.697, rec=0.074, cos=0.002), tot_loss_proj:3.263 [t=0.24s]
prediction: ['[CLS] grace call for it to than prevention place of blame, one rather place making the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.393 (perp=6.589, rec=0.074, cos=0.002), tot_loss_proj:3.230 [t=0.24s]
prediction: ['[CLS] grace call for it to prevention than place of blame, one rather place making the best war movies ever made [SEP]']
[1650/2000] tot_loss=1.391 (perp=6.589, rec=0.072, cos=0.002), tot_loss_proj:3.231 [t=0.24s]
prediction: ['[CLS] grace call for it to prevention than place of blame, one rather place making the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.342 (perp=6.403, rec=0.060, cos=0.002), tot_loss_proj:3.199 [t=0.24s]
prediction: ['[CLS] grace call to it for prevention than place of blame, one rather place making the best war movies ever made [SEP]']
Attempt swap
[1750/2000] tot_loss=1.347 (perp=6.403, rec=0.065, cos=0.002), tot_loss_proj:3.195 [t=0.24s]
prediction: ['[CLS] grace call to it for prevention than place of blame, one rather place making the best war movies ever made [SEP]']
[1800/2000] tot_loss=1.355 (perp=6.403, rec=0.073, cos=0.002), tot_loss_proj:3.198 [t=0.24s]
prediction: ['[CLS] grace call to it for prevention than place of blame, one rather place making the best war movies ever made [SEP]']
Attempt swap
[1850/2000] tot_loss=1.342 (perp=6.403, rec=0.060, cos=0.002), tot_loss_proj:3.197 [t=0.24s]
prediction: ['[CLS] grace call to it for prevention than place of blame, one rather place making the best war movies ever made [SEP]']
Attempt swap
[1900/2000] tot_loss=1.357 (perp=6.403, rec=0.075, cos=0.002), tot_loss_proj:3.199 [t=0.24s]
prediction: ['[CLS] grace call to it for prevention than place of blame, one rather place making the best war movies ever made [SEP]']
[1950/2000] tot_loss=1.356 (perp=6.403, rec=0.074, cos=0.002), tot_loss_proj:3.195 [t=0.24s]
prediction: ['[CLS] grace call to it for prevention than place of blame, one rather place making the best war movies ever made [SEP]']
Attempt swap
[2000/2000] tot_loss=1.351 (perp=6.403, rec=0.069, cos=0.002), tot_loss_proj:3.192 [t=0.24s]
prediction: ['[CLS] grace call to it for prevention than place of blame, one rather place making the best war movies ever made [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] grace call to it for prevention than place of blame, one rather place making the best war movies ever made [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.455 | p: 95.455 | r: 95.455
rouge2     | fm: 38.095 | p: 38.095 | r: 38.095
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 133.550

[Aggregate metrics]:
rouge1     | fm: 92.984 | p: 92.538 | r: 93.527
rouge2     | fm: 58.709 | p: 58.470 | r: 58.981
rougeL     | fm: 79.114 | p: 78.794 | r: 79.489
rougeLsum  | fm: 78.808 | p: 78.494 | r: 79.276
r1fm+r2fm = 151.692

input #62 time: 0:09:27 | total time: 9:41:12


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9992638993081941
highest_index [0]
highest [0.9992638993081941]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.9526534080505371 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.8990910053253174 for ['[CLS] touch alternative glacier bentry [SEP]']
[Init] best rec loss: 0.7447170615196228 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7446317672729492 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 0.7400466203689575 for ['[CLS] diploma catalogue honors knee skirt [SEP]']
[Init] best rec loss: 0.7324649691581726 for ['[CLS] forces solutions... offense civil [SEP]']
[Init] best perm rec loss: 0.727935254573822 for ['[CLS] forces offense civil... solutions [SEP]']
[Init] best perm rec loss: 0.7276415228843689 for ['[CLS] forces solutions offense... civil [SEP]']
[Init] best perm rec loss: 0.727533221244812 for ['[CLS]... solutions civil offense forces [SEP]']
[Init] best perm rec loss: 0.7274791598320007 for ['[CLS] solutions... offense civil forces [SEP]']
[Init] best perm rec loss: 0.7251647710800171 for ['[CLS] offense... solutions civil forces [SEP]']
[Init] best perm rec loss: 0.7243860960006714 for ['[CLS] forces offense... solutions civil [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.436 (perp=10.666, rec=0.268, cos=0.035), tot_loss_proj:3.135 [t=0.23s]
prediction: ['[CLS]gned face us return ticket [SEP]']
[ 100/2000] tot_loss=2.285 (perp=10.837, rec=0.112, cos=0.006), tot_loss_proj:2.837 [t=0.24s]
prediction: ['[CLS] for for looking return ticket [SEP]']
[ 150/2000] tot_loss=2.266 (perp=10.837, rec=0.094, cos=0.004), tot_loss_proj:2.847 [t=0.24s]
prediction: ['[CLS] for for looking return ticket [SEP]']
[ 200/2000] tot_loss=2.254 (perp=10.837, rec=0.083, cos=0.004), tot_loss_proj:2.840 [t=0.24s]
prediction: ['[CLS] for for looking return ticket [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.759 (perp=8.384, rec=0.079, cos=0.003), tot_loss_proj:2.237 [t=0.24s]
prediction: ['[CLS] for looking for return ticket [SEP]']
[ 300/2000] tot_loss=1.758 (perp=8.384, rec=0.079, cos=0.003), tot_loss_proj:2.233 [t=0.24s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.307 (perp=6.111, rec=0.083, cos=0.002), tot_loss_proj:1.314 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.293 (perp=6.111, rec=0.069, cos=0.001), tot_loss_proj:1.318 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 450/2000] tot_loss=1.292 (perp=6.111, rec=0.069, cos=0.001), tot_loss_proj:1.313 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.279 (perp=6.111, rec=0.056, cos=0.001), tot_loss_proj:1.311 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.292 (perp=6.111, rec=0.068, cos=0.001), tot_loss_proj:1.316 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 600/2000] tot_loss=1.279 (perp=6.111, rec=0.055, cos=0.001), tot_loss_proj:1.325 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.280 (perp=6.111, rec=0.057, cos=0.001), tot_loss_proj:1.317 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.297 (perp=6.111, rec=0.073, cos=0.001), tot_loss_proj:1.321 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 750/2000] tot_loss=1.281 (perp=6.111, rec=0.057, cos=0.001), tot_loss_proj:1.313 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.296 (perp=6.111, rec=0.072, cos=0.001), tot_loss_proj:1.323 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.285 (perp=6.111, rec=0.062, cos=0.001), tot_loss_proj:1.300 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 900/2000] tot_loss=1.287 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.325 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.285 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.309 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.287 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.317 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1050/2000] tot_loss=1.284 (perp=6.111, rec=0.060, cos=0.001), tot_loss_proj:1.310 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.292 (perp=6.111, rec=0.068, cos=0.001), tot_loss_proj:1.313 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.277 (perp=6.111, rec=0.053, cos=0.001), tot_loss_proj:1.319 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1200/2000] tot_loss=1.283 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.312 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.285 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.308 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.292 (perp=6.111, rec=0.068, cos=0.001), tot_loss_proj:1.313 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.286 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.317 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.284 (perp=6.111, rec=0.060, cos=0.001), tot_loss_proj:1.314 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.289 (perp=6.111, rec=0.065, cos=0.001), tot_loss_proj:1.319 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.292 (perp=6.111, rec=0.068, cos=0.001), tot_loss_proj:1.320 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.285 (perp=6.111, rec=0.062, cos=0.001), tot_loss_proj:1.319 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.001), tot_loss_proj:1.315 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.275 (perp=6.111, rec=0.051, cos=0.001), tot_loss_proj:1.312 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.282 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.300 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.282 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.321 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.321 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.001), tot_loss_proj:1.311 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.277 (perp=6.111, rec=0.053, cos=0.001), tot_loss_proj:1.318 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.288 (perp=6.111, rec=0.065, cos=0.001), tot_loss_proj:1.322 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.284 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.317 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.087 | p: 92.617 | r: 93.593
rouge2     | fm: 59.494 | p: 59.301 | r: 59.809
rougeL     | fm: 79.312 | p: 78.991 | r: 79.697
rougeLsum  | fm: 79.136 | p: 78.840 | r: 79.535
r1fm+r2fm = 152.581

input #63 time: 0:09:18 | total time: 9:50:30


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.9991605989689818
highest_index [0]
highest [0.9991605989689818]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8780370354652405 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.865992546081543 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 0.7271021604537964 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6768224239349365 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.67481529712677 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 0.6732637882232666 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.962 (perp=8.653, rec=0.197, cos=0.034), tot_loss_proj:2.055 [t=0.22s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=1.901 (perp=8.653, rec=0.151, cos=0.019), tot_loss_proj:2.055 [t=0.22s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.871 (perp=8.653, rec=0.128, cos=0.013), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=1.863 (perp=8.653, rec=0.124, cos=0.009), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.701 (perp=8.065, rec=0.083, cos=0.005), tot_loss_proj:1.708 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 300/2000] tot_loss=1.687 (perp=8.065, rec=0.072, cos=0.002), tot_loss_proj:1.701 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.670 (perp=8.065, rec=0.055, cos=0.002), tot_loss_proj:1.704 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.670 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.682 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.716 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.673 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.711 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.712 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.669 (perp=8.065, rec=0.054, cos=0.002), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.706 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.656 (perp=8.065, rec=0.042, cos=0.002), tot_loss_proj:1.708 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.711 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.679 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.715 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.671 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.720 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.715 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.663 (perp=8.065, rec=0.048, cos=0.002), tot_loss_proj:1.708 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.719 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.674 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.712 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.690 (perp=8.065, rec=0.075, cos=0.002), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.697 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.676 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.709 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.673 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.702 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.699 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.670 (perp=8.065, rec=0.055, cos=0.002), tot_loss_proj:1.699 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.670 (perp=8.065, rec=0.055, cos=0.002), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.685 (perp=8.065, rec=0.070, cos=0.002), tot_loss_proj:1.709 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.688 (perp=8.065, rec=0.073, cos=0.002), tot_loss_proj:1.714 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.665 (perp=8.065, rec=0.051, cos=0.002), tot_loss_proj:1.706 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.689 (perp=8.065, rec=0.074, cos=0.002), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.670 (perp=8.065, rec=0.055, cos=0.002), tot_loss_proj:1.699 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.668 (perp=8.065, rec=0.054, cos=0.002), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.674 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.702 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.206 | p: 92.784 | r: 93.724
rouge2     | fm: 60.012 | p: 59.879 | r: 60.284
rougeL     | fm: 79.694 | p: 79.396 | r: 80.074
rougeLsum  | fm: 79.658 | p: 79.377 | r: 80.120
r1fm+r2fm = 153.218

input #64 time: 0:08:41 | total time: 9:59:12


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9992253462692213
highest_index [0]
highest [0.9992253462692213]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.025086522102356 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9568408727645874 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.9551860094070435 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.9448243975639343 for ['[CLS]blpf bce med stride plot skip honest what [SEP]']
[Init] best rec loss: 0.8855191469192505 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8788135051727295 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.8770949840545654 for ['[CLS]mament even news general fun pu overshoff someday [SEP]']
[Init] best perm rec loss: 0.8740336894989014 for ['[CLS] even someday oversmament general pu funhoff news [SEP]']
[Init] best perm rec loss: 0.8733600378036499 for ['[CLS] news pu general evenmamenthoff someday fun overs [SEP]']
[Init] best perm rec loss: 0.8727949261665344 for ['[CLS] general newsmament someday overs fun puhoff even [SEP]']
[Init] best perm rec loss: 0.8721603155136108 for ['[CLS] general news someday pu even overshoff funmament [SEP]']
[Init] best perm rec loss: 0.8717846274375916 for ['[CLS] general pu even news someday overshoff funmament [SEP]']
[Init] best perm rec loss: 0.8717253804206848 for ['[CLS] general someday even news fun overs puhoffmament [SEP]']
[Init] best perm rec loss: 0.8714078068733215 for ['[CLS] someday generalhoff even oversmament pu news fun [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.252 (perp=9.802, rec=0.282, cos=0.010), tot_loss_proj:2.452 [t=0.23s]
prediction: ['[CLS]! joy joyousy joy film film joy [SEP]']
[ 100/2000] tot_loss=2.244 (perp=10.424, rec=0.155, cos=0.004), tot_loss_proj:2.569 [t=0.23s]
prediction: ['[CLS], joy joyousous rom film film joy [SEP]']
[ 150/2000] tot_loss=1.791 (perp=8.425, rec=0.104, cos=0.002), tot_loss_proj:2.557 [t=0.23s]
prediction: ['[CLS], rom joyousous romp. film [SEP]']
[ 200/2000] tot_loss=1.788 (perp=8.425, rec=0.101, cos=0.002), tot_loss_proj:2.560 [t=0.24s]
prediction: ['[CLS], rom joyousous romp. film [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.566 (perp=7.346, rec=0.095, cos=0.002), tot_loss_proj:2.285 [t=0.23s]
prediction: ['[CLS], rom joyousous romp film. [SEP]']
[ 300/2000] tot_loss=1.554 (perp=7.346, rec=0.083, cos=0.002), tot_loss_proj:2.286 [t=0.23s]
prediction: ['[CLS], rom joyousous romp film. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.487 (perp=7.018, rec=0.082, cos=0.002), tot_loss_proj:1.764 [t=0.23s]
prediction: ['[CLS], joyous romous romp film. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.452 (perp=6.723, rec=0.105, cos=0.002), tot_loss_proj:1.810 [t=0.23s]
prediction: ['[CLS]ousp, joyous romp film. [SEP]']
[ 450/2000] tot_loss=1.543 (perp=7.267, rec=0.088, cos=0.002), tot_loss_proj:2.086 [t=0.23s]
prediction: ['[CLS]ousp, joyous rom of film. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.468 (perp=6.972, rec=0.072, cos=0.002), tot_loss_proj:1.930 [t=0.23s]
prediction: ['[CLS] romp, joyousous of film. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.385 (perp=6.516, rec=0.080, cos=0.002), tot_loss_proj:1.694 [t=0.23s]
prediction: ['[CLS]ous romp, joyous of film. [SEP]']
[ 600/2000] tot_loss=1.380 (perp=6.516, rec=0.075, cos=0.002), tot_loss_proj:1.691 [t=0.23s]
prediction: ['[CLS]ous romp, joyous of film. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.262 (perp=5.949, rec=0.071, cos=0.002), tot_loss_proj:1.559 [t=0.23s]
prediction: ['[CLS] joyous romp, a of film. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.163 (perp=5.446, rec=0.072, cos=0.002), tot_loss_proj:1.414 [t=0.23s]
prediction: ['[CLS] joyous romp of, a film. [SEP]']
[ 750/2000] tot_loss=1.153 (perp=5.446, rec=0.062, cos=0.002), tot_loss_proj:1.399 [t=0.23s]
prediction: ['[CLS] joyous romp of, a film. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.094 (perp=5.097, rec=0.073, cos=0.002), tot_loss_proj:1.301 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.095 (perp=5.097, rec=0.074, cos=0.002), tot_loss_proj:1.300 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[ 900/2000] tot_loss=1.104 (perp=5.097, rec=0.083, cos=0.002), tot_loss_proj:1.299 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.083 (perp=5.097, rec=0.063, cos=0.002), tot_loss_proj:1.305 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.098 (perp=5.097, rec=0.078, cos=0.002), tot_loss_proj:1.308 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1050/2000] tot_loss=1.094 (perp=5.097, rec=0.073, cos=0.002), tot_loss_proj:1.297 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.081 (perp=5.097, rec=0.060, cos=0.002), tot_loss_proj:1.306 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.097 (perp=5.097, rec=0.076, cos=0.002), tot_loss_proj:1.305 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1200/2000] tot_loss=1.078 (perp=5.097, rec=0.057, cos=0.002), tot_loss_proj:1.309 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.089 (perp=5.097, rec=0.068, cos=0.002), tot_loss_proj:1.310 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.098 (perp=5.097, rec=0.077, cos=0.002), tot_loss_proj:1.296 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1350/2000] tot_loss=1.089 (perp=5.097, rec=0.068, cos=0.002), tot_loss_proj:1.302 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.082 (perp=5.097, rec=0.061, cos=0.002), tot_loss_proj:1.312 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.087 (perp=5.097, rec=0.066, cos=0.002), tot_loss_proj:1.300 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1500/2000] tot_loss=1.099 (perp=5.097, rec=0.078, cos=0.002), tot_loss_proj:1.299 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.087 (perp=5.097, rec=0.066, cos=0.002), tot_loss_proj:1.296 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.079 (perp=5.097, rec=0.058, cos=0.002), tot_loss_proj:1.311 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1650/2000] tot_loss=1.080 (perp=5.097, rec=0.059, cos=0.002), tot_loss_proj:1.301 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.081 (perp=5.097, rec=0.060, cos=0.002), tot_loss_proj:1.304 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.085 (perp=5.097, rec=0.065, cos=0.002), tot_loss_proj:1.302 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1800/2000] tot_loss=1.086 (perp=5.097, rec=0.066, cos=0.002), tot_loss_proj:1.301 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.089 (perp=5.097, rec=0.068, cos=0.002), tot_loss_proj:1.300 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.074 (perp=5.097, rec=0.053, cos=0.002), tot_loss_proj:1.300 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1950/2000] tot_loss=1.078 (perp=5.097, rec=0.057, cos=0.002), tot_loss_proj:1.309 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.076 (perp=5.097, rec=0.055, cos=0.002), tot_loss_proj:1.308 [t=0.23s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] joyous romp, of a film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.343 | p: 92.920 | r: 93.815
rouge2     | fm: 60.701 | p: 60.490 | r: 60.899
rougeL     | fm: 79.951 | p: 79.703 | r: 80.299
rougeLsum  | fm: 79.860 | p: 79.560 | r: 80.249
r1fm+r2fm = 154.044

input #65 time: 0:09:12 | total time: 10:08:24


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9992334111460102
highest_index [0]
highest [0.9992334111460102]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.9737173318862915 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.9308234453201294 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.9202260971069336 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8853452801704407 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.868087112903595 for ['[CLS]beersa bryce two [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.291 (perp=9.831, rec=0.306, cos=0.018), tot_loss_proj:3.058 [t=0.23s]
prediction: ['[CLS] fans ethnic tolkien fans [SEP]']
[ 100/2000] tot_loss=1.953 (perp=9.355, rec=0.080, cos=0.002), tot_loss_proj:2.028 [t=0.23s]
prediction: ['[CLS] longtime a tolkien fan [SEP]']
[ 150/2000] tot_loss=1.944 (perp=9.355, rec=0.072, cos=0.002), tot_loss_proj:2.027 [t=0.23s]
prediction: ['[CLS] longtime a tolkien fan [SEP]']
[ 200/2000] tot_loss=1.930 (perp=9.355, rec=0.057, cos=0.002), tot_loss_proj:2.023 [t=0.23s]
prediction: ['[CLS] longtime a tolkien fan [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.601 (perp=7.672, rec=0.065, cos=0.002), tot_loss_proj:1.596 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.600 (perp=7.672, rec=0.064, cos=0.002), tot_loss_proj:1.598 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.596 (perp=7.672, rec=0.060, cos=0.002), tot_loss_proj:1.605 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.599 (perp=7.672, rec=0.063, cos=0.002), tot_loss_proj:1.616 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.606 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.611 (perp=7.672, rec=0.075, cos=0.002), tot_loss_proj:1.604 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.605 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.598 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.598 (perp=7.672, rec=0.062, cos=0.002), tot_loss_proj:1.596 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.609 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.599 (perp=7.672, rec=0.063, cos=0.002), tot_loss_proj:1.593 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.594 (perp=7.672, rec=0.058, cos=0.002), tot_loss_proj:1.590 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.602 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.596 (perp=7.672, rec=0.060, cos=0.002), tot_loss_proj:1.605 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.599 (perp=7.672, rec=0.063, cos=0.002), tot_loss_proj:1.586 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.585 (perp=7.672, rec=0.049, cos=0.002), tot_loss_proj:1.600 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.585 (perp=7.672, rec=0.049, cos=0.002), tot_loss_proj:1.599 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.593 (perp=7.672, rec=0.057, cos=0.002), tot_loss_proj:1.602 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.594 (perp=7.672, rec=0.058, cos=0.002), tot_loss_proj:1.615 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.593 (perp=7.672, rec=0.057, cos=0.002), tot_loss_proj:1.613 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.600 (perp=7.672, rec=0.064, cos=0.002), tot_loss_proj:1.602 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.587 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.587 (perp=7.672, rec=0.051, cos=0.002), tot_loss_proj:1.612 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.602 (perp=7.672, rec=0.066, cos=0.002), tot_loss_proj:1.597 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.586 (perp=7.672, rec=0.050, cos=0.002), tot_loss_proj:1.606 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.580 (perp=7.672, rec=0.044, cos=0.002), tot_loss_proj:1.597 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.601 (perp=7.672, rec=0.065, cos=0.002), tot_loss_proj:1.599 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.582 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.613 (perp=7.672, rec=0.077, cos=0.002), tot_loss_proj:1.605 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.598 (perp=7.672, rec=0.062, cos=0.002), tot_loss_proj:1.614 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.598 (perp=7.672, rec=0.062, cos=0.002), tot_loss_proj:1.603 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.598 (perp=7.672, rec=0.062, cos=0.002), tot_loss_proj:1.610 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.590 (perp=7.672, rec=0.054, cos=0.002), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.591 (perp=7.672, rec=0.055, cos=0.002), tot_loss_proj:1.589 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.384 | p: 92.980 | r: 93.927
rouge2     | fm: 61.117 | p: 60.943 | r: 61.328
rougeL     | fm: 80.318 | p: 80.004 | r: 80.604
rougeLsum  | fm: 80.350 | p: 80.055 | r: 80.706
r1fm+r2fm = 154.501

input #66 time: 0:09:17 | total time: 10:17:42


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.9992930121177666
highest_index [0]
highest [0.9992930121177666]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.005165934562683 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9613745808601379 for ['[CLS] clear winnie cloudsc ling commercialiny royal classic [UNK] [SEP]']
[Init] best rec loss: 0.9571365714073181 for ['[CLS] repeat well rv strikes combined leaned written itself welsh bunch [SEP]']
[Init] best rec loss: 0.9488541483879089 for ['[CLS] position citationliga carriage demands source administered leancode pope [SEP]']
[Init] best rec loss: 0.9410316348075867 for ['[CLS] contributions. cars tied sir if - stalk alexis hilton [SEP]']
[Init] best rec loss: 0.9324914216995239 for ['[CLS] investment parker mostly radical national snow nearly baltimore contact are [SEP]']
[Init] best rec loss: 0.9314884543418884 for ['[CLS]ible ultimately season mainly swifthood abby source price need [SEP]']
[Init] best rec loss: 0.930374264717102 for ['[CLS] wild tribes upon cone home enough promotion mural courtney ） [SEP]']
[Init] best perm rec loss: 0.929959774017334 for ['[CLS] cone upon promotion ） courtney enough mural tribes wild home [SEP]']
[Init] best perm rec loss: 0.9298282265663147 for ['[CLS] mural tribes promotion wild cone ） courtney home enough upon [SEP]']
[Init] best perm rec loss: 0.927698016166687 for ['[CLS] home cone wild enough tribes ） courtney upon mural promotion [SEP]']
[Init] best perm rec loss: 0.9275584816932678 for ['[CLS] promotion ） wild courtney cone mural home tribes upon enough [SEP]']
[Init] best perm rec loss: 0.9234167337417603 for ['[CLS] ） cone home mural wild upon courtney promotion enough tribes [SEP]']
[Init] best perm rec loss: 0.923023521900177 for ['[CLS] upon tribes home cone promotion ） enough wild courtney mural [SEP]']
[Init] best perm rec loss: 0.921942949295044 for ['[CLS] upon promotion wild home cone tribes mural ） enough courtney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.693 (perp=12.203, rec=0.242, cos=0.010), tot_loss_proj:3.210 [t=0.23s]
prediction: ['[CLS] heartming ) kind nonguidetute historicalental kind [SEP]']
[ 100/2000] tot_loss=2.089 (perp=9.682, rec=0.150, cos=0.003), tot_loss_proj:2.567 [t=0.23s]
prediction: ['[CLS] heartwar, kind non -gmentalental kind [SEP]']
[ 150/2000] tot_loss=2.255 (perp=10.840, rec=0.085, cos=0.002), tot_loss_proj:2.937 [t=0.23s]
prediction: ['[CLS] heartwar,ming non -gmentalental kind [SEP]']
[ 200/2000] tot_loss=2.364 (perp=11.385, rec=0.086, cos=0.002), tot_loss_proj:3.115 [t=0.23s]
prediction: ['[CLS] heartwar,ming nondgmjuental kind [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.705 (perp=8.173, rec=0.069, cos=0.001), tot_loss_proj:2.270 [t=0.23s]
prediction: ['[CLS] heartwar,ming nonjudgmental kind [SEP]']
[ 300/2000] tot_loss=1.699 (perp=8.173, rec=0.063, cos=0.001), tot_loss_proj:2.267 [t=0.23s]
prediction: ['[CLS] heartwar,ming nonjudgmental kind [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.185 (perp=5.648, rec=0.054, cos=0.002), tot_loss_proj:1.204 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.197 (perp=5.648, rec=0.066, cos=0.001), tot_loss_proj:1.206 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[ 450/2000] tot_loss=1.191 (perp=5.648, rec=0.061, cos=0.001), tot_loss_proj:1.199 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.192 (perp=5.648, rec=0.061, cos=0.001), tot_loss_proj:1.192 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.179 (perp=5.648, rec=0.048, cos=0.001), tot_loss_proj:1.206 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[ 600/2000] tot_loss=1.202 (perp=5.648, rec=0.071, cos=0.001), tot_loss_proj:1.201 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.185 (perp=5.648, rec=0.055, cos=0.001), tot_loss_proj:1.194 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.198 (perp=5.648, rec=0.067, cos=0.001), tot_loss_proj:1.195 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[ 750/2000] tot_loss=1.190 (perp=5.648, rec=0.059, cos=0.001), tot_loss_proj:1.191 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.189 (perp=5.648, rec=0.058, cos=0.001), tot_loss_proj:1.201 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.194 (perp=5.648, rec=0.063, cos=0.001), tot_loss_proj:1.195 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[ 900/2000] tot_loss=1.197 (perp=5.648, rec=0.066, cos=0.001), tot_loss_proj:1.198 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.200 (perp=5.648, rec=0.069, cos=0.001), tot_loss_proj:1.190 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1000/2000] tot_loss=1.197 (perp=5.648, rec=0.066, cos=0.001), tot_loss_proj:1.191 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1050/2000] tot_loss=1.191 (perp=5.648, rec=0.060, cos=0.001), tot_loss_proj:1.194 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1100/2000] tot_loss=1.192 (perp=5.648, rec=0.061, cos=0.001), tot_loss_proj:1.204 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1150/2000] tot_loss=1.180 (perp=5.648, rec=0.049, cos=0.001), tot_loss_proj:1.204 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1200/2000] tot_loss=1.193 (perp=5.648, rec=0.062, cos=0.001), tot_loss_proj:1.187 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1250/2000] tot_loss=1.195 (perp=5.648, rec=0.065, cos=0.001), tot_loss_proj:1.204 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1300/2000] tot_loss=1.184 (perp=5.648, rec=0.053, cos=0.001), tot_loss_proj:1.197 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1350/2000] tot_loss=1.197 (perp=5.648, rec=0.066, cos=0.001), tot_loss_proj:1.189 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1400/2000] tot_loss=1.190 (perp=5.648, rec=0.059, cos=0.001), tot_loss_proj:1.192 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1450/2000] tot_loss=1.183 (perp=5.648, rec=0.052, cos=0.001), tot_loss_proj:1.194 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1500/2000] tot_loss=1.189 (perp=5.648, rec=0.058, cos=0.001), tot_loss_proj:1.192 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1550/2000] tot_loss=1.190 (perp=5.648, rec=0.059, cos=0.001), tot_loss_proj:1.191 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1600/2000] tot_loss=1.198 (perp=5.648, rec=0.068, cos=0.001), tot_loss_proj:1.187 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1650/2000] tot_loss=1.184 (perp=5.648, rec=0.054, cos=0.001), tot_loss_proj:1.199 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1700/2000] tot_loss=1.182 (perp=5.648, rec=0.051, cos=0.001), tot_loss_proj:1.201 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1750/2000] tot_loss=1.185 (perp=5.648, rec=0.054, cos=0.001), tot_loss_proj:1.184 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1800/2000] tot_loss=1.187 (perp=5.648, rec=0.056, cos=0.001), tot_loss_proj:1.195 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1850/2000] tot_loss=1.180 (perp=5.648, rec=0.049, cos=0.001), tot_loss_proj:1.190 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1900/2000] tot_loss=1.187 (perp=5.648, rec=0.056, cos=0.001), tot_loss_proj:1.204 [t=0.23s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1950/2000] tot_loss=1.191 (perp=5.648, rec=0.060, cos=0.001), tot_loss_proj:1.199 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[2000/2000] tot_loss=1.193 (perp=5.648, rec=0.062, cos=0.001), tot_loss_proj:1.193 [t=0.24s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.490 | p: 93.086 | r: 93.999
rouge2     | fm: 61.844 | p: 61.596 | r: 62.081
rougeL     | fm: 80.658 | p: 80.362 | r: 80.945
rougeLsum  | fm: 80.497 | p: 80.146 | r: 80.915
r1fm+r2fm = 155.335

input #67 time: 0:09:17 | total time: 10:26:59


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9992788464941955
highest_index [0]
highest [0.9992788464941955]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9892685413360596 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9690264463424683 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 0.9392844438552856 for ['[CLS] raise describedwehrwork witch rom can bray fictional elton here sex pilots [SEP]']
[Init] best rec loss: 0.9260305762290955 for ['[CLS] neutron acrosswas 2005 security tip fa— identity david entitled readers letters [SEP]']
[Init] best rec loss: 0.8682870864868164 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8625865578651428 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8616510033607483 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.8608852028846741 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.8606603145599365 for ['[CLS]iferous form medal comfort councils possibly diedyn riding floor. view beth [SEP]']
[Init] best perm rec loss: 0.8585078120231628 for ['[CLS]yn view beth form. comfort riding medal died councils flooriferous possibly [SEP]']
[Init] best perm rec loss: 0.8575673699378967 for ['[CLS] riding possibly died bethyn medal. comfortiferous form view councils floor [SEP]']
[Init] best perm rec loss: 0.8523683547973633 for ['[CLS] medal comfort riding. councils beth died formyniferous floor view possibly [SEP]']
[Init] best perm rec loss: 0.8509644269943237 for ['[CLS]iferous died beth. ridingyn form councils medal possibly floor view comfort [SEP]']
[Init] best perm rec loss: 0.8499634861946106 for ['[CLS] died comfort beth riding councils possibly. medalyn floor form viewiferous [SEP]']
[Init] best perm rec loss: 0.8496124148368835 for ['[CLS] viewiferous comfort councils form beth possibly died medalyn floor riding. [SEP]']
[Init] best perm rec loss: 0.8491353988647461 for ['[CLS]yn councils possibly formiferous beth medal floor. riding comfort view died [SEP]']
[Init] best perm rec loss: 0.8445032835006714 for ['[CLS]yn. comfort diediferous possibly form councils beth floor medal view riding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.311 (perp=10.645, rec=0.176, cos=0.006), tot_loss_proj:2.641 [t=0.22s]
prediction: ['[CLS]ulously absurdsibleice, unexsible absurd vicious absurd absurd ( [SEP]']
[ 100/2000] tot_loss=2.345 (perp=11.148, rec=0.113, cos=0.002), tot_loss_proj:2.848 [t=0.22s]
prediction: ['[CLS]ulouslycouth (, unompsiblesible vicious un absurd and [SEP]']
[ 150/2000] tot_loss=1.939 (perp=9.265, rec=0.084, cos=0.002), tot_loss_proj:2.219 [t=0.22s]
prediction: ['[CLS] extremelycouth,, unhensiblesible vicious vicious absurd and [SEP]']
[ 200/2000] tot_loss=2.118 (perp=10.204, rec=0.075, cos=0.002), tot_loss_proj:2.403 [t=0.22s]
prediction: ['[CLS]ompcouth,, unhensibleomp vicious vicious absurd and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.835 (perp=8.733, rec=0.087, cos=0.002), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS]ompcouth absurd, unhensibleomp vicious vicious, and [SEP]']
[ 300/2000] tot_loss=1.844 (perp=8.850, rec=0.072, cos=0.002), tot_loss_proj:2.147 [t=0.22s]
prediction: ['[CLS]ompcouth absurd, unhensiblere vicious vicious, and [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.607 (perp=7.675, rec=0.071, cos=0.001), tot_loss_proj:1.897 [t=0.22s]
prediction: ['[CLS]ompcouth absurd, unrehensible vicious vicious, and [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.696 (perp=7.799, rec=0.133, cos=0.003), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS]ompcouth inc absurd, unrehensible vicious, and [SEP]']
[ 450/2000] tot_loss=1.648 (perp=7.799, rec=0.087, cos=0.002), tot_loss_proj:2.003 [t=0.22s]
prediction: ['[CLS]ompcouth inc absurd, unrehensible vicious, and [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.306 (perp=6.155, rec=0.074, cos=0.002), tot_loss_proj:1.658 [t=0.22s]
prediction: ['[CLS] uncouth inc absurd,omprehensible vicious, and [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.188 (perp=5.594, rec=0.068, cos=0.002), tot_loss_proj:1.402 [t=0.22s]
prediction: ['[CLS] uncouth inc,omprehensible vicious, and absurd [SEP]']
[ 600/2000] tot_loss=1.194 (perp=5.594, rec=0.074, cos=0.001), tot_loss_proj:1.401 [t=0.22s]
prediction: ['[CLS] uncouth inc,omprehensible vicious, and absurd [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.097 (perp=5.106, rec=0.074, cos=0.001), tot_loss_proj:1.228 [t=0.22s]
prediction: ['[CLS] uncouth, incomprehensible vicious, and absurd [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=0.972 (perp=4.495, rec=0.072, cos=0.001), tot_loss_proj:0.992 [t=0.22s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[ 750/2000] tot_loss=0.966 (perp=4.495, rec=0.066, cos=0.001), tot_loss_proj:0.985 [t=0.22s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.966 (perp=4.495, rec=0.065, cos=0.001), tot_loss_proj:0.981 [t=0.22s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.955 (perp=4.495, rec=0.054, cos=0.001), tot_loss_proj:0.975 [t=0.22s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[ 900/2000] tot_loss=0.967 (perp=4.495, rec=0.067, cos=0.001), tot_loss_proj:0.986 [t=0.22s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.965 (perp=4.495, rec=0.065, cos=0.001), tot_loss_proj:0.982 [t=0.22s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1000/2000] tot_loss=0.960 (perp=4.495, rec=0.060, cos=0.001), tot_loss_proj:0.983 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1050/2000] tot_loss=0.960 (perp=4.495, rec=0.059, cos=0.001), tot_loss_proj:0.979 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1100/2000] tot_loss=0.973 (perp=4.495, rec=0.073, cos=0.001), tot_loss_proj:0.981 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1150/2000] tot_loss=0.955 (perp=4.495, rec=0.054, cos=0.001), tot_loss_proj:0.972 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1200/2000] tot_loss=0.957 (perp=4.495, rec=0.056, cos=0.001), tot_loss_proj:0.983 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1250/2000] tot_loss=0.963 (perp=4.495, rec=0.063, cos=0.001), tot_loss_proj:0.979 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1300/2000] tot_loss=0.951 (perp=4.495, rec=0.051, cos=0.001), tot_loss_proj:0.981 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1350/2000] tot_loss=0.957 (perp=4.495, rec=0.057, cos=0.001), tot_loss_proj:0.979 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1400/2000] tot_loss=0.958 (perp=4.495, rec=0.057, cos=0.001), tot_loss_proj:0.976 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1450/2000] tot_loss=0.958 (perp=4.495, rec=0.058, cos=0.001), tot_loss_proj:0.977 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1500/2000] tot_loss=0.969 (perp=4.495, rec=0.069, cos=0.001), tot_loss_proj:0.986 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1550/2000] tot_loss=0.963 (perp=4.495, rec=0.063, cos=0.001), tot_loss_proj:0.980 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1600/2000] tot_loss=0.959 (perp=4.495, rec=0.059, cos=0.001), tot_loss_proj:0.978 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1650/2000] tot_loss=0.953 (perp=4.495, rec=0.053, cos=0.001), tot_loss_proj:0.977 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=0.963 (perp=4.495, rec=0.062, cos=0.001), tot_loss_proj:0.981 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=0.964 (perp=4.495, rec=0.064, cos=0.001), tot_loss_proj:0.983 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1800/2000] tot_loss=0.966 (perp=4.495, rec=0.066, cos=0.001), tot_loss_proj:0.979 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=0.968 (perp=4.495, rec=0.068, cos=0.001), tot_loss_proj:0.984 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=0.971 (perp=4.495, rec=0.071, cos=0.001), tot_loss_proj:0.970 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1950/2000] tot_loss=0.952 (perp=4.495, rec=0.052, cos=0.001), tot_loss_proj:0.966 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=0.966 (perp=4.495, rec=0.066, cos=0.001), tot_loss_proj:0.968 [t=0.24s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.626 | p: 93.194 | r: 94.118
rouge2     | fm: 62.401 | p: 62.199 | r: 62.637
rougeL     | fm: 80.820 | p: 80.563 | r: 81.132
rougeLsum  | fm: 80.757 | p: 80.462 | r: 81.114
r1fm+r2fm = 156.027

input #68 time: 0:09:03 | total time: 10:36:03


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.9992906888884341
highest_index [0]
highest [0.9992906888884341]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.0882316827774048 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.945919394493103 for ['[CLS] cade atoms especially suddenly schneider commanded noble retirement causescap meant grin immortals fai act paternal [SEP]']
[Init] best rec loss: 0.930613100528717 for ['[CLS] meetings bells mountain bloody technical script⁄ sarah rebound fare they br hospital christmas value turkmenistan [SEP]']
[Init] best rec loss: 0.9267537593841553 for ['[CLS] et roughly christian cinema angela zoo commanded determinedpine treatcraft said being amountigo ; [SEP]']
[Init] best rec loss: 0.9248879551887512 for ['[CLS] transplant valley true bu golfer grabbed law ee wet especially comics energytics shorter packed hunting [SEP]']
[Init] best rec loss: 0.9164901375770569 for ['[CLS] operation tactics toes collective valley stitches drop criticism insteadivequitable francis surnamezer san zone [SEP]']
[Init] best rec loss: 0.9076429605484009 for ['[CLS] mans border mormon vocational be doubt recordseft outcomes same humor spring chi ears other ling [SEP]']
[Init] best rec loss: 0.8819190859794617 for ['[CLS] tract havinggated libraries himself odd magna courtney jonah tempted miller stunning spit opened french now [SEP]']
[Init] best rec loss: 0.8754848837852478 for ['[CLS]mission down unopposedacio tray adelaide african platform burnham ferrisest port case [MASK] gross main [SEP]']
[Init] best perm rec loss: 0.8741894364356995 for ['[CLS] [MASK]acio burnham platformest gross adelaide case unopposed ferris tray down africanmission main port [SEP]']
[Init] best perm rec loss: 0.8735032677650452 for ['[CLS]acio african tray burnham adelaide ferris gross port unopposed case [MASK] main platform downestmission [SEP]']
[Init] best perm rec loss: 0.8721978068351746 for ['[CLS] case platform portmission african adelaide tray mainacio ferrisest [MASK] burnham gross down unopposed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.128 (perp=12.795, rec=0.540, cos=0.029), tot_loss_proj:4.461 [t=0.24s]
prediction: ['[CLS] hutchinson actually strain understand did are alecused masculine early author son. thanksgiving forward variety [SEP]']
[ 100/2000] tot_loss=2.920 (perp=13.008, rec=0.312, cos=0.006), tot_loss_proj:4.206 [t=0.24s]
prediction: ['[CLS] hutchinson actuallymes trust - the alexused smart early writer professions super dinner jude characters [SEP]']
[ 150/2000] tot_loss=2.560 (perp=11.524, rec=0.251, cos=0.004), tot_loss_proj:4.133 [t=0.24s]
prediction: ['[CLS] hutchinson actuallymes quinlan -. james enough smart early winner episode sounding dinner sober hello [SEP]']
[ 200/2000] tot_loss=2.419 (perp=10.966, rec=0.222, cos=0.004), tot_loss_proj:3.369 [t=0.24s]
prediction: ['[CLS] hutchinson actuallymes trust -. james. smart early winner - real ( sober species [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.158 (perp=9.710, rec=0.213, cos=0.003), tot_loss_proj:3.655 [t=0.24s]
prediction: ['[CLS] james actuallymes real -. hutchinson. smartrom winner - real ( - characters [SEP]']
[ 300/2000] tot_loss=2.084 (perp=9.443, rec=0.193, cos=0.002), tot_loss_proj:3.618 [t=0.24s]
prediction: ['[CLS] james,mes real - - hutchinson and smartrom winner - real ( - client [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.882 (perp=8.491, rec=0.182, cos=0.002), tot_loss_proj:2.924 [t=0.24s]
prediction: ['[CLS] jamesrommesnator - - hutchinson and subtle, winner, real, - client [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.116 (perp=9.597, rec=0.194, cos=0.003), tot_loss_proj:2.458 [t=0.24s]
prediction: ['[CLS] james discmesnator - -, winner - real, strength hugh and subtle and [SEP]']
[ 450/2000] tot_loss=1.946 (perp=8.853, rec=0.172, cos=0.003), tot_loss_proj:2.503 [t=0.24s]
prediction: ['[CLS] james deepmesnator - -, winner - real, medical dragon and funny and [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.725 (perp=7.835, rec=0.155, cos=0.002), tot_loss_proj:2.215 [t=0.24s]
prediction: ['[CLS] james deepmesnator - -, winner, real, strength dragon and subtle. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.522 (perp=6.845, rec=0.151, cos=0.002), tot_loss_proj:2.258 [t=0.24s]
prediction: ['[CLS] james deepmesnator - -, winner, real, dragon, and subtle. [SEP]']
[ 600/2000] tot_loss=1.534 (perp=6.861, rec=0.159, cos=0.002), tot_loss_proj:2.159 [t=0.24s]
prediction: ["[CLS] james deepmes'- -, winner, real, dragon - and subtle. [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.434 (perp=6.407, rec=0.151, cos=0.002), tot_loss_proj:1.785 [t=0.24s]
prediction: ["[CLS] james dragonen'- -, winner, real, deep - and subtle. [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.427 (perp=6.407, rec=0.143, cos=0.002), tot_loss_proj:1.782 [t=0.24s]
prediction: ["[CLS] james dragonen'- -, winner, real, deep - and subtle. [SEP]"]
[ 750/2000] tot_loss=1.427 (perp=6.407, rec=0.144, cos=0.002), tot_loss_proj:1.782 [t=0.24s]
prediction: ["[CLS] james dragonen'- -, winner, real, deep - and subtle. [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.240 (perp=5.472, rec=0.144, cos=0.002), tot_loss_proj:1.574 [t=0.24s]
prediction: ["[CLS] james winneren'- -, dragon, real, deep - and funny. [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.248 (perp=5.558, rec=0.135, cos=0.002), tot_loss_proj:1.596 [t=0.24s]
prediction: ["[CLS] james winneren'- -, dragon, real, deep -, funny. [SEP]"]
[ 900/2000] tot_loss=1.253 (perp=5.558, rec=0.139, cos=0.002), tot_loss_proj:1.600 [t=0.24s]
prediction: ["[CLS] james winneren'- -, dragon, real, deep -, funny. [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.604 (perp=7.333, rec=0.136, cos=0.002), tot_loss_proj:2.050 [t=0.24s]
prediction: ["[CLS] james winneren 'ona -, dragon, real, deep -, funny. [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.530 (perp=6.948, rec=0.138, cos=0.002), tot_loss_proj:2.017 [t=0.24s]
prediction: ["[CLS]'winneren jamesona -, dragon, real, smart -, funny. [SEP]"]
[1050/2000] tot_loss=1.611 (perp=7.351, rec=0.139, cos=0.002), tot_loss_proj:2.056 [t=0.24s]
prediction: ["[CLS]'winneren jamesona -, dragon, real, smart /, funny. [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.492 (perp=6.712, rec=0.147, cos=0.002), tot_loss_proj:1.890 [t=0.24s]
prediction: ["[CLS]'winneren jamesona - /, dragon, real, smart, funny. [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.485 (perp=6.712, rec=0.141, cos=0.002), tot_loss_proj:1.890 [t=0.24s]
prediction: ["[CLS]'winneren jamesona - /, dragon, real, smart, funny. [SEP]"]
[1200/2000] tot_loss=1.476 (perp=6.712, rec=0.131, cos=0.002), tot_loss_proj:1.897 [t=0.24s]
prediction: ["[CLS]'winneren jamesona - /, dragon, real, smart, funny. [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.462 (perp=6.620, rec=0.136, cos=0.002), tot_loss_proj:1.843 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, smart, funny. [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.457 (perp=6.620, rec=0.131, cos=0.002), tot_loss_proj:1.847 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, smart, funny. [SEP]"]
[1350/2000] tot_loss=1.460 (perp=6.620, rec=0.134, cos=0.002), tot_loss_proj:1.854 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, smart, funny. [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.459 (perp=6.620, rec=0.133, cos=0.002), tot_loss_proj:1.844 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, smart, funny. [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.460 (perp=6.620, rec=0.134, cos=0.002), tot_loss_proj:1.848 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, smart, funny. [SEP]"]
[1500/2000] tot_loss=1.464 (perp=6.620, rec=0.138, cos=0.002), tot_loss_proj:1.849 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, smart, funny. [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.458 (perp=6.620, rec=0.132, cos=0.002), tot_loss_proj:1.848 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, smart, funny. [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.458 (perp=6.620, rec=0.132, cos=0.002), tot_loss_proj:1.850 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, smart, funny. [SEP]"]
[1650/2000] tot_loss=1.464 (perp=6.620, rec=0.138, cos=0.002), tot_loss_proj:1.845 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, smart, funny. [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.445 (perp=6.537, rec=0.135, cos=0.002), tot_loss_proj:1.831 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, funny, smart. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.443 (perp=6.537, rec=0.134, cos=0.002), tot_loss_proj:1.828 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, funny, smart. [SEP]"]
[1800/2000] tot_loss=1.439 (perp=6.537, rec=0.129, cos=0.002), tot_loss_proj:1.829 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, funny, smart. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.444 (perp=6.537, rec=0.135, cos=0.002), tot_loss_proj:1.821 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, funny, smart. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.443 (perp=6.537, rec=0.134, cos=0.002), tot_loss_proj:1.831 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, funny, smart. [SEP]"]
[1950/2000] tot_loss=1.430 (perp=6.537, rec=0.121, cos=0.002), tot_loss_proj:1.831 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, funny, smart. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.443 (perp=6.537, rec=0.133, cos=0.002), tot_loss_proj:1.836 [t=0.24s]
prediction: ["[CLS]ona winneren james'- /, dragon, real, funny, smart. [SEP]"]
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS]ona winneren james'- /, dragon, real, funny, smart. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 52.632 | p: 55.556 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.105 | p: 44.444 | r: 40.000
rougeLsum  | fm: 42.105 | p: 44.444 | r: 40.000
r1fm+r2fm = 52.632

[Aggregate metrics]:
rouge1     | fm: 92.996 | p: 92.601 | r: 93.452
rouge2     | fm: 61.374 | p: 61.147 | r: 61.630
rougeL     | fm: 80.266 | p: 80.061 | r: 80.593
rougeLsum  | fm: 80.231 | p: 79.982 | r: 80.491
r1fm+r2fm = 154.370

input #69 time: 0:09:25 | total time: 10:45:28


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.999374729045543
highest_index [0]
highest [0.999374729045543]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8474195003509521 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.8209116458892822 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7967671751976013 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7394418716430664 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best perm rec loss: 0.7338972091674805 for ['[CLS] detention technological sharma herself blood mark effects [SEP]']
[Init] best perm rec loss: 0.7322249412536621 for ['[CLS] blood sharma herself effects mark detention technological [SEP]']
[Init] best perm rec loss: 0.7319478988647461 for ['[CLS] mark herself sharma effects technological detention blood [SEP]']
[Init] best perm rec loss: 0.731513500213623 for ['[CLS] effects sharma blood detention herself technological mark [SEP]']
[Init] best perm rec loss: 0.7302557826042175 for ['[CLS] sharma mark herself technological detention effects blood [SEP]']
[Init] best perm rec loss: 0.7295522689819336 for ['[CLS] mark sharma herself technological detention effects blood [SEP]']
[Init] best perm rec loss: 0.7283495664596558 for ['[CLS] herself sharma effects detention technological mark blood [SEP]']
[Init] best perm rec loss: 0.7259199619293213 for ['[CLS] detention sharma herself blood effects technological mark [SEP]']
[Init] best perm rec loss: 0.7253750562667847 for ['[CLS] detention sharma mark blood technological herself effects [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.047 (perp=13.469, rec=0.326, cos=0.027), tot_loss_proj:3.621 [t=0.23s]
prediction: ['[CLS]ick robot jammedunkunk aroundunk [SEP]']
[ 100/2000] tot_loss=2.643 (perp=12.105, rec=0.205, cos=0.017), tot_loss_proj:3.372 [t=0.23s]
prediction: ['[CLS] gets screenunkunkunkyy [SEP]']
[ 150/2000] tot_loss=2.821 (perp=13.382, rec=0.136, cos=0.009), tot_loss_proj:3.924 [t=0.23s]
prediction: ['[CLS] gets screenunkunkunk on cl [SEP]']
[ 200/2000] tot_loss=2.353 (perp=11.226, rec=0.104, cos=0.004), tot_loss_proj:3.002 [t=0.23s]
prediction: ['[CLS] gets screen clunkunk ony [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.856 (perp=8.768, rec=0.098, cos=0.004), tot_loss_proj:2.471 [t=0.23s]
prediction: ['[CLS] gets screen on clunkunky [SEP]']
[ 300/2000] tot_loss=1.844 (perp=8.768, rec=0.087, cos=0.003), tot_loss_proj:2.482 [t=0.23s]
prediction: ['[CLS] gets screen on clunkunky [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.751 (perp=8.391, rec=0.070, cos=0.003), tot_loss_proj:2.212 [t=0.23s]
prediction: ['[CLS] gets on screen clunkunky [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.609 (perp=7.667, rec=0.073, cos=0.003), tot_loss_proj:2.369 [t=0.23s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[ 450/2000] tot_loss=1.616 (perp=7.667, rec=0.080, cos=0.002), tot_loss_proj:2.365 [t=0.23s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.614 (perp=7.667, rec=0.078, cos=0.002), tot_loss_proj:2.364 [t=0.23s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.620 (perp=7.667, rec=0.084, cos=0.003), tot_loss_proj:2.355 [t=0.23s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[ 600/2000] tot_loss=1.615 (perp=7.667, rec=0.080, cos=0.002), tot_loss_proj:2.358 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.603 (perp=7.667, rec=0.067, cos=0.002), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.601 (perp=7.667, rec=0.066, cos=0.002), tot_loss_proj:2.360 [t=0.23s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[ 750/2000] tot_loss=1.605 (perp=7.667, rec=0.069, cos=0.002), tot_loss_proj:2.365 [t=0.23s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.601 (perp=7.667, rec=0.066, cos=0.002), tot_loss_proj:2.361 [t=0.23s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.612 (perp=7.667, rec=0.077, cos=0.002), tot_loss_proj:2.361 [t=0.23s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[ 900/2000] tot_loss=1.602 (perp=7.667, rec=0.067, cos=0.002), tot_loss_proj:2.365 [t=0.23s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.600 (perp=7.667, rec=0.065, cos=0.002), tot_loss_proj:2.361 [t=0.23s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.602 (perp=7.667, rec=0.066, cos=0.002), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1050/2000] tot_loss=1.621 (perp=7.667, rec=0.085, cos=0.002), tot_loss_proj:2.363 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.613 (perp=7.667, rec=0.077, cos=0.002), tot_loss_proj:2.365 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.613 (perp=7.667, rec=0.078, cos=0.002), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1200/2000] tot_loss=1.606 (perp=7.667, rec=0.071, cos=0.002), tot_loss_proj:2.363 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.606 (perp=7.667, rec=0.070, cos=0.002), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.609 (perp=7.667, rec=0.073, cos=0.002), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1350/2000] tot_loss=1.606 (perp=7.667, rec=0.071, cos=0.002), tot_loss_proj:2.360 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.610 (perp=7.667, rec=0.075, cos=0.002), tot_loss_proj:2.358 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.607 (perp=7.667, rec=0.072, cos=0.002), tot_loss_proj:2.358 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1500/2000] tot_loss=1.600 (perp=7.667, rec=0.065, cos=0.002), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.608 (perp=7.667, rec=0.073, cos=0.002), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.606 (perp=7.667, rec=0.071, cos=0.002), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1650/2000] tot_loss=1.615 (perp=7.667, rec=0.080, cos=0.002), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.607 (perp=7.667, rec=0.072, cos=0.002), tot_loss_proj:2.358 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.600 (perp=7.667, rec=0.065, cos=0.002), tot_loss_proj:2.368 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1800/2000] tot_loss=1.602 (perp=7.667, rec=0.066, cos=0.002), tot_loss_proj:2.357 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.612 (perp=7.667, rec=0.076, cos=0.002), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.606 (perp=7.667, rec=0.070, cos=0.002), tot_loss_proj:2.360 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1950/2000] tot_loss=1.612 (perp=7.667, rec=0.077, cos=0.002), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.613 (perp=7.667, rec=0.078, cos=0.002), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] gets on screenunk clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 18.182 | p: 20.000 | r: 16.667
rougeL     | fm: 61.538 | p: 66.667 | r: 57.143
rougeLsum  | fm: 61.538 | p: 66.667 | r: 57.143
r1fm+r2fm = 95.105

[Aggregate metrics]:
rouge1     | fm: 92.782 | p: 92.518 | r: 93.170
rouge2     | fm: 60.907 | p: 60.725 | r: 61.129
rougeL     | fm: 79.951 | p: 79.836 | r: 80.247
rougeLsum  | fm: 79.925 | p: 79.746 | r: 80.198
r1fm+r2fm = 153.689

input #70 time: 0:08:59 | total time: 10:54:28


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.9993408837696341
highest_index [0]
highest [0.9993408837696341]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8875375986099243 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.844735324382782 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8433874845504761 for ['[CLS] fed to radar county sun gunshot parchment waiting regional wallacewo dia [CLS] smiles fantasy [SEP]']
[Init] best rec loss: 0.8301323652267456 for ['[CLS] shoulders protocol powerfulfication sash jonas obligatory definition box thorough whole except visit flanked dated [SEP]']
[Init] best rec loss: 0.8257005214691162 for ['[CLS] cidloubridge living blues republicfl projections transition rally mere torpedo spellingcio espn [SEP]']
[Init] best rec loss: 0.8135210871696472 for ['[CLS] mutual internal travel grief with album careful item serious european either warp spoil waived every [SEP]']
[Init] best perm rec loss: 0.8111921548843384 for ['[CLS] serious album every either internal waived european grief warp travel mutual spoil item with careful [SEP]']
[Init] best perm rec loss: 0.809777557849884 for ['[CLS] either mutual travel warp album every grief with careful waived serious spoil european internal item [SEP]']
[Init] best perm rec loss: 0.8083569407463074 for ['[CLS] grief with careful serious warp every item internal mutual either waived album travel european spoil [SEP]']
[Init] best perm rec loss: 0.8064085245132446 for ['[CLS] serious mutual grief warp album european waived travel internal with spoil every item either careful [SEP]']
[Init] best perm rec loss: 0.8064031004905701 for ['[CLS] mutual every item with grief travel careful european serious warp waived spoil either album internal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.465 (perp=10.353, rec=0.351, cos=0.044), tot_loss_proj:3.140 [t=0.23s]
prediction: ['[CLS] coast 4 jump moment triggered jump moment no single moment something the ward - not [SEP]']
[ 100/2000] tot_loss=1.944 (perp=8.496, rec=0.220, cos=0.024), tot_loss_proj:3.142 [t=0.24s]
prediction: ['[CLS] coast 4 jump moment single jump moment a single jump something - - - not [SEP]']
[ 150/2000] tot_loss=1.896 (perp=8.600, rec=0.164, cos=0.012), tot_loss_proj:3.117 [t=0.24s]
prediction: ['[CLS] coast - jump seat single jump moment with single jump and - - seat not [SEP]']
[ 200/2000] tot_loss=2.083 (perp=9.774, rec=0.123, cos=0.005), tot_loss_proj:3.563 [t=0.24s]
prediction: ['[CLS] there - jump your your jump moment there single jump and - your seat not [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.871 (perp=8.791, rec=0.109, cos=0.004), tot_loss_proj:3.369 [t=0.24s]
prediction: ['[CLS] there - seat not your jump moment there single jump and - your seat your [SEP]']
[ 300/2000] tot_loss=1.927 (perp=9.197, rec=0.085, cos=0.003), tot_loss_proj:3.423 [t=0.24s]
prediction: ['[CLS] there - seat not your jump moment s single jump and - in seat your [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.711 (perp=8.172, rec=0.075, cos=0.002), tot_loss_proj:3.377 [t=0.24s]
prediction: ['[CLS] there - seat not your a moment s single jump and - in your seat [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.553 (perp=7.302, rec=0.090, cos=0.003), tot_loss_proj:3.210 [t=0.24s]
prediction: ['[CLS] there - your seat not a moment s single jump and - in your seat [SEP]']
[ 450/2000] tot_loss=1.546 (perp=7.302, rec=0.084, cos=0.002), tot_loss_proj:3.210 [t=0.24s]
prediction: ['[CLS] there - your seat not a moment s single jump and - in your seat [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.479 (perp=7.013, rec=0.075, cos=0.001), tot_loss_proj:3.175 [t=0.24s]
prediction: ['[CLS] there - your seat not a moment - s single jump and in your seat [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.429 (perp=6.833, rec=0.061, cos=0.002), tot_loss_proj:3.150 [t=0.24s]
prediction: ['[CLS] there - your seat not a moment - s in jump and single your seat [SEP]']
[ 600/2000] tot_loss=1.439 (perp=6.833, rec=0.071, cos=0.001), tot_loss_proj:3.147 [t=0.24s]
prediction: ['[CLS] there - your seat not a moment - s in jump and single your seat [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.382 (perp=6.555, rec=0.070, cos=0.001), tot_loss_proj:3.075 [t=0.24s]
prediction: ['[CLS] there - your seat not a single moment - s in jump and your seat [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.237 (perp=5.807, rec=0.074, cos=0.002), tot_loss_proj:2.944 [t=0.24s]
prediction: ['[CLS] there - not a single moment - s in jump your seat and your seat [SEP]']
[ 750/2000] tot_loss=1.233 (perp=5.807, rec=0.071, cos=0.001), tot_loss_proj:2.945 [t=0.24s]
prediction: ['[CLS] there - not a single moment - s in jump your seat and your seat [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.260 (perp=5.951, rec=0.068, cos=0.001), tot_loss_proj:2.554 [t=0.24s]
prediction: ['[CLS] there - not a single moment - s jump in your seat and - seat [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.154 (perp=5.356, rec=0.081, cos=0.001), tot_loss_proj:2.088 [t=0.24s]
prediction: ['[CLS] there and not a single moment - s jump in your seat - - seat [SEP]']
[ 900/2000] tot_loss=1.139 (perp=5.356, rec=0.067, cos=0.001), tot_loss_proj:2.085 [t=0.24s]
prediction: ['[CLS] there and not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.130 (perp=5.315, rec=0.066, cos=0.001), tot_loss_proj:1.944 [t=0.24s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1000/2000] tot_loss=1.138 (perp=5.315, rec=0.074, cos=0.001), tot_loss_proj:1.954 [t=0.24s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
[1050/2000] tot_loss=1.135 (perp=5.315, rec=0.070, cos=0.001), tot_loss_proj:1.953 [t=0.24s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1100/2000] tot_loss=1.125 (perp=5.315, rec=0.060, cos=0.001), tot_loss_proj:1.944 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1150/2000] tot_loss=1.126 (perp=5.315, rec=0.062, cos=0.001), tot_loss_proj:1.943 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
[1200/2000] tot_loss=1.133 (perp=5.315, rec=0.069, cos=0.001), tot_loss_proj:1.949 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1250/2000] tot_loss=1.138 (perp=5.315, rec=0.073, cos=0.001), tot_loss_proj:1.949 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1300/2000] tot_loss=1.129 (perp=5.315, rec=0.065, cos=0.001), tot_loss_proj:1.945 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
[1350/2000] tot_loss=1.130 (perp=5.315, rec=0.066, cos=0.001), tot_loss_proj:1.947 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1400/2000] tot_loss=1.128 (perp=5.315, rec=0.064, cos=0.001), tot_loss_proj:1.949 [t=0.23s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1450/2000] tot_loss=1.131 (perp=5.315, rec=0.066, cos=0.001), tot_loss_proj:1.950 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
[1500/2000] tot_loss=1.133 (perp=5.315, rec=0.069, cos=0.001), tot_loss_proj:1.950 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1550/2000] tot_loss=1.129 (perp=5.315, rec=0.065, cos=0.001), tot_loss_proj:1.955 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1600/2000] tot_loss=1.137 (perp=5.315, rec=0.072, cos=0.001), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
[1650/2000] tot_loss=1.133 (perp=5.315, rec=0.068, cos=0.001), tot_loss_proj:1.947 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1700/2000] tot_loss=1.131 (perp=5.315, rec=0.067, cos=0.001), tot_loss_proj:1.954 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1750/2000] tot_loss=1.131 (perp=5.315, rec=0.067, cos=0.001), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
[1800/2000] tot_loss=1.120 (perp=5.315, rec=0.056, cos=0.001), tot_loss_proj:1.957 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1850/2000] tot_loss=1.130 (perp=5.315, rec=0.066, cos=0.001), tot_loss_proj:1.957 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[1900/2000] tot_loss=1.111 (perp=5.315, rec=0.047, cos=0.001), tot_loss_proj:1.955 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
[1950/2000] tot_loss=1.129 (perp=5.315, rec=0.065, cos=0.001), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Attempt swap
[2000/2000] tot_loss=1.133 (perp=5.315, rec=0.069, cos=0.001), tot_loss_proj:1.962 [t=0.22s]
prediction: ['[CLS] and there not a single moment - s jump in your seat - - seat [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] and there not a single moment - s jump in your seat - - seat [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.296 | p: 92.857 | r: 100.000
rouge2     | fm: 40.000 | p: 38.462 | r: 41.667
rougeL     | fm: 74.074 | p: 71.429 | r: 76.923
rougeLsum  | fm: 74.074 | p: 71.429 | r: 76.923
r1fm+r2fm = 136.296

[Aggregate metrics]:
rouge1     | fm: 92.783 | p: 92.500 | r: 93.193
rouge2     | fm: 60.369 | p: 60.161 | r: 60.587
rougeL     | fm: 79.978 | p: 79.778 | r: 80.242
rougeLsum  | fm: 79.767 | p: 79.564 | r: 80.062
r1fm+r2fm = 153.152

input #71 time: 0:09:11 | total time: 11:03:39


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9992332805099025
highest_index [0]
highest [0.9992332805099025]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7866917848587036 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7584322690963745 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7510275840759277 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7389710545539856 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.7389072179794312 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.7173200249671936 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7166939377784729 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.7151522636413574 for ['[CLS] zone except orbital walking! ta support dna vanungen pork accidentally lifeboat nonetheless reserve [SEP]']
[Init] best perm rec loss: 0.7150953412055969 for ['[CLS] lifeboat support accidentallyungen zone nonetheless reserve ta orbital van dna! walking except pork [SEP]']
[Init] best perm rec loss: 0.7140606045722961 for ['[CLS] reserve ta nonetheless walking dna van orbital support except pork! zone lifeboatungen accidentally [SEP]']
[Init] best perm rec loss: 0.7136176228523254 for ['[CLS] pork reserve ta nonetheless walking! van lifeboat exceptungen orbital support dna zone accidentally [SEP]']
[Init] best perm rec loss: 0.7135342955589294 for ['[CLS] ta lifeboat accidentally van! walking zone except nonetheless dna orbital support reserveungen pork [SEP]']
[Init] best perm rec loss: 0.7135124802589417 for ['[CLS] reserve zone lifeboat walking pork support except dna van nonetheless ta! accidentally orbitalungen [SEP]']
[Init] best perm rec loss: 0.7132373452186584 for ['[CLS] zoneungen nonetheless walking van dna pork orbital lifeboat accidentally ta except reserve! support [SEP]']
[Init] best perm rec loss: 0.7126136422157288 for ['[CLS] lifeboat supportungen van! accidentally reserve ta dna pork except zone orbital walking nonetheless [SEP]']
[Init] best perm rec loss: 0.7125565409660339 for ['[CLS]! walking nonetheless pork van accidentally dna lifeboat reserveungen zone orbital ta except support [SEP]']
[Init] best perm rec loss: 0.7125199437141418 for ['[CLS] walking pork lifeboat nonetheless zone accidentally dna! reserve supportungen van ta orbital except [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.581 (perp=11.345, rec=0.284, cos=0.028), tot_loss_proj:3.201 [t=0.24s]
prediction: ['[CLS] heavily a tough time grey balancing toughbreak usually whose followed has guess hallbiotic [SEP]']
[ 100/2000] tot_loss=2.354 (perp=10.891, rec=0.166, cos=0.009), tot_loss_proj:3.750 [t=0.24s]
prediction: ['[CLS] heavily a tough time tough balancing toughers violence inspired followed has balancing oliver philosophy [SEP]']
[ 150/2000] tot_loss=2.418 (perp=11.480, rec=0.118, cos=0.004), tot_loss_proj:3.793 [t=0.24s]
prediction: ['[CLS] write aer time violence balancing toughers violence mimic followed has balancing with philosophy [SEP]']
[ 200/2000] tot_loss=2.310 (perp=11.051, rec=0.093, cos=0.007), tot_loss_proj:3.942 [t=0.24s]
prediction: ['[CLS] inspired aer time violence balancing tough violence itsfk would has balancing with philosophy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.000 (perp=9.514, rec=0.094, cos=0.003), tot_loss_proj:3.532 [t=0.24s]
prediction: ['[CLS] inspired a tough time violence balancinger violence itsfk, has balancing with philosophy [SEP]']
[ 300/2000] tot_loss=1.981 (perp=9.514, rec=0.076, cos=0.002), tot_loss_proj:3.527 [t=0.24s]
prediction: ['[CLS] inspired a tough time violence balancinger violence itsfk, has balancing with philosophy [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.819 (perp=8.727, rec=0.072, cos=0.002), tot_loss_proj:3.218 [t=0.24s]
prediction: ['[CLS] inspired a tough time balancing violenceer violence itsfk, has balancing with philosophy [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.762 (perp=8.410, rec=0.078, cos=0.002), tot_loss_proj:3.101 [t=0.24s]
prediction: ['[CLS] inspired a tough time balancing violenceer violence its balancing, hasfk with philosophy [SEP]']
[ 450/2000] tot_loss=1.746 (perp=8.410, rec=0.063, cos=0.002), tot_loss_proj:3.103 [t=0.24s]
prediction: ['[CLS] inspired a tough time balancing violenceer violence its balancing, hasfk with philosophy [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.680 (perp=7.960, rec=0.087, cos=0.002), tot_loss_proj:3.080 [t=0.24s]
prediction: ['[CLS] inspired a tough time balancing violenceer balancing its violence, hasfk with philosophy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.639 (perp=7.850, rec=0.067, cos=0.002), tot_loss_proj:2.408 [t=0.24s]
prediction: ['[CLS] has a tough time balancing violenceer balancing its violence, inspiredfk with philosophy [SEP]']
[ 600/2000] tot_loss=1.648 (perp=7.850, rec=0.077, cos=0.002), tot_loss_proj:2.410 [t=0.24s]
prediction: ['[CLS] has a tough time balancing violenceer balancing its violence, inspiredfk with philosophy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.584 (perp=7.553, rec=0.072, cos=0.002), tot_loss_proj:2.272 [t=0.24s]
prediction: ['[CLS] has a tough time balancing violenceer balancing its violence, withfk inspired philosophy [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.536 (perp=7.281, rec=0.078, cos=0.002), tot_loss_proj:1.910 [t=0.24s]
prediction: ['[CLS] has a tough time balancinger balancing its violence, violence withfk inspired philosophy [SEP]']
[ 750/2000] tot_loss=1.522 (perp=7.281, rec=0.064, cos=0.002), tot_loss_proj:1.905 [t=0.24s]
prediction: ['[CLS] has a tough time balancinger balancing its violence, violence withfk inspired philosophy [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.529 (perp=7.309, rec=0.065, cos=0.002), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS]er has a tough time balancing balancing its violence - violence withfk inspired philosophy [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.417 (perp=6.745, rec=0.066, cos=0.002), tot_loss_proj:1.853 [t=0.24s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
[ 900/2000] tot_loss=1.426 (perp=6.745, rec=0.076, cos=0.002), tot_loss_proj:1.860 [t=0.24s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.421 (perp=6.745, rec=0.070, cos=0.002), tot_loss_proj:1.855 [t=0.24s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.420 (perp=6.745, rec=0.069, cos=0.002), tot_loss_proj:1.850 [t=0.24s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
[1050/2000] tot_loss=1.415 (perp=6.745, rec=0.065, cos=0.002), tot_loss_proj:1.863 [t=0.24s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.417 (perp=6.745, rec=0.067, cos=0.002), tot_loss_proj:1.863 [t=0.24s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.424 (perp=6.745, rec=0.074, cos=0.002), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
[1200/2000] tot_loss=1.416 (perp=6.745, rec=0.065, cos=0.002), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.422 (perp=6.745, rec=0.071, cos=0.002), tot_loss_proj:1.863 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.418 (perp=6.745, rec=0.068, cos=0.002), tot_loss_proj:1.854 [t=0.23s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
[1350/2000] tot_loss=1.431 (perp=6.745, rec=0.080, cos=0.002), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.419 (perp=6.745, rec=0.068, cos=0.002), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.411 (perp=6.745, rec=0.061, cos=0.002), tot_loss_proj:1.856 [t=0.23s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
[1500/2000] tot_loss=1.422 (perp=6.745, rec=0.071, cos=0.002), tot_loss_proj:1.854 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.422 (perp=6.745, rec=0.071, cos=0.002), tot_loss_proj:1.859 [t=0.23s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.414 (perp=6.745, rec=0.064, cos=0.002), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
[1650/2000] tot_loss=1.407 (perp=6.745, rec=0.057, cos=0.002), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.423 (perp=6.745, rec=0.073, cos=0.002), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.419 (perp=6.745, rec=0.069, cos=0.002), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
[1800/2000] tot_loss=1.417 (perp=6.745, rec=0.066, cos=0.002), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.426 (perp=6.745, rec=0.075, cos=0.002), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.422 (perp=6.745, rec=0.071, cos=0.002), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
[1950/2000] tot_loss=1.423 (perp=6.745, rec=0.072, cos=0.002), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.414 (perp=6.745, rec=0.064, cos=0.002), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS]er has a tough time balancing its violence - balancing violence withfk inspired philosophy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 66.667 | r: 76.923
rouge2     | fm: 46.154 | p: 42.857 | r: 50.000
rougeL     | fm: 71.429 | p: 66.667 | r: 76.923
rougeLsum  | fm: 71.429 | p: 66.667 | r: 76.923
r1fm+r2fm = 117.582

[Aggregate metrics]:
rouge1     | fm: 92.524 | p: 92.126 | r: 93.017
rouge2     | fm: 60.152 | p: 59.934 | r: 60.399
rougeL     | fm: 79.891 | p: 79.659 | r: 80.176
rougeLsum  | fm: 79.791 | p: 79.546 | r: 80.138
r1fm+r2fm = 152.676

input #72 time: 0:09:12 | total time: 11:12:51


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9991739905462714
highest_index [0]
highest [0.9991739905462714]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9930576682090759 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.970208466053009 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9534759521484375 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9143747687339783 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.911167323589325 for ['[CLS]dicated circles [SEP]']
[Init] best rec loss: 0.8457381725311279 for ['[CLS] tierney sector [SEP]']
[Init] best perm rec loss: 0.8437196016311646 for ['[CLS] sector tierney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.122 (perp=9.724, rec=0.169, cos=0.008), tot_loss_proj:2.019 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.016 (perp=9.724, rec=0.070, cos=0.002), tot_loss_proj:2.018 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=1.999 (perp=9.724, rec=0.053, cos=0.002), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.005 (perp=9.724, rec=0.059, cos=0.002), tot_loss_proj:2.019 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.011 (perp=9.724, rec=0.064, cos=0.002), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.014 (perp=9.724, rec=0.067, cos=0.002), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.999 (perp=9.724, rec=0.052, cos=0.002), tot_loss_proj:2.019 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.010 (perp=9.724, rec=0.064, cos=0.002), tot_loss_proj:2.003 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.001 (perp=9.724, rec=0.054, cos=0.002), tot_loss_proj:2.020 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.996 (perp=9.724, rec=0.050, cos=0.002), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.012 (perp=9.724, rec=0.066, cos=0.002), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.010 (perp=9.724, rec=0.063, cos=0.002), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.009 (perp=9.724, rec=0.062, cos=0.002), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.014 (perp=9.724, rec=0.068, cos=0.002), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.007 (perp=9.724, rec=0.061, cos=0.002), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.015 (perp=9.724, rec=0.068, cos=0.002), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.004 (perp=9.724, rec=0.057, cos=0.002), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.008 (perp=9.724, rec=0.061, cos=0.002), tot_loss_proj:2.003 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.008 (perp=9.724, rec=0.062, cos=0.002), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.003 (perp=9.724, rec=0.057, cos=0.002), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.012 (perp=9.724, rec=0.065, cos=0.002), tot_loss_proj:2.019 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.020 (perp=9.724, rec=0.073, cos=0.002), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.003 (perp=9.724, rec=0.057, cos=0.002), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.013 (perp=9.724, rec=0.067, cos=0.002), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.008 (perp=9.724, rec=0.062, cos=0.002), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.009 (perp=9.724, rec=0.063, cos=0.002), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.001 (perp=9.724, rec=0.055, cos=0.002), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.013 (perp=9.724, rec=0.066, cos=0.002), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.007 (perp=9.724, rec=0.060, cos=0.002), tot_loss_proj:2.014 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.010 (perp=9.724, rec=0.064, cos=0.002), tot_loss_proj:2.014 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.007 (perp=9.724, rec=0.061, cos=0.002), tot_loss_proj:2.022 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.002 (perp=9.724, rec=0.055, cos=0.002), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.001 (perp=9.724, rec=0.055, cos=0.002), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.006 (perp=9.724, rec=0.060, cos=0.002), tot_loss_proj:2.014 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.007 (perp=9.724, rec=0.061, cos=0.002), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.007 (perp=9.724, rec=0.061, cos=0.002), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.008 (perp=9.724, rec=0.062, cos=0.002), tot_loss_proj:2.018 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.007 (perp=9.724, rec=0.061, cos=0.002), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.010 (perp=9.724, rec=0.063, cos=0.002), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.005 (perp=9.724, rec=0.058, cos=0.002), tot_loss_proj:2.014 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.578 | p: 92.219 | r: 93.088
rouge2     | fm: 60.890 | p: 60.633 | r: 61.163
rougeL     | fm: 80.145 | p: 79.900 | r: 80.511
rougeLsum  | fm: 80.067 | p: 79.802 | r: 80.383
r1fm+r2fm = 153.468

input #73 time: 0:08:41 | total time: 11:21:32


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9992586513675699
highest_index [0]
highest [0.9992586513675699]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.0039318799972534 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6881205439567566 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.6577026844024658 for ['[CLS] birth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.015 (perp=8.178, rec=0.340, cos=0.040), tot_loss_proj:2.172 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.745 (perp=8.178, rec=0.106, cos=0.004), tot_loss_proj:1.916 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.705 (perp=8.178, rec=0.068, cos=0.002), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.714 (perp=8.178, rec=0.077, cos=0.002), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.720 (perp=8.178, rec=0.083, cos=0.002), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.708 (perp=8.178, rec=0.071, cos=0.002), tot_loss_proj:1.736 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.002), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.002), tot_loss_proj:1.732 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.708 (perp=8.178, rec=0.071, cos=0.002), tot_loss_proj:1.720 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.002), tot_loss_proj:1.740 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.701 (perp=8.178, rec=0.063, cos=0.002), tot_loss_proj:1.722 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.686 (perp=8.178, rec=0.049, cos=0.001), tot_loss_proj:1.729 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.713 (perp=8.178, rec=0.076, cos=0.001), tot_loss_proj:1.726 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.715 (perp=8.178, rec=0.078, cos=0.001), tot_loss_proj:1.722 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.701 (perp=8.178, rec=0.064, cos=0.001), tot_loss_proj:1.727 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.001), tot_loss_proj:1.736 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.693 (perp=8.178, rec=0.055, cos=0.002), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.714 (perp=8.178, rec=0.077, cos=0.001), tot_loss_proj:1.727 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.682 (perp=8.178, rec=0.044, cos=0.001), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.001), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.705 (perp=8.178, rec=0.068, cos=0.001), tot_loss_proj:1.729 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.702 (perp=8.178, rec=0.065, cos=0.001), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.001), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.705 (perp=8.178, rec=0.068, cos=0.001), tot_loss_proj:1.731 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.702 (perp=8.178, rec=0.064, cos=0.001), tot_loss_proj:1.731 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.711 (perp=8.178, rec=0.074, cos=0.001), tot_loss_proj:1.725 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.001), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.731 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.711 (perp=8.178, rec=0.073, cos=0.001), tot_loss_proj:1.729 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.708 (perp=8.178, rec=0.071, cos=0.001), tot_loss_proj:1.733 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.001), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.708 (perp=8.178, rec=0.071, cos=0.001), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.722 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.734 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.001), tot_loss_proj:1.730 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.740 | p: 92.362 | r: 93.208
rouge2     | fm: 61.294 | p: 61.067 | r: 61.543
rougeL     | fm: 80.348 | p: 80.140 | r: 80.672
rougeLsum  | fm: 80.202 | p: 79.995 | r: 80.547
r1fm+r2fm = 154.034

input #74 time: 0:08:35 | total time: 11:30:08


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9993457140726361
highest_index [0]
highest [0.9993457140726361]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.9596470594406128 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.9503890872001648 for ['[CLS] changed door covert obviously tone sinclair final hard eventdrome apps nick tempo nations diveiii willem nodded rolled [SEP]']
[Init] best rec loss: 0.9403657913208008 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.9036276936531067 for ['[CLS] years public during cup months du sources community ind baseman viz together clinton est frog gum firing points prick [SEP]']
[Init] best rec loss: 0.8985481858253479 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 0.897793173789978 for ['[CLS] brother eco clockizes clint wagon identification % already spirit ceo vampires sighted international version glare contraction eds buck [SEP]']
[Init] best rec loss: 0.8942992091178894 for ['[CLS]orin rearview bore nicky yang dynasty confidence hockey preaching mangrove meanllet ventureix resistance constitution sun nicholas piece [SEP]']
[Init] best rec loss: 0.8870740532875061 for ['[CLS] stir will case bills blocked hand miniseries electricchen words tha batting shed az happen women known gen tourist [SEP]']
[Init] best rec loss: 0.8610764741897583 for ['[CLS]ception resultedrate left fact crown skill apollo auxiliary regardedcl magic to eachmmel viewed stood loop royalties [SEP]']
[Init] best perm rec loss: 0.8609409332275391 for ['[CLS]rate magic viewed apollo crown fact loop resulted auxiliarycl stood each regarded toceptionmmel skill left royalties [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.761 (perp=11.816, rec=0.370, cos=0.027), tot_loss_proj:4.222 [t=0.23s]
prediction: ['[CLS]bird miss passengers disregard hardly. panic potentially visibility here held butter soon to lopez dismissed visitors without coast [SEP]']
[ 100/2000] tot_loss=3.012 (perp=12.933, rec=0.393, cos=0.032), tot_loss_proj:4.473 [t=0.24s]
prediction: ['[CLS]anies became chick not barely bottom playground placement frequently suddenly started guestslis its cannotdilly invited have. [SEP]']
[ 150/2000] tot_loss=2.810 (perp=12.510, rec=0.293, cos=0.015), tot_loss_proj:4.271 [t=0.24s]
prediction: ['[CLS]icular isi not lieutenant particular forgotten improvisation frequently suddenly split executive™ [SEP] cerebraldilly visiting have. [SEP]']
[ 200/2000] tot_loss=2.668 (perp=12.036, rec=0.251, cos=0.010), tot_loss_proj:4.250 [t=0.24s]
prediction: ['[CLS]icular isi not lieutenant not forgotten improvisation frequently forgotten easily executivelas amidst exceedsdilly when have. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.271 (perp=10.263, rec=0.212, cos=0.007), tot_loss_proj:3.887 [t=0.24s]
prediction: ['[CLS] isborg is not lieutenant not forgotten improvisation easily forgotten easily executivelas excursionurities based when visited. [SEP]']
[ 300/2000] tot_loss=2.221 (perp=10.072, rec=0.201, cos=0.005), tot_loss_proj:3.843 [t=0.24s]
prediction: ['[CLS] iscent is not lieutenant not forgotten improvisation easily forgotten easily executiveopers excursion mental based when visited. [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.210 (perp=10.119, rec=0.182, cos=0.005), tot_loss_proj:3.815 [t=0.24s]
prediction: ['[CLS] iscola is not lieutenant not forgotten involvement easily forgotten easily executiveopers excursion mental based when visit. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.299 (perp=10.582, rec=0.178, cos=0.004), tot_loss_proj:3.971 [t=0.24s]
prediction: ['[CLS] iscola this not lieutenant barely forgotten involvement easily forgotten easily executive of excursion mental based whenplate. [SEP]']
[ 450/2000] tot_loss=2.228 (perp=10.314, rec=0.161, cos=0.004), tot_loss_proj:3.855 [t=0.24s]
prediction: ['[CLS] iscola this not lieutenant or forgotten excursion easily forgotten easily executive of excursion instability based whenres. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.161 (perp=9.950, rec=0.168, cos=0.003), tot_loss_proj:3.743 [t=0.24s]
prediction: ['[CLS] this hydro is not lieutenant or forgotten excursion easily forgotten easily executive of excursion instability based whenres. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.973 (perp=9.130, rec=0.144, cos=0.003), tot_loss_proj:3.607 [t=0.24s]
prediction: ['[CLS] thistem is not lieutenant excursion or forgotten easily forgotten easily executive of excursion instability based whenres. [SEP]']
[ 600/2000] tot_loss=1.958 (perp=9.089, rec=0.137, cos=0.003), tot_loss_proj:3.633 [t=0.24s]
prediction: ['[CLS] this vent is not lieutenant excursion or forgotten easily forgotten easily legendary of excursion instability based whenres. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.971 (perp=9.121, rec=0.144, cos=0.003), tot_loss_proj:3.674 [t=0.24s]
prediction: ['[CLS] this corrugated is not lieutenant excursion or forgotten easily forgotten easily when of excursion instability based executiveres. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.943 (perp=9.019, rec=0.137, cos=0.003), tot_loss_proj:3.619 [t=0.24s]
prediction: ['[CLS] this corrugated is not lieutenant excursion or forgotten easily forgotten easily when of excursion instability basedres executive. [SEP]']
[ 750/2000] tot_loss=1.930 (perp=9.019, rec=0.124, cos=0.003), tot_loss_proj:3.618 [t=0.24s]
prediction: ['[CLS] this corrugated is not lieutenant excursion or forgotten easily forgotten easily when of excursion instability basedres executive. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.865 (perp=8.727, rec=0.118, cos=0.002), tot_loss_proj:3.612 [t=0.24s]
prediction: ['[CLS] this corrugated excursion is not lieutenant or forgotten easily forgotten easily when of excursion instability basedres executive. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.894 (perp=8.879, rec=0.116, cos=0.002), tot_loss_proj:3.633 [t=0.24s]
prediction: ['[CLS] thistem excursion is not lieutenant or forgotten easily forgotten easily when of excursion instability basedres executive. [SEP]']
[ 900/2000] tot_loss=1.895 (perp=8.879, rec=0.117, cos=0.002), tot_loss_proj:3.634 [t=0.24s]
prediction: ['[CLS] thistem excursion is not lieutenant or forgotten easily forgotten easily when of excursion instability basedres executive. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.850 (perp=8.686, rec=0.110, cos=0.002), tot_loss_proj:3.556 [t=0.24s]
prediction: ['[CLS] thistem excursion is not laboratory or forgotten easily forgotten easily when of excursion instability basedres executive. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.871 (perp=8.686, rec=0.132, cos=0.002), tot_loss_proj:3.553 [t=0.24s]
prediction: ['[CLS] thistem excursion is not laboratory or forgotten easily forgotten easily when of excursion instability basedres executive. [SEP]']
[1050/2000] tot_loss=1.865 (perp=8.686, rec=0.125, cos=0.002), tot_loss_proj:3.549 [t=0.24s]
prediction: ['[CLS] thistem excursion is not laboratory or forgotten easily forgotten easily when of excursion instability basedres executive. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.856 (perp=8.686, rec=0.117, cos=0.002), tot_loss_proj:3.550 [t=0.24s]
prediction: ['[CLS] thistem excursion is not laboratory or forgotten easily forgotten easily when of excursion instability basedres executive. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.776 (perp=8.262, rec=0.121, cos=0.002), tot_loss_proj:3.446 [t=0.24s]
prediction: ['[CLS] thislastic excursion is not laboratory or forgotten easily forgotten easily when of excursion executive instability basedres. [SEP]']
[1200/2000] tot_loss=1.820 (perp=8.487, rec=0.120, cos=0.002), tot_loss_proj:3.518 [t=0.24s]
prediction: ['[CLS] thistem excursion is not laboratory or forgotten easily forgotten easily when of excursion executive instability basedres. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.760 (perp=8.235, rec=0.111, cos=0.002), tot_loss_proj:3.408 [t=0.24s]
prediction: ['[CLS] thislastic excursion is not laboratory or forgotten easily forgotten easily when ofres executive instability based excursion. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.842 (perp=8.651, rec=0.110, cos=0.002), tot_loss_proj:3.567 [t=0.24s]
prediction: ['[CLS] thistem excursion is not laboratory or forgotten easily forgotten easily when ofres instability based legendary excursion. [SEP]']
[1350/2000] tot_loss=1.840 (perp=8.651, rec=0.108, cos=0.002), tot_loss_proj:3.565 [t=0.24s]
prediction: ['[CLS] thistem excursion is not laboratory or forgotten easily forgotten easily when ofres instability based legendary excursion. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.860 (perp=8.714, rec=0.115, cos=0.002), tot_loss_proj:3.520 [t=0.24s]
prediction: ['[CLS] this excursion is notlastic mental or forgotten easily forgotten easily when ofres instability based legendary excursion. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.924 (perp=9.027, rec=0.116, cos=0.002), tot_loss_proj:3.565 [t=0.24s]
prediction: ['[CLS] this excursion is nottem mental or forgotten easily forgotten easily when basedres instability ofqua excursion. [SEP]']
[1500/2000] tot_loss=1.915 (perp=9.027, rec=0.108, cos=0.002), tot_loss_proj:3.562 [t=0.24s]
prediction: ['[CLS] this excursion is nottem mental or forgotten easily forgotten easily when basedres instability ofqua excursion. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.836 (perp=8.614, rec=0.111, cos=0.002), tot_loss_proj:3.492 [t=0.24s]
prediction: ['[CLS] this excursion is notiction mental or forgotten easily forgotten easily when based instability ofresqua excursion. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.844 (perp=8.637, rec=0.114, cos=0.002), tot_loss_proj:3.647 [t=0.24s]
prediction: ['[CLS] this excursion is notiction mental or easily dismissed easily forgotten when based instability ofresqua excursion. [SEP]']
[1650/2000] tot_loss=1.835 (perp=8.637, rec=0.106, cos=0.002), tot_loss_proj:3.654 [t=0.24s]
prediction: ['[CLS] this excursion is notiction mental or easily dismissed easily forgotten when based instability ofresqua excursion. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.838 (perp=8.637, rec=0.108, cos=0.002), tot_loss_proj:3.662 [t=0.24s]
prediction: ['[CLS] this excursion is notiction mental or easily dismissed easily forgotten when based instability ofresqua excursion. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.765 (perp=8.239, rec=0.115, cos=0.002), tot_loss_proj:3.364 [t=0.24s]
prediction: ['[CLS] this excursion is notiction based or easily dismissed easily forgotten when mental instability ofresqua excursion. [SEP]']
[1800/2000] tot_loss=1.766 (perp=8.239, rec=0.116, cos=0.002), tot_loss_proj:3.363 [t=0.24s]
prediction: ['[CLS] this excursion is notiction based or easily dismissed easily forgotten when mental instability ofresqua excursion. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.767 (perp=8.239, rec=0.117, cos=0.002), tot_loss_proj:3.365 [t=0.24s]
prediction: ['[CLS] this excursion is notiction based or easily dismissed easily forgotten when mental instability ofresqua excursion. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.749 (perp=8.169, rec=0.112, cos=0.002), tot_loss_proj:3.314 [t=0.24s]
prediction: ['[CLS] this excursion is notiction based or easily dismissed easily forgotten when mental instabilityquares of excursion. [SEP]']
[1950/2000] tot_loss=1.743 (perp=8.169, rec=0.107, cos=0.002), tot_loss_proj:3.309 [t=0.24s]
prediction: ['[CLS] this excursion is notiction based or easily dismissed easily forgotten when mental instabilityquares of excursion. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.744 (perp=8.169, rec=0.109, cos=0.002), tot_loss_proj:3.310 [t=0.24s]
prediction: ['[CLS] this excursion is notiction based or easily dismissed easily forgotten when mental instabilityquares of excursion. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this excursion is notiction based or easily dismissed easily forgotten when mental instability ofresqua excursion. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.706 | p: 64.706 | r: 64.706
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 47.059 | p: 47.059 | r: 47.059
rougeLsum  | fm: 47.059 | p: 47.059 | r: 47.059
r1fm+r2fm = 89.706

[Aggregate metrics]:
rouge1     | fm: 92.318 | p: 91.963 | r: 92.761
rouge2     | fm: 60.897 | p: 60.628 | r: 61.188
rougeL     | fm: 79.889 | p: 79.678 | r: 80.234
rougeLsum  | fm: 79.839 | p: 79.624 | r: 80.142
r1fm+r2fm = 153.216

input #75 time: 0:09:24 | total time: 11:39:32


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9991390736873003
highest_index [0]
highest [0.9991390736873003]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.921407163143158 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.9002844095230103 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 0.8949021100997925 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 0.8901370167732239 for ['[CLS] carrie word 38 saying subject window rican disc anatomy awardscles cf past resisted [SEP]']
[Init] best rec loss: 0.8706420660018921 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 0.8616399168968201 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.8554098606109619 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 0.8517670035362244 for ['[CLS] pushed ( purse onwards lefthaw tautoning surreal hard ab backwardˣ mango [SEP]']
[Init] best perm rec loss: 0.8514449000358582 for ['[CLS] purse backward hard ab taut surreal onwards mango ( lefthaw pushedoningˣ [SEP]']
[Init] best perm rec loss: 0.8474489450454712 for ['[CLS] onwards aboning lefthaw taut ( pushed hardˣ surreal backward mango purse [SEP]']
[Init] best perm rec loss: 0.8473937511444092 for ['[CLS] mangoˣ abhaw purse onwards ( surrealoning hard taut pushed backward left [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.357 (perp=10.225, rec=0.288, cos=0.023), tot_loss_proj:3.547 [t=0.23s]
prediction: ['[CLS] seems had stopped himself when. is challenging. stopped challenging ace stopped attack [SEP]']
[ 100/2000] tot_loss=1.962 (perp=8.643, rec=0.218, cos=0.015), tot_loss_proj:2.614 [t=0.23s]
prediction: ['[CLS] like has stopped himself when, has challenging. stopped challenging has stopped himself [SEP]']
[ 150/2000] tot_loss=2.033 (perp=9.290, rec=0.164, cos=0.011), tot_loss_proj:2.937 [t=0.23s]
prediction: ['[CLS] as 66 stopped himself., has challenging, stopped challenging has stopped himself [SEP]']
[ 200/2000] tot_loss=1.906 (perp=8.811, rec=0.138, cos=0.006), tot_loss_proj:2.813 [t=0.23s]
prediction: ["[CLS] as 66'himself., has challenging, stopped challenging has stopped himself [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.968 (perp=9.001, rec=0.159, cos=0.009), tot_loss_proj:2.896 [t=0.23s]
prediction: ["[CLS] as 66'challenging., has challenging. stopped himself has stopped himself [SEP]"]
[ 300/2000] tot_loss=2.011 (perp=9.400, rec=0.126, cos=0.005), tot_loss_proj:2.828 [t=0.23s]
prediction: ['[CLS] as 66 at allen., has challenging, stopped himself has stopped challenging [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.877 (perp=8.762, rec=0.119, cos=0.005), tot_loss_proj:2.800 [t=0.23s]
prediction: ['[CLS] as 66 challenging, at allen., has stopped himself has stopped themselves [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.696 (perp=7.676, rec=0.154, cos=0.007), tot_loss_proj:2.428 [t=0.23s]
prediction: ['[CLS] as 66 challenging, at allen, has stopped himself has stopped challenges. [SEP]']
[ 450/2000] tot_loss=1.644 (perp=7.676, rec=0.104, cos=0.005), tot_loss_proj:2.414 [t=0.23s]
prediction: ['[CLS] as 66 challenging, at allen, has stopped himself has stopped challenges. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.893 (perp=8.936, rec=0.101, cos=0.004), tot_loss_proj:2.703 [t=0.23s]
prediction: ['[CLS] as 66 challenging, at allen,. stopped himself has stopped challenges. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.123 (perp=9.569, rec=0.200, cos=0.010), tot_loss_proj:2.938 [t=0.23s]
prediction: ['[CLS] as 66 challenging, at allen, stopped [SEP] himself has stopped challenges, [SEP]']
[ 600/2000] tot_loss=2.099 (perp=9.777, rec=0.138, cos=0.006), tot_loss_proj:2.954 [t=0.23s]
prediction: ['[CLS] as 66 challenging, at allen, stopped [SEP] himself has stopped challenge, [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.052 (perp=9.599, rec=0.128, cos=0.005), tot_loss_proj:2.917 [t=0.23s]
prediction: ['[CLS] as stopped challenging, at allen, 66 [SEP] himself has stopped challenge is [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.935 (perp=9.081, rec=0.114, cos=0.005), tot_loss_proj:2.936 [t=0.23s]
prediction: ['[CLS] as stopped challenging, at allen challenge 66 [SEP] himself has stopped, is [SEP]']
[ 750/2000] tot_loss=1.872 (perp=8.765, rec=0.114, cos=0.005), tot_loss_proj:2.813 [t=0.23s]
prediction: ['[CLS] as stopped challenging, at allen challenge 66 [SEP] himself has stopped,. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.806 (perp=8.440, rec=0.113, cos=0.005), tot_loss_proj:2.982 [t=0.23s]
prediction: ['[CLS] as stopped challenging, at allen 66 [SEP] himself has stopped, challenge. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.782 (perp=8.344, rec=0.109, cos=0.005), tot_loss_proj:2.567 [t=0.23s]
prediction: ['[CLS] as stopped challenging, at allen 66, himself has stopped [SEP] challenge. [SEP]']
[ 900/2000] tot_loss=1.785 (perp=8.344, rec=0.112, cos=0.004), tot_loss_proj:2.560 [t=0.23s]
prediction: ['[CLS] as stopped challenging, at allen 66, himself has stopped [SEP] challenge. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.703 (perp=7.951, rec=0.109, cos=0.004), tot_loss_proj:2.561 [t=0.23s]
prediction: ['[CLS] as challenge challenging, at allen 66, himself has stopped [SEP] stopped. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.696 (perp=7.907, rec=0.110, cos=0.004), tot_loss_proj:2.669 [t=0.23s]
prediction: ['[CLS] as challenge challenging, at allen 66, has himself stopped [SEP] stopped. [SEP]']
[1050/2000] tot_loss=1.924 (perp=9.072, rec=0.105, cos=0.004), tot_loss_proj:3.019 [t=0.23s]
prediction: ['[CLS] as challenge challenging, at allen 66, has himself stopped [SEP] stopped s [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.875 (perp=8.841, rec=0.103, cos=0.004), tot_loss_proj:2.931 [t=0.23s]
prediction: ['[CLS] as challenge challenging, at allen 66, has himself stopped stopped [SEP] s [SEP]']
Attempt swap
[1150/2000] tot_loss=1.871 (perp=8.841, rec=0.099, cos=0.004), tot_loss_proj:2.935 [t=0.23s]
prediction: ['[CLS] as challenge challenging, at allen 66, has himself stopped stopped [SEP] s [SEP]']
[1200/2000] tot_loss=1.863 (perp=8.841, rec=0.091, cos=0.004), tot_loss_proj:2.927 [t=0.23s]
prediction: ['[CLS] as challenge challenging, at allen 66, has himself stopped stopped [SEP] s [SEP]']
Attempt swap
[1250/2000] tot_loss=1.874 (perp=8.841, rec=0.102, cos=0.004), tot_loss_proj:2.933 [t=0.23s]
prediction: ['[CLS] as challenge challenging, at allen 66, has himself stopped stopped [SEP] s [SEP]']
Attempt swap
[1300/2000] tot_loss=1.879 (perp=8.841, rec=0.107, cos=0.004), tot_loss_proj:2.933 [t=0.23s]
prediction: ['[CLS] as challenge challenging, at allen 66, has himself stopped stopped [SEP] s [SEP]']
[1350/2000] tot_loss=1.970 (perp=9.344, rec=0.097, cos=0.004), tot_loss_proj:2.888 [t=0.22s]
prediction: ['[CLS] as. challenging, at allen 66, has himself stopped stopped [SEP] s [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.837 (perp=8.650, rec=0.103, cos=0.004), tot_loss_proj:2.769 [t=0.22s]
prediction: ['[CLS] as [SEP] challenging, at allen 66, has himself stopped stopped. s [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.774 (perp=8.345, rec=0.100, cos=0.005), tot_loss_proj:2.768 [t=0.22s]
prediction: ['[CLS] as s challenging, at allen 66, has himself stopped stopped. [SEP] [SEP]']
[1500/2000] tot_loss=1.772 (perp=8.345, rec=0.099, cos=0.004), tot_loss_proj:2.769 [t=0.22s]
prediction: ['[CLS] as s challenging, at allen 66, has himself stopped stopped. [SEP] [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.737 (perp=8.171, rec=0.098, cos=0.004), tot_loss_proj:2.728 [t=0.22s]
prediction: ['[CLS] as s challenging, at allen 66, has stopped stopped himself. [SEP] [SEP]']
Attempt swap
[1600/2000] tot_loss=1.725 (perp=8.171, rec=0.086, cos=0.004), tot_loss_proj:2.724 [t=0.22s]
prediction: ['[CLS] as s challenging, at allen 66, has stopped stopped himself. [SEP] [SEP]']
[1650/2000] tot_loss=1.743 (perp=8.171, rec=0.105, cos=0.004), tot_loss_proj:2.722 [t=0.22s]
prediction: ['[CLS] as s challenging, at allen 66, has stopped stopped himself. [SEP] [SEP]']
Attempt swap
[1700/2000] tot_loss=1.743 (perp=8.171, rec=0.105, cos=0.004), tot_loss_proj:2.723 [t=0.22s]
prediction: ['[CLS] as s challenging, at allen 66, has stopped stopped himself. [SEP] [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.703 (perp=8.014, rec=0.097, cos=0.004), tot_loss_proj:2.669 [t=0.22s]
prediction: ['[CLS] as s, challenging at allen 66, has stopped stopped himself. [SEP] [SEP]']
[1800/2000] tot_loss=1.711 (perp=8.014, rec=0.104, cos=0.004), tot_loss_proj:2.664 [t=0.22s]
prediction: ['[CLS] as s, challenging at allen 66, has stopped stopped himself. [SEP] [SEP]']
Attempt swap
[1850/2000] tot_loss=1.708 (perp=8.014, rec=0.101, cos=0.004), tot_loss_proj:2.672 [t=0.22s]
prediction: ['[CLS] as s, challenging at allen 66, has stopped stopped himself. [SEP] [SEP]']
Attempt swap
[1900/2000] tot_loss=1.705 (perp=8.014, rec=0.098, cos=0.004), tot_loss_proj:2.667 [t=0.22s]
prediction: ['[CLS] as s, challenging at allen 66, has stopped stopped himself. [SEP] [SEP]']
[1950/2000] tot_loss=1.702 (perp=8.014, rec=0.095, cos=0.004), tot_loss_proj:2.667 [t=0.22s]
prediction: ['[CLS] as s, challenging at allen 66, has stopped stopped himself. [SEP] [SEP]']
Attempt swap
[2000/2000] tot_loss=1.706 (perp=8.014, rec=0.099, cos=0.004), tot_loss_proj:2.671 [t=0.22s]
prediction: ['[CLS] as s, challenging at allen 66, has stopped stopped himself. [SEP] [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] as s, challenging at allen 66, has stopped stopped himself. [SEP] [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 26.087 | p: 25.000 | r: 27.273
rougeL     | fm: 64.000 | p: 61.538 | r: 66.667
rougeLsum  | fm: 64.000 | p: 61.538 | r: 66.667
r1fm+r2fm = 114.087

[Aggregate metrics]:
rouge1     | fm: 92.289 | p: 91.842 | r: 92.783
rouge2     | fm: 60.374 | p: 60.131 | r: 60.674
rougeL     | fm: 79.769 | p: 79.469 | r: 80.108
rougeLsum  | fm: 79.681 | p: 79.414 | r: 80.064
r1fm+r2fm = 152.663

input #76 time: 0:09:03 | total time: 11:48:36


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9992001897790881
highest_index [0]
highest [0.9992001897790881]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.9115081429481506 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8812075853347778 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.872740626335144 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best perm rec loss: 0.8698508143424988 for ['[CLS] grayraphic sheep most purple winno lime sometime medium park ways outside where ole [SEP]']
[Init] best perm rec loss: 0.8668491840362549 for ['[CLS] purple most ole park sometime sheep outside limeno ways win gray medium whereraphic [SEP]']
[Init] best perm rec loss: 0.8652713298797607 for ['[CLS] sometime ole where lime ways park purpleno win medium sheepraphic most outside gray [SEP]']
[Init] best perm rec loss: 0.8633628487586975 for ['[CLS] outside most gray whereraphic mediumno ole sheep sometime ways lime purple park win [SEP]']
[Init] best perm rec loss: 0.8618069887161255 for ['[CLS] purple outsideno where lime park most ole sometime win ways medium sheepraphic gray [SEP]']
[Init] best perm rec loss: 0.8598276376724243 for ['[CLS] win gray park where sometime medium ole most limeno ways sheep purpleraphic outside [SEP]']
[Init] best perm rec loss: 0.8584883213043213 for ['[CLS] ways park where oleraphic sometime win limeno most purple medium outside gray sheep [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.648 (perp=11.405, rec=0.345, cos=0.022), tot_loss_proj:3.036 [t=0.22s]
prediction: ['[CLS] itself movie believed camera will above life itsga. olivia greattering him heart [SEP]']
[ 100/2000] tot_loss=1.912 (perp=8.220, rec=0.258, cos=0.009), tot_loss_proj:2.650 [t=0.22s]
prediction: ['[CLS] itself perhaps believe life that above life its cover is its greattering material appeal [SEP]']
[ 150/2000] tot_loss=2.151 (perp=9.689, rec=0.207, cos=0.007), tot_loss_proj:3.005 [t=0.22s]
prediction: ['[CLS] genetics its believe promise that above life its release is its itsre material realm [SEP]']
[ 200/2000] tot_loss=1.974 (perp=8.987, rec=0.172, cos=0.005), tot_loss_proj:2.852 [t=0.22s]
prediction: ['[CLS] realm its believe promise that above life its life is its ofre material realm [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.536 (perp=6.768, rec=0.178, cos=0.005), tot_loss_proj:2.108 [t=0.22s]
prediction: ['[CLS] above make believe above life its promise that life is reach of the material realm [SEP]']
[ 300/2000] tot_loss=1.604 (perp=7.325, rec=0.133, cos=0.006), tot_loss_proj:2.182 [t=0.22s]
prediction: ['[CLS] promise make believe above life its promise that life isars of the material realm [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.502 (perp=6.881, rec=0.123, cos=0.003), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] promise life make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.475 (perp=6.809, rec=0.111, cos=0.003), tot_loss_proj:2.264 [t=0.23s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
[ 450/2000] tot_loss=1.465 (perp=6.809, rec=0.102, cos=0.002), tot_loss_proj:2.263 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.459 (perp=6.809, rec=0.095, cos=0.002), tot_loss_proj:2.276 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.454 (perp=6.809, rec=0.090, cos=0.002), tot_loss_proj:2.265 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
[ 600/2000] tot_loss=1.440 (perp=6.809, rec=0.076, cos=0.002), tot_loss_proj:2.274 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.445 (perp=6.809, rec=0.081, cos=0.002), tot_loss_proj:2.271 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.443 (perp=6.809, rec=0.079, cos=0.002), tot_loss_proj:2.273 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
[ 750/2000] tot_loss=1.447 (perp=6.809, rec=0.084, cos=0.002), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.444 (perp=6.809, rec=0.080, cos=0.002), tot_loss_proj:2.278 [t=0.23s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.449 (perp=6.809, rec=0.085, cos=0.002), tot_loss_proj:2.276 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
[ 900/2000] tot_loss=1.445 (perp=6.809, rec=0.081, cos=0.002), tot_loss_proj:2.276 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.445 (perp=6.809, rec=0.081, cos=0.002), tot_loss_proj:2.275 [t=0.23s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[1000/2000] tot_loss=1.434 (perp=6.809, rec=0.070, cos=0.002), tot_loss_proj:2.278 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
[1050/2000] tot_loss=1.438 (perp=6.809, rec=0.074, cos=0.002), tot_loss_proj:2.277 [t=0.23s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[1100/2000] tot_loss=1.442 (perp=6.809, rec=0.078, cos=0.002), tot_loss_proj:2.278 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[1150/2000] tot_loss=1.447 (perp=6.809, rec=0.083, cos=0.002), tot_loss_proj:2.276 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
[1200/2000] tot_loss=1.444 (perp=6.809, rec=0.081, cos=0.002), tot_loss_proj:2.280 [t=0.22s]
prediction: ['[CLS] life promise make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[1250/2000] tot_loss=1.500 (perp=7.064, rec=0.085, cos=0.002), tot_loss_proj:2.165 [t=0.22s]
prediction: ['[CLS] life fireworks make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[1300/2000] tot_loss=1.495 (perp=7.064, rec=0.080, cos=0.002), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] life fireworks make believe above its promise that life isars of the material realm [SEP]']
[1350/2000] tot_loss=1.498 (perp=7.064, rec=0.084, cos=0.002), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] life fireworks make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[1400/2000] tot_loss=1.494 (perp=7.064, rec=0.079, cos=0.002), tot_loss_proj:2.159 [t=0.22s]
prediction: ['[CLS] life fireworks make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[1450/2000] tot_loss=1.488 (perp=7.064, rec=0.073, cos=0.002), tot_loss_proj:2.162 [t=0.24s]
prediction: ['[CLS] life fireworks make believe above its promise that life isars of the material realm [SEP]']
[1500/2000] tot_loss=1.488 (perp=7.064, rec=0.074, cos=0.002), tot_loss_proj:2.165 [t=0.24s]
prediction: ['[CLS] life fireworks make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[1550/2000] tot_loss=1.491 (perp=7.064, rec=0.077, cos=0.002), tot_loss_proj:2.162 [t=0.24s]
prediction: ['[CLS] life fireworks make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
[1600/2000] tot_loss=1.492 (perp=7.064, rec=0.077, cos=0.002), tot_loss_proj:2.168 [t=0.24s]
prediction: ['[CLS] life fireworks make believe above its promise that life isars of the material realm [SEP]']
[1650/2000] tot_loss=1.489 (perp=7.064, rec=0.074, cos=0.002), tot_loss_proj:2.168 [t=0.24s]
prediction: ['[CLS] life fireworks make believe above its promise that life isars of the material realm [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.411 (perp=6.615, rec=0.086, cos=0.002), tot_loss_proj:2.179 [t=0.24s]
prediction: ['[CLS] fortune make believe life above its promise that life isars of the material realm [SEP]']
Attempt swap
[1750/2000] tot_loss=1.408 (perp=6.615, rec=0.083, cos=0.002), tot_loss_proj:2.180 [t=0.24s]
prediction: ['[CLS] fortune make believe life above its promise that life isars of the material realm [SEP]']
[1800/2000] tot_loss=1.413 (perp=6.615, rec=0.088, cos=0.002), tot_loss_proj:2.182 [t=0.24s]
prediction: ['[CLS] fortune make believe life above its promise that life isars of the material realm [SEP]']
Attempt swap
[1850/2000] tot_loss=1.412 (perp=6.615, rec=0.087, cos=0.002), tot_loss_proj:2.179 [t=0.24s]
prediction: ['[CLS] fortune make believe life above its promise that life isars of the material realm [SEP]']
Attempt swap
[1900/2000] tot_loss=1.395 (perp=6.615, rec=0.070, cos=0.002), tot_loss_proj:2.174 [t=0.24s]
prediction: ['[CLS] fortune make believe life above its promise that life isars of the material realm [SEP]']
[1950/2000] tot_loss=1.406 (perp=6.615, rec=0.082, cos=0.002), tot_loss_proj:2.174 [t=0.24s]
prediction: ['[CLS] fortune make believe life above its promise that life isars of the material realm [SEP]']
Attempt swap
[2000/2000] tot_loss=1.405 (perp=6.615, rec=0.080, cos=0.002), tot_loss_proj:2.176 [t=0.24s]
prediction: ['[CLS] fortune make believe life above its promise that life isars of the material realm [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] fortune make believe life above its promise that life isars of the material realm [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.871 | p: 81.250 | r: 86.667
rouge2     | fm: 27.586 | p: 26.667 | r: 28.571
rougeL     | fm: 58.065 | p: 56.250 | r: 60.000
rougeLsum  | fm: 58.065 | p: 56.250 | r: 60.000
r1fm+r2fm = 111.457

[Aggregate metrics]:
rouge1     | fm: 92.134 | p: 91.701 | r: 92.653
rouge2     | fm: 59.889 | p: 59.654 | r: 60.231
rougeL     | fm: 79.532 | p: 79.231 | r: 79.894
rougeLsum  | fm: 79.386 | p: 79.078 | r: 79.784
r1fm+r2fm = 152.023

input #77 time: 0:09:01 | total time: 11:57:38


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9992701713024241
highest_index [0]
highest [0.9992701713024241]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9870139360427856 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9769070744514465 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8536514043807983 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8296306133270264 for ['[CLS] le screens grant [SEP]']
[Init] best rec loss: 0.8287628889083862 for ['[CLS] lightatics help [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.052 (perp=9.115, rec=0.218, cos=0.012), tot_loss_proj:2.820 [t=0.23s]
prediction: ['[CLS] exit theater theater [SEP]']
[ 100/2000] tot_loss=1.673 (perp=7.958, rec=0.079, cos=0.002), tot_loss_proj:1.679 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[ 150/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.690 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[ 200/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.683 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=1.664 (perp=7.958, rec=0.071, cos=0.001), tot_loss_proj:1.682 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.681 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.655 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.675 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.655 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.671 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.671 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.641 (perp=7.958, rec=0.048, cos=0.001), tot_loss_proj:1.671 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.667 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.672 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.640 (perp=7.958, rec=0.047, cos=0.001), tot_loss_proj:1.673 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.685 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.679 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.640 (perp=7.958, rec=0.047, cos=0.001), tot_loss_proj:1.667 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.646 (perp=7.958, rec=0.053, cos=0.001), tot_loss_proj:1.672 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.685 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.658 (perp=7.958, rec=0.065, cos=0.001), tot_loss_proj:1.670 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.643 (perp=7.958, rec=0.050, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.651 (perp=7.958, rec=0.058, cos=0.001), tot_loss_proj:1.671 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.654 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.687 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.680 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.673 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.674 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.648 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.653 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.661 (perp=7.958, rec=0.068, cos=0.001), tot_loss_proj:1.670 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.648 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.672 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.672 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.663 (perp=7.958, rec=0.070, cos=0.001), tot_loss_proj:1.666 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.673 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.648 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.678 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.667 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.675 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.663 (perp=7.958, rec=0.070, cos=0.001), tot_loss_proj:1.677 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.238 | p: 91.872 | r: 92.804
rouge2     | fm: 60.555 | p: 60.322 | r: 60.854
rougeL     | fm: 79.699 | p: 79.419 | r: 80.068
rougeLsum  | fm: 79.693 | p: 79.397 | r: 80.109
r1fm+r2fm = 152.793

input #78 time: 0:09:17 | total time: 12:06:55


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.999333502749002
highest_index [0]
highest [0.999333502749002]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9713650941848755 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.8481886982917786 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.8465403318405151 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.8365461826324463 for ['[CLS] funslow [SEP]']
[Init] best rec loss: 0.8340138792991638 for ['[CLS] gray should [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.018 (perp=9.381, rec=0.139, cos=0.003), tot_loss_proj:1.963 [t=0.23s]
prediction: ['[CLS] is fascinating [SEP]']
[ 100/2000] tot_loss=1.957 (perp=9.381, rec=0.079, cos=0.001), tot_loss_proj:1.962 [t=0.24s]
prediction: ['[CLS] is fascinating [SEP]']
[ 150/2000] tot_loss=1.943 (perp=9.381, rec=0.065, cos=0.001), tot_loss_proj:1.965 [t=0.24s]
prediction: ['[CLS] is fascinating [SEP]']
[ 200/2000] tot_loss=1.940 (perp=9.381, rec=0.063, cos=0.001), tot_loss_proj:1.943 [t=0.24s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.836 (perp=8.695, rec=0.094, cos=0.002), tot_loss_proj:1.956 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.790 (perp=8.695, rec=0.050, cos=0.001), tot_loss_proj:1.956 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.809 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.957 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.808 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.957 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.957 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.958 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.789 (perp=8.695, rec=0.049, cos=0.001), tot_loss_proj:1.962 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.950 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.953 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.952 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.967 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.809 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.956 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.959 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.803 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.953 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.800 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.962 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.806 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.958 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.956 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.955 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.808 (perp=8.695, rec=0.068, cos=0.001), tot_loss_proj:1.957 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.807 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.961 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.800 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.800 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.952 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.958 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.807 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.950 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.798 (perp=8.695, rec=0.057, cos=0.001), tot_loss_proj:1.955 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.963 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.793 (perp=8.695, rec=0.052, cos=0.001), tot_loss_proj:1.959 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.816 (perp=8.695, rec=0.076, cos=0.001), tot_loss_proj:1.952 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.948 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.959 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.811 (perp=8.695, rec=0.071, cos=0.001), tot_loss_proj:1.961 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.959 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.950 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.955 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.963 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] is fascinating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.305 | p: 91.949 | r: 92.863
rouge2     | fm: 61.121 | p: 60.851 | r: 61.427
rougeL     | fm: 79.854 | p: 79.595 | r: 80.220
rougeLsum  | fm: 79.863 | p: 79.569 | r: 80.249
r1fm+r2fm = 153.426

input #79 time: 0:09:07 | total time: 12:16:03


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9992804445056542
highest_index [0]
highest [0.9992804445056542]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9627042412757874 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9625917673110962 for ['[CLS]sol floor stand now district [SEP]']
[Init] best rec loss: 0.9617151618003845 for ['[CLS]yna snaps california mussolini kicked [SEP]']
[Init] best rec loss: 0.940487802028656 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.929239809513092 for ['[CLS]down frasercake court beta [SEP]']
[Init] best rec loss: 0.9261685013771057 for ['[CLS] western area whilepres took [SEP]']
[Init] best rec loss: 0.9155707359313965 for ["[CLS]'incense kraft it jubilee [SEP]"]
[Init] best perm rec loss: 0.9146585464477539 for ["[CLS] jubilee it'kraft incense [SEP]"]
[Init] best perm rec loss: 0.9138307571411133 for ["[CLS] jubilee it incense'kraft [SEP]"]
[Init] best perm rec loss: 0.9125903844833374 for ["[CLS] it'incense jubilee kraft [SEP]"]
[Init] best perm rec loss: 0.912357747554779 for ["[CLS] it kraft'jubilee incense [SEP]"]
[Init] best perm rec loss: 0.9113789796829224 for ["[CLS] it kraft incense jubilee'[SEP]"]
[Init] best perm rec loss: 0.9109885096549988 for ["[CLS] it jubilee kraft incense'[SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.733 (perp=12.318, rec=0.263, cos=0.006), tot_loss_proj:3.381 [t=0.23s]
prediction: ['[CLS] wise jeff miles divelay [SEP]']
[ 100/2000] tot_loss=1.928 (perp=8.728, rec=0.179, cos=0.003), tot_loss_proj:2.931 [t=0.23s]
prediction: ['[CLS] wisey ;zened [SEP]']
[ 150/2000] tot_loss=2.110 (perp=9.861, rec=0.135, cos=0.003), tot_loss_proj:2.568 [t=0.23s]
prediction: ['[CLS] wise,edzened [SEP]']
[ 200/2000] tot_loss=2.097 (perp=9.861, rec=0.123, cos=0.003), tot_loss_proj:2.564 [t=0.23s]
prediction: ['[CLS] wise,edzened [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.909 (perp=8.719, rec=0.161, cos=0.004), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] wise, wizen dickens [SEP]']
[ 300/2000] tot_loss=2.239 (perp=10.522, rec=0.132, cos=0.003), tot_loss_proj:2.781 [t=0.22s]
prediction: ['[CLS] wise, wizenend [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.142 (perp=10.029, rec=0.134, cos=0.003), tot_loss_proj:2.769 [t=0.22s]
prediction: ['[CLS]is wise! wizen [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.571 (perp=7.294, rec=0.110, cos=0.003), tot_loss_proj:1.829 [t=0.22s]
prediction: ['[CLS] wizened wise - [SEP]']
[ 450/2000] tot_loss=1.402 (perp=6.463, rec=0.107, cos=0.003), tot_loss_proj:1.509 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.412 (perp=6.463, rec=0.117, cos=0.002), tot_loss_proj:1.518 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.394 (perp=6.463, rec=0.099, cos=0.002), tot_loss_proj:1.518 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[ 600/2000] tot_loss=1.404 (perp=6.463, rec=0.109, cos=0.002), tot_loss_proj:1.521 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.405 (perp=6.463, rec=0.109, cos=0.002), tot_loss_proj:1.520 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.392 (perp=6.463, rec=0.096, cos=0.002), tot_loss_proj:1.526 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[ 750/2000] tot_loss=1.403 (perp=6.463, rec=0.108, cos=0.002), tot_loss_proj:1.525 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.402 (perp=6.463, rec=0.107, cos=0.002), tot_loss_proj:1.505 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.391 (perp=6.463, rec=0.096, cos=0.002), tot_loss_proj:1.512 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[ 900/2000] tot_loss=1.403 (perp=6.463, rec=0.108, cos=0.002), tot_loss_proj:1.530 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.413 (perp=6.463, rec=0.118, cos=0.002), tot_loss_proj:1.515 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.401 (perp=6.463, rec=0.106, cos=0.002), tot_loss_proj:1.520 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[1050/2000] tot_loss=1.405 (perp=6.463, rec=0.110, cos=0.002), tot_loss_proj:1.519 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.394 (perp=6.463, rec=0.098, cos=0.002), tot_loss_proj:1.508 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.401 (perp=6.463, rec=0.106, cos=0.002), tot_loss_proj:1.512 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[1200/2000] tot_loss=1.394 (perp=6.463, rec=0.098, cos=0.003), tot_loss_proj:1.510 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.401 (perp=6.463, rec=0.106, cos=0.002), tot_loss_proj:1.512 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.400 (perp=6.463, rec=0.105, cos=0.002), tot_loss_proj:1.512 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
[1350/2000] tot_loss=1.403 (perp=6.463, rec=0.108, cos=0.002), tot_loss_proj:1.513 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.401 (perp=6.463, rec=0.106, cos=0.002), tot_loss_proj:1.515 [t=0.22s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.393 (perp=6.463, rec=0.098, cos=0.002), tot_loss_proj:1.517 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
[1500/2000] tot_loss=1.389 (perp=6.463, rec=0.094, cos=0.002), tot_loss_proj:1.512 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.395 (perp=6.463, rec=0.100, cos=0.002), tot_loss_proj:1.520 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.400 (perp=6.463, rec=0.105, cos=0.002), tot_loss_proj:1.517 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
[1650/2000] tot_loss=1.405 (perp=6.463, rec=0.110, cos=0.002), tot_loss_proj:1.524 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.389 (perp=6.463, rec=0.094, cos=0.002), tot_loss_proj:1.517 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.400 (perp=6.463, rec=0.105, cos=0.002), tot_loss_proj:1.514 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
[1800/2000] tot_loss=1.392 (perp=6.463, rec=0.097, cos=0.002), tot_loss_proj:1.509 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.396 (perp=6.463, rec=0.101, cos=0.002), tot_loss_proj:1.516 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.388 (perp=6.463, rec=0.093, cos=0.002), tot_loss_proj:1.511 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
[1950/2000] tot_loss=1.409 (perp=6.463, rec=0.114, cos=0.002), tot_loss_proj:1.520 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.397 (perp=6.463, rec=0.102, cos=0.002), tot_loss_proj:1.518 [t=0.23s]
prediction: ['[CLS] wizened wise, [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wizened wise, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.415 | p: 92.002 | r: 92.981
rouge2     | fm: 60.215 | p: 59.967 | r: 60.500
rougeL     | fm: 79.800 | p: 79.577 | r: 80.176
rougeLsum  | fm: 79.892 | p: 79.583 | r: 80.211
r1fm+r2fm = 152.629

input #80 time: 0:08:55 | total time: 12:24:59


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9992872482218231
highest_index [0]
highest [0.9992872482218231]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9009989500045776 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.8568158745765686 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8462851047515869 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8266099095344543 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.8195542097091675 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.8106294274330139 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 0.7963440418243408 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 0.7945745587348938 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best rec loss: 0.7920742630958557 for ['[CLS] crawl taken grind choice azerbaijan potter [SEP]']
[Init] best perm rec loss: 0.7888742089271545 for ['[CLS] taken choice grind azerbaijan crawl potter [SEP]']
[Init] best perm rec loss: 0.7881178259849548 for ['[CLS] crawl choice potter azerbaijan taken grind [SEP]']
[Init] best perm rec loss: 0.7879045009613037 for ['[CLS] grind crawl taken choice azerbaijan potter [SEP]']
[Init] best perm rec loss: 0.7871419191360474 for ['[CLS] potter crawl taken choice azerbaijan grind [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.644 (perp=11.143, rec=0.363, cos=0.053), tot_loss_proj:3.939 [t=0.23s]
prediction: ['[CLS] is drinking never an representatives criminal [SEP]']
[ 100/2000] tot_loss=2.451 (perp=10.809, rec=0.264, cos=0.025), tot_loss_proj:3.055 [t=0.24s]
prediction: ['[CLS] is beer not most player impressive [SEP]']
[ 150/2000] tot_loss=2.140 (perp=9.833, rec=0.165, cos=0.008), tot_loss_proj:3.564 [t=0.24s]
prediction: ['[CLS] is impressive not most player impressive [SEP]']
[ 200/2000] tot_loss=2.119 (perp=9.833, rec=0.145, cos=0.007), tot_loss_proj:3.569 [t=0.24s]
prediction: ['[CLS] is impressive not most player impressive [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.751 (perp=8.170, rec=0.111, cos=0.006), tot_loss_proj:3.127 [t=0.24s]
prediction: ['[CLS] is impressive not most impressive player [SEP]']
[ 300/2000] tot_loss=1.738 (perp=8.170, rec=0.099, cos=0.005), tot_loss_proj:3.123 [t=0.24s]
prediction: ['[CLS] is impressive not most impressive player [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.681 (perp=7.898, rec=0.097, cos=0.005), tot_loss_proj:2.151 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.676 (perp=7.898, rec=0.092, cos=0.004), tot_loss_proj:2.154 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
[ 450/2000] tot_loss=1.672 (perp=7.898, rec=0.088, cos=0.004), tot_loss_proj:2.152 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.680 (perp=7.898, rec=0.096, cos=0.004), tot_loss_proj:2.162 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.666 (perp=7.898, rec=0.082, cos=0.004), tot_loss_proj:2.152 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
[ 600/2000] tot_loss=1.670 (perp=7.898, rec=0.087, cos=0.004), tot_loss_proj:2.164 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.685 (perp=7.898, rec=0.101, cos=0.004), tot_loss_proj:2.154 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.676 (perp=7.898, rec=0.092, cos=0.004), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
[ 750/2000] tot_loss=1.666 (perp=7.898, rec=0.082, cos=0.004), tot_loss_proj:2.162 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.665 (perp=7.898, rec=0.082, cos=0.004), tot_loss_proj:2.158 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.675 (perp=7.898, rec=0.091, cos=0.004), tot_loss_proj:2.152 [t=0.23s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
[ 900/2000] tot_loss=1.660 (perp=7.898, rec=0.077, cos=0.004), tot_loss_proj:2.163 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.665 (perp=7.898, rec=0.082, cos=0.004), tot_loss_proj:2.156 [t=0.23s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.681 (perp=7.898, rec=0.097, cos=0.004), tot_loss_proj:2.149 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
[1050/2000] tot_loss=1.662 (perp=7.898, rec=0.079, cos=0.004), tot_loss_proj:2.160 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.673 (perp=7.898, rec=0.089, cos=0.004), tot_loss_proj:2.159 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.668 (perp=7.898, rec=0.084, cos=0.004), tot_loss_proj:2.158 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
[1200/2000] tot_loss=1.659 (perp=7.898, rec=0.075, cos=0.004), tot_loss_proj:2.157 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.672 (perp=7.898, rec=0.088, cos=0.004), tot_loss_proj:2.154 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.667 (perp=7.898, rec=0.084, cos=0.004), tot_loss_proj:2.157 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
[1350/2000] tot_loss=1.673 (perp=7.898, rec=0.089, cos=0.004), tot_loss_proj:2.156 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.662 (perp=7.898, rec=0.079, cos=0.004), tot_loss_proj:2.157 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.665 (perp=7.898, rec=0.082, cos=0.004), tot_loss_proj:2.161 [t=0.22s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
[1500/2000] tot_loss=1.674 (perp=7.898, rec=0.090, cos=0.004), tot_loss_proj:2.158 [t=0.22s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.665 (perp=7.898, rec=0.081, cos=0.004), tot_loss_proj:2.159 [t=0.22s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.673 (perp=7.898, rec=0.089, cos=0.004), tot_loss_proj:2.150 [t=0.22s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
[1650/2000] tot_loss=1.668 (perp=7.898, rec=0.085, cos=0.004), tot_loss_proj:2.156 [t=0.22s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.668 (perp=7.898, rec=0.084, cos=0.004), tot_loss_proj:2.161 [t=0.22s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.674 (perp=7.898, rec=0.091, cos=0.004), tot_loss_proj:2.152 [t=0.23s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
[1800/2000] tot_loss=1.659 (perp=7.898, rec=0.075, cos=0.004), tot_loss_proj:2.155 [t=0.24s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.675 (perp=7.898, rec=0.091, cos=0.004), tot_loss_proj:2.156 [t=0.23s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.673 (perp=7.898, rec=0.090, cos=0.004), tot_loss_proj:2.157 [t=0.23s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
[1950/2000] tot_loss=1.670 (perp=7.898, rec=0.087, cos=0.004), tot_loss_proj:2.154 [t=0.23s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.666 (perp=7.898, rec=0.082, cos=0.004), tot_loss_proj:2.154 [t=0.23s]
prediction: ['[CLS] is not impressive most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not impressive most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 71.429 | p: 71.429 | r: 71.429
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 158.929

[Aggregate metrics]:
rouge1     | fm: 92.402 | p: 91.983 | r: 92.891
rouge2     | fm: 60.250 | p: 60.056 | r: 60.520
rougeL     | fm: 79.913 | p: 79.665 | r: 80.284
rougeLsum  | fm: 79.979 | p: 79.711 | r: 80.305
r1fm+r2fm = 152.652

input #81 time: 0:09:14 | total time: 12:34:13


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.999280197064362
highest_index [0]
highest [0.999280197064362]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9871094822883606 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9780022501945496 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.9488106966018677 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9384766817092896 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9379804730415344 for ['[CLS] provided yards master cases risky wickets aboveflict [SEP]']
[Init] best rec loss: 0.9337881207466125 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 0.8673442602157593 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.826836884021759 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8214476704597473 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8205435276031494 for ['[CLS]furbasket respectiveach role record plumage whoever [SEP]']
[Init] best perm rec loss: 0.819252073764801 for ['[CLS]basket respective whoeverach record rolefur plumage [SEP]']
[Init] best perm rec loss: 0.8188300728797913 for ['[CLS]achbasket whoeverfur record respective plumage role [SEP]']
[Init] best perm rec loss: 0.8187480568885803 for ['[CLS] whoeverbasketfurach respective plumage role record [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.251 (perp=10.203, rec=0.203, cos=0.007), tot_loss_proj:2.799 [t=0.23s]
prediction: ['[CLS] a sloppy sloppy undone its sloppy script undone [SEP]']
[ 100/2000] tot_loss=2.052 (perp=9.686, rec=0.113, cos=0.002), tot_loss_proj:2.455 [t=0.23s]
prediction: ['[CLS] a sloppy sloppy undone by sloppy script undone [SEP]']
[ 150/2000] tot_loss=1.950 (perp=9.312, rec=0.086, cos=0.002), tot_loss_proj:2.343 [t=0.23s]
prediction: ["[CLS] s sloppy'undone by sloppy script undone [SEP]"]
[ 200/2000] tot_loss=1.969 (perp=9.450, rec=0.077, cos=0.002), tot_loss_proj:2.400 [t=0.23s]
prediction: ['[CLS] s sloppy it undone by sloppy script undone [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.794 (perp=8.631, rec=0.066, cos=0.002), tot_loss_proj:2.082 [t=0.23s]
prediction: ['[CLS] s sloppy it undone by a undone script [SEP]']
[ 300/2000] tot_loss=1.792 (perp=8.631, rec=0.065, cos=0.002), tot_loss_proj:2.083 [t=0.23s]
prediction: ['[CLS] s sloppy it undone by a undone script [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.786 (perp=8.631, rec=0.058, cos=0.002), tot_loss_proj:2.081 [t=0.23s]
prediction: ['[CLS] s sloppy it undone by a undone script [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.784 (perp=8.561, rec=0.070, cos=0.002), tot_loss_proj:2.089 [t=0.23s]
prediction: ['[CLS] it sloppy s undone by a undone script [SEP]']
[ 450/2000] tot_loss=1.769 (perp=8.561, rec=0.056, cos=0.002), tot_loss_proj:2.094 [t=0.23s]
prediction: ['[CLS] it sloppy s undone by a undone script [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.602 (perp=7.681, rec=0.065, cos=0.001), tot_loss_proj:1.778 [t=0.23s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.601 (perp=7.681, rec=0.063, cos=0.001), tot_loss_proj:1.779 [t=0.23s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
[ 600/2000] tot_loss=1.601 (perp=7.681, rec=0.063, cos=0.001), tot_loss_proj:1.770 [t=0.23s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.598 (perp=7.681, rec=0.061, cos=0.001), tot_loss_proj:1.771 [t=0.23s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.601 (perp=7.681, rec=0.064, cos=0.001), tot_loss_proj:1.763 [t=0.24s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
[ 750/2000] tot_loss=1.819 (perp=8.768, rec=0.064, cos=0.001), tot_loss_proj:2.038 [t=0.24s]
prediction: ['[CLS] it undone s ী by a sloppy script [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.196 (perp=5.694, rec=0.056, cos=0.001), tot_loss_proj:1.235 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.196 (perp=5.694, rec=0.056, cos=0.001), tot_loss_proj:1.227 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[ 900/2000] tot_loss=1.203 (perp=5.694, rec=0.063, cos=0.001), tot_loss_proj:1.230 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.194 (perp=5.694, rec=0.054, cos=0.001), tot_loss_proj:1.225 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.197 (perp=5.694, rec=0.057, cos=0.001), tot_loss_proj:1.225 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1050/2000] tot_loss=1.204 (perp=5.694, rec=0.064, cos=0.001), tot_loss_proj:1.231 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.204 (perp=5.694, rec=0.064, cos=0.001), tot_loss_proj:1.216 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.194 (perp=5.694, rec=0.054, cos=0.001), tot_loss_proj:1.232 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1200/2000] tot_loss=1.202 (perp=5.694, rec=0.062, cos=0.001), tot_loss_proj:1.228 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.195 (perp=5.694, rec=0.055, cos=0.001), tot_loss_proj:1.227 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.198 (perp=5.694, rec=0.057, cos=0.001), tot_loss_proj:1.235 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1350/2000] tot_loss=1.199 (perp=5.694, rec=0.059, cos=0.001), tot_loss_proj:1.223 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.199 (perp=5.694, rec=0.058, cos=0.001), tot_loss_proj:1.236 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.200 (perp=5.694, rec=0.060, cos=0.001), tot_loss_proj:1.225 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1500/2000] tot_loss=1.200 (perp=5.694, rec=0.060, cos=0.001), tot_loss_proj:1.219 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.197 (perp=5.694, rec=0.056, cos=0.001), tot_loss_proj:1.243 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.193 (perp=5.694, rec=0.053, cos=0.001), tot_loss_proj:1.222 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1650/2000] tot_loss=1.208 (perp=5.694, rec=0.068, cos=0.001), tot_loss_proj:1.218 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.198 (perp=5.694, rec=0.058, cos=0.001), tot_loss_proj:1.229 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.203 (perp=5.694, rec=0.063, cos=0.001), tot_loss_proj:1.217 [t=0.23s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1800/2000] tot_loss=1.202 (perp=5.694, rec=0.062, cos=0.001), tot_loss_proj:1.227 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.205 (perp=5.694, rec=0.065, cos=0.001), tot_loss_proj:1.229 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.202 (perp=5.694, rec=0.062, cos=0.001), tot_loss_proj:1.233 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1950/2000] tot_loss=1.204 (perp=5.694, rec=0.063, cos=0.001), tot_loss_proj:1.225 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.203 (perp=5.694, rec=0.063, cos=0.001), tot_loss_proj:1.221 [t=0.24s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.479 | p: 92.111 | r: 92.985
rouge2     | fm: 60.925 | p: 60.713 | r: 61.211
rougeL     | fm: 80.156 | p: 79.944 | r: 80.529
rougeLsum  | fm: 80.234 | p: 79.924 | r: 80.606
r1fm+r2fm = 153.403

input #82 time: 0:09:16 | total time: 12:43:30


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9992437339704883
highest_index [0]
highest [0.9992437339704883]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.9575920701026917 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.9534390568733215 for ['[CLS] consisting hartley lives champions forgotten johnson account integeronal merge [SEP]']
[Init] best rec loss: 0.9510172605514526 for ['[CLS] ben tawork position naked map because sort been season [SEP]']
[Init] best rec loss: 0.9441697001457214 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.8845860362052917 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 0.8710569739341736 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8709710240364075 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.8656304478645325 for ['[CLS] original review giggled field floor arid read beckett cecil i [SEP]']
[Init] best rec loss: 0.8608826398849487 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.8563296794891357 for ['[CLS] ut sighed another tex predicted hooper alsoов toes personally [SEP]']
[Init] best rec loss: 0.8355855941772461 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best rec loss: 0.8123910427093506 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.8044590353965759 for ['[CLS] nearly pitch residence vice stew follows comprehensive neck boys envelope [SEP]']
[Init] best perm rec loss: 0.8041741251945496 for ['[CLS] residence neck follows nearly stew pitch boys comprehensive vice envelope [SEP]']
[Init] best perm rec loss: 0.8038275837898254 for ['[CLS] nearly pitch vice boys neck residence envelope comprehensive follows stew [SEP]']
[Init] best perm rec loss: 0.8033164143562317 for ['[CLS] stew nearly boys follows neck pitch comprehensive vice residence envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.716 (perp=11.465, rec=0.376, cos=0.048), tot_loss_proj:3.579 [t=0.23s]
prediction: ['[CLS] protection care. david originated growth what. including 2016 [SEP]']
[ 100/2000] tot_loss=2.457 (perp=10.868, rec=0.266, cos=0.017), tot_loss_proj:3.799 [t=0.24s]
prediction: ['[CLS] protection know when production originated grown when. wants everywhere [SEP]']
[ 150/2000] tot_loss=2.069 (perp=9.346, rec=0.194, cos=0.006), tot_loss_proj:3.016 [t=0.24s]
prediction: ['[CLS] protection know what its be when when. wants grows [SEP]']
[ 200/2000] tot_loss=1.802 (perp=8.300, rec=0.139, cos=0.003), tot_loss_proj:2.765 [t=0.24s]
prediction: ['[CLS] it know what it be when grow i wants be [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.759 (perp=8.148, rec=0.126, cos=0.003), tot_loss_proj:2.474 [t=0.24s]
prediction: ['[CLS] know what it be when grows it wants be it [SEP]']
[ 300/2000] tot_loss=1.824 (perp=8.663, rec=0.090, cos=0.002), tot_loss_proj:2.419 [t=0.24s]
prediction: ['[CLS] know what it be when grows it wants up up [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.566 (perp=7.386, rec=0.087, cos=0.002), tot_loss_proj:1.999 [t=0.24s]
prediction: ['[CLS] know what it be when grows up wants it up [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.432 (perp=6.709, rec=0.089, cos=0.002), tot_loss_proj:1.730 [t=0.24s]
prediction: ['[CLS] know what it wants be when grows up it up [SEP]']
[ 450/2000] tot_loss=1.419 (perp=6.709, rec=0.076, cos=0.001), tot_loss_proj:1.727 [t=0.24s]
prediction: ['[CLS] know what it wants be when grows up it up [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.300 (perp=6.129, rec=0.073, cos=0.001), tot_loss_proj:1.503 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.299 (perp=6.129, rec=0.072, cos=0.001), tot_loss_proj:1.501 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
[ 600/2000] tot_loss=1.292 (perp=6.129, rec=0.065, cos=0.001), tot_loss_proj:1.487 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.296 (perp=6.129, rec=0.069, cos=0.001), tot_loss_proj:1.494 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.288 (perp=6.129, rec=0.060, cos=0.001), tot_loss_proj:1.488 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
[ 750/2000] tot_loss=1.298 (perp=6.129, rec=0.070, cos=0.001), tot_loss_proj:1.492 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.292 (perp=6.129, rec=0.065, cos=0.001), tot_loss_proj:1.494 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.295 (perp=6.129, rec=0.068, cos=0.001), tot_loss_proj:1.491 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
[ 900/2000] tot_loss=1.200 (perp=5.677, rec=0.063, cos=0.001), tot_loss_proj:1.431 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up to [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.203 (perp=5.677, rec=0.066, cos=0.001), tot_loss_proj:1.424 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up to [SEP]']
Attempt swap
[1000/2000] tot_loss=1.205 (perp=5.677, rec=0.069, cos=0.001), tot_loss_proj:1.423 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up to [SEP]']
[1050/2000] tot_loss=1.204 (perp=5.677, rec=0.068, cos=0.001), tot_loss_proj:1.430 [t=0.24s]
prediction: ['[CLS] know what it wants be when it grows up to [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.012 (perp=4.691, rec=0.072, cos=0.002), tot_loss_proj:1.070 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=0.999 (perp=4.691, rec=0.059, cos=0.002), tot_loss_proj:1.079 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1200/2000] tot_loss=1.009 (perp=4.691, rec=0.069, cos=0.001), tot_loss_proj:1.073 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.011 (perp=4.691, rec=0.071, cos=0.001), tot_loss_proj:1.065 [t=0.23s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.004 (perp=4.691, rec=0.064, cos=0.001), tot_loss_proj:1.069 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1350/2000] tot_loss=1.003 (perp=4.691, rec=0.063, cos=0.001), tot_loss_proj:1.069 [t=0.23s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.002 (perp=4.691, rec=0.062, cos=0.001), tot_loss_proj:1.060 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.004 (perp=4.691, rec=0.064, cos=0.001), tot_loss_proj:1.071 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1500/2000] tot_loss=1.003 (perp=4.691, rec=0.063, cos=0.001), tot_loss_proj:1.069 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=0.999 (perp=4.691, rec=0.060, cos=0.001), tot_loss_proj:1.067 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.011 (perp=4.691, rec=0.072, cos=0.001), tot_loss_proj:1.076 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1650/2000] tot_loss=0.997 (perp=4.691, rec=0.057, cos=0.001), tot_loss_proj:1.073 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.000 (perp=4.691, rec=0.060, cos=0.001), tot_loss_proj:1.067 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.004 (perp=4.691, rec=0.064, cos=0.001), tot_loss_proj:1.067 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1800/2000] tot_loss=1.008 (perp=4.691, rec=0.069, cos=0.001), tot_loss_proj:1.068 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.005 (perp=4.691, rec=0.065, cos=0.001), tot_loss_proj:1.065 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.006 (perp=4.691, rec=0.067, cos=0.001), tot_loss_proj:1.065 [t=0.23s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1950/2000] tot_loss=1.011 (perp=4.691, rec=0.071, cos=0.001), tot_loss_proj:1.063 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=0.996 (perp=4.691, rec=0.056, cos=0.001), tot_loss_proj:1.073 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.607 | p: 92.209 | r: 93.067
rouge2     | fm: 61.261 | p: 61.035 | r: 61.543
rougeL     | fm: 80.486 | p: 80.209 | r: 80.841
rougeLsum  | fm: 80.486 | p: 80.218 | r: 80.806
r1fm+r2fm = 153.868

input #83 time: 0:09:20 | total time: 12:52:50


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9991129649261612
highest_index [0]
highest [0.9991129649261612]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.927739679813385 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.9178661108016968 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 0.9015358686447144 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8932105898857117 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 0.8898106813430786 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.8857002258300781 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 0.8841055631637573 for ['[CLS]oglaise catholicur prototype issues cheered [SEP]']
[Init] best rec loss: 0.8625176548957825 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 0.8600064516067505 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best perm rec loss: 0.8589123487472534 for ['[CLS] caused infinite ca each goingiter its [SEP]']
[Init] best perm rec loss: 0.8584563136100769 for ['[CLS] going infiniteiter caused each its ca [SEP]']
[Init] best perm rec loss: 0.8573440313339233 for ['[CLS] going each caused its ca infiniteiter [SEP]']
[Init] best perm rec loss: 0.8568987250328064 for ['[CLS] its going infinite ca caused eachiter [SEP]']
[Init] best perm rec loss: 0.8566478490829468 for ['[CLS] caiter going its caused each infinite [SEP]']
[Init] best perm rec loss: 0.8562791347503662 for ['[CLS] ca going infinite its caused eachiter [SEP]']
[Init] best perm rec loss: 0.8562309145927429 for ['[CLS] eachiter going infinite caused ca its [SEP]']
[Init] best perm rec loss: 0.8557958602905273 for ['[CLS]iter infinite each its caused going ca [SEP]']
[Init] best perm rec loss: 0.8551145195960999 for ['[CLS]iter going ca its infinite caused each [SEP]']
[Init] best perm rec loss: 0.8549153208732605 for ['[CLS] going ca caused each itsiter infinite [SEP]']
[Init] best perm rec loss: 0.8547622561454773 for ['[CLS]iter infinite its ca each going caused [SEP]']
[Init] best perm rec loss: 0.8544797897338867 for ['[CLS] causediter infinite its ca going each [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.237 (perp=9.643, rec=0.287, cos=0.021), tot_loss_proj:2.642 [t=0.23s]
prediction: ['[CLS] kid lost ability lost lost people ability [SEP]']
[ 100/2000] tot_loss=2.087 (perp=9.642, rec=0.152, cos=0.007), tot_loss_proj:2.468 [t=0.23s]
prediction: ['[CLS] have lost people lost have think ability [SEP]']
[ 150/2000] tot_loss=2.113 (perp=10.054, rec=0.099, cos=0.003), tot_loss_proj:2.661 [t=0.24s]
prediction: ['[CLS] people lost people having have think ability [SEP]']
[ 200/2000] tot_loss=2.086 (perp=9.978, rec=0.088, cos=0.002), tot_loss_proj:2.684 [t=0.23s]
prediction: ['[CLS] people lost people the have think ability [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.684 (perp=7.962, rec=0.090, cos=0.002), tot_loss_proj:2.895 [t=0.23s]
prediction: ['[CLS] people lost people think have the ability [SEP]']
[ 300/2000] tot_loss=1.701 (perp=8.142, rec=0.071, cos=0.002), tot_loss_proj:3.136 [t=0.24s]
prediction: ['[CLS] to lost people think have the ability [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.477 (perp=7.054, rec=0.065, cos=0.002), tot_loss_proj:2.364 [t=0.23s]
prediction: ['[CLS] to people think have lost the ability [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.181 (perp=5.494, rec=0.079, cos=0.002), tot_loss_proj:1.463 [t=0.23s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
[ 450/2000] tot_loss=1.166 (perp=5.494, rec=0.066, cos=0.002), tot_loss_proj:1.457 [t=0.23s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.179 (perp=5.494, rec=0.078, cos=0.002), tot_loss_proj:1.466 [t=0.23s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.060 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 600/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.054 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.061 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.013 (perp=4.681, rec=0.075, cos=0.002), tot_loss_proj:1.053 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 750/2000] tot_loss=1.003 (perp=4.681, rec=0.065, cos=0.002), tot_loss_proj:1.054 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.990 (perp=4.681, rec=0.052, cos=0.002), tot_loss_proj:1.057 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.057 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 900/2000] tot_loss=0.998 (perp=4.681, rec=0.060, cos=0.002), tot_loss_proj:1.054 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.003 (perp=4.681, rec=0.065, cos=0.002), tot_loss_proj:1.058 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.055 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1050/2000] tot_loss=1.004 (perp=4.681, rec=0.066, cos=0.002), tot_loss_proj:1.051 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.015 (perp=4.681, rec=0.077, cos=0.002), tot_loss_proj:1.047 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1150/2000] tot_loss=0.996 (perp=4.681, rec=0.058, cos=0.002), tot_loss_proj:1.053 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1200/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.054 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.003 (perp=4.681, rec=0.065, cos=0.002), tot_loss_proj:1.049 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.045 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.046 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=0.998 (perp=4.681, rec=0.060, cos=0.002), tot_loss_proj:1.051 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=0.989 (perp=4.681, rec=0.051, cos=0.002), tot_loss_proj:1.057 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.043 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=1.007 (perp=4.681, rec=0.069, cos=0.002), tot_loss_proj:1.050 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=0.992 (perp=4.681, rec=0.054, cos=0.002), tot_loss_proj:1.047 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=1.008 (perp=4.681, rec=0.070, cos=0.002), tot_loss_proj:1.057 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.003 (perp=4.681, rec=0.065, cos=0.002), tot_loss_proj:1.049 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=0.990 (perp=4.681, rec=0.052, cos=0.002), tot_loss_proj:1.057 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.059 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.051 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.057 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.053 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.050 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.672 | p: 92.293 | r: 93.165
rouge2     | fm: 61.801 | p: 61.592 | r: 62.033
rougeL     | fm: 80.601 | p: 80.303 | r: 80.932
rougeLsum  | fm: 80.654 | p: 80.381 | r: 81.034
r1fm+r2fm = 154.473

input #84 time: 0:09:17 | total time: 13:02:08


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9992370346205339
highest_index [0]
highest [0.9992370346205339]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9693423509597778 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.9537092447280884 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.9295451641082764 for ['[CLS] creek i instrumental bottomifnotes kensington military kowalski smoky [SEP]']
[Init] best rec loss: 0.8857548236846924 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8701900839805603 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best perm rec loss: 0.8665063977241516 for ['[CLS] indies backgroundleinthing road laps indianrman fallen defender [SEP]']
[Init] best perm rec loss: 0.8620833158493042 for ['[CLS]lein roadthing defender indianrman indies laps fallen background [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.903 (perp=7.979, rec=0.294, cos=0.013), tot_loss_proj:2.188 [t=0.23s]
prediction: ['[CLS] unfortunately unfortunately because. unfortunately not is unfortunately not good [SEP]']
[ 100/2000] tot_loss=1.695 (perp=7.654, rec=0.159, cos=0.005), tot_loss_proj:2.026 [t=0.24s]
prediction: ['[CLS] unfortunately unfortunately because. also also is necessarily not good [SEP]']
[ 150/2000] tot_loss=1.469 (perp=6.726, rec=0.121, cos=0.003), tot_loss_proj:1.832 [t=0.24s]
prediction: ['[CLS] unfortunately, it. also also very very not good [SEP]']
[ 200/2000] tot_loss=1.386 (perp=6.487, rec=0.087, cos=0.002), tot_loss_proj:1.725 [t=0.24s]
prediction: ['[CLS] unfortunately, it. s also very it not good [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.790 (perp=8.181, rec=0.149, cos=0.005), tot_loss_proj:2.387 [t=0.24s]
prediction: ['[CLS] unfortunately. harper s also very it not good. [SEP]']
[ 300/2000] tot_loss=1.490 (perp=7.012, rec=0.085, cos=0.003), tot_loss_proj:1.932 [t=0.24s]
prediction: ['[CLS] unfortunately, something s also very it not good. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.224 (perp=5.715, rec=0.078, cos=0.002), tot_loss_proj:1.570 [t=0.24s]
prediction: ['[CLS] unfortunately, something it also very s not good. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.189 (perp=5.292, rec=0.127, cos=0.004), tot_loss_proj:1.470 [t=0.24s]
prediction: ['[CLS] unfortunately, anymore it also s not very good. [SEP]']
[ 450/2000] tot_loss=1.154 (perp=5.292, rec=0.094, cos=0.002), tot_loss_proj:1.472 [t=0.24s]
prediction: ['[CLS] unfortunately, anymore it also s not very good. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.118 (perp=5.155, rec=0.085, cos=0.002), tot_loss_proj:1.448 [t=0.24s]
prediction: ['[CLS] unfortunately, it anymore also s not very good. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.069 (perp=4.864, rec=0.093, cos=0.002), tot_loss_proj:1.401 [t=0.24s]
prediction: ['[CLS] unfortunately anymore, it also s not very good. [SEP]']
[ 600/2000] tot_loss=1.058 (perp=4.864, rec=0.083, cos=0.002), tot_loss_proj:1.395 [t=0.24s]
prediction: ['[CLS] unfortunately anymore, it also s not very good. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.057 (perp=4.864, rec=0.082, cos=0.002), tot_loss_proj:1.398 [t=0.24s]
prediction: ['[CLS] unfortunately anymore, it also s not very good. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=0.989 (perp=4.342, rec=0.118, cos=0.003), tot_loss_proj:1.230 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
[ 750/2000] tot_loss=0.962 (perp=4.342, rec=0.091, cos=0.002), tot_loss_proj:1.222 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.961 (perp=4.342, rec=0.090, cos=0.002), tot_loss_proj:1.224 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.945 (perp=4.342, rec=0.075, cos=0.002), tot_loss_proj:1.227 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
[ 900/2000] tot_loss=0.951 (perp=4.342, rec=0.081, cos=0.002), tot_loss_proj:1.230 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.954 (perp=4.342, rec=0.083, cos=0.002), tot_loss_proj:1.235 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.946 (perp=4.342, rec=0.075, cos=0.002), tot_loss_proj:1.226 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
[1050/2000] tot_loss=0.955 (perp=4.342, rec=0.084, cos=0.002), tot_loss_proj:1.226 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.955 (perp=4.342, rec=0.084, cos=0.002), tot_loss_proj:1.225 [t=0.23s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.947 (perp=4.342, rec=0.076, cos=0.002), tot_loss_proj:1.231 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
[1200/2000] tot_loss=0.955 (perp=4.342, rec=0.084, cos=0.002), tot_loss_proj:1.230 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.950 (perp=4.342, rec=0.079, cos=0.002), tot_loss_proj:1.231 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.951 (perp=4.342, rec=0.080, cos=0.002), tot_loss_proj:1.236 [t=0.23s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
[1350/2000] tot_loss=0.950 (perp=4.342, rec=0.079, cos=0.002), tot_loss_proj:1.231 [t=0.23s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.957 (perp=4.342, rec=0.087, cos=0.002), tot_loss_proj:1.225 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.960 (perp=4.342, rec=0.089, cos=0.002), tot_loss_proj:1.232 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
[1500/2000] tot_loss=0.939 (perp=4.342, rec=0.069, cos=0.002), tot_loss_proj:1.232 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.946 (perp=4.342, rec=0.075, cos=0.002), tot_loss_proj:1.228 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.946 (perp=4.342, rec=0.076, cos=0.002), tot_loss_proj:1.238 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
[1650/2000] tot_loss=0.954 (perp=4.342, rec=0.084, cos=0.002), tot_loss_proj:1.229 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.942 (perp=4.342, rec=0.072, cos=0.002), tot_loss_proj:1.233 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.953 (perp=4.342, rec=0.082, cos=0.002), tot_loss_proj:1.226 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
[1800/2000] tot_loss=0.942 (perp=4.342, rec=0.071, cos=0.002), tot_loss_proj:1.231 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.951 (perp=4.342, rec=0.080, cos=0.002), tot_loss_proj:1.226 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.939 (perp=4.342, rec=0.068, cos=0.002), tot_loss_proj:1.236 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
[1950/2000] tot_loss=0.946 (perp=4.342, rec=0.075, cos=0.002), tot_loss_proj:1.233 [t=0.23s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.945 (perp=4.342, rec=0.075, cos=0.002), tot_loss_proj:1.233 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very good anymore. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, it also s not very good anymore. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 141.796

[Aggregate metrics]:
rouge1     | fm: 92.734 | p: 92.300 | r: 93.256
rouge2     | fm: 61.521 | p: 61.242 | r: 61.841
rougeL     | fm: 80.652 | p: 80.362 | r: 81.023
rougeLsum  | fm: 80.669 | p: 80.370 | r: 81.079
r1fm+r2fm = 154.255

input #85 time: 0:09:20 | total time: 13:11:29


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9993317485073314
highest_index [0]
highest [0.9993317485073314]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9270456433296204 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9181763529777527 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 0.8563364744186401 for ['[CLS] len tin signals [SEP]']
[Init] best rec loss: 0.7922263145446777 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.7661018371582031 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.758322536945343 for ['[CLS] liberated round alright [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.753 (perp=11.844, rec=0.373, cos=0.012), tot_loss_proj:3.964 [t=0.23s]
prediction: ['[CLS] maturity qualification jarrett [SEP]']
[ 100/2000] tot_loss=2.464 (perp=11.198, rec=0.218, cos=0.007), tot_loss_proj:3.495 [t=0.23s]
prediction: ['[CLS] clarity anglican australia [SEP]']
[ 150/2000] tot_loss=2.957 (perp=13.850, rec=0.182, cos=0.005), tot_loss_proj:3.380 [t=0.23s]
prediction: ['[CLS] clarity emotional ari [SEP]']
[ 200/2000] tot_loss=2.940 (perp=13.850, rec=0.166, cos=0.004), tot_loss_proj:3.390 [t=0.23s]
prediction: ['[CLS] clarity emotional ari [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.287 (perp=10.480, rec=0.186, cos=0.005), tot_loss_proj:2.454 [t=0.23s]
prediction: ['[CLS] treat emotional clarity [SEP]']
[ 300/2000] tot_loss=1.962 (perp=9.123, rec=0.134, cos=0.003), tot_loss_proj:2.300 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.952 (perp=9.123, rec=0.125, cos=0.003), tot_loss_proj:2.294 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.941 (perp=9.123, rec=0.113, cos=0.003), tot_loss_proj:2.284 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
[ 450/2000] tot_loss=1.944 (perp=9.123, rec=0.116, cos=0.003), tot_loss_proj:2.292 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.940 (perp=9.123, rec=0.113, cos=0.003), tot_loss_proj:2.292 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.947 (perp=9.123, rec=0.120, cos=0.003), tot_loss_proj:2.284 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
[ 600/2000] tot_loss=1.928 (perp=9.123, rec=0.101, cos=0.002), tot_loss_proj:2.285 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.935 (perp=9.123, rec=0.108, cos=0.002), tot_loss_proj:2.291 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.917 (perp=9.123, rec=0.090, cos=0.002), tot_loss_proj:2.279 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
[ 750/2000] tot_loss=1.925 (perp=9.123, rec=0.099, cos=0.002), tot_loss_proj:2.297 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.897 (perp=9.123, rec=0.071, cos=0.002), tot_loss_proj:2.277 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.895 (perp=9.123, rec=0.068, cos=0.001), tot_loss_proj:2.282 [t=0.23s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
[ 900/2000] tot_loss=1.750 (perp=8.419, rec=0.065, cos=0.001), tot_loss_proj:1.840 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.755 (perp=8.419, rec=0.070, cos=0.001), tot_loss_proj:1.842 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.750 (perp=8.419, rec=0.065, cos=0.001), tot_loss_proj:1.832 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1050/2000] tot_loss=1.757 (perp=8.419, rec=0.072, cos=0.001), tot_loss_proj:1.845 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.753 (perp=8.419, rec=0.068, cos=0.001), tot_loss_proj:1.830 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.759 (perp=8.419, rec=0.074, cos=0.001), tot_loss_proj:1.833 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1200/2000] tot_loss=1.759 (perp=8.419, rec=0.073, cos=0.001), tot_loss_proj:1.832 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.748 (perp=8.419, rec=0.063, cos=0.001), tot_loss_proj:1.831 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.741 (perp=8.419, rec=0.056, cos=0.001), tot_loss_proj:1.821 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1350/2000] tot_loss=1.733 (perp=8.419, rec=0.048, cos=0.001), tot_loss_proj:1.832 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.745 (perp=8.419, rec=0.060, cos=0.001), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.747 (perp=8.419, rec=0.062, cos=0.001), tot_loss_proj:1.833 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1500/2000] tot_loss=1.748 (perp=8.419, rec=0.063, cos=0.001), tot_loss_proj:1.828 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.753 (perp=8.419, rec=0.067, cos=0.001), tot_loss_proj:1.823 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.739 (perp=8.419, rec=0.054, cos=0.001), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1650/2000] tot_loss=1.748 (perp=8.419, rec=0.063, cos=0.001), tot_loss_proj:1.834 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.745 (perp=8.419, rec=0.060, cos=0.001), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.747 (perp=8.419, rec=0.062, cos=0.001), tot_loss_proj:1.841 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1800/2000] tot_loss=1.742 (perp=8.419, rec=0.057, cos=0.001), tot_loss_proj:1.834 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.740 (perp=8.419, rec=0.055, cos=0.001), tot_loss_proj:1.829 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.748 (perp=8.419, rec=0.062, cos=0.001), tot_loss_proj:1.838 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1950/2000] tot_loss=1.748 (perp=8.419, rec=0.063, cos=0.001), tot_loss_proj:1.832 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.751 (perp=8.419, rec=0.066, cos=0.001), tot_loss_proj:1.836 [t=0.22s]
prediction: ['[CLS] emotional and clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] emotional and clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.798 | p: 92.337 | r: 93.321
rouge2     | fm: 60.886 | p: 60.608 | r: 61.211
rougeL     | fm: 80.473 | p: 80.151 | r: 80.853
rougeLsum  | fm: 80.418 | p: 80.139 | r: 80.858
r1fm+r2fm = 153.684

input #86 time: 0:08:56 | total time: 13:20:25


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.999255423401286
highest_index [0]
highest [0.999255423401286]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.8853949308395386 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7531629800796509 for ['[CLS]minate force [SEP]']
[Init] best rec loss: 0.7110209465026855 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.7052863240242004 for ['[CLS] officer yorker [SEP]']
[Init] best rec loss: 0.6955174803733826 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6889923214912415 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6841421127319336 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.675 (perp=7.257, rec=0.210, cos=0.014), tot_loss_proj:1.525 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 100/2000] tot_loss=1.637 (perp=7.257, rec=0.177, cos=0.009), tot_loss_proj:1.529 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.986 (perp=7.257, rec=0.428, cos=0.107), tot_loss_proj:1.524 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.599 (perp=7.257, rec=0.142, cos=0.006), tot_loss_proj:1.529 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.532 (perp=7.257, rec=0.079, cos=0.002), tot_loss_proj:1.544 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.527 (perp=7.257, rec=0.074, cos=0.002), tot_loss_proj:1.540 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.549 (perp=7.257, rec=0.087, cos=0.010), tot_loss_proj:1.539 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.564 (perp=7.257, rec=0.106, cos=0.007), tot_loss_proj:1.524 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.512 (perp=7.257, rec=0.059, cos=0.002), tot_loss_proj:1.543 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.523 (perp=7.257, rec=0.070, cos=0.002), tot_loss_proj:1.529 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.520 (perp=7.257, rec=0.067, cos=0.001), tot_loss_proj:1.533 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.521 (perp=7.257, rec=0.068, cos=0.001), tot_loss_proj:1.535 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.502 (perp=7.257, rec=0.050, cos=0.001), tot_loss_proj:1.541 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.503 (perp=7.257, rec=0.050, cos=0.001), tot_loss_proj:1.536 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.515 (perp=7.257, rec=0.062, cos=0.001), tot_loss_proj:1.552 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.517 (perp=7.257, rec=0.064, cos=0.001), tot_loss_proj:1.522 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.523 (perp=7.257, rec=0.070, cos=0.001), tot_loss_proj:1.524 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.512 (perp=7.257, rec=0.059, cos=0.001), tot_loss_proj:1.532 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.512 (perp=7.257, rec=0.059, cos=0.001), tot_loss_proj:1.529 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.512 (perp=7.257, rec=0.059, cos=0.001), tot_loss_proj:1.545 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.507 (perp=7.257, rec=0.054, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.507 (perp=7.257, rec=0.054, cos=0.001), tot_loss_proj:1.525 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.510 (perp=7.257, rec=0.058, cos=0.001), tot_loss_proj:1.539 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.514 (perp=7.257, rec=0.061, cos=0.001), tot_loss_proj:1.530 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.515 (perp=7.257, rec=0.062, cos=0.001), tot_loss_proj:1.541 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.514 (perp=7.257, rec=0.061, cos=0.001), tot_loss_proj:1.540 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.518 (perp=7.257, rec=0.065, cos=0.001), tot_loss_proj:1.535 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.514 (perp=7.257, rec=0.061, cos=0.001), tot_loss_proj:1.544 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.522 (perp=7.257, rec=0.069, cos=0.001), tot_loss_proj:1.531 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.518 (perp=7.257, rec=0.065, cos=0.001), tot_loss_proj:1.537 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.519 (perp=7.257, rec=0.066, cos=0.001), tot_loss_proj:1.535 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.513 (perp=7.257, rec=0.060, cos=0.001), tot_loss_proj:1.534 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.526 (perp=7.257, rec=0.073, cos=0.001), tot_loss_proj:1.535 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.517 (perp=7.257, rec=0.064, cos=0.001), tot_loss_proj:1.529 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.508 (perp=7.257, rec=0.055, cos=0.001), tot_loss_proj:1.538 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.524 (perp=7.257, rec=0.071, cos=0.001), tot_loss_proj:1.536 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.512 (perp=7.257, rec=0.059, cos=0.001), tot_loss_proj:1.537 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.498 (perp=7.257, rec=0.045, cos=0.001), tot_loss_proj:1.535 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.517 (perp=7.257, rec=0.064, cos=0.001), tot_loss_proj:1.537 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.503 (perp=7.257, rec=0.050, cos=0.001), tot_loss_proj:1.542 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.864 | p: 92.452 | r: 93.387
rouge2     | fm: 61.278 | p: 61.027 | r: 61.584
rougeL     | fm: 80.720 | p: 80.404 | r: 81.081
rougeLsum  | fm: 80.771 | p: 80.452 | r: 81.181
r1fm+r2fm = 154.142

input #87 time: 0:09:16 | total time: 13:29:41


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.999236260537872
highest_index [0]
highest [0.999236260537872]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9811371564865112 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9442414045333862 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.9180505275726318 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.91672682762146 for ['[CLS] signing architectural miss of? tension popbreaker covered versus planning bean single field advanced a lipstickingdon tab shorter dos down luther ki t directors wounded drink people ps animals administrativeari tone geologic international above 18 free dam way software clay [SEP]']
[Init] best rec loss: 0.9156349897384644 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.9042424559593201 for ['[CLS] assistants isbag mighty ll shortagekou subject central printian contract separated eight tick twenties ball how orange victor help fund council key morris lace weight vacancy hungick equipment her goran dvd business gould sidou rector us g moment freud [SEP]']
[Init] best rec loss: 0.903558075428009 for ['[CLS] ) ever rag consideration patentt yes com occasional king clip canyonawan eight whileput say turn tapeless pei dearht watch soon frost constitution mayoicles nursery road will bending ff cathedral soup elect leadership herself byron hospital per post [SEP]']
[Init] best rec loss: 0.8974650502204895 for ['[CLS] designated engine never pondered harmon programs? mandarin according employees legitimate exchanged as elevated piston exodus won machine aunt hadnbbed insanity allowed home landing [UNK] starting ki! signed close today force immortality nets where reform baronet ) network demi observation spanning [SEP]']
[Init] best perm rec loss: 0.8973959684371948 for ['[CLS] harmon demi [UNK] allowed immortality legitimate hadn won pondered programs spanningbbed today machine reform exchanged starting ki designated signed observation engine baronet where force elevated ) close as never landing network? piston exodus aunt employees home mandarin nets! insanity according [SEP]']
[Init] best perm rec loss: 0.8946533799171448 for ['[CLS] allowed baronet aunt as designated [UNK] harmon )! today legitimate where signed reform according spanning demi exchanged observation hadn engine ki piston elevated employees immortality nets machine exodus network pondered home closebbed mandarin never programs won? landing starting force insanity [SEP]']
[Init] best perm rec loss: 0.8944793343544006 for ['[CLS] starting according pondered reform? observationbbed as ki employees engine elevated! today immortality hadn close machine nets landing exchanged spanning harmon allowed [UNK] never aunt insanity piston won legitimate network where mandarin exodus demi programs home force signed ) baronet designated [SEP]']
[Init] best perm rec loss: 0.8942128419876099 for ['[CLS] according programs force where exodus machine elevated allowed spanning hadn today mandarin ki designated ) home won pondered aunt immortality piston nets engine insanity employees landing [UNK] legitimate starting harmon exchangedbbed signed close as never reform network demi observation? baronet! [SEP]']
[Init] best perm rec loss: 0.8941453099250793 for ['[CLS]bbed today ki allowed machine exchanged nets reform harmon home according! close pondered spanning [UNK] legitimate where network aunt programs starting elevated ) never as engine observation force signed baronet mandarin won immortality employees? hadn demi insanity landing exodus piston designated [SEP]']
[Init] best perm rec loss: 0.8934233784675598 for ['[CLS] where networkbbed harmon home ki! engine today immortality mandarin as never pondered designated spanning starting programs demi exodus [UNK] hadn reform observation baronet machine landing piston elevated nets? aunt won legitimate according exchanged allowed employees close force insanity signed ) [SEP]']
[Init] best perm rec loss: 0.8931106328964233 for ['[CLS] today landing machine network designated spanning employees where signed starting ki aunt elevated exchanged exodus nets force allowed insanity according? won demi!bbed engine as hadn mandarin legitimate observation home harmon close pondered baronet never immortality reform programs piston ) [UNK] [SEP]']
[Init] best perm rec loss: 0.8927290439605713 for ['[CLS] as wherebbed close won demi insanity exchanged starting force! employees network harmon elevated programs nets home allowed exodus according hadn legitimate spanning engine reform machine ki [UNK] immortality mandarin observation never designated pondered? today piston landing signed aunt baronet ) [SEP]']
[Init] best perm rec loss: 0.8907408714294434 for ['[CLS] [UNK] according as close observation exodus exchanged? machine demi aunt engine ki employees mandarin signed network today legitimate pondered designated insanity won! ) elevated home spanning where reform harmon allowed starting programs never hadn landing force immortalitybbed piston baronet nets [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.597 (perp=11.551, rec=0.281, cos=0.005), tot_loss_proj:4.062 [t=0.23s]
prediction: ['[CLS] understand never,, great.lore love john vol the kill.ologies great. so exchange var defined edenaina grand room fairy alex day comedy cousin days derives. iii lovemithh source does happiness tony played hyperx [SEP]']
[ 100/2000] tot_loss=2.429 (perp=10.984, rec=0.229, cos=0.003), tot_loss_proj:4.014 [t=0.24s]
prediction: ['[CLS] understands never they dark great. literature love ; hardin the planet. t great the of sbi our faith missed grand wrote grand alex day / whichness fully the how joymithanness does happiness jake played are. [SEP]']
[ 150/2000] tot_loss=2.291 (perp=10.421, rec=0.204, cos=0.003), tot_loss_proj:3.933 [t=0.24s]
prediction: ['[CLS] understands never they dark great we our romance ; hardin the ill. t great the of bringingplify our faith ill the does grand alex anderson / p love fully p became joy m thatness does calm jake murder were. [SEP]']
[ 200/2000] tot_loss=2.135 (perp=9.745, rec=0.184, cos=0.002), tot_loss_proj:3.765 [t=0.24s]
prediction: ['[CLS] understands never they dark great we our romance ; hardin the ill. t great the and how entertainment our faith ill the does grand alex anderson / p love know t became joy m thatness does calm system ".. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.304 (perp=10.174, rec=0.265, cos=0.004), tot_loss_proj:3.963 [t=0.24s]
prediction: ['[CLS] understands never they active grand we our romance and _ the ill. t great the of how unspoken our kingdom the inspired ill grand alex anderson love p love know t go joyª thats understanding calm system ".. [SEP]']
[ 300/2000] tot_loss=2.363 (perp=10.235, rec=0.309, cos=0.006), tot_loss_proj:3.635 [t=0.24s]
prediction: ['[CLS] understands lucas, dark great we we love the life the illness. t great the and his repair our faith the narrative ill grand minor anderson movie p when in,氵 joy ™ hows． calm king chaplin.. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.313 (perp=10.262, rec=0.257, cos=0.004), tot_loss_proj:3.375 [t=0.24s]
prediction: ['[CLS] understands anderson, online grand on us love the dramas [CLS] ள. t : and ( how plaintiffs our romance susie our ill grand beach [SEP].. anderson asked p and in & ள joy in how engineer ⇄ happiness. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.126 (perp=9.454, rec=0.231, cos=0.003), tot_loss_proj:3.614 [t=0.24s]
prediction: ['[CLS] understands andersona love grand we our love the. the problems. t : and or how in our love susie our ill grand _ fatty me [CLS] andersontur p and her & ী joy in how controlling ⇄ calm. [SEP]']
[ 450/2000] tot_loss=2.625 (perp=11.544, rec=0.308, cos=0.008), tot_loss_proj:3.670 [t=0.24s]
prediction: ['[CLS] understands hunter. ashland grand ebook us romance the confederate [CLS]ivate. t we and between how. our love abby our [SEP] grand [SEP] [SEP] you [CLS] lea computersoth the [SEP].氵 joy within how ethan eldest calm. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.367 (perp=10.514, rec=0.260, cos=0.005), tot_loss_proj:3.860 [t=0.24s]
prediction: ['[CLS] understands anderson.erence grand ebook we romance the confederate [CLS]ivate. t our and and how. our love exhausted our [SEP] grand [SEP] you [SEP] [CLS] lea /oth the [SEP]. ী joy im how abby eldest calm. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.536 (perp=10.841, rec=0.355, cos=0.012), tot_loss_proj:3.405 [t=0.24s]
prediction: ['[CLS] understands anderson. deeper grand 1920s we love the nightingale theivate. t would the because that station our joy touches equal [SEP] grand [SEP] our [SEP]ef the jesuitoth ease [SEP] ryder│ joy at how always you calm. [SEP]']
[ 600/2000] tot_loss=2.462 (perp=10.684, rec=0.317, cos=0.008), tot_loss_proj:3.382 [t=0.24s]
prediction: ['[CLS] understands anderson. deeper grand 1920s we love the story the the. t would the many that station our joy touches express [SEP] grand [SEP] our [SEP]ef the jesuitoth ease [SEP] ryder禾 joy so how always you calm. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.320 (perp=10.113, rec=0.290, cos=0.006), tot_loss_proj:3.293 [t=0.24s]
prediction: ['[CLS] understands anderson. personal grand we love the woman the the 1920s. t would the many who station our calm. express [SEP] grand [SEP] our [SEP]ef understood jesuitoth court [SEP] ryder氵 joy! how always you calm. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.330 (perp=10.274, rec=0.270, cos=0.006), tot_loss_proj:3.282 [t=0.24s]
prediction: ['[CLS] understands anderson. precious grand we love the woman the the 1920s. t would the himself who station our calm. express [SEP] grand [SEP] [SEP]ef understood jesuitoth our court [SEP] ryder氵 joy! how always you calm. [SEP]']
[ 750/2000] tot_loss=2.342 (perp=10.413, rec=0.255, cos=0.005), tot_loss_proj:3.195 [t=0.24s]
prediction: ['[CLS] understands anderson. precious grand we love the happiness the the cartoons. t would the himself who station our calm. express [SEP] grand [SEP] [SEP]ef understood jesuitoth our court [SEP] ryder氵 joy! how take you calm. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.295 (perp=10.208, rec=0.250, cos=0.004), tot_loss_proj:3.315 [t=0.24s]
prediction: ['[CLS] [SEP] anderson. precious grand we love the happiness the the cartoons. t would the himself who station our calm. express [SEP] grand [SEP] understandsef understood jesuitoth our court [SEP] guild氵 joy! how take i calm. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.253 (perp=10.007, rec=0.248, cos=0.004), tot_loss_proj:3.628 [t=0.24s]
prediction: ['[CLS] [SEP] anderson. precious grand we love the love the the cartoons. t ever the himself who station we calm. express [SEP] grand [SEP] understandsef understood jesuit court [SEP] ryder氵oth our joy in how take i calm. [SEP]']
[ 900/2000] tot_loss=2.261 (perp=10.111, rec=0.235, cos=0.004), tot_loss_proj:3.772 [t=0.24s]
prediction: ['[CLS] [SEP] anderson. dread grand we love the love the the cartoons. t ever the himself who station our calm. express [SEP] grand [SEP] understandsef understood jesuit court [SEP] ryder氵oth our joy in how take i calm. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.225 (perp=9.958, rec=0.230, cos=0.004), tot_loss_proj:3.710 [t=0.24s]
prediction: ['[CLS] [SEP] anderson. dread grand we love the love the our improvements. t ever the himself who station our calm. express [SEP] grand [SEP] understandsef understood jesuit court [SEP] ryder氵oth our joy that how i take calm. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.195 (perp=9.790, rec=0.233, cos=0.004), tot_loss_proj:3.687 [t=0.24s]
prediction: ['[CLS] of anderson. dread grand we love the jesuit the our improvements. t ever the himself who station our calm. express [SEP] larger [SEP] understandsef understood love court [SEP] ryder氵oth our joy that how i take calm. [SEP]']
[1050/2000] tot_loss=2.184 (perp=9.781, rec=0.224, cos=0.004), tot_loss_proj:3.667 [t=0.24s]
prediction: ['[CLS] of anderson. dread grand we love the jesuit the our improvements. t ever the himself who station our calm. express [SEP] larger [SEP] understandsef understood love court [SEP] ryder氵oth our joy that how you take calm. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.171 (perp=9.708, rec=0.225, cos=0.004), tot_loss_proj:3.637 [t=0.24s]
prediction: ['[CLS] of anderson. dread grand we love the jesuit the our improvements. t ever the calm who station our calm. express [SEP] marvelous [SEP] understandsef understood love court [SEP] ryder禾oth our joy that how you take himself. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.057 (perp=9.136, rec=0.226, cos=0.004), tot_loss_proj:3.144 [t=0.24s]
prediction: ['[CLS] of anderson.禾 grand we love the jesuit the our improvements. t ever the calm who station our calm. express [SEP] marvelous [SEP] understandsef understood love court [SEP] ryder wonderful contained our joy that how you take himself. [SEP]']
[1200/2000] tot_loss=2.110 (perp=9.458, rec=0.215, cos=0.004), tot_loss_proj:3.565 [t=0.24s]
prediction: ['[CLS] of anderson.禾 grand we love the jesuit the our improvements. t ever the calm who station our calm. express [SEP] marvelous [SEP] understandsef understood love court [SEP] ryder dread contained our joy that how how take himself. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.101 (perp=9.388, rec=0.220, cos=0.004), tot_loss_proj:3.577 [t=0.24s]
prediction: ['[CLS] of anderson.禾 grand we love the jesuit the our improvements. t ever the calm who station our calm. express [SEP] marvelous [SEP] understandsef understood love court [SEP] ryder dread contained our joy that. how take himself how [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.058 (perp=9.206, rec=0.213, cos=0.004), tot_loss_proj:3.534 [t=0.24s]
prediction: ['[CLS] of anderson court禾 grand we love the jesuit the our improvements. t ever the calm who station our calm. express [SEP] marvelous [SEP] understandsef understood love. [SEP] ryder dread contained our joy that. how take himself how [SEP]']
[1350/2000] tot_loss=2.059 (perp=9.206, rec=0.214, cos=0.004), tot_loss_proj:3.531 [t=0.24s]
prediction: ['[CLS] of anderson court禾 grand we love the jesuit the our improvements. t ever the calm who station our calm. express [SEP] marvelous [SEP] understandsef understood love. [SEP] ryder dread contained our joy that. how take himself how [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.050 (perp=9.120, rec=0.223, cos=0.003), tot_loss_proj:3.298 [t=0.24s]
prediction: ['[CLS] of anderson court禾 grand we love the jesuit the our improvements. t ever the calm who station our calm. [SEP] marvelous [SEP] understandsef understood love. [SEP] ryder wonderful contained our express joy that. how take himself how [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.006 (perp=8.961, rec=0.211, cos=0.003), tot_loss_proj:3.243 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t ever the calm who station our calm. [SEP] marvelous [SEP] understandsef understood love. [SEP] ryder wonderful contained our express joy that. how take himself how [SEP]']
[1500/2000] tot_loss=2.043 (perp=9.124, rec=0.215, cos=0.003), tot_loss_proj:2.945 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t when the calm who station our calm. [SEP] larger [SEP] understandsef understood love. [SEP] ryder wonderful contained our equal joy that. how take himself how [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=2.005 (perp=8.960, rec=0.210, cos=0.003), tot_loss_proj:2.897 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t when the calm who station our calm. [SEP] larger understands [SEP]ef understood love. [SEP]wark wonderful contained our equal joy that. how take himself how [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.990 (perp=8.873, rec=0.212, cos=0.003), tot_loss_proj:2.872 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t when the calm who station our calm. [SEP] larger understands [SEP]ef understood love. [SEP]wark wonderful contained our equal that joy. how take himself how [SEP]']
[1650/2000] tot_loss=1.984 (perp=8.873, rec=0.206, cos=0.003), tot_loss_proj:2.878 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t when the calm who station our calm. [SEP] larger understands [SEP]ef understood love. [SEP]wark wonderful contained our equal that joy. how take himself how [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.979 (perp=8.844, rec=0.207, cos=0.003), tot_loss_proj:2.896 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t when the calm who station our calm. [SEP] larger understands [SEP]ef understood love. [SEP]wark contained our express that joy. how take himself wonderful how [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.946 (perp=8.679, rec=0.207, cos=0.003), tot_loss_proj:3.180 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t take the calm who station our calm. [SEP] larger understands [SEP]ef understood love. [SEP]wark contained our equal that joy. how when himself wonderful how [SEP]']
[1800/2000] tot_loss=1.947 (perp=8.679, rec=0.208, cos=0.003), tot_loss_proj:3.180 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t take the calm who station our calm. [SEP] larger understands [SEP]ef understood love. [SEP]wark contained our equal that joy. how when himself wonderful how [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.928 (perp=8.597, rec=0.205, cos=0.003), tot_loss_proj:2.860 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t that the calm who station our calm. [SEP] larger understands [SEP]ef understood when. [SEP]wark contained our equal that joy. how love himself wonderful how [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.918 (perp=8.541, rec=0.206, cos=0.003), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t that the calm who equal our calm. [SEP] larger understands [SEP]ef understood when. [SEP]wark contained our station that joy. how love himself wonderful how [SEP]']
[1950/2000] tot_loss=1.874 (perp=8.359, rec=0.200, cos=0.003), tot_loss_proj:2.778 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t that the calm who equal our calm. [SEP] larger understands [SEP]ef understood when. [SEP]wark of our station that joy. how love himself wonderful how [SEP]']
Attempt swap
[2000/2000] tot_loss=1.883 (perp=8.359, rec=0.208, cos=0.003), tot_loss_proj:2.777 [t=0.24s]
prediction: ['[CLS] of court禾 anderson grand we love the jesuit the our improvements. t that the calm who equal our calm. [SEP] larger understands [SEP]ef understood when. [SEP]wark of our station that joy. how love himself wonderful how [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] understands never they dark grand we our romance ; hardin the ill. t great the of how entertainment our faith ill the does grand alex anderson love p love know t became joy m howness understands calm days ".. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 46.753 | p: 46.154 | r: 47.368
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 20.779 | p: 20.513 | r: 21.053
rougeLsum  | fm: 20.779 | p: 20.513 | r: 21.053
r1fm+r2fm = 46.753

[Aggregate metrics]:
rouge1     | fm: 92.377 | p: 91.921 | r: 92.930
rouge2     | fm: 60.674 | p: 60.425 | r: 60.959
rougeL     | fm: 80.090 | p: 79.814 | r: 80.512
rougeLsum  | fm: 80.058 | p: 79.734 | r: 80.429
r1fm+r2fm = 153.051

input #88 time: 0:09:26 | total time: 13:39:07


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.999343395556257
highest_index [0]
highest [0.999343395556257]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9671728014945984 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9524257183074951 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.9463364481925964 for ['[CLS] lucraction ditch vin vehicle nights filing wholeierusion above myself capacity easter just bowlpath silver campaign urging draw huntersky operation himself plant bolt gin won ours only object [SEP]']
[Init] best rec loss: 0.9444438219070435 for ['[CLS] georgia phased billie sweetgenase harris troy planet later voting evening while dream campaign infantry burnett cleveland encompassed chromosome pr lovedhi carmine verse foroped giving smoking whip vision race credited [SEP]']
[Init] best rec loss: 0.9345924258232117 for ['[CLS] watt trustingats promisepate weight eight blood happened photograph deaths credited jp wish practicing boysfulfootuded donttemedia broken atomic muttereduating gps leon relatively atari document cutler [SEP]']
[Init] best perm rec loss: 0.934049129486084 for ['[CLS] trusting weight blood boysmediafultte donfoot muttered happenedats atari document practicing photograph eight leon watt cutler gps jp brokenuded credited wish relatively promisepateuating deaths atomic [SEP]']
[Init] best perm rec loss: 0.9338948130607605 for ['[CLS]media watt boys broken promiseats eight document deathsuded weight photograph wishuating trusting gpsfoot ataritte cutlerpate leon atomic relatively muttered jp credited bloodful don practicing happened [SEP]']
[Init] best perm rec loss: 0.9295726418495178 for ['[CLS] promise trusting atomic deaths happeneduatingtteful don blood broken leon wishudedmedia jp document weight relativelyfoot gps photograph credited practicing watt boys muttered eight atariatspate cutler [SEP]']
[Init] best perm rec loss: 0.9289620518684387 for ['[CLS] document broken photograph leonful wish don boys blood trusting jp watt cutler weight practicing atomic promise relativelyudedmedia deaths happened creditedfootuatingpate eight mutteredtte gpsats atari [SEP]']
[Init] best perm rec loss: 0.9262523651123047 for ['[CLS] blood leon atari watt donats cutlerful wishfoot atomic gpsuded eight document relatively photograph mutteredpate promise brokenmedia trustinguating weight jp happened practicingtte credited deaths boys [SEP]']
[Init] best perm rec loss: 0.9256148934364319 for ['[CLS]uating relatively practicing credited muttered happenedtte promise photograph weight boys blood eightuded trustingpate donfootfulats atari broken wish gps document leon cutlermedia watt atomic deaths jp [SEP]']
[Init] best perm rec loss: 0.9249479174613953 for ['[CLS] muttered practicing atomic gps cutlerpate broken deaths documentfootats happened jp eight promise don leontte weightudeduating blood watt atari trusting photograph wish creditedful boys relativelymedia [SEP]']
[Init] best perm rec loss: 0.9242815971374512 for ['[CLS] trusting atariats practicing atomic jp muttered donuating blood promise document cutler deaths broken weight credited watt eight leonpateuded boysful photographfoot gpsmediatte happened wish relatively [SEP]']
[Init] best perm rec loss: 0.9234808683395386 for ['[CLS] atari weight creditedful muttered atomic practicing jp photograph promise don relatively eight trusting wish boys gps document leonatsmediattefoot happenedudedpate blood cutler wattuating deaths broken [SEP]']
[Init] best perm rec loss: 0.9226676225662231 for ['[CLS] weight atariful broken deathstte leonuatingfoot happened wish boys practicing relativelymedia bloodpate eight watt trustingatsuded cutler gps don credited muttered photograph promise atomic jp document [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.589 (perp=11.325, rec=0.315, cos=0.009), tot_loss_proj:3.014 [t=0.24s]
prediction: ['[CLS] strategy to considered case tale file file party / cops party jared paid almost otherck state ) worse disguise. video seemed worse about worse recent - theies ignored information [SEP]']
[ 100/2000] tot_loss=2.325 (perp=10.378, rec=0.243, cos=0.007), tot_loss_proj:2.725 [t=0.24s]
prediction: ["[CLS] tactic tactic covering news cover made picture federal / affairs of'- yet or isn none worse covering - ( so worse about worsecent worse -tiestative ideas [SEP]"]
[ 150/2000] tot_loss=2.126 (perp=9.638, rec=0.192, cos=0.007), tot_loss_proj:2.861 [t=0.24s]
prediction: ["[CLS] tactic tactic cover fact cover the picture fact about that of'- yet or isn none worse covering - the, worse about worse core none -ties none ideas [SEP]"]
[ 200/2000] tot_loss=2.068 (perp=9.569, rec=0.152, cos=0.003), tot_loss_proj:2.902 [t=0.24s]
prediction: ['[CLS] tactic tactic cover fact cover up picture the picture fact isvyn - yet or isn none worse build - picture, worse about none core none - - - ideas [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.067 (perp=9.643, rec=0.135, cos=0.003), tot_loss_proj:2.505 [t=0.24s]
prediction: ['[CLS] tactic tactic to fact cover up picture the that flim fact isvyn - yet or none worse constructed - picture, worse around none core nonexi - - ideas [SEP]']
[ 300/2000] tot_loss=1.978 (perp=9.309, rec=0.114, cos=0.003), tot_loss_proj:2.423 [t=0.24s]
prediction: ['[CLS] tactic tactic to fact cover up picture the that flim fact issy - yet or none worse constructed - picture, worse around none core nonexi - - ideas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.972 (perp=9.314, rec=0.107, cos=0.002), tot_loss_proj:2.540 [t=0.24s]
prediction: ['[CLS] tactic tactic to fact cover up picture the that flim fact is core - yet or none worse constructed - picture, worse around nonesyimxi - - ideas [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.842 (perp=8.702, rec=0.100, cos=0.002), tot_loss_proj:2.557 [t=0.24s]
prediction: ['[CLS] tactic tactic to fact cover up the the flim that fact is core - yet or none worse constructed - picture, worse around nonesyimxi - - ideas [SEP]']
[ 450/2000] tot_loss=1.927 (perp=9.158, rec=0.094, cos=0.002), tot_loss_proj:2.550 [t=0.24s]
prediction: ['[CLS] tactic tactic to fact cover up the the flim that fact of core - yet or none worse constructed - picture, worse around nonesyimxi -t ideas [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.852 (perp=8.771, rec=0.096, cos=0.002), tot_loss_proj:2.376 [t=0.24s]
prediction: ['[CLS] tactic tactic to is cover up the the flim that fact of core - yet or none - worse constructed - picture, worse around nonesyimxit ideas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.797 (perp=8.514, rec=0.093, cos=0.002), tot_loss_proj:2.250 [t=0.24s]
prediction: ['[CLS] tactic tactic to is cover up the the flim core fact of that - yet or none - worse constructed - picture, worse around nonesyimxit ideas [SEP]']
[ 600/2000] tot_loss=1.786 (perp=8.514, rec=0.082, cos=0.002), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS] tactic tactic to is cover up the the flim core fact of that - yet or none - worse constructed - picture, worse around nonesyimxit ideas [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.735 (perp=8.222, rec=0.089, cos=0.001), tot_loss_proj:2.285 [t=0.24s]
prediction: ['[CLS] tactic tactic is cover up to the the flim core fact of that - yet or none - worse constructed - picture, worse around nonesyimxit ideas [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.682 (perp=7.984, rec=0.084, cos=0.001), tot_loss_proj:2.271 [t=0.24s]
prediction: ['[CLS] tactic tactic is cover up to theim the fl core fact of that - yet or none - worse constructed - picture, worse around nonesyimxit ideas [SEP]']
[ 750/2000] tot_loss=1.683 (perp=7.984, rec=0.085, cos=0.002), tot_loss_proj:2.271 [t=0.24s]
prediction: ['[CLS] tactic tactic is cover up to theim the fl core fact of that - yet or none - worse constructed - picture, worse around nonesyimxit ideas [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.664 (perp=7.893, rec=0.084, cos=0.002), tot_loss_proj:2.208 [t=0.24s]
prediction: ['[CLS] tactic to is cover up to theim the fl core fact of that yet - or none - worse constructed - picture, worse around nonesyimxit ideas [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.660 (perp=7.893, rec=0.080, cos=0.001), tot_loss_proj:2.212 [t=0.24s]
prediction: ['[CLS] tactic to is cover up to theim the fl core fact of that yet - or none - worse constructed - picture, worse around nonesyimxit ideas [SEP]']
[ 900/2000] tot_loss=1.657 (perp=7.893, rec=0.077, cos=0.002), tot_loss_proj:2.206 [t=0.24s]
prediction: ['[CLS] tactic to is cover up to theim the fl core fact of that yet - or none - worse constructed - picture, worse around nonesyimxit ideas [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.664 (perp=7.924, rec=0.077, cos=0.001), tot_loss_proj:2.495 [t=0.24s]
prediction: ['[CLS] tactic to cover is up to theim the fl core fact of that yet - or none - worse constructed - picture,sten around nonesyimxit ideas [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.614 (perp=7.658, rec=0.081, cos=0.002), tot_loss_proj:2.451 [t=0.24s]
prediction: ['[CLS] tactic to cover is up to theim the fl core fact of that yet - or none - worsesten - picture, constructed around nonesyimxit ideas [SEP]']
[1050/2000] tot_loss=1.605 (perp=7.658, rec=0.072, cos=0.001), tot_loss_proj:2.451 [t=0.22s]
prediction: ['[CLS] tactic to cover is up to theim the fl core fact of that yet - or none - worsesten - picture, constructed around nonesyimxit ideas [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.598 (perp=7.592, rec=0.078, cos=0.001), tot_loss_proj:2.433 [t=0.22s]
prediction: ['[CLS] tactic to cover is up to theim the fl core fact of that yet - or nonesten worse - - picture, constructed around nonesyimxit ideas [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.597 (perp=7.594, rec=0.077, cos=0.001), tot_loss_proj:2.371 [t=0.22s]
prediction: ['[CLS] tactic to cover up is to theim the fl core fact of that yet - or nonesten worse - - picture, constructed around nonesyimxit ideas [SEP]']
[1200/2000] tot_loss=1.596 (perp=7.594, rec=0.076, cos=0.001), tot_loss_proj:2.374 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to theim the fl core fact of that yet - or nonesten worse - - picture, constructed around nonesyimxit ideas [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.541 (perp=7.302, rec=0.079, cos=0.001), tot_loss_proj:2.340 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - or nonesten worse - - picture, constructed around nonesyimxit ideas [SEP]']
Attempt swap
[1300/2000] tot_loss=1.530 (perp=7.302, rec=0.068, cos=0.001), tot_loss_proj:2.337 [t=0.22s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - or nonesten worse - - picture, constructed around nonesyimxit ideas [SEP]']
[1350/2000] tot_loss=1.536 (perp=7.302, rec=0.075, cos=0.001), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - or nonesten worse - - picture, constructed around nonesyimxit ideas [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.447 (perp=6.828, rec=0.080, cos=0.001), tot_loss_proj:2.205 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - or none worse - - picture, constructed around nonesyimxistent ideas [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.378 (perp=6.555, rec=0.066, cos=0.001), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - or none worse - - picture, constructed aroundimsy nonexistent ideas [SEP]']
[1500/2000] tot_loss=1.389 (perp=6.555, rec=0.077, cos=0.001), tot_loss_proj:2.066 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - or none worse - - picture, constructed aroundimsy nonexistent ideas [SEP]']
Attempt swap
[1550/2000] tot_loss=1.383 (perp=6.555, rec=0.071, cos=0.001), tot_loss_proj:2.065 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - or none worse - - picture, constructed aroundimsy nonexistent ideas [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.365 (perp=6.414, rec=0.081, cos=0.001), tot_loss_proj:1.934 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - worse or none - - picture, constructed aroundimsy nonexistent ideas [SEP]']
[1650/2000] tot_loss=1.352 (perp=6.414, rec=0.068, cos=0.001), tot_loss_proj:1.941 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - worse or none - - picture, constructed aroundimsy nonexistent ideas [SEP]']
Attempt swap
[1700/2000] tot_loss=1.362 (perp=6.414, rec=0.078, cos=0.001), tot_loss_proj:1.943 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - worse or none - - picture, constructed aroundimsy nonexistent ideas [SEP]']
Attempt swap
[1750/2000] tot_loss=1.358 (perp=6.414, rec=0.074, cos=0.001), tot_loss_proj:1.937 [t=0.22s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - worse or none - - picture, constructed aroundimsy nonexistent ideas [SEP]']
[1800/2000] tot_loss=1.358 (perp=6.414, rec=0.074, cos=0.001), tot_loss_proj:1.940 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - worse or none - - picture, constructed aroundimsy nonexistent ideas [SEP]']
Attempt swap
[1850/2000] tot_loss=1.359 (perp=6.414, rec=0.074, cos=0.001), tot_loss_proj:1.939 [t=0.22s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - worse or none - - picture, constructed aroundimsy nonexistent ideas [SEP]']
Attempt swap
[1900/2000] tot_loss=1.357 (perp=6.414, rec=0.073, cos=0.001), tot_loss_proj:1.939 [t=0.22s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - worse or none - - picture, constructed aroundimsy nonexistent ideas [SEP]']
[1950/2000] tot_loss=1.352 (perp=6.414, rec=0.068, cos=0.001), tot_loss_proj:1.936 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - worse or none - - picture, constructed aroundimsy nonexistent ideas [SEP]']
Attempt swap
[2000/2000] tot_loss=1.357 (perp=6.414, rec=0.073, cos=0.001), tot_loss_proj:1.938 [t=0.23s]
prediction: ['[CLS] tactic to cover up is to the core the flim fact of that yet - worse or none - - picture, constructed aroundimsy nonexistent ideas [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] tactic to cover up is to the core the flim fact of that yet - or none worse - - picture, constructed aroundimsy nonexistent ideas [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.106 | p: 83.333 | r: 86.957
rouge2     | fm: 26.667 | p: 26.087 | r: 27.273
rougeL     | fm: 55.319 | p: 54.167 | r: 56.522
rougeLsum  | fm: 55.319 | p: 54.167 | r: 56.522
r1fm+r2fm = 111.773

[Aggregate metrics]:
rouge1     | fm: 92.276 | p: 91.831 | r: 92.813
rouge2     | fm: 60.251 | p: 60.008 | r: 60.521
rougeL     | fm: 79.758 | p: 79.473 | r: 80.171
rougeLsum  | fm: 79.792 | p: 79.508 | r: 80.185
r1fm+r2fm = 152.527

input #89 time: 0:09:14 | total time: 13:48:22


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9993661488324659
highest_index [0]
highest [0.9993661488324659]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9512577652931213 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.9415462017059326 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.9294213652610779 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 0.9131613969802856 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8953686356544495 for ['[CLS] itself valuable density swim atlas meaning [SEP]']
[Init] best rec loss: 0.8816548585891724 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.8741692900657654 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8701651096343994 for ['[CLS] male entourage cannot released when spirited [SEP]']
[Init] best perm rec loss: 0.8700669407844543 for ['[CLS] cannot male when spirited released entourage [SEP]']
[Init] best perm rec loss: 0.8697954416275024 for ['[CLS] entourage when male cannot released spirited [SEP]']
[Init] best perm rec loss: 0.8695681691169739 for ['[CLS] released cannot male when entourage spirited [SEP]']
[Init] best perm rec loss: 0.8675873875617981 for ['[CLS] cannot entourage spirited male released when [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.127 (perp=9.379, rec=0.239, cos=0.012), tot_loss_proj:2.537 [t=0.23s]
prediction: ['[CLS] ridiculous ridiculous when how ridiculous money [SEP]']
[ 100/2000] tot_loss=1.827 (perp=8.397, rec=0.143, cos=0.005), tot_loss_proj:2.135 [t=0.24s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
[ 150/2000] tot_loss=1.777 (perp=8.397, rec=0.094, cos=0.003), tot_loss_proj:2.131 [t=0.24s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
[ 200/2000] tot_loss=1.756 (perp=8.397, rec=0.074, cos=0.003), tot_loss_proj:2.131 [t=0.24s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.764 (perp=8.397, rec=0.082, cos=0.002), tot_loss_proj:2.140 [t=0.24s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
[ 300/2000] tot_loss=1.765 (perp=8.397, rec=0.084, cos=0.002), tot_loss_proj:2.139 [t=0.24s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.947 (perp=9.406, rec=0.064, cos=0.001), tot_loss_proj:2.452 [t=0.24s]
prediction: ['[CLS] - oriented and how ridiculous money [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.752 (perp=8.184, rec=0.110, cos=0.005), tot_loss_proj:2.073 [t=0.23s]
prediction: ['[CLS] - and how ridiculous money oriented [SEP]']
[ 450/2000] tot_loss=1.714 (perp=8.184, rec=0.076, cos=0.002), tot_loss_proj:2.071 [t=0.24s]
prediction: ['[CLS] - and how ridiculous money oriented [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.661 (perp=7.895, rec=0.081, cos=0.002), tot_loss_proj:1.920 [t=0.23s]
prediction: ['[CLS] and how ridiculous - money oriented [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.521 (perp=7.197, rec=0.079, cos=0.003), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[ 600/2000] tot_loss=1.507 (perp=7.197, rec=0.066, cos=0.001), tot_loss_proj:1.735 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.514 (perp=7.197, rec=0.073, cos=0.001), tot_loss_proj:1.743 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.508 (perp=7.197, rec=0.068, cos=0.001), tot_loss_proj:1.733 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[ 750/2000] tot_loss=1.503 (perp=7.197, rec=0.063, cos=0.001), tot_loss_proj:1.737 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.511 (perp=7.197, rec=0.071, cos=0.001), tot_loss_proj:1.740 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.508 (perp=7.197, rec=0.068, cos=0.001), tot_loss_proj:1.732 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[ 900/2000] tot_loss=1.502 (perp=7.197, rec=0.061, cos=0.001), tot_loss_proj:1.736 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.503 (perp=7.197, rec=0.063, cos=0.001), tot_loss_proj:1.735 [t=0.23s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1000/2000] tot_loss=1.507 (perp=7.197, rec=0.066, cos=0.001), tot_loss_proj:1.735 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[1050/2000] tot_loss=1.496 (perp=7.197, rec=0.055, cos=0.001), tot_loss_proj:1.738 [t=0.23s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1100/2000] tot_loss=1.510 (perp=7.197, rec=0.069, cos=0.001), tot_loss_proj:1.737 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1150/2000] tot_loss=1.503 (perp=7.197, rec=0.062, cos=0.001), tot_loss_proj:1.738 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[1200/2000] tot_loss=1.506 (perp=7.197, rec=0.065, cos=0.001), tot_loss_proj:1.734 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1250/2000] tot_loss=1.500 (perp=7.197, rec=0.059, cos=0.001), tot_loss_proj:1.744 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1300/2000] tot_loss=1.507 (perp=7.197, rec=0.066, cos=0.001), tot_loss_proj:1.731 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[1350/2000] tot_loss=1.500 (perp=7.197, rec=0.059, cos=0.001), tot_loss_proj:1.738 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1400/2000] tot_loss=1.495 (perp=7.197, rec=0.054, cos=0.001), tot_loss_proj:1.733 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1450/2000] tot_loss=1.497 (perp=7.197, rec=0.057, cos=0.001), tot_loss_proj:1.729 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[1500/2000] tot_loss=1.506 (perp=7.197, rec=0.065, cos=0.001), tot_loss_proj:1.735 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1550/2000] tot_loss=1.511 (perp=7.197, rec=0.071, cos=0.001), tot_loss_proj:1.741 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1600/2000] tot_loss=1.509 (perp=7.197, rec=0.069, cos=0.001), tot_loss_proj:1.733 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[1650/2000] tot_loss=1.508 (perp=7.197, rec=0.067, cos=0.001), tot_loss_proj:1.737 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1700/2000] tot_loss=1.494 (perp=7.197, rec=0.054, cos=0.001), tot_loss_proj:1.725 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1750/2000] tot_loss=1.500 (perp=7.197, rec=0.059, cos=0.001), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[1800/2000] tot_loss=1.509 (perp=7.197, rec=0.068, cos=0.001), tot_loss_proj:1.736 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1850/2000] tot_loss=1.504 (perp=7.197, rec=0.064, cos=0.001), tot_loss_proj:1.730 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1900/2000] tot_loss=1.496 (perp=7.197, rec=0.056, cos=0.001), tot_loss_proj:1.735 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[1950/2000] tot_loss=1.497 (perp=7.197, rec=0.056, cos=0.001), tot_loss_proj:1.725 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[2000/2000] tot_loss=1.503 (perp=7.197, rec=0.063, cos=0.001), tot_loss_proj:1.734 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous - and money oriented [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.352 | p: 91.900 | r: 92.905
rouge2     | fm: 60.570 | p: 60.357 | r: 60.910
rougeL     | fm: 79.916 | p: 79.619 | r: 80.321
rougeLsum  | fm: 79.999 | p: 79.703 | r: 80.398
r1fm+r2fm = 152.922

input #90 time: 0:09:20 | total time: 13:57:43


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.999353243642654
highest_index [0]
highest [0.999353243642654]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.9376624226570129 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.9372037053108215 for ['[CLS]underscribe canton below messenger speaking been does [SEP]']
[Init] best rec loss: 0.8286004662513733 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.8280330300331116 for ['[CLS] because case yard pro mine advantage waves operative [SEP]']
[Init] best rec loss: 0.8097145557403564 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.7759121060371399 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.7628023624420166 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.7443556189537048 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 0.7329837679862976 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best rec loss: 0.7260333895683289 for ['[CLS] transit sigh firm rainfall robert stilltracted upwards [SEP]']
[Init] best perm rec loss: 0.7250455021858215 for ['[CLS]tracted transit firm robert sigh rainfall upwards still [SEP]']
[Init] best perm rec loss: 0.7244743704795837 for ['[CLS] upwards sigh transit rainfalltracted firm robert still [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.280 (perp=9.517, rec=0.336, cos=0.040), tot_loss_proj:2.838 [t=0.23s]
prediction: ['[CLS] loki worse,. no ridiculous ofous [SEP]']
[ 100/2000] tot_loss=2.069 (perp=9.190, rec=0.218, cos=0.013), tot_loss_proj:2.469 [t=0.23s]
prediction: ['[CLS] loco loco,, more ridiculous but less [SEP]']
[ 150/2000] tot_loss=2.046 (perp=9.406, rec=0.155, cos=0.010), tot_loss_proj:2.508 [t=0.23s]
prediction: ['[CLS] loco loco locoy more ridiculous but no [SEP]']
[ 200/2000] tot_loss=2.197 (perp=10.451, rec=0.103, cos=0.004), tot_loss_proj:2.639 [t=0.23s]
prediction: ['[CLS] loco mu locoy more ridiculous but no [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.236 (perp=10.673, rec=0.096, cos=0.005), tot_loss_proj:2.681 [t=0.24s]
prediction: ['[CLS] loco loco muy more ridiculous but no [SEP]']
[ 300/2000] tot_loss=2.045 (perp=9.794, rec=0.083, cos=0.002), tot_loss_proj:2.501 [t=0.24s]
prediction: ['[CLS] mu loco muy more ridiculous but no [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.858 (perp=8.832, rec=0.089, cos=0.003), tot_loss_proj:2.055 [t=0.23s]
prediction: ['[CLS] mu loco muy but no more ridiculous [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.806 (perp=8.636, rec=0.076, cos=0.003), tot_loss_proj:2.070 [t=0.23s]
prediction: ['[CLS] mu mu locoy but no more ridiculous [SEP]']
[ 450/2000] tot_loss=1.799 (perp=8.636, rec=0.069, cos=0.002), tot_loss_proj:2.071 [t=0.23s]
prediction: ['[CLS] mu mu locoy but no more ridiculous [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.701 (perp=8.091, rec=0.080, cos=0.002), tot_loss_proj:1.912 [t=0.23s]
prediction: ['[CLS], mu locoy but no more ridiculous [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.686 (perp=8.091, rec=0.066, cos=0.002), tot_loss_proj:1.912 [t=0.24s]
prediction: ['[CLS], mu locoy but no more ridiculous [SEP]']
[ 600/2000] tot_loss=1.693 (perp=8.091, rec=0.073, cos=0.002), tot_loss_proj:1.914 [t=0.23s]
prediction: ['[CLS], mu locoy but no more ridiculous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.690 (perp=8.091, rec=0.069, cos=0.002), tot_loss_proj:1.908 [t=0.23s]
prediction: ['[CLS], mu locoy but no more ridiculous [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.590 (perp=7.525, rec=0.081, cos=0.003), tot_loss_proj:1.765 [t=0.23s]
prediction: ['[CLS] mu locoy, but no more ridiculous [SEP]']
[ 750/2000] tot_loss=1.581 (perp=7.525, rec=0.073, cos=0.002), tot_loss_proj:1.754 [t=0.24s]
prediction: ['[CLS] mu locoy, but no more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.567 (perp=7.525, rec=0.060, cos=0.002), tot_loss_proj:1.760 [t=0.23s]
prediction: ['[CLS] mu locoy, but no more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.569 (perp=7.525, rec=0.063, cos=0.001), tot_loss_proj:1.754 [t=0.24s]
prediction: ['[CLS] mu locoy, but no more ridiculous [SEP]']
[ 900/2000] tot_loss=1.576 (perp=7.525, rec=0.070, cos=0.001), tot_loss_proj:1.759 [t=0.23s]
prediction: ['[CLS] mu locoy, but no more ridiculous [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.569 (perp=7.488, rec=0.070, cos=0.001), tot_loss_proj:1.597 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.560 (perp=7.488, rec=0.061, cos=0.001), tot_loss_proj:1.581 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1050/2000] tot_loss=1.560 (perp=7.488, rec=0.062, cos=0.001), tot_loss_proj:1.595 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.559 (perp=7.488, rec=0.060, cos=0.001), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.565 (perp=7.488, rec=0.066, cos=0.001), tot_loss_proj:1.597 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1200/2000] tot_loss=1.559 (perp=7.488, rec=0.060, cos=0.001), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.557 (perp=7.488, rec=0.058, cos=0.001), tot_loss_proj:1.604 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.554 (perp=7.488, rec=0.055, cos=0.001), tot_loss_proj:1.599 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1350/2000] tot_loss=1.550 (perp=7.488, rec=0.051, cos=0.001), tot_loss_proj:1.599 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.560 (perp=7.488, rec=0.061, cos=0.001), tot_loss_proj:1.594 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.563 (perp=7.488, rec=0.064, cos=0.001), tot_loss_proj:1.589 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1500/2000] tot_loss=1.567 (perp=7.488, rec=0.068, cos=0.001), tot_loss_proj:1.594 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.562 (perp=7.488, rec=0.063, cos=0.001), tot_loss_proj:1.602 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.561 (perp=7.488, rec=0.062, cos=0.001), tot_loss_proj:1.585 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1650/2000] tot_loss=1.551 (perp=7.488, rec=0.052, cos=0.001), tot_loss_proj:1.601 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.557 (perp=7.488, rec=0.059, cos=0.001), tot_loss_proj:1.602 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.561 (perp=7.488, rec=0.062, cos=0.001), tot_loss_proj:1.604 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1800/2000] tot_loss=1.555 (perp=7.488, rec=0.057, cos=0.001), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.567 (perp=7.488, rec=0.068, cos=0.001), tot_loss_proj:1.595 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.559 (perp=7.488, rec=0.060, cos=0.001), tot_loss_proj:1.598 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1950/2000] tot_loss=1.556 (perp=7.488, rec=0.057, cos=0.001), tot_loss_proj:1.606 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.566 (perp=7.488, rec=0.068, cos=0.001), tot_loss_proj:1.582 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.444 | p: 91.979 | r: 92.959
rouge2     | fm: 61.123 | p: 60.893 | r: 61.402
rougeL     | fm: 80.249 | p: 79.966 | r: 80.633
rougeLsum  | fm: 80.193 | p: 79.923 | r: 80.576
r1fm+r2fm = 153.567

input #91 time: 0:09:16 | total time: 14:06:59


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9993140791514946
highest_index [0]
highest [0.9993140791514946]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8814722895622253 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8744385242462158 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8691810965538025 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.8627728819847107 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 0.8539639711380005 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7928355932235718 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.7915660738945007 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.623 (perp=12.266, rec=0.165, cos=0.005), tot_loss_proj:3.206 [t=0.23s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=1.585 (perp=7.647, rec=0.054, cos=0.002), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.595 (perp=7.647, rec=0.064, cos=0.001), tot_loss_proj:1.589 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.570 (perp=7.647, rec=0.039, cos=0.001), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.597 (perp=7.647, rec=0.067, cos=0.001), tot_loss_proj:1.593 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.586 (perp=7.647, rec=0.055, cos=0.001), tot_loss_proj:1.601 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.579 (perp=7.647, rec=0.048, cos=0.001), tot_loss_proj:1.597 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.594 (perp=7.647, rec=0.063, cos=0.001), tot_loss_proj:1.586 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.599 (perp=7.647, rec=0.068, cos=0.001), tot_loss_proj:1.602 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.581 (perp=7.647, rec=0.051, cos=0.001), tot_loss_proj:1.597 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.597 (perp=7.647, rec=0.066, cos=0.001), tot_loss_proj:1.605 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.589 (perp=7.647, rec=0.059, cos=0.001), tot_loss_proj:1.595 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.585 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.594 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.590 (perp=7.647, rec=0.059, cos=0.001), tot_loss_proj:1.599 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.586 (perp=7.647, rec=0.055, cos=0.001), tot_loss_proj:1.590 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.582 (perp=7.647, rec=0.051, cos=0.001), tot_loss_proj:1.593 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.585 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.593 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.582 (perp=7.647, rec=0.052, cos=0.001), tot_loss_proj:1.589 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.595 (perp=7.647, rec=0.064, cos=0.001), tot_loss_proj:1.585 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=7.647, rec=0.057, cos=0.001), tot_loss_proj:1.596 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.576 (perp=7.647, rec=0.045, cos=0.001), tot_loss_proj:1.587 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.585 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.584 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.584 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.590 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.601 (perp=7.647, rec=0.071, cos=0.001), tot_loss_proj:1.600 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.579 (perp=7.647, rec=0.048, cos=0.001), tot_loss_proj:1.580 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.596 (perp=7.647, rec=0.065, cos=0.001), tot_loss_proj:1.588 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.602 (perp=7.647, rec=0.071, cos=0.001), tot_loss_proj:1.598 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.573 (perp=7.647, rec=0.042, cos=0.001), tot_loss_proj:1.588 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.600 (perp=7.647, rec=0.069, cos=0.001), tot_loss_proj:1.598 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.598 (perp=7.647, rec=0.068, cos=0.001), tot_loss_proj:1.592 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.589 (perp=7.647, rec=0.058, cos=0.001), tot_loss_proj:1.594 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.585 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.595 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.595 (perp=7.647, rec=0.065, cos=0.001), tot_loss_proj:1.593 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.589 (perp=7.647, rec=0.058, cos=0.001), tot_loss_proj:1.593 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.588 (perp=7.647, rec=0.057, cos=0.001), tot_loss_proj:1.607 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.599 (perp=7.647, rec=0.068, cos=0.001), tot_loss_proj:1.591 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.584 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.591 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.589 (perp=7.647, rec=0.059, cos=0.001), tot_loss_proj:1.594 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.589 (perp=7.647, rec=0.058, cos=0.001), tot_loss_proj:1.603 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.590 (perp=7.647, rec=0.059, cos=0.001), tot_loss_proj:1.598 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.518 | p: 92.079 | r: 93.053
rouge2     | fm: 61.567 | p: 61.316 | r: 61.862
rougeL     | fm: 80.468 | p: 80.171 | r: 80.832
rougeLsum  | fm: 80.431 | p: 80.121 | r: 80.833
r1fm+r2fm = 154.084

input #92 time: 0:09:18 | total time: 14:16:17


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9993328041825775
highest_index [0]
highest [0.9993328041825775]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.0106152296066284 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8291399478912354 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.8261485695838928 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 0.8090434074401855 for ['[CLS] solo specificball shrinking lad 1970s judicial [SEP]']
[Init] best perm rec loss: 0.8087723255157471 for ['[CLS] specific 1970sball lad shrinking solo judicial [SEP]']
[Init] best perm rec loss: 0.8081687092781067 for ['[CLS] solo specific judicial shrinkingball 1970s lad [SEP]']
[Init] best perm rec loss: 0.8072903156280518 for ['[CLS] shrinking soloball lad judicial specific 1970s [SEP]']
[Init] best perm rec loss: 0.8065516352653503 for ['[CLS] 1970s solo specific shrinking ladball judicial [SEP]']
[Init] best perm rec loss: 0.8060869574546814 for ['[CLS]ball solo specific shrinking 1970s lad judicial [SEP]']
[Init] best perm rec loss: 0.8057830333709717 for ['[CLS]ball specific lad shrinking 1970s judicial solo [SEP]']
[Init] best perm rec loss: 0.8052436709403992 for ['[CLS] shrinking specific soloball 1970s judicial lad [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.526 (perp=11.130, rec=0.291, cos=0.010), tot_loss_proj:2.883 [t=0.23s]
prediction: ['[CLS] humorous about funny metric struck funny way [SEP]']
[ 100/2000] tot_loss=2.038 (perp=9.082, rec=0.213, cos=0.009), tot_loss_proj:2.183 [t=0.24s]
prediction: ['[CLS] understanding its understanding in struck funny way [SEP]']
[ 150/2000] tot_loss=2.275 (perp=10.750, rec=0.122, cos=0.003), tot_loss_proj:2.507 [t=0.24s]
prediction: ['[CLS] often its understanding in struck funny way [SEP]']
[ 200/2000] tot_loss=2.069 (perp=9.875, rec=0.092, cos=0.002), tot_loss_proj:2.438 [t=0.24s]
prediction: ['[CLS] often its understanding in : funny way [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.709 (perp=8.154, rec=0.077, cos=0.002), tot_loss_proj:1.980 [t=0.24s]
prediction: ['[CLS] often, understanding in its funny way [SEP]']
[ 300/2000] tot_loss=1.701 (perp=8.154, rec=0.069, cos=0.001), tot_loss_proj:1.972 [t=0.24s]
prediction: ['[CLS] often, understanding in its funny way [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.573 (perp=7.511, rec=0.069, cos=0.001), tot_loss_proj:1.796 [t=0.24s]
prediction: ['[CLS], understanding in its often funny way [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.410 (perp=6.705, rec=0.068, cos=0.001), tot_loss_proj:1.696 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 450/2000] tot_loss=1.402 (perp=6.705, rec=0.059, cos=0.001), tot_loss_proj:1.701 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.414 (perp=6.705, rec=0.072, cos=0.001), tot_loss_proj:1.692 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.406 (perp=6.705, rec=0.063, cos=0.001), tot_loss_proj:1.701 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 600/2000] tot_loss=1.404 (perp=6.705, rec=0.062, cos=0.001), tot_loss_proj:1.692 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.411 (perp=6.705, rec=0.069, cos=0.001), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.403 (perp=6.705, rec=0.061, cos=0.001), tot_loss_proj:1.696 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 750/2000] tot_loss=1.402 (perp=6.705, rec=0.059, cos=0.001), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.407 (perp=6.705, rec=0.065, cos=0.001), tot_loss_proj:1.691 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.402 (perp=6.705, rec=0.060, cos=0.001), tot_loss_proj:1.692 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 900/2000] tot_loss=1.408 (perp=6.705, rec=0.066, cos=0.001), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.417 (perp=6.705, rec=0.074, cos=0.001), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.413 (perp=6.705, rec=0.071, cos=0.001), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1050/2000] tot_loss=1.399 (perp=6.705, rec=0.057, cos=0.001), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.407 (perp=6.705, rec=0.064, cos=0.001), tot_loss_proj:1.686 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.399 (perp=6.705, rec=0.056, cos=0.001), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1200/2000] tot_loss=1.402 (perp=6.705, rec=0.059, cos=0.001), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.408 (perp=6.705, rec=0.066, cos=0.001), tot_loss_proj:1.689 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.399 (perp=6.705, rec=0.056, cos=0.001), tot_loss_proj:1.692 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1350/2000] tot_loss=1.396 (perp=6.705, rec=0.053, cos=0.001), tot_loss_proj:1.686 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.402 (perp=6.705, rec=0.059, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.403 (perp=6.705, rec=0.061, cos=0.001), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1500/2000] tot_loss=1.409 (perp=6.705, rec=0.066, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.403 (perp=6.705, rec=0.061, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.414 (perp=6.705, rec=0.072, cos=0.001), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1650/2000] tot_loss=1.405 (perp=6.705, rec=0.063, cos=0.001), tot_loss_proj:1.693 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.397 (perp=6.705, rec=0.054, cos=0.001), tot_loss_proj:1.693 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.404 (perp=6.705, rec=0.061, cos=0.001), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1800/2000] tot_loss=1.407 (perp=6.705, rec=0.065, cos=0.001), tot_loss_proj:1.693 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.404 (perp=6.705, rec=0.062, cos=0.001), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.419 (perp=6.705, rec=0.077, cos=0.001), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1950/2000] tot_loss=1.399 (perp=6.705, rec=0.057, cos=0.001), tot_loss_proj:1.697 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.405 (perp=6.705, rec=0.062, cos=0.001), tot_loss_proj:1.692 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding in its often funny way, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 92.630 | p: 92.195 | r: 93.135
rouge2     | fm: 61.545 | p: 61.343 | r: 61.836
rougeL     | fm: 80.495 | p: 80.201 | r: 80.908
rougeLsum  | fm: 80.493 | p: 80.172 | r: 80.843
r1fm+r2fm = 154.175

input #93 time: 0:09:21 | total time: 14:25:39


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9993172942000517
highest_index [0]
highest [0.9993172942000517]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9766421318054199 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9562913775444031 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9171427488327026 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9082192778587341 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.8862788677215576 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 0.8804725408554077 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 0.8800083994865417 for ['[CLS] internal plum flowering expedition territorial shocks chronic centre crushed rockwellventing [SEP]']
[Init] best perm rec loss: 0.879869282245636 for ['[CLS] shocksventing internal chronic expedition centre rockwell flowering crushed plum territorial [SEP]']
[Init] best perm rec loss: 0.8795231580734253 for ['[CLS]venting plum territorial flowering expedition shocks internal centre chronic rockwell crushed [SEP]']
[Init] best perm rec loss: 0.8793690800666809 for ['[CLS]venting plum expedition shocks crushed chronic centre territorial rockwell flowering internal [SEP]']
[Init] best perm rec loss: 0.8776559829711914 for ['[CLS] chronic plum shocks expedition crushed internal territorialventing centre flowering rockwell [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.873 (perp=12.588, rec=0.340, cos=0.015), tot_loss_proj:3.747 [t=0.23s]
prediction: ['[CLS] or poorlyter restrained pack drug neither bars dungeon neither neither [SEP]']
[ 100/2000] tot_loss=2.414 (perp=11.061, rec=0.194, cos=0.007), tot_loss_proj:2.912 [t=0.23s]
prediction: ['[CLS] or neither original caper neither neither original original neither funny [SEP]']
[ 150/2000] tot_loss=1.968 (perp=9.104, rec=0.142, cos=0.005), tot_loss_proj:2.352 [t=0.23s]
prediction: ['[CLS] s neither original caper a neither original terribly nor funny [SEP]']
[ 200/2000] tot_loss=1.944 (perp=9.104, rec=0.121, cos=0.003), tot_loss_proj:2.345 [t=0.23s]
prediction: ['[CLS] s neither original caper a neither original terribly nor funny [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.922 (perp=8.929, rec=0.133, cos=0.003), tot_loss_proj:2.195 [t=0.23s]
prediction: ['[CLS] s neither original caper that neither original nor terribly funny [SEP]']
[ 300/2000] tot_loss=1.884 (perp=8.929, rec=0.096, cos=0.002), tot_loss_proj:2.220 [t=0.23s]
prediction: ['[CLS] s neither original caper that neither original nor terribly funny [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.791 (perp=8.359, rec=0.115, cos=0.003), tot_loss_proj:2.123 [t=0.23s]
prediction: ['[CLS] s neither that original caper neither original nor terribly funny [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.847 (perp=8.682, rec=0.109, cos=0.002), tot_loss_proj:2.256 [t=0.23s]
prediction: ['[CLS] s neither thatr neither a cape original nor terribly funny [SEP]']
[ 450/2000] tot_loss=1.826 (perp=8.682, rec=0.088, cos=0.002), tot_loss_proj:2.252 [t=0.23s]
prediction: ['[CLS] s neither thatr neither a cape original nor terribly funny [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.637 (perp=7.753, rec=0.085, cos=0.001), tot_loss_proj:2.074 [t=0.23s]
prediction: ['[CLS] s neither that neither a caper original nor terribly funny [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.627 (perp=7.753, rec=0.075, cos=0.001), tot_loss_proj:2.068 [t=0.23s]
prediction: ['[CLS] s neither that neither a caper original nor terribly funny [SEP]']
[ 600/2000] tot_loss=1.617 (perp=7.753, rec=0.065, cos=0.001), tot_loss_proj:2.068 [t=0.23s]
prediction: ['[CLS] s neither that neither a caper original nor terribly funny [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.625 (perp=7.753, rec=0.073, cos=0.001), tot_loss_proj:2.077 [t=0.23s]
prediction: ['[CLS] s neither that neither a caper original nor terribly funny [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.618 (perp=7.753, rec=0.066, cos=0.001), tot_loss_proj:2.080 [t=0.23s]
prediction: ['[CLS] s neither that neither a caper original nor terribly funny [SEP]']
[ 750/2000] tot_loss=1.624 (perp=7.753, rec=0.072, cos=0.001), tot_loss_proj:2.073 [t=0.23s]
prediction: ['[CLS] s neither that neither a caper original nor terribly funny [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.548 (perp=7.385, rec=0.069, cos=0.001), tot_loss_proj:1.976 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.543 (perp=7.385, rec=0.064, cos=0.001), tot_loss_proj:1.984 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
[ 900/2000] tot_loss=1.556 (perp=7.385, rec=0.078, cos=0.001), tot_loss_proj:1.990 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.543 (perp=7.385, rec=0.064, cos=0.001), tot_loss_proj:1.982 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1000/2000] tot_loss=1.536 (perp=7.385, rec=0.058, cos=0.001), tot_loss_proj:1.987 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
[1050/2000] tot_loss=1.541 (perp=7.385, rec=0.063, cos=0.001), tot_loss_proj:1.992 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1100/2000] tot_loss=1.549 (perp=7.385, rec=0.070, cos=0.001), tot_loss_proj:1.993 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1150/2000] tot_loss=1.544 (perp=7.385, rec=0.066, cos=0.001), tot_loss_proj:1.990 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
[1200/2000] tot_loss=1.547 (perp=7.385, rec=0.069, cos=0.001), tot_loss_proj:1.996 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1250/2000] tot_loss=1.551 (perp=7.385, rec=0.073, cos=0.001), tot_loss_proj:1.987 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1300/2000] tot_loss=1.542 (perp=7.385, rec=0.064, cos=0.001), tot_loss_proj:1.982 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
[1350/2000] tot_loss=1.555 (perp=7.385, rec=0.077, cos=0.001), tot_loss_proj:1.990 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1400/2000] tot_loss=1.541 (perp=7.385, rec=0.063, cos=0.001), tot_loss_proj:1.987 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1450/2000] tot_loss=1.535 (perp=7.385, rec=0.057, cos=0.001), tot_loss_proj:1.994 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
[1500/2000] tot_loss=1.551 (perp=7.385, rec=0.072, cos=0.001), tot_loss_proj:1.982 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1550/2000] tot_loss=1.543 (perp=7.385, rec=0.065, cos=0.001), tot_loss_proj:1.993 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1600/2000] tot_loss=1.537 (perp=7.385, rec=0.059, cos=0.001), tot_loss_proj:1.985 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
[1650/2000] tot_loss=1.543 (perp=7.385, rec=0.065, cos=0.001), tot_loss_proj:1.984 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1700/2000] tot_loss=1.550 (perp=7.385, rec=0.072, cos=0.001), tot_loss_proj:1.986 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1750/2000] tot_loss=1.540 (perp=7.385, rec=0.062, cos=0.001), tot_loss_proj:1.983 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
[1800/2000] tot_loss=1.540 (perp=7.385, rec=0.062, cos=0.001), tot_loss_proj:1.987 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1850/2000] tot_loss=1.542 (perp=7.385, rec=0.064, cos=0.001), tot_loss_proj:1.987 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[1900/2000] tot_loss=1.543 (perp=7.385, rec=0.065, cos=0.001), tot_loss_proj:1.989 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
[1950/2000] tot_loss=1.545 (perp=7.385, rec=0.067, cos=0.001), tot_loss_proj:1.992 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Attempt swap
[2000/2000] tot_loss=1.545 (perp=7.385, rec=0.066, cos=0.001), tot_loss_proj:1.995 [t=0.24s]
prediction: ['[CLS] s neither that neither original a caper nor terribly funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] s neither that neither original a caper nor terribly funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 57.143 | p: 54.545 | r: 60.000
rougeL     | fm: 69.565 | p: 66.667 | r: 72.727
rougeLsum  | fm: 69.565 | p: 66.667 | r: 72.727
r1fm+r2fm = 152.795

[Aggregate metrics]:
rouge1     | fm: 92.656 | p: 92.179 | r: 93.214
rouge2     | fm: 61.443 | p: 61.139 | r: 61.727
rougeL     | fm: 80.383 | p: 80.049 | r: 80.763
rougeLsum  | fm: 80.321 | p: 80.019 | r: 80.729
r1fm+r2fm = 154.099

input #94 time: 0:09:17 | total time: 14:34:57


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9991571833716502
highest_index [0]
highest [0.9991571833716502]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9717789888381958 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9435426592826843 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 0.9418174624443054 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.9320042133331299 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 0.9293991923332214 for ['[CLS] oval foster welfarecu range turk partly support turret familiesumatic helping inclinedsteredling [SEP]']
[Init] best rec loss: 0.9255191683769226 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 0.9003634452819824 for ['[CLS] plenty heroes kit operating aim ouby fa physics pinco victim playing cisco feeling [SEP]']
[Init] best rec loss: 0.8562151193618774 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.8513796925544739 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 0.8484290838241577 for ['[CLS] ] damp tech trailer cut privateے hanging block complete monty pressure sister wirenne [SEP]']
[Init] best perm rec loss: 0.8474252820014954 for ['[CLS] cut sister trailer block monty tech damp wire private pressure ] hangingnne completeے [SEP]']
[Init] best perm rec loss: 0.8452731966972351 for ['[CLS] trailer private sisterے wire pressure monty ] damp blocknne hanging cut tech complete [SEP]']
[Init] best perm rec loss: 0.8449822664260864 for ['[CLS] wire montyے private cut pressure hanging sisternne tech complete damp block trailer ] [SEP]']
[Init] best perm rec loss: 0.8435211181640625 for ['[CLS] cut wire damp tech trailer ] pressure private blockے monty complete sister hangingnne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.553 (perp=11.608, rec=0.225, cos=0.006), tot_loss_proj:2.906 [t=0.23s]
prediction: ['[CLS] storage story already, hopeless hopeless hopeless hopelesss became hopeless extremely hopelessential hopeless [SEP]']
[ 100/2000] tot_loss=2.393 (perp=11.187, rec=0.151, cos=0.005), tot_loss_proj:2.747 [t=0.24s]
prediction: ['[CLS]dle story a, hopeless hopeless hopeless hopeless story becomes asatfyingfying hopeless [SEP]']
[ 150/2000] tot_loss=2.574 (perp=12.275, rec=0.115, cos=0.003), tot_loss_proj:3.027 [t=0.24s]
prediction: ['[CLS]dle mud (, hopelessitating hopeless hopeless story becomes asatfyingfying mud [SEP]']
[ 200/2000] tot_loss=2.574 (perp=12.357, rec=0.100, cos=0.003), tot_loss_proj:3.087 [t=0.24s]
prediction: ["[CLS]dle'(, hopeless denis hopeless mud story becomes asatfying denis mud [SEP]"]
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.263 (perp=10.571, rec=0.145, cos=0.004), tot_loss_proj:2.604 [t=0.24s]
prediction: ["[CLS]'(, hopeless denis hopeless hopeless story becomes asatfying s muddle [SEP]"]
[ 300/2000] tot_loss=2.261 (perp=10.789, rec=0.100, cos=0.002), tot_loss_proj:2.613 [t=0.24s]
prediction: ["[CLS]'(, hopeless denis hopeless hopeless story becomes asatfyinges muddle [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.099 (perp=10.057, rec=0.085, cos=0.002), tot_loss_proj:2.422 [t=0.24s]
prediction: ["[CLS]'a a hopeless denis hopeless hopeless story becomes,satfyingis muddle [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.770 (perp=8.374, rec=0.093, cos=0.002), tot_loss_proj:2.121 [t=0.24s]
prediction: ["[CLS]') a hopeless denis hopeless un story becomes,satisfying muddle [SEP]"]
[ 450/2000] tot_loss=1.762 (perp=8.374, rec=0.085, cos=0.002), tot_loss_proj:2.112 [t=0.24s]
prediction: ["[CLS]') a hopeless denis hopeless un story becomes,satisfying muddle [SEP]"]
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.735 (perp=7.983, rec=0.136, cos=0.002), tot_loss_proj:1.998 [t=0.24s]
prediction: ["[CLS]') a hopeless denis un hopeless story becomes,satisfying muddle [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.581 (perp=7.380, rec=0.103, cos=0.002), tot_loss_proj:1.817 [t=0.24s]
prediction: ["[CLS]') a hopeless denis, hopeless story becomes unsatisfying muddle [SEP]"]
[ 600/2000] tot_loss=1.577 (perp=7.380, rec=0.098, cos=0.002), tot_loss_proj:1.825 [t=0.24s]
prediction: ["[CLS]') a hopeless denis, hopeless story becomes unsatisfying muddle [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.507 (perp=7.032, rec=0.098, cos=0.002), tot_loss_proj:1.734 [t=0.24s]
prediction: ["[CLS]'denis ) a hopeless, hopeless story becomes unsatisfying muddle [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.536 (perp=7.187, rec=0.097, cos=0.002), tot_loss_proj:2.048 [t=0.24s]
prediction: ["[CLS]'denis ), ( a hopeless story becomes unsatisfying muddle [SEP]"]
[ 750/2000] tot_loss=1.533 (perp=7.187, rec=0.094, cos=0.002), tot_loss_proj:2.047 [t=0.24s]
prediction: ["[CLS]'denis ), ( a hopeless story becomes unsatisfying muddle [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.325 (perp=6.173, rec=0.088, cos=0.002), tot_loss_proj:1.637 [t=0.24s]
prediction: ["[CLS] ( denis ),'a hopeless story becomes unsatisfying muddle [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.326 (perp=6.173, rec=0.090, cos=0.002), tot_loss_proj:1.639 [t=0.24s]
prediction: ["[CLS] ( denis ),'a hopeless story becomes unsatisfying muddle [SEP]"]
[ 900/2000] tot_loss=1.321 (perp=6.173, rec=0.084, cos=0.002), tot_loss_proj:1.639 [t=0.24s]
prediction: ["[CLS] ( denis ),'a hopeless story becomes unsatisfying muddle [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.317 (perp=6.173, rec=0.080, cos=0.002), tot_loss_proj:1.638 [t=0.24s]
prediction: ["[CLS] ( denis ),'a hopeless story becomes unsatisfying muddle [SEP]"]
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.276 (perp=5.941, rec=0.086, cos=0.002), tot_loss_proj:1.474 [t=0.23s]
prediction: ["[CLS] ( denis ),'story becomes a hopeless unsatisfying muddle [SEP]"]
[1050/2000] tot_loss=1.270 (perp=5.941, rec=0.080, cos=0.002), tot_loss_proj:1.467 [t=0.24s]
prediction: ["[CLS] ( denis ),'story becomes a hopeless unsatisfying muddle [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.217 (perp=5.705, rec=0.074, cos=0.002), tot_loss_proj:1.407 [t=0.24s]
prediction: ["[CLS] ( denis )'story, becomes a hopeless unsatisfying muddle [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.210 (perp=5.705, rec=0.067, cos=0.002), tot_loss_proj:1.404 [t=0.24s]
prediction: ["[CLS] ( denis )'story, becomes a hopeless unsatisfying muddle [SEP]"]
[1200/2000] tot_loss=1.208 (perp=5.705, rec=0.065, cos=0.002), tot_loss_proj:1.411 [t=0.23s]
prediction: ["[CLS] ( denis )'story, becomes a hopeless unsatisfying muddle [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.212 (perp=5.705, rec=0.070, cos=0.002), tot_loss_proj:1.400 [t=0.24s]
prediction: ["[CLS] ( denis )'story, becomes a hopeless unsatisfying muddle [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.211 (perp=5.705, rec=0.068, cos=0.002), tot_loss_proj:1.405 [t=0.23s]
prediction: ["[CLS] ( denis )'story, becomes a hopeless unsatisfying muddle [SEP]"]
[1350/2000] tot_loss=1.218 (perp=5.705, rec=0.075, cos=0.002), tot_loss_proj:1.399 [t=0.24s]
prediction: ["[CLS] ( denis )'story, becomes a hopeless unsatisfying muddle [SEP]"]
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.119 (perp=5.240, rec=0.069, cos=0.002), tot_loss_proj:1.214 [t=0.23s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.125 (perp=5.240, rec=0.076, cos=0.002), tot_loss_proj:1.215 [t=0.24s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
[1500/2000] tot_loss=1.119 (perp=5.240, rec=0.069, cos=0.002), tot_loss_proj:1.215 [t=0.24s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.121 (perp=5.240, rec=0.071, cos=0.002), tot_loss_proj:1.200 [t=0.24s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.127 (perp=5.240, rec=0.078, cos=0.002), tot_loss_proj:1.207 [t=0.23s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
[1650/2000] tot_loss=1.112 (perp=5.240, rec=0.062, cos=0.002), tot_loss_proj:1.208 [t=0.24s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.122 (perp=5.240, rec=0.072, cos=0.002), tot_loss_proj:1.203 [t=0.24s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.122 (perp=5.240, rec=0.072, cos=0.002), tot_loss_proj:1.208 [t=0.23s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
[1800/2000] tot_loss=1.113 (perp=5.240, rec=0.063, cos=0.002), tot_loss_proj:1.208 [t=0.24s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.124 (perp=5.240, rec=0.074, cos=0.002), tot_loss_proj:1.200 [t=0.23s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.126 (perp=5.240, rec=0.076, cos=0.002), tot_loss_proj:1.211 [t=0.29s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
[1950/2000] tot_loss=1.115 (perp=5.240, rec=0.066, cos=0.002), tot_loss_proj:1.211 [t=0.23s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.112 (perp=5.240, rec=0.062, cos=0.002), tot_loss_proj:1.199 [t=0.24s]
prediction: ["[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]"]
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] ( denis )'story becomes a hopeless, unsatisfying muddle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.755 | p: 92.306 | r: 93.301
rouge2     | fm: 61.772 | p: 61.555 | r: 62.100
rougeL     | fm: 80.604 | p: 80.347 | r: 81.030
rougeLsum  | fm: 80.592 | p: 80.241 | r: 81.027
r1fm+r2fm = 154.527

input #95 time: 0:09:23 | total time: 14:44:20


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9992863442853963
highest_index [0]
highest [0.9992863442853963]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8897403478622437 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8798883557319641 for ['[CLS] regrets emotionsoit purpose superior loop released given higher careini speechply springs assist [SEP]']
[Init] best rec loss: 0.860714316368103 for ['[CLS] all nova resolution which assault domestic look mandy headquarteredtated thanlus completion stillboards [SEP]']
[Init] best rec loss: 0.8265302181243896 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 0.8220264911651611 for ['[CLS] flex thought considerationlin kylie ste in gasped somewherese top close christian raised us [SEP]']
[Init] best rec loss: 0.8179569840431213 for ['[CLS] lea corps cellrily smashed unconscious garcia broke intensity baseball urban who reins brigade β [SEP]']
[Init] best rec loss: 0.8156690001487732 for ['[CLS]culus teacher robson colonies now world over enables who obsidianrlerving peacehwa contract [SEP]']
[Init] best rec loss: 0.7906668186187744 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.7905946969985962 for ['[CLS] statue projectile pondered typical living save sounding august spent time smashwords wig eragn memoir [SEP]']
[Init] best perm rec loss: 0.7904244065284729 for ['[CLS] sounding smashwords time typical pondered augustgn memoir projectile spent save wig era statue living [SEP]']
[Init] best perm rec loss: 0.7902461290359497 for ['[CLS] spent august smashwords projectile pondered save sounding living era time wiggn typical memoir statue [SEP]']
[Init] best perm rec loss: 0.789009153842926 for ['[CLS] statue memoir smashwordsgn spent wig typical time projectile sounding save august era living pondered [SEP]']
[Init] best perm rec loss: 0.7879628539085388 for ['[CLS] august living era typical save spent sounding memoirgn projectile time pondered wig smashwords statue [SEP]']
[Init] best perm rec loss: 0.7875304222106934 for ['[CLS] statuegn wig era spent save pondered typical projectile sounding smashwords august time living memoir [SEP]']
[Init] best perm rec loss: 0.7873085141181946 for ['[CLS] smashwords memoir spent august wig projectile statue era sounding typical savegn time pondered living [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.716 (perp=11.942, rec=0.306, cos=0.022), tot_loss_proj:4.062 [t=0.23s]
prediction: ['[CLS] force ( corps lesser blow thomas off people in people easily responsibility in : out [SEP]']
[ 100/2000] tot_loss=2.288 (perp=10.128, rec=0.244, cos=0.018), tot_loss_proj:3.182 [t=0.24s]
prediction: ['[CLS] force mostly men lesser situations thomas cover people in people force ways himself, women [SEP]']
[ 150/2000] tot_loss=2.475 (perp=11.357, rec=0.195, cos=0.009), tot_loss_proj:3.492 [t=0.24s]
prediction: ['[CLS] force lesser men lesser situations thomas lesser people on people force situations himself lesser for [SEP]']
[ 200/2000] tot_loss=2.420 (perp=11.257, rec=0.161, cos=0.008), tot_loss_proj:3.618 [t=0.24s]
prediction: ['[CLS] force lesser men lesser situations thomas lesser people on men force situations himself lesser and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.109 (perp=9.539, rec=0.191, cos=0.011), tot_loss_proj:3.316 [t=0.24s]
prediction: ['[CLS] men and force lesser situations when lesser people on men force situations himself lesser and [SEP]']
[ 300/2000] tot_loss=2.056 (perp=9.519, rec=0.146, cos=0.006), tot_loss_proj:3.396 [t=0.24s]
prediction: ['[CLS] men would make cover situations him lesser people on men force situations himself became and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.890 (perp=8.766, rec=0.132, cos=0.005), tot_loss_proj:3.000 [t=0.24s]
prediction: ['[CLS] men would make cover situations and lesser people on men force situations himself would him [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.787 (perp=8.331, rec=0.116, cos=0.004), tot_loss_proj:3.079 [t=0.24s]
prediction: ['[CLS] men would make him situations and lesser people on men force situations himself would cover [SEP]']
[ 450/2000] tot_loss=1.884 (perp=8.888, rec=0.103, cos=0.004), tot_loss_proj:3.479 [t=0.24s]
prediction: ['[CLS] run would make him situations and lesser people on men force situations himself would cover [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.975 (perp=9.321, rec=0.108, cos=0.003), tot_loss_proj:3.627 [t=0.24s]
prediction: ['[CLS] situations would make was run and lesser people on men force situations himself would cover [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.872 (perp=8.778, rec=0.113, cos=0.003), tot_loss_proj:3.111 [t=0.24s]
prediction: ['[CLS] and make was situations run and lesser people on men force situations himself would cover [SEP]']
[ 600/2000] tot_loss=1.900 (perp=8.946, rec=0.107, cos=0.003), tot_loss_proj:3.296 [t=0.24s]
prediction: ['[CLS] and make was situations run and lesser people on men force situations himself for cover [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.868 (perp=8.769, rec=0.111, cos=0.003), tot_loss_proj:3.529 [t=0.24s]
prediction: ['[CLS] and make was run situations and lesser people on men force situations himself for cover [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.765 (perp=8.341, rec=0.095, cos=0.003), tot_loss_proj:3.455 [t=0.23s]
prediction: ['[CLS] was make and run situations and lesser people on men force situations himself for cover [SEP]']
[ 750/2000] tot_loss=1.800 (perp=8.499, rec=0.098, cos=0.003), tot_loss_proj:3.174 [t=0.22s]
prediction: ['[CLS] that make and run situations and lesser people on men force situations himself for cover [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.852 (perp=8.743, rec=0.100, cos=0.003), tot_loss_proj:3.254 [t=0.22s]
prediction: ['[CLS] make and run situations and on lesser people on men force situations himself for cover [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.786 (perp=8.406, rec=0.102, cos=0.003), tot_loss_proj:3.437 [t=0.22s]
prediction: ['[CLS] make on and run situations and lesser people on men force would himself for cover [SEP]']
[ 900/2000] tot_loss=1.778 (perp=8.406, rec=0.094, cos=0.002), tot_loss_proj:3.437 [t=0.23s]
prediction: ['[CLS] make on and run situations and lesser people on men force would himself for cover [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.663 (perp=7.880, rec=0.084, cos=0.003), tot_loss_proj:3.211 [t=0.22s]
prediction: ['[CLS] make on and run situations and lesser people on men would force himself for cover [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.570 (perp=7.383, rec=0.091, cos=0.003), tot_loss_proj:3.083 [t=0.22s]
prediction: ['[CLS] make on and run situations and people on lesser men would force himself for cover [SEP]']
[1050/2000] tot_loss=1.559 (perp=7.383, rec=0.080, cos=0.003), tot_loss_proj:3.083 [t=0.23s]
prediction: ['[CLS] make on and run situations and people on lesser men would force himself for cover [SEP]']
Attempt swap
[1100/2000] tot_loss=1.558 (perp=7.383, rec=0.079, cos=0.003), tot_loss_proj:3.076 [t=0.24s]
prediction: ['[CLS] make on and run situations and people on lesser men would force himself for cover [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.577 (perp=7.431, rec=0.089, cos=0.003), tot_loss_proj:3.042 [t=0.24s]
prediction: ['[CLS] on make and run situations and people on lesser men would force himself for cover [SEP]']
[1200/2000] tot_loss=1.585 (perp=7.431, rec=0.096, cos=0.003), tot_loss_proj:3.038 [t=0.24s]
prediction: ['[CLS] on make and run situations and people on lesser men would force himself for cover [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.713 (perp=8.073, rec=0.096, cos=0.003), tot_loss_proj:3.085 [t=0.24s]
prediction: ['[CLS] make when and run situations and people on lesser men would force himself for cover [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.573 (perp=7.442, rec=0.082, cos=0.003), tot_loss_proj:3.029 [t=0.24s]
prediction: ['[CLS] when make and run situations and people on lesser men would force himself for cover [SEP]']
[1350/2000] tot_loss=1.577 (perp=7.442, rec=0.086, cos=0.003), tot_loss_proj:3.024 [t=0.24s]
prediction: ['[CLS] when make and run situations and people on lesser men would force himself for cover [SEP]']
Attempt swap
[1400/2000] tot_loss=1.575 (perp=7.442, rec=0.084, cos=0.003), tot_loss_proj:3.032 [t=0.24s]
prediction: ['[CLS] when make and run situations and people on lesser men would force himself for cover [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.519 (perp=7.107, rec=0.094, cos=0.003), tot_loss_proj:3.047 [t=0.24s]
prediction: ['[CLS] when make and force situations and people on lesser men would run himself for cover [SEP]']
[1500/2000] tot_loss=1.509 (perp=7.107, rec=0.085, cos=0.003), tot_loss_proj:3.050 [t=0.24s]
prediction: ['[CLS] when make and force situations and people on lesser men would run himself for cover [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.541 (perp=7.279, rec=0.083, cos=0.003), tot_loss_proj:2.572 [t=0.24s]
prediction: ['[CLS] make and force situations and on people on lesser men would run himself for cover [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.517 (perp=7.128, rec=0.089, cos=0.003), tot_loss_proj:2.892 [t=0.24s]
prediction: ['[CLS] make on and force situations and people on lesser men would run himself for cover [SEP]']
[1650/2000] tot_loss=1.523 (perp=7.128, rec=0.095, cos=0.003), tot_loss_proj:2.887 [t=0.24s]
prediction: ['[CLS] make on and force situations and people on lesser men would run himself for cover [SEP]']
Attempt swap
[1700/2000] tot_loss=1.512 (perp=7.128, rec=0.084, cos=0.003), tot_loss_proj:2.884 [t=0.24s]
prediction: ['[CLS] make on and force situations and people on lesser men would run himself for cover [SEP]']
Attempt swap
[1750/2000] tot_loss=1.519 (perp=7.128, rec=0.091, cos=0.003), tot_loss_proj:2.884 [t=0.24s]
prediction: ['[CLS] make on and force situations and people on lesser men would run himself for cover [SEP]']
[1800/2000] tot_loss=1.516 (perp=7.128, rec=0.088, cos=0.003), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS] make on and force situations and people on lesser men would run himself for cover [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.465 (perp=6.891, rec=0.084, cos=0.003), tot_loss_proj:2.256 [t=0.24s]
prediction: ['[CLS] make and force on situations and people on lesser men would run himself for cover [SEP]']
Attempt swap
[1900/2000] tot_loss=1.464 (perp=6.891, rec=0.083, cos=0.003), tot_loss_proj:2.252 [t=0.24s]
prediction: ['[CLS] make and force on situations and people on lesser men would run himself for cover [SEP]']
[1950/2000] tot_loss=1.460 (perp=6.891, rec=0.079, cos=0.003), tot_loss_proj:2.249 [t=0.24s]
prediction: ['[CLS] make and force on situations and people on lesser men would run himself for cover [SEP]']
Attempt swap
[2000/2000] tot_loss=1.463 (perp=6.891, rec=0.083, cos=0.003), tot_loss_proj:2.249 [t=0.24s]
prediction: ['[CLS] make and force on situations and people on lesser men would run himself for cover [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] make on and force situations and people on lesser men would run himself for cover [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.235 | p: 88.235 | r: 88.235
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 58.824 | p: 58.824 | r: 58.824
rougeLsum  | fm: 58.824 | p: 58.824 | r: 58.824
r1fm+r2fm = 106.985

[Aggregate metrics]:
rouge1     | fm: 92.680 | p: 92.235 | r: 93.176
rouge2     | fm: 61.401 | p: 61.149 | r: 61.673
rougeL     | fm: 80.375 | p: 80.034 | r: 80.755
rougeLsum  | fm: 80.371 | p: 80.006 | r: 80.793
r1fm+r2fm = 154.081

input #96 time: 0:09:18 | total time: 14:53:39


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9991662155443171
highest_index [0]
highest [0.9991662155443171]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.8431113362312317 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.8104252219200134 for ['[CLS] [SEP] crates margarita trip decisionsylus [SEP]']
[Init] best rec loss: 0.8035948872566223 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 0.7755175828933716 for ['[CLS] jealous glennm his = empire [SEP]']
[Init] best rec loss: 0.7488246560096741 for ['[CLS] perfect channel cam working 140et [SEP]']
[Init] best perm rec loss: 0.7483882904052734 for ['[CLS]et cam perfect working 140 channel [SEP]']
[Init] best perm rec loss: 0.7473320364952087 for ['[CLS] cam channel working perfect 140et [SEP]']
[Init] best perm rec loss: 0.7467406988143921 for ['[CLS] channel perfect workinget 140 cam [SEP]']
[Init] best perm rec loss: 0.7466690540313721 for ['[CLS] channel working cam perfect 140et [SEP]']
[Init] best perm rec loss: 0.7466669082641602 for ['[CLS] perfect working channelet 140 cam [SEP]']
[Init] best perm rec loss: 0.7462400794029236 for ['[CLS] working channel cam perfectet 140 [SEP]']
[Init] best perm rec loss: 0.7460934519767761 for ['[CLS] working cam 140 perfectet channel [SEP]']
[Init] best perm rec loss: 0.7458518743515015 for ['[CLS] perfect cam channel working 140et [SEP]']
[Init] best perm rec loss: 0.7445951104164124 for ['[CLS] perfect working cam 140et channel [SEP]']
[Init] best perm rec loss: 0.7433086037635803 for ['[CLS] cam channel perfectet working 140 [SEP]']
[Init] best perm rec loss: 0.743118941783905 for ['[CLS] cam working 140et perfect channel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.540 (perp=11.018, rec=0.313, cos=0.024), tot_loss_proj:3.978 [t=0.23s]
prediction: ['[CLS] unfor betheltable figure generation [SEP]']
[ 100/2000] tot_loss=2.120 (perp=9.472, rec=0.204, cos=0.022), tot_loss_proj:2.629 [t=0.23s]
prediction: ['[CLS]forforgettable characters characters [SEP]']
[ 150/2000] tot_loss=2.028 (perp=9.472, rec=0.129, cos=0.005), tot_loss_proj:2.604 [t=0.24s]
prediction: ['[CLS]forforgettable characters characters [SEP]']
[ 200/2000] tot_loss=1.204 (perp=5.520, rec=0.098, cos=0.002), tot_loss_proj:1.295 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.195 (perp=5.520, rec=0.087, cos=0.004), tot_loss_proj:1.293 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 300/2000] tot_loss=1.183 (perp=5.520, rec=0.078, cos=0.002), tot_loss_proj:1.304 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.165 (perp=5.520, rec=0.059, cos=0.002), tot_loss_proj:1.298 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.161 (perp=5.520, rec=0.056, cos=0.002), tot_loss_proj:1.295 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 450/2000] tot_loss=1.164 (perp=5.520, rec=0.058, cos=0.002), tot_loss_proj:1.299 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.164 (perp=5.520, rec=0.058, cos=0.002), tot_loss_proj:1.292 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.183 (perp=5.514, rec=0.078, cos=0.002), tot_loss_proj:1.382 [t=0.23s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 600/2000] tot_loss=1.183 (perp=5.514, rec=0.079, cos=0.002), tot_loss_proj:1.376 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.174 (perp=5.514, rec=0.069, cos=0.002), tot_loss_proj:1.372 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.388 [t=0.23s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 750/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.395 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.167 (perp=5.514, rec=0.063, cos=0.002), tot_loss_proj:1.381 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.174 (perp=5.514, rec=0.070, cos=0.002), tot_loss_proj:1.375 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 900/2000] tot_loss=1.162 (perp=5.514, rec=0.058, cos=0.002), tot_loss_proj:1.372 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.177 (perp=5.514, rec=0.073, cos=0.002), tot_loss_proj:1.367 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.382 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1050/2000] tot_loss=1.171 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.376 [t=0.23s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.171 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.372 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.167 (perp=5.514, rec=0.062, cos=0.002), tot_loss_proj:1.365 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1200/2000] tot_loss=1.164 (perp=5.514, rec=0.059, cos=0.002), tot_loss_proj:1.374 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.171 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.371 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.174 (perp=5.514, rec=0.069, cos=0.002), tot_loss_proj:1.375 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1350/2000] tot_loss=1.169 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.371 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.167 (perp=5.514, rec=0.063, cos=0.002), tot_loss_proj:1.370 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.174 (perp=5.514, rec=0.070, cos=0.002), tot_loss_proj:1.363 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1500/2000] tot_loss=1.167 (perp=5.514, rec=0.063, cos=0.002), tot_loss_proj:1.370 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.169 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.366 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.172 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.381 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1650/2000] tot_loss=1.175 (perp=5.514, rec=0.070, cos=0.002), tot_loss_proj:1.378 [t=0.23s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.174 (perp=5.514, rec=0.069, cos=0.002), tot_loss_proj:1.365 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.162 (perp=5.514, rec=0.057, cos=0.002), tot_loss_proj:1.372 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1800/2000] tot_loss=1.165 (perp=5.514, rec=0.061, cos=0.002), tot_loss_proj:1.379 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.175 (perp=5.514, rec=0.071, cos=0.002), tot_loss_proj:1.374 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.171 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.376 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1950/2000] tot_loss=1.179 (perp=5.514, rec=0.075, cos=0.002), tot_loss_proj:1.375 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.175 (perp=5.514, rec=0.071, cos=0.002), tot_loss_proj:1.378 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] unforgettable and characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.791 | p: 92.313 | r: 93.309
rouge2     | fm: 61.060 | p: 60.806 | r: 61.349
rougeL     | fm: 80.456 | p: 80.146 | r: 80.814
rougeLsum  | fm: 80.414 | p: 80.062 | r: 80.767
r1fm+r2fm = 153.851

input #97 time: 0:09:19 | total time: 15:02:59


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9991922212899854
highest_index [0]
highest [0.9991922212899854]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.7134081721305847 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.7081572413444519 for ['[CLS] prohibited nos jed ada [SEP]']
[Init] best perm rec loss: 0.70798659324646 for ['[CLS] nos ada prohibited jed [SEP]']
[Init] best perm rec loss: 0.7077512145042419 for ['[CLS] ada nos jed prohibited [SEP]']
[Init] best perm rec loss: 0.7026987075805664 for ['[CLS] nos jed ada prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.569 (perp=11.687, rec=0.221, cos=0.011), tot_loss_proj:3.191 [t=0.22s]
prediction: ['[CLS] unfulful boarding [SEP]']
[ 100/2000] tot_loss=2.255 (perp=10.618, rec=0.126, cos=0.005), tot_loss_proj:2.538 [t=0.22s]
prediction: ['[CLS] unfulfullling [SEP]']
[ 150/2000] tot_loss=1.066 (perp=4.948, rec=0.074, cos=0.002), tot_loss_proj:1.067 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 200/2000] tot_loss=1.060 (perp=4.948, rec=0.069, cos=0.002), tot_loss_proj:1.064 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.067 (perp=4.948, rec=0.073, cos=0.005), tot_loss_proj:1.066 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.064 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.062 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.058 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.059 (perp=4.948, rec=0.068, cos=0.002), tot_loss_proj:1.065 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.061 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.064 (perp=4.948, rec=0.073, cos=0.002), tot_loss_proj:1.061 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.067 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.065 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.053 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.062 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.059 (perp=4.948, rec=0.068, cos=0.002), tot_loss_proj:1.066 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.053 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.057 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.051 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.053 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.059 (perp=4.948, rec=0.068, cos=0.002), tot_loss_proj:1.065 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.044 (perp=4.948, rec=0.052, cos=0.002), tot_loss_proj:1.062 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.068 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.036 (perp=4.948, rec=0.045, cos=0.002), tot_loss_proj:1.056 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.052 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.042 (perp=4.948, rec=0.051, cos=0.002), tot_loss_proj:1.057 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.055 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.061 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.053 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.067 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.050 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.058 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.043 (perp=4.948, rec=0.052, cos=0.002), tot_loss_proj:1.048 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.057 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.060 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.065 (perp=4.948, rec=0.074, cos=0.002), tot_loss_proj:1.056 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.059 (perp=4.948, rec=0.068, cos=0.002), tot_loss_proj:1.064 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.060 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.058 (perp=4.948, rec=0.067, cos=0.002), tot_loss_proj:1.060 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.059 (perp=4.948, rec=0.068, cos=0.002), tot_loss_proj:1.047 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.059 (perp=4.948, rec=0.068, cos=0.002), tot_loss_proj:1.059 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.062 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.062 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.058 (perp=4.948, rec=0.067, cos=0.002), tot_loss_proj:1.054 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.857 | p: 92.418 | r: 93.372
rouge2     | fm: 61.369 | p: 61.099 | r: 61.658
rougeL     | fm: 80.601 | p: 80.309 | r: 80.968
rougeLsum  | fm: 80.599 | p: 80.270 | r: 80.971
r1fm+r2fm = 154.226

input #98 time: 0:08:41 | total time: 15:11:41


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.999309739415734
highest_index [0]
highest [0.999309739415734]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8733632564544678 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8684595823287964 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8659393191337585 for ['[CLS] freedom lay third cartwright u to tear supply disputed glasses operahus album [MASK] literature bart now associatedtmenty thou stated microphone poly frederick rogers lineshtake furport modern point rosewood mid early [SEP]']
[Init] best rec loss: 0.8593382239341736 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.8483469486236572 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 0.8376026749610901 for ['[CLS] sealed−1 bearing anticipated laps advanced champion priest unit ottoman match party fluidprint cord eric boom twice raf chain [ key bank growing 2009 south reaching words completely sin asked read tehranzziness [CLS] bottles [SEP]']
[Init] best rec loss: 0.8301820158958435 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 0.8222801685333252 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.8184991478919983 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.8171400427818298 for ['[CLS] still barbie dental cushion distance whente screens taste ratings temps currently earliest himselfaging services garcia slight forced orientˈ re synonym te [MASK] thunder knowledge bearing right actuallyts ferns opposed bet claire harper [SEP]']
[Init] best perm rec loss: 0.8165922164916992 for ['[CLS] te bearing taste actually right dental forced harper opposed ferns re distance garcia bettste cushion orient still screens temps synonym ratings himself slightaging when barbie thunder services currently [MASK] knowledge claire earliestˈ [SEP]']
[Init] best perm rec loss: 0.8164383769035339 for ['[CLS] re harper knowledge claire cushionˈ currently bearing dental screensaging still right temps slight earliest services taste [MASK] forcedtets te thunder himself distance ratings barbie actually orient ferns when bet opposed garcia synonym [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.683 (perp=11.831, rec=0.300, cos=0.017), tot_loss_proj:3.095 [t=0.22s]
prediction: ['[CLS] walked out his horrible [CLS] junction stupid wanted out film but they passengersenting blow products heavily weeks several hadssing but scandal raped inca like prizessing affairs festival - then guilty harmonic filmssing [SEP]']
[ 100/2000] tot_loss=2.414 (perp=10.940, rec=0.217, cos=0.009), tot_loss_proj:3.460 [t=0.22s]
prediction: ["[CLS] walked out film ` ` junctionssing ride out film but began immediately them ` films heavily di these helpedssing had fun terrible and like ticketssing obviously festival,'fees whose filmssing [SEP]"]
[ 150/2000] tot_loss=4.078 (perp=11.724, rec=0.940, cos=0.793), tot_loss_proj:3.982 [t=0.22s]
prediction: ['[CLS] walked out lower villages..ssingnivorous trails film and. [SEP] [SEP] oregon upstream [SEP] arboretum several [SEP] was has fun waterfall lies practicesʔssing.⊕ of modified [SEP] nests.ssing [SEP]']
[ 200/2000] tot_loss=4.169 (perp=11.617, rec=0.891, cos=0.954), tot_loss_proj:4.025 [t=0.22s]
prediction: ['[CLS] walked out lower villages..ssingnivorous trails film and. [SEP] [SEP] oregon upstream [SEP] arboretum is [SEP] was has fun waterfall lies practicesʔssing.⊕ of modified [SEP] nests.ssing [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.840 (perp=10.909, rec=0.820, cos=0.838), tot_loss_proj:3.992 [t=0.22s]
prediction: ['[CLS] walked is [SEP] was has fun waterfall economic practicesʔssing out lower villages..ssing trail filly film and. [SEP] [SEP] oregon upstream [SEP] arboretum.⊕ of legislator [SEP] vineyard.ssing [SEP]']
[ 300/2000] tot_loss=3.045 (perp=10.977, rec=0.641, cos=0.209), tot_loss_proj:3.837 [t=0.22s]
prediction: ['[CLS] walked is the was has fun workers economic practicesʔssing out fremont villages..ssing trail filly film but. [SEP] [SEP] oregon upstream [SEP] arboretum.⊕ of plaintiffs [SEP] nests. [SEP] [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.819 (perp=10.587, rec=0.574, cos=0.127), tot_loss_proj:3.920 [t=0.22s]
prediction: ['[CLS] walked is the film but was has fun workers economic practicesʔssing out fremont villages..ssing vineyards filly. [SEP] [SEP] oregon horsepower [SEP] arboretum.⊕ of plaintiffs [SEP] nests. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.741 (perp=10.509, rec=0.540, cos=0.099), tot_loss_proj:4.053 [t=0.22s]
prediction: ['[CLS] walked is [MASK] film but was has fun workers economic practicesʔssing out fremont villages..ssing vineyards railroad. [SEP]⊕ oregon horsepower [SEP] arboretum. [SEP] of is [SEP] nests. [SEP] [SEP]']
[ 450/2000] tot_loss=2.719 (perp=10.609, rec=0.513, cos=0.083), tot_loss_proj:4.037 [t=0.22s]
prediction: ['[CLS] walked several [MASK] film but is has fun workers economic practices romanizedssing out fremont villages..ssing vineyards railroad. [SEP] capitalist oregon horsepower [SEP] arboretum, [SEP] of is and nests. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.643 (perp=10.415, rec=0.487, cos=0.073), tot_loss_proj:3.972 [t=0.22s]
prediction: ['[CLS] walked several [MASK] film but is has fun capitalist economic practices romanizedssing out fremont villages..ssing vineyards locomotives. [SEP] workers oregon horsepowerdae arboretum, [SEP] of is and nests. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.590 (perp=10.274, rec=0.471, cos=0.064), tot_loss_proj:3.889 [t=0.22s]
prediction: ['[CLS] walked. [MASK] film but is has fun capitalist economic practices romanizedssing out pennsylvania villages. severalssing vineyards billboard. [SEP] workers adults horsepowerdae arboretum, [SEP] of is and nests. [SEP] [SEP]']
[ 600/2000] tot_loss=2.626 (perp=10.528, rec=0.462, cos=0.058), tot_loss_proj:3.956 [t=0.22s]
prediction: ['[CLS] walked. [MASK] film but is has fun capitalist is practices romanizedssing out pennsylvania villages. severalssing gmina train. [SEP] workers adults upstreamdae arboretum, [SEP] of is and nests. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.548 (perp=10.245, rec=0.446, cos=0.053), tot_loss_proj:3.900 [t=0.22s]
prediction: ['[CLS] walked. [MASK] film but is has fun capitalist is practices romanizedssing out pennsylvania villages. [SEP]ssing gmina train. is workers adults centsdae arboretum, [SEP] of is and nests. [SEP] [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.641 (perp=10.513, rec=0.467, cos=0.072), tot_loss_proj:3.411 [t=0.22s]
prediction: ['[CLS] walked [SEP] a is film but is has [SEP] capitalist practices romanizedssing out pennsylvania villages. [SEP]ssing gmina train. is workers adults genusdae arboretum, [SEP] of is and goats. [SEP] [SEP]']
[ 750/2000] tot_loss=2.622 (perp=10.658, rec=0.438, cos=0.053), tot_loss_proj:3.628 [t=0.22s]
prediction: ['[CLS] walked [SEP] a is film but is has [SEP]↔ practices romanizedssing out pennsylvania villages. [SEP]ssing gmina train. is workers adults genusdae arboretum, [SEP] of is and goats. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.557 (perp=10.428, rec=0.426, cos=0.046), tot_loss_proj:3.761 [t=0.22s]
prediction: ['[CLS] walked is a [SEP] film but is has [SEP]↔ practices romanizedssing out pennsylvania villages. [SEP]ssing gmina train. is skater adults genusdae arboretum, [SEP] of is and goats. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.574 (perp=10.576, rec=0.416, cos=0.042), tot_loss_proj:3.781 [t=0.24s]
prediction: ['[CLS] walked is a [SEP] film but is has [SEP]☉ system romanizedssing out wren villages. [SEP]ssing gmina train. is workers adults genus and arboretum, [SEP] of isdae goats. [SEP] [SEP]']
[ 900/2000] tot_loss=2.580 (perp=10.667, rec=0.406, cos=0.040), tot_loss_proj:3.793 [t=0.24s]
prediction: ['[CLS] walked is a [SEP] film but is has [SEP]☉ system romanizedssing out wren villages. [SEP]ssing gmina train. is workersrite genus and arboretum, [SEP] of isdae goats. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.494 (perp=10.239, rec=0.409, cos=0.038), tot_loss_proj:3.745 [t=0.24s]
prediction: ['[CLS] walked is a romanized film but is has [SEP]☉ system [SEP]ssing out wren villages. [SEP]ssing gmina train. is workersrite genus and arboretum, [SEP] of isdae goats. [SEP] [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.446 (perp=10.001, rec=0.409, cos=0.037), tot_loss_proj:3.625 [t=0.24s]
prediction: ['[CLS] walked is a romanized film but is has [SEP]☉ system [SEP]ssing out is villages. [SEP]ssing gmina train. they workersrite genus and arboretum, [SEP] of wrendae goats. [SEP] [SEP]']
[1050/2000] tot_loss=2.436 (perp=10.020, rec=0.397, cos=0.035), tot_loss_proj:3.697 [t=0.24s]
prediction: ['[CLS] walked is a romanized film but is has [SEP]☉ system [SEP]ssing out is villages. [SEP]ssing gmina train. they adultsrite genus the arboretum, [SEP] of wrendae goats. [SEP] [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.393 (perp=9.816, rec=0.395, cos=0.035), tot_loss_proj:3.724 [t=0.24s]
prediction: ['[CLS] walked is a romanized film but is. [SEP]☉ system [SEP]ssing out is villages. [SEP]ssing gmina train has they adultsrite genus the arboretum, [SEP] of wrendae goats. [SEP] [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.375 (perp=9.748, rec=0.392, cos=0.034), tot_loss_proj:3.282 [t=0.24s]
prediction: ['[CLS] walked is a romanized film but is out. [SEP]☉ system [SEP]ssing is villages. [SEP]ssing gmina train has they adultsrite genus the botanical, [SEP] of wrendae goats. [SEP] [SEP]']
[1200/2000] tot_loss=2.432 (perp=10.080, rec=0.384, cos=0.033), tot_loss_proj:3.391 [t=0.24s]
prediction: ['[CLS] walked is [MASK] romanized film but is out. [SEP]☉ system [SEP]ssing is villages. [SEP]ssing gmina train has they adultsrite genus the botanical, [SEP] of wrendae goats. [SEP] [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.409 (perp=9.955, rec=0.387, cos=0.032), tot_loss_proj:3.301 [t=0.24s]
prediction: ['[CLS] walked is [MASK] romanized, but is out. [SEP]↔ system [SEP]ssing is villages. [SEP]ssing gmina bonds has they adultsrite genus the botanical film [SEP] of wrendae goats. [SEP] [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.380 (perp=9.806, rec=0.387, cos=0.031), tot_loss_proj:3.309 [t=0.24s]
prediction: ['[CLS] walked is [MASK] romanized, but is out. [SEP]↔ system [SEP]ssing is villages. [SEP]ssing gminaacies has they adultsrite the botanical film [SEP] genus of wren [SEP] goats. [SEP] [SEP]']
[1350/2000] tot_loss=2.416 (perp=10.008, rec=0.385, cos=0.030), tot_loss_proj:3.218 [t=0.24s]
prediction: ['[CLS] walked is [MASK] romanized, but is out. [SEP]↔ system [SEP]ssing is villages. [SEP]ssingmityacies has they adultsrite the botanical film [SEP] genus of wren [SEP] goats.ssing [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.377 (perp=9.863, rec=0.375, cos=0.030), tot_loss_proj:3.172 [t=0.24s]
prediction: ['[CLS] walked is [MASK] romanized, but is out. [SEP]ssing system [SEP]↔ is villages. [SEP]ssingmityacies has they adultsrite the botanical film [SEP] genus of wren [SEP] goats.ssing [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.380 (perp=9.841, rec=0.382, cos=0.029), tot_loss_proj:3.354 [t=0.24s]
prediction: ['[CLS] walked is [MASK] out, but is romanized. [SEP]ssing system [SEP]↔ is villages. [SEP]ssingmityacies has they adultsrite the botanical film [SEP] genus of wren [SEP] goats.ssing [SEP]']
[1500/2000] tot_loss=2.399 (perp=9.982, rec=0.373, cos=0.029), tot_loss_proj:3.266 [t=0.24s]
prediction: ['[CLS] walked the [MASK] out, but is romanized. [SEP]ssing system [SEP]↔ is villages. [SEP]ssingmityacies has they adultsrite the botanical film [SEP] genus of wren [SEP] goats.ssing [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.366 (perp=9.816, rec=0.374, cos=0.029), tot_loss_proj:3.289 [t=0.24s]
prediction: ['[CLS] walked the goats out, but is romanized. [SEP]ssing system [SEP]↔ is villages. [SEP]ssingmityacies has they adultsrite the botanical film [SEP] genus of wren [SEP] [MASK].ssing [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.339 (perp=9.649, rec=0.380, cos=0.029), tot_loss_proj:3.314 [t=0.24s]
prediction: ['[CLS] walked the goats out, but is romanized. [SEP]ssing system [SEP]↔ is villages. [SEP]ssingmityacies. they adultsrite the botanical film [SEP] genus of wren [SEP] [MASK] hasssing [SEP]']
[1650/2000] tot_loss=2.330 (perp=9.649, rec=0.371, cos=0.029), tot_loss_proj:3.315 [t=0.24s]
prediction: ['[CLS] walked the goats out, but is romanized. [SEP]ssing system [SEP]↔ is villages. [SEP]ssingmityacies. they adultsrite the botanical film [SEP] genus of wren [SEP] [MASK] hasssing [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.307 (perp=9.541, rec=0.369, cos=0.029), tot_loss_proj:3.336 [t=0.24s]
prediction: ['[CLS] walked the goats out, but is romanized. [SEP]ssing system [SEP]↔ is villages. [SEP]ssingmityacies. they adultsrite the botanical film genus of wren [SEP] [MASK] has [SEP]ssing [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.277 (perp=9.369, rec=0.375, cos=0.028), tot_loss_proj:3.278 [t=0.24s]
prediction: ['[CLS] walked the goats out, but is romanized. [SEP]ssing system [SEP]↔ is [MASK]. [SEP]ssingmityacies. they adultsrite the botanical film genus of wren [SEP] villages has [SEP]! [SEP]']
[1800/2000] tot_loss=2.270 (perp=9.369, rec=0.369, cos=0.027), tot_loss_proj:3.281 [t=0.24s]
prediction: ['[CLS] walked the goats out, but is romanized. [SEP]ssing system [SEP]↔ is [MASK]. [SEP]ssingmityacies. they adultsrite the botanical film genus of wren [SEP] villages has [SEP]! [SEP]']
Attempt swap
[1850/2000] tot_loss=2.256 (perp=9.310, rec=0.367, cos=0.027), tot_loss_proj:2.680 [t=0.24s]
prediction: ['[CLS] walked the goats out, but is romanized. [SEP]ssing system [SEP]↔ is [MASK]. [SEP]ssingmityacies. they adults abuse the botanical film genus of wrendae villages has [SEP]! [SEP]']
Attempt swap
[1900/2000] tot_loss=2.252 (perp=9.310, rec=0.364, cos=0.026), tot_loss_proj:2.670 [t=0.24s]
prediction: ['[CLS] walked the goats out, but is romanized. [SEP]ssing system [SEP]↔ is [MASK]. [SEP]ssingmityacies. they adults abuse the botanical film genus of wrendae villages has [SEP]! [SEP]']
[1950/2000] tot_loss=2.248 (perp=9.310, rec=0.360, cos=0.026), tot_loss_proj:2.677 [t=0.24s]
prediction: ['[CLS] walked the goats out, but is romanized. [SEP]ssing system [SEP]↔ is [MASK]. [SEP]ssingmityacies. they adults abuse the botanical film genus of wrendae villages has [SEP]! [SEP]']
Attempt swap
[2000/2000] tot_loss=2.299 (perp=9.535, rec=0.366, cos=0.026), tot_loss_proj:3.280 [t=0.24s]
prediction: ['[CLS] walked the goats out, but is romanized. [SEP]ssing system [SEP]↔ is a. [SEP]ssingmityacies. they adults hurdles the botanical film genus of wrendae villages has [SEP]! [SEP]']
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] walked out film `'troublessing ticket out film but had immediately them ` films heavily di the helpedssing had fun terrible and like ticketssing tamil festival,'fees whose filmssing [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 47.273 | p: 44.828 | r: 50.000
rouge2     | fm: 11.321 | p: 10.714 | r: 12.000
rougeL     | fm: 25.455 | p: 24.138 | r: 26.923
rougeLsum  | fm: 25.455 | p: 24.138 | r: 26.923
r1fm+r2fm = 58.593

[Aggregate metrics]:
rouge1     | fm: 92.344 | p: 91.894 | r: 92.938
rouge2     | fm: 60.934 | p: 60.684 | r: 61.308
rougeL     | fm: 80.017 | p: 79.694 | r: 80.371
rougeLsum  | fm: 80.045 | p: 79.667 | r: 80.470
r1fm+r2fm = 153.278

input #99 time: 0:09:12 | total time: 15:20:53


Average Cosine Similarity: 0.9992812812989129
Done with all.
